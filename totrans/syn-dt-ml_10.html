<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer081">
<h1 class="chapter-number" id="_idParaDest-175"><a id="_idTextAnchor178"/>10</h1>
<h1 id="_idParaDest-176"><a id="_idTextAnchor179"/>Case Study 1 – Computer Vision</h1>
<p>In this chapter, you will be introduced to a multitude of industrial applications of computer vision. You will discover some of the key problems that were successfully solved using computer vision. In parallel to this, you will grasp the major issues with traditional computer vision solutions. Additionally, you will explore and comprehend thought-provoking examples of using synthetic data to improve computer vision solutions <span class="No-Break">in practice.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Industrial revolutions – computer vision as <span class="No-Break">a solution</span></li>
<li>Synthetic data and computer vision – examples <span class="No-Break">from industry</span></li>
</ul>
<h1 id="_idParaDest-177"><a id="_idTextAnchor180"/>Transforming industries – the power of computer vision</h1>
<p>In this section, we’ll briefly discuss the main four industrial revolutions as they help us to better comprehend the historical context of AI, data, and computer vision. Then, we will learn why computer vision is becoming an integral component of our <span class="No-Break">modern industries.</span></p>
<h2 id="_idParaDest-178"><a id="_idTextAnchor181"/>The four waves of the industrial revolution</h2>
<p><strong class="bold">Industrial revolution</strong> refers<a id="_idIndexMarker457"/> to a global and rapid transformation in the economy. Usually, this transformation brings and utilizes new inventions, discoveries, and technologies to make manufacturing and production processes more efficient. The history of the industrial revolutions can be summarized into <span class="No-Break">four stages:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer080">
<img alt="Figure 10.1 – Industrial revolutions" height="468" src="image/Figure_10_01_B18494.jpg" width="1256"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – Industrial revolutions</p>
<p>Next, let’s discuss each of the industrial revolutions shown in <span class="No-Break"><em class="italic">Figure 10</em></span><em class="italic">.1</em> in <span class="No-Break">greater depth.</span></p>
<h3>Industry 1.0</h3>
<p>This refers to the first industrial<a id="_idIndexMarker458"/> revolution, which happened in the early 19th century. It supplemented, supported, and enhanced existing labor processes by incorporating machinery; animals and manual labor were mostly replaced with water and steam engines. It was a great shift toward using machinery to carry out mostly the same tasks but more efficiently. This opened the door for new industries, such as iron production, which significantly influenced the development of industries such as construction, transportation, and manufacturing. Industry 1.0 changed the way products were produced, which laid the foundation for the next revolution <span class="No-Break">in industry.</span></p>
<h3>Industry 2.0</h3>
<p>Electricity was the <a id="_idIndexMarker459"/>major driver of the substantial shift in production that happened with Industry 2.0. Assembly line production and the widespread adoption of electricity as a power source facilitated mass production. In parallel to that, the great advancement in steelmaking and production enabled the building of more sophisticated and powerful machinery. This set the stage for the following <span class="No-Break">industrial revolution.</span></p>
<h3>Industry 3.0</h3>
<p>Electricity <a id="_idIndexMarker460"/>was one of the discoveries that changed our civilization dramatically, including communication and industry. With mass production, which is considered one of the main themes of Industry 2.0, there was an urgent need for automation to minimize errors and maximize efficiency. Thus, computers were utilized by manufacturers to achieve yet more precise and <span class="No-Break">efficient productions.</span></p>
<h3>Industry 4.0</h3>
<p>The digital transformations<a id="_idIndexMarker461"/> of most industries, great competition between global companies, and scarce resources all opened the door for cyber-physical systems and thus <strong class="bold">smart factories</strong>. Consequently, AI, robotics, and <strong class="bold">big data</strong> started to attract more attention in<a id="_idIndexMarker462"/> industry and academia. Since the main properties of this industrial revolution are great <a id="_idIndexMarker463"/>efficiency, customized products, and services, ML and data are the gems of achieving <span class="No-Break">these aims.</span></p>
<p>Next, we will see why computer vision is the backbone of many of our <span class="No-Break">current industries.</span></p>
<h2 id="_idParaDest-179"><a id="_idTextAnchor182"/>Industry 4.0 and computer vision</h2>
<p>Computer vision is an<a id="_idIndexMarker464"/> interdisciplinary field that enables machines to understand images. Computer vision is an essential component of our current industrial revolution. It has been widely applied for quality control, safety assurance, predictive maintenance, and<a id="_idIndexMarker465"/> other essential and critical applications. Next, let’s discuss the main uses of computer vision in the <span class="No-Break">following fields:</span></p>
<ul>
<li><span class="No-Break">Manufacturing</span></li>
<li><span class="No-Break">Autonomous driving</span></li>
<li><span class="No-Break">Healthcare</span></li>
<li><span class="No-Break">Agriculture</span></li>
<li>Surveillance <span class="No-Break">and security</span></li>
</ul>
<h3>Manufacturing</h3>
<p>In manufacturing<a id="_idIndexMarker466"/> industries, human error can cause significant delays that affect the entire production pipeline. It may even cause damage to machines and infrastructures, injuries, and death. Computer vision comes as a solution to complement, support, or replace the human element in the process. Computer vision can be utilized to guide the assembly and manufacturing processes to achieve higher throughput with lower costs and <span class="No-Break">higher quality.</span></p>
<p>Contact lens manufacturers worked with <em class="italic">ADLINK</em> and <em class="italic">LEDA</em> that have used computer vision to automate the contact lens inspection process. This task was usually performed by human inspectors where thousands of lenses were visually inspected each day. It was a time-consuming process where errors were not avoidable. By deploying ADLINK and LEDA’s computer vision-based solution, the company which manufactures contact lenses was able to make its inspection process 3 times more accurate and 50 times faster! Their novel solution removes the human element from the process, which substantially increases the scalability and quality of the inspection process. For more information about this use case, please refer to <em class="italic">ADLINK and LEDA Technology Create AI-Enabled Contact Lens Inspection </em><span class="No-Break"><em class="italic">Solution</em></span><span class="No-Break"> (</span><a href="https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf"><span class="No-Break">https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf</span></a><span class="No-Break">).</span></p>
<h3>Autonomous driving</h3>
<p>This is one of the main <a id="_idIndexMarker467"/>sectors that is closely associated with computer vision. <strong class="bold">Autonomous driving</strong> technology can reduce human errors in <a id="_idIndexMarker468"/>driving and thus minimize accidents, injuries, and death. In 2022, the number of road traffic fatalities exceeded 46,200 cases in the US (<a href="https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states">https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states</a>). Thus, computer vision presents a promising safe, efficient, and productive solution. Self-driving companies such as <em class="italic">Tesla</em>, <em class="italic">Waymo</em>, and <em class="italic">Mobileye</em> have already started utilizing computer vision for lane detection and tracking, pedestrian detection, object recognition, and traffic sign detection and recognition. As you may guess, the failure of such computer vision algorithms can cause damage to property, severe injuries, or death. Thus, training and developing a robust computer vision algorithm is a hot topic for ML researchers and is gaining more momentum and receiving <span class="No-Break">more attention.</span></p>
<p><strong class="bold">Tesla cars</strong> have <a id="_idIndexMarker469"/>developed a computer vision system based on neural networks that takes video inputs from different cameras. Then, it processes the visual information and predicts the road layout, static objects, pedestrians, and other vehicles in the scene. For more information, please refer to <em class="italic">Tesla – AI &amp; </em><span class="No-Break"><em class="italic">Robotics</em></span><span class="No-Break"> (</span><a href="https://www.tesla.com/AI"><span class="No-Break">https://www.tesla.com/AI</span></a><span class="No-Break">).</span></p>
<p><strong class="bold">Aurora Driver</strong> is a <a id="_idIndexMarker470"/>computer vision system that can be utilized for autonomous driving. The system learns to fuse information collected from various sensors, such as lidar, radar, and cameras, to provide an understanding of the driving environment. For more information, check out <em class="italic">Perception at Aurora: No measurement left </em><span class="No-Break"><em class="italic">behind</em></span><span class="No-Break"> (</span><a href="https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind"><span class="No-Break">https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind</span></a><span class="No-Break">).</span></p>
<p>Next, let’s move on to computer vision applications in the <span class="No-Break">healthcare sector.</span></p>
<h3>Healthcare</h3>
<p>Computer vision <a id="_idIndexMarker471"/>revolutionized the field of healthcare thanks to its great ability to analyze large amounts of patient data and provide quick, accurate, and efficient diagnoses. Computer vision algorithms can assist healthcare practitioners, surgeons, and physicians in making accurate and timely decisions that can reduce costs, improve treatments and operations, and reduce <span class="No-Break">human errors.</span></p>
<p>A multitude of healthcare providers have already started harnessing computer vision’s potential in this field. Let’s highlight two examples from <em class="italic">Viz.ai</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">Paige</em></span><span class="No-Break">.</span></p>
<p><strong class="bold">Viz.ai</strong> utilizes <a id="_idIndexMarker472"/>computer vision algorithms to identify signs of a stroke by analyzing patients’ medical<a id="_idIndexMarker473"/> images. They deploy these algorithms to efficiently analyze <strong class="bold">Computerized Tomography</strong> (<strong class="bold">CT</strong>) and <strong class="bold">Magnetic Resonance Imaging</strong> (<strong class="bold">MRI</strong>) scans and<a id="_idIndexMarker474"/> notify neurologists if a sign of a stroke is present to take the <span class="No-Break">appropriate action.</span></p>
<p><strong class="bold">Paige</strong> is another <a id="_idIndexMarker475"/>company that has deployed computer vision to improve diagnostics and predictive tests of pathologists. In a recent study by <em class="italic">Yale Medicine</em> on the effectiveness of Paige Prostate (the name of their computer vision tool), 1,876 predictions by this system classified as “suspicious” were reviewed by professional pathologists. The study concluded that only 31.4% of biopsies had to be reviewed by pathologists. Thus, this tool can indeed improve the productivity of pathologists. Additionally, it demonstrated that this tool could improve the detection of prostate cancer especially when being reviewed by non-genitourinary specialized pathologists. For more details, refer to <em class="italic">An independent assessment of AI for prostate cancer </em><span class="No-Break"><em class="italic">detection</em></span><span class="No-Break"> (</span><a href="https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection"><span class="No-Break">https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection</span></a><span class="No-Break">).</span></p>
<p>In the following section, let’s examine computer vision applications in the <span class="No-Break">agriculture field.</span></p>
<h3>Agriculture</h3>
<p>A recent report<a id="_idIndexMarker476"/> published by the <strong class="bold">Food Security Information Network</strong> (<strong class="bold">FSIN</strong>) titled <em class="italic">Global Report on Food Crises 2023</em> (<a href="https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf">https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf</a>) raised a<a id="_idIndexMarker477"/> red flag about the current and future food insecurity in 58 countries. The report highlighted that almost 250 million people were facing severe food insecurity in 2022, which was a large increase from 2021, when the number was around 190 million. According to experts, the situation is just going to become worse in <span class="No-Break">the future.</span></p>
<p>Many companies, such as <em class="italic">Taranis</em> and <em class="italic">Prospera,</em> utilize computer vision to guide farmers to better optimize resources, analyze crop data, continuously monitor crops, and detect potential issues, such as pests and diseases. Let’s talk in more detail about Taranis <span class="No-Break">and Prospera.</span></p>
<p><strong class="bold">Taranis</strong> is a <a id="_idIndexMarker478"/>company focused on developing technologies that help agriculture businesses and farmers to improve their crop quality, yield, and profit. It utilizes drones and computer vision to analyze farms and make the treatment more efficient. The technology developed is used to efficiently control large farms at the leaf level, which is almost impossible without computer vision. For more information, please refer to the <a id="_idIndexMarker479"/>company <span class="No-Break">website (</span><a href="https://www.taranis.com"><span class="No-Break">https://www.taranis.com</span></a><span class="No-Break">).</span></p>
<p><strong class="bold">Prospera</strong> is <a id="_idIndexMarker480"/>another company that relies on computer vision to support farmers. The technology helps them control pivots, pumps, and other aspects of the irrigation system. Additionally, it continuously monitors crop health and instantly detects any issues. For more<a id="_idIndexMarker481"/> details, refer to the company <span class="No-Break">website (</span><a href="https://prospera.ag"><span class="No-Break">https://prospera.ag</span></a><span class="No-Break">).</span></p>
<p>As you may expect, these key traditional computer vision solutions can be further enhanced by utilizing synthetic data as a complementary or alternative to real data. Now, let’s delve into the main issues with these computer vision solutions, stemming from their significant reliance on <span class="No-Break">real data.</span></p>
<p>As we have discussed in previous chapters, computer vision algorithms that are based on real data usually suffer from the <span class="No-Break">following issues:</span></p>
<ul>
<li>Insufficient <span class="No-Break">training data</span></li>
<li>Data quality issues <span class="No-Break">and bias</span></li>
<li><span class="No-Break">Limited variability</span></li>
</ul>
<p>In the next section, you will learn how and why industries have started incorporating synthetic data in their computer <span class="No-Break">vision-based solutions.</span></p>
<h3>Surveillance and security</h3>
<p>One of the <a id="_idIndexMarker482"/>main key capabilities of computer vision is accurately and efficiently analyzing visual information, such as images and videos. For example, it can be leveraged for the <span class="No-Break">following aims:</span></p>
<ul>
<li>Detecting <span class="No-Break">unusual behaviors</span></li>
<li>Identifying suspicious people, items, <span class="No-Break">or actions</span></li>
<li>License <span class="No-Break">plate recognition</span></li>
<li>Biometric identification: face, iris, palm print, vein, voice, and <span class="No-Break">fingerprint recognition</span></li>
</ul>
<p>Thus, computer vision can be leveraged to prevent unauthorized access, protect people and assets, and identify security threats and risks in real time. Computer vision is used these days to ensure public safety. For example, it is used in airports, public transport, streets, parks, and other public spaces. Many companies have been successfully deploying computer vision for security and surveillance <a id="_idIndexMarker483"/>problems, such <a id="_idIndexMarker484"/>as Hikvision (<a href="https://www.hikvision.com">https://www.hikvision.com</a>), Avigilon (<a href="https://www.avigilon.com">https://www.avigilon.com</a>), Verkada (<a href="https://www.verkada.com">https://www.verkada.com</a>), Huawei, Google, Microsoft, and Amazon. Let’s <a id="_idIndexMarker485"/>delve into one interesting case study with Fujitsu and its interesting use of computer vision to monitor and smooth traffic flows <span class="No-Break">in Montreal.</span></p>
<p>The city of Montreal struggled with many issues related to traffic flow because of factors such as limited entry and exit points, insufficient road infrastructure, and an inadequate traffic management system. As a solution, Fujitsu proposed a computer vision-based solution for most traffic issues. The system collects data from CCTV cameras, more than 2,500 traffic lights, and other sensors. Then, the system makes a real-time decision to optimize the traffic flow. The computer vision-based solution has reduced travel time, air pollution, and other traffic-related issues. For more details, please refer to <em class="italic">Smoothing traffic flows with AI </em><span class="No-Break"><em class="italic">analysis </em></span><span class="No-Break">(</span><a href="https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701"><span class="No-Break">https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701</span></a><span class="No-Break">).</span></p>
<h1 id="_idParaDest-180"><a id="_idTextAnchor183"/>Synthetic data and computer vision – examples from industry</h1>
<p>In this section, you will learn about and understand how companies have just started using synthetic data-based computer vision solutions to stand out from competitors and overcome real data limitations <span class="No-Break">and issues.</span></p>
<h2 id="_idParaDest-181"><a id="_idTextAnchor184"/>Neurolabs using synthetic data in retail</h2>
<p>According to <em class="italic">Getting Availability Right: Bringing Out-of-Stocks Under Control</em> (<a href="https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf">https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf</a>), out-of-stock items<a id="_idIndexMarker486"/> cause heavy financial losses and dissatisfied customers. The consequences can be dramatic on businesses and revenues. At the same time, collecting and annotating large-scale real data for this task is an expensive and time-consuming process. Neurolabs, an ML company specializing in providing solutions in retail automation, investigated an elegant solution using synthetic data for this issue. They utilized Unity and their own synthetic data <a id="_idIndexMarker487"/>generator to generate 1,200 images of 129 unique <strong class="bold">Stock Keeping Units</strong> (<strong class="bold">SKUs</strong>) on shelves. The dataset is named CPGDet-129 and can be downloaded from this link (<a href="https://dl.orangedox.com/SampleRetailSyntheticDataset">https://dl.orangedox.com/SampleRetailSyntheticDataset</a>) . Additionally, for more details about the dataset and license, please refer to the GitHub repository (<a href="https://github.com/neurolaboratories/reshelf-detection">https://github.com/neurolaboratories/reshelf-detection</a>). The dataset was automatically generated and labeled. Moreover, it specifically supports object detection tasks. Training a state-of-the-art object detection algorithm on their synthetic dataset alone, without using any real data, they were able to achieve 60% <strong class="bold">Mean Average Precision</strong> (<strong class="bold">mAP</strong>) on a real test <a id="_idIndexMarker488"/>dataset. mAP is a metric used to tell us how accurate the object detection model is at predicting the bounding boxes around the objects of interest. Higher values of the mAP score indicate that our model is making <span class="No-Break">accurate predictions.</span></p>
<p>This is a perfect example showing how synthetic data can be deployed to solve complex computer <a id="_idIndexMarker489"/>vision problems <span class="No-Break">in practice.</span></p>
<p>For more details, please refer to <a href="https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5">https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5</a> <span class="No-Break">and </span><a href="https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production"><span class="No-Break">https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor185"/>Microsoft using synthetic data alone for face analysis</h2>
<p>Face analysis such as<a id="_idIndexMarker490"/> face parsing and landmark localization is fundamental for modern industry. The applications range from security and advertising to medical diagnosis. Using synthetic data for face analysis seems inescapable as annotating real images for these tasks not only is extremely hard but also brings ethical and privacy issues. You can refer to <a href="B18494_03.xhtml#_idTextAnchor049"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, where we discussed <span class="No-Break">these issues.</span></p>
<p>Microsoft is one of the pioneer companies in face recognition technologies. They have many years of research and development in this area. <em class="italic">Face API</em> is just one example (<a href="https://azure.microsoft.com/en-gb/products/cognitive-services/face">https://azure.microsoft.com/en-gb/products/cognitive-services/face</a>). Their recent work, titled <em class="italic">Fake it till you make it: face analysis in the wild using synthetic data alone</em> (<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf">https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf</a>), is an excellent demonstration of how synthetic data can be deployed in <span class="No-Break">computer vision.</span></p>
<p>The researchers in this work first procedurally generated photorealistic synthetic faces. They used a template face and then randomized the hair, clothes, expression, and, essentially, identity. They simulated these faces in random environments. The synthetic dataset they have generated contains 100,000 synthetic faces with ground-truth annotations, including 2D dense face landmarks and per-pixel face parts <span class="No-Break">semantic segmentation.</span></p>
<p>They trained face parsing and landmark localization ML models on their generated synthetic data alone without using any real images. Their experimental results show that the trained ML models were able to achieve superior results on real datasets. For example, their synthetic-data-trained ML model was able to predict 10 times more landmarks as compared to real-data-trained ML ones. They claim that this success is due to the superiority of their synthetic training data. They emphasize that it is impossible for human annotators to accurately label that many landmarks in practice. Additionally, they show that their synthetic data generation pipeline can be easily adapted to generate synthetic training data for other computer vision tasks, such as eye-tracking. They simply add a virtual eye-tracking camera and generate training images with the corresponding<a id="_idIndexMarker491"/> ground truth. To download the dataset, you can refer to their GitHub <span class="No-Break">repository (</span><a href="https://microsoft.github.io/FaceSynthetics"><span class="No-Break">https://microsoft.github.io/FaceSynthetics</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-183"><a id="_idTextAnchor186"/>Synthesis AI using synthetic data for virtual try-on</h2>
<p>Virtual fashion<a id="_idIndexMarker492"/> is gaining more momentum because it provides a sustainable solution that, unlike traditional fashion, reduces cost and effort. Additionally, it provides a scalable and more personalized solution for companies and customers. Furthermore, it opens more opportunities for creativity, collaboration, and social impact. For this industry to flourish and achieve the intended outcomes, computer vision technologies need to excel at a number of tasks, such as pose estimation, semantic segmentation, visual object detection, and tracking. <em class="italic">Synthesis AI</em> proposed an elegant solution by using synthetic photorealistic 3D humans with huge variations in body type, gender, ethnicity, age, height, and other attributes. They were able to generate depth maps, surface normals, segmentation maps, and many other annotations. For more details, please refer to <em class="italic">Synthesis AI Virtual Try-on</em> (<a href="https://synthesis.ai/applications/virtual-try-on">https://synthesis.ai/applications/virtual-try-on</a>). Additionally, they experimentally demonstrated the usability of the generated synthetic data for a number of tasks, such as face segmentation, background matting, and facial landmark detection. They found that fine-tuning on real data after pretraining on synthetic data achieves the best results as compared to training on real data or synthetic data alone or even a mixture of both. To explore the case study in more detail, please refer to <em class="italic">Synthetic Data Case Studies: It Just </em><span class="No-Break"><em class="italic">Works</em></span><span class="No-Break"> (</span><a href="https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works"><span class="No-Break">https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works</span></a><span class="No-Break">).</span></p>
<h1 id="_idParaDest-184"><a id="_idTextAnchor187"/>Summary</h1>
<p>In summary, you were introduced to various industrial applications of computer vision. You learned why and how computer vision is shaping the future of our modern industry. Moreover, you explored two case studies of companies that started to utilize synthetic data for their computer <span class="No-Break">vision-based solutions.</span></p>
<p>In the next chapter, you will delve into another set of interesting case studies in the field of natural <span class="No-Break">language processing.</span></p>
</div>
</div></body></html>