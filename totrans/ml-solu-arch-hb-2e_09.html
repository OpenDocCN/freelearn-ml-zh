<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer153">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 class="chapterTitle" id="_idParaDest-230"><span class="koboSpan" id="kobo.2.1">Designing an Enterprise ML Architecture with AWS ML Services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">Many organizations opt to build enterprise ML platforms to support numerous fast-moving initiatives. </span><span class="koboSpan" id="kobo.3.2">These platforms are designed to facilitate the entire ML lifecycle and accommodate various usage patterns, all while emphasizing automation and scalability. </span><span class="koboSpan" id="kobo.3.3">As a practitioner, I often get asked to provide architectural guidance for creating such enterprise ML platforms. </span><span class="koboSpan" id="kobo.3.4">In this chapter, we will explore the fundamental requirements for designing enterprise ML platforms. </span><span class="koboSpan" id="kobo.3.5">We will cover a range of topics, such as workflow automation, infrastructure scalability, and system monitoring.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">Throughout the discussion, you will gain insights into architecture patterns that enable the development of technology solutions to automate the end-to-end ML workflow and ensure seamless deployment at a large scale. </span><span class="koboSpan" id="kobo.4.2">Additionally, we will delve deep into essential components of enterprise ML architecture, such as model training, model hosting, the feature store, and the model registry, all tailored to meet the demands of enterprise-level operations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.5.1">AI risk, governance, and security are other important considerations for enterprise ML platforms, and we will cover them in greater detail in </span><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapters 12</span></em><span class="koboSpan" id="kobo.7.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.8.1">13</span></em><span class="koboSpan" id="kobo.9.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.10.1">In a nutshell, the following topics will be covered in this chapter:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.11.1">Key considerations for ML platforms</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.12.1">Key requirements for an enterprise ML platform</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.13.1">Enterprise ML architecture pattern overview</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.14.1">Adopting MLOps for an ML workflow</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.15.1">Best practices in building and operating ML platforms</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-231"><span class="koboSpan" id="kobo.16.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.17.1">We will continue to use the AWS environment for the hands-on portion of this chapter. </span><span class="koboSpan" id="kobo.17.2">All the source code mentioned in this chapter can be found at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter09"><span class="url"><span class="koboSpan" id="kobo.18.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter09</span></span></a><span class="koboSpan" id="kobo.19.1">.</span></p>
<h1 class="heading-1" id="_idParaDest-232"><span class="koboSpan" id="kobo.20.1">Key considerations for ML platforms</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.21.1">Designing, building, and operating ML platforms are complex endeavors as there are many different </span><a id="_idIndexMarker834"/><span class="koboSpan" id="kobo.22.1">considerations, including the personas, key ML process workflows, and various technical capability requirements for the different personas and workflows. </span><span class="koboSpan" id="kobo.22.2">In this section, we will delve into each of these key considerations in depth. </span><span class="koboSpan" id="kobo.22.3">Let’s dive in!</span></p>
<h2 class="heading-2" id="_idParaDest-233"><span class="koboSpan" id="kobo.23.1">The personas of ML platforms and their requirements</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.24.1">In the</span><a id="_idIndexMarker835"/><span class="koboSpan" id="kobo.25.1"> previous chapter, we talked about building a data science environment for the data scientists and ML engineers who mainly focus on experimentation and model development. </span><span class="koboSpan" id="kobo.25.2">In an enterprise setting where an ML platform is needed, there are other personas involved, each with their own specific requirements. </span><span class="koboSpan" id="kobo.25.3">At a high level, there are two types of personas associated with the ML platform: ML platform builders and ML platform users.</span></p>
<h3 class="heading-3" id="_idParaDest-234"><span class="koboSpan" id="kobo.26.1">ML platform builders</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.27.1">ML platform builders</span><a id="_idIndexMarker836"/><span class="koboSpan" id="kobo.28.1"> have the crucial responsibility of constructing the infrastructure for data and ML platforms. </span><span class="koboSpan" id="kobo.28.2">Here are some essential builder types required to build a cloud-based ML platform:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.29.1">Cloud infrastructure architect/engineer</span></strong><span class="koboSpan" id="kobo.30.1">: These experts design the overall cloud infrastructure, selecting </span><a id="_idIndexMarker837"/><span class="koboSpan" id="kobo.31.1">appropriate cloud services and setting up the foundation for the ML platform.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.32.1">Security engineer</span></strong><span class="koboSpan" id="kobo.33.1">: Security engineers </span><a id="_idIndexMarker838"/><span class="koboSpan" id="kobo.34.1">ensure that the ML platform adheres to industry-standard security practices, safeguarding sensitive data and protecting against potential threats.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.35.1">ML platform product manager</span></strong><span class="koboSpan" id="kobo.36.1">: ML</span><a id="_idIndexMarker839"/><span class="koboSpan" id="kobo.37.1"> platform product managers are responsible for understanding functional user requirements and non-functional requirements, defining ML platform capabilities and the implementation roadmap. </span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.38.1">ML platform engineers</span></strong><span class="koboSpan" id="kobo.39.1">: ML platform</span><a id="_idIndexMarker840"/><span class="koboSpan" id="kobo.40.1"> engineers are responsible for designing, building, and maintaining the infrastructure and systems that support the end-to-end ML lifecycle within an organization. </span><span class="koboSpan" id="kobo.40.2">ML platform engineers play a crucial role in ensuring that data scientists and ML practitioners can efficiently develop, deploy, and manage ML models on the organization’s ML platform. </span><span class="koboSpan" id="kobo.40.3">They are responsible for the platform design, covering </span><a id="_idIndexMarker841"/><span class="koboSpan" id="kobo.41.1">key functional areas such as training and hosting, taking into account scalability, performance, security, and integration with existing systems.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.42.1">Data engineers</span></strong><span class="koboSpan" id="kobo.43.1">: Data engineers </span><a id="_idIndexMarker842"/><span class="koboSpan" id="kobo.44.1">are responsible for building data pipelines, data storage solutions, and data processing frameworks to ensure seamless data access and processing for ML tasks.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.45.1">ML platform tester</span></strong><span class="koboSpan" id="kobo.46.1">: ML platform</span><a id="_idIndexMarker843"/><span class="koboSpan" id="kobo.47.1"> testers are responsible for testing the core capabilities of platforms to meet the desired functional and non-functional requirements.</span></li>
</ul>
<h3 class="heading-3" id="_idParaDest-235"><span class="koboSpan" id="kobo.48.1">Platform users and operators</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.49.1">Platform</span><a id="_idIndexMarker844"/><span class="koboSpan" id="kobo.50.1"> users and operators are the actual users of an ML platform. </span><span class="koboSpan" id="kobo.50.2">They use the ML platform to perform full lifecycle ML tasks from data exploration to model monitoring. </span><span class="koboSpan" id="kobo.50.3">The following are some of the key platform user and operator types:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">Data scientists/ML engineers</span></strong><span class="koboSpan" id="kobo.52.1">: Data scientists and ML engineers are the primary users</span><a id="_idIndexMarker845"/><span class="koboSpan" id="kobo.53.1"> of an ML platform. </span><span class="koboSpan" id="kobo.53.2">They use the platform to explore data, build and train ML models, perform feature engineering, and evaluate model performance. </span><span class="koboSpan" id="kobo.53.3">They partner with ML platform engineers and ops engineers to integrate trained models into production systems, optimize model inference </span><a id="_idIndexMarker846"/><span class="koboSpan" id="kobo.54.1">performance, and ensure the models are scalable and reliable in real-world environments.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">Model tester and validator</span></strong><span class="koboSpan" id="kobo.56.1">: The primary responsibilities for a model tester involve assessing</span><a id="_idIndexMarker847"/><span class="koboSpan" id="kobo.57.1"> the performance and reliability of ML models developed by data scientists using the ML platform. </span><span class="koboSpan" id="kobo.57.2">Specifically, model testers are responsible for model testing using different datasets, model performance metrics calculation and evaluation, overfitting/underfitting detection, and testing edge cases. </span><span class="koboSpan" id="kobo.57.3">Model validators are responsible for validating models against business objectives, risk assessment, and other issues such as ethics considerations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.58.1">Model approver</span></strong><span class="koboSpan" id="kobo.59.1">: This </span><a id="_idIndexMarker848"/><span class="koboSpan" id="kobo.60.1">individual or team is responsible for reviewing and approving the deployment of ML models into production or other critical environments. </span><span class="koboSpan" id="kobo.60.2">The model approver’s primary role is to ensure that the developed ML models meet the organization’s standards, business requirements, and compliance policies before they are deployed. </span><span class="koboSpan" id="kobo.60.3">They also help ensure all the required testing, post-deployment operations, and policies are in place.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.61.1">Operations and support engineers</span></strong><span class="koboSpan" id="kobo.62.1">: This </span><a id="_idIndexMarker849"/><span class="koboSpan" id="kobo.63.1">role ensures the smooth operation, maintenance, and ongoing support of the ML platform within an organization. </span><span class="koboSpan" id="kobo.63.2">Their </span><a id="_idIndexMarker850"/><span class="koboSpan" id="kobo.64.1">responsibilities encompass various technical and operational aspects to keep the ML platform running efficiently and to provide assistance to users. </span><span class="koboSpan" id="kobo.64.2">Some of the key functions include platform maintenance and upgrades, performance monitoring and optimization, incident management, infrastructure management, security and access control, and platform documentation.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.65.1">AI risk/governance manager</span></strong><span class="koboSpan" id="kobo.66.1">: The primary responsibility of an AI risk/governance </span><a id="_idIndexMarker851"/><span class="koboSpan" id="kobo.67.1">manager is to manage and mitigate the potential risks associated with the use of AI/ML systems. </span><span class="koboSpan" id="kobo.67.2">Their role is essential in ensuring that AI technologies are developed, deployed, and used responsibly, ethically, and in compliance with relevant regulations. </span><span class="koboSpan" id="kobo.67.3">They help ensure appropriate processes, policies, and technology standards are created and adhered to.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.68.1">You might wonder where the ML solutions architect fits into this overall picture. </span><span class="koboSpan" id="kobo.68.2">The ML solutions architect plays a pivotal role that spans builders, users, and operators. </span><span class="koboSpan" id="kobo.68.3">They serve as a </span><a id="_idIndexMarker852"/><span class="koboSpan" id="kobo.69.1">bridge between these groups, offering valuable insights and guidance. </span><span class="koboSpan" id="kobo.69.2">Firstly, ML solutions architect collaborate with builders, understanding user requirements, and assisting in the end-to-end architecture design. </span><span class="koboSpan" id="kobo.69.3">They ensure that the ML platform aligns with the specific needs of users and operators. </span><span class="koboSpan" id="kobo.69.4">Secondly, ML solutions architects advise users and operators on effectively utilizing the ML platform. </span><span class="koboSpan" id="kobo.69.5">They educate them on best practices for configuring and leveraging the platform to meet diverse needs and use cases.</span></p>
<h2 class="heading-2" id="_idParaDest-236"><span class="koboSpan" id="kobo.70.1">Common workflow of an ML initiative</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.71.1">Different </span><a id="_idIndexMarker853"/><span class="koboSpan" id="kobo.72.1">organizations have diverse workflows and governance processes when running ML initiatives. </span><span class="koboSpan" id="kobo.72.2">However, most of these workflows typically consist of the following key steps:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.73.1">Collecting and processing data from different sources and making it available for data scientists.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.74.1">Performing data exploratory analysis, forming hypotheses, creating ML features, performing experimentation, and building different ML models using different techniques and ML algorithms using a subset of data.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.75.1">A data labeling workflow is sometimes needed to label training data for supervised ML tasks such as document classification or object detection.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.76.1">Conducting full model training and tuning using a full dataset.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.77.1">Candidate models trained using the full dataset are promoted into a testing environment for formal quality assurance. </span><span class="koboSpan" id="kobo.77.2">Testers document testing details for all the testers and verify if the models meet desired performance metrics and other evaluation criteria, such as latency and scalability. </span><span class="koboSpan" id="kobo.77.3">Model validators evaluate the ML techniques, perform an analysis of the model, and check the alignment with the business outcome.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.78.1">Model risk assessment is performed to ensure risk items are assessed, mitigated, or accepted.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.79.1">After the model passes the testing and validation step, the model is sent to the model approver for final review and approval for production deployment.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.80.1">The model is deployed into production with approval. </span><span class="koboSpan" id="kobo.80.2">The model is registered in the model registry, the dataset is versioned and retained, any code artifacts are also versioned and stored, and detailed training configuration details are also documented.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.81.1">The model is monitored in production for model performance, data drift, system issues, and security exposure and attacks. </span><span class="koboSpan" id="kobo.81.2">The incident management process is followed to address issues identified.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.82.1">At required schedules, auditors perform end-to-end audits to ensure all processes and policies are followed, artifacts are stored, access to systems and models is properly logged, documentation meets the required standards, and any violations are flagged and escalated.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.83.1">It is worth </span><a id="_idIndexMarker854"/><span class="koboSpan" id="kobo.84.1">noting that these steps are not exhaustive. </span><span class="koboSpan" id="kobo.84.2">Depending on the organizational, risk, and regulatory requirements, organizations can carry out more steps to address these requirements.</span></p>
<h2 class="heading-2" id="_idParaDest-237"><span class="koboSpan" id="kobo.85.1">Platform requirements for the different personas</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.86.1">ML </span><a id="_idIndexMarker855"/><span class="koboSpan" id="kobo.87.1">platforms involve a diverse array of potential players and users. </span><span class="koboSpan" id="kobo.87.2">The following table outlines the essential needs for ML platforms for both users and operators of the platform. </span><span class="koboSpan" id="kobo.87.3">Note that the table does not include the builder of the platform.</span></p>
<table class="table-container" id="table001-1">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.88.1">User/operator</span></strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.89.1">Tools/capability requirements</span></strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.90.1">Data scientist</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.91.1">Access to various ML libraries, tools, and frameworks for model development and experimentation</span></p>
<p class="normal"><span class="koboSpan" id="kobo.92.1">Access to different datasets to perform different ML tasks</span></p>
<p class="normal"><span class="koboSpan" id="kobo.93.1">Capabilities to perform data exploration and model training using different hardware</span></p>
<p class="normal"><span class="koboSpan" id="kobo.94.1">Workflow automation including data retrieval and processing, feature engineering, experimentation, model building, and model versioning for reproducibility</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.95.1">Model tester and validator</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.96.1">Access to different test datasets for model testing and validation</span></p>
<p class="normal"><span class="koboSpan" id="kobo.97.1">Access to various libraries and tools for data visualization, model evaluation, an ML testing framework, bias detection tools, model interpretability tools, and statistical testing tools</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.98.1">Model approvers</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.99.1">Access to model documentation, model evaluation metrics, a compliance checklist, and a model explainability report</span></p>
<p class="normal"><span class="koboSpan" id="kobo.100.1">Access to an approval workflow management tool</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.101.1">Ops and support engineers</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.102.1">Access to all infrastructure components within the ML platform, including code and container repositories, library packages, training, hosting, pipelines, logging, monitoring and alerting, security and access control, backup and discovery, performance testing, and incident management tools</span></p>
<p class="normal"><span class="koboSpan" id="kobo.103.1">Access to tools for platform automation and management</span></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.104.1">AI risk officer</span></p>
</td>
<td class="table-cell">
<p class="normal"><span class="koboSpan" id="kobo.105.1">Access to an AI risk assessment tool, a governance platform, model explainability and interpretability tools, bias detection and fairness assessment tools, AI risk reporting and dashboards, and AI regulation and policy monitoring</span></p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref"><span class="koboSpan" id="kobo.106.1">Table 9.1: ML platform requirements by personas</span></p>
<p class="normal"><span class="koboSpan" id="kobo.107.1">In</span><a id="_idIndexMarker856"/><span class="koboSpan" id="kobo.108.1"> summary, the success of an ML platform relies heavily on meeting the distinct tools and capability requirements of its users/operators. </span><span class="koboSpan" id="kobo.108.2">By addressing these distinct needs, the ML platform can effectively support its users and operators in building, deploying, and managing AI solutions with confidence.</span></p>
<h1 class="heading-1" id="_idParaDest-238"><span class="koboSpan" id="kobo.109.1">Key requirements for an enterprise ML platform</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.110.1">To deliver business</span><a id="_idIndexMarker857"/><span class="koboSpan" id="kobo.111.1"> benefits through ML at scale, organizations must have the capability to rapidly experiment with diverse scientific approaches, ML technologies, and extensive datasets. </span><span class="koboSpan" id="kobo.111.2">Once ML models are trained and validated, they need to seamlessly transition to production deployment. </span><span class="koboSpan" id="kobo.111.3">While some similarities exist between a traditional enterprise software system and an ML platform, such as scalability and security concerns, an enterprise ML platform presents distinctive challenges. </span><span class="koboSpan" id="kobo.111.4">These include the need to integrate with the data platform and high-performance computing infrastructure to facilitate large-scale model training.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.112.1">Let’s delve into some specific core requirements of an enterprise ML platform to meet the needs of different users and operators:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.113.1">Support for the end-to-end ML lifecycle</span></strong><span class="koboSpan" id="kobo.114.1">: An enterprise ML platform must cater to both data science experimentation and production-grade operations and deployments. </span><span class="koboSpan" id="kobo.114.2">In </span><em class="italic"><span class="koboSpan" id="kobo.115.1">Chapter 8</span></em><span class="koboSpan" id="kobo.116.1">, </span><em class="italic"><span class="koboSpan" id="kobo.117.1">Building a Data Science Environment Using AWS ML Services,</span></em><span class="koboSpan" id="kobo.118.1"> we explored the essential architecture components required to construct a data science experimentation environment using AWS ML services. </span><span class="koboSpan" id="kobo.118.2">However, to facilitate seamless production-grade operations and deployment, the enterprise ML platform should also include specific architecture components dedicated to large-scale model training, model management, feature management, and highly available and scalable model hosting.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.119.1">Support for continuous integration (CI), continuous training (CT), and continuous deployment (CD)</span></strong><span class="koboSpan" id="kobo.120.1">: In addition to testing and validating code and components, an enterprise ML platform extends</span><a id="_idIndexMarker858"/><span class="koboSpan" id="kobo.121.1"> its CI capabilities to include data and models. </span><span class="koboSpan" id="kobo.121.2">The </span><a id="_idIndexMarker859"/><span class="koboSpan" id="kobo.122.1">CD capability for ML goes beyond merely deploying a single software piece; it involves managing both ML models and inference engines in conjunction. </span><span class="koboSpan" id="kobo.122.2">CT is </span><a id="_idIndexMarker860"/><span class="koboSpan" id="kobo.123.1">a unique aspect of ML, wherein a model is continuously monitored, and automated model retraining can be triggered upon detecting data drift, model drift, or changes in the training data. </span><span class="koboSpan" id="kobo.123.2">Data drift refers to a change in the data wherein the statistical characteristics of the production data differ from the data used for model training. </span><span class="koboSpan" id="kobo.123.3">On the other hand, model drift signifies a decline in model performance compared to the performance achieved during the model training phase.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.124.1">Operations support</span></strong><span class="koboSpan" id="kobo.125.1">: An enterprise ML platform should provide capabilities to monitor</span><a id="_idIndexMarker861"/><span class="koboSpan" id="kobo.126.1"> the statuses, errors, and metrics of different pipeline workflows, processing/training jobs, model behavior changes, data drift, and model-serving engines. </span><span class="koboSpan" id="kobo.126.2">Additionally, infrastructure-level statistics and resource usage are continuously monitored to ensure efficient operations. </span><span class="koboSpan" id="kobo.126.3">An automated alert mechanism is a crucial component of operations, promptly notifying relevant stakeholders of any issues or anomalies. </span><span class="koboSpan" id="kobo.126.4">Moreover, implementing automated failure recovery mechanisms wherever possible further enhances the platform’s robustness and minimizes downtime, ensuring smooth and reliable ML operations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.127.1">Support for different languages and ML frameworks</span></strong><span class="koboSpan" id="kobo.128.1">: An enterprise ML platform empowers data scientists and ML engineers to use their preferred programming languages and ML libraries. </span><span class="koboSpan" id="kobo.128.2">It should accommodate popular languages like Python and R, along with well-known ML frameworks such as TensorFlow, PyTorch, and scikit-learn. </span><span class="koboSpan" id="kobo.128.3">This flexibility ensures that teams can leverage their expertise and utilize the most suitable tools for efficient and effective model development within the platform.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.129.1">Computing hardware resource management</span></strong><span class="koboSpan" id="kobo.130.1">: An enterprise ML platform should cater to diverse model training and inference requirements, taking into account cost considerations. </span><span class="koboSpan" id="kobo.130.2">This entails providing support for various types of computing hardware, such as CPUs and GPUs, to optimize performance and cost-effectiveness. </span><span class="koboSpan" id="kobo.130.3">Furthermore, the platform should be equipped to handle specialized ML hardware, like AWS’s Inferentia and Tranium chips, wherever relevant, to leverage the benefits of specialized hardware accelerators for specific ML workloads.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.131.1">Integration with other third-party systems and software</span></strong><span class="koboSpan" id="kobo.132.1">: An enterprise ML platform rarely operates in isolation. </span><span class="koboSpan" id="kobo.132.2">It must offer robust integration capabilities with various third-party software and platforms, including workflow</span><a id="_idIndexMarker862"/><span class="koboSpan" id="kobo.133.1"> orchestration tools, container registries, and code repositories. </span><span class="koboSpan" id="kobo.133.2">This seamless integration enables smooth collaboration and interoperability, allowing teams to leverage existing tools and workflows while benefiting from the advanced features and capabilities of the ML platform.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.134.1">Authentication and authorization</span></strong><span class="koboSpan" id="kobo.135.1">: For an enterprise ML platform, ensuring secure access to data, artifacts, and ML platform resources is essential. </span><span class="koboSpan" id="kobo.135.2">This requires offering various levels of authentication and authorization control. </span><span class="koboSpan" id="kobo.135.3">The platform may include built-in authentication and authorization capabilities, or it can integrate with an external authentication and authorization service.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.136.1">Data encryption</span></strong><span class="koboSpan" id="kobo.137.1">: In regulated industries like financial services and healthcare, data encryption is a critical requirement. </span><span class="koboSpan" id="kobo.137.2">An enterprise ML platform must offer robust capabilities for encrypting data both at rest and in transit, often allowing customers to manage their encryption keys. </span><span class="koboSpan" id="kobo.137.3">This level of data protection ensures that sensitive information remains secure and compliant with industry regulations, providing the necessary reassurance for handling confidential data within these sectors.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.138.1">Artifact management</span></strong><span class="koboSpan" id="kobo.139.1">: In the ML lifecycle, an enterprise ML platform handles datasets and generates various artifacts at different stages. </span><span class="koboSpan" id="kobo.139.2">These artifacts can be features, code, models, and containers. </span><span class="koboSpan" id="kobo.139.3">To ensure reproducibility and adhere to governance and compliance standards, the platform must possess the capability to track, manage, and version-control these artifacts. </span><span class="koboSpan" id="kobo.139.4">By effectively managing and recording the changes made throughout the ML process, the platform maintains a clear and organized record, facilitating the reproducibility of results and providing a reliable audit trail for compliance purposes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.140.1">ML library package management</span></strong><span class="koboSpan" id="kobo.141.1">: Standardizing and approving ML library packages used by data scientists is crucial for many organizations. </span><span class="koboSpan" id="kobo.141.2">By establishing a central library that contains pre-approved packages, it becomes possible to enforce consistent standards and policies across the usage of library packages. </span><span class="koboSpan" id="kobo.141.3">This approach ensures that data scientists work with vetted and authorized libraries, promoting reliability, security, and adherence to organizational guidelines when developing ML solutions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.142.1">Access to different data stores</span></strong><span class="koboSpan" id="kobo.143.1">: An essential feature of an enterprise ML platform is to offer seamless access to various data stores, simplifying model development and training processes. </span><span class="koboSpan" id="kobo.143.2">This accessibility to diverse data sources streamlines the workflow for data scientists and ML engineers, enabling them to efficiently access and utilize the necessary data for their tasks within the platform.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.144.1">Self-service capability</span></strong><span class="koboSpan" id="kobo.145.1">: To enhance operational efficiency and reduce reliance</span><a id="_idIndexMarker863"/><span class="koboSpan" id="kobo.146.1"> on central teams, an enterprise ML platform should incorporate self-service capabilities for tasks like user onboarding, environment setup, and pipeline provisioning. </span><span class="koboSpan" id="kobo.146.2">By enabling users to perform these tasks independently, the platform streamlines operations, empowering data scientists and ML engineers to work more autonomously and efficiently.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.147.1">Model testing and validation</span></strong><span class="koboSpan" id="kobo.148.1">: An enterprise ML platform should provide comprehensive model testing and validation features to support thorough assessments of ML models. </span><span class="koboSpan" id="kobo.148.2">This can include features such as A/B testing infrastructure, model robustness testing packages, automated testing pipelines, performance metrics tracking and error analysis tools, and visualization.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.149.1">Having covered the essential requirements of an enterprise ML platform, let’s now explore how AWS ML and DevOps services, such as SageMaker, CodePipeline, and Step Functions, can be effectively utilized to construct a robust, enterprise-grade ML platform.</span></p>
<h1 class="heading-1" id="_idParaDest-239"><span class="koboSpan" id="kobo.150.1">Enterprise ML architecture pattern overview</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.151.1">Building </span><a id="_idIndexMarker864"/><span class="koboSpan" id="kobo.152.1">an enterprise ML platform on AWS starts with creating different environments to enable different data science and operation functions. </span><span class="koboSpan" id="kobo.152.2">The following diagram shows the core environments that normally make up an enterprise ML platform. </span><span class="koboSpan" id="kobo.152.3">From an isolation perspective, in the context of the AWS cloud, each environment in the following diagram is a separate AWS account:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.153.1"><img alt="Figure 9.1 – Enterprise ML architecture environments " src="../Images/B20836_09_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.154.1">Figure 9.1: Enterprise ML architecture environments</span></p>
<p class="normal"><span class="koboSpan" id="kobo.155.1">As we discussed in </span><em class="italic"><span class="koboSpan" id="kobo.156.1">Chapter 8</span></em><span class="koboSpan" id="kobo.157.1">, </span><em class="italic"><span class="koboSpan" id="kobo.158.1">Building a Data Science Environment Using AWS ML Services</span></em><span class="koboSpan" id="kobo.159.1">, data scientists utilize the data science environment for experimentation, model building, and tuning. </span><span class="koboSpan" id="kobo.159.2">Once these experiments are completed, the data scientists commit their work to the proper code and data repositories. </span><span class="koboSpan" id="kobo.159.3">The next step is to train and tune the ML models in a controlled and automated environment using the algorithms, data, and training scripts that were created by the data scientists. </span><span class="koboSpan" id="kobo.159.4">This controlled and automated model training process will help ensure consistency, reproducibility, and traceability for scalable model building. </span><span class="koboSpan" id="kobo.159.5">The following are the core functionalities and technology options provided by the training, hosting, and shared services environments:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.160.1">Model training environment</span></strong><span class="koboSpan" id="kobo.161.1">: This environment manages the full lifecycle of model </span><a id="_idIndexMarker865"/><span class="koboSpan" id="kobo.162.1">training, from computing and storage infrastructure resource provisioning to training job monitoring and model persistence. </span><span class="koboSpan" id="kobo.162.2">For this purpose, the SageMaker training service offers a suitable technology option to construct the training infrastructure.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.163.1">Model hosting environment</span></strong><span class="koboSpan" id="kobo.164.1">: This environment is used to serve the trained models behind </span><a id="_idIndexMarker866"/><span class="koboSpan" id="kobo.165.1">web service endpoints or in batch inference mode. </span><span class="koboSpan" id="kobo.165.2">For this purpose, you can use the SageMaker hosting service for this environment. </span><span class="koboSpan" id="kobo.165.3">Other supporting services such as the online feature store and API management service can also run in the model hosting environment. </span><span class="koboSpan" id="kobo.165.4">There can be multiple model hosting environments for different stages. </span><span class="koboSpan" id="kobo.165.5">For example, you can have a testing hosting environment designated for model testing, and a production hosting environment for production model deployment serving real-world traffic. </span><span class="koboSpan" id="kobo.165.6">Model testers can perform different tests, such as model performance, robustness, bias, explainability analysis, and model hosting testing.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.166.1">Shared services environment</span></strong><span class="koboSpan" id="kobo.167.1">: The shared services environment hosts common</span><a id="_idIndexMarker867"/><span class="koboSpan" id="kobo.168.1"> services, tooling such as workflow orchestration tools, CI/CD tools, code repositories, Docker image repositories, and private library package tools. </span><span class="koboSpan" id="kobo.168.2">A central model registry can also run in the shared services environment for model registration and model lifecycle management. </span><span class="koboSpan" id="kobo.168.3">Service provisioning capabilities, such as creating resources in different environments</span><a id="_idIndexMarker868"/><span class="koboSpan" id="kobo.169.1"> through </span><strong class="keyWord"><span class="koboSpan" id="kobo.170.1">Infrastructure as Code</span></strong><span class="koboSpan" id="kobo.171.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.172.1">IaC</span></strong><span class="koboSpan" id="kobo.173.1">) or APIs, also run out of this environment. </span><span class="koboSpan" id="kobo.173.2">Any service ticketing tools, such as ServiceNow, and service provisioning tools, such as Service Catalog, can also be hosted in this environment.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.174.1">In addition </span><a id="_idIndexMarker869"/><span class="koboSpan" id="kobo.175.1">to the core ML environments, there are other supporting environments, such as security, governance, monitoring, and logging, that are required for designing and building enterprise ML platforms:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.176.1">Security and governance environment</span></strong><span class="koboSpan" id="kobo.177.1">: The security and governance environment</span><a id="_idIndexMarker870"/><span class="koboSpan" id="kobo.178.1"> centrally manages authentication services, user credentials, and data encryption keys. </span><span class="koboSpan" id="kobo.178.2">Security audit and reporting processes also run in this environment. </span><span class="koboSpan" id="kobo.178.3">Native AWS services, such as Amazon IAM, AWS KMS, and AWS Config, can be used for various security and governance functions. </span><span class="koboSpan" id="kobo.178.4">Any custom-built risk and governance tools can also be hosted in this environment to service AI risk/governance manager.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.179.1">Monitoring and logging environment</span></strong><span class="koboSpan" id="kobo.180.1">: The monitoring and logging environment </span><a id="_idIndexMarker871"/><span class="koboSpan" id="kobo.181.1">centrally aggregates monitoring and logging data from other environments for further processing and reporting. </span><span class="koboSpan" id="kobo.181.2">Custom dashboarding and alerting mechanisms are normally developed to provide easy access to key metrics and alerts from the underlying monitoring and logging data.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.182.1">Now that </span><a id="_idIndexMarker872"/><span class="koboSpan" id="kobo.183.1">you have a comprehensive overview of the fundamental elements that constitute an enterprise ML platform, let’s delve deeper into specific core areas. </span><span class="koboSpan" id="kobo.183.2">It is important to recognize that there are various patterns and services available for constructing an ML platform on AWS. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.184.1">Moreover, while </span><em class="italic"><span class="koboSpan" id="kobo.185.1">Figure 9.1</span></em><span class="koboSpan" id="kobo.186.1"> showcases distinct AWS environments (i.e., AWS accounts) to host different ML platform environments, organizations can also choose to combine some of the environments in a single AWS account as long as there are proper boundaries between different environments to ensure the isolation of infrastructure, process flow, and security control. </span><span class="koboSpan" id="kobo.186.2">Furthermore, organizations can create separate AWS accounts for hosting a specific environment for different users or groups. </span><span class="koboSpan" id="kobo.186.3">For instance, a large enterprise can choose to create one data science environment for each of the LoBs, or a separate production hosting environment based on either organizational structure or workload separation. </span><span class="koboSpan" id="kobo.186.4">In this chapter, we will focus mainly on exploring one of the enterprise patterns to build an efficient and scalable ML platform.</span></p>
<h2 class="heading-2" id="_idParaDest-240"><span class="koboSpan" id="kobo.187.1">Model training environment</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.188.1">Within an</span><a id="_idIndexMarker873"/><span class="koboSpan" id="kobo.189.1"> enterprise, a</span><a id="_idIndexMarker874"/><span class="koboSpan" id="kobo.190.1"> model training environment is a controlled environment with well-defined processes and policies on how it is used and who can use it. </span><span class="koboSpan" id="kobo.190.2">Normally, it should be an automated environment that’s managed by an ML operations team, though self-service can be enabled for direct usage by data scientists.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.191.1">Automated model training</span><a id="_idIndexMarker875"/><span class="koboSpan" id="kobo.192.1"> and tuning are the core capabilities of the model training environment. </span><span class="koboSpan" id="kobo.192.2">To support a broad range of use cases, a model training environment needs to support different ML and deep learning frameworks, training patterns (single-node and distributed training), and hardware (different CPUs, GPUs, and custom silicon chips).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.193.1">The model training environment manages the lifecycle of the model training process. </span><span class="koboSpan" id="kobo.193.2">This can include authentication and authorization, infrastructure provisioning, data movement, data preprocessing, ML library deployment, training loop management and monitoring, model persistence and registry, training job management, and lineage tracking. </span><span class="koboSpan" id="kobo.193.3">From a security perspective, the training environment needs to provide security capabilities for different isolation requirements, such as network isolation, job isolation, and artifact isolation. </span><span class="koboSpan" id="kobo.193.4">To assist with operational support, a model training environment also needs to be able to support training status logging, metrics reporting, and training job monitoring and alerting. </span><span class="koboSpan" id="kobo.193.5">In the following sections, we will discuss how Amazon SageMaker can be used as a managed model training engine for enterprises.</span></p>
<h3 class="heading-3" id="_idParaDest-241"><span class="koboSpan" id="kobo.194.1">Model training engine using SageMaker</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.195.1">The </span><a id="_idIndexMarker876"/><span class="koboSpan" id="kobo.196.1">SageMaker training service provides built-in model training capabilities for a range of ML/DL libraries. </span><span class="koboSpan" id="kobo.196.2">In addition, you can bring your own Docker containers for customized model training needs. </span><span class="koboSpan" id="kobo.196.3">The following are a subset of supported options for the SageMaker Python SDK:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.197.1">Training TensorFlow models</span></strong><span class="koboSpan" id="kobo.198.1">: SageMaker provides a built-in training container</span><a id="_idIndexMarker877"/><span class="koboSpan" id="kobo.199.1"> for TensorFlow models. </span><span class="koboSpan" id="kobo.199.2">The following code sample shows how to train a TensorFlow model using the built-in container through the TensorFlow estimator API:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.200.1">from</span></span><span class="koboSpan" id="kobo.201.1"> sagemaker.tensorflow </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.202.1">import</span></span><span class="koboSpan" id="kobo.203.1"> TensorFlow
tf_estimator = TensorFlow(
  entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.204.1">"&lt;Training script name&gt;"</span></span><span class="koboSpan" id="kobo.205.1">,
  role= </span><span class="hljs-string"><span class="koboSpan" id="kobo.206.1">"&lt;AWS IAM role&gt;"</span></span><span class="koboSpan" id="kobo.207.1">,
  instance_count=&lt;Number of instances),
  instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.208.1">"&lt;Instance type&gt;"</span></span><span class="koboSpan" id="kobo.209.1">,
  framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.210.1">"&lt;TensorFlow version&gt;"</span></span><span class="koboSpan" id="kobo.211.1">,
  py_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.212.1">"&lt;Python version&gt;"</span></span><span class="koboSpan" id="kobo.213.1">,)
tf_estimator.fit(</span><span class="hljs-string"><span class="koboSpan" id="kobo.214.1">"&lt;Training data location&gt;"</span></span><span class="koboSpan" id="kobo.215.1">)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.216.1">Training PyTorch models</span></strong><span class="koboSpan" id="kobo.217.1">: SageMaker provides a built-in training container for </span><a id="_idIndexMarker878"/><span class="koboSpan" id="kobo.218.1">PyTorch models. </span><span class="koboSpan" id="kobo.218.2">The following code sample shows how to train a PyTorch model using the PyTorch estimator:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.219.1">from</span></span><span class="koboSpan" id="kobo.220.1"> sagemaker.pytorch </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.221.1">import</span></span><span class="koboSpan" id="kobo.222.1"> PyTorch
pytorch_estimator = PyTorch(
  entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.223.1">"&lt;Training script name&gt;"</span></span><span class="koboSpan" id="kobo.224.1">,
  role= </span><span class="hljs-string"><span class="koboSpan" id="kobo.225.1">"&lt;AWS IAM role&gt;"</span></span><span class="koboSpan" id="kobo.226.1">,
  instance_count=&lt;Number of instances),
  instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.227.1">"&lt;Instance type&gt;"</span></span><span class="koboSpan" id="kobo.228.1">,
  framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.229.1">"&lt;PyTorch version&gt;"</span></span><span class="koboSpan" id="kobo.230.1">,
  py_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.231.1">"&lt;Python version&gt;"</span></span><span class="koboSpan" id="kobo.232.1">,)
pytorch_estimator.fit(</span><span class="hljs-string"><span class="koboSpan" id="kobo.233.1">"&lt;Training data location&gt;"</span></span><span class="koboSpan" id="kobo.234.1">)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.235.1">Training XGBoost models</span></strong><span class="koboSpan" id="kobo.236.1">: XGBoost training is also supported via a built-in container. </span><span class="koboSpan" id="kobo.236.2">The </span><a id="_idIndexMarker879"/><span class="koboSpan" id="kobo.237.1">following code shows the syntax for training an XGBoost model using the XGBoost estimator:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.238.1">from</span></span><span class="koboSpan" id="kobo.239.1"> sagemaker.xgboost.estimator </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.240.1">import</span></span><span class="koboSpan" id="kobo.241.1"> XGBoost
xgb_estimator = XGBoost(
  entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.242.1">"&lt;Training script name&gt;"</span></span><span class="koboSpan" id="kobo.243.1">,
  hyperparameters=&lt;dictionary of hyperparameters&gt;,
  role=&lt;AWS IAM role&gt;,
  instance_count=&lt;Number of instances&gt;,
  instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.244.1">"&lt;Instance type&gt;"</span></span><span class="koboSpan" id="kobo.245.1">,
  framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.246.1">"&lt;Xgboost version&gt;"</span></span><span class="koboSpan" id="kobo.247.1">)
xgb_estimator.fit(</span><span class="hljs-string"><span class="koboSpan" id="kobo.248.1">"&lt;train data location&gt;"</span></span><span class="koboSpan" id="kobo.249.1">)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.250.1">Training scikit-learn models</span></strong><span class="koboSpan" id="kobo.251.1">: The </span><a id="_idIndexMarker880"/><span class="koboSpan" id="kobo.252.1">following code sample shows how to train a scikit-learn </span><a id="_idIndexMarker881"/><span class="koboSpan" id="kobo.253.1">model using the built-in container:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.254.1">from</span></span><span class="koboSpan" id="kobo.255.1"> sagemaker.sklearn.estimator </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.256.1">import</span></span><span class="koboSpan" id="kobo.257.1"> SKLearn
sklearn_estimator = SKLearn(
  entry_point=</span><span class="hljs-string"><span class="koboSpan" id="kobo.258.1">"&lt;Training script name&gt;"</span></span><span class="koboSpan" id="kobo.259.1">,
  hyperparameters=&lt;dictionary of hyperparameters&gt;,
  role=&lt;AWS IAM role&gt;,
  instance_count=&lt;Number of instances&gt;,
  instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.260.1">"&lt;Instance type&gt;"</span></span><span class="koboSpan" id="kobo.261.1">,
     framework_version=</span><span class="hljs-string"><span class="koboSpan" id="kobo.262.1">"&lt;sklearn version&gt;"</span></span><span class="koboSpan" id="kobo.263.1">)
Sklearn_estimator.fit(</span><span class="hljs-string"><span class="koboSpan" id="kobo.264.1">"&lt;training data&gt;"</span></span><span class="koboSpan" id="kobo.265.1">)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.266.1">Training models using custom containers</span></strong><span class="koboSpan" id="kobo.267.1">: You can also build a custom training </span><a id="_idIndexMarker882"/><span class="koboSpan" id="kobo.268.1">container and use the SageMaker training service for model training. </span><span class="koboSpan" id="kobo.268.2">See the following code for an example:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.269.1">from</span></span><span class="koboSpan" id="kobo.270.1"> sagemaker.estimator </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.271.1">import</span></span><span class="koboSpan" id="kobo.272.1"> Estimator
custom_estimator = Estimator (
  image_uri=</span><span class="hljs-string"><span class="koboSpan" id="kobo.273.1">"&lt;custom model inference container image uri&gt;"</span></span><span class="koboSpan" id="kobo.274.1">
  role=&lt;AWS IAM role&gt;,
  instance_count=&lt;Number of instances&gt;,
  instance_type=</span><span class="hljs-string"><span class="koboSpan" id="kobo.275.1">"&lt;Instance type&gt;"</span></span><span class="koboSpan" id="kobo.276.1">)
custom_estimator.fit(</span><span class="hljs-string"><span class="koboSpan" id="kobo.277.1">"&lt;training data location&gt;"</span></span><span class="koboSpan" id="kobo.278.1">)
</span></code></pre>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.279.1">In addition to </span><a id="_idIndexMarker883"/><span class="koboSpan" id="kobo.280.1">using the SageMaker Python SDK to kick off training, you can also use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.281.1">boto3</span></code><span class="koboSpan" id="kobo.282.1"> library and SageMaker CLI commands to start training jobs.</span></p>
<h3 class="heading-3" id="_idParaDest-242"><span class="koboSpan" id="kobo.283.1">Automation support</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.284.1">The SageMaker training</span><a id="_idIndexMarker884"/><span class="koboSpan" id="kobo.285.1"> service is exposed through a set of APIs and can be automated by integrating with external applications or workflow tools, such as SageMaker Pipelines, Airflow, and AWS Step Functions. </span><span class="koboSpan" id="kobo.285.2">For example, it can be one of the steps in an Airflow-based pipeline for an end-to-end ML workflow. </span><span class="koboSpan" id="kobo.285.3">Some workflow tools, such as Airflow and AWS Step Functions, also provide SageMaker-specific connectors to interact with the SageMaker training service more seamlessly. </span><span class="koboSpan" id="kobo.285.4">The SageMaker training service also provides Kubernetes operators, so it can be integrated and automated as part of the Kubernetes application flow. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.286.1">The following sample code shows how to kick off a training job using the low-level API via the AWS </span><code class="inlineCode"><span class="koboSpan" id="kobo.287.1">boto3</span></code><span class="koboSpan" id="kobo.288.1"> SDK:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.289.1">import</span></span><span class="koboSpan" id="kobo.290.1"> boto3
client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.291.1">'sagemaker'</span></span><span class="koboSpan" id="kobo.292.1">)
response = client.create_training_job(
    TrainingJobName=</span><span class="hljs-string"><span class="koboSpan" id="kobo.293.1">'&lt;job name&gt;'</span></span><span class="koboSpan" id="kobo.294.1">,
    HyperParameters={&lt;</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.295.1">list</span></span><span class="koboSpan" id="kobo.296.1"> of parameters </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.297.1">and</span></span><span class="koboSpan" id="kobo.298.1"> value&gt;},
    AlgorithmSpecification={...},
    RoleArn=</span><span class="hljs-string"><span class="koboSpan" id="kobo.299.1">'&lt;AWS IAM Role&gt;'</span></span><span class="koboSpan" id="kobo.300.1">,
    InputDataConfig=[...],
    OutputDataConfig={...},
    ResourceConfig={...},
    ...
</span><span class="koboSpan" id="kobo.300.2">}
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.301.1">Regarding using</span><a id="_idIndexMarker885"/><span class="koboSpan" id="kobo.302.1"> Airflow as the workflow tool, the following sample shows how to use the Airflow SageMaker operator as part of the workflow definition. </span><span class="koboSpan" id="kobo.302.2">Here, </span><code class="inlineCode"><span class="koboSpan" id="kobo.303.1">train_config</span></code><span class="koboSpan" id="kobo.304.1"> contains training configuration details, such as the training estimator, training instance type and number, and training data location:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.305.1">import</span></span><span class="koboSpan" id="kobo.306.1"> airflow
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.307.1">from</span></span><span class="koboSpan" id="kobo.308.1"> airflow </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.309.1">import</span></span><span class="koboSpan" id="kobo.310.1"> DAG
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.311.1">from</span></span><span class="koboSpan" id="kobo.312.1"> airflow.contrib.operators.sagemaker_training_operator </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.313.1">import</span></span><span class="koboSpan" id="kobo.314.1"> SageMakerTrainingOperator
default_args = {
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.315.1">'owner'</span></span><span class="koboSpan" id="kobo.316.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.317.1">'myflow'</span></span><span class="koboSpan" id="kobo.318.1">,
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.319.1">'start_date'</span></span><span class="koboSpan" id="kobo.320.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.321.1">'2021-01-01'</span></span><span class="koboSpan" id="kobo.322.1">
}
dag = DAG(</span><span class="hljs-string"><span class="koboSpan" id="kobo.323.1">'tensorflow_training'</span></span><span class="koboSpan" id="kobo.324.1">, default_args=default_args,
          schedule_interval=</span><span class="hljs-string"><span class="koboSpan" id="kobo.325.1">'@once'</span></span><span class="koboSpan" id="kobo.326.1">)
train_op = SageMakerTrainingOperator(
    task_id=</span><span class="hljs-string"><span class="koboSpan" id="kobo.327.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.328.1">tf_training'</span></span><span class="koboSpan" id="kobo.329.1">,
    config=train_config,
    wait_for_completion=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.330.1">True</span></span><span class="koboSpan" id="kobo.331.1">,
    dag=dag)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.332.1">SageMaker also has a built-in workflow automation </span><a id="_idIndexMarker886"/><span class="koboSpan" id="kobo.333.1">tool called </span><strong class="keyWord"><span class="koboSpan" id="kobo.334.1">SageMaker Pipelines</span></strong><span class="koboSpan" id="kobo.335.1">. </span><span class="koboSpan" id="kobo.335.2">A training step can be created</span><a id="_idIndexMarker887"/><span class="koboSpan" id="kobo.336.1"> using the SageMaker </span><strong class="keyWord"><span class="koboSpan" id="kobo.337.1">Training Step</span></strong><span class="koboSpan" id="kobo.338.1"> API and integrated into the larger SageMaker Pipelines workflow.</span></p>
<h3 class="heading-3" id="_idParaDest-243"><span class="koboSpan" id="kobo.339.1">Model training lifecycle management</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.340.1">SageMaker training</span><a id="_idIndexMarker888"/><span class="koboSpan" id="kobo.341.1"> manages the lifecycle of the model training process. </span><span class="koboSpan" id="kobo.341.2">It uses Amazon IAM as the mechanism to authenticate and authorize access to its functions. </span><span class="koboSpan" id="kobo.341.3">Once authorized, it provides the desired infrastructure, deploys the software stacks for the different model training requirements, moves the data from sources to training nodes, and kicks off the training job. </span><span class="koboSpan" id="kobo.341.4">Once the training job has been completed, the model artifacts are saved into an S3 output bucket and the infrastructure is torn down. </span><span class="koboSpan" id="kobo.341.5">For lineage tracing, model training metadata such as source datasets, model training containers, hyperparameters, and model output locations are captured. </span><span class="koboSpan" id="kobo.341.6">Any logging from the training job runs is saved in CloudWatch Logs, and system metrics such as CPU and GPU utilization are captured in the CloudWatch metrics.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.342.1">Depending on </span><a id="_idIndexMarker889"/><span class="koboSpan" id="kobo.343.1">the overall end-to-end ML platform architecture, a model training environment can also host services for data preprocessing, model validation, and model training postprocessing, as those are important steps in an end-to-end ML flow. </span><span class="koboSpan" id="kobo.343.2">There are multiple technology options available for this, such as the SageMaker Processing service, AWS Glue, and AWS Lambda.</span></p>
<h2 class="heading-2" id="_idParaDest-244"><span class="koboSpan" id="kobo.344.1">Model hosting environment</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.345.1">An </span><a id="_idIndexMarker890"/><span class="koboSpan" id="kobo.346.1">enterprise-grade </span><a id="_idIndexMarker891"/><span class="koboSpan" id="kobo.347.1">model hosting environment needs to support a broad range of ML frameworks in a secure, performant, and scalable way. </span><span class="koboSpan" id="kobo.347.2">It should come with a list of pre-built inference engines that can serve common models out of the box </span><a id="_idIndexMarker892"/><span class="koboSpan" id="kobo.348.1">behind a </span><strong class="keyWord"><span class="koboSpan" id="kobo.349.1">RESTful API</span></strong><span class="koboSpan" id="kobo.350.1"> or via the </span><strong class="keyWord"><span class="koboSpan" id="kobo.351.1">gRPC protocol</span></strong><span class="koboSpan" id="kobo.352.1">. </span><span class="koboSpan" id="kobo.352.2">It also needs to</span><a id="_idIndexMarker893"/><span class="koboSpan" id="kobo.353.1"> provide flexibility to host custom-built inference engines for unique requirements. </span><span class="koboSpan" id="kobo.353.2">Users should also have access to different hardware devices, such as CPU, GPU, and purpose-built chips, for different inference needs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.354.1">Some model inference patterns demand more complex inference graphs, such as traffic split, request transformations, or model ensemble support. </span><span class="koboSpan" id="kobo.354.2">A model hosting environment can provide this capability as an out-of-the-box feature or provide technology options for building custom inference graphs. </span><span class="koboSpan" id="kobo.354.3">Other common model hosting capabilities</span><a id="_idIndexMarker894"/><span class="koboSpan" id="kobo.355.1"> include </span><strong class="keyWord"><span class="koboSpan" id="kobo.356.1">concept drift detection</span></strong><span class="koboSpan" id="kobo.357.1"> and </span><strong class="keyWord"><span class="koboSpan" id="kobo.358.1">model performance drift detection</span></strong><span class="koboSpan" id="kobo.359.1">. </span><span class="koboSpan" id="kobo.359.2">Concept </span><a id="_idIndexMarker895"/><span class="koboSpan" id="kobo.360.1">drift occurs when the statistical characteristics of the production data deviate from the data that’s used for model training. </span><span class="koboSpan" id="kobo.360.2">An example of concept drift is the mean and standard deviation of a feature changing significantly in production from that of the training dataset. </span><span class="koboSpan" id="kobo.360.3">Model performance drift happens when the accuracy of the model degrades in production.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.361.1">Components in a model hosting environment can participate in an automation workflow through its API, scripting, or IaC deployment (such as AWS CloudFormation). </span><span class="koboSpan" id="kobo.361.2">For example, a RESTful endpoint can be deployed using a CloudFormation template or by invoking its API as part of an automated workflow.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.362.1">From a security perspective, the model hosting environment needs to provide authentication and authorization control to manage access to both</span><a id="_idIndexMarker896"/><span class="koboSpan" id="kobo.363.1"> the </span><strong class="keyWord"><span class="koboSpan" id="kobo.364.1">control plane</span></strong><span class="koboSpan" id="kobo.365.1"> (management functions) and</span><a id="_idIndexMarker897"/><span class="koboSpan" id="kobo.366.1"> the </span><strong class="keyWord"><span class="koboSpan" id="kobo.367.1">data plane</span></strong><span class="koboSpan" id="kobo.368.1"> (model endpoints). </span><span class="koboSpan" id="kobo.368.2">The accesses and operations that are performed against the hosting environments should be logged for auditing purposes. </span><span class="koboSpan" id="kobo.368.3">For operations support, a hosting environment needs to enable status logging and system monitoring to support system observability and problem troubleshooting.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.369.1">The </span><a id="_idIndexMarker898"/><span class="koboSpan" id="kobo.370.1">SageMaker hosting service is a fully managed model hosting service. </span><span class="koboSpan" id="kobo.370.2">Similar to KFServing and Seldon Core, which we reviewed earlier in this book, the SageMaker hosting service is also a multi-framework model-serving service. </span><span class="koboSpan" id="kobo.370.3">Next, let’s take a closer look at its various capabilities for enterprise-grade model hosting.</span></p>
<h3 class="heading-3" id="_idParaDest-245"><span class="koboSpan" id="kobo.371.1">Inference engines</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.372.1">SageMaker </span><a id="_idIndexMarker899"/><span class="koboSpan" id="kobo.373.1">provides built-in inference engines for multiple ML frameworks, including scikit-learn, XGBoost, TensorFlow, PyTorch, and Spark ML. </span><span class="koboSpan" id="kobo.373.2">SageMaker supplies these built-in inference engines as Docker containers. </span><span class="koboSpan" id="kobo.373.3">To stand up an API endpoint to serve a model, you just need to provide the model artifacts and infrastructure configuration. </span><span class="koboSpan" id="kobo.373.4">The following is a list of model-serving options:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.374.1">Serving TensorFlow models</span></strong><span class="koboSpan" id="kobo.375.1">: SageMaker uses TensorFlow Serving as the inference </span><a id="_idIndexMarker900"/><span class="koboSpan" id="kobo.376.1">engine for TensorFlow models. </span><span class="koboSpan" id="kobo.376.2">The following code sample shows how to deploy a TensorFlow Serving model using the SageMaker hosting service where a TensorFlow model is loaded using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.377.1">Model</span></code><span class="koboSpan" id="kobo.378.1"> class from the S3 location and deployed as a SageMaker endpoint using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.379.1">deploy()</span></code><span class="koboSpan" id="kobo.380.1"> function with the specified compute instance type and number:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.381.1">from</span></span><span class="koboSpan" id="kobo.382.1"> sagemaker.tensorflow.serving </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.383.1">import</span></span><span class="koboSpan" id="kobo.384.1"> Model
tensorflow_model = Model(
    model_data=&lt;S3 location of the TF ML model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
   framework_version=&lt;tensorflow version&gt;
)
tensorflow_model.deploy(
  initial_instance_count=&lt;instance count&gt;, instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.385.1">type</span></span><span class="koboSpan" id="kobo.386.1">&gt;
)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.387.1">Serving PyTorch models</span></strong><span class="koboSpan" id="kobo.388.1">: SageMaker hosting uses TorchServe under the hood to </span><a id="_idIndexMarker901"/><span class="koboSpan" id="kobo.389.1">serve PyTorch models. </span><span class="koboSpan" id="kobo.389.2">The following code sample shows how to deploy a PyTorch model, which is very similar to the code for deploying TensorFlow models:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.390.1">from</span></span><span class="koboSpan" id="kobo.391.1"> sagemaker.pytorch.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.392.1">import</span></span><span class="koboSpan" id="kobo.393.1"> PyTorchModel
pytorch_model = PyTorchModel(
    model_data=&lt;S3 location of the PyTorch model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
    framework_version=&lt;PyTorch version&gt;
)
pytorch_model.deploy(
    initial_instance_count=&lt;instance count&gt;, instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.394.1">type</span></span><span class="koboSpan" id="kobo.395.1">&gt;
)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.396.1">Serving Spark ML models</span></strong><span class="koboSpan" id="kobo.397.1">: For Spark ML-based models, SageMaker uses MLeap as the</span><a id="_idIndexMarker902"/><span class="koboSpan" id="kobo.398.1"> backend to serve Spark ML models. </span><span class="koboSpan" id="kobo.398.2">These Spark ML models need to be serialized into MLeap format so they can be used by the MLeap engine. </span><span class="koboSpan" id="kobo.398.3">The following code sample shows how to deploy a Spark ML model using the SageMaker hosting service where the </span><code class="inlineCode"><span class="koboSpan" id="kobo.399.1">SparkMLModel</span></code><span class="koboSpan" id="kobo.400.1"> class is used to specify</span><a id="_idIndexMarker903"/><span class="koboSpan" id="kobo.401.1"> the model configuration and the </span><code class="inlineCode"><span class="koboSpan" id="kobo.402.1">deploy()</span></code><span class="koboSpan" id="kobo.403.1"> function is used for the actual deployment into a SageMaker endpoint:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.404.1">import</span></span><span class="koboSpan" id="kobo.405.1"> sagemaker
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.406.1">from</span></span><span class="koboSpan" id="kobo.407.1"> sagemaker.sparkml.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.408.1">import</span></span><span class="koboSpan" id="kobo.409.1"> SparkMLModel
sparkml_model = SparkMLModel(
    model_data=&lt;S3 location of the Spark ML model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
    sagemaker_session=sagemaker.Session(),
    name=&lt;Model name&gt;,
    env={</span><span class="hljs-string"><span class="koboSpan" id="kobo.410.1">"SAGEMAKER_SPARKML_SCHEMA"</span></span><span class="koboSpan" id="kobo.411.1">: &lt;schema_json&gt;}
)
sparkml_model.deploy(
    initial_instance_count=&lt;instance count&gt;, instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.412.1">type</span></span><span class="koboSpan" id="kobo.413.1">&gt;
)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.414.1">Serving XGBoost models</span></strong><span class="koboSpan" id="kobo.415.1">: SageMaker provides an XGBoost model server for serving</span><a id="_idIndexMarker904"/><span class="koboSpan" id="kobo.416.1"> trained XGBoost models. </span><span class="koboSpan" id="kobo.416.2">Under the hood, it uses Nginx, Gunicorn, and Flask as part of the model-serving architecture. </span><span class="koboSpan" id="kobo.416.3">The entry Python script loads the trained XGBoost model and can optionally perform pre- and post-data processing:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.417.1">from</span></span><span class="koboSpan" id="kobo.418.1"> sagemaker.xgboost.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.419.1">import</span></span><span class="koboSpan" id="kobo.420.1"> XGBoostModel
xgboost_model = XGBoostModel(
    model_data=&lt;S3 location of the Xgboost ML model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
    entry_point=&lt;entry python script&gt;,
    framework_version=&lt;xgboost version&gt;
)
xgboost_model.deploy(
    instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.421.1">type</span></span><span class="koboSpan" id="kobo.422.1">&gt;,
    initial_instance_count=&lt;instance count&gt;
)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.423.1">Serving scikit-learn models</span></strong><span class="koboSpan" id="kobo.424.1">: SageMaker provides a built-in serving container for serving </span><a id="_idIndexMarker905"/><span class="koboSpan" id="kobo.425.1">scikit-learn-based models. </span><span class="koboSpan" id="kobo.425.2">The technology stack is similar to the one for the</span><a id="_idIndexMarker906"/><span class="koboSpan" id="kobo.426.1"> XGBoost model server, which is also based on Nginx, Gunicorn, and Flask:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.427.1">from</span></span><span class="koboSpan" id="kobo.428.1"> sagemaker.sklearn.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.429.1">import</span></span><span class="koboSpan" id="kobo.430.1"> SKLearnModel
sklearn_model = SKLearnModel(
    model_data=&lt;S3 location of the Xgboost ML model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
    entry_point=&lt;entry python script&gt;,
    framework_version=&lt;scikit-learn version&gt;
)
sklearn_model.deploy(instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.431.1">type</span></span><span class="koboSpan" id="kobo.432.1">&gt;, initial_instance_count=&lt;instance count&gt;)
</span></code></pre>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.433.1">Serving models with custom containers</span></strong><span class="koboSpan" id="kobo.434.1">: For custom-created inference containers, you </span><a id="_idIndexMarker907"/><span class="koboSpan" id="kobo.435.1">can follow a similar syntax to deploy the model. </span><span class="koboSpan" id="kobo.435.2">The main difference is that a custom inference container image’s uri must be provided to specify the custom container location. </span><span class="koboSpan" id="kobo.435.3">You can find detailed documentation on building a custom inference container at </span><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html"><span class="url"><span class="koboSpan" id="kobo.436.1">https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html</span></span></a><span class="koboSpan" id="kobo.437.1">:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.438.1">from</span></span><span class="koboSpan" id="kobo.439.1"> sagemaker.model </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.440.1">import</span></span><span class="koboSpan" id="kobo.441.1"> Model
custom_model = Model(
    Image_uri = &lt;custom model inference container image uri&gt;,
    model_data=&lt;S3 location of the ML model artifacts&gt;,
    role=&lt;AWS IAM role&gt;,
    framework_version=&lt;scikit-learn version&gt;
)
custom_model.deploy(instance_type=&lt;instance </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.442.1">type</span></span><span class="koboSpan" id="kobo.443.1">&gt;, initial_instance_count=&lt;instance count&gt;)
</span></code></pre>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.444.1">SageMaker </span><a id="_idIndexMarker908"/><span class="koboSpan" id="kobo.445.1">hosting provides an inference pipeline feature that allows you to create a linear sequence of containers to perform custom data processing before and after invoking a model for predictions. </span><span class="koboSpan" id="kobo.445.2">SageMaker hosting can support traffic splits between multiple versions of a model for A/B testing.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.446.1">SageMaker hosting can be provisioned using an AWS CloudFormation template. </span><span class="koboSpan" id="kobo.446.2">There is also support for the AWS CLI for scripting automation, and it can be integrated into custom applications via its API. </span><span class="koboSpan" id="kobo.446.3">The following are some code samples for different endpoint deployment automation methods:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.447.1">The following is a CloudFormation code sample for SageMaker endpoint deployment. </span><span class="koboSpan" id="kobo.447.2">In this code sample, you specify the compute instance, the number of instances, the model name, and the model-serving container used to host the model. </span><span class="koboSpan" id="kobo.447.3">You can find the complete code at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter09/sagemaker_hosting.yaml"><span class="url"><span class="koboSpan" id="kobo.448.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/blob/main/Chapter09/sagemaker_hosting.yaml</span></span></a><span class="koboSpan" id="kobo.449.1">:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr"><span class="koboSpan" id="kobo.450.1">Description:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.451.1">"Model hosting cloudformation template"</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.452.1">Resources:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.453.1">Endpoint:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.454.1">Type:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.455.1">"AWS::SageMaker::Endpoint"</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.456.1">Properties:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.457.1">EndpointConfigName:</span></span>
<span class="hljs-type"><span class="koboSpan" id="kobo.458.1">!GetAtt</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.459.1">EndpointConfig.EndpointConfigName</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.460.1">EndpointConfig:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.461.1">Type:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.462.1">"AWS::SageMaker::EndpointConfig"</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.463.1">Properties:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.464.1">ProductionVariants:</span></span>
<span class="hljs-bullet"><span class="koboSpan" id="kobo.465.1">-</span></span> <span class="hljs-attr"><span class="koboSpan" id="kobo.466.1">InitialInstanceCount:</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.467.1">1</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.468.1">InitialVariantWeight:</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.469.1">1.0</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.470.1">InstanceType:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.471.1">ml.t2.large</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.472.1">ModelName:</span></span> <span class="hljs-type"><span class="koboSpan" id="kobo.473.1">!GetAtt</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.474.1">Model.ModelName</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.475.1">VariantName:</span></span> <span class="hljs-type"><span class="koboSpan" id="kobo.476.1">!GetAtt</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.477.1">Model.ModelName</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.478.1">Model:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.479.1">Type:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.480.1">"AWS::SageMaker::Model"</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.481.1">Properties:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.482.1">PrimaryContainer:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.483.1">Image:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.484.1">&lt;container</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.485.1">uri&gt;</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.486.1">ExecutionRoleArn:</span></span> <span class="hljs-type"><span class="koboSpan" id="kobo.487.1">!GetAtt</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.488.1">ExecutionRole.Arn</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.489.1">...</span></span>
</code></pre>
</li>
<li class="bulletList"><span class="koboSpan" id="kobo.490.1">The following is an AWS CLI sample for SageMaker endpoint deployment, which consists of three main steps: creating a model, specifying a SageMaker endpoint configuration, and the actual deployment of the model into a SageMaker endpoint:
        </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-string"><span class="koboSpan" id="kobo.491.1">Aws</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.492.1">sagemaker</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.493.1">create-model</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.494.1">--model-name</span></span><span class="koboSpan" id="kobo.495.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.496.1">value</span></span><span class="koboSpan" id="kobo.497.1">&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.498.1">--execution-role-arn</span></span><span class="koboSpan" id="kobo.499.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.500.1">value</span></span><span class="koboSpan" id="kobo.501.1">&gt;
</span><span class="hljs-string"><span class="koboSpan" id="kobo.502.1">aws</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.503.1">sagemaker</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.504.1">Create-endpoint-config</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.505.1">--endpoint-config-name</span></span><span class="koboSpan" id="kobo.506.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.507.1">value</span></span><span class="koboSpan" id="kobo.508.1">&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.509.1">--production-variants</span></span><span class="koboSpan" id="kobo.510.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.511.1">value</span></span><span class="koboSpan" id="kobo.512.1">&gt;
</span><span class="hljs-string"><span class="koboSpan" id="kobo.513.1">aws</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.514.1">sagemaker</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.515.1">Create-endpoint</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.516.1">--endpoint-name</span></span><span class="koboSpan" id="kobo.517.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.518.1">value</span></span><span class="koboSpan" id="kobo.519.1">&gt; </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.520.1">--endpoint-config-name</span></span><span class="koboSpan" id="kobo.521.1"> &lt;</span><span class="hljs-string"><span class="koboSpan" id="kobo.522.1">value</span></span><span class="koboSpan" id="kobo.523.1">&gt;
</span></code></pre>
</li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.524.1">If the built-in</span><a id="_idIndexMarker909"/><span class="koboSpan" id="kobo.525.1"> inference engines do not meet your requirements, you should consider bringing your own Docker container to serve your ML models.</span></p>
<h3 class="heading-3" id="_idParaDest-246"><span class="koboSpan" id="kobo.526.1">Authentication and security control</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.527.1">The </span><a id="_idIndexMarker910"/><span class="koboSpan" id="kobo.528.1">SageMaker hosting service uses AWS IAM as the mechanism to control access to its control plane APIs (for example, an API for creating an endpoint) and data plane APIs (for example, an API for invoking a hosted model endpoint). </span><span class="koboSpan" id="kobo.528.2">If you need to support other authentication methods for the data plane API, such</span><a id="_idIndexMarker911"/><span class="koboSpan" id="kobo.529.1"> as </span><strong class="keyWord"><span class="koboSpan" id="kobo.530.1">OpenID Connect</span></strong><span class="koboSpan" id="kobo.531.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.532.1">OIDC</span></strong><span class="koboSpan" id="kobo.533.1">), you can implement a proxy service as the frontend to manage user authentication. </span><span class="koboSpan" id="kobo.533.2">A common pattern is to use AWS API Gateway to frontend the SageMaker API for custom authentication management, as well as other API management features such as metering and throttling management.</span></p>
<h3 class="heading-3" id="_idParaDest-247"><span class="koboSpan" id="kobo.534.1">Monitoring and logging</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.535.1">SageMaker </span><a id="_idIndexMarker912"/><span class="koboSpan" id="kobo.536.1">provides out-of-the-box monitoring and logging capabilities to assist with support operations. </span><span class="koboSpan" id="kobo.536.2">It monitors both system resource metrics (for example, CPU/GPU utilization) and model invocation metrics (for example, the number of invocations, model latencies, and failures). </span><span class="koboSpan" id="kobo.536.3">These monitoring metrics and any model processing logs are captured by AWS CloudWatch metrics and CloudWatch Logs.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.537.1">Now that we have covered the training, inference, security, and monitoring aspects of an ML platform, we will dive into implementing MLOps to automate ML workflows next.</span></p>
<h1 class="heading-1" id="_idParaDest-248"><span class="koboSpan" id="kobo.538.1">Adopting MLOps for ML workflows</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.539.1">Similar to the </span><a id="_idIndexMarker913"/><span class="koboSpan" id="kobo.540.1">DevOps practice, which has been widely adopted for the traditional software development and deployment process, the MLOps practice is intended to streamline the building and deployment processes of ML pipelines while enhancing the collaborations between data scientists/ML engineers, data engineering, and the operations team. </span><span class="koboSpan" id="kobo.540.2">Specifically, the primary objective of MLOps practice is to yield the </span><a id="_idIndexMarker914"/><span class="koboSpan" id="kobo.541.1">following main benefits</span><a id="_idIndexMarker915"/><span class="koboSpan" id="kobo.542.1"> throughout the entire ML lifecycle:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.543.1">Process consistency</span></strong><span class="koboSpan" id="kobo.544.1">: The</span><a id="_idIndexMarker916"/><span class="koboSpan" id="kobo.545.1"> MLOps practice aims to create consistency in the ML model-building and deployment process. </span><span class="koboSpan" id="kobo.545.2">A consistent process improves the efficiency of the ML workflow and ensures a high degree of certainty in the input and output of the ML workflow.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.546.1">Tooling and process reusability</span></strong><span class="koboSpan" id="kobo.547.1">: One</span><a id="_idIndexMarker917"/><span class="koboSpan" id="kobo.548.1"> of the core objectives of the MLOps practice is to create reusable technology tooling and templates for faster adoption and deployment of new ML use cases. </span><span class="koboSpan" id="kobo.548.2">These can include common tools such as code and library repositories, package and image building tools, pipeline orchestration tools, the model registry, as well as common infrastructure for model training and model deployment. </span><span class="koboSpan" id="kobo.548.3">From a reusable template perspective, these can include common reusable scripts for Docker image builds, workflow </span><a id="_idIndexMarker918"/><span class="koboSpan" id="kobo.549.1">orchestration definitions, and CloudFormation scripts for model building and model deployment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.550.1">Model-building reproducibility</span></strong><span class="koboSpan" id="kobo.551.1">: ML is highly iterative and can involve a large number </span><a id="_idIndexMarker919"/><span class="koboSpan" id="kobo.552.1">of experimentations and model training runs using different datasets, algorithms, and hyperparameters. </span><span class="koboSpan" id="kobo.552.2">An MLOps process needs to capture all the data inputs, source code, and artifacts that are used to build an</span><a id="_idIndexMarker920"/><span class="koboSpan" id="kobo.553.1"> ML model and establish model lineage from this input data, code, and artifacts for the final models. </span><span class="koboSpan" id="kobo.553.2">This is important for both experiment tracking as well as governance and control purposes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.554.1">Delivery scalability</span></strong><span class="koboSpan" id="kobo.555.1">: An </span><a id="_idIndexMarker921"/><span class="koboSpan" id="kobo.556.1">MLOps process and the associated tooling enable a large number of ML pipelines to run in parallel for high delivery throughputs. </span><span class="koboSpan" id="kobo.556.2">Different ML project teams can use the standard MLOps processes and common tools independently without creating conflicts from a resource contention, environment isolation, and governance perspective.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.557.1">Process and operation auditability</span></strong><span class="koboSpan" id="kobo.558.1">: MLOps enables greater audibility in the process </span><a id="_idIndexMarker922"/><span class="koboSpan" id="kobo.559.1">and the auditability of ML pipelines. </span><span class="koboSpan" id="kobo.559.2">This includes capturing the details of machine pipeline executions, dependencies, and lineage across different steps, job execution statuses, model training and deployment details, approval tracking, and actions that are performed by human operators.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.560.1">Now that we are familiar with the intended goals and benefits of the MLOps practice, let’s delve into the specific operational process and concrete technology architecture of MLOps on AWS.</span></p>
<h2 class="heading-2" id="_idParaDest-249"><span class="koboSpan" id="kobo.561.1">Components of the MLOps architecture</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.562.1">One of the </span><a id="_idIndexMarker923"/><span class="koboSpan" id="kobo.563.1">most important MLOps concepts is the automation pipeline, which executes a sequence of tasks, such as data processing, model training, and model deployment. </span><span class="koboSpan" id="kobo.563.2">This pipeline can be a linear sequence of steps or a more complex </span><strong class="keyWord"><span class="koboSpan" id="kobo.564.1">directed acyclic graph</span></strong><span class="koboSpan" id="kobo.565.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.566.1">DAG</span></strong><span class="koboSpan" id="kobo.567.1">) with parallel execution for multiple tasks. </span><span class="koboSpan" id="kobo.567.2">The following diagram illustrates a sample DAG for an ML pipeline.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.568.1"><img alt="A diagram of steps to a model  Description automatically generated" src="../Images/B20836_09_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.569.1">Figure 9.2: Sample ML pipeline flow</span></p>
<p class="normal"><span class="koboSpan" id="kobo.570.1">An MLOps architecture</span><a id="_idIndexMarker924"/><span class="koboSpan" id="kobo.571.1"> also has several repositories for storing different assets and metadata as part of pipeline executions. </span><span class="koboSpan" id="kobo.571.2">The following diagram lists the core components and tasks involved in an MLOps operation:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.572.1"><img alt="Figure 9.2 – MLOps components " src="../Images/B20836_09_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.573.1">Figure 9.3: MLOps components</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.574.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.575.1">code repository</span></strong><span class="koboSpan" id="kobo.576.1"> is an </span><a id="_idIndexMarker925"/><span class="koboSpan" id="kobo.577.1">MLOps architecture component that not only serves as a source code control mechanism for data scientists and engineers – it can also be the triggering mechanism to kick off different pipeline executions. </span><span class="koboSpan" id="kobo.577.2">For example, when a data scientist checks an updated training script into the code repository, a model training pipeline execution can be triggered.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.578.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.579.1">feature repository</span></strong><span class="koboSpan" id="kobo.580.1"> stores </span><a id="_idIndexMarker926"/><span class="koboSpan" id="kobo.581.1">reusable ML features and can be the target of a data processing/feature engineering job. </span><span class="koboSpan" id="kobo.581.2">The features from the feature repository can be a part of the training datasets where applicable. </span><span class="koboSpan" id="kobo.581.3">The feature repository is also used as a part of the model inference request.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.582.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.583.1">container repository</span></strong><span class="koboSpan" id="kobo.584.1"> stores </span><a id="_idIndexMarker927"/><span class="koboSpan" id="kobo.585.1">the container images that are used for data processing tasks, model training jobs, and model inference engines. </span><span class="koboSpan" id="kobo.585.2">It is usually the target of the container-building pipeline.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.586.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.587.1">model registry</span></strong><span class="koboSpan" id="kobo.588.1"> keeps </span><a id="_idIndexMarker928"/><span class="koboSpan" id="kobo.589.1">an inventory of trained models, along with all the metadata associated with the model, such as its algorithm, hyperparameters, model metrics, and training dataset location. </span><span class="koboSpan" id="kobo.589.2">It also maintains the status of the model lifecycle, such as its deployment approval status.</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.590.1">A </span><strong class="keyWord"><span class="koboSpan" id="kobo.591.1">pipeline repository</span></strong><span class="koboSpan" id="kobo.592.1"> maintains </span><a id="_idIndexMarker929"/><span class="koboSpan" id="kobo.593.1">the definition of automation pipelines and the statuses of different pipeline job executions.</span></li>
</ul>
<div class="note">
<p class="normal"><span class="koboSpan" id="kobo.594.1">In an enterprise setting, a task ticket also needs to be created when different tasks, such as model deployment, are performed, so that these actions can be tracked in a common enterprise ticketing management system. </span><span class="koboSpan" id="kobo.594.2">To support audit requirements, the lineage of different pipeline tasks and their associated artifacts need to be tracked.</span></p>
</div>
<p class="normal"><span class="koboSpan" id="kobo.595.1">Another critical component of</span><a id="_idIndexMarker930"/><span class="koboSpan" id="kobo.596.1"> the MLOps architecture is </span><strong class="keyWord"><span class="koboSpan" id="kobo.597.1">monitoring</span></strong><span class="koboSpan" id="kobo.598.1">. </span><span class="koboSpan" id="kobo.598.2">In general, you want to monitor items such as the pipeline’s execution status, model training status, and model endpoint status. </span><span class="koboSpan" id="kobo.598.3">Model endpoint monitoring can also include system/resource performance monitoring, model statistical metrics monitoring, drift and outlier monitoring, and model explainability monitoring. </span><span class="koboSpan" id="kobo.598.4">Alerts can be triggered on certain execution statuses to invoke human or automation actions that are needed.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.599.1">AWS provides </span><a id="_idIndexMarker931"/><span class="koboSpan" id="kobo.600.1">multiple technology options for implementing an MLOps architecture. </span><span class="koboSpan" id="kobo.600.2">The following diagram shows where these technology services fit in an enterprise MLOps architecture:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.601.1"><img alt="Figure 9.3 – MLOps architecture using AWS services  " src="../Images/B20836_09_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.602.1">Figure 9.4: MLOps architecture using AWS services</span></p>
<p class="normal"><span class="koboSpan" id="kobo.603.1">As we mentioned earlier, the shared service environment hosts common tools for pipeline management and execution, as well as common repositories such as code repositories and model registries.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.604.1">Here, we use AWS CodePipeline to orchestrate the overall CI/CD pipeline. </span><span class="koboSpan" id="kobo.604.2">AWS CodePipeline is a continuous delivery service. </span><span class="koboSpan" id="kobo.604.3">We use this service here as it integrates natively with different code repositories such as AWS CodeCommit, GitHub repos, and Bitbucket. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.605.1">It can source files from the code repository and make them available to downstream tasks such as building containers using the AWS CodeBuild service, or training models in the model training environment. </span><span class="koboSpan" id="kobo.605.2">You can create different pipelines to meet different needs. </span><span class="koboSpan" id="kobo.605.3">A pipeline can be triggered on-demand via an API or the CodePipeline management console, or it can be triggered by code changes in a code repository. </span><span class="koboSpan" id="kobo.605.4">Depending on your requirements, you can create different pipelines. </span><span class="koboSpan" id="kobo.605.5">In the preceding diagram, we can see four example pipelines:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.606.1">A container build pipeline for building different container images for training, processing, and inference</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.607.1">A model training pipeline for training a model for release</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.608.1">A model deployment pipeline for deploying trained models to production </span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.609.1">A development, training, and testing pipeline for model training and deployment testing in a data science environment</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.610.1">Note that</span><a id="_idIndexMarker932"/><span class="koboSpan" id="kobo.611.1"> while </span><em class="italic"><span class="koboSpan" id="kobo.612.1">Figure 9.4</span></em><span class="koboSpan" id="kobo.613.1"> only showcases four distinct pipelines, in reality, organizations can have many more pipelines based on specific requirements. </span><span class="koboSpan" id="kobo.613.2">Moreover, they can run multiple instances of the same pipeline in parallel to accommodate various ML projects. </span><span class="koboSpan" id="kobo.613.3">For instance, different instances of training job pipelines may run independently and concurrently, each dedicated to training distinct ML models using different datasets and configurations.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.614.1">A code repository is one of the most essential components in an MLOps environment. </span><span class="koboSpan" id="kobo.614.2">It is not only used by data scientists/ML engineers and other engineers to persist code artifacts, but it also serves as a triggering mechanism for a CI/CD pipeline. </span><span class="koboSpan" id="kobo.614.3">This means that when a data scientist/ML engineer commits a code change, it can automatically kick off a CI/CD pipeline. </span><span class="koboSpan" id="kobo.614.4">For example, if the data scientist makes a change to the model training script and wants to test the automated training pipeline in the development environment, they can commit the code to a development branch to kick off a model training pipeline in the dev environment. </span><span class="koboSpan" id="kobo.614.5">When it is ready for production release deployment, the data scientist can commit/merge the code to a release branch to kick off the production release pipelines.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.615.1">In a nutshell, in the MLOps architecture in </span><em class="italic"><span class="koboSpan" id="kobo.616.1">Figure 9.4</span></em><span class="koboSpan" id="kobo.617.1">, we use: </span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.618.1">Amazon</span><strong class="keyWord"><span class="koboSpan" id="kobo.619.1"> Elastic Container Registry</span></strong><span class="koboSpan" id="kobo.620.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.621.1">ECR</span></strong><span class="koboSpan" id="kobo.622.1">) as the central container registry service. </span><span class="koboSpan" id="kobo.622.2">ECR is</span><a id="_idIndexMarker933"/><span class="koboSpan" id="kobo.623.1"> used to store containers for data processing, model training, and model inference. </span><span class="koboSpan" id="kobo.623.2">You can tag the container images to indicate different lifecycle statuses, such as development or production.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.624.1">SageMaker Model Registry</span></strong><span class="koboSpan" id="kobo.625.1"> as the</span><a id="_idIndexMarker934"/><span class="koboSpan" id="kobo.626.1"> central model repository. </span><span class="koboSpan" id="kobo.626.2">The central model repository can reside in the shared service environment, so it can be accessed by different projects. </span><span class="koboSpan" id="kobo.626.3">All the models that go through the formal training and deployment cycles should be managed and tracked in the central model repository.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.627.1">SageMaker Feature Store</span></strong><span class="koboSpan" id="kobo.628.1"> provides</span><a id="_idIndexMarker935"/><span class="koboSpan" id="kobo.629.1"> a common feature repository for reusable features to be used by different projects. </span><span class="koboSpan" id="kobo.629.2">It can reside in the shared services environment or be part of the data platform. </span><span class="koboSpan" id="kobo.629.3">Features are normally pre-calculated in a data management environment and sent to SageMaker Feature Store for offline model training in the model training environment, as well as online inferences by the different model hosting environments.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-250"><span class="koboSpan" id="kobo.630.1">Monitoring and logging</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.631.1">The </span><a id="_idIndexMarker936"/><span class="koboSpan" id="kobo.632.1">ML platform presents some unique challenges in terms of monitoring. </span><span class="koboSpan" id="kobo.632.2">In addition to monitoring common software system-related metrics and statuses, such as infrastructure utilization and processing status, an ML platform also needs to monitor model, and data-specific metrics and performances. </span><span class="koboSpan" id="kobo.632.3">Also, unlike traditional system-level monitoring, which is fairly straightforward to understand, the opaqueness of ML models makes it inherently difficult to understand the system. </span><span class="koboSpan" id="kobo.632.4">Now, let’s take a closer look at the three main areas of monitoring for an ML platform.</span></p>
<h3 class="heading-3" id="_idParaDest-251"><span class="koboSpan" id="kobo.633.1">Model training monitoring</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.634.1">Model training monitoring</span><a id="_idIndexMarker937"/><span class="koboSpan" id="kobo.635.1"> provides visibility into the training progress and helps identify training bottlenecks and error conditions during the training process. </span><span class="koboSpan" id="kobo.635.2">It enables operational processes such as training job progress reporting and response, model training performance progress evaluation and response, training problem troubleshooting, and data and model bias detection and model interpretability and response. </span><span class="koboSpan" id="kobo.635.3">Specifically, we want to monitor the following key metrics and conditions during model training:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.636.1">General system and resource utilization and error metrics</span></strong><span class="koboSpan" id="kobo.637.1">: These provide visibility into how the infrastructure resources (such as CPU, GPU, disk I/O, and memory) are utilized for model training. </span><span class="koboSpan" id="kobo.637.2">These can help with making decisions on provisioning infrastructure for the different model training needs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.638.1">Training job events and status</span></strong><span class="koboSpan" id="kobo.639.1">: This provides visibility into the progress of a training job, such as a job starting and running, its completion, and failure details.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.640.1">Model training metrics</span></strong><span class="koboSpan" id="kobo.641.1">: These are model training metrics such as the loss curve and accuracy reports to help you understand the model’s performance.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.642.1">Bias detection metrics and model explainability reporting</span></strong><span class="koboSpan" id="kobo.643.1">: These metrics help you understand if there is any bias in the training datasets or ML models. </span><span class="koboSpan" id="kobo.643.2">Model explainability can also be monitored and reported to help you understand high-importance features versus low-importance features.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.644.1">Model training bottlenecks and training issues</span></strong><span class="koboSpan" id="kobo.645.1">: These provide visibility into training issues such as vanishing gradients, poor weight initialization, and overfitting to help determine the required data and algorithmic and training configuration changes. </span><span class="koboSpan" id="kobo.645.2">Metrics such as CPU and I/O bottlenecks, uneven load balancing, and low GPU utilization can help determine infrastructure configuration changes for more efficient model training.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.646.1">There are multiple</span><a id="_idIndexMarker938"/><span class="koboSpan" id="kobo.647.1"> native AWS services for building out a model monitoring architecture on AWS. </span><span class="koboSpan" id="kobo.647.2">The following diagram shows an example architecture for building a monitoring solution for a SageMaker-based model training environment:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.648.1"><img alt="Figure 9.4 – Model training monitoring architecture  " src="../Images/B20836_09_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.649.1">Figure 9.5: Model training monitoring architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.650.1">This</span><a id="_idIndexMarker939"/><span class="koboSpan" id="kobo.651.1"> architecture lets you monitor training and system metrics and perform log capture and processing, training event capture and processing, and model training bias and explainability reporting. </span><span class="koboSpan" id="kobo.651.2">It helps enable operation processes, such as training progress and status reporting, model metric evaluation, system resource utilization reporting and response, training problem troubleshooting, bias detection, and model decision explainability.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.652.1">During model training, SageMaker can emit model training metrics, such as training loss and accuracy, to AWS CloudWatch to help with model training evaluation. </span><span class="koboSpan" id="kobo.652.2">AWS CloudWatch is the AWS monitoring and observability service. </span><span class="koboSpan" id="kobo.652.3">It collects metrics and logs from other AWS services and provides dashboards for visualizing and analyzing these metrics and logs. </span><span class="koboSpan" id="kobo.652.4">System utilization metrics (such as CPU/GPU/memory utilization) are also reported to CloudWatch for analysis to help you understand any infrastructure constraints or under-utilization. </span><span class="koboSpan" id="kobo.652.5">CloudWatch alarms can be created for a single metric or composite metrics to automate notifications or responses. </span><span class="koboSpan" id="kobo.652.6">For example, you can create alarms on low CPU/GPU utilization to help proactively identify sub-optimal hardware configuration for the training job. </span><span class="koboSpan" id="kobo.652.7">Also, when an alarm is triggered, it can send automated notifications (such as SMS and emails) to </span><a id="_idIndexMarker940"/><span class="koboSpan" id="kobo.653.1">support for review via AWS </span><strong class="keyWord"><span class="koboSpan" id="kobo.654.1">Simple Notification Service</span></strong><span class="koboSpan" id="kobo.655.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.656.1">SNS</span></strong><span class="koboSpan" id="kobo.657.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.658.1">You can use CloudWatch Logs to collect, monitor, and analyze the logs that are emitted by your training jobs. </span><span class="koboSpan" id="kobo.658.2">You can use these captured logs to understand the progress of your training jobs and identify errors and patterns to help troubleshoot any model training problems. </span><span class="koboSpan" id="kobo.658.3">For </span><a id="_idIndexMarker941"/><span class="koboSpan" id="kobo.659.1">example, CloudWatch Logs might contain errors such as insufficient GPU memory to run model training or permission issues when accessing specific resources to help you troubleshoot model training problems. </span><span class="koboSpan" id="kobo.659.2">By default, CloudWatch Logs provides a UI tool called CloudWatch Logs Insights for interactively analyzing logs using a purpose-built query language. </span><span class="koboSpan" id="kobo.659.3">Alternatively, these logs can also be forwarded to an Elasticsearch cluster for analysis and querying. </span><span class="koboSpan" id="kobo.659.4">These logs can be aggregated in a designated logging and monitoring account to centrally manage log access and analysis.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.660.1">SageMaker training jobs can also send events, such as a training job status changing from running to complete. </span><span class="koboSpan" id="kobo.660.2">You can create automated notification and response mechanisms based on these different events. </span><span class="koboSpan" id="kobo.660.3">For example, you can send out notifications to data scientists when a training job has either completed successfully or failed, along with a failure reason. </span><span class="koboSpan" id="kobo.660.4">You can also automate responses to these failures to the different statuses, such as model retraining on a particular failure condition.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.661.1">The SageMaker Clarify component can detect data and model bias and provide model explainability reporting on the trained model. </span><span class="koboSpan" id="kobo.661.2">You can access bias and model explainability reports inside the SageMaker Studio UI or SageMaker APIs.</span></p>
<h3 class="heading-3" id="_idParaDest-252"><span class="koboSpan" id="kobo.662.1">Model endpoint monitoring</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.663.1">Model endpoint monitoring</span><a id="_idIndexMarker942"/><span class="koboSpan" id="kobo.664.1"> provides visibility into the performance of the model serving infrastructure, as well as model-specific metrics such as data drift, model drift, and inference explainability. </span><span class="koboSpan" id="kobo.664.2">The following are some of the key metrics for model endpoint monitoring:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.665.1">General system and resource utilization and error metrics</span></strong><span class="koboSpan" id="kobo.666.1">: These provide visibility into how the infrastructure resources (such as CPU, GPU, and memory) are utilized for model servicing. </span><span class="koboSpan" id="kobo.666.2">They can help with making decisions on provisioning infrastructure for the different model-serving needs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.667.1">Data statistics monitoring metrics</span></strong><span class="koboSpan" id="kobo.668.1">: The statistical nature of data could change over time, which can result in degraded ML model performance from the original benchmarks. </span><span class="koboSpan" id="kobo.668.2">These metrics can include basic statistics deviations such as mean and standard changes, as well as data distribution changes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.669.1">Model quality monitoring metrics</span></strong><span class="koboSpan" id="kobo.670.1">: These model quality metrics provide visibility into model performance deviation from the original benchmark. </span><span class="koboSpan" id="kobo.670.2">These metrics can include regression metrics (such as MAE and RMSE) and classification metrics (such as confusion matrix, F1, precision, recall, and accuracy).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.671.1">Model inference explainability</span></strong><span class="koboSpan" id="kobo.672.1">: This provides model explainability on a per-prediction basis to help you understand what features had the most influence on the decision that was made by the prediction.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.673.1">Model bias monitoring metrics</span></strong><span class="koboSpan" id="kobo.674.1">: Similar to bias detection for training, the bias metrics help us understand model bias at inference time.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.675.1">The model monitoring architecture</span><a id="_idIndexMarker943"/><span class="koboSpan" id="kobo.676.1"> relies on many of the same AWS services, including CloudWatch, EventBridge, and SNS. </span><span class="koboSpan" id="kobo.676.2">The following diagram shows an architecture pattern for a SageMaker-based model monitoring solution:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.677.1"><img alt="Figure 9.5 – Model endpoint monitoring architecture " src="../Images/B20836_09_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.678.1">Figure 9.6: Model endpoint monitoring architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.679.1">This </span><a id="_idIndexMarker944"/><span class="koboSpan" id="kobo.680.1">architecture works similarly to the model training architecture. </span><strong class="keyWord"><span class="koboSpan" id="kobo.681.1">CloudWatch metrics</span></strong><span class="koboSpan" id="kobo.682.1"> capture </span><a id="_idIndexMarker945"/><span class="koboSpan" id="kobo.683.1">endpoint metrics such as CPU/GPU utilization, model invocation metrics (number of invocations and errors), and model latencies. </span><span class="koboSpan" id="kobo.683.2">These metrics help with operations such as hardware optimization and endpoint scaling.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.684.1">CloudWatch Logs</span></strong><span class="koboSpan" id="kobo.685.1"> captures </span><a id="_idIndexMarker946"/><span class="koboSpan" id="kobo.686.1">logs that are emitted by the model-serving endpoint to help us understand the status and troubleshoot technical problems. </span><span class="koboSpan" id="kobo.686.2">Similarly, endpoint events, such as the status changing from </span><strong class="keyWord"><span class="koboSpan" id="kobo.687.1">Creating</span></strong><span class="koboSpan" id="kobo.688.1"> to </span><strong class="keyWord"><span class="koboSpan" id="kobo.689.1">InService</span></strong><span class="koboSpan" id="kobo.690.1">, can help you build automated notification pipelines to kick off corrective actions or provide status updates.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.691.1">In addition to system- and status-related monitoring, this architecture also supports data and model-specific monitoring through a combination of SageMaker Model Monitor and SageMaker Clarify. </span><span class="koboSpan" id="kobo.691.2">Specifically, SageMaker Model Monitor can help you monitor data drift and model quality.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.692.1">For data drift, SageMaker Model Monitor can use the training dataset to create baseline statistics metrics such as standard deviation, mean, max, min, and data distribution for the dataset features. </span><span class="koboSpan" id="kobo.692.2">It uses these metrics and other data characteristics, such as data types and completeness, to establish constraints. </span><span class="koboSpan" id="kobo.692.3">Then, it captures the input data in the production environment, calculates the metrics, compares them with the baseline metrics/constraints, and reports baseline drifts. </span><span class="koboSpan" id="kobo.692.4">Model Monitor can also report data quality issues such as incorrect data types and missing values. </span><span class="koboSpan" id="kobo.692.5">Data drift metrics can be sent to CloudWatch metrics for visualization and analysis, and CloudWatch alarms can be configured to trigger a notification or automated response when a metric crosses a predefined threshold.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.693.1">For</span><a id="_idIndexMarker947"/><span class="koboSpan" id="kobo.694.1"> model quality monitoring, it creates baseline metrics (such as MAE for regression and accuracy for classification) using the baseline dataset, which contains both predictions and true labels. </span><span class="koboSpan" id="kobo.694.2">Then, it captures the predictions in production, ingests ground-truth labels, and merges the ground truth with the predictions to calculate various regression and classification metrics before comparing those with the baseline metrics. </span><span class="koboSpan" id="kobo.694.3">Similar to data drift metrics, model quality metrics can be sent to CloudWatch Metrics for analysis and visualization and CloudWatch alarms can be configured for automated notifications and/or responses. </span><span class="koboSpan" id="kobo.694.4">The following diagram shows how SageMaker Model Monitor works:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.695.1"><img alt="Figure 9.6 – SageMaker Model Monitor process flow " src="../Images/B20836_09_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.696.1">Figure 9.7: SageMaker Model Monitor process flow</span></p>
<p class="normal"><span class="koboSpan" id="kobo.697.1">For bias detection, SageMaker Clarify can monitor bias metrics for deployed models continuously and raises alerts through CloudWatch when a metric crosses a threshold. </span><span class="koboSpan" id="kobo.697.2">We will cover bias detection in detail in </span><em class="italic"><span class="koboSpan" id="kobo.698.1">Chapter 13, Bias, Explainability, Privacy, and, Adversarial Attacks</span></em><span class="koboSpan" id="kobo.699.1">.</span></p>
<h3 class="heading-3" id="_idParaDest-253"><span class="koboSpan" id="kobo.700.1">ML pipeline monitoring</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.701.1">The ML pipeline’s execution</span><a id="_idIndexMarker948"/><span class="koboSpan" id="kobo.702.1"> needs to be monitored for statuses and errors, so corrective actions can be taken as needed. </span><span class="koboSpan" id="kobo.702.2">During a pipeline execution, there are pipeline-level statuses/events as well as stage-level and action-level statuses/events. </span><span class="koboSpan" id="kobo.702.3">You can use these events and statuses to understand the progress of each pipeline and stage and be alerted when something is wrong. </span><span class="koboSpan" id="kobo.702.4">The following diagram shows how AWS CodePipeline, CodeBuild, and CodeCommit can work with CloudWatch, CloudWatch Logs, and EventBridge for general status monitoring and reporting, as well as problem troubleshooting:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.703.1"><img alt="Figure 9.7 – ML CI/CD pipeline monitoring architecture " src="../Images/B20836_09_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.704.1">Figure 9.8: ML CI/CD pipeline monitoring architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.705.1">CodeBuild can send metrics, such as </span><code class="inlineCode"><span class="koboSpan" id="kobo.706.1">SucceededBuilds</span></code><span class="koboSpan" id="kobo.707.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.708.1">FailedBuilds</span></code><span class="koboSpan" id="kobo.709.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.710.1">Duration</span></code><span class="koboSpan" id="kobo.711.1"> metrics. </span><span class="koboSpan" id="kobo.711.2">These CodeBuild metrics can be accessed through both the CodeBuild console and the CloudWatch dashboard. </span><span class="koboSpan" id="kobo.711.3">CodeBuild, CodeCommit, and CodePipeline can all emit events to EventBridge to report detailed status changes and trigger custom event processing, such as</span><a id="_idIndexMarker949"/><span class="koboSpan" id="kobo.712.1"> notifications, or log the events to another data repository for event archiving. </span><span class="koboSpan" id="kobo.712.2">All three services can send detailed logs to CloudWatch Logs to support operations such as troubleshooting or detailed error reporting.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.713.1">Step Functions also provides a list of monitoring metrics to CloudWatch, such as execution metrics (such as execution failure, success, abort, and timeout) and activity metrics (such as activity started, scheduled, and succeeded). </span><span class="koboSpan" id="kobo.713.2">You can view these metrics in the management console and set a threshold to set up alerts.</span></p>
<h3 class="heading-3" id="_idParaDest-254"><span class="koboSpan" id="kobo.714.1">Service provisioning management</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.715.1">Another</span><a id="_idIndexMarker950"/><span class="koboSpan" id="kobo.716.1"> key component of enterprise-scale ML platform management is </span><strong class="keyWord"><span class="koboSpan" id="kobo.717.1">service</span></strong> <strong class="keyWord"><span class="koboSpan" id="kobo.718.1">provisioning management</span></strong><span class="koboSpan" id="kobo.719.1">. </span><span class="koboSpan" id="kobo.719.2">For large-scale service </span><a id="_idIndexMarker951"/><span class="koboSpan" id="kobo.720.1">provisioning and deployment, an automated and controlled process should be adopted. </span><span class="koboSpan" id="kobo.720.2">Here, we will focus on provisioning the ML platform itself, not provisioning AWS accounts and networking, which should be established as the base environment for ML platform provisioning in advance. </span><span class="koboSpan" id="kobo.720.3">For ML platform provisioning, there are the following two main provisioning tasks:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.721.1">Data science environment provisioning</span></strong><span class="koboSpan" id="kobo.722.1">: Provisioning the data science environment for data scientists mainly includes provisioning data science and data management tools, storage for experimentation, as well as access entitlement for data sources and pre-built ML automation pipelines.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.723.1">ML automation pipeline provisioning</span></strong><span class="koboSpan" id="kobo.724.1">: ML automation pipelines need to be provisioned in advance for data scientists and MLOps engineers to use them to automate different tasks such as container build, model training, and model deployment.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.725.1">There are multiple technical approaches to automating service provisioning on AWS, such as using provisioning shell scripts, CloudFormation scripts, and AWS Service Catalog. </span><span class="koboSpan" id="kobo.725.2">With shell scripts, you can sequentially call the different AWS CLI commands in a script to provision different components, such as creating a SageMaker Studio notebook. </span><span class="koboSpan" id="kobo.725.3">CloudFormation is the IaC service for infrastructure deployment on AWS. </span><span class="koboSpan" id="kobo.725.4">With CloudFormation, you create templates that describe the desired resources and dependencies that can be launched as a single stack. </span><span class="koboSpan" id="kobo.725.5">When the template is executed, all the resources and</span><a id="_idIndexMarker952"/><span class="koboSpan" id="kobo.726.1"> dependencies specified in the stack will be deployed automatically. </span><span class="koboSpan" id="kobo.726.2">The following code shows the template for deploying a SageMaker Studio domain:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr"><span class="koboSpan" id="kobo.727.1">Type:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.728.1">AWS::SageMaker::Domain</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.729.1">Properties:</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.730.1">AppNetworkAccessType:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.731.1">String</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.732.1">AuthMode:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.733.1">String</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.734.1">DefaultUserSettings:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.735.1">UserSettings</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.736.1">DomainName:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.737.1">String</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.738.1">KmsKeyId:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.739.1">String</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.740.1">SubnetIds:</span></span>
<span class="hljs-bullet"><span class="koboSpan" id="kobo.741.1">-</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.742.1">String</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.743.1">Tags:</span></span>
<span class="hljs-bullet"><span class="koboSpan" id="kobo.744.1">-</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.745.1">Tag</span></span>
<span class="hljs-attr"><span class="koboSpan" id="kobo.746.1">VpcId:</span></span> <span class="hljs-string"><span class="koboSpan" id="kobo.747.1">String</span></span>
</code></pre>
<p class="normal"><span class="koboSpan" id="kobo.748.1">AWS Service Catalog</span><a id="_idIndexMarker953"/><span class="koboSpan" id="kobo.749.1"> allows you to create different IT products to be deployed on AWS. </span><span class="koboSpan" id="kobo.749.2">These IT products can include SageMaker notebooks, a CodeCommit repository, and CodePipeline workflow definitions. </span><span class="koboSpan" id="kobo.749.3">AWS Service Catalog uses CloudFormation templates to describe IT products. </span><span class="koboSpan" id="kobo.749.4">With Service Catalog, administrators create IT products with CloudFormation templates, organize these products by product portfolio, and entitle end users to access. </span><span class="koboSpan" id="kobo.749.5">The end users then access the products from the Service Catalog product portfolio.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.750.1">The following diagram shows the flow of creating a Service Catalog product and launching the product from the Service Catalog service:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.751.1"><img alt="Figure 9.8 – Service Catalog workflow " src="../Images/B20836_09_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.752.1">Figure 9.9: Service Catalog workflow</span></p>
<p class="normal"><span class="koboSpan" id="kobo.753.1">For large-scale and governed IT product management, Service Catalog is the recommended</span><a id="_idIndexMarker954"/><span class="koboSpan" id="kobo.754.1"> approach. </span><span class="koboSpan" id="kobo.754.2">Service Catalog supports multiple deployment options, including single AWS account deployments and hub-and-spoke cross-account deployments. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.755.1">A hub-and-spoke deployment allows you to centrally manage all the products </span><a id="_idIndexMarker955"/><span class="koboSpan" id="kobo.756.1">and make them available in different accounts. </span><span class="koboSpan" id="kobo.756.2">For our enterprise ML reference architecture in </span><em class="italic"><span class="koboSpan" id="kobo.757.1">Figure 9.4</span></em><span class="koboSpan" id="kobo.758.1">, we can use the hub-and-spoke architecture to support the provisioning of data science environments and ML pipelines, as shown in the following diagram:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.759.1"><img alt="Figure 9.9 – The hub-and-spoke Service Catalog architecture for enterprise ML product management " src="../Images/B20836_09_10.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.760.1">Figure 9.10: The hub-and-spoke Service Catalog architecture for enterprise ML product management</span></p>
<p class="normal"><span class="koboSpan" id="kobo.761.1">In the </span><a id="_idIndexMarker956"/><span class="koboSpan" id="kobo.762.1">preceding architecture, we set up the central portfolio</span><a id="_idIndexMarker957"/><span class="koboSpan" id="kobo.763.1"> in the shared services account. </span><span class="koboSpan" id="kobo.763.2">All the products, such as creating new Studio domains, new Studio user profiles, CodePipeline definitions, and training pipeline definitions, are centrally managed in the central hub account. </span><span class="koboSpan" id="kobo.763.3">Some products are shared with the different data science accounts to create data science environments for data scientists and teams. </span><span class="koboSpan" id="kobo.763.4">Some other products are shared with model training accounts for standing up ML training pipelines.</span></p>
<h1 class="heading-1" id="_idParaDest-255"><span class="koboSpan" id="kobo.764.1">Best practices in building and operating an ML platform</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.765.1">Constructing</span><a id="_idIndexMarker958"/><span class="koboSpan" id="kobo.766.1"> an enterprise ML platform is a multifaceted undertaking. </span><span class="koboSpan" id="kobo.766.2">It often requires significant time, with organizations taking six months or more to implement the initial phase of their ML platform. </span><span class="koboSpan" id="kobo.766.3">Continuous efforts are needed to incorporate new functionalities and enhancements for many years to come. </span><span class="koboSpan" id="kobo.766.4">Onboarding users and ML projects onto the new platform is another demanding aspect, involving extensive education for the user base and providing direct technical support. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.767.1">In some cases, platform adjustments might be necessary to ensure smooth onboarding and successful utilization. </span><span class="koboSpan" id="kobo.767.2">Having collaborated with many customers in building their enterprise ML platform, I have identified some best practices for the construction and adoption of an ML platform.</span></p>
<h2 class="heading-2" id="_idParaDest-256"><span class="koboSpan" id="kobo.768.1">ML platform project execution best practices</span></h2>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.769.1">Assemble cross-functional teams</span></strong><span class="koboSpan" id="kobo.770.1">: Bring together data engineers, ML researchers, DevOps </span><a id="_idIndexMarker959"/><span class="koboSpan" id="kobo.771.1">engineers, application developers, and business domain experts into integrated teams. </span><span class="koboSpan" id="kobo.771.2">This diversity of skills and perspectives will enrich the platform design and implementation.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.772.1">Develop governance requirements and processes</span></strong><span class="koboSpan" id="kobo.773.1">: Define processes and requirements early on for model verification, explainability, ethics reviews, and approvals prior to production deployment. </span><span class="koboSpan" id="kobo.773.2">This will embed responsible AI practices into the platform.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.774.1">Define key performance indicators (KPIs) to measure success</span></strong><span class="koboSpan" id="kobo.775.1">: Identify relevant business KPIs and implement processes to actively monitor and report on model and platform impact on these KPIs. </span><span class="koboSpan" id="kobo.775.2">Share reports with stakeholders.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.776.1">Select pilot ML workloads</span></strong><span class="koboSpan" id="kobo.777.1">: Choose a few pilot ML projects or workloads to implement first on the new platform. </span><span class="koboSpan" id="kobo.777.2">Learn from these real-world use cases to validate and improve the platform design and capabilities.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.778.1">Define the target state and execute in phases</span></strong><span class="koboSpan" id="kobo.779.1">: Articulate the long-term vision and target state for the enterprise ML platform. </span><span class="koboSpan" id="kobo.779.2">However, strategically execute adoption in incremental phases for faster learning.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-257"><span class="koboSpan" id="kobo.780.1">ML platform design and implementation best practices</span></h2>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.781.1">Adopt fully managed built-in capabilities</span></strong><span class="koboSpan" id="kobo.782.1">: Leverage SageMaker’s managed algorithms, containers, and </span><a id="_idIndexMarker960"/><span class="koboSpan" id="kobo.783.1">features as defaults to reduce overhead and simplify integration. </span><span class="koboSpan" id="kobo.783.2">Only use custom built features if needed.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.784.1">Implement infrastructure as code</span></strong><span class="koboSpan" id="kobo.785.1">: Use CloudFormation or Terraform to provision, configure, and manage ML infrastructure through code. </span><span class="koboSpan" id="kobo.785.2">This enables consistency and automation.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.786.1">Build CI/CD pipelines</span></strong><span class="koboSpan" id="kobo.787.1">: Implement continuous integration and deployment pipelines leveraging CodePipeline, CodeBuild, CodeDeploy, and SageMaker for automated workflows. </span><span class="koboSpan" id="kobo.787.2">Consider GitHub Actions/Jenkins if needed.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.788.1">Automate experiment tracking</span></strong><span class="koboSpan" id="kobo.789.1">: Configure SageMaker or third-party tools to automatically log model training metadata like parameters, metrics, and artifacts. </span><span class="koboSpan" id="kobo.789.2">This enables debugging, comparisons, and reproducibility.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.790.1">Establish an approved library repository</span></strong><span class="koboSpan" id="kobo.791.1">: Create a centralized, governed repository of approved libraries and packages for training, deployment, and inference code. </span><span class="koboSpan" id="kobo.791.2">This ensures consistency.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.792.1">Design for scalability and spikes</span></strong><span class="koboSpan" id="kobo.793.1">: Architect the platform to handle varied usage patterns and traffic spikes via auto-scaling capabilities.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.794.1">Prioritize security from the start</span></strong><span class="koboSpan" id="kobo.795.1">: Implement security best practices including scanning, patching, encryption, and access controls. </span><span class="koboSpan" id="kobo.795.2">Have an incident response plan.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.796.1">Build self-service capability</span></strong><span class="koboSpan" id="kobo.797.1">: Develop self-service functionality early and evolve it to</span><a id="_idIndexMarker961"/><span class="koboSpan" id="kobo.798.1"> empower users while maintaining governance.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.799.1">Centralize the model repository</span></strong><span class="koboSpan" id="kobo.800.1">: Use a single, central repository for models to improve collaboration, discovery, compliance, and efficient deployment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.801.1">Establish a central feature store</span></strong><span class="koboSpan" id="kobo.802.1">: Implement a centralized feature store for sharing, monitoring, and governing feature engineering work and usage.</span></li>
</ul>
<h2 class="heading-2" id="_idParaDest-258"><span class="koboSpan" id="kobo.803.1">Platform use and operations best practices</span></h2>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.804.1">Limit production access</span></strong><span class="koboSpan" id="kobo.805.1">: Restrict </span><a id="_idIndexMarker962"/><span class="koboSpan" id="kobo.806.1">access to production systems to only essential support and operations staff. </span><span class="koboSpan" id="kobo.806.2">This reduces the risk of mistakes or unauthorized changes.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.807.1">Optimize costs</span></strong><span class="koboSpan" id="kobo.808.1">: Leverage auto-scaling, spot instances, availability-based pricing, and other capabilities to optimize and reduce cloud costs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.809.1">Monitoring and observability</span></strong><span class="koboSpan" id="kobo.810.1">: Actively monitor model accuracy, data drift, system performance, and so on using CloudWatch, SageMaker Debugger, Model Monitor, and other tools.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.811.1">Establish change management</span></strong><span class="koboSpan" id="kobo.812.1">: Define a structured process for managing, reviewing, approving, and communicating platform/model changes prior to deployment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.813.1">Incident management process</span></strong><span class="koboSpan" id="kobo.814.1">: Institute an incident response plan with procedures to detect, escalate, and resolve production issues and anomalies in a timely manner.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.815.1">Multi-AZ and region deployments</span></strong><span class="koboSpan" id="kobo.816.1">: Deploy models and platform infrastructure across multiple availability zones and regions to improve resilience and minimize latency.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.817.1">Release management</span></strong><span class="koboSpan" id="kobo.818.1">: Implement structured release processes for coordinating, reviewing, and planning changes and new model/platform versions before deployment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.819.1">Capacity planning</span></strong><span class="koboSpan" id="kobo.820.1">: Proactively assess and project infrastructure capacity needs based on roadmaps and workloads. </span><span class="koboSpan" id="kobo.820.2">Scale appropriately.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.821.1">Resource tagging</span></strong><span class="koboSpan" id="kobo.822.1">: A properly designed tagging strategy provides organization, discovery, security, automation, compliance, and improved visibility in an ML platform.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.823.1">Implementing </span><a id="_idIndexMarker963"/><span class="koboSpan" id="kobo.824.1">a robust enterprise ML platform requires thoughtful strategy and orchestration across people, processes, and technology. </span><span class="koboSpan" id="kobo.824.2">By bringing together cross-functional teams, instituting responsible AI governance, monitoring business impact, and designing for scalability, security, and collaboration, organizations can accelerate their AI journey. </span><span class="koboSpan" id="kobo.824.3">Adopting modern infrastructure as code, CI/CD pipelines, and cloud services lays a solid technology foundation. </span><span class="koboSpan" id="kobo.824.4">However, to realize value, platforms must be tightly integrated with line-of-business priorities and continuously provide trustworthy AI. </span><span class="koboSpan" id="kobo.824.5">With deliberate planning and phased execution centered on business goals and users, companies can transform into AI-driven enterprises.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.825.1">The key is to balance innovation with governance, move fast through automation while maintaining control, and evolve a platform that responsibly democratizes AI capabilities for both experts and business users. </span><span class="koboSpan" id="kobo.825.2">This enables embedding reliable and accountable AI throughout operations for a competitive advantage.</span></p>
<h1 class="heading-1" id="_idParaDest-259"><span class="koboSpan" id="kobo.826.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.827.1">In this chapter, we explored the key requirements and best practices for building an enterprise ML platform. </span><span class="koboSpan" id="kobo.827.2">We discussed how to design a platform that supports the end-to-end ML lifecycle, process automation, and separation of environments. </span><span class="koboSpan" id="kobo.827.3">Architectural patterns were reviewed, including how to leverage AWS services to build a robust ML platform on the cloud.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.828.1">The core capabilities of different ML environments were covered, such as training, hosting, and shared services. </span><span class="koboSpan" id="kobo.828.2">Best practices around platform design, operations, governance, and integration were also discussed. </span><span class="koboSpan" id="kobo.828.3">You should now have a solid understanding of what an enterprise-grade ML platform entails and key considerations for building one on AWS leveraging proven patterns.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.829.1">In the next chapter, we will dive deeper into advanced ML engineering topics. </span><span class="koboSpan" id="kobo.829.2">This includes distributed training techniques to scale model development and low-latency serving methods for optimizing inference.</span></p>
<h1 class="heading-1"><span class="koboSpan" id="kobo.830.1">Join our community on Discord</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.831.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
<p class="normal"><a href="https://packt.link/mlsah "><span class="url"><span class="koboSpan" id="kobo.832.1">https://packt.link/mlsah</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.833.1"><img alt="" role="presentation" src="../Images/QR_Code70205728346636561.png"/></span></p>
</div>
</body></html>