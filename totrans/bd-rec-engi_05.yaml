- en: Chapter 5. Building Collaborative Filtering Recommendation Engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learn how to implement collaborative filtering recommendation
    systems using popular data analysis programming languages, R and Python. We will
    learn how to implement user-based collaborative filtering and item-based collaborative
    filtering in R and Python programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we learn about:'
  prefs: []
  type: TYPE_NORMAL
- en: The Jester5k dataset we will be using for this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the dataset and understanding the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation engine packages/libraries available in R and Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building user-based collaborative filtering in R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building item-based collaborative filtering in R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building user-based collaborative filtering in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Item-based collaborative filtering in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **recommenderlab**, R package is a framework for developing and testing
    recommendation algorithms including user-based collaborative filtering, item-based
    collaborative filtering, SVD, and association rule-based algorithms, which are
    used to build recommendation engines. This package also provides basic infrastructure
    or mechanisms to develop our own recommendation engine methodology.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the recommenderlab package in RStudio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following code snippet, will install the `recommenderlab` package into
    RStudio, if it is not available:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'First the r-environment checks if there are any previous installations of the
    recommender lab package, if none are found then it installs as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code snippet using `library()` loads the `recommenderlab` package
    into the r-environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To get help on the `recommenderlab` package using the help function, run the
    following command in Rstudio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the help page for details on the usage of the package by clicking on
    the links provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing the recommenderlab package in RStudio](img/image00320.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Datasets available in the recommenderlab package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Like any other package available in R, `recommenderlab` also comes with default
    datasets. Run the following command to show the available packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Datasets available in the recommenderlab package](img/image00321.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Out of all the available datasets, we have chosen to use the `Jester5k` dataset
    for implementing user-based collaborative filtering and item-based collaborative
    filtering recommendation engines using R.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Jester5K dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we shall explore the `Jester5K` dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dataset contains a sample of 5000 users from the Jester Online Joke Recommender
    System anonymous ratings data, collected between April 1999 and May 2003.
  prefs: []
  type: TYPE_NORMAL
- en: Usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The format of `Jester5k` is: `Formal class ''realRatingMatrix'' [package "recommenderlab"]`.'
  prefs: []
  type: TYPE_NORMAL
- en: The format of `JesterJokes` is a vector of character strings.
  prefs: []
  type: TYPE_NORMAL
- en: Details
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`Jester5k` contains a *5000 x 100* rating matrix (5000 users and 100 jokes)
    with ratings between -10.00 and +10.00\. All selected users have rated 36 or more
    jokes.'
  prefs: []
  type: TYPE_NORMAL
- en: The data also contains the actual jokes in `JesterJokes`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of ratings present in the real-rating matrix is represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can display the class of the rating matrices by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `recommenderlab` package efficiently stores the rating information in a
    compact way. Usually, rating matrices are sparse matrices. For this reason, the
    `realRatingMatrix` class supports a compact storage of sparse matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compare the size of `Jester5k` with the corresponding R matrix to understand
    the advantage of the real rating matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We observe that the real-rating matrix stores `0.92` times less space than the
    R matrix. For collaborative filtering methods, which are memory-based models,
    where all the data is loaded into the memory while generating recommendations,
    storing data efficiently is very important. The `recommenderlab` package does
    this job efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '`The recommenderlab` package exposes many functions which can be operated on
    using the rating matrix object. Run the following command to see the available
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![Details](img/image00322.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the following commands to see the available recommendation algorithms in
    the `recommenderlab` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![Details](img/image00323.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code snippet displays the same result as in the previous image,
    `lapply()` function applies the function to all the elements of the list, in our
    case, for each of the items in the `recommender_models` object, `lapply` will
    extract the description and display the results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Exploring the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section let''s explore the data in more detail. To find the dimensions
    of the data and the type of data, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are `5000` users and `100` items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The data is of R Matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Exploring the rating values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following code snippet will help us understand the rating values distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rating distribution is given as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Exploring the rating values](img/image00324.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding image shows the frequency of the ratings available from the `Jester5K`
    dataset. We can observe that the negative ratings are more or less of uniform
    distribution or the same frequency, and the positive ratings are of a higher frequency
    and are declining towards the right of the plot. This may attribute to the bias
    induced by the ratings given by the users.
  prefs: []
  type: TYPE_NORMAL
- en: Building user-based collaborative filtering with recommenderlab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Run the following code in order to load the `recommenderlab` library and data
    into the R environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at the sample rating data of the first six users on the first 10
    jokes. Run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Building user-based collaborative filtering with recommenderlab](img/image00325.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We have looked at exploring the data in the previous section so we will get
    directly to building a user-based collaborative recommender system.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section is divided as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Building a base recommender model for benchmarking by splitting the data into
    80% training data and 20% test data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the recommender model using a k-fold cross-validation approach model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameter tuning for the recommender model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing training and test data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For building and evaluating a recommender model, we need training data and
    test data. Run the following command to create it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the seed function for generating reproducible results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The previous code creates a logical object with an equal length to the number
    of users. True indexes will be part of the train set and false indexes will be
    part of the test set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Creating a user-based collaborative model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s create a recommendation model on the whole data of `Jester5k`.
    Before that, let''s explore the recommender models available and their parameters
    in the `recommenderlab` package as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![Creating a user-based collaborative model](img/image00326.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Image we just saw displays the 6 different recommender models available and
    its parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following code to build a user-based collaborative filtering model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `recc_model@model$data` object contains the rating matrix. The reason for
    this is that UBCF is a lazy-learning technique, which means that it needs to access
    all the data to perform a prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Predictions on the test set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have built the model, let''s predict the recommendations on the
    test set. For this we will use the `predict()` function available in the library.
    We generate 10 recommendations per user. See the following code for the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The resultant object is a list type given by the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The first two recommendations are given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can observe that for user `u21505`, the top 10 recommendations are given
    as `j81, j73, j83, ... j96`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows the recommendations for four users:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predictions on the test set](img/image00327.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how many recommendations are generated for all the test users by
    running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: From the above results, we see that for `286` users, zero recommendations were
    generated. The reason is that they have rated all the movies in the original dataset.
    For 691 users, 10 ratings for each of them has been generated, the reason is that
    in the original dataset, they have not rated for any movies. Other users who have
    received 2, 3, 4, and so on recommendations means that they have recommended very
    few movies.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we evaluate the model, let's take one step back and analyze the data.
    By analyzing the number of ratings given by all the users for the jokes, we can
    observe that there are 1422 people who have rated all 100 jokes, which seems to
    be unusual as there are very few people who have rated 80 to 99 jokes. Further
    analyzing the jokes we find that, there are 221, 364, 312, and 131 users who have
    rated 71, 72, 73, and 74 jokes respectively which seems to be unusual compared
    to other joke ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following code to extract the number of ratings given to each joke:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/image00328.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'For the next step, let''s remove the records of users who have rated 80 or
    more jokes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The dimension has been reduced from `5000` to `3261` records.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's analyze the average ratings given by each user. A boxplot shows us
    the average distribution of the joke ratings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/image00329.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding image shows us that there are very few ratings that deviate from
    normal behavior. From the preceding image we see that the average ratings that
    are above 7 (approximately) and below -5 (approximately) are kind of outliers
    and are less in number. Let''s see the count by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/image00330.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Dropping users who have given very low average ratings and very high average
    ratings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s examine the rating distribution of the first 100 users in the data as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/image00331.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Evaluating the recommendation model using the k-cross validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `recommenderlab` package provides an infrastructure for evaluating the models
    using the `evaluationScheme()` function. By definition, from the Cran website,
    evaluationScheme *creates an evaluationScheme object from a data set. The scheme
    can be a simple split into training and test data, k-fold cross-evaluation or
    using k independent bootstrap samples*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the arguments for the `evaluationScheme()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating the recommendation model using the k-cross validation](img/image00332.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We use cross-validation method to split the data, for example the 5-fold cross-validation
    approach divides the training data into five smaller sets where four sets will
    be used for training the model and the remaining one set is used for evaluating
    the model. Let''s define the parameters into minimum good ratings, number of folds
    for cross-validation method, and split method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s examine the size of the five sets formed by the cross-validation approach
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to extract the sets, we need to use `getData()`. There are three sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**train**: This is the training set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**known**: This is the test set, with the item used to build the recommendations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**unknown**: This is the test set, with the item used to test the recommendations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the training set in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating user-based collaborative filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let''s evaluate the models, let''s set the parameters `model_to_evaluate`
    with user-based collaborative filtering and `model_parameters` with `NULL` for
    using default settings as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to build the recommender model using the recommender() function
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We have seen that the user-based recommender model has been learned with a training
    data of `2528 users`. Now we can predict the known ratings in `eval_sets` and
    evaluate the results with unknown sets as described earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before making the predictions for the known ratings, we have to set the number
    of items to be recommended. Next, we have to provide the test set to the `predict()`
    function for prediction. The prediction of ratings is done by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Executing the `predict()` function will take time because the user-based collaborative
    filtering approach is memory-based and a lazy learning technique implemented at
    run time, to show that the whole dataset is loaded during the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we shall evaluate the predictions with the unknown sets and estimate the
    model accuracy with metrics such as precision, recall, and F1 measure. Run the
    following code to calculate the model accuracy metrics by calling the `calcPredicitonAccuracy()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'By setting `byUser = TRUE`, we are calculating the model accuracy for each
    user. Taking the average will give us the overall accuracy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'By setting `byUser=FALSE`, in the previous `calcPredictionAccuracy()` we can
    calculate the overall model accuracy given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous approach, we evaluated the model accuracy using the **root
    mean squared error** (**RMSE**), and **mean absolute error** (**MAE**), but we
    can also evaluate the model accuracy using precision/recall For this, we use the
    `evaluate()` function and then the result of the `evaluate()` method is used to
    create a confusion matrix containing precision/recall/f1 measures as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![Evaluating user-based collaborative filtering](img/image00333.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The first four columns contain the true-false positives/negatives, and they
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positives** (**TP**): These are recommended items that have been rated
    correctly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positives** (**FP**): These are recommended items that haven''t been
    rated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negatives** (**FN**): These are not recommended items that have been
    rated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negatives** (**TN**): These are not recommended items that haven''t
    been rated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A perfect (or overfitted) model would have only `TP` and `TN`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to take account of all the splits at the same time, we can just
    sum up the indices as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Since summarizing the model is difficult by referring to the above table, we
    can use a `ROC curve` to evaluate the model. Use `plot()` to build the ROC plot
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![Evaluating user-based collaborative filtering](img/image00334.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding plot shows the relation between **True Positive Rate** (**TPR**)
    and **False Positive Rate** (**FPR**), but we have to choose the values in such
    a way that we give a trade-off between TPR and FPR. In our case, we observe that
    *nn=30* is a very good trade-off since when considering neighbors of 30 we have
    TPR closer to *0.7*, FPR is *0.4* and when moving to *nn=40* the TPR is still
    close to *0.7* but the FPR has been changed to *0.4.* This means that the False
    Positive Rate has been increased.
  prefs: []
  type: TYPE_NORMAL
- en: Building an item-based recommender model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with UBCF, we use the same `Jester5k` dataset for the item-based recommender
    system. In this section, we do not explore the data as we have already done so
    in the previous section. We first remove the user data of those who have rated
    all the items and also those records who have rated more than `80` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see how the average ratings are distributed for each user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![Building an item-based recommender model](img/image00335.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code snippet calculates the average ratings given by each user
    and identifies users who have given extreme ratings - either very high ratings
    or very low ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the below results, we observe that there are 19 records with very high
    average ratings and 79 records with very low ratings, compared with the majority
    of users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Of the total `3261` records, only `98` records had much less than the average
    and much more than the average ratings, so we removed these from our dataset as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'From here, we divide the sections as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Building the IBCF recommender model using the training and test data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameter tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an IBCF recommender model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step in building any recommender model is to prepare the training
    data. Previously, we have prepared the data required for building the model by
    removing outlying data. Now run the following code to divide the available data
    into two sets: 80% training set and 20% test set. We build the recommender model
    using the training data and generate the recommendations on the test set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code first creates a logical object of the same length as the
    original dataset containing 80% elements as TRUE and 20% as a test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we use the logical object in the `model_data` to generate the training
    set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we use the logical object in the `model_data` to generate the test set
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have prepared the training set and the test set, let's train the
    model and generate the top recommendations on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: For model building, as mentioned in the UBCF section, we use the same `recommender()`
    function available in the `recommenderlab` package. Run the following code to
    train the model with training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the parameters for the `recommender()` function. We set the model to evaluate
    as `"IBCF"` and `k=30`. `k` is the number of neighbors to be considered while
    calculating the similarity values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code snippet shows building the recommendation engine model using
    the `recommender()` function and its input parameters such as input data, model
    to evaluate the parameters, and the k parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The IBCF model object is created as a `model_recommender`. This model is trained
    and learned using the `2506` training set we created earlier as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have created the model, let''s explore the model bit. We use `getModel()`
    available in the `recommenderlab` to extract the model details as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Building an IBCF recommender model](img/image00336.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the above results, the important parameters to note are `k` value, the
    default similarity value, and method, `cosine similarity`.
  prefs: []
  type: TYPE_NORMAL
- en: The final step is to generate the recommendations on the test set. Run the following
    code on the test set and generate the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: '`items_to_recommend` is the parameter to set the number of recommendations
    to be generated for each user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the `predict()` method available in the reocommenderlab package to predict
    the unknowns in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the slot details of the prediction object using the `slotNames()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s have a look of the predictions generated for the first user in the test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s add the item labels to each of the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's take one step back to evaluate the recommender model before we generate
    the predictions. As we saw in UBCF, we can use the available `evaluationScheme()`
    method. We use the cross-validation setting to generate the training and test
    sets. Then we make predictions on each test set and evaluate the model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Run the following code to generate the training and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: '`n_fold` defines the 4-fold cross-validation, that divides the data into 4
    sets; 3 training sets and 1 test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '`items_to_keep` defines the minimum number of items to use to generate recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '`rating_threshold` defines the minimum rating which is considered as a good
    rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '`evaluationScheme` method creates the test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the `model_to_evaluate` to set the recommender method to be used. `model_parameters`
    defines the model parameters such as the number of neighbors to be considered
    while computing the similarity using cosine. For now we will set it as `NULL`
    in order to make the model choose the default values, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `recommender()` method to generate the model. Let''s understand each
    parameter of the `recommender()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '`getData` extracts the training data from `eval_sets` and passes it on to the
    `recommender()` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are using 4-folds cross-validation, the `recommender()` method uses
    the three sets from `eval_sets` for training and the remaining one set for testing/
    evaluating the model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we use the built model to make predictions on a `"known"` dataset from
    `eval_sets`. As seen before, we use the `predict()` method to generate the predictions
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Model accuracy using metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Until now, the procedure has been the same as for making the initial predictions,
    now we will see how to evaluate the model accuracy for the predictions made on
    the "known" set of test data from `eval_sets`. As we saw in the UBCF section,
    we use the `calcPredictionAccuracy()` method to calculate the prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `calcPredictionAccuracy()` method and pass the `"unknown"` dataset
    available in the `eval_sets` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using `byUser = TRUE` in the previous method calculates the accuracy for each
    user. In the table above we can see that for user - `u238` the `RMSE` is `4.62`
    and `MAE` is `4.25`
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to see the accuracy of the whole model, just calculate the mean
    of each column, that is to say the average for all the users as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'By setting `byUser=FALSE` we can calculate the model accuracy for the whole
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Model accuracy using plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we can see the model accuracy using Precision-Recall, ROC curves, and precision/recall
    curves. These curves help us to decide the trade-off between Precision-Recall
    while choosing the parameters we use for the recommender models, IBCF in our case.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `evaluate()` method and then set the n value which defines the number
    of nearest neighbors while calculating the similarities between items as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the following evaluate method makes the model run four times for each
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the model accuracy at each fold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '![Model accuracy using plots](img/image00337.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s sum up all the 4-fold results using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '![Model accuracy using plots](img/image00338.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the previous table, we can observe that the model accuracy, Precision-Recall
    values are good for n values of 30 and 40\. The same results can be visually inferred
    using ROC curves and Precision-Recall plots as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '![Model accuracy using plots](img/image00339.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '![Model accuracy using plots](img/image00340.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Parameter tuning for IBCF
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While building the IBCF model there are a few places where we can choose the
    optimal values before we generate recommendations for building a final model:'
  prefs: []
  type: TYPE_NORMAL
- en: We have to choose, optimal number of neighbors for calculating the similarities
    between items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarity method to be used, whether it is the cosine or Pearson method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'See the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First set the different k-values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `lapply` to generate different models using the cosine method and different
    values of k:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '![Parameter tuning for IBCF](img/image00341.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Set the total number of recommendations to be generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the evaluate method to the build 4-fold methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have got the results, let''s plot and choose the optimal parameters
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '![Parameter tuning for IBCF](img/image00342.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding plot, the best methods are IBCF with cosine similarity with
    *n = 30*, and the next best is the Pearson method with *n = 40*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s confirm this with the `Precision-Recall` curve as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '![Parameter tuning for IBCF](img/image00343.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the above plot we see that the best Precision-Recall ratio is achieved
    when the number of recommendations = 30 with cosine similarity and *n=40*. Another
    good model is achieved with the Pearson similarity method and *n=10*.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering using Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section we saw implementations of user-based recommender systems
    and item-based recommender systems using the R package, `recommenderlab`. In this
    section, we see UBCF and IBCF implementation using the Python programming language.
  prefs: []
  type: TYPE_NORMAL
- en: For this section, we use the MovieLens 100k dataset, which contains 943 user
    ratings on 1682 movies. Unlike in R, in Python we do not have a proper Python
    package dedicated to building recommender engines, at least the neighborhood-based
    recommenders such as user-based/item-based recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: We have the Crab Python package available but it is not actively supported.
    So I thought of building a recommender engine using scientific packages in Python
    such as NumPy, sklearn, and Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the required packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this section, please make sure you have the following system requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pandas 1.9.2 - Pandas is an open source, BSD-licensed library providing high-performance,
    easy-to-use data structures, and data analysis tools for the Python programming
    language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy 1.9.2 - NumPy is the fundamental package for scientific computing with
    Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: sklearn 0.16.1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The best way to install the preceding packages is to install, Anaconda distribution
    which will install all the required packages such as Python, Pandas, and Numpy.
    Anaconda can be found at:[https://www.continuum.io/downloads](https://www.continuum.io/downloads)
  prefs: []
  type: TYPE_NORMAL
- en: Data source
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The MovieLens 100k data can be downloaded from the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://files.grouplens.org/datasets/movielens/ml-100k.zip](http://files.grouplens.org/datasets/movielens/ml-100k.zip)'
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started with implementing user-based collaborative filtering. Assuming
    we have downloaded the data into our local system, let's load the data into a
    Python environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'We load the data using the Pandas package and the `read_csv()` method by passing
    two parameters, path and separator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: The data will be loaded as a DataFrame, a table-like data structure that can
    easily be used for data handling and manipulation tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the first six results of the data frame to have a look at how data
    seems to be using the `head()` method available in the Pandas DataFrame object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the column names of the data frame, `df` using the columns attributes.
    The result of the following code snippet shows that there are four columns: `UserID`,
    `ItemId`, `Rating`, `Timestamp`, and that it is of the object datatype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the size of the data frame by calling the shape attribute; we observe
    that we have 100k records with 4 columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Data exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the MovieLens dataset and also prepare the
    data required for building collaborative filtering recommendation engines using
    python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the distribution of ratings using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'From the following image we see that we have more movies with 4 star ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data exploration](img/image00344.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the following code snippet, we shall see the counts of ratings by applying
    the `groupby()` function and the `count()` function on DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data exploration](img/image00345.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code snippet shows the distribution of movie views. In the following
    code we apply the `count()` function on DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '![Data exploration](img/image00346.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the previous image, we can observe that the starting ItemId has more ratings
    than later movies.
  prefs: []
  type: TYPE_NORMAL
- en: Rating matrix representation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have explored the data, let's represent the data in a rating matrix
    form so that we can get started with our original task of building a recommender
    engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'For creating a rating matrix, we make use of NumPy package capabilities such
    as arrays and row iterations in a matrix. Run the following code to represent
    the data frame in a rating matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the following code, first we extract all the unique user IDs and then we
    check the length using the shape parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a variable of `n_users` to find the total number of unique users in
    the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a variable `n_items` to find the total number of unique movies in the
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the counts of unique users and movies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a zero value matrix of size (*n_users x n_items*) to store the ratings
    in the cell of the matrix ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'For each tuple in the DataFrame, `df` extracts the information from each column
    of the row and stores it in the rating matrix cell value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the loop and the whole DataFrame movie ratings information will be stored
    in the matrix ratings of the `numpy.ndarray` type as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s see the dimensions of the multidimensional array ''ratings'' using
    the shape attribute as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the sample data for how a ratings multidimensional array looks by
    running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'We observe that the rating matrix is sparse as we see a lot of zeros in the
    data. Let''s determine the `sparsity` in the data, by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: We observe that the sparsity is `6.3%` that is to say that we only have rating
    information for `6.3%` of the data and for the others it is just zeros. Also please
    note that, the `0` value we see in the rating matrix doesn't represent the rating
    given by the user, it just means that they are empty.
  prefs: []
  type: TYPE_NORMAL
- en: Creating training and test sets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a ratings matrix, let's create a training set and test set
    to build the recommender model using a training set and evaluate the model using
    a test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'To divide the data into training and test sets, we use the `sklearn` package''s
    capabilities. Run the following code to create training and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `train_test_split` module into the python environment using the following
    import functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the `train_test_split()` method with a test size of `0.33` and random
    seed of `42`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the dimensions of the train set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: For user-based collaborative filtering, we predict that a user's rating for
    an item is given by the weighted sum of all other users' ratings for that item,
    where the weighting is the cosine similarity between each user and the input user.
  prefs: []
  type: TYPE_NORMAL
- en: The steps for building a UBCF
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The steps for building a UBCF are:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a similarity matrix between the users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the unknown rating value of item *i* for an active user *u* by calculating
    the weighted sum of all the users' ratings for the item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Here the weighting is the cosine similarity calculated in the previous step
    between the user and neighboring users.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Recommending the new items to the users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-based similarity calculation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next step is to create pairwise similarity calculations for each user in
    the rating matrix, that is to say we have to calculate the similarity of each
    user with all the other users in the matrix. The similarity calculation we choose
    here is cosine similarity. For this, we make use of pairwise distance capabilities
    to calculate the cosine similarity available in the `sklearn` package as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![User-based similarity calculation](img/image00347.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see a sample dataset of the distance matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '![User-based similarity calculation](img/image00348.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Predicting the unknown ratings for an active user
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As previously mentioned, the unknown values can be calculated for all the users
    by taking the dot product between the distance matrix and the rating matrix and
    then normalizing the data with the number of ratings as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have predicted the unknown ratings for use in the training set,
    let''s define a function to check the error or performance of the model. The following
    code defines a function for calculating the root mean square error (RMSE) by taking
    the predicted values and original values. We use `sklearn` capabilities for calculating
    RMSE as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'We call the `get_mse()` method to check the model prediction error rate as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that the model accuracy or RMSE is `7.8`. Now let''s run the same `get_mse()`
    method on the test data and check the accuracy as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: User-based collaborative filtering with the k-nearest neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we observe the RMSE values in the above model, we can see that the error
    is a bit higher. The reason may be that we have chosen all the users' rating information
    while making the predictions. Instead of considering all the users, let's consider
    only the top-N similar users' ratings information and then make the predictions.
    This may result in improving the model accuracy by eliminating some biases in
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: To explain in a more elaborate way; in the previous code we predicted the ratings
    of the users by taking the weighted sum of the ratings of all users, instead we
    first chose the top-N similar users for each user and then the ratings were calculated
    by considering the weighted sum of the ratings of these top-N users.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the top-N nearest neighbors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Firstly, for computational easiness, we shall choose the top five similar users
    by setting a variable, *k*.
  prefs: []
  type: TYPE_NORMAL
- en: '*k=5*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the k-nearest neighbors method to choose the top five nearest neighbors
    for an active user. We will see this in action shortly. We choose sklearn.knn
    capabilities for this task as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the `NearestNeighbors` object by passing k and the similarity method
    as parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit the training data to the `nearestNeighbor` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the top five similar users for each user and their similarity values,
    that is the distance values between each pair of users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'We can observe below that the resultant `top_k_distances` ndarray contains
    similarity values and top five similar users for each users in the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the top five users that are similar to user 1 in the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: The next step would be to choose only the top five users for each user and use
    their rating information while predicting the ratings using the weighted sum of
    all of the ratings of these top five similar users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following code to predict the unknown ratings in the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see the data predicted by the model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image displays the results for `user_pred_k`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Finding the top-N nearest neighbors](img/image00349.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let''s see if the model has improved or not. Run the get_mse() method defined
    earlier as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: Item-based recommendations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IBCF is very similar to UBCF but with very minor changes in how we use the rating
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to calculate the similarities between movies, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we have to calculate the similarity between movies, we use movie count
    as `k` instead of user count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'We fit the transpose of the rating matrix to the `NearestNeighbors` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculate the cosine similarity distance between each movie pair:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to predict the movie ratings using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image shows the result for `item_pred`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Item-based recommendations](img/image00350.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Evaluating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let''s evaluate the model using the `get_mse()` method we have defined
    by passing the prediction ratings and the training and test set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: The training model for k-nearest neighbors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Run the following code to calculate the distance matrix for the top 40 nearest
    neighbors and then calculate the weighted sum of ratings by the top 40 users for
    all the movies. If we closely observe the code, it is very similar to what we
    have done for UBCF. Instead of passing `ratings_train` as is, we transpose the
    data matrix and pass to the previous code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The follow code snippet calculates the mean squared error for the training and
    test set. We can observe that the training error is 11.12 whereas the test error
    is 12.12.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have explored building collaborative filtering approaches
    such as user-based and item-based approaches in R and Python, the popular data
    mining programming languages. The recommendation engines are built on MovieLens,
    and Jester5K datasets available online.
  prefs: []
  type: TYPE_NORMAL
- en: We have learnt about how to build the model, choose data, explore the data,
    create training and test sets, and evaluate the models using metrics such as RMSE,
    Precision-Recall, and ROC curves. Also, we have seen how to tune parameters for
    model improvements.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be covering personalized recommendation engines
    such as content-based recommendation engines and context-aware recommendation
    engines using R and Python.
  prefs: []
  type: TYPE_NORMAL
