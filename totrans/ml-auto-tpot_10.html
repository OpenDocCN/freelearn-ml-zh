<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer164">
			<h1 id="_idParaDest-85"><em class="italic"><a id="_idTextAnchor086"/>Chapter 7</em>: Neural Network Classifier with TPOT</h1>
			<p>In this chapter, you'll learn how to build your deep learning classifier in an automated fashion – by using the TPOT library. It's assumed that you know the basics of artificial neural networks, so terms such as <em class="italic">neurons</em>, <em class="italic">layers</em>, <em class="italic">activation functions</em>, and <em class="italic">learning rates</em> should sound familiar. If you don't know how to explain these terms simply, please revisit <a href="B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 6</em></a>, <em class="italic">Getting Started with Deep Learning: Crash Course in Neural Networks</em>. </p>
			<p>Throughout this chapter, you'll learn how easy it is to build a simple classifier based on neural networks and how you can tweak the neural network so that it better suits your needs and the training data. </p>
			<p>This chapter will cover the following topics:</p>
			<ul>
				<li>Exploring the dataset</li>
				<li>Exploring options for training neural network classifiers</li>
				<li>Training a neural network classifier</li>
			</ul>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor087"/>Technical requirements</h1>
			<p>You don't need any prior hands-on experience with deep learning and neural networks. A knowledge of some basics concepts and terminology is a must, however. If you're entirely new to the subject, please revisit <a href="B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 6</em></a>, <em class="italic">Getting Started with Deep Learning: Crash Course in Neural Networks</em>.</p>
			<p>You can download the source code and dataset for this chapter here: <a href="https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07">https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07</a>.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor088"/>Exploring the dataset</h1>
			<p>There is no reason to go wild with the dataset. Just because we can train neural network models with TPOT doesn't mean we should spend 50+ pages exploring and transforming needlessly complex datasets.</p>
			<p>For that reason, you'll use a scikit-learn built-in dataset throughout the chapter – the Breast cancer dataset. This dataset doesn't have to be downloaded from the web as it comes built-in with scikit-learn. Let's start by <a id="_idIndexMarker420"/>loading and exploring it:</p>
			<ol>
				<li>To begin, you'll need to load in a couple of libraries. We're importing NumPy, pandas, Matplotlib, and Seaborn for easy data analysis and visualization. Also, we're importing the <strong class="source-inline">load_breast_cancer</strong> function from the <strong class="source-inline">sklearn.datasets</strong> module. That's the function that will load in the dataset. Finally, the <strong class="source-inline">rcParams</strong> module is imported from Matplotlib to make default styling a bit easier on the eyes:<p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">import seaborn as sns</p><p class="source-code">from sklearn.datasets import load_breast_cancer</p><p class="source-code">from matplotlib import rcParams</p><p class="source-code">rcParams['figure.figsize'] = (14, 7)</p><p class="source-code">rcParams['axes.spines.top'] = False</p><p class="source-code">rcParams['axes.spines.right'] = False</p></li>
				<li>You can now use the <strong class="source-inline">load_breast_cancer</strong> function to load in the dataset. The function returns a dictionary, so we can use the <strong class="source-inline">keys()</strong> method to print the keys:<p class="source-code">data = load_breast_cancer()</p><p class="source-code">data.keys()</p><p>The results are shown in the following diagram:</p><div id="_idContainer144" class="IMG---Figure"><img src="Images/B16954_07_1.jpg" alt="Figure 7.1 – Dictionary keys of the Breast cancer dataset&#13;&#10;" width="1446" height="35"/></div><p class="figure-caption">Figure 7.1 – Dictionary keys of the Breast cancer dataset</p></li>
				<li>You can now <a id="_idIndexMarker421"/>use this dictionary to extract attributes of interest. What is essential for now are the <strong class="source-inline">data</strong> and <strong class="source-inline">target</strong> keys. You can store their values to separate variables and then construct a data frame object from them. Working with raw values is possible, but a pandas data frame data structure will allow easier data manipulation, transformation, and exploration. <p>Here's how you can transform these to a pandas data frame:</p><p class="source-code">features = data.data</p><p class="source-code">target = data.target</p><p class="source-code">df =\</p><p class="source-code">pd.DataFrame(data=features,columns=data.feature_names)</p><p class="source-code">df['target'] = target</p><p class="source-code">df.sample(8)</p><p>The results are shown in the following table:</p><div id="_idContainer145" class="IMG---Figure"><img src="Images/B16954_07_2.jpg" alt="Figure 7.2 – Sample of eights rows from the Breast cancer dataset&#13;&#10;" width="1586" height="600"/></div><p class="figure-caption">Figure 7.2 – Sample of eights rows from the Breast cancer dataset</p></li>
				<li>The first thing you <a id="_idIndexMarker422"/>always want to do, analysis-wise, is to check for missing data. Pandas has an <strong class="source-inline">isnull()</strong> method built in, which returns Booleans for every value in the dataset. You can then call the <strong class="source-inline">sum()</strong> method on top of these results to get the count of missing values per column:<p class="source-code">df.isnull().sum()</p><p>The results are shown in the following diagram:</p><div id="_idContainer146" class="IMG---Figure"><img src="Images/B16954_07_3.jpg" alt="Figure 7.3 – Missing value count per column&#13;&#10;" width="476" height="984"/></div><p class="figure-caption">Figure 7.3 – Missing value count per column</p><p>As you can see, there are no missing values.</p></li>
				<li>The next thing to do in the <a id="_idIndexMarker423"/>exploratory phase is to get familiar with your dataset. Data visualization techniques can provide an excellent way of doing so.<p>For example, you can declare a function called <strong class="source-inline">make_count_chart()</strong> that takes any categorical attribute and visualizes its distribution. Here's what the code for this function could look like:</p><p class="source-code">def make_count_chart(column, title, ylabel, xlabel, y_offset=0.12, x_offset=700):</p><p class="source-code">    ax = df[column].value_counts().plot(kind='bar', fontsize=13, color='#4f4f4f')</p><p class="source-code">    ax.set_title(title, size=20, pad=30)</p><p class="source-code">    ax.set_ylabel(ylabel, fontsize=14)</p><p class="source-code">    ax.set_xlabel(xlabel, fontsize=14)</p><p class="source-code">                  </p><p class="source-code">    for i in ax.patches:</p><p class="source-code">        ax.text(i.get_x() + x_offset, i.get_height()\</p><p class="source-code"> + y_offset, f'{str(round(i.get_height(), 2))}',\</p><p class="source-code"> fontsize=15)</p><p class="source-code">    return ax</p><p>You can now use the <a id="_idIndexMarker424"/>following code snippet to visualize the target variable to find out how many instances were benign and how many were malignant:</p><p class="source-code">make_count_chart(</p><p class="source-code">    column='target',</p><p class="source-code">    title=\</p><p class="source-code">'Number of malignant (1) vs benign (0) cases',</p><p class="source-code">    ylabel='Malignant? (0 = No, 1 = Yes)',</p><p class="source-code">    xlabel='Count',</p><p class="source-code">    y_offset=10,</p><p class="source-code">    x_offset=0.22</p><p class="source-code">)</p><p>The results are shown in the following diagram:</p><div id="_idContainer147" class="IMG---Figure"><img src="Images/B16954_07_4.jpg" alt="Figure 7.4 – Number of malignant and benign cases&#13;&#10;" width="1650" height="929"/></div><p class="figure-caption">Figure 7.4 – Number of malignant and benign cases</p><p>As you can see, there's a <a id="_idIndexMarker425"/>decent amount more of malignant cases, so the classes aren't perfectly balanced. Class imbalance can lead to highly accurate but unusable models. Just imagine you are classifying a rare event. In every 10,000 transactions, only one is classified as an anomaly. Clearly, the machine learning model doesn't have much chance to learn what makes an anomaly so different from the rest.</p><p>Furthermore, always predicting that the transaction is normal leads to a 99.99% accurate model. State-of-the-art accuracy, for certain, but the model is unusable. </p><p>There are numerous techniques for dealing with imbalanced datasets, but they are beyond the scope for this book.</p></li>
				<li>Next stop – correlation analysis. The aim of this step is to take a glimpse at which feature(s) have the biggest effect on the target variables. In other words, we want to establish how correlated a change in direction in a feature is with the target class. Visualizing an entire correlation matrix on a dataset of 30+ columns isn't the best idea because it would require a figure too large to fit comfortably on a single page. Instead, we can calculate the correlation of the feature with the target variable.<p>Here's how you can do this for the <strong class="source-inline">mean area</strong> feature – by calling the <strong class="source-inline">corrcoeff()</strong> method from NumPy:</p><p class="source-code">np.corrcoef(df['mean area'], df['target'])[1][0]</p><p>The results are shown in the following figure:</p><div id="_idContainer148" class="IMG---Figure"><img src="Images/B16954_07_5.jpg" alt="Figure 7.5 – Correlation coefficient between a single feature and the target variable&#13;&#10;" width="302" height="30"/></div><p class="figure-caption">Figure 7.5 – Correlation coefficient between a single feature and the target variable</p><p>You can now easily <a id="_idIndexMarker426"/>apply the same logic to the entire dataset. The following code snippet keeps track of the correlation between every feature and the target variable, converts the results to a pandas data frame, and sorts the values by the correlation coefficient in descending order:</p><p class="source-code">corr_with_target = []</p><p class="source-code">for col in df.columns[:-1]:</p><p class="source-code">    corr = np.corrcoef(df[col], df['target'])[1][0]</p><p class="source-code">    corr_with_target.append({'Column': col, 'Correlation': corr})</p><p class="source-code">    </p><p class="source-code">corr_df = pd.DataFrame(corr_with_target)</p><p class="source-code">corr_df = \</p><p class="source-code">corr_df.sort_values(by='Correlation', ascending=False)</p><p>Please note the <strong class="source-inline">[:-1]</strong> at the beginning of the loop. Since the target variable is the last column, we can use the aforementioned slicing technique to exclude the target variable from the correlation calculation. The correlation coefficient between the target <a id="_idIndexMarker427"/>variable and the non-target variable would be 1, which is not particularly useful to us.</p><p>You can now use the following code to make a horizontal bar chart of the correlations with the target variable:</p><p class="source-code">plt.figure(figsize=(10, 14))</p><p class="source-code">plt.barh(corr_df['Column'], corr_df['Correlation'], color='#4f4f4f')</p><p class="source-code">plt.title('Feature correlation with the target variable', fontsize=20)</p><p class="source-code">plt.xlabel('Feature', fontsize=14)</p><p class="source-code">plt.ylabel('Correlation', fontsize=14)</p><p class="source-code">plt.show()</p><p>The results are shown in the following diagram:</p><div id="_idContainer149" class="IMG---Figure"><img src="Images/B16954_07_6.jpg" alt="Figure 7.6 – Feature correlation with the target variable&#13;&#10;" width="934" height="1072"/></div><p class="figure-caption">Figure 7.6 – Feature correlation with the target variable</p><p>As you can see, most of the features have a high negative correlation with the target variable. Negative correlation means that one variable increases as the other one decreases. In our case, a decrease in the number of features leads to an increase in the target variable.</p></li>
				<li>You could also <a id="_idIndexMarker428"/>visualize the distribution of every numeric column with respect to the target variable value. To be more precise, this means two separate histograms are drawn on a single chart, and each histogram shows the distribution only for the respective target value's subset. <p>For example, this means that one histogram will show the distribution of malignant and the other of benign instances, for each variable.</p><p>The code snippet you're about to see declares a <strong class="source-inline">draw_histogram()</strong> function that goes over every column in a dataset, makes a histogram with respect to the distinct classes in the target variable, and appends this histogram to a figure.</p><p>Once all of the histograms are appended, the figure is displayed to the user. The user also has to specify how many rows and columns they want, which gives a bit of extra freedom when designing visualizations.</p><p>Here is the code snippet for drawing this histogram grid:</p><p class="source-code">def draw_histogram(data, columns, n_rows, n_cols):</p><p class="source-code">    fig = plt.figure(figsize=(12, 18))</p><p class="source-code">    for i, var_name in enumerate(columns):</p><p class="source-code">        ax = fig.add_subplot(n_rows, n_cols, i + 1)</p><p class="source-code">        sns.histplot(data=data, x=var_name, hue='target')</p><p class="source-code">        ax.set_title(f'Distribution of {var_name}')</p><p class="source-code">    fig.tight_layout()</p><p class="source-code">    plt.show()</p><p class="source-code">draw_histogram(df, df.columns[:-1], 9, 4)</p><p>This will be a pretty <a id="_idIndexMarker429"/>large data visualization, containing 9 rows and 4 columns. The last row will have only 2 histograms, as there are 30 continuous variables in total.</p><p>The results are shown in the following diagram:</p></li>
			</ol>
			<div>
				<div id="_idContainer150" class="IMG---Figure">
					<img src="Images/B16954_07_7.jpg" alt="Figure 7.7 – Histogram for every continuous variable&#13;&#10;" width="980" height="1300"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.7 – Histogram for every continuous variable</p>
			<p>As you can see, there is a <a id="_idIndexMarker430"/>distinct separation most of the time, so our model shouldn't have too much trouble making decent separations between the classes.</p>
			<p>And that's all we'll do with regard to the exploratory data analysis. You can, and are encouraged to, do more, especially with custom and more complex datasets. The next section will introduce you to the options you have for training automated neural network classifiers.</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor089"/>Exploring options for training neural network classifiers</h1>
			<p>You have a lot of <a id="_idIndexMarker431"/>options when training neural network models with TPOT. The whole neural network story is still new and experimental with TPOT, requiring a bit more manual work than regular scikit-learn estimators.</p>
			<p>By default, TPOT won't use the neural network models unless you explicitly specify that it has to. This specification is done by selecting an adequate configuration dictionary that includes one or more neural network estimators (you can also write these manually).</p>
			<p>The more convenient option is to import configuration dictionaries from the <strong class="source-inline">tpot/config/classifier_nn.py</strong> file. This file contains two PyTorch classifier configurations, as visible in the following diagram:</p>
			<div>
				<div id="_idContainer151" class="IMG---Figure">
					<img src="Images/B16954_07_8.jpg" alt="Figure 7.8 – TPOT PyTorch classifier configurations&#13;&#10;" width="716" height="517"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8 – TPOT PyTorch classifier configurations</p>
			<p>From the preceding diagram, you <a id="_idIndexMarker432"/>can see that TPOT can currently handle two different types of classifiers based on deep learning libraries:</p>
			<ul>
				<li>Logistic regression: shown in <strong class="source-inline">tpot.builtins.PytorchLRClassifier</strong></li>
				<li>Multi-layer perceptron: shown in <strong class="source-inline">tpot.builtins.PytorchMLPClassifier</strong></li>
			</ul>
			<p>You can either import this file or write the configurations manually. In addition, you can also specify your own configuration dictionaries, which somehow modify the existing ones. For example, you can use this code to use a PyTorch-based logistic regression estimator:</p>
			<p class="source-code">tpot_config = {</p>
			<p class="source-code">    'tpot.nn.PytorchLRClassifier': {</p>
			<p class="source-code">        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.]</p>
			<p class="source-code">    }</p>
			<p class="source-code">}</p>
			<p>Custom configurations will be discussed later in the chapter when we start to implement neural network classifiers.</p>
			<p>You should keep in mind that training neural network classifiers with TPOT is an expensive task and will typically take much more time to train than scikit-learn estimators. As a rule of thumb, you should expect the training time to be several orders of magnitude slower with <a id="_idIndexMarker433"/>neural networks. This is because neural network architectures can have millions of trainable and adjustable parameters, and finding the correct value for all of them takes time. </p>
			<p>Having that in mind, you should always consider simpler options first, as TPOT is highly likely to give you an excellent-performing pipeline on the default scikit-learn estimators.</p>
			<p>The next section will continue with the training of neural network classifiers right where the previous section stopped and will show you how different training configurations can be used to train your models.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor090"/>Training a neural network classifier</h1>
			<p>Up to this point, we've loaded in the dataset and undertaken a basic exploratory data analysis. This section of the <a id="_idIndexMarker434"/>chapter will focus on training models through different configurations:</p>
			<ol>
				<li value="1">Before we can move on to model training, we need to split our dataset into training and testing subsets. Doing so will allow us to have a sample of the data never seen by the model, and which can later be used for evaluation.<p>The following code snippet will split the data in a 75:25 ratio:</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">X = df.drop('target', axis=1)</p><p class="source-code">y = df['target']</p><p class="source-code">X_train, X_test, y_train, y_test =train_test_split(\</p><p class="source-code">X, y, test_size=0.25, random_state=42)</p><p>We can begin with training next.</p></li>
				<li>As always, let's start simply by training a baseline model. This will serve as a minimum viable performance that the neural network classifier has to outperform.<p>The simplest binary classification algorithm is logistic regression. The following code snippet <a id="_idIndexMarker435"/>imports it from scikit-learn, alongside some evaluation metrics, such as a confusion matrix and an accuracy score. Furthermore, the snippet instantiates the model, trains it, makes a prediction on the holdout set, and prints the confusion matrix and the accuracy score.</p><p>The code snippet is as follows:</p><p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code">from sklearn.metrics import confusion_matrix, accuracy_score</p><p class="source-code">lr_model = LogisticRegression()</p><p class="source-code">lr_model.fit(X_train, y_train)</p><p class="source-code">lr_preds = lr_model.predict(X_test)</p><p class="source-code">print(confusion_matrix(y_test, lr_preds))</p><p class="source-code">print()</p><p class="source-code">print(accuracy_score(y_test, lr_preds))</p><p>The results are shown in the following diagram:</p><div id="_idContainer152" class="IMG---Figure"><img src="Images/B16954_07_9.jpg" alt="Figure 7.9 – Confusion matrix and accuracy of the baseline model&#13;&#10;" width="301" height="139"/></div><p class="figure-caption">Figure 7.9 – Confusion matrix and accuracy of the baseline model</p><p>We now know that the baseline model is 96.5% accurate, making 4 false positives and 1 false negative. Next, we'll train an automated neural network classifier with TPOT and see how the results compare.</p></li>
				<li>As mentioned before, training a <a id="_idIndexMarker436"/>neural network classifier with TPOT is a heavy task. For that reason, you might be better off switching to a free GPU Cloud environment, such as <em class="italic">Google Colab</em>. <p>This will ensure faster training time, but also you won't melt your PC. Once there, you can use the following snippet to train the PyTorch-based logistic regression model:</p><p class="source-code">from tpot import TPOTClassifier</p><p class="source-code">classifier_lr = TPOTClassifier(</p><p class="source-code">    config_dict='TPOT NN',</p><p class="source-code">    template='PytorchLRClassifier',</p><p class="source-code">    generations=2,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=3</p><p class="source-code">)</p><p class="source-code">classifier_lr.fit(X_train, y_train)</p><p>This will train the model for two generations. You'll see various outputs during training, such as the following:</p><div id="_idContainer153" class="IMG---Figure"><img src="Images/B16954_07_10.jpg" alt="Figure 7.10 – TPOT neural network training process&#13;&#10;" width="1045" height="88"/></div><p class="figure-caption">Figure 7.10 – TPOT neural network training process</p><p>The training process will take a long time. Please make sure that your PC doesn't go into sleep mode, and also make sure to click somewhere on a blank space in Google Colab every couple of minutes. Failing to do so will cause runtime disconnection, and you'll have to start training from the beginning.</p><p>This happens <a id="_idIndexMarker437"/>because Colab is a free environment, and if you aren't active, it's assumed you're not using it, so the resources you're occupying are allocated to someone else.</p><p>Once the training process completes, you'll see the following output on your screen:</p><div id="_idContainer154" class="IMG---Figure"><img src="Images/B16954_07_11.jpg" alt="Figure 7.11 – TPOT PyTorch logistic regression classifier&#13;&#10;" width="1380" height="564"/></div><p class="figure-caption">Figure 7.11 – TPOT PyTorch logistic regression classifier</p><p>The pipeline was only optimized for two generations, so please don't expect any groundbreaking results. Set it to a realistic number if you want a better performing model.</p><p>Once the training is done, you can use the following line of code to examine the best-fitted pipeline:</p><p class="source-code">classifier_lr.fitted_pipeline_</p><p>The results are shown in the following diagram:</p><div id="_idContainer155" class="IMG---Figure"><img src="Images/B16954_07_12.jpg" alt="Figure 7.12 – TPOT PyTorch logistic regression best pipeline&#13;&#10;" width="1185" height="210"/></div><p class="figure-caption">Figure 7.12 – TPOT PyTorch logistic regression best pipeline</p><p>You can now export this pipeline if you want to, but we won't do this in this section. </p><p>Before <a id="_idIndexMarker438"/>proceeding to the next model, let's quickly examine how the PyTorch logistic regression model performed. Just like with the baseline model, we'll print the confusion matrix and the accuracy score.</p><p>You can use the following code snippet to do precisely that:</p><p class="source-code">from sklearn.metrics import confusion_matrix,\</p><p class="source-code"> accuracy_score</p><p class="source-code">tpot_lr_preds = classifier_lr.predict(X_test)</p><p class="source-code">print(confusion_matrix(y_test, tpot_lr_preds))</p><p class="source-code">print()</p><p class="source-code">print(accuracy_score(y_test, tpot_lr_preds))</p><p>The results are shown in the following figure:</p><div id="_idContainer156" class="IMG---Figure"><img src="Images/B16954_07_13.jpg" alt="Figure 7.13 – Confusion matrix and accuracy score of a PyTorch logistic regression model&#13;&#10;" width="314" height="135"/></div><p class="figure-caption">Figure 7.13 – Confusion matrix and accuracy score of a PyTorch logistic regression model</p><p>As you can see, two generations weren't enough to produce a better-than-baseline model. Let's see whether using a multi-layer perceptron model could help.</p></li>
				<li>We're still in the Google Colab environment, as training on your own PC is significantly <a id="_idIndexMarker439"/>slower (depending on your configuration). The idea now is to use the multi-layer perceptron model instead of logistic regression and see how the change in the model could affect performance.<p>To begin, you'll have to make a change to the <strong class="source-inline">template</strong> parameter of <strong class="source-inline">TPOTClassifier</strong>, as shown here:</p><p class="source-code">classifier_mlp = TPOTClassifier(</p><p class="source-code">    config_dict='TPOT NN',</p><p class="source-code">    template='PytorchMLPClassifier',</p><p class="source-code">    generations=2,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=3</p><p class="source-code">)</p><p>As you can see, we're now using <strong class="source-inline">PytorchMLPClassifier</strong> instead of <strong class="source-inline">PytorchLRClassifier</strong>. To begin the optimization process, simply call the <strong class="source-inline">fit()</strong> method with the training data:</p><p class="source-code">classifier_mlp.fit(X_train, y_train)</p><p>As with the logistic regression algorithm, you'll also see the progress bar during the optimization process:</p><div id="_idContainer157" class="IMG---Figure"><img src="Images/B16954_07_14.jpg" alt="Figure 7.14 – TPOT multi-layer perceptron training process&#13;&#10;" width="1072" height="90"/></div><p class="figure-caption">Figure 7.14 – TPOT multi-layer perceptron training process</p><p>Once the training process is complete, you'll be presented with the following results:</p><div id="_idContainer158" class="IMG---Figure"><img src="Images/B16954_07_15.jpg" alt="Figure 7.15 – TPOT PyTorch multi-layer perceptron classifier&#13;&#10;" width="1650" height="671"/></div><p class="figure-caption">Figure 7.15 – TPOT PyTorch multi-layer perceptron classifier</p><p>Once again, the <a id="_idIndexMarker440"/>pipeline was only optimized for two generations, so please don't expect any groundbreaking results. Set it to a realistic number if you want a better performing model.</p><p>Once the training is complete, you can use the following line of code to examine the best-fitted pipeline:</p><p class="source-code">classifier_mlp.fitted_pipeline_</p><p>The results are shown in the following diagram:</p><div id="_idContainer159" class="IMG---Figure"><img src="Images/B16954_07_16.jpg" alt="Figure 7.16 – TPOT PyTorch multi-layer perceptron best pipeline&#13;&#10;" width="1231" height="204"/></div><p class="figure-caption">Figure 7.16 – TPOT PyTorch multi-layer perceptron best pipeline</p><p>Let's quickly examine how the logistic regression model with PyTorch performed. Just <a id="_idIndexMarker441"/>like with the previous model, we'll print the confusion matrix and the accuracy score.</p><p>You can use the following code snippet to do precisely that:</p><p class="source-code">from sklearn.metrics import confusion_matrix,\</p><p class="source-code"> accuracy_score</p><p class="source-code">tpot_mlp_preds = classifier_mlp.predict(X_test)</p><p class="source-code">print(confusion_matrix(y_test, tpot_mlp_preds))</p><p class="source-code">print()</p><p class="source-code">print(accuracy_score(y_test, tpot_mlp_preds))</p><p>The results are shown in the following figure:</p><div id="_idContainer160" class="IMG---Figure"><img src="Images/B16954_07_17.jpg" alt="Figure 7.17 – Confusion matrix and accuracy score of a PyTorch multi-layer perceptron model&#13;&#10;" width="317" height="144"/></div><p class="figure-caption">Figure 7.17 – Confusion matrix and accuracy score of a PyTorch multi-layer perceptron model</p><p>As you can see, two generations still weren't enough to produce a better-than-baseline model, but the MLP model outperformed the logistic regression one. Let's now see whether using a custom training configuration could push the accuracy even higher.</p></li>
				<li>Finally, let's see <a id="_idIndexMarker442"/>how you can specify possible hyperparameter values for either logistic regression or multi-layer perceptron models. All you have to do is specify a custom configuration dictionary, which holds the hyperparameters you want to test for (such as learning rate, batch size, and number of epochs), and assign values to those hyperparameters in the form of a list.<p>Here's an example:</p><p class="source-code">custom_config = {</p><p class="source-code">    'tpot.builtins.PytorchMLPClassifier': {</p><p class="source-code">        'learning_rate': [1e-1, 0.5, 1.],</p><p class="source-code">        'batch_size': [16, 32],</p><p class="source-code">        'num_epochs': [10, 15],</p><p class="source-code">    }</p><p class="source-code">}</p><p>You can now use this <strong class="source-inline">custom_config</strong> dictionary when training models. Here is an example training snippet based on a multi-layer perceptron model:</p><p class="source-code">classifier_custom = TPOTClassifier(</p><p class="source-code">    config_dict=custom_config,</p><p class="source-code">    template='PytorchMLPClassifier',</p><p class="source-code">    generations=2,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=3</p><p class="source-code">)</p><p class="source-code">classifier_custom.fit(X_train, y_train)</p><p>As you <a id="_idIndexMarker443"/>can see, only the <strong class="source-inline">config_dict</strong> parameter has changed. Once the training process has started, you'll see a progress bar similar to this one in the notebook:</p></li>
			</ol>
			<div>
				<div id="_idContainer161" class="IMG---Figure">
					<img src="Images/B16954_07_18.jpg" alt="Figure 7.18 – TPOT custom tuning with neural networks&#13;&#10;" width="522" height="52"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.18 – TPOT custom tuning with neural networks</p>
			<p>Once the training process is complete, you should see something along the following lines in the notebook:</p>
			<div>
				<div id="_idContainer162" class="IMG---Figure">
					<img src="Images/B16954_07_19.jpg" alt="Figure 7.19 – TPOT multi-layer perceptron classifier with custom hyperparameters&#13;&#10;" width="1650" height="1149"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.19 – TPOT multi-layer perceptron classifier with custom hyperparameters</p>
			<p>And that's all <a id="_idIndexMarker444"/>there is to it! Just to verify, you can examine the best-fitted pipeline by executing the following command:</p>
			<p class="source-code">classifier_custom.fitted_pipeline_</p>
			<p>The results are shown in the following figure:</p>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="Images/B16954_07_20.jpg" alt="Figure 7.20 – TPOT best-fitted pipeline for a model with custom hyperparameters&#13;&#10;" width="603" height="108"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.20 – TPOT best-fitted pipeline for a model with custom hyperparameters</p>
			<p>As you can see, all of the hyperparameter values are within the specified range, which indicates that the custom model was trained successfully.</p>
			<p>This concludes the model training portion of this section and this section in general. What follows is a brief summary of everything we have learned thus far, and a brief introduction to everything that will follow in the upcoming chapters.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor091"/>Summary</h1>
			<p>This chapter was quite intensive in terms of hands-on examples and demonstrations. You've hopefully managed to learn how to train automated classification pipelines with TPOT and what you can tweak during the process.</p>
			<p>You should now be capable of training any kind of automated machine learning model with TPOT, whether we're talking about regression, classification, standard classifiers, or neural network classifiers. There is good news, as this was the last chapter with TPOT examples.</p>
			<p>In the following chapter, <a href="B16954_08_Final_SK_ePub.xhtml#_idTextAnchor093"><em class="italic">Chapter 8</em></a>, <em class="italic">TPOT Model Deployment</em>, you'll learn how to wrap the predictive functionality of your models inside a REST API, which will then be tested and deployed both locally and to the cloud. You'll also learn how to communicate with the API once it's deployed.</p>
			<p>Finally, in the previous chapter, <a href="B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102"><em class="italic">Chapter 9</em></a>, <em class="italic">Using the Deployed TPOT Model in Production</em>, you'll learn how to develop something useful with the deployed APIs. To be more precise, you'll learn how to make predictions in the Notebook environment by making REST calls to the deployed API, and you'll learn how to develop a simple GUI application that makes your model presentable to the end user.</p>
			<p>As always, feel free to study TPOT in more depth, but by now, you're well ahead of the majority, and you're ready to make machine learning useful. See you there!</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor092"/>Questions</h1>
			<ol>
				<li value="1">Which two algorithms are available in TPOT with regard to neural networks? </li>
				<li>Approximately how many times are neural network classifiers slower to train than the default, scikit-learn ones?</li>
				<li>List and briefly explain the different hyperparameters available when training models with TPOT and neural networks.</li>
				<li>Can you specify a custom range of hyperparameter values when training custom neural network models with TPOT? If so, how?</li>
				<li>How can you find the best-fitted pipeline after the model has finished training? </li>
				<li>What are the advantages of using a GPU runtime such as Google Colab when training neural network models with TPOT? </li>
				<li>Describe why a single neuron in the multi-layer perceptron model can be thought of as logistic regression.</li>
			</ol>
		</div>
	</div></body></html>