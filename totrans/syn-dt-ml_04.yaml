- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: An Introduction to Synthetic Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据简介
- en: In this chapter, we will define and introduce synthetic data. We will briefly
    explore the history and evolution of synthetic data. Then, we will introduce the
    main types of synthetic data and the basic data augmentation approaches and techniques.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将定义并介绍合成数据。我们将简要探讨合成数据的历史和演变。然后，我们将介绍合成数据的主要类型以及基本的数据增强方法和技巧。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: What is synthetic data?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是合成数据？
- en: History of synthetic data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据的历史
- en: Synthetic data types
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据类型
- en: Data augmentation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据增强
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The code used in this chapter will be available under the corresponding chapter
    folder in the book’s GitHub repository: [https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning](https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码将在本书GitHub仓库的相应章节文件夹中提供：[https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning](https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning)。
- en: What is synthetic data?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是合成数据？
- en: '**Synthetic data** is artificially generated data: the data is not captured,
    measured, or recorded from the real world. Instead, algorithms or software were
    used to create or generate this data. Synthetic data can be generated by simulating
    natural phenomena using mathematical models or by applying some approximations
    of real-world processes. There are many approaches to generating synthetic data,
    such as leveraging game engines, such as Unreal and Unity, or utilizing statistical
    models, such as GANs and diffusion models. As we know, ML models require large-scale
    training datasets for training and evaluation. Collecting and annotating these
    datasets is extremely time-consuming, error-prone, and subject to privacy issues.
    Please refer to *Chapters 2* and *3*. Synthetic data is a powerful solution to
    address these previous limitations.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成数据**是人工生成数据：这些数据并非从现实世界中捕获、测量或记录。相反，使用算法或软件来创建或生成这些数据。合成数据可以通过使用数学模型模拟自然现象或应用对现实世界过程的近似来生成。生成合成数据有许多方法，例如利用游戏引擎，如Unreal和Unity，或利用统计模型，如GANs和扩散模型。众所周知，机器学习模型需要大规模的训练数据集进行训练和评估。收集和标注这些数据集非常耗时、易出错，且存在隐私问题。请参阅*第2章*和*第3章*。合成数据是解决这些先前限制的有力解决方案。'
- en: Synthetic data is useful for scenarios where collecting and annotating data
    is expensive, but its applications go beyond this particular use case, as we will
    see later. Synthetic data has been used in AI, ML, and data analytics, specifically
    for **computer vision** tasks, which usually require large and hard-to-annotate
    data for training. Thus, synthetic data has been widely utilized in this field
    and has shown great progress.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据在收集和标注数据成本高昂的场景中非常有用，但其应用范围远不止这个特定用例，正如我们稍后将会看到的。合成数据在人工智能、机器学习和数据分析领域被广泛应用，特别是在**计算机视觉**任务中，这些任务通常需要大量且难以标注的数据进行训练。因此，合成数据在这一领域得到了广泛的应用，并取得了显著的进步。
- en: Synthetic data can be generated to train or evaluate ML models under certain
    conditions that are usually hard to capture in the real world. For example, let
    us assume we would like to train a computer vision model to predict road traffic
    accidents based on some visual information such as RGB and LiDAR images. We would
    need to feed our training model with a sufficiently large dataset that includes
    thousands of road traffic accidents. Collecting this dataset from the real world
    may take us weeks, months, or years; it would require many engineers and annotators,
    and a huge budget to achieve our aim. At the same time, our dataset may not be
    valid in other countries or after a few years. If you collected your dataset in
    the UK, where people drive on the left, this dataset would not be applicable to
    China, where people drive on the right! In parallel to this, if you collected
    your dataset in 2005, your dataset may not be applicable for 2024 because of,
    for instance, new car models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些通常难以在现实世界中捕捉到的条件下，可以生成合成数据来训练或评估机器学习模型。例如，让我们假设我们想要训练一个计算机视觉模型，根据一些视觉信息（如RGB和激光雷达图像）来预测交通事故。我们需要为我们的训练模型提供包含数千起交通事故的足够大的数据集。从现实世界中收集这个数据集可能需要我们几周、几个月甚至几年；这需要许多工程师和标注员，以及巨大的预算来实现我们的目标。同时，我们的数据集可能在其他国家或几年后不再有效。如果你在英国收集数据集，那里的人靠左行驶，这个数据集就不适用于中国，那里的人靠右行驶！与此并行的是，如果你在2005年收集数据集，由于例如新车型等原因，你的数据集可能不适用于2024年。
- en: On the other hand, if you generate your synthetic training data using a simulator
    such as *CARLA* ([https://carla.org](https://carla.org)), you can simulate thousands
    of road traffic accidents. Additionally, you can control car models, scene attributes,
    weather conditions, and other attributes. This is just an example of the advantages
    of synthetic data for the training and evaluation of ML models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你使用模拟器（如*CARLA* ([https://carla.org](https://carla.org)））生成合成训练数据，你可以模拟数千起交通事故。此外，你可以控制车型、场景属性、天气条件和其他属性。这仅仅是合成数据在机器学习模型的训练和评估中的优势的一个例子。
- en: Synthetic and real data
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据和真实数据
- en: Assume that you want to train your ML model to predict the profit of selling
    a given product. The maximum profit that you can get is £10 and the maximum loss
    is £10 as well. In the real world, this specific financial problem can be modeled
    using a simple sinusoidal wave as shown in *Figure 4**.1.* Thus, to get the maximum
    profit, you must sell the product on certain days approximately close to the second
    and eighth days from the production day (day 0). The blue line gives us the actual
    model of this problem in the real world. However, this model is hidden from us
    because if we know this model, then there is no need to use ML for the prediction.
    Assume that real data perfectly represents this model. Then, the synthetic data
    in this scenario is the black dots. In other words, synthetic data approximates
    the real data and real data is also an approximation of the actual process or
    phenomenon in the real world.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要训练你的机器学习模型来预测销售给定产品的利润。你可以获得的最高利润是10英镑，最大损失也是10英镑。在现实世界中，这个特定的财务问题可以使用一个简单的正弦波来建模，如图*图4**.1*所示。因此，为了获得最大利润，你必须在大约从生产日（第0天）起第二和第八天左右销售产品。蓝色线给出了现实世界中这个问题的实际模型。然而，这个模型对我们来说是隐藏的，因为如果我们知道这个模型，那么就没有必要使用机器学习来进行预测。假设真实数据完美地代表了这个模型。那么，在这个场景中的合成数据就是黑色点。换句话说，合成数据近似真实数据，而真实数据也是对现实世界中实际过程或现象的近似。
- en: '![Figure 4.1 – Simple example of real and synthetic data](img/Figure_04_01_B18494.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – 真实和合成数据的简单示例](img/Figure_04_01_B18494.jpg)'
- en: Figure 4.1 – Simple example of real and synthetic data
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 真实和合成数据的简单示例
- en: 'At this point, we may ask, why do we need to use synthetic data if real data
    is available? Indeed, this is a sound question: if you have sufficient, annotated,
    and unbiased real data with no privacy issues, you should not use synthetic data!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们可能会问，为什么在真实数据可用的情况下，我们还需要使用合成数据？确实，这是一个合理的问题：如果你有足够、标注且无偏见的真实数据，且没有隐私问题，那么你不应该使用合成数据！
- en: Unfortunately, in most real-world problems, such optimal datasets are unavailable,
    extremely expensive, and limited. Thus, synthetic data comes as a last resort
    to help ML models learn about the process or the task even when the real data
    is limited or absent. As you can see in *Figure 4**.1*, given only the scatter
    plot, we can still observe a clear pattern, that is, a **sine wave**, in this
    data. Thus, a suitable ML model will still be able to learn how to predict what
    is the best time to sell this product even if you train it using only synthetic
    data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在大多数现实世界的问题中，这样的最优数据集是不可用的，极其昂贵，且有限。因此，合成数据作为最后的手段来帮助机器学习模型了解过程或任务，即使真实数据有限或不存在。正如你在
    *图 4.1* 中所看到的，仅给出散点图，我们仍然可以观察到明显的模式，即一种 **正弦波**，在这组数据中。因此，一个合适的机器学习模型仍然能够学会如何预测最佳的销售时间，即使你只用合成数据进行训练。
- en: Data-centric and architecture-centric approaches in ML
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的数据中心和架构中心方法
- en: 'In the field of ML, there are two primary approaches: a model-centric approach,
    which focuses on the ML model and its architecture, and a data-centric approach,
    which prioritizes the data as shown in *Figure 4**.2*.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的领域中，有两种主要的方法：一种是以模型为中心的方法，它关注机器学习模型及其架构；另一种是以数据为中心的方法，它优先考虑数据，如图 *4.2*
    所示。
- en: '![Figure 4.2 – Data-centric and model -centric ML](img/Figure_04_02_B18494.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 以数据和模型为中心的机器学习](img/Figure_04_02_B18494.jpg)'
- en: Figure 4.2 – Data-centric and model -centric ML
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 以数据和模型为中心的机器学习
- en: Next, let us discuss these two approaches in more detail.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们更详细地讨论这两种方法。
- en: '**Model-centric ML**: The model-centric paradigm has been the predominant approach
    in ML until recently. This approach assumes that the dataset is fixed and strives
    to come up with a better architecture, novel training procedures, and new ways
    to search and find optimal hyperparameters. Let us focus on these elements and
    discuss them in more detail:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**以模型为中心的机器学习**：直到最近，以模型为中心的方法一直是机器学习中的主要方法。这种方法假设数据集是固定的，并努力提出更好的架构、新颖的训练程序以及新的搜索和找到最佳超参数的方法。让我们关注这些要素，并更详细地讨论它们：'
- en: '**Code and architecture**: Researchers continuously develop new architectures
    to better leverage and learn about the training data. For example, after the release
    of the well-known *ImageNet Large Scale Visual Recognition Challenge (ILSVRC)
    dataset* ([https://www.image-net.org/challenges/LSVRC](https://www.image-net.org/challenges/LSVRC)),
    many architectures were proposed to improve the top-5 classification error, such
    as AlexNet, *ImageNet Classification with Deep Convolutional Neural Networks*
    ([https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)),
    and ResNet, *Deep Residual Learning for Image Recognition* ([https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)).
    The improvements in the ML model can be in the number of layers, that is, the
    deep network; model parameters; learning filters; and others.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码和架构**：研究人员持续开发新的架构，以更好地利用和了解训练数据。例如，在著名的 *ImageNet 大规模视觉识别挑战（ILSVRC）数据集*
    ([https://www.image-net.org/challenges/LSVRC](https://www.image-net.org/challenges/LSVRC))
    发布之后，提出了许多架构来提高前 5 类分类误差，如 AlexNet、*使用深度卷积神经网络进行 ImageNet 分类* ([https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf))
    和 ResNet、*用于图像识别的深度残差学习* ([https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385))。机器学习模型在层数（即深度网络）、模型参数、学习滤波器等方面都有所改进。'
- en: '**Training**: Training is an interesting research area for ML researchers.
    Researchers try to find faster ways to train complex ML models and use less data.
    This addresses issues such as model parameter initialization techniques and their
    impact on the optimization process, proposes novel optimization techniques, better
    generalization, less overfitting, novel pretraining techniques, and better fine-tuning
    tricks for ML models.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练**：对于机器学习研究人员来说，训练是一个有趣的研究领域。研究人员试图找到更快的方式来训练复杂的机器学习模型，并使用更少的数据。这涉及到模型参数初始化技术及其对优化过程的影响，提出了新的优化技术，更好的泛化能力，减少过拟合，新的预训练技术，以及更好的机器学习模型微调技巧。'
- en: '**Hyperparameters**: Parameters such as the learning rate, batch size, and
    the number of layers highly impact the overall learning process and thus the model’s
    performance in the real world. Different approaches have been proposed to search
    for optimal hyperparameters efficiently to further improve ML models.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数**：如学习率、批量大小和层数等参数对整体学习过程以及模型在现实世界中的性能有重大影响。已经提出了不同的方法来高效地搜索最优超参数，以进一步改进机器学习模型。'
- en: '**Data-centric ML**: This approach started to get more momentum just recently.
    It focuses on the data itself rather than the architecture and code. It assumes
    the ML model’s architecture is fixed and strives to improve performance by focusing
    only on the dataset. It gives more attention to the following data-related concepts:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据为中心的机器学习**：这种方法最近才开始获得更多动力。它关注数据本身，而不是架构和代码。它假设机器学习模型的架构是固定的，并试图通过仅关注数据集来提高性能。它更关注以下与数据相关的概念：'
- en: Data quality
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据质量
- en: Ground-truth quality
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实数据质量
- en: Feature engineering
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Domain knowledge
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域知识
- en: Let’s see how synthetic data was developed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看合成数据是如何发展的。
- en: History of synthetic data
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据的历史
- en: In this section, we will learn about the evolution of synthetic data. Basically,
    we can categorize the use of synthetic data into the following categories, which
    may not reflect the chronological order, as it is very hard to track the early
    uses of synthetic data for each category.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解合成数据的演变。基本上，我们可以将合成数据的使用分为以下几类，这些类别可能不反映时间顺序，因为很难追踪每个类别早期使用合成数据的情况。
- en: Random number generators
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机数生成器
- en: '**Random number generators** are one of the simplest forms of synthetic data.
    Assume you are training an ML model to recognize faces. Let us say you have only
    a limited number of images. You can add, for example, random noise to the original
    images to create new synthetic ones. The implementation of random noise is possible
    through the utilization of random number generators. This will help the face recognizer
    ML model to learn how the person’s face changes under certain types of noise (see
    *Figure 4**.3*).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机数生成器**是合成数据最简单的形式之一。假设你正在训练一个机器学习模型来识别人脸。比如说，你只有有限数量的图像。你可以向原始图像添加随机噪声，以创建新的合成图像。随机噪声的实现可以通过使用随机数生成器来完成。这将帮助人脸识别机器学习模型学习在特定类型的噪声下人脸是如何变化的（参见*图4*.3）。'
- en: '![Figure 4.3 – Utilizing random number generators to generate synthetic images](img/Figure_04_03_B18494.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 利用随机数生成器生成合成图像](img/Figure_04_03_B18494.jpg)'
- en: Figure 4.3 – Utilizing random number generators to generate synthetic images
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 利用随机数生成器生成合成图像
- en: Next, we’ll learn about GANs, which are another step in the development of synthetic
    data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解GANs，这是合成数据发展中的另一个步骤。
- en: Generative Adversarial Networks (GANs)
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）
- en: GANs were introduced in 2014 by the famous **NeurIPS** (formerly **NIPS**) paper
    titled *Generative Adversarial Nets* by Ian Goodfellow et al. ([https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)).
    Since then, GANs have been utilized in various applications, such as generating
    human faces, photo inpainting, 3D object generation, text-to-image translations,
    and many more interesting applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GANs是由Ian Goodfellow等人于2014年通过一篇著名的**NeurIPS**（原名**NIPS**）论文引入的，该论文题为《生成对抗网络》（*Generative
    Adversarial Nets*）。([https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf))。从那时起，GANs被应用于各种应用，如生成人脸、照片修复、3D对象生成、文本到图像的翻译等等有趣的领域。
- en: 'A typical GAN is composed of two networks: a generator and a discriminator.
    The **generator** receives a noise random input vector and outputs a synthetic
    sample, for instance, say, a car image. The generator aims at making the synthetically
    generated data, for example, the car image, indistinguishable from the real data,
    real car images. The **discriminator**, on the other hand, strives to identify
    synthetic data from real data. The discriminator is fed with real or synthetic
    data and asked to predict the data source of the training sample. If the data
    sample was drawn from real data and the discriminator correctly identified the
    data source as real data, no error is backpropagated to the discriminator. On
    the other hand, the generator is penalized for predicting a sample that is distinguishable
    from the real dataset. Similarly, if the discriminator failed to identify the
    source of the image, the discriminator is penalized, and the generator is rewarded
    for generating indistinguishable synthetic samples close to the real dataset (see
    *Figure 4**.4*).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的GAN由两个网络组成：一个生成器和判别器。**生成器**接收一个噪声随机输入向量并输出一个合成样本，例如，可以说，一个汽车图像。生成器的目标是使合成的数据，例如，汽车图像，与真实数据不可区分，即真实汽车图像。另一方面，**判别器**努力从真实数据中识别合成数据。判别器被提供真实或合成数据，并要求预测训练样本的数据来源。如果数据样本是从真实数据中抽取的，并且判别器正确地将数据来源识别为真实数据，则不会向判别器回传错误。另一方面，如果生成器预测了一个与真实数据集可区分的样本，则生成器会受到惩罚。同样，如果判别器未能识别图像的来源，则判别器会受到惩罚，而生成器会因为生成接近真实数据集的不可区分的合成样本而获得奖励（见*图4.4*）。
- en: '![Figure 4.4 – A typical GAN training process](img/Figure_04_04_B18494.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – 典型的GAN训练过程](img/Figure_04_04_B18494.jpg)'
- en: Figure 4.4 – A typical GAN training process
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – 典型的GAN训练过程
- en: We will discuss GANs in more detail in [*Chapter 7*](B18494_07.xhtml#_idTextAnchor120).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第七章*](B18494_07.xhtml#_idTextAnchor120)中更详细地讨论GAN。
- en: Synthetic data for privacy issues
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于隐私问题的合成数据
- en: As we discussed in [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049), there are
    enormous privacy issues in real data, and current solutions are only partial solutions
    to the problem. Recently, synthetic data was proposed as a legitimate solution
    to these privacy issues. Usually, financial data is often associated with privacy
    issues as it is problematic to share customers’ data, such as personal details,
    transactions, assets, and income. This information usually is stored in tables.
    Surprisingly, it was shown that real data can be learned, and synthetic data can
    be generated. For example, the researchers who authored the paper titled *Modeling
    Tabular data using Conditional GAN* ([https://arxiv.org/abs/1907.00503](https://arxiv.org/abs/1907.00503))
    demonstrated that their **Conditional Tabular GAN** (**CTGAN**) can model the
    probability distribution of tabular real data with a complex distribution. Their
    code can be accessed from the paper’s GitHub repository at [https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[*第三章*](B18494_03.xhtml#_idTextAnchor049)中讨论的，真实数据中存在巨大的隐私问题，而当前解决方案只是部分解决方案。最近，合成数据被提出作为解决这些隐私问题的合法解决方案。通常，金融数据经常与隐私问题相关联，因为共享客户数据，如个人细节、交易、资产和收入是有问题的。这些信息通常存储在表格中。令人惊讶的是，已经证明可以从真实数据中学习，并可以生成合成数据。例如，撰写题为*使用条件GAN对表格数据进行建模*（[https://arxiv.org/abs/1907.00503](https://arxiv.org/abs/1907.00503)）的论文的研究人员证明了他们的**条件表格GAN**（**CTGAN**）可以以复杂分布对表格真实数据的概率分布进行建模。他们的代码可以从论文的GitHub存储库[https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN)中获取。
- en: Synthetic data in computer vision
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉中的合成数据
- en: Computer vision is one of the main fields in ML that requires large-scale training
    data. As we discussed earlier, collecting and annotating data for computer vision
    tasks is extremely expensive and the annotation process is error-prone. As a solution,
    researchers started to utilize various methods to generate synthetic data such
    as game engines, video games, GANs, and **Variational Auto****e****ncoders** (**VAEs**).
    The huge advancement in game engines such as *Unreal* ([https://www.unrealengine.com](https://www.unrealengine.com))
    and *Unity* ([https://unity.com](https://unity.com)) facilitated the creation
    of photorealistic 3D virtual worlds and thus the generation of high-quality and
    large-scale synthetic data. At the same time, the availability of powerful and
    affordable **Graphics Processing Units** (**GPUs**) for small research groups
    further popularized such game engines.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是机器学习领域需要大规模训练数据的主要领域之一。正如我们之前讨论的，为计算机视觉任务收集和标注数据极为昂贵，标注过程也容易出错。作为解决方案，研究人员开始利用各种方法来生成合成数据，例如游戏引擎、视频游戏、生成对抗网络（GANs）和**变分自编码器**（**VAEs**）。游戏引擎如*虚幻引擎*（[https://www.unrealengine.com](https://www.unrealengine.com)）和*Unity*（[https://unity.com](https://unity.com)）的巨大进步促进了逼真3D虚拟世界的创建，从而产生了高质量和大规模的合成数据。同时，小型研究组能够获得强大且价格合理的**图形处理单元**（**GPUs**），这进一步普及了这些游戏引擎。
- en: Synthetic data and ethical considerations
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据与伦理考量
- en: As synthetic data is gaining more attention and being utilized in various applications,
    in the last few months, many researchers, scientists, artists, and even the public
    started to question the copyright issues in texts and images generated using models,
    such as *Chat-GPT* ([https://chat.openai.com/chat](https://chat.openai.com/chat))
    and *Stable Diffusion* ([https://stablediffusionweb.com](https://stablediffusionweb.com)).
    At the same time, other issues such as accountability and transparency are being
    brought to light by the ML community for further precautions and more research.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随着合成数据越来越受到关注并被应用于各种应用中，在过去的几个月里，许多研究人员、科学家、艺术家甚至公众开始质疑使用模型（如*Chat-GPT*（[https://chat.openai.com/chat](https://chat.openai.com/chat)）和*Stable
    Diffusion*（[https://stablediffusionweb.com](https://stablediffusionweb.com)））生成的文本和图像中的版权问题。同时，机器学习社区也提出了其他问题，如问责制和透明度，以采取进一步预防措施并进行更多研究。
- en: Next, we will dive into the world of synthetic data and learn about its main
    types in ML.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入合成数据的世界，了解其在机器学习中的主要类型。
- en: Synthetic data types
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据类型
- en: There are various synthetic data types, such as textual, imagery, point cloud,
    and tabular. Based on the ML problem and task, different types of data are required.
    In this section, we will discuss the main types of synthetic data in more detail.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据类型有很多，例如文本、图像、点云和表格。根据机器学习问题和任务，需要不同类型的数据。在本节中，我们将更详细地讨论合成数据的主要类型。
- en: '![Figure 4.5 – A sample of synthetic data types](img/Figure_04_05_B18494.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 合成数据类型的示例](img/Figure_04_05_B18494.jpg)'
- en: Figure 4.5 – A sample of synthetic data types
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 合成数据类型的示例
- en: '**Text**: Wikipedia, digital books, lexicons, and text corpora are examples
    of textual data. ML models can be trained on large-scale textual datasets to learn
    the structure of the text that we generate or write as humans. Then, these models
    can be leveraged to answer questions, summarize texts, or translate from one language
    to another. These models, such as *ChatGPT*, *ChatSonic* ([https://writesonic.com](https://writesonic.com)),
    and *Jasper Chat* ([https://www.jasper.ai](https://www.jasper.ai)), work by generating
    synthetic texts based on making predictions on what word should come next.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本**：维基百科、数字书籍、词典和文本语料库是文本数据的例子。机器学习模型可以在大规模文本数据集上训练，以学习我们作为人类生成或编写的文本结构。然后，这些模型可以被用来回答问题、总结文本或从一种语言翻译到另一种语言。这些模型，如*ChatGPT*、*ChatSonic*（[https://writesonic.com](https://writesonic.com)）和*Jasper
    Chat*（[https://www.jasper.ai](https://www.jasper.ai)），通过预测下一个应该出现的单词来生成合成文本。'
- en: '**Video, image, and audio**: ML models can learn the patterns in a video, image,
    or audio, and then they can generate synthetic ones with some new conditions.
    Models such as *Stable Diffusion* ([https://github.com/CompVis/stable-diffusion#stable-diffusion-v1](https://github.com/CompVis/stable-diffusion#stable-diffusion-v1)),
    *DALL·E 2* ([https://openai.com/dall-e-2](https://openai.com/dall-e-2)), and *Imagen*
    ([https://imagen.research.google](https://imagen.research.google)) can be leveraged
    to generate, theoretically, an unlimited number of synthetic images under various
    conditions.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频、图像和音频**：ML模型可以学习视频、图像或音频中的模式，然后它们可以在某些新条件下生成合成的版本。例如，可以使用*Stable Diffusion*([https://github.com/CompVis/stable-diffusion#stable-diffusion-v1](https://github.com/CompVis/stable-diffusion#stable-diffusion-v1))、*DALL·E
    2*([https://openai.com/dall-e-2](https://openai.com/dall-e-2))和*Imagen*([https://imagen.research.google](https://imagen.research.google))等模型，理论上在多种条件下生成无限数量的合成图像。'
- en: '**Tabular**: This refers to data that is usually organized in rows and columns
    using tables. Typically, rows are the observations and columns are the attributes.
    ML models can be used to predict missing values in tabular data, for example,
    *Diffusion models for missing value imputation in tabular* *data* ([https://arxiv.org/abs/2210.17128](https://arxiv.org/abs/2210.17128)).'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表格**：这指的是通常使用表格按行和列组织的数据。通常，行是观测值，列是属性。ML模型可以用于预测表格数据中的缺失值，例如，*表格数据缺失值插补的扩散模型*([https://arxiv.org/abs/2210.17128](https://arxiv.org/abs/2210.17128))。'
- en: '`SynthCity` dataset was proposed in this paper titled *SynthCity: A large scale
    synthetic point cloud* ([https://arxiv.org/pdf/1907.04758.pdf](https://arxiv.org/pdf/1907.04758.pdf)),
    which provides more than 360 million synthetic point clouds.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这篇题为*SynthCity：大规模合成点云*的论文中提出了`SynthCity`数据集([https://arxiv.org/pdf/1907.04758.pdf](https://arxiv.org/pdf/1907.04758.pdf))，它提供了超过3.6亿个合成点云。
- en: In the next section, we delve into data augmentation techniques in ML.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入探讨ML中的数据增强技术。
- en: Data augmentation
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据增强
- en: 'Data augmentation is a simple yet powerful tool to mitigate overfitting problems,
    particularly when limited real data is available. Data augmentation techniques
    aim to leverage domain knowledge to enrich the available training data. Thus,
    data augmentation is usually applied only to the training data and not to validation
    or test data. For example, assume you are training a face recognition algorithm
    and you have only 10 images per person. We can simply double the number of these
    training samples if we horizontally flip the images. Furthermore, we can enhance
    the diversity of our training data by applying various transformations, such as
    shifting, scaling, and rotating, using random variables. Instead of using fixed
    values for these transformations, we can leverage a random number generator to
    generate new values for each training epoch. Thus, the ML model will be exposed
    to new variations of our training data at each training epoch. This simple data
    augmentation technique will help the model in the training process. There are
    various data augmentation techniques for images, audio, and texts. Next, let us
    discuss some of these techniques. Please refer to *Image Data Augmentation for
    Deep Learning: A Survey* ([https://arxiv.org/abs/2204.08610](https://arxiv.org/abs/2204.08610))
    for more details and techniques for image data augmentation.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一种简单而强大的工具，用于缓解过拟合问题，尤其是在可用真实数据有限的情况下。数据增强技术旨在利用领域知识来丰富可用的训练数据。因此，数据增强通常仅应用于训练数据，而不是验证或测试数据。例如，假设你正在训练一个面部识别算法，而你只有每人10张图片。如果我们水平翻转这些图片，我们可以简单地加倍这些训练样本的数量。此外，我们可以通过应用各种变换，如平移、缩放和旋转，使用随机变量来增强我们训练数据的多样性。而不是使用这些变换的固定值，我们可以利用随机数生成器为每个训练周期生成新的值。因此，ML模型将在每个训练周期接触到我们训练数据的新变体。这种简单的数据增强技术将有助于训练过程中的模型。有各种针对图像、音频和文本的数据增强技术。接下来，让我们讨论一些这些技术。请参阅*《深度学习中的图像数据增强：综述》*([https://arxiv.org/abs/2204.08610](https://arxiv.org/abs/2204.08610))以获取更多细节和图像数据增强的技术。
- en: Geometric transformations
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 几何变换
- en: When limited training images are available and acquiring new ones is expensive,
    we can apply geometric transformations to the original images, such as translation,
    rotation, cropping, and flipping. However, it is important to take care that the
    semantic meaning of the image is preserved after these operations. For example,
    for cats-versus-dogs classification training images, flipping the image horizontally
    is acceptable, but a vertical flip is not. Similarly, horizontal and vertical
    flips may not be valid for traffic sign recognition tasks (see *Figure 4**.6*).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当可用的训练图像有限且获取新的图像成本高昂时，我们可以对原始图像应用几何变换，例如平移、旋转、裁剪和翻转。然而，重要的是要注意在这些操作之后图像的语义意义得到保留。例如，对于猫与狗分类训练图像，水平翻转是可以接受的，但垂直翻转则不行。同样，水平和垂直翻转对于交通标志识别任务可能也不适用（参见
    *图 4.6*）。
- en: '![Figure 4.6 – Sample of valid and invalid geometric transformations](img/Figure_04_06_B18494.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 有效和无效的几何变换示例](img/Figure_04_06_B18494.jpg)'
- en: Figure 4.6 – Sample of valid and invalid geometric transformations
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 有效和无效的几何变换示例
- en: '**Translation** is simply shifting an image horizontally or vertically by a
    fixed or random number of units to avoid object bias. For example, assume all
    cat images in your cats-dogs classification dataset are in the upper right of
    the image. Then, the ML model will develop a wrong association between the cat
    class and the upper right of the image. **Rotation** refers to rotating the image
    at a specific angle clockwise or anticlockwise. Like flipping, for some applications,
    a specific range may be valid but other ranges may change the semantic meaning
    of the training image. **Cropping** is cutting the image using a virtual cropping
    window. It is possible to use a fixed or dynamic cropping window size (height
    and width).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**翻译**简单地说就是通过固定的或随机的单位数水平或垂直移动图像以避免对象偏差。例如，假设你分类数据集中的所有猫图像都位于图像的右上角。那么，ML
    模型将发展出错误的关联，将猫类别与图像的右上角联系起来。**旋转**指的是以特定的角度顺时针或逆时针旋转图像。像翻转一样，对于某些应用，特定的范围可能是有效的，但其他范围可能会改变训练图像的语义意义。**裁剪**是使用虚拟裁剪窗口裁剪图像。可以使用固定或动态的裁剪窗口大小（高度和宽度）。'
- en: Noise injection
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 噪声注入
- en: This technique can be applied to almost all data types and specifically to audio
    and images. Noise can be drawn from various probability distributions, such as
    normal (Gaussian), uniform, Poisson, and Bernoulli. As expected, training an ML
    model with carefully augmented data makes the model more robust against similar
    noise types. The injected noise can be utilized to simulate issues in a camera
    lens, microphone, transmission medium, and other sorts of distortions. When the
    ML model learns how to deal with similar scenarios in the training process, it
    will not struggle when these scenarios occur in the real world due to unpredictable
    factors, such as adverse weather conditions and hardware failures or other issues.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术可以应用于几乎所有的数据类型，特别是音频和图像。噪声可以从各种概率分布中抽取，例如正态（高斯）、均匀、泊松和伯努利。正如预期的那样，使用精心增强的数据训练
    ML 模型可以使模型对类似的噪声类型更加鲁棒。注入的噪声可以用来模拟相机镜头、麦克风、传输介质和其他类型的失真。当 ML 模型在训练过程中学习如何处理类似的场景时，由于不可预测的因素，如恶劣天气条件、硬件故障或其他问题，这些场景在现实世界中发生时，模型不会感到困难。
- en: Text replacement, deletion, and injection
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本替换、删除和注入
- en: These techniques are widely used to increase the size of the textual datasets
    when training a `Synthetic Data is essential in ML`” and we want to apply a text
    augmentation technique to it. Given the sentence, we can randomly select a word,
    in this example, “`essential`,” and replace it with one of its synonyms selected
    at random, for example, “`crucial`.” The augmented synthetic sentence becomes
    “`Synthetic Data is crucial` `in ML`.”
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术被广泛用于在训练“`合成数据在机器学习中至关重要`”时增加文本数据集的大小。当我们想要对它应用文本增强技术时，给定一个句子，我们可以随机选择一个单词，例如在这个例子中，“`essential`”，并用随机选择的一个同义词替换它，例如，“`crucial`”。增强后的合成句子变为“`Synthetic
    Data is crucial in ML`”。
- en: '![Figure 4.7 – Text augmentation pipeline using synonyms](img/Figure_04_07_B18494.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 使用同义词进行文本增强的流程](img/Figure_04_07_B18494.jpg)'
- en: Figure 4.7 – Text augmentation pipeline using synonyms
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 使用同义词进行文本增强的流程
- en: Similarly, **text deletion** and **text injection** can be utilized to generate
    synthetic text to improve the performance of ML models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，**文本删除**和**文本注入**可以被用来生成合成文本以改善 ML 模型的性能。
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored synthetic data and its evolution. We learned about
    the main types of synthetic data. In this chapter, we also discussed the key data
    augmentation techniques to enrich a limited real dataset for images, audio, and
    textual data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了合成数据及其演变。我们了解了合成数据的主要类型。在本章中，我们还讨论了关键的数据增强技术，用于丰富图像、音频和文本数据的有限真实数据集。
- en: In the next chapter, we will bring to light how synthetic data is being used
    as a solution for problems such as privacy and data scarcity. Additionally, we
    will learn why it is better in terms of cost and why it is a revolutionary solution
    for rare and limited real data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将揭示合成数据如何被用作解决隐私和数据稀缺等问题的一种解决方案。此外，我们还将了解为什么它在成本方面更优，以及为什么它是对稀有和有限真实数据的革命性解决方案。
