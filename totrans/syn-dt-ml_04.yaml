- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An Introduction to Synthetic Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will define and introduce synthetic data. We will briefly
    explore the history and evolution of synthetic data. Then, we will introduce the
    main types of synthetic data and the basic data augmentation approaches and techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is synthetic data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: History of synthetic data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code used in this chapter will be available under the corresponding chapter
    folder in the book’s GitHub repository: [https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning](https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning).'
  prefs: []
  type: TYPE_NORMAL
- en: What is synthetic data?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Synthetic data** is artificially generated data: the data is not captured,
    measured, or recorded from the real world. Instead, algorithms or software were
    used to create or generate this data. Synthetic data can be generated by simulating
    natural phenomena using mathematical models or by applying some approximations
    of real-world processes. There are many approaches to generating synthetic data,
    such as leveraging game engines, such as Unreal and Unity, or utilizing statistical
    models, such as GANs and diffusion models. As we know, ML models require large-scale
    training datasets for training and evaluation. Collecting and annotating these
    datasets is extremely time-consuming, error-prone, and subject to privacy issues.
    Please refer to *Chapters 2* and *3*. Synthetic data is a powerful solution to
    address these previous limitations.'
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data is useful for scenarios where collecting and annotating data
    is expensive, but its applications go beyond this particular use case, as we will
    see later. Synthetic data has been used in AI, ML, and data analytics, specifically
    for **computer vision** tasks, which usually require large and hard-to-annotate
    data for training. Thus, synthetic data has been widely utilized in this field
    and has shown great progress.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data can be generated to train or evaluate ML models under certain
    conditions that are usually hard to capture in the real world. For example, let
    us assume we would like to train a computer vision model to predict road traffic
    accidents based on some visual information such as RGB and LiDAR images. We would
    need to feed our training model with a sufficiently large dataset that includes
    thousands of road traffic accidents. Collecting this dataset from the real world
    may take us weeks, months, or years; it would require many engineers and annotators,
    and a huge budget to achieve our aim. At the same time, our dataset may not be
    valid in other countries or after a few years. If you collected your dataset in
    the UK, where people drive on the left, this dataset would not be applicable to
    China, where people drive on the right! In parallel to this, if you collected
    your dataset in 2005, your dataset may not be applicable for 2024 because of,
    for instance, new car models.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you generate your synthetic training data using a simulator
    such as *CARLA* ([https://carla.org](https://carla.org)), you can simulate thousands
    of road traffic accidents. Additionally, you can control car models, scene attributes,
    weather conditions, and other attributes. This is just an example of the advantages
    of synthetic data for the training and evaluation of ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic and real data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assume that you want to train your ML model to predict the profit of selling
    a given product. The maximum profit that you can get is £10 and the maximum loss
    is £10 as well. In the real world, this specific financial problem can be modeled
    using a simple sinusoidal wave as shown in *Figure 4**.1.* Thus, to get the maximum
    profit, you must sell the product on certain days approximately close to the second
    and eighth days from the production day (day 0). The blue line gives us the actual
    model of this problem in the real world. However, this model is hidden from us
    because if we know this model, then there is no need to use ML for the prediction.
    Assume that real data perfectly represents this model. Then, the synthetic data
    in this scenario is the black dots. In other words, synthetic data approximates
    the real data and real data is also an approximation of the actual process or
    phenomenon in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Simple example of real and synthetic data](img/Figure_04_01_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Simple example of real and synthetic data
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we may ask, why do we need to use synthetic data if real data
    is available? Indeed, this is a sound question: if you have sufficient, annotated,
    and unbiased real data with no privacy issues, you should not use synthetic data!'
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, in most real-world problems, such optimal datasets are unavailable,
    extremely expensive, and limited. Thus, synthetic data comes as a last resort
    to help ML models learn about the process or the task even when the real data
    is limited or absent. As you can see in *Figure 4**.1*, given only the scatter
    plot, we can still observe a clear pattern, that is, a **sine wave**, in this
    data. Thus, a suitable ML model will still be able to learn how to predict what
    is the best time to sell this product even if you train it using only synthetic
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Data-centric and architecture-centric approaches in ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the field of ML, there are two primary approaches: a model-centric approach,
    which focuses on the ML model and its architecture, and a data-centric approach,
    which prioritizes the data as shown in *Figure 4**.2*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Data-centric and model -centric ML](img/Figure_04_02_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Data-centric and model -centric ML
  prefs: []
  type: TYPE_NORMAL
- en: Next, let us discuss these two approaches in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: '**Model-centric ML**: The model-centric paradigm has been the predominant approach
    in ML until recently. This approach assumes that the dataset is fixed and strives
    to come up with a better architecture, novel training procedures, and new ways
    to search and find optimal hyperparameters. Let us focus on these elements and
    discuss them in more detail:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code and architecture**: Researchers continuously develop new architectures
    to better leverage and learn about the training data. For example, after the release
    of the well-known *ImageNet Large Scale Visual Recognition Challenge (ILSVRC)
    dataset* ([https://www.image-net.org/challenges/LSVRC](https://www.image-net.org/challenges/LSVRC)),
    many architectures were proposed to improve the top-5 classification error, such
    as AlexNet, *ImageNet Classification with Deep Convolutional Neural Networks*
    ([https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)),
    and ResNet, *Deep Residual Learning for Image Recognition* ([https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)).
    The improvements in the ML model can be in the number of layers, that is, the
    deep network; model parameters; learning filters; and others.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training**: Training is an interesting research area for ML researchers.
    Researchers try to find faster ways to train complex ML models and use less data.
    This addresses issues such as model parameter initialization techniques and their
    impact on the optimization process, proposes novel optimization techniques, better
    generalization, less overfitting, novel pretraining techniques, and better fine-tuning
    tricks for ML models.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hyperparameters**: Parameters such as the learning rate, batch size, and
    the number of layers highly impact the overall learning process and thus the model’s
    performance in the real world. Different approaches have been proposed to search
    for optimal hyperparameters efficiently to further improve ML models.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-centric ML**: This approach started to get more momentum just recently.
    It focuses on the data itself rather than the architecture and code. It assumes
    the ML model’s architecture is fixed and strives to improve performance by focusing
    only on the dataset. It gives more attention to the following data-related concepts:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data quality
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ground-truth quality
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain knowledge
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s see how synthetic data was developed.
  prefs: []
  type: TYPE_NORMAL
- en: History of synthetic data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will learn about the evolution of synthetic data. Basically,
    we can categorize the use of synthetic data into the following categories, which
    may not reflect the chronological order, as it is very hard to track the early
    uses of synthetic data for each category.
  prefs: []
  type: TYPE_NORMAL
- en: Random number generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Random number generators** are one of the simplest forms of synthetic data.
    Assume you are training an ML model to recognize faces. Let us say you have only
    a limited number of images. You can add, for example, random noise to the original
    images to create new synthetic ones. The implementation of random noise is possible
    through the utilization of random number generators. This will help the face recognizer
    ML model to learn how the person’s face changes under certain types of noise (see
    *Figure 4**.3*).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Utilizing random number generators to generate synthetic images](img/Figure_04_03_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Utilizing random number generators to generate synthetic images
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll learn about GANs, which are another step in the development of synthetic
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Networks (GANs)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GANs were introduced in 2014 by the famous **NeurIPS** (formerly **NIPS**) paper
    titled *Generative Adversarial Nets* by Ian Goodfellow et al. ([https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)).
    Since then, GANs have been utilized in various applications, such as generating
    human faces, photo inpainting, 3D object generation, text-to-image translations,
    and many more interesting applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical GAN is composed of two networks: a generator and a discriminator.
    The **generator** receives a noise random input vector and outputs a synthetic
    sample, for instance, say, a car image. The generator aims at making the synthetically
    generated data, for example, the car image, indistinguishable from the real data,
    real car images. The **discriminator**, on the other hand, strives to identify
    synthetic data from real data. The discriminator is fed with real or synthetic
    data and asked to predict the data source of the training sample. If the data
    sample was drawn from real data and the discriminator correctly identified the
    data source as real data, no error is backpropagated to the discriminator. On
    the other hand, the generator is penalized for predicting a sample that is distinguishable
    from the real dataset. Similarly, if the discriminator failed to identify the
    source of the image, the discriminator is penalized, and the generator is rewarded
    for generating indistinguishable synthetic samples close to the real dataset (see
    *Figure 4**.4*).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – A typical GAN training process](img/Figure_04_04_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – A typical GAN training process
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss GANs in more detail in [*Chapter 7*](B18494_07.xhtml#_idTextAnchor120).
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data for privacy issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we discussed in [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049), there are
    enormous privacy issues in real data, and current solutions are only partial solutions
    to the problem. Recently, synthetic data was proposed as a legitimate solution
    to these privacy issues. Usually, financial data is often associated with privacy
    issues as it is problematic to share customers’ data, such as personal details,
    transactions, assets, and income. This information usually is stored in tables.
    Surprisingly, it was shown that real data can be learned, and synthetic data can
    be generated. For example, the researchers who authored the paper titled *Modeling
    Tabular data using Conditional GAN* ([https://arxiv.org/abs/1907.00503](https://arxiv.org/abs/1907.00503))
    demonstrated that their **Conditional Tabular GAN** (**CTGAN**) can model the
    probability distribution of tabular real data with a complex distribution. Their
    code can be accessed from the paper’s GitHub repository at [https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN).
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data in computer vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computer vision is one of the main fields in ML that requires large-scale training
    data. As we discussed earlier, collecting and annotating data for computer vision
    tasks is extremely expensive and the annotation process is error-prone. As a solution,
    researchers started to utilize various methods to generate synthetic data such
    as game engines, video games, GANs, and **Variational Auto****e****ncoders** (**VAEs**).
    The huge advancement in game engines such as *Unreal* ([https://www.unrealengine.com](https://www.unrealengine.com))
    and *Unity* ([https://unity.com](https://unity.com)) facilitated the creation
    of photorealistic 3D virtual worlds and thus the generation of high-quality and
    large-scale synthetic data. At the same time, the availability of powerful and
    affordable **Graphics Processing Units** (**GPUs**) for small research groups
    further popularized such game engines.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data and ethical considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As synthetic data is gaining more attention and being utilized in various applications,
    in the last few months, many researchers, scientists, artists, and even the public
    started to question the copyright issues in texts and images generated using models,
    such as *Chat-GPT* ([https://chat.openai.com/chat](https://chat.openai.com/chat))
    and *Stable Diffusion* ([https://stablediffusionweb.com](https://stablediffusionweb.com)).
    At the same time, other issues such as accountability and transparency are being
    brought to light by the ML community for further precautions and more research.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will dive into the world of synthetic data and learn about its main
    types in ML.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are various synthetic data types, such as textual, imagery, point cloud,
    and tabular. Based on the ML problem and task, different types of data are required.
    In this section, we will discuss the main types of synthetic data in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – A sample of synthetic data types](img/Figure_04_05_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – A sample of synthetic data types
  prefs: []
  type: TYPE_NORMAL
- en: '**Text**: Wikipedia, digital books, lexicons, and text corpora are examples
    of textual data. ML models can be trained on large-scale textual datasets to learn
    the structure of the text that we generate or write as humans. Then, these models
    can be leveraged to answer questions, summarize texts, or translate from one language
    to another. These models, such as *ChatGPT*, *ChatSonic* ([https://writesonic.com](https://writesonic.com)),
    and *Jasper Chat* ([https://www.jasper.ai](https://www.jasper.ai)), work by generating
    synthetic texts based on making predictions on what word should come next.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video, image, and audio**: ML models can learn the patterns in a video, image,
    or audio, and then they can generate synthetic ones with some new conditions.
    Models such as *Stable Diffusion* ([https://github.com/CompVis/stable-diffusion#stable-diffusion-v1](https://github.com/CompVis/stable-diffusion#stable-diffusion-v1)),
    *DALL·E 2* ([https://openai.com/dall-e-2](https://openai.com/dall-e-2)), and *Imagen*
    ([https://imagen.research.google](https://imagen.research.google)) can be leveraged
    to generate, theoretically, an unlimited number of synthetic images under various
    conditions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tabular**: This refers to data that is usually organized in rows and columns
    using tables. Typically, rows are the observations and columns are the attributes.
    ML models can be used to predict missing values in tabular data, for example,
    *Diffusion models for missing value imputation in tabular* *data* ([https://arxiv.org/abs/2210.17128](https://arxiv.org/abs/2210.17128)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SynthCity` dataset was proposed in this paper titled *SynthCity: A large scale
    synthetic point cloud* ([https://arxiv.org/pdf/1907.04758.pdf](https://arxiv.org/pdf/1907.04758.pdf)),
    which provides more than 360 million synthetic point clouds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we delve into data augmentation techniques in ML.
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data augmentation is a simple yet powerful tool to mitigate overfitting problems,
    particularly when limited real data is available. Data augmentation techniques
    aim to leverage domain knowledge to enrich the available training data. Thus,
    data augmentation is usually applied only to the training data and not to validation
    or test data. For example, assume you are training a face recognition algorithm
    and you have only 10 images per person. We can simply double the number of these
    training samples if we horizontally flip the images. Furthermore, we can enhance
    the diversity of our training data by applying various transformations, such as
    shifting, scaling, and rotating, using random variables. Instead of using fixed
    values for these transformations, we can leverage a random number generator to
    generate new values for each training epoch. Thus, the ML model will be exposed
    to new variations of our training data at each training epoch. This simple data
    augmentation technique will help the model in the training process. There are
    various data augmentation techniques for images, audio, and texts. Next, let us
    discuss some of these techniques. Please refer to *Image Data Augmentation for
    Deep Learning: A Survey* ([https://arxiv.org/abs/2204.08610](https://arxiv.org/abs/2204.08610))
    for more details and techniques for image data augmentation.'
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When limited training images are available and acquiring new ones is expensive,
    we can apply geometric transformations to the original images, such as translation,
    rotation, cropping, and flipping. However, it is important to take care that the
    semantic meaning of the image is preserved after these operations. For example,
    for cats-versus-dogs classification training images, flipping the image horizontally
    is acceptable, but a vertical flip is not. Similarly, horizontal and vertical
    flips may not be valid for traffic sign recognition tasks (see *Figure 4**.6*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Sample of valid and invalid geometric transformations](img/Figure_04_06_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – Sample of valid and invalid geometric transformations
  prefs: []
  type: TYPE_NORMAL
- en: '**Translation** is simply shifting an image horizontally or vertically by a
    fixed or random number of units to avoid object bias. For example, assume all
    cat images in your cats-dogs classification dataset are in the upper right of
    the image. Then, the ML model will develop a wrong association between the cat
    class and the upper right of the image. **Rotation** refers to rotating the image
    at a specific angle clockwise or anticlockwise. Like flipping, for some applications,
    a specific range may be valid but other ranges may change the semantic meaning
    of the training image. **Cropping** is cutting the image using a virtual cropping
    window. It is possible to use a fixed or dynamic cropping window size (height
    and width).'
  prefs: []
  type: TYPE_NORMAL
- en: Noise injection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This technique can be applied to almost all data types and specifically to audio
    and images. Noise can be drawn from various probability distributions, such as
    normal (Gaussian), uniform, Poisson, and Bernoulli. As expected, training an ML
    model with carefully augmented data makes the model more robust against similar
    noise types. The injected noise can be utilized to simulate issues in a camera
    lens, microphone, transmission medium, and other sorts of distortions. When the
    ML model learns how to deal with similar scenarios in the training process, it
    will not struggle when these scenarios occur in the real world due to unpredictable
    factors, such as adverse weather conditions and hardware failures or other issues.
  prefs: []
  type: TYPE_NORMAL
- en: Text replacement, deletion, and injection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These techniques are widely used to increase the size of the textual datasets
    when training a `Synthetic Data is essential in ML`” and we want to apply a text
    augmentation technique to it. Given the sentence, we can randomly select a word,
    in this example, “`essential`,” and replace it with one of its synonyms selected
    at random, for example, “`crucial`.” The augmented synthetic sentence becomes
    “`Synthetic Data is crucial` `in ML`.”
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Text augmentation pipeline using synonyms](img/Figure_04_07_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Text augmentation pipeline using synonyms
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, **text deletion** and **text injection** can be utilized to generate
    synthetic text to improve the performance of ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored synthetic data and its evolution. We learned about
    the main types of synthetic data. In this chapter, we also discussed the key data
    augmentation techniques to enrich a limited real dataset for images, audio, and
    textual data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will bring to light how synthetic data is being used
    as a solution for problems such as privacy and data scarcity. Additionally, we
    will learn why it is better in terms of cost and why it is a revolutionary solution
    for rare and limited real data.
  prefs: []
  type: TYPE_NORMAL
