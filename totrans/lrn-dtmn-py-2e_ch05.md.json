["```py\nimport os\nimport pandas as pd\ndata_folder = os.path.join(os.path.expanduser(\"~\"), \"Data\", \"Adult\")\nadult_filename = os.path.join(data_folder, \"adult.data\")\n\nadult = pd.read_csv(adult_filename, header=None, names=[\"Age\", \"Work-Class\", \"fnlwgt\", \n                     \"Education\", \"Education-Num\", \"Marital-Status\", \"Occupation\",\n                     \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\",\n                     \"Hours-per-week\", \"Native-Country\", \"Earnings-Raw\"])\n\n```", "```py\nadult.dropna(how='all', inplace=True)\n\n```", "```py\nadult.columns\n\n```", "```py\nIndex(['Age', 'Work-Class', 'fnlwgt', 'Education', \n'Education-Num', 'Marital-Status', 'Occupation', 'Relationship', \n'Race', 'Sex', 'Capital-gain', 'Capital-loss', 'Hours-per-week', \n'Native-Country', 'Earnings-Raw'], dtype='object')\n\n```", "```py\nadult[\"Hours-per-week\"].describe()\n\n```", "```py\ncount 32561.000000\nmean 40.437456\nstd 12.347429\nmin 1.000000\n25% 40.000000\n50% 40.000000\n75% 45.000000\nmax 99.000000\ndtype: float64\n\n```", "```py\nadult[\"Education-Num\"].median()\n\n```", "```py\nadult[\"Work-Class\"].unique()\n\n```", "```py\narray([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n' Never-worked', nan], dtype=object)\n\n```", "```py\n%matplotlib inline\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nsns.swarmplot(x=\"Education-Num\", y=\"Hours-per-week\", hue=\"Earnings-Raw\", data=adult[::50])\n\n```", "```py\nimport numpy as np\nX = np.arange(30).reshape((10, 3))\n\n```", "```py\narray([[ 0, 1, 2],\n[ 3, 4, 5],\n[ 6, 7, 8],\n[ 9, 10, 11],\n[12, 13, 14],\n[15, 16, 17],\n[18, 19, 20],\n[21, 22, 23],\n[24, 25, 26],\n[27, 28, 29]])\n\n```", "```py\nX[:,1] = 1\n\n```", "```py\narray([[ 0, 1, 2],\n[ 3, 1, 5],\n[ 6, 1, 8],\n[ 9, 1, 11],\n[12, 1, 14],\n[15, 1, 17],\n[18, 1, 20],\n[21, 1, 23],\n[24, 1, 26],\n[27, 1, 29]])\n\n```", "```py\nfrom sklearn.feature_selection import VarianceThreshold\nvt = VarianceThreshold()\nXt = vt.fit_transform(X)\n\n```", "```py\narray([[ 0, 2],\n[ 3, 5],\n[ 6, 8],\n[ 9, 11],\n[12, 14],\n[15, 17],\n[18, 20],\n[21, 23],\n[24, 26],\n[27, 29]])\n\n```", "```py\nprint(vt.variances_)\n\n```", "```py\narray([ 74.25, 0\\. , 74.25])\n\n```", "```py\nX = adult[[\"Age\", \"Education-Num\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\"]].values\n\n```", "```py\ny = (adult[\"Earnings-Raw\"] == ' >50K').values\n\n```", "```py\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\ntransformer = SelectKBest(score_func=chi2, k=3)\n\n```", "```py\nXt_chi2 = transformer.fit_transform(X, y)\n\n```", "```py\nprint(transformer.scores_)\n\n```", "```py\n[ 8.60061182e+03 2.40142178e+03 8.21924671e+07 1.37214589e+066.47640900e+03]\n\n```", "```py\nfrom scipy.stats import pearsonr\n\n```", "```py\ndef multivariate_pearsonr(X, y):\n    scores, pvalues = [], []\n    for column in range(X.shape[1]):\n        # Compute the Pearson correlation for this column only\n        cur_score, cur_p = pearsonr(X[:,column], y)\n        # Record both the score and p-value.\n        scores.append(abs(cur_score))\n        pvalues.append(cur_p)\n    return (np.array(scores), np.array(pvalues))\n\n```", "```py\ntransformer = SelectKBest(score_func=multivariate_pearsonr, k=3)\nXt_pearson = transformer.fit_transform(X, y)\nprint(transformer.scores_)\n\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cross_validation import cross_val_score\nclf = DecisionTreeClassifier(random_state=14)\nscores_chi2 = cross_val_score(clf, Xt_chi2, y, scoring='accuracy')\nscores_pearson = cross_val_score(clf, Xt_pearson, y, scoring='accuracy')\n\nprint(\"Chi2 score: {:.3f}\".format(scores_chi2.mean()))\nprint(\"Pearson score: {:.3f}\".format(scores_pearson.mean()))\n\n```", "```py\nimport os\nimport numpy as np\nimport pandas as pd\ndata_folder = os.path.join(os.path.expanduser(\"~\"), \"Data\")\ndata_filename = os.path.join(data_folder, \"Ads\", \"ad.data\")\n\n```", "```py\ndef convert_number(x):\n    try:\n        return float(x)\n    except ValueError:\n        return np.nan\n\n```", "```py\nconverters = {}\nfor i in range(1558):\n    converters[i] = convert_number\n\n```", "```py\nconverters[1558] = lambda x: 1 if x.strip() == \"ad.\" else 0\n\n```", "```py\nads = pd.read_csv(data_filename, header=None, converters=converters)\n\n```", "```py\nads.dropna(inplace=True)\nX = ads.drop(1558, axis=1).values\ny = ads[1558]\n\n```", "```py\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=5)\nXd = pca.fit_transform(X)\n\n```", "```py\nnp.set_printoptions(precision=3, suppress=True)\npca.explained_variance_ratio_\n\n```", "```py\nclf = DecisionTreeClassifier(random_state=14)\nscores_reduced = cross_val_score(clf, Xd, y, scoring='accuracy')\n\n```", "```py\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\n```", "```py\nclasses = set(y)\n\n```", "```py\ncolors = ['red', 'green']\n\n```", "```py\nfor cur_class, color in zip(classes, colors):\nmask = (y == cur_class)\n    plt.scatter(Xd[mask,0], Xd[mask,1], marker='o', color=color, label=int(cur_class))\n\n```", "```py\nplt.legend()\nplt.show()\n\n```", "```py\nfrom sklearn.base import TransformerMixin\nfrom sklearn.utils import as_float_array\n\n```", "```py\nclass MeanDiscrete(TransformerMixin):\n    def fit(self, X, y=None):\n        X = as_float_array(X)\n        self.mean = X.mean(axis=0)\n        return self\n\n    def transform(self, X, y=None):\n        X = as_float_array(X)\n        assert X.shape[1] == self.mean.shape[0]\n        return X > self.mean\n\n```", "```py\nmean_discrete = MeanDiscrete()\nX_mean = mean_discrete.fit_transform(X)\n\n```", "```py\ndef test_meandiscrete():\n    X_test = np.array([[ 0, 2],\n                       [ 3, 5],\n                       [ 6, 8],\n                       [ 9, 11],\n                       [12, 14],\n                       [15, 17],\n                       [18, 20],\n                       [21, 23],\n                       [24, 26],\n                       [27, 29]])\n    # Create an instance of our Transformer\n    mean_discrete = MeanDiscrete()\n    mean_discrete.fit(X_test)\n    # Check that the computed mean is correct\n    assert_array_equal(mean_discrete.mean, np.array([13.5, 15.5]))\n    # Also test that transform works properly\n    X_transformed = mean_discrete.transform(X_test)\n    X_expected = np.array([[ 0, 0],\n                           [ 0, 0], \n                           [ 0, 0],\n                           [ 0, 0],\n                           [ 0, 0],\n                           [ 1, 1],\n                           [ 1, 1],\n                           [ 1, 1],\n                           [ 1, 1],\n                           [ 1, 1]])\n    assert_array_equal(X_transformed, X_expected)\n\n```", "```py\ntest_meandiscrete()\n\n```", "```py\nfrom sklearn.pipeline import Pipeline\npipeline = Pipeline([('mean_discrete', MeanDiscrete()), ('classifier', DecisionTreeClassifier(random_state=14))])\nscores_mean_discrete = cross_val_score(pipeline, X, y, scoring='accuracy')\nprint(\"Mean Discrete performance: {0:.3f}\".format(scores_mean_discrete.mean()))\n\n```"]