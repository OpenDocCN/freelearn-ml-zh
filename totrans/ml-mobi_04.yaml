- en: TensorFlow Mobile in Android
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we focused on supervised learning and unsupervised
    learning, and learned about the different types of learning algorithms. In this chapter,
    we will get introduced to TensorFlow for mobile, and go through a sample program
    implementation using TensorFlow for mobile. In [Chapter 9](3e97f92b-a2d9-4618-9a3b-91552fa3fc3d.xhtml), *Neural
    Networks on Mobile*, we will be using it to implement a classification algorithm.
    But we need to understand how TensorFlow for mobile works and be able to write
    samples using it before we can implement machine learning algorithms with it.
    The objective of this chapter is to get introduced to TensorFlow, TensorFlow Lite,
    TensorFlow for mobile, and their ways of working, and to try hands-on examples
    using TensorFlow for mobile in Android.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to TensorFlow, TensorFlow Lite, and TensorFlow for mobile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The components of TensorFlow for mobile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture of a mobile machine learning application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a sample program using TensorFlow for mobile in Android
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will know how to build an application using
    TensorFlow for mobile in Android. We will walk through using it in order to implement
    a classification algorithm in [Chapter 9](3e97f92b-a2d9-4618-9a3b-91552fa3fc3d.xhtml), *Neural
    Networks on Mobile*.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TensorFlow is a tool to implement machine learning developed by Google, and
    was open sourced in 2015. It is a product that can be installed on desktops and
    can be used to create machine learning models. Once the model has been built and
    trained on the desktop, the developer can transfer these models to mobile devices
    and start using them to predict results in mobile applications by integrating
    them into iOS and Android mobile applications. There are currently two flavors of
    TensorFlow available for implementing machine learning solutions on mobile and
    embedded devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mobile devices**: TensorFlow for Mobile'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mobile and Embedded devices**: TensorFlow Lite'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table will help you to understand the key differences between
    TensorFlow for mobile and TensorFlow Lite:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **TensorFlow for Mobile** | **TensorFlow Lite** |'
  prefs: []
  type: TYPE_TB
- en: '| Designed to work with larger devices. | Designed to work with really small
    devices. |'
  prefs: []
  type: TYPE_TB
- en: '| Binary is optimized for mobile. | Binary is really very small in size optimized
    for mobile and embedded devices, minimal dependencies, and enhanced performance.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Enables deployment in CPU, GPU, and TPU across Android, iOS, and Raspberry
    Pi. | Supports hardware acceleration. Deployment possible on iOS, Android, and
    Raspberry Pi. |'
  prefs: []
  type: TYPE_TB
- en: '| Recommended for usage now in mobile devices for production deployments. |
    Still under Beta and is undergoing improvements. |'
  prefs: []
  type: TYPE_TB
- en: '| Wider operator and ML model support available. | Limited operators supported,
    and not all ML models are supported. |'
  prefs: []
  type: TYPE_TB
- en: TensorFlow Lite components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will go through the details of TensorFlow Lite: the overall
    architecture, the key components, and their functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram provides a high-level overview of the key components
    and how they interact to bring machine learning to mobile devices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/628519c5-2f39-4323-a659-99e7b4efd8f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following are the key steps to be followed when implementing ML on devices:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the TensorFlow, or any other machine learning framework, to create the trained
    TensorFlow/ML models on the desktop. The trained model can also be created using
    any Cloud ML engine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the TensorFlow Lite converter to convert the trained ML model to the TensorFlow
    Lite model file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a mobile application using these files and convert it into a package for
    deployment and execution in mobile devices. These lite files could be interpreted
    and executed directly in the kernels or in the hardware accelerators, if available
    in the device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following are the key components of TensorFlow Lite:'
  prefs: []
  type: TYPE_NORMAL
- en: Model-file format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ops/kernel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interface to hardware acceleration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model-file format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the highlights of the model-file format:'
  prefs: []
  type: TYPE_NORMAL
- en: It is lightweight and has very few software dependencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It supports quantization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This format is FlatBuffer-based and, hence, increases the speed of execution.
    FlatBuffer is an open source project by Google, originally designed for video
    games.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: FlatBuffer is a cross-platform serialization library and is similar to protocol
    buffers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This format is more memory-efficient as it does not need a parsing/unpacking
    step to perform a secondary representation prior to data access. There is no marshaling step
    and, hence, it uses less code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the highlights of the interpreter:'
  prefs: []
  type: TYPE_NORMAL
- en: It is a mobile-optimized interpreter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It helps to keep mobile apps lean and fast.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It uses a static-graph ordering and a custom (less dynamic) memory allocator
    to ensure minimal load, initialization, and execution latency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interpreter has a static memory plan and a static execution plan.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ops/Kernel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A set of core operators, both quantized and float, many of which have been tuned
    for mobile platforms. These can be used to create and run custom models. Developers
    can also write their own custom operators and use them in models.
  prefs: []
  type: TYPE_NORMAL
- en: Interface to hardware acceleration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow Lite has an interface to hardware accelerators; in Android, it is
    through the Android Neural Network API and, in iOS, it is through CoreML.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the pretested models that are guaranteed to work out of the
    box with TensorFlow Lite:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inception V3**: A popular model for detecting the dominant objects present
    in an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MobileNets:** Computer vision models that can be used for classification,
    detection, and segmentation. MobileNet models are smaller, but less accurate,
    than Inception V3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**On-device smart reply**: An on-device model that provides one-touch replies
    for an incoming text message by suggesting contextually-relevant messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture of a mobile machine learning application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we understand the components of TensorFlow Lite, we'll look at how
    a mobile application works with the TensorFlow components to provide the mobile
    ML solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mobile application should leverage the TensorFlow Lite model file to perform
    the inference for future data. The TensorFlow Lite model file can either be packaged
    with the mobile application and deployed together, or kept separate from the mobile
    application deployment package. The following diagram depicts the two possible
    deployment scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6bffeb98-43b8-4317-b06d-15857be6f603.png)'
  prefs: []
  type: TYPE_IMG
- en: Each deployment has its pros and cons. In the first case, where both are coupled,
    there is more security for the model file and it can be kept safe and secured.
    This is a more straightforward approach. However, the application package size
    is increased due to the size of the model file. In the second case, where both
    are kept separate, it is easy to update the model file separately, without performing
    an application upgrade. Hence, all activities with respect to the application
    upgrade, deployment to the app store, and so on can be avoided for a model upgrade.
    The application package size can also be minimized due to this separation. However,
    since the model file is standalone, it should be handled with greater care, without
    leaving it vulnerable to security threats.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having got an overview of the mobile application with the TensorFlow Lite model
    file, let''s look at the whole picture. The mobile application is packaged with
    the TensorFlow Lite model file. This interaction between the mobile application
    written using the Android SDK and the TensorFlow Lite model file happens through
    the TensorFlow Lite Interpreter, which is part of the Android NDK layer. The C
    functions are invoked through the interfaces exposed to the SDK layer from the
    mobile application in order to do the prediction or inference by using the trained
    TensorFlow Lite model deployed with the mobile application. The following diagram
    provides a clear view of the layers of the SDK and NDK of the Android ecosystem
    that will be involved in a typical machine learning program. The execution can
    also be triggered on GPU or any specialized processors through the android NN
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf31274a-6fd3-4944-b593-0ac6b96428e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Understanding the model concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before writing our first program using TensorFlow, we will briefly go through
    the concepts that will help us to understand how the TensorFlow Lite model work.
    We won't be going into the details, but a conceptual high level overview alone
    for better understanding.
  prefs: []
  type: TYPE_NORMAL
- en: MobileNet and Inception V3 are the built-in models that are based on **convolutional
    neural networks** (**CNNs**).
  prefs: []
  type: TYPE_NORMAL
- en: At its most basic level, CNN can be thought of as a kind of neural network that
    uses many identical copies of the same neuron. This allows the network to have
    lots of neurons and express computationally large models while keeping the number
    of actual parameters – the values describing how neurons behave – that need to
    be learned fairly low.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept can be understood with the analogy of a Jigsaw puzzle and how
    we usually solve one. The following diagram is a puzzle that needs to be solved:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6d8c0e4b-9f45-45ea-a30b-32460471c42e.png)'
  prefs: []
  type: TYPE_IMG
- en: If we have to assemble this puzzle from the pieces provided, just think about
    how you will start solving it. You may group all the pieces with different colors
    together. Then within the same color, you'd check for patterns and then assemble
    them. This is the same way that convolutional networks train for image classification
    and recognition. Hence there is only a small portion, each neuron remembers. But
    the parent neuron understands how the things within its scope needs to be assembled
    to get the big picture.
  prefs: []
  type: TYPE_NORMAL
- en: In the Inception V3 and the MobileNet models, both work based on the CNN concept.
    The model is pretty much trained and stable. All we need to do to use our set
    of images is retrain the model with our images. So now that we have had enough
    of concepts and theory, we will move on to writing our first sample program using
    TensorFlow Lite for Android.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using the TensorFlow for mobile for a classification application
    in [Chapter 9](3e97f92b-a2d9-4618-9a3b-91552fa3fc3d.xhtml), *Neural Networks on
    Mobile*
  prefs: []
  type: TYPE_NORMAL
- en: Writing the mobile application using the TensorFlow model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**What we are going to do?**'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to build a small `(a+b)2` model in TensorFlow,
    deploy it into an android mobile application, and run it from the Android mobile
    device.
  prefs: []
  type: TYPE_NORMAL
- en: '**What do you need to know?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To proceed in this section, you need a working installation of Python, TensorFlow
    dependencies, and android studio, and also some knowledge of python and java android.
    You can find the instructions on how to install TensorFlow here: [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/).'
  prefs: []
  type: TYPE_NORMAL
- en: If you need a detailed installation procedure for Windows, please refer to the
    one provided with screenshots in the [Chapter 11](d7ddae2d-9276-461e-9526-73448159e26b.xhtml),
    *The Future of ML on Mobile Applications* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: We saw the details of TensorFlow already. To put it onto a simple words TensorFlow
    is nothing but saving the tensor flow program written in python into a small file
    that can be read by the C++ native libraries what we will install in our Android
    app and can execute and do the inference from the mobile. To do so, JNI (Java
    native interface) is working as a bridge between java and C++.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about the idea behind tensor flow lite, check out [https://www.tensorflow.org/mobile/tflite/.](https://www.tensorflow.org/mobile/tflite/)
  prefs: []
  type: TYPE_NORMAL
- en: Writing our first program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to write a TensorFlow mobile application, there are a few steps that
    we need to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the TF (TensorFlow) model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Freeze the graph
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimize the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the Android application and execute it
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will go through each of the steps in detail now.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and Saving the TF model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we first create a simple model and save its computation graph as a serialized
    `GraphDef` file. After training the model, we then save the values of its variables
    into a checkpoint file. We have to turn these two files into an optimized standalone
    file, which is all we need to use inside the Android app.
  prefs: []
  type: TYPE_NORMAL
- en: For this tutorial, we create a very simple TensorFlow graph that implements
    a small use case that will calculate *(a+b)²=c*. Here, we are saving the input
    as *a* and *b*, and the output as *c*.
  prefs: []
  type: TYPE_NORMAL
- en: To implement this sample program, we are going to use Python. So, as a prerequisite,
    you need to install python in your machine and install the TensorFlow libraries
    on your machine using `pip`.
  prefs: []
  type: TYPE_NORMAL
- en: Please check the software installations/appendix section of this book for instructions
    on how to install Python. `pip` is a python package manager that comes with Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you install python and set the path correctly, you can run the `pip` command
    from the command prompt. To install TensorFlow, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This sample might seem too simple and might not contain anything related to
    machine learning, but this example should be a good starting point to understand
    the concepts of TensorFlow and its working:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding program, we are creating two placeholders, named *a* and *b*,
    that can hold integer values. For now, just you can imagine placeholders as nodes
    in a tree for a decision tree. In the next line, we are creating a variable named
    times. We are creating this to store how many times we need to multiply the input.
    In this case, we are giving two as agenda is to do for *(a+b)*^(*2*)*.*
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next line, we are applying addition operation on both the *a* and *b*
    nodes. And for that sum, we are applying power operation and saving the result
    in a new node called c. To run the code, first save it in a file with the `.py` extension.
    Then execute the program using the `python` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Running the previous piece of code will produce two files. First, it saves the
    TF computation graph in a `GraphDef` text file called `tfdroid.pbtxt`. Next, it
    will perform a simple assignment (which normally would be done through actual
    learning) and save a checkpoint of the model variables in `tfdroid.ckpt`.
  prefs: []
  type: TYPE_NORMAL
- en: Freezing the graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have these files, we need to freeze the graph by converting the
    variables in the checkpoint file into `Const Ops` that contain the values of the
    variables, and combining them with the GraphDef in a standalone file. Using this
    file makes it easier to load the model inside a mobile app. TensorFlow provides
    `freeze_graph` in `tensorflow.python.tools` for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Optimizing the model file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have the frozen graph, we can further optimize the file for inference-only
    purposes by removing the parts of the graph that are only needed during training.
    According to the documentation, this includes:'
  prefs: []
  type: TYPE_NORMAL
- en: Removing training-only operations, such as checkpoint saving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stripping out parts of the graph that are never reached
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing debug operations, such as `CheckNumerics`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Folding batch normalization ops into the pre-calculated weights
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fusing common operations into unified versions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TensorFlow provides `optimize_for_inference_lib` in `tensorflow.python.tools`
    for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Take note of the input and output nodes in the preceding code. Our graph only
    has one input node, named I, and one output node, named O. These names correspond
    to the names you use when you define your tensors. You should adjust these based
    on your graph in case you are using a different one.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a binary file, called `optimized_tfdroid.pb`, which means we are
    ready to build our Android app. If you got an exception when creating `optimized_tfdroid.pb`,
    you can use `tfdroid.somewhat`, which is an unoptimized version of the model –
    it is fairly large.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Android app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to get the TensorFlow libraries for Android, create an Android app,
    configure it to use these libraries, and then invoke the TensorFlow model inside
    the app.
  prefs: []
  type: TYPE_NORMAL
- en: Although you can compile the TensorFlow libraries from scratch, it’s easier
    to use the prebuilt libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Now use Android Studio to create an Android project with an empty activity.
  prefs: []
  type: TYPE_NORMAL
- en: Once the project is created, add the TF Libraries to the project's `libs` folder.
    You can get these libraries from the GitHub repository: [https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/tensorflow%20simple/TensorflowSample/app/libs](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/tensorflow%20simple/TensorflowSample/app/libs).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now your project''s `libs/` folder should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You need to let your build system know where these libraries are located by
    putting the following lines inside of the Android block in `app/build.gradle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Copying the TF Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Create an Android Asset Folder for the app and place the `optimized_tfdroid.pb
    or tfdroid.pb` file that we just created inside it (`app/src/main/assets/`).
  prefs: []
  type: TYPE_NORMAL
- en: Creating an activity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Click on the project and create an empty activity named `MainActivity`. In
    the layout of that activity, paste the following XML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `mainactivity.java` file, paste the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding program, we are loading the TensorFlow binaries using the
    following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the create Bundle method, we have the main logic. Here, we are creating the
    TensorFlow inference object by supplying the TensorFlow model's `.pb` file, which
    has been generated and we saw that in the section - create and save model
  prefs: []
  type: TYPE_NORMAL
- en: Then we registered a click event to the Run button. In this, we are feeding
    the values to the a and b nodes in TensorFlow and running the inference, then
    we fetch the value in the C node and show it to the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now run the app to see the results of the `(a+b)2 = c` expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6abc781a-f565-4d2e-8273-a38058dfb194.png)'
  prefs: []
  type: TYPE_IMG
- en: On the left side, it is showing the app's opening screen. In the provided text
    boxes, we need to give the `a` and `b` values. Once you click on the Run button,
    you will see the result in the output area.
  prefs: []
  type: TYPE_NORMAL
- en: You can get the preceding app code from the GitHub repository: [https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/tensorflow%20simple](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/tensorflow%20simple).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we got introduced to Google's machine learning tools for Mobile
    and looked at the various flavors of the toolkit – TensorFlow for Mobile and TensorFlow
    Lite. We also explored the architecture of a TensorFlow-ML-enabled mobile application.
    Then we discussed the architecture and details of TensorFlow Lite and its components,
    and even demonstrated a simple use case for an android mobile application using
    TensorFlow for mobile.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be using the TensorFlow for mobile that we discussed
    here to implement a classification algorithm.
  prefs: []
  type: TYPE_NORMAL
