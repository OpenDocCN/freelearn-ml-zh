<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer104">
			<h1 id="_idParaDest-58"><em class="italic"><a id="_idTextAnchor058"/>Chapter 4</em>: Exploring Classification with TPOT</h1>
			<p>In this chapter, you'll continue going through hands-on examples of automated machine learning. You will learn how to handle classification tasks with TPOT in an automated manner by going through three complete datasets.</p>
			<p>We will cover essential topics such as dataset loading, cleaning, necessary data preparation, and exploratory data analysis. Then, we'll dive deep into classification with TPOT. You will learn how to train and evaluate automated classification models.</p>
			<p>Before training models automatically, you will see how good models can be obtained with basic classification algorithms, such as logistic regression. This model will serve as the baseline that TPOT needs to outperform.</p>
			<p>This chapter will cover the following topics:</p>
			<ul>
				<li>Applying automated classification modeling to the Iris dataset</li>
				<li>Applying automated classification modeling to the Titanic dataset</li>
			</ul>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/>Technical requirements</h1>
			<p>To complete this chapter, You will need to have Python and TPOT installed in your computer with Python and TPOT installed. Refer to <a href="B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036"><em class="italic">Chapter 2</em></a>, <em class="italic">Deep Dive into TPOT</em>, for detailed instructions on environment setup. If the concept of classification is entirely new to you, refer to <a href="B16954_01_Final_SK_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>,<em class="italic"> Machine Learning and the Idea of Automation</em>.</p>
			<p>You can download the source code and dataset for this chapter here: <a href="https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04">https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04</a><a href="https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter4%20"/></p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor060"/>Applying automated classification models to the iris dataset</h1>
			<p>Let's <a id="_idIndexMarker229"/>start simple, with one of <a id="_idIndexMarker230"/>the most basic datasets out there – the Iris dataset (<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>). The challenge here won't be to build an automated model but to build a model that can outperform the baseline model. The Iris dataset is so simple that even the most basic classification algorithm can achieve high accuracy.</p>
			<p>Because of that, you should focus on getting the classification basics down in this section. You'll have enough time to worry about performance later:</p>
			<ol>
				<li>As with the regression section, the first thing you should do is import the required libraries and load the dataset. You'll need <strong class="source-inline">n</strong><strong class="source-inline">umpy</strong>, <strong class="source-inline">pandas</strong>, <strong class="source-inline">matplotlib</strong>, and <strong class="source-inline">seaborn</strong> for starters. The <strong class="source-inline">matplotlib.rcParams</strong> module is imported to tweak the default stylings.<p>Here's the code snippet for library imports and dataset loading:</p><p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">import seaborn as sns</p><p class="source-code">from matplotlib import rcParams</p><p class="source-code">rcParams['axes.spines.top'] = False</p><p class="source-code">rcParams['axes.spines.right'] = False</p><p class="source-code">df = pd.read_csv('data/iris.csv')</p><p class="source-code">df.head()</p><p>And here is the output returned by the <strong class="source-inline">head()</strong> function:</p><div id="_idContainer077" class="IMG---Figure"><img src="Images/B16954_04_01.jpg" alt="Figure 4.1 – Head of the Iris dataset&#13;&#10;" width="600" height="224"/></div><p class="figure-caption">Figure 4.1 – Head of the Iris dataset</p><p>Great – just what we need to get started.</p></li>
				<li>The next <a id="_idIndexMarker231"/>step is to check if data quality is <a id="_idIndexMarker232"/>good enough to be passed to a machine learning algorithm. The first step here is to check for missing values. The following code snippet does just that:<p class="source-code">df.isnull().sum()</p><p>The output is shown in the following figure:</p><div id="_idContainer078" class="IMG---Figure"><img src="Images/B16954_04_02.jpg" alt="Figure 4.2 – Missing value counts per column for the Iris dataset&#13;&#10;" width="200" height="135"/></div><p class="figure-caption">Figure 4.2 – Missing value counts per column for the Iris dataset</p><p>There seem to be no missing values, so we can proceed.</p></li>
				<li>Let's now check for class distribution in the target variable. This refers to the number of instances belonging to each class – <strong class="source-inline">setosa</strong>, <strong class="source-inline">virginica</strong>, and <strong class="source-inline">versicolor</strong>, in this case. Machine learning models are known to perform poorly if a severe class imbalance is present.<p>The following code snippet visualizes the class distribution:</p><p class="source-code">ax = df.groupby('species').count().plot(kind='bar', figsize=(10, 6), fontsize=13, color='#4f4f4f')</p><p class="source-code">ax.set_title('Iris Dataset target variable distribution', size=20, pad=30)</p><p class="source-code">ax.set_ylabel('Count', fontsize=14)</p><p class="source-code">ax.set_xlabel('Species', fontsize=14)</p><p class="source-code">ax.get_legend().remove()</p><p>The <a id="_idIndexMarker233"/>visualization is shown in the <a id="_idIndexMarker234"/>following figure:</p><div id="_idContainer079" class="IMG---Figure"><img src="Images/B16954_04_03.jpg" alt="Figure 4.3 – Iris dataset target variable distribution&#13;&#10;" width="1000" height="770"/></div><p class="figure-caption">Figure 4.3 – Iris dataset target variable distribution</p><p>The Iris dataset is <a id="_idIndexMarker235"/>as nice as they come – so <a id="_idIndexMarker236"/>once again, nothing for us to do preparation-wise.</p></li>
				<li>The final step in the data exploratory analysis and preparation is to check for correlation. A high correlation between features typically means there's some redundancy in the dataset, at least to a degree.<p>The following code snippet plots a correlation matrix with annotations:</p><p class="source-code">plt.figure(figsize=(12, 9))</p><p class="source-code">plt.title('Correlation matrix', size=20)</p><p class="source-code">sns.heatmap(df.corr(), annot=True, cmap='Blues');</p><p>The correlation matrix is shown in the following figure:</p><div id="_idContainer080" class="IMG---Figure"><img src="Images/B16954_04_04.jpg" alt="Figure 4.4 – Correlation matrix of the Iris dataset&#13;&#10;" width="1089" height="905"/></div><p class="figure-caption">Figure 4.4 – Correlation matrix of the Iris dataset</p><p>As expected, there's a <a id="_idIndexMarker237"/>strong correlation <a id="_idIndexMarker238"/>between most of the features.</p><p>You're now familiar with the Iris dataset, which means we can move on to modeling the next.</p></li>
				<li>Let's build a baseline model with a logistic regression algorithm first. It will serve as a starting model that TPOT needs to outperform.<p>The first step in the process is the train/test split. The following code snippet does just that, and it also prints the number of instances in both sets:</p><p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">X = df.drop('species', axis=1)</p><p class="source-code">y = df['species']</p><p class="source-code">X_train, X_test, y_train, y_test = train_test_split(</p><p class="source-code">    X, y, test_size=0.25, random_state=3</p><p class="source-code">)</p><p class="source-code">y_train.shape, y_test.shape</p><p>The <a id="_idIndexMarker239"/>number of instances is shown in the <a id="_idIndexMarker240"/>following figure:</p><div id="_idContainer081" class="IMG---Figure"><img src="Images/B16954_04_05.jpg" alt="Figure 4.5 – Number of instances in train and test sets&#13;&#10;" width="230" height="34"/></div><p class="figure-caption">Figure 4.5 – Number of instances in train and test sets</p><p>Let's build the baseline model next.</p></li>
				<li>As mentioned earlier, we'll use logistic regression for the job. The code snippet below fits a logistic regression model, makes the predictions on the test set, and prints a confusion matrix of actual and predicted values:<p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">lm = LogisticRegression(random_state=42)</p><p class="source-code">lm.fit(X_train, y_train)</p><p class="source-code">lm_preds = lm.predict(X_test)</p><p class="source-code">print(confusion_matrix(y_test, lm_preds))</p><p>The <a id="_idIndexMarker241"/>corresponding confusion <a id="_idIndexMarker242"/>matrix is shown in the following figure:</p><div id="_idContainer082" class="IMG---Figure"><img src="Images/B16954_04_06.jpg" alt="Figure 4.6 – Logistic regression confusion matrix for the Iris dataset&#13;&#10;" width="184" height="89"/></div><p class="figure-caption">Figure 4.6 – Logistic regression confusion matrix for the Iris dataset</p><p>As you can see, there's only one misclassification – a false positive for the <em class="italic">virginica</em> class. Even the baseline model performed exceptionally well. The code lines that follow obtain the accuracy for a baseline model:</p><p class="source-code">from sklearn.metrics import accuracy_score</p><p class="source-code">print(accuracy_score(y_test, lm_preds))</p><p>The accuracy score is shown in the following image:</p><div id="_idContainer083" class="IMG---Figure"><img src="Images/B16954_04_07.jpg" alt="Figure 4.7 – Accuracy on the test set with logistic regression for the Iris dataset&#13;&#10;" width="287" height="24"/></div><p class="figure-caption">Figure 4.7 – Accuracy on the test set with logistic regression for the Iris dataset</p><p>And there you have it – 97% accuracy and only a single misclassification out of the box, with the simplest classification algorithm. Let's see if TPOT can outperform that next.</p></li>
				<li>Let's build an automated classification model next. We'll optimize for accuracy and train for 10 minutes – similar to what we did in <a href="B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051"><em class="italic">Chapter 3</em></a>, <em class="italic">Exploring Regression with TPOT</em>. The <a id="_idIndexMarker243"/>code snippet below imports TPOT, instantiates a pipeline optimizer, and trains the <a id="_idIndexMarker244"/>model on the training datasets:<p class="source-code">from tpot import TPOTClassifier</p><p class="source-code">pipeline_optimizer = TPOTClassifier(</p><p class="source-code">    scoring='accuracy',</p><p class="source-code">    max_time_mins=10,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=2</p><p class="source-code">)</p><p class="source-code">pipeline_optimizer.fit(X_train, y_train)</p><p>TPOT managed to fit 18 generations on my machine, which are shown in the following figure:</p><div id="_idContainer084" class="IMG---Figure"><img src="Images/B16954_04_08.jpg" alt="" width="1046" height="1070"/></div><p class="figure-caption">Figure 4.8 – Output of a TPOT pipeline optimization on the Iris dataset</p></li>
				<li>Let's see if training <a id="_idIndexMarker245"/>an automated model managed <a id="_idIndexMarker246"/>to increase accuracy. You can use the following snippet to obtain the accuracy score:<p class="source-code">tpot_preds = pipeline_optimizer.predict(X_test)</p><p class="source-code">accuracy_score(y_test, tpot_preds)</p><p>The accuracy score is shown in the following figure:</p><div id="_idContainer085" class="IMG---Figure"><img src="Images/B16954_04_09.jpg" alt="Figure 4.9 – Accuracy on the test set with an automated model for the Iris dataset&#13;&#10;" width="285" height="27"/></div><p class="figure-caption">Figure 4.9 – Accuracy on the test set with an automated model for the Iris dataset</p><p>As you can see, the accuracy on the test set didn't improve. If you were to make a scatter plot of the target variable and features, you would see some overlap for the <em class="italic">virginica</em> and <em class="italic">versicolor</em> classes. That's most likely the case here, and no amount of training would manage to correctly classify this single instance.</p></li>
				<li>There's only two things left to do here, and both are optional. The <a id="_idIndexMarker247"/>first one is to see what TPOT <a id="_idIndexMarker248"/>declared as an optimal pipeline after 10 minutes of training. The following code snippet will output that pipeline to the console:<p class="source-code">pipeline_optimizer.fitted_pipeline_</p><p>The corresponding pipeline is shown in the following figure:</p><div id="_idContainer086" class="IMG---Figure"><img src="Images/B16954_04_10.jpg" alt="Figure 4.10 – Optimal TPOT pipeline for the Iris dataset&#13;&#10;" width="1000" height="124"/></div><p class="figure-caption">Figure 4.10 – Optimal TPOT pipeline for the Iris dataset</p></li>
				<li>As always, you can also export the pipeline with the <strong class="source-inline">export()</strong> function:<p class="source-code">pipeline_optimizer.export('iris_pipeline.py')</p><p>The entire Python code is shown in the following figure:</p></li>
			</ol>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="Images/B16954_04_11.jpg" alt="Figure 4.11 – Python code for an optimal TPOT pipeline for the Iris dataset&#13;&#10;" width="1100" height="631"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.11 – Python code for an optimal TPOT pipeline for the Iris dataset</p>
			<p>And there you <a id="_idIndexMarker249"/>have it – your first fully automated <a id="_idIndexMarker250"/>classification model with TPOT. Yes, the dataset was as basic as they come, but the principle always remains the same. We'll make automated models on a more complex dataset next, so there will be time to get your hands dirty.</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor061"/>Applying automated classification modeling to the titanic dataset</h1>
			<p>We're <a id="_idIndexMarker251"/>now going to apply automated TPOT classification <a id="_idIndexMarker252"/>modeling to a slightly more complicated dataset. You'll get your hands dirty with the Titanic dataset (<a href="https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv">https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv</a>) – a dataset containing various attributes and descriptions of passengers who did and did not survive the Titanic accident.</p>
			<p>The goal is to build an automated model capable of predicting whether a passenger would have survived the accident, based on various input features, such as passenger class, gender, age, cabin, number of siblings, spouses, parents, and children, among other features.</p>
			<p>We'll start by loading the libraries and the dataset next:</p>
			<ol>
				<li value="1">As always, the first step is to load in the libraries and the dataset. You'll need <strong class="source-inline">numpy</strong>, <strong class="source-inline">pandas</strong>, <strong class="source-inline">matplotlib</strong>, and <strong class="source-inline">seaborn</strong> to get you started. The <strong class="source-inline">Matplotlib.rcParams</strong> module is also imported, just to make the visualizations a bit more appealing.<p>The <a id="_idIndexMarker253"/>following code snippet <a id="_idIndexMarker254"/>imports the libraries, loads in the dataset, and displays the first five rows:</p><p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">import matplotlib.pyplot as plt</p><p class="source-code">from matplotlib import rcParams</p><p class="source-code">rcParams['axes.spines.top'] = False</p><p class="source-code">rcParams['axes.spines.right'] = False</p><p class="source-code">df = pd.read_csv('data/titanic.csv')</p><p class="source-code">df.head()</p><p>Calling the <strong class="source-inline">head()</strong> function returns the first five rows of the dataset. They are shown in the following figure:</p><div id="_idContainer088" class="IMG---Figure"><img src="Images/B16954_04_12.jpg" alt="Figure 4.12 – Head of the Titanic dataset&#13;&#10;" width="1288" height="208"/></div><p class="figure-caption">Figure 4.12 – Head of the Titanic dataset</p><p>You can now proceed with the exploratory data analysis and preparation.</p></li>
				<li>The first step in the exploratory data analysis and preparation is to check for missing values. The following code line does just that:<p class="source-code">df.isnull().sum()</p><p>The preceding line of code reports back the <a id="_idIndexMarker255"/>number of missing values per column in the dataset, as shown in the following figure: </p><div id="_idContainer089" class="IMG---Figure"><img src="Images/B16954_04_13.jpg" alt="Figure 4.13 – Missing values count per column for the Titanic dataset&#13;&#10;" width="280" height="328"/></div><p class="figure-caption">Figure 4.13 – Missing values count per column for the Titanic dataset</p><p>As you can see, there are a lot of missing values present in the dataset. Most of the missing values are in the <strong class="source-inline">Age</strong> and <strong class="source-inline">Cabin</strong> attributes. It's easy to understand for <strong class="source-inline">Cabin</strong> – the value is missing if the passenger didn't have their own cabin. </p><p>We'll deal with these missing values later, but for now, let's shift our focus to data visualization, so you can better understand the dataset.</p></li>
				<li>To avoid code duplication, let's define a single function for displaying a bar chart. The function shows a bar chart with column counts on top of the bars. It also allows you to specify for which dataset column you want to draw a bar chart, values for the title, <em class="italic">x</em>-axis label, and <em class="italic">y</em>-axis label, and also offsets for the counts.<p>You <a id="_idIndexMarker256"/>can find the code for this <a id="_idIndexMarker257"/>function here:</p><p class="source-code">def make_bar_chart(column, title, ylabel, xlabel, y_offset=10, x_offset=0.2):</p><p class="source-code">    ax = df.groupby(column).count()[['PassengerId']].plot(</p><p class="source-code">        kind='bar', figsize=(10, 6), fontsize=13, color='#4f4f4f'</p><p class="source-code">    )</p><p class="source-code">    ax.set_title(title, size=20, pad=30)</p><p class="source-code">    ax.set_ylabel(ylabel, fontsize=14)</p><p class="source-code">    ax.set_xlabel(xlabel, fontsize=14)</p><p class="source-code">    ax.get_legend().remove()</p><p class="source-code">                  </p><p class="source-code">    for i in ax.patches:</p><p class="source-code">        ax.text(i.get_x() + x_offset, i.get_height() + y_offset, i.get_height(), fontsize=20)</p><p class="source-code">    return ax</p><p>You'll use this function extensively during the next couple of pages. The goal is to visualize how categorical variables are distributed, so you can get a better understanding of the dataset.</p></li>
				<li>To start, let's visualize how many passengers have survived and how many haven't. The previously declared <strong class="source-inline">make_bar_chart()</strong> function comes in handy for the job.<p>The <a id="_idIndexMarker258"/>following code snippet makes <a id="_idIndexMarker259"/>the visualization:</p><p class="source-code">make_bar_chart(</p><p class="source-code">    column='Survived',</p><p class="source-code">    title='Distribution of the Survived variable',</p><p class="source-code">    ylabel='Count',</p><p class="source-code">    xlabel='Has the passenger survived? (0 = No, 1 = Yes)'</p><p class="source-code">);</p><p>The visualization is displayed in the following figure:</p><div id="_idContainer090" class="IMG---Figure"><img src="Images/B16954_04_14.jpg" alt="Figure 4.14 – Target class distribution for the Titanic dataset&#13;&#10;" width="1149" height="754"/></div><p class="figure-caption">Figure 4.14 – Target class distribution for the Titanic dataset</p><p>As you can see, most of the passengers didn't survive the Titanic accident. This information alone doesn't tell you much because you don't <a id="_idIndexMarker260"/>know how many passengers <a id="_idIndexMarker261"/>survived per gender, passenger class, and other attributes. </p><p>You can use the <strong class="source-inline">make_bar_chart()</strong> function to make this type of visualization.</p></li>
				<li>Let's continue our data visualization journey by visualizing the number of passengers in each passenger class. You can use the same <strong class="source-inline">make_bar_chart()</strong> function for this visualization. Just make sure to change the parameters accordingly.<p>The following code snippet visualizes the number of passengers per passenger class. The lower the class number, the better – a more expensive ticket, better service, and who knows, maybe a higher chance of survival:</p><p class="source-code">make_bar_chart(</p><p class="source-code">    column='Pclass',</p><p class="source-code">    title='Distirbution of the Passenger Class variable',</p><p class="source-code">    ylabel='Count',</p><p class="source-code">    xlabel='Passenger Class (smaller is better)',</p><p class="source-code">    x_offset=0.15</p><p class="source-code">);</p><p>The <a id="_idIndexMarker262"/>visualization is <a id="_idIndexMarker263"/>shown in the following figure:</p><div id="_idContainer091" class="IMG---Figure"><img src="Images/B16954_04_15.jpg" alt="Figure 4.15 – Number of passengers per passenger class&#13;&#10;" width="1140" height="751"/></div><p class="figure-caption">Figure 4.15 – Number of passengers per passenger class</p><p>As you can see, most of the <a id="_idIndexMarker264"/>passengers belong to <a id="_idIndexMarker265"/>the third class. This is expected, as there were more workers on board than rich people.</p></li>
				<li>For the next step in the data visualization phase, let's see how the <strong class="source-inline">Sex</strong> attribute is distributed. This will give us insight into whether there were more women or men on board and how large the difference was.<p>The following code snippet makes the visualization: </p><p class="source-code">make_bar_chart(</p><p class="source-code">    column='Sex',</p><p class="source-code">    title='Distirbution of the Sex variable',</p><p class="source-code">    ylabel='Count',</p><p class="source-code">    xlabel='Gender'</p><p class="source-code">);</p><p>The visualization is shown in the following figure:</p><div id="_idContainer092" class="IMG---Figure"><img src="Images/B16954_04_16.jpg" alt="Figure 4.16 – Number of passengers per gender&#13;&#10;" width="1252" height="893"/></div><p class="figure-caption">Figure 4.16 – Number of passengers per gender</p><p>As you can see, there <a id="_idIndexMarker266"/>were definitely more men <a id="_idIndexMarker267"/>aboard. This is connected with the conclusion made in the previous visualization, where we concluded that there were many workers on board.</p><p>Most of the workers are male, so this visualization makes sense.</p></li>
				<li>Let's take a little break from the bar charts and visualize a continuous variable for change. The goal is to make a histogram of the <strong class="source-inline">Fare</strong> attribute, which will show the distribution of the amounts paid for the ticket.<p>The following code snippet draws a histogram for the mentioned attribute:</p><p class="source-code">plt.figure(figsize=(12, 7))</p><p class="source-code">plt.title('Fare cost distribution', size=20)</p><p class="source-code">plt.xlabel('Cost', size=14)</p><p class="source-code">plt.ylabel('Count', size=14)</p><p class="source-code">plt.hist(df['Fare'], bins=15, color='#4f4f4f', ec='#040404');</p><p>The <a id="_idIndexMarker268"/>histogram is shown in the <a id="_idIndexMarker269"/>following figure:</p><div id="_idContainer093" class="IMG---Figure"><img src="Images/B16954_04_17.jpg" alt="Figure 4.17 – Distribution of the Fare variable&#13;&#10;" width="1251" height="756"/></div><p class="figure-caption">Figure 4.17 – Distribution of the Fare variable</p><p>It looks like most of the passengers paid 30 dollars or less for a ticket. As always, there are extreme <a id="_idIndexMarker270"/>cases. It seems like a <a id="_idIndexMarker271"/>single passenger paid around 500 dollars for the trip. Not a wise decision, taking into consideration how things ended.</p></li>
				<li>Let's do something a bit different now. The <strong class="source-inline">Name</strong> attribute is more or less useless in this format. But if you take a closer look, you can see that every value in the mentioned attribute is formatted identically.<p>This means we can keep the single word after the first comma and store it in a new variable. We'll call this variable <strong class="source-inline">Title</strong> because it represents passenger titles (for example, Mr., Miss., and so on).</p><p>The following code snippet extracts the Title value to a new attribute and uses the <strong class="source-inline">make_bar_chart()</strong> function to visually represent different titles among Titanic passengers:</p><p class="source-code">df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].strip().split(' ')[0])</p><p class="source-code">make_bar_chart(</p><p class="source-code">    column='Title',</p><p class="source-code">    title='Distirbution of the Passenger Title variable',</p><p class="source-code">    ylabel='Count',</p><p class="source-code">    xlabel='Title',</p><p class="source-code">    x_offset=-0.2</p><p class="source-code">);</p><p>The results are shown in the following figure:</p><div id="_idContainer094" class="IMG---Figure"><img src="Images/B16954_04_18.jpg" alt="Figure 4.18 – Distribution of the passenger titles&#13;&#10;" width="1168" height="861"/></div><p class="figure-caption">Figure 4.18 – Distribution of the passenger titles</p><p>Once again, these are expected <a id="_idIndexMarker272"/>results. Most of the <a id="_idIndexMarker273"/>passengers have common titles, such as Mr. and Miss. There's just a handful of them with unique titles. You could leave this column as is or turn it into a binary column – the value is zero if a title is common, and one otherwise. You'll see how to do that next.</p></li>
				<li>That's about enough with regards to the exploratory data analysis. We've made quite a few visualizations, but you can always make more on your own.<p>It's now time to prepare the dataset for machine learning. The steps are described here:</p><p>a) Drop the columns that are of no use – <strong class="source-inline">Ticket</strong> and <strong class="source-inline">PassengerId</strong>. The first one is just a collection of dummy letters and numbers and is of no use for predictive modeling. The second one is an arbitrary ID, most likely generated with a database sequence. You can remove both by calling the <strong class="source-inline">drop()</strong> function.</p><p>b) Remap values in the <strong class="source-inline">Sex</strong> attribute to integers. The textual values <em class="italic">male</em> and <em class="italic">female</em> can't be passed to a machine learning algorithm directly. Some form of conversion is a must – so replace males with 0 and females with 1. The <strong class="source-inline">replace()</strong> function is the perfect candidate for the job.</p><p>c) Use the previously generated <strong class="source-inline">Title</strong> column and convert it into a binary one – the value is <a id="_idIndexMarker274"/>zero if the title is <a id="_idIndexMarker275"/>common (for example, Mr., Miss., and Mrs.) and one otherwise. You can then rename the column to something a bit more appropriate, such as <strong class="source-inline">Title_Unusal</strong>. The <strong class="source-inline">Name</strong> column isn't needed anymore, so delete it.</p><p>d) Handle missing values in the <strong class="source-inline">Cabin</strong> column by turning this attribute into a binary one – the value is zero if the value for the cabin is missing, and one otherwise. Name this new column <strong class="source-inline">Cabin_Known</strong>. After that, you can delete the <strong class="source-inline">Cabin</strong> column because it's not needed anymore, and it can't be passed to a machine learning model.</p><p>e) Create dummy variables with the <strong class="source-inline">Embarked</strong> attribute. This attribute indicates the port on which the passengers entered the ship. You be the judge of whether this attribute is even necessary, but we'll keep it for TPOT to decide. After declaring dummy variables, concatenate them to the original dataset and delete the <strong class="source-inline">Embarked</strong> column.</p><p>f) Handle missing values in the <strong class="source-inline">Age</strong> attribute somehow. There are many sophisticated methods, such as <em class="italic">KNN imputing</em> or <em class="italic">MissForest imputing</em>, but for simplicity's sake, just impute the missing values with a simple average.</p><p>The following code snippet shows you how to apply all of the mentioned transformations:</p><p class="source-code">df.drop(['Ticket', 'PassengerId'], axis=1, inplace=True)</p><p class="source-code">gender_mapper = {'male': 0, 'female': 1}</p><p class="source-code">df['Sex'].replace(gender_mapper, inplace=True)</p><p class="source-code">df['Title'] = [0 if x in ['Mr.', 'Miss.', 'Mrs.'] else 1 for x in df['Title']]</p><p class="source-code">df = df.rename(columns={'Title': 'Title_Unusual'})</p><p class="source-code">df.drop('Name', axis=1, inplace=True)</p><p class="source-code">df['Cabin_Known'] = [0 if str(x) == 'nan' else 1 for x in df['Cabin']]</p><p class="source-code">df.drop('Cabin', axis=1, inplace=True)</p><p class="source-code">emb_dummies = pd.get_dummies(df['Embarked'], drop_first=True, prefix='Embarked')</p><p class="source-code">df = pd.concat([df, emb_dummies], axis=1)</p><p class="source-code">df.drop('Embarked', axis=1, inplace=True)</p><p class="source-code">df['Age'] = df['Age'].fillna(int(df['Age'].mean()))</p><p class="source-code">df.head()</p><p>You can take a peek at the prepared dataset by examining the following figure:</p><div id="_idContainer095" class="IMG---Figure"><img src="Images/B16954_04_19.jpg" alt="Figure 4.19 – Prepared Titanic dataset&#13;&#10;" width="1267" height="268"/></div><p class="figure-caption">Figure 4.19 – Prepared Titanic dataset</p><p>And that's all you have to do with regard to data preparation. Scaling/standardization is not required, as TPOT will decide whether that step is necessary. </p><p>We'll begin with predictive modeling shortly – just one step remains.</p></li>
				<li>Before you can train a classification <a id="_idIndexMarker276"/>model, you'll have to split the dataset into training and testing <a id="_idIndexMarker277"/>subsets. Keep in mind the <strong class="source-inline">random_state</strong> parameter – use the same value if you want the same data split:<p class="source-code">from sklearn.model_selection import train_test_split</p><p class="source-code">X = df.drop('Survived', axis=1)</p><p class="source-code">y = df['Survived']</p><p class="source-code">X_train, X_test, y_train, y_test = train_test_split(</p><p class="source-code">    X, y, test_size=0.25, random_state=42</p><p class="source-code">)</p><p class="source-code">y_train.shape, y_test.shape</p><p>The last code line prints the number of instances in training and testing subsets. You can see the numbers in the following figure:</p><div id="_idContainer096" class="IMG---Figure"><img src="Images/B16954_04_20.jpg" alt="Figure 4.20 – Number of instances in training and testing sets (Titanic)&#13;&#10;" width="264" height="33"/></div><p class="figure-caption">Figure 4.20 – Number of instances in training and testing sets (Titanic)</p><p>Now you're ready to train predictive models.</p></li>
				<li>Let's start with a baseline model – logistic regression. We'll train it on the train set and evaluate <a id="_idIndexMarker278"/>it on the test set. The <a id="_idIndexMarker279"/>following code snippet trains the model and prints the confusion matrix:<p class="source-code">from sklearn.linear_model import LogisticRegression</p><p class="source-code">from sklearn.metrics import confusion_matrix</p><p class="source-code">lm = LogisticRegression(random_state=42)</p><p class="source-code">lm.fit(X_train, y_train)</p><p class="source-code">lm_preds = lm.predict(X_test)</p><p class="source-code">print(confusion_matrix(y_test, lm_preds))</p><p>You can see the confusion matrix in the following figure:</p><div id="_idContainer097" class="IMG---Figure"><img src="Images/B16954_04_21.jpg" alt="Figure 4.21 – Logistic regression confusion matrix (Titanic)&#13;&#10;" width="169" height="58"/></div><p class="figure-caption">Figure 4.21 – Logistic regression confusion matrix (Titanic)</p><p>It looks like there's the same number of false positives and false negatives (23). If we take ratios into account, there are more false negatives. In translation, the baseline model is more likely to say that the passenger survived even if they didn't.</p></li>
				<li>Interpreting the confusion matrix is great, but what if you want to look at a concrete number instead? Since this is a classification problem, you could use accuracy. But there's a "better" metric – <strong class="bold">F1 score</strong>. The value for this metric ranges between 0 and 1 (higher is better) and represents a harmonic mean between precision and recall.<p>Here's how to calculate it with Python:</p><p class="source-code">from sklearn.metrics import f1_score</p><p class="source-code">print(f1_score(y_test, lm_preds))</p><p>The value of the F1 score on the test set is shown in the following figure:</p><div id="_idContainer098" class="IMG---Figure"><img src="Images/B16954_04_22.jpg" alt="Figure 4.22 – Logistic regression F1 score on the test set (Titanic)&#13;&#10;" width="288" height="28"/></div><p class="figure-caption">Figure 4.22 – Logistic regression F1 score on the test set (Titanic)</p><p>The value of 0.74 isn't <a id="_idIndexMarker280"/>bad for a baseline <a id="_idIndexMarker281"/>model. Can TPOT outperform it? Let's train an automated model and see what happens.</p></li>
				<li>In a similar fashion as before, we'll train an automated classification model for 10 minutes. Instead of accuracy, we'll optimize for the F1 score. By doing so, we can compare the F1 scores of an automated model with the baseline one.<p>The following code snippet trains the model on the training set:</p><p class="source-code">from tpot import TPOTClassifier</p><p class="source-code">pipeline_optimizer = TPOTClassifier(</p><p class="source-code">    scoring='f1',</p><p class="source-code">    max_time_mins=10,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=2</p><p class="source-code">)</p><p class="source-code">pipeline_optimizer.fit(X_train, y_train)</p><p>In the following figure, you can see the output printed in the notebook during training. TPOT managed to <a id="_idIndexMarker282"/>train for 7 generations <a id="_idIndexMarker283"/>in 10 minutes, and the score increases as the model is training:</p><div id="_idContainer099" class="IMG---Figure"><img src="Images/B16954_04_23.jpg" alt="Figure 4.23 – TPOT pipeline optimization output (Titanic)&#13;&#10;" width="1032" height="395"/></div><p class="figure-caption">Figure 4.23 – TPOT pipeline optimization output (Titanic)</p><p>You are free to leave the model to train for longer than 10 minutes. Still, this time frame should be enough to outperform the baseline model.</p></li>
				<li>Let's take a look at the value of the F1 score on the test set now. Remember, anything above 0.7415 means TPOT outperformed the baseline model.<p>The following code snippet prints the F1 score:</p><p class="source-code">pipeline_optimizer.score(X_test, y_test)</p><p>The corresponding F1 score is shown in the following figure:</p><div id="_idContainer100" class="IMG---Figure"><img src="Images/B16954_04_24.jpg" alt="Figure 4.24 – TPOT optimized model F1 score on the test set (Titanic)&#13;&#10;" width="308" height="33"/></div><p class="figure-caption">Figure 4.24 – TPOT optimized model F1 score on the test set (Titanic)</p><p>It looks like TPOT outperformed the baseline model – as expected.</p></li>
				<li>In case you're <a id="_idIndexMarker284"/>more trustworthy of basic <a id="_idIndexMarker285"/>metrics, such as accuracy, here's how you can compare it between baseline and automated models:<p class="source-code">tpot_preds = pipeline_optimizer.predict(X_test)</p><p class="source-code">from sklearn.metrics import accuracy_score</p><p class="source-code">print(f'Baseline model accuracy: {accuracy_score(y_test, lm_preds)}')</p><p class="source-code">print(f'TPOT model accuracy: {accuracy_score(y_test, tpot_preds)}')</p><p>Corresponding accuracy scores are shown in the following figure:</p><div id="_idContainer101" class="IMG---Figure"><img src="Images/B16954_04_25.jpg" alt="Figure 3.25 – Accuracies of the baseline model and TPOT optimized model on the test set (Titanic)&#13;&#10;" width="690" height="62"/></div><p class="figure-caption">Figure 3.25 – Accuracies of the baseline model and TPOT optimized model on the test set (Titanic)</p><p>As you can see, the simple accuracy metric tells a similar story – the model built by TPOT is still better than the baseline one.</p></li>
				<li>We are near the end of this practical example. There are two optional things left to do. The first one is to take a look at the optimal pipeline. You can obtain it with the following line of code:<p class="source-code">pipeline_optimizer.fitted_pipeline_</p><p>The optimal pipeline is shown in the following figure:</p><div id="_idContainer102" class="IMG---Figure"><img src="Images/B16954_04_26.jpg" alt="Figure 4.26 – TPOT optimized pipeline (Titanic)&#13;&#10;" width="1274" height="416"/></div><p class="figure-caption">Figure 4.26 – TPOT optimized pipeline (Titanic)</p><p>As you can <a id="_idIndexMarker286"/>see, TPOT used extreme gradient <a id="_idIndexMarker287"/>boosting to solve this classification problem.</p></li>
				<li>Finally, you can convert the optimal pipeline into Python code. Doing so makes the process of sharing the code that much easier. You can find the code for doing so here:<p class="source-code">pipeline_optimizer.export('titanic_pipeline.py')</p><p>The full source code for the automated pipeline is shown in the following figure:</p></li>
			</ol>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="Images/B16954_04_27.jpg" alt="Figure 4.27 – Source code for the optimized TPOT pipeline (Titanic)&#13;&#10;" width="1000" height="538"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.27 – Source code for the optimized TPOT pipeline (Titanic)</p>
			<p>And that <a id="_idTextAnchor062"/><a id="_idIndexMarker288"/>does it for solving classification <a id="_idIndexMarker289"/>problems on the Titanic dataset in an automated fashion. You've now built two fully automated classification machine learning solutions. Let's wrap up this chapter next.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor063"/>Summary</h1>
			<p>This was the second hands-on chapter in the book. You've learned how to solve classification machine learning tasks in an automated fashion with two in-depth examples on well-known datasets. Without any kind of doubt, you are now ready to use TPOT to solve any type of classification problem.</p>
			<p>By now, you know how to solve regression and classification tasks. But what about parallel training? What about neural networks? The following chapter, <a href="B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065"><em class="italic">Chapter 5</em></a><em class="italic">, Parallel Training with TPOT and Dask</em>, will teach you what parallel training is and how to utilize it with TPOT. Later, in <a href="B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 6</em></a>, <em class="italic">Getting Started with Deep Learning – Crash Course in Neural Networks</em>, you'll reinforce your knowledge of basic deep learning and neural networks. As the icing on the cake, you'll learn how to use deep learning with TPOT in <a href="B16954_07_Final_SK_ePub.xhtml#_idTextAnchor086"><em class="italic">Chapter 7</em></a>, <em class="italic">Neural Network Classifier with TPOT</em>.</p>
			<p>Please feel encouraged to practice solving classification problems automatically with tools and techniques covered in this chapter.</p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor064"/>Q&amp;A</h1>
			<ol>
				<li value="1">Can you explore the distribution of a categorical variable with bar charts? Explain. </li>
				<li>Explain the confusion matrix and the terms true positive, true negative, false positive, and false negative.</li>
				<li>What is precision? Explain by giving a practical example.</li>
				<li>What is recall? Explain by giving a practical example.</li>
				<li>What's the difference between accuracy and F1 score? When would you use F1 over accuracy?</li>
				<li>What does "1" in the F1 score mean? Can this number be altered? What happens in that scenario? </li>
				<li>During training, does TPOT output the value of your scoring metric for the train set or the test set? Explain.</li>
			</ol>
		</div>
	</div></body></html>