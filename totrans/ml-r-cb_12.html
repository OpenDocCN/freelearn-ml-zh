<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;12.&#xA0;Big Data Analysis (R and Hadoop)"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12" class="calibre1"/>Chapter 12. Big Data Analysis (R and Hadoop)</h1></div></div></div><p class="calibre7">In this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Preparing the RHadoop environment</li><li class="listitem">Installing rmr2</li><li class="listitem">Installing rhdfs</li><li class="listitem">Operating HDFS with rhdfs</li><li class="listitem">Implementing a word count problem with RHadoop</li><li class="listitem">Comparing the performance between an R MapReduce program and a standard R program</li><li class="listitem">Testing and debugging the rmr2 program</li><li class="listitem">Installing plyrmr</li><li class="listitem">Manipulating data with plyrmr</li><li class="listitem">Conducting machine learning with RHadoop</li><li class="listitem">Configuring RHadoop clusters on Amazon EMR</li></ul></div></div>

<div class="book" title="Chapter&#xA0;12.&#xA0;Big Data Analysis (R and Hadoop)">
<div class="book" title="Introduction"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch12lvl1sec132" class="calibre1"/>Introduction</h1></div></div></div><p class="calibre7">RHadoop <a id="id964" class="calibre1"/>is a collection of R packages that enables users to process and analyze big data with Hadoop. Before understanding how to set up RHadoop and put it in to practice, we have to know why we need to use machine learning to big-data scale.</p><p class="calibre7">In the previous chapters, we have mentioned how useful R is when performing data analysis and machine learning. In traditional statistical analysis, the focus is to perform analysis on historical samples (small data), which may ignore rarely occurring but valuable events and results to uncertain conclusions.</p><p class="calibre7">The emergence of Cloud technology has made real-time interaction between customers and businesses much more frequent; therefore, the focus of machine learning has now shifted to the development of accurate predictions for various customers. For example, businesses can provide real-time personal recommendations or online advertisements based on personal behavior via the use of a real-time prediction model.</p><p class="calibre7">However, if the data (for example, behaviors of all online users) is too large to fit in the memory of a <a id="id965" class="calibre1"/>single machine, you have no choice but to use a supercomputer or some other scalable solution. The most popular scalable big-data solution is Hadoop, which is an open source framework able to store and perform parallel computations across clusters. As a result, you can use RHadoop, which allows R to leverage the scalability of Hadoop, helping to process and analyze big data. In RHadoop, there are five main packages, which are:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">rmr</code>: This<a id="id966" class="calibre1"/> is an interface between R and Hadoop MapReduce, which <a id="id967" class="calibre1"/>calls the Hadoop streaming MapReduce API to perform MapReduce jobs across Hadoop clusters. To develop an R MapReduce program, you only need to focus on the design of the map and reduce functions, and the remaining scalability issues will be taken care of by Hadoop itself.</li><li class="listitem"><code class="email">rhdfs</code>: This <a id="id968" class="calibre1"/>is an interface between R and HDFS, which calls the HDFS API to access the data stored in HDFS. The use of <code class="email">rhdfs</code> is <a id="id969" class="calibre1"/>very similar to the use of the Hadoop shell, which allows users to manipulate HDFS easily from the R console.</li><li class="listitem"><code class="email">rhbase</code>: This<a id="id970" class="calibre1"/> is an interface between R and HBase, which accesses Hbase and is distributed in clusters through a Thrift server. You<a id="id971" class="calibre1"/> can use <code class="email">rhbase</code> to read/write data and manipulate tables stored within HBase.</li><li class="listitem"><code class="email">plyrmr</code>: This<a id="id972" class="calibre1"/> is a higher-level abstraction of MapReduce, which<a id="id973" class="calibre1"/> allows users to perform common data manipulation in a plyr-like syntax. This package greatly lowers the learning curve of big-data manipulation.</li><li class="listitem"><code class="email">ravro</code>: This <a id="id974" class="calibre1"/>allows users to read <code class="email">avro</code> files in R, or <a id="id975" class="calibre1"/>write <code class="email">avro</code> files. It allows R to exchange data with HDFS.</li></ul></div><p class="calibre7">In this chapter, we will start by preparing the Hadoop environment, so that you can install RHadoop. We then cover the installation of three main packages: <code class="email">rmr</code>, <code class="email">rhdfs</code>, and <code class="email">plyrmr</code>. Next, we will introduce how to use <code class="email">rmr</code> to perform MapReduce from R, operate an HDFS file through <code class="email">rhdfs</code>, and perform a common data operation using <code class="email">plyrmr</code>. Further, we will explore how to perform machine learning using RHadoop. Lastly, we will introduce <a id="id976" class="calibre1"/>how to deploy multiple RHadoop clusters on Amazon EC2.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Preparing the RHadoop environment"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec133" class="calibre1"/>Preparing the RHadoop environment </h1></div></div></div><p class="calibre7">As RHadoop requires an R and Hadoop integrated environment, we must first prepare an environment <a id="id977" class="calibre1"/>with both R and Hadoop installed. Instead of building a new Hadoop system, we can use the <span class="strong"><strong class="calibre2">Cloudera QuickStart VM</strong></span> (the VM is free), which contains a single node Apache Hadoop Cluster and R. In this <a id="id978" class="calibre1"/>recipe, we will demonstrate how to download the Cloudera QuickStart VM.</p></div>

<div class="book" title="Preparing the RHadoop environment">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec461" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">To use the Cloudera QuickStart VM, it is suggested that you should prepare a 64-bit guest OS with either VMWare or VirtualBox, or the KVM installed.</p><p class="calibre7">If you choose to use VMWare, you should prepare a player compatible with WorkStation 8.x or higher: Player 4.x or higher, ESXi 5.x or higher, or Fusion 4.x or higher.</p><p class="calibre7">Note, 4 GB of RAM is required to start VM, with an available disk space of at least 3 GB.</p></div></div>

<div class="book" title="Preparing the RHadoop environment">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec462" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the<a id="id979" class="calibre1"/> following steps to set up a Hadoop environment using the Cloudera QuickStart VM:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Visit the Cloudera QuickStart VM download site (you may need to update the link as<a id="id980" class="calibre1"/> Cloudera upgrades its VMs , the current version of CDH is 5.3) at <a class="calibre1" href="http://www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-3-x.html">http://www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-3-x.html</a>.<div class="mediaobject"><img src="../images/00267.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">A screenshot of the Cloudera QuickStart VM download site</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="2">Depending <a id="id981" class="calibre1"/>on the virtual<a id="id982" class="calibre1"/> machine platform installed on your OS, choose the appropriate link (you may need to update the link as Cloudera upgrades its VMs) to download the VM file:<div class="book"><ul class="itemizedlist3"><li class="listitem"><span class="strong"><strong class="calibre2">To download VMWare</strong></span>: You <a id="id983" class="calibre1"/>can visit <a class="calibre1" href="https://downloads.cloudera.com/demo_vm/vmware/cloudera-quickstart-vm-5.2.0-0-vmware.7z">https://downloads.cloudera.com/demo_vm/vmware/cloudera-quickstart-vm-5.2.0-0-vmware.7z</a></li><li class="listitem"><span class="strong"><strong class="calibre2">To download KVM</strong></span>: You <a id="id984" class="calibre1"/>can visit <a class="calibre1" href="https://downloads.cloudera.com/demo_vm/kvm/cloudera-quickstart-vm-5.2.0-0-kvm.7z">https://downloads.cloudera.com/demo_vm/kvm/cloudera-quickstart-vm-5.2.0-0-kvm.7z</a></li><li class="listitem"><span class="strong"><strong class="calibre2">To download VirtualBox</strong></span>: You can visit <a class="calibre1" href="https://downloads.cloudera.com/demo_vm/virtualbox/cloudera-quickstart-vm-5.2.0-0-virtualbox.7z">https://downloads.cloudera.com/demo_vm/virtualbox/cloudera-quickstart-vm-5.2.0-0-virtualbox.7z</a></li></ul></div></li><li class="listitem" value="3">Next, you <a id="id985" class="calibre1"/>can start the QuickStart VM using the virtual machine platform installed on your OS. You should see the desktop of Centos 6.2 in a few minutes.<div class="mediaobject"><img src="../images/00268.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">The screenshot of Cloudera QuickStart VM.</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="4">You <a id="id986" class="calibre1"/>can then open a terminal<a id="id987" class="calibre1"/> and type <code class="email">hadoop</code>, which will display a list of functions that can operate a Hadoop cluster.<div class="mediaobject"><img src="../images/00269.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">The terminal screenshot after typing <code class="email">hadoop</code>
</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="5">Open a terminal and type <code class="email">R</code>. Access an R session and check whether version 3.1.1 is already installed in the Cloudera QuickStart VM. If you cannot find R installed in the VM, please use the following command to install R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ yum install R R-core R-core-devel R-devel</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Preparing the RHadoop environment">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec463" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">Instead of building a Hadoop system on your own, you can use the Hadoop VM application provided by Cloudera (the VM is free). The QuickStart VM runs on CentOS 6.2 with a single node Apache Hadoop cluster, Hadoop Ecosystem module, and R installed. This helps you to save time, instead of requiring you to learn how to install and use Hadoop.</p><p class="calibre7">The<a id="id988" class="calibre1"/> QuickStart VM requires you to have a<a id="id989" class="calibre1"/> computer with a 64-bit guest OS, at least 4 GB of RAM, 3 GB of disk space, and either VMWare, VirtualBox, or KVM installed. As a result, you may not be able to use this version of VM on some computers. As an alternative, you could consider using Amazon's Elastic MapReduce instead. We will illustrate how to prepare a RHadoop environment in EMR in the last recipe of this chapter.</p><p class="calibre7">Setting up the Cloudera QuickStart VM is simple. Download the VM from the download site and then open the built image with either VMWare, VirtualBox, or KVM. Once you can see the desktop of CentOS, you can then access the terminal and type <code class="email">hadoop</code> to see whether Hadoop is working; then, type <code class="email">R</code> to see whether R works in the QuickStart VM.</p></div></div>

<div class="book" title="Preparing the RHadoop environment">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec464" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">Besides using the Cloudera QuickStart VM, you may consider using a Sandbox VM provided <a id="id990" class="calibre1"/>by Hontonworks or MapR. You can find Hontonworks Sandbox at <a class="calibre1" href="http://hortonworks.com/products/hortonworks-sandbox/#install">http://hortonworks.com/products/hortonworks-sandbox/#install</a> and <a id="id991" class="calibre1"/>mapR Sandbox at <a class="calibre1" href="https://www.mapr.com/products/mapr-sandbox-hadoop/download">https://www.mapr.com/products/mapr-sandbox-hadoop/download</a>.</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Installing rmr2"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec134" class="calibre1"/>Installing rmr2</h1></div></div></div><p class="calibre7">The <code class="email">rmr2</code> package <a id="id992" class="calibre1"/>allows you to perform big data processing and <a id="id993" class="calibre1"/>analysis via MapReduce on a Hadoop cluster. To perform MapReduce on a Hadoop cluster, you have to install R and <code class="email">rmr2</code> on every task node. In this recipe, we will illustrate how to install <code class="email">rmr2</code> on a single node of a Hadoop cluster.</p></div>

<div class="book" title="Installing rmr2">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec465" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">Ensure that you have completed the previous recipe by starting the Cloudera QuickStart VM and connecting the VM to the Internet, so that you can proceed with downloading and installing the <code class="email">rmr2</code> package.</p></div></div>

<div class="book" title="Installing rmr2">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec466" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the<a id="id994" class="calibre1"/> following steps to install <code class="email">rmr2</code> on the QuickStart VM:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, open <a id="id995" class="calibre1"/>the terminal within the Cloudera QuickStart VM.</li><li class="listitem" value="2">Use the permission of the root to enter an R session:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo R</strong></span>
</pre></div></li><li class="listitem" value="3">You can then install dependent packages before installing <code class="email">rmr2</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; install.packages(c("codetools", "Rcpp", "RJSONIO", "bitops", "digest", "functional", "stringr", "plyr", "reshape2", "rJava", "caTools"))</strong></span>
</pre></div></li><li class="listitem" value="4">Quit the R session:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; q()</strong></span>
</pre></div></li><li class="listitem" value="5">Next, you can download <code class="email">rmr-3.3.0</code> to the QuickStart VM. You may need to update the link if Revolution Analytics upgrades the version of <code class="email">rmr2</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ wget --no-check-certificate https://raw.githubusercontent.com/RevolutionAnalytics/rmr2/3.3.0/build/rmr2_3.3.0.tar.gz</strong></span>
</pre></div></li><li class="listitem" value="6">You can then install <code class="email">rmr-3.3.0</code> to the QuickStart VM:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo R CMD INSTALL rmr2_3.3.0.tar.gz</strong></span>
</pre></div></li><li class="listitem" value="7">Lastly, you can enter an R session and use the <code class="email">library</code> function to test whether the library has been successfully installed:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ R</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rmr2)</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Installing rmr2">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec467" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In order to perform MapReduce on a Hadoop cluster, you have to install R and RHadoop on every task node. Here, we illustrate how to install <code class="email">rmr2</code> on a single node of a Hadoop cluster. First, open the terminal of the Cloudera QuickStart VM. Before installing <code class="email">rmr2</code>, we first access an R session with root privileges and install dependent R packages.</p><p class="calibre7">Next, after all the dependent packages are installed, quit the R session and use the <code class="email">wget</code> command in the Linux shell to download <code class="email">rmr-3.3.0</code> from GitHub to the local filesystem. You can then begin the installation of <code class="email">rmr2</code>. Lastly, you can access an R session and use the library function to validate whether the package has been installed.</p></div></div>

<div class="book" title="Installing rmr2">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec468" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">To see<a id="id996" class="calibre1"/> more information and read updates about <a id="id997" class="calibre1"/>RHadoop, you can refer to the RHadoop wiki page hosted on GitHub: <a class="calibre1" href="https://github.com/RevolutionAnalytics/RHadoop/wiki">https://github.com/RevolutionAnalytics/RHadoop/wiki</a></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Installing rhdfs"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec135" class="calibre1"/>Installing rhdfs</h1></div></div></div><p class="calibre7">The <code class="email">rhdfs</code> package<a id="id998" class="calibre1"/> is the interface between R and HDFS, which <a id="id999" class="calibre1"/>allows users to access HDFS from an R console. Similar to <code class="email">rmr2</code>, one should install <code class="email">rhdfs</code> on every task node, so that one can access HDFS resources through R. In this recipe, we will introduce how to install <code class="email">rhdfs</code> on the Cloudera QuickStart VM.</p></div>

<div class="book" title="Installing rhdfs">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec469" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">Ensure that you have completed the previous recipe by starting the Cloudera QuickStart VM and connecting the VM to the Internet, so that you can proceed with downloading and installing the <code class="email">rhdfs</code> package.</p></div></div>

<div class="book" title="Installing rhdfs">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec470" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to install <code class="email">rhdfs</code>:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you can download <code class="email">rhdfs 1.0.8</code> from GitHub. You may need to update the link if Revolution Analytics upgrades the version of <code class="email">rhdfs</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$wget --no-check-certificate https://raw.github.com/RevolutionAnalytics/rhdfs/master/build/rhdfs_1.0.8.tar.gz</strong></span>
</pre></div></li><li class="listitem" value="2">Next, you can install <code class="email">rhdfs</code> under the command-line mode:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo HADOOP_CMD=/usr/bin/hadoop  R CMD INSTALL rhdfs_1.0.8.tar.gz</strong></span>
</pre></div></li><li class="listitem" value="3">You can then set up <code class="email">JAVA_HOME</code>. The configuration of <code class="email">JAVA_HOME</code> depends on the installed Java version within the VM:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera R CMD javareconf</strong></span>
</pre></div></li><li class="listitem" value="4">Last, you can set up the system environment and initialize <code class="email">rhdfs</code>. You may need to update the environment setup if you use a different version of QuickStart VM:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ R</strong></span>
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_CMD="/usr/bin/hadoop")</strong></span>
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop-</strong></span>
<span class="strong"><strong class="calibre2">streaming-2.5.0-cdh5.2.0.jar")</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rhdfs)</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.init()</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Installing rhdfs">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec471" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">The package, <code class="email">rhdfs</code>, provides functions so that users can manage HDFS using R. Similar to <code class="email">rmr2</code>, you <a id="id1000" class="calibre1"/>should install <code class="email">rhdfs</code> on every task node, so that <a id="id1001" class="calibre1"/>one can access HDFS through the R console.</p><p class="calibre7">To install <code class="email">rhdfs</code>, you should first download <code class="email">rhdfs</code> from GitHub. You can then install <code class="email">rhdfs</code> in R by specifying where the <code class="email">HADOOP_CMD</code> is located. You must configure R with Java support through the command, <code class="email">javareconf</code>.</p><p class="calibre7">Next, you can access R and configure where <code class="email">HADOOP_CMD</code> and <code class="email">HADOOP_STREAMING</code> are located. Lastly, you can initialize <code class="email">rhdfs</code> via the <code class="email">rhdfs.init</code> function, which allows you to begin operating HDFS through <code class="email">rhdfs</code>.</p></div></div>

<div class="book" title="Installing rhdfs">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec472" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">To find where <code class="email">HADOOP_CMD</code> is located, you can use the <code class="email">which hadoop</code> command in the Linux shell. In most Hadoop systems, <code class="email">HADOOP_CMD</code> is located at <code class="email">/usr/bin/hadoop</code>.</li><li class="listitem">As for the location of <code class="email">HADOOP_STREAMING</code>, the streaming JAR file is often located in <code class="email">/usr/lib/hadoop-mapreduce/</code>. However, if you cannot find the directory, <code class="email">/usr/lib/Hadoop-mapreduce</code>, in your Linux system, you can search the streaming JAR by using the <code class="email">locate</code> command. For example:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo updatedb</strong></span>
<span class="strong"><strong class="calibre2">$ locate streaming | grep jar | more</strong></span>
</pre></div></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Operating HDFS with rhdfs"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec136" class="calibre1"/>Operating HDFS with rhdfs</h1></div></div></div><p class="calibre7">The <code class="email">rhdfs</code> package is an interface between Hadoop and R, which can call an HDFS API in the<a id="id1002" class="calibre1"/> backend to operate HDFS. As a result, you<a id="id1003" class="calibre1"/> can easily operate HDFS from the R console through the use of the <code class="email">rhdfs</code> package. In the following recipe, we will demonstrate how to use the <code class="email">rhdfs</code> function to manipulate HDFS.</p></div>

<div class="book" title="Operating HDFS with rhdfs">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec473" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">To proceed with this recipe, you need to have completed the previous recipe by installing <code class="email">rhdfs</code> into R, and validate that you can initial HDFS via the <code class="email">hdfs.init</code> function.</p></div></div>

<div class="book" title="Operating HDFS with rhdfs">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec474" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform <a id="id1004" class="calibre1"/>the following steps to operate files stored<a id="id1005" class="calibre1"/> on HDFS:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Initialize the <code class="email">rhdfs</code> package:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_CMD="/usr/bin/hadoop")</strong></span>
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop-streaming-2.5.0-cdh5.2.0.jar")</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rhdfs)</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.init ()</strong></span>
</pre></div></li><li class="listitem" value="2">You can then manipulate files stored on HDFS, as follows:<div class="book"><ul class="itemizedlist3"><li class="listitem"><code class="email">hdfs.put</code>: Copy a file from the local filesystem to HDFS:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.put('word.txt', './')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.ls</code>: Read the list of directory from HDFS:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.ls('./')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.copy</code>: Copy a file from one HDFS directory to another:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.copy('word.txt', 'wordcnt.txt')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.move</code> : Move a file from one HDFS directory to another:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.move('wordcnt.txt', './data/wordcnt.txt')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.delete</code>: Delete an HDFS directory from R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.delete('./data/')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.rm</code>: Delete an HDFS directory from R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.rm('./data/')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.get</code>: Download a file from HDFS to a local filesystem:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.get(word.txt', '/home/cloudera/word.txt')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.rename</code>: Rename a file stored on HDFS:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">hdfs.rename('./test/q1.txt','./test/test.txt')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.chmod</code>: Change the permissions of a file or directory:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.chmod('test', permissions= '777')</strong></span>
</pre></div></li><li class="listitem"><code class="email">hdfs.file.info</code>: Read the meta information of the HDFS file:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.file.info('./')</strong></span>
</pre></div></li></ul></div></li><li class="listitem" value="3">Also, you can write stream to the HDFS file:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; f = hdfs.file("iris.txt","w")</strong></span>
<span class="strong"><strong class="calibre2">&gt; data(iris)</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.write(iris,f)</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.close(f)</strong></span>
</pre></div></li><li class="listitem" value="4">Lastly, you can read stream from the HDFS file:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; f = hdfs.file("iris.txt", "r")</strong></span>
<span class="strong"><strong class="calibre2">&gt; dfserialized = hdfs.read(f)</strong></span>
<span class="strong"><strong class="calibre2">&gt; df = unserialize(dfserialized)</strong></span>
<span class="strong"><strong class="calibre2">&gt; df</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.close(f)</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Operating HDFS with rhdfs">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec475" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this<a id="id1006" class="calibre1"/> recipe, we demonstrate how to manipulate <a id="id1007" class="calibre1"/>HDFS using the <code class="email">rhdfs</code> package. Normally, you can use the Hadoop shell to manipulate HDFS, but if you would like to access HDFS from R, you can use the <code class="email">rhdfs</code> package.</p><p class="calibre7">Before you start using <code class="email">rhdfs</code>, you have to initialize <code class="email">rhdfs</code> with <code class="email">hdfs.init()</code>. After initialization, you can operate HDFS through the functions provided in the <code class="email">rhdfs</code> package.</p><p class="calibre7">Besides manipulating HDFS files, you can exchange streams to HDFS through <code class="email">hdfs.read</code> and <code class="email">hdfs.write</code>. We, therefore, demonstrate how to write a data frame in R to an HDFS file, <code class="email">iris.txt</code>, using <code class="email">hdfs.write</code>. Lastly, you can recover the written file back to the data frame using the <code class="email">hdfs.read</code> function and the <code class="email">unserialize</code> function.</p></div></div>

<div class="book" title="Operating HDFS with rhdfs">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec476" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">To initialize <code class="email">rhdfs</code>, you have to set <code class="email">HADOOP_CMD</code> and <code class="email">HADOOP_STREAMING</code> in the system environment. Instead of setting the configuration each time you're using <code class="email">rhdfs</code>, you can put the configurations in the <code class="email">.rprofile</code> file. Therefore, every time you start an R session, the configuration will be automatically loaded.</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Implementing a word count problem with RHadoop"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec137" class="calibre1"/>Implementing a word count problem with RHadoop</h1></div></div></div><p class="calibre7">To demonstrate<a id="id1008" class="calibre1"/> how MapReduce works, we illustrate the example of a word count, which counts the number of occurrences of each word in a given input set. In this recipe, we will demonstrate how to use <code class="email">rmr2</code> to implement a word count problem.</p></div>

<div class="book" title="Implementing a word count problem with RHadoop">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec477" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this recipe, we will need an input file as our word count program input. You can download the<a id="id1009" class="calibre1"/> example input from <a class="calibre1" href="https://github.com/ywchiu/ml_R_cookbook/tree/master/CH12">https://github.com/ywchiu/ml_R_cookbook/tree/master/CH12</a>.</p></div></div>

<div class="book" title="Implementing a word count problem with RHadoop">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec478" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform<a id="id1010" class="calibre1"/> the following steps to implement the word count program:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you need to configure the system environment, and then load <code class="email">rmr2</code> and <code class="email">rhdfs</code> into an R session. You may need to update the use of the JAR file if you use a different version of QuickStart VM:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_CMD="/usr/bin/hadoop")</strong></span>
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop-streaming-2.5.0-cdh5.2.0.jar ")</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rmr2)</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rhdfs)</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.init()</strong></span>
</pre></div></li><li class="listitem" value="2">You can then create a directory on HDFS and put the input file into the newly created directory:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.mkdir("/user/cloudera/wordcount/data")</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.put("wc_input.txt", "/user/cloudera/wordcount/data")</strong></span>
</pre></div></li><li class="listitem" value="3">Next, you can create a <code class="email">map</code> function:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; map = function(.,lines) { keyval(</strong></span>
<span class="strong"><strong class="calibre2">+   unlist(</strong></span>
<span class="strong"><strong class="calibre2">+     strsplit(</strong></span>
<span class="strong"><strong class="calibre2">+       x = lines, </strong></span>
<span class="strong"><strong class="calibre2">+       split = " +")),</strong></span>
<span class="strong"><strong class="calibre2">+   1)}</strong></span>
</pre></div></li><li class="listitem" value="4">Create a <code class="email">reduce</code> function:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; reduce = function(word, counts) { </strong></span>
<span class="strong"><strong class="calibre2">+   keyval(word, sum(counts)) </strong></span>
<span class="strong"><strong class="calibre2">+ }</strong></span>
</pre></div></li><li class="listitem" value="5">Call the <code class="email">MapReduce</code> program to count the words within a document:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; hdfs.root = 'wordcount' &gt; hdfs.data = file.path(hdfs.root, 'data')</strong></span>
<span class="strong"><strong class="calibre2">&gt; hdfs.out = file.path(hdfs.root, 'out')</strong></span>
<span class="strong"><strong class="calibre2">&gt; wordcount = function (input, output=NULL) { </strong></span>
<span class="strong"><strong class="calibre2">+  mapreduce(input=input, output=output, input.format="text", map=map, </strong></span>
<span class="strong"><strong class="calibre2">+  reduce=reduce) </strong></span>
<span class="strong"><strong class="calibre2">+ } </strong></span>
<span class="strong"><strong class="calibre2">&gt; out = wordcount(hdfs.data, hdfs.out)</strong></span>
</pre></div></li><li class="listitem" value="6">Lastly, you can retrieve the top 10 occurring words within the document:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; results = from.dfs(out) </strong></span>
<span class="strong"><strong class="calibre2">&gt; results$key[order(results$val, decreasing = TRUE)][1:10]</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Implementing a word count problem with RHadoop">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec479" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this<a id="id1011" class="calibre1"/> recipe, we demonstrate how to implement a word count using the <code class="email">rmr2</code> package. First, we need to configure the system environment and load <code class="email">rhdfs</code> and <code class="email">rmr2</code> into R. Then, we specify the input of our word count program from the local filesystem into the HDFS directory, <code class="email">/user/cloudera/wordcount/data</code>, via the <code class="email">hdfs.put</code> function.</p><p class="calibre7">Next, we begin implementing the MapReduce program. Normally, we can divide the MapReduce program into the <code class="email">map</code> and <code class="email">reduce</code> functions. In the <code class="email">map</code> function, we first use the <code class="email">strsplit</code> function to split each line into words. Then, as the <code class="email">strsplit</code> function returns a list of words, we can use the <code class="email">unlist</code> function to character vectors. Lastly, we can return key-value pairs with each word as a key and the value as one. As the <code class="email">reduce</code> function receives the key-value pair generated from the <code class="email">map</code> function, the <code class="email">reduce</code> function sums the count and returns the number of occurrences of each word (or key).</p><p class="calibre7">After we have implemented the <code class="email">map</code> and <code class="email">reduce</code> functions, we can submit our job via the <code class="email">mapreduce</code> function. Normally, the <code class="email">mapreduce</code> function requires four inputs, which are the HDFS input path, the HDFS output path, the map function, and the reduce function. In this case, we specify the input as <code class="email">wordcount/data</code>, output as <code class="email">wordcount/out</code>, map<code class="email"> </code>function as <code class="email">map</code>, reduce function as <code class="email">reduce</code>, and wrap the <code class="email">mapreduce</code> call in function, <code class="email">wordcount</code>. Lastly, we call the function, <code class="email">wordcount</code> and store the output path in the variable, <code class="email">out</code>.</p><p class="calibre7">We can use the <code class="email">from.dfs</code> function to load the HDFS data into the <code class="email">results</code> variable, which contains the mapping of words and number of occurrences. We can then generate the top 10 occurring words from the <code class="email">results</code> variable.</p></div></div>

<div class="book" title="Implementing a word count problem with RHadoop">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec480" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">In this recipe, we demonstrate how to write an R MapReduce program to solve a <a id="id1012" class="calibre1"/>word count problem. However, if <a id="id1013" class="calibre1"/>you are interested in how to write a native Java MapReduce program, you can refer to <a class="calibre1" href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a>.</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Comparing the performance between an R MapReduce program and a standard R program"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec138" class="calibre1"/>Comparing the performance between an R MapReduce program and a standard R program</h1></div></div></div><p class="calibre7">Those not<a id="id1014" class="calibre1"/> familiar with how <a id="id1015" class="calibre1"/>Hadoop works may often see Hadoop as a remedy for big data processing. Some might believe that Hadoop can return the processed results for any size of data within a few milliseconds. In this recipe, we will compare the performance between an R MapReduce program and a standard R program to demonstrate that Hadoop does not perform as quickly as some may believe.</p></div>

<div class="book" title="Comparing the performance between an R MapReduce program and a standard R program">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec481" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this recipe, you should have completed the previous recipe by installing <code class="email">rmr2</code> into the R environment.</p></div></div>

<div class="book" title="Comparing the performance between an R MapReduce program and a standard R program">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec482" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to compare the performance of a standard R program and an R MapReduce program:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you can implement a standard R program to have all numbers squared:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; a.time = proc.time() </strong></span>
<span class="strong"><strong class="calibre2">&gt; small.ints2=1:100000 </strong></span>
<span class="strong"><strong class="calibre2">&gt; result.normal = sapply(small.ints2, function(x) x^2) </strong></span>
<span class="strong"><strong class="calibre2">&gt; proc.time() - a.time</strong></span>
</pre></div></li><li class="listitem" value="2">To compare the performance, you can implement an R MapReduce program to have all numbers squared:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; b.time = proc.time() </strong></span>
<span class="strong"><strong class="calibre2">&gt; small.ints= to.dfs(1:100000) </strong></span>
<span class="strong"><strong class="calibre2">&gt; result = mapreduce(input = small.ints, map = function(k,v)       cbind(v,v^2)) </strong></span>
<span class="strong"><strong class="calibre2">&gt; proc.time() - b.time</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Comparing the performance between an R MapReduce program and a standard R program">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec483" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this recipe, we implement two programs to square all the numbers. In the first program, we use a standard R function, <code class="email">sapply</code>, to square the sequence from 1 to 100,000. To record the program execution time, we first record the processing time before the<a id="id1016" class="calibre1"/> execution in <code class="email">a.time</code>, and then subtract <code class="email">a.time</code> from the current processing time after the execution. Normally, the execution takes no more than 10 seconds. In the second program, we<a id="id1017" class="calibre1"/> use the <code class="email">rmr2</code> package to implement a program in the R MapReduce version. In this program, we also record the execution time. Normally, this program takes a few minutes to complete a task.</p><p class="calibre7">The performance comparison shows that a standard R program outperforms the MapReduce program when processing small amounts of data. This is because a Hadoop system often requires time to spawn daemons, job coordination between daemons, and fetching data from data nodes. Therefore, a MapReduce program often takes a few minutes to a couple of hours to finish the execution. As a result, if you can fit your data in the memory, you should write a standard R program to solve the problem. Otherwise, if the data is too large to fit in the memory, you can implement a MapReduce solution.</p></div></div>

<div class="book" title="Comparing the performance between an R MapReduce program and a standard R program">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec484" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">In order to check whether a job will run smoothly and efficiently in Hadoop, you can run a MapReduce benchmark, MRBench, to evaluate the performance of the job:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-test.jar mrbench -numRuns 50</strong></span>
</pre></div></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Testing and debugging the rmr2 program"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec139" class="calibre1"/>Testing and debugging the rmr2 program</h1></div></div></div><p class="calibre7">Since running a MapReduce program will require a considerable amount of time, varying from a <a id="id1018" class="calibre1"/>few minutes to several hours, testing and debugging <a id="id1019" class="calibre1"/>become very important. In this recipe, we will illustrate some techniques you can use to troubleshoot an R MapReduce program.</p></div>

<div class="book" title="Testing and debugging the rmr2 program">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec485" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this recipe, you should have completed the previous recipe by installing <code class="email">rmr2</code> into an R environment.</p></div></div>

<div class="book" title="Testing and debugging the rmr2 program">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec486" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to test and debug an R MapReduce program:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you can configure the backend as local in <code class="email">rmr.options</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; rmr.options(backend = 'local')</strong></span>
</pre></div></li><li class="listitem" value="2">Again, you<a id="id1020" class="calibre1"/> can execute the number squared MapReduce program mentioned in the previous recipe:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; b.time = proc.time() </strong></span>
<span class="strong"><strong class="calibre2">&gt; small.ints= to.dfs(1:100000) </strong></span>
<span class="strong"><strong class="calibre2">&gt; result = mapreduce(input = small.ints, map = function(k,v)       cbind(v,v^2)) </strong></span>
<span class="strong"><strong class="calibre2">&gt; proc.time() - b.time</strong></span>
</pre></div></li><li class="listitem" value="3">In addition<a id="id1021" class="calibre1"/> to this, if you want to print the structure information of any variable in the MapReduce program, you can use the <code class="email">rmr.str</code> function:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; out = mapreduce(to.dfs(1), map = function(k, v) rmr.str(v))</strong></span>
<span class="strong"><strong class="calibre2">Dotted pair list of 14</strong></span>
<span class="strong"><strong class="calibre2"> $ : language mapreduce(to.dfs(1), map = function(k, v) rmr.str(v))</strong></span>
<span class="strong"><strong class="calibre2"> $ : language mr(map = map, reduce = reduce, combine = combine, vectorized.reduce, in.folder = if (is.list(input)) {     lapply(input, to.dfs.path) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language c.keyval(do.call(c, lapply(in.folder, function(fname) {     kv = get.data(fname) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language do.call(c, lapply(in.folder, function(fname) {     kv = get.data(fname) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language lapply(in.folder, function(fname) {     kv = get.data(fname) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language FUN("/tmp/Rtmp813BFJ/file25af6e85cfde"[[1L]], ...)</strong></span>
<span class="strong"><strong class="calibre2"> $ : language unname(tapply(1:lkv, ceiling((1:lkv)/(lkv/(object.size(kv)/10^6))), function(r) {     kvr = slice.keyval(kv, r) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language tapply(1:lkv, ceiling((1:lkv)/(lkv/(object.size(kv)/10^6))), function(r) {     kvr = slice.keyval(kv, r) ...</strong></span>
<span class="strong"><strong class="calibre2"> $ : language lapply(X = split(X, group), FUN = FUN, ...)</strong></span>
<span class="strong"><strong class="calibre2"> $ : language FUN(X[[1L]], ...)</strong></span>
<span class="strong"><strong class="calibre2"> $ : language as.keyval(map(keys(kvr), values(kvr)))</strong></span>
<span class="strong"><strong class="calibre2"> $ : language is.keyval(x)</strong></span>
<span class="strong"><strong class="calibre2"> $ : language map(keys(kvr), values(kvr))</strong></span>
<span class="strong"><strong class="calibre2"> $ :length 2 rmr.str(v)</strong></span>
<span class="strong"><strong class="calibre2">  ..- attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 34 1 58 34 58 1 1</strong></span>
<span class="strong"><strong class="calibre2">  .. .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' &lt;environment: 0x3f984f0&gt; </strong></span>
<span class="strong"><strong class="calibre2">v</strong></span>
<span class="strong"><strong class="calibre2"> num 1</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Testing and debugging the rmr2 program">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec487" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this<a id="id1022" class="calibre1"/> recipe, we introduced some debugging and testing<a id="id1023" class="calibre1"/> techniques you can use while implementing the MapReduce program. First, we introduced the technique to test a MapReduce program in a local mode. If you would like to run the MapReduce program in a pseudo distributed or fully distributed mode, it would take you a few minutes to several hours to complete the task, which would involve a lot of wastage of time while troubleshooting your MapReduce program. Therefore, you can set the backend to the local mode in <code class="email">rmr.options</code> so that the program will be executed in the local mode, which takes lesser time to execute.</p><p class="calibre7">Another debugging technique is to list the content of the variable within the <code class="email">map</code> or <code class="email">reduce</code> function. In an R program, you can use the <code class="email">str</code> function to display the compact structure of a single variable. In <code class="email">rmr2</code>, the package also provides a function named <code class="email">rmr.str</code>, which allows you to print out the content of a single variable onto the console. In this example, we use <code class="email">rmr.str</code> to print the content of variables within a MapReduce program.</p></div></div>

<div class="book" title="Testing and debugging the rmr2 program">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec488" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">For those who are interested in the <code class="email">option</code> settings for the <code class="email">rmr2</code> package, you can refer to the help document of <code class="email">rmr.options</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; help(rmr.options)</strong></span>
</pre></div></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Installing plyrmr"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec140" class="calibre1"/>Installing plyrmr</h1></div></div></div><p class="calibre7">The <code class="email">plyrmr</code> package<a id="id1024" class="calibre1"/> provides common operations (as found in <code class="email">plyr</code> or <code class="email">reshape2</code>) for<a id="id1025" class="calibre1"/> users to easily perform data manipulation through the MapReduce framework. In this recipe, we will introduce how to install <code class="email">plyrmr</code> on the Hadoop system.</p></div>

<div class="book" title="Installing plyrmr">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec489" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">Ensure that you have completed the previous recipe by starting the Cloudera QuickStart VM and connecting the VM to the Internet. Also, you need to have the <code class="email">rmr2</code> package installed beforehand.</p></div></div>

<div class="book" title="Installing plyrmr">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec490" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to install <code class="email">plyrmr</code> on the Hadoop system:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you should install <code class="email">libxml2-devel</code> and <code class="email">curl-devel</code> in the Linux shell:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ yum install libxml2-devel</strong></span>
<span class="strong"><strong class="calibre2">$ sudo yum install curl-devel</strong></span>
</pre></div></li><li class="listitem" value="2">You can then access R and install the dependent packages:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ sudo R</strong></span>
<span class="strong"><strong class="calibre2">&gt; Install.packages(c(" Rcurl", "httr"),  dependencies = TRUE</strong></span>
<span class="strong"><strong class="calibre2">&gt; Install.packages("devtools", dependencies = TRUE)</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(devtools)</strong></span>
<span class="strong"><strong class="calibre2">&gt; install_github("pryr", "hadley")</strong></span>
<span class="strong"><strong class="calibre2">&gt; install.packages(c(" R.methodsS3", "hydroPSO"),  dependencies = TRUE)</strong></span>
<span class="strong"><strong class="calibre2">&gt; q()</strong></span>
</pre></div></li><li class="listitem" value="3">Next, you can download <code class="email">plyrmr 0.5.0</code> and install it on Hadoop VM. You may need to update the link if Revolution Analytics upgrades the version of <code class="email">plyrmr</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ wget -no-check-certificate https://raw.github.com/RevolutionAnalytics/plyrmr/master/build/plyrmr_0.5.0.tar.gz</strong></span>
<span class="strong"><strong class="calibre2">$ sudo R CMD INSTALL plyrmr_0.5.0.tar.gz</strong></span>
</pre></div></li><li class="listitem" value="4">Lastly, validate the installation:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">$ R</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(plyrmr)</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Installing plyrmr">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec491" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">Besides writing an R MapReduce program using the <code class="email">rmr2</code> package, you can use the <code class="email">plyrmr</code> to manipulate data. The <code class="email">plyrmr</code> package is similar to hive and pig in the Hadoop ecosystem, which is the abstraction of the MapReduce program. Therefore, we can implement an R MapReduce program in <code class="email">plyr</code> style instead of implementing the <code class="email">map</code> f and <code class="email">reduce</code> functions.</p><p class="calibre7">To install <code class="email">plyrmr</code>, first install the package of <code class="email">libxml2-devel</code> and <code class="email">curl-devel</code>, using the <code class="email">yum install</code> command. Then, access R and install the dependent packages. Lastly, download <a id="id1026" class="calibre1"/>the file from GitHub and install <code class="email">plyrmr</code> in R.</p></div></div>

<div class="book" title="Installing plyrmr">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec492" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">To read <a id="id1027" class="calibre1"/>more information about <code class="email">plyrmr</code>, you can use the <code class="email">help</code> function to refer to the following document:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; help(package=plyrmr) </strong></span>
</pre></div></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Manipulating data with plyrmr"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec141" class="calibre1"/>Manipulating data with plyrmr</h1></div></div></div><p class="calibre7">While <a id="id1028" class="calibre1"/>writing a MapReduce program with <code class="email">rmr2</code> is much easier than writing a native Java version, it is still hard for nondevelopers to write a MapReduce program. Therefore, you can use <code class="email">plyrmr</code>, a high-level abstraction of the MapReduce program, so that you can use plyr-like operations to manipulate big data. In this recipe, we will introduce some operations you can use to manipulate data.</p></div>

<div class="book" title="Manipulating data with plyrmr">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec493" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this recipe, you should have completed the previous recipes by installing <code class="email">plyrmr</code> and <code class="email">rmr2</code> in R.</p></div></div>

<div class="book" title="Manipulating data with plyrmr">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec494" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to manipulate data with <code class="email">plyrmr</code>:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you need to load both <code class="email">plyrmr</code> and <code class="email">rmr2</code> into R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; library(rmr2)</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(plyrmr)</strong></span>
</pre></div></li><li class="listitem" value="2">You can then set the execution mode to the local mode:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; plyrmr.options(backend="local")</strong></span>
</pre></div></li><li class="listitem" value="3">Next, load the Titanic dataset into R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; data(Titanic)</strong></span>
<span class="strong"><strong class="calibre2">&gt; titanic = data.frame(Titanic)</strong></span>
</pre></div></li><li class="listitem" value="4">Begin the operation by filtering the data:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; where(</strong></span>
<span class="strong"><strong class="calibre2">+    Titanic, </strong></span>
<span class="strong"><strong class="calibre2">+ Freq &gt;=100)</strong></span>
</pre></div></li><li class="listitem" value="5">You can also use a pipe operator to filter the data:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; titanic %|% where(Freq &gt;=100)</strong></span>
</pre></div></li><li class="listitem" value="6">Put the Titanic data into HDFS and load the path of the data to the variable, <code class="email">tidata</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; tidata = to.dfs(data.frame(Titanic), output = '/tmp/titanic')</strong></span>
<span class="strong"><strong class="calibre2">&gt; tidata</strong></span>
</pre></div></li><li class="listitem" value="7">Next, you can generate a summation of the frequency from the Titanic data:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; input(tidata) %|% transmute(sum(Freq))</strong></span>
</pre></div></li><li class="listitem" value="8">You <a id="id1029" class="calibre1"/>can also group the frequency by sex:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; input(tidata) %|% group(Sex) %|% transmute(sum(Freq))</strong></span>
</pre></div></li><li class="listitem" value="9">You can then sample 10 records out of the population:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; sample(input(tidata), n=10)</strong></span>
</pre></div></li><li class="listitem" value="10">In addition to this, you can use plyrmr to join two datasets:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; convert_tb = data.frame(Label=c("No","Yes"), Symbol=c(0,1))</strong></span>
<span class="strong"><strong class="calibre2">ctb = to.dfs(convert_tb, output = 'convert')</strong></span>
<span class="strong"><strong class="calibre2">&gt; as.data.frame(plyrmr::merge(input(tidata), input(ctb), by.x="Survived", by.y="Label"))</strong></span>
<span class="strong"><strong class="calibre2">&gt; file.remove('convert')</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Manipulating data with plyrmr">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec495" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this recipe, we introduce how to use <code class="email">plyrmr</code> to manipulate data. First, we need to load the <code class="email">plyrmr</code> package into R. Then, similar to <code class="email">rmr2</code>, you have to set the backend option of <code class="email">plyrmr</code> as the local mode. Otherwise, you will have to wait anywhere between a few minutes to several hours if <code class="email">plyrmr</code> is running on Hadoop mode (the default setting).</p><p class="calibre7">Next, we can begin the data manipulation with data filtering. You can choose to call the function nested inside the other function call in step 4. On the other hand, you can use the pipe operator, <code class="email">%|%</code>, to chain multiple operations. Therefore, we can filter data similar to step 4, using pipe operators in step 5.</p><p class="calibre7">Next, you can input the dataset into either the HDFS or local filesystem, using <code class="email">to.dfs</code> in accordance with the current running mode. The function will generate the path of the dataset and save it in the variable, <code class="email">tidata</code>. By knowing the path, you can access the data using the <code class="email">input</code> function. Next, we illustrate how to generate a summation of the frequency from the Titanic dataset with the <code class="email">transmute</code> and <code class="email">sum</code> functions. Also, <code class="email">plyrmr</code> allows users to sum up the frequency by gender.</p><p class="calibre7">Additionally, in order to sample data from a population, you can also use the <code class="email">sample</code> function to select 10 records out of the Titanic dataset. Lastly, we demonstrate how to join two datasets using the <code class="email">merge</code> function from <code class="email">plyrmr</code>.</p></div></div>

<div class="book" title="Manipulating data with plyrmr">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec496" class="calibre1"/>See also</h2></div></div></div><p class="calibre7">Here <a id="id1030" class="calibre1"/>we list some functions that can be used to manipulate data with <code class="email">plyrmr</code>. You may refer to the <code class="email">help</code> function for further details on their usage and functionalities:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Data manipulation:<div class="book"><ul class="itemizedlist3"><li class="listitem"><code class="email">bind.cols</code>: This adds new columns</li><li class="listitem"><code class="email">select</code>: This is used to select columns</li><li class="listitem"><code class="email">where</code>: This is used to select rows</li><li class="listitem"><code class="email">transmute</code>: This uses all of the above plus their summaries</li></ul></div></li><li class="listitem">From <code class="email">reshape2</code>:<div class="book"><ul class="itemizedlist3"><li class="listitem"><code class="email">melt</code> and <code class="email">dcast</code>: It converts long and wide data frames</li></ul></div></li><li class="listitem">Summary:<div class="book"><ul class="itemizedlist3"><li class="listitem"><code class="email">count</code></li><li class="listitem"><code class="email">quantile</code></li><li class="listitem"><code class="email">sample</code></li></ul></div></li><li class="listitem">Extract:<div class="book"><ul class="itemizedlist3"><li class="listitem"><code class="email">top.k</code></li><li class="listitem"><code class="email">bottom.k</code></li></ul></div></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Conducting machine learning with RHadoop"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec142" class="calibre1"/>Conducting machine learning with RHadoop</h1></div></div></div><p class="calibre7">In the<a id="id1031" class="calibre1"/> previous chapters, we have demonstrated how powerful R is when used to solve machine<a id="id1032" class="calibre1"/> learning problems. Also, we have shown that the use of Hadoop allows R to process big data in parallel. At this point, some may believe that the use of RHadoop can easily solve machine learning problems of big data via numerous existing machine learning packages. However, you cannot use most of these to solve machine learning problems as they cannot be executed in the MapReduce mode. In the following recipe, we will demonstrate how to implement a MapReduce version of linear regression and compare this version with the one using the <code class="email">lm</code> function.</p></div>

<div class="book" title="Conducting machine learning with RHadoop">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec497" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this recipe, you should have completed the previous recipe by installing <code class="email">rmr2</code> into the R environment.</p></div></div>

<div class="book" title="Conducting machine learning with RHadoop">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec498" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform <a id="id1033" class="calibre1"/>the following steps to implement a linear<a id="id1034" class="calibre1"/> regression in MapReduce:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, load the <code class="email">cats</code> dataset from the <code class="email">MASS</code> package:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; library(MASS)</strong></span>
<span class="strong"><strong class="calibre2">&gt; data(cats)</strong></span>
<span class="strong"><strong class="calibre2">&gt; X = matrix(cats$Bwt)</strong></span>
<span class="strong"><strong class="calibre2">&gt; y = matrix(cats$Hwt)</strong></span>
</pre></div></li><li class="listitem" value="2">You can then generate a linear regression model by calling the <code class="email">lm</code> function:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; model = lm(y~X)</strong></span>
<span class="strong"><strong class="calibre2">&gt; summary(model)</strong></span>

<span class="strong"><strong class="calibre2">Call:</strong></span>
<span class="strong"><strong class="calibre2">lm(formula = y ~ X)</strong></span>

<span class="strong"><strong class="calibre2">Residuals:</strong></span>
<span class="strong"><strong class="calibre2">    Min      1Q  Median      3Q     Max </strong></span>
<span class="strong"><strong class="calibre2">-3.5694 -0.9634 -0.0921  1.0426  5.1238 </strong></span>

<span class="strong"><strong class="calibre2">Coefficients:</strong></span>
<span class="strong"><strong class="calibre2">            Estimate Std. Error t value Pr(&gt;|t|)    </strong></span>
<span class="strong"><strong class="calibre2">(Intercept)  -0.3567     0.6923  -0.515    0.607    </strong></span>
<span class="strong"><strong class="calibre2">X             4.0341     0.2503  16.119   &lt;2e-16 ***</strong></span>
<span class="strong"><strong class="calibre2">---</strong></span>
<span class="strong"><strong class="calibre2">Signif. codes:  </strong></span>
<span class="strong"><strong class="calibre2">0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</strong></span>

<span class="strong"><strong class="calibre2">Residual standard error: 1.452 on 142 degrees of freedom</strong></span>
<span class="strong"><strong class="calibre2">Multiple R-squared:  0.6466,  Adjusted R-squared:  0.6441 </strong></span>
<span class="strong"><strong class="calibre2">F-statistic: 259.8 on 1 and 142 DF,  p-value: &lt; 2.2e-16</strong></span>
</pre></div></li><li class="listitem" value="3">You can <a id="id1035" class="calibre1"/>now make a regression plot with<a id="id1036" class="calibre1"/> the given data points and model:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; plot(y~X)</strong></span>
<span class="strong"><strong class="calibre2">&gt; abline(model, col="red")</strong></span>
</pre></div><div class="mediaobject"><img src="../images/00270.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Linear regression plot of cats dataset</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="4">Load <code class="email">rmr2</code> into R:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_CMD="/usr/bin/hadoop")</strong></span>
<span class="strong"><strong class="calibre2">&gt; Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop-&gt; streaming-2.5.0-cdh5.2.0.jar")</strong></span>
<span class="strong"><strong class="calibre2">&gt; library(rmr2)</strong></span>
<span class="strong"><strong class="calibre2">&gt; rmr.options(backend="local")</strong></span>
</pre></div></li><li class="listitem" value="5">You can then set up <code class="email">X</code> and <code class="email">y</code> values:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; X = matrix(cats$Bwt)</strong></span>
<span class="strong"><strong class="calibre2">&gt; X.index = to.dfs(cbind(1:nrow(X), X))</strong></span>
<span class="strong"><strong class="calibre2">&gt; y = as.matrix(cats$Hwt)</strong></span>
</pre></div></li><li class="listitem" value="6">Make a <code class="email">Sum</code> function to sum up the values: <div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; Sum = </strong></span>
<span class="strong"><strong class="calibre2">+   function(., YY) </strong></span>
<span class="strong"><strong class="calibre2">+     keyval(1, list(Reduce('+', YY)))</strong></span>
</pre></div></li><li class="listitem" value="7">Compute <code class="email">Xtx</code> in<a id="id1037" class="calibre1"/> MapReduce, <code class="email">Job1</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; XtX = </strong></span>
<span class="strong"><strong class="calibre2">+    values(</strong></span>
<span class="strong"><strong class="calibre2">+      from.dfs(</strong></span>
<span class="strong"><strong class="calibre2">+        mapreduce(</strong></span>
<span class="strong"><strong class="calibre2">+          input = X.index,</strong></span>
<span class="strong"><strong class="calibre2">+          map = </strong></span>
<span class="strong"><strong class="calibre2">+            function(., Xi) {</strong></span>
<span class="strong"><strong class="calibre2">+              Xi = Xi[,-1]</strong></span>
<span class="strong"><strong class="calibre2">+              keyval(1, list(t(Xi) %*% Xi))},</strong></span>
<span class="strong"><strong class="calibre2">+          reduce = Sum,</strong></span>
<span class="strong"><strong class="calibre2">+          combine = TRUE)))[[1]]</strong></span>
</pre></div></li><li class="listitem" value="8">You <a id="id1038" class="calibre1"/>can then compute <code class="email">Xty</code> in MapReduce, <code class="email">Job2</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">Xty = </strong></span>
<span class="strong"><strong class="calibre2">+    values(</strong></span>
<span class="strong"><strong class="calibre2">+      from.dfs(</strong></span>
<span class="strong"><strong class="calibre2">+        mapreduce(</strong></span>
<span class="strong"><strong class="calibre2">+          input = X.index,</strong></span>
<span class="strong"><strong class="calibre2">+          map = function(., Xi) {</strong></span>
<span class="strong"><strong class="calibre2">+            yi = y[Xi[,1],]</strong></span>
<span class="strong"><strong class="calibre2">+            Xi = Xi[,-1]</strong></span>
<span class="strong"><strong class="calibre2">+            keyval(1, list(t(Xi) %*% yi))},</strong></span>
<span class="strong"><strong class="calibre2">+          reduce = Sum,</strong></span>
<span class="strong"><strong class="calibre2">+          combine = TRUE)))[[1]]</strong></span>
</pre></div></li><li class="listitem" value="9">Lastly, you can derive the coefficient from <code class="email">XtX</code> and <code class="email">Xty</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">&gt; solve(XtX, Xty)</strong></span>
<span class="strong"><strong class="calibre2">         [,1]</strong></span>
<span class="strong"><strong class="calibre2">[1,] 3.907113</strong></span>
</pre></div></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Conducting machine learning with RHadoop">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec499" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this recipe, we demonstrate how to implement linear logistic regression in a MapReduce fashion in R. Before we start the implementation, we review how traditional linear models work. We first retrieve the <code class="email">cats</code> dataset from the <code class="email">MASS</code> package. We then load <code class="email">X</code> as the body weight (<code class="email">Bwt</code>) and <code class="email">y</code> as the heart weight (<code class="email">Hwt</code>).</p><p class="calibre7">Next, we begin to fit the data into a linear regression model using the <code class="email">lm</code> function. We can then <a id="id1039" class="calibre1"/>compute the fitted model and obtain the summary <a id="id1040" class="calibre1"/>of the model. The summary shows that the coefficient is 4.0341 and the intercept is -0.3567. Furthermore, we draw a scatter plot in accordance with the given data points and then draw a regression line on the plot.</p><p class="calibre7">As we cannot perform linear regression using the <code class="email">lm</code> function in the MapReduce form, we have to rewrite the regression model in a MapReduce fashion. Here, we would like to implement a MapReduce version of linear regression in three steps, which are: calculate the <code class="email">Xtx</code> value with the MapReduce, job1, calculate the <code class="email">Xty</code> value with MapReduce, <code class="email">job2</code>, and then derive the coefficient value:</p><div class="book"><ul class="itemizedlist"><li class="listitem">In the first step, we pass the matrix, <code class="email">X</code>, as the input to the <code class="email">map</code> function. The <code class="email">map</code> function then calculates the cross product of the transposed matrix, <code class="email">X</code>, and, <code class="email">X</code>. The <code class="email">reduce</code> function then performs the sum operation defined in the previous section.</li><li class="listitem">In the second step, the procedure of calculating <code class="email">Xty</code> is similar to calculating <code class="email">XtX</code>. The procedure calculates the cross product of the transposed matrix, <code class="email">X,</code> and, <code class="email">y</code>. The <code class="email">reduce</code> function then performs the sum operation.</li><li class="listitem">Lastly, we use the <code class="email">solve</code> function to derive the coefficient, which is 3.907113.</li></ul></div><p class="calibre7">As the results show, the coefficients computed by <code class="email">lm</code> and MapReduce differ slightly. Generally speaking, the coefficient computed by the <code class="email">lm</code> model is more accurate than the one calculated by MapReduce. However, if your data is too large to fit in the memory, you have no choice but to implement linear regression in the MapReduce version.</p></div></div>

<div class="book" title="Conducting machine learning with RHadoop">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec500" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">You can<a id="id1041" class="calibre1"/> access more information on machine learning algorithms at: <a class="calibre1" href="https://github.com/RevolutionAnalytics/rmr2/tree/master/pkg/tests">https://github.com/RevolutionAnalytics/rmr2/tree/master/pkg/tests</a></li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Configuring RHadoop clusters on Amazon EMR"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch12lvl1sec143" class="calibre1"/>Configuring RHadoop clusters on Amazon EMR</h1></div></div></div><p class="calibre7">Until now, we have only demonstrated how to run a RHadoop program in a single Hadoop node. In order to test our RHadoop program on a multi-node cluster, the only thing you need to do is to install RHadoop on all the task nodes (nodes with either task tracker for mapreduce version 1 or node manager for map reduce version 2) of Hadoop clusters. However, the deployment and installation is time consuming. On the other hand, you can choose to deploy your RHadoop program on Amazon EMR, so that you can deploy multi-node clusters and RHadoop on every task node in only a few minutes. In the following recipe, we will demonstrate how to configure RHadoop cluster on an Amazon EMR service.</p></div>

<div class="book" title="Configuring RHadoop clusters on Amazon EMR">
<div class="book" title="Getting ready"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch12lvl2sec501" class="calibre1"/>Getting ready</h2></div></div></div><p class="calibre7">In this <a id="id1042" class="calibre1"/>recipe, you must register and create an <a id="id1043" class="calibre1"/>account on AWS, and you also must know how to generate a EC2 key-pair before using Amazon EMR.</p><p class="calibre7">For those who seek more information on how to start using AWS, please refer to the  tutorial provided by <a id="id1044" class="calibre1"/>Amazon at <a class="calibre1" href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html</a>.</p></div></div>

<div class="book" title="Configuring RHadoop clusters on Amazon EMR">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch12lvl2sec502" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre7">Perform the following steps to configure RHadoop on Amazon EMR:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, you can access the console of the Amazon Web Service (refer to <a class="calibre1" href="https://us-west-2.console.aws.amazon.com/console/">https://us-west-2.console.aws.amazon.com/console/</a>) and find EMR in the analytics section. Then, click on <span class="strong"><strong class="calibre2">EMR</strong></span>.<div class="mediaobject"><img src="../images/00271.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Access EMR service from AWS console.</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="2">You should <a id="id1045" class="calibre1"/>find yourself in the cluster list of the EMR dashboard (refer to <a class="calibre1" href="https://us-west-2.console.aws.amazon.com/elasticmapreduce/home?region=us-west-2#cluster-list::">https://us-west-2.console.aws.amazon.com/elasticmapreduce/home?region=us-west-2#cluster-list::</a>); click on <span class="strong"><strong class="calibre2">Create cluster</strong></span>.<div class="mediaobject"><img src="../images/00272.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Cluster list of EMR</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="3">Then, you should find yourself on the <span class="strong"><strong class="calibre2">Create Cluster</strong></span> page (refer to <a class="calibre1" href="https://us-west-2.console.aws.amazon.com/elasticmapreduce/home?region=us-west-2#create-cluster:">https://us-west-2.console.aws.amazon.com/elasticmapreduce/home?region=us-west-2#create-cluster:</a>).</li><li class="listitem" value="4">Next, you <a id="id1046" class="calibre1"/>should specify <span class="strong"><strong class="calibre2">Cluster name</strong></span> and<a id="id1047" class="calibre1"/> <span class="strong"><strong class="calibre2">Log folder S3 location</strong></span> in the cluster configuration.<div class="mediaobject"><img src="../images/00273.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Cluster configuration in the create cluster page</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="5">You can then configure the Hadoop distribution on <span class="strong"><strong class="calibre2">Software Configuration</strong></span>.<div class="mediaobject"><img src="../images/00274.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Configure the software and applications</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="6">Next, you<a id="id1048" class="calibre1"/> can configure the <a id="id1049" class="calibre1"/>number of nodes within the Hadoop cluster.<div class="mediaobject"><img src="../images/00275.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Configure the hardware within Hadoop cluster</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="7">You can then specify the EC2 key-pair for the master node login.<div class="mediaobject"><img src="../images/00276.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Security and access to the master node of the EMR cluster</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="8">To set <a id="id1050" class="calibre1"/>up RHadoop, one has to<a id="id1051" class="calibre1"/> perform bootstrap actions to install RHadoop on every task node. Please write a file named <code class="email">bootstrapRHadoop.sh</code>, and insert the following lines within the file:<div class="informalexample"><pre class="programlisting">echo 'install.packages(c("codetools", "Rcpp", "RJSONIO", "bitops", "digest", "functional", "stringr", "plyr", "reshape2", "rJava", "caTools"), repos="http://cran.us.r-project.org")' &gt; /home/hadoop/installPackage.R
sudo Rscript /home/hadoop/installPackage.R
wget --no-check-certificate https://raw.githubusercontent.com/RevolutionAnalytics/rmr2/master/build/rmr2_3.3.0.tar.gz
sudo R CMD INSTALL rmr2_3.3.0.tar.gz
wget --no-check-certificate https://raw.github.com/RevolutionAnalytics/rhdfs/master/build/rhdfs_1.0.8.tar.gz
sudo HADOOP_CMD=/home/hadoop/bin/hadoop R CMD INSTALL rhdfs_1.0.8.tar.gz</pre></div></li><li class="listitem" value="9">You should upload <code class="email">bootstrapRHadoop.sh</code> to <code class="email">S3</code>.</li><li class="listitem" value="10">You now need to add the bootstrap action with <code class="email">Custom action</code>, and add <code class="email">s3://&lt;location&gt;/bootstrapRHadoop.sh</code> within the S3 location.<div class="mediaobject"><img src="../images/00277.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Set up the bootstrap action</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="11">Next, you can click on <span class="strong"><strong class="calibre2">Create cluster</strong></span> to launch the Hadoop cluster.<div class="mediaobject"><img src="../images/00278.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">Create the cluster</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="12">Lastly, you<a id="id1052" class="calibre1"/> should see the master <a id="id1053" class="calibre1"/>public DNS when the cluster is ready. You can now access the terminal of the master node with your EC2-key pair:<div class="mediaobject"><img src="../images/00279.jpeg" alt="How to do it..." class="calibre9"/><div class="caption"><p class="calibre12">A screenshot of the created cluster</p></div></div><p class="calibre13"> </p></li></ol><div class="calibre14"/></div></div></div>

<div class="book" title="Configuring RHadoop clusters on Amazon EMR">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch12lvl2sec503" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre7">In this recipe, we demonstrate how to set up RHadoop on Amazon EMR. The benefit of this is that you can quickly create a scalable, on demand Hadoop with just a few clicks within a few minutes. This helps save you time from building and deploying a Hadoop application. However, you have to pay for the number of running hours for each instance. Before using Amazon EMR, you should create an AWS account and know how to set up the EC2 key-pair and the S3. You can then start installing RHadoop on Amazon EMR.</p><p class="calibre7">In the first step, access the EMR cluster list and click on <span class="strong"><strong class="calibre2">Create cluster</strong></span>. You can see a list of configurations on the <span class="strong"><strong class="calibre2">Create cluster</strong></span> page. You should then set up the cluster name and log folder in the S3 location in the cluster configuration. </p><p class="calibre7">Next, you can set up the software configuration and choose the Hadoop distribution you would like to <a id="id1054" class="calibre1"/>install. Amazon provides both its own <a id="id1055" class="calibre1"/>distribution and the MapR distribution. Normally, you would skip this section unless you have concerns about the default Hadoop distribution.</p><p class="calibre7">You can then configure the hardware by specifying the master, core, and task node. By default, there is only one master node, and two core nodes. You can add more core and task nodes if you like. You should then set up the key-pair to login to the master node.</p><p class="calibre7">You should next make a file containing all the start scripts named <code class="email">bootstrapRHadoop.sh</code>. After the file is created, you should save the file in the S3 storage. You can then specify <code class="email">custom action</code> in <span class="strong"><strong class="calibre2">Bootstrap Action</strong></span> with <code class="email">bootstrapRHadoop.sh</code> as the Bootstrap script. Lastly, you can click on <code class="email">Create cluster</code> and wait until the cluster is ready. Once the cluster is ready, one can see the master public DNS and can use the EC2 key-pair to access the terminal of the master node.</p><p class="calibre7">Beware! Terminate the running instance if you do not want to continue using the EMR service. Otherwise, you will be charged per instance for every hour you use.</p></div></div>

<div class="book" title="Configuring RHadoop clusters on Amazon EMR">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch12lvl2sec504" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">Google also provides its own cloud solution, the Google compute engine. For those who <a id="id1056" class="calibre1"/>would like to know more, please refer to <a class="calibre1" href="https://cloud.google.com/compute/">https://cloud.google.com/compute/</a>.</li></ul></div></div></div>
<div class="book" title="Appendix&#xA0;A.&#xA0;Resources for R and Machine Learning"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="appA" class="calibre1"/>Appendix A. Resources for R and Machine Learning</h1></div></div></div><p class="calibre7">The following table lists all the resources for R and machine learning:</p><div class="informalexample"><table border="1" class="calibre15"><colgroup class="calibre16"><col class="calibre17"/><col class="calibre17"/><col class="calibre17"/><col class="calibre17"/></colgroup><thead class="calibre18"><tr class="calibre19"><th colspan="4" valign="bottom" class="calibre28">
<p class="calibre21">R introduction</p>
</th></tr></thead><tbody class="calibre22"><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Title</strong></span>
</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Link</strong></span>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Author</strong></span>
</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">R in Action</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.amazon.com/R-Action-Robert-Kabacoff/dp/1935182390">http://www.amazon.com/R-Action-Robert-Kabacoff/dp/1935182390</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Robert Kabacoff</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">The Art of R Programming: A Tour of Statistical Software Design</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.amazon.com/The-Art-Programming-Statistical-Software/dp/1593273843">http://www.amazon.com/The-Art-Programming-Statistical-Software/dp/1593273843</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Norman Matloff</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">An Introduction to R</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://cran.r-project.org/doc/manuals/R-intro.pdf">http://cran.r-project.org/doc/manuals/R-intro.pdf</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">W. N. Venables, D. M. Smith, and the R Core Team</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Quick-R</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.statmethods.net/">http://www.statmethods.net/</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Robert I. Kabacoff, PhD</p>
</td></tr><tr class="calibre19"><td colspan="4" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Online courses</strong></span>
</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Title</strong></span>
</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Link</strong></span>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Instructor</strong></span>
</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Computing for Data Analysis (with R)</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="https://www.coursera.org/course/compdata">https://www.coursera.org/course/compdata</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Roger D. Peng, Johns Hopkins University</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Data Analysis</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="https://www.coursera.org/course/dataanalysis">https://www.coursera.org/course/dataanalysis</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Jeff Leek, Johns Hopkins University</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Data Analysis and Statistical Inference</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="https://www.coursera.org/course/statistics">https://www.coursera.org/course/statistics</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Mine Çetinkaya-Rundel, Duke University</p>
</td></tr><tr class="calibre19"><td colspan="4" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Machine learning</strong></span>
</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Title</strong></span>
</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Link</strong></span>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">
<span><strong class="calibre29">Author</strong></span>
</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Machine Learning for Hackers</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.amazon.com/dp/1449303714?tag=inspiredalgor-20">http://www.amazon.com/dp/1449303714?tag=inspiredalgor-20</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Drew Conway and John Myles White</p>
</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">Machine Learning with R</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.packtpub.com/machine-learning-with-r/book">http://www.packtpub.com/machine-learning-with-r/book</a>
</p>
</td><td valign="top" class="calibre23">
<p class="calibre21">Brett Lantz</p>
</td></tr><tr class="calibre19"><td colspan="4" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Online blog</strong></span>
</p>
</td></tr><tr class="calibre19"><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Title</strong></span>
</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Link</strong></span>
</p>
</td></tr><tr class="calibre19"><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">R-bloggers</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://www.r-bloggers.com/">http://www.r-bloggers.com/</a>
</p>
</td></tr><tr class="calibre19"><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">The R Journal</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://journal.r-project.org/">http://journal.r-project.org/</a>
</p>
</td></tr><tr class="calibre19"><td colspan="4" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">CRAN task view</strong></span>
</p>
</td></tr><tr class="calibre19"><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Title</strong></span>
</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<span><strong class="calibre29">Link</strong></span>
</p>
</td></tr><tr class="calibre19"><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">CRAN Task View: Machine Learning and Statistical Learning</p>
</td><td colspan="2" valign="top" class="calibre30">
<p class="calibre21">
<a class="indexterm" href="http://cran.r-project.org/web/views/MachineLearning.html">http://cran.r-project.org/web/views/MachineLearning.html</a>
</p>
</td></tr></tbody></table></div></div>
<div class="book" title="Appendix&#xA0;B.&#xA0;Dataset &#x2013; Survival of Passengers on the Titanic"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="appB" class="calibre1"/>Appendix B. Dataset – Survival of Passengers on the Titanic</h1></div></div></div><p class="calibre7">Before the exploration process, we would like to introduce the example adopted here. It is the demographic information on passengers aboard the RMS Titanic, provided by Kaggle (<a class="calibre1" href="https://www.kaggle.com/">https://www.kaggle.com/</a>, a platform for data prediction competitions). The result we are examining is whether passengers on board would survive the shipwreck or not.</p><p class="calibre7">There are two reasons to apply this dataset:</p><div class="book"><ul class="itemizedlist"><li class="listitem">RMS Titanic is considered as the most infamous shipwreck in history, with a death toll of up to 1,502 out of 2,224 passengers and crew. However, after the ship sank, the passengers' chance of survival was not by chance only; actually, the cabin class, sex, age, and other factors might also have affected their chance of survival.</li><li class="listitem">The dataset is relatively simple; you do not need to spend most of your time on data munging (except when dealing with some missing values), but you can focus on the application of exploratory analysis.</li></ul></div><p class="calibre7">The following chart is the variables' descriptions of the target dataset:</p><div class="mediaobject"><img src="../images/00280.jpeg" alt="Dataset – Survival of Passengers on the Titanic" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre7">Judging from the description of the variables, one might have some questions in mind, such as, "Are there any missing values in this dataset?", "What was the average age of the passengers on the Titanic?", "What proportion of the passengers survived the disaster?", "What social class did most passengers on board belong to?". All these questions presented here will be answered in <a class="calibre1" title="Chapter 2. Data Exploration with RMS Titanic" href="part0024_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre8">Data Exploration with RMS Titanic</em></span>.</p><p class="calibre7">Beyond questions relating to descriptive statistics, the eventual object of <a class="calibre1" title="Chapter 2. Data Exploration with RMS Titanic" href="part0024_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre8">Data Exploration with RMS Titanic</em></span>, is to generate a model to predict the chance of survival given by the input parameters. In addition to this, we will assess the performance of the generated model to determine whether the model is suited for the problem.</p></div></body></html>