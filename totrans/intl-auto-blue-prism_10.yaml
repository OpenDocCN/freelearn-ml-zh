- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: IA’s Impact on the Robotic Operating Model
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IA对机器人操作模型的影响
- en: The **Robotic Operating Model** (**ROM**) is what I call the *management* side
    of RPA. It distills BP’s 20+ years of automation experience and best practices
    into a framework that can be applied to all types of firms. This framework’s purpose
    is to help ensure the continued success and growth of automation in a company.
    This includes areas that may not be immediately obvious, such as securing executive
    sponsorship, developing career paths, choosing an appropriate organizational structure,
    and facilitating cultural adoption.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我所说的**机器人操作模型**（**ROM**）是RPA的*管理*方面。它将BP 20多年的自动化经验和最佳实践提炼成一个框架，该框架可以应用于所有类型的公司。这个框架的目的是帮助确保公司在自动化方面的持续成功和增长。这包括一些可能不是立即显而易见的问题领域，例如确保获得高管支持、开发职业路径、选择合适的组织结构以及促进文化接受度。
- en: 'Although the ROM isn’t a technology product, it’s still a key differentiator
    between BP and its competitors. Anyone who works in RPA should become familiar
    with the ROM, especially since its guidance is vendor-agnostic. As technologies
    and the regulatory environment change, so must our management frameworks; the
    ROM is constantly undergoing revisions and is currently on version 2.0\. More
    information about the ROM can be found here: [https://community.blueprism.com/content/rom-hub](https://community.blueprism.com/content/rom-hub).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ROM不是一个技术产品，但它仍然是BP与其竞争对手之间的一个关键差异化因素。任何从事RPA工作的人都应该熟悉ROM，特别是由于其指导是供应商无关的。随着技术和监管环境的变化，我们的管理框架也必须随之变化；ROM正在不断修订，目前处于2.0版本。有关ROM的更多信息，请参阅[https://community.blueprism.com/content/rom-hub](https://community.blueprism.com/content/rom-hub)。
- en: 'This new version of the ROM is organized into five foundations: **Strategy**,
    **Workforce**, **Design**, **Development**, and **Operations**. Each foundation
    is further subdivided into six subtopics, leading to 30 topics overall. While
    IA is certainly mentioned in the ROM, it isn’t one of the primary focuses. As
    a framework, the ROM is meant to provide general guidance, leaving us to fill
    in specifics. Trying to fill in these specifics was one of the main goals of my
    IA research, and you’ll find a number of my research results here. In this chapter,
    we’ll discuss how IA impacts the five ROM foundations so that you’re better prepared
    to tackle IA implementation in your organization:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这个ROM的新版本被组织成五个基础：**战略**、**劳动力**、**设计**、**开发**和**运营**。每个基础进一步细分为六个子主题，总共达到30个主题。虽然IA在ROM中确实被提及，但它并不是主要焦点。作为一个框架，ROM旨在提供一般性指导，让我们来填补具体细节。试图填补这些细节是我IA研究的主要目标之一，你在这里会找到我的许多研究成果。在本章中，我们将讨论IA如何影响ROM的五个基础，以便你更好地准备在你自己的组织中实施IA：
- en: Strategy
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 战略
- en: Workforce
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 劳动力
- en: Design
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计
- en: Development
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发展
- en: Operations
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运营
- en: Strategy
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 战略
- en: Three of the subtopics within the Strategy foundation are more heavily affected
    by IA. These are *Future of Work Vision*, *Business Case and Value*, and *Governance,
    Risk, and Controls*. The Future of Work Vision subtopic discusses the vision statement,
    mission statement, and objectives of the overall automation program. It also discusses
    the importance of having a communication plan in place to ensure that the IA vision
    is spread throughout the organization. Business Case and Value is about ensuring
    that IA is aligned with corporate strategy and that there are measurable KPIs
    to support that argument. Finally, Governance, Risk, and Controls discusses the
    governance board and the management of risk.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 战略基础中的三个子主题受到IA的影响更为明显。这些是*工作未来愿景*、*业务案例和价值*以及*治理、风险和控制*。工作未来愿景子主题讨论了整体自动化计划的愿景声明、使命声明和目标。它还讨论了制定沟通计划的重要性，以确保IA愿景在整个组织中传播。业务案例和价值是确保IA与公司战略一致，并支持该论点的可衡量KPI。最后，治理、风险和控制讨论了治理委员会和风险管理。
- en: Future of Work Vision
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作未来愿景
- en: If we’re looking to transition from RPA to IA, it’s important that the head
    of automation and executive sponsors explicitly update the vision to include this.
    For the more specific portions of the vision (mission statement and objectives),
    we can specify whether the focus should be placed on integrating pre-built ML
    services, such as API-based OCR, publicly available LLMs, and so on, or developing
    in-house expertise for building custom ML models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望从RPA过渡到IA，自动化负责人和执行赞助人明确更新愿景以包括这一点非常重要。对于愿景的更具体部分（使命声明和目标），我们可以指定是否应侧重于集成预构建的ML服务，如基于API的OCR、公开可用的LLMs等，还是开发内部专业知识以构建定制的ML模型。
- en: 'Setting up the vision to include IA would be best done for RPA teams that have
    been in operation for at least 1 or 2 years. This would be a minimum of level
    3 in the ROM Maturity Model: [https://community.blueprism.com/content/rom-hub/rom2-maturity-model](https://community.blueprism.com/content/rom-hub/rom2-maturity-model).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经运营至少1到2年的RPA团队，建立包含IA的愿景是最好的。这至少是ROM成熟度模型中的第3级：[https://community.blueprism.com/content/rom-hub/rom2-maturity-model](https://community.blueprism.com/content/rom-hub/rom2-maturity-model)。
- en: Business case and value
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业案例和价值
- en: As ML is a trending technology, no shortage of executive management wants to
    see it being used across their business. Despite executive support, we should
    still work out how IA can be measured as contributing to the overall corporate
    strategy. Commonly used KPIs, such as **full-time employee** (**FTE**) savings
    and hours returned to business, rely on quantifying how much time is saved by
    Digital Workers versus human workers. But for IA, the amount of time saved can
    be negligible – for instance, if we’re replacing an expert’s decision-making process
    that takes only minutes to perform. We may need to shift from time-based and dollar
    savings-based KPI measurements to *business-value-based* assessments. Examples
    of these can be found in the ROM 2 training materials.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ML是一种趋势技术，许多高管都希望看到它在整个业务中得到应用。尽管有高管的支持，我们仍然需要弄清楚如何衡量IA对整体企业战略的贡献。常用的关键绩效指标（KPI），如**全职员工**（**FTE**）节省和返还给业务的小时数，依赖于量化数字工作者与人工工作者节省的时间。但对于IA，节省的时间可能微不足道——例如，如果我们正在替换一个只需几分钟就能完成的专家决策过程。我们可能需要从基于时间和基于美元节省的KPI测量转向基于**业务价值**的评估。这些评估的例子可以在ROM
    2培训材料中找到。
- en: The **total cost of ownership** (**TCO**) also changes significantly with IA.
    We still have the traditional RPA costs, but we also have the costs of ML on top
    of that. Three primary scenarios lead to different ML costs on an IA project.
    The first case is if ML development is outsourced to a third party. This will
    likely have fixed and variable development costs. There are also possible ongoing
    service costs if the model is hosted by a third party. If the model is deployed
    back on-premises and managed completely by internal teams, there will still be
    internal ongoing costs. The second is consuming ML through an API service, which
    incurs per-transaction costs. These costs can be forecasted based on expected
    work volumes and the API pricing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: IA的**总拥有成本**（**TCO**）也会显著变化。我们仍然有传统的RPA成本，但还有ML的成本。三个主要场景导致IA项目上的ML成本不同。第一种情况是将ML开发外包给第三方。这可能会产生固定和可变开发成本。如果模型由第三方托管，还可能有持续的服务成本。如果模型在本地部署并由内部团队完全管理，仍将存在内部持续成本。第二种是通过API服务消费ML，这会产生每笔交易的成本。这些成本可以根据预期的作业量和API定价进行预测。
- en: The third scenario is if ML is developed in-house. Through cursory research,
    I found that deploying an in-house ML solution into production for the first time
    costs roughly 100,000 USD, excluding RPA costs. IA is similar to introducing any
    new technology, in that there are high costs for the first project, but the marginal
    costs decrease as more IA projects are deployed into production. Deciding to build
    ML in-house should be thought of as a multi-year endeavor, not as a one-off or
    pilot. The costs of in-house ML are mostly from salaries and renting hardware.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种情况是如果内部开发机器学习（ML）。通过初步研究，我发现第一次将内部ML解决方案部署到生产中大约需要100,000美元，不包括RPA成本。智能自动化（IA）与引入任何新技术类似，第一次项目的成本很高，但随着更多IA项目投入生产，边际成本会降低。决定内部构建ML应被视为一项多年努力，而不是一次性或试点项目。内部ML的成本主要来自薪资和硬件租赁。
- en: Outside of ML which is completely consumed through API calls, models will have
    ongoing costs as data and model performance need to be actively monitored, and
    models must be rebuilt. There may be costs related to hiring ML prediction reviewers
    as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 除了完全通过API调用消耗的ML之外，模型将会有持续的成本，因为需要积极监控数据和模型的表现，并且必须重建模型。还可能有与雇佣ML预测审查员相关的成本。
- en: Governance, Risk, and Controls
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 治理、风险和控制
- en: One way to think about IA governance is to take the governance concerns of RPA
    and add them to the governance of ML. On its own, ML governance is already a huge
    topic, so the *governance board* must have someone very familiar with productionizing
    ML and can keep up to date with the shifting regulatory environment surrounding
    it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑IA治理的一种方式是将RPA的治理关注点添加到ML的治理中。单独来看，ML治理已经是一个巨大的话题，因此*治理委员会*必须要有非常熟悉ML生产化并能够跟上其周围不断变化的监管环境的人。
- en: A starting point for the IA team to develop proper governance is to look internally
    for existing data and AI policies around data privacy, data retention, and security.
    We also need to consider whether the use of an ML model is advisable from a fairness
    and ethical perspective. Currently, very few companies have AI ethics policies
    in place. Some potential starting points for developing internal ethical guidelines
    are the *IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems*
    and the *Montreal Declaration for* *Responsible AI*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: IA团队发展适当治理的起点是内部寻找现有的数据隐私、数据保留和安全方面的数据和AI政策。我们还需要考虑从公平和伦理的角度来看，使用ML模型是否可取。目前，很少有公司已经建立了AI伦理政策。发展内部伦理指南的一些潜在起点包括*IEEE全球自主和智能系统伦理倡议*和*蒙特利尔负责任AI宣言*。
- en: Risks
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险
- en: IA has numerous risks associated with it that aren’t present in RPA. First,
    we need to *comply* with existing and upcoming laws around AI. As discussed in
    [*Chapter 4*](B18416_04.xhtml#_idTextAnchor062), nations are already developing
    laws to govern the use of AI in business.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: IA与RPA相比，存在许多与之相关的风险。首先，我们需要*遵守*与AI相关的现有和即将出台的法律。如[*第4章*](B18416_04.xhtml#_idTextAnchor062)中所述，各国已经在制定法律来规范商业中AI的使用。
- en: Another category of risks is *model-based*, with the primary one being low prediction
    accuracy. The performance of ML models is also known to degrade over time and
    certain types of ML algorithms are prone to adversarial attacks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一类风险是*基于模型的*，其中主要的一个是预测精度低。ML模型的表现也已知会随时间退化，某些类型的ML算法容易受到对抗性攻击。
- en: There are also *data-based* risks, which include data bias, data quality, and
    data drift. Data bias refers to data that has “undesirable properties,” such as
    when the collected data underrepresents certain populations when it shouldn’t.
    Data quality refers to the presence of “desirable properties,” such as having
    a sufficient number of samples and having features that are highly relevant to
    the prediction that we’re trying to make. Data drift refers to changes in the
    underlying input data distributions that occur naturally over time. An example
    of data drift can be seen in consumer purchasing behavior. Even among similar
    age and salary ranges, the types of items that people purchase today are different
    from what people purchased 10 years ago.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还存在*基于数据*的风险，包括数据偏差、数据质量和数据漂移。数据偏差指的是具有“不良属性”的数据，例如当收集的数据在不应代表某些群体时却未能充分代表。数据质量指的是存在“良好属性”，例如拥有足够的样本数量和具有与我们试图做出的预测高度相关的特征。数据漂移指的是随时间自然发生的底层输入数据分布的变化。数据漂移的一个例子可以在消费者购买行为中看到。即使在相似年龄和薪资范围内，今天人们购买的商品类型与10年前人们购买的商品类型不同。
- en: The next class of risks that can be reduced through ML governance has to do
    with *security and data access*. The introduction of new servers that host models,
    and new staff that must interact with data and models, increases the potential
    areas of attack that can target an IA solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过ML治理可以降低的下一类风险与*安全和数据访问*有关。引入新的服务器来托管模型，以及必须与数据和模型交互的新员工，增加了可以针对IA解决方案进行攻击的潜在攻击区域。
- en: Addressing risks through governance
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过治理应对风险
- en: Governance can help address all of the risks that were mentioned in the previous
    section. For *compliance risks*, governance can mandate that all IA solutions
    have a way to disable ML predictions (the kill switch we designed in [*Chapter
    6*](B18416_06.xhtml#_idTextAnchor093)), a preference for inherently interpretable
    algorithms, and a channel for customers to request that ML isn’t used when handling
    their cases.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 治理可以帮助解决上一节中提到的所有风险。对于*合规风险*，治理可以强制要求所有IA解决方案都有一种方法来禁用ML预测（我们在[*第6章*](B18416_06.xhtml#_idTextAnchor093)中设计的“终止开关”），偏好固有可解释的算法，并为客户提供一个渠道，让他们在处理他们的案件时请求不使用ML。
- en: ML governance can help reduce *model-based risks*. Governance can require that
    we implement formalized review and testing processes to ensure that a minimum
    proportion of predictions are correct before allowing a model to reach production.
    We might also mandate that general ML explainability methods, such as LIME and
    SHAP, are used to assess models before they’re put into production.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ML治理可以帮助减少*基于模型的风险*。治理可以要求我们实施正式的审查和测试流程，以确保在模型达到生产之前，至少有一定比例的预测是正确的。我们还可以强制要求在模型投入生产之前使用通用的ML可解释性方法，如LIME和SHAP来评估模型。
- en: Governance should define requirements around the continuous monitoring of model
    performance since models are known to lose predictive power over time. This includes
    collecting human-reviewed predictions for regular review and understanding how
    the frequencies of predicted labels for classification change over time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型随着时间的推移会失去预测能力，治理应该定义关于持续监控模型性能的要求。这包括收集经过人工审查的预测进行定期审查，并了解分类预测标签的频率随时间的变化。
- en: Governance can address *data risks* by implementing standards for data, and
    training requirements for data scientists. An example of establishing data quality
    might be to mandate that data must have a minimum of 1,000 samples per label,
    and that each row must have fewer than 5% missing columns. Governance can request
    data scientists to complete training around identifying data biases before allowing
    them to develop models for IA projects.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 治理可以通过实施数据标准和数据科学家培训要求来应对*数据风险*。建立数据质量的一个例子可能是强制规定数据必须至少有1,000个样本每个标签，并且每行必须少于5%的缺失列。治理可以要求数据科学家在允许他们为IA项目开发模型之前，完成关于识别数据偏差的培训。
- en: Governance can also set standards around the need to monitor data regularly.
    First, baseline statistics need to be gathered, usually from the training data.
    Some common statistics that are calculated include the mean, maximum, minimum,
    and standard deviations of data columns. Then, new statistics are regularly recalculated
    based on the input data used in production. Governance might mandate that this
    be done monthly and that any changes in data columns with more than one standard
    deviation be manually assessed or trigger the model to be rebuilt and deployed
    into production.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 治理还可以围绕定期监控数据的需求制定标准。首先，需要收集基线统计数据，通常来自训练数据。计算的一些常见统计数据包括数据列的平均值、最大值、最小值和标准差。然后，基于生产中使用的输入数据，定期重新计算新的统计数据。治理可能要求每月进行此操作，并对数据列中超过一个标准差的变化进行手动评估或触发模型重建并部署到生产中。
- en: For *security*, we need to amend the existing governance policies to define
    who can make changes to these IA components and the procedures for doing so. This
    can make use of the *ML Deployer* and *ML Reviewer* roles that were developed
    in [*Chapter 8*](B18416_08.xhtml#_idTextAnchor133).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了*安全*，我们需要修改现有的治理政策，以定义谁可以更改这些IA组件以及相应的程序。这可以利用在[*第8章*](B18416_08.xhtml#_idTextAnchor133)中开发的*ML
    Deployer*和*ML Reviewer*角色。
- en: Workforce
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人力资源
- en: For the workforce foundation, we will dive deeper into *Building Your Organizational
    Model*, *Adopting New Ways of Thinking and Working*, and *Roles and Career Paths*.
    Building Your Organizational Model discusses different ways that the IA function
    can be structured in a company. Some examples include IA as a central unit that
    serves everyone, individual IA teams within different business units, or IA being
    completely outsourced to a vendor. *Adopting New Ways of Thinking and* Working
    is about influencing the organization and overcoming resistance to get buy-in
    into IA. Finally, *Roles and Career Paths* is about which skillsets and roles
    are needed to create successful IA outcomes and ensure career progression within
    the IA team.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于劳动力基础，我们将更深入地探讨 *构建您的组织模型*、*采用新的思维和工作方式* 以及 *角色和职业道路*。构建您的组织模型讨论了 IA 功能在公司中可以采取的不同结构方式。一些例子包括
    IA 作为为所有人服务的中央单位，不同业务单元内的个人 IA 团队，或者 IA 完全外包给供应商。*采用新的思维和工作方式* 是关于影响组织并克服对 IA
    的阻力以获得支持。最后，*角色和职业道路* 是关于需要哪些技能集和角色来创造成功的 IA 结果并确保 IA 团队内的职业发展。
- en: Building your organizational model
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建您的组织模型
- en: Some of the main things to consider regarding the organization model are where
    ML expertise resides in the organization, how to engage with it, and whether ML
    expertise needs to be brought directly into the IA team. If the firm already has
    a centralized data science team, we have to consider their organizational model
    as well, and how they expect to provide ML expertise to the rest of the company.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于组织模型的一些主要考虑因素包括 ML 专业知识在组织中的位置，如何与之互动，以及是否需要直接将 ML 专业知识带入 IA 团队。如果公司已经有一个集中的数据科学团队，我们必须考虑他们的组织模型，以及他们期望如何向公司其他部门提供
    ML 专业知识。
- en: If the company is serious about IA, it’s expected that the automation team will
    have at least a few members who can perform data science work without relying
    on external teams. For the **Center of Excellence** (**COE**), *Franchise*, or
    *Hub and Spoke* organizational models, the central team should have in-house expertise
    that can productionize ML models. For *Divisional*, *Divisional Alliance*, and
    *Outsourced Managed Service* models, ML expertise can sit in those teams instead.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果公司对 IA 严肃认真，预计自动化团队至少会有几名成员能够执行数据科学工作，而不依赖于外部团队。对于 **卓越中心**（**COE**）、*特许经营*
    或 *中心和辐射* 组织模型，中央团队应拥有能够将 ML 模型投入生产的内部专业知识。对于 *部门*、*部门联盟* 和 *外包管理服务* 模型，ML 专业知识可以存在于那些团队中。
- en: Adopting new ways of thinking and working
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采用新的思维和工作方式
- en: It’s important to understand ways in which IA can be opposed by both *individual
    staff* and *management*. The adoption of IA will likely be more difficult to manage
    than RPA due to the widened scope of what can potentially be automated. During
    my research, I identified some important ways in which employees and management
    oppose IA adoption and some ways to counteract this opposition.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 理解 IA 可能受到 *个人员工* 和 *管理层* 反对的方式非常重要。由于潜在可自动化的范围扩大，IA 的采用可能比 RPA 更难管理。在我的研究中，我确定了员工和管理层反对
    IA 采用的一些重要方式以及一些对抗这种反对的方法。
- en: IA resistance at the employee level
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 员工层面的 IA 阻力
- en: IA can lead to a *loss of job meaning* if work that’s deemed meaningful to the
    employee is automated. A real-life example of this is replacing social workers’
    elderly benefit screening phone calls with chatbots and RPA. Interviews with the
    affected employees showed that they had lower job satisfaction post-automation.
    A questionnaire called the **Work and Meaning Inventory** (**WAMI**) can be used
    to establish whether employees have experienced a loss of job meaning after IA
    is implemented.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果认为对员工有意义的任务是自动化的，IA 可能会导致 *工作意义的丧失*。一个现实生活中的例子是用聊天机器人和 RPA 替换社会工作者对老年人的福利筛选电话。受影响的员工的访谈显示，他们在自动化后工作满意度较低。可以使用名为
    **工作与意义清单**（**WAMI**）的调查问卷来确定员工在 IA 实施后是否经历了工作意义的丧失。
- en: 'Job meaningfulness can be broken into four components: the *individual*, the
    *job*, the *organization*, and *society*. If we think that IA will reduce job
    meaningfulness for someone, we can try to counteract this by targeting improvements
    at these different levels. For instance, at an *individual* level, we could provide
    more flexibility and autonomy to affected staff by allowing work-from-home days.
    At the *job* level, we could change the significance, visibility, and scope of
    the work of the affected people. At the *organizational* level, we could increase
    the number of corporate social responsibility activities. A more practical approach
    would be to ask affected staff whether the proposed automation has the potential
    to reduce their job satisfaction and to avoid automating those areas.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 工作的意义可以分为四个组成部分：*个人*、*工作*、*组织*和*社会*。如果我们认为IA会降低某人的工作意义，我们可以通过针对这些不同层面的改进来对抗这种影响。例如，在*个人*层面，我们可以通过允许在家工作日来为受影响的员工提供更多的灵活性和自主性。在*工作*层面，我们可以改变受影响人员工作的意义、可见性和范围。在*组织*层面，我们可以增加企业社会责任活动的数量。更实际的方法是询问受影响的员工，所提出的自动化是否有可能降低他们的工作满意度，并避免自动化那些领域。
- en: Another risk that employees can encounter is *reduced work preparedness*. In
    one financial services firm, documents were digitized and automatically input
    into internal systems through IA, instead of being input by the case workers themselves.
    Removing the manual digitization and entry tasks meant that less time was spent
    looking at customer’s details. The affected staff felt more anxious and less prepared
    to directly interact with customers. Counteracting reduced work preparedness requires
    making access to data simpler or improving the presentation of the data through
    summary dashboards.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 员工可能遇到的其他风险是*工作准备度降低*。在一家金融服务公司，通过IA将文件数字化并自动输入到内部系统中，而不是由案件工作人员自己输入。移除手动数字化和输入任务意味着花在查看客户详细信息上的时间减少。受影响的员工感到更加焦虑，并且不太准备好直接与客户互动。对抗工作准备度降低需要简化数据访问或通过汇总仪表板改进数据的展示。
- en: IA potentially affects employees’ sense of overall *job security*. There are
    two parts to measuring job security. First, we can measure how “stable” an employee
    thinks their job is through a *Job Security Index* questionnaire. Next, we can
    measure the employee’s attitude, given how they view their level of job security,
    through the *Job Security Satisfaction scale*. If practical, we can engage HR
    to measure these before and after IA has been implemented, to determine whether
    there are job security concerns that need to be addressed.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: IA可能会影响员工对整体*工作安全感*的感觉。衡量工作安全感的两个方面包括：首先，我们可以通过*工作安全感指数*问卷来衡量员工认为他们的工作有多“稳定”；其次，我们可以通过*工作安全感满意度量表*来衡量员工的态度，即他们如何看待自己的工作安全感。如果可行，我们可以让人力资源部门在IA实施前后进行测量，以确定是否存在需要解决的工作安全感问题。
- en: If the goal of IA isn’t to reduce headcount, make “no job loss” an explicit
    message and publicize which measurable metrics will be used to evaluate the success
    of the IA program. One message that SS&C has put forward since implementing IA
    is not to cut jobs but to slow hiring down. If the goal is to cut jobs, training
    plans should be prepared to educate the staff that will be retained on how to
    work together with the digital workers. The job role definitions for staff should
    also be revised. These two actions can help reduce the perception of job insecurity.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果IA的目标不是减少员工人数，那么应明确传达“无岗位流失”的信息，并公布将用于评估IA项目成功与否的可衡量指标。SS&C自实施IA以来提出的一个信息是，不是裁员，而是减缓招聘。如果目标是裁员，应准备培训计划，教育将被保留的员工如何与数字工作者协作。还应修订员工的工作角色定义。这两项行动可以帮助减少对工作不安全的感知。
- en: A key to counteracting the potential negative impact on employees more broadly
    is developing an understanding of AI sentiment across the organization. In all
    companies, there will be people who support or want to work with AI technologies,
    and there will be those who don’t. The first rollouts of IA should target individuals
    or departments that view AI positively as this improves the odds of initial positive
    results, which can help convince other areas of the business of IA’s benefits.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 防止对员工产生更广泛负面影响的关键在于在整个组织中培养对AI情绪的理解。在所有公司中，都会有支持或希望与AI技术合作的人，也会有那些不支持的人。IA的首次推广应针对那些对AI持积极态度的个人或部门，因为这可以提高最初获得积极结果的几率，从而有助于说服业务的其他领域认识到IA的好处。
- en: IA resistance at the management level
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理层对IA的抵制
- en: IA may face *managerial resistance* as it’s often presented as a way to reduce
    headcount and costs. It’s natural for managers to be concerned about their budget,
    sphere of influence, and ability to meet KPIs if their headcount stays the same
    or is reduced. IA can lead managers to passively resist, stall, and even actively
    sabotage IA efforts. IA metrics that are gathered by uncooperative management
    teams will often be underreported to undermine IA.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: IA可能会面临*管理层抵制*，因为它通常被描绘为减少人员数量和成本的方式。如果管理层的人员数量保持不变或减少，他们自然会担心他们的预算、影响力范围以及达到KPI的能力。IA可能导致管理层被动抵制、拖延甚至积极破坏IA的努力。由不合作的管理团队收集的IA指标通常会低估，以破坏IA。
- en: Studies have been performed to understand management resistance to automation.
    *Senior management* opposition is mostly due to a lack of knowledge. *Middle management*,
    who directly supervise staff or processes that will be replaced by IA, have more
    nuanced reasons for opposition. In order of importance, these are being unconvinced,
    not having enough training, and worrying about their job importance. The fear
    of losing headcount was also directly mentioned as a major management concern.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解管理层对自动化的抵制，已经进行了研究。*高级管理层*的反对主要是因为缺乏知识。*中层管理层*，他们直接监督将被IA取代的员工或流程，对反对的原因更为复杂。按重要性排序，这些原因包括缺乏信心、培训不足和对工作重要性的担忧。失去人员数量的恐惧也被直接提及，作为管理层的主要担忧。
- en: The proposed ways of addressing managerial resistance in research are quite
    vague from a practical point of view. Suggestions to reduce resistance include
    education, using data to convince management, implementing change gradually, and
    training. One practical way of reducing the fear of headcount loss (assuming that
    it isn’t the primary goal of IA) is to explicitly ask managers to submit plans
    on what other value-added tasks staff will be performing post-IA implementation.
    Going through the motions of planning how their staff will be used after freeing
    up their time can help alleviate fears.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中提出的解决管理层抵制的方法在实践观点上相当模糊。减少抵制的建议包括教育、使用数据来说服管理层、逐步实施变革和培训。减少人员流失恐惧的一种实际方法（假设这不是IA的主要目标）是明确要求经理提交计划，说明IA实施后员工将执行的其他增值任务。规划如何利用他们的员工在释放他们的时间后使用，可以帮助缓解恐惧。
- en: Managers also worry that IA can trigger *employee turnover* and lower employee
    retention rates. There have been studies specifically about AI adoption, and its
    impact on employees. As expected, staff with negative attitudes toward AI are
    more likely to quit if AI is adopted. Again, we should understand how staff perceive
    AI and target use cases that affect employees with positive AI perceptions. Turnover
    intention is weakened when employees feel they have support from the company.
    This includes many things, including team building exercises, career planning,
    employee development, education, and more.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 经理们也担心IA可能会引发*员工流失*并降低员工的留存率。已有针对AI采纳及其对员工影响的具体研究。正如预期的那样，对AI持负面态度的员工在AI被采纳时更有可能离职。再次强调，我们应该了解员工对AI的看法，并针对那些对AI持正面看法的员工使用用例。当员工感到公司给予他们支持时，离职意向会减弱。这包括许多事情，如团队建设活动、职业规划、员工发展、教育等。
- en: Another key management fear is that of *financial loss*. This has been expressed
    in two main ways. The first is financial loss through litigation – for instance
    if someone belonging to a protected class feels they’ve been treated unfairly
    due to biases in an ML model and decides to pursue legal action. The second type
    of financial loss is from incorrect predictions, which lead to further incorrect
    processing. We can manage these fears by allowing management to review the governance
    that’s in place to select models for production use, select IA use cases, and
    review specific predictions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键的管理层担忧是*财务损失*。这主要体现在两个方面。首先是通过诉讼造成的财务损失——例如，如果属于受保护类别的某个人认为他们因为机器学习模型中的偏见而受到了不公平的对待，并决定采取法律行动。第二种类型的财务损失是由于预测错误导致的进一步错误处理。我们可以通过允许管理层审查现有的治理结构来管理这些担忧，以选择用于生产使用的模型，选择IA用例，并审查特定的预测。
- en: Roles and career paths
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 角色和职业路径
- en: If the overall strategy of the organization is to consume ML through APIs or
    other pre-built services, no changes need to be made to the roles that are needed
    on the team. Existing senior developers or team leads should already be equipped
    to handle these types of integrations. The exception to this is needing *ML reviewers*,
    but this role likely sits outside of the IA team, on the business side.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: However, if the strategy is to develop ML capability internally, a few new roles
    emerge. The first is the *IA data scientist*. This person will be responsible
    for analyzing data, building models, testing models, and evaluating them. I’d
    recommend hiring a person with these skills or borrowing this person from elsewhere
    in the organization instead of developing someone internally as the first data
    scientist. The main reason for this is that the time investment needed to become
    a data scientist is extremely long.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果策略是内部发展机器学习能力，将出现一些新的角色。第一个是*人工智能数据科学家*。这个人将负责分析数据、构建模型、测试模型以及评估它们。我建议雇佣具有这些技能的人，或者从组织内部的其他地方借用这个人，而不是首先内部培养数据科学家。主要原因是因为成为一名数据科学家所需的时间投资非常长。
- en: This data scientist can then build up a team of *IA developers*, which is a
    hybrid role between the data scientist and the automation developer. IA developers
    will start with a strong RPA base, and slowly build up their data science skills
    over time. IA developers should also keep up to date on what commercial ML services
    are available on the market. IA developers with enough experience can become full-fledged
    data scientists as a lateral career move.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据科学家可以组建一个由*IA开发者*组成的团队，这是一个介于数据科学家和自动化开发者之间的混合角色。IA开发者将从强大的RPA基础开始，并随着时间的推移逐渐建立起他们的数据科学技能。IA开发者还应关注市场上可用的商业机器学习服务。拥有足够经验的IA开发者可以通过横向职业发展成为全职数据科学家。
- en: An important question is who manages the ML infrastructure. As the IA initiative
    grows, we may need a dedicated *IA technical architect* to define the appropriate
    deployment method, manage deployments and rollbacks, monitor data, and manage
    other infrastructure concerns that support IA. Unlike the “traditional” RPA technical
    architect role, which often isn’t a full-time position, the IA technical architect
    will likely have enough work to eventually become full-time as the IA program
    grows, due to the ongoing management needs of ML models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的问题是，谁管理机器学习基础设施。随着人工智能（IA）项目的增长，我们可能需要一个专门的*人工智能技术架构师*来定义适当的部署方法，管理部署和回滚，监控数据，以及管理支持人工智能的其他基础设施问题。与通常不是全职职位的“传统”RPA技术架构师角色不同，由于机器学习模型持续的管理需求，人工智能技术架构师可能会因为人工智能项目的增长而有足够的工作量，最终可能成为全职职位。
- en: It’s unrealistic to expect that *citizen developers* will ever be able to build
    and deploy ML models. Citizen developers will eventually be able to use AutoML
    services (such as **Decision**, as discussed in [*Chapter 13*](B18416_13.xhtml#_idTextAnchor212)),
    and **LLMs**, although the use of LLMs has numerous challenges to overcome, such
    as dealing with hallucinated results, hallucinated confidence scores, and parsing
    an unstructured response. The *governance board* and *design authority* will need
    to set guidelines on how citizen developers can use AI.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 期望普通开发者能够构建和部署机器学习模型是不切实际的。普通开发者最终将能够使用AutoML服务（例如，在第13章中讨论的**Decision**），以及**大型语言模型**（LLMs），尽管使用LLMs存在许多挑战需要克服，例如处理幻觉结果、幻觉置信度分数以及解析非结构化响应。*治理委员会*和*设计权威机构*将需要制定关于普通开发者如何使用AI的指导方针。
- en: Design
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计
- en: In this section, we will dive deeper into the subtopics of *Assessment and Prioritization*,
    which discusses how to select IA processes for development, and *Requirements
    Design*, which discusses capturing the process steps and functional requirements
    of the business process.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更深入地探讨*评估和优先级排序*的子主题，该主题讨论如何选择开发IA流程，以及*需求设计*，该主题讨论捕捉业务流程的步骤和功能需求。
- en: Assessment and Prioritization
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估和优先级
- en: As part of the *assessment phase* of process discovery, a use case should have
    endorsement from an experienced data scientist as to whether the ML portion is
    even feasible or not, before moving on to process analysis. Part of the *analysis
    phase* should include either the POC-style development of an ML model or testing
    ready-to-use APIs to ensure that there’s sufficient accuracy (or other desired
    metrics) to warrant continuing with the IA use case. Again, there must be someone
    on the *governance board* who is experienced with ML to greenlight IA processes
    for development.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在流程发现过程的**评估阶段**，在使用案例进行分析之前，应该有一个经验丰富的数据科学家的背书，以确定机器学习部分是否可行。分析阶段的一部分应该包括ML模型的POC（原型）开发或测试现成的API，以确保有足够的准确性（或其他所需指标）来证明继续进行IA用例的合理性。再次强调，治理委员会上必须有一位对ML有经验的成员，以便批准IA开发流程。
- en: One important area to assess is how IA will *affect existing SLAs*. While we’d
    expect IA to increase the overall throughput of work that can be completed, the
    SLA might also include *quality-based targets*, which would depend on the accuracy
    of the model that’s used. An example of a quality-based target would be to maintain
    a customer satisfaction score above 3/5.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的评估领域是IA将如何**影响现有的SLA**。虽然我们预计IA会增加可以完成的工作的整体吞吐量，但SLA也可能包括基于**质量的目标**，这取决于所使用的模型的准确性。一个基于质量的目标示例是保持客户满意度评分在3/5以上。
- en: The introduction of new infrastructure to deploy ML also affects SLAs since
    it’s a new *source of downtime*. Many ML models are cloud-hosted on major cloud
    platforms, such as GCP, AWS, and Azure. In December 2021, AWS had multiple outages
    during the workday. Azure also had a major outage in January 2023\. If your model
    was hosted there at that time, there’s a chance that you’d have an SLA breach
    due to the ML model being unavailable.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 新基础设施的引入对部署机器学习（ML）也产生影响，因为它是一个新的**停机源**。许多机器学习模型托管在主要的云平台上，如GCP、AWS和Azure。2021年12月，AWS在工作日期间出现了多次故障。Azure在2023年1月也发生了重大故障。如果您的模型当时托管在这些平台上，那么由于机器学习模型不可用，您可能会违反服务等级协议（SLA）。
- en: Requirements Design
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需求设计
- en: Under IA, we need to help the business define requirements that didn’t exist
    before. For example, what are the *criteria to trigger the HITL review* of predictions?
    As seen in [*Chapter 4*](B18416_04.xhtml#_idTextAnchor062), this can include random
    sampling, different threshold values for different labels, or formula-based methods.
    The specific threshold values themselves don’t need to be picked yet as they should
    be chosen based on experimentation on the candidate models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在IA（智能自动化）方面，我们需要帮助业务定义之前不存在的要求。例如，触发预测的HITL（人类-机器交互）审查的**标准是什么**？如[第4章](B18416_04.xhtml#_idTextAnchor062)所示，这可以包括随机抽样、不同标签的不同阈值，或基于公式的方
    法。具体的阈值值本身还不必选择，因为它们应该基于候选模型的实验来选择。
- en: The business also needs to define *how prediction data will be presented to
    reviewers*, such as through Excel, a custom-developed website, or a database.
    Once a prediction is made, we need to know whether there’s a maximum allowable
    *delay between a completed prediction and human review* for SLA purposes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 业务还需要定义**如何向审阅者展示预测数据**，例如通过Excel、自定义开发的网站或数据库。一旦做出预测，我们需要知道是否存在一个最大允许的**完成预测与人工审查之间的延迟**，这对于SLA目的而言。
- en: There can also be requirements around the data and model itself. In some use
    cases, some data fields, such as age and gender, are protected and cannot be used
    in the model. If data is deemed *sensitive*, it likely can’t be sent outside the
    organization, removing online ML APIs from being considered in our solution design.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据和模型本身也可能有要求。在某些用例中，一些数据字段，如年龄和性别，受到保护，不能用于模型。如果数据被认为是**敏感的**，那么它可能不能发送到组织外部，这会排除在线机器学习API在我们的解决方案设计中被考虑。
- en: If models need to be *explainable*, this implies that certain types of regression
    and tree models should be favored. We also might have *desired algorithms* already
    in mind, such as deep learning, or LLMs, which impose hardware requirements (GPUs)
    on solutions. We also need to understand whether predictions are *time-sensitive*
    as this also informs the data scientists on which algorithms are possible and
    roughly what hardware requirements are needed to deploy a solution.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型需要**可解释性**，这意味着应该优先考虑某些类型的回归和树模型。我们可能已经考虑了**期望的算法**，如深度学习或LLM（大型语言模型），这会对解决方案提出硬件要求（GPU）。我们还需要了解预测是否**时间敏感**，因为这也会告知数据科学家哪些算法是可能的，以及部署解决方案的大致硬件需求。
- en: Development
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发
- en: The *Methodology and Teamwork* subsection is affected by IA as there’s a separate
    development cycle for ML models that runs in parallel to the traditional RPA development.
    In terms of *Delivery Controls*, having a high-enough quality model also often
    acts as a go-no-go decision toward continuing the development of the IA solution.
    Under IA, *Testing and Quality Assurance* never really stop as the ML model needs
    constant monitoring to ensure that quality levels are maintained.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法和团队合作**子部分受到IA的影响，因为ML模型有一个并行于传统RPA开发的独立开发周期。在**交付控制**方面，一个足够高质量的模型也常常作为继续开发IA解决方案的通过与否的决定因素。在IA下，**测试和质量保证**永远不会真正停止，因为ML模型需要持续的监控以确保质量水平得到维持。'
- en: Methodology and Teamwork
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法与团队合作
- en: ML model development is normally independent of RPA development. While BP has
    a six-phase delivery methodology (Define, Design, Build, Test, UAT, and Deploy),
    this isn’t exactly applicable to ML model building. For example, many ML model
    development methodologies have data analysis and refinement phases, which aren’t
    needed in RPA.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型开发通常独立于RPA开发。虽然BP有六个阶段的交付方法（定义、设计、构建、测试、UAT和部署），但这并不完全适用于机器学习模型构建。例如，许多机器学习模型开发方法都有数据分析和完善阶段，这些在RPA中是不需要的。
- en: If the ML model is built by a different team, we don’t need to think too much
    about what particular ML methodology is being used. However, if ML is being built
    internally, the IA team should look to standardize their ML model development
    approach. There are many examples of this online – for example, from AWS ([https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html))
    and GCP ([https://cloud.google.com/blog/products/ai-machine-learning/making-the-machine-the-machine-learning-lifecycle](https://cloud.google.com/blog/products/ai-machine-learning/making-the-machine-the-machine-learning-lifecycle)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果机器学习模型是由不同的团队构建的，我们不需要过多考虑正在使用什么特定的机器学习方法。然而，如果机器学习是内部构建的，IA团队应该寻求标准化他们的机器学习模型开发方法。网上有许多这样的例子——例如，来自AWS
    ([https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html))
    和 GCP ([https://cloud.google.com/blog/products/ai-machine-learning/making-the-machine-the-machine-learning-lifecycle](https://cloud.google.com/blog/products/ai-machine-learning/making-the-machine-the-machine-learning-lifecycle))。
- en: It’s normal for the ML model development life cycle to begin before the *Process
    Definition Document* is finalized, especially for gathering and analyzing training
    data. During the *Design* phase of development, we need to work with the data
    scientists to choose the interface between the ML model and BP, whether that be
    Web API calls, executables, programmatic scripts, or Code Stages. We also need
    the data scientists to provide different examples of prediction responses so that
    they can be mocked in BP. This allows RPA developers to test their work locally,
    even if the ML program isn’t ready yet. The functional requirements should also
    be discussed, such as required SLAs, response times, whether we can send prediction
    requests in batch, and so on. This should all be documented in the *Solution*
    *Design Document*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型开发的生命周期在**流程定义文档**最终确定之前开始是很正常的，尤其是在收集和分析训练数据时。在开发的**设计**阶段，我们需要与数据科学家合作，选择机器学习模型与BP之间的接口，无论是Web
    API调用、可执行文件、程序脚本还是代码阶段。我们还需要数据科学家提供不同的预测响应示例，以便在BP中进行模拟。这允许RPA开发者即使机器学习程序尚未准备好，也能在本地测试他们的工作。还应该讨论功能需求，例如所需的SLA、响应时间、我们是否可以批量发送预测请求等。所有这些都应该记录在**解决方案设计文档**中。
- en: It’s often the case that for the first few initial IA projects, the RPA team
    needs to borrow expertise from elsewhere in the organization. If data scientists
    aren’t fully dedicated to the project, there’s a risk that work on the IA project
    will be deprioritized and delivery timelines get pushed back.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最初的几个IA项目，RPA团队通常需要从组织内部的其他地方借用专业知识。如果数据科学家没有完全致力于项目，IA项目的工作可能会被降级，交付时间表可能会推迟。
- en: The *Design Authority* should have someone who has hands-on experience developing
    models. If models are developed internally, thought needs to be put into whether
    a model can be designed to be reused across multiple IA use cases, or whether
    models must remain separate. Part of the Design Authority’s work will be extended
    to keep track of what ML models are being used and where.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 设计权威机构应有一名具有实际开发模型经验的成员。如果模型是内部开发的，需要考虑模型是否可以设计为跨多个IA用例重用，或者模型是否必须保持独立。设计权威机构的工作部分将扩展到跟踪正在使用的机器学习模型及其应用位置。
- en: Delivery Controls
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交付控制
- en: During the *Build* phase of RPA or the equivalent ML development stage, we need
    to keep in mind that insufficient prediction accuracy can lead to a no-go decision
    in terms of continuing development on the overall IA solution. In a sense, the
    progress of ML model development should be slightly ahead of RPA development to
    minimize the risk of wasted development work.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在RPA或等效机器学习开发阶段的构建阶段，我们需要记住，预测精度不足可能导致在整体IA解决方案的开发方面做出不继续开发的决策。从某种意义上说，机器学习模型开发应略领先于RPA开发，以最大限度地减少开发工作浪费的风险。
- en: The UAT of the ML model is likely to be done completely separately from RPA.
    Completion of ML model UAT should be part of the entrance criteria before starting
    the RPA UAT.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的用户验收测试可能完全独立于RPA进行。机器学习模型UAT的完成应作为开始RPA UAT前的入门标准之一。
- en: Testing and Quality Assurance
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试和质量保证
- en: During the UAT of the ML model, it’s important to capture the predicted result
    and the confidence scores. This data is needed to help us calibrate the appropriate
    confidence scores needed for different labels, in case thresholding is used to
    determine whether human review is needed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习模型的用户验收测试（UAT）期间，捕捉预测结果和置信度得分非常重要。这些数据有助于我们校准不同标签所需的适当置信度得分，以防使用阈值来确定是否需要人工审查。
- en: One of the main differences between IA and RPA is that ML model QA never really
    stops. An ML operations team should monitor the results of ML predictions regularly
    to detect potential drift.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: IA与RPA之间的主要区别之一是机器学习模型的质量保证（QA）永远不会真正停止。机器学习运营团队应定期监控机器学习预测的结果，以检测潜在的漂移。
- en: Operations
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运营
- en: IA affects *Deploy and Release*, as ML deployments are expected to be done even
    if there are no changes to the business logic (Process) or applications (Objects).
    The *Support Model* has numerous changes as the addition of ML brings in numerous
    ongoing operations that need to be performed, including monitoring models, monitoring
    data, exporting HITL review results, and more.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 智能分析（IA）会影响部署和发布，因为即使业务逻辑（流程）或应用程序（对象）没有发生变化，也预期会进行机器学习部署。由于机器学习的加入带来了许多需要执行的操作，包括监控模型、监控数据、导出HITL审查结果等，因此支持模型有众多变更。
- en: Deploy and Release
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署和发布
- en: As we saw in the previous chapter, ML models are expected to be deployed regularly
    into production, on a schedule that’s independent from Process and Object updates.
    The deployment methodology that’s used for the ML model informs the Control Room
    operators of how the overall IA solution must be updated, to maintain auditability,
    and also how to roll back in case there’s an issue with the newly deployed model.
    It’s recommended to choose a deployment method that doesn’t require downtime to
    roll back and for the prediction response of the model to return the model version
    that was used to make the prediction, for auditing purposes. Deploying new ML
    models should also require a formal change request, which requires approval.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，机器学习模型应定期部署到生产环境中，部署时间表应独立于流程和对象更新。用于机器学习模型的部署方法应通知控制室操作员如何更新整体智能分析（IA）解决方案，以保持可审计性，以及如何在部署的新模型出现问题时进行回滚。建议选择一种不需要停机即可回滚的部署方法，并且模型的预测响应应返回用于做出预测的模型版本，以便进行审计。部署新的机器学习模型还应需要正式的变更请求，并需获得批准。
- en: Support model
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持模型
- en: IA brings significant additions to the support model. We now have to worry about
    the uptime of the ML model (business continuity), ensuring the accuracy of the
    ML model (this can be assessed through random sampling), and potentially the SLAs
    for human review. Each ML model will have their own ML reviewers, who potentially
    also need training and access to BP as they might be manually changing the Statuses
    of Work Queue Items or editing Session Variables to recreate review data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: IA（智能代理）为支持模型带来了重大补充。我们现在必须担心ML模型的正常运行时间（业务连续性），确保ML模型的准确性（这可以通过随机抽样进行评估），以及可能的人类审查的SLA（服务等级协议）。每个ML模型都将有自己的ML审查员，他们可能也需要培训和访问BP（业务流程），因为他们可能会手动更改工作队列项的状态或编辑会话变量以重新创建审查数据。
- en: If the ML models are maintained within the IA team, the models and their data
    will need constant monitoring to prevent performance degradation and data drifts.
    This is usually done through web-based dashboards that read ML server logs. This
    works if ML is deployed through Web APIs, but not if models are called through
    the CLI or Code Stages. In this case, the support model needs to include exporting
    ML results, from the Work Queue or Session Logs, to data scientists for analysis,
    and ingestion into monitoring systems. Regardless of the method used by BP to
    make the ML prediction, we still need to feedback information regarding reviewed
    predictions to the data scientists as that data isn’t present in ML API server
    logs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ML模型由IA团队维护，模型及其数据需要持续监控，以防止性能下降和数据漂移。这通常是通过基于Web的仪表板完成的，该仪表板读取ML服务器日志。如果ML通过Web
    API部署，则这种方法有效，但如果模型是通过CLI（命令行界面）或代码阶段调用，则不适用。在这种情况下，支持模型需要包括从工作队列或会话日志中导出ML结果，供数据科学家进行分析，并将其纳入监控系统中。无论BP使用何种方法进行ML预测，我们仍然需要将关于已审查预测的信息反馈给数据科学家，因为该数据不在ML
    API服务器日志中。
- en: Monitoring data and models can lead to *regular updates and deployments of ML
    models*. Other concerns, such as updates to the ML libraries, the addition of
    new training data received by the HITL reviews, or experimentation with new algorithms,
    can also lead to model updates. Changes in business logic can also trigger changes
    to the ML model. The IA support team needs to become very familiar with deploying
    new models into production.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 监控数据和模型可能导致ML模型的*定期更新和部署*。其他关注点，如ML库的更新、通过HITL（人机交互学习）审查接收到的新的训练数据，或对新算法的实验，也可能导致模型更新。业务逻辑的变化也可能触发ML模型的更改。IA支持团队需要非常熟悉将新模型部署到生产环境中。
- en: Another major concern (related to referral handling and exception handling,
    although it isn’t directly one of the two) is something called *time lag effects*.
    Imagine that we’re a bank that’s using ML to determine whether an account opening
    application is fraudulent or not. If the ML model is flawed, many fraudulent account
    creation requests will be processed further, with the data being sent to many
    other systems. Thousands of account opening applications might have been processed
    before the model flaw was detected. The amount of work that needs to be undone
    or corrected between making an incorrect ML prediction, and discovering it, is
    a time lag effect.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主要关注点（虽然它与引用处理和异常处理相关，但并不是这两者之一）是所谓的*时间滞后效应*。想象一下，我们是一家使用机器学习（ML）来判定账户开立申请是否欺诈的银行。如果ML模型存在缺陷，许多欺诈性账户创建请求将被进一步处理，数据将被发送到许多其他系统。在模型缺陷被检测到之前，可能已经处理了数千个账户开立申请。在做出错误的ML预测和发现它之间需要撤销或纠正的工作量，就是时间滞后效应。
- en: Issues with time lag are inevitable unless the ML model is perfect. The support
    model needs to consider how to deal with individual cases – for example, if a
    business user flags a case where an incorrect ML prediction has led to incorrect
    processing. The support model also needs to deal with batch cases, which can be
    caused by flawed ML models. It might even be necessary to create a separate automated
    process specifically to undo the steps that were performed by the IA solution
    post-prediction.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除非ML模型完美无缺，否则时间滞后问题是不可避免的。支持模型需要考虑如何处理个别案例——例如，如果业务用户标记了一个由错误的ML预测导致错误处理的案例。支持模型还需要处理批量案例，这些案例可能是由有缺陷的ML模型引起的。甚至可能需要创建一个专门的自动化流程，专门用于撤销IA解决方案在预测后执行的操作。
- en: The support model should try to address *how liability should be assigned* to
    a prediction that has led to losses of some sort. At some point, a person or a
    team will need to be held responsible for the incorrect processing caused by an
    incorrect ML prediction. Is it someone on the IA team or the data science team?
    Is it the business users who have signed off on the model testing results? Is
    it the reviewers (assuming that the prediction in question has been reviewed)?
    This is something that needs to be agreed on by all parties before finger-pointing
    occurs.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 支持模型应尝试解决*如何分配预测责任*的问题，该预测导致某种形式的损失。在某个时候，需要有人或团队对由错误的机器学习预测引起的错误处理负责。是IA团队或数据科学团队的人？是签署了模型测试结果批准的业务用户？是审查员（假设所讨论的预测已被审查过）？这是在指责发生之前所有各方需要达成一致的事项。
- en: ML liability is an active area of legal research. I’ve found that legal experts
    believe that the company that makes use of the prediction will be held liable,
    even if the ML model development is completely outsourced. While the company that
    makes use of the prediction can try to seek legal damages against the third party,
    it’s almost impossible to prove that the algorithm is defective.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习责任是法律研究的一个活跃领域。我发现法律专家认为，使用预测的公司将被追究责任，即使机器学习模型开发完全外包。虽然使用预测的公司可以尝试寻求对第三方提起法律诉讼，但几乎不可能证明算法有缺陷。
- en: An intuitive assignment of liability would be to a person or team that maintains
    the model or has reviewed the prediction, but both of these can potentially be
    outsourced. If those functions have been outsourced, the next intuitive liability
    assignment would go to the business users who have signed off on the model after
    UAT.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对责任归属的直观分配可能是给维护模型或审查预测的个人或团队，但这两者都可能被外包。如果这些功能已经被外包，那么下一个直观的责任分配将转向在UAT（用户验收测试）后签署模型批准的业务用户。
- en: Finally, if the IA practice is advanced, it’s worth looking into implementing
    some generic *ML interpretability methods*, such as LIME and SHAP. While these
    interpretability algorithms are most often thought of as an auditing step before
    deploying a model into production, they can also find some use in helping the
    IA team investigate problematic predictions for the business users and find ways
    to tweak the model to avoid them in the future.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果IA（可解释人工智能）实践较为先进，那么实施一些通用的*机器学习可解释性方法*是值得考虑的，例如LIME和SHAP。虽然这些可解释性算法通常被认为是在将模型部署到生产之前的一个审计步骤，但它们也可以在帮助IA团队调查对业务用户有问题的预测以及找到避免未来出现这些问题的模型调整方法时发挥作用。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The BP ROM is a framework and methodology that guides the entire automation
    program. Having a good understanding of the ROM significantly improves the odds
    of reaching your automation goals and scaling your Digital Workforce more quickly.
    While the ROM is an invaluable resource, it doesn’t provide specific guidance
    on how to add ML predictions to your RPA processes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: BP ROM是一个框架和方法论，指导整个自动化程序。对ROM有良好的理解可以显著提高实现自动化目标并更快地扩展数字工作力的可能性。虽然ROM是一个无价的资源，但它不提供如何将机器学习预测添加到RPA流程的具体指导。
- en: In this chapter, I went through the five ROM 2 foundations and discussed the
    subtopics that are the most heavily affected by moving from RPA to IA. The discussion
    was informed by my IA research findings and my experience in ML. IA mainly affects
    the ROM by adding a separate set of ML concerns on top of existing RPA ones.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我介绍了ROM 2的五个基础，并讨论了从RPA转向IA最受影响的子主题。讨论是基于我的IA研究发现和我在机器学习方面的经验。IA主要通过在现有的RPA问题之上增加一套独立的机器学习关注点来影响ROM。
- en: That concludes this chapter on the management aspects of BP. In the next chapter,
    we’ll consolidate what we’ve learned in this book by examining two real-life use
    cases.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了关于BP（业务流程自动化）管理方面的章节。在下一章中，我们将通过考察两个真实案例来巩固本书所学的内容。
- en: Part 4:Real-Life Scenarios and Other Blue Prism Products
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4部分：真实场景和其他Blue Prism产品
- en: In *Part 4*, we’ll consolidate the contents of *Part 2* and *Part 3* of this
    book by examining two scenarios that are modeled on real-life use cases. [*Chapter
    11*](B18416_11.xhtml#_idTextAnchor179) describes an IA use case with three different
    ML models. Here, we’ll analyze the ML model requirements to select a proper solution
    design and implement the solution structure by using the IA process templates
    developed in [*Chapter 7*](B18416_07.xhtml#_idTextAnchor114).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4部分*中，我们将通过考察两个基于现实案例的情景，来整合本书的*第2部分*和*第3部分*的内容。[第11章](B18416_11.xhtml#_idTextAnchor179)描述了一个包含三个不同机器学习模型的IA用例。在这里，我们将分析机器学习模型的要求，以选择合适的设计方案，并通过使用[第7章](B18416_07.xhtml#_idTextAnchor114)中开发的IA流程模板来实施解决方案结构。
- en: '[*Chapter 12*](B18416_12.xhtml#_idTextAnchor196) describes a different use
    case, where ML auditability is of primary concern. Here, we’ll go through examples
    of how to deploy a new version of the ML model and roll back. We’ll also look
    at how to extract ML auditing data through the BP database.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](B18416_12.xhtml#_idTextAnchor196)描述了一个不同的用例，其中机器学习可审计性是首要关注点。在这里，我们将通过实例说明如何部署机器学习模型的新版本以及如何回滚。我们还将探讨如何通过BP数据库提取机器学习审计数据。'
- en: Throughout the book, we’ve only discussed the main BP product. There are numerous
    other products in the BP ecosystem that are also directly or indirectly related
    to IA. [*Chapter 13*](B18416_13.xhtml#_idTextAnchor212) describes these additional
    products, their purposes, and how they can be used for IA. Finally, we conclude
    the book by discussing three future IA trends.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们只讨论了主要的BP产品。BP生态系统中还有许多其他产品，它们也与IA直接或间接相关。[第13章](B18416_13.xhtml#_idTextAnchor212)描述了这些附加产品、它们的目的以及如何用于IA。最后，我们通过讨论三个未来的IA趋势来结束本书。
- en: 'This part contains the following chapters:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 11*](B18416_11.xhtml#_idTextAnchor179), *Processing Refunds*'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第11章](B18416_11.xhtml#_idTextAnchor179)，*处理退款*'
- en: '[*Chapter 12*](B18416_12.xhtml#_idTextAnchor196), *Power Service Interruptions*'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第12章](B18416_12.xhtml#_idTextAnchor196)，*电力服务中断*'
- en: '[*Chapter 13*](B18416_13.xhtml#_idTextAnchor212), *Other Intelligent Blue Prism
    Products*'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第13章](B18416_13.xhtml#_idTextAnchor212)，*其他智能蓝宝石产品*'
- en: '*Appendix, IA Risk Management*'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*附录，IA风险管理*'
