- en: Chapter 7. Social Media Analysis – Analyzing Twitter Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 社交媒体分析 – 分析Twitter数据
- en: Connected is the word that describes life in the 21^(st) century. Though various
    factors contribute to the term connected, there's one aspect which has played
    a pivotal role. It's called the Web. The Web, which has made distance an irrelevant
    metric and blurred socio-economic boundaries, is a world in itself and we all
    are a part of it. The Web or Internet in particular has been a central entity
    in this data-driven revolution. As we have seen in our previous chapters, for
    most modern day problems, it is the Web/Internet (henceforth used interchangeably)
    that acts as a source of data. Be it e-commerce platforms or financial domain,
    the Internet provides us with huge amounts of data every second. There's another
    ocean of data within this virtual world which touches our lives at a very personal
    level. Social networks, or social media, is a behemoth of information and the
    topic for this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “连接”是描述21世纪生活的词汇。尽管有许多因素促成了这个术语，但有一个方面发挥了关键作用。那就是网络。网络使距离变得无关紧要，模糊了社会经济界限，它本身就是一个世界，我们都是其中的一部分。特别是网络或互联网在这个数据驱动革命中是一个核心实体。正如我们在前面的章节中看到的，对于大多数现代问题，网络/互联网（以下将互换使用）是数据来源。无论是电子商务平台还是金融领域，互联网每秒都为我们提供大量数据。在这个虚拟世界中，还有另一个数据海洋，它以非常个人化的方式触及我们的生活。社交网络，或社交媒体，是信息巨无霸，也是本章的主题。
- en: In the previous chapter, we covered the financial domain, where we analyzed
    and predicted credit risk for customers of a certain bank. We now shift gears
    and move into the realm of social media and see how machine learning and R empower
    us to uncover insights from this ocean of data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了金融领域，在那里我们分析了并预测了某家银行客户的信用风险。我们现在转换方向，进入社交媒体领域，看看机器学习和R如何使我们能够从这个数据海洋中揭示洞察力。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Data mining specifics for social networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交网络的数据挖掘具体方法
- en: The importance and use of different data visualizations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同数据可视化的重要性和用途
- en: An overview of how to connect and collect Twitter data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何连接和收集Twitter数据的概述
- en: Utilizing Twitter data to uncover amazing insights
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Twitter数据揭示惊人的洞察力
- en: Seeing how social networks pose new challenges to the data mining process
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看社交网络如何对数据挖掘过程提出新的挑战
- en: Social networks (Twitter)
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 社交网络（Twitter）
- en: We all use social networks day in and day out. There are numerous social networks
    catering to all sorts of ideologies and philosophies, but Facebook and Twitter
    (barring a couple more) have become synonymous with the term social network itself.
    These two social networks enjoy popularity not only because of their uniqueness
    and the quality of service but because of the way they enable us to interact in
    a very intuitive way. As we saw with recommendation engines used in e-commerce
    websites (see [Chapter 4](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 4. Building a Product Recommendation System"), *Building a Product Recommendation
    System*), social networks have existed long before Facebook, Twitter, or even
    the Internet.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每天都使用社交网络。有无数社交网络迎合各种意识形态和哲学，但Facebook和Twitter（除少数几个外）已经成为社交网络本身的同义词。这两个社交网络之所以受欢迎，不仅因为它们的独特性和服务质量，还因为它们使我们能够以非常直观的方式互动。正如我们在电子商务网站中使用的推荐引擎（见[第4章](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8
    "第4章 建立产品推荐系统")）所看到的，“建立产品推荐系统”，社交网络在Facebook、Twitter甚至互联网出现之前就已经存在。
- en: Social networks have interested scientists and mathematicians alike. It is an
    interdisciplinary topic which spans but is not limited to sociology, psychology,
    biology, economics, communication studies, and information science. Various theories
    have been developed to analyze social networks and their impact on human lives
    in the form of factors influencing economics, demographics, health, language,
    literacy, crime, and more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络对科学家和数学家都产生了兴趣。这是一个跨学科的话题，它跨越但不限于社会学、心理学、生物学、经济学、传播学和信息科学。已经发展出各种理论来分析社交网络及其对人类生活的影响，这些影响以影响经济、人口统计、健康、语言、读写能力、犯罪等因素的形式出现。
- en: Studies done as early as the late 1800s form the basis of what we today refer
    to as social networks. A social network, as the word itself says, is a sort of
    connection/network between nodes or entities represented by humans and elements
    affecting social life. More formally, it is a network depicting relationships
    and interactions. Hence, it is not surprising to see various graph theories and
    algorithms being employed to understand social networks. Where the 19^(th) and
    20^(th) centuries were limited to theoretical models and painstaking social experiments,
    the 21^(st) century's technology has opened the doors for these theories to be
    tested, fine tuned, and modeled to help understand the dynamics of social interactions.
    Though testing these theories by some social networks (called social experiments)
    have been caught in controversies, such topics are beyond the scope of this book.
    We shall limit ourselves to the algorithmic/data science space and leave the controversies
    for the experts to discuss.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 早在19世纪末进行的研究构成了我们今天所说的社会网络的基础。正如其词本身所表明的，社会网络是节点或实体之间的一种连接/网络，这些节点或实体由人类和影响社会生活的元素所代表。更正式地说，它是一个描绘关系和互动的网络。因此，看到各种图理论和算法被用来理解社会网络并不令人惊讶。在19世纪和20世纪，这些理论仅限于理论模型和艰苦的社会实验，而21世纪的技术为这些理论的测试、微调和建模打开了大门，以帮助理解社会互动的动态。尽管通过某些社会网络（称为社会实验）测试这些理论引起了争议，但这些话题超出了本书的范围。我们将限制自己在算法/数据科学领域，并将争议留给专家讨论。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: The Milgram Experiment, or the small world experiment, was conducted in the
    late 1960s to examine the average path length for people in United States. As
    part of this experiment, random people were selected as starting points of a mail
    chain. These random people were tasked to send the mail to the next person so
    that the mail gets one step closer to its destination (somewhere in Boston) and
    so on. An average of six hops to the destination is the documented result of this
    famous experiment. Urban folklore suggests the phrase *6 degrees of separation*
    originated from this experiment, even though Dr. Milgram never used the term himself!
    He conducted many more experiments; search and be amazed.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 米尔格拉姆实验，或称为小世界实验，是在20世纪60年代末进行的，旨在考察美国人的平均路径长度。作为该实验的一部分，随机挑选的人被选为邮件链的起点。这些随机挑选的人被要求将邮件发送给下一个人，以便邮件更接近其目的地（波士顿某地），依此类推。这个著名实验记录的平均跳数是六步。都市传说表明，“六度分隔”这个短语起源于这个实验，尽管米尔格拉姆博士本人从未使用过这个术语！他进行了许多更多的实验；去搜索并惊叹吧。
- en: 'Source:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：
- en: '[http://www.simplypsychology.org/milgram.html](http://www.simplypsychology.org/milgram.html)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.simplypsychology.org/milgram.html](http://www.simplypsychology.org/milgram.html)'
- en: Before we jump into the specifics, let us try and understand the reason behind
    choosing Twitter as our point of analysis for this and the upcoming chapter. Let
    us begin with understanding what Twitter is and why is it so popular with both
    end users and data scientists alike.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入具体内容之前，让我们尝试理解选择Twitter作为本章节和下一章节分析点的理由。让我们从了解Twitter是什么以及为什么它对终端用户和数据科学家都如此受欢迎开始。
- en: Twitter, as we all know, is a social network/micro-blogging service that enables
    its users to send and receive tweets of a maximum of 140 characters. But what
    makes Twitter so popular is the way it caters to the basic human instincts. We,
    humans, are curious creatures with an incessant need to be heard. It is important
    for us to have someone or some place to voice our opinions. We love to share our
    experiences, feats, failures, and ideas. At some level or other, we also want
    to know what our peers are up to, what's keeping celebrities busy, or simply what's
    on the news. Twitter addresses just that.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，Twitter是一个社交网络/微博服务，它允许用户发送和接收最多140个字符的推文。但使Twitter如此受欢迎的是它满足基本的人类本能的方式。我们人类是好奇的生物，有着不断被听到的需求。对我们来说，有一个地方或某个人可以表达我们的观点是很重要的。我们喜欢分享我们的经历、成就、失败和想法。在某种程度上，我们也想知道我们的同龄人在做什么，名人忙于什么，或者新闻上有什么。Twitter正是解决了这些问题。
- en: With multiple social networks existing long before Twitter came into existence,
    it wasn't some other service which Twitter replaced. In our view, it was the way
    Twitter organized the information and its users that clicked. Its unique *Follow*
    model of relationship caters to our hunger for curiosity, while its short, free,
    and high-speed communication platform enables the users to speak out and be heard
    globally. By allowing users to follow a person or an entity of interest, it enables
    us to keep up with their latest happenings without the other user following us
    back. The *Follow* model tips Twitter's relationships towards more of an interest
    graph rather than the friendship model usually found in social networks such as
    Facebook.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter出现之前，就已经存在多个社交网络，Twitter并没有取代其他服务。在我们看来，是Twitter组织信息和用户的方式吸引了人们的注意。其独特的*关注*关系模型满足了我们对好奇心的渴望，而其简短、免费、高速的通信平台使用户能够发声并被全球听到。通过允许用户关注感兴趣的人或实体，它使我们能够跟上他们的最新动态，而无需其他用户反过来关注我们。*关注*模型使Twitter的关系更倾向于兴趣图谱，而不是像Facebook这样的社交网络中通常发现的友谊模式。
- en: Twitter is known and used across the globe for the super-fast spread of information
    (and rumors). It has been innovatively used in certain circumstances unimaginable
    before, such as finding people in times of natural calamities such as earthquakes
    or typhoons. It has been used to spread information so far and deep that it takes
    viral proportions. The asymmetric relationships and high speed information exchange
    aid in making Twitter such a dynamic entity. If we closely analyze and study the
    data and dynamics of this social network we can uncover many insights. Hence,
    it is the topic for this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter因其信息（以及谣言）的超级快速传播而闻名并被全球使用。在某些以前无法想象的情况下，它被创新地使用，例如在地震或台风等自然灾害时期寻找人们。它被用来传播信息，范围之广，深度之深，以至于达到了病毒般的规模。不对称的关系和高速度的信息交换有助于使Twitter成为一个如此动态的实体。如果我们仔细分析和研究这个社交网络的数据和动态，我们可以揭示许多见解。因此，它是本章的主题。
- en: Note
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Interesting links**:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的链接**:'
- en: '[https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/](https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/](https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/)'
- en: '[http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/](http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/](http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/)'
- en: '[https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true](https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true](https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true)'
- en: '[http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123](http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123](http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123)'
- en: '[http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully](http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully](http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully)'
- en: 'Let''s apply some data science to tweets using #RMachineLearningByExample!'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用#RMachineLearningByExample!来对推文应用一些数据科学！
- en: Data mining @social networks
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘 @社交网络
- en: We have traveled quite a distance so far through the chapters of this book,
    understanding various concepts and learning some amazing algorithms. We have even
    worked on projects that have applications in our daily lives. In short, we have
    done data mining without using the term explicitly. Let us now take this opportunity
    to formally define data mining.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过这本书的章节走过了很长的路，理解了各种概念，并学习了一些令人惊叹的算法。我们甚至参与了在我们的日常生活中有应用的项目。简而言之，我们已经在没有明确使用术语的情况下进行了数据挖掘。现在，让我们抓住这个机会，正式定义数据挖掘。
- en: 'Mining, in the classical sense of the word, refers to the extraction of useful
    minerals from the Earth (such as coal mining). Put in the context of the information
    age, mining refers to the extraction of useful information from large pools of
    data. Thus, if we look carefully, **Knowledge** **Mining** or **Knowledge Discovery
    from** **Data** (**KDD**) seems to be a better representation than the term data
    mining. As is the case with many keywords, short and sweet catches the attention.
    Thus, you may find in many places the terms Knowledge Discovery from Data and
    data mining being used interchangeably, which is rightly so. The process of data
    mining, analogous to the mining of minerals, involves the following steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Data cleansing to remove noise and unwanted data
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data transformation to transform the data into relevant form for analysis
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data/pattern evaluation to uncover interesting insights
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data presentation to visualize knowledge in a useful form
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data mining isn't about using a search engine to get information, say regarding
    snakes. Rather it is about uncovering hidden insights like snakes are the only
    creatures found on every continent except Antarctica!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: If we take a minute to understand the preceding steps, we can see that we used
    exactly the same process across our projects. Please keep in mind that we have
    simply formalized and presented the process we have been following across chapters
    and not missed or modified any step done in previous chapters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Mining social network data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have formally defined data mining and seen the steps involved in
    transforming data to knowledge, let us focus on data from social networks. While
    data mining methodology is independent of the source of data, there are certain
    things to be kept in mind which could lead to better processing and improved results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Like the mining of any other type of data, domain knowledge is definitely a
    plus for mining social network data. Even though social network analysis is an
    interdisciplinary subject (as discussed in the previous section), it primarily
    involves the analysis of data pertaining to users or entities and their interactions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: In previous chapters, we have seen all sorts of data from e-commerce platforms
    to banks to data related to the characteristics of flowers. The data we have seen
    has had different attributes and characteristics. But if we look carefully, the
    data was a result of some sort of measurement or event capture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Coming onto the social network's domain, the playground is a little, if not
    completely different. Unlike what we have seen so far, data from social media
    platforms is extremely dynamic. When we say dynamic, we refer to the actual content
    on a data point and not its structure. The data point itself may (or may not)
    be structured, but the content itself is not.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us be specific and talk about data contained in a tweet. A sample tweet
    looks something like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![Mining social network data](img/00214.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: 'Image source: [https://twitter.com/POTUS/status/680464195993911296](https://twitter.com/POTUS/status/680464195993911296)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[https://twitter.com/POTUS/status/680464195993911296](https://twitter.com/POTUS/status/680464195993911296)
- en: A tweet, as we all know, is a 140 character message. Since the message is generated
    by a user (usually), the actual message may be of a different length, language,
    and or it may contain images, links, videos, and more. Thus, a tweet is a structured
    data point which contains the handle of the user (`@POTUS`), the name of the user
    (`President Obama`), the message (`From the Obama family...`), along with information
    related to when was it tweeted (`26 Dec 2015`), the number of likes, and the number
    of retweets. A tweet may also contain hashtags, hyperlinks, images, and videos
    embedded within the message. As we will see in the coming sections, a tweet contains
    tons of metadata (data about the data) apart from the attributes discussed preceding.
    Similarly, data from other social networks also contains a lot more information
    than what usually meets the eye.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，推文是一个140个字符的消息。由于消息是由用户（通常）生成的，实际消息的长度、语言可能不同，或者可能包含图片、链接、视频等。因此，推文是一个包含用户名（`@POTUS`）、用户名（`奥巴马总统`）、消息（`来自奥巴马家族...`）以及与推文时间（`2015年12月26日`）、点赞数和转发数相关的结构化数据点。推文还可能包含嵌入在消息中的标签、超链接、图片和视频。正如我们将在接下来的章节中看到的，推文除了前面讨论的属性外，还包含大量的元数据（关于数据的数据）。同样，其他社交网络的数据也包含比肉眼所见多得多的信息。
- en: This much information from a single tweet coupled with millions of users tweeting
    frantically every second across the globe presents a huge amount of data with
    interesting patterns waiting to be discovered.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 单条推文就能产生如此多的信息，再加上全球范围内每秒有数百万用户疯狂地发推，这产生了大量具有有趣模式的数据，等待被发现。
- en: In its true sense, Twitter's data (and of social networks in general) represents
    the 3 Vs (Volume, Variety, and Velocity) of big data very well.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在其真正意义上，Twitter的数据（以及社交网络的一般数据）很好地代表了大数据的3V（体积、种类和速度）。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '143,199 tweets per second is a record achieved during the airing of the film
    Castle in the Sky in Japan on August 3, 2013\. The average tweets per second is
    usually around 5700; the record multiplied it 25 times! Read more about it on
    the Twitter blog: [https://blog.twitter.com/2013/new-tweets-per-second-record-and-how](https://blog.twitter.com/2013/new-tweets-per-second-record-and-how)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年8月3日，日本播出电影《天空之城》期间，每秒产生了143,199条推文，这是记录下的一个记录。平均每秒的推文数量通常约为5700；这个记录是它的25倍！更多关于这个记录的信息可以在Twitter博客上阅读：[https://blog.twitter.com/2013/new-tweets-per-second-record-and-how](https://blog.twitter.com/2013/new-tweets-per-second-record-and-how)
- en: Thus, the mining of data from a social network involves understanding the structure
    of the data point, the underlying philosophy or use of the social network (Twitter
    is used for quick exchange of information, while LinkedIn is used for professional
    networking), the velocity and volume of the data being generated, along with the
    thinking cap of a data scientist.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从社交网络中挖掘数据涉及理解数据点的结构，社交网络（如Twitter用于快速交换信息，而LinkedIn用于专业网络）的潜在哲学或用途，生成数据的速度和数量，以及数据科学家的大脑。
- en: Towards the end of the chapter, we will also touch upon the challenges presented
    by social networks to the usual mining methodology.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的结尾，我们还将探讨社交网络对传统挖掘方法提出的挑战。
- en: Data and visualization
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据和可视化
- en: When the amount of data is growing exponentially every passing minute, the outcome
    of data mining activity must empower decision-makers to quickly identify action
    points. The outcome should be free of noise/excess information, yet be crisp and
    complete enough to be useable.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据量每分钟以指数级增长时，数据挖掘活动的结果必须能够使决策者快速识别行动点。结果应该是无噪声/多余信息的，同时足够清晰和完整，以便可以使用。
- en: This unique challenge of presenting information in its most convenient and useable
    form for easy consumption by its intended audience (which may be nontechnical)
    is an important aspect of the data mining process. So far in this book, we have
    analyzed data and made use of line graphs, bar graphs, histograms, and scatter
    plots to uncover and present insights. Before we make use of these and a few more
    visualizations/graphs in this chapter as well, let us try and understand their
    importance and use them wisely.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将信息以最便捷和可用的形式呈现给目标受众（可能是不懂技术的受众），以便他们轻松消费，这是数据挖掘过程中的一个重要方面。到目前为止，在这本书中，我们已经分析了数据，并利用了折线图、条形图、直方图和散点图来揭示和展示洞察。在我们使用本章中的这些以及一些更多的可视化/图表之前，让我们先尝试理解它们的重要性，并明智地使用它们。
- en: While working on a data mining assignment, we usually get so engrossed in the
    data, its complexities, algorithms, and whatnot, that we tend to overlook the
    part where we have to make the outcome consumable rather than a difficult to read
    sheet of numbers and jargon. Apart from making sure that the final report/document
    contains the correct and verified figures, we also need to make sure that the
    figures are presented in such a manner that it is easy for the end user to make
    use of it. To enable easy consumption of this information/knowledge, we take the
    help of different visualizations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据挖掘作业时，我们通常会如此专注于数据、其复杂性、算法等，以至于我们往往会忽视我们需要使结果易于消费而不是难以阅读的数字和术语表格的部分。除了确保最终报告/文档包含正确和经过验证的数字外，我们还需要确保这些数字以易于最终用户使用的方式呈现。为了使信息/知识易于消费，我们借助不同的可视化。
- en: Since this isn't a book on visualizations, we've taken the liberty of skipping
    the usual line graphs, bar graphs, pie charts, histograms, and other details.
    Let us understand some unconventional yet widely known/used visualizations before
    we use them in the coming sections.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这不是一本关于可视化的书，所以我们有选择性地跳过了通常的折线图、条形图、饼图、直方图和其他细节。在我们接下来使用这些可视化之前，让我们先了解一些非传统但广为人知/使用的可视化。
- en: Word clouds
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词云
- en: Social networks generate data in different forms and formats. The data on such
    platforms may be created, shared, modified, quoted, or used in various different
    ways. To represent complex relationships, one of the most widely used visualizations
    for social network data are **tag** **clouds** or **word clouds**. For example,
    objects such as text, images, videos, and blogs on these platforms are frequently
    tagged. Thus, a tag cloud/word cloud represents statistics of user-generated tags.
    These tags may represent the relative frequency of the use of words or their presence
    in multiple objects. The words/tags are differentiated using different font sizes
    and colors to represent the statistic of choice (mostly frequency).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络以不同的形式和格式生成数据。这些平台上的数据可能被创建、共享、修改、引用或以各种不同的方式使用。为了表示复杂的关系，社交网络数据最广泛使用的可视化之一是**标签云**或**词云**。例如，这些平台上的文本、图像、视频和博客等对象通常会被频繁标记。因此，标签云/词云代表了用户生成标签的统计数据。这些标签可能代表单词使用的相对频率或它们在多个对象中的存在。使用不同的字体大小和颜色来区分单词/标签，以表示选择的统计数据（通常是频率）。
- en: '![Word clouds](img/00215.jpeg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![词云](img/00215.jpeg)'
- en: A word cloud depicting frequently used words in a subset of tweets
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 展示一组推文中常用词汇的词云
- en: Treemaps
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 树状图
- en: To represent data of high dimensionality, it is usually not possible to visualize
    all dimensions at the same time. Treemaps are one such type of visualization that
    partition all dimensions into subsets and present them in a hierarchical manner.
    Specifically, treemaps partition dimensions into a set of nested rectangles. One
    of the mostly widely cited examples of a treemap is the newsmap, which visualizes
    news aggregated by Google news and displays it in different categories shown by
    different colors; color gradients denote the appearance of the article (on a time
    scale), while the size of the rectangle denotes the popularity of the news item.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了表示高维数据，通常不可能同时可视化所有维度。树状图就是这样一种可视化类型，它将所有维度划分为子集，并以分层的方式呈现。具体来说，树状图将维度划分为一组嵌套的矩形。树状图最常引用的例子之一是新闻地图，它可视化由谷歌新闻聚合的新闻，并以不同颜色显示不同的类别；颜色渐变表示文章的出现（在时间尺度上），而矩形的大小表示新闻条目的流行度。
- en: '![Treemaps](img/00216.jpeg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![树状图](img/00216.jpeg)'
- en: Treemap showing news aggregated by Google News
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 展示由谷歌新闻聚合的新闻的树状图
- en: 'Image source: [http://newsmap.jp/](http://newsmap.jp/)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Pixel-oriented maps
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Visualizations not only make outcomes easier to understand, they are very utilitarian
    as well. Most of the time, the outcome of an analysis process is multidimensional.
    To represent this data graphically on a two dimensional screen/piece of paper
    is a challenge. This is where pixel-oriented visualizations come into the picture.
    For an *n-dimensional* data set, pixel-oriented visualizations map each *n-dimensional*
    data point to a single pixel in *n* different sub-windows. Thus, each data point
    is split across *n* windows, one for each dimension. These help us map a large
    amount of data in single visualization. Pixel-oriented visualization look like
    this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![Pixel-oriented maps](img/00217.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: Sample pixel-oriented maps
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Image source: [http://bib.dbvis.de/uploadedFiles/163.pdf](http://bib.dbvis.de/uploadedFiles/163.pdf)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Other visualizations
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apart from the already mentioned visualizations, there are many other interesting
    visualizations, which come in handy for different use cases. For example, visualizations
    such as box plots come in handy for understanding data distribution and outlier
    detection. Similarly, there are visualizations such as Chernoff faces, scatter
    plots, network graphs, and so on which have their own merits and use cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Please do note that visualization is in itself a field of study and this section
    is merely trying to touch the tip of the iceberg. We urge readers to go through
    books/online content as shared in the *References* section of the chapter to read
    more on this.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Twitter APIs
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Twitter is as much a delight for tweeple (people using Twitter to tweet) as
    it is for data scientists. The APIs and the documentation are well updated and
    easy to use. Let us get started with the APIs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Twitter has one of easiest yet most powerful set of APIs available of any social
    network out there. These APIs have been used by Twitter itself and data scientists
    to understand the dynamics of the Twitter world. Twitter APIs make use of four
    different objects, namely:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**Tweets**: A tweet is the central entity that defines Twitter itself. As discussed
    in the previous section, a tweet contains far more information (metadata) than
    just the content/message of the tweet.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Users**: Anybody or anything that can tweet, follow, or perform any of Twitter''s
    actions is a user. Twitter is unique in its definition of user, which need not
    necessarily be a human. `@MarsCuriosity` is one such nonhuman popular Twitter
    handle with over 2 million followers!'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entities**: These are structured pieces of information extracted from the
    tweet object itself. These may include information on URLs, hashtags, user mentions,
    and so on. These objects enable quicker processing without parsing the tweet text.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Places**: A tweet may also have location attached to it. This information
    may be used for various purposes, such as displaying *Trending Topics Near You*
    or targeted marketing.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地点**：一条推文也可能附有位置信息。这些信息可能用于各种目的，例如显示“您附近的趋势话题”或定向营销。'
- en: The preceding objects from the Twitter APIs have been explained at length on
    the website [https://dev.twitter.com/](https://dev.twitter.com/). We urge readers
    to go through it to understand the objects and APIs even better.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter API中的前述对象已在网站[https://dev.twitter.com/](https://dev.twitter.com/)上进行了详细解释。我们敦促读者阅读以更好地理解对象和API。
- en: Twitter has libraries available in all major programming languages/platforms.
    We will be making use of TwitteR, that is, Twitter's library for R.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter在所有主要编程语言/平台上都有可用的库。我们将使用TwitteR，即Twitter为R提供的库。
- en: Tip
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Twitter Best Practices**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**Twitter最佳实践**'
- en: Twitter has a set of *best practices* and a list of dos and don'ts specified
    clearly on its developer site, [https://dev.twitter.com/](https://dev.twitter.com/),
    which talks about security/authentication, privacy, and more. Since Twitter supports
    a huge customer base with high availability, it tracks the usage of its APIs as
    well to keep its systems healthy. There is a defined rate limit on the number
    of times their APIs are queried. Kindly go through the best practices and be a
    `#gooddeveloper`!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter在其开发者网站[https://dev.twitter.com/](https://dev.twitter.com/)上明确指定了一套**最佳实践**和一系列的“可以做”和“不可以做”的事项，其中讨论了安全性/身份验证、隐私等。由于Twitter支持庞大的客户群并具有高可用性，它还跟踪其API的使用情况，以保持其系统健康。对API查询次数有明确的速率限制。请阅读最佳实践，并成为一个`#gooddeveloper`！
- en: Registering the application
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册应用程序
- en: Now that we have enough background about Twitter and its API objects, let us
    get our hands dirty. The first step when starting to use the APIs is to inform
    Twitter about your application. Twitter uses the standard **Open Authentication**
    (**OAuth**) protocol for authorizing a third party app. OAuth uses an application's
    consumer key, consumer secret, access token, and access token secret to allow
    it to use APIs and data of the connected service.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对Twitter及其API对象有了足够的背景知识，让我们动手实践。开始使用API的第一步是通知Twitter关于您的应用程序。Twitter使用标准的**开放认证**（**OAuth**）协议来授权第三方应用程序。OAuth使用应用程序的消费者密钥、消费者密钥、访问令牌和访问令牌密钥，允许它使用连接服务的API和数据。
- en: 'The following quick steps will set us up for the game:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下快速步骤将为我们设置游戏做好准备：
- en: Go to Twitter's Application Management Console at [https://apps.twitter.com/](https://apps.twitter.com/)
    and log in with your credentials or create an account if you don't have one.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Twitter的应用管理控制台[https://apps.twitter.com/](https://apps.twitter.com/)，使用您的凭据登录或如果您还没有账户，则创建一个账户。
- en: Click on **Create New App** and fill in the details for the app's name, website,
    and so on. For our purposes, we will name our app `TwitterAnalysis_rmre`. For
    callback URL use `http://127.0.0.1:1410` to point back to your local system. You
    may choose any other port number as well.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建新应用**并填写应用的名称、网站等详细信息。在我们的用途中，我们将命名我们的应用为`TwitterAnalysis_rmre`。对于回调URL，请使用`http://127.0.0.1:1410`指向您的本地系统。您也可以选择其他端口号。
- en: Click on **Create your Twitter Application** to complete the process. Your Application
    Management Console would look like the following screenshot:![Registering the
    application](img/00218.jpeg)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建您的Twitter应用程序**以完成流程。您的应用程序管理控制台将类似于以下截图：![注册应用程序](img/00218.jpeg)
- en: The Twitter application page
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Twitter应用程序页面
- en: Congratulations, your app is created and registered with Twitter. But before
    we can use it, there's one more piece to it. We need to create access tokens,
    and to do that we perform the following steps.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您的应用程序已创建并注册到Twitter。但在我们能够使用它之前，还有一件事情要做。我们需要创建访问令牌，为此我们需要执行以下步骤。
- en: Go to the link **Keys and Access Tokens** on the Twitter app's details page.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Twitter应用详情页面上的**密钥和访问令牌**链接。
- en: Scroll down and click on **Create My Access Token** to generate an access token
    for your profile.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动并点击**创建我的访问令牌**以为您个人资料生成访问令牌。
- en: The **Keys and Access Tokens** page looks like the following screenshot after
    completing the preceding steps:![Registering the application](img/00219.jpeg)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成前述步骤后，**密钥和访问令牌**页面将类似于以下截图：![注册应用程序](img/00219.jpeg)
- en: Application keys and access tokens
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用密钥和访问令牌
- en: We will be using the same application for this as well as in the coming chapter.
    Make a note of the consumer key, consumer secret, access token and access secret;
    we will need these in our application.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The keys and secrets generated for OAuth are sensitive pieces of information.
    They enable access for your app to Twitter's data. Please keep them as safe as
    you would keep your passwords (even safer than that). `#SafetyFirst`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Connect/authenticate
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have everything ready at Twitter's end, let us set things up at
    R's end as well. Before we start playing with the data from Twitter, the first
    step would be to connect and authenticate ourselves through the app we just created
    using R.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'We will make use of R''s TwitteR library by Jeff Gentry. This library or client
    allows us to use Twitter''s web APIs through R. We will use the method `setup_twitter_oauth()`
    to connect to Twitter using our app''s credentials (keys and access tokens). Kindly
    replace `XXXX` in the following code with your access keys/tokens generated in
    the previous step:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Connect/authenticate](img/00220.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: 'This will open up your browser and ask you to log in using your Twitter credentials
    and authorize this app, as shown in the following screenshot:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![Connect/authenticate](img/00221.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Authorize app to fetch data
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Once authorized, the browser will be redirected to the callback URL we mentioned
    when we created the app on Twitter. You may use a more informative URL for the
    user as well.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![Connect/authenticate](img/00222.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: Congratulations, you are now connected to the ocean of tweets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Extracting sample tweets
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we are connected to Twitter using R, it''s time to extract some latest
    tweets and analyze what we get. To extract tweets, we will use the handle for
    Twitter''s account 001 (Twitter''s founder and first user), Jack Dorsey, `@jack`.
    The following snippet of code extracts the latest 300 tweets from him:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output contains text combined with unprintable characters and URLs due
    to Twitter''s content-rich data. We will look at the metadata of a tweet in a
    bit, but before that, the extracted information looks like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![Extracting sample tweets](img/00223.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: Sample tweets
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the attributes and functions available to analyze and manipulate each
    tweet, use the `getClass` method as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following output will be generated:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '![Extracting sample tweets](img/00224.jpeg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Twitter data mining
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have tested our tools, libraries, and connections to Twitter APIs,
    the time has come to begin our search for the hidden treasures in Twitter land.
    Let's wear our data miner's cap and start digging!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will be working on Twitter data gathered from searching
    keywords (or hashtags in Twitter vocabulary) and user timelines. Using this data,
    we will be uncovering some interesting insights while using different functions
    and utilities from TwitteR and other R packages.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please note that our process will implicitly follow the steps outlined for data
    mining. In the spirit of brevity, we might take the liberty to not mention each
    of the steps explicitly. We are mining for some *gold-plated* insights; rest assured
    nothing is skipped!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Every year, we begin with a new zeal to achieve great feats and improve upon
    our shortcomings. Most of us make promises to ourselves in the form of New Year's
    resolutions. Let us explore what tweeple are doing with their resolutions in 2016!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: Twitter data changes very rapidly and your results/plots may vary
    from the ones depicted in this chapter.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same app and its credentials to connect and tap into Twitter
    for data. The following code works in exactly the same way that we extracted sample
    tweets in the previous section:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Apart from connecting to Twitter, we have also loaded required packages, such
    as `ggplot`, `stringr`, `tm`, and `wordcloud`. We will see where and how these
    packages are useful as we proceed.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Once connected to our data source, we can proceed towards collecting the required
    data. Since we are planning to learn about tweeple and their New Year's resolutions,
    we will extract data for the hashtag `#ResolutionsFor2016`. We can also use any
    hashtag, such as `#NewYearResolutions`, `#2016Resolutions`, or a combination of
    hashtags to get relevant tweets. The following piece of code not only extracts
    tweets, but also converts the list of tweet/status objects into an R data frame.
    We also convert each of the tweets to UTF-8 to handle text from different languages.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazing fact**: Twitter is available in 48 different languages and counting!'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As we saw in the previous section, a tweet contains far more information than
    mere text. One of the various attributes is the status source. The status source
    denotes the device from where the tweet was made. It may be a mobile phone, tablet,
    and so on. Before we apply major transformations and clean up tweet objects, we
    apply a quick transformation to transform status source to meaningful form:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding code transforms `statusSource` from values such as `<a href=\"http://twitter.com/download/android\"
    rel=\"nofollow\">Twitter for Android</a>` to simply Android and assigns it to
    a new attribute named `tweetSource`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the data, the next set of steps in the data mining process is to
    clean up the data. We use the text mining package `tm` to perform transformation
    and cleanup. The `Corpus` function in particular helps us handle tweet/status
    objects as a collection of documents. We then use the `tm_map` utility from the
    same package to apply/map transformations such as converting all text to lower
    case, removing punctuation, numbers, and stop words. Stop words is a list of the
    most commonly used words, such as a, an, the, and so on, which can safely be removed
    while analyzing text without loss of meaning.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The final transformation before we proceed to the next step of analyzing our
    data for hidden patterns/insights is a term-document matrix. As the name itself
    says, a term-document matrix is a matrix representation in which terms act as
    rows while columns are represented by documents. Each entry in this matrix represents
    the number of occurrences of a term in a given document. More formally, a term-document
    matrix is a matrix representation that describes the frequency of terms in a collection
    of documents. This representation is extremely useful in natural language processing
    applications. It is an optimized data structure that enables quick searches, topical
    modeling, and more. The data structure can be explained using the following simple
    example where we have two text documents, **TD1** and **TD2**:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Twitter data mining](img/00225.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
- en: Sample term-document matrix
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'The tm package provides us another easy-to-use utility called term-document
    matrix (`TermDocumentMatrix` is also available), which we use to convert our `Corpus`
    object into the required form:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Frequent words and associations
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The term-document matrix thus prepared contains words from each of the tweets
    (post the cleanup and transformations) as rows, while columns represent the tweet
    themselves.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: As a quick check, let us see which of the words are most frequently used in
    our dataset. Let the threshold be set to `30` occurrences or more. We use the
    apply utility to iterate each term in our term-document matrix and sum its occurrences.
    The function helps us filter out the terms that have appeared 30 times or more.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result will be as shown in the following screenshot:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00226.jpeg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: Terms with 30 or more occurrences across tweets
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: As the preceding screenshot shows, words such as healthy, inspire, and positivity
    feature in the list of words with 30 or more occurrences. We all have a lot in
    common when it comes to yearly goals, no?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding manipulation was a quick check to see if we really have tweets
    that help us find out something interesting about New Year''s resolutions. Let
    us now take a formal approach and identify frequent terms in our data set. We
    will also try and present the information in a creative yet easy-to-understand
    representation. To get the most frequent terms in our data set, we use the function
    `findFreqTerms` from the `tm` package again. This function provides us an abstraction
    over quick hacks, such as the one we previously used. `findFreqTerms` also lets
    us set a minimum and maximum threshold for term frequencies. For our case, we
    will only mention the lower bound and see the results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results look something like the following screenshot:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00227.jpeg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: We get about 107 terms with a minimum occurrence of 10\. If you look carefully,
    the terms we saw with frequencies of at least 30 also appear in this list, and
    rightly so.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are certain that there are terms/words with occurrences of more
    than 10, let us create a data frame and plot the terms versus their frequencies
    as we decided previously. We use the `rowSums` function to calculate the total
    occurrence of each term/word. We then pick a subset of terms which have more than
    10 occurrences and plot them using `ggplot`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding piece of code generates the following frequency graph:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00228.jpeg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: 'Upon analyzing the preceding graph, we can quickly get some interesting points:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: The words **mom**, **elected**, **president**, and **trillionaire** feature
    in the top 10\. Strange set, yet interesting. More on this in a bit.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health features high in the list, but doesn't make it to the top 10\. So, it
    seems like health is on the cards but not very high. This is the same for **fitness**
    and **diet**.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the words in this list are positive in essence. Words such as **happy**,
    **hope**, **positivity**, **change**, and so on all point to the upbeat mood while
    taking up New Year's resolutions!
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Though the preceding graph gives us quite a lot of information regarding the
    words and their frequencies in a nice layout, it still doesn't show us the full
    picture. Remember that we crafted a subset of items from our data set before generating
    this graph? We did that on purpose, otherwise the graph would have become too
    long and words with lesser frequencies would clutter the whole thing. Another
    point which this graph misses out is the relative difference in the frequencies.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'If our aim is to see the relative difference between the frequencies, we need
    a different visualization altogether. Here comes word cloud to the rescue. Using
    the `wordcloud` library, we can easily generate word clouds from a dataframe using
    a one liner:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The wordcloud using the complete data frame looks something like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00229.jpeg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
- en: The preceding word cloud renders words in decreasing order of frequency. The
    size of each word emphasizes its frequency. You can play around with the `wordcloud`
    function to generate some interesting visualizations or even art!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'A lot of words appear in the preceding graphs, but isn''t it rather interesting
    to see the word trillionaire pop up in the top 10? What could be the reason for
    it? Was it a spam post by a bot, or a tweet by some celebrity that went viral,
    or something completely different altogether? Let''s check out the top tweet in
    this list and see if it contains the word trillionaire:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following screenshot is what you get:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00230.jpeg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: 'It turns out that our hunch was right. It was a New Year resolution tweet by
    a celebrity that went viral. A quick search on Twitter reveals the tweet:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00231.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: 'Image source: [https://twitter.com/mishacollins?lang=en](https://twitter.com/mishacollins?lang=en)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: A bit further searching reveals Misha Collins is a famous actor from the television
    series Supernatural. We can also see that the above resolution was retweeted a
    staggering 5k times! It's interesting to note that the number of likes is 14k,
    outnumbering the retweets. Can we infer that tweeple prefer likes/hearts to retweets?
    It can also be seen that words such as mom, learn, trillionaire, elected, and
    President all occur as most frequent words without a doubt. Indirectly, we can
    also infer that Supernatural has a huge fan following on Twitter and that Castiel
    (Misha's role in the TV series) is a popular character from the show. A bit of
    a surprise is his resolution to learn to crochet, no?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Moving on from supernatural stuff, let us go back to the fitness debate. Fitness
    is important to most of us. Activities such as exercising or hitting the gym see
    a surge during the initial months/weeks of the year. Let's see how health-conscious
    our friends on Twitter are!
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'Since a lot of words such as health, diet, fitness, gym, and so on point towards
    a healthy lifestyle, let us try and find words associated with the word *fitness*
    itself. `findAssocs` is a handy function which helps us find words from a term-document
    matrix that have at least a specified level of correlation to a given word. We
    will use the output from this function to prepare a term-association (correlation)
    graph using `ggplot`. The process is similar to how we prepared the preceding
    frequency graph:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The words most closely correlated to the word fitness are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00232.jpeg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
- en: 'The same data is more readable in graphical form, as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![Frequent words and associations](img/00233.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
- en: As evident from the preceding graph, terms such as **lossweight**, **workout**,
    **getfit**, and so on. prove our point that tweeple are as concerned about health
    as we are. It is interesting to note the occurrence of the term *yogavideos* in
    this list. It looks like yoga is catching up with other techniques of staying
    fit in 2016\. There's **meditation** on the list too.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Popular devices
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have dealt with the visible components of a tweet, such as the text,
    retweet counts, and so on, and we were able to extract many interesting insights.
    Let us take out our precision tools and dig deeper into our data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned a couple times in the above sections, a tweet has far more information
    than what meets the eye. One such piece of information is about the source of
    the tweet. Twitter was born of the SMS era, and many of its characteristics, such
    as the 140 character word limit, are reminiscent of that era. It would be interesting
    to see how tweeple use Twitter, that is, what devices are used to access and post
    on Twitter frequently. Though the world has moved a long way from the SMS era,
    mobile phones are ubiquitous. To get this information, we will make use of the
    attribute `tweetSource` from our dataframe `trendingTweets.df`. We created this
    additional attribute from the `statusSource` attribute already existing in the
    `tweet` object (see the beginning of this section for a quick recap).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: We shall use a subset of the data frame `trendingTweets.df` based upon retweet
    counts for the sake of clarity. We will use `ggplot` again to visualize our results.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following plot is your result:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![Popular devices](img/00234.jpeg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: Without a doubt, the iPhone is the most preferred device, followed by Android
    and the Web. It is interesting to see that people use the Web/website to retweet
    more than the iPad! Windows Phone clearly has some serious issues to tackle here.
    Can we also infer that the iPhone is the preferred device amongst tweeples? Or
    does the iPhone provide a better experience than any other device for Twitter?
    Or we could even go deeper and say that Twitter on iPhone has an easier-to-access
    "retweets" button than any other device. Inferences such as these and many more,
    require a bit more digging than this, but all of this has a lot of knowledge/potential
    that could be used by managements, UX teams, and so on to improve and change things
    around.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchical clustering
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have seen clustering and classification in previous chapters (see [Chapter
    2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8 "Chapter 2. Let's
    Help Machines Learn"), *Let's Help Machines Learn*) and uncovered some interesting
    facts about the data at hand. For our current use case, even though our tweets
    are all related to 2016 resolutions, we can never be sure of the kinds of resolutions
    tweeple make. This makes it a very apt use case for hierarchical clustering. Unlike
    k-means or other clustering algorithms that require a preset number of clusters
    before computation, hierarchical clustering algorithms work independently of it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us take this opportunity to understand hierarchical clustering before we
    apply it to our data. Hierarchical clustering, like any other clustering algorithm,
    helps us group similar items together. The exact details for this algorithm in
    general can be explained as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '**Initialize**: This is the first step, where each element is assigned to a
    cluster of its own. For a dataset containing *n* elements, the algorithm creates
    *n* different clusters with one element in each of them. A distance/similarity
    measure is decided at this step.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Merge**: During this step, depending upon the distance/similarity measure
    chosen, the closest pair of clusters are identified and merged into a single cluster.
    This step results in one fewer clusters than the total clusters so far.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compute**/**recompute**: We compute/recompute distances/similarities between
    the new cluster formed in the Merge step and the existing clusters.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **merge** and **compute** steps are repeated until we are left with a single
    cluster containing all *n* items. As the name suggests, this algorithm generates
    a hierarchical structure with the leaves denoting individual elements as clusters
    combined based upon similarity/distance as we go toward the root of the tree.
    The output tree is generally referred to as a **dendrogram**.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: The merge step is where variations of this algorithm exist. There are several
    ways in which the closest clusters could be identified. From simple methods, such
    as single-link, which consider the shortest distance between any two elements
    of the two clusters in consideration as the distance measure, to complex ones
    such as Ward's method which uses variance to find the most compact clusters, there
    are several methods that could be employed depending upon the use case.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to the Twitter world, let us use hierarchical clustering to see
    which terms/tweets are the closest. For our current use case, we will use the
    single method for our merge criteria. You may try out different algorithms and
    observe the differences.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform hierarchical clustering, we first treat our dataset to remove sparse
    terms for the sake of clarity. For this, the `removeSparseTerms` function helps
    us remove rows of data that have sparsity below a specified limit. We then use
    the `hclust` utility to form clusters. The output of this utility is directly
    plottable. Let us write some code for this:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output *dendrogram* is amazingly simple to understand:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![Hierarchical clustering](img/00235.jpeg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: If you observe the second cluster from right, it contains terms **trillionaire**,
    **elected**, **mom**, **call**, and so on. Mapping back to the top retweeted tweet
    from Mischa Collins, all these terms are mentioned in that single tweet and our
    algorithm has rightly clustered them together. Smart, isn't it? As a small exercise,
    observe other clusters and see how the terms occur in the tweets that contain
    them. One important observation to make here is that the *dendrogram* correctly
    maps all frequent terms under a single root, which reaffirms that all these terms
    point to our central theme of 2016 resolutions!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Topic modeling
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, our analysis has been about tweets related to New Year's resolutions
    from users across the world. We have analyzed tweets related to a topic of our
    choice. Ignoring spam and other noisy tweets, more or less, our data conformed
    to a single topic. The topic itself constituted a group of words (such as health,
    trillionaire, fitness, diet, mom, and so on) which broadly describe different
    resolutions. To broaden our scope of analysis and to discover even more insights,
    let us touch upon the concept of topic modeling.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Topic modeling is a process of discovering patterns in a corpus of unlabeled
    text that represents the gist of the corpus. A topic itself may be described as
    a group of words that occur together to describe a large body of text.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'Another definition tweeted during one of the conferences on topic modeling:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![Topic modeling](img/00236.jpeg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: 'Image source: [https://twitter.com/footnotesrising/status/264823621799780353](https://twitter.com/footnotesrising/status/264823621799780353)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: The aim of topic modeling is to automatically identify the underlying theme
    of a corpus and thus be useful in applications that require information retrieval
    based on a theme but in absence of known keywords (the exact opposite of our current
    usage of search engines). For example, wouldn't it be amazing to learn about relations
    between two countries from a newspaper's archive by using the theme *relations
    between country one and country two* rather than searching for a keyword and then
    following link after link. Please note that following links to discover information
    is equally powerful, but it leaves a lot to be desired.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: One of the ways to perform topic modeling is through **Latent Dirichlet Allocation**
    (**LDA**); it is one of the most powerful and widely used models.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: LDA was presented by David M Blie in his paper *Introduction to Probabilistic
    Topic Models* in 2003\. LDA, as his paper says, can be defined as a generative
    model that allows sets of observations to be explained by unobserved groups that
    explain why some parts of the data is similar. LDA works upon the assumption that
    documents exhibit multiple topics.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: LDA is a probabilistic model and the mathematics of it are fairly involved and
    beyond the scope of this book. In a nonmathematical way, LDA can be explained
    as a model/process that helps identify the topics that have resulted in the generation
    of a collection of documents.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For further reading, refer to Blei's paper.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf](https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 'A blog which explains everything in simple words:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/](http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: For our purpose/use case, we can assume LDA as a model/process which helps us
    to identify the underlying (hidden/latent) topics from a corpus of unlabeled text.
    Luckily, R abstracts most of the mathematical details in the form of a library
    called `topicmodels`.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purpose of topic modeling, we shall use a new set of tweets. The **International
    Space** **Station** (**ISS**) has multiple Twitter handles, and one of them is
    `@ISS_Research`, which particularly caters to research related tweets from the
    ISS. Let us explore what `@ISS_Research` is up to these days by analyzing the
    tweets from its timeline. We will analyze these tweets to identify the underlying
    topics of research at the ISS. For this purpose, we will use the same process
    to extract tweets and perform transformations/cleanup as we have done before.
    The following snippet of code does this:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have tweets in the required format, the `LDA` utility from the `topicmodels`
    package helps us uncover the hidden topics/patterns. The LDA utility requires
    the number of topics as input along with the document-term matrix. We will try
    eight topics for now. The following code uses `LDA` to extract six terms for each
    of the eight topics:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The list of topics generated using LDA is as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '![Topic modeling](img/00237.jpeg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
- en: 'A visual representation would be easier to understand. We can make use of `qplot`
    to quickly plot the topics across time on an area chart, as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The generated chart looks like the following screenshot:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![Topic modeling](img/00238.jpeg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: Let us now analyze the outputs. The list of terms per topic generated by LDA
    seems to give us a nice insight into the kind of work/research going on at the
    ISS. Terms such as mars, microgravity, flower, Cygnus, and so on tell us about
    the main areas of research or at least the topics about which scientists/astronauts
    on the ISS are talking. Terms such as stationcdrkelly and astrotimpeake look more
    like Twitter handles.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A quick exercise would be to use the current `@ISS_Research` timeline data and
    mine for the handles, such as `stationcdrkelly`, to discover more information.
    Who knows, it may turn out be a nice list of astronauts to follow!
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The `qplot` output adds the time dimension to our plain list of topics. Analyzing
    topics across the time dimension helps us understand when a particular research
    topic was discussed or when something amazing was announced. Topic two in the
    list, or the fourth one from the top in the graph legend comprises the word flower.
    Since scientists were successful in blooming some orange flowers in space recently,
    the above graph helps us get an idea that the news first broke on Twitter on/around
    15^(th) January. A quick look on Twitter/news websites confirms that the news
    broke by tweet on 18^(th) January 2016…close enough!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Colorful area charts**'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Try removing the option `scale_fill_grey()` from `qplot` to get some beautiful
    charts that are far easier to read than plain gray scale.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: So, finally we learnt about topic modeling using LDA on data from the ISS and
    found what amazing things scientists and astronauts are doing up there in outer
    space.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Challenges with social network data mining
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we close the chapter, let us look at the different challenges posed
    by social networks to the process of data mining. The following points present
    a few arguments, questions, and challenges:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: No doubt the data generated by social networks classifies as big data in every
    aspect. It has all the volume, velocity, and variety in it to overwhelm any system.
    Yet, interestingly, the challenge with such a huge source of data is the availability
    of enough granular data. If we zoom into our data sets and try to use data on
    a per user basis, we find that there isn't enough data to do some of the most
    common tasks, such as making recommendations!
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social networks such as Twitter handle millions of users creating and sharing
    tons of data every second. To keep their systems up and running at all times,
    they put limits upon the amount of data that can be tapped using their APIs (security
    is also a major reason behind these limits, though). These limits put data science
    efforts in a quandary as it is difficult to obtain sufficient samples of data
    that represent the population correctly/completely. Insufficient samples may result
    in incorrect patterns or missing out on patterns altogether.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing and evaluation of results is also a challenge with social network
    analysis. While preprocessing data, we remove noisy content. With data coming
    in all shapes and sizes, determining noisy content is far more of a challenge
    than simply removing stopwords. Evaluation of results is another challenge, as
    there is no ground truth available in most cases, and due to the limitations presented
    here and otherwise, it is difficult to ascertain the validity of results with
    confidence.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The arguments/challenges presented above call for innovative and creative ways
    to be devised by data scientists, and that is what makes their job interesting
    and highly rewarding.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the well-known books on visualization are as follows :'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001](http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X](http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192](http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some well known blogs on this are as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '**Tableau** **specific**: [http://www.jewelloree.com/](http://www.jewelloree.com/)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://flowingdata.com/](http://flowingdata.com/)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.informationisbeautiful.net/](http://www.informationisbeautiful.net/)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://infosthetics.com/](http://infosthetics.com/)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.visualisingdata.com/](http://www.visualisingdata.com/)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://eagereyes.org/](https://eagereyes.org/)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://thedailyviz.com/](http://thedailyviz.com/)'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D3**: [https://d3js.org/](https://d3js.org/)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social network analysis is one the trending topics in the world of data science.
    As we have seen throughout the chapter, these platforms not only provide us with
    ways to connect but they also present a unique opportunity to study human dynamics
    at a global scale. Through this chapter, we have learned some interesting techniques.
    We started off by understanding data mining in the social network context followed
    by the importance of visualizations. We focused on Twitter and understood different
    objects and APIs to manipulate them. We used various packages from R, such as
    `TwitteR` and `TM`, to connect, collect, and manipulate data for our analysis.
    We used data from Twitter to learn about frequency throughout. Finally, we presented
    some of the challenges posed by social networks words and associations, popular
    devices used by tweeple, hierarchical clustering and even touched upon topic modeling.
    We used `ggplot2` and `wordcloud` to visualize our results to the data mining
    process in general. While concluding this chapter, we are sure that by now you
    can appreciate the amazing dynamics behind these platforms and R's ability to
    analyze it all. We aren't done with `@Twitter` yet, hold on to your `#sentiments`!
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
