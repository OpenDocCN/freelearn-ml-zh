- en: Chapter 7. Social Media Analysis – Analyzing Twitter Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 社交媒体分析 – 分析Twitter数据
- en: Connected is the word that describes life in the 21^(st) century. Though various
    factors contribute to the term connected, there's one aspect which has played
    a pivotal role. It's called the Web. The Web, which has made distance an irrelevant
    metric and blurred socio-economic boundaries, is a world in itself and we all
    are a part of it. The Web or Internet in particular has been a central entity
    in this data-driven revolution. As we have seen in our previous chapters, for
    most modern day problems, it is the Web/Internet (henceforth used interchangeably)
    that acts as a source of data. Be it e-commerce platforms or financial domain,
    the Internet provides us with huge amounts of data every second. There's another
    ocean of data within this virtual world which touches our lives at a very personal
    level. Social networks, or social media, is a behemoth of information and the
    topic for this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “连接”是描述21世纪生活的词汇。尽管有许多因素促成了这个术语，但有一个方面发挥了关键作用。那就是网络。网络使距离变得无关紧要，模糊了社会经济界限，它本身就是一个世界，我们都是其中的一部分。特别是网络或互联网在这个数据驱动革命中是一个核心实体。正如我们在前面的章节中看到的，对于大多数现代问题，网络/互联网（以下将互换使用）是数据来源。无论是电子商务平台还是金融领域，互联网每秒都为我们提供大量数据。在这个虚拟世界中，还有另一个数据海洋，它以非常个人化的方式触及我们的生活。社交网络，或社交媒体，是信息巨无霸，也是本章的主题。
- en: In the previous chapter, we covered the financial domain, where we analyzed
    and predicted credit risk for customers of a certain bank. We now shift gears
    and move into the realm of social media and see how machine learning and R empower
    us to uncover insights from this ocean of data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了金融领域，在那里我们分析了并预测了某家银行客户的信用风险。我们现在转换方向，进入社交媒体领域，看看机器学习和R如何使我们能够从这个数据海洋中揭示洞察力。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Data mining specifics for social networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交网络的数据挖掘具体方法
- en: The importance and use of different data visualizations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同数据可视化的重要性和用途
- en: An overview of how to connect and collect Twitter data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何连接和收集Twitter数据的概述
- en: Utilizing Twitter data to uncover amazing insights
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Twitter数据揭示惊人的洞察力
- en: Seeing how social networks pose new challenges to the data mining process
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看看社交网络如何对数据挖掘过程提出新的挑战
- en: Social networks (Twitter)
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 社交网络（Twitter）
- en: We all use social networks day in and day out. There are numerous social networks
    catering to all sorts of ideologies and philosophies, but Facebook and Twitter
    (barring a couple more) have become synonymous with the term social network itself.
    These two social networks enjoy popularity not only because of their uniqueness
    and the quality of service but because of the way they enable us to interact in
    a very intuitive way. As we saw with recommendation engines used in e-commerce
    websites (see [Chapter 4](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 4. Building a Product Recommendation System"), *Building a Product Recommendation
    System*), social networks have existed long before Facebook, Twitter, or even
    the Internet.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每天都使用社交网络。有无数社交网络迎合各种意识形态和哲学，但Facebook和Twitter（除少数几个外）已经成为社交网络本身的同义词。这两个社交网络之所以受欢迎，不仅因为它们的独特性和服务质量，还因为它们使我们能够以非常直观的方式互动。正如我们在电子商务网站中使用的推荐引擎（见[第4章](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8
    "第4章 建立产品推荐系统")）所看到的，“建立产品推荐系统”，社交网络在Facebook、Twitter甚至互联网出现之前就已经存在。
- en: Social networks have interested scientists and mathematicians alike. It is an
    interdisciplinary topic which spans but is not limited to sociology, psychology,
    biology, economics, communication studies, and information science. Various theories
    have been developed to analyze social networks and their impact on human lives
    in the form of factors influencing economics, demographics, health, language,
    literacy, crime, and more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络对科学家和数学家都产生了兴趣。这是一个跨学科的话题，它跨越但不限于社会学、心理学、生物学、经济学、传播学和信息科学。已经发展出各种理论来分析社交网络及其对人类生活的影响，这些影响以影响经济、人口统计、健康、语言、读写能力、犯罪等因素的形式出现。
- en: Studies done as early as the late 1800s form the basis of what we today refer
    to as social networks. A social network, as the word itself says, is a sort of
    connection/network between nodes or entities represented by humans and elements
    affecting social life. More formally, it is a network depicting relationships
    and interactions. Hence, it is not surprising to see various graph theories and
    algorithms being employed to understand social networks. Where the 19^(th) and
    20^(th) centuries were limited to theoretical models and painstaking social experiments,
    the 21^(st) century's technology has opened the doors for these theories to be
    tested, fine tuned, and modeled to help understand the dynamics of social interactions.
    Though testing these theories by some social networks (called social experiments)
    have been caught in controversies, such topics are beyond the scope of this book.
    We shall limit ourselves to the algorithmic/data science space and leave the controversies
    for the experts to discuss.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 早在19世纪末进行的研究构成了我们今天所说的社会网络的基础。正如其词本身所表明的，社会网络是节点或实体之间的一种连接/网络，这些节点或实体由人类和影响社会生活的元素所代表。更正式地说，它是一个描绘关系和互动的网络。因此，看到各种图理论和算法被用来理解社会网络并不令人惊讶。在19世纪和20世纪，这些理论仅限于理论模型和艰苦的社会实验，而21世纪的技术为这些理论的测试、微调和建模打开了大门，以帮助理解社会互动的动态。尽管通过某些社会网络（称为社会实验）测试这些理论引起了争议，但这些话题超出了本书的范围。我们将限制自己在算法/数据科学领域，并将争议留给专家讨论。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: The Milgram Experiment, or the small world experiment, was conducted in the
    late 1960s to examine the average path length for people in United States. As
    part of this experiment, random people were selected as starting points of a mail
    chain. These random people were tasked to send the mail to the next person so
    that the mail gets one step closer to its destination (somewhere in Boston) and
    so on. An average of six hops to the destination is the documented result of this
    famous experiment. Urban folklore suggests the phrase *6 degrees of separation*
    originated from this experiment, even though Dr. Milgram never used the term himself!
    He conducted many more experiments; search and be amazed.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 米尔格拉姆实验，或称为小世界实验，是在20世纪60年代末进行的，旨在考察美国人的平均路径长度。作为该实验的一部分，随机挑选的人被选为邮件链的起点。这些随机挑选的人被要求将邮件发送给下一个人，以便邮件更接近其目的地（波士顿某地），依此类推。这个著名实验记录的平均跳数是六步。都市传说表明，“六度分隔”这个短语起源于这个实验，尽管米尔格拉姆博士本人从未使用过这个术语！他进行了许多更多的实验；去搜索并惊叹吧。
- en: 'Source:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：
- en: '[http://www.simplypsychology.org/milgram.html](http://www.simplypsychology.org/milgram.html)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.simplypsychology.org/milgram.html](http://www.simplypsychology.org/milgram.html)'
- en: Before we jump into the specifics, let us try and understand the reason behind
    choosing Twitter as our point of analysis for this and the upcoming chapter. Let
    us begin with understanding what Twitter is and why is it so popular with both
    end users and data scientists alike.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入具体内容之前，让我们尝试理解选择Twitter作为本章节和下一章节分析点的理由。让我们从了解Twitter是什么以及为什么它对终端用户和数据科学家都如此受欢迎开始。
- en: Twitter, as we all know, is a social network/micro-blogging service that enables
    its users to send and receive tweets of a maximum of 140 characters. But what
    makes Twitter so popular is the way it caters to the basic human instincts. We,
    humans, are curious creatures with an incessant need to be heard. It is important
    for us to have someone or some place to voice our opinions. We love to share our
    experiences, feats, failures, and ideas. At some level or other, we also want
    to know what our peers are up to, what's keeping celebrities busy, or simply what's
    on the news. Twitter addresses just that.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，Twitter是一个社交网络/微博服务，它允许用户发送和接收最多140个字符的推文。但使Twitter如此受欢迎的是它满足基本的人类本能的方式。我们人类是好奇的生物，有着不断被听到的需求。对我们来说，有一个地方或某个人可以表达我们的观点是很重要的。我们喜欢分享我们的经历、成就、失败和想法。在某种程度上，我们也想知道我们的同龄人在做什么，名人忙于什么，或者新闻上有什么。Twitter正是解决了这些问题。
- en: With multiple social networks existing long before Twitter came into existence,
    it wasn't some other service which Twitter replaced. In our view, it was the way
    Twitter organized the information and its users that clicked. Its unique *Follow*
    model of relationship caters to our hunger for curiosity, while its short, free,
    and high-speed communication platform enables the users to speak out and be heard
    globally. By allowing users to follow a person or an entity of interest, it enables
    us to keep up with their latest happenings without the other user following us
    back. The *Follow* model tips Twitter's relationships towards more of an interest
    graph rather than the friendship model usually found in social networks such as
    Facebook.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter出现之前，就已经存在多个社交网络，Twitter并没有取代其他服务。在我们看来，是Twitter组织信息和用户的方式吸引了人们的注意。其独特的*关注*关系模型满足了我们对好奇心的渴望，而其简短、免费、高速的通信平台使用户能够发声并被全球听到。通过允许用户关注感兴趣的人或实体，它使我们能够跟上他们的最新动态，而无需其他用户反过来关注我们。*关注*模型使Twitter的关系更倾向于兴趣图谱，而不是像Facebook这样的社交网络中通常发现的友谊模式。
- en: Twitter is known and used across the globe for the super-fast spread of information
    (and rumors). It has been innovatively used in certain circumstances unimaginable
    before, such as finding people in times of natural calamities such as earthquakes
    or typhoons. It has been used to spread information so far and deep that it takes
    viral proportions. The asymmetric relationships and high speed information exchange
    aid in making Twitter such a dynamic entity. If we closely analyze and study the
    data and dynamics of this social network we can uncover many insights. Hence,
    it is the topic for this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter因其信息（以及谣言）的超级快速传播而闻名并被全球使用。在某些以前无法想象的情况下，它被创新地使用，例如在地震或台风等自然灾害时期寻找人们。它被用来传播信息，范围之广，深度之深，以至于达到了病毒般的规模。不对称的关系和高速度的信息交换有助于使Twitter成为一个如此动态的实体。如果我们仔细分析和研究这个社交网络的数据和动态，我们可以揭示许多见解。因此，它是本章的主题。
- en: Note
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Interesting links**:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的链接**:'
- en: '[https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/](https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/](https://www.technologyreview.com/s/419368/how-twitter-helps-in-a-disaster/)'
- en: '[http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/](http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/](http://www.citylab.com/tech/2015/04/how-twitter-maps-can-be-useful-during-disasters/391436/)'
- en: '[https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true](https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true](https://www.researchgate.net/publication/282150020_A_Systematic_Literature_Review_of_Twitter_Research_from_a_Socio-Political_Revolution_Perspective?channel=doi&linkId=56050b3f08ae5e8e3f3125cb&showFulltext=true)'
- en: '[http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123](http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123](http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.696123)'
- en: '[http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully](http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully](http://www.psmag.com/nature-and-technology/how-to-use-social-media-usefully)'
- en: 'Let''s apply some data science to tweets using #RMachineLearningByExample!'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用#RMachineLearningByExample!来对推文应用一些数据科学！
- en: Data mining @social networks
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘 @社交网络
- en: We have traveled quite a distance so far through the chapters of this book,
    understanding various concepts and learning some amazing algorithms. We have even
    worked on projects that have applications in our daily lives. In short, we have
    done data mining without using the term explicitly. Let us now take this opportunity
    to formally define data mining.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过这本书的章节走过了很长的路，理解了各种概念，并学习了一些令人惊叹的算法。我们甚至参与了在我们的日常生活中有应用的项目。简而言之，我们已经在没有明确使用术语的情况下进行了数据挖掘。现在，让我们抓住这个机会，正式定义数据挖掘。
- en: 'Mining, in the classical sense of the word, refers to the extraction of useful
    minerals from the Earth (such as coal mining). Put in the context of the information
    age, mining refers to the extraction of useful information from large pools of
    data. Thus, if we look carefully, **Knowledge** **Mining** or **Knowledge Discovery
    from** **Data** (**KDD**) seems to be a better representation than the term data
    mining. As is the case with many keywords, short and sweet catches the attention.
    Thus, you may find in many places the terms Knowledge Discovery from Data and
    data mining being used interchangeably, which is rightly so. The process of data
    mining, analogous to the mining of minerals, involves the following steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统意义上，采矿指的是从地球中提取有用的矿物（如煤矿开采）。将这一概念置于信息时代的大背景下，采矿则指的是从大量数据中提取有用的信息。因此，如果我们仔细观察，**知识挖掘**或**从数据中发现知识**（KDD）似乎比“数据挖掘”这个术语更能准确地表达。正如许多关键词一样，简洁明了往往能吸引人的注意。因此，你可能会在很多地方看到“从数据中发现知识”和“数据挖掘”这两个术语被交替使用，这是完全正确的。数据挖掘的过程，类似于采矿，包括以下步骤：
- en: Data cleansing to remove noise and unwanted data
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据清洗以去除噪声和不需要的数据
- en: Data transformation to transform the data into relevant form for analysis
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据转换以将数据转换为适合分析的相关形式
- en: Data/pattern evaluation to uncover interesting insights
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据/模式评估以揭示有趣的洞察
- en: Data presentation to visualize knowledge in a useful form
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据展示以可视化有用的知识形式
- en: Note
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Data mining isn't about using a search engine to get information, say regarding
    snakes. Rather it is about uncovering hidden insights like snakes are the only
    creatures found on every continent except Antarctica!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘并不是使用搜索引擎获取信息，比如关于蛇的信息。相反，它涉及到揭示隐藏的洞察，比如蛇是唯一一种在除南极洲以外的每个大陆都能找到的生物！
- en: If we take a minute to understand the preceding steps, we can see that we used
    exactly the same process across our projects. Please keep in mind that we have
    simply formalized and presented the process we have been following across chapters
    and not missed or modified any step done in previous chapters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们花点时间理解前面的步骤，我们就可以看到我们在所有项目中使用了完全相同的过程。请记住，我们只是将我们在章节中一直遵循的过程进行了形式化和展示，并没有遗漏或修改之前章节中完成的任何步骤。
- en: Mining social network data
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采矿社交网络数据
- en: Now that we have formally defined data mining and seen the steps involved in
    transforming data to knowledge, let us focus on data from social networks. While
    data mining methodology is independent of the source of data, there are certain
    things to be kept in mind which could lead to better processing and improved results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经正式定义了数据挖掘，并看到了将数据转换为知识所涉及的步骤，让我们专注于社交网络的数据。虽然数据挖掘方法与数据来源无关，但有一些需要注意的事项，这可能导致更好的处理和改进的结果。
- en: Like the mining of any other type of data, domain knowledge is definitely a
    plus for mining social network data. Even though social network analysis is an
    interdisciplinary subject (as discussed in the previous section), it primarily
    involves the analysis of data pertaining to users or entities and their interactions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 就像采矿任何其他类型的数据一样，领域知识对于采矿社交网络数据来说绝对是一个加分项。尽管社交网络分析是一个跨学科的主题（如前所述），但它主要涉及分析与用户或实体及其互动相关的数据。
- en: In previous chapters, we have seen all sorts of data from e-commerce platforms
    to banks to data related to the characteristics of flowers. The data we have seen
    has had different attributes and characteristics. But if we look carefully, the
    data was a result of some sort of measurement or event capture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了来自电子商务平台、银行以及与花卉特征相关的各种数据。我们所看到的数据具有不同的属性和特征。但如果我们仔细观察，这些数据都是某种测量或事件捕获的结果。
- en: Coming onto the social network's domain, the playground is a little, if not
    completely different. Unlike what we have seen so far, data from social media
    platforms is extremely dynamic. When we say dynamic, we refer to the actual content
    on a data point and not its structure. The data point itself may (or may not)
    be structured, but the content itself is not.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 进入社交网络的领域，游戏场域略有不同，如果不是完全不同。与我们所看到的不同，社交媒体平台的数据极其动态。当我们说动态时，我们指的是数据点的实际内容，而不是其结构。数据点本身可能（也可能不）是结构化的，但内容本身不是。
- en: 'Let us be specific and talk about data contained in a tweet. A sample tweet
    looks something like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们具体谈谈包含在推文中的数据。一个样本推文可能看起来像这样：
- en: '![Mining social network data](img/00214.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![采矿社交网络数据](img/00214.jpeg)'
- en: 'Image source: [https://twitter.com/POTUS/status/680464195993911296](https://twitter.com/POTUS/status/680464195993911296)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[https://twitter.com/POTUS/status/680464195993911296](https://twitter.com/POTUS/status/680464195993911296)
- en: A tweet, as we all know, is a 140 character message. Since the message is generated
    by a user (usually), the actual message may be of a different length, language,
    and or it may contain images, links, videos, and more. Thus, a tweet is a structured
    data point which contains the handle of the user (`@POTUS`), the name of the user
    (`President Obama`), the message (`From the Obama family...`), along with information
    related to when was it tweeted (`26 Dec 2015`), the number of likes, and the number
    of retweets. A tweet may also contain hashtags, hyperlinks, images, and videos
    embedded within the message. As we will see in the coming sections, a tweet contains
    tons of metadata (data about the data) apart from the attributes discussed preceding.
    Similarly, data from other social networks also contains a lot more information
    than what usually meets the eye.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，推文是一个140个字符的消息。由于消息是由用户（通常）生成的，实际消息的长度、语言可能不同，或者可能包含图片、链接、视频等。因此，推文是一个包含用户名（`@POTUS`）、用户名（`奥巴马总统`）、消息（`来自奥巴马家族...`）以及与推文时间（`2015年12月26日`）、点赞数和转发数相关的结构化数据点。推文还可能包含嵌入在消息中的标签、超链接、图片和视频。正如我们将在接下来的章节中看到的，推文除了前面讨论的属性外，还包含大量的元数据（关于数据的数据）。同样，其他社交网络的数据也包含比肉眼所见多得多的信息。
- en: This much information from a single tweet coupled with millions of users tweeting
    frantically every second across the globe presents a huge amount of data with
    interesting patterns waiting to be discovered.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 单条推文就能产生如此多的信息，再加上全球范围内每秒有数百万用户疯狂地发推，这产生了大量具有有趣模式的数据，等待被发现。
- en: In its true sense, Twitter's data (and of social networks in general) represents
    the 3 Vs (Volume, Variety, and Velocity) of big data very well.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在其真正意义上，Twitter的数据（以及社交网络的一般数据）很好地代表了大数据的3V（体积、种类和速度）。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '143,199 tweets per second is a record achieved during the airing of the film
    Castle in the Sky in Japan on August 3, 2013\. The average tweets per second is
    usually around 5700; the record multiplied it 25 times! Read more about it on
    the Twitter blog: [https://blog.twitter.com/2013/new-tweets-per-second-record-and-how](https://blog.twitter.com/2013/new-tweets-per-second-record-and-how)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年8月3日，日本播出电影《天空之城》期间，每秒产生了143,199条推文，这是记录下的一个记录。平均每秒的推文数量通常约为5700；这个记录是它的25倍！更多关于这个记录的信息可以在Twitter博客上阅读：[https://blog.twitter.com/2013/new-tweets-per-second-record-and-how](https://blog.twitter.com/2013/new-tweets-per-second-record-and-how)
- en: Thus, the mining of data from a social network involves understanding the structure
    of the data point, the underlying philosophy or use of the social network (Twitter
    is used for quick exchange of information, while LinkedIn is used for professional
    networking), the velocity and volume of the data being generated, along with the
    thinking cap of a data scientist.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从社交网络中挖掘数据涉及理解数据点的结构，社交网络（如Twitter用于快速交换信息，而LinkedIn用于专业网络）的潜在哲学或用途，生成数据的速度和数量，以及数据科学家的大脑。
- en: Towards the end of the chapter, we will also touch upon the challenges presented
    by social networks to the usual mining methodology.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的结尾，我们还将探讨社交网络对传统挖掘方法提出的挑战。
- en: Data and visualization
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据和可视化
- en: When the amount of data is growing exponentially every passing minute, the outcome
    of data mining activity must empower decision-makers to quickly identify action
    points. The outcome should be free of noise/excess information, yet be crisp and
    complete enough to be useable.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据量每分钟以指数级增长时，数据挖掘活动的结果必须能够使决策者快速识别行动点。结果应该是无噪声/多余信息的，同时足够清晰和完整，以便可以使用。
- en: This unique challenge of presenting information in its most convenient and useable
    form for easy consumption by its intended audience (which may be nontechnical)
    is an important aspect of the data mining process. So far in this book, we have
    analyzed data and made use of line graphs, bar graphs, histograms, and scatter
    plots to uncover and present insights. Before we make use of these and a few more
    visualizations/graphs in this chapter as well, let us try and understand their
    importance and use them wisely.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将信息以最便捷和可用的形式呈现给目标受众（可能是不懂技术的受众），以便他们轻松消费，这是数据挖掘过程中的一个重要方面。到目前为止，在这本书中，我们已经分析了数据，并利用了折线图、条形图、直方图和散点图来揭示和展示洞察。在我们使用本章中的这些以及一些更多的可视化/图表之前，让我们先尝试理解它们的重要性，并明智地使用它们。
- en: While working on a data mining assignment, we usually get so engrossed in the
    data, its complexities, algorithms, and whatnot, that we tend to overlook the
    part where we have to make the outcome consumable rather than a difficult to read
    sheet of numbers and jargon. Apart from making sure that the final report/document
    contains the correct and verified figures, we also need to make sure that the
    figures are presented in such a manner that it is easy for the end user to make
    use of it. To enable easy consumption of this information/knowledge, we take the
    help of different visualizations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据挖掘作业时，我们通常会如此专注于数据、其复杂性、算法等，以至于我们往往会忽视我们需要使结果易于消费而不是难以阅读的数字和术语表格的部分。除了确保最终报告/文档包含正确和经过验证的数字外，我们还需要确保这些数字以易于最终用户使用的方式呈现。为了使信息/知识易于消费，我们借助不同的可视化。
- en: Since this isn't a book on visualizations, we've taken the liberty of skipping
    the usual line graphs, bar graphs, pie charts, histograms, and other details.
    Let us understand some unconventional yet widely known/used visualizations before
    we use them in the coming sections.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这不是一本关于可视化的书，所以我们有选择性地跳过了通常的折线图、条形图、饼图、直方图和其他细节。在我们接下来使用这些可视化之前，让我们先了解一些非传统但广为人知/使用的可视化。
- en: Word clouds
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词云
- en: Social networks generate data in different forms and formats. The data on such
    platforms may be created, shared, modified, quoted, or used in various different
    ways. To represent complex relationships, one of the most widely used visualizations
    for social network data are **tag** **clouds** or **word clouds**. For example,
    objects such as text, images, videos, and blogs on these platforms are frequently
    tagged. Thus, a tag cloud/word cloud represents statistics of user-generated tags.
    These tags may represent the relative frequency of the use of words or their presence
    in multiple objects. The words/tags are differentiated using different font sizes
    and colors to represent the statistic of choice (mostly frequency).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络以不同的形式和格式生成数据。这些平台上的数据可能被创建、共享、修改、引用或以各种不同的方式使用。为了表示复杂的关系，社交网络数据最广泛使用的可视化之一是**标签云**或**词云**。例如，这些平台上的文本、图像、视频和博客等对象通常会被频繁标记。因此，标签云/词云代表了用户生成标签的统计数据。这些标签可能代表单词使用的相对频率或它们在多个对象中的存在。使用不同的字体大小和颜色来区分单词/标签，以表示选择的统计数据（通常是频率）。
- en: '![Word clouds](img/00215.jpeg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![词云](img/00215.jpeg)'
- en: A word cloud depicting frequently used words in a subset of tweets
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 展示一组推文中常用词汇的词云
- en: Treemaps
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 树状图
- en: To represent data of high dimensionality, it is usually not possible to visualize
    all dimensions at the same time. Treemaps are one such type of visualization that
    partition all dimensions into subsets and present them in a hierarchical manner.
    Specifically, treemaps partition dimensions into a set of nested rectangles. One
    of the mostly widely cited examples of a treemap is the newsmap, which visualizes
    news aggregated by Google news and displays it in different categories shown by
    different colors; color gradients denote the appearance of the article (on a time
    scale), while the size of the rectangle denotes the popularity of the news item.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了表示高维数据，通常不可能同时可视化所有维度。树状图就是这样一种可视化类型，它将所有维度划分为子集，并以分层的方式呈现。具体来说，树状图将维度划分为一组嵌套的矩形。树状图最常引用的例子之一是新闻地图，它可视化由谷歌新闻聚合的新闻，并以不同颜色显示不同的类别；颜色渐变表示文章的出现（在时间尺度上），而矩形的大小表示新闻条目的流行度。
- en: '![Treemaps](img/00216.jpeg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![树状图](img/00216.jpeg)'
- en: Treemap showing news aggregated by Google News
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 展示由谷歌新闻聚合的新闻的树状图
- en: 'Image source: [http://newsmap.jp/](http://newsmap.jp/)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[http://newsmap.jp/](http://newsmap.jp/)
- en: Pixel-oriented maps
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 像素导向地图
- en: 'Visualizations not only make outcomes easier to understand, they are very utilitarian
    as well. Most of the time, the outcome of an analysis process is multidimensional.
    To represent this data graphically on a two dimensional screen/piece of paper
    is a challenge. This is where pixel-oriented visualizations come into the picture.
    For an *n-dimensional* data set, pixel-oriented visualizations map each *n-dimensional*
    data point to a single pixel in *n* different sub-windows. Thus, each data point
    is split across *n* windows, one for each dimension. These help us map a large
    amount of data in single visualization. Pixel-oriented visualization look like
    this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化不仅使结果更容易理解，而且非常实用。大多数时候，分析过程的结果是多维的。要在二维屏幕/纸张上图形化地表示这些数据是一个挑战。这就是像素导向可视化出现的地方。对于一个n维数据集，像素导向可视化将每个n维数据点映射到n个不同的子窗口中的单个像素。因此，每个数据点被分散在n个窗口中，每个窗口对应一个维度。这些帮助我们在一个可视化中映射大量数据。像素导向可视化看起来是这样的：
- en: '![Pixel-oriented maps](img/00217.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![像素导向地图](img/00217.jpeg)'
- en: Sample pixel-oriented maps
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 样本像素导向地图
- en: 'Image source: [http://bib.dbvis.de/uploadedFiles/163.pdf](http://bib.dbvis.de/uploadedFiles/163.pdf)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[http://bib.dbvis.de/uploadedFiles/163.pdf](http://bib.dbvis.de/uploadedFiles/163.pdf)
- en: Other visualizations
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他可视化
- en: Apart from the already mentioned visualizations, there are many other interesting
    visualizations, which come in handy for different use cases. For example, visualizations
    such as box plots come in handy for understanding data distribution and outlier
    detection. Similarly, there are visualizations such as Chernoff faces, scatter
    plots, network graphs, and so on which have their own merits and use cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了已经提到的可视化之外，还有许多其他有趣的可视化，这些可视化在不同的用例中非常有用。例如，箱线图等可视化对于理解数据分布和异常检测非常有用。同样，还有Chernoff面孔、散点图、网络图等可视化，它们各有其优点和用例。
- en: Please do note that visualization is in itself a field of study and this section
    is merely trying to touch the tip of the iceberg. We urge readers to go through
    books/online content as shared in the *References* section of the chapter to read
    more on this.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，可视化本身就是一个研究领域，本节只是试图触及冰山一角。我们鼓励读者阅读章节“参考文献”部分中分享的书籍/在线内容，以了解更多相关信息。
- en: Getting started with Twitter APIs
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Twitter API
- en: Twitter is as much a delight for tweeple (people using Twitter to tweet) as
    it is for data scientists. The APIs and the documentation are well updated and
    easy to use. Let us get started with the APIs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter对于使用Twitter发推文的tweple（人们）和数据科学家来说都同样令人愉悦。API和文档都得到了很好的更新，易于使用。让我们从API开始吧。
- en: Overview
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'Twitter has one of easiest yet most powerful set of APIs available of any social
    network out there. These APIs have been used by Twitter itself and data scientists
    to understand the dynamics of the Twitter world. Twitter APIs make use of four
    different objects, namely:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter拥有最简单但最强大的API集合之一，这是任何社交网络都有的。这些API已被Twitter本身和数据科学家用来理解Twitter世界的动态。Twitter
    API使用四个不同的对象，即：
- en: '**Tweets**: A tweet is the central entity that defines Twitter itself. As discussed
    in the previous section, a tweet contains far more information (metadata) than
    just the content/message of the tweet.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推文**: 推文是定义Twitter本身的中心实体。正如前文所述，推文包含的信息（元数据）远不止推文的内容/信息。'
- en: '**Users**: Anybody or anything that can tweet, follow, or perform any of Twitter''s
    actions is a user. Twitter is unique in its definition of user, which need not
    necessarily be a human. `@MarsCuriosity` is one such nonhuman popular Twitter
    handle with over 2 million followers!'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户**: 任何可以发推文、关注或执行Twitter任何操作的任何人或事物都是用户。Twitter在用户定义上具有独特性，不一定是人类。`@MarsCuriosity`就是这样一种非人类流行的Twitter账号，拥有超过200万粉丝！'
- en: '**Entities**: These are structured pieces of information extracted from the
    tweet object itself. These may include information on URLs, hashtags, user mentions,
    and so on. These objects enable quicker processing without parsing the tweet text.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实体**: 这些是从推文对象本身提取的结构化信息片段。这可能包括有关URL、标签、用户提及等信息。这些对象使处理更快，无需解析推文文本。'
- en: '**Places**: A tweet may also have location attached to it. This information
    may be used for various purposes, such as displaying *Trending Topics Near You*
    or targeted marketing.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地点**：一条推文也可能附有位置信息。这些信息可能用于各种目的，例如显示“您附近的趋势话题”或定向营销。'
- en: The preceding objects from the Twitter APIs have been explained at length on
    the website [https://dev.twitter.com/](https://dev.twitter.com/). We urge readers
    to go through it to understand the objects and APIs even better.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter API中的前述对象已在网站[https://dev.twitter.com/](https://dev.twitter.com/)上进行了详细解释。我们敦促读者阅读以更好地理解对象和API。
- en: Twitter has libraries available in all major programming languages/platforms.
    We will be making use of TwitteR, that is, Twitter's library for R.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter在所有主要编程语言/平台上都有可用的库。我们将使用TwitteR，即Twitter为R提供的库。
- en: Tip
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Twitter Best Practices**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**Twitter最佳实践**'
- en: Twitter has a set of *best practices* and a list of dos and don'ts specified
    clearly on its developer site, [https://dev.twitter.com/](https://dev.twitter.com/),
    which talks about security/authentication, privacy, and more. Since Twitter supports
    a huge customer base with high availability, it tracks the usage of its APIs as
    well to keep its systems healthy. There is a defined rate limit on the number
    of times their APIs are queried. Kindly go through the best practices and be a
    `#gooddeveloper`!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter在其开发者网站[https://dev.twitter.com/](https://dev.twitter.com/)上明确指定了一套**最佳实践**和一系列的“可以做”和“不可以做”的事项，其中讨论了安全性/身份验证、隐私等。由于Twitter支持庞大的客户群并具有高可用性，它还跟踪其API的使用情况，以保持其系统健康。对API查询次数有明确的速率限制。请阅读最佳实践，并成为一个`#gooddeveloper`！
- en: Registering the application
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册应用程序
- en: Now that we have enough background about Twitter and its API objects, let us
    get our hands dirty. The first step when starting to use the APIs is to inform
    Twitter about your application. Twitter uses the standard **Open Authentication**
    (**OAuth**) protocol for authorizing a third party app. OAuth uses an application's
    consumer key, consumer secret, access token, and access token secret to allow
    it to use APIs and data of the connected service.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对Twitter及其API对象有了足够的背景知识，让我们动手实践。开始使用API的第一步是通知Twitter关于您的应用程序。Twitter使用标准的**开放认证**（**OAuth**）协议来授权第三方应用程序。OAuth使用应用程序的消费者密钥、消费者密钥、访问令牌和访问令牌密钥，允许它使用连接服务的API和数据。
- en: 'The following quick steps will set us up for the game:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下快速步骤将为我们设置游戏做好准备：
- en: Go to Twitter's Application Management Console at [https://apps.twitter.com/](https://apps.twitter.com/)
    and log in with your credentials or create an account if you don't have one.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Twitter的应用管理控制台[https://apps.twitter.com/](https://apps.twitter.com/)，使用您的凭据登录或如果您还没有账户，则创建一个账户。
- en: Click on **Create New App** and fill in the details for the app's name, website,
    and so on. For our purposes, we will name our app `TwitterAnalysis_rmre`. For
    callback URL use `http://127.0.0.1:1410` to point back to your local system. You
    may choose any other port number as well.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建新应用**并填写应用的名称、网站等详细信息。在我们的用途中，我们将命名我们的应用为`TwitterAnalysis_rmre`。对于回调URL，请使用`http://127.0.0.1:1410`指向您的本地系统。您也可以选择其他端口号。
- en: Click on **Create your Twitter Application** to complete the process. Your Application
    Management Console would look like the following screenshot:![Registering the
    application](img/00218.jpeg)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建您的Twitter应用程序**以完成流程。您的应用程序管理控制台将类似于以下截图：![注册应用程序](img/00218.jpeg)
- en: The Twitter application page
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Twitter应用程序页面
- en: Congratulations, your app is created and registered with Twitter. But before
    we can use it, there's one more piece to it. We need to create access tokens,
    and to do that we perform the following steps.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您的应用程序已创建并注册到Twitter。但在我们能够使用它之前，还有一件事情要做。我们需要创建访问令牌，为此我们需要执行以下步骤。
- en: Go to the link **Keys and Access Tokens** on the Twitter app's details page.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Twitter应用详情页面上的**密钥和访问令牌**链接。
- en: Scroll down and click on **Create My Access Token** to generate an access token
    for your profile.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动并点击**创建我的访问令牌**以为您个人资料生成访问令牌。
- en: The **Keys and Access Tokens** page looks like the following screenshot after
    completing the preceding steps:![Registering the application](img/00219.jpeg)
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成前述步骤后，**密钥和访问令牌**页面将类似于以下截图：![注册应用程序](img/00219.jpeg)
- en: Application keys and access tokens
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应用密钥和访问令牌
- en: We will be using the same application for this as well as in the coming chapter.
    Make a note of the consumer key, consumer secret, access token and access secret;
    we will need these in our application.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与下一章相同的同一个应用。请记住消费者密钥、消费者秘密、访问令牌和访问秘密；我们将在我们的应用中需要这些。
- en: Note
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The keys and secrets generated for OAuth are sensitive pieces of information.
    They enable access for your app to Twitter's data. Please keep them as safe as
    you would keep your passwords (even safer than that). `#SafetyFirst`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为OAuth生成的密钥和秘密是敏感信息。它们使您的应用能够访问Twitter的数据。请像保管您的密码（甚至更安全）一样保管它们。`#安全第一`。
- en: Connect/authenticate
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接/认证
- en: Now that we have everything ready at Twitter's end, let us set things up at
    R's end as well. Before we start playing with the data from Twitter, the first
    step would be to connect and authenticate ourselves through the app we just created
    using R.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在Twitter端准备好了所有东西，让我们在R端也设置一下。在我们开始处理Twitter的数据之前，第一步将是使用我们刚刚创建的应用通过R进行连接和认证。
- en: 'We will make use of R''s TwitteR library by Jeff Gentry. This library or client
    allows us to use Twitter''s web APIs through R. We will use the method `setup_twitter_oauth()`
    to connect to Twitter using our app''s credentials (keys and access tokens). Kindly
    replace `XXXX` in the following code with your access keys/tokens generated in
    the previous step:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用Jeff Gentry的R的TwitteR库。这个库或客户端允许我们通过R使用Twitter的Web API。我们将使用`setup_twitter_oauth()`方法使用我们的应用凭证（密钥和访问令牌）连接到Twitter。请将以下代码中的`XXXX`替换为您在之前步骤中生成的访问密钥/令牌：
- en: '[PRE0]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Connect/authenticate](img/00220.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![连接/认证](img/00220.jpeg)'
- en: 'This will open up your browser and ask you to log in using your Twitter credentials
    and authorize this app, as shown in the following screenshot:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开您的浏览器，并要求您使用Twitter凭证登录并授权此应用，如下面的截图所示：
- en: '![Connect/authenticate](img/00221.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![连接/认证](img/00221.jpeg)'
- en: Authorize app to fetch data
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 授权应用以获取数据
- en: Once authorized, the browser will be redirected to the callback URL we mentioned
    when we created the app on Twitter. You may use a more informative URL for the
    user as well.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦授权，浏览器将重定向到我们在Twitter上创建应用时提到的回调URL。您也可以为用户使用一个更具信息量的URL。
- en: '![Connect/authenticate](img/00222.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![连接/认证](img/00222.jpeg)'
- en: Congratulations, you are now connected to the ocean of tweets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，您现在已连接到推文的海洋。
- en: Extracting sample tweets
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取样本推文
- en: 'Now that we are connected to Twitter using R, it''s time to extract some latest
    tweets and analyze what we get. To extract tweets, we will use the handle for
    Twitter''s account 001 (Twitter''s founder and first user), Jack Dorsey, `@jack`.
    The following snippet of code extracts the latest 300 tweets from him:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已通过R连接到Twitter，是时候提取一些最新的推文并分析我们得到的结果了。为了提取推文，我们将使用Twitter账号001（Twitter的创始人及第一位用户）Jack
    Dorsey的账号`@jack`。以下代码片段将从他那里提取最新的300条推文：
- en: '[PRE2]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output contains text combined with unprintable characters and URLs due
    to Twitter''s content-rich data. We will look at the metadata of a tweet in a
    bit, but before that, the extracted information looks like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Twitter内容丰富，输出包含文本、不可打印的字符和URL。我们将在稍后查看推文的元数据，但在那之前，提取的信息看起来如下：
- en: '![Extracting sample tweets](img/00223.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![提取样本推文](img/00223.jpeg)'
- en: Sample tweets
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 样本推文
- en: 'To see the attributes and functions available to analyze and manipulate each
    tweet, use the `getClass` method as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看可用于分析和操作每条推文的属性和函数，请使用以下`getClass`方法：
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following output will be generated:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成以下输出：
- en: '![Extracting sample tweets](img/00224.jpeg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![提取样本推文](img/00224.jpeg)'
- en: Twitter data mining
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Twitter数据挖掘
- en: Now that we have tested our tools, libraries, and connections to Twitter APIs,
    the time has come to begin our search for the hidden treasures in Twitter land.
    Let's wear our data miner's cap and start digging!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经测试了我们的工具、库和与Twitter API的连接，是时候开始寻找Twitter领域的隐藏宝藏了。让我们戴上数据挖掘者的帽子，开始挖掘吧！
- en: In this section, we will be working on Twitter data gathered from searching
    keywords (or hashtags in Twitter vocabulary) and user timelines. Using this data,
    we will be uncovering some interesting insights while using different functions
    and utilities from TwitteR and other R packages.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将处理从搜索关键词（或Twitter词汇中的标签）和用户时间线收集的Twitter数据。使用这些数据，我们将通过使用TwitteR和其他R包的不同函数和实用工具来揭示一些有趣的见解。
- en: Note
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that our process will implicitly follow the steps outlined for data
    mining. In the spirit of brevity, we might take the liberty to not mention each
    of the steps explicitly. We are mining for some *gold-plated* insights; rest assured
    nothing is skipped!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们的过程将隐式遵循数据挖掘中概述的步骤。为了简洁起见，我们可能不会明确提及每个步骤。我们正在挖掘一些“镀金”的见解；请放心，没有任何步骤被遗漏！
- en: Every year, we begin with a new zeal to achieve great feats and improve upon
    our shortcomings. Most of us make promises to ourselves in the form of New Year's
    resolutions. Let us explore what tweeple are doing with their resolutions in 2016!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每年，我们都带着新的热情去实现伟大的成就，并改进我们的不足。我们大多数人会以新年决心的形式给自己许下承诺。让我们来看看2016年用户是如何处理他们的决心的！
- en: Note
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Twitter data changes very rapidly and your results/plots may vary
    from the ones depicted in this chapter.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：Twitter数据变化非常快，你的结果/图表可能与本章中描述的不同。'
- en: 'We will use the same app and its credentials to connect and tap into Twitter
    for data. The following code works in exactly the same way that we extracted sample
    tweets in the previous section:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的应用程序及其凭证来连接并获取Twitter数据。以下代码与我们在上一节中提取样本推文的方式完全相同：
- en: '[PRE4]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Apart from connecting to Twitter, we have also loaded required packages, such
    as `ggplot`, `stringr`, `tm`, and `wordcloud`. We will see where and how these
    packages are useful as we proceed.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 除了连接到Twitter，我们还加载了所需的包，如`ggplot`、`stringr`、`tm`和`wordcloud`。随着我们的进展，我们将看到这些包在哪里以及如何有用。
- en: Once connected to our data source, we can proceed towards collecting the required
    data. Since we are planning to learn about tweeple and their New Year's resolutions,
    we will extract data for the hashtag `#ResolutionsFor2016`. We can also use any
    hashtag, such as `#NewYearResolutions`, `#2016Resolutions`, or a combination of
    hashtags to get relevant tweets. The following piece of code not only extracts
    tweets, but also converts the list of tweet/status objects into an R data frame.
    We also convert each of the tweets to UTF-8 to handle text from different languages.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦连接到我们的数据源，我们就可以开始收集所需的数据。由于我们计划了解用户及其新年决心，我们将提取`#ResolutionsFor2016`标签的数据。我们也可以使用任何标签，例如`#NewYearResolutions`、`#2016Resolutions`或标签的组合来获取相关的推文。以下代码不仅提取推文，还将推文/状态对象的列表转换为R数据框。我们还把每条推文转换为UTF-8格式，以处理不同语言的文本。
- en: Note
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Amazing fact**: Twitter is available in 48 different languages and counting!'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**惊人事实**：Twitter有48种不同的语言，并且还在不断增加！'
- en: '[PRE5]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As we saw in the previous section, a tweet contains far more information than
    mere text. One of the various attributes is the status source. The status source
    denotes the device from where the tweet was made. It may be a mobile phone, tablet,
    and so on. Before we apply major transformations and clean up tweet objects, we
    apply a quick transformation to transform status source to meaningful form:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中看到的，一条推文包含的信息远不止文本本身。众多属性之一是状态源。状态源表示发布推文的设备。它可能是一部手机、平板电脑等等。在我们应用主要转换和清理推文对象之前，我们首先对状态源进行快速转换，将其转换为有意义的格式：
- en: '[PRE6]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding code transforms `statusSource` from values such as `<a href=\"http://twitter.com/download/android\"
    rel=\"nofollow\">Twitter for Android</a>` to simply Android and assigns it to
    a new attribute named `tweetSource`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将`statusSource`从类似`<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter
    for Android</a>`的值转换为简单的“Android”，并将其分配给一个名为`tweetSource`的新属性。
- en: Once we have the data, the next set of steps in the data mining process is to
    clean up the data. We use the text mining package `tm` to perform transformation
    and cleanup. The `Corpus` function in particular helps us handle tweet/status
    objects as a collection of documents. We then use the `tm_map` utility from the
    same package to apply/map transformations such as converting all text to lower
    case, removing punctuation, numbers, and stop words. Stop words is a list of the
    most commonly used words, such as a, an, the, and so on, which can safely be removed
    while analyzing text without loss of meaning.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了数据，数据挖掘过程中的下一步就是清理数据。我们使用文本挖掘包`tm`来进行转换和清理。特别是`Corpus`函数帮助我们将推文/状态对象作为文档集合来处理。然后我们使用来自同一包的`tm_map`实用工具来应用/映射转换，例如将所有文本转换为小写，删除标点符号、数字和停用词。停用词是一系列最常用的词，如a、an、the等，在分析文本时可以安全地删除，而不会失去意义。
- en: '[PRE7]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The final transformation before we proceed to the next step of analyzing our
    data for hidden patterns/insights is a term-document matrix. As the name itself
    says, a term-document matrix is a matrix representation in which terms act as
    rows while columns are represented by documents. Each entry in this matrix represents
    the number of occurrences of a term in a given document. More formally, a term-document
    matrix is a matrix representation that describes the frequency of terms in a collection
    of documents. This representation is extremely useful in natural language processing
    applications. It is an optimized data structure that enables quick searches, topical
    modeling, and more. The data structure can be explained using the following simple
    example where we have two text documents, **TD1** and **TD2**:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行下一步分析数据以寻找隐藏的模式/见解之前，最后的转换是一个术语-文档矩阵。正如其名所示，术语-文档矩阵是一种矩阵表示，其中术语作为行，而列则代表文档。矩阵中的每个条目表示一个术语在给定文档中的出现次数。更正式地说，术语-文档矩阵是一种描述文档集中术语频率的矩阵表示。这种表示在自然语言处理应用中非常有用。它是一种优化的数据结构，能够实现快速搜索、主题建模等。以下是一个简单示例，说明了如何使用这种数据结构，其中我们有两个文本文档，**TD1**和**TD2**：
- en: '![Twitter data mining](img/00225.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![Twitter数据挖掘](img/00225.jpeg)'
- en: Sample term-document matrix
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 样本术语-文档矩阵
- en: 'The tm package provides us another easy-to-use utility called term-document
    matrix (`TermDocumentMatrix` is also available), which we use to convert our `Corpus`
    object into the required form:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: tm包为我们提供了一个易于使用的实用工具，称为术语-文档矩阵（`TermDocumentMatrix`也是可用的），我们使用它将我们的`Corpus`对象转换为所需的形式：
- en: '[PRE8]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Frequent words and associations
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常用词汇和关联
- en: The term-document matrix thus prepared contains words from each of the tweets
    (post the cleanup and transformations) as rows, while columns represent the tweet
    themselves.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 因此准备好的术语-文档矩阵包含每个推文（在清理和转换之后）中的词汇作为行，而列则代表推文本身。
- en: As a quick check, let us see which of the words are most frequently used in
    our dataset. Let the threshold be set to `30` occurrences or more. We use the
    apply utility to iterate each term in our term-document matrix and sum its occurrences.
    The function helps us filter out the terms that have appeared 30 times or more.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 作为快速检查，让我们看看在我们的数据集中哪些词汇使用得最频繁。将阈值设置为`30`次或更多。我们使用apply实用工具迭代术语-文档矩阵中的每个术语并计算其出现次数。该函数帮助我们过滤掉出现30次或更多的术语。
- en: '[PRE9]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result will be as shown in the following screenshot:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将如以下截图所示：
- en: '![Frequent words and associations](img/00226.jpeg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![常用词汇和关联](img/00226.jpeg)'
- en: Terms with 30 or more occurrences across tweets
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在推文中出现30次或更多的术语
- en: As the preceding screenshot shows, words such as healthy, inspire, and positivity
    feature in the list of words with 30 or more occurrences. We all have a lot in
    common when it comes to yearly goals, no?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个截图所示，诸如健康、启发和积极等词汇出现在30次或更多出现的词汇列表中。说到年度目标，我们大家有很多共同之处，不是吗？
- en: 'The preceding manipulation was a quick check to see if we really have tweets
    that help us find out something interesting about New Year''s resolutions. Let
    us now take a formal approach and identify frequent terms in our data set. We
    will also try and present the information in a creative yet easy-to-understand
    representation. To get the most frequent terms in our data set, we use the function
    `findFreqTerms` from the `tm` package again. This function provides us an abstraction
    over quick hacks, such as the one we previously used. `findFreqTerms` also lets
    us set a minimum and maximum threshold for term frequencies. For our case, we
    will only mention the lower bound and see the results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的操作是一个快速检查，看看我们是否真的有可以帮助我们了解新年愿望的推文。现在让我们采取正式的方法，并识别数据集中的频繁术语。我们还将尝试以创新且易于理解的方式呈现信息。为了获取数据集中最频繁的术语，我们再次使用`tm`包中的`findFreqTerms`函数。此函数为我们提供了一个比之前使用的快速修复更高级的抽象。`findFreqTerms`还允许我们设置术语频率的最小和最大阈值。在我们的情况下，我们只提到下限并查看结果：
- en: '[PRE10]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The results look something like the following screenshot:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来像以下截图：
- en: '![Frequent words and associations](img/00227.jpeg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![常用词汇和关联](img/00227.jpeg)'
- en: We get about 107 terms with a minimum occurrence of 10\. If you look carefully,
    the terms we saw with frequencies of at least 30 also appear in this list, and
    rightly so.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到大约107个术语，最小出现次数为10。如果你仔细看，我们看到的至少30次频率的术语也出现在这个列表中，这是理所当然的。
- en: 'Now that we are certain that there are terms/words with occurrences of more
    than 10, let us create a data frame and plot the terms versus their frequencies
    as we decided previously. We use the `rowSums` function to calculate the total
    occurrence of each term/word. We then pick a subset of terms which have more than
    10 occurrences and plot them using `ggplot`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们确定确实有一些术语/单词的频率超过10次，让我们创建一个数据框，并按照我们之前决定的方式绘制术语与其频率的关系图。我们使用`rowSums`函数计算每个术语/单词的总出现次数。然后我们选择出现次数超过10次的术语子集，并使用`ggplot`进行绘图：
- en: '[PRE11]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding piece of code generates the following frequency graph:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块生成了以下频率图：
- en: '![Frequent words and associations](img/00228.jpeg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![频繁单词及其关联](img/00228.jpeg)'
- en: 'Upon analyzing the preceding graph, we can quickly get some interesting points:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 分析前面的图表后，我们可以迅速得到一些有趣的点：
- en: The words **mom**, **elected**, **president**, and **trillionaire** feature
    in the top 10\. Strange set, yet interesting. More on this in a bit.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**妈妈**、**当选**、**总统**和**亿万富翁**这些词出现在前十位。这个组合很奇怪，但很有趣。关于这一点，我们稍后再详细讨论。'
- en: Health features high in the list, but doesn't make it to the top 10\. So, it
    seems like health is on the cards but not very high. This is the same for **fitness**
    and **diet**.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康在列表中排名很高，但并未进入前十。因此，看起来健康是势在必行，但并不是特别突出。**健身**和**饮食**也是如此。
- en: Most of the words in this list are positive in essence. Words such as **happy**,
    **hope**, **positivity**, **change**, and so on all point to the upbeat mood while
    taking up New Year's resolutions!
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表中的大多数单词在本质上都是积极的。例如，**快乐**、**希望**、**积极**、**改变**等单词都指向了乐观的情绪，在迎接新年决心时！
- en: Though the preceding graph gives us quite a lot of information regarding the
    words and their frequencies in a nice layout, it still doesn't show us the full
    picture. Remember that we crafted a subset of items from our data set before generating
    this graph? We did that on purpose, otherwise the graph would have become too
    long and words with lesser frequencies would clutter the whole thing. Another
    point which this graph misses out is the relative difference in the frequencies.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的图表以很好的布局方式为我们提供了很多关于单词及其频率的信息，但它仍然没有展示出完整的画面。记住，我们在生成这个图表之前，故意从数据集中提取了一个子集？我们这样做是有目的的，否则图表会变得过长，频率较低的单词会使得整个图表显得杂乱。这个图表遗漏的另一个点是频率之间的相对差异。
- en: 'If our aim is to see the relative difference between the frequencies, we need
    a different visualization altogether. Here comes word cloud to the rescue. Using
    the `wordcloud` library, we can easily generate word clouds from a dataframe using
    a one liner:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的目标是看到频率之间的相对差异，我们需要一种不同的可视化方式。这时，词云就派上用场了。使用`wordcloud`库，我们可以轻松地从数据框中生成词云，只需一行代码：
- en: '[PRE12]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The wordcloud using the complete data frame looks something like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用完整数据集生成的词云看起来大致如下：
- en: '![Frequent words and associations](img/00229.jpeg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![频繁单词及其关联](img/00229.jpeg)'
- en: The preceding word cloud renders words in decreasing order of frequency. The
    size of each word emphasizes its frequency. You can play around with the `wordcloud`
    function to generate some interesting visualizations or even art!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的词云按照频率递减的顺序显示单词。每个单词的大小强调其频率。你可以尝试使用`wordcloud`函数生成一些有趣的视觉或艺术作品！
- en: 'A lot of words appear in the preceding graphs, but isn''t it rather interesting
    to see the word trillionaire pop up in the top 10? What could be the reason for
    it? Was it a spam post by a bot, or a tweet by some celebrity that went viral,
    or something completely different altogether? Let''s check out the top tweet in
    this list and see if it contains the word trillionaire:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表中出现了很多单词，但看到**亿万富翁**这个词出现在前十位，难道不是很有趣吗？这背后的原因是什么？是机器人发出的垃圾邮件，还是某个名人爆红的推文，或者是完全不同的事情？让我们查看这个列表中的顶级推文，看看它是否包含**亿万富翁**这个词：
- en: '[PRE13]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following screenshot is what you get:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是您会得到的结果：
- en: '![Frequent words and associations](img/00230.jpeg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![频繁单词及其关联](img/00230.jpeg)'
- en: 'It turns out that our hunch was right. It was a New Year resolution tweet by
    a celebrity that went viral. A quick search on Twitter reveals the tweet:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明我们的猜测是正确的。这是一条名人发布的、迅速走红的新年决心推文。在Twitter上快速搜索，我们发现这条推文：
- en: '![Frequent words and associations](img/00231.jpeg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![频繁单词及其关联](img/00231.jpeg)'
- en: 'Image source: [https://twitter.com/mishacollins?lang=en](https://twitter.com/mishacollins?lang=en)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[https://twitter.com/mishacollins?lang=en](https://twitter.com/mishacollins?lang=en)
- en: A bit further searching reveals Misha Collins is a famous actor from the television
    series Supernatural. We can also see that the above resolution was retweeted a
    staggering 5k times! It's interesting to note that the number of likes is 14k,
    outnumbering the retweets. Can we infer that tweeple prefer likes/hearts to retweets?
    It can also be seen that words such as mom, learn, trillionaire, elected, and
    President all occur as most frequent words without a doubt. Indirectly, we can
    also infer that Supernatural has a huge fan following on Twitter and that Castiel
    (Misha's role in the TV series) is a popular character from the show. A bit of
    a surprise is his resolution to learn to crochet, no?
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步搜索发现，Misha Collins是电视剧《超自然力量》中的著名演员。我们还可以看到，上述决议被转发惊人的5k次！值得注意的是，点赞数达到14k，超过了转发数。我们能推断出推友们更喜欢点赞/心形符号而不是转发吗？我们还可以看到，诸如mom、learn、trillionaire、elected和President等词汇无疑都是最常见的词汇。间接地，我们也可以推断出《超自然力量》在Twitter上拥有庞大的粉丝群，而Castiel（Misha在电视剧中的角色）是该剧中一个受欢迎的角色。他决定学习钩针，这有点令人惊讶吗？
- en: Moving on from supernatural stuff, let us go back to the fitness debate. Fitness
    is important to most of us. Activities such as exercising or hitting the gym see
    a surge during the initial months/weeks of the year. Let's see how health-conscious
    our friends on Twitter are!
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 从超自然的事物转移到健身辩论。健身对我们大多数人来说都很重要。像锻炼或去健身房这样的活动在年初的头几个月/几周会激增。让我们看看Twitter上的朋友们有多注重健康！
- en: 'Since a lot of words such as health, diet, fitness, gym, and so on point towards
    a healthy lifestyle, let us try and find words associated with the word *fitness*
    itself. `findAssocs` is a handy function which helps us find words from a term-document
    matrix that have at least a specified level of correlation to a given word. We
    will use the output from this function to prepare a term-association (correlation)
    graph using `ggplot`. The process is similar to how we prepared the preceding
    frequency graph:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多词汇如健康、饮食、健身、健身房等都与健康的生活方式相关，让我们尝试找到与“健身”一词本身相关的词汇。“findAssocs”是一个方便的函数，它可以帮助我们从词-文档矩阵中找到与给定词汇至少有指定程度相关性的词汇。我们将使用该函数的输出结果，使用`ggplot`准备一个词-关联（相关性）图。这个过程与准备前面的频率图类似：
- en: '[PRE14]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The words most closely correlated to the word fitness are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 与“健康”一词最密切相关的词汇如下：
- en: '![Frequent words and associations](img/00232.jpeg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![频繁词汇及其关联](img/00232.jpeg)'
- en: 'The same data is more readable in graphical form, as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的数据以图形形式更易于阅读，如下所示：
- en: '![Frequent words and associations](img/00233.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![频繁词汇及其关联](img/00233.jpeg)'
- en: As evident from the preceding graph, terms such as **lossweight**, **workout**,
    **getfit**, and so on. prove our point that tweeple are as concerned about health
    as we are. It is interesting to note the occurrence of the term *yogavideos* in
    this list. It looks like yoga is catching up with other techniques of staying
    fit in 2016\. There's **meditation** on the list too.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，诸如**减肥**、**锻炼**、**getfit**等术语证明了我们的观点，即推友们对健康的关注程度与我们一样。值得注意的是，列表中出现了“yogavideos”这个术语。看起来在2016年，瑜伽似乎正在赶上其他保持健康的技术。列表中还有**冥想**。
- en: Popular devices
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流行设备
- en: So far, we have dealt with the visible components of a tweet, such as the text,
    retweet counts, and so on, and we were able to extract many interesting insights.
    Let us take out our precision tools and dig deeper into our data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经处理了推文的可见组件，如文本、转发次数等，并且能够提取许多有趣的见解。让我们拿出我们的精确工具，更深入地挖掘我们的数据。
- en: As mentioned a couple times in the above sections, a tweet has far more information
    than what meets the eye. One such piece of information is about the source of
    the tweet. Twitter was born of the SMS era, and many of its characteristics, such
    as the 140 character word limit, are reminiscent of that era. It would be interesting
    to see how tweeple use Twitter, that is, what devices are used to access and post
    on Twitter frequently. Though the world has moved a long way from the SMS era,
    mobile phones are ubiquitous. To get this information, we will make use of the
    attribute `tweetSource` from our dataframe `trendingTweets.df`. We created this
    additional attribute from the `statusSource` attribute already existing in the
    `tweet` object (see the beginning of this section for a quick recap).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如上几节所提到的几次，一条推文所包含的信息远比表面所见的多。其中一条信息就是关于推文的来源。Twitter诞生于短信时代，其许多特征，如140个字符的字数限制，都让人联想到那个时代。了解人们如何使用Twitter，即经常用来访问和发布推文的设备，将会很有趣。尽管世界已经远离了短信时代，但手机无处不在。为了获取这些信息，我们将利用我们的数据框`trendingTweets.df`中的属性`tweetSource`。我们是从`tweet`对象中已经存在的`statusSource`属性创建了这个附加属性（参见本节开头快速回顾）。
- en: We shall use a subset of the data frame `trendingTweets.df` based upon retweet
    counts for the sake of clarity. We will use `ggplot` again to visualize our results.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，我们将使用基于转发次数的`trendingTweets.df`数据框的子集。我们再次使用`ggplot`来可视化我们的结果。
- en: '[PRE15]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following plot is your result:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表是您的结果：
- en: '![Popular devices](img/00234.jpeg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![流行设备](img/00234.jpeg)'
- en: Without a doubt, the iPhone is the most preferred device, followed by Android
    and the Web. It is interesting to see that people use the Web/website to retweet
    more than the iPad! Windows Phone clearly has some serious issues to tackle here.
    Can we also infer that the iPhone is the preferred device amongst tweeples? Or
    does the iPhone provide a better experience than any other device for Twitter?
    Or we could even go deeper and say that Twitter on iPhone has an easier-to-access
    "retweets" button than any other device. Inferences such as these and many more,
    require a bit more digging than this, but all of this has a lot of knowledge/potential
    that could be used by managements, UX teams, and so on to improve and change things
    around.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，iPhone是最受欢迎的设备，其次是Android和网页。有趣的是，人们使用网页/网站转发推文的次数比iPad还要多！Windows Phone显然在这里有一些严重的问题需要解决。我们也可以推断iPhone是tweeples的首选设备吗？或者iPhone为Twitter提供了比其他设备更好的体验？或者我们甚至可以更进一步，说iPhone上的Twitter比任何其他设备都有一个更容易访问的“转发”按钮。这样的推断还有很多，但所有这些都蕴含着大量的知识/潜力，可以被管理层、用户体验团队等用来改进和改变事物。
- en: Hierarchical clustering
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层次聚类
- en: We have seen clustering and classification in previous chapters (see [Chapter
    2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8 "Chapter 2. Let's
    Help Machines Learn"), *Let's Help Machines Learn*) and uncovered some interesting
    facts about the data at hand. For our current use case, even though our tweets
    are all related to 2016 resolutions, we can never be sure of the kinds of resolutions
    tweeple make. This makes it a very apt use case for hierarchical clustering. Unlike
    k-means or other clustering algorithms that require a preset number of clusters
    before computation, hierarchical clustering algorithms work independently of it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的章节中已经看到了聚类和分类（参见[第2章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "第2章。让我们帮助机器学习")，*让我们帮助机器学习*)，并揭示了关于手头数据的某些有趣事实。对于我们的当前用例，尽管我们的推文都与2016年的决心有关，但我们永远无法确定tweeples会做出什么样的决心。这使得层次聚类成为一个非常合适的用例。与需要预先设置集群数量的k-means或其他聚类算法不同，层次聚类算法在计算时不依赖于它。
- en: 'Let us take this opportunity to understand hierarchical clustering before we
    apply it to our data. Hierarchical clustering, like any other clustering algorithm,
    helps us group similar items together. The exact details for this algorithm in
    general can be explained as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将层次聚类应用于我们的数据之前，让我们抓住这个机会来理解层次聚类。层次聚类，就像任何其他聚类算法一样，帮助我们将相似的项目分组在一起。这个算法的一般细节可以解释如下：
- en: '**Initialize**: This is the first step, where each element is assigned to a
    cluster of its own. For a dataset containing *n* elements, the algorithm creates
    *n* different clusters with one element in each of them. A distance/similarity
    measure is decided at this step.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始化**：这是第一步，其中每个元素被分配到它自己的集群中。对于一个包含*n*个元素的集合，算法创建了*n*个不同的集群，每个集群中有一个元素。在这一步决定了一个距离/相似度度量。'
- en: '**Merge**: During this step, depending upon the distance/similarity measure
    chosen, the closest pair of clusters are identified and merged into a single cluster.
    This step results in one fewer clusters than the total clusters so far.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合并**：在此步骤中，根据选择的距离/相似性度量，识别最近的簇对并将它们合并成一个簇。这一步骤的结果是比迄今为止的总簇数少一个簇。'
- en: '**Compute**/**recompute**: We compute/recompute distances/similarities between
    the new cluster formed in the Merge step and the existing clusters.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算**/**重新计算**：我们计算/重新计算在合并步骤中形成的新簇与现有簇之间的距离/相似性。'
- en: The **merge** and **compute** steps are repeated until we are left with a single
    cluster containing all *n* items. As the name suggests, this algorithm generates
    a hierarchical structure with the leaves denoting individual elements as clusters
    combined based upon similarity/distance as we go toward the root of the tree.
    The output tree is generally referred to as a **dendrogram**.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**合并**和**计算**步骤会重复进行，直到我们只剩下一个包含所有*n*个项目的单个簇。正如其名所示，此算法生成一个层次结构，叶子表示基于相似性/距离结合的个体元素簇，随着我们向树根靠近。输出树通常被称为**树状图**。'
- en: The merge step is where variations of this algorithm exist. There are several
    ways in which the closest clusters could be identified. From simple methods, such
    as single-link, which consider the shortest distance between any two elements
    of the two clusters in consideration as the distance measure, to complex ones
    such as Ward's method which uses variance to find the most compact clusters, there
    are several methods that could be employed depending upon the use case.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 合并步骤是此算法存在变体的地方。有几种方法可以识别最近的簇。从简单的方法，如单链，它考虑两个簇中任何两个元素之间的最短距离作为距离度量，到复杂的方法，如Ward的方法，它使用方差来找到最紧凑的簇，有几种方法可以根据用例采用。
- en: Coming back to the Twitter world, let us use hierarchical clustering to see
    which terms/tweets are the closest. For our current use case, we will use the
    single method for our merge criteria. You may try out different algorithms and
    observe the differences.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 回到Twitter世界，让我们使用层次聚类来查看哪些术语/推文是最接近的。对于我们的当前用例，我们将使用单一方法作为合并标准。您可以尝试不同的算法并观察差异。
- en: 'To perform hierarchical clustering, we first treat our dataset to remove sparse
    terms for the sake of clarity. For this, the `removeSparseTerms` function helps
    us remove rows of data that have sparsity below a specified limit. We then use
    the `hclust` utility to form clusters. The output of this utility is directly
    plottable. Let us write some code for this:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行层次聚类，我们首先处理我们的数据集以去除稀疏术语，以便于清晰。为此，`removeSparseTerms`函数帮助我们删除具有低于指定限制的稀疏性的数据行。然后我们使用`hclust`实用程序来形成簇。此实用程序输出的结果可以直接绘制。让我们为此编写一些代码：
- en: '[PRE16]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output *dendrogram* is amazingly simple to understand:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的**树状图**非常简单易懂：
- en: '![Hierarchical clustering](img/00235.jpeg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![层次聚类](img/00235.jpeg)'
- en: If you observe the second cluster from right, it contains terms **trillionaire**,
    **elected**, **mom**, **call**, and so on. Mapping back to the top retweeted tweet
    from Mischa Collins, all these terms are mentioned in that single tweet and our
    algorithm has rightly clustered them together. Smart, isn't it? As a small exercise,
    observe other clusters and see how the terms occur in the tweets that contain
    them. One important observation to make here is that the *dendrogram* correctly
    maps all frequent terms under a single root, which reaffirms that all these terms
    point to our central theme of 2016 resolutions!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您观察右侧第二个簇，它包含术语**万亿富翁**、**当选**、**妈妈**、**打电话**等等。将这些术语映射回Mischa Collins的顶转发推文，所有这些术语都在那条推文中被提及，并且我们的算法正确地将它们聚类在一起。聪明，不是吗？作为一个小练习，观察其他簇并看看这些术语在包含它们的推文中是如何出现的。在这里的一个重要观察是，**树状图**正确地将所有频繁术语映射到单个根下，这再次证实了所有这些术语都指向我们2016年决议的中心主题！
- en: Topic modeling
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主题建模
- en: So far, our analysis has been about tweets related to New Year's resolutions
    from users across the world. We have analyzed tweets related to a topic of our
    choice. Ignoring spam and other noisy tweets, more or less, our data conformed
    to a single topic. The topic itself constituted a group of words (such as health,
    trillionaire, fitness, diet, mom, and so on) which broadly describe different
    resolutions. To broaden our scope of analysis and to discover even more insights,
    let us touch upon the concept of topic modeling.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的分析主要关于来自世界各地的用户有关新年决心的推文。我们已经分析了与我们选择的主题相关的推文。忽略垃圾邮件和其他噪声推文，我们的数据大致符合一个单一的主题。这个主题本身构成了一组单词（如健康、亿万富翁、健身、饮食、妈妈等），这些单词广泛描述了不同的决心。为了拓宽我们的分析范围并发现更多见解，让我们来谈谈主题建模的概念。
- en: Topic modeling is a process of discovering patterns in a corpus of unlabeled
    text that represents the gist of the corpus. A topic itself may be described as
    a group of words that occur together to describe a large body of text.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模是一个发现未标记文本语料库中模式的过程，它代表了语料库的精髓。一个主题本身可以描述为一组共同出现的单词，用来描述大量文本。
- en: 'Another definition tweeted during one of the conferences on topic modeling:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在一次关于主题建模的会议期间提到的另一个定义：
- en: '![Topic modeling](img/00236.jpeg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![主题建模](img/00236.jpeg)'
- en: 'Image source: [https://twitter.com/footnotesrising/status/264823621799780353](https://twitter.com/footnotesrising/status/264823621799780353)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[https://twitter.com/footnotesrising/status/264823621799780353](https://twitter.com/footnotesrising/status/264823621799780353)
- en: The aim of topic modeling is to automatically identify the underlying theme
    of a corpus and thus be useful in applications that require information retrieval
    based on a theme but in absence of known keywords (the exact opposite of our current
    usage of search engines). For example, wouldn't it be amazing to learn about relations
    between two countries from a newspaper's archive by using the theme *relations
    between country one and country two* rather than searching for a keyword and then
    following link after link. Please note that following links to discover information
    is equally powerful, but it leaves a lot to be desired.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模的目的是自动识别语料库的潜在主题，因此对于需要基于主题进行信息检索的应用程序（但在没有已知关键词的情况下）是有用的。例如，通过使用“一国与另一国的关系”这样的主题而不是搜索关键词然后跟随链接，从报纸档案中了解两个国家之间的关系，这不是很令人惊讶吗？请注意，通过跟随链接来发现信息同样强大，但它还有很多不足之处。
- en: One of the ways to perform topic modeling is through **Latent Dirichlet Allocation**
    (**LDA**); it is one of the most powerful and widely used models.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 执行主题建模的一种方式是通过**潜在狄利克雷分配**（**LDA**）；它是功能最强大且应用最广泛的模型之一。
- en: LDA was presented by David M Blie in his paper *Introduction to Probabilistic
    Topic Models* in 2003\. LDA, as his paper says, can be defined as a generative
    model that allows sets of observations to be explained by unobserved groups that
    explain why some parts of the data is similar. LDA works upon the assumption that
    documents exhibit multiple topics.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: LDA由David M Blie在2003年的论文《概率主题模型导论》中提出。正如他的论文所说，LDA可以被定义为一个生成模型，它允许通过未观察到的组来解释一组观察结果，这些组解释了为什么数据的一些部分是相似的。LDA基于这样的假设，即文档表现出多个主题。
- en: LDA is a probabilistic model and the mathematics of it are fairly involved and
    beyond the scope of this book. In a nonmathematical way, LDA can be explained
    as a model/process that helps identify the topics that have resulted in the generation
    of a collection of documents.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: LDA是一个概率模型，其数学相当复杂，超出了本书的范围。以非数学的方式，LDA可以被解释为一个模型/过程，它有助于识别导致一组文档生成的主题。
- en: Note
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For further reading, refer to Blei's paper.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进一步阅读，请参阅Blei的论文。
- en: '[https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf](https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf](https://www.cs.princeton.edu/~blei/papers/Blei2011.pdf)'
- en: 'A blog which explains everything in simple words:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇用简单语言解释一切的博客：
- en: '[http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/](http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/](http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/)'
- en: For our purpose/use case, we can assume LDA as a model/process which helps us
    to identify the underlying (hidden/latent) topics from a corpus of unlabeled text.
    Luckily, R abstracts most of the mathematical details in the form of a library
    called `topicmodels`.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的/用例，我们可以假设LDA是一个模型/过程，它帮助我们从一个未标记文本的语料库中识别潜在（隐藏/潜在）主题。幸运的是，R将大部分数学细节以名为`topicmodels`的库的形式抽象出来。
- en: 'For the purpose of topic modeling, we shall use a new set of tweets. The **International
    Space** **Station** (**ISS**) has multiple Twitter handles, and one of them is
    `@ISS_Research`, which particularly caters to research related tweets from the
    ISS. Let us explore what `@ISS_Research` is up to these days by analyzing the
    tweets from its timeline. We will analyze these tweets to identify the underlying
    topics of research at the ISS. For this purpose, we will use the same process
    to extract tweets and perform transformations/cleanup as we have done before.
    The following snippet of code does this:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行主题建模，我们将使用一组新的推文。国际空间站（**ISS**）有多个Twitter账号，其中之一是`@ISS_Research`，它特别针对来自ISS的研究相关推文。让我们通过分析其时间线上的推文来探索`@ISS_Research`最近在忙些什么。我们将分析这些推文，以识别ISS研究背后的主题。为此，我们将使用与之前相同的过程提取推文并进行转换/清理。以下代码片段就是这样做的：
- en: '[PRE17]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have tweets in the required format, the `LDA` utility from the `topicmodels`
    package helps us uncover the hidden topics/patterns. The LDA utility requires
    the number of topics as input along with the document-term matrix. We will try
    eight topics for now. The following code uses `LDA` to extract six terms for each
    of the eight topics:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了所需格式的推文，`topicmodels`包中的`LDA`实用程序帮助我们揭示隐藏的主题/模式。LDA实用程序需要输入主题数量以及文档-术语矩阵。我们现在将尝试八个主题。以下代码使用`LDA`为八个主题中的每一个提取六个术语：
- en: '[PRE19]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The list of topics generated using LDA is as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LDA生成的主题列表如下：
- en: '![Topic modeling](img/00237.jpeg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![主题建模](img/00237.jpeg)'
- en: 'A visual representation would be easier to understand. We can make use of `qplot`
    to quickly plot the topics across time on an area chart, as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一个视觉表示将更容易理解。我们可以利用`qplot`快速在面积图上按时间绘制主题，如下所示：
- en: '[PRE20]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The generated chart looks like the following screenshot:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表看起来如下截图所示：
- en: '![Topic modeling](img/00238.jpeg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![主题建模](img/00238.jpeg)'
- en: Let us now analyze the outputs. The list of terms per topic generated by LDA
    seems to give us a nice insight into the kind of work/research going on at the
    ISS. Terms such as mars, microgravity, flower, Cygnus, and so on tell us about
    the main areas of research or at least the topics about which scientists/astronauts
    on the ISS are talking. Terms such as stationcdrkelly and astrotimpeake look more
    like Twitter handles.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在分析输出结果。LDA生成的每个主题的术语列表似乎给我们提供了对ISS上正在进行的工作/研究的一些很好的洞察。诸如火星、微重力、花朵、Cygnus等术语告诉我们主要的研究领域或至少科学家/宇航员在ISS上讨论的主题。诸如stationcdrkelly和astrotimpeake之类的术语看起来更像是Twitter账号。
- en: Note
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A quick exercise would be to use the current `@ISS_Research` timeline data and
    mine for the handles, such as `stationcdrkelly`, to discover more information.
    Who knows, it may turn out be a nice list of astronauts to follow!
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速练习是使用当前的`@ISS_Research`时间线数据，挖掘如`stationcdrkelly`这样的处理，以发现更多信息。谁知道呢，这可能会变成一个很好的宇航员名单来关注！
- en: The `qplot` output adds the time dimension to our plain list of topics. Analyzing
    topics across the time dimension helps us understand when a particular research
    topic was discussed or when something amazing was announced. Topic two in the
    list, or the fourth one from the top in the graph legend comprises the word flower.
    Since scientists were successful in blooming some orange flowers in space recently,
    the above graph helps us get an idea that the news first broke on Twitter on/around
    15^(th) January. A quick look on Twitter/news websites confirms that the news
    broke by tweet on 18^(th) January 2016…close enough!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`qplot`输出为我们的普通主题列表添加了时间维度。分析时间维度上的主题有助于我们了解特定研究主题何时被讨论，或者何时宣布了令人惊叹的事情。列表中的第二个主题，或者图例顶部的第四个主题包含单词flower。由于科学家最近在太空中成功培育了一些橙色花朵，上面的图表帮助我们得出结论，新闻最早在1月15日左右在Twitter上发布。快速查看Twitter/新闻网站确认，新闻是在2016年1月18日通过推文发布的……非常接近！'
- en: Tip
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Colorful area charts**'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**彩色面积图**'
- en: Try removing the option `scale_fill_grey()` from `qplot` to get some beautiful
    charts that are far easier to read than plain gray scale.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试从`qplot`中移除`scale_fill_grey()`选项，以获得一些比纯灰色更容易阅读的美丽图表。
- en: So, finally we learnt about topic modeling using LDA on data from the ISS and
    found what amazing things scientists and astronauts are doing up there in outer
    space.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们最终学习了使用LDA在ISS数据上进行的主题建模，并发现了科学家和宇航员在太空中所做的一些令人惊叹的事情。
- en: Challenges with social network data mining
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 社会网络数据挖掘的挑战
- en: 'Before we close the chapter, let us look at the different challenges posed
    by social networks to the process of data mining. The following points present
    a few arguments, questions, and challenges:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束这一章之前，让我们看看社交网络对数据挖掘过程提出的不同挑战。以下是一些论点、问题和挑战：
- en: No doubt the data generated by social networks classifies as big data in every
    aspect. It has all the volume, velocity, and variety in it to overwhelm any system.
    Yet, interestingly, the challenge with such a huge source of data is the availability
    of enough granular data. If we zoom into our data sets and try to use data on
    a per user basis, we find that there isn't enough data to do some of the most
    common tasks, such as making recommendations!
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毫无疑问，社交网络生成数据在各个方面都归类为大数据。它具有所有体积、速度和多样性，足以压倒任何系统。然而，有趣的是，如此庞大的数据源所面临的挑战是足够细粒度数据的可用性。如果我们放大我们的数据集，并尝试基于每个用户使用数据，我们会发现没有足够的数据来完成一些最常见的工作，比如做出推荐！
- en: Social networks such as Twitter handle millions of users creating and sharing
    tons of data every second. To keep their systems up and running at all times,
    they put limits upon the amount of data that can be tapped using their APIs (security
    is also a major reason behind these limits, though). These limits put data science
    efforts in a quandary as it is difficult to obtain sufficient samples of data
    that represent the population correctly/completely. Insufficient samples may result
    in incorrect patterns or missing out on patterns altogether.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如Twitter这样的社交网络每秒处理数百万用户创建和分享的大量数据。为了确保他们的系统始终运行，他们会对通过API获取的数据量设置限制（安全性也是这些限制背后的一个主要原因）。这些限制使数据科学工作陷入困境，因为很难获得足够的数据样本来正确/完整地代表总体。样本不足可能会导致错误的模式或完全错过模式。
- en: Preprocessing and evaluation of results is also a challenge with social network
    analysis. While preprocessing data, we remove noisy content. With data coming
    in all shapes and sizes, determining noisy content is far more of a challenge
    than simply removing stopwords. Evaluation of results is another challenge, as
    there is no ground truth available in most cases, and due to the limitations presented
    here and otherwise, it is difficult to ascertain the validity of results with
    confidence.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会网络分析中的预处理和结果评估也是一个挑战。在预处理数据时，我们会移除噪声内容。由于数据以各种形状和大小涌入，确定噪声内容比简单地移除停用词更具挑战性。由于大多数情况下没有可用的基准事实，以及由于此处和其它方面的限制，评估结果也是一个挑战，很难有信心确定结果的可靠性。
- en: The arguments/challenges presented above call for innovative and creative ways
    to be devised by data scientists, and that is what makes their job interesting
    and highly rewarding.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 上文提出的论点/挑战要求数据科学家设计出创新和创造性的方法，这也是他们的工作有趣且极具回报性的原因。
- en: References
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Some of the well-known books on visualization are as follows :'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 一些关于可视化的知名书籍如下：
- en: '[http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001](http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001](http://www.amazon.in/Information-Dashboard-Design-At-Glance/dp/1938377001)'
- en: '[http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X](http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X](http://www.amazon.com/Visual-Display-Quantitative-Information/dp/096139210X)'
- en: '[http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192](http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192](http://www.amazon.com/Information-Visualization-Second-Interactive-Technologies/dp/1558608192)'
- en: 'Some well known blogs on this are as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的一些知名博客如下：
- en: '**Tableau** **specific**: [http://www.jewelloree.com/](http://www.jewelloree.com/)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tableau** **特定**：[http://www.jewelloree.com/](http://www.jewelloree.com/)'
- en: '[http://flowingdata.com/](http://flowingdata.com/)'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://flowingdata.com/](http://flowingdata.com/)'
- en: '[http://www.informationisbeautiful.net/](http://www.informationisbeautiful.net/)'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.informationisbeautiful.net/](http://www.informationisbeautiful.net/)'
- en: '[http://infosthetics.com/](http://infosthetics.com/)'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://infosthetics.com/](http://infosthetics.com/)'
- en: '[http://www.visualisingdata.com/](http://www.visualisingdata.com/)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.visualisingdata.com/](http://www.visualisingdata.com/)'
- en: '[https://eagereyes.org/](https://eagereyes.org/)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://eagereyes.org/](https://eagereyes.org/)'
- en: '[http://thedailyviz.com/](http://thedailyviz.com/)'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://thedailyviz.com/](http://thedailyviz.com/)'
- en: '**D3**: [https://d3js.org/](https://d3js.org/)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D3**: [https://d3js.org/](https://d3js.org/)'
- en: Summary
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Social network analysis is one the trending topics in the world of data science.
    As we have seen throughout the chapter, these platforms not only provide us with
    ways to connect but they also present a unique opportunity to study human dynamics
    at a global scale. Through this chapter, we have learned some interesting techniques.
    We started off by understanding data mining in the social network context followed
    by the importance of visualizations. We focused on Twitter and understood different
    objects and APIs to manipulate them. We used various packages from R, such as
    `TwitteR` and `TM`, to connect, collect, and manipulate data for our analysis.
    We used data from Twitter to learn about frequency throughout. Finally, we presented
    some of the challenges posed by social networks words and associations, popular
    devices used by tweeple, hierarchical clustering and even touched upon topic modeling.
    We used `ggplot2` and `wordcloud` to visualize our results to the data mining
    process in general. While concluding this chapter, we are sure that by now you
    can appreciate the amazing dynamics behind these platforms and R's ability to
    analyze it all. We aren't done with `@Twitter` yet, hold on to your `#sentiments`!
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络分析是数据科学领域的一个热门话题。正如我们在本章中看到的，这些平台不仅为我们提供了连接的方式，而且也为我们提供了一个独特的机会来研究全球范围内的人类动态。通过本章，我们学习了一些有趣的技术。我们首先从理解社交网络环境中的数据挖掘开始，接着讨论了可视化的重要性。我们专注于Twitter，并了解了不同的对象和API来操作它们。我们使用了R的各种包，如`TwitteR`和`TM`，来连接、收集和操作我们的分析数据。我们使用Twitter的数据来了解频率分布。最后，我们展示了社交网络词汇和关联、推特用户常用的流行设备、层次聚类甚至触及了主题建模所提出的挑战。我们使用了`ggplot2`和`wordcloud`来可视化我们的结果，以及数据挖掘过程。在总结本章时，我们确信你现在可以欣赏到这些平台背后的惊人动态以及R分析这些动态的能力。我们还没有结束对`@Twitter`的分析，请继续关注你的`#sentiments`！
