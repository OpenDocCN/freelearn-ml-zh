- en: Java Libraries and Platforms for Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java机器学习库和平台
- en: Implementing machine learning algorithms by yourself is probably the best way
    to learn machine learning, but you can progress much faster if you step on the
    shoulders of the giants and leverage one of the existing open source libraries.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自己实现机器学习算法可能是学习机器学习的最佳方式，但如果你站在巨人的肩膀上，利用现有的开源库，你可以进步得更快。
- en: This chapter reviews various libraries and platforms for machine learning in
    Java. The goal is to understand what each library brings to the table and what
    kind of problems it is able to solve.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章回顾了Java中用于机器学习的各种库和平台。目标是了解每个库能为桌面带来什么，以及它能解决什么类型的问题。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The requirement of Java for implementing a machine learning application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java在实现机器学习应用中的必要性
- en: Weka, a general purpose machine learning platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weka，一个通用的机器学习平台
- en: The Java machine learning library, a collection of machine learning algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java机器学习库，一组机器学习算法
- en: Apache Mahout, a scalable machine learning platform
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mahout，一个可扩展的机器学习平台
- en: Apache Spark, a distributed machine learning library
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Spark，一个分布式机器学习库
- en: Deeplearning4j, a deep learning library
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deeplearning4j，一个深度学习库
- en: MALLET, a text mining library
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MALLET，一个文本挖掘库
- en: We'll also discuss how to design the complete machine learning application stack
    for both single-machine and big data apps by using these libraries with other
    components.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论如何使用这些库以及其他组件来设计适用于单机和大数据应用的完整机器学习应用堆栈。
- en: The need for Java
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java在实现机器学习应用中的需求
- en: New machine learning algorithms are often first scripted at university labs,
    gluing together several languages such as shell scripting, Python, R, MATLAB,
    Scala, or C++ to provide a new concept and theoretically analyze its properties.
    An algorithm might take a long path of refactoring before it lands in a library
    with standardized input or output and interfaces. While Python, R, and MATLAB
    are quite popular, they are mainly used for scripting, research, and experimenting.
    Java, on the other hand, is the de facto enterprise language, which could be attributed
    to static typing, robust IDE support, good maintainability, as well as decent
    threading model and high performance concurrent data structure libraries. Moreover,
    there are already many Java libraries available for machine learning, which makes
    it really convenient to apply them in existing Java applications and leverage
    powerful machine learning capabilities.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 新的机器学习算法通常首先在大学实验室中编写脚本，将几种语言如shell脚本、Python、R、MATLAB、Scala或C++粘合在一起，以提供一个新的概念并对其属性进行理论分析。一个算法可能需要经过多次重构才能进入一个具有标准化输入或输出和接口的库。虽然Python、R和MATLAB相当流行，但它们主要用于脚本编写、研究和实验。另一方面，Java是事实上的企业语言，这可以归因于静态类型、强大的IDE支持、良好的可维护性以及不错的线程模型和高性能并发数据结构库。此外，已经有许多Java库可用于机器学习，这使得在现有的Java应用程序中应用它们并利用强大的机器学习功能变得非常方便。
- en: Machine learning libraries
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习库
- en: There are over 70 Java-based open source machine learning projects listed on
    the [MLOSS.org](https://mloss.org/software/) website, and probably many more unlisted
    projects live at university servers, GitHub, or Bitbucket. In this section, we
    will review the major libraries and platforms, the kind of problems they can solve,
    the algorithms they support, and the kind of data they can work with.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[MLOSS.org](https://mloss.org/software/)网站上列出了超过70个基于Java的开源机器学习项目，可能还有更多未列出的项目存在于大学服务器、GitHub或Bitbucket上。在本节中，我们将回顾主要的库和平台，它们能解决的问题类型，它们支持的算法，以及它们可以处理的数据类型。
- en: Weka
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Weka
- en: '**Waikato Environment for Knowledge Analysis** (**WEKA**) is a machine learning
    library that was developed at the University of Waikato, New Zealand, and is probably
    the most well-known Java library. It is a general purpose library that is able
    to solve a wide variety of machine learning tasks, such as classification, regression,
    and clustering. It features a rich graphical user interface, command-line interface,
    and Java API. You can check out Weka at [http://www.cs.waikato.ac.nz/ml/weka/](http://www.cs.waikato.ac.nz/ml/weka/).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**Waikato环境知识分析**（**WEKA**）是一个在新西兰怀卡托大学开发的机器学习库，可能是最知名的Java库。它是一个通用的库，能够解决各种机器学习任务，如分类、回归和聚类。它具有丰富的图形用户界面、命令行界面和Java
    API。您可以在[http://www.cs.waikato.ac.nz/ml/weka/](http://www.cs.waikato.ac.nz/ml/weka/)上查看Weka。'
- en: 'At the time of writing this book, Weka contains 267 algorithms in total: data
    preprocessing (82), attribute selection (33), classification and regression (133),
    clustering (12), and association rules mining (7). Graphical interfaces are well
    suited for exploring your data, while the Java API allows you to develop new machine
    learning schemes and use the algorithms in your applications.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，Weka总共有267个算法：数据预处理（82个）、属性选择（33个）、分类和回归（133个）、聚类（12个）和关联规则挖掘（7个）。图形界面非常适合探索您的数据，而Java
    API允许您开发新的机器学习方案并在您的应用程序中使用这些算法。
- en: Weka is distributed under the **GNU General Public License** (**GNU GPL**),
    which means that you can copy, distribute, and modify it as long as you track
    changes in source files and keep it under GNU GPL. You can even distribute it
    commercially, but you must disclose the source code or obtain a commercial license.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Weka是在**GNU通用公共许可证**（**GNU GPL**）下分发的，这意味着您可以复制、分发和修改它，只要您跟踪源文件中的更改并保持其在GNU
    GPL之下。您甚至可以将其商业分发，但您必须披露源代码或获得商业许可证。
- en: 'In addition to several supported file formats, Weka features its own default
    data format, ARFF, to describe data by attribute-data pairs. It consists of two
    parts. The first part contains a header, which specifies all of the attributes
    and their types, for instance, nominal, numeric, date, and string. The second
    part contains the data, where each line corresponds to an instance. The last attribute
    in the header is implicitly considered the target variable and missing data is
    marked with a question mark. For example, returning to the example from [Chapter
    1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml), *Applied Machine Learning Quick
    Start*, the `Bob` instance written in an ARFF file format would be as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了支持多种文件格式外，Weka还特色其默认的数据格式ARFF，通过属性-数据对来描述数据。它由两部分组成。第一部分包含一个标题，它指定了所有属性及其类型，例如，名义、数值、日期和字符串。第二部分包含数据，其中每一行对应一个实例。标题中的最后一个属性隐式地被认为是目标变量，缺失数据用问号标记。例如，回到[第1章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)的例子，“应用机器学习快速入门”，用ARFF文件格式编写的`Bob`实例如下：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The file consists of three sections. The first section starts with the `@RELATION
    <String>` keyword, specifying the dataset name. The next section starts with the
    `@ATTRIBUTE` keyword, followed by the attribute name and type. The available types
    are `STRING`, `NUMERIC`, `DATE`, and a set of categorical values. The last attribute
    is implicitly assumed to be the target variable that we want to predict. The last
    section starts with the `@DATA` keyword, followed by one instance per line. Instance
    values are separated by commas and must follow the same order as attributes in
    the second section.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 文件由三个部分组成。第一部分以`@RELATION <String>`关键字开始，指定数据集名称。下一部分以`@ATTRIBUTE`关键字开始，后跟属性名称和类型。可用的类型有`STRING`、`NUMERIC`、`DATE`和一系列分类值。最后一个属性隐式地假设为目标变量，我们想要预测的变量。最后一部分以`@DATA`关键字开始，每行一个实例。实例值由逗号分隔，必须遵循第二部分中属性的相同顺序。
- en: More Weka examples will be demonstrated in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml),
    *Basic Algorithms – Classification, Regression, and Clustering*, and [Chapter
    4](6ac8d4de-1e7f-4f60-9cf0-93ab2fe55e4d.xhtml), *Customer Relationship Prediction
    with Ensembles*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 更多Weka的示例将在[第3章](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml)“基本算法——分类、回归和聚类”和[第4章](6ac8d4de-1e7f-4f60-9cf0-93ab2fe55e4d.xhtml)“使用集成进行客户关系预测”中演示。
- en: 'To learn more about Weka, pick up a quick-start book—*Weka How-to,* by *Kaluza, Packt
    Publishing* to start coding, or look into *Data Mining: Practical Machine Learning
    Tools and Techniques with Java Implementations* by *Witten and Frank*, *Morgan
    Kaufmann Publishers* for theoretical background and in-depth explanations.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '要了解更多关于Weka的信息，可以阅读一本快速入门书籍——由*Kaluza, Packt Publishing*出版的*Weka How-to*，开始编码，或者查阅*Witten
    and Frank*的*Data Mining: Practical Machine Learning Tools and Techniques with
    Java Implementations*，由*Morgan Kaufmann Publishers*出版，以获取理论背景和深入解释。'
- en: 'Weka''s Java API is organized into the following top-level packages:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Weka的Java API组织成以下顶级包：
- en: '`weka.associations`: These are data structures and algorithms for association
    rules learning, including **Apriori**, **predictive Apriori**, **FilteredAssociator**, **FP-Growth**,
    **Generalized Sequential Patterns** (**GSP**), **hotSpot**, and **Tertius**.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.associations`：这是关联规则学习的数据结构和算法，包括**Apriori**、**预测Apriori**、**FilteredAssociator**、**FP-Growth**、**广义序列模式**（**GSP**）、**hotSpot**和**Tertius**。'
- en: '`weka.classifiers`: These are supervised learning algorithms, evaluators, and
    data structures. The package is further split into the following components:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers`: 这些是监督学习算法、评估器和数据结构。该包进一步分为以下组件：'
- en: '`weka.classifiers.bayes`: This implements Bayesian methods, including Naive
    Bayes, Bayes net, Bayesian logistic regression, and so on.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.bayes`: 这实现了贝叶斯方法，包括朴素贝叶斯、贝叶斯网络、贝叶斯逻辑回归等等。'
- en: '`weka.classifiers.evaluation`: These are supervised evaluation algorithms for
    nominal and numerical prediction, such as evaluation statistics, confusion matrix,
    ROC curve, and so on.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.evaluation`: 这些是针对名义和数值预测的监督评估算法，例如评估统计、混淆矩阵、ROC曲线等等。'
- en: '`weka.classifiers.functions`: These are regression algorithms, including linear
    regression, isotonic regression, Gaussian processes, **Support Vector Machines **(**SVMs**),
    multilayer perceptron, voted perceptron, and others.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.functions`: 这些是回归算法，包括线性回归、同质回归、高斯过程、**支持向量机（SVMs**）、多层感知器、投票感知器等等。'
- en: '`weka.classifiers.lazy`: These are instance-based algorithms such as k-nearest
    neighbors, K*, and lazy Bayesian rules.'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.lazy`: 这些是基于实例的算法，例如k-最近邻、K*和懒惰贝叶斯规则。'
- en: '`weka.classifiers.meta`: These are supervised learning meta-algorithms, including
    AdaBoost, bagging, additive regression, random committee, and so on.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.meta`: 这些是监督学习元算法，包括AdaBoost、Bagging、加性回归、随机委员会等等。'
- en: '`weka.classifiers.mi`: These are multiple-instance learning algorithms, such
    as citation k-nearest neighbors, diverse density, AdaBoost, and others.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.mi`: 这些是多个实例学习算法，例如引用k-最近邻、多样性密度、AdaBoost等等。'
- en: '`weka.classifiers.rules`: These are decision tables and decision rules based
    on the separate-and-conquer approach, RIPPER, PART, PRISM, and so on.'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.rules`: 这些是基于分离征服方法的决策表和决策规则，包括RIPPER、PART、PRISM等等。'
- en: '`weka.classifiers.trees`: These are various decision trees algorithms, including
    ID3, C4.5, M5, functional tree, logistic tree, random forest, and so on.'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.trees`: 这些是各种决策树算法，包括ID3、C4.5、M5、功能树、逻辑树、随机森林等等。'
- en: '`weka.clusterers`: These are clustering algorithms, including k-means, CLOPE,
    Cobweb, DBSCAN hierarchical clustering, and FarthestFirst.'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.clusterers`: 这些是聚类算法，包括k-means、CLOPE、蜘蛛网、DBSCAN层次聚类和FarthestFirst。'
- en: '`weka.core`: These are various utility classes such as the attribute class,
    statistics class, and instance class.'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.core`: 这些是各种实用类，例如属性类、统计类和实例类。'
- en: '`weka.datagenerators`: These are data generators for classification, regression,
    and clustering algorithms.'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.datagenerators`: 这些是用于分类、回归和聚类算法的数据生成器。'
- en: '`weka.estimators`: These are various data distribution estimators for discrete/nominal
    domains, conditional probability estimations, and so on.'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.estimators`: 这些是针对离散/名义域的各种数据分布估计器，包括条件概率估计等等。'
- en: '`weka.experiment`: These are a set of classes supporting necessary configuration,
    datasets, model setups, and statistics to run experiments.'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.experiment`: 这些是一组支持必要配置、数据集、模型设置和统计信息的类，用于运行实验。'
- en: '`weka.filters`: These are attribute-based and instance-based selection algorithms
    for both supervised and unsupervised data preprocessing.'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.filters`: 这些是基于属性和实例的选择算法，用于监督和未监督数据的预处理。'
- en: '`weka.gui`: These are graphical interface implementing explorer, experimenter,
    and knowledge flow applications. The Weka Explorer allows you to investigate datasets,
    algorithms, as well as their parameters, and visualize datasets with scatter plots
    and other visualizations. The Weka Experimenter is used to design batches of experiments,
    but it can only be used for classification and regression problems.The Weka KnowledgeFlow
    implements a visual drag-and-drop user interface to build data flows and, for
    example, load data, apply filter, build classifier, and evaluate it.'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.gui`: 这些是实现探索者、实验者和知识流应用的图形界面。Weka探索者允许你调查数据集、算法以及它们的参数，并使用散点图和其他可视化方法可视化数据集。Weka实验者用于设计实验批次，但它只能用于分类和回归问题。Weka知识流实现了一个可视拖放用户界面来构建数据流，例如加载数据、应用过滤器、构建分类器并对其进行评估。'
- en: Java machine learning
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java机器学习
- en: The **Java Machine Learning Library** (**Java-ML**) is a collection of machine
    learning algorithms with a common interface for algorithms of the same type. It
    only features the Java API, and so it is primarily aimed at software engineers
    and programmers. Java-ML contains algorithms for data preprocessing, feature selection,
    classification, and clustering. In addition, it features several Weka bridges
    to access Weka's algorithms directly through the Java-ML API. It can be downloaded
    from [http://java-ml.sourceforge.net](http://java-ml.sourceforge.net/).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**Java机器学习库**（**Java-ML**）是一个具有相同类型算法通用接口的机器学习算法集合。它只提供Java API，因此主要面向软件工程师和程序员。Java-ML包含数据预处理、特征选择、分类和聚类的算法。此外，它还提供了一些Weka桥接，可以直接通过Java-ML
    API访问Weka的算法。可以从[http://java-ml.sourceforge.net](http://java-ml.sourceforge.net/)下载。'
- en: Java-ML is also a general-purpose machine learning library. Compared to Weka,
    it offers more consistent interfaces and implementations of recent algorithms
    that are not present in other packages, such as an extensive set of state-of-the-art
    similarity measures and feature-selection techniques, for example, **dynamic time
    warping** (**DTW**), random forest attribute evaluation, and so on. Java-ML is
    also available under the GNU GPL license.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Java-ML也是一个通用的机器学习库。与Weka相比，它提供了更一致的接口和实现，包括一些最新的算法，这些算法在其他包中不存在，例如，广泛的最先进的相似度度量集和特征选择技术，例如，**动态时间规整**（**DTW**）、随机森林属性评估等。Java-ML也遵循GNU
    GPL许可证。
- en: Java-ML supports all types of files as long as they contain one data sample
    per line and the features are separated by a symbol such as a comma, semicolon,
    or tab.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Java-ML支持所有类型的文件，只要它们每行包含一个数据样本，并且特征由逗号、分号或制表符等符号分隔。
- en: 'The library is organized around the following top-level packages:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 该库围绕以下顶级包组织：
- en: '`net.sf.javaml.classification`: These are classification algorithms, including
    Naive Bayes, random forests, bagging, self-organizing maps, k-nearest neighbors,
    and so on'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.classification`: 这些是分类算法，包括朴素贝叶斯、随机森林、装袋、自组织映射、k近邻等'
- en: '`net.sf.javaml.clustering`: These are clustering algorithms such as k-means,
    self-organizing maps, spatial clustering, Cobweb, ABC, and others'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.clustering`: 这些是聚类算法，如k-means、自组织映射、空间聚类、蜘蛛网、ABC等'
- en: '`net.sf.javaml.core`: These are classes representing instances and datasets'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.core`: 这些是表示实例和数据集的类'
- en: '`net.sf.javaml.distance`: These are algorithms that measure instance distance
    and similarity, for example, Chebyshev distance, cosine distance/similarity, Euclidean
    distance, Jaccard distance/similarity, Mahalanobis distance, Manhattan distance,
    Minkowski distance, Pearson correlation coefficient, Spearman''s footrule distance,
    DTW, and so on'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.distance`: 这些是测量实例距离和相似性的算法，例如，切比雪夫距离、余弦距离/相似度、欧几里得距离、杰卡德距离/相似度、马氏距离、曼哈顿距离、闵可夫斯基距离、皮尔逊相关系数、斯皮尔曼脚规距离、DTW等'
- en: '`net.sf.javaml.featureselection`: These are algorithms for feature evaluation,
    scoring, selection, and ranking, for instance, gain ratio, ReliefF, Kullback-Leibler
    divergence, symmetrical uncertainty, and so on'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.featureselection`: 这些是特征评估、评分、选择和排名的算法，例如，增益比率、ReliefF、Kullback-Leibler散度、对称不确定性等'
- en: '`net.sf.javaml.filter`: These are methods for manipulating instances by filtering,
    removing attributes, setting classes or attribute values, and so on'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.filter`: 这些是通过过滤、删除属性、设置类或属性值等操作实例的方法'
- en: '`net.sf.javaml.matrix`: This implements in-memory or file-based arrays'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.matrix`: 这实现了内存或基于文件的数组'
- en: '`net.sf.javaml.sampling`: This implements sampling algorithms to select a subset
    of datasets'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.sampling`: 这实现了采样算法以选择数据集的子集'
- en: '`net.sf.javaml.tools`: These are utility methods on dataset, instance manipulation,
    serialization, Weka API interface, and so on'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.tools`: 这些是数据集、实例操作、序列化、Weka API接口等实用方法'
- en: '`net.sf.javaml.utils`: These are utility methods for algorithms, for example,
    statistics, math methods, contingency tables, and others'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net.sf.javaml.utils`: 这些是算法的实用方法，例如，统计、数学方法、列联表等'
- en: Apache Mahout
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Mahout
- en: The Apache Mahout project aims to build a scalable machine learning library.
    It is built atop scalable, distributed architectures, such as Hadoop, using the
    MapReduce paradigm, which is an approach for processing and generating large datasets
    with a parallel, distributed algorithm using a cluster of servers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Mahout项目旨在构建一个可扩展的机器学习库。它是基于可扩展的、分布式架构构建的，如Hadoop，使用MapReduce范式，这是一种使用服务器集群的并行、分布式算法处理和生成大型数据集的方法。
- en: 'Mahout features a console interface and the Java API as scalable algorithms
    for clustering, classification, and collaborative filtering. It is able to solve
    three business problems:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout提供控制台界面和Java API作为可扩展的聚类、分类和协同过滤算法。它能够解决三个商业问题：
- en: '**Item recommendation**: Recommending items such as **People who liked this
    movie also liked**'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**项目推荐**：推荐类似“喜欢这部电影的人也喜欢”的项目'
- en: '**Clustering**: Sorting of text documents into groups of topically-related
    documents'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：将文本文档排序到主题相关的文档组中'
- en: '**Classification**: Learning which topic to assign to an unlabelled document'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：学习将哪个主题分配给未标记的文档'
- en: Mahout is distributed under a commercially friendly Apache license, which means
    that you can use it as long as you keep the Apache license included and display
    it in your program's copyright notice.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout在商业友好的Apache许可证下分发，这意味着只要您保留Apache许可证并将其包含在程序版权声明中，您就可以使用它。
- en: 'Mahout features the following libraries:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout具有以下库：
- en: '`org.apache.mahout.cf.taste`: These are collaborative filtering algorithms
    based on user-based and item-based collaborative filtering and matrix factorization
    with ALS'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.cf.taste`: 这些是基于用户和项目协同过滤以及ALS矩阵分解的协同过滤算法'
- en: '`org.apache.mahout.classifier`: These are in-memory and distributed implementations,
    including logistic regression, Naive Bayes, random forest, **hidden Markov models**
    (**HMM**), and multilayer perceptron'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.classifier`: 这些是内存和分布式实现，包括逻辑回归、朴素贝叶斯、随机森林、**隐马尔可夫模型**（HMM）和多层感知器'
- en: '`org.apache.mahout.clustering`: These are clustering algorithms such as canopy
    clustering, k-means, fuzzy k-means, streaming k-means, and spectral clustering'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.clustering`: 这些是聚类算法，如canopy聚类、k-means、模糊k-means、流k-means和谱聚类'
- en: '`org.apache.mahout.common`: These are utility methods for algorithms, including
    distances, MapReduce operations, iterators, and so on'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.common`: 这些是算法的实用方法，包括距离、MapReduce操作、迭代器等'
- en: '`org.apache.mahout.driver`: This implements a general-purpose driver to run
    main methods of other classes'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.driver`: 这实现了用于运行其他类主方法的通用驱动程序'
- en: '`org.apache.mahout.ep`: This is the evolutionary optimization using the recorded-step
    mutation'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.ep`: 这是一种使用记录步长突变的进化优化'
- en: '`org.apache.mahout.math`: These are various math utility methods and implementations
    in Hadoop'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.math`: 这些是在Hadoop中的各种数学实用方法和实现'
- en: '`org.apache.mahout.vectorizer`: These are classes for data presentation, manipulation,
    and MapReduce jobs'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.mahout.vectorizer`: 这些是用于数据展示、操作和MapReduce作业的类'
- en: Apache Spark
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark, or simply Spark, is a platform for large-scale data processing
    builds atop Hadoop, but, in contrast to Mahout, it is not tied to the MapReduce
    paradigm. Instead, it uses in-memory caches to extract a working set of data,
    process it, and repeat the query. This is reported to be up to ten times as fast
    as a Mahout implementation that works directly with data stored in the disk. It
    can be grabbed from [https://spark.apache.org](https://spark.apache.org/).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark，或简称Spark，是一个构建在Hadoop之上的大规模数据处理平台，但与Mahout不同，它并不依赖于MapReduce范式。相反，它使用内存缓存来提取一组工作数据，处理它，并重复查询。据报道，这比直接与存储在磁盘中的数据工作的Mahout实现快十倍。可以从[https://spark.apache.org](https://spark.apache.org/)获取。
- en: There are many modules built atop Spark, for instance, GraphX for graph processing,
    Spark Streaming for processing real-time data streams, and MLlib for machine learning
    library featuring classification, regression, collaborative filtering, clustering,
    dimensionality reduction, and optimization.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark之上构建了许多模块，例如GraphX用于图处理、Spark Streaming用于处理实时数据流，以及MLlib，它是一个机器学习库，具有分类、回归、协同过滤、聚类、降维和优化等功能。
- en: 'Spark''s MLlib can use a Hadoop-based data source, for example, **Hadoop Distributed
    File System** (**HDFS**) or HBase, as well as local files. The supported data
    types include the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的MLlib可以使用基于Hadoop的数据源，例如**Hadoop分布式文件系统**（**HDFS**）或HBase，以及本地文件。支持的数据类型包括以下内容：
- en: '**Local vectors** are stored on a single machine. Dense vectors are presented
    as an array of double-typed values, for example, (2.0, 0.0, 1.0, 0.0), while sparse
    vector is presented by the size of the vector, an array of indices, and an array
    of values, for example, [4, (0, 2), (2.0, 1.0)].'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地向量**存储在单个机器上。密集向量表示为双精度值数组，例如，（2.0，0.0，1.0，0.0），而稀疏向量通过向量的大小、索引数组和值数组表示，例如，[4,
    (0, 2), (2.0, 1.0)]。'
- en: '**Labelled point** is used for supervised learning algorithms and consists
    of a local vector labelled with double-typed class values. The label can be a
    class index, binary outcome, or a list of multiple class indices (multiclass classification).
    For example, a labelled dense vector is presented as [1.0, (2.0, 0.0, 1.0, 0.0)].'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记点**用于监督学习算法，由带有双精度类型类值的局部向量标记组成。标签可以是类索引、二元结果或多个类索引的列表（多类分类）。例如，标记的密集向量表示为[1.0,
    (2.0, 0.0, 1.0, 0.0)]。'
- en: '**Local matrices** store a dense matrix on a single machine. It is defined
    by matrix dimensions and a single double-array arranged in a column-major order.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地矩阵**在单个机器上存储一个密集矩阵。它由矩阵维度和一个按列主序排列的单个双精度数组定义。'
- en: '**Distributed matrices** operate on data stored in Spark''s **Resilient Distributed
    Dataset** (**RDD**), which represents a collection of elements that can be operated
    on in parallel. There are three presentations: row matrix, where each row is a
    local vector that can be stored on a single machine, row indices are meaningless;
    indexed row matrix, which is similar to row matrix, but the row indices are meaningful,
    that is, rows can be identified and joins can be executed; and coordinate matrix,
    which is used when a row cannot be stored on a single machine and the matrix is
    very sparse.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式矩阵**在Spark的**弹性分布式数据集**（**RDD**）上操作，它表示可以并行操作的一组元素。有三种表示形式：行矩阵，其中每一行是可以在单个机器上存储的本地向量，行索引没有意义；索引行矩阵，与行矩阵类似，但行索引是有意义的，即可以识别行并执行连接操作；以及坐标矩阵，当行不能存储在单个机器上且矩阵非常稀疏时使用。'
- en: 'Spark''s MLlib API library provides interfaces for various learning algorithms
    and utilities, as outlined in the following list:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的MLlib API库提供了各种学习算法和实用工具的接口，如下列所示：
- en: '`org.apache.spark.mllib.classification`: These are binary and multiclass classification
    algorithms, including linear SVMs, logistic regression, decision trees, and Naive
    Bayes'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.classification`：这些是二元和多类分类算法，包括线性SVM、逻辑回归、决策树和朴素贝叶斯。'
- en: '`org.apache.spark.mllib.clustering`: These are k-means clustering algorithms'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.clustering`：这些是k-means聚类算法。'
- en: '`org.apache.spark.mllib.linalg`: These are data presentations, including dense
    vectors, sparse vectors, and matrices'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.linalg`：这些是数据表示，包括密集向量、稀疏向量和矩阵。'
- en: '`org.apache.spark.mllib.optimization`: These are the various optimization algorithms
    that are used as low-level primitives in MLlib, including gradient descent, **stochastic
    gradient descent** (**SGD**), update schemes for distributed SGD, and the limited-memory
    **Broyden–Fletcher–Goldfarb–Shanno** (**BFGS**) algorithm'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.optimization`：这些是在MLlib中用作低级原语的多种优化算法，包括梯度下降、**随机梯度下降**（**SGD**）、分布式SGD的更新方案以及有限内存的**Broyden–Fletcher–Goldfarb–Shanno**（**BFGS**）算法。'
- en: '`org.apache.spark.mllib.recommendation`: These are model-based collaborative
    filtering techniques implemented with alternating least squares matrix factorization'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.recommendation`：这些是基于模型的协同过滤技术，通过交替最小二乘矩阵分解实现。'
- en: '`org.apache.spark.mllib.regression`: These are regression learning algorithms,
    such as linear least squares, decision trees, Lasso, and Ridge regression'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.regression`：这些是回归学习算法，例如线性最小二乘法、决策树、Lasso和岭回归。'
- en: '`org.apache.spark.mllib.stat`: These are statistical functions for samples
    in sparse or dense vector format to compute the mean, variance, minimum, maximum,
    counts, and nonzero counts'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.stat`：这些是在稀疏或密集向量格式中对样本进行统计的函数，用于计算均值、方差、最小值、最大值、计数和非零计数。'
- en: '`org.apache.spark.mllib.tree`: This implements classification and regression
    decision tree-learning algorithms'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.tree`：这实现了分类和回归决策树学习算法。'
- en: '`org.apache.spark.mllib.util`: These are a collection of methods used for loading,
    saving, preprocessing, generating, and validating the data'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.apache.spark.mllib.util`：这是一系列用于加载数据、保存数据、预处理、生成和验证数据的实用方法。'
- en: Deeplearning4j
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Deeplearning4j
- en: Deeplearning4j, or DL4J, is a deep learning library written in Java. It features
    a distributed as well as a single-machine deep learning framework that includes
    and supports various neural network structures such as feedforward neural networks,
    RBM, convolutional neural nets, deep belief networks, autoencoders, and others.
    DL4J can solve distinct problems, such as identifying faces, voices, spam, or
    e-commerce fraud.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Deeplearning4j，或DL4J，是一个用Java编写的深度学习库。它具有分布式和单机深度学习框架，包括并支持各种神经网络结构，如前馈神经网络、RBM、卷积神经网络、深度信念网络、自动编码器等。DL4J可以解决不同的问题，例如识别人脸、声音、垃圾邮件或电子商务欺诈。
- en: 'Deeplearning4j is also distributed under the Apache 2.0 license and can be
    downloaded from [http://deeplearning4j.org](http://deeplearning4j.org/). The library
    is organized as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Deeplearning4j也采用Apache 2.0许可证，并可以从[http://deeplearning4j.org](http://deeplearning4j.org/)下载。该库的组织结构如下：
- en: '`org.deeplearning4j.base`: These are loading classes'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.base`：这些是加载类。'
- en: '`org.deeplearning4j.berkeley`: These are math utility methods'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.berkeley`：这些是数学实用方法。'
- en: '`org.deeplearning4j.clustering`: This is the implementation of k-means clustering'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.clustering`：这是k-means聚类的实现。'
- en: '`org.deeplearning4j.datasets`: This is dataset manipulation, including import,
    creation, iterating, and so on'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.datasets`：这是数据集操作，包括导入、创建、迭代等。'
- en: '`org.deeplearning4j.distributions`: These are utility methods for distributions'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.distributions`：这些是分布的实用方法。'
- en: '`org.deeplearning4j.eval`: These are evaluation classes, including the confusion
    matrix'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.eval`：这些是评估类，包括混淆矩阵。'
- en: '`org.deeplearning4j.exceptions`: This implements the exception handlers'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.exceptions`：这实现了异常处理程序。'
- en: '`org.deeplearning4j.models`: These are supervised learning algorithms, including
    deep belief networks, stacked autoencoders, stacked denoising autoencoders, and
    RBM'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.models`：这些是监督学习算法，包括深度信念网络、堆叠自动编码器、堆叠降噪自动编码器和RBM。'
- en: '`org.deeplearning4j.nn`: These are the implementations of components and algorithms
    based on neural networks, such as neural networks, multi-layer networks, convolutional
    multi-layer networks, and so on'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.nn`：这些是基于神经网络的组件和算法的实现，如神经网络、多层网络、卷积多层网络等。'
- en: '`org.deeplearning4j.optimize`: These are neural net optimization algorithms,
    including back propagation, multi-layer optimization, output layer optimization,
    and so on'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.optimize`：这些是神经网络优化算法，包括反向传播、多层优化、输出层优化等。'
- en: '`org.deeplearning4j.plot`: These are various methods for rendering data'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.plot`：这些是渲染数据的各种方法。'
- en: '`org.deeplearning4j.rng`: This is a random data generator'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.rng`：这是一个随机数据生成器。'
- en: '`org.deeplearning4j.util`: These are helper and utility methods'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`org.deeplearning4j.util`：这些是辅助和实用方法。'
- en: MALLET
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MALLET
- en: The **Machine Learning for Language Toolkit** (**MALLET**) is a large library
    of natural language processing algorithms and utilities. It can be used in a variety
    of tasks such as document classification, document clustering, information extraction,
    and topic modelling. It features a command-line interface as well as a Java API
    for several algorithms such as Naive Bayes, HMM, Latent Dirichlet topic models,
    logistic regression, and conditional random fields.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习语言工具包**（MALLET）是一个包含大量自然语言处理算法和实用工具的大型库。它可以用于各种任务，如文档分类、文档聚类、信息提取和主题建模。它具有命令行界面，以及用于多种算法（如朴素贝叶斯、HMM、潜在狄利克雷主题模型、逻辑回归和条件随机字段）的Java
    API。'
- en: 'MALLET is available under the Common Public License 1.0, which means that you
    can even use it in commercial applications. It can be downloaded from [http://mallet.cs.umass.edu](http://mallet.cs.umass.edu/).
    A MALLET instance is represented by name, label, data, and source. However, there
    are two methods to import data into the MALLET format, as shown in the following
    list:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: MALLET采用通用公共许可证1.0，这意味着你甚至可以在商业应用中使用它。可以从[http://mallet.cs.umass.edu](http://mallet.cs.umass.edu/)下载。MALLET实例由名称、标签、数据和源表示。然而，有两种方法可以将数据导入MALLET格式，如下列所示：
- en: '**Instance per file**: Each file or document corresponds to an instance and
    MALLET accepts the directory name for the input.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每文件一个实例**：每个文件或文档对应一个实例，MALLET接受输入目录名。'
- en: '**Instance per line**: Each line corresponds to an instance, where the following
    format is assumed—the `instance_name` label token. Data will be a feature vector,
    consisting of distinct words that appear as tokens and their occurrence count.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每行一个实例**：每一行对应一个实例，假设以下格式——`instance_name`标签标记。数据将是一个特征向量，由作为标记的独特单词及其出现次数组成。'
- en: 'The library is comprised of the following packages:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 该库包含以下包：
- en: '`cc.mallet.classify`: These are algorithms for training and classifying instances,
    including AdaBoost, bagging, C4.5, as well as other decision tree models, multivariate
    logistic regression, Naive Bayes, and Winnow2.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.classify`: 这些是用于训练和分类实例的算法，包括AdaBoost、bagging、C4.5以及其他决策树模型、多元逻辑回归、朴素贝叶斯和Winnow2。'
- en: '`cc.mallet.cluster`: These are unsupervised clustering algorithms, including
    greedy agglomerative, hill climbing, k-best, and k-means clustering.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.cluster`: 这些是无监督聚类算法，包括贪婪聚合、爬山、k-best和k-means聚类。'
- en: '`cc.mallet.extract`: This implements tokenizers, document extractors, document
    viewers, cleaners, and so on.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.extract`: 此实现分词器、文档提取器、文档查看器、清理器等。'
- en: '`cc.mallet.fst`: This implements sequence models, including conditional random
    fields, HMM, maximum entropy Markov models, and corresponding algorithms and evaluators.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.fst`: 此实现序列模型，包括条件随机字段、HMM、最大熵马尔可夫模型以及相应的算法和评估器。'
- en: '`cc.mallet.grmm`: This implements graphical models and factor graphs such as
    inference algorithms, learning, and testing, for example, loopy belief propagation,
    Gibbs sampling, and so on.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.grmm`: 此实现图形模型和因子图，例如推理算法、学习、测试等，例如循环信念传播、吉布斯抽样等。'
- en: '`cc.mallet.optimize`: These are optimization algorithms for finding the maximum
    of a function, such as gradient ascent, limited-memory BFGS, stochastic meta ascent,
    and so on.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.optimize`: 这些是用于寻找函数最大值的优化算法，例如梯度上升、有限内存BFGS、随机元上升等。'
- en: '`cc.mallet.pipe`: These are methods as pipelines to process data into MALLET
    instances.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.pipe`: 这些是作为管道处理数据到MALLET实例的方法。'
- en: '`cc.mallet.topics`: These are topics modelling algorithms, such as Latent Dirichlet
    allocation, four-level pachinko allocation, hierarchical PAM, DMRT, and so on.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.topics`: 这些是主题建模算法，例如潜在狄利克雷分配、四级弹珠机分配、层次PAM、DMRT等。'
- en: '`cc.mallet.types`: This implements fundamental data types such as dataset,
    feature vector, instance, and label.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.types`: 此实现基本数据类型，如数据集、特征向量、实例和标签。'
- en: '`cc.mallet.util`: These are miscellaneous utility functions such as command-line
    processing, search, math, test, and so on.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cc.mallet.util`: 这些是各种实用函数，如命令行处理、搜索、数学、测试等。'
- en: The Encog Machine Learning Framework
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Encog机器学习框架
- en: Encog is a machine learning framework in Java/C# that was developed by Jeff
    Heaton, a data scientist. It supports normalizing and processing data and a variety
    of advanced algorithm such as SVM, Neural Networks, Bayesian Networks, Hidden
    Markov Models, Genetic Programming, and Genetic Algorithms. It has been actively
    developed since 2008\. It supports multi-threading, which boosts performance on
    multi-core systems.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Encog是一个由数据科学家Jeff Heaton开发的Java/C#机器学习框架。它支持数据归一化和处理，以及SVM、神经网络、贝叶斯网络、隐马尔可夫模型、遗传编程和遗传算法等多种高级算法。自2008年以来，它一直在积极开发。它支持多线程，这提高了多核系统上的性能。
- en: 'It can be found at [https://www.heatonresearch.com/encog/](https://www.heatonresearch.com/encog/).
    MLMethod is the base interface, which includes all of the methods for the models.
    The following are some of the interfaces and classes that it includes:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[https://www.heatonresearch.com/encog/](https://www.heatonresearch.com/encog/)找到。MLMethod是基本接口，它包括所有模型的方法。以下是一些它包含的接口和类：
- en: '`MLRegression`: This interface defines regression algorithms'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLRegression`: 此接口定义了回归算法'
- en: '`MLClassification`: This interface defines classification algorithms'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLClassification`: 此接口定义了分类算法'
- en: '`MLClustering`: This interface defines clustering algorithms'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLClustering`: 此接口定义了聚类算法'
- en: '`MLData`: This class represents a vector used in a model, either for input
    or output'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLData`: 此类表示模型中使用的向量，无论是输入还是输出'
- en: '`MLDataPair`: The functionality of this class is similar to that of `MLData`,
    but can be used for both input and output'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLDataPair`：此类的功能类似于`MLData`，但可用于输入和输出'
- en: '`MLDataSet`: This represents the list of `MLDataPair` instances for trainers'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLDataSet`：代表训练器的`MLDataPair`实例列表'
- en: '`FreeformNeuron`: This class is used as a neuron'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FreeformNeuron`：此类用作神经元'
- en: '`FreeformConnection`: This shows the weighted connection between neurons'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FreeformConnection`：这显示了神经元之间的加权连接'
- en: '`FreeformContextNeuron`: This represents a context neuron'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FreeformContextNeuron`：这代表一个上下文神经元'
- en: '`InputSummation`: This value specifies how the inputs are summed to form a
    single neuron'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InputSummation`：此值指定了如何将输入求和以形成一个单独的神经元'
- en: '`BasicActiveSummation`: This is the simple sum of all input neurons'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BasicActiveSummation`：这是所有输入神经元的简单求和'
- en: '`BasicFreeConnection`: This is the basic weighted connection between neurons'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BasicFreeConnection`：这是神经元之间的基本加权连接'
- en: '`BasicFreeformLayer`: This interface provides a layer'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BasicFreeformLayer`：此接口提供了一个层'
- en: ELKI
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ELKI
- en: ELKI creates an environment for developing KDD applications supported by index
    structures, with an emphasis on unsupervised learning. It provides various implementations
    for cluster analysis and outlier detection. It provides index structures such
    as R*-tree for performance boosting and scalability. It is widely used in research
    areas by students and faculties up until now and has been gaining attention from
    other parties recently.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ELKI创建了一个环境，用于开发由索引结构支持的KDD应用程序，重点在于无监督学习。它提供了聚类分析和异常检测的各种实现。它提供了R*-tree等索引结构以提升性能和可扩展性。到目前为止，它已被学生和教师广泛应用于研究领域，并且最近引起了其他方面的关注。
- en: 'ELKI uses the AGPLv3 license, and can be found at [https://elki-project.github.io/](https://elki-project.github.io/).
    It is comprised of the following packages:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ELKI使用AGPLv3许可证，可在[https://elki-project.github.io/](https://elki-project.github.io/)找到。它由以下包组成：
- en: '`de.lmu.ifi.dbs.elki.algorithm`: Contains various algorithms such as clustering,
    classification, itemset mining, and so on'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.algorithm`：包含各种算法，如聚类、分类、项集挖掘等'
- en: '`de.lmu.ifi.dbs.elki.outlier`: Defines an outlier-based algorithm'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.outlier`：定义了一个基于异常的算法'
- en: '`de.lmu.ifi.dbs.elki.statistics`: Defines a statistical analysis algorithm'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.statistics`：定义了一个统计分析算法'
- en: '`de.lmu.ifi.dbs.elki.database`: This is the ELKI database layer'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.database`：这是ELKI数据库层'
- en: '`de.lmu.ifi.dbs.elki.index`: This is for index structure implementation'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.index`：这是索引结构实现'
- en: '`de.lmu.ifi.dbs.elki.data`: Defines various data types and database object
    types'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`de.lmu.ifi.dbs.elki.data`：定义了各种数据类型和数据库对象类型'
- en: MOA
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MOA
- en: '**Massive Online Analysis** (**MOA**) contains a vast collection of various
    machine learning algorithms that includes algorithms for classification, regression,
    clustering, outlier detection, concept drift detection and recommender system,
    and tools for evaluation. All algorithms are designed for large-scale machine
    learning, with the concept of drift and deals with big streams of real-time data.
    It also works and integrates well with Weka.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**大规模在线分析**（**MOA**）包含大量各种机器学习算法，包括分类、回归、聚类、异常检测、概念漂移检测和推荐系统，以及评估工具。所有算法都针对大规模机器学习设计，具有漂移的概念，并处理实时大数据流。它还与Weka很好地协同工作。'
- en: 'It is available as a GNU license and can be downloaded from [https://moa.cms.waikato.ac.nz/](https://moa.cms.waikato.ac.nz/).
    The following are its main packages:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以作为GNU许可证使用，并可以从[https://moa.cms.waikato.ac.nz/](https://moa.cms.waikato.ac.nz/)下载。以下是其主要包：
- en: '`moa.classifiers`: Contains the algorithms for classification'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moa.classifiers`：包含分类算法'
- en: '`moa.clusters`: Contains the algorithms for clustering'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moa.clusters`：包含聚类算法'
- en: '`moa.streams`: Contains the classes related to working with streams'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moa.streams`：包含与流处理相关的类'
- en: '`moa.evaluation`: Used for evaluating'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moa.evaluation`：用于评估'
- en: Comparing libraries
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较库
- en: 'The following table summarizes all of the presented libraries. The table is,
    by no means, exhaustive—there are many more libraries that cover specific problem
    domains. This review should serve as an overview of the big names in the Java
    machine learning world:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了所有展示的库。该表格绝不是详尽的——还有许多更多覆盖特定问题领域的库。本综述应作为Java机器学习世界大名的概述：
- en: '| **Libraries** | **Problem domains** | **License** | **Architecture** | **Algorithms**
    |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| **库** | **问题领域** | **许可证** | **架构** | **算法** |'
- en: '| Weka | General purpose | GNU GPL | Single machine | Decision trees, Naive
    Bayes, neural network, random forest, AdaBoost, hierarchical clustering, and so
    on |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Weka | 通用目的 | GNU GPL | 单机 | 决策树、朴素贝叶斯、神经网络、随机森林、AdaBoost、层次聚类等 |'
- en: '| Java-ML | General purpose | GNU GPL | Single machine | K-means clustering,
    self-organizing maps, Markov chain clustering, Cobweb, random forest, decision
    trees, bagging, distance measures, and so on |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Java-ML | 通用目的 | GNU GPL | 单机 | K-means 聚类、自组织映射、马尔可夫链聚类、蜘蛛网、随机森林、决策树、袋装、距离度量等
    |'
- en: '| Mahout | Classification, recommendation and clustering | Apache 2.0 License
    | Distributed single machine | Logistic regression, Naive Bayes, random forest,
    HMM, multilayer perceptron, k-means clustering, and so on |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Mahout | 分类、推荐和聚类 | Apache 2.0 许可证 | 分布式单机 | 逻辑回归、朴素贝叶斯、随机森林、HMM、多层感知器、k-means
    聚类等 |'
- en: '| Spark | General purpose | Apache 2.0 License | Distributed | SVM, logistic
    regression, decision trees, Naive Bayes, k-means clustering, linear least squares,
    Lasso, ridge regression, and so on |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Spark | 通用目的 | Apache 2.0 许可证 | 分布式 | 支持向量机（SVM）、逻辑回归、决策树、朴素贝叶斯、k-means 聚类、线性最小二乘、Lasso、岭回归等
    |'
- en: '| DL4J | Deep learning | Apache 2.0 License | Distributed single machine |
    RBM, deep belief networks, deep autoencoders, recursive neural tensor networks,
    convolutional neural network, and stacked denoising autoencoders |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| DL4J | 深度学习 | Apache 2.0 许可证 | 分布式单机 | RBM、深度信念网络、深度自动编码器、递归神经网络张量、卷积神经网络和堆叠去噪自动编码器
    |'
- en: '| MALLET | Text mining | Common Public License 1.0 | Single machine | Naive
    Bayes, decision trees, maximum entropy, HMM, and conditional random fields |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| MALLET | 文本挖掘 | 公共许可 1.0 | 单机 | 朴素贝叶斯、决策树、最大熵、HMM 和条件随机字段 |'
- en: '| Encog | Machine Learning Framework | Apache 2.0 License | Cross Platform
    | SVM, Neural Network, Bayesian Networks, HMMs, Genetic Programming, and Genetic
    Algorithms |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Encog | 机器学习框架 | Apache 2.0 许可证 | 跨平台 | 支持向量机（SVM）、神经网络、贝叶斯网络、隐马尔可夫模型（HMMs）、遗传编程和遗传算法
    |'
- en: '| ELKI | Data Mining | AGPL | Distributed single machine | Cluster Detection,
    Anomaly Detection, Evaluation, Index |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| ELKI | 数据挖掘 | AGPL | 分布式单机 | 聚类检测、异常检测、评估、索引 |'
- en: '| MOA | Machine Learning | GNU GPL | Distributed single machine | Classification,
    Regression, Clustering, Outlier Detection, Recommender System, Frequent Pattern
    Mining |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| MOA | 机器学习 | GNU GPL | 分布式单机 | 分类、回归、聚类、异常检测、推荐系统、频繁模式挖掘 |'
- en: Building a machine learning application
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建机器学习应用
- en: 'Machine learning applications, especially those focused on classification,
    usually follow the same high-level workflow that''s shown in the following diagram.
    The workflow is comprised of two phases—training the classifier and the classification
    of new instances. Both phases share common steps, as shown here:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习应用，尤其是那些专注于分类的应用，通常遵循以下图中所示的高级工作流程。该工作流程由两个阶段组成——训练分类器和对新实例进行分类。这两个阶段共享一些共同步骤，如下所示：
- en: '![](img/f2371275-8390-457f-bc94-2b1fb45251b9.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2371275-8390-457f-bc94-2b1fb45251b9.png)'
- en: First, we use a set of training data, select a representative subset as the
    training set, preprocess the missing data, and extract its features. A selected
    supervised learning algorithm is used to train a model, which is deployed in the
    second phase. The second phase puts a new data instance through the same preprocessing
    and feature extraction procedure and applies the learned model to obtain the instance
    label. If you are able to collect new labelled data, periodically rerun the learning
    phase to retrain the model and replace the old one with the retrained one in the
    classification phase.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用一组训练数据，选择一个代表性子集作为训练集，预处理缺失数据，并提取其特征。选择一个监督学习算法来训练一个模型，该模型在第二阶段部署。第二阶段将新的数据实例通过相同的预处理和特征提取程序，并应用学习到的模型来获取实例标签。如果你能够收集新的标记数据，定期重新运行学习阶段以重新训练模型，并在分类阶段用重新训练的模型替换旧的模型。
- en: Traditional machine learning architecture
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统机器学习架构
- en: Structured data, such as transactional, customers, analytical, and market data,
    usually resides within a local relational database. Given a query language, such
    as SQL, we can query the data used for processing, as shown in the workflow in
    the preceding diagram. Usually, all the data can be stored in memory and further
    processed with a machine learning library such as Weka, Java-ML, or MALLET.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据，如交易、客户、分析和市场数据，通常存储在本地关系型数据库中。给定一个查询语言，例如SQL，我们可以查询用于处理的数据，如前一个图中的工作流程所示。通常，所有数据都可以存储在内存中，并使用Weka、Java-ML或MALLET等机器学习库进一步处理。
- en: A common practice in the architecture design is to create data pipelines, where
    different steps in the workflow are split. For instance, in order to create a
    client data record, we might have to scrap the data from different data sources.
    The record can be then saved in an intermediate database for further processing.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构设计中，一个常见的做法是创建数据管道，将工作流程中的不同步骤分开。例如，为了创建客户数据记录，我们可能需要从不同的数据源抓取数据。然后，该记录可以保存在中间数据库中，以供进一步处理。
- en: To understand how the high-level aspects of big data architecture differ, let's
    first clarify when data is considered big.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解大数据架构的高级方面如何不同，我们首先需要明确何时数据被认为是大的。
- en: Dealing with big data
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理大数据
- en: 'Big data existed long before the phrase was invented. For instance, banks and
    stock exchanges have been processing billions of transactions daily for years
    and airline companies have worldwide real-time infrastructures for operational
    management of passenger booking, and so on. So, what is big data really? Doug
    Laney (2001) suggested that big data is defined by three Vs: volume, velocity,
    and variety. Therefore, to answer the question of whether your data is big, we
    can translate this into the following three sub-questions:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据在短语被发明之前就已经存在了。例如，银行和证券交易所多年来每天都在处理数十亿笔交易，航空公司也有全球实时基础设施用于乘客预订的运营管理等等。那么，大数据究竟是什么呢？道格·兰尼（2001年）提出，大数据由三个V定义：体积、速度和多样性。因此，为了回答你的数据是否大的问题，我们可以将其转化为以下三个子问题：
- en: '**Volume**: Can you store your data in memory?'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**体积**：你能将你的数据存储在内存中吗？'
- en: '**Velocity**: Can you process new incoming data with a single machine?'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：你能用一台机器处理新到达的数据吗？'
- en: '**Variety**: Is your data from a single source?'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性**：你的数据来自单一来源吗？'
- en: If you answered all of these questions with yes, then your data is probably
    not big, and you have just simplified your application architecture.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对所有这些问题都回答了是，那么你的数据可能不是大的，你只是简化了你的应用架构。
- en: 'If your answer to all of these questions was no, then your data is big! However,
    if you have mixed answers, then it''s complicated. Some may argue that one V is
    important; others may say that the other Vs are more important. From a machine
    learning point of view, there is a fundamental difference in algorithm implementation
    in order process the data in memory or from distributed storage. Therefore, a
    rule of thumb is: if you cannot store your data in memory, then you should look
    into a big data machine learning library.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对所有这些问题的回答都是否定的，那么你的数据是大的！然而，如果你有混合的回答，那么情况就复杂了。有些人可能认为一个V很重要；其他人可能说其他V更重要。从机器学习的角度来看，处理内存中或分布式存储中的数据的基本算法实现存在根本差异。因此，一个经验法则是：如果你不能将你的数据存储在内存中，那么你应该考虑使用大数据机器学习库。
- en: The exact answer depends on the problem that you are trying to solve. If you're
    starting a new project, I suggest that you start off with a single-machine library
    and prototype your algorithm, possibly with a subset of your data if the entire
    data does not fit into the memory. Once you've established good initial results,
    consider moving to something more heavy duty such as Mahout or Spark.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 确切的答案取决于你试图解决的问题。如果你正在启动一个新项目，我建议你从一个单机库开始，并使用你的数据子集（如果整个数据不适合内存）原型化你的算法。一旦你取得了良好的初步结果，可以考虑转向更强大的工具，如Mahout或Spark。
- en: Big data application architecture
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据应用架构
- en: Big data, such as documents, web blogs, social networks, sensor data, and others,
    are stored in a NoSQL database, such as MongoDB, or a distributed filesystem,
    such as HDFS. In case we deal with structured data, we can deploy database capabilities
    using systems such as Cassandra or HBase, which are built atop Hadoop. Data processing
    follows the MapReduce paradigm, which breaks data processing problems into smaller
    sub problems and distributes tasks across processing nodes. Machine learning models
    are finally trained with machine learning libraries such as Mahout and Spark.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据，如文档、网络博客、社交网络、传感器数据等，存储在NoSQL数据库中，如MongoDB，或者分布式文件系统中，如HDFS。如果我们处理结构化数据，我们可以使用Cassandra或HBase等系统部署数据库功能，这些系统建立在Hadoop之上。数据处理遵循MapReduce范式，它将数据处理问题分解成更小的子问题，并将任务分配到处理节点。最后，使用如Mahout和Spark等机器学习库训练机器学习模型。
- en: MongoDB is a NoSQL database, which stores documents in a JSON-like format. You
    can read more about it at [https://www.mongodb.org](https://www.mongodb.org/).
    Hadoop is a framework for the distributed processing of large datasets across
    a cluster of computers. It includes its own filesystem format, HDFS, job scheduling
    framework, YARD, and implements the MapReduce approach for parallel data processing.
    We can learn more about Hadoop at [http://hadoop.apache.org/](http://hadoop.apache.org/).
    Cassandra is a distributed database management system that was built to provide
    fault-tolerant, scalable, and decentralized storage. More information is available
    at [http://cassandra.apache.org/](http://cassandra.apache.org/). HBase is another
    database that focuses on random read/write access for distributed storage. More
    information is available at [https://hbase.apache.org/](https://hbase.apache.org/).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB是一个NoSQL数据库，它以类似JSON的格式存储文档。您可以在[https://www.mongodb.org](https://www.mongodb.org/)了解更多关于它的信息。Hadoop是一个用于在计算机集群上分布式处理大数据集的框架。它包括自己的文件系统格式HDFS、作业调度框架YARD，并实现了并行数据处理MapReduce方法。您可以在[http://hadoop.apache.org/](http://hadoop.apache.org/)了解更多关于Hadoop的信息。Cassandra是一个旨在提供容错、可扩展和去中心化存储的分布式数据库管理系统。更多信息可在[http://cassandra.apache.org/](http://cassandra.apache.org/)找到。HBase是另一个专注于分布式存储随机读写访问的数据库。更多信息可在[https://hbase.apache.org/](https://hbase.apache.org/)找到。
- en: Summary
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Selecting a machine learning library has an important impact on your application
    architecture. The key is to consider your project requirements. What kind of data
    do you have? What kind of problem are you trying to solve? Is your data big? Do
    you need distributed storage? What kind of algorithm are you planning to use?
    Once you figure out what you need to solve your problem, pick a library that best
    fits your needs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 选择机器学习库对你的应用架构有重要影响。关键是考虑你的项目需求。你有什么样的数据？你试图解决什么类型的问题？你的数据量大吗？你需要分布式存储吗？你打算使用什么类型的算法？一旦你弄清楚你需要解决什么问题，选择一个最适合你需求的库。
- en: In the next chapter, we will cover how to complete basic machine learning tasks
    such as classification, regression, and clustering by using some of the presented
    libraries.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何使用所提供的库来完成基本的机器学习任务，例如分类、回归和聚类。
