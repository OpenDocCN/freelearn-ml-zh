- en: '*Chapter 4*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第四章*'
- en: Dimension Reduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降维
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Apply different dimension reduction techniques
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用不同的降维技术
- en: Execute market basket analysis using the Apriori algorithm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Apriori算法执行市场篮子分析
- en: Perform principal component analysis on a dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据集执行主成分分析
- en: In this chapter, we will have a look at different dimension reduction techniques.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨不同的降维技术。
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: 'This chapter presents techniques for unsupervised learning that accomplish
    something called **dimension reduction**. First, we will discuss what a dimension
    is, why we want to avoid having too many dimensions, and the basic idea of dimension
    reduction. The chapter then covers two dimension reduction techniques in detail:
    market basket analysis and **Principal Component Analysis** (**PCA**). Market
    basket analysis is a technique for generating associative rules in datasets. The
    chapter will contain a walk-through of detailed R code that accomplishes this.
    PCA, a very common dimension reduction technique, comes from theoretical linear
    algebra. The chapter will also show a detailed walk-through of how to accomplish
    PCA with R.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了无监督学习技术，这些技术实现了所谓的**降维**。首先，我们将讨论什么是维度，为什么我们想要避免拥有太多的维度，以及降维的基本思想。然后，本章将详细介绍两种降维技术：市场篮子分析和**主成分分析**（PCA）。市场篮子分析是一种在数据集中生成关联规则的技术。本章将包含一个详细的R代码示例，展示如何实现这一目标。PCA是一种非常常见的降维技术，源自理论线性代数。本章还将详细展示如何使用R实现PCA。
- en: The Idea of Dimension Reduction
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 降维的概念
- en: 'The **dimensions** of a dataset are nothing more than the collection of distinct
    numbers that are required to describe observations in it. For example, consider
    the position of Pac-Man in the game named after him. Pac-Man is a game that was
    popular in the 20th century in America. It is an extremely simple game: Pac-Man
    is a little circular creature on a screen who likes to eat little dots and fruits.
    He lives in a maze that he has to navigate with only two sets of directions to
    move in: up/down and left/right. There are some monsters who try to chase Pac-Man
    and kill him. You can see in the following illustration what a Pac-Man game looks
    like, and what the world that he inhabits and has to move in looks like:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的**维度**不过是描述其中观测所需的不同数字的集合。例如，考虑以Pac-Man命名的游戏中的Pac-Man位置。Pac-Man是一款在20世纪美国流行的游戏。这是一款极其简单的游戏：Pac-Man是一个屏幕上的小圆形生物，喜欢吃小点和水果。他生活在一个迷宫中，只能用两组方向移动：上/下和左/右。有一些怪物试图追赶Pac-Man并杀死他。你可以在下面的插图看到Pac-Man游戏的样子，以及他必须在其中移动的世界：
- en: '![Figure 4.1: Illustration of a Pac-Man-Style Game](img/C12628_04_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1：Pac-Man风格游戏的插图](img/C12628_04_01.jpg)'
- en: 'Figure 4.1: Illustration of a Pac-Man-style game'
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.1：Pac-Man风格游戏的插图
- en: 'As you can see, Pac-Man''s position can be fully described by two numbers:
    how far he is from the left side of the screen and how far he is from the top
    of the screen. If we know those two numeric measurements, then there is only one
    unique place on the screen where he could be. So, if we wanted to collect data
    on where Pac-Man was over time, we would be able to collect a two-dimensional
    dataset that consisted of those two numbers measured repeatedly. We would feel
    completely confident that each observation, consisting of two numbers, fully described
    everything that could be known about where Pac-Man was located at the time of
    the observation.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Pac-Man的位置可以用两个数字完全描述：他距离屏幕左侧有多远，以及他距离屏幕顶部的距离有多远。如果我们知道这两个数值测量值，那么屏幕上就只有一个唯一的位置他可能在那里。所以，如果我们想要收集关于Pac-Man随时间位置的数据，我们就能收集一个包含这两个数字的二维数据集，这些数字被反复测量。我们会完全确信，每个由两个数字组成的观测值，完全描述了在观测时刻关于Pac-Man位置所能知道的一切。
- en: It is not only location data or geometric data that can be described as two-dimensional.
    Any dataset that contains two different measurements can be described as two-dimensional.
    For example, if we measured individuals' heights and weights, we could create
    a two-dimensional dataset that consisted of their height and weight measurements.
    If we recorded height, weight, and shoe size, then we would have a three-dimensional
    dataset. There is no limit to the number of dimensions that can be contained in
    a dataset.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 不只是位置数据或几何数据可以被描述为二维。任何包含两种不同测量的数据集都可以被描述为二维。例如，如果我们测量了个人身高和体重，我们可以创建一个包含他们的身高和体重测量的二维数据集。如果我们记录了身高、体重和鞋码，那么我们就会有一个三维数据集。数据集中可以包含的维度数量没有限制。
- en: Dimension reduction is the process of finding a lower-dimensional dataset that
    approximates a higher-dimensional dataset. Consider an example related to Pac-Man.
    Imagine that we have a three-dimensional dataset that describes Pac-Man's location.
    Suppose that the dimensions of this dataset are (1) how far Pac-Man is from the
    left side of the screen, (2) how far Pac-Man is from the top of the screen, and
    (3) how far Pac-Man is from the blue monster that is chasing him. This is a three-dimensional
    dataset; however, we can have complete knowledge of Pac-Man's location with only
    the information contained in the first two dimensions. The simplest way we could
    perform effective dimension reduction here would be to discard the third dimension,
    since it would not help us locate Pac-Man any better than we would be able to
    with only the first two dimensions. So, the two-dimensional dataset consisting
    of the dataset's first two dimensions would be a good approximation of the three-dimensional
    dataset that we started with.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 降维是找到一个低维数据集来近似高维数据集的过程。考虑一个与Pac-Man相关的例子。想象我们有一个描述Pac-Man位置的三个维度的数据集。假设这个数据集的维度是（1）Pac-Man距离屏幕左侧有多远，（2）Pac-Man距离屏幕顶部有多远，以及（3）Pac-Man距离追逐他的蓝色怪物有多远。这是一个三维数据集；然而，我们只需要前两个维度的信息就可以完全了解Pac-Man的位置。我们进行有效降维的最简单方法就是丢弃第三个维度，因为它不会比只有前两个维度帮助我们更好地定位Pac-Man。因此，由数据集的前两个维度组成的二维数据集将是我们最初开始的三维数据集的良好近似。
- en: In most real-life scenarios, dimension reduction is not as easy as discarding
    dimensions. Typically, we will attempt to use data from all dimensions to create
    a completely new dataset whose dimensions have different meanings from the dimensions
    in the original dataset. The exercises in the rest of the chapter will illustrate
    this process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数实际场景中，降维并不像丢弃维度那样简单。通常，我们将尝试使用所有维度的数据来创建一个全新的数据集，其维度与原始数据集的维度具有不同的含义。本章剩余的练习将说明这个过程。
- en: In the following exercise, we will look at a dataset that contains multiple
    dimensions. We will create plots that illustrate dimension reduction and how it
    can help us.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将查看一个包含多个维度的数据集。我们将创建图表来说明降维以及它如何帮助我们。
- en: 'Exercise 21: Examining a Dataset that Contains the Chemical Attributes of Different
    Wines'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习21：检查包含不同葡萄酒化学属性的数据集
- en: 'Prerequisites:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 前提条件：
- en: To download the data, go to [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下载数据，请访问[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv)。
- en: Note
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is taken from the UCI Machine Learning Repository. You can find
    the dataset at [http://archive.ics.uci.edu/ml/datasets/Wine](http://archive.ics.uci.edu/ml/datasets/Wine).
    We have downloaded the file and saved it at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集来自UCI机器学习仓库。您可以在[http://archive.ics.uci.edu/ml/datasets/Wine](http://archive.ics.uci.edu/ml/datasets/Wine)找到数据集。我们已经下载了文件，并将其保存于[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise21/wine.csv)。
- en: Download this data and store it on your computer in a file called `wine.csv`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 下载此数据，并将其存储在名为`wine.csv`的文件中。
- en: Note
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For all the exercises and activities where we are importing external csv or
    images, Go to **R Studio**-> **Session**-> **Set Working Directory**-> **To Source
    File Location**. You can see in the console that the path is set automatically.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有需要导入外部 csv 或图像的练习和活动，请转到 **R Studio**-> **会话**-> **设置工作目录**-> **到源文件位置**。你可以在控制台中看到路径已被自动设置。
- en: This data contains information about the chemical measurements of 13 different
    attributes of 178 different samples of wine. Altogether, this is a 13-dimensional
    dataset. If we consider a subset of the data consisting of only 2 of the 13 attributes,
    we will have a 2-dimensional dataset comparable to our hypothetical Pac-Man data.
    With 2-dimensional data, we can always plot it on a 2-dimensional scatterplot.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据包含了关于 178 个不同葡萄酒样本 13 个不同化学测量值的信息。总共有 13 维数据集。如果我们考虑只包含 13 个属性中的 2 个属性的数据子集，我们将得到一个
    2 维数据集，这与我们的假设 Pac-Man 数据相似。对于 2 维数据，我们总是可以在 2 维散点图上绘制它。
- en: In this dataset, the first column records the class of the wine, or, in other
    words, what type of wine it is. Every other column records a measurement related
    to the chemical makeup of the wine. One wonderful thing about machine learning
    is that even without knowing anything about the chemistry of wine, we can use
    pure data analysis tools to find patterns and draw conclusions that may be unnoticed
    even by chemistry experts.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，第一列记录了葡萄酒的类别，换句话说，就是它的类型。其他每一列都记录了与葡萄酒化学成分相关的测量值。机器学习的一个美妙之处在于，即使我们对葡萄酒的化学知识一无所知，我们也可以使用纯粹的数据分析工具来发现模式并得出可能连化学专家都未曾注意到的结论。
- en: 'Here are the steps for completion:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 完成步骤如下：
- en: 'Open the R console and make sure you have saved the data file (`wine.csv`)
    in a location that R can access. You can use the `setwd()` command to make sure
    your file is accessible. For example, if your `wine.csv` file is located in the
    `C:/Users/me/datasets` folder, then you can run the `setwd(''C:/Users/me/datasets'')`
    command in the R console. Then, you will be able to open the wine data file in
    R as follows:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 R 控制台，确保你已将数据文件（`wine.csv`）保存在 R 可以访问的位置。你可以使用 `setwd()` 命令来确保你的文件是可访问的。例如，如果你的
    `wine.csv` 文件位于 `C:/Users/me/datasets` 文件夹中，那么你可以在 R 控制台中运行 `setwd('C:/Users/me/datasets')`
    命令。然后，你将能够在 R 中打开葡萄酒数据文件，如下所示：
- en: '[PRE0]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Consider the following scatterplot of the two-dimensional data created by the
    `flavanoids` and `total phenols` attributes:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑以下由 `flavanoids` 和 `total phenols` 属性创建的二维数据散点图：
- en: '[PRE1]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.2: Scatterplot of two-dimensional data of flavanoids and phenol](img/C12628_04_02.jpg)'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.2：黄酮和酚类二维数据的散点图](img/C12628_04_02.jpg)'
- en: 'Figure 4.2: Scatterplot of two-dimensional data of flavanoids and phenol'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.2：黄酮和酚类二维数据的散点图
- en: 'After plotting the data, we observe that there appears to be a strong correlation
    between the `flavanoid` and `phenol` measurements. We can draw a line on the plot
    that represents this correlation. For now, don''t worry about where we found the
    coefficients labeled `a` and `b` in the following commands:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在绘制数据后，我们观察到黄酮和酚类测量值之间似乎存在强烈的关联。我们可以在图上画一条线来表示这种相关性。现在，你不必担心我们如何在下面的命令中找到标记为
    `a` 和 `b` 的系数：
- en: '[PRE2]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 4.3: Scatterplot with a line representing correlation between flavanoids
    and phenol](img/C12628_04_03.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3：表示黄酮和酚类之间相关性的散点图，其中有一条线表示这种相关性](img/C12628_04_03.jpg)'
- en: 'Figure 4.3: Scatterplot with a line representing correlation between flavanoids
    and phenol'
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.3：表示黄酮和酚类之间相关性的散点图，其中有一条线表示这种相关性
- en: As you can see, the red line follows the geometric shape of our data quite closely.
    The majority of the points in the data are quite close to the red line. If we
    wanted a concise way to describe the points, we could simply say what point on
    the red line they are closest to. This would not be a perfect description of the
    data, since some points would map to the same point on the red line even though
    they have different `flavanoid` and `phenol` levels. However, describing this
    data using only the red line is a reasonable approximation to the actual data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，红线非常接近我们数据的几何形状。数据中的大多数点都非常接近红线。如果我们想要简洁地描述这些点，我们可以说它们最接近红线的哪个点。这不会是数据的完美描述，因为即使它们的黄酮和酚类水平不同，一些点也会映射到红线上相同的点。然而，仅使用红线来描述这些数据是对实际数据的合理近似。
- en: If we describe each observation using the point on the red line that it is closest
    to, then what we have accomplished is dimension reduction. We started with a dataset
    that requires two measurements to describe each observation and found a way to
    describe each observation using only one point. This is the basic idea of every
    dimension reduction strategy, and this chapter contains several practical strategies
    to accomplish it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用每个观察结果最接近的红线上的点来描述它，那么我们所完成的就是降维。我们从一个需要两个测量值来描述每个观察结果的数据库开始，并找到了只用一个点来描述每个观察结果的方法。这是所有降维策略的基本思想，本章包含了一些实现它的实用策略。
- en: Importance of Dimension Reduction
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 降维的重要性
- en: 'Why is dimension reduction something that we are interested in doing? Here
    are a couple of reasons:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么降维是我们感兴趣做的事情？以下是一些原因：
- en: One reason may be for the sake of compressing data. If a dataset is particularly
    large, and if the R instance running on your laptop takes too long to do simple
    calculations on it, it may be useful to reduce the dimensions of the data so that
    it can more easily fit into your computer's memory.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个原因可能是为了压缩数据。如果一个数据集特别大，而且如果你的笔记本电脑上运行的R实例在对其进行简单计算时花费时间过长，那么降低数据的维度可能是有用的，这样它就可以更容易地适应你的计算机内存。
- en: A more interesting reason for dimension reduction is that it provides insights
    into the underlying structure of our data and the ways that different attributes
    relate to each other. In the preceding exercise, even if we don't have advanced
    training in chemistry, we can use what we have learned from our simple dimension
    reduction exercise to understand wine chemistry better.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维更有趣的原因是，它为我们提供了对数据潜在结构和不同属性之间相互关系的洞察。在前面的练习中，即使我们没有在化学方面的先进培训，我们也可以使用我们从简单的降维练习中学到的知识来更好地理解葡萄酒化学。
- en: Note
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'If we read a little more about phenols and flavanoids (for example, at this
    website: [https://www.researchgate.net/post/What_is_the_relation_between_total_Phenol_total_Flavonoids](
    https://www.researchgate.net/post/What_is_the_relation_between_total_Phenol_total_Flavonoids)),
    we can learn that phenols and flavanoids both possess antioxidant activity. So,
    it could be that the red line on the chart represents the level of antioxidant
    activity of a particular wine, and that flavanoid and phenol measurements are
    both just capturing a noisy measurement of this one thing. So, dimension reduction
    has enabled us to generate a hypothesis about the chemical makeup of wine, even
    without advanced domain knowledge.'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们阅读更多关于酚类和黄烷醇（例如，在这个网站上：[https://www.researchgate.net/post/What_is_the_relation_between_total_Phenol_total_Flavonoids](https://www.researchgate.net/post/What_is_the_relation_between_total_Phenol_total_Flavonoids)），我们可以了解到酚类和黄烷醇都具备抗氧化活性。因此，图表上的红线可能代表了特定葡萄酒的抗氧化活性水平，而黄酮醇和酚类的测量只是捕捉了这一事物的噪声测量。因此，降维使我们能够对葡萄酒的化学成分提出假设，即使没有高级领域的知识。
- en: Market Basket Analysis
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 市场篮子分析
- en: Market basket analysis is a method that allows us to take high-dimensional data
    and reduce it to something that is simple and manageable without losing too much
    information along the way. In market basket analysis, our goal is to generate
    rules that govern the data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 市场篮子分析是一种方法，它允许我们将高维数据降低到简单且易于管理的程度，同时不会在过程中丢失太多信息。在市场篮子分析中，我们的目标是生成控制数据的规则。
- en: 'Market basket analysis is also called **affinity analysis**. It is named after
    the example of a grocery store trying to do analysis on its customers'' transactions
    – analysis of the products each customer puts in his or her basket. A large grocery
    store may have something like 5,000 items for sale at any given time. They may
    have thousands of customers per day. For each customer, the grocery store can
    keep a record of those customers'' transactions. One way to do this would be to
    use binary encodings, as shown in the following example:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 市场篮子分析也称为**亲和分析**。它是以一家杂货店试图对其顾客的交易进行分析的例子命名的——分析每个顾客放入其篮子的产品。任何给定时间，大型杂货店可能有大约5,000种商品出售。他们每天可能有数千名顾客。对于每位顾客，杂货店可以记录这些顾客的交易记录。一种方法就是使用二进制编码，如下面的例子所示：
- en: 'Customer 1''s transactions on Day 1:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 客户1在第一天交易：
- en: 'Peanut Butter: No'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 花生酱：否
- en: 'Jelly: Yes'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 果冻：是
- en: 'Bread: No'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 面包：否
- en: 'Milk: No'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 牛奶：否
- en: …
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: 'Customer 2''s transactions on Day 1:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 客户2在第一天交易：
- en: 'Peanut Butter: Yes'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 花生酱：是
- en: 'Jelly: Yes'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 果冻：是
- en: 'Bread: No'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 面包：否
- en: 'Milk: No'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 牛奶：否
- en: '...'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: 'These transactions could be stored in a table that had 5,000 columns – one
    for each item for sale in the store – and one row for every recorded transaction.
    And instead of storing "Yes" and "No" values for every item, they could store
    1s and 0s, where 1 denotes "Yes" and 0 denotes "No", in a table that looks something
    like the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些交易可以存储在一个有5,000列的表中——每列代表商店中出售的每个项目——以及每行代表每条记录的交易。而不是为每个项目存储“是”和“否”的值，它们可以在一个看起来像以下表格的表中存储1s和0s，其中1表示“是”，0表示“否”：
- en: '![Figure 4.4: Table demonstrating transactions of the customers](img/C12628_04_04.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4：展示客户交易的表格](img/C12628_04_04.jpg)'
- en: 'Figure 4.4: Table demonstrating transactions of the customers'
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.4：展示客户交易的表格
- en: The preceding table shows only four columns and five rows, but in practice,
    the table would be much, much larger.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述表格只显示了四列和五行，但在实践中，表格会大得多。
- en: 'The simplest use case for market basket analysis is to answer a simple question:
    what items are usually bought together? A grocery store owner may be interested
    in this purely out of curiosity. But, in fact, there are some compelling business
    reasons why they would want to know about their customers'' most common baskets.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 市场篮子分析的最简单用例是回答一个简单的问题：通常一起购买哪些商品？杂货店老板可能纯粹出于好奇对此感兴趣。但事实上，有一些令人信服的商业理由使他们想要了解客户最常见的篮子。
- en: So far, this problem seems quite simple. Our binary data is as simple as it
    could be, consisting only of 0s and 1s. Our problem is merely to find what items
    tend to be purchased together. The complexity lies not in these simple ideas,
    but rather in their practical implementation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这个问题似乎相当简单。我们的二进制数据是最简单的，只由0s和1s组成。我们的问题仅仅是找到哪些商品倾向于一起购买。复杂性不在于这些简单想法，而在于它们的实际实施。
- en: Consider the **brute-force**approach to finding items that tend to be bought
    together. If we consider every possible basket of items, which is every possible
    combination of 0s and 1s in the preceding data, we find that there are 2^5000
    possible baskets. This is much more than the estimated number of particles in
    the known universe, and it would not be computationally feasible to check each
    possible basket in a reasonable amount of time, or to store findings about each
    possible basket.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑寻找倾向于一起购买的商品的**暴力**方法。如果我们考虑每个可能的项目篮子，即前述数据中0s和1s的每个可能组合，我们发现存在2^5000个可能的篮子。这比已知宇宙中的粒子数还要多，在合理的时间内检查每个可能的篮子或存储关于每个可能的篮子的发现都是计算上不可行的。
- en: If we cannot check each possible basket, how can we find baskets that are bought
    together with any confidence that we are doing a comprehensive check? The answer
    is to apply an algorithmic solution. The **Apriori** algorithm is the most popular
    method to do thorough market basket analysis given time and space constraints.
    It was invented by Agrawal and Srikant, who published a paper about it in 1994\.
    It proceeds sequentially through increasing market basket sizes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不能检查每个可能的篮子，我们如何才能找到任何信心地认为我们进行了全面检查的与任何篮子一起购买的篮子？答案是应用算法解决方案。**Apriori**算法是在时间和空间限制下进行彻底市场篮子分析的最流行方法。它是由Agrawal和Srikant发明的，他们在1994年发表了关于它的论文。它按顺序通过不断增加的市场篮子大小进行。
- en: The Apriori algorithm consists of several steps. In the first few steps, we
    will **pass** through our data set to find the most common baskets. In our first
    pass, we will find the most common baskets that have exactly one item in them.
    In our second pass, we will find the most common baskets that have exactly two
    items in them. We will continue these passes until we have found the most common
    baskets of every size that interests us. In the example of a grocery store, maybe
    the most common two-item basket is "peanut butter, jelly" and the most common
    three-item basket is "peanut butter, jelly, bread."
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori算法由几个步骤组成。在前几个步骤中，我们将**遍历**我们的数据集以找到最常见的篮子。在我们的第一次遍历中，我们将找到包含恰好一个项目的最常见的篮子。在我们的第二次遍历中，我们将找到包含恰好两个项目的最常见的篮子。我们将继续进行这些遍历，直到我们找到我们感兴趣的每个尺寸的最常见篮子。在杂货店的例子中，可能最常见的两个项目篮子是“花生酱，果酱”，而最常见的三个项目篮子是“花生酱，果酱，面包”。
- en: After finding the most common baskets, we will generate **associative rules**
    for these baskets. These rules will express relationships between items in the
    most common baskets. For example, an associative rule for a grocery store might
    be something such as, "if peanut butter and jelly are both in a basket, then it
    is likely that bread is also in the basket." These types of rules enable us to
    find associations between different individual items that could be useful for
    us. For example, after knowing that peanut butter and jelly are often accompanied
    by bread, the grocery store owner might be interested in rearranging the displays
    of these items so that they are closer together in the store and easier for shoppers
    to put into their baskets with minimal effort.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在找到最常见的篮子后，我们将为这些篮子生成**关联规则**。这些规则将表达最常见的篮子中项目之间的关系。例如，一个杂货店的关联规则可能如下所示：“如果花生酱和果酱都在篮子里，那么面包很可能也在篮子里。”这类规则使我们能够找到不同单个项目之间的关联，这可能对我们有用。例如，在知道花生酱和果酱经常与面包一起出现后，杂货店老板可能会对重新排列这些商品的陈列感兴趣，以便它们在商店中更靠近，让购物者更容易且不费力地将它们放入篮子中。
- en: Note
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The rule "If peanut butter and jelly are present [in a basket], then bread is
    likely to be present [in that basket]" is a simple associative rule. Associative
    rules are sometimes drawn with an arrow pointing from X to Y, indicating the idea
    that X "implies" Y, although associative rules are not necessarily causal.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 规则“如果花生酱和果酱[在篮子里]存在，那么面包很可能[在那个篮子里]存在”是一个简单的关联规则。关联规则有时会画一个箭头从X指向Y，表示X“意味着”Y，尽管关联规则不一定具有因果关系。
- en: Many Americans have grown up eating peanut butter and jelly sandwiches, so it
    may seem obvious to them that peanut butter, jelly, and bread are likely to be
    bought together. Market basket analysis may generate some seemingly obvious associative
    rules like these. However, in practice, market basket analysis is likely to generate
    associative rules that are surprising and unexpected. This is another example
    where without being an expert in grocery shopping or retail, we can use machine
    learning to find patterns and insights that are surprising even to experts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 许多美国人从小吃着花生酱和果酱三明治长大，因此对他们来说，花生酱、果酱和面包可能很可能会一起购买。市场篮子分析可能会生成一些看似明显的关联规则，例如这些。然而，在实践中，市场篮子分析可能会生成一些令人惊讶和意外的关联规则。这是另一个例子，即使不是购物或零售方面的专家，我们也可以使用机器学习来发现即使是专家也会感到惊讶的模式和见解。
- en: 'In the next exercise, we will be applying market basket analysis to census
    survey data. The data in the dataset looks as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将应用市场篮子分析到人口普查调查数据中。数据集的数据如下所示：
- en: '![Figure 4.5: Screenshot of the dataset](img/C12628_04_05.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5：数据集截图](img/C12628_04_05.jpg)'
- en: 'Figure 4.5: Screenshot of the dataset'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.5：数据集截图
- en: Note
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is taken from the UCI Machine Learning Repository. You can find
    the dataset at [http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult).
    We have downloaded the file and saved it at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集来自UCI机器学习仓库。您可以在[http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult)找到数据集。我们已经下载了文件并将其保存在[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/)。
- en: This data is different from the hypothetical grocery basket data we described
    previously as its columns are not 0-1 binary encodings, but rather can take in
    multiple values. Since the Apriori algorithm is designed for 0-1 data, we will
    do **re-coding** of the data. Here, re-coding means that we will create new variables
    that are simpler and easier to work with than the original variables, but nevertheless
    convey the same information. The re-coding that we will perform here will transform
    the data so that it consists of 0-1 encodings. Another term for what we will do
    here is creating dummy variables. A dummy variable is a variable that only takes
    on the values 0 and 1\. For each of the columns in the dataset, we can refer to
    the data at [http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult)
    to find information about the column, and then use that information for our re-coding.
    We can do analogous transformations to all of the variables.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据与我们之前描述的假设购物篮数据不同，因为它的列不是0-1的二进制编码，而是可以接受多个值。由于Apriori算法是为0-1数据设计的，我们将对数据进行**重新编码**。在这里，重新编码意味着我们将创建新的变量，这些变量比原始变量更简单、更容易处理，但仍然传达相同的信息。我们将在这里执行的重编码将使数据由0-1编码组成。我们在这里所做的事情的另一个术语是创建虚拟变量。虚拟变量是一个只取0和1值的变量。对于数据集中的每一列，我们可以参考[http://archive.ics.uci.edu/ml/datasets/Adult](http://archive.ics.uci.edu/ml/datasets/Adult)上的数据，以找到有关该列的信息，然后使用这些信息进行我们的重新编码。我们可以对所有的变量执行类似的转换。
- en: For categorical variables such as employment status, we make new 0-1 variables
    for each possible response. For ordinal variables such as age, we make two new
    variables, indicating whether the value is high or low.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像就业状态这样的分类变量，我们为每个可能的响应创建新的0-1变量。对于像年龄这样的有序变量，我们创建两个新的变量，表示值是高还是低。
- en: We will draw conclusions about what survey answers tend to be answered in the
    same way. Market basket analysis can be used for a wide variety of datasets outside
    of just grocery data. No matter what dataset is used, market basket analysis will
    generate associative rules and tell us which attributes of the data tend to take
    the same values.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得出关于哪些调查答案倾向于以相同方式回答的结论。除了购物数据之外，市场篮子分析可以用于各种数据集。无论使用什么数据集，市场篮子分析都会生成关联规则，并告诉我们哪些数据属性倾向于具有相同的值。
- en: 'Exercise 22: Data Preparation for the Apriori Algorithm'
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习22：为Apriori算法准备数据
- en: Note
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Exercise 22-25 should be executed together.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 练习22-25应一起执行。
- en: 'In this exercise, we will use data that is freely available at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/census.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/census.csv).
    This is survey data. To use this data, you should first download it to your computer
    – save it to a file called `census.csv`. You will not need to load any special
    packages in order to run this data or complete any prerequisites:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用在[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/census.csv](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-R/tree/master/Lesson04/Exercise22-Exercise25/census.csv)上免费提供的数据库。这是调查数据。要使用此数据，您应首先将其下载到您的计算机上
    - 保存为名为`census.csv`的文件。您不需要加载任何特殊包来运行此数据或完成任何先决条件：
- en: 'Use the `setwd()` function in R to read data. After you have set the working
    directory, you can read it into R as follows:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用R中的`setwd()`函数读取数据。在设置工作目录后，你可以按以下方式将其读入R：
- en: '[PRE3]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Examine the data:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据：
- en: '[PRE4]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 4.6: Screenshot of the data](img/C12628_04_06.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.6：数据截图](img/C12628_04_06.jpg)'
- en: 'Figure 4.6: Screenshot of the data'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.6：数据截图
- en: One thing you will notice is that R has automatically assigned column names
    to the data, since the raw data file did not contain column names. By default,
    R assigns numbered column names beginning with `V`, since each column can be thought
    of as a vector.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你会注意到，R已经自动为数据分配了列名，因为原始数据文件没有包含列名。默认情况下，R从`V`开始分配编号列名，因为每一列都可以被视为一个向量。
- en: Create dummy variables.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建虚拟变量。
- en: 'We can see from the data''s website that the first variable, which R has called
    `V1`, is a measurement of age in years. For this variable, we recode it as a 0-1
    binary variable based on whether its value is above the median age value or below
    the median age value. We can calculate the median age value with "`median(mkt$V1)`":'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以从数据网站上看到第一个变量，R将其称为`V1`，是年龄的测量值。对于这个变量，我们根据其值是否高于或低于中位数年龄值将其重新编码为0-1二进制变量。我们可以用"`median(mkt$V1)`"来计算中位数年龄值：
- en: '[PRE5]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Similarly, we can see on the website that the second column, which R has labeled
    `V2`, refers to employment status. For employment, we can create several new variables,
    one for each class of employment:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们可以在网站上看到第二列，R将其标记为`V2`，指的是就业状况。对于就业，我们可以创建几个新变量，每个就业类别一个：
- en: '[PRE6]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here we encode 0-1 variables for the education level of a respondent:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为受访者的教育水平编码0-1变量：
- en: '[PRE7]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We use the `V4` column to encode education levels as the column labeled `V3`
    is not useful for our purposes. We will not use the `V5` column, which contains
    the same data expressed in a different way.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用`V4`列来编码教育水平，因为标记为`V3`的列对我们来说没有用。我们不会使用`V5`列，因为它包含的是以不同方式表达相同数据。
- en: 'Here we encode 0-1 variables for a person''s marital status:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为一个人的婚姻状况编码0-1变量：
- en: '[PRE8]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here we encode 0-1 variables for a respondent''s occupation:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为受访者的职业编码0-1变量：
- en: '[PRE9]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We will not use the `V8` column since it is recorded for census purposes and
    is not useful for our analysis.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们不会使用`V8`列，因为它是为了普查目的而记录的，对我们分析没有用。
- en: 'Here we encode 0-1 variables for a respondent''s self-reported sex:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为受访者的自报性别编码0-1变量：
- en: '[PRE10]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `V10` and `V11` columns are not very informative, so we will not use them
    in our analysis.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`V10`和`V11`列不太具有信息量，所以我们不会在分析中使用它们。'
- en: 'Here we encode 0-1 variables for the self-reported number of work hours of
    each respondent:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为每个受访者的自报工作时间编码0-1变量：
- en: '[PRE11]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here we encode 0-1 variables for whether a respondent reports that their native
    country is the United States:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为受访者报告的国籍是否为美国编码0-1变量：
- en: '[PRE12]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here we encode 0-1 variables for whether a respondent reports an income above
    or below $50,000:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们为受访者报告的收入是否高于或低于$50,000编码0-1变量：
- en: '[PRE13]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, we have added 33 new variables that are 0-1 encodings. Since we will be
    performing market basket analysis only on the 0-1 encodings, we can remove the
    initial 14 variables that we started with to create a dummy-only dataset as follows:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经添加了33个新的变量，它们是0-1编码。由于我们只会在0-1编码上执行市场篮子分析，我们可以删除最初用来创建只包含虚拟变量的数据集的14个初始变量，如下所示：
- en: '[PRE14]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can see the mean values of each of our variables by running the following
    code:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过运行以下代码来查看我们每个变量的平均值：
- en: '[PRE15]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The mean of a dummy variable is equal to the percentage of the time that it
    is equal to 1\. So, when we see that the mean of the `married` variable is 0.473,
    we know that about 47.3% of survey respondents were married.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚拟变量的平均值等于它等于1的时间百分比。所以，当我们看到`已婚`变量的平均值是0.473时，我们知道大约47.3%的受访者已婚。
- en: 'After completing this exercise, your data will have 33 columns, each of which
    is a `dummy variable` instance that takes only the values 0 and 1\. If you print
    the top 6 rows by running `print(head(mktdummies))` in the console, then you can
    see that the resulting dataset looks as follows:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 完成这个练习后，你的数据将会有33列，每一列都是一个只取0和1值的`虚拟变量`实例。如果你在控制台中运行`print(head(mktdummies))`来打印前6行，那么你可以看到生成的数据集如下所示：
- en: '![Figure 4.7: Section of resulting dataset of dummy variables](img/C12628_04_07.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.7：虚拟变量结果数据集的一部分](img/C12628_04_07.jpg)'
- en: 'Figure 4.7: Section of resulting dataset of dummy variables'
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.7：虚拟变量结果数据集的一部分
- en: Now that we have completed the exercise, we have a dummy-only dataset that consists
    of 0-1 variables that give true/false information about each of the original variables
    in the dataset.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了练习，我们有一个只包含0-1变量的虚拟变量数据集，这些变量提供了关于数据集中每个原始变量的真/假信息。
- en: Finally, we are ready to actually perform the Apriori algorithm. In the following
    exercise, we will begin to "take passes" through our data. In each pass, we will
    find the most common baskets that have a particular size.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们准备实际执行Apriori算法。在接下来的练习中，我们将开始“遍历”我们的数据。在每次遍历中，我们将找到具有特定大小的最常见的篮子。
- en: Before we begin to pass through our data, we will need to specify something
    called **support**. Support is a name for one of the parameters of the Apriori
    algorithm. Here, support refers to the percentage of baskets that contain a particular
    combination of items. If we find that 40% of survey takers in the marketing data
    are both high income and female, then we will say that high-income, female "baskets"
    have 40% support in our data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始遍历数据之前，我们需要指定一个称为**支持率**的东西。支持率是Apriori算法参数之一的名字。在这里，支持率指的是包含特定项目组合的篮子百分比。如果我们发现市场数据中40%的受访者既是高收入又是女性，那么我们将说在我们的数据中，高收入、女性的“篮子”有40%的支持率。
- en: We need to make a decision about the minimum support we are interested in. If
    we set the minimum support threshold too high, we will not find any baskets that
    meet the threshold. If we set the minimum support threshold too low, we will find
    so many baskets that it will be difficult to look at all of them to find an interesting
    one. Also, since we want to find rules that will be practically useful, we want
    to find baskets that are relatively common, because more common baskets are more
    likely to have practical use for us.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要决定我们感兴趣的最低支持率。如果我们设定的最低支持率阈值过高，我们将找不到任何满足阈值的篮子。如果我们设定的最低支持率阈值过低，我们将找到太多的篮子，这将很难查看所有篮子以找到有趣的一个。此外，因为我们希望找到实际有用的规则，所以我们希望找到相对常见的篮子，因为更常见的篮子更有可能对我们有实际用途。
- en: 'Exercise 23: Passing through the Data to Find the Most Common Baskets'
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习23：通过数据遍历以找到最常见的篮子
- en: 'Now our data is prepared for the main steps of market basket analysis. Before
    going further, we have to make decisions about the parameters we will use in our
    algorithm:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经准备好进行市场篮子分析的主要步骤。在继续之前，我们必须决定我们将在算法中使用哪些参数：
- en: The first parameter we will work with is support, as explained previously. In
    this case, we can start by setting the minimum support threshold at 10%.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将要处理的第一参数是支持率，如前所述。在这种情况下，我们可以从将最低支持率阈值设定为10%开始。
- en: '[PRE16]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'First, we will find all one-item baskets that match our support threshold as
    follows:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将找到所有符合我们支持阈值的单项篮子，如下所示：
- en: '[PRE17]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This shows the collection of all survey items that were answered in the same
    way by at least 10% of respondents.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这显示了至少有10%的受访者以相同方式回答的所有调查项目。
- en: 'To take the second pass through the data, we will define all possible candidates
    for two-item baskets that might have more than 10% support as follows:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了对数据进行第二次遍历，我们将定义所有可能的两项篮子候选者，这些篮子可能支持率超过10%，如下所示：
- en: '[PRE18]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: If less than 10% of baskets contain a particular item, then it is impossible
    that more than 10% of baskets contain that item plus a different item. So, the
    candidates for two-item baskets that have more than 10% support will be combinations
    of items that survived the first pass through the data.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果少于10%的篮子包含某个特定项目，那么超过10%的篮子同时包含该项目和另一个项目的可能性是不存在的。因此，支持率超过10%的两项篮子候选者将是那些在第一次数据遍历中幸存的项目组合。
- en: We have defined `secondcand`, which is the set of candidates for our second
    pass, and `secondpass`, which we will use to store the results of the second pass.
    The `secondpass` variable starts with a `NULL` value because we have not yet begun
    the second pass.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们已经定义了`secondcand`，这是我们第二次遍历的候选者集合，以及`secondpass`，我们将用它来存储第二次遍历的结果。`secondpass`变量初始值为`NULL`，因为我们还没有开始第二次遍历。
- en: If we look at `secondcand`, we can see that it consists of pairs of numbers.
    Each number refers to a column in the `mktdummies` data. For example, the fourth
    row of `secondcand` refers to a potential basket consisting of people who responded
    that they are older than the median age and also privately employed. In the second
    pass through the data, we will check each two-item candidate in `secondcand`,
    and if it has greater than 10% support, it will survive the second pass through
    the data.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们查看`secondcand`，我们可以看到它由一对数字组成。每个数字都指代`mktdummies`数据中的一个列。例如，`secondcand`的第四行指代一个潜在篮子，其中包含那些表示他们年龄大于中位数且是私企雇员的受访者。在第二次数据遍历中，我们将检查`secondcand`中的每个两项候选者，如果其支持率超过10%，它将成功通过第二次数据遍历。
- en: 'In order to check the support of the fourth row of our candidates in `secondcand`,
    we can do the following calculation:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查我们的候选者`secondcand`中第四行的支持率，我们可以进行以下计算：
- en: '[PRE19]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE20]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We need to do this same calculation for every candidate basket, which we can
    do by putting this calculation in a loop. This loop will save the final two-item
    baskets that reach the support threshold in the `secondpass` variable:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要为每个候选篮子进行相同的计算，我们可以通过将这个计算放入循环中来实现。这个循环将把达到支持阈值的最终两个项篮子保存在`secondpass`变量中：
- en: '[PRE21]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The important outcome variable of this exercise is the variable called `secondpass`.
    This variable contains all two-item baskets that reach the support threshold (10%)
    that we have specified. Look at the top six rows of this variable by running the
    following in the console:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个练习的重要结果变量是名为`secondpass`的变量。这个变量包含所有达到我们指定的支持阈值（10%）的两个项篮子。通过在控制台中运行以下命令，查看这个变量的前六行：
- en: '[PRE22]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE23]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, each row contains two numbers, and each refers to a column number in the
    original dataset. For example, the first row indicates that the first column and
    the sixth column of the `mktdummies` dataset together constitute a two-item basket
    that has greater than 10% support. Since the first column of our dataset is called
    `old` and the sixth column in our dataset is called `private_employment`, then
    we conclude that survey respondents who are both old and employed privately constitute
    more than 10% of all survey respondents.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，每一行包含两个数字，每个数字都指代原始数据集中的列号。例如，第一行表示`mktdummies`数据集的第一列和第六列共同构成一个支持度超过10%的两个项篮子。由于我们数据集的第一列被称为`old`，而数据集的第六列被称为`private_employment`，因此我们得出结论，既是老年人又是私营部门雇员的调查受访者占所有调查受访者的10%以上。
- en: After this, we have finalized the second pass through the data. By completing
    the second pass, we now have a list of all of the most common baskets that have
    size two.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们已经完成了第二次数据遍历。通过完成第二次遍历，我们现在有一个包含所有最常见的两个项篮子的列表。
- en: The point of the Apriori algorithm is that we can use the two-item baskets and
    one-item baskets to narrow down the three-item candidate baskets that we look
    at, which makes our search much faster.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Apriori算法的要点在于，我们可以利用两项篮子和单项篮子来缩小我们关注的三个项候选篮子，这使得我们的搜索速度大大加快。
- en: To get a full sense of how the Apriori algorithm works, we should pass through
    the data at least one more time, which is covered in the following exercise.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要全面了解Apriori算法的工作原理，我们应该至少再遍历一次数据，这将在下面的练习中介绍。
- en: 'Exercise 24: More Passes through the Data'
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习24：多次遍历数据
- en: In the following exercise, we will take more passes through the data. Recall
    that each time we pass through the data, we are looking for baskets that meet
    our support threshold. In each pass, we seek baskets that have more items than
    we sought in previous passes. So, in the first pass, we sought one-item baskets
    that met our support threshold. In the second pass, we sought two-item baskets
    that met our support threshold. In the following exercise, we will illustrate
    how to take more passes through the data, including a third pass, in which we
    will seek baskets with three items that meet our support threshold, and a fourth
    pass, in which we will seek baskets with four items that meet our support threshold.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的练习中，我们将多次遍历数据。回想一下，每次我们遍历数据时，我们都在寻找符合我们支持阈值的篮子。在每次遍历中，我们寻求比之前遍历中更多的篮子。因此，在第一次遍历中，我们寻找符合我们支持阈值的单项篮子。在第二次遍历中，我们寻找符合我们支持阈值的两项篮子。在下面的练习中，我们将说明如何进行多次数据遍历，包括第三次遍历，我们将寻找符合我们支持阈值的三个项篮子，以及第四次遍历，我们将寻找符合我们支持阈值的四个项篮子。
- en: 'Being able to take many passes through the data will be important to us if
    we are interested in complex rules that govern many items:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对许多项目所遵循的复杂规则感兴趣，能够多次遍历数据对我们来说将非常重要：
- en: 'In the third pass through the data, we will look for three-item baskets that
    have at least 10% support. The third pass through the data will start with a `product`
    variable equal to 1\. This `product` variable will give us the product of different
    columns of our data, and the mean of the `product` variable will give us the support
    of different baskets, as follows:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三次遍历数据时，我们将寻找至少有10%支持度的三个项篮子。第三次遍历数据将从`product`变量等于1开始。这个`product`变量将给我们数据的不同列的乘积，而`product`变量的平均值将给我们不同篮子的支持度，如下所示：
- en: '[PRE24]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This `product` variable will be multiplied by the observations related to a
    two-item basket that survived the second pass:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个`product`变量将与在第二次遍历中幸存下来的两项篮子相关的观测值相乘：
- en: '[PRE25]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, each `product` variable will be multiplied by the observations of
    a one-item basket that survived the first pass:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，每个`product`变量将乘以第一轮中幸存下来的单个项目篮子的观测值：
- en: '[PRE26]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We take the mean of our product to find the support of the basket we have specified:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们取产品的平均值以找到我们指定的篮子的支持度：
- en: '[PRE27]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If the support of the resulting three-item basket is higher than our specified
    support threshold, then we save it to our final `thirdpass` variable:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果结果三项篮子的支持度高于我们指定的支持度阈值，则将其保存到我们的最终`thirdpass`变量中：
- en: '[PRE28]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Steps 2-5 should be executed together.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 步骤2-5应一起执行。
- en: Now we have a list of all baskets of size three that are common in the data.
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们有一个包含数据中所有大小为三的常见篮子的列表。
- en: 'After going through several passes through the data, we can start to see the
    general form of the steps taken in the Apriori algorithm. In general, to find
    the baskets that survive pass `n`, we need to take the baskets that survived pass
    `n-1`, add an item to them that survived pass 1, and see whether the resulting
    combination has support greater than our chosen threshold:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经过几轮数据遍历后，我们可以开始看到Apriori算法所采取步骤的一般形式。一般来说，为了找到在`n`轮中幸存下来的篮子，我们需要取在`n-1`轮中幸存下来的篮子，向其中添加一个在第一轮中幸存下来的项目，并查看结果组合的支持度是否大于我们选择的阈值：
- en: '[PRE29]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can continue in this way indefinitely and create baskets of any size that
    meet our support threshold. For our purpose here, we will stop after four passes
    through the data, and we will examine the results of our third pass.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以无限期地继续这样做，创建任何大小且符合我们支持度阈值的篮子。在这里，我们的目的是在数据中遍历四次后停止，并检查我们第三遍的结果。
- en: The final important outcomes of this exercise are the `thirdpass` and `fourthpass`
    variables. These variables contain information about the three-item and four-item
    baskets that have met our support threshold. You can interpret each row of these
    variables in the same way you interpreted each row of `secondpass`. Each row represents
    one basket that meets our support threshold, and each number in each row refers
    to a column number in our dataset.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本练习的最终重要结果是`thirdpass`和`fourthpass`变量。这些变量包含关于符合我们支持度阈值的三项和四项篮子的信息。您可以像解释`secondpass`的每一行一样解释这些变量的每一行。每一行代表一个符合我们支持度阈值的篮子，每一行中的每个数字都指的是我们的数据集中的一列编号。
- en: 'You can verify what the top six rows of `thirdpass` look like by executing
    the following:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以通过执行以下操作来验证`thirdpass`的前六行：
- en: '[PRE30]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output is as follows:'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE31]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can interpret row 2 as indicating that the basket containing item 1, item
    6, and item 12 meets our support threshold.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以将第二行解释为表示包含项目1、项目6和项目12的篮子达到了我们的支持度阈值。
- en: 'You can verify the top six rows of `fourthpass` as follows:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过以下方式验证`fourthpass`的前六行：
- en: '[PRE32]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output is as follows:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE33]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We can interpret row 5 as telling us that the basket containing items 1, 6,
    12, and 26 meets our support threshold.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以将第五行解释为告诉我们包含项目1、项目6、项目12和项目26的篮子达到了我们的支持度阈值。
- en: In the previous exercises, we have found the baskets that interest us. In this
    exercise, we will obtain the final product of market basket analysis. The final
    product we are interested in will be coherent `old`", "`private_employment`",
    and "`low_hours`" is common. We are also interested in generating a rule that
    relates these three items. One such rule might be "people who are older than the
    median survey respondent and who are privately employed are highly likely to work
    fewer hours than the median respondent". Market basket analysis thus goes further
    than other distribution analyses and clustering methods that only find groups
    in data. Market basket analysis not only finds groups but also groups them in
    coherent, meaningful rules.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的练习中，我们已经找到了我们感兴趣的篮子。在这个练习中，我们将获得市场篮子分析的最后产品。我们感兴趣的最后产品将是“旧”、“私人雇佣”和“低小时数”的统一。我们还感兴趣于生成一个关联这三个项目的规则。这样一个规则可能就是“年龄超过中位数调查受访者且为私人雇佣的人，很可能工作时间少于中位数受访者”。因此，市场篮子分析比其他仅发现数据中组的分布分析和聚类方法更进一步。市场篮子分析不仅找到组，而且将它们按照有意义的规则进行分组。
- en: In order to generate these rules, we will need to specify more parameters, similar
    to the support threshold we specified earlier.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成这些规则，我们需要指定更多的参数，类似于我们之前指定的支持度阈值。
- en: One of these parameters is called **confidence**. Confidence is merely a conditional
    likelihood. Given that a person is both female and low-income, what is the likelihood
    that she is also divorced? What we have determined so far is support, which may
    tell us that the three-item basket consisting of female, low income, and divorced
    makes up more than 10% of all survey takers. Confidence tells us more – it tells
    us whether "divorced" is only a common basket item, or whether it is especially
    common conditional on the presence of "female" and "low income."
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些参数中的一个被称为**置信度**。置信度仅仅是一个条件概率。假设一个人既是女性又是低收入，她离婚的可能性有多大？我们迄今为止确定的是支持度，这可能告诉我们由女性、低收入和离婚这三个项目组成的篮子占所有调查者的10%以上。置信度告诉我们更多——它告诉我们“离婚”是否只是一个常见的篮子项目，或者是否在“女性”和“低收入”存在的情况下特别常见。
- en: The final parameter we will have to specify is called **lift**. Lift is the
    confidence divided by the overall prevalence of the item predicted by the rule.
    In this case, suppose that if a person is female and low income, she has a 90%
    likelihood of also being divorced. Then 90% is the confidence of this rule, which
    seems quite high. However, this confidence will not seem impressive if 89% of
    all people are divorced anyway. If so, then knowing the presence of "female" and
    "low income" in the basket only improves our predictive capabilities very slightly,
    by about 1%. The value of lift in this case will be 90%/89%, or about 1.011\.
    That is just a hypothetical – we will have to check the actual data to see what
    the actual value of lift is.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后必须指定的参数被称为**提升度**。提升度是规则预测的项目总体普遍性的置信度。在这种情况下，假设如果一个人是女性且低收入，她有90%的可能性也是离婚的。那么90%是这个规则的置信度，这似乎相当高。然而，如果89%的人无论如何都是离婚的，那么这个置信度就不会显得那么令人印象深刻。如果是这样，那么知道篮子中存在“女性”和“低收入”只会略微提高我们的预测能力，大约1%。在这种情况下，提升度的值将是90%/89%，或大约1.011。这只是一个假设——我们得检查实际数据来看到提升度的实际值是多少。
- en: Together, confidence and lift provide measurements that help us decide whether
    an associative rule is useful or not. In a complex situation such as the many-question
    survey we are looking at here, we specify minimum thresholds for confidence and
    lift that filter out associative rules that are not sufficiently useful, so that
    we finish the Apriori algorithm with a small number of very useful rules.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一起，置信度和提升度提供了帮助我们决定一个关联规则是否有用的测量指标。在一个复杂的情况，比如我们在这里看到的许多问题调查中，我们指定置信度和提升度的最小阈值，以过滤掉不够有用的关联规则，这样我们就可以用少量非常有用的规则完成Apriori算法。
- en: 'Exercise 25: Generating Associative Rules as the Final Step of the Apriori
    Algorithm'
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习25：作为Apriori算法最后一步生成关联规则
- en: 'In this exercise, we will complete the final steps of the Apriori algorithm.
    Any of the baskets that have survived our passes through the data so far can be
    considered candidate rules. In the final steps of market basket analysis, we will
    reduce the candidate rules further based on our final criteria – confidence and
    lift:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将完成Apriori算法的最后一步。到目前为止，任何经过我们数据处理而幸存下来的篮子都可以被认为是候选规则。在市场篮子分析的最终步骤中，我们将根据我们的最终标准——置信度和提升度进一步减少候选规则。
- en: 'Examine baskets that have survived multiple passes through the data as follows:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查以下经过多次数据处理的篮子：
- en: '[PRE34]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output is as follows:'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE35]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You can see the number of three-item baskets that survived the third pass as
    follows:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以这样看到经过第三次处理幸存下来的三项篮子的数量：
- en: '[PRE36]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We see that there are 549 three-item baskets, that is, 549 candidate rules that
    have at least 10% support in our data. These baskets are not the final products
    of market basket analysis – associative rules are the final products we are looking
    for.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到有549个三项篮子，即549个至少在我们的数据中有10%支持度的候选规则。这些篮子不是市场篮子分析的最终产品——我们正在寻找的最终产品是关联规则。
- en: 'The formula for confidence for our three-item baskets is as follows: the support
    of the basket consisting of all three items, divided by the support of a basket
    consisting of only the first two items. We can calculate confidence as follows
    for the fifth row of our `thirdpass` three-item baskets:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们三项篮子的置信度公式如下：由所有三个项目组成的篮子的支持度，除以只包含前两个项目的篮子的支持度。我们可以这样计算我们的`thirdpass`三项篮子的第五行的置信度：
- en: '[PRE38]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This is just the support of the full three-item basket, divided by the support
    of the two-item basket not containing the third item.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这只是包含三个项目的完整购物篮的支持度，除以不包含第三个项目的两个项目的支持度。
- en: 'Lift is the confidence divided by the overall prevalence of the item predicted
    by the rule. Lift can be calculated easily as follows for the fifth row of our
    third-pass candidates:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提升度是置信度除以规则预测的项目总体流行度。对于我们的第三遍候选人的第五行，提升度可以很容易地按以下方式计算：
- en: '[PRE39]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To narrow down candidate rules to a final set of acceptable associative rules,
    we will specify minimum thresholds for confidence and lift, just like we did for
    support. Here, we have specified a lift threshold of 1.8 and a confidence threshold
    of 0.8:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将候选规则缩小到一组可接受的关联规则，我们将指定最小置信度和提升度阈值，就像我们对支持度所做的那样。在这里，我们指定了提升度阈值为1.8和置信度阈值为0.8：
- en: Note
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE40]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We can calculate `lift` and `confidence` for each of our candidate rules by
    constructing a loop as follows:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过以下循环为我们的每个候选规则计算`提升度`和`置信度`：
- en: '[PRE41]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This has generated a new variable called `thirdpass_conf`, which is a DataFrame
    that contains columns for the `support`, `confidence`, and `lift` for each candidate
    rule. Here, `conf` is used to be short for `confidence`, something we have added
    to the `thirdpass` data.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这生成了一个名为`thirdpass_conf`的新变量，它是一个包含每个候选规则的`支持度`、`置信度`和`提升度`列的DataFrame。在这里，`conf`被用作`置信度`的简称，这是我们添加到`thirdpass`数据中的。
- en: 'Finally, we can eliminate all candidate rules that do not meet the specified
    confidence and lift thresholds, as follows:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以消除所有不符合指定置信度和提升度阈值的候选规则，如下所示：
- en: '[PRE42]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now we have `thirdpass_high`, which is a set of associative three-item rules
    that have high confidence and high lift in our data. We can browse through some
    of them by printing the DataFrame to the console as follows:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了`thirdpass_high`，这是我们数据中具有高置信度和高提升度的关联三项目规则的集合。我们可以通过以下方式将其中一些打印到控制台来浏览它们：
- en: '[PRE43]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Figure 4.8: Output of thirdpass_high](img/C12628_04_08.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8：thirdpass_high的输出](img/C12628_04_08.jpg)'
- en: 'Figure 4.8: Output of thirdpass_high'
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.8：thirdpass_high的输出
- en: 'Altogether, the steps we have followed in market basket analysis can be summarized
    as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们在市场篮子分析中遵循的步骤可以总结如下：
- en: '![Figure 4.9: Flowchart of steps followed in market basket analysis](img/C12628_04_09.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9：市场篮子分析中遵循的步骤流程图](img/C12628_04_09.jpg)'
- en: 'Figure 4.9: Flowchart of steps followed in market basket analysis'
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '![图4.9：市场篮子分析中遵循的步骤流程图](img/C12628_04_09.jpg)'
- en: Note
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Remember, these refer to the dummy variables we created in *Exercise 22*, *Data
    Preparation for the Apriori Algorithm*, where we created a dummy variable called
    `old` that was 1 for individuals in the higher age ranges and 0 otherwise. We
    also created a dummy variable for high income where 1 was used to indicate annual
    income greater than $50,000, and 0 was used otherwise.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这些是指我们在*练习22*，*为Apriori算法准备数据*中创建的虚拟变量，其中我们创建了一个名为`old`的虚拟变量，对于年龄较高的个体，其值为1，否则为0。我们还创建了一个表示高收入的虚拟变量，其中1表示年收入超过50,000美元，否则为0。
- en: 'The interpretation of the rule on the first row of `thirdpass_high` is that
    people who are older than median, and also have high income, are likely (with
    high confidence and high lift) to also be married. This makes intuitive sense:
    marriage and high income can both take many years to achieve, so it makes sense
    that there are not many young, married, high income individuals. We find that
    this has confidence of about 87% and lift of about 1.84.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`thirdpass_high`的第一行规则的解释是：年龄超过中位数且收入较高的人，很可能（具有高置信度和高提升度）已婚。这在直觉上是有道理的：婚姻和高收入都需要很多年才能实现，所以没有很多年轻、已婚、高收入的人是有道理的。我们发现这个规则的置信度约为87%，提升度约为1.84。'
- en: In this case, the firm that conducted the survey could use this data to create
    advertising campaigns – either creating a campaign that targeted older married
    people for homeownership because that is a proven high-income demographic, or
    targeting younger married people for homeownership because that could be an underserved
    demographic that would constitute a business opportunity. Each of the seven three-item
    rules we found could provide insights into population patterns and business opportunities,
    together with quantified measurements of what these rules tell us and what certainty
    they provide.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，进行调查的公司可以使用这些数据来创建广告活动——要么创建针对已婚老年人的住房广告活动，因为这是一个经过证明的高收入人口群体，要么针对年轻的已婚人士的住房广告活动，因为这可能是一个未得到充分服务的群体，将构成商业机会。我们发现的每个七项规则都可以提供对人口模式和商业机会的见解，以及这些规则告诉我们什么以及它们提供的确定性量化测量。
- en: There are some different choices we could make in our market basket analysis
    process that could change our results. If we change the thresholds we specified,
    we could potentially get more rules, or more useful rules. For example, if we
    set a 9% instead of a 10% support threshold, fewer rules would be filtered out,
    and we might have ended with a rule such as "young students who live in condominiums
    are likely to be Asian-Americans," a rule referring to a group that constitutes
    only about 9% of survey respondents.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的市场篮子分析过程中，我们可以做出一些不同的选择，这些选择可能会改变我们的结果。如果我们改变指定的阈值，我们可能会得到更多的规则，或者更有用的规则。例如，如果我们将支持阈值设置为9%而不是10%，则过滤出的规则会更少，我们可能最终得到一条规则，例如“住在公寓里的年轻学生很可能是亚裔美国人”，这是一条只占调查受访者约9%的群体的规则。
- en: We have focused only on three-item baskets and rules that relate elements of
    these baskets. By allowing more or fewer items into the baskets we are using to
    search for rules, we could find more interesting rules that could lead to solid
    business insights. All of this has been done with relatively few lines of code
    in a relatively short amount of time. This indicates the usefulness and potential
    of market basket analysis for solving data problems and business problems.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只关注了包含三项的篮子和与这些篮子元素相关的规则。通过允许更多或更少的物品进入我们用于搜索规则的篮子，我们可以找到更有趣的规则，这些规则可能导致坚实的商业洞察。所有这些都是在相对较短的时间内用相对较少的代码行完成的。这表明市场篮子分析在解决数据问题和商业问题方面的有用性和潜力。
- en: Market basket analysis has taken a high-dimensional problem (the problem of
    finding patterns in a large dataset) and given us a low-dimensional solution (six
    simple, high-confidence rules) without too much effort, computational power, or
    time.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 市场篮子分析将一个高维问题（在大数据集中寻找模式的问题）转化为一个低维解决方案（六个简单、高置信度的规则），而无需太多的努力、计算能力或时间。
- en: Principal Component Analysis
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主成分分析
- en: The next type of dimension reduction method we will cover is called PCA. This
    is a very common technique used by researchers in a wide variety of fields.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要介绍的下一类降维方法是主成分分析（PCA）。这是一种在广泛领域的学者中非常常见的技巧。
- en: Linear Algebra Refresher
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性代数复习
- en: This short section will not contain an exhaustive review of linear algebra,
    but merely a reminder of some of its main points.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 本节不会对线性代数进行全面回顾，而只是提醒一些主要观点。
- en: Note
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 备注
- en: http://joshua.smcvt.edu/linearalgebra/#current_version covers some basics, including
    matrices, covariance matrices, eigenvectors, and eigenvalues. You can feel free
    to skip the linear algebra refresher if you are already familiar with these terms.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://joshua.smcvt.edu/linearalgebra/#current_version](http://joshua.smcvt.edu/linearalgebra/#current_version)
    覆盖了一些基础知识，包括矩阵、协方差矩阵、特征向量和特征值。如果您已经熟悉这些术语，可以自由跳过线性代数复习。'
- en: Matrices
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'Linear algebra is largely concerned with the analysis of matrices. A matrix
    can be thought of as just a collection of numbers in a rectangular format. We
    can create a matrix in R as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数主要关注矩阵的分析。矩阵可以被视为一个矩形格式的数字集合。我们可以在R中创建一个矩阵，如下所示：
- en: '[PRE44]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Here we have created a matrix with two rows and three columns, with six entries
    total. We describe entries in a matrix according to the row and column in which
    they appear. In our "`matrix1`" that we have just created, the number 3 is in
    the "1-2" position, because it is in the first row and the second column. We can
    access that particular position in R by calling `matrix1[1,2]`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个两行三列的矩阵，总共有六个条目。我们根据矩阵中条目出现的行和列来描述条目。在我们刚刚创建的"`matrix1`"中，数字3位于"1-2"位置，因为它位于第一行第二列。我们可以在R中通过调用`matrix1[1,2]`来访问该特定位置。
- en: Variance
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方差
- en: In general, the variance of a variable gives us an idea of how widely that variable
    is spread out.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个变量的方差让我们了解该变量分布的广泛程度。
- en: Covariance
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协方差
- en: Covariance is variance that is measured for two different variables together.
    It measures the extent to which their dispersion matches. In other words, it measures
    the extent to which if one is high, the other is also high, and how high each
    of them is expected to be.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差是测量两个不同变量一起的方差。它衡量它们的分散程度是否匹配。换句话说，它衡量如果一个变量高，另一个变量也高的程度，以及每个变量预期会多高。
- en: 'Exercise 26: Examining Variance and Covariance on the Wine Dataset'
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习26：检查葡萄酒数据集中的方差和协方差
- en: 'Execute all the steps that are to be followed in *Exercise 21*, *Examining
    a Dataset that Contains Chemical Attributes of Different Wines*. Then calculate
    variance and covariance for the same dataset:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 执行*练习21*中要遵循的所有步骤，即*检查包含不同葡萄酒化学属性的数据集*。然后计算同一数据集的方差和协方差：
- en: 'The alcohol measurements are all between 11.03 and 14.83, which you can see
    by running the following:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 酒精测量值都在11.03和14.83之间，你可以通过运行以下代码来看到：
- en: '[PRE45]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output is as follows:'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE46]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We can calculate variance by using R''s `var` command. For the wine''s alcohol
    measurement, we find `var(wine$alcohol)` is about 0.66\. By contrast, we find
    that the magnesium measurements in our dataset are more widely dispersed by executing
    the following:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用R的`var`命令来计算方差。对于葡萄酒的酒精测量，我们发现`var(wine$alcohol)`约为0.66。相比之下，我们发现通过执行以下代码，我们数据集中的镁测量值分布更广：
- en: '[PRE47]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE48]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This shows that the variable ranges from 70 to 162\. Since it is more widely
    dispersed, we should expect a higher variance, which we indeed find by executing
    the following:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这表明变量范围从70到162。由于它分布更广，我们应该预期方差更高，我们确实通过执行以下代码找到了这一点：
- en: '[PRE49]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE50]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'To calculate covariance, execute the following code:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算协方差，执行以下代码：
- en: '[PRE51]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output is as follows:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE52]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In *Step 4*, we found that the covariance of the alcohol and magnesium variables
    is about 3.14\. Please note that covariance is symmetric, so the covariance of
    X with Y is the same as the covariance of Y with X. You can check this by trying
    the following:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*步骤4*中，我们发现酒精和镁变量的协方差约为3.14。请注意，协方差是对称的，所以X与Y的协方差与Y与X的协方差相同。你可以通过尝试以下代码来检查这一点：
- en: '[PRE53]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE54]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: You will note that it yields the same value.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你会注意到它产生了相同的值。
- en: 'Variance of a variable is just the covariance of that variable with itself.
    You can see this by running the following code:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个变量的方差就是该变量与其自身的协方差。你可以通过运行以下代码来看到这一点：
- en: '[PRE55]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output is as follows:'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE56]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You will yield the same output by executing the following code:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过执行以下代码，你会得到相同的输出：
- en: '[PRE57]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE58]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The covariance matrix is a square matrix where every entry is a variance or
    a covariance. To construct a covariance matrix, first we must number each of the
    variables in our dataset. In the wine dataset, we can give each variable a number
    according to its order in the list of columns. So, alcohol would be variable 1,
    malic would be variable 2, and so on.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差矩阵是一个方阵，其中每个条目都是一个方差或协方差。要构建协方差矩阵，首先我们必须给我们的数据集中的每个变量编号。在葡萄酒数据集中，我们可以根据列列表中的顺序给每个变量一个编号。因此，酒精将是变量1，苹果酸将是变量2，依此类推。
- en: Note
  id: totrans-277
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Remember that you can see the list of variables at the data's source website
    at [https://archive.ics.uci.edu/ml/datasets/wine](https://archive.ics.uci.edu/ml/datasets/wine).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，你可以在数据源网站[https://archive.ics.uci.edu/ml/datasets/wine](https://archive.ics.uci.edu/ml/datasets/wine)看到变量的列表。
- en: After ordering the variables, we can create the covariance matrix. In this matrix,
    what we say is, "the i-j entry is the covariance of variable i and variable j."
    So, the item in the first row, second column is the 1-2 entry, and it will be
    equal to the covariance of the first variable (alcohol) with the second variable
    (malic). Since covariance is a symmetric operation, the 2-1 entry will be the
    same as the 1-2 entry. This means that the matrix itself will be symmetrical –
    every entry is the same as the entry on the mirror image other side of the main
    diagonal.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在对变量排序后，我们可以创建协方差矩阵。在这个矩阵中，我们说的是，“i-j条目是变量i和变量j的协方差。”因此，第一行第二列的项目是1-2条目，它将等于第一个变量（酒精）与第二个变量（苹果酸）的协方差。由于协方差是一个对称操作，2-1条目将与1-2条目相同。这意味着矩阵本身将是对称的——每个条目都与主对角线另一侧镜像位置的条目相同。
- en: The entries on the main diagonal of the covariance matrix will be variances
    rather than covariances. For example, the entry in the 3-3 position of the matrix
    will be the covariance of variable 3 with variable 3 – this is the covariance
    of a variable with itself, which is another way of saying it is the variable's
    variance.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差矩阵主对角线上的条目将是方差而不是协方差。例如，矩阵的3-3位置的条目将是变量3与变量3的协方差——这是变量与其自身的协方差，这也是说它是变量方差的一种方式。
- en: Eigenvectors and Eigenvalues
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征向量和特征值
- en: When we have a square matrix such as a covariance matrix, there are certain
    special vectors we can calculate called **eigenvectors**. Each eigenvector has
    a value associated with it called an **eigenvalue**. A discussion about eigenvectors
    and eigenvalues could easily fill a whole book. For our purposes, the most important
    thing to know about eigenvectors is that they express the directions of maximum
    variance in our data. The most important thing to know about eigenvalues is that
    they indicate which eigenvectors are the most important.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一个如协方差矩阵这样的方阵时，我们可以计算一些特殊的向量，称为**特征向量**。每个特征向量都有一个与之相关的值，称为**特征值**。关于特征向量和特征值的讨论可以轻易填满一本书。对我们来说，关于特征向量最重要的知道是它们表达了数据中最大方差的方向。关于特征值最重要的知道是它们表明哪些特征向量是最重要的。
- en: The Idea of PCA
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PCA的概念
- en: PCA is a powerful dimension reduction technique that is based on the linear
    algebra topics described in the preceding refresher.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: PCA是一种基于前面复习中描述的线性代数主题的强大降维技术。
- en: To accomplish PCA, we will take the covariance matrix of our data, and then
    find its eigenvectors. The eigenvectors of the covariance matrix are called **principal
    components**. The principal components enable us to re-express the data in different
    terms and different numbers of dimensions.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成PCA，我们将取我们数据的协方差矩阵，然后找到它的特征向量。协方差矩阵的特征向量被称为**主成分**。主成分使我们能够用不同的术语和不同的维度重新表达数据。
- en: We will use the dataset related to wine that we explored at the beginning of
    the chapter. Recall that the wine dataset had 13 dimensions that measured a particular
    chemical attribute of a particular wine. One observation in that dataset consists
    of 13 numbers – one for each of the dimensions of the data.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用本章开头探索的与葡萄酒相关的数据集。回想一下，葡萄酒数据集有13个维度，这些维度测量了特定葡萄酒的特定化学属性。该数据集中的一项观测值由13个数字组成——每个维度一个。
- en: One of the things that PCA enables is re-expressing data in different terms.
    The covariance matrix of the wine dataset will have 13 eigenvectors. We can interpret
    those eigenvectors as a set of 13 new dimensions – we will see how to do this
    in the following exercise. Essentially, we will be able to fully describe each
    observation in terms of a new set of dimensions that we discovered with PCA.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）使数据能够以不同的术语重新表达。葡萄酒数据集的协方差矩阵将包含13个特征向量。我们可以将这些特征向量解释为13个新的维度——我们将在接下来的练习中看到如何做到这一点。本质上，我们将能够用我们通过PCA发现的新维度完全描述每个观测值。
- en: More importantly, PCA enables us to do dimension reduction. Instead of re-expressing
    the data in terms of 13 new dimensions defined by the eigenvectors, we can select
    only the 12 most important of these new dimensions, and express the data in terms
    of those 12 dimensions instead of the original 13\. PCA makes it easy to select
    which dimensions are the most important, because the importance of each eigenvector
    is measured by its corresponding eigenvalue. The following exercise will illustrate
    how to do this more thoroughly.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，PCA使我们能够进行降维。我们不必用特征向量定义的13个新维度重新表示数据，而只需选择这13个新维度中最重要的12个，并用这12个维度来表示数据，而不是原来的13个维度。PCA使得选择最重要的维度变得容易，因为每个特征向量的重要性是通过其对应的特征值来衡量的。以下练习将更详细地说明如何做到这一点。
- en: There is a new type of plot that we will create as part of PCA, called a **scree
    plot**. A scree plot is a simple line segment plot that shows the eigenvalues
    of a matrix represented in order from highest to lowest, in order to indicate
    the relative importance of their associated eigenvectors.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在PCA过程中，我们将创建一种新的图表类型，称为**散点图**。散点图是一个简单的线段图，显示了矩阵的特征值，按从高到低的顺序排列，以指示它们相关特征向量的相对重要性。
- en: A scree plot shows the values of the eigenvalues of a matrix, plotted in order
    from largest to smallest. We will use the scree plot to decide which eigenvectors
    (that is, which dimensions) are the most important.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图显示了矩阵的特征值，按从大到小的顺序绘制。我们将使用散点图来决定哪些特征向量（即哪些维度）是最重要的。
- en: PCA may sound difficult, and it is based on some terms and ideas that may be
    new to you, but actually it is relatively simple to implement in R.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: PCA可能听起来很难，它基于一些可能对你来说是新术语和想法，但实际上在R中实现相对简单。
- en: 'Exercise 27: Performing PCA'
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 27：执行主成分分析（PCA）
- en: 'If we have a covariance matrix, we are ready to perform PCA. In this case,
    we will use the wine dataset that we explored earlier in this chapter. Our goal
    is to perform dimension reduction – to express the wine dataset in fewer dimensions
    than it originally possessed. This exercise is built on top of *Exercise 26*,
    *Examining Variance and Covariance on the Wine Dataset*:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个协方差矩阵，我们就准备好执行PCA了。在这种情况下，我们将使用本章前面探索过的葡萄酒数据集。我们的目标是进行降维——用比原始数据集更少的维度来表示葡萄酒数据集。这个练习建立在*练习
    26*，“在葡萄酒数据集上检查方差和协方差”的基础上：
- en: 'To begin, load the same `wine` dataset that we used earlier in the chapter.
    As a first step, we will remove the `class` column from our wine dataset. We are
    doing this because `class` is not a chemical attribute of the wine, but rather
    a label, and we are interested in studying the chemical attributes of wine. We
    can remove this column as follows:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，加载本章前面使用的相同`wine`数据集。作为第一步，我们将从葡萄酒数据集中删除`class`列。我们这样做是因为`class`不是葡萄酒的化学属性，而是一个标签，我们感兴趣的是研究葡萄酒的化学属性。我们可以按照以下方式删除此列：
- en: '[PRE59]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We can get the covariance matrix of this smaller matrix as follows:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以按照以下方式获取这个较小矩阵的协方差矩阵：
- en: '[PRE60]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next, we will use a function in R called `eigen`. This function calculates
    the special vectors called `eigenvectors`, and the special values called `eigenvalues`.
    We can apply it to our covariance matrix as follows:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用R中的一个函数`eigen`。这个函数计算称为`特征向量`的特殊向量，以及称为`特征值`的特殊值。我们可以将其应用于我们的协方差矩阵，如下所示：
- en: '[PRE61]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now we can look at the eigenvectors we have found:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以查看我们找到的特征向量：
- en: '[PRE62]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output is as follows:'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.10: Eigenvectors of wine](img/C12628_04_10.jpg)'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.10：葡萄酒的特征向量](img/C12628_04_10.jpg)'
- en: 'Figure 4.10: Eigenvectors of wine'
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.10：葡萄酒的特征向量
- en: 'R has compiled the eigenvectors into a square matrix the same size as our original
    covariance matrix. Each column of this new matrix is one of the eigenvectors of
    the covariance matrix. If we look at the eigenvalues we have found, we can see
    the relative importance of each of these eigenvectors. Execute the following to
    look at the eigenvalues:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R已经将特征向量编译成一个与我们的原始协方差矩阵大小相同的方阵。这个新矩阵的每一列都是协方差矩阵的一个特征向量。如果我们查看我们找到的特征值，我们可以看到每个特征向量的相对重要性。执行以下命令来查看特征值：
- en: '[PRE63]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output is as follows:'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.11: Eigenvalues of wine](img/C12628_04_11.jpg)'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.11：葡萄酒的特征值](img/C12628_04_11.jpg)'
- en: 'Figure 4.11: Eigenvalues of wine'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.11：葡萄酒的特征值
- en: 'We are essentially finished with our PCA. The eigenvectors of the covariance
    matrix are called the principal components of the data. Let''s look at the first
    one:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实际上已经完成了我们的PCA。协方差矩阵的特征向量被称为数据的特征值。让我们看看第一个：
- en: '[PRE64]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output is as follows:'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.12: This first eigenvector expresses a linear combination of our
    original dimensions. ](img/C12628_04_12.jpg)'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.12：这个第一个特征向量表示了原始维度的线性组合。](img/C12628_04_12.jpg)'
- en: 'Figure 4.12: This first eigenvector expresses a linear combination of our original
    dimensions.'
  id: totrans-314
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.12：这个第一个特征向量表示了原始维度的线性组合。
- en: 'We can understand our first principal component as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样理解我们的第一个主成分：
- en: Principal Component 1 = -0.0016592647 * alcohol + 0.0006810156 * malic -0.0001949057
    * ash + 0.0046713006 * alcalinity -0.0178680075 * magnesium - 0.0009898297 * phenol
    -0.0015672883 * flavanoid +0.0001230867 * nonfphenol -0.0006006078 * proanthocyanin
    -0.0023271432 * color -0.0001713800 * hue -0.0007049316 * od280 -0.9998229365
    * proline
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分1 = -0.0016592647 * 酒精 + 0.0006810156 * 苹果酸 -0.0001949057 * 灰分 + 0.0046713006
    * 碱度 -0.0178680075 * 镁 - 0.0009898297 * 酚 -0.0015672883 * 黄烷醇 +0.0001230867 *
    非酚 -0.0006006078 * 白藜芦醇 -0.0023271432 * 颜色 -0.0001713800 * 色调 -0.0007049316 *
    OD280 -0.9998229365 * 脯氨酸
- en: So, each element of the eigenvector is a coefficient in this equation to generate
    a new principal component. The principal component is a linear combination of
    the original dimensions. We can use each of the principal components as new dimensions.
    So, instead of describing an observation by saying "it has a 14.23 measurement
    for alcohol, a 1.71 measurement for malic…." and so on, we can describe it by
    saying something like "it has a 5.62 measurement for principal component 1, a
    9.19 measurement for principal component 2…." and so on.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，特征向量的每个元素都是这个方程中的一个系数，用于生成一个新的主成分。主成分是原始维度的线性组合。我们可以将每个主成分用作新的维度。所以，我们不必通过说“它有14.23的酒精测量值，1.71的苹果酸测量值……”等等来描述一个观察结果，我们可以通过说类似“它有5.62的主成分1测量值，9.19的主成分2测量值……”等等来描述它。
- en: The most important outcomes for this exercise are the `wine_eigen$vectors` and
    `wine_eigen$values` objects.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习最重要的结果是`wine_eigen$vectors`和`wine_eigen$values`对象。
- en: 'Any dimension reduction technique will mean that we have to lose some of the
    information encoded in the dataset. This is inevitable: one number can never completely
    express everything that is expressed in 13 numbers. The benefit of PCA is that
    it guarantees that it is the most efficient way to do dimension reduction – that
    by expressing data in terms of the principal components, we have lost the least
    possible amount of what is encoded in the original data.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 任何降维技术都意味着我们必须在数据集中丢失一些编码的信息。这是不可避免的：一个数字永远不能完全表达出13个数字所表达的一切。PCA的好处是它保证了这是降维最有效的方法——通过用主成分来表示数据，我们丢失了尽可能少的信息。
- en: In the following exercise, we will discuss how to transform the data to accomplish
    dimension reduction.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将讨论如何转换数据以实现降维。
- en: 'Exercise 28: Performing Dimension Reduction with PCA'
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习28：使用PCA进行降维
- en: 'This exercise is a continuation of the previous exercise – it will use the
    same data and the same matrices and eigenvectors that we calculated there:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习是前一个练习的延续——它将使用相同的数据和相同的矩阵以及我们之前计算的特征向量：
- en: 'Remember, each of the eigenvectors of our covariance matrix tells us a linear
    combination of the 13 wine attributes that can be used to summarize the data.
    In this case, the first eigenvector is telling us that we can make transformation
    of the data as follows:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记住，我们协方差矩阵的每个特征向量都告诉我们一个可以用来总结数据的13个葡萄酒属性的线性组合。在这种情况下，第一个特征向量告诉我们我们可以这样转换数据：
- en: '[PRE65]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Here, we have specified a number of eigenvectors (1), and we have multiplied
    our original dataset by this number of eigenvectors, creating a transformed dataset
    that is expressed in terms of this eigenvector or our first principal component.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们指定了若干个特征向量（1），并且将我们的原始数据集乘以这个数量的特征向量，创建了一个用这个特征向量或我们的第一个主成分表示的转换后的数据集。
- en: 'We can look at part of our transformed dataset as follows:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以这样查看我们转换后的数据集的一部分：
- en: '[PRE66]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'This will give us the following output:'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将给出以下输出：
- en: '![Figure 4.13: Transformed dataset](img/C12628_04_13.jpg)'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.13：转换后的数据集](img/C12628_04_13.jpg)'
- en: 'Figure 4.13: Transformed dataset'
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.13：转换后的数据集
- en: Here, we have a one-dimensional dataset that describes each observation with
    only one number. So, we are saying that the first observed wine has a score of
    -1067.0557 on principal component 1\. We have accomplished dimension reduction.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们有一个一维数据集，它只使用一个数字来描述每个观测值。因此，我们说第一个观测的葡萄酒在主成分1上的得分为-1067.0557。我们已经完成了降维。
- en: 'We can do a partial restoration of the dataset with the following multiplication:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过以下乘法进行数据集的部分恢复：
- en: '[PRE67]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This should approximately restore our original dataset.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这应该可以恢复我们的原始数据集。
- en: Note
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Since dimension reduction always loses some of the original information encoded
    in data, it will not be a perfect restoration.
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于降维总是丢失一些数据中编码的原始信息，因此它不会是一个完美的恢复。
- en: 'We can test whether our transformation has led to an accurate reconstruction
    of the data as follows:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式测试我们的变换是否导致了数据的准确重建：
- en: '[PRE68]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output is as follows:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE69]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: In this case, the error is quite small, indicating that we have been fairly
    successful in restoring our data.
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，错误相当小，这表明我们在恢复数据方面相当成功。
- en: 'We can do dimension reduction using any number of dimensions. In general, we
    can determine how many dimensions we should use in transformations by generating
    a scree plot, as follows:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用任意数量的维度进行降维。通常，我们可以通过生成以下所示的碎石图来确定在变换中应使用多少维度：
- en: '[PRE70]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'In this case, our scree plot appears as follows:'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的碎石图如下所示：
- en: '![Figure 4.14: Scree plot showing the eigenvalues of a covariance matrix](img/C12628_04_14.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14：显示协方差矩阵特征值的碎石图](img/C12628_04_14.jpg)'
- en: 'Figure 4.14: Scree plot showing the eigenvalues of a covariance matrix'
  id: totrans-346
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.14：显示协方差矩阵特征值的碎石图
- en: To decide how many dimensions to use for dimension reduction, we can look at
    this scree plot and choose a number of dimensions corresponding to the number
    of eigenvalues that are relatively high compared to the rest.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定使用多少维度进行降维，我们可以查看这个碎石图，并选择一个与相对较高的特征值数量相对应的维度数。
- en: We can see that the first eigenvalue is by far the highest, so therefore the
    first eigenvector is by far the most important one, telling us that the first
    principal component is the most important dimension. In this case, reduction to
    a one-dimensional dataset is quite appropriate.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，第一个特征值远远是最高的，因此第一个特征向量也是最重要的一个，它告诉我们第一个主成分是最重要的维度。在这种情况下，将数据集简化为一维数据集是非常合适的。
- en: You have just performed PCA on a covariance matrix.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚对一个协方差矩阵进行了PCA。
- en: 'Activity 10: Performing PCA and Market Basket Analysis on a New Dataset'
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动10：对新的数据集执行PCA和市场篮子分析
- en: In the following activity, you will load a new dataset, and then you will perform
    PCA and market basket analysis on it. The activity will go through each of the
    major steps of both of those procedures, including the required data preparation.
    The dataset we will use comes from a study that was done of neighborhoods in the
    area around Boston, Massachusetts, and it contains features of many neighborhoods,
    including tax rates, property values, and demographics of the local populations.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的活动中，你将加载一个新的数据集，然后你将对它执行PCA和市场篮子分析。该活动将涵盖这两个程序的所有主要步骤，包括所需的数据准备。我们将使用的数据集来自对马萨诸塞州波士顿周边地区的社区所进行的研究，它包含了许多社区的属性，包括税率、房产价值和当地人口的人口统计信息。
- en: 'For this activity, use the "`Boston`" dataset, which can be obtained by running
    the following code in R:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个活动，使用"`Boston`"数据集，可以在R中运行以下代码：
- en: '[PRE71]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'These steps will help you complete the activity:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助你完成活动：
- en: 'Convert all variables into dummy variables by doing the following: for each
    variable, create a new variable that is equal to 1 if it is at or above that variable''s
    median, and 0 if it is below that variable''s median. Create another new variable
    that is the complement of this: where every 0 in the previously created dummy
    variable is a 1 and every 1 in the previously created dummy variable is a 0\.
    Save all the dummy variables into a new dataset called `Bostondummy`.'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下方式将所有变量转换为虚拟变量：对于每个变量，创建一个新的变量，如果它等于或高于该变量的中位数，则等于1，如果它低于该变量的中位数，则等于0。创建另一个新的变量，它是这个变量的补数：在之前创建的虚拟变量中，每个0都是1，每个1都是0。将所有虚拟变量保存到一个名为`Bostondummy`的新数据集中。
- en: Find all eigenvectors and eigenvalues of the original data
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到原始数据的所有特征向量和特征值
- en: Create a scree plot of the eigenvalues of this data. How should this scree plot
    be interpreted?
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建该数据的特征值散点图。如何解释这个散点图？
- en: Attempt to approximate this data using only a few of the principal components.
    How close is your approximation to the original data?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试仅使用少数几个主成分来近似此数据。你的近似与原始数据有多接近？
- en: Using the dummy variables you created in *Step 1*, perform the first pass of
    market basket analysis by finding all of the variables whose value is 1 for more
    than 10% of rows.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你在*步骤1*中创建的虚拟变量，通过找到值在超过10%的行中为1的所有变量来进行市场篮子分析的第一遍。
- en: Perform the second pass of market basket analysis by finding all combinations
    of variables in the data that have more than 10% support in the data.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过找到在数据中有超过10%支持的所有变量的组合来进行市场篮子分析的第二次遍历。
- en: Complete market basket analysis up to three-item baskets.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成市场篮子分析，直到三项篮子。
- en: 'Expected output: The most important outputs for this activity are the principal
    components of the dataset, as well as the three-item rules obtained from market
    basket analysis. The principal components are obtained in the solution to the
    activity''s second step, when we create `Boston_eigen`, and we can run the `print(Boston_eigen$vectors)`
    command to see the principal components as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出：此活动的最重要的输出是数据集的主成分，以及从市场篮子分析中获得的三项规则。主成分在活动的第二步解决方案中获得，当我们创建`Boston_eigen`时，我们可以运行`print(Boston_eigen$vectors)`命令来查看主成分，如下所示：
- en: '![Figure 4.15: Principal components of the original data](img/C12628_04_15.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![图4.15：原始数据的主成分](img/C12628_04_15.jpg)'
- en: 'Figure 4.15: Principal components of the original data'
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.15：原始数据的主成分
- en: 'The three-item rules for market basket analysis are obtained in the solution
    to the activity''s *Step 14*, and we can see the final results when we run `print(head(thirdpass_conf))`
    in the console:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 市场篮子分析的三项规则在活动的*步骤14*的解决方案中获得，当我们运行控制台中的`print(head(thirdpass_conf))`时，我们可以看到最终结果：
- en: '![Figure 4.16: Three-item rules for market basket analysis](img/C12628_04_16.jpg)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
  zh: '![图4.16：市场篮子分析的三项规则](img/C12628_04_16.jpg)'
- en: 'Figure 4.16: Three-item rules for market basket analysis'
  id: totrans-367
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.16：市场篮子分析的三项规则
- en: Note
  id: totrans-368
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 222.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第222页找到。
- en: Summary
  id: totrans-370
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the idea of the dimensionality of data. We went
    over why it could be useful to reduce the dimensionality of data and highlighted
    that the process of dimension reduction can reveal important truths about the
    underlying structure of data. We covered two important dimension reduction methods.
    The first method we discussed was market basket analysis. This method is useful
    for generating associative rules from complex data and can be used for the use
    case it was named after (analyzing baskets of groceries) or a wide variety of
    other applications (such as analyzing the clustering of survey responses). We
    also discussed PCA, a common way to describe data in terms of linear combinations
    of its dimensions. PCA is easy to perform with some linear algebra tools, and
    provides an easy way to approximate even very complex data.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了数据维度的概念。我们探讨了为什么降低数据的维度可能是有用的，并强调了降维过程可以揭示关于数据潜在结构的重要真相。我们介绍了两种重要的降维方法。我们讨论的第一种方法是市场篮子分析。这种方法对于从复杂数据中生成关联规则很有用，并且可以用于其命名的用例（分析购物篮）或广泛的其它应用（例如分析调查响应的聚类）。我们还讨论了PCA，这是一种用其维度的线性组合来描述数据的方法。PCA使用一些线性代数工具很容易执行，并提供了一种简单的方法来近似甚至非常复杂的数据。
- en: In the next chapter, we will have a look at the different data comparison methods.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨不同的数据比较方法。
