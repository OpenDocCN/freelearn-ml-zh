["```py\nIn:\ntry:\n    import urllib.request as urllib2\nexcept:\n    import urllib2\nimport requests, io, os\nimport zipfile, gzip\n\ndef download_from_UCI(UCI_url, dest):\n    r = requests.get(UCI_url)\n    filename = UCI_url.split('/')[-1]\n    print ('Extracting in %s' %  dest)\n    try:\n        os.mkdir(dest)\n    except:\n        pass\n    with open (os.path.join(dest, filename), 'wb') as fh:\n        print ('\\tdecompression %s' % filename)\n        fh.write(r.content)\n\ndef unzip_from_UCI(UCI_url, dest):\n    r = requests.get(UCI_url)\n    z = zipfile.ZipFile(io.BytesIO(r.content))\n    print ('Extracting in %s' %  dest)\n    for name in z.namelist():\n        print ('\\tunzipping %s' % name)\n        z.extract(name, path=dest)\n\ndef gzip_from_UCI(UCI_url, dest):\n    response = urllib2.urlopen(UCI_url)\n    compressed_file = io.BytesIO(response.read())\n    decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n    filename = UCI_url.split('/')[-1][:-4]\n    print ('Extracting in %s' %  dest)\n    try:\n        os.mkdir(dest)\n    except:\n        pass\n    with open( os.path.join(dest, filename), 'wb') as outfile:\n        print ('\\tgunzipping %s' % filename)\n        cnt = decompressed_file.read()\n        outfile.write(cnt)\n```", "```py\nIn:\nUCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00312/dow_jones_index.zip'\nunzip_from_UCI(UCI_url, dest='./dji')\nOut:\nExtracting in ./dji\n  unzipping dow_jones_index.data\n  unzipping dow_jones_index.names\nIn:\n! head -2 ./dji/dow_jones_index.data\nOut:\n```", "```py\nIn:\nUCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip'\nunzip_from_UCI(UCI_url, dest='./msd')\nOut:\nExtracting in ./msd\n  unzipping YearPredictionMSD.txt\nIn:\n! head -n 2 ./msd/YearPredictionMSD.txt\nOut:\n```", "```py\nIn:\nUCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/kddcup99-mld/kddcup.data.gz'\ngzip_from_UCI(UCI_url, dest='./kdd')\nOut:\nExtracting in ./kdd\n  gunzipping kddcup.dat\nIn:\n!head -2 ./kdd/kddcup.dat\nOut:\n```", "```py\nIn:\nUCI_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\ndownload_from_UCI(UCI_url, dest='./autos')\nOut:\nExtracting in ./autos\n  decompression imports-85.data\nIn:\n!head -2 ./autos/imports-85.data\nOut:\n```", "```py\nIn:\nimport matplotlib.pyplot as plt\n%matplotlib inline  \n\nimport numpy as np\nimport pandas as pd\n\ndataset = pd.read_csv('./msd/YearPredictionMSD.txt', \n                      header=None).as_matrix()\nIn:\nX_train = dataset[:463715, 1:]\ny_train = np.asarray(dataset[:463715, 0])\n\nX_test = dataset[463715:, 1:]\ny_test = np.asarray(dataset[463715:, 0])\nIn:\nprint(\"Dataset is MB:\", dataset.nbytes/1E6)\ndel dataset\nOut:\nDataset is MB: 375.17116\n```", "```py\nIn:\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import mean_absolute_error\nimport time\nIn:\nregr = LinearRegression()\n\ntic = time.clock()\nregr.fit(X_train, y_train)\nprint(\"Training time [s]:\", time.clock()-tic)\n\nprint(\"MAE train set:\", mean_absolute_error(y_train, \n                                  regr.predict(X_train)))\n\nprint(\"MAE test set:\", mean_absolute_error(y_test, \n                                  regr.predict(X_test)))\nOut:\nTraining time [s]: 9.989145000000002\nMAE train set: 6.79557016727\nMAE test set: 6.80049646319\n```", "```py\nIn:\nregr = SGDRegressor()\n\ntic = time.clock()\nregr.fit(X_train, y_train)\nprint(\"Training time [s]:\", time.clock()-tic)\n\nprint(\"MAE train set:\", mean_absolute_error(y_train, \n                                  regr.predict(X_train)))\n\nprint(\"MAE test set:\", mean_absolute_error(y_test, \n                                  regr.predict(X_test)))\nOut:\nTraining time [s]: 1.5492949999999972\nMAE train set: 3.27482912145e+15\nMAE test set: 3.30350427822e+15\nIn:\nregr = SGDRegressor(n_iter=100)\n\ntic = time.clock()\nregr.fit(X_train, y_train)\nprint(\"Training time [s]:\", time.clock()-tic)\n\nprint(\"MAE train set:\", mean_absolute_error(y_train, \n                                  regr.predict(X_train)))\n\nprint(\"MAE test set:\", mean_absolute_error(y_test, \n                                  regr.predict(X_test)))\nOut:\nTraining time [s]: 24.713879\nMAE train set: 2.12094618827e+15\nMAE test set: 2.14161266897e+15\n```", "```py\nIn:\nfrom sklearn.preprocessing import PolynomialFeatures\nPolynomialFeatures().fit_transform(X_train[:10,:]).shape[1]\nOut:\n4186\n```", "```py\nIn:\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import feature_selection\nfrom sklearn.feature_selection import SelectKBest\nimport gc\n\nfolds = 12\ntrain_idx = list(KFold(X_train.shape[0], folds, random_state=101, shuffle=True))[0][1]\n\nto_plot = []\n\nfor k_feat in range(50, 2001, 50):\n\n    gc.collect()\n\n    print('---------------------------')\n    print(\"K = \", k_feat)\n\n    poly = PolynomialFeatures()\n    regr = LinearRegression()\n    f_sel = SelectKBest(feature_selection.f_regression, k=k_feat)\n\n    pipeline = Pipeline([('poly', poly), ('f_sel', f_sel), ('regr', regr)])\n\n    tic = time.clock()\n    pipeline.fit(X_train[train_idx], y_train[train_idx])\n    print(\"Training time [s]:\", time.clock()-tic)\n\n    mae_train = mean_absolute_error(y_train[train_idx], pipeline.predict(X_train[train_idx]))\n    mae_test = mean_absolute_error(y_test, pipeline.predict(X_test))\n\n    print(\"MAE train set:\", mae_train)\n\n    print(\"MAE test set:\", mae_test)\n\n    to_plot.append((k_feat, mae_train, mae_test))\nOut:\n...[output]...\nIn:\nplt.plot([x[0] for x in to_plot], [x[1] for x in to_plot], 'b', label='Train')\nplt.plot([x[0] for x in to_plot], [x[2] for x in to_plot], 'r--', label='Test')\nplt.xlabel('Num. features selected')\nplt.ylabel('MAE train/test')\nplt.legend(loc=0)\n\nplt.show()\nOut:\n```", "```py\nIn:\nprint(np.unique(np.ascontiguousarray(y_train)))\nprint(len(np.unique(np.ascontiguousarray(y_train))))\nOut:\n[ 1922\\.  1924\\.  1925\\.  1926\\.  1927\\.  1928\\.  1929\\.  1930\\.  1931\\.  1932.\n  1933\\.  1934\\.  1935\\.  1936\\.  1937\\.  1938\\.  1939\\.  1940\\.  1941\\.  1942.\n  1943\\.  1944\\.  1945\\.  1946\\.  1947\\.  1948\\.  1949\\.  1950\\.  1951\\.  1952.\n  1953\\.  1954\\.  1955\\.  1956\\.  1957\\.  1958\\.  1959\\.  1960\\.  1961\\.  1962.\n  1963\\.  1964\\.  1965\\.  1966\\.  1967\\.  1968\\.  1969\\.  1970\\.  1971\\.  1972.\n  1973\\.  1974\\.  1975\\.  1976\\.  1977\\.  1978\\.  1979\\.  1980\\.  1981\\.  1982.\n  1983\\.  1984\\.  1985\\.  1986\\.  1987\\.  1988\\.  1989\\.  1990\\.  1991\\.  1992.\n  1993\\.  1994\\.  1995\\.  1996\\.  1997\\.  1998\\.  1999\\.  2000\\.  2001\\.  2002.\n  2003\\.  2004\\.  2005\\.  2006\\.  2007\\.  2008\\.  2009\\.  2010\\.  2011.]\n89\nIn:\nfrom sklearn.linear_model import SGDClassifier\nregr = SGDClassifier('log', random_state=101)\n\ntic = time.clock()\nregr.fit(X_train, y_train)\nprint(\"Training time [s]:\", time.clock()-tic)\n\nprint(\"MAE train set:\", mean_absolute_error(y_train, \n                                  regr.predict(X_train)))\n\nprint(\"MAE test set:\", mean_absolute_error(y_test, \n                                  regr.predict(X_test)))\nOut:\nTraining time [s]: 117.23069399999986 \nMAE train set: 7.88104546974 \nMAE test set: 7.7926593066\n```", "```py\nIn:\nimport matplotlib.pyplot as plt\n%matplotlib inline  \nimport matplotlib.pylab as pylab\n\nimport numpy as np\nimport pandas as pd\n\ncolumns = [\"duration\", \"protocol_type\", \"service\", \n           \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \n           \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \n           \"logged_in\", \"num_compromised\", \"root_shell\", \n           \"su_attempted\", \"num_root\", \"num_file_creations\", \n           \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \n           \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \n           \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \n           \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \n           \"srv_diff_host_rate\", \"dst_host_count\", \n           \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \n           \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \n           \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \n           \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n           \"dst_host_srv_rerror_rate\", \"outcome\"]\n\ndataset = pd.read_csv('./kdd/kddcup.dat', names=columns, nrows=1000000)\n```", "```py\nIn:\nprint(dataset.head())\nOut:\n...[head of the dataset] ...\nIn:\ndataset.shape\nOut:\n(1000000, 42)\nIn:\ndataset.dtypes\nOut:\nduration                         int64 \nprotocol_type                   object \nservice                         object\nflag                            object\nsrc_bytes                        int64 \ndst_bytes                        int64 \nland                             int64 \nwrong_fragment                   int64\n urgent                          int64 \nhot                              int64 \nnum_failed_logins                int64 \nlogged_in                        int64 \nnum_compromised                  int64 \nroot_shell                       int64 \nsu_attempted                     int64 \nnum_root                         int64 \nnum_file_creations               int64 \nnum_shells                       int64 \nnum_access_files                 int64 \nnum_outbound_cmds                int64 \nis_host_login                    int64 \nis_guest_login                   int64 \ncount                            int64 \nsrv_count                        int64 \nserror_rate                    float64 \nsrv_serror_rate                float64 \nrerror_rate                    float64 \nsrv_rerror_rate                float64 \nsame_srv_rate                  float64 \ndiff_srv_rate                  float64 \nsrv_diff_host_rate             float64 \ndst_host_count                   int64 \ndst_host_srv_count               int64 \ndst_host_same_srv_rate         float64 \ndst_host_diff_srv_rate         float64 \ndst_host_same_src_port_rate    float64 \ndst_host_srv_diff_host_rate    float64 \ndst_host_serror_rate           float64 \ndst_host_srv_serror_rate       float64 \ndst_host_rerror_rate           float64 \ndst_host_srv_rerror_rate       float64 \noutcome                         object \ndtype: object\n```", "```py\nIn:\nsorted(dataset['outcome'].unique())\nOut:\n['back.',  'buffer_overflow.',  'ftp_write.',  'guess_passwd.',  'imap.',  'ipsweep.',  'land.',  'loadmodule.',  'multihop.',  'neptune.',  'nmap.',  'normal.',  'perl.',  'phf.',  'pod.',  'portsweep.', 'satan.',  'smurf.', 'teardrop.', 'warezmaster.']\nIn:\nfrom sklearn.preprocessing import LabelEncoder\n\nlabels_enc = LabelEncoder()\n\nlabels = labels_enc.fit_transform(dataset['outcome'])\nlabels_map = labels_enc.classes_\nOut:\narray(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.', 'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.', 'neptune.', 'nmap.', 'normal.', 'perl.', 'phf.', 'pod.', 'portsweep.', 'satan.', 'smurf.', 'teardrop.', 'warezmaster.'], dtype=object)\n```", "```py\nIn:\ndataset.drop('outcome', axis=1, inplace=True)\nIn:\nobservations = pd.get_dummies(dataset, sparse=True)\ndel dataset\nIn:\nobservations.shape\nOut:\n(1000000, 118)\n```", "```py\nIn:\nfrom sklearn.cross_validation import train_test_split\n\nX_train, X_test, y_train, y_test = \\\n    train_test_split(observations.as_matrix(), labels,\n                    train_size=0.5, random_state=101)\n\ndel observations\n```", "```py\nIn:\ndef plot_normalised_confusion_matrix(cm, labels_str, title='Normalised confusion matrix', cmap=plt.cm.Blues):\n    pylab.rcParams['figure.figsize'] = (6.0, 6.0)\n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels_str))\n    plt.xticks(tick_marks, labels_str, rotation=90)\n    plt.yticks(tick_marks, labels_str)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n```", "```py\nIn:\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\nclf = SGDClassifier('log', random_state=101)\nclf.fit(X_train, y_train)\n\ny_train_pred = clf.predict(X_train)\ny_test_pred = clf.predict(X_test)\n\nprint(\"TRAIN SET\")\nprint(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(y_train, y_train_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_train, y_train_pred, target_names=labels_map))\n\nprint(\"TEST SET\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(y_test, y_test_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_test, y_test_pred, target_names=labels_map))\n\nOut:\nTRAIN SET \nAccuracy: 0.781702 \nConfusion matrix:\n```", "```py\nClassification report:\n                  precision    recall  f1-score   support\n\n           back.       0.00      0.00      0.00      1005\nbuffer_overflow.       0.00      0.00      0.00         1\n      ftp_write.       0.00      0.00      0.00         2\n   guess_passwd.       0.00      0.00      0.00        30\n           imap.       0.00      0.00      0.00         2\n        ipsweep.       0.00      0.00      0.00      3730\n           land.       0.00      0.00      0.00        10\n     loadmodule.       0.00      0.00      0.00         3\n       multihop.       1.00      1.00      1.00    102522\n        neptune.       0.06      0.00      0.00      1149\n           nmap.       0.96      0.64      0.77    281101\n         normal.       0.00      0.00      0.00         1\n           perl.       0.00      0.00      0.00         2\n            phf.       0.00      0.00      0.00        22\n            pod.       0.00      0.00      0.00      1437\n      portsweep.       1.00      0.88      0.93      2698\n          satan.       0.99      0.99      0.99    106165\n          smurf.       0.00      0.00      0.00       110\n       teardrop.       0.00      0.90      0.01        10\n\n     avg / total       0.96      0.78      0.85    500000\n\nTEST SET\nAccuracy: 0.781338\nConfusion matrix:\n```", "```py\nClassification report:\n                  precision    recall  f1-score   support\n\n           back.       0.00      0.00      0.00       997\nbuffer_overflow.       0.00      0.00      0.00         4\n      ftp_write.       0.00      0.00      0.00         6\n   guess_passwd.       0.00      0.00      0.00        23\n           imap.       0.00      0.00      0.00        10\n        ipsweep.       0.00      0.00      0.00      3849\n           land.       0.00      0.00      0.00         7\n     loadmodule.       0.00      0.00      0.00         2\n       multihop.       0.00      0.00      0.00         3\n        neptune.       1.00      1.00      1.00    102293\n           nmap.       0.05      0.00      0.00      1167\n         normal.       0.96      0.64      0.77    281286\n           perl.       0.00      0.00      0.00         1\n            phf.       0.00      0.00      0.00         1\n            pod.       0.00      0.00      0.00        18\n      portsweep.       0.00      0.00      0.00      1345\n          satan.       1.00      0.88      0.94      2691\n          smurf.       0.99      1.00      0.99    106198\n       teardrop.       0.00      0.00      0.00        89\n    warezmaster.       0.00      0.90      0.01        10\n\n     avg / total       0.96      0.78      0.85    500000\n```", "```py\nIn:\nimport random\nrandom.seed(101)\n\ndef sample_class_with_replacement(X, y, label, min_samples_out, max_samples_out):\n    rows = np.where(y==label)[0]\n\n    if len(rows) == 0:\n        raise Exception\n\n    n_estraction = min(max(len(rows), min_samples_out), max_samples_out)\n    extracted = [random.choice(rows) for _ in range(n_estraction)]\n\n    return extracted\n\ntrain_idx = []\n\nfor label in np.unique(labels):\n    try:\n        idx = sample_class_with_replacement(X_train, y_train, label, 500, 20000)\n        train_idx.extend(idx)\n    except:\n        pass\n\nX_train_sampled_balanced = X_train[train_idx, :]\ny_train_sampled_balanced = y_train[train_idx]\n```", "```py\nIn:\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nclf = SGDClassifier('log', random_state=101)\nclf.fit(X_train_sampled_balanced, y_train_sampled_balanced)\n\ny_train_pred = clf.predict(X_train_sampled_balanced)\ny_test_pred = clf.predict(X_test)\n\nprint(\"TRAIN SET\")\nprint(\"Accuracy:\", accuracy_score(y_train_sampled_balanced, y_train_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(\n        y_train_sampled_balanced, y_train_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_train_sampled_balanced, y_train_pred, target_names=labels_map))\n\nprint(\"TEST SET\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(y_test, y_test_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_test, y_test_pred, target_names=labels_map))\nOut:\nTRAIN SET\nAccuracy: 0.712668335121\n[...]\nTEST SET\nAccuracy: 0.723616\n[...]\n```", "```py\nIn:\nfrom sklearn.grid_search import GridSearchCV\n\nparameters = {\n    'loss': ('log', 'hinge'),\n    'alpha': [0.1, 0.01, 0.001, 0.0001]\n}\n\nclfgs = GridSearchCV(SGDClassifier(random_state=101, n_jobs=1),\n                   param_grid=parameters,\n                   cv=3,\n                   n_jobs=1,\n                   scoring='accuracy'\n                  )\nclfgs.fit(X_train_sampled_balanced, y_train_sampled_balanced)\nclf = clfgs.best_estimator_\n\nprint(clfgs.best_estimator_)\n\ny_train_pred = clf.predict(X_train_sampled_balanced)\ny_test_pred = clf.predict(X_test)\n\nprint(\"TRAIN SET\")\nprint(\"Accuracy:\", accuracy_score(y_train_sampled_balanced, \n                                  y_train_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(\n    confusion_matrix(y_train_sampled_balanced, y_train_pred), \n    labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(\n        y_train_sampled_balanced, y_train_pred,\n        target_names=labels_map))\n\nprint(\"TEST SET\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(\n    confusion_matrix(y_test, y_test_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(\n        y_test, y_test_pred, target_names=labels_map))\n\nOut:\nTRAIN SET\nAccuracy: 0.695202531813\n[...]\nTEST SET\nAccuracy: 0.706034\n[...]\n```", "```py\nIn:\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.grid_search import GridSearchCV\n\nparameters = {\n    'estimator__loss': ('log', 'hinge'),\n    'estimator__alpha': [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n}\n\nclfgs = GridSearchCV(OneVsOneClassifier(SGDClassifier(random_state=101, n_jobs=1)),\n                   param_grid=parameters,\n                   cv=3,\n                   n_jobs=1,\n                   scoring='accuracy'\n                  )\nclfgs.fit(X_train_sampled_balanced, y_train_sampled_balanced)\nclf = clfgs.best_estimator_\n\ny_train_pred = clf.predict(X_train_sampled_balanced)\ny_test_pred = clf.predict(X_test)\n\nprint(\"TRAIN SET\")\nprint(\"Accuracy:\", accuracy_score(y_train_sampled_balanced, y_train_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(y_train_sampled_balanced, y_train_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_train_sampled_balanced, y_train_pred, target_names=labels_map))\n\nprint(\"TEST SET\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(confusion_matrix(y_test, y_test_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(y_test, y_test_pred, target_names=labels_map))\nOut:\nTRAIN SET\nAccuracy: 0.846250612429\n[...]\nTEST SET\nAccuracy: 0.905708\n[...]\n```", "```py\nIn:\nfrom sklearn.linear_model import LogisticRegression\n\nclf = OneVsOneClassifier(LogisticRegression(random_state=101, n_jobs=1))\nclf.fit(X_train_sampled_balanced, y_train_sampled_balanced)\n\ny_train_pred = clf.predict(X_train_sampled_balanced)\ny_test_pred = clf.predict(X_test)\n\nprint(\"TRAIN SET\")\nprint(\"Accuracy:\", accuracy_score(y_train_sampled_balanced, \n                                  y_train_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(\n    confusion_matrix(y_train_sampled_balanced, y_train_pred), \n    labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(\n        y_train_sampled_balanced, y_train_pred,\n        target_names=labels_map))\n\nprint(\"TEST SET\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n\nprint(\"Confusion matrix:\")\nplot_normalised_confusion_matrix(\n    confusion_matrix(y_test, y_test_pred), labels_map)\n\nprint(\"Classification report:\")\nprint(classification_report(\n        y_test, y_test_pred, target_names=labels_map))\n\nOut:\nTRAIN SET\nAccuracy: 0.985712204876\nConfusion matrix:\n```", "```py\nClassification report:\n                  precision    recall  f1-score   support\n\n           back.       1.00      0.98      0.99      1005\nbuffer_overflow.       1.00      1.00      1.00       500\n      ftp_write.       1.00      1.00      1.00       500\n   guess_passwd.       1.00      0.11      0.19       500\n           imap.       1.00      1.00      1.00       500\n        ipsweep.       1.00      0.99      1.00      3730\n           land.       1.00      1.00      1.00       500\n     loadmodule.       1.00      0.32      0.49       500\n       multihop.       1.00      1.00      1.00     20000\n        neptune.       0.91      1.00      0.95      1149\n           nmap.       0.97      1.00      0.98     20000\n         normal.       1.00      1.00      1.00       500\n           perl.       1.00      1.00      1.00       500\n            phf.       0.99      1.00      1.00       500\n            pod.       1.00      1.00      1.00      1437\n      portsweep.       0.98      1.00      0.99      2698\n          satan.       1.00      1.00      1.00     20000\n          smurf.       1.00      1.00      1.00       500\n       teardrop.       0.55      0.83      0.66       500\n\n     avg / total       0.99      0.99      0.98     75519\n\nTEST SET\nAccuracy: 0.996818\nConfusion matrix:\n```", "```py\nClassification report:\n                  precision    recall  f1-score   support\n\n           back.       1.00      0.98      0.99       997\nbuffer_overflow.       0.00      0.00      0.00         4\n      ftp_write.       0.00      0.00      0.00         6\n   guess_passwd.       1.00      0.13      0.23        23\n           imap.       0.43      0.30      0.35        10\n        ipsweep.       0.97      0.99      0.98      3849\n           land.       0.38      0.86      0.52         7\n     loadmodule.       0.00      0.00      0.00         2\n       multihop.       0.00      0.00      0.00         3\n        neptune.       1.00      1.00      1.00    102293\n           nmap.       0.52      0.99      0.68      1167\n         normal.       1.00      1.00      1.00    281286\n           perl.       0.00      0.00      0.00         1\n            phf.       0.17      1.00      0.29         1\n            pod.       0.26      1.00      0.42        18\n      portsweep.       0.96      0.99      0.98      1345\n          satan.       0.96      1.00      0.98      2691\n          smurf.       1.00      1.00      1.00    106198\n       teardrop.       0.99      0.98      0.98        89\n    warezmaster.       0.45      0.90      0.60        10\n\n     avg / total       1.00      1.00      1.00    500000\n```", "```py\nIn:\nimport matplotlib.pyplot as plt\n%matplotlib inline  \nimport matplotlib.pylab as pylab\n\nimport numpy as np\nimport pandas as pd\n\ncolumns = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\n           \"aspiration\",\"num-of-doors\",\"body-style\",\"drive-wheels\",\n           \"engine-location\",\"wheel-base\",\"length\",\"width\",\"height\",\n           \"curb-weight\",\"engine-type\",\"num-of-cylinders\",\n           \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\n           \"compression-ratio\",\"horsepower\",\"peak-rpm\",\"city-mpg\",\n           \"highway-mpg\",\"price\"]\n\ndataset = pd.read_csv('./autos/imports-85.data', \n                       na_values=\"?\", names=columns)\n```", "```py\nIn:\nprint(dataset.head())\nOut:\n   symboling  normalized-losses         make fuel-type aspiration  \\\n0          3                NaN  alfa-romero       gas        std   \n1          3                NaN  alfa-romero       gas        std   \n2          1                NaN  alfa-romero       gas        std   \n3          2                164         audi       gas        std   \n4          2                164         audi       gas        std   \n\n  num-of-doors   body-style drive-wheels engine-location  wheel-base  ...    \\\n0          two  convertible          rwd           front        88.6  ...     \n1          two  convertible          rwd           front        88.6  ...     \n2          two    hatchback          rwd           front        94.5  ...     \n3         four        sedan          fwd           front        99.8  ...     \n4         four        sedan          4wd           front        99.4  ...     \n\n   engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n0          130         mpfi  3.47    2.68                 9        111   \n1          130         mpfi  3.47    2.68                 9        111   \n2          152         mpfi  2.68    3.47                 9        154   \n3          109         mpfi  3.19    3.40                10        102   \n4          136         mpfi  3.19    3.40                 8        115   \n\n   peak-rpm city-mpg  highway-mpg  price  \n0      5000       21           27  13495  \n1      5000       21           27  16500  \n2      5000       19           26  16500  \n3      5500       24           30  13950  \n4      5500       18           22  17450  \n\n[5 rows x 26 columns]\nIn:\ndataset.dtypes\nOut:\nsymboling              int64\nnormalized-losses    float64\nmake                  object\nfuel-type             object\naspiration            object\nnum-of-doors          object\nbody-style            object\ndrive-wheels          object\nengine-location       object\nwheel-base           float64\nlength               float64\nwidth                float64\nheight               float64\ncurb-weight            int64\nengine-type           object\nnum-of-cylinders      object\nengine-size            int64\nfuel-system           object\nbore                 float64\nstroke               float64\ncompression-ratio    float64\nhorsepower           float64\npeak-rpm             float64\ncity-mpg               int64\nhighway-mpg            int64\nprice                float64\ndtype: object\n```", "```py\nIn:\nfrom sklearn.preprocessing import LabelEncoder\n\nwords_to_nums = {'two':2, 'three':3, 'four':4, 'five':5, \n                 'six':6, 'eight':8, 'twelve':12}\n\ncolumns_to_map = ['num-of-cylinders', 'num-of-doors']\ncolumns_to_dummy = ['make', 'body-style', 'drive-wheels', \n                    'engine-type', 'fuel-system']\ncolumns_to_label_encode = ['fuel-type', 'aspiration', \n                           'engine-location']\n\nfor col in columns_to_map:\n    dataset[col] = dataset[col].map(pd.Series(words_to_nums))\n\nfor col in columns_to_label_encode:\n    dataset[col] = LabelEncoder().fit_transform(dataset[col])\n\ndataset = pd.get_dummies(dataset, columns=columns_to_dummy)\n\ndataset.shape\nOut:\n(205,66)\n```", "```py\nIn:\nranks = dataset['symboling'].as_matrix()\nobservations = dataset.drop('symboling', axis=1).as_matrix()\nIn:\nfrom sklearn.preprocessing import Imputer\nimp = Imputer(strategy=\"median\", axis=0)\nobservations = imp.fit_transform(observations)\n```", "```py\nIn:\nfrom sklearn.cross_validation import StratifiedKFold\n\nkf = StratifiedKFold(ranks, 4, shuffle=True, random_state=101)\nidxs = list(kf)[0]\n\nX_train = observations[idxs[0], :]\nX_test = observations[idxs[1], :]\ny_train = ranks[idxs[0]]\ny_test = ranks[idxs[1]]\n```", "```py\nIn:\ndef prediction_to_probas(class_pred):\n\n    probas = []\n    for el in class_pred:\n        prob = [0.]*6\n        prob[el+2] = 1.0\n        probas.append(prob)\n    return np.array(probas)\n\ndef check_estimator(estimator):\n        assert sum(\n            np.abs(clf.classes_ - np.array([-2, -1, 0, 1, 2, 3]))\n        ) == 0\n```", "```py\nIn:\nfrom sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(random_state=101)\nclf.fit(X_train, y_train)\ncheck_estimator(clf)\n\ny_test_proba = prediction_to_probas(y_test)\ny_pred_proba = clf.predict_proba(X_test)\nIn:\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom sklearn.metrics import label_ranking_loss\n\nprint(\"Ranking loss:\", label_ranking_loss(y_test_proba, y_pred_proba))\nprint(\"Ranking avg precision:\", label_ranking_average_precision_score(y_test_proba, y_pred_proba))\nOut:\nRanking loss: 0.0905660377358\nRanking avg precision: 0.822327044025\n```", "```py\nIn:\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\ndef scorer(estimator, X, y):\n\n    check_estimator(estimator)\n    y_proba = prediction_to_probas(y)\n    return -1*label_ranking_loss(y_proba, estimator.predict_proba(X))\n\nparams = {'C': np.logspace(-1, 1, 10)}\n\ncv = StratifiedShuffleSplit(y_train, random_state=101,\n\n                            n_iter=5, train_size=0.70)\ngs_cv = GridSearchCV(LogisticRegression(random_state=101),\n                     param_grid=params,\n                     n_jobs=1,\n                     cv=cv,\n                     scoring=scorer)\n\ngs_cv.fit(X_train, y_train)\nclf = gs_cv.best_estimator_\n\ny_pred_proba = clf.predict_proba(X_test)\n\nprint(\"Ranking loss:\", \n      label_ranking_loss(y_test_proba, y_pred_proba))\nprint(\"Ranking avg precision:\", \n      label_ranking_average_precision_score(y_test_proba, \n                                            y_pred_proba))\nOut:\nRanking loss: 0.0716981132075\nRanking avg precision: 0.839622641509\n```", "```py\nIn:\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_normalised_confusion_matrix(cm):\n    labels_str = [str(n) for n in range(-2, 4)]\n    pylab.rcParams['figure.figsize'] = (6.0, 6.0)\n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.colorbar()\n    tick_marks = np.arange(len(labels_str))\n    plt.xticks(tick_marks, labels_str, rotation=90)\n    plt.yticks(tick_marks, labels_str)\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\nplot_normalised_confusion_matrix(confusion_matrix(y_test, clf.predict(X_test)), )\nOut:\n```", "```py\nIn:\nimport matplotlib.pyplot as plt\n%matplotlib inline  \n\nimport numpy as np\nimport pandas as pd\n\ndataset = pd.read_csv('./dji/dow_jones_index.data')\n```", "```py\nIn:\nprint(dataset.head())\nOut:\n   quarter stock       date    open    high     low   close     volume  \\\n0        1    AA   1/7/2011  $15.82  $16.72  $15.78  $16.42  239655616   \n1        1    AA  1/14/2011  $16.71  $16.71  $15.64  $15.97  242963398   \n2        1    AA  1/21/2011  $16.19  $16.38  $15.60  $15.79  138428495   \n3        1    AA  1/28/2011  $15.87  $16.63  $15.82  $16.13  151379173   \n4        1    AA   2/4/2011  $16.18  $17.39  $16.18  $17.14  154387761   \n\n   percent_change_price  percent_change_volume_over_last_wk  \\\n0               3.79267                                 NaN   \n1              -4.42849                            1.380223   \n2              -2.47066                          -43.024959   \n3               1.63831                            9.355500   \n4               5.93325                            1.987452   \n\n   previous_weeks_volume next_weeks_open next_weeks_close  \\\n0                    NaN          $16.71           $15.97   \n1              239655616          $16.19           $15.79   \n2              242963398          $15.87           $16.13   \n3              138428495          $16.18           $17.14   \n4              151379173          $17.33           $17.37   \n\n   percent_change_next_weeks_price  days_to_next_dividend  \\\n0                        -4.428490                     26   \n1                        -2.470660                     19   \n2                         1.638310                     12   \n3                         5.933250                      5   \n4                         0.230814                     97   \n\n   percent_return_next_dividend  \n0                      0.182704  \n1                      0.187852  \n2                      0.189994  \n3                      0.185989  \n4                      0.175029  \nIn:\nobservations = {}\n\nfor el in dataset[['stock', 'close']].iterrows():\n\n    stock = el[1].stock\n    close = float(el[1].close.replace(\"$\", \"\"))\n\n    try:\n        observations[stock].append(close)\n    except KeyError:\n        observations[stock] = [close]\n```", "```py\nIn:\nX = []\nstock_names = sorted(observations.keys())\n\nfor stock in stock_names:\n    X.append(observations[stock])\n\nX = np.array(X)\n```", "```py\nIn:\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error\n\nX_train = X[:, :12]\ny_train = X[:, 12]\n\nregr_1 = LinearRegression()\nregr_1.fit(X_train, y_train)\nIn:\nplot_vals = []\n\nfor offset in range(0, X.shape[1]-X_train.shape[1]):\n    X_test = X[:, offset:12+offset]\n    y_test = X[:, 12+offset]\n\n    r2 = r2_score(y_test, regr_1.predict(X_test))\n    mae = mean_absolute_error(y_test, regr_1.predict(X_test))\n\n    print(\"offset=\", offset, \"r2_score=\", r2)\n    print(\"offset=\", offset, \"MAE     =\", mae)\n\n    plot_vals.append( (offset, r2, mae) )\n\nprint()\nprint(\"r2_score: mean=\", np.mean([x[1] for x in plot_vals]), \"variance=\", np.var([x[1] for x in plot_vals]))\nprint(\"mae_score: mean=\", np.mean([x[2] for x in plot_vals]), \"variance=\", np.var([x[2] for x in plot_vals]))\nOut:\noffset= 0 r2_score= 0.999813479679\noffset= 0 MAE     = 0.384145971072\noffset= 1 r2_score= 0.99504246854\noffset= 1 MAE     = 1.602203752\noffset= 2 r2_score= 0.995188278161\noffset= 2 MAE     = 1.76248455475\noffset= 3 r2_score= 0.998287091734\noffset= 3 MAE     = 1.15856848271\noffset= 4 r2_score= 0.997938802118\noffset= 4 MAE     = 1.11955148717\noffset= 5 r2_score= 0.985036566148\noffset= 5 MAE     = 2.94239117688\noffset= 6 r2_score= 0.991598279578\noffset= 6 MAE     = 2.35632383083\noffset= 7 r2_score= 0.995485519307\noffset= 7 MAE     = 1.73191962456\noffset= 8 r2_score= 0.992872581249\noffset= 8 MAE     = 1.9828644662\noffset= 9 r2_score= 0.990012202362\noffset= 9 MAE     = 2.66825249081\noffset= 10 r2_score= 0.996984329367\noffset= 10 MAE     = 1.38682132207\noffset= 11 r2_score= 0.999029861989\noffset= 11 MAE     = 0.761720947323\noffset= 12 r2_score= 0.996280599178\noffset= 12 MAE     = 1.53124828142\n\nr2_score: mean= 0.99489000457 variance= 1.5753065199e-05\nmae_score: mean= 1.64526895291 variance= 0.487371842069\n```", "```py\nIn:\nfig, ax1 = plt.subplots()\nax1.plot([x[0] for x in plot_vals], [x[1] for x in plot_vals], 'b-')\nax1.plot(plot_vals[0][0], plot_vals[0][1], 'bo')\n\nax1.set_xlabel('test week')\n# Make the y-axis label and tick labels match the line color.\nax1.set_ylabel('r2_score', color='b')\nfor tl in ax1.get_yticklabels():\n    tl.set_color('b')\nax1.set_ylim([0.9, 1.1])\n\nax2 = ax1.twinx()\nax2.plot([x[0] for x in plot_vals], [x[2] for x in plot_vals], 'r-')\nax2.plot(plot_vals[0][0], plot_vals[0][2], 'ro')\nax2.set_ylabel('mae score', color='r')\nfor tl in ax2.get_yticklabels():\n    tl.set_color('r')\nax2.set_ylim([0, 3.3])\n\nplt.xlim([-.1, 12.1])\n\nplt.show()\nOut:\n```", "```py\nIn:\ntraining_len = 5\n\nX_train_short = X[:, :training_len]\ny_train_short = X[:, training_len]\n\nfor offset in range(1, 12-training_len):\n    X_train_short = np.vstack( (X_train_short, X[:, offset:training_len+offset]) )\n    y_train_short = np.concatenate( (y_train_short, X[:, training_len+offset]) )    \nIn:\nregr_2 = LinearRegression()\nregr_2.fit(X_train_short, y_train_short)\nIn:\nplot_vals = []\n\nfor offset in range(0, X.shape[1]-X_train.shape[1]):\n    X_test = X[:, 12-training_len+offset:12+offset]\n    y_test = X[:, 12+offset]\n\n    r2 = r2_score(y_test, regr_2.predict(X_test))\n    mae = mean_absolute_error(y_test, regr_2.predict(X_test))\n\n    print(\"offset=\", offset, \"r2_score=\", r2)\n    print(\"offset=\", offset, \"MAE     =\", mae)\n\n    plot_vals.append( (offset, r2, mae) )\n\nprint()\nprint(\"r2_score: mean=\", np.mean([x[1] for x in plot_vals]), \"variance=\", np.var([x[1] for x in plot_vals]))\nprint(\"mae_score: mean=\", np.mean([x[2] for x in plot_vals]), \"variance=\", np.var([x[2] for x in plot_vals]))\nOut:\noffset= 0 r2_score= 0.998579501272\noffset= 0 MAE     = 0.85687189133\noffset= 1 r2_score= 0.999412004606\noffset= 1 MAE     = 0.552138850961\noffset= 2 r2_score= 0.998668959234\noffset= 2 MAE     = 0.941052814674\noffset= 3 r2_score= 0.998291291965\noffset= 3 MAE     = 1.03476245234\noffset= 4 r2_score= 0.997006831124\noffset= 4 MAE     = 1.45857426198\noffset= 5 r2_score= 0.996849578723\noffset= 5 MAE     = 1.04394939395\noffset= 6 r2_score= 0.998134003499\noffset= 6 MAE     = 1.05938998285\noffset= 7 r2_score= 0.998391605331\noffset= 7 MAE     = 0.865007491822\noffset= 8 r2_score= 0.999317752361\noffset= 8 MAE     = 0.607975744054\noffset= 9 r2_score= 0.996058731277\noffset= 9 MAE     = 1.62548930127\noffset= 10 r2_score= 0.997319345983\noffset= 10 MAE     = 1.2305378204\noffset= 11 r2_score= 0.999264102166\noffset= 11 MAE     = 0.649407612032\noffset= 12 r2_score= 0.998227164258\noffset= 12 MAE     = 1.020568135\n\nr2_score: mean= 0.998116990138 variance= 9.8330905525e-07\nmae_score: mean= 0.995825057897 variance= 0.0908384278533\n```", "```py\nIn:\nfig, ax1 = plt.subplots()\nax1.plot([x[0] for x in plot_vals], [x[1] for x in plot_vals], 'b-')\nax1.plot(plot_vals[0][0], plot_vals[0][1], 'bo')\n\nax1.set_xlabel('test week')\n# Make the y-axis label and tick labels match the line color.\nax1.set_ylabel('r2_score', color='b')\nfor tl in ax1.get_yticklabels():\n    tl.set_color('b')\nax1.set_ylim([0.95, 1.05])\n\nax2 = ax1.twinx()\nax2.plot([x[0] for x in plot_vals], [x[2] for x in plot_vals], 'r-')\nax2.plot(plot_vals[0][0], plot_vals[0][2], 'ro')\nax2.set_ylabel('mae score', color='r')\nfor tl in ax2.get_yticklabels():\n    tl.set_color('r')\nax2.set_ylim([0, 2.2])\n\nplt.xlim([-.1, 12.1])\n\nplt.show()\nOut:\n```", "```py\nIn:\ntraining_lens = range(1,13)\nmodels = {}\n\nfor training_len in training_lens:\n    X_train_short = X[:, :training_len]\n    y_train_short = X[:, training_len]\n\n    for offset in range(1, 12-training_len):\n        X_train_short = np.vstack( (X_train_short, X[:, offset:training_len+offset]) )\n        y_train_short = np.concatenate( (y_train_short, X[:, training_len+offset]) )\n\n    regr_x = LinearRegression()\n    regr_x.fit(X_train_short, y_train_short)\n    models[training_len] = regr_x\n\n    plot_vals = []\n\n    for offset in range(0, X.shape[1]-X_train.shape[1]):\n        X_test = X[:, 12-training_len+offset:12+offset]\n        y_test = X[:, 12+offset]\n\n        r2 = r2_score(y_test, regr_x.predict(X_test))\n        mae = mean_absolute_error(y_test, regr_x.predict(X_test))\n\n        plot_vals.append( (offset, r2, mae) )\n\n    fig, ax1 = plt.subplots()\n    ax1.plot([x[0] for x in plot_vals], [x[1] for x in plot_vals], 'b-')\n    ax1.plot(plot_vals[0][0], plot_vals[0][1], 'bo')\n\n    ax1.set_xlabel('test week')\n    # Make the y-axis label and tick labels match the line color.\n    ax1.set_ylabel('r2_score', color='b')\n    for tl in ax1.get_yticklabels():\n        tl.set_color('b')\n    ax1.set_ylim([0.95, 1.05])\n\n    ax2 = ax1.twinx()\n    ax2.plot([x[0] for x in plot_vals], [x[2] for x in plot_vals], 'r-')\n    ax2.plot(plot_vals[0][0], plot_vals[0][2], 'ro')\n    ax2.set_ylabel('mae score', color='r')\n    for tl in ax2.get_yticklabels():\n        tl.set_color('r')\n    ax2.set_ylim([0, max([2.2, 1.1*np.max([x[2] for x in plot_vals])])])\n\n    plt.xlim([-.1, 12.1])\n\n    plt.title(\"results with training_len={}\".format(training_len))\n\n    plt.show()\n\n    print(\"r2_score: mean=\", np.mean([x[1] for x in plot_vals]), \"variance=\", np.var([x[1] for x in plot_vals]))\n    print(\"mae_score: mean=\", np.mean([x[2] for x in plot_vals]), \"variance=\", np.var([x[2] for x in plot_vals]))\n\nOut:\n... [images are omitted] ...\nresults with training_len=1\nr2_score: mean= 0.998224065712 variance= 1.00685934679e-06\nmae_score: mean= 0.95962574798 variance= 0.0663013566722\n\nresults with training_len=2\nr2_score: mean= 0.998198628321 variance= 9.17757825917e-07\nmae_score: mean= 0.969741651259 variance= 0.0661101843822\n\nresults with training_len=3\nr2_score: mean= 0.998223327997 variance= 8.57207677825e-07\nmae_score: mean= 0.969261583196 variance= 0.0715715354908\n\nresults with training_len=4\nr2_score: mean= 0.998223602314 variance= 7.91949263056e-07\nmae_score: mean= 0.972853132744 variance= 0.0737436496017\n\nresults with training_len=5\nr2_score: mean= 0.998116990138 variance= 9.8330905525e-07\nmae_score: mean= 0.995825057897 variance= 0.0908384278533\n\nresults with training_len=6\nr2_score: mean= 0.997953763986 variance= 1.14333232014e-06\nmae_score: mean= 1.04107069762 variance= 0.100961792252\n\nresults with training_len=7\nr2_score: mean= 0.997481850128 variance= 1.85277659214e-06\nmae_score: mean= 1.19114613181 variance= 0.121982635728\n\nresults with training_len=8\nr2_score: mean= 0.99715522262 variance= 3.27488548806e-06\nmae_score: mean= 1.23998671525 variance= 0.173529737205\n\nresults with training_len=9\nr2_score: mean= 0.995975415477 variance= 5.76973840581e-06\nmae_score: mean= 1.48200981286 variance= 0.22134177338\n\nresults with training_len=10\nr2_score: mean= 0.995828230003 variance= 4.92217626753e-06\nmae_score: mean= 1.51007677609 variance= 0.209938740518\n\nresults with training_len=11\nr2_score: mean= 0.994520917305 variance= 7.24129427869e-06\nmae_score: mean= 1.78424593989 variance= 0.213259808552\n\nresults with training_len=12\nr2_score: mean= 0.99489000457 variance= 1.5753065199e-05\nmae_score: mean= 1.64526895291 variance= 0.487371842069\n```"]