- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine Learning with Copilot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Machine learning, or ML, involves data and learning patterns from that said
    data and using those patterns to make predictions or decisions. Machine learning
    consists of a series of steps, all the way from loading data and cleaning it to
    eventually training a model to get the insights you need from said model. All
    these steps are roughly the same for most problems in this problem space. However,
    details may differ, like the choice of pre-processing step, the choice of algorithm,
    etc. An AI tool like GitHub Copilot comes into machine learning from a few different
    angles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Suggesting workflows**: Thanks to Copilot having been trained in machine
    learning work flows, it’s able to suggest a workflow that fits your problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommending tools and algorithms**: If you provide your AI tool with enough
    context on what your problem is and the shape of your data, an AI tool like Copilot
    can suggest tools and algorithms that fit your specific problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code assistance**: Another way that Copilot is a great help is by being able
    to generate code for various steps in the machine learning process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will explore an e-commerce dataset, and the chapter will serve
    as an interesting comparison exercise to the other chapters, which used ChatGPT
    to solve machine learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive in and discover the suggestions from GitHub Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot Chat in your IDE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GitHub Copilot Chat is a tool within certain **Integrated Development Environments**
    (**IDEs**) that answers coding questions. It helps by suggesting code, explaining
    code functionality, creating unit tests, and fixing bugs.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You have two different ways of providing prompts to GitHub Copilot:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In-editor: In this mode, you provide text comments, and through the *Tab* or
    *Return* key, Copilot is able to produce an output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chat mode: In chat mode, you type a prompt in the text box, and then GitHub
    Copilot will treat an open file/files as context (if you use `@workspace`, then
    it will look at all files in your directory).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A text file can be, for example, a code file like `app.py` or a Jupyter Notebook.
    Copilot can treat both these files as context, together with your typed prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_17_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.1: GitHub Copilot chat on the left side and an open Jupyter Notebook
    on the right side'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s explore the dataset we’re about to use. Like we did in other chapters
    on machine learning, we start with a dataset, this one being a dataset of Amazon
    book reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset contains information about different products and their reviews.
    It includes the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`marketplace` (string): Location of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`customer_id` (string): Unique ID of the customer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_id` (string): Review ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_id` (string): Unique ID of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_parent` (string): Parent product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_title` (string): Title of the product reviewed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` (string): Different product categories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating` (int): Rating of the product out of 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes` (int): Number of helpful votes for the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_votes` (int): Total number of votes for the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_headline` (string): Heading of the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_body` (string): Content of the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_date` (string): Date on which the product was reviewed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentiment` (string): Sentiment of the review (positive or negative)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steps for data exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Performing data exploration helps us understand the dataset and its characteristics.
    It involves examining the data, identifying patterns, and summarizing key insights.
    Here are the steps we will follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load the dataset**: Read the dataset into a pandas DataFrame to work with
    the data effectively.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Inspect the data**: Display the first few rows of the DataFrame to get a
    glimpse of the data. Check the column names, data types, and any missing values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Summary statistics**: Calculate summary statistics such as the mean, median,
    minimum, maximum, and quartiles for numeric columns. This helps in understanding
    the distribution and range of values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Explore categorical variables**: Analyze the unique values and their frequencies
    for categorical variables like `marketplace`, `product_category`, `and` `sentiment`.
    Visualizations such as bar plots can be helpful for this analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Distribution of ratings**: Plot a histogram or bar plot to visualize the
    distribution of `star_ratings`. This helps in understanding the overall sentiment
    of the reviews.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Temporal analysis**: Analyze the temporal aspect of the data by examining
    the `review_date` column. Explore trends, seasonality, or any patterns over time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review length analysis**: Analyze the length of `review_body` to understand
    the amount of information provided in the reviews. Calculate descriptive statistics
    like the mean, median, and maximum length.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correlation analysis**: Investigate the correlation between numeric variables
    using correlation matrices or scatter plots. This helps in identifying relationships
    between variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Additional exploratory analysis**: Conduct additional analysis based on specific
    project requirements or interesting patterns observed during the exploration process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that you can also ask GitHub Copilot which steps to follow when doing machine
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The prompts we are about to use provide high-level guidance for Copilot, and
    the outputs/results allow further tailoring of Copilot’s responses to match the
    specific dataset and analysis needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key aspects of the prompting approach are:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the task. Clearly instruct the AI assistant what task we are solving.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Break down into steps. Breaking the data exploration down into logical steps
    (like data loading, inspection, summary stats etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing context/intent for each prompt to guide Copilot (like requesting numeric
    summary statistics)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing previous results as input. Sharing outputs and results from Copilot’s
    code snippets to further guide the conversation (like printing the summary stats)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refine, iteratively refining prompts and conversing with Copilot in a back-and-forth
    way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, we will use the TAG (Task-Action-Guidance) prompt pattern described
    in *Chapter 2*. Let’s describe this project to fit this pattern, so we get a sense
    on how to write our initial prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Task**: Data exploration, find patterns and insights into customers reviews
    in an e-commerce project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Action**: We’ve described the steps we should take in a previous section;
    those should be reflected in the prompt we write.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Guidance**: The extra guidance we will provide is that we want exploratory
    techniques suggested as well as code snippets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Your initial data exploration prompt: Prompt 1, setting the high-level context'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like in other chapters where we used ChatGPT, our initial prompt sets the
    high-level context for the problem we’re looking to solve, including the domain
    and the shape of our data. All this context helps the AI tool to provide the correct
    steps both in text and code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is an initial prompt you can try:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'I am performing data exploration for the AwesomeShop e-commerce project. The
    dataset contains information about various products and their reviews. I want
    to gain insights into the data, identify patterns, and understand the characteristics
    of the reviews. Can you provide me with some exploratory analysis techniques and
    code snippets to help me uncover interesting insights from the dataset? The dataset
    for the AwesomeShop E-commerce project contains information about different products
    and their reviews. It includes the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`marketplace` (string): Location of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`customer_id` (string): Unique ID of the customer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_id` (string): Review ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_id` (string): Unique ID of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_parent` (string): Parent product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_title` (string): Title of the product reviewed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` (string): Different product categories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating` (int): Rating of the product out of 5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes` (int): Number of helpful votes for the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_votes` (int): Total number of votes for the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_headline` (string): Heading of the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_body` (string): Content of the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_date` (string): Date on which the product was reviewed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentiment` (string): Sentiment of the review (positive or negative)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'But remember that I want to learn step by step, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load the Dataset**: Read the dataset into a pandas DataFrame to work with
    the data effectively.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Inspect the Data**: Display the first few rows of the DataFrame to get a
    glimpse of the data. Check the column names, data types, and any missing values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Summary Statistics**: Calculate summary statistics such as the mean, median,
    minimum, maximum, and quartiles for numeric columns. This helps in understanding
    the distribution and range of values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Explore Categorical Variables**: Analyze the unique values and their frequencies
    for categorical variables like `marketplace`, `product_category`, `and` `sentiment`.
    Visualizations such as bar plots can be helpful for this analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Distribution of Ratings**: Plot a histogram or bar plot to visualize the
    distribution of `star_ratings`. This helps in understanding the overall sentiment
    of the reviews.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Temporal Analysis**: Analyze the temporal aspect of the data by examining
    the `review_date` column. Explore trends, seasonality, or any patterns over time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review Length Analysis**: Analyze the length of `review_body` to understand
    the amount of information provided in the reviews. Calculate descriptive statistics
    like the mean, median, and maximum length.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correlation Analysis**: Investigate the correlation between numeric variables
    using correlation matrices or scatter plots. This helps in identifying relationships
    between variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Additional Exploratory Analysis**: Conduct additional analysis based on specific
    project requirements or interesting patterns observed during the exploration process.
    Seek feedback from the user after each step.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Load the dataset'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We get quite a wordy response from Copilot, so let’s break down the response
    into parts and explain what we get.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sure, let’s start with step 1: loading the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Please replace `'/path/to/your/file.csv'` with your actual filename or path
    to the file. Once you’ve done this, you can run the code to load your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let me know once you’ve successfully loaded the data, and we can proceed to
    the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_17_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.2: Showing part of the Copilot prompt and the start of the Copilot
    result on loading data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try the output code generated by Copilot and see if it works. Modify
    the `file_path` variable to point to the location of your dataset, and then execute
    the code. Note below how we edited the file path to reflect an actual path in
    our system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Running the code for loading data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s run the code provided by Copilot. See the below output from our Jupyter
    Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Inspect the data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, let’s inspect the data. For the inspection prompt, we’ll use the output
    from our code execution and see if we can get Copilot to tell us about the next
    step we need to take:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It runs fine; below is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The output is truncated. View it as a scrollable element or open it in a text
    editor. Adjust cell output settings...
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Great! Now that you’ve successfully loaded the dataset, let’s move on to “inspecting
    the data.”
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This code will give you an overview of your dataset, including the names of
    the columns, the data types of each column, and the number of missing values in
    each column. Run this code and let me know what you find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try the code above to inspect the data and see if it works. Run the below
    code in a code cell in your Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Great! So far, it has served us well when we provide Copilot with a state of
    where we are going and get it to suggest the next steps; let’s keep following
    that format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Summary statistics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we want to summarize things, so we again provide it with output data
    in the hope that Copilot will tell us what the next step is:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are no missing values; below is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Now that we’ve inspected the data, let’s move on to step 3: calculating
    summary statistics for numeric columns. This will help us understand the distribution
    and range of values.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This code will provide you with the count, mean, standard deviation, minimum,
    25th percentile, median (50th percentile), 75th percentile, and maximum of the
    numeric columns in your dataset. Run this code and let me know what you find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this and see if it works. Let’s run the code below and call `df.describe`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Great! We’re able to see the count, mean value standard deviation, and more.
    We’ve continued to use the idea of feeding Copilot the output of our code, and
    it’s been able to understand at which point in the machine learning process it
    is and what to do next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Explore categorical variables'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like before, let’s construct a prompt consisting of the output of the
    code we just ran and let Copilot tell us what should happen next:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Now that we have the summary statistics, let’s move on to step 4: exploring
    categorical variables. We’ll analyze the unique values and their frequencies for
    categorical variables like `marketplace`, `product_category`, and `sentiment`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this and see if it works. Run the below code in a code cell to analyze
    the categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 5: Distribution of ratings'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we want to understand the distribution of ratings. To learn more about
    the ratings, we will provide the output from the last code execution as a prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '`market_place` unique values: [‘“US”’]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`market_place` value counts: `market_place` “US” 100 Name: count, dtype: int64'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` unique values: [‘“Books”’]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` value counts: product_category “Books” 100 Name: count,
    dtype: int64'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sentiment_books` unique values: [‘positive’ ‘negative’]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Sentiment_books` value counts: `Sentiment_books` positive 84 negative 16 Name:
    count, dtype: int64'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Now that we’ve explored the categorical variables, let’s move on to
    step 5: visualizing the distribution of star ratings.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This code will plot a histogram of the star ratings, which will help us understand
    the overall sentiment of the reviews. Run this code and let me know what you find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this and see if it works. Below, we have code for performing visualization;
    run this code in a code cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B21232_17_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.3: Distribution of star ratings'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 6: Temporal analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have a good idea of how ratings are distributed; it seems
    like they are either very low or very high. Let’s progress to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Now let’s move on to step 6: Temporal Analysis. We’ll analyze the `review_date`
    column to explore trends, seasonality, or any patterns over time.'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to convert the `review_date` column to a datetime format. Then,
    we can extract the year, month, and day into separate columns for easier analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This code will print the number of reviews per year, month, and day. Run this
    code and let me know what you find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this code and see if it works. Run the above code in a code cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see an output similar to the below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 7: Review length analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s move forward in our analysis; next up is a review length analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the output: year 2015 100 Name: count, dtype: int64 month 8 100 Name:
    count, dtype: int64 day 31 100 Name: count, dtype: int64'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Now that we’ve analyzed the temporal aspect of the data, let’s move
    on to step 7: Review Length Analysis. We’ll analyze the length of `review_body`
    to understand the amount of information provided in the reviews.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This code will calculate the length of each review and provide descriptive statistics
    like mean, median, and maximum length. Run this code and let me know what you
    find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we want to understand what the above code is doing; let’s ask
    Copilot for help:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Before we move on to step 7, can you please explain how to interpret the output?
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Absolutely. The output you’ve shared indicates the frequency of reviews based
    on the year, month, and day.
  prefs: []
  type: TYPE_NORMAL
- en: '`year`: All 100 reviews in your dataset were written in the year 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`month`: All 100 reviews were written in the 8th month, which is August.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`day`: All 100 reviews were written on the 31st day of the month.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This suggests that all the reviews in your dataset were written on the same
    date - August 31, 2015.
  prefs: []
  type: TYPE_NORMAL
- en: In a larger, more diverse dataset, you might see reviews spread across different
    years, months, and days. Analyzing these could help identify trends or patterns
    over time, such as an increase in reviews during certain periods.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, we have a problem – our dataset is limited, and all reviews seem to have
    taken place at the same point in time, which prevents us from discovering trends.
    Let’s inform Copilot of that and see what we can do next:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: In that case, we cannot explore trends or patterns within this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[P****rompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: That’s correct. Since all the reviews in this dataset are from the same date,
    we won’t be able to analyze trends or patterns over time. However, you can still
    perform other types of analysis. For instance, you can analyze the length of the
    reviews, the distribution of star ratings, or the frequency of certain words or
    phrases in the review text.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a larger, more diverse dataset, you could also analyze trends over
    time, compare different products or categories, or use machine learning to predict
    star ratings based on the review text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s proceed with the review length analysis as planned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This code will calculate the length of each review and provide descriptive statistics
    like mean, median, and maximum length. Run this code and let me know what you
    find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this code and see if it works. Type this code into a code cell and
    run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output similar to the below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: 'count 100.000000 mean 253.190000 std 420.934403 min 6.000000 25% 36.000000
    50% 104.500000 75% 269.750000 max 2685.000000 Name: review_length, dtype: float64'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: You should receive a response similar to the response below.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! The output you’ve shared provides a summary of the review lengths in
    your dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '`count`: There are 100 reviews in your dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mean`: On average, a review is about 253 characters long.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std`: The standard deviation is approximately 421, indicating that the lengths
    of the reviews vary quite a bit around the mean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min`: The shortest review is 6 characters long.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`25%`: 25% of the reviews are 36 characters long or shorter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`50%` (or median): Half of the reviews are 104.5 characters long or shorter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`75%`: 75% of the reviews are 269.75 characters long or shorter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max`: The longest review is 2685 characters long.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This information can be useful to understand the amount of text available for
    any text analysis or natural language processing tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For the next step, you could consider visualizing this data or analyzing the
    text content of the reviews. For example, you could create a histogram of review
    lengths, or you could use a word cloud to visualize the most common words in the
    reviews. Let me know what you’d like to do next.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 8: Correlation analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we want to determine the relationship between two or more variables to
    understand what variables are related. The below prompt shows how we progress
    in our analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Proceed to the next step for correlation analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sure, let’s move on to step 8: Correlation Analysis. We’ll analyze the correlation
    between numeric variables like `star_rating`, `helpful_votes`, and `total_votes`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This code will calculate and print a correlation matrix, which shows the correlation
    coefficients between pairs of variables. The correlation coefficient ranges from
    -1 to 1\. A value close to 1 implies a high positive correlation while a value
    close to -1 implies a high negative correlation. A value close to 0 implies no
    correlation. Run this code and let me know what you find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this code and see if it works. Add the correlation code to a code
    cell in your Notebook and run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see an output similar to the below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s send the above output to Copilot and see if we can get an explanation
    of the correlations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the output: star_rating helpful_votes total_votes star_rating 1.000000
    -0.324371 -0.517002 helpful_votes -0.324371 1.000000 0.659612 total_votes -0.517002
    0.659612 1.000000'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! The output you’ve shared is a correlation matrix, which shows the correlation
    coefficients between pairs of variables. Here’s how to interpret it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`star_rating` and `helpful_votes`: The correlation coefficient is -0.324371,
    indicating a weak negative correlation. This suggests that as the star rating
    increases, the number of helpful votes tends to decrease slightly, and vice versa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating` and `total_votes`: The correlation coefficient is -0.517002,
    indicating a moderate negative correlation. This suggests that as the star rating
    increases, the total number of votes (both helpful and not helpful) tends to decrease,
    and vice versa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes` and `total_votes`: The correlation coefficient is 0.659612,
    indicating a moderate positive correlation. This suggests that as the number of
    helpful votes increases, the total number of votes also tends to increase, and
    vice versa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the next step, you could consider visualizing these correlations using a
    heatmap, or you could move on to another type of analysis. Let me know what you’d
    like to do next.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we want to look into visualizations of these correlations; a heatmap is
    one way to do this.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: For Step 8.1, visualize these correlations using a heatmap.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[P****rompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Sure, let’s visualize the correlation matrix using a heatmap. We’ll use the
    seaborn library for this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will create a heatmap of the correlation matrix. The colors represent
    the correlation coefficients: warm colors (towards red) indicate positive correlation,
    cool colors (towards blue) indicate negative correlation, and neutral colors (around
    white) indicate no correlation. The `annot=True` option will display the correlation
    coefficients on the heatmap. Run this code and let me know what you find.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try this code to create a heatmap visualization using the seaborn library
    and see if it works. Run the code in a code cell in your Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output similar to the below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_17_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.4: Heatmap showing the correlation between three variables: total_votes,
    helpful_votes, and star_rating'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 9: Additional exploratory analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, why do we want to perform an additional exploratory analysis? Well, there
    are some good reasons why we would want to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Uncovering hidden user patterns: Sometimes, there are trends, patterns, and
    relationships not immediately discoverable, and taking a second deeper look can
    find these.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Validate initial findings: By validating the results from the initial analysis
    with a second analysis, you ensure robustness and reliability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Identify outliers: Not effectively finding outliers can skew the results. Spending
    more time on finding these can pay off.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Improve model accuracy: Additional variables can be identified that can improve
    accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Above is a non-exhaustive list of reasons why we should do an additional analysis.
    Let’s see how Copilot can help us:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Thank you, I wish to understand if there is any more exploratory analysis for
    the sentiment analysis of this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly, sentiment analysis often involves exploring the text data in more
    depth. Here are a few additional steps you could consider:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 10: Text Preprocessing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before analyzing the text, it’s often helpful to clean it up a bit. This can
    involve converting all text to lower case, removing punctuation, removing stop
    words (common words like “and”, “the”, “a”, which don’t add much meaning), and
    stemming or lemmatizing (reducing words to their root form).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 11: Word Frequency Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After preprocessing the text, you can analyze the frequency of words in the
    reviews. This can help identify common themes or topics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 12: Sentiment Score Calculation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can calculate a sentiment score for each review using a sentiment analysis
    tool like TextBlob or Vader. This can provide a more quantitative measure of the
    sentiment expressed in the reviews.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Please note that you’ll need to install the `nltk` and `textblob` libraries
    to run this code, which you can do using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Let me know if you’d like to proceed with any of these steps, or if there’s
    something else you’d like to do.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This prompt yielded three steps as a response. Let’s try the code from all
    three steps and see if it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Text preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Word frequency analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see an output similar to the below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, use the output above and construct the next prompt to understand our
    situation better:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Below is the output: [(‘book’, 80), (‘read’, 25), (‘love’, 24), (‘great’, 24),
    (‘stori’, 19), (‘good’, 17), (‘page’, 16), (‘one’, 15), (‘like’, 14), (‘realli’,
    14)]'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! The output you’ve shared shows the 10 most common words in the cleaned
    reviews, along with their frequencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This suggests that most of the reviews are positive, with words like ‘love’,
    ‘great’, and ‘good’ being quite common. The words ‘book’, ‘read’, and ‘page’ are
    also common, which is expected in a dataset of book reviews.
  prefs: []
  type: TYPE_NORMAL
- en: For the next step, you could consider calculating a sentiment score for each
    review to get a more quantitative measure of the sentiment. Alternatively, you
    could visualize the word frequencies using a bar chart or a word cloud. Let me
    know what you’d like to do next.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to run the sentiment score calculation code below:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment score calculation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s try to interpret the response. As usual, let’s create a prompt
    from the response and see what Copilot thinks of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the code below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output: 0.23785470981747298'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should receive a response similar to the response below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Great! The output you’ve shared is the average sentiment score for the reviews
    in your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The sentiment score is a number between -1 and 1\. A score of -1 represents
    extremely negative sentiment, a score of 1 represents extremely positive sentiment,
    and a score of 0 represents neutral sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: The average sentiment score in your dataset is approximately 0.238, which indicates
    a generally positive sentiment in the reviews. This aligns with the word frequency
    analysis, which showed that positive words like ‘love’, ‘great’, and ‘good’ are
    quite common in the reviews.
  prefs: []
  type: TYPE_NORMAL
- en: For the next step, you could consider visualizing the distribution of sentiment
    scores using a histogram or a box plot. Alternatively, you could analyze the relationship
    between sentiment score and other variables like star rating or review length.
    Let me know what you’d like to do next.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these instructions step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualize the distribution of sentiment scores using a histogram.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyze the relationship between sentiment score and other variables like star
    rating or review length.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: You should receive a response similar to the response below.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Sure, let’s proceed with those steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 13: Visualize the Distribution of Sentiment Scores'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use a histogram to visualize the distribution of sentiment scores.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 14: Analyze the Relationship Between Sentiment Score and Other Variables'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use scatter plots to visualize the relationship between sentiment score
    and other variables like star rating and review length.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: These plots will help you understand if there’s any correlation between sentiment
    score and star rating or review length. Run these codes and let me know what you
    find.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try the above code and see if it works. Add the below code to a code
    cell and run it:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualize the distribution of sentiment scores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B21232_17_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.5: Image depicting the distribution of sentiment scores'
  prefs: []
  type: TYPE_NORMAL
- en: Analyze the relationship between sentiment score and other variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B21232_17_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.6: Sentiment score versus star rating'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_17_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.7: Sentiment score versus review length'
  prefs: []
  type: TYPE_NORMAL
- en: Assignment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Your assignment is to reflect on the approach taken and go through a similar
    regression scenario for this dataset on house prices in Boston: [https://www.kaggle.com/datasets/vikrishnan/boston-house-prices](https://www.kaggle.com/datasets/vikrishnan/boston-house-prices).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some questions you could try answering using the above dataset and
    regression:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Price Prediction: What is the estimated price of a house, given its features
    (e.g., size, location, and number of bedrooms)?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feature Importance: Which features have the most significant impact on house
    prices?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Price Trends: How do house prices change over time in a specific area?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The solution is in the repository: [https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT](https://github.com/PacktPublishing/AI-Assisted-Software-Development-with-GitHub-Copilot-and-ChatGPT)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter had one important purpose – to compare and contrast the experience
    of using ChatGPT with GitHub Copilot and, in this case, its chat function. We
    used an approach that consisted of providing a lot of upfront information to Copilot,
    by describing the overall problem and the shape of the dataset. We also provided
    instructions to let Copilot guide us on what to do, which showed us the steps
    to take gradually and what code to run. The general conclusion is that we can
    use roughly the same method using Copilot Chat as we did with ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: We also saw how Copilot can help explain our output, understand where in the
    process we are, and suggest the next step to take.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule, we should always test code and ask our AI assistant to help if it
    doesn’t run or produce the expected output.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/aicode](https://packt.link/aicode)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code510410532445718281.png)'
  prefs: []
  type: TYPE_IMG
