- en: Beating CAPTCHAs with Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络击败CAPTCHA
- en: Images pose interesting and difficult challenges for data miners. Until recently,
    only small amounts of progress were made with analyzing images for extracting
    information. However recently, such as with the progress made on self-driving
    cars, significant advances have been made in a very short time-frame. The latest
    research is providing algorithms that can understand images for commercial surveillance,
    self-driving vehicles, and person identification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图像对数据挖掘者提出了有趣且困难的挑战。直到最近，在分析图像以提取信息方面只取得了少量进展。然而，最近，例如在自动驾驶汽车方面的进展，在很短的时间内取得了显著的进步。最新的研究提供了可以理解图像的算法，用于商业监控、自动驾驶车辆和人员识别。
- en: There is lots of raw data in an image, and the standard method for encoding
    images - pixels - isn't that informative by itself. Images and photos can be blurry,
    too close to the targets, too dark, too light, scaled, cropped, skewed, or any
    other of a variety of problems that cause havoc for a computer system trying to
    extract useful information. Neural networks can combine these lower level features
    into higher level patterns that are more able to generalize and deal with these
    issues.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中包含大量的原始数据，而编码图像的标准方法——像素——本身并不具有太多信息。图像和照片也可能模糊、过于接近目标、过暗、过亮、缩放、裁剪、倾斜，或者任何其他可能导致计算机系统在提取有用信息时出现混乱的问题。神经网络可以将这些低级特征组合成更高级的模式，这些模式更有能力进行泛化和处理这些问题。
- en: 'In this chapter, we look at extracting text data from images by using neural
    networks for predicting each letter in the CAPTCHA. CAPTCHAs are images designed
    to be easy for humans to solve and hard for a computer to solve, as per the acronym:
    **Completely Automated Public Turing test to tell Computers and Humans Apart**.
    Many websites use them for registration and commenting systems to stop automated
    programs flooding their site with fake accounts and spam comments.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过使用神经网络预测CAPTCHA中的每个字母来提取图像中的文本数据。CAPTCHA是设计得对人类来说容易解决而对计算机来说难以解决的图像，正如其首字母缩略词：**完全自动化的公开图灵测试，用于区分计算机和人类**。许多网站使用它们作为注册和评论系统，以阻止自动化程序向其网站发送虚假账户和垃圾评论。
- en: These tests help stop programs (bots) using websites, such as a bot intent on
    automatically signing up new people to a website. We play the part of such a spammer,
    trying to get around a CAPTCHA-protected system for posting messages to an online
    forum. The website is protected by a CAPTCHA, meaning we can't post unless we
    pass the test.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试有助于阻止程序（机器人）使用网站，例如一个旨在自动将新用户注册到网站上的机器人。我们扮演这样的垃圾邮件发送者的角色，试图绕过保护在线论坛发帖的CAPTCHA系统。该网站受到CAPTCHA的保护，这意味着除非我们通过测试，否则我们无法发帖。
- en: 'The topics covered in this chapter include:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的主题包括：
- en: Neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Creating our own dataset of CAPTCHAs and letters
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建我们自己的CAPTCHA和字母数据集
- en: The scikit-image library for working with image data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于处理图像数据的scikit-image库
- en: Extracting basic features from images
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从图像中提取基本特征
- en: Using neural networks for larger-scale classification tasks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络进行更大规模的分类任务
- en: Improving performance using postprocessing
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过后处理提高性能
- en: Artificial neural networks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: Artificial neural networks
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: 'Neural networks are a class of algorithm that was originally designed based
    on the way that human brains work. However, modern advances are generally based
    on mathematics rather than biological insights. A neural network is a collection
    of neurons that are connected together. Each neuron is a simple function of its
    inputs, which are combined using some function to generate an output:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是一类最初基于人类大脑工作方式设计的算法。然而，现代的进步通常基于数学而不是生物洞察。神经网络是一组相互连接的神经元。每个神经元是其输入的简单函数，这些输入通过某种函数组合起来生成输出：
- en: '![](img/B06162_08_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_08_01.jpg)'
- en: 'The functions that define a neuron''s processing can be any standard function,
    such as a linear combination of the inputs, and is called the **activation function**.
    For the commonly used learning algorithms to work, we need the activation function
    to be *derivable* and  *smooth*. A frequently used activation function is the
    **logistic function**, which is defined by the following equation (*k* is often
    simply 1, *x* is the inputs into the neuron, and L is normally 1, that is, the
    maximum value of the function):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 定义神经元处理功能的函数可以是任何标准函数，例如输入的线性组合，这被称为**激活函数**。为了使常用的学习算法能够工作，我们需要激活函数是**可导的**和**平滑的**。一个常用的激活函数是**逻辑函数**，其定义如下（*k*通常简单地取1，*x*是输入到神经元的值，L通常是1，即函数的最大值）：
- en: '![](img/B06162_08_02.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_08_02.png)'
- en: The value of this graph, from -6 to +6, is shown below. The red lines indicate
    that the value is 0.5 when *x* is zero, but the function quickly climbs to 1.0
    as x increases, and quickly drops to -1.0 when x decreases.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 该图从-6到+6的值如下所示。红色线条表示当*x*为零时值为0.5，但随着*x*的增加，函数迅速上升到1.0，当*x*减少时，迅速下降到-1.0。
- en: '![](img/B06162_08_03.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_08_03.png)'
- en: Each individual neuron receives its inputs and then computes the output based
    on these values. Neural networks can be considered as a collection of these neurons
    connected together, and they can be very powerful for data mining applications.
    The combinations of these neurons, how they fit together, and how they combine
    to learn a model are one of the most powerful concepts in machine learning.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元都会接收其输入，然后根据这些值计算输出。神经网络可以被视为这些神经元相互连接的集合，它们在数据挖掘应用中可以非常强大。这些神经元的组合、它们如何相互配合以及它们如何组合来学习模型是机器学习中最强大的概念之一。
- en: An introduction to neural networks
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络简介
- en: For data mining applications, the arrangement of neurons is usually in **layers**.
    The first layer is called the **input layer** and takes its input from samples
    in the data. The outputs of each of these neurons are computed and then passed
    along to the neurons in the next layer. This is called a **feed-forward neural
    network**. We will refer to these simply as **neural networks** for this chapter,
    as they are the most common type used and the only type used in this chapter.
    There are other types of neural networks too that are used for different applications.
    We will see another type of network in [Chapter 11](4b36fb74-3c44-430a-ac71-92412fc77a7b.xhtml)*,
    Object Detection in Images Using Deep Neural Networks*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据挖掘应用，神经元的排列通常是**分层**的。第一层被称为**输入层**，它从数据样本中获取输入。这些神经元的输出被计算，然后传递到下一层的神经元。这被称为**前馈神经网络**。在本章中，我们将简单地称之为**神经网络**，因为它们是最常用的类型，也是本章唯一使用的类型。还有其他类型的神经网络，用于不同的应用。我们将在[第11章](4b36fb74-3c44-430a-ac71-92412fc77a7b.xhtml)*，使用深度神经网络的图像目标检测*中看到另一种类型的网络。
- en: 'The outputs of one layer become the inputs of the next layer, continuing until
    we reach the final layer: the **output layer**. These outputs represent the predictions
    of the neural network as the classification. Any layer of neurons between the
    input layer and the output layer is referred to as a **hidden layer**, as they
    learn a representation of the data not intuitively interpretable by humans. Most
    neural networks have at least three layers, although most modern applications
    use networks with many more layers than that.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一层的输出成为下一层的输入，一直持续到我们达到最后一层：**输出层**。这些输出代表了神经网络的预测，作为分类。输入层和输出层之间的任何神经元层都被称为**隐藏层**，因为它们学习的数据表示对于人类来说不是直观可解释的。大多数神经网络至少有三层，尽管大多数现代应用使用的网络比这多得多。
- en: '![](img/B06162_08_04.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B06162_08_04.jpg)'
- en: Typically, we consider fully connected layers. The outputs of each neuron in
    a layer go to all neurons in the next layer. While we do define a fully connected
    network, many of the weights will be set to zero during the training process,
    effectively removing these links. Additionally, many of these weights might retain
    very small values, even after training.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们考虑全连接层。每一层的每个神经元的输出都流向下一层的所有神经元。虽然我们定义了全连接网络，但在训练过程中，许多权重将被设置为0，从而有效地移除了这些链接。此外，许多这些权重可能在训练后仍然保留非常小的值。
- en: In addition to being one of the conceptually simpler forms for neural networks,
    fully connected neural networks are also simpler and more efficient to program
    than other connection patterns.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了是神经网络概念上更简单的形式之一外，全连接神经网络在编程上比其他连接模式更简单、更高效。
- en: See [Chapter 11](4b36fb74-3c44-430a-ac71-92412fc77a7b.xhtml), *Object Detection
    in images using Deep Neural Networks*,  for an investigation into different types
    of neural networks, including layers built specifically for image processing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[第11章](4b36fb74-3c44-430a-ac71-92412fc77a7b.xhtml)，*使用深度神经网络在图像中进行目标检测*，了解不同类型神经网络的调查，包括专门用于图像处理的层。
- en: As the function of the neurons is normally the logistic function, and the neurons
    are fully connected to the next layer, the parameters for building and training
    a neural network must be other factors.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由于神经元的函数通常是逻辑函数，并且神经元与下一层完全连接，因此构建和训练神经网络所需的参数必须是其他因素。
- en: 'The first factor for neural networks is in the building phase: the size and
    shape of the neural network. This includes how many layers the neural network
    has and how many neurons it has in each hidden layer (the size of the input and
    output layers is usually dictated by the dataset).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的第一个因素在构建阶段：神经网络的大小和形状。这包括神经网络有多少层以及每个隐藏层中有多少个神经元（输入和输出层的大小通常由数据集决定）。
- en: 'The second parameter for neural networks is determined in the training phase:
    the weight of the connections between neurons. When one neuron connects to another,
    this connection has an associated weight that is multiplied by the signal (the
    output of the first neuron). If the connection has a weight of 0.8, the neuron
    is activated, and it outputs a value of 1, the resulting input to the next neuron
    is 0.8\. If the first neuron is not activated and has a value of 0, this stays
    at 0.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络的第二个参数在训练阶段确定：神经元之间连接的权重。当一个神经元连接到另一个神经元时，这个连接有一个相关的权重，该权重会乘以信号（第一个神经元的输出）。如果连接的权重为0.8，则神经元被激活，并输出值为1，因此传递给下一个神经元的输入是0.8。如果第一个神经元未激活且值为0，则该值保持在0。
- en: The combination of an appropriately sized network and well-trained weights determines
    how accurate the neural network can be when making classifications. The word *appropriately*
    in the previous sentence also doesn't necessarily mean bigger, as neural networks
    that are too large can take a long time to train and can more easily over-fit
    the training data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 网络大小和训练良好的权重的组合决定了神经网络在分类时的准确性。前一句话中的“适当”一词也不一定意味着更大，因为过大的神经网络可能需要很长时间来训练，并且更容易过拟合训练数据。
- en: Weights can be set randomly to start with but are then updated during the training
    phase. Setting weights to zero is normally not a good idea, as all neurons in
    the network act similarly to begin with! Having randomly set weights gives each
    neuron a different *role* in the learning process that can be improved with training.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 权重可以随机设置以开始，但在训练阶段会进行更新。将权重设置为零通常不是一个好主意，因为网络中的所有神经元最初都表现得非常相似！随机设置权重给每个神经元在学习过程中提供了一个不同的*角色*，这个角色可以通过训练得到改善。
- en: A neural network in this configuration is a classifier that can then be used
    to predict the target of a data sample based on the inputs, much like the classification
    algorithms we have used in previous chapters. But first, we need a dataset to
    train and test with.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种配置下的神经网络是一个分类器，可以用来根据输入预测数据样本的目标，就像我们在前几章中使用过的分类算法一样。但首先，我们需要一个用于训练和测试的数据集。
- en: Neural networks are, by a margin, the biggest area of advancement in data mining
    in recent years. This might make you think: *Why bother learning any other type
    of classification algorithm?* While neural networks are state of the art in pretty
    much every domain (at least, right now), the reason to learn other classifiers
    is that neural networks often require larger amounts of data to work well, and
    they take a long time to learn. If you don't have **big data**, you will probably
    get better results from another algorithm.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是近年来数据挖掘领域最大的进步。这可能会让你想：*为什么还要学习其他类型的分类算法呢？*虽然神经网络在几乎所有领域都是最先进的（至少，现在是这样），但学习其他分类器的理由是神经网络通常需要更多的数据才能有效工作，并且学习时间较长。如果你没有**大数据**，你可能会从另一个算法中获得更好的结果。
- en: Creating the dataset
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建数据集
- en: In this chapter, to spice up things a little, let us take on the role of the
    bad guy. We want to create a program that can beat CAPTCHAs, allowing our comment
    spam program to advertise on someone's website. It should be noted that our CAPTCHAs
    will be a little easier than those used on the web today and that spamming isn't
    a very nice thing to do.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，为了使内容更加生动，让我们扮演一下坏人的角色。我们想要创建一个能够击败CAPTCHAs的程序，让我们的评论垃圾邮件程序能够在某个人的网站上做广告。需要注意的是，我们的CAPTCHAs将比现在网络上使用的那些稍微简单一些，而且垃圾邮件并不是一件很体面的事情。
- en: We play the bad guy today, but please *don't* use this against real world sites.
    One reason to "play the bad guy" is to help improve the security of our website,
    by looking for issues with it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天扮演坏人，但请*不要*将其用于现实世界的网站。扮演坏人的一个原因是为了帮助提高我们网站的安全性，通过寻找它的问题。
- en: 'Our experiment will simplify a CAPTCHA to be individual English words of four
    letters only, as shown in the following image:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验将简化CAPTCHA，使其仅包含四个字母的单独英语单词，如下面的图像所示：
- en: '![](img/B06162_08_05.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_05.png)'
- en: 'Our goal will be to create a program that can recover the word from images
    like this. To do this, we will use four steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是创建一个程序，可以从这样的图像中恢复单词。为此，我们将使用以下四个步骤：
- en: Break the image into individual letters.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像分解成单个字母。
- en: Classify each individual letter.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对每个单独的字母进行分类。
- en: Recombine the letters to form a word.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将字母重新组合成一个单词。
- en: Rank words with a dictionary to try to fix errors.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用词典对单词进行排序，以尝试纠正错误。
- en: Our CAPTCHA-busting algorithm will make the following assumptions. First, the
    word will be a whole and valid four-character English word (in fact, we use the
    same dictionary for creating and busting CAPTCHAs). Second, the word will only
    contain uppercase letters. No symbols, numbers, or spaces will be used.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的CAPTCHA破解算法将做出以下假设。首先，单词将是一个完整的、有效的四个字符的英语单词（实际上，我们使用相同的词典来创建和破解CAPTCHAs）。其次，单词将只包含大写字母。不会使用符号、数字或空格。
- en: We are going to make the problem slightly harder than simply identifying letters,
    by performing a shear transform to the text, along with varying rates of shearing and
    scaling.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使问题比仅仅识别字母稍微困难一些，通过对文本执行剪切变换，以及不同的剪切和缩放率。
- en: Drawing basic CAPTCHAs
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制基本的CAPTCHAs
- en: Before we can start classifying CAPTCHAs, we first need a dataset to learn from.
    In this section, we will be generating our own data to perform the data mining
    on.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始对CAPTCHAs进行分类之前，我们首先需要一个用于学习的数据集。在本节中，我们将生成自己的数据以进行数据挖掘。
- en: In more real-world applications, you'll be wanting to use an existing CAPTCHA
    service to generate the data, but for our purposes in this chapter, our own data
    will be sufficient. One of the issues that can arise is that we code in our assumptions
    around how the data works when we create the dataset ourselves, and then carry
    those same assumptions over to our data mining training.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在更现实的应用中，你可能想要使用现有的CAPTCHA服务来生成数据，但就本章的目的而言，我们自己的数据就足够了。可能出现的一个问题是，当我们自己创建数据集时，我们会在数据的工作方式上编码我们的假设，然后将这些相同的假设应用到我们的数据挖掘训练中。
- en: Our goal here is to draw an image with a word on it, along with a shear transform.
    We are going to use the PIL library to draw our CAPTCHAs and the `scikit-image`
    library to perform the shear transform. The `scikit-image` library can read images
    in a NumPy array format that PIL can export to, allowing us to use both libraries.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是绘制一个带有单词的图像，并对其进行剪切变换。我们将使用PIL库来绘制我们的CAPTCHAs，并使用`scikit-image`库来执行剪切变换。`scikit-image`库可以以NumPy数组格式读取图像，而PIL可以导出这种格式，这使得我们可以使用这两个库。
- en: 'Both PIL and scikit-image can be installed via Anaconda. However, I recommend
    getting PIL through its replacement called **pillow**:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PIL和scikit-image都可以通过Anaconda安装。然而，我建议通过其替代品**pillow**来获取PIL：
- en: conda install pillow scikit-image
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: conda install pillow scikit-image
- en: 'First, we import the necessary libraries and modules. We import NumPy and the
    Image drawing functions as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的库和模块。我们按照以下方式导入NumPy和图像绘制函数：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then we create our base function for generating CAPTCHAs. This function takes
    a word and a shear value (which is normally between 0 and 0.5) to return an image
    in a NumPy array format. We allow the user to set the size of the resulting image,
    as we will use this function for single-letter training samples as well:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建生成CAPTCHAs的基本函数。这个函数接受一个单词和一个剪切值（通常在0和0.5之间），以返回一个NumPy数组格式的图像。我们允许用户设置结果的图像大小，因为我们还将使用这个函数来生成单个字母的训练样本：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this function, we create a new image using L for the format, which means
    black-and-white pixels only, and create an instance of the `ImageDraw` class.
    This allows us to draw on this image using PIL. We then load the font, draw the
    text, and perform a `scikit-image` shear transform on it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个函数中，我们使用 L 格式创建一个新的图像，这意味着只有黑白像素，并创建一个 `ImageDraw` 类的实例。这允许我们使用 PIL 在这个图像上绘制。然后我们加载字体，绘制文本，并对它执行
    `scikit-image` 的剪切变换。
- en: 'You can get the Coval font I used from the Open Font Library at:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 Open Font Library 在以下链接获取我使用的 Coval 字体：
- en: '[http://openfontlibrary.org/en/font/bretan](http://openfontlibrary.org/en/font/bretan)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://openfontlibrary.org/en/font/bretan](http://openfontlibrary.org/en/font/bretan)'
- en: Download the `.zip` file and extract the `Coval-Black.otf` file into the same
    directory as your Notebook.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 `.zip` 文件，并将 `Coval-Black.otf` 文件提取到与您的 Notebook 相同的目录中。
- en: 'From here, we can now generate images quite easily and use `pyplot` to display
    them. First, we use our inline display for the matplotlib graphs and import `pyplot`.
    The code is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们现在可以很容易地生成图像，并使用 `pyplot` 显示它们。首先，我们使用 matplotlib 图表的内联显示并导入 `pyplot`。代码如下：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The result is the image shown at the start of this section: our CAPTCHA. Here
    are some other examples with different shear and scale values:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是本节开头显示的图像：我们的 CAPTCHA。这里有一些具有不同剪切和缩放值的其他示例：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/B06162_08_12-2-e1493021528419.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_12-2-e1493021528419.png)'
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](img/B06162_08_13-e1493021566785.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_13-e1493021566785.png)'
- en: 'Here is a variant scaled to `1.5` sized. While it looks similar to the BONE
    image above, note the *x*-axis and *y*-axis values are larger:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个放大到 `1.5` 倍的变体。虽然它看起来与上面的 BONE 图像相似，但请注意 *x* 轴和 *y* 轴的值更大：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/B06162_08_14-e1493021653291.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_14-e1493021653291.png)'
- en: Splitting the image into individual letters
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将图像分割成单个字母
- en: 'Our CAPTCHAs are words. Instead of building a classifier that can identify
    the thousands and thousands of possible words, we will break the problem down
    into a smaller problem: predicting letters.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 CAPTCHA 是单词。我们不会构建一个可以识别成千上万可能单词的分类器，而是将问题分解成更小的问题：预测字母。
- en: Our experiment is in English, and all uppercase, meaning we have 26 classes
    to predict from for each letter. If you try these experiments in other languages,
    keep in mind the number of output classes will have to change.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实验使用的是英语，并且全部大写，这意味着对于每个字母，我们都有 26 个类别来预测。如果您在其他语言中尝试这些实验，请记住输出类别的数量将需要改变。
- en: The first step in our algorithm for beating these CAPTCHAs involves segmenting
    the word to discover each of the letters within it. To do this, we are going to
    create a function that finds contiguous sections of black pixels in the image
    and extract them as subimages. These are (or at least should be) our letters.
    The `scikit-image` function has tools for performing these operations.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们算法中击败这些 CAPTCHA 的第一步是分割单词以发现其中的每个字母。为此，我们将创建一个函数来找到图像中连续的黑色像素区域，并将它们作为子图像提取出来。这些就是（或者至少应该是）我们的字母。`scikit-image`
    函数有执行这些操作的工具。
- en: Our function will take an image, and return a list of sub-images, where each
    sub-image is a letter from the original word in the image. The first thing we
    need to do is to detect where each letter is. To do this, we will use the label
    function in `scikit-image`, which finds connected sets of pixels that have the
    same value. This has analogies to our connected component discovery in [Chapter
    7](67684c84-b6f7-4f09-b0ce-cabe2d2c373d.xhtml)*, Follow Recommendations Using
    Graph Mining*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的函数将接受一个图像，并返回一个子图像列表，其中每个子图像是图像中原始单词的一个字母。首先，我们需要做的是检测每个字母的位置。为此，我们将使用 `scikit-image`
    中的标签函数，该函数可以找到具有相同值的像素的连通集合。这与我们在 [第 7 章](67684c84-b6f7-4f09-b0ce-cabe2d2c373d.xhtml)*使用图挖掘遵循建议*
    中的连通组件发现有相似之处。
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can then get the subimages from the example CAPTCHA using this function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用此函数从示例 CAPTCHA 中获取子图像：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can also view each of these subimages:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看这些子图像：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The result will look something like this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来可能像这样：
- en: '![](img/B06162_08_11.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_11.jpg)'
- en: As you can see, our image segmentation does a reasonable job, but the results
    are still quite messy, with bits of previous letters showing. This is fine, and
    almost preferable. While training on data with regular noise makes our training
    worse, training on data with random noise can actually make it better. One reason
    is that the underlying data mining model learns the important aspects, namely
    the non-noise parts instead of specific noise inherent in the training data set.
    It is a fine line between too much and too little noise, and this can be hard
    to properly model. Testing on validation sets is a good way to ensure your training
    is improving.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们的图像分割做得相当不错，但结果仍然相当杂乱，有前一个字母的碎片显示。这是可以接受的，甚至更可取。虽然在对具有常规噪声的数据进行训练时会使我们的训练变得更差，但使用具有随机噪声的数据进行训练实际上可以使其变得更好。一个原因是，底层的数据挖掘模型学会了重要的方面，即非噪声部分而不是训练数据集中固有的特定噪声。过多和过少的噪声之间的界限很微妙，这可能会很难正确建模。在验证集上进行测试是确保你的训练正在改进的好方法。
- en: 'One important note is that this code is not consistent in finding letters.
    Lower shear values typically result in accurately segmented images. For example,
    here is the code to segment the WOOF example from above:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的注意事项是，此代码在查找字母方面并不一致。较低的剪切值通常会导致准确分割的图像。例如，以下是分割上面 WOOF 示例的代码：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/B06162_08_15-e1493021829708.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_15-e1493021829708.png)'
- en: 'In contrast, higher shear values are not segmented properly. For example, here
    is the BARK example from before:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，较高的剪切值无法正确分割。例如，以下是之前提到的 BARK 示例：
- en: '![](img/B06162_08_16.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_16.png)'
- en: Notice the large overlap caused by the square segmentation. One suggestion for
    an improvement on this chapter's code is to improve our segmentation by finding
    non-square segments.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 注意由方形分割引起的大面积重叠。对于本章代码的一个改进建议是，通过找到非方形分割来改进我们的分割方法。
- en: Creating a training dataset
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建训练数据集
- en: Using the functions we have already defined, we can now create a dataset of
    letters, each with different shear values. From this, we will train a neural network
    to recognize each letter from the image.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们已定义的函数，我们现在可以创建一个包含不同剪切值的字母数据集。从这些数据中，我们将训练一个神经网络来识别图像中的每个字母。
- en: 'We first set up our random state and an array that holds the options for letters,
    shear values and scale values that we will randomly select from. There isn''t
    much surprise here, but if you haven''t used NumPy''s `arange` function before,
    it is similar to Python''s `range` function—except this one works with NumPy arrays
    and allows the step to be a float. The code is as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先设置随机状态和数组，该数组包含我们将随机选择的字母、剪切值和缩放值的选项。这里没有太多惊喜，但如果你之前没有使用过 NumPy 的 `arange`
    函数，它类似于 Python 的 `range` 函数——只不过这个函数可以与 NumPy 数组一起工作，并且允许步长为浮点数。代码如下：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We then create a function (for generating a single sample in our training dataset)
    that randomly selects a letter, a shear value, and a scale value selected from
    the available options.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个函数（用于生成训练数据集中的单个样本），该函数会随机选择一个字母、一个剪切值和一个从可用选项中选择的缩放值。
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We return the image of the letter, along with the target value representing
    the letter in the image. Our classes will be 0 for A, 1 for B, 2 for C, and so
    on.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们返回字母的图像，以及表示图像中字母的目标值。我们的类别将为 A 为 0，B 为 1，C 为 2，依此类推。
- en: 'Outside the function block, we can now call this code to generate a new sample
    and then show it using `pyplot`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数块外部，我们现在可以调用此代码来生成一个新的样本，然后使用 `pyplot` 展示它：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The resulting image has just a single letter, with a random shear and random
    scale value.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像只有一个字母，具有随机的剪切和缩放值。
- en: '![](img/B06162_08_17-e1493023909718.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B06162_08_17-e1493023909718.png)'
- en: 'We can now generate all of our data by calling this several thousand times.
    We then put the data into NumPy arrays, as they are easier to work with than lists.
    The code is as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过多次调用此函数来生成所有数据。然后我们将数据放入 NumPy 数组中，因为它们比列表更容易处理。代码如下：
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Our targets are integer values between 0 and 26, with each representing a letter
    of the alphabet. Neural networks don''t usually support multiple values from a
    single neuron, instead preferring to have multiple outputs, each with values 0
    or 1\. We perform one-hot-encoding of the targets, giving us a target array that
    has 26 outputs per sample, using values near 1 if that letter is likely and near
    0 otherwise. The code is as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是介于0和26之间的整数，每个代表字母表中的一个字母。神经网络通常不支持单个神经元的多值，而是更喜欢有多个输出，每个输出值为0或1。我们对目标进行one-hot编码，为每个样本生成一个有26个输出的目标数组，如果该字母可能，则使用接近1的值，否则使用接近0的值。代码如下：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: From this output, we know that our neural network's output layer will have 26
    neurons. The goal of the neural network is to determine which of these neurons
    to fire, based on a given input--the pixels that compose the image.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们知道我们的神经网络输出层将有26个神经元。神经网络的目标是根据给定的输入（构成图像的像素）确定要激活哪个神经元。
- en: 'The library we are going to use doesn''t support sparse arrays, so we need
    to turn our sparse matrix into a dense NumPy array. The code is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的库不支持稀疏数组，因此我们需要将我们的稀疏矩阵转换为密集的NumPy数组。代码如下：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we perform a train/test split to later evaluate our data:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行训练/测试数据集的划分，以便稍后评估我们的数据：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Training and classifying
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和分类
- en: We are now going to build a neural network that will take an image as input
    and try to predict which (single) letter is in the image.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将构建一个神经网络，它将接受图像作为输入并尝试预测图像中包含的是哪个（单个）字母。
- en: We will use the training set of single letters we created earlier. The dataset
    itself is quite simple. We have a 20-by-20-pixel image, each pixel 1 (black) or
    0 (white). These represent the 400 features that we will use as inputs into the
    neural network. The outputs will be 26 values between 0 and 1, where higher values
    indicate a higher likelihood that the associated letter (the first neuron is A,
    the second is B, and so on) is the letter represented by the input image.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们之前创建的单个字母的训练集。数据集本身相当简单。我们有一个20x20像素的图像，每个像素为1（黑色）或0（白色）。这些代表我们将用作神经网络输入的400个特征。输出将是介于0和1之间的26个值，其中较高的值表示关联字母（第一个神经元是A，第二个是B，以此类推）是输入图像所代表的字母的可能性更高。
- en: We are going to use the scikit-learn's `MLPClassifier` for our neural network
    in this chapter.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用scikit-learn的`MLPClassifier`作为我们的神经网络。
- en: 'You will need a recent version of `scikit-learn` to use MLPClassifier. If the
    below import statement fails, try again after updating scikit-learn. You can do
    this using the following Anaconda command:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要`scikit-learn`的较新版本才能使用MLPClassifier。如果下面的导入语句失败，请在更新scikit-learn后重试。您可以使用以下Anaconda命令来完成此操作：
- en: '`conda update scikit-learn`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`conda update scikit-learn`'
- en: 'As for other `scikit-learn` classifiers, we import the model type and create
    a new one. The constructor below specifies that we create one hidden layer with
    100 nodes in it. The size of the input and output layers is determined at training
    time:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他`scikit-learn`分类器，我们导入模型类型并创建一个新的模型。下面的构造函数指定我们创建一个包含100个节点的隐藏层。输入层和输出层的大小在训练时确定：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To see the internal parameters of the neural network, we can use the `get_params()`
    function. This function exists on all `scikit-learn` models. Here is the output
    from the above model. Many of these parameters can improve training or the speed
    of training. For example, increasing the learning rate will train the model faster,
    at the risk of missing optimal values:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看神经网络的内部参数，我们可以使用`get_params()`函数。这个函数存在于所有的`scikit-learn`模型中。以下是上述模型的输出。许多这些参数可以提高训练或训练速度。例如，增加学习率可以使模型训练得更快，但可能会错过最佳值：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we fit our model using the standard scikit-learn interface:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用标准的scikit-learn接口来拟合我们的模型：
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Our model has now learned weights between each of the layers. We can view those
    weights by examining `clf.coefs_`, which is a list of NumPy arrays that join each
    of the layers. For example, the weights between the input layer with 400 neurons
    (from each of our pixels) to the hidden layer with 100 neurons (a parameter we
    set), can be obtained using `clf.coefs_[0]`. In addition, the weights between
    the hidden layer and the output layer (with 26 neurons) can be obtained using
    `clf.coefs_[1]`. These weights, together with the parameters above, wholly define
    our trained network.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网络现在已经学会了每一层之间的权重。我们可以通过检查`clf.coefs_`来查看这些权重，它是一个连接每一层的NumPy数组的列表。例如，从包含400个神经元（来自我们每个像素）的输入层到包含100个神经元（我们设置的参数）的隐藏层的权重可以通过`clf.coefs_[0]`获得。此外，隐藏层和输出层（包含26个神经元）之间的权重可以通过`clf.coefs_[1]`获得。这些权重，连同上面的参数，完全定义了我们的训练网络。
- en: 'We can now use that trained network to predict our test dataset:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这个训练好的网络来预测我们的测试数据集：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we evaluate the results:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们评估结果：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The result is 0.96, which is pretty impressive. This version of the F1 score
    is based on the macro-average, which computes the individual F1 score for each
    class, and then averages them without considering the size of each class.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是0.96，这相当令人印象深刻。这个版本的F1分数是基于宏平均，它计算每个类的个体F1分数，然后不考虑每个类的大小进行平均。
- en: 'To examine these individual class results, we can view the classification report:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这些个体类别的结果，我们可以查看分类报告：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The results from my experiment are shown here:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我实验的结果如下所示：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The final `f1-score` for this report is shown on the bottom right, the second
    last number - 0.99\. This is the micro-average, where the `f1-score` is computed
    for each sample and then the mean is computed. This form makes more sense for
    relatively similar class sizes, while the macro-average makes more sense for imbalanced
    classes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本报告的最终`f1-score`显示在右下角，倒数第二个数字——0.99。这是微观平均，其中对每个样本计算`f1-score`，然后计算平均值。这种形式对于相对相似的类别大小更有意义，而宏平均对于不平衡的类别更有意义。
- en: Pretty simple from an API perspective, as `scikit-learn` hides all of the complexity.
    However what actually happened in the backend? How do we train a neural network?
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从API的角度来看，这很简单，因为`scikit-learn`隐藏了所有的复杂性。然而，在后台实际上发生了什么？我们如何训练一个神经网络？
- en: Back-propagation
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播
- en: Training a neural network is specifically focused on the following things.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络特别关注以下事项。
- en: The first is the size and shape of the network - how many layers, what sized
    layers and what error functions they use. While types of neural networks exists
    that can alter their size and shape, the most common type, a feed-forward neural
    network, rarely has this capability. Instead, its size is fixed at initialization
    time, which in this chapter is 400 neurons in the first layer, 100 in the hidden
    layer and 26 in the final layer. Training for the shape is usually the job of
    a meta-algorithm that trains a set of neural networks and determines which is
    the most effective, outside of training the networks themselves.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一是网络的大小和形状——有多少层，层的大小以及它们使用的错误函数。虽然存在可以改变其大小和形状的神经网络类型，但最常见的类型，前馈神经网络，很少具有这种能力。相反，其大小在初始化时固定，在本章中是第一层400个神经元，隐藏层100个，最终层26个。通常，形状的训练是元算法的工作，它训练一组神经网络并确定哪个是最有效的，而不仅仅是训练网络本身。
- en: The second part of training a neural network is to alter the weights between
    neurons. In a standard neural network, nodes from one layer are attached to nodes
    of the next layer by edges with a specific weight. These can be initialized randomly
    (although several smarter methods do exist such as autoencoders), but need to
    be adjusted to allow the network to *learn* the relationship between training
    samples and training classes.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练神经网络的第二部分是改变神经元之间的权重。在一个标准的神经网络中，一个层的节点通过具有特定权重的边连接到下一层的节点。这些可以随机初始化（尽管存在一些更智能的方法，如自动编码器），但需要调整以允许网络*学习*训练样本和训练类别之间的关系。
- en: This adjusting of weights was one of the key issues holding back very-early
    neural networks, before an algorithm called **back propagation** was developed
    to solve the issue.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这种调整权重是早期神经网络面临的一个关键问题，在开发出称为**反向传播**的算法来解决该问题之前。
- en: The **back propagation** (**backprop**) algorithm is a way of assigning blame
    to each neuron for incorrect predictions. First, we consider the usage of a neural
    network, where we feed a sample into the input layer and see which of the output
    layer's neurons fire, as *forward propagation*. Back propagation goes backwards
    from the output layer to the input layer, assigning blame to each weight in the
    network, in proportion to the effect that weight has on any errors that the network
    makes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'The amount of change is based on two aspects:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Neuron activation
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The gradient of the activation function
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first is the degree to which the neuron was *activated*. Neurons that fire
    with high (absolute) values are considered to have a great impact on the result,
    while those that fired with small (absolute) values have a low impact on the result.
    Due to this, weights around neurons that fire with high values are changed more
    than those around small values.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The second aspect to the amount that weights change is proportional to the *gradient
    of the activation function*. Many neural networks you use will have the same activation
    function for all neurons, but there are lots of situations where it makes sense
    to have different activation functions for different layers of neurons (or more
    rarely, different activation functions in the same layer). The gradient of the
    activation function, combined with the activation of the neuron, and the error
    assigned to that neuron, together form the amount that the weights are changed.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: I've skipped over the maths involved in back propagation, as the focus of this
    book is on practical usage. As you increase your usage of neural networks, it
    pays to know more about what goes on inside the algorithm. I recommend looking
    into the details of the back-prop algorithm, which can be understood with some
    basic knowledge of gradients and derivatives.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Predicting words
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have a classifier for predicting individual letters, we now move
    onto the next step in our plan - predicting words. To do this, we want to predict
    each letter from each of these segments, and put those predictions together to
    form the predicted word from a given CAPTCHA.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'Our function will accept a CAPTCHA and the trained neural network, and it will
    return the predicted word:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can now test on a word using the following code. Try different words and
    see what sorts of errors you get, but keep in mind that our neural network only
    knows about capital letters:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can codify this into a function, allowing us to perform predictions more
    easily:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The returned results specify whether the prediction is correct, the original
    word, and the predicted word. This code correctly predicts the word GENE, but
    makes mistakes with other words. How accurate is it? To test, we will create a
    dataset with a whole bunch of four-letter English words from NLTK. The code is
    as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Install NLTK using Anaconda: conda install nltk'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'After installation, and before using it in code, you will need to download
    the corpus using:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: python -c "import nltk; nltk.download('words')"
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'The words instance here is actually a corpus object, so we need to call `words()`
    on it to extract the individual words from this corpus. We also filter to get
    only four-letter words from this list:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can then iterate over all of the words to see how many we get correct by
    simply counting the correct and incorrect predictions:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The results I get are 3,342 correct and 2,170 incorrect for an accuracy of just
    over 62 percent. From our original 99 percent per-letter accuracy, this is a big
    decline. What happened?
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'The reasons for this decline are listed here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The first factor to impact is our accuracy. All other things being equal, if
    we have four letters, and 99 percent accuracy per-letter, then we can expect about
    a 96 percent success rate (all other things being equal) getting four letters
    in a row (0.99⁴&ap;0.96). A single error in a single letter's prediction results
    in the wrong word being predicted.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second impact is the shear value. Our dataset chose randomly between shear
    values of 0 to 0.5\. The previous test used a shear of 0.2\. For a value of 0,
    I get 75 percent accuracy; for a shear of 0.5, the result is much worse at 2.5
    percent. The higher the shear, the lower the performance.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third impact is that often words are incorrectly segmented. Another issue
    is that some vowels are commonly mistaken, causing more errors than can be expected
    by the above error rates.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s examine the second of these issues, and map the relationship between
    shear and performance. First, we turn our evaluation code into a function that
    is dependent on a given shear value:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Then, we take a list of shear values and then use this function to evaluate
    the accuracy for each value. Note that this code will take a while to run, approximately
    30 minutes depending on your hardware.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, plot the result using matplotlib:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](img/B06162_08_18-1.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: You can see that there is a severe drop in performance as the shear value increases
    past 0.4\. Normalizing the input would help, with tasks such as image rotation
    and unshearing the input.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Another surprising option to address issues with shear is to increase the amount
    of training data with high shear values, which can lead to the model learning
    a more generalized output.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: We look into improving the accuracy using post-processing in the next section.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Improving accuracy using a dictionary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rather than just returning the given prediction, we can check whether the word
    actually exists in our dictionary. If it does, then that is our prediction. If
    it isn't in the dictionary, we can try and find a word that is similar to it and
    predict that instead. Note that this strategy relies on our assumption that all
    CAPTCHA words will be valid English words, and therefore this strategy wouldn't
    work for a random sequence of characters. This is one reason why some CAPTCHAs
    don't use words.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: There is one issue here—how do we determine the closest word? There are many
    ways to do this. For instance, we can compare the lengths of words. Two words
    that have a similar length could be considered more similar. However, we commonly
    consider words to be similar if they have the same letters in the same positions.
    This is where the **edit distance** comes in.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Ranking mechanisms for word similarity
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Levenshtein edit distance** is a commonly used method for comparing two
    short strings to see how similar they are. It isn''t very scalable, so it isn''t
    commonly used for very long strings. The edit distance computes the number of
    steps it takes to go from one word to another. The steps can be one of the following
    three actions:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Insert a new letter into the word at any position
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delete any letter from the word
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Substitute a letter for another one
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum number of actions needed to transform the first word into the second
    is given as the distance. Higher values indicate that the words are less similar.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'This distance is available in NLTK as `nltk.metrics.edit_distance`. We can
    call it using only two strings and it returns the edit distance:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: When used with different words, the edit distance is quite a good approximation
    to what many people would intuitively feel are similar words. The edit distance
    is great for testing spelling mistakes, dictation errors, and name matching (where
    you can mix up your Marc and Mark spelling quite easily).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it isn''t very good for our case. We don''t really expect letters
    to be moved around, just individual letter comparisons to be wrong. For this reason,
    we will create a different distance metric, which is simply the number of letters
    in the same positions that are incorrect. The code is as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We subtract the value from the length of the prediction word (which is four)
    to make it a distance metric where lower values indicate more similarity between
    the words.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now test our improved prediction function using similar code to before.
    First, we define a prediction function, which also takes our list of valid words:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We compute the distance between our predicted word and each other word in the dictionary,
    and sort it by distance (lowest first). The changes in our testing code are in
    the following code:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The preceding code will take a while to run (computing all of the distances
    will take some time) but the net result is 3,037 samples correct and 2,476 samples
    incorrect. This is an accuracy of 71.5 percent for a boost of nearly 10 percentage
    points!
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Looking for a challenge? Update the `predict_captcha` function to return the
    probabilities assigned to each letter. By default, the letter with the highest
    probability is chosen for each letter in a word. If that doesn't work, choose
    the next most probable word, by multiplying the per-letter probabilities together.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we worked with images in order to use simple pixel values to
    predict the letter being portrayed in a CAPTCHA. Our CAPTCHAs were a bit simplified;
    we only used complete four-letter English words. In practice, the problem is much
    harder--as it should be! With some improvements, it would be possible to solve
    much harder CAPTCHAs with neural networks and a methodology similar to what we
    discussed. The `scikit-image` library contains lots of useful functions for extracting
    shapes from images, functions for improving contrast, and other image tools that
    will help.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: We took our larger problem of predicting words, and created a smaller and simple
    problem of predicting letters. From here, we were able to create a feed-forward
    neural network to accurately predict which letter was in the image. At this stage,
    our results were very good with 97 percent accuracy.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are simply connected sets of neurons, which are basic computation
    devices consisting of a single function. However, when you connect these together,
    they can solve incredibly complex problems. Neural networks are the basis for
    deep learning, which is one of the most effective areas of data mining at the
    moment.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Despite our great per-letter accuracy, the performance when predicting a word
    drops to just over 60 percent when trying to predict a whole word. We improved
    our accuracy using a dictionary, searching for the best matching word. To do this,
    we considered the commonly used edit distance; however, we simplified it because
    we were only concerned with individual mistakes on letters, not insertions or
    deletions. This improvement netted some benefit, but there are still many improvements
    you could try to further boost the accuracy.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: To take the concepts in this chapter further, investigate changing the neural
    network structure, by adding more hidden layers, or changing the shape of those
    layers. Investigate the impact this has on the result. Further, try creating a
    more difficult CAPTCHA--does this drop the accuracy? Can you build a more complicated
    network to learn it?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Data mining problems such as the CAPTCHA example show that an initial problem
    statement, such as *guess this word*, can be broken into individual subtasks that
    can be performed using data mining. Further, those subtasks can be combined in
    a few different ways, such as with the use of external information. In this chapter,
    we combined our letter prediction with a dictionary of valid words to provide
    a final response, giving better accuracy than letter prediction alone.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue with string comparisons. We will attempt
    to determine which author (out of a set of authors) wrote a particular document--using
    only the content and no other information!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
