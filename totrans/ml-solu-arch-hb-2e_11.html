<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer179">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">11</span></h1>
<h1 class="chapterTitle" id="_idParaDest-301"><span class="koboSpan" id="kobo.2.1">Building ML Solutions with AWS AI Services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">Up to this point, we have mainly focused on the skills and technologies required to build and deploy ML models using open-source technologies and managed ML platforms. </span><span class="koboSpan" id="kobo.3.2">To solve business problems with ML, however, you don’t always have to build, train, and deploy your ML models from scratch. </span><span class="koboSpan" id="kobo.3.3">An alternative option is to use fully managed AI services. </span><span class="koboSpan" id="kobo.3.4">AI services are fully managed APIs or applications with pre-trained models that perform specific ML tasks, such as object detection or sentiment analysis. </span><span class="koboSpan" id="kobo.3.5">Some AI services also allow you to train custom models with your data for a defined ML task, such as document classification. </span><span class="koboSpan" id="kobo.3.6">AI services promise to enable organizations to build ML-enabled solutions without requiring strong ML competencies.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">In this chapter, we are going to switch gears and talk about several AWS AI services and where they can be used in business applications. </span><span class="koboSpan" id="kobo.4.2">Please note that the focus of this chapter will not be to deep dive into individual AI services, as that warrants dedicated books. </span><span class="koboSpan" id="kobo.4.3">Instead, we will focus on ML use cases that can be powered by AI services, and the architecture patterns that you can use to deploy these AI services. </span><span class="koboSpan" id="kobo.4.4">After reading this chapter, you should be able to identify some use cases where AI services can be a good fit and know where to find additional resources to get a deeper understanding of these services. </span><span class="koboSpan" id="kobo.4.5">Specifically, we are going to cover the following topics:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.5.1">What are AI services?</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.6.1">Overview of AWS AI services</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.7.1">Building intelligent solutions using AI services</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.8.1">Designing an MLOps architecture for AI services</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.9.1">Hands-on lab – running ML tasks with AI services</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-302"><span class="koboSpan" id="kobo.10.1">Technical requirements</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.11.1">You will continue to use our AWS environment for the hands-on portion of this book. </span><span class="koboSpan" id="kobo.11.2">The associated code samples can be found at </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter11"><span class="url"><span class="koboSpan" id="kobo.12.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/tree/main/Chapter11</span></span></a></p>
<h1 class="heading-1" id="_idParaDest-303"><span class="koboSpan" id="kobo.13.1">What are AI services?</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.14.1">AI services </span><a id="_idIndexMarker1137"/><span class="koboSpan" id="kobo.15.1">are pre-built fully managed services that perform a particular set of ML tasks out of the box, such as facial analysis or text analysis. </span><span class="koboSpan" id="kobo.15.2">The primary target users for AI services are application developers who want to build AI applications without the need to build ML models from scratch. </span><span class="koboSpan" id="kobo.15.3">In contrast, the target audiences for ML platforms are data scientists and ML engineers, who need to go through the full ML lifecycle to build and deploy ML models.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.16.1">For an organization, AI services </span><a id="_idIndexMarker1138"/><span class="koboSpan" id="kobo.17.1">mainly solve the following key challenges:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.18.1">Lack of high-quality training data for ML model development</span></strong><span class="koboSpan" id="kobo.19.1">: To train high-quality models, you need a large amount of high-quality curated data. </span><span class="koboSpan" id="kobo.19.2">For many organizations, data poses many challenges in data sourcing, data engineering, and data labeling.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.20.1">Lack of data science skills for building and deploying custom ML models</span></strong><span class="koboSpan" id="kobo.21.1">: Data science and ML engineering skills are scarce in the market and expensive to acquire.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.22.1">Slow product time-to-market</span></strong><span class="koboSpan" id="kobo.23.1">: Building and deploying custom models and engineering infrastructure is time-consuming. </span><span class="koboSpan" id="kobo.23.2">This can be a hurdle for a quick time-to-market product delivery goal.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.24.1">Undifferentiated ML capabilities</span></strong><span class="koboSpan" id="kobo.25.1">: Many ML problems can be solved using commodity ML capabilities that do not provide unique competitive advantages. </span><span class="koboSpan" id="kobo.25.2">Spending resources on building undifferentiated ML capabilities can be a waste of scarce resources.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.26.1">System scalability challenge</span></strong><span class="koboSpan" id="kobo.27.1">: Managing scalable infrastructure to meet dynamic market demands and growth is an engineering challenge.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.28.1">While AI services can provide a cost-effective way of building ML-enabled products quickly, they do come with limitations. </span><span class="koboSpan" id="kobo.28.2">The main limitation is the lack of customization flexibility for specific </span><a id="_idIndexMarker1139"/><span class="koboSpan" id="kobo.29.1">functional and technical requirements. </span><span class="koboSpan" id="kobo.29.2">AI services usually focus on specific ML tasks with a predefined set of algorithms, so you usually don’t have the flexibility to alter the functionality of AI services. </span><span class="koboSpan" id="kobo.29.3">With AI services, you normally do not have access to the underlying models, thus limiting your ability to deploy the model elsewhere.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.30.1">The number of offerings in AI services has grown extensively in recent years, and we expect this trend to continue at an accelerated pace. </span><span class="koboSpan" id="kobo.30.2">Let’s shift our focus and talk about several AWS AI services.</span></p>
<h1 class="heading-1" id="_idParaDest-304"><span class="koboSpan" id="kobo.31.1">Overview of AWS AI services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.32.1">AWS </span><a id="_idIndexMarker1140"/><span class="koboSpan" id="kobo.33.1">provides AI services in multiple ML domains, such as text and vision, as well as AI services for industrial use cases such as manufacturing anomaly detection and predictive maintenance. </span><span class="koboSpan" id="kobo.33.2">In this section, we will cover a subset of AWS AI services. </span><span class="koboSpan" id="kobo.33.3">The objective of this section will not be to deep dive into individual services but rather to make you aware of the fundamental capabilities offered by these AI services. </span><span class="koboSpan" id="kobo.33.4">This will let you know where and how these services can be integrated into your applications.</span></p>
<h2 class="heading-2" id="_idParaDest-305"><span class="koboSpan" id="kobo.34.1">Amazon Comprehend</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.35.1">NLP has </span><a id="_idIndexMarker1141"/><span class="koboSpan" id="kobo.36.1">gained significant interest across different industries in solving a range of business problems, such as automatic document processing, text summarization, document understanding, and document management and retrieval. </span><strong class="keyWord"><span class="koboSpan" id="kobo.37.1">Amazon Comprehend</span></strong><span class="koboSpan" id="kobo.38.1"> is an AI service that can perform NLP analysis on </span><a id="_idIndexMarker1142"/><span class="koboSpan" id="kobo.39.1">unstructured text documents. </span><span class="koboSpan" id="kobo.39.2">At its core, Amazon Comprehend </span><a id="_idIndexMarker1143"/><span class="koboSpan" id="kobo.40.1">provides the following main capabilities:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.41.1">Entity recognition</span></strong><span class="koboSpan" id="kobo.42.1">: Entities are the who, what, where, and when of text analytics. </span><span class="koboSpan" id="kobo.42.2">Entities can be the most important parts of a sentence as they identify the key components in a text. </span><span class="koboSpan" id="kobo.42.3">Examples of entities are proper nouns such as a person, place, or product. </span><span class="koboSpan" id="kobo.42.4">Entities can be used to create document search indexes and identify key information or relationships across documents. </span><span class="koboSpan" id="kobo.42.5">Comprehend provides APIs (for example, </span><code class="inlineCode"><span class="koboSpan" id="kobo.43.1">DetectEntities</span></code><span class="koboSpan" id="kobo.44.1">) for detecting entities with its built-in entity recognition models. </span><span class="koboSpan" id="kobo.44.2">It can detect entities such as people, places, organizations, and dates from the input text. </span><span class="koboSpan" id="kobo.44.3">You can also use Comprehend to train a custom entity recognizer for your custom entities if the built-in models do not meet your requirements. </span><span class="koboSpan" id="kobo.44.4">To train a </span><a id="_idIndexMarker1144"/><span class="koboSpan" id="kobo.45.1">custom entity recognizer, you can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.46.1">CreateEntityRecognizer</span></code><span class="koboSpan" id="kobo.47.1"> API with your training data in the </span><a id="_idIndexMarker1145"/><span class="koboSpan" id="kobo.48.1">following two formats:</span><ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.49.1">Annotation</span></strong><span class="koboSpan" id="kobo.50.1">: You provide the locations of entities (beginning and end offsets of target characters) in documents, along with the entity type for each pair of offsets. </span><span class="koboSpan" id="kobo.50.2">This helps Comprehend train on both the entities and the context they are in.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.51.1">Entity list</span></strong><span class="koboSpan" id="kobo.52.1">: You provide a list of entities and their entity types in plaintext and Comprehend will train to detect these specific entities. </span><span class="koboSpan" id="kobo.52.2">You can evaluate the custom model using the metrics emitted by a Comprehend custom model training job. </span><span class="koboSpan" id="kobo.52.3">Example evaluation metrics include precision, recall, and F1 scores. </span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.53.1">Additional details on the evaluation metrics for Comprehend can be found at </span><a href="https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html"><span class="url"><span class="koboSpan" id="kobo.54.1">https://docs.aws.amazon.com/comprehend/latest/dg/cer-metrics.html</span></span></a><span class="koboSpan" id="kobo.55.1">. </span><span class="koboSpan" id="kobo.55.2">Once the model has been trained, you have the option to deploy the model behind a private prediction endpoint to serve predictions.</span></p>
</li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.56.1">Sentiment analysis</span></strong><span class="koboSpan" id="kobo.57.1">: Comprehend can detect sentiment in text with its </span><code class="inlineCode"><span class="koboSpan" id="kobo.58.1">DetectSentiment</span></code><span class="koboSpan" id="kobo.59.1"> API. </span><span class="koboSpan" id="kobo.59.2">Sentiment analysis is widely used in many business use cases, such as analyzing customers’ sentiments in customer support calls or understanding customers’ perceptions of products and services in reviews.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.60.1">Topic modeling</span></strong><span class="koboSpan" id="kobo.61.1">: Topic modeling has a wide range of uses, including document understanding, document categorization and organization, information retrieval, and content recommendation. </span><span class="koboSpan" id="kobo.61.2">Comprehend can discover common topics among documents with its </span><code class="inlineCode"><span class="koboSpan" id="kobo.62.1">StartTopicsDetectionJob</span></code><span class="koboSpan" id="kobo.63.1"> API.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.64.1">Language detection</span></strong><span class="koboSpan" id="kobo.65.1">: Comprehend can detect the dominant language that’s used in the text with its </span><code class="inlineCode"><span class="koboSpan" id="kobo.66.1">DetectDominantLanguage</span></code><span class="koboSpan" id="kobo.67.1"> API. </span><span class="koboSpan" id="kobo.67.2">This feature can help with use cases such as routing incoming customer support calls to the right channel based on the language or classifying documents by different languages.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.68.1">Syntax analysis</span></strong><span class="koboSpan" id="kobo.69.1">: Comprehend can </span><a id="_idIndexMarker1146"/><span class="koboSpan" id="kobo.70.1">perform </span><strong class="keyWord"><span class="koboSpan" id="kobo.71.1">part-of-speech</span></strong><span class="koboSpan" id="kobo.72.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.73.1">POS</span></strong><span class="koboSpan" id="kobo.74.1">) analysis of sentences using its </span><code class="inlineCode"><span class="koboSpan" id="kobo.75.1">DetectSyntax</span></code><span class="koboSpan" id="kobo.76.1"> API. </span><span class="koboSpan" id="kobo.76.2">Example POSes include nouns, pronouns, verbs, adverbs, conjunctions, and adjectives in a sentence. </span><span class="koboSpan" id="kobo.76.3">POS analysis can help with use cases such as checking for the correctness of syntax and grammar in written text.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.77.1">Event detection</span></strong><span class="koboSpan" id="kobo.78.1">: Comprehend</span><a id="_idIndexMarker1147"/><span class="koboSpan" id="kobo.79.1"> can detect a predefined list of financial events such as IPO, stock split, and bankruptcy. </span><span class="koboSpan" id="kobo.79.2">It also detects augments associated with events such as a person or company filing for bankruptcy. </span><span class="koboSpan" id="kobo.79.3">This relationship helps build a knowledge graph to help us understand the who-did-what of the different events. </span><span class="koboSpan" id="kobo.79.4">You can find a full list of event and augment types at </span><a href="https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html"><span class="url"><span class="koboSpan" id="kobo.80.1">https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html</span></span></a><span class="koboSpan" id="kobo.81.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.82.1">Text classification</span></strong><span class="koboSpan" id="kobo.83.1">: You can train a custom text classifier using your training data with Comprehend. </span><span class="koboSpan" id="kobo.83.2">Comprehend lets you train multi-class and multi-label classifiers through its </span><code class="inlineCode"><span class="koboSpan" id="kobo.84.1">CreateDocumentClassifier</span></code><span class="koboSpan" id="kobo.85.1"> API. </span><span class="koboSpan" id="kobo.85.2">Multi-class assigns a single label to a text, whereas multi-label assigns multiple labels to a text. </span><span class="koboSpan" id="kobo.85.3">To evaluate the performance of the custom classifier, Comprehend provides a list of metrics that include accuracy, recall, and F1 score. </span><span class="koboSpan" id="kobo.85.4">You can find the full list of metrics at </span><a href="https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html"><span class="url"><span class="koboSpan" id="kobo.86.1">https://docs.aws.amazon.com/comprehend/latest/dg/cer-doc-class.html</span></span></a><span class="koboSpan" id="kobo.87.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.88.1">Personally identifiable information (PII) detection</span></strong><span class="koboSpan" id="kobo.89.1">: You can detect PII within English </span><a id="_idIndexMarker1148"/><span class="koboSpan" id="kobo.90.1">or Spanish text documents. </span><span class="koboSpan" id="kobo.90.2">The PII detection process offers the option to either locate or redact PII entities within the text. </span><span class="koboSpan" id="kobo.90.3">For locating PII entities, real-time analysis or asynchronous batch jobs can be employed. </span><span class="koboSpan" id="kobo.90.4">On the other hand, redacting PII entities specifically requires the use of an asynchronous batch job.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.91.1">Key phrase detection</span></strong><span class="koboSpan" id="kobo.92.1">: The Key Phrases functionality in Amazon Comprehend uses ML models to analyze the input text and extract the most significant phrases or topics. </span><span class="koboSpan" id="kobo.92.2">These key phrases can provide a concise summary or highlight the main ideas and concepts present in the text.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.93.1">Flywheels are a feature of Comprehend that provides a managed workflow for continuously improving a custom natural language processing model. </span><span class="koboSpan" id="kobo.93.2">A flywheel stores all model data and versions in an AWS-managed data lake. </span><span class="koboSpan" id="kobo.93.3">As new labeled datasets become available, you create flywheel iterations to retrain and evaluate new model versions using the latest data. </span><span class="koboSpan" id="kobo.93.4">Based on performance metrics, the best new version can be promoted</span><a id="_idIndexMarker1149"/><span class="koboSpan" id="kobo.94.1"> to become the active model serving inferences. </span><span class="koboSpan" id="kobo.94.2">This iterative process allows the model </span><a id="_idIndexMarker1150"/><span class="koboSpan" id="kobo.95.1">accuracy to improve over time as regular model retraining incorporates fresh data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.96.1">Comprehend APIs can be invoked using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.97.1">boto3</span></code><span class="koboSpan" id="kobo.98.1"> library </span><a id="_idIndexMarker1151"/><span class="koboSpan" id="kobo.99.1">and AWS </span><strong class="keyWord"><span class="koboSpan" id="kobo.100.1">command-line interface</span></strong><span class="koboSpan" id="kobo.101.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.102.1">CLI</span></strong><span class="koboSpan" id="kobo.103.1">). </span><span class="koboSpan" id="kobo.103.2">You can find a full list of supported </span><code class="inlineCode"><span class="koboSpan" id="kobo.104.1">boto3</span></code><span class="koboSpan" id="kobo.105.1"> methods for Comprehend at </span><a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html"><span class="url"><span class="koboSpan" id="kobo.106.1">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html</span></span></a><span class="koboSpan" id="kobo.107.1">. </span><span class="koboSpan" id="kobo.107.2">The following shows the Python syntax for invoking Comprehend’s entity detection functionality:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.108.1">import</span></span><span class="koboSpan" id="kobo.109.1"> boto3
client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.110.1">'comprehend'</span></span><span class="koboSpan" id="kobo.111.1">)
response = client.detect_entities(Text=</span><span class="hljs-string"><span class="koboSpan" id="kobo.112.1">'&lt;input text&gt;'</span></span><span class="koboSpan" id="kobo.113.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.114.1">Amazon Comprehend can be a good fit for building intelligent document processing solutions and other NLP products. </span><span class="koboSpan" id="kobo.114.2">It can also serve as a good baseline tool that can be compared with custom NLP models.</span></p>
<h2 class="heading-2" id="_idParaDest-306"><span class="koboSpan" id="kobo.115.1">Amazon Textract</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.116.1">Many business</span><a id="_idIndexMarker1152"/><span class="koboSpan" id="kobo.117.1"> processes, such as loan application </span><a id="_idIndexMarker1153"/><span class="koboSpan" id="kobo.118.1">processing, expense processing, and medical claim processing, require extracting text and numbers from images and documents. </span><span class="koboSpan" id="kobo.118.2">Currently, many organizations largely handle these processes manually and the processes can be highly time-consuming and slow.</span></p>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.119.1">Amazon Textract</span></strong><span class="koboSpan" id="kobo.120.1"> is </span><a id="_idIndexMarker1154"/><span class="koboSpan" id="kobo.121.1">an </span><strong class="keyWord"><span class="koboSpan" id="kobo.122.1">optical character recognition</span></strong><span class="koboSpan" id="kobo.123.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.124.1">OCR</span></strong><span class="koboSpan" id="kobo.125.1">) AI service that’s primarily used for extracting printed text, handwritten text, and numbers from images and PDF documents. </span><span class="koboSpan" id="kobo.125.2">Textract is normally used as a processing step for downstream tasks such as document analysis and data entries. </span><span class="koboSpan" id="kobo.125.3">The core</span><a id="_idIndexMarker1155"/><span class="koboSpan" id="kobo.126.1"> Textract functionalities are as follows:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.127.1">OCR</span></strong><span class="koboSpan" id="kobo.128.1">: OCR is a computer vision task that detects and extracts text data from PDF documents and images. </span><span class="koboSpan" id="kobo.128.2">The OCR component in Textract extracts raw text from the input documents and provides additional structural information about the documents. </span><span class="koboSpan" id="kobo.128.3">For example, the Textract output contains hierarchical structural relationships for the different objects in a document such as pages, paragraphs, sentences, and words. </span><span class="koboSpan" id="kobo.128.4">Textract also captures the positional information of the different objects in the input document. </span><span class="koboSpan" id="kobo.128.5">The hierarchical structural information and object positional data are </span><a id="_idIndexMarker1156"/><span class="koboSpan" id="kobo.129.1">useful when you’re extracting specific information from different locations in the documents. </span><span class="koboSpan" id="kobo.129.2">The OCR APIs are </span><code class="inlineCode"><span class="koboSpan" id="kobo.130.1">DetectDocumentText</span></code><span class="koboSpan" id="kobo.131.1"> for detecting text synchronously and </span><code class="inlineCode"><span class="koboSpan" id="kobo.132.1">StartDocumentTextDetection</span></code><span class="koboSpan" id="kobo.133.1"> for detecting text asynchronously.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.134.1">Table extraction</span></strong><span class="koboSpan" id="kobo.135.1">: Many documents contain tabular data structures and need to be processed as a table. </span><span class="koboSpan" id="kobo.135.2">For example, you might have an insurance claim document that contains a list of claim items and their details in different columns, and you may want to enter these claim items into a system. </span><span class="koboSpan" id="kobo.135.3">The </span><a id="_idIndexMarker1157"/><span class="koboSpan" id="kobo.136.1">table extraction component in Textract can extract tables and cells in the tables from a document. </span><span class="koboSpan" id="kobo.136.2">To use the table extraction feature, you can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.137.1">AnalyzeDocument</span></code><span class="koboSpan" id="kobo.138.1"> API for synchronous operations and </span><code class="inlineCode"><span class="koboSpan" id="kobo.139.1">StartDocumentAnalysis</span></code><span class="koboSpan" id="kobo.140.1"> for asynchronous operations.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.141.1">Form extraction</span></strong><span class="koboSpan" id="kobo.142.1">: Documents such as paystubs and loan application forms contain many name-value pairs whose relationships need to be preserved when they’re processed automatically. </span><span class="koboSpan" id="kobo.142.2">The form extraction component in Textract can detect these name-value pairs and their relationships for downstream processing, such as entering the names in those documents into a system. </span><span class="koboSpan" id="kobo.142.3">The form extraction component shares the same </span><code class="inlineCode"><span class="koboSpan" id="kobo.143.1">AnalyzeDocument</span></code><span class="koboSpan" id="kobo.144.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.145.1">StartDocumentAnalysis</span></code><span class="koboSpan" id="kobo.146.1"> APIs as the table extraction component.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.147.1">Signature in document analysis</span></strong><span class="koboSpan" id="kobo.148.1">: Textract can detect signature locations in documents, returning bounding boxes specifying signature positions and confidence scores. </span><span class="koboSpan" id="kobo.148.2">Signature detection can run independently or alongside other features like forms, tables, and custom queries. </span><span class="koboSpan" id="kobo.148.3">When combined with forms or tables, Textract relates detected signatures to corresponding cells or key-value pairs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.149.1">Queries in document analysis:</span></strong><span class="koboSpan" id="kobo.150.1"> Textract allows adding custom queries to extract specific information from documents. </span><span class="koboSpan" id="kobo.150.2">A query like “What is the applicant’s address?” </span><span class="koboSpan" id="kobo.150.3">will return just that data point from the analyzed document in a separate response structure.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.151.1">Textract also has features for analyzing a specific kind of documents such as invoices and identity documents. </span><span class="koboSpan" id="kobo.151.2">For example, Textract can extract relevant data such as vendor and receiver </span><a id="_idIndexMarker1158"/><span class="koboSpan" id="kobo.152.1">contact information from an invoice or receipt without the need for any templates or configuration. </span><span class="koboSpan" id="kobo.152.2">Similarly, it can extract relevant information from passports, driver’s licenses, and other identity documentation issued by the US Government.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.153.1">The Textract APIs are </span><a id="_idIndexMarker1159"/><span class="koboSpan" id="kobo.154.1">supported in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.155.1">boto3</span></code><span class="koboSpan" id="kobo.156.1"> library. </span><span class="koboSpan" id="kobo.156.2">The following code sample shows how to detect text using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.157.1">boto3</span></code><span class="koboSpan" id="kobo.158.1"> library. </span><span class="koboSpan" id="kobo.158.2">The full list of Textract APIs for </span><code class="inlineCode"><span class="koboSpan" id="kobo.159.1">boto3</span></code><span class="koboSpan" id="kobo.160.1"> can be found at </span><a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html"><span class="url"><span class="koboSpan" id="kobo.161.1">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html</span></span></a><span class="koboSpan" id="kobo.162.1">.</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.163.1">import</span></span><span class="koboSpan" id="kobo.164.1"> boto3
client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.165.1">'textract'</span></span><span class="koboSpan" id="kobo.166.1">)
response = client.detect_document_text(
        Document={
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.167.1">'Bytes'</span></span><span class="koboSpan" id="kobo.168.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.169.1">b'bytes'</span></span><span class="koboSpan" id="kobo.170.1">,
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.171.1">'S3Object'</span></span><span class="koboSpan" id="kobo.172.1">: {
                </span><span class="hljs-string"><span class="koboSpan" id="kobo.173.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.174.1">Bucket'</span></span><span class="koboSpan" id="kobo.175.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.176.1">'&lt;S3 bucket name&gt;'</span></span><span class="koboSpan" id="kobo.177.1">,
                </span><span class="hljs-string"><span class="koboSpan" id="kobo.178.1">'Name'</span></span><span class="koboSpan" id="kobo.179.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.180.1">'&lt;name of the file&gt;'</span></span><span class="koboSpan" id="kobo.181.1">}
})
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.182.1">Textract also integrates with the </span><strong class="keyWord"><span class="koboSpan" id="kobo.183.1">Amazon Augmented AI</span></strong><span class="koboSpan" id="kobo.184.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.185.1">A2I</span></strong><span class="koboSpan" id="kobo.186.1">) service to enable human-in-the-loop workflow integration for reviewing low-confidence prediction results from Textract. </span><span class="koboSpan" id="kobo.186.2">You can find more information about the A2I service at </span><a href="https://aws.amazon.com/augmented-ai"><span class="url"><span class="koboSpan" id="kobo.187.1">https://aws.amazon.com/augmented-ai</span></span></a><span class="koboSpan" id="kobo.188.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-307"><span class="koboSpan" id="kobo.189.1">Amazon Rekognition</span></h2>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.190.1">Amazon Rekognition</span></strong><span class="koboSpan" id="kobo.191.1"> is</span><a id="_idIndexMarker1160"/><span class="koboSpan" id="kobo.192.1"> a video and image analysis AI service. </span><span class="koboSpan" id="kobo.192.2">It </span><a id="_idIndexMarker1161"/><span class="koboSpan" id="kobo.193.1">supports a range of use cases, such as metadata extraction from images and videos, content moderation, and security and surveillance. </span><span class="koboSpan" id="kobo.193.2">The core</span><a id="_idIndexMarker1162"/><span class="koboSpan" id="kobo.194.1"> capabilities of Rekognition are as follows:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.195.1">Label or object detection</span></strong><span class="koboSpan" id="kobo.196.1">: Label detection can be applied to use cases such as media metadata extraction for search and discovery, item identification and counting for insurance claim processing, and brand and logo detection. </span><span class="koboSpan" id="kobo.196.2">Rekognition can detect different objects, scenes, and activities in images and videos, and assign labels to them such as </span><code class="inlineCode"><span class="koboSpan" id="kobo.197.1">soccer</span></code><span class="koboSpan" id="kobo.198.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.199.1">outdoor</span></code><span class="koboSpan" id="kobo.200.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.201.1">playing soccer</span></code><span class="koboSpan" id="kobo.202.1">. </span><span class="koboSpan" id="kobo.202.2">For the common objects that are detected, it also provides bounding boxes for the objects to indicate their specific positions in the image or videos. </span><span class="koboSpan" id="kobo.202.3">To use Rekognition for label detection, you can call the </span><code class="inlineCode"><span class="koboSpan" id="kobo.203.1">DetectLabels</span></code><span class="koboSpan" id="kobo.204.1"> API. </span><span class="koboSpan" id="kobo.204.2">If Rekognition cannot detect specific objects in your images, you can also train a custom label detector with your training data using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.205.1">CreateProject</span></code><span class="koboSpan" id="kobo.206.1"> API. </span><span class="koboSpan" id="kobo.206.2">Once the model has been trained, you have the option to deploy a private prediction endpoint using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.207.1">StartProjectVersion</span></code><span class="koboSpan" id="kobo.208.1"> API.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.209.1">Facial analysis and recognition</span></strong><span class="koboSpan" id="kobo.210.1">: Facial analysis and recognition are useful for use </span><a id="_idIndexMarker1163"/><span class="koboSpan" id="kobo.211.1">cases such as video surveillance and security, automatic people labeling in images and video for content search, and understanding demographics. </span><span class="koboSpan" id="kobo.211.2">Rekognition can identify and </span><a id="_idIndexMarker1164"/><span class="koboSpan" id="kobo.212.1">analyze faces in images and videos. </span><span class="koboSpan" id="kobo.212.2">For example, you can perform analysis on faces to detect gender, age, and sentiment. </span><span class="koboSpan" id="kobo.212.3">You can also build an index of faces and assign names to them. </span><span class="koboSpan" id="kobo.212.4">Rekognition can map a detected face to a face in the index if a match is found. </span><span class="koboSpan" id="kobo.212.5">The main APIs for facial analysis and recognition are </span><code class="inlineCode"><span class="koboSpan" id="kobo.213.1">DetectFaces</span></code><span class="koboSpan" id="kobo.214.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.215.1">SearchFaces</span></code><span class="koboSpan" id="kobo.216.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.217.1">IndexFaces</span></code><span class="koboSpan" id="kobo.218.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.219.1">CompareFaces</span></code><span class="koboSpan" id="kobo.220.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.221.1">Content moderation</span></strong><span class="koboSpan" id="kobo.222.1">: Rekognition has APIs (</span><code class="inlineCode"><span class="koboSpan" id="kobo.223.1">StartContentModeration</span></code><span class="koboSpan" id="kobo.224.1">) for detecting images and videos with explicit content and scenes, such as violence. </span><span class="koboSpan" id="kobo.224.2">Organizations can use this feature to filter out inappropriate and offensive content before making the content available to consumers.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.225.1">Short text detection</span></strong><span class="koboSpan" id="kobo.226.1">: Rekognition can detect short text in images and provide bounding boxes around the detected text using its </span><code class="inlineCode"><span class="koboSpan" id="kobo.227.1">DetectText</span></code><span class="koboSpan" id="kobo.228.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.229.1">StartTextDetection</span></code><span class="koboSpan" id="kobo.230.1"> APIs. </span><span class="koboSpan" id="kobo.230.2">This feature can be used to detect street names, the names of stores, and license plate numbers.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.231.1">Personal protection equipment (PPE) detection</span></strong><span class="koboSpan" id="kobo.232.1">: Rekognition provides a built-in feature for </span><a id="_idIndexMarker1165"/><span class="koboSpan" id="kobo.233.1">detecting PPE in images and videos using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.234.1">DetectProtectiveEquipment</span></code><span class="koboSpan" id="kobo.235.1"> API. </span><span class="koboSpan" id="kobo.235.2">This feature can be used for automated PPE compliance monitoring.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.236.1">Celebrity identification</span></strong><span class="koboSpan" id="kobo.237.1">: Rekognition also maintains a celebrity database that can be used for identifying known celebrities in images and videos. </span><span class="koboSpan" id="kobo.237.2">It has a list of APIs for this feature, including </span><code class="inlineCode"><span class="koboSpan" id="kobo.238.1">RecognizeCelebrities</span></code><span class="koboSpan" id="kobo.239.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.240.1">GetCelebrityInfo</span></code><span class="koboSpan" id="kobo.241.1">.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.242.1">You can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.243.1">boto3</span></code><span class="koboSpan" id="kobo.244.1"> library to access the APIs. </span><span class="koboSpan" id="kobo.244.2">The following code snippet shows the syntax of using the label detection feature. </span><span class="koboSpan" id="kobo.244.3">The full list of supported </span><code class="inlineCode"><span class="koboSpan" id="kobo.245.1">boto3</span></code><span class="koboSpan" id="kobo.246.1"> APIs for Rekognition can be found at </span><a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html"><span class="url"><span class="koboSpan" id="kobo.247.1">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html</span></span></a><span class="koboSpan" id="kobo.248.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.249.1">import</span></span><span class="koboSpan" id="kobo.250.1"> boto3
client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.251.1">'rekognition'</span></span><span class="koboSpan" id="kobo.252.1">)
response = client.detect_labels(
    Image={
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.253.1">'Bytes'</span></span><span class="koboSpan" id="kobo.254.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.255.1">b'bytes'</span></span><span class="koboSpan" id="kobo.256.1">,
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.257.1">'S3Object'</span></span><span class="koboSpan" id="kobo.258.1">: {
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.259.1">'Bucket'</span></span><span class="koboSpan" id="kobo.260.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.261.1">'&lt;S3 bucket name&gt;'</span></span><span class="koboSpan" id="kobo.262.1">,
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.263.1">'Name'</span></span><span class="koboSpan" id="kobo.264.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.265.1">'&lt;file name&gt;'</span></span><span class="koboSpan" id="kobo.266.1">
        }
    })
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.267.1">Rekognition also has</span><a id="_idIndexMarker1166"/><span class="koboSpan" id="kobo.268.1"> native integration with Amazon Kinesis Video, a video stream service from AWS. </span><span class="koboSpan" id="kobo.268.2">You can build solutions to detect faces in </span><a id="_idIndexMarker1167"/><span class="koboSpan" id="kobo.269.1">real-time video streams.</span></p>
<h2 class="heading-2" id="_idParaDest-308"><span class="koboSpan" id="kobo.270.1">Amazon Transcribe</span></h2>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.271.1">Amazon Transcribe</span></strong><span class="koboSpan" id="kobo.272.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.273.1">Transcribe</span></strong><span class="koboSpan" id="kobo.274.1">) is a </span><a id="_idIndexMarker1168"/><span class="koboSpan" id="kobo.275.1">speech-to-text AI service. </span><span class="koboSpan" id="kobo.275.2">It can be used to transcribe </span><a id="_idIndexMarker1169"/><span class="koboSpan" id="kobo.276.1">video and audio files and streams to text for a range of use cases, such as media content and meeting subtitling, call analytics, and converting medical conversations into electronic health records.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.277.1">Amazon Transcribe </span><a id="_idIndexMarker1170"/><span class="koboSpan" id="kobo.278.1">supports both real-time transcription and batch transcription and has the following key capabilities:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.279.1">Media transcription</span></strong><span class="koboSpan" id="kobo.280.1">: Transcribe has pre-trained models for converting media files or streams into text in different languages, such as English, Chinese, and Spanish. </span><span class="koboSpan" id="kobo.280.2">It also adds punctuation and capitalization to make the transcribed text more readable. </span><span class="koboSpan" id="kobo.280.3">To kick off transcription, you can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.281.1">StartTranscriptionJob</span></code><span class="koboSpan" id="kobo.282.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.283.1">StartMedicalTranscriptionJob</span></code><span class="koboSpan" id="kobo.284.1"> APIs for batch transcription, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.285.1">StartStreamingTranscription</span></code><span class="koboSpan" id="kobo.286.1"> API for streaming transcription, and the </span><code class="inlineCode"><span class="koboSpan" id="kobo.287.1">StartMedicalStreamTranscription</span></code><span class="koboSpan" id="kobo.288.1"> API for streaming medical input.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.289.1">Custom models</span></strong><span class="koboSpan" id="kobo.290.1">: You can provide your training data to train custom language models to increase the accuracy of the transcription for industry-specific terms or acronyms. </span><span class="koboSpan" id="kobo.290.2">The API for creating custom models is </span><code class="inlineCode"><span class="koboSpan" id="kobo.291.1">CreateLanguageModel</span></code><span class="koboSpan" id="kobo.292.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.293.1">Call analytics</span></strong><span class="koboSpan" id="kobo.294.1">: Transcribe provides built-in analytics capabilities for calls. </span><span class="koboSpan" id="kobo.294.2">The transcripts for calls are displayed in a turn-by-turn format. </span><span class="koboSpan" id="kobo.294.3">Some examples of supported</span><a id="_idIndexMarker1171"/><span class="koboSpan" id="kobo.295.1"> analytics are sentiment analysis, call categorization, issue detection (the reason behind the call), and call characteristics (talk time, non-talk time, loudness, interruption). </span><span class="koboSpan" id="kobo.295.2">The API for starting a call analytics job is </span><code class="inlineCode"><span class="koboSpan" id="kobo.296.1">StartCallAnalyticsJob</span></code><span class="koboSpan" id="kobo.297.1">.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.298.1">Redaction</span></strong><span class="koboSpan" id="kobo.299.1">: Transcribe can automatically mask or </span><a id="_idIndexMarker1172"/><span class="koboSpan" id="kobo.300.1">remove sensitive </span><strong class="keyWord"><span class="koboSpan" id="kobo.301.1">personally identifiable information</span></strong><span class="koboSpan" id="kobo.302.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.303.1">PII</span></strong><span class="koboSpan" id="kobo.304.1">) data from transcripts to preserve privacy. </span><span class="koboSpan" id="kobo.304.2">When transcribing with redaction, Transcribe replaces PII information </span><a id="_idIndexMarker1173"/><span class="koboSpan" id="kobo.305.1">with </span><strong class="keyWord"><span class="koboSpan" id="kobo.306.1">[PII]</span></strong><span class="koboSpan" id="kobo.307.1"> in the transcript. </span><span class="koboSpan" id="kobo.307.2">To enable redaction, you can configure the </span><code class="inlineCode"><span class="koboSpan" id="kobo.308.1">ContentRedaction</span></code><span class="koboSpan" id="kobo.309.1"> parameter in the batch transcription jobs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.310.1">Subtitle</span></strong><span class="koboSpan" id="kobo.311.1">: Transcribe can generate out-of-the-box subtitle files in WebVTT and SubRip format to use as video subtitles. </span><span class="koboSpan" id="kobo.311.2">To enable subtitle file generation, you can configure the </span><code class="inlineCode"><span class="koboSpan" id="kobo.312.1">Subtitles</span></code><span class="koboSpan" id="kobo.313.1"> parameter for the transcription job.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.314.1">Detecting toxic speech</span></strong><span class="koboSpan" id="kobo.315.1">: Transcribe Toxicity Detection leverages both audio and text-based cues to identify and classify voice-based toxic content across seven categories including sexual harassment, hate speech, threat, abuse, profanity, insult, and graphic.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.316.1">Redacting transcripts</span></strong><span class="koboSpan" id="kobo.317.1">: Redaction helps securely remove sensitive data like names, addresses, and account details from speech-to-text outputs before further processing or analytics. </span><span class="koboSpan" id="kobo.317.2">This preserves privacy while still allowing leveraging transcripts for other downstream applications.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.318.1">Partitioning speakers</span></strong><span class="koboSpan" id="kobo.319.1">: In your transcription output, Amazon Transcribe allows you to distinguish between various speakers. </span><span class="koboSpan" id="kobo.319.2">The system can identify up to 10 distinct speakers and assigns a unique label to the text associated with each speaker.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.320.1">Multi-channel transcription</span></strong><span class="koboSpan" id="kobo.321.1">: When dealing with audio containing two channels, you can employ channel identification to transcribe the speech from each channel independently.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.322.1">There is also a medical-related transcription service called Amazon Transcribe Medical, a HIPAA-eligible </span><strong class="keyWord"><span class="koboSpan" id="kobo.323.1">automatic speech recognition</span></strong><span class="koboSpan" id="kobo.324.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.325.1">ASR</span></strong><span class="koboSpan" id="kobo.326.1">) service </span><a id="_idIndexMarker1174"/><span class="koboSpan" id="kobo.327.1">that is designed specifically for transcribing </span><a id="_idIndexMarker1175"/><span class="koboSpan" id="kobo.328.1">medical speech. </span><span class="koboSpan" id="kobo.328.2">The service can automatically identify and transcribe medical terminology, anatomical references, medications, procedures, and other clinically relevant information with high accuracy. </span><span class="koboSpan" id="kobo.328.3">Transcribe Medical also supports multiple</span><a id="_idIndexMarker1176"/><span class="koboSpan" id="kobo.329.1"> input sources, including audio files, streaming data, and real-time transcription for live sessions, making it a versatile solution for healthcare providers, medical researchers, and life sciences organizations to efficiently convert medical speech into text for documentation, analysis, and downstream applications.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.330.1">Transcribe has a set of APIs for these different operations. </span><span class="koboSpan" id="kobo.330.2">The following code sample shows how to use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.331.1">boto3</span></code><span class="koboSpan" id="kobo.332.1"> library to kick off a transcription job:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.333.1">import</span></span><span class="koboSpan" id="kobo.334.1"> boto3
transcribe_client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.335.1">'transcribe'</span></span><span class="koboSpan" id="kobo.336.1">)
transcribe_job = transcribe_client.start_transcription_job(**job_args)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.337.1">You can find the full list of </span><code class="inlineCode"><span class="koboSpan" id="kobo.338.1">boto3</span></code><span class="koboSpan" id="kobo.339.1"> APIs for Transcribe at </span><a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/transcribe.html"><span class="url"><span class="koboSpan" id="kobo.340.1">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/transcribe.html</span></span></a><span class="koboSpan" id="kobo.341.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-309"><span class="koboSpan" id="kobo.342.1">Amazon Personalize</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.343.1">Personalized </span><a id="_idIndexMarker1177"/><span class="koboSpan" id="kobo.344.1">recommendations can help you optimize user </span><a id="_idIndexMarker1178"/><span class="koboSpan" id="kobo.345.1">engagement and revenues for many businesses such as e-commerce, financial product recommendation, and media content delivery. </span><strong class="keyWord"><span class="koboSpan" id="kobo.346.1">Amazon Personalize</span></strong><span class="koboSpan" id="kobo.347.1"> allows you to build personalized recommendation models using your data. </span><span class="koboSpan" id="kobo.347.2">You can use Personalize as the recommendation engine to power product and content recommendations based on individual tastes and behaviors. </span><span class="koboSpan" id="kobo.347.3">At a high level, the Personalize</span><a id="_idIndexMarker1179"/><span class="koboSpan" id="kobo.348.1"> service provides the following three core functionalities:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.349.1">User personalization</span></strong><span class="koboSpan" id="kobo.350.1">: Predicts the items a user will interact with or explore</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.351.1">Similar items</span></strong><span class="koboSpan" id="kobo.352.1">: Computes similar items based on the co-occurrence of items and item metadata</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.353.1">Personalized re-ranking</span></strong><span class="koboSpan" id="kobo.354.1">: Re-ranks the input list of items for a given user</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.355.1">Amazon Personalize does not provide pre-trained models for recommendations. </span><span class="koboSpan" id="kobo.355.2">Instead, you need to train custom models using your data with the built-in algorithms provided by Personalize. </span><span class="koboSpan" id="kobo.355.3">To </span><a id="_idIndexMarker1180"/><span class="koboSpan" id="kobo.356.1">train a personalized </span><a id="_idIndexMarker1181"/><span class="koboSpan" id="kobo.357.1">model, you need to provide three datasets:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.358.1">Item dataset</span></strong><span class="koboSpan" id="kobo.359.1">: The item dataset contains the attributes of the items you want to recommend. </span><span class="koboSpan" id="kobo.359.2">This dataset helps Personalize learn about the contextual information about the items for better recommendations. </span><span class="koboSpan" id="kobo.359.3">This dataset is optional.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.360.1">User dataset</span></strong><span class="koboSpan" id="kobo.361.1">: The user dataset contains attributes of the users. </span><span class="koboSpan" id="kobo.361.2">This allows Personalize to have a better representation of each user to provide highly personalized recommendations. </span><span class="koboSpan" id="kobo.361.3">This dataset is also optional.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.362.1">User-item interaction dataset</span></strong><span class="koboSpan" id="kobo.363.1">: This is a required dataset, and it provides the historical interaction between users and items, such as viewing a movie or purchasing a product. </span><span class="koboSpan" id="kobo.363.2">Personalize uses this data to learn the behaviors of individual users toward different items to generate highly personalized recommendations.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.364.1">To help understand how Personalize works, let’s review some of the main Personalize concepts:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.365.1">Dataset group</span></strong><span class="koboSpan" id="kobo.366.1">: A dataset group contains related datasets (item, user, and interaction dataset) for model training.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.367.1">Recipe</span></strong><span class="koboSpan" id="kobo.368.1">: A recipe is the ML algorithm that’s used for model training. </span><span class="koboSpan" id="kobo.368.2">Personalize provides multiple recipes for the three main functionalities.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.369.1">Solution</span></strong><span class="koboSpan" id="kobo.370.1">: A solution represents a trained Personalize model.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.371.1">Campaign</span></strong><span class="koboSpan" id="kobo.372.1">: A Personalize campaign is a hosted endpoint for a trained Personalize model to handle recommendation and ranking requests.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.373.1">To train and deploy a custom model using Personalize, you must follow these steps:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.374.1">Prepare and ingest the dataset</span></strong><span class="koboSpan" id="kobo.375.1">: In this step, you prepare the dataset in the required format, store it in S3, and then load the dataset into Personalize. </span><span class="koboSpan" id="kobo.375.2">There are three main API actions involved in this step – </span><code class="inlineCode"><span class="koboSpan" id="kobo.376.1">CreateDatasetGroup</span></code><span class="koboSpan" id="kobo.377.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.378.1">CreateDataset</span></code><span class="koboSpan" id="kobo.379.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.380.1">CreateDatasetImportJob</span></code><span class="koboSpan" id="kobo.381.1">. </span><code class="inlineCode"><span class="koboSpan" id="kobo.382.1">CreateDatasetGroup</span></code><span class="koboSpan" id="kobo.383.1"> creates an empty dataset group. </span><code class="inlineCode"><span class="koboSpan" id="kobo.384.1">CreateDataset</span></code><span class="koboSpan" id="kobo.385.1"> adds datasets (for example, item dataset, user dataset, and interaction dataset) to a dataset group, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.386.1">CreateDatasetImportJob</span></code><span class="koboSpan" id="kobo.387.1"> kicks off a data ingestion job to load data from S3 to the Personalize data repository for subsequent model training.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.388.1">Pick a recipe for model training</span></strong><span class="koboSpan" id="kobo.389.1">: In this step, you choose a recipe (ML algorithm) to use for the different model training processes. </span><span class="koboSpan" id="kobo.389.2">There are multiple </span><a id="_idIndexMarker1182"/><span class="koboSpan" id="kobo.390.1">recipe options available for user personalization, related items, and personalized ranking. </span><span class="koboSpan" id="kobo.390.2">You can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.391.1">ListRecipes</span></code><span class="koboSpan" id="kobo.392.1"> API to get the full list of recipes. </span><span class="koboSpan" id="kobo.392.2">The recipes are designed for specific use cases such as next best action, trending and popular items, or similar items. </span><span class="koboSpan" id="kobo.392.3">Pick the appropriate recipes based on the use cases.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.393.1">Create a solution</span></strong><span class="koboSpan" id="kobo.394.1">: In this step, you configure a solution with the dataset group and </span><a id="_idIndexMarker1183"/><span class="koboSpan" id="kobo.395.1">recipe for the model training job using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.396.1">CreateSolution</span></code><span class="koboSpan" id="kobo.397.1"> API. </span><span class="koboSpan" id="kobo.397.2">Then, you use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.398.1">CreateSolutionVersion</span></code><span class="koboSpan" id="kobo.399.1"> API to kick off the training job.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.400.1">Evaluate the model</span></strong><span class="koboSpan" id="kobo.401.1">: In this step, you evaluate the model metrics and determine if they meet the performance target. </span><span class="koboSpan" id="kobo.401.2">If they do not, then consider retraining the model using higher-quality and/or more data. </span><span class="koboSpan" id="kobo.401.3">Personalize outputs several evaluation metrics for the trained models, such as coverage, mean reciprocal rank, precision, and normalized discounted accumulative gain. </span><span class="koboSpan" id="kobo.401.4">You can find more details about these metrics at </span><a href="https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html"><span class="url"><span class="koboSpan" id="kobo.402.1">https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html</span></span></a><span class="koboSpan" id="kobo.403.1">. </span><span class="koboSpan" id="kobo.403.2">The performance metrics are available in the Personalize management console. </span><span class="koboSpan" id="kobo.403.3">You can also get the metrics programmatically using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.404.1">GetSolutionMetrics</span></code><span class="koboSpan" id="kobo.405.1"> API.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.406.1">Create a campaign</span></strong><span class="koboSpan" id="kobo.407.1">: In this final step, you deploy a solution (trained model) into the prediction endpoint so that you can use it in your applications. </span><span class="koboSpan" id="kobo.407.2">To do this, you can use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.408.1">CreateCampaign</span></code><span class="koboSpan" id="kobo.409.1"> API. </span><span class="koboSpan" id="kobo.409.2">You can provide additional configurations such </span><a id="_idIndexMarker1184"/><span class="koboSpan" id="kobo.410.1">as the </span><strong class="keyWord"><span class="koboSpan" id="kobo.411.1">minimum provisioned transaction per second</span></strong><span class="koboSpan" id="kobo.412.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.413.1">minProvisionedTPS</span></strong><span class="koboSpan" id="kobo.414.1">) throughput, as well as item exploration configuration. </span><span class="koboSpan" id="kobo.414.2">Item exploration configuration allows Personalize to show a percentage of random items to users that are not based on user personalization. </span><span class="koboSpan" id="kobo.414.3">The idea is to let users explore items that they have not interacted with before to gauge interest. </span><span class="koboSpan" id="kobo.414.4">The item exploration configuration is only applicable for user personalization.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.415.1">You can use the Personalize management console to build Personalize solutions and campaigns. </span><span class="koboSpan" id="kobo.415.2">Alternatively, you can use </span><code class="inlineCode"><span class="koboSpan" id="kobo.416.1">boto3</span></code><span class="koboSpan" id="kobo.417.1"> to access the </span><code class="inlineCode"><span class="koboSpan" id="kobo.418.1">personalize</span></code><span class="koboSpan" id="kobo.419.1"> API. </span><span class="koboSpan" id="kobo.419.2">The following code sample shows the Python syntax for creating a campaign. </span><span class="koboSpan" id="kobo.419.3">You can find the full list of </span><code class="inlineCode"><span class="koboSpan" id="kobo.420.1">boto3</span></code><span class="koboSpan" id="kobo.421.1"> APIs for Personalize at </span><a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/personalize.html"><span class="url"><span class="koboSpan" id="kobo.422.1">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/personalize.html</span></span></a><span class="koboSpan" id="kobo.423.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.424.1">import</span></span><span class="koboSpan" id="kobo.425.1"> boto3
client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.426.1">'personalize'</span></span><span class="koboSpan" id="kobo.427.1">)
response = client.create_campaign(
    name=</span><span class="hljs-string"><span class="koboSpan" id="kobo.428.1">'&lt;name of the campaign&gt;'</span></span><span class="koboSpan" id="kobo.429.1">,
    solutionVersionArn=</span><span class="hljs-string"><span class="koboSpan" id="kobo.430.1">'&lt;AWS Arn to the solution&gt;'</span></span><span class="koboSpan" id="kobo.431.1">,
    minProvisionedTPS=&lt;provisioned TPS&gt;,
    campaignConfig={
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.432.1">'itemExplorationConfig'</span></span><span class="koboSpan" id="kobo.433.1">: {
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.434.1">'&lt;name of configuration&gt;'</span></span><span class="koboSpan" id="kobo.435.1">: </span><span class="hljs-string"><span class="koboSpan" id="kobo.436.1">'&lt;value of configuration&gt;'</span></span><span class="koboSpan" id="kobo.437.1">
        }})
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.438.1">Personalize also </span><a id="_idIndexMarker1185"/><span class="koboSpan" id="kobo.439.1">provides several advanced functionalities, such </span><a id="_idIndexMarker1186"/><span class="koboSpan" id="kobo.440.1">as filters, which allow you to remove items from your list of items based on rules. </span><span class="koboSpan" id="kobo.440.2">You can also optimize the model training using a business objective such as customer loyalty. </span><span class="koboSpan" id="kobo.440.3">This feature allows you to give recommendations that optimize a certain business outcome.</span></p>
<h2 class="heading-2" id="_idParaDest-310"><span class="koboSpan" id="kobo.441.1">Amazon Lex V2</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.442.1">Conversational agents</span><a id="_idIndexMarker1187"/><span class="koboSpan" id="kobo.443.1"> have been broadly adopted across</span><a id="_idIndexMarker1188"/><span class="koboSpan" id="kobo.444.1"> many different industries to improve the user engagement experience, such as self-service customer support and automating IT functions.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.445.1">Amazon Lex V2 facilitates the creation of conversational interfaces using voice and text for applications. </span><span class="koboSpan" id="kobo.445.2">It offers functionalities</span><a id="_idIndexMarker1189"/><span class="koboSpan" id="kobo.446.1"> like </span><strong class="keyWord"><span class="koboSpan" id="kobo.447.1">natural language understanding</span></strong><span class="koboSpan" id="kobo.448.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.449.1">NLU</span></strong><span class="koboSpan" id="kobo.450.1">) and </span><strong class="keyWord"><span class="koboSpan" id="kobo.451.1">automatic speech recognition</span></strong><span class="koboSpan" id="kobo.452.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.453.1">ASR</span></strong><span class="koboSpan" id="kobo.454.1">), allowing developers</span><a id="_idIndexMarker1190"/><span class="koboSpan" id="kobo.455.1"> to build user-friendly interactions. </span><span class="koboSpan" id="kobo.455.2">Amazon Lex V2 has </span><a id="_idIndexMarker1191"/><span class="koboSpan" id="kobo.456.1">the following key concepts:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.457.1">Bot</span></strong><span class="koboSpan" id="kobo.458.1">: An automated tool designed for tasks like placing orders, hotel bookings, or flower orders.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.459.1">Language</span></strong><span class="koboSpan" id="kobo.460.1">: Amazon Lex V2 bots can handle multiple languages independently. </span><span class="koboSpan" id="kobo.460.2">Configurable to engage users with native expressions, the platform supports a variety of languages and locales.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.461.1">Intent</span></strong><span class="koboSpan" id="kobo.462.1">: Representing user actions, intents are created to support related functionalities. </span><span class="koboSpan" id="kobo.462.2">For instance, an intent for ordering pizzas may include details like the intent name (e.g., </span><code class="inlineCode"><span class="koboSpan" id="kobo.463.1">PlaceOrder</span></code><span class="koboSpan" id="kobo.464.1">), sample utterances, and fulfillment instructions, typically executed through a Lambda function.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.465.1">Slot</span></strong><span class="koboSpan" id="kobo.466.1">: Intents may require parameters known as slots, such as destination or date, with slot types defining the expected values. </span><span class="koboSpan" id="kobo.466.2">It prompts users for these values and ensures all required information is provided before fulfilling the intent.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.467.1">Slot Type</span></strong><span class="koboSpan" id="kobo.468.1">: Each slot is associated with a slot type, which can be custom or built-in. </span><span class="koboSpan" id="kobo.468.2">For instance, sizes may have an enumeration of </span><code class="inlineCode"><span class="koboSpan" id="kobo.469.1">Small</span></code><span class="koboSpan" id="kobo.470.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.471.1">Medium</span></code><span class="koboSpan" id="kobo.472.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.473.1">Large</span></code><span class="koboSpan" id="kobo.474.1">, while built-in types like </span><code class="inlineCode"><span class="koboSpan" id="kobo.475.1">AMAZON.Number</span></code><span class="koboSpan" id="kobo.476.1"> handle numeric inputs.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.477.1">Version</span></strong><span class="koboSpan" id="kobo.478.1">: A </span><a id="_idIndexMarker1192"/><span class="koboSpan" id="kobo.479.1">version in Amazon Lex V2 represents a snapshot of the bot’s configuration. </span><span class="koboSpan" id="kobo.479.2">It allows for different versions to be used in various workflow stages, like development, beta deployment, or production.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.480.1">Alias</span></strong><span class="koboSpan" id="kobo.481.1">: An alias serves as a pointer to a specific version of a bot, enabling seamless updates for client applications. </span><span class="koboSpan" id="kobo.481.2">By changing the alias to point to a new version, all clients receive the updated functionality without requiring individual updates.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.482.1">To build a bot, you outline the conversation flow in the Amazon Lex V2 console, which dynamically manages the dialog and responses. </span><span class="koboSpan" id="kobo.482.2">The console supports the building, testing, and publishing of text or voice chatbots for integration into platforms like mobile devices and web applications. </span><span class="koboSpan" id="kobo.482.3">It also integrates with AWS Lambda and other AWS services, enhancing connectivity to data in various applications. </span><span class="koboSpan" id="kobo.482.4">In addition to the console, you can also use bot templates and automated bot designers to create bots.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.483.1">Amazon Lex V2 also</span><a id="_idIndexMarker1193"/><span class="koboSpan" id="kobo.484.1"> utilizes the generative AI features of Amazon Bedrock to facilitate the development of bots. </span><span class="koboSpan" id="kobo.484.2">With Amazon Bedrock, you can create new bots, incorporating relevant intents and slot types through natural language descriptions. </span><span class="koboSpan" id="kobo.484.3">The tool automates the generation of sample utterances tailored to your bot’s intents. </span><span class="koboSpan" id="kobo.484.4">Additionally, Amazon Bedrock facilitates the creation of specialized intents designed to address customer inquiries.</span></p>
<h2 class="heading-2" id="_idParaDest-311"><span class="koboSpan" id="kobo.485.1">Amazon Kendra</span></h2>
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.486.1">Amazon Kendra</span></strong><span class="koboSpan" id="kobo.487.1"> is a</span><a id="_idIndexMarker1194"/><span class="koboSpan" id="kobo.488.1"> fully managed intelligent search service. </span><span class="koboSpan" id="kobo.488.2">It </span><a id="_idIndexMarker1195"/><span class="koboSpan" id="kobo.489.1">uses ML to understand your natural language requests and perform NLU on the target data sources to return the relevant information. </span><span class="koboSpan" id="kobo.489.2">Instead of searching for answers using keywords such as </span><code class="inlineCode"><span class="koboSpan" id="kobo.490.1">IT desk location</span></code><span class="koboSpan" id="kobo.491.1"> and getting a list of documents containing these keywords, you can ask natural language questions such as </span><em class="italic"><span class="koboSpan" id="kobo.492.1">Where is the IT desk?</span></em><span class="koboSpan" id="kobo.493.1"> and get the location of the IT desk, such as </span><em class="italic"><span class="koboSpan" id="kobo.494.1">3rd floor, room 301</span></em><span class="koboSpan" id="kobo.495.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.496.1">You can use </span><a id="_idIndexMarker1196"/><span class="koboSpan" id="kobo.497.1">Amazon Kendra to solve several use cases. </span><span class="koboSpan" id="kobo.497.2">For example, you can use it as part of a contact center workflow where customer agents can quickly find the most relevant information for customer requests. </span><span class="koboSpan" id="kobo.497.3">You can also use it within an enterprise for information discovery across different data sources to improve productivity. </span><span class="koboSpan" id="kobo.497.4">At a high level, Kendra</span><a id="_idIndexMarker1197"/><span class="koboSpan" id="kobo.498.1"> has the following key functionalities:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.499.1">Document reading understanding</span></strong><span class="koboSpan" id="kobo.500.1">: Kendra performs reading comprehension on the source document and returns the specific information requested by the user in their questions.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.501.1">Frequently asked question (FAQ) matching</span></strong><span class="koboSpan" id="kobo.502.1">: If you provide a list of FAQs, Kendra can automatically match the questions to the answers in the list.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.503.1">Document ranking</span></strong><span class="koboSpan" id="kobo.504.1">: Kendra can return a list of documents that contain the relevant information for the questions asked. </span><span class="koboSpan" id="kobo.504.2">To return the list in the order of semantic relevancies, Kendra uses ML to understand the semantic meaning of the documents.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.505.1">To understand how Kendra works, let’s review some of the key technical Amazon Kendra concepts:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.506.1">Index</span></strong><span class="koboSpan" id="kobo.507.1">: An index provides search results for the documents and FAQ lists that it has indexed. </span><span class="koboSpan" id="kobo.507.2">Kendra generates indexes for documents and FAQ lists that allow them to be searched.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.508.1">Documents</span></strong><span class="koboSpan" id="kobo.509.1">: Documents can be structured (FAQs) and unstructured (HTML, PDFs) and can be indexed by the Kendra index engine.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.510.1">Data sources</span></strong><span class="koboSpan" id="kobo.511.1">: Data sources are locations where the documents are located. </span><span class="koboSpan" id="kobo.511.2">These can be S3 locations, Amazon RDS databases, and Google Workspace drives, among others. </span><span class="koboSpan" id="kobo.511.3">Kendra has a list of built-in connectors for connecting to different data sources.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.512.1">Queries</span></strong><span class="koboSpan" id="kobo.513.1">: Queries are used for getting results from indexes. </span><span class="koboSpan" id="kobo.513.2">Queries can be natural language containing criteria and filters.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.514.1">Tags</span></strong><span class="koboSpan" id="kobo.515.1">: Tags are metadata that can be assigned to indexes, data sources, and FAQs.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.516.1">There are two </span><a id="_idIndexMarker1198"/><span class="koboSpan" id="kobo.517.1">main steps in setting up Kendra to perform an intelligent search against your documents:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.518.1">Generate index</span></strong><span class="koboSpan" id="kobo.519.1">: The first step is to set up an index for your documents.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.520.1">Add documents to index</span></strong><span class="koboSpan" id="kobo.521.1">: Once the index has been created, you can add document sources to the index to be indexed.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.522.1">Once the index</span><a id="_idIndexMarker1199"/><span class="koboSpan" id="kobo.523.1"> has been created, you use the Kendra </span><code class="inlineCode"><span class="koboSpan" id="kobo.524.1">query()</span></code><span class="koboSpan" id="kobo.525.1"> API to get responses for your index with queries. </span><span class="koboSpan" id="kobo.525.2">The following code snippet shows the Python syntax for querying an index:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.526.1">kendra = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.527.1">'kendra'</span></span><span class="koboSpan" id="kobo.528.1">)
query = </span><span class="hljs-string"><span class="koboSpan" id="kobo.529.1">'${searchString}'</span></span><span class="koboSpan" id="kobo.530.1">
index_id = </span><span class="hljs-string"><span class="koboSpan" id="kobo.531.1">'${indexID}'</span></span><span class="koboSpan" id="kobo.532.1">
response=kendra.query(
QueryText = query, IndexId = index_id)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.533.1">Kendra has built-in connectors for a range of data sources, so you don’t have to build custom code to extract data from those sources. </span><span class="koboSpan" id="kobo.533.2">It also has native application integration with Amazon Lex, which allows Lex to send user queries directly to a Kendra index for fulfillment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.534.1">Kendra is being increasingly used along with large language models to provide a better user experience and accuracy for intelligent enterprise search solutions.</span></p>
<h2 class="heading-2" id="_idParaDest-312"><span class="koboSpan" id="kobo.535.1">Amazon Q</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.536.1">Amazon Q is </span><a id="_idIndexMarker1200"/><span class="koboSpan" id="kobo.537.1">a generative AI-powered service designed to be an assistant tailored for various business needs and developer tasks. </span><span class="koboSpan" id="kobo.537.2">There are multiple sub-Q assistants for the different domains and services including Q for business, Q for </span><a id="_idIndexMarker1201"/><span class="koboSpan" id="kobo.538.1">builder, Q for QuickSight (an AWS business intelligence tool), and Q for Connect (a contact center solution). </span><span class="koboSpan" id="kobo.538.2">In this section, we will briefly cover Q for business as it is designed to help businesses connect to their own data. </span><span class="koboSpan" id="kobo.538.3">Business users, such as marketers, project and program managers, and sales representatives, can engage in customized conversations, address issues, create content, and execute various actions through Amazon Q for business. </span><span class="koboSpan" id="kobo.538.4">This platform is cognizant of the specific systems these users can access, enabling them to pose intricate and detailed queries. </span><span class="koboSpan" id="kobo.538.5">The responses they receive are tailored, ensuring that the results incorporate only information for which they have authorized access. </span><span class="koboSpan" id="kobo.538.6">To learn how Amazon Q for business works, check out the documentation at </span><a href="https://docs.aws.amazon.com/amazonq/latest/business-use-dg/getting-started.html"><span class="url"><span class="koboSpan" id="kobo.539.1">https://docs.aws.amazon.com/amazonq/latest/business-use-dg/getting-started.html</span></span></a><span class="koboSpan" id="kobo.540.1">.</span></p>
<h2 class="heading-2" id="_idParaDest-313"><span class="koboSpan" id="kobo.541.1">Evaluating AWS AI services for ML use cases</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.542.1">To determine if an </span><a id="_idIndexMarker1202"/><span class="koboSpan" id="kobo.543.1">AI service is a good fit for your use cases, you need to evaluate it across multiple dimensions:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.544.1">Functional requirements</span></strong><span class="koboSpan" id="kobo.545.1">: Identify the functional requirements for your ML use cases and test whether the target AI services provide the features you are looking for. </span><span class="koboSpan" id="kobo.545.2">For example, Rekognition is a computer vision service, but it does not support all computer vision tasks. </span><span class="koboSpan" id="kobo.545.3">If you have an instance segmentation computer vision use case, you will have to build a model using an algorithm that supports it, such as Mask-RCNN.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.546.1">Model performance against your data</span></strong><span class="koboSpan" id="kobo.547.1">: AWS AI services are trained with data sources to solve common use cases. </span><span class="koboSpan" id="kobo.547.2">To ensure the models perform well against your data, use your test dataset to evaluate the model metrics for your specific needs. </span><span class="koboSpan" id="kobo.547.3">If the pre-built models do not meet your performance target, then try the custom model building options if the services support it. </span><span class="koboSpan" id="kobo.547.4">If neither option works, then consider building custom models with your data.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.548.1">API latency and throughput requirements</span></strong><span class="koboSpan" id="kobo.549.1">: Determine your latency and throughput requirements for your application and test the target AI service’s API against your requirements. </span><span class="koboSpan" id="kobo.549.2">In general, AWS AI services are designed for low latency and high throughput. </span><span class="koboSpan" id="kobo.549.3">However, you might have use cases that require extremely low latency, such as computer vision tasks at the edge. </span><span class="koboSpan" id="kobo.549.4">If the AI services cannot meet your requirements, then consider building models and hosting them in dedicated hosting infrastructure.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.550.1">Security and integration requirements</span></strong><span class="koboSpan" id="kobo.551.1">: Determine your security and integration requirements and validate whether the AI services meet your requirements. </span><span class="koboSpan" id="kobo.551.2">For example, you might have custom requirements around authentication and might need to develop a custom integration architecture to enable support.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.552.1">Model reproducibility requirements</span></strong><span class="koboSpan" id="kobo.553.1">: Since AI services manage the pre-trained models and ML algorithms for custom models, those models and algorithms can change over time. </span><span class="koboSpan" id="kobo.553.2">If you have strict reproducibility requirements, such as training a custom model using an old version of an algorithm for compliance reasons, then verify if the AI service provides such support before using it.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.554.1">Cost</span></strong><span class="koboSpan" id="kobo.555.1">: Understand your usage pattern requirements and evaluate the cost of using the AI services. </span><span class="koboSpan" id="kobo.555.2">If the cost of developing and hosting a custom model is more cost-effective, and the operational overhead does not outweigh the cost benefits of a custom model, then consider the build-your-own option.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.556.1">There are other</span><a id="_idIndexMarker1203"/><span class="koboSpan" id="kobo.557.1"> considerations when it comes to adopting AI services, such as monitoring metrics, versioning the control of APIs for audit requirements, and data types and volume requirements.</span></p>
<h1 class="heading-1" id="_idParaDest-314"><span class="koboSpan" id="kobo.558.1">Building intelligent solutions with AI services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.559.1">AI services </span><a id="_idIndexMarker1204"/><span class="koboSpan" id="kobo.560.1">can be used for building different intelligent solutions. </span><span class="koboSpan" id="kobo.560.2">To determine if you can use an AI service for your use case, you</span><a id="_idIndexMarker1205"/><span class="koboSpan" id="kobo.561.1"> must identify the business and ML requirements and then evaluate if an AI service offers the functional and non-functional capabilities you are looking for. </span><span class="koboSpan" id="kobo.561.2">In this section, we will present several business use cases and architecture patterns that incorporate AI services.</span></p>
<h2 class="heading-2" id="_idParaDest-315"><span class="koboSpan" id="kobo.562.1">Automating loan document verification and data extraction</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.563.1">When we </span><a id="_idIndexMarker1206"/><span class="koboSpan" id="kobo.564.1">apply for a loan from a bank, we need to provide the bank with physical copies of documentation such as tax returns, pay stubs, bank statements, and photo ID. </span><span class="koboSpan" id="kobo.564.2">Upon receiving</span><a id="_idIndexMarker1207"/><span class="koboSpan" id="kobo.565.1"> those documents, the bank needs to verify them and enter the information from the documents into loan application systems for further processing. </span><span class="koboSpan" id="kobo.565.2">At the time of writing, many banks still perform this verification and data extraction process manually, which is time-consuming and error-prone.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.566.1">To determine if you can use any AI services to solve your problem, you need to identify the ML problems to be solved. </span><span class="koboSpan" id="kobo.566.2">In this particular business workflow, we can identify the following ML problems:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.567.1">Document classification</span></strong><span class="koboSpan" id="kobo.568.1">: Documentation classification is an ML task where the documents are classified into different types, such as driver’s license, pay stubs, and bank statements. </span><span class="koboSpan" id="kobo.568.2">This process identifies the document types and ensures the required documents are received and can be further processed based on their types.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.569.1">Data extraction</span></strong><span class="koboSpan" id="kobo.570.1">: Data extraction is the task of identifying the relevant information from the documents and extracting it. </span><span class="koboSpan" id="kobo.570.2">Examples of such information include customer names and addresses, income information, data of birth details, and bank balances.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.571.1">As we </span><a id="_idIndexMarker1208"/><span class="koboSpan" id="kobo.572.1">have </span><a id="_idIndexMarker1209"/><span class="koboSpan" id="kobo.573.1">learned, these two tasks can be performed by the Comprehend and Textract AI services. </span><span class="koboSpan" id="kobo.573.2">The following diagram shows the architecture flow that incorporates these two services:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.574.1"><img alt="Diagram  Description automatically generated" src="../Images/B20836_11_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.575.1">Figure 11.1: The loan document verification and data extraction process</span></p>
<p class="normal"><span class="koboSpan" id="kobo.576.1">In this architecture, we use a combination of Textract, Comprehend, and Amazon Augmented AI services to support loan document classification and the loan data processing flow.</span></p>
<h3 class="heading-3" id="_idParaDest-316"><span class="koboSpan" id="kobo.577.1">Loan document classification workflow</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.578.1">First, we</span><a id="_idIndexMarker1210"/><span class="koboSpan" id="kobo.579.1"> need to train a custom text classification model for classifying the text that appears in each type of document. </span><span class="koboSpan" id="kobo.579.2">Here, we will train a custom classification model using Comprehend. </span><span class="koboSpan" id="kobo.579.3">The training data for Comprehend’s custom classifier consists of the necessary input text and labels. </span><span class="koboSpan" id="kobo.579.4">Note that Comprehend has limits on the input text size and the maximum number of classes, and this limit can change. </span><span class="koboSpan" id="kobo.579.5">Check out the official documentation for the latest limitation details. </span><span class="koboSpan" id="kobo.579.6">Once the model has been trained, you get a private API endpoint for the classifier.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.580.1">Once the</span><a id="_idIndexMarker1211"/><span class="koboSpan" id="kobo.581.1"> custom model has been trained and deployed, the main flow of the architecture is as follows:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><strong class="keyWord"><span class="koboSpan" id="kobo.582.1">Data extraction</span></strong><span class="koboSpan" id="kobo.583.1">: Once the documents have been received and digitized as images or PDFs, Textract can be used to extract text, tabular data, and form data from the documents. </span><span class="koboSpan" id="kobo.583.2">The output will be in JSON format and stored as files in S3.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.584.1">Human review</span></strong><span class="koboSpan" id="kobo.585.1">: To ensure the high accuracy of the extracted data by Textract, a human-in-the-loop process can be implemented to verify low-confidence predictions and manually correct them. </span><span class="koboSpan" id="kobo.585.2">This human-in-the-loop workflow can be implemented using the Amazon Augmented AI service.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.586.1">Document classification</span></strong><span class="koboSpan" id="kobo.587.1">: The JSON outputs are processed to generate classification prediction using the custom Comprehend model that has been trained.</span></li>
<li class="numberedList"><strong class="keyWord"><span class="koboSpan" id="kobo.588.1">Update downstream systems</span></strong><span class="koboSpan" id="kobo.589.1">: The prediction outputs are passed to downstream systems for further processing.</span></li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.590.1">There are alternative architecture options available. </span><span class="koboSpan" id="kobo.590.2">For example, you can also treat documents as images and perform image classification using the Rekognition service. </span><span class="koboSpan" id="kobo.590.3">Another option is to train a custom model using your algorithms, such as LayoutLM, and prepare a training dataset with the output of Textract. </span><span class="koboSpan" id="kobo.590.4">It is prudent to validate multiple options to achieve the optimal price/performance trade-off when deciding on the right technology.</span></p>
<h3 class="heading-3" id="_idParaDest-317"><span class="koboSpan" id="kobo.591.1">Loan data processing flow</span></h3>
<p class="normal"><span class="koboSpan" id="kobo.592.1">The </span><a id="_idIndexMarker1212"/><span class="koboSpan" id="kobo.593.1">loan data processing flow is concerned with processing the JSON outputs from the data extraction process. </span><span class="koboSpan" id="kobo.593.2">The JSON document contains raw text and structure details for the entire document, and only a subset of text is needed for downstream processing and storage. </span><span class="koboSpan" id="kobo.593.3">The processing scripts can parse the documents using the structures in the JSON file to identify and extract the specific data points required. </span><span class="koboSpan" id="kobo.593.4">Then, it can input those data points into the downstream databases or systems.</span></p>
<h2 class="heading-2" id="_idParaDest-318"><span class="koboSpan" id="kobo.594.1">Media processing and analysis workflow</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.595.1">The </span><a id="_idIndexMarker1213"/><span class="koboSpan" id="kobo.596.1">media and entertainment industry has accumulated a huge number of digital media assets over the years, and the growth of these new digital assets is accelerating. </span><span class="koboSpan" id="kobo.596.2">One key capability in digital asset management is search and discovery. </span><span class="koboSpan" id="kobo.596.3">This capability not only impacts the user experience but also the effective monetization of media content. </span><span class="koboSpan" id="kobo.596.4">To quickly surface the most relevant content, media companies need to enrich the content with metadata for indexing and searching.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.597.1">In this particular business challenge, we can identify the following ML problems:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.598.1">Speech-to-text transcription</span></strong><span class="koboSpan" id="kobo.599.1">: The </span><a id="_idIndexMarker1214"/><span class="koboSpan" id="kobo.600.1">audio portion of videos and audio files need to be transcribed into text transcripts. </span><span class="koboSpan" id="kobo.600.2">The transcripts can then be further analyzed for additional information.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.601.1">Text NLP analysis</span></strong><span class="koboSpan" id="kobo.602.1">: NLP analysis </span><a id="_idIndexMarker1215"/><span class="koboSpan" id="kobo.603.1">such as entity extraction, sentiment analysis, and topic modeling can be performed on the transcripts.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.604.1">Object/people/scene/activity detection</span></strong><span class="koboSpan" id="kobo.605.1">: Compute vision tasks can be performed on video frames and images to extract objects, people, scenes, and activities.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.606.1">The following diagram shows an architecture that uses Transcribe, Comprehend, and Rekognition to perform the identified ML tasks:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.607.1"><img alt="Graphical user interface, diagram  Description automatically generated" src="../Images/B20836_11_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.608.1">Figure 11.2: Media tagging and analysis architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.609.1">In this architecture, we build a pipeline for subtitle and text analysis of video content, video tagging and analysis, and image tagging and analysis.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.610.1">For live </span><a id="_idIndexMarker1216"/><span class="koboSpan" id="kobo.611.1">video sources such as broadcasting, the AWS Elemental services can take live broadcasting streams, process them, and store them in S3. </span><span class="koboSpan" id="kobo.611.2">You can find more details about the Elemental services at </span><a href="https://aws.amazon.com/elemental-live/"><span class="url"><span class="koboSpan" id="kobo.612.1">https://aws.amazon.com/elemental-live/</span></span></a><span class="koboSpan" id="kobo.613.1">. </span><span class="koboSpan" id="kobo.613.2">Images and video file data sources can be ingested into S3 using a variety of different capabilities, including S3 APIs or higher-level services such as </span><a id="_idIndexMarker1217"/><span class="koboSpan" id="kobo.614.1">AWS Transfer for </span><strong class="keyWord"><span class="koboSpan" id="kobo.615.1">Secure File Transfer Protocol</span></strong><span class="koboSpan" id="kobo.616.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.617.1">SFTP</span></strong><span class="koboSpan" id="kobo.618.1">).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.619.1">As there are multiple parallel processing streams in the pipeline, we can use AWS Step Functions to orchestrate the parallel execution of different streams. </span><span class="koboSpan" id="kobo.619.2">These can generate the following output streams:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.620.1">Subtitle and text analysis stream</span></strong><span class="koboSpan" id="kobo.621.1">: This stream primarily uses the Amazon Transcribe and Amazon Comprehend AI services. </span><span class="koboSpan" id="kobo.621.2">Transcribe transcribes the audio portion of the videos and generates both subtitle files and regular transcripts. </span><span class="koboSpan" id="kobo.621.3">The regular transcripts are then used by Comprehend to run text analysis. </span><span class="koboSpan" id="kobo.621.4">Some example metadata that’s extracted from this stream can include the entities of people and places, the language used, and sentiment for different sections of the transcripts.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.622.1">Video tagging and analysis stream</span></strong><span class="koboSpan" id="kobo.623.1">: This stream identifies objects, scenes, activities, people, celebrities, and text with timestamps in the different video frames.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.624.1">Image tagging and analysis stream</span></strong><span class="koboSpan" id="kobo.625.1">: This stream identifies objects, scenes, activities, celebrities, and text in different images.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.626.1">The outputs from the media processing streams can be further processed and organized as useful metadata for the different media assets. </span><span class="koboSpan" id="kobo.626.2">Once this has been done, they are stored in a media metadata repository to support content search and discovery.</span></p>
<h2 class="heading-2" id="_idParaDest-319"><span class="koboSpan" id="kobo.627.1">E-commerce product recommendation</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.628.1">Product </span><a id="_idIndexMarker1218"/><span class="koboSpan" id="kobo.629.1">recommendation is an important capability in e-commerce. </span><span class="koboSpan" id="kobo.629.2">It is a key enabler for increasing sales, improving engagement experience, and retaining customer loyalty.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.630.1">In e-commerce product recommendation, multiple functional requirements can be framed as ML problems:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.631.1">Recommendations based on customer behaviors and profiles</span></strong><span class="koboSpan" id="kobo.632.1">: ML algorithms can learn the intrinsic characteristics and purchasing patterns of customers from their past e-commerce interactions to predict the products they will like.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.633.1">Ability to address recommendations of cold items (items without history)</span></strong><span class="koboSpan" id="kobo.634.1">: ML algorithms can explore customers’ reactions toward cold items and adjust their recommendations to balance explore (recommending new items) and exploit (recommending known items).</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.635.1">Ability to recommend similar items</span></strong><span class="koboSpan" id="kobo.636.1">: ML algorithms can learn the intrinsic characteristics of products based on product attributes and collective interaction patterns from a group of customers to determine product similarity.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.637.1">With these</span><a id="_idIndexMarker1219"/><span class="koboSpan" id="kobo.638.1"> functional requirements in mind, the following architecture diagram illustrates an e-commerce architecture that uses Amazon Personalize as the recommendation engine:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.639.1"><img alt="Figure 12.3 – e-commerce site and recommendation architecture " src="../Images/B20836_11_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.640.1">Figure 11.3: E-commerce site and recommendation architecture</span></p>
<p class="normal"><span class="koboSpan" id="kobo.641.1">In this architecture, we use Personalize as the recommendation engine to power both the online user experience as well as the target user marketing experience.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.642.1">The </span><a id="_idIndexMarker1220"/><span class="koboSpan" id="kobo.643.1">RDS database, DynamoDB, and Elasticsearch are the main data sources for item, user, and interaction data. </span><span class="koboSpan" id="kobo.643.2">Glue ETL jobs are used to transform the source data into the datasets required for Personalize solution building.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.644.1">Once a Personalize solution has been evaluated to meet the desired criteria, it is deployed as a Personalize campaign to serve recommendation requests from customers visiting the e-commerce website.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.645.1">Amazon Pinpoint is a managed target marketing service. </span><span class="koboSpan" id="kobo.645.2">You can use Pinpoint to manage user segmentation and send email and SMS marketing campaigns. </span><span class="koboSpan" id="kobo.645.3">In this architecture, the Pinpoint service gets a list of recommended products for a group of target customers and sends out email or SMS campaigns to those users with personalized recommendations.</span></p>
<h2 class="heading-2" id="_idParaDest-320"><span class="koboSpan" id="kobo.646.1">Customer self-service automation with intelligent search</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.647.1">Good customer </span><a id="_idIndexMarker1221"/><span class="koboSpan" id="kobo.648.1">service boosts customer satisfaction and builds long-term customer loyalty. </span><span class="koboSpan" id="kobo.648.2">However, customer support is very labor-intensive and can result in poor customer satisfaction due to long waiting times and unknowledgeable support agents. </span><span class="koboSpan" id="kobo.648.3">The customer self-service capability has been widely adopted by organizations in different industries to deflect customer support call volumes and improve customer satisfaction.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.649.1">In a customer self-service scenario, we can identify the following ML problems:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.650.1">Automatic speech recognition</span></strong><span class="koboSpan" id="kobo.651.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.652.1">ASR</span></strong><span class="koboSpan" id="kobo.653.1">): This </span><a id="_idIndexMarker1222"/><span class="koboSpan" id="kobo.654.1">ML task recognizes human speech and converts it into text, and then uses NLU to understand the meaning of the text.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.655.1">Natural language understanding</span></strong><span class="koboSpan" id="kobo.656.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.657.1">NLU</span></strong><span class="koboSpan" id="kobo.658.1">): NLU is a subfield of NLP, and it deals with intent </span><a id="_idIndexMarker1223"/><span class="koboSpan" id="kobo.659.1">understanding and reading comprehension. </span><span class="koboSpan" id="kobo.659.2">NLU focuses on the meaning and intent of the text. </span><span class="koboSpan" id="kobo.659.3">For example, if the text is </span><em class="italic"><span class="koboSpan" id="kobo.660.1">Can I get the cash balance in my savings account?</span></em><span class="koboSpan" id="kobo.661.1">, then the intent here is </span><em class="italic"><span class="koboSpan" id="kobo.662.1">get account balance</span></em><span class="koboSpan" id="kobo.663.1">. </span><span class="koboSpan" id="kobo.663.2">Another example of NLU is understanding the text and extracting specific information from it based on the semantic meaning of the question and the text.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.664.1">Text to speech</span></strong><span class="koboSpan" id="kobo.665.1">: This </span><a id="_idIndexMarker1224"/><span class="koboSpan" id="kobo.666.1">ML task converts text into natural human voices.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.667.1">The</span><a id="_idIndexMarker1225"/><span class="koboSpan" id="kobo.668.1"> following diagram shows a sample architecture for implementing a self-service chat functionality for customers to look up customer-related details, as well as general information and FAQs:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.669.1"><img alt="Figure 12.4 – Self-service chat portal with an intelligent virtual assistant " src="../Images/B20836_11_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.670.1">Figure 11.4: Self-service chat portal with an intelligent virtual assistant</span></p>
<p class="normal"><span class="koboSpan" id="kobo.671.1">In this architecture, an Amazon Lex bot is used to provide the text-based conversational interface for customer engagement. </span><span class="koboSpan" id="kobo.671.2">The customer uses the self-service chat portal to initiate the conversation and the chat portal integrates with the Lex bots via the Lex API.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.672.1">Lex bots support several different intents, such as </span><em class="italic"><span class="koboSpan" id="kobo.673.1">look up account info</span></em><span class="koboSpan" id="kobo.674.1">, </span><em class="italic"><span class="koboSpan" id="kobo.675.1">update customer profile</span></em><span class="koboSpan" id="kobo.676.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.677.1">How do I return a purchase?</span></em><span class="koboSpan" id="kobo.678.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.679.1">Depending on the intent, the Lex bot will route the fulfillment requests to a different backend. </span><span class="koboSpan" id="kobo.679.2">For customer account-related inquiries, it will use a Lambda function for fulfillment. </span><span class="koboSpan" id="kobo.679.3">For information search-related questions, the Lex bot will send the query to a Kendra index for fulfillment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.680.1">Having explored the various AI services and their practical business applications, the subsequent sections will focus on operational considerations related to the adoption of these services. </span><span class="koboSpan" id="kobo.680.2">This includes delving into MLOps, code promotion, and monitoring processes to enhance the operational efficiency of AI implementations.</span></p>
<h1 class="heading-1" id="_idParaDest-321"><span class="koboSpan" id="kobo.681.1">Designing an MLOps architecture for AI services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.682.1">Implementing</span><a id="_idIndexMarker1226"/><span class="koboSpan" id="kobo.683.1"> custom AI service models requires a data engineering, model training, and model deployment pipeline. </span><span class="koboSpan" id="kobo.683.2">This process is similar to the process of building, training, and deploying models using an ML platform. </span><span class="koboSpan" id="kobo.683.3">As such, we can also adopt MLOps practice for AI services when running them at scale.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.684.1">Fundamentally, MLOps for AI services intends to deliver similar benefits as MLOps for the ML platform, including process consistency, tooling reusability, reproducibility, delivery scalability, and auditability. </span><span class="koboSpan" id="kobo.684.2">Architecturally, we can implement a similar MLOps pattern for AI services.</span></p>
<h2 class="heading-2" id="_idParaDest-322"><span class="koboSpan" id="kobo.685.1">AWS account setup strategy for AI services and MLOps</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.686.1">To isolate </span><a id="_idIndexMarker1227"/><span class="koboSpan" id="kobo.687.1">the different environments, we can adopt a multi-account strategy for configuring the MLOps environment for AI services. </span><span class="koboSpan" id="kobo.687.2">The following diagram illustrates a design pattern for a multi-account AWS environment. </span><span class="koboSpan" id="kobo.687.3">Depending on your organizational requirements for separation of duties and control, you may also consider consolidating these into fewer environments:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.688.1"><img alt="Figure 12.5 – MLOps architecture for AI services on AWS  " src="../Images/B20836_11_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.689.1">Figure 11.5: MLOps architecture for AI services on AWS</span></p>
<p class="normal"><span class="koboSpan" id="kobo.690.1">In this </span><a id="_idIndexMarker1228"/><span class="koboSpan" id="kobo.691.1">multi-account AWS environment, developers use the custom model development environment to build and test the pipelines for data engineering, model training, and model deployment. </span><span class="koboSpan" id="kobo.691.2">When ready, the pipelines are promoted for formal model building and testing using production training data in the model development environment. </span><span class="koboSpan" id="kobo.691.3">Since trained AI services models cannot normally be exported, we will need to replicate the model training workflow in the production environment for model deployment.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.692.1">The shared services environment hosts CI/CD tools such as AWS CodePipeline and AWS CodeBuild. </span><span class="koboSpan" id="kobo.692.2">You use the CI/CD tools to build different pipelines for data engineering, model building, and model deployment running in different environments. </span><span class="koboSpan" id="kobo.692.3">For example, a pipeline for the UAT environment could have the following components and steps:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.693.1">CodePipeline definition</span></strong><span class="koboSpan" id="kobo.694.1">: This</span><a id="_idIndexMarker1229"/><span class="koboSpan" id="kobo.695.1"> definition would have a CodeBuild step, a CloudFormation execution step, and a Step Functions workflow execution step.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.696.1">CodeBuild step</span></strong><span class="koboSpan" id="kobo.697.1">: The CodeBuild step enriches the CloudFormation template with additional inputs needed to create a Step Functions workflow that orchestrates data engineering, dataset creation, data ingestion, model training, and model deployment.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.698.1">CloudFormation execution step</span></strong><span class="koboSpan" id="kobo.699.1">: This step executes the CloudFormation template to create the Step Functions workflow.</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.700.1">Step Functions workflow execution step</span></strong><span class="koboSpan" id="kobo.701.1">: This step kicks off the Step Functions workflow to run the various steps, such as data engineering and model training, in the workflow. </span><span class="koboSpan" id="kobo.701.2">For example, if we build a Step Functions workflow for Personalize model training and deployment, the workflow will consist </span><a id="_idIndexMarker1230"/><span class="koboSpan" id="kobo.702.1">of six steps: create dataset group, create dataset, import dataset, create solution, create solution version, and create campaign.</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.703.1">In a multi-account environment, there could also be other purpose-built accounts for data management, monitoring, and security.</span></p>
<h2 class="heading-2" id="_idParaDest-323"><span class="koboSpan" id="kobo.704.1">Code promotion across environments</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.705.1">Similar to the</span><a id="_idIndexMarker1231"/><span class="koboSpan" id="kobo.706.1"> pattern we use for the ML platform, we can use a code repository as the mechanism to promote code to different environments. </span><span class="koboSpan" id="kobo.706.2">For example, during code development, a developer creates code artifacts such as data engineering scripts for Glue ETL jobs and CloudFormation template skeletons and builds specification files for CodeBuild to run different commands. </span><span class="koboSpan" id="kobo.706.3">Once the code is deemed ready to promote them for formal model building and testing, the developer checks the code into a release branch in the code repository. </span><span class="koboSpan" id="kobo.706.4">The code check-in event can trigger a CodePipeline job to run the CodeBuild step in the shared services and then run a Step Functions workflow step in the model development environment. </span><span class="koboSpan" id="kobo.706.5">When it is ready for production release, a deployment CodePipeline job can be triggered in the shared services environment to execute a CloudFormation template to deploy the model in the production environment.</span></p>
<h2 class="heading-2" id="_idParaDest-324"><span class="koboSpan" id="kobo.707.1">Monitoring operational metrics for AI services</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.708.1">AI services </span><a id="_idIndexMarker1232"/><span class="koboSpan" id="kobo.709.1">emit operational statuses to CloudWatch. </span><span class="koboSpan" id="kobo.709.2">For example, Amazon Personalize sends metrics such as the number of successful recommendation calls or training job errors. </span><span class="koboSpan" id="kobo.709.3">Rekognition sends metrics such as successful request counts and response time. </span><span class="koboSpan" id="kobo.709.4">Alarms can be configured to send alerts when specified metrics meet a defined threshold. </span><span class="koboSpan" id="kobo.709.5">The following diagram shows a sample monitoring architecture for Amazon Personalize:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.710.1"><img alt="Figure 12.6 – Monitoring architecture for Amazon Personalize " src="../Images/B20836_11_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.711.1">Figure 11.6: Monitoring architecture for Amazon Personalize</span></p>
<p class="normal"><span class="koboSpan" id="kobo.712.1">With this </span><a id="_idIndexMarker1233"/><span class="koboSpan" id="kobo.713.1">monitoring architecture, CloudWatch collects metrics from the Personalize service. </span><span class="koboSpan" id="kobo.713.2">A scheduled CloudWatch event triggers a Lambda function, which pulls a set of CloudWatch metrics and sends events to the EventBridge service. </span><span class="koboSpan" id="kobo.713.3">EventBridge rules can be configured to trigger Lambda functions to update Personalize configuration, such as updating </span><code class="inlineCode"><span class="koboSpan" id="kobo.714.1">minProvisionedTPS</span></code><span class="koboSpan" id="kobo.715.1"> configuration for Personalize when throttling is detected or sending an email notification when certain errors occur.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.716.1">You can also adopt similar monitoring architecture patterns to other AI services, such as Comprehend and Rekognition.</span></p>
<h1 class="heading-1" id="_idParaDest-325"><span class="koboSpan" id="kobo.717.1">Hands-on lab – running ML tasks using AI services</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.718.1">In this</span><a id="_idIndexMarker1234"/><span class="koboSpan" id="kobo.719.1"> hands-on lab, you will perform a list of ML tasks using Rekognition, Comprehend, Textract, Personalize and Transcribe. </span><span class="koboSpan" id="kobo.719.2">After the lab, you will have </span><a id="_idIndexMarker1235"/><span class="koboSpan" id="kobo.720.1">developed hands-on experience with the core features of several AI services and how they can be used for various ML tasks. </span><span class="koboSpan" id="kobo.720.2">Follow these steps to get started:</span></p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.721.1">Launch the SageMaker Studio profile you created in </span><em class="chapterRef"><span class="koboSpan" id="kobo.722.1">Chapter 8</span></em><span class="koboSpan" id="kobo.723.1">, </span><em class="italic"><span class="koboSpan" id="kobo.724.1">Building a Data Science Environment Using AWS ML Services</span></em><span class="koboSpan" id="kobo.725.1">. </span><span class="koboSpan" id="kobo.725.2">You will create and run new notebooks in this profile.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.726.1">We </span><a id="_idIndexMarker1236"/><span class="koboSpan" id="kobo.727.1">need to provide the new notebooks with permission to access AI services. </span><span class="koboSpan" id="kobo.727.2">To do this, find the Studio execution role for the Studio environment and attach the </span><code class="inlineCode"><span class="koboSpan" id="kobo.728.1">AdministratorAccess</span></code><span class="koboSpan" id="kobo.729.1"> IAM policy to it. </span><span class="koboSpan" id="kobo.729.2">We will use this policy for simplicity here. </span><span class="koboSpan" id="kobo.729.3">In a controlled environment, you would need to design a policy to provide the specific permissions needed to access different services.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.730.1">Clone </span><a href="https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/"><span class="url"><span class="koboSpan" id="kobo.731.1">https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/</span></span></a><span class="koboSpan" id="kobo.732.1"> into your Studio environment using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.733.1">git clone https://github.com/PacktPublishing/The-Machine-Learning-Solutions-Architect-and-Risk-Management-Handbook-Second-Edition/</span></code><span class="koboSpan" id="kobo.734.1"> command if you have not already done so.</span></li>
<li class="numberedList"><span class="koboSpan" id="kobo.735.1">Run NLP tasks</span><a id="_idIndexMarker1237"/><span class="koboSpan" id="kobo.736.1"> using Comprehend:</span><ol class="romanList" style="list-style-type: lower-roman;">
<li class="romanList" value="1"><span class="koboSpan" id="kobo.737.1">Open the </span><code class="inlineCode"><span class="koboSpan" id="kobo.738.1">comprehend.ipynb</span></code><span class="koboSpan" id="kobo.739.1"> notebook in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.740.1">Chapter11</span></code><span class="koboSpan" id="kobo.741.1"> directory. </span><span class="koboSpan" id="kobo.741.2">This notebook performs a list of ML tasks using Comprehend, including language detection, entity detection, sentiment detection, PII detection, key phrase detection, and syntax analysis.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.742.1">Create some sample text you would like to run NLP analysis on and save it as </span><code class="inlineCode"><span class="koboSpan" id="kobo.743.1">comprehend_sample.txt</span></code><span class="koboSpan" id="kobo.744.1"> in the data directory.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.745.1">Run the following code in the notebook to import the library and set up the </span><code class="inlineCode"><span class="koboSpan" id="kobo.746.1">boto3</span></code><span class="koboSpan" id="kobo.747.1"> client for Comprehend:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.748.1">from</span></span><span class="koboSpan" id="kobo.749.1"> pprint </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.750.1">import</span></span><span class="koboSpan" id="kobo.751.1"> pprint
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.752.1">import</span></span><span class="koboSpan" id="kobo.753.1"> boto3 items_to_show = </span><span class="hljs-number"><span class="koboSpan" id="kobo.754.1">10</span></span>
<span class="hljs-key ord"><span class="koboSpan" id="kobo.755.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.756.1">open</span></span><span class="koboSpan" id="kobo.757.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.758.1">'data/comprehend_sample.txt'</span></span><span class="koboSpan" id="kobo.759.1">) </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.760.1">as</span></span><span class="koboSpan" id="kobo.761.1"> sample_file:
    sample_text = sample_file.read()
comprehend_client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.762.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.763.1">comprehend'</span></span><span class="koboSpan" id="kobo.764.1">)
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.765.1">Run the following code in the notebook to detect the dominant language in the text:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.766.1">print</span></span><span class="koboSpan" id="kobo.767.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.768.1">"detecting dominant language"</span></span><span class="koboSpan" id="kobo.769.1">)
languages = comprehend_client.detect_dominant_language(
                Text=sample_text)
lang_code = languages[</span><span class="hljs-string"><span class="koboSpan" id="kobo.770.1">'Languages'</span></span><span class="koboSpan" id="kobo.771.1">][</span><span class="hljs-number"><span class="koboSpan" id="kobo.772.1">0</span></span><span class="koboSpan" id="kobo.773.1">][</span><span class="hljs-string"><span class="koboSpan" id="kobo.774.1">'LanguageCode'</span></span><span class="koboSpan" id="kobo.775.1">]
pprint(lang_code)
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.776.1">Run the following code in the notebook to detect entities:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.777.1">print</span></span><span class="koboSpan" id="kobo.778.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.779.1">"Detecting entities using the pre-trained model."</span></span><span class="koboSpan" id="kobo.780.1">)
entities = comprehend_client.detect_entities(
                Text=sample_text, LanguageCode=lang_code)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.781.1">print</span></span><span class="koboSpan" id="kobo.782.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.783.1">f"The first </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.784.1">{items_to_show}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.785.1"> are:"</span></span><span class="koboSpan" id="kobo.786.1">)
pprint(entities[</span><span class="hljs-string"><span class="koboSpan" id="kobo.787.1">'Entities'</span></span><span class="koboSpan" id="kobo.788.1">][:items_to_show])
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.789.1">Run the</span><a id="_idIndexMarker1238"/><span class="koboSpan" id="kobo.790.1"> following code in the notebook to detect sentiment:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.791.1">print</span></span><span class="koboSpan" id="kobo.792.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.793.1">"Detecting sentiment in text"</span></span><span class="koboSpan" id="kobo.794.1">)
sentiment = comprehend_client.detect_sentiment(
                Text=sample_text, LanguageCode=lang_code)
pprint(sentiment[</span><span class="hljs-string"><span class="koboSpan" id="kobo.795.1">'Sentiment'</span></span><span class="koboSpan" id="kobo.796.1">])
pprint(sentiment[</span><span class="hljs-string"><span class="koboSpan" id="kobo.797.1">'SentimentScore'</span></span><span class="koboSpan" id="kobo.798.1">])
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.799.1">Run the </span><a id="_idIndexMarker1239"/><span class="koboSpan" id="kobo.800.1">following code in the notebook to detect PII entities:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.801.1">print</span></span><span class="koboSpan" id="kobo.802.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.803.1">"Detecting pii entities in text"</span></span><span class="koboSpan" id="kobo.804.1">)
pii = comprehend_client.detect_pii_entities(
            Text=sample_text, LanguageCode=lang_code)
pprint(pii[</span><span class="hljs-string"><span class="koboSpan" id="kobo.805.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.806.1">Entities'</span></span><span class="koboSpan" id="kobo.807.1">][:items_to_show])
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.808.1">Run the following code in the notebook to detect key phrases:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.809.1">print</span></span><span class="koboSpan" id="kobo.810.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.811.1">'Dectecting key phrases'</span></span><span class="koboSpan" id="kobo.812.1">)
key_phrases = comprehend_client.detect_key_phrases(
                Text=sample_text, LanguageCode=lang_code)
pprint(key_phrases[</span><span class="hljs-string"><span class="koboSpan" id="kobo.813.1">'KeyPhrases'</span></span><span class="koboSpan" id="kobo.814.1">][:items_to_show])
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.815.1">Run the following code in the notebook to detect syntax:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.816.1">print</span></span><span class="koboSpan" id="kobo.817.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.818.1">'Detecting syntax'</span></span><span class="koboSpan" id="kobo.819.1">)
syntax = comprehend_client.detect_syntax(
                Text=sample_text, LanguageCode=lang_code)
pprint(syntax[</span><span class="hljs-string"><span class="koboSpan" id="kobo.820.1">'SyntaxTokens'</span></span><span class="koboSpan" id="kobo.821.1">][:items_to_show])
</span></code></pre>
</li>
</ol>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.822.1">Run an audio transcription job using Transcribe:</span><ol class="romanList" style="list-style-type: lower-roman;">
<li class="romanList" value="1"><span class="koboSpan" id="kobo.823.1">Open</span><a id="_idIndexMarker1240"/><span class="koboSpan" id="kobo.824.1"> the </span><code class="inlineCode"><span class="koboSpan" id="kobo.825.1">transcribe.ipynb</span></code><span class="koboSpan" id="kobo.826.1"> notebook in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.827.1">Chapter11</span></code><span class="koboSpan" id="kobo.828.1"> directory. </span><span class="koboSpan" id="kobo.828.2">This notebook runs a transcription job using a sample audio file in the data directory.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.829.1">Find a sample MP3 audio file that you would like to run transcription on and save it as </span><code class="inlineCode"><span class="koboSpan" id="kobo.830.1">transcribe_sample.mp3</span></code><span class="koboSpan" id="kobo.831.1"> in the data directory.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.832.1">Run the</span><a id="_idIndexMarker1241"/><span class="koboSpan" id="kobo.833.1"> following code in the notebook to set up a </span><code class="inlineCode"><span class="koboSpan" id="kobo.834.1">boto3</span></code><span class="koboSpan" id="kobo.835.1"> client for Transcribe:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.836.1">from</span></span><span class="koboSpan" id="kobo.837.1"> pprint </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.838.1">import</span></span><span class="koboSpan" id="kobo.839.1"> pprint
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.840.1">import</span></span><span class="koboSpan" id="kobo.841.1"> boto3
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.842.1">import</span></span><span class="koboSpan" id="kobo.843.1"> time
transcribe_client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.844.1">'transcribe'</span></span><span class="koboSpan" id="kobo.845.1">)
s3_resource = boto3.resource(</span><span class="hljs-string"><span class="koboSpan" id="kobo.846.1">'s3'</span></span><span class="koboSpan" id="kobo.847.1">)
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.848.1">Run the following code in the notebook to create an S3 bucket for storing the audio file:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.849.1">bucket_name = </span><span class="hljs-string"><span class="koboSpan" id="kobo.850.1">f'transcribe-bucket-</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.851.1">{time.time_ns()}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.852.1">'</span></span><span class="koboSpan" id="kobo.853.1">
bucket = s3_resource.create_bucket(
        Bucket=bucket_name,
        CreateBucketConfiguration={
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.854.1">'LocationConstraint'</span></span><span class="koboSpan" id="kobo.855.1">: transcribe_client.meta.region_name})
media_file_name = </span><span class="hljs-string"><span class="koboSpan" id="kobo.856.1">'data/transcribe_sample.mp3'</span></span><span class="koboSpan" id="kobo.857.1">
media_object_key = </span><span class="hljs-string"><span class="koboSpan" id="kobo.858.1">'transcribe_sample.mp3'</span></span><span class="koboSpan" id="kobo.859.1">
bucket.upload_file(media_file_name, media_object_key)
media_uri = </span><span class="hljs-string"><span class="koboSpan" id="kobo.860.1">f's3://</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.861.1">{bucket.name}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.862.1">/</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.863.1">{media_object_key}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.864.1">'</span></span>
</code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.865.1">Run the following code in the notebook to kick off the transcription job:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.866.1">job_name = </span><span class="hljs-string"><span class="koboSpan" id="kobo.867.1">f'transcribe_job_</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.868.1">{time.time_ns()}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.869.1">'</span></span><span class="koboSpan" id="kobo.870.1">
media_format = </span><span class="hljs-string"><span class="koboSpan" id="kobo.871.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.872.1">mp3'</span></span><span class="koboSpan" id="kobo.873.1">
language_code = </span><span class="hljs-string"><span class="koboSpan" id="kobo.874.1">'en-US'</span></span><span class="koboSpan" id="kobo.875.1">
job_args = {
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.876.1">'TranscriptionJobName'</span></span><span class="koboSpan" id="kobo.877.1">: job_name,
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.878.1">'Media'</span></span><span class="koboSpan" id="kobo.879.1">: {</span><span class="hljs-string"><span class="koboSpan" id="kobo.880.1">'MediaFileUri'</span></span><span class="koboSpan" id="kobo.881.1">: media_uri},
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.882.1">'MediaFormat'</span></span><span class="koboSpan" id="kobo.883.1">: media_format,
            </span><span class="hljs-string"><span class="koboSpan" id="kobo.884.1">'LanguageCode'</span></span><span class="koboSpan" id="kobo.885.1">: language_code}
transcribe_job = transcribe_client.start_transcription_job(**job_args)
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.886.1">Navigate to the </span><strong class="keyWord"><span class="koboSpan" id="kobo.887.1">Transcribe</span></strong><span class="koboSpan" id="kobo.888.1"> console. </span><span class="koboSpan" id="kobo.888.2">Under the </span><strong class="keyWord"><span class="koboSpan" id="kobo.889.1">Transcription Jobs</span></strong><span class="koboSpan" id="kobo.890.1"> section, you will see the newly created transcription job.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.891.1">Wait until the status changes to </span><strong class="keyWord"><span class="koboSpan" id="kobo.892.1">Complete</span></strong><span class="koboSpan" id="kobo.893.1"> and click on the job link; you will see the transcripts under the </span><strong class="keyWord"><span class="koboSpan" id="kobo.894.1">Text</span></strong><span class="koboSpan" id="kobo.895.1"> tab in the </span><strong class="keyWord"><span class="koboSpan" id="kobo.896.1">transcription preview</span></strong><span class="koboSpan" id="kobo.897.1"> section.</span></li>
</ol>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.898.1">Run computer vision with Rekognition:</span><ol class="romanList" style="list-style-type: lower-roman;">
<li class="romanList" value="1"><span class="koboSpan" id="kobo.899.1">Open </span><a id="_idIndexMarker1242"/><span class="koboSpan" id="kobo.900.1">the </span><code class="inlineCode"><span class="koboSpan" id="kobo.901.1">rekognition.ipynb</span></code><span class="koboSpan" id="kobo.902.1"> notebook in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.903.1">Chapter11</span></code><span class="koboSpan" id="kobo.904.1"> directory. </span><span class="koboSpan" id="kobo.904.2">This notebook runs a list of text extraction tasks, including</span><a id="_idIndexMarker1243"/><span class="koboSpan" id="kobo.905.1"> text extraction, table extraction, and form extraction.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.906.1">Save a sample image for analysis as </span><code class="inlineCode"><span class="koboSpan" id="kobo.907.1">textract_sample.jpeg</span></code><span class="koboSpan" id="kobo.908.1"> in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.909.1">data</span></code><span class="koboSpan" id="kobo.910.1"> directory. </span><span class="koboSpan" id="kobo.910.2">Try to use a sample image with text, tables, and forms in it.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.911.1">Run the following code in the notebook to set up a </span><code class="inlineCode"><span class="koboSpan" id="kobo.912.1">boto3</span></code><span class="koboSpan" id="kobo.913.1"> client for Textract:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-key ord"><span class="koboSpan" id="kobo.914.1">from</span></span><span class="koboSpan" id="kobo.915.1"> pprint </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.916.1">import</span></span><span class="koboSpan" id="kobo.917.1"> pprint
</span><span class="hljs-key ord"><span class="koboSpan" id="kobo.918.1">import</span></span><span class="koboSpan" id="kobo.919.1"> boto3
textract_client = boto3.client(</span><span class="hljs-string"><span class="koboSpan" id="kobo.920.1">'textract'</span></span><span class="koboSpan" id="kobo.921.1">)
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.922.1">Run the following code in the notebook to load the image:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.923.1">document_file_name = </span><span class="hljs-string"><span class="koboSpan" id="kobo.924.1">'data/textract_sample.png'</span></span>
<span class="hljs-key ord"><span class="koboSpan" id="kobo.925.1">with</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.926.1">open</span></span><span class="koboSpan" id="kobo.927.1">(document_file_name, </span><span class="hljs-string"><span class="koboSpan" id="kobo.928.1">'rb'</span></span><span class="koboSpan" id="kobo.929.1">) </span><span class="hljs-key ord"><span class="koboSpan" id="kobo.930.1">as</span></span><span class="koboSpan" id="kobo.931.1"> document_file:
                document_bytes = document_file.read()
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.932.1">Run the following code in the notebook to detect tables and forms:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.933.1">print</span></span><span class="koboSpan" id="kobo.934.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.935.1">'Detecting tables and forms'</span></span><span class="koboSpan" id="kobo.936.1">)
feature_types = [</span><span class="hljs-string"><span class="koboSpan" id="kobo.937.1">'TABLES'</span></span><span class="koboSpan" id="kobo.938.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.939.1">'</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.940.1">FORMS'</span></span><span class="koboSpan" id="kobo.941.1">]
tables_forms = textract_client.analyze_document(
        Document={</span><span class="hljs-string"><span class="koboSpan" id="kobo.942.1">'Bytes'</span></span><span class="koboSpan" id="kobo.943.1">: document_bytes},
        FeatureTypes=feature_types)
blocks_to_show = </span><span class="hljs-number"><span class="koboSpan" id="kobo.944.1">10</span></span><span class="koboSpan" id="kobo.945.1">
pprint(tables_forms[</span><span class="hljs-string"><span class="koboSpan" id="kobo.946.1">'Blocks'</span></span><span class="koboSpan" id="kobo.947.1">][:blocks_to_show])
</span></code></pre>
</li>
<li class="romanList"><span class="koboSpan" id="kobo.948.1">Run the following code in the notebook to detect text:
            </span><pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in"><span class="koboSpan" id="kobo.949.1">print</span></span><span class="koboSpan" id="kobo.950.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.951.1">'Detect text'</span></span><span class="koboSpan" id="kobo.952.1">)
text = textract_client.detect_document_text(
        Document={</span><span class="hljs-string"><span class="koboSpan" id="kobo.953.1">'Bytes'</span></span><span class="koboSpan" id="kobo.954.1">: document_bytes})
blocks_to_show = </span><span class="hljs-number"><span class="koboSpan" id="kobo.955.1">20</span></span><span class="koboSpan" id="kobo.956.1">
pprint(text[</span><span class="hljs-string"><span class="koboSpan" id="kobo.957.1">'Blocks'</span></span><span class="koboSpan" id="kobo.958.1">][:blocks_to_show])
</span></code></pre>
</li>
</ol>
</li>
<li class="numberedList"><span class="koboSpan" id="kobo.959.1">Train a recommendation model using Personalize:</span><ol class="romanList" style="list-style-type: lower-roman;">
<li class="romanList" value="1"><span class="koboSpan" id="kobo.960.1">Open </span><a id="_idIndexMarker1244"/><span class="koboSpan" id="kobo.961.1">the </span><code class="inlineCode"><span class="koboSpan" id="kobo.962.1">personalize.ipynb</span></code><span class="koboSpan" id="kobo.963.1"> notebook in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.964.1">Chapter11</span></code><span class="koboSpan" id="kobo.965.1"> directory. </span><span class="koboSpan" id="kobo.965.2">This notebook trains a Personalize model for movie review recommendations using the movie lens dataset. </span><span class="koboSpan" id="kobo.965.3">It goes through the </span><a id="_idIndexMarker1245"/><span class="koboSpan" id="kobo.966.1">process of creating a dataset group/dataset, importing the data, building the solution, and creating a Personalize campaign.</span></li>
<li class="romanList"><span class="koboSpan" id="kobo.967.1">Follow the instructions in the notebook and run all the cells in sequence to complete all the steps.</span></li>
</ol>
</li>
</ol>
<p class="normal"><span class="koboSpan" id="kobo.968.1">Congratulations! </span><span class="koboSpan" id="kobo.968.2">You have successfully used several AWS AI services and their APIs. </span><span class="koboSpan" id="kobo.968.3">As you can see, it is quite straightforward to use AI services with pre-trained models to perform different ML tasks. </span><span class="koboSpan" id="kobo.968.4">Training a custom model using AI services involves some additional steps, but the underlying infrastructure and data science details are abstracted away to make it easy for non-data-scientists to use these services as well.</span></p>
<h2 class="heading-2" id="_idParaDest-326"><span class="koboSpan" id="kobo.969.1">Summary</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.970.1">In this chapter, we covered topics surrounding AI services. </span><span class="koboSpan" id="kobo.970.2">We went over a list of AWS AI services and where they can be used to build ML solutions. </span><span class="koboSpan" id="kobo.970.3">We also talked about adopting MLOps for AI services deployment. </span><span class="koboSpan" id="kobo.970.4">Now, you should have a good understanding of what AI services are and know that you don’t need to always build custom models to solve ML problems. </span><span class="koboSpan" id="kobo.970.5">AI services provide you with a quick way to build AI-enabled applications when they are a good fit.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.971.1">In the next chapter, we will dive deep into AI risk management, an important area for ML practitioners to become familiar with as it is critical to understand the key risks and mitigation approaches throughout the entire ML lifecycle.</span></p>
<h1 class="heading-1"><span class="koboSpan" id="kobo.972.1">Join our community on Discord</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.973.1">Join our community’s Discord space for discussions with the author and other readers:</span></p>
<p class="normal"><a href="https://packt.link/mlsah "><span class="url"><span class="koboSpan" id="kobo.974.1">https://packt.link/mlsah</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.975.1"><img alt="" role="presentation" src="../Images/QR_Code70205728346636561.png"/></span></p>
</div>
</body></html>