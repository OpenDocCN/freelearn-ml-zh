- en: Classification Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Classification problems involve detecting patterns in data and using those
    patterns to assign a data point to a group of similar data points. If that''s
    too abstract, here are some examples of classification problems: analyzing an
    email to determine whether it''s spam; detecting the language of a piece of text;
    reading an article and categorizing it as finance, sports, politics, opinion pieces,
    or crime; and determining whether a review of your product posted on Twitter is
    positive or negative (this last example is commonly called **sentiment analysis**).'
  prefs: []
  type: TYPE_NORMAL
- en: Classification algorithms are tools that solve classification problems. By definition,
    they are supervised learning algorithms, as they'll always need a labeled training
    set to build a model from. There are lots of classification algorithms, each designed
    with a specific principle in mind or for a particular type of input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll discuss four classifiers: **k-Nearest Neighbors** (**KNN**),
    Naive Bayes, **Support Vector Machines** (**SVMs**), and random forest. Here''s
    a brief introduction to each of the algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: The KNN algorithm is one of the simplest classifiers, and works well when your
    dataset has numerical features and clustered patterns. It is similar in nature
    to the k-means clustering algorithm, in that it relies on plotting data points
    and measuring distances from point to point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Naive Bayes classifier is an effective and versatile classifier based on
    Bayesian probability. While it can be used for numerical data, it's most commonly
    used in text classification problems, such as spam detection and sentiment analysis.
    Naive Bayes classifiers, when implemented properly, can be both fast and highly
    accurate for narrow domains. The Naive Bayes classifier is one of my go-to algorithms
    for classification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVMs are, in spirit, a very advanced form of the KNN algorithm. The SVM graphs
    your data and attempts to find dividing lines between the categories you've labeled.
    Using some non-trivial mathematics, the SVM can linearize non-linear patterns,
    so this tool can be effective for both linear and non linear data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests are a relatively recent development in classification algorithms,
    but they are effective and versatile and therefore a go-to classifier for many
    researchers, myself included. Random forests build an ensemble of decision trees
    (another type of classifier we'll discuss later), each with a random subset of
    the data's features. Decision trees can handle both numerical and categorical
    data, they can perform both regression and classification tasks, and they also
    assist in feature selection, so they are becoming many researchers' first tool
    to grab when facing new problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k-Nearest Neighbor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The KNN is a simple, fast, and straightforward classification algorithm. It
    is very useful for categorized numerical datasets where the data is naturally
    clustered. It will feel similar in some ways to the k-means clustering algorithm,
    with the major distinction being that k-means is an unsupervised algorithm while
    KNN is a supervised learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you were to perform a KNN analysis manually, here''s how it would go: first,
    plot all your training data on a graph, and label each point with its category
    or label. When you wish to classify a new, unknown point, put it on the graph
    and find the *k* closest points to it (the *nearest neighbors*). The number *k*
    should be an odd number in order to avoid ties; three is a good starting point,
    but some applications will need more and some can get away with one. Report whatever
    the majority of the *k* nearest neighbors are classified as, and that will be
    the result of the algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the *k* nearest neighbors to a test point is straightforward, but can
    use some optimizations if your training data is very large. Typically, when evaluating
    a new point, you would calculate the Euclidean distance (the typical, high school
    geometry distance measure we introduced in [Chapter 4](84fd2c4d-41b4-46c4-82e5-4d8e55bb0066.xhtml),
    *Grouping with Clustering Algorithms*) between your test point and every other
    training point, and sort them by distance. This algorithm is quite fast because
    the training data is generally not more than 10,000 points or so.
  prefs: []
  type: TYPE_NORMAL
- en: If you have many training examples (in the order of millions) or you really
    need the algorithm to be lightning-fast, there are two optimizations you can make.
    The first is to skip the square root operation in the distance measure, and use
    the squared distance instead. While modern CPUs are very fast, the square root
    operation is still much slower than multiplication and addition, so you can save
    a few milliseconds by avoiding the square root. The second optimization is to
    only consider points within some bounding rectangle of distance to your test point;
    for instance, only consider points within +/- 5 units in each dimension from the
    test point's location. If your training data is dense, this optimization will
    not affect results but will speed up the algorithm because it will avoid calculating
    distances for many points.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the KNN algorithm as a high-level description:'
  prefs: []
  type: TYPE_NORMAL
- en: Record all training data and their labels
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Given a new point to evaluate, generate a list of its distances to all training
    points
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sort the list of distances in order of closest to farthest
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throw out all but the *k* nearest distances
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine which label represents the majority of your *k* nearest neighbors;
    this is the result of the algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A more efficient version avoids maintaining a large list of distances that need
    to be sorted by limiting the list of distances to *k* items. Let's now write our
    own implementation of the KNN algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Building the KNN algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since the KNN algorithm is quite simple, we''ll build our own implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new folder and name it `Ch5-knn`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To the folder, add the following `package.json` file. Note that this file is
    a little different from previous examples because we have added a dependency for
    the `jimp` library, which is an image processing library that we''ll use in the
    second example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Run the `yarn install` command to download and install all the dependencies,
    and then create subfolders called `src`, `dist`, and `files`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the `src` folder, create an `index.js` file and an `knn.js` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will also need a `data.js` file. For these examples, I'm using a larger
    dataset than can be printed in this book, so you should take a minute to download
    the `Ch5-knn/src/data.js` file from this book's GitHub account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the `knn.js` file. Like the k-means example in the previous
    chapter, we will need a distance-measuring function. Let''s use the one from [Chapter
    4](84fd2c4d-41b4-46c4-82e5-4d8e55bb0066.xhtml), *Grouping with Clustering Algorithms*;
    add the following to the beginning of `knn.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you really need a performance optimization for your KNN implementation, this
    is where you might omit the `Math.sqrt` operation and return just the squared
    distance. I reiterate, however, that because this is such a fast algorithm by
    nature, you should only need to do this if you're working on an extreme problem
    with a lot of data or with very strict speed requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s add the stub of our KNN class. Add the following to `knn.js`,
    beneath the distance function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The constructor accepts three arguments: the `k`*,* or the number of neighbors
    to consider when classifying your new point; the training data split up into the
    data points alone; and a corresponding array of their labels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to add an internal method that considers a test point and calculates
    a sorted list of distances from the test point to the training points. We''ll
    call this a **distance map**. Add the following to the body of the KNN class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This method could be easier to read, but the simpler version is not efficient
    for very large training sets. What we're doing here is maintaining a list of points
    that might be the KNNs and storing them in `map`. By maintaining a variable called
    `maxDistanceInMap`, we can loop over every training point and make a simple comparison
    to see whether the point should be added to our candidates list. If the point
    we're iterating over is closer than the farthest of our candidates, we can add
    the point to the list, re-sort the list, remove the farthest point to keep the
    list small, and then update `mapDistanceInMap`.
  prefs: []
  type: TYPE_NORMAL
- en: If that sounds like a lot of work, a simpler version might loop over all points,
    add each one with its distance measurement to the map, sort the map, and then
    return the first *k* items. The downside of that implementation is that for a
    dataset of a million points, you'd need to build a distance map of a million points
    and then sort that giant list in memory. In our version, you only ever hold *k*
    items as candidates, so you never need to store a separate million-point map.
    Our version does require a call to `Array.sort` whenever an item is added to the
    map. This is inefficient in its own way, as the sort function is called for each
    addition to the map. Fortunately, the sort operation is only for *k* items, where
    *k* might be something like 3 or 5\. The computational complexity of the sorting
    algorithm is most likely `O(n log n)` (for a quicksort or mergesort implementation),
    so it only takes about 30 data points for the more sophisticated version to be
    more efficient than the simple version when *k = 3*, and for *k = 5*, that happens
    at around 3,000 data points. However, both versions are so fast that for a dataset
    smaller than 3,000 points, you won't notice the difference.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we tie the algorithm together with a `predict` method. The `predict`
    method must accept a test point, and at the very least return the determined label
    for the `point`. We will also add some additional output to the method, and report
    the labels of the *k* nearest neighbors as well as the number of votes each label
    contributed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following to the body of the KNN class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This method requires a little bit of datatype juggling in JavaScript, but is
    simple in concept. First, we generate our distance map using the method we just
    implemented. Then, we remove all data except for the *k* nearest points and store
    that in a `votes` variable. If you're using 3 as *k*, then `votes` will be an
    array of length three.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our *k* nearest neighbors, we need to figure out which label
    represents the majority of the neighbors. We''ll do this by reducing our votes
    array into an object called `voteCounts`. To get a picture of what we want `voteCounts`
    to look like, imagine that we''re looking for the three nearest neighbors and
    the possible categories are `Male` or `Female`. The `voteCounts` variable might
    look like this: `{"Female": 2, "Male": 1}`.'
  prefs: []
  type: TYPE_NORMAL
- en: Our job is still not done, however—after reducing our votes into a vote-count
    object, we still need to sort that and determine the majority label. We do this
    by mapping the vote counts object back into an array and then sorting the array
    based on vote counts.
  prefs: []
  type: TYPE_NORMAL
- en: There are other ways to approach this problem of tallying votes; any method
    you can think of will work, as long as you can return the majority vote at the
    end of the day. I like thinking about data in terms of structure and the transformations
    necessary to get from one structure to the next, but as long as you can report
    the top vote, the algorithm will work.
  prefs: []
  type: TYPE_NORMAL
- en: That's all we need to do in the `knn.js` file. The algorithm is complete, requiring
    fewer than 70 lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Let's set up our `index.js` file and get ready to run some examples. Remember
    that you need to download the `data.js` file first—see Packt's GitHub account
    or my personal GitHub account at [https://github.com/bkanber/MLinJSBook](https://github.com/bkanber/MLinJSBook).
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following to the top of `index.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's try our algorithm out on a few simple examples.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1 – Height, weight, and gender
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'KNN, like k-means, can work on high-dimensional data—but, like k-means, we
    can only graph example data in a two-dimensional plane so we''ll keep our examples
    simple. The first question we''ll tackle is: can we predict a person''s biological
    sex given only their height and weight?'
  prefs: []
  type: TYPE_NORMAL
- en: 'I''ve downloaded some data for this example from a national longitudinal survey
    on people''s perception of their weight. Included in the data are the respondents''
    height, weight, and gender. This is what the data looks like, when graphed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39a20c3b-71d0-40d6-b896-6a43a084a953.png)'
  prefs: []
  type: TYPE_IMG
- en: Just by looking at the preceding charted data, you can get a sense as to why
    KNN is so effective at evaluating clustered data. It's true that there's no neat
    boundary between male and female, but if you were to evaluate a new data point
    of a 200 pound, 72 inches-tall person, it's clear that all the training data around
    that point is male and it's likely your new point is male, too. Conversely, a
    new respondent at 125 pounds and a height of 62 inches is well into the female
    area of the graph, though there are a couple of males with those characteristics
    as well. The middle of the graph, around 145 pounds and 65 inches tall, is the
    most ambiguous, with an even split of male and female training points. I would
    expect the algorithm to be uncertain about new points in that area. Because there
    is no clear dividing line in this dataset, we would need more features or more
    dimensions to get a better resolution of the boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, let''s try out a few examples. We''ll pick five points that we
    expect to be definitely male, definitely female, probably male, probably female,
    and indeterminable. Add the following code to `index.js`, beneath the two import
    lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Run `yarn start` from the command line and you should see the following output.
    Since the KNN is not stochastic, meaning it does not use any random conditions
    in its evaluation, you should see exactly the same output as I do—with the possible
    exception of the ordering of votes and their indexes, if two votes have the same
    distance.
  prefs: []
  type: TYPE_NORMAL
- en: If you get an error when you run `yarn start`, make sure your `data.js` file
    has been correctly downloaded and installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the output from the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm has determined genders just as we would have done, visually, by
    looking at the chart. Feel free to play with this example more and experiment
    with different values of `k` to see how results might differ for any given test
    point.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at a second example of KNN in action. This time, we'll choose
    a problem where `k = 1` really shines.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2 – Decolorizing a photo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The KNN algorithm is very susceptible to local noise and isn't very useful when
    there is a lot of overlap between classes expected. It is typically not very useful
    for more advanced tasks, such as psychographic, demographic, or behavioral analysis.
    But it's a very useful tool to keep handy in your toolbox, because it can assist
    with lower-level tasks very easily.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we'll use our KNN class to de colorize a photo. Specifically,
    we're going to take colorful input photos and restrict them to a color scheme
    of only 16 colors. We'll use KNN here to select the appropriate replacement color
    for a pixel, given that pixel's original color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our workflow will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Use the `jimp` library to read an input image
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Loop over each pixel in the image and:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the most similar color in our 16-color scheme
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace that pixel with the new color
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a new output file, based on the 16-color scheme
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we start, *verify* that the following exists in your `data.js` file.
    If you downloaded the `data.js` file from the GitHub for this book, then this
    should already be in there. However, if you sourced your gender survey data from
    a different place, you will need the following in the `data.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The preceding color definitions represent a common color scheme of 16 colors.
    You can also experiment with color schemes on your own; you can use this approach
    to colorize to shades of blue, or to warm colors, or to sepia tones, and so on.
    You can also allow for far more than 16 colors by increasing the training data
    size.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by writing a couple of helper functions. Create a new file, in
    the `src` folder, called `decolorize.js`. Make sure you added `jimp` to your `package.json`—if
    you''re unsure, run `yarn add jimp` from the command line. Add the following imports
    to the top of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, create and export a function that accepts an image filename and writes
    a new file with the decolorized image. I''ve left some gentle comments in the
    code snippet that describe the workflow; most of the code is just juggling data
    formats. In general, our approach is to open and read the input file, iterate
    over all pixels, use a KNN to find a substitute color for that pixel, write the
    new color to the pixel, and then finally write a new output file using the modified
    colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We now have a function that will accept a filename and create a new de-colorized
    photo. If you haven't already, create a folder called `files` in the `Ch5-knn`
    directory. Find a few of your favorite pictures and add them to the `files` folder.
    Or, you can use the image examples from the book's GitHub, which are `landscape.jpeg`,
    `lily.jpeg`, and `waterlilies.jpeg`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, open up `index.js` and add the following to the bottom of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you are using your own example files, make sure to update the filenames shown
    in bold in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code with `yarn start` and you should see output like the following
    (you may have the results from the other KNN experiment in your output, as well):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If there are any errors with filenames or permissions, resolve them. Look in
    the `files` folder for your new photos. I don't know which format you're reading
    this book in and how these images will look to you, but the following is my `landscape.jpeg`
    file, original and processed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The original:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e0e320d-9170-48f2-8979-7553f8e10b02.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the de-colorized version:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be92c1f9-c64a-47f7-ba1c-31d0acb46818.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: I think it did a very good job on the foreground and the scenery, however, the
    limited color palette definitely affects the sky, water, and mountains in the
    background. Try adding another 8 or 16 colors to the training data to see what
    happens.
  prefs: []
  type: TYPE_NORMAL
- en: I like this project as a KNN example because it shows you that **machine learning**
    (**ML**) algorithms don't always have to be used for sophisticated analyses. Many
    of them can be used as part of your everyday toolbox, trained with smaller models
    to help you with simpler data-processing tasks.
  prefs: []
  type: TYPE_NORMAL
- en: I should also make a note here about measuring the distance between colors.
    The approach we have taken, using the Euclidean distance formula to measure distances
    between RGB values, is not perceptually accurate. The RGB space is slightly warped
    when it comes to human visual perception, so our Euclidean distance measurements
    are not totally accurate. For our purposes, they are close enough because we are
    downgrading to a very low resolution. If you need perceptually-accurate image
    processing, you will either need to transform all RGB values into a more accurate
    color space, such as *Lab*,or update your distance function to measure perceptual
    distance rather than just the geometric distance between points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s move on from KNN and look at a more sophisticated way to classify objects,
    based on centuries-old probability theory that is still powerful today: Bayesian
    classification.'
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Naive Bayes classifier is a type of probabilistic classifier, or an algorithm
    that assigns a probability distribution to the potential outcomes. As opposed
    to a binary classification, such as `Male` or `Female`, the probabilistic classifier
    tells you there is an 87% chance this data point is `Male` and a 13% chance it
    is `Female`.
  prefs: []
  type: TYPE_NORMAL
- en: Not all probabilistic classifiers are Bayesian, nor are they all necessarily
    naive. The term *Naive*, in this context, is not a veiled insult to the classifier—it's
    a mathematical term that has a meaning in probability theory, which we'll discuss
    further later. The term *Bayes* or *Bayesian* means that the principles used in
    the classifier were first published by Reverend Thomas Bayes, an 18th century
    mathematician, popular for his *Bayes theorem *in probability theory.
  prefs: []
  type: TYPE_NORMAL
- en: Let's first have a probability refresher. First, you should know that probability
    can work with both *continuous distributions* and *discrete distributions*. Continuous
    distributions are those where your variable is a number and can have any value.
    Discrete distributions have only a fixed number of possible states, even if that
    number is large. Continuous values are things such as *activity of 54.21 minutes
    per week; $23.34 per share; 18 total logins*. Discrete values are *true*/*false*;
    *Hollywood*, *gossip*, *politics*, *sports*, *local events*, or *world news*,
    or even the frequency of individual words in an article. Most of the theorems
    in probability can be used both for continuous and discrete distributions, though
    the implementation details between the two will differ.
  prefs: []
  type: TYPE_NORMAL
- en: In discrete probability, which we will use for our example, you work with the
    probability of various *events* occurring. An event is a set of possible outcomes
    from an experiment. The classical illustrative example of this involves a pack
    of playing cards; imagine you draw a card at random from a shuffled deck. What's
    the probability that the card you pulled is a heart? When we ask this question,
    we're asking about the probability of a certain event, specifically *that the
    card is a heart*. We can give our event a label, such as `H` for heart, and then
    we can shorten the phrase *probability that the card is a heart* to simply, `P(H)`.
    The answer is 13/52, or 1/4, or 0.25, so you could also say that `P(H) = 0.25`.
    There are many other possible events in our scenario. What's the chance the card
    is the five of diamonds? What's the chance the card is black? What's the chance
    the card is a face card? What's the chance the value is less than five? All of
    those are types of events, and each one has its own probability.
  prefs: []
  type: TYPE_NORMAL
- en: Not all events are independent. For instance, let's say the experiment is *did
    you drink a soda yesterday?*, and we are surveying Americans. We can define the
    event `S` as *drank a soda yesterday*. By surveying everyone in America (or at
    least a representative sample), we find that nearly 50% of respondents said yes!
    (It is actually 48%, according to Yale University.) So we can say that the probability
    of `S` is 50%, or `P(S) = 0.5`. We can also define an event as `S',`, which is
    the probability of the event *did not drink a soda yesterday*, or the inverse.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to develop more insight into citizens'' eating habits, so we add another
    question to the survey: did you eat at a fast food restaurant yesterday? We''ll
    name this event `M`, for McDonald''s, and we find that `P(M) = 0.25`, or a quarter
    of the nation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now ask more sophisticated questions, such as: does eating fast food
    affect whether people drink soda? We can ask about the probability that someone
    drank a soda given that they ate fast food yesterday. This is called the **conditional
    probability** of `S` events given `M`, or `P(S|M)`.'
  prefs: []
  type: TYPE_NORMAL
- en: If we asked the questions about drinking a soda and eating fast food in the
    same survey, then we can calculate `P(S|M)` by finding the probability of a respondent
    doing both events (this is written `P(S ∩ M)`, pronounced *probability of S intersect
    M*), and dividing by `P(M)`. The full formula is `P(S|M) = P(S ∩ M) / P(M)`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that 20% of respondents both drank a soda and ate fast food. We can
    now calculate that `P(S|M) = 0.2 / 0.25 = 0.8`. The probability of having drunk
    a soda yesterday is 80%, given that you ate fast food yesterday.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is *not* the probability that you drank a soda *while* eating
    fast food. To answer that question, you'd have to go to a fast food restaurant
    and survey the people there. Our version is less committal in terms of causation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you want to ask the reverse question: what''s the probability of someone
    having eaten fast food given that they drank a soda yesterday? This is asking
    about `P(M|S)`. We could just reverse the preceding formula, but let''s say that
    we lost the original survey data and can no longer determine `P(S ∩ M)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the Bayes theorem to correctly reverse our probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(M|S) = P(S|M) * P(M) / P(S)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we remember those three values and find that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(M|S) = 0.8 * 0.25 / 0.5  = 0.4*'
  prefs: []
  type: TYPE_NORMAL
- en: The probability that someone ate fast food yesterday, knowing that they drank
    a soda, is 40%. That's up from the baseline of 25% for anyone eating fast food.
  prefs: []
  type: TYPE_NORMAL
- en: How does this apply to naive Bayes classifiers? We use the preceding conditional
    probability theorems to relate features to their respective classes. In a spam
    filter, we ask the question: what's the probability that this document is spam
    given that it has the word *credit *in it*?* And what's the probability this document
    is spam given that it has the word *transfer* in it*?* We ask that question for
    every word in the document, and then we combine those probabilities to get the
    overall probability that the document is spam. The naive Bayes classifier is naive
    because it assumes that the events are all independent. Truthfully, this is a
    bad assumption. Emails with the word *credit *are more likely to also have the
    word *transfer* in them, but in practice it turns out that these classifiers are
    still very accurate despite the incorrect assumption.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We also must briefly discuss the concept of *tokenization*. We will discuss
    tokenization in depth in Chapter 10, *Natural Language Processing in Practice*
    when we discuss natural language programming, but we do need a short introduction
    to it now. Tokenization is the act of breaking up a document into individual *tokens*.
    You can think of a token as a word, but not all words are necessarily tokens and
    not all tokens are necessarily words.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest tokenizer would be to split a document up by spaces. The result
    would be an array of words, including their capitalization and their punctuation.
    A slightly more advanced tokenizer might convert everything to lowercase and remove
    any non-alphanumeric characters. Now the tokens are all lowercase words, numbers,
    and words with numbers in them. Your tokenizer can remove common words, such as *and*
    and *the*—this is called **stopword filtering***.* You can also *stem* as part
    of your tokenizer, which is to remove extraneous endings from a word. For instance
    *parties*, *partied*, and *party* might all become *parti*. This is a great dimensionality
    reduction technique, and helps your classifier focus on the meaning of words rather
    than the particular tense or usage. You can take it even farther by *lemmatizing*,
    which is similar to stemming but actually grammatically transforms words to their
    root form, so that *running*, *runs*, and *ran* would all become *run*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tokenization can take more advanced forms. A token does not need to be a single
    word; it can be pairs or trios of words. These are called **bigrams** and **trigrams**,
    respectively. Tokens can also be generated from metadata. Email spam filters,
    in particular, do very well when some information from the message''s headers
    are included as tokens: whether the email passed or failed its SPF check, whether
    it has a valid DKIM key, the sender''s domain, and so on. Tokenizers can also
    modify tokens from certain fields; for instance, it was found that prefixing tokens
    from email subject lines (as opposed to body content) improved spam filtering
    performance. Rather than tokenizing *buy pharmaceuticals now* as *buy*, *pharmaceuticals*,
    *now*, you can tokenize those as *SUBJ_buy*, *SUBJ_pharmaceuticals*, *SUBJ_now*.
    The effect of this prefixing is to allow the classifier to consider subject and
    body words separately, which may increase performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Do not underestimate the importance of the tokenizer. Often, you can get significant
    accuracy improvements by being thoughtful about your tokenizer algorithm. In this
    example, we'll use a simple, intuitive one that is still quite effective.
  prefs: []
  type: TYPE_NORMAL
- en: Building the algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s now build the naive Bayes classifier. These are the steps that are to
    be followed to build the algorithm :'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new folder for the project called `Ch5-Bayes`. As usual, create `src`
    and `data` and `dist` folders, and add the following `package.json` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Once you've added the `package.json` file, run `yarn install` from the command
    line to install all the project dependencies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to the book's GitHub account, and download the four files in the `data`
    folder. They should be called `train_negative.txt`, `train_positive.txt`, `test_negative.txt`,
    and `test_positive.txt`. These files contain reviews of movies from [https://www.imdb.com/](https://www.imdb.com/),
    and are pre-sorted into positive reviews and negative reviews, using IMDB's star-rating
    system. We will use this data to train and later validate an algorithm to detect
    movie review sentiment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `bayes.js` file in the `src` folder. Add the following tokenizer function
    to the top of the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This function accepts a string as an input, and returns an array of tokens as
    the output. The string is first converted to lowercase, because our analysis is
    case-sensitive. Then any characters that are not word or number characters are
    removed and replaced with spaces. We split the string up by spaces to get an array
    of tokens. Next, we filter out any tokens that are three characters or shorter
    (so the words *the* and *was* would be removed, while words like *this* and *that*
    are preserved). The last line of the tokenizer filters out non-unique tokens;
    we will consider only the existence of words in documents, not the number of times
    those words are used.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `filter` function in the tokenizer does not preserve word order.
    To preserve word order, you would need to add `.reverse()` before and after the
    final filter line. However, our algorithm doesn't consider word order, so preserving
    it is not necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `BayesClassifier` class and export it from `bayes.js`. Add the following
    to the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The constructor for the classifier accepts only a `tokenizer` function, however,
    it defaults to the simple preceding tokenizer we created. Making the tokenizer
    configurable like this will allow you to experiment with better tokenizers that
    fit your particular dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Training a Naive Bayes classifier is a straightforward process. First, simply
    count the number of documents in each category that you have seen. If your training
    set has 600 positive movie reviews and 400 negative movie reviews, then you should
    have 600 and 400 as your document counts, respectively. Next, tokenize the document
    to be trained. You must always make sure to use the same tokenizer during training
    as you do during evaluation. For each token in the training document, record how
    many times you've seen that token amongst all documents in the category. For example,
    if your training data has 600 positive movie reviews and the word *beautiful* appears
    in 100 of them, you would need to maintain a count of 100 for the token *beautiful* in
    the *positive* category. If the token *beautiful* only appears three times in
    your negative review training data, then you must maintain that count separately.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s translate this into code. It''s a very simple operation, but we are
    also dividing up the work between many small count and incrementing functions;
    we will use these counting functions in our evaluation stage as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `train()` method is quite simple: increment the document
    count for the given label (for example, `spam` or `not spam`, `positive sentiment`
    or `negative sentiment`); then, for each token in the document, increment the
    token count for the given label (for example, *beautiful* was seen 100 times in
    positive-sentiment documents, and was seen three times in negative-sentiment documents).
    These counts are maintained in an instance variable called `this.database` in
    the `BayesClassifier` class.'
  prefs: []
  type: TYPE_NORMAL
- en: In order to make a prediction on a new document, we'll need to consider each
    of the labels we encountered during training separately, calculate a probability
    for that label, and return the most probable label. Let's work backwards in terms
    of implementing the prediction; we'll start by adding the `predict` method and
    then work backwards, filling in all the other methods we'll need.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, add the following `predict` method to the `BayesClassifier` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This method accepts an input string or document, and returns a `result` object
    with the most likely label or category, the probability of that label or category,
    and an array of all the probabilities for all labels encountered during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add the method that `predict` relies upon to calculate the probability
    of each label on the input document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This method tokenizes the input text, and then generates an array of all labels
    and their probabilities, sorted in order of most probable to least probable. You
    will now need to add these two methods to the class—first, the simple `getAllLabels()`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'And then add the more complex `calculateLabelProbability`, which is responsible
    for calculating the probability of an individual label fitting a document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The inline comments in the `calculateLabelProbability` method illuminate the
    specifics of how the method works, but the basic goal of this step is to calculate
    a probability for each token in the document, and then to combine the individual
    token probabilities into one overall probability for the label.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if a movie review states *beautiful [but] awful garbage*, this
    method is responsible for looking at all of the tokens (*but* is omitted by the
    tokenizer) and determining how well they fit a given label (for example, *positive*
    or *negative*).
  prefs: []
  type: TYPE_NORMAL
- en: Let's imagine we're running this method for the *positive *category label. The
    word *beautiful* would get a strong score, maybe 90%, but the tokens *awful* and
    *garbage* would both get weak scores, for instance 5%. This method would then
    report that the probability of the *positive* label is low for this document.
    On the other hand, when this method is run for the *negative* category label,
    the *beautiful* token gets a low score but both *awful* and *garbage* get high
    scores, so the method will return a high probability of the document being negative.
  prefs: []
  type: TYPE_NORMAL
- en: This method involves a couple of tricks. The first one is an accuracy enhancement.
    If a token is ambiguous (a word such as *that* or *movie*, something that applies
    equally to all categories), it is removed from consideration. We do this by filtering
    out token scores that are close to 50%; specifically, we ignore all tokens that
    have a score between 35-65%. This is a very effective technique and increases
    accuracy by about 10%. The reason it works so well is that it filters out noise
    in those marginal tokens. If the word *movie* has a positive score of 55% but
    is generally seen in both positive and negative documents, it'll skew all documents
    toward the positive category. Our approach is to instead only consider the most
    impactful tokens.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second trick is our log sum approach. Normally, the way to combine individual
    words or token probabilities into an overall probability looks like this—assuming
    you already have an array variable called `tokenScores`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Put another way, assume you have probabilities for individual tokens called
    `p1`, `p2`, `p3`, ... `pN`; the way to get the combined probability of all those
    tokens would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This approach has some issues when dealing with small, floating-point numbers.
    If you start multiplying small, floating-point numbers by each other, you risk
    creating numbers so small that floating-point math can't deal with it, and you
    get *floating-point underflow*, or NaN in JavaScript. The solution is to convert
    this calculation to log space, and manage the whole calculation by adding natural
    log values of each of the probabilities and removing the log at the end.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final piece of the puzzle is to generate the probabilities of each individual
    token given a label. This is where the Bayes theorem truly comes into play. What
    we''re looking for is a probability like `P(L|W)`, or the probability that the
    document has a **label** given a **word**. We need this probability for each token
    in the document, and for each label that we''re considering. However, we don''t
    have the `P(L|W)` value on hand, so we can use Bayes'' theorem to get an equivalent
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(L|W) = P(W|L)P(L) / P(W|L)P(L) + P(W|L'')P(L'')*'
  prefs: []
  type: TYPE_NORMAL
- en: This may look complicated, but it's not bad. We are transforming the `P(L|W)` goal
    into much easier probabilities, such as `P(W|L)` (the probability the word appears
    given a label, or its frequency in that label) and `P(L)` (the probability of
    any given label). The denominator also uses the inverse probabilities, `P(W|L')`
    (the probability the word appears in any other label) and `P(L')` (the probability
    of any other label).
  prefs: []
  type: TYPE_NORMAL
- en: We make this transformation because we can get the word frequencies just by
    counting tokens and labels when we see them during training; we do not need to
    record which tokens appear in which documents, and we can keep our database simple
    and fast.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding expression is what we've been calling the *token score*, or the
    probability that a document has a label, given that the document has a word in
    it. Making things a little more concrete, we can ask the question `P("positive
    review" | "beautiful")`, or the probability that a document is a positive movie
    review, given that the word beautiful is in it.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a 50/50 chance of reviews being positive or negative, and we see
    the word *beautiful* in 10% of positive reviews and only 1% of negative reviews,
    then our `P(L|W)` probability is around 91%. (The calculation for this was `(0.1
    * 0.5) / ( (0.1 * 0.5) + (0.01 * 0.5) )`, using the preceding formula.) You can
    interpret this 91% figure as the *positivity* of the word *beautiful*. By analyzing
    all words in a document in this manner, we can combine their positivity scores
    to get an overall probability that a document is positive. The same holds for
    any type of classification, whether it's positive/negative movie reviews, spam/ham
    emails, or English/French/Spanish language detection.
  prefs: []
  type: TYPE_NORMAL
- en: There is one other thing we need to consider when calculating token scores.
    What do we do if we've never seen a token before? Or if we've only seen it once
    or twice? The best approach for us is to adjust the token score that we calculate
    by a weighted average; we want to weight the average so that rare words are pulled
    toward a 50/50 score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s implement all of the preceding logic. This method is long, but as you
    can see, much of the work is simply grabbing the correct counts for the various
    variables we need to calculate. We also define a *strength* for our rare word
    weighting; we define the strength as three so that we must see the token in question
    three times for it to have an equivalent weight as the default 50/50 weighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To review the way this algorithm works, here is a brief summary:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To train:'
  prefs: []
  type: TYPE_NORMAL
- en: Accept an input document and known label or category
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tokenize the input document into an array of tokens
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Record the total number of documents you've seen for this specific label
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each token, record the number of times you've seen this token *with this
    specific label*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To predict:'
  prefs: []
  type: TYPE_NORMAL
- en: Accept an input document and tokenize it
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each possible label (all the labels you encountered during training), and
    for each token in the document, calculate the *token score* for that token (mathematically,
    the probability of a document having that label, given that specific token)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You may need to filter token scores for significance
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You may need to adjust token scores for rare words
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each possible label, combine the token scores into a single, overall label
    probability (for example, the probability that the document is in this category
    or label)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Report the label with the highest overall probability
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With all of our code added, we're ready to train and test our Naive Bayes classifier.
    We'll train it on IMDB movie reviews, and try to guess the sentiment of never-before-seen
    reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3 – Movie review sentiment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We're going to use our Naive Bayes classifier to tackle the *sentiment analysis*
    problem, or the problem of inspecting a piece of text and determining whether
    it has an overall positive or negative sentiment. This is a common analysis done
    in advertising, marketing, and public relations; most brand managers want to know
    whether people on Twitter have good things or bad things to say about their brand
    or product.
  prefs: []
  type: TYPE_NORMAL
- en: The training data for this example will come from [https://www.imdb.com/](https://www.imdb.com/).
    We'll train our classifier on positive and negative movie reviews, and then use
    our classifier to check untrained (but pre-labeled) reviews to see how many it
    gets right.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you haven''t done so yet, download the data files from the `data` directory
    from this project''s GitHub page. You will need all four text files: `train_positive.txt`,
    `train_negative.txt`, `test_positive.txt`, and `test_negative.txt`. We will use
    the two training files for training, and the two test files for validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create an `index.js` file in the `src` folder. Add the following code
    to the top of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We import the `readline` and `fs` libraries to help us process the training
    files. Next, create a `utility` function to help us train the classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This `helper` function accepts a filename, a label, and an instance of a `BayesClassifier`
    class. It reads an input file line by line, and trains the classifier on each
    line for the given label. All the logic is wrapped up in a promise so that we
    can externally detect when the trainer has completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, add a helper utility to test the classifier. In order to test the classifier,
    it must be trained first. The testing function will open up a test file with a
    known label, and test each line in the file using the classifier''s `predict`
    method. The utility will count how many examples the classifier got right and
    how many it got wrong, and report back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We also wrap this in a promise, and make sure to deliver the results as part
    of the resolution of the promise, so we can inspect the results from without.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, add some bootstrap code. This code will train the classifier on the
    two training files, wait for training to complete, and then test the classifier
    on the two test files, reporting the overall results when finished:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this code is added, you can run the program by issuing `yarn start` from
    the command line. You should see output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This simple, probabilistic classifier has an accuracy of over 91%! A 9% error
    rate may not seem impressive, but in the ML world this is actually a very good
    result, especially considering the ease of implementation and speed of operation
    of the classifier. These results are why the Naive Bayes classifier is so popular
    when classifying text. With more thoughtful tokenization, especially in narrow
    fields, such as spam detection, you can get the accuracy of a Naive Bayes classifier
    over 95%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what an individual example looks like. You can add the following
    code to the `index.js` file if you would like to test out some documents on your
    own:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the preceding code results in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The classifier works as expected. Our strongly negative statement has a 97%
    probability of being negative. Our positive statement has an 86% probability of
    being positive. And our indifferent statement, even though it returns the negative
    label, also reports an even 50/50 probability split between positive and negative
    sentiments.
  prefs: []
  type: TYPE_NORMAL
- en: We did all this, and achieved great accuracy, by simply counting the number
    of times we saw words in documents and using centuries-old probability theory
    to interpret the data. We didn't need a neural network, an advanced framework,
    or a deep natural language programming knowledge to get these results; for these
    reasons, the Naive Bayes classifier should be one of the core algorithms you pay
    attention to when researching ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following sections, we''ll take a look at two more classification algorithms
    that should not be ignored: the SVM and the random forest.'
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An SVM is a numerical classifier that in some ways is similar to the KNN algorithm,
    although the SVM is far more mathematically advanced. Rather than comparing a
    test point to the points closest to it, an SVM attempts to draw boundary lines
    between the classes of data points, creating regions where all points inside that
    region will be considered a member of that class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this image (from Wikipedia''s article on SVMs). The two categories
    of data points are separated by a straight line. The line that separates the classes
    is chosen as the line of *maximum margin*, meaning this dividing line has the
    most room on either side of it, as compared to any other separating line you can
    draw:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/45f79df8-1acd-4185-971b-6e4054d2de29.png)'
  prefs: []
  type: TYPE_IMG
- en: The SVM, exactly as implemented here, is useful in some limited situations,
    but is not a powerful tool, because it requires that the classes be *linearly
    separable*; that is, it requires that you can draw a straight line through the
    two classes. This SVM is also a *binary classifier*, meaning it only works with
    two categories or classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following data (this image and the one after are both courtesy
    of Shiyu Ji, licensed under Creative Commons CC BY-SA 4.0). While there are only
    two classes, they are not linearly separable; only a circle or ellipse can separate
    the two classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82c62bf3-1bbb-4414-83c3-d57062f504ab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While the SVM has been around since the 1960s, it wasn''t until 1992 that researchers
    figured out how to approach this problem. By using a technique called the **kernel
    trick**, you can transform the non-linearly-separable data into linearly-separable
    data in a higher number of dimensions. In this case, transforming the data through
    a kernel will add a third dimension, and it''s that new third dimension that becomes
    linearly separable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d7619f08-a3f9-402b-a36f-a1ad21502235.png)'
  prefs: []
  type: TYPE_IMG
- en: After applying the kernel trick, the data has been mapped onto three dimensions.
    The class of red data points have been pulled downward in the third dimension,
    while the purple points have been pulled upward. It's now possible to draw a plane
    (the three-dimensional equivalent of a straight line in two dimensions) that separates
    the two categories.
  prefs: []
  type: TYPE_NORMAL
- en: Through appropriate selection of kernels and parameters, the support vector
    machine can work its way through all sorts of shapes of data. While the support
    vector machine will always draw a line, plane, or hyperplane (a higher-dimensional
    version of a plane) through the data—these are always *straight—*the algorithm
    first transforms the data into something that can be separated by straight lines.
  prefs: []
  type: TYPE_NORMAL
- en: There are many types of kernels that can be used with an SVM. Each kernel transforms
    the data in a different manner, and the appropriate selection of kernel will depend
    on the shape of your data. In our case, we will use the *radial basis function
    kernel*, which is a good general-purpose kernel to use for clustered data. The
    SVM itself has settings and parameters that you must tweak, such as the error
    cost parameter, but keep in mind that the kernel you select may also have its
    own configurable parameters. The radial basis function, for instance, uses a parameter
    called **gamma**, which controls the curvature of the kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Because SVMs require a lot of math, we won't attempt to build our own. Instead,
    we'll use an off-the-shelf library with a popular, classical dataset. The dataset
    we'll use is called the `iris flower` dataset. This particular dataset was created
    around 1936 by Edgar Anderson (a botanist) and Ronald Fisher (a statistician and
    biologist). Anderson chose three species of iris flowers, specifically the *Iris
    setosa,* the *Iris versicolor,* and the *Iris virginica*. For each species, Anderson
    chose 50 samples and measured the petal length, petal width, sepal length, and
    sepal width, and recorded the measurements along with the species name (a *sepal*
    is the green leaf that protects the flower bud before it blooms).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Iris` dataset is a common toy or test dataset for many ML algorithms for
    a few reasons. It''s a small dataset: there are only 150 samples, four dimensions
    or features, and three categories. The data is multidimensional, but with only
    four features, it is still easy to visualize and understand intuitively. The pattern
    in the data is also interesting and poses a non-trivial challenge for classifiers:
    one species (*Iris setosa*) is clearly separated from the other two, but *Iris
    versicolor* and *Iris virginica* are more intermingled.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the data is four-dimensional, it cannot be visualized directly, but
    we can plot each combination of two features separately into a grid. This image
    is courtesy of Wikipedian Nicoguaro, and is licensed CC BY 4.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9554a32-a247-4bae-85a1-f90aac3b5203.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see why this dataset would be interesting to researchers. In several
    dimensions, such as sepal length versus sepal width, the *Iris versicolor* and
    *Iris virginica* overlap a great deal; in others, they look nearly linearly separable,
    for instance, in the petal length versus petal width plots.
  prefs: []
  type: TYPE_NORMAL
- en: Let's finally implement an SVM to solve this problem for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new folder called `Ch5-SVM` and add the following `package.json` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Once the file is in place, run `yarn install` to install all the dependencies.
    Rather than using a `data.js` file, we will use the `Iris` dataset that comes
    with the `MLJS` library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create an `src` folder and an `index.js` file. At the top of `index.js`,
    import the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to extract the data from the `IrisDataset` library. This implementation
    of the SVM algorithm requires our labels to be integers (it doesn''t support strings
    as labels), so we must simply map the species names from the dataset to integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also write a simple function that measures accuracy, or more specifically
    *los**s* (or error). This function must accept an array of expected values as
    well as an array of actual values, and return the proportion of incorrect guesses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re now ready to implement the SVM class. We will test our classifier in
    two ways: first, we''ll train the classifier on the full dataset and then test
    it on the full dataset; this will test the algorithm''s ability to fit data. Then
    we will use a cross-validation method to train the classifier on only subsets
    of the data and test it on unseen data; this will test the algorithm''s ability
    to generalize its learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following code to `index.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We initialize the SVM with some reasonable parameters. We choose the radial
    basis function as our kernel, we choose a specific algorithm called **CSVC** for
    our SVM (this is the most common SVM algorithm), and we choose values of 1 for
    cost and 0.25 for gamma. Cost and gamma will both have similar effects on how
    the classifier draws boundaries around your classes: the larger the values, the
    tighter the curves and boundaries around the clusters will be.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `svm.crossValidation` method accepts three arguments: the data, the labels,
    and the number of segments to divide the data into, reserving one segment for
    validation on each pass.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `yarn start` from the command line and you should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: This is a very strong result. The SVM was able to correctly recall 99% of training
    examples, meaning only a couple of data points were guessed incorrectly after
    being fully trained. When crossvalidating, we see a loss of only 3%; only perhaps
    five examples out of 150 were guessed incorrectly. The crossvalidation step is
    important because it more accurately represents what real-world performance would
    be; you should tune your algorithm's parameters so that the crossvalidated accuracy
    is maximized.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is easy to get 100% accuracy for the fully-trained algorithm: we can simply
    overfit the data and memorize the category of each datapoint. Change the values
    of both gamma and cost to 50 and re-run the algorithm. You should see something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: By cranking up the cost and the gamma, we're drawing really tight boundaries
    around our existing data points. With a high enough value of cost and gamma, we
    might even be drawing individual circles around each and every data point! The
    result is a perfect score when testing the fully-trained classifier (for example,
    every training point has been memorized), but an awful score when cross-validating
    the dataset. Our cross-validation uses 80% of the data for training and reserves
    20% for validation; in this case, we've overfit the training data so much that
    the classifier simply cannot categorize unseen data points. The classifier has
    memorized the data, but has not learned from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a rule of thumb, a good starting point for the cost value is around 1\.
    A higher cost will penalize training errors more harshly, meaning that your classification
    boundaries will try to more tightly wrap the training data. The cost parameter
    attempts to balance the simplicity of the boundaries with the recall of the training
    data: a lower cost will favor simpler, smoother boundaries, while a higher cost
    will favor higher training accuracy even if it means drawing more complex boundaries.
    This might lead to large sections of the sample space being misclassified with
    real-world data, especially if your dataset is highly dispersed. A higher cost
    value works better for very tightly clustered and neatly separated data; the more
    you trust your data, the higher you can make the cost. Values between 0.01 and
    100 are most common for the cost parameter, though there are certainly cases where
    you may need a larger or smaller cost.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the gamma value also controls the shape and curvature of the SVM's
    boundaries, however, this value influences the data preprocessing when applying
    the kernel trick to transform the data. The result is similar to that of the cost
    parameter, but arises from a completely different mechanism. The gamma parameter
    essentially controls the influence of a single training example. Lower values
    for gamma will result in smoother, broader boundaries around training points,
    while higher values will result in closer, tighter boundaries. One common rule
    of thumb for gamma is to set it to roughly 1/M, where M is the number of features
    in your data. In our case, we have four features or dimensions in our data, so
    we've set gamma to 1/4 or 0.25.
  prefs: []
  type: TYPE_NORMAL
- en: 'When training an SVM for the first time, you should always use cross-validation
    to tune your parameters. As with any ML algorithm, you''ll have to tune the parameters
    to fit your data set and make sure that you''re sufficiently generalizing the
    problem and not overfitting your data. Tune and test parameters methodically:
    for instance, choose five possible values for cost and five possible values for
    gamma, test all 25 combinations with cross-validation, and choose the parameters
    with the highest accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll take a look at a modern workhorse of ML: the random forest.'
  prefs: []
  type: TYPE_NORMAL
- en: Random forest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The random forest algorithm is modern, versatile, robust, accurate, and is deserving
    of consideration for nearly any new classification task that you might encounter.
    It won't always be the best algorithm for a given problem domain, and it has issues
    with high dimensional and very large datasets. Give it more than 20-30 features
    or more than, say, 100,000 training points and it will certainly struggle in terms
    of resources and training time.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the random forest is virtuous in many ways. It can easily handle features
    of different types, meaning that some features can be numerical and others can
    be categorical; you can blend features such as `number_of_logins: 24` with features
    such as `account_type: guest`. A random forest is very robust to noise and therefore
    performs well with real-world data. Random forests are designed to avoid overfitting,
    and therefore are quite easy to train and implement, requiring less tweaking and
    tuning than other algorithms. Random forests also automatically evaluate the importance
    of each feature of your data, and therefore can help you reduce dimensionality
    or select better features *for free*, so to speak. And while random forests can
    be expensive for high dimensional data, in my experience, most real-world ML problems
    involve only about a dozen features and a few thousand training points, which
    random forests can handle. These virtues make the random forest a great go-to
    algorithm for general-purpose classification tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: I am therefore heartbroken to report that, at the time of writing, I have found
    no high-quality random forest classifiers in the JavaScript ecosystem. Regardless,
    I'm going to continue writing this section—and even show you one existing library
    that I believe may have some bugs or problems—in the hopes that by the time you
    read this everything will be fixed and high-quality random forests will be readily
    available in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: Random forests are a type of *ensemble* classifier built on top of decision
    trees. An ensemble classifier comprises several or many individual classifiers
    that all vote on the prediction. In [Chapter 2](94c3773e-b3a5-4c82-a542-80dd5cf5c094.xhtml),
    *Data Exploration*, we ran the k-means algorithm several times with different
    random initial conditions in order to avoid getting caught in local optima; that
    was a rudimentary example of ensemble classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'A random forest is an ensemble of *decision trees*. You''re probably already
    familiar with decision trees: in everyday life, decision trees are more commonly
    called **flowcharts**. In an ML context, decision trees are automatically trained
    and built by an algorithm, rather than drawn by hand.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s discuss a single decision tree. Decision trees predate random
    forests, but have historically been of only moderate usefulness to ML. The concept
    behind a decision tree is the same as a hand-drawn flowchart. When a decision
    tree evaluates a data point, it''ll check each feature in turn: *is petal length
    less than 1.5 centimeters? If so, check the sepal length; if not, check the petal
    width.* Eventually, the decision tree will come to a final leaf or node where
    no more decisions are possible, and the tree will predict the category of the
    data point.'
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees are automatically trained by using a couple of concepts from
    information theory, such as information gain, entropy, and a metric called **Gini
    impurity**. In essence, these techniques are used to determine what the most important
    branching decisions are. A decision tree wants to be as small and simple as possible,
    so these techniques are used to determine how best to split the dataset between
    decisions and when. Should the first branch in the tree check petal width or sepal
    length? If it checks sepal length, should it split at 2.0 centimeters or 1.5 centimeters?
    Which comparisons will result in the best splits for the whole dataset? This training
    is done recursively, and each feature and each training point is evaluated to
    determine its effect on the whole.
  prefs: []
  type: TYPE_NORMAL
- en: The result is a lightning-fast classifier that is also easy to understand and
    debug. Unlike a neural network, where the influence of each neuron is highly abstract,
    and unlike a Bayesian classifier, which requires skill in probability to understand,
    a decision tree can be rendered as a flowchart and interpreted directly by a researcher.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, a decision tree by itself is not very accurate, they are not
    robust to changes in training data or noise, they can get trapped in local optima,
    and there are certain categories of problems that a decision tree cannot handle
    well (like the classic XOR problem, which will result in a very complex tree).
  prefs: []
  type: TYPE_NORMAL
- en: In the mid-1990s, researchers figured out two new ensemble approaches to decision
    trees. First, the technique of *sample bagging* (or *bootstrap aggregating*) was
    developed. In this approach, you create a number of decision trees, each based
    on a totally random subset of the training data (with replacement), and you use
    the majority vote of all the trees when coming up with a prediction. Bagging works
    because the variance due to noise is high for a single tree, but for many uncorrelated
    trees the noise tends to cancel out. Think of concertgoers singing along to their
    favorite band in an arena—the crowd always sounds in tune because the people singing
    sharp get canceled out by the people singing flat.
  prefs: []
  type: TYPE_NORMAL
- en: The random forest builds on the idea of bagging by not only randomizing the
    samples that are given to each tree, but also the *features* that are given to
    each tree. As opposed to *sample bagging*, you could call this *feature bagging*.
    If you build a random forest of 50 trees for our `Iris` dataset (which has four
    features and 150 data points), you might expect each tree to have only 100 unique
    data points and only two of the four features. Like sample bagging, feature bagging
    serves to decouple each of the decision trees and reduce the overall variance
    of the ensemble. Feature bagging also serves to identify the most important features,
    and if you need to save resources you can always remove the least important features
    from the dataset. When you attempt to predict a data point, each of the 50 trees
    will submit its vote; some trees will be wildly incorrect, but the ensemble as
    a whole will make a very good prediction that is robust to noise.
  prefs: []
  type: TYPE_NORMAL
- en: Let's build a random forest and test our `Iris` data against it. You should
    already have the random forest and cross-validation libraries installed in your
    `package.json` file from the SVM section; if not, you should `yarn add` both `ml-cross-validation`
    and `ml-random-forest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the existing `index.js` file for the `Ch5-SVM` example, import
    the appropriate classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'You should already have `labels` and `data` set up from the SVM section. Now,
    add the following to the bottom of the file, beneath the SVM example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the SVM example, we're evaluating the random forest in two ways.
    We first train the forest on the full training data and evaluate its recall, then
    we use cross-validation to get an idea of its real-world performance. In this
    example, we're using MLJS's cross-validation and confusion matrix tools to evaluate
    the classifier's performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code with `yarn start` and you should see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, the accuracy of this algorithm is very poor. In fact, this performance
    is atypical of random forests, especially for the `Iris` dataset, which should
    be very easy for an algorithm to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: 'I wanted to be certain that these poor results were an implementation problem
    rather than a conceptual one, so I ran the same exact Iris data through a familiar
    random forest library that I use daily, using the same options and parameters,
    and I got very different results: **my random forest has a cross-validated loss
    of 2% only**. Unfortunately, I must blame this poor accuracy not on the random
    forest itself, but this specific implementation of the algorithm. While I did
    spend some time looking into the matter, I was not able to quickly identify the
    issue with this implementation. There is a possibility I am misusing this tool,
    however, it is more likely that there''s a minus sign where there should be a
    plus (or something similarly silly and disastrous) somewhere in the library. My
    personal prediction for the performance of a random forest on the `Iris` dataset
    was around 95% accuracy, my familiar random forest library resulted in 98% accuracy,
    yet this library resulted in only 70% accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: Even worse is the fact that I was unable to find a single random forest library
    in JavaScript that works for the `Iris` dataset. There are a couple of random
    forest libraries out there, but none that are modern, maintained, and correct.
    Andrej Karpathy has an abandoned random forest library that seems to work, but
    it can only handle binary classifications (only 1 and -1 as labels), and a few
    other random forest libraries are limited in similar ways. The `MLJS` random forest
    library that we used previously is the closest thing to a working, maintained
    library that I've found, so I hope the issue—whatever it is—will be discovered
    and resolved by the time you read this.
  prefs: []
  type: TYPE_NORMAL
- en: I do not want you to be discouraged from using random forests. If you are working
    in languages other than JavaScript, there are many random forest libraries available
    to you. You should become familiar with them as they'll quickly become your go-to
    first choice for the majority of classification problems. In terms of JavaScript,
    while random forests are harder to build from scratch than Bayesian classifiers,
    they are still quite achievable. If you are able to correctly implement a decision
    tree, or port one from a different language, building a random forest becomes
    very easy—the trees do most of the work in the forest.
  prefs: []
  type: TYPE_NORMAL
- en: While JavaScript's ML toolset is advancing all the time, this random forest
    example perfectly highlights that there's still work to be done. You must proceed
    cautiously. I started writing this example with the expectation of 95% accuracy
    or greater, based on my prior experience with random forests. But what if I had
    no expectations or experience going into it? Would I have just accepted the 70%
    accuracy from this tool? Would I have convinced myself that a random forest is
    the wrong tool for the job? Would it have discouraged me from using random forests
    in the future? Maybe! The ML in the JavaScript ecosystem will have more land mines
    like this one; look out for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we finish this chapter, I would like to revisit the confusion matrix
    we just saw, as this may be a new concept for you. We discussed precision, recall,
    and accuracy in an earlier chapter. The confusion matrix is the raw data from
    which these values can be derived for any classification. Here''s the confusion
    matrix from the random forest, again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'If we organize this into a table, it might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Guessed *I. setosa*** | **Guessed *I. versicolor*** | **Guessed *I.
    virginica*** |'
  prefs: []
  type: TYPE_TB
- en: '| Actual *I. setosa* | 43 | 6 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Actual *I. versicolor* | 8 | 11 | 31 |'
  prefs: []
  type: TYPE_TB
- en: '| Actual *I. virginica* | 1 | 2 | 47 |'
  prefs: []
  type: TYPE_TB
- en: The confusion matrix is the matrix (or table) of guesses versus actual categories.
    In a perfect world, you want the confusion matrix to be all zeros except for the
    diagonal. The confusion matrix tells us that the random forest did a pretty good
    job of guessing *Iris setosa* and *Iris virginica*, but it got most *Iris versicolor*
    wrong and incorrectly labeled them as *Iris virginica*. This is not too surprising,
    considering the shape of the data; recall that the latter two species overlap
    quite a bit (however, a random forest still should have been able to resolve this).
  prefs: []
  type: TYPE_NORMAL
- en: 'The code we wrote for the random forest also printed out the individual predictions
    for each data point, which looked like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The numbers are not exactly the same as in the confusion matrix, because these
    predictions came from the fully-trained tree while the confusion matrix came from
    the cross-validation process; but you can see that they are still similar. The
    first 50 predictions should all be 0s (for *Iris setosa*), and they mostly are.
    The next 50 predictions should be all 1s, but they are primarily 2s; the confusion
    matrix tells us the same thing (that most `I. versicolor` were incorrectly labeled
    `I. virginica`). The last 50 predictions should be all 2s, and are for the most
    part correct. The confusion matrix is a more compact and intuitive way of looking
    at the difference between expected and actual guesses, and this is exactly the
    type of information you'll need when fine-tuning an algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In short, the random forest is an excellent classifier algorithm that currently
    has no convincing JavaScript implementation. I encourage you to be part of JavaScript's
    evolution and build your own random forest, or at least keep this algorithm in
    mind for the future.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification algorithms are a type of supervised learning algorithm whose
    purpose is to analyze data and assign unseen data points to a pre-existing category,
    label, or classification. Classification algorithms are a very popular subset
    of ML, and there are many classification algorithms to choose from.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we discussed the simple and intuitive k-nearest-neighbor algorithm,
    which compares a data point to its neighbors on a graph. We discussed the excellent
    and very popular Naive Bayes classifier, which is a classic probability-based
    classifier that dominates the text classification and sentiment analysis problem
    spaces (though it can be used for many other types of problems). We also discussed
    the support vector machine, an advanced geometric classifier that works well for
    non-linearly-separable data. Finally, we discussed the random forest classifier,
    a robust and powerful ensemble technique that relies on decision trees but unfortunately
    has only a questionable implementation in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed cross-validation and the confusion matrix, two powerful techniques
    for evaluating the accuracy of your models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll look at association rules, which give us some more
    predictive power. If someone buys bread and butter from a store, are they more
    likely to also buy milk, or to buy deli meat? Association rules can help us model
    and interpret those relationships.
  prefs: []
  type: TYPE_NORMAL
