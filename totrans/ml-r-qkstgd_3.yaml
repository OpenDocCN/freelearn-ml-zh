- en: Predicting Failures of Banks - Descriptive Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to understand and prepare our dataset of
    banks for model development. We will answer questions regarding the number of
    variables we have and their quality. Descriptive analysis is crucial to understanding
    our data and for analyzing possible problems with the information quality. We
    will see how to deal with missing values, convert variables into different formats,
    and how to split our data to train and validate our predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with missing and outliers values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing descriptive analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we are going to analyze the types of variables that we have in the dataset.
    For that, we can use the `class` function, which tells us whether a variable is
    a number, a character, or a matrix. For example, the class of the identifying
    number of a bank `ID_RSSD` can be obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This function indicates that this variable is a number without decimals.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can calculate the same information for all the variables and store it using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With `sapply`, calculate iteratively the `class` function on the dataset. Then,
    combine the name of variables with the class in only a data frame, and, finally,
    rename the resulting dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This dataset contains four different types of variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: According to previous steps, we know that only variables with a `Date` format
    collect the date of financial statements.
  prefs: []
  type: TYPE_NORMAL
- en: Getting acquainted with our variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The character type of some variables is not yet clear. Our dataset belongs to
    the financial domain and has only financial ratios as data, so we'd expect variable
    types to be integers or numerical. Let's find out whether we're right.
  prefs: []
  type: TYPE_NORMAL
- en: 'Filter the `character` variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first variable, `UBPRE543`, measures the total losses of a bank providing
    construction loans divided by the total amount of granted construction loans.
    As we suspected, this variable should be numeric, a percentage, or a decimal number.
  prefs: []
  type: TYPE_NORMAL
- en: Finding missing values for a variable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are going to count the number of missing values of this variable, `UBPRE543`,
    over time using this code, with the intention of understanding a little more about
    this variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the ratio displays some missing values from 2002 to 2006.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, we can calculate the number of observations by year in the
    dataset using the `table` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Comparing the two preceding tables, we can see this variable is not informed
    during the first years.
  prefs: []
  type: TYPE_NORMAL
- en: When we started to upload the `.txt` files into R at the beginning of the exercise,
    as this variable was not informed during the first years, R automatically assigns
    a character format to this variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'For later years, when the variable was informed, the variable was read as numeric,
    but the format changed when all the years were merged together into a data frame,
    just when we executed this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The format of variables in the first table used in the `rbind` function, belonging
    to the year 2002, fixed and conditioned the format of the resulting merged table.
  prefs: []
  type: TYPE_NORMAL
- en: Converting the format of the variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now need to convert all these variables into a numeric format. From the
    second variable (the first is the identifier) to the rest of variables in the
    data frame, variables will be explicitly converted to a numeric. The last two
    variables will be also be excluded from this process (`Date` and the target variable).
    Let’s convert variables to a numeric format with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see whether the changes have been applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Before continuing with the development, and once we have solved problems in
    the data formats, in the following section, we will specify which part of the
    sample will be used for the development and which part to validate the model.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the following steps and descriptive analysis will be done only considering
    the training or development sample. Therefore, our data will be divided into two
    samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training set**: It usually represents 70% of the data and it is used to train
    the model (select the parameters that better fit the model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validation set**: It usually represents 30% of the data and it is used to
    measure how well the model performs at making predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partitioning samples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although there are numerous approaches to achieve data partitioning, the `caTools`
    package is one of the most useful. This package contains a function called `sample.split`,
    which generates random numbers to split a sample but keeps the proportion of *bads*
    and *goods* in the original dataset also in the separated samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the `caTools` package uses random numbers, it is convenient to fix a `seed`
    to the replicability of the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, use the `sample.split` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function takes two arguments, the target variable and the partition size,
    in our case, the 70%.
  prefs: []
  type: TYPE_NORMAL
- en: 'It generates an `index` with two values, `TRUE` and `FALSE`, which can be used
    to split the dataset into the two desired samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Checking samples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s check the number of observations and the proportion of failed banks over
    the total banks in each sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As can be seen, train and test samples represent 70% and 30% of the total sample
    respectively. Both samples maintain approximately the same ratio of failed banks,
    that is, 4.7%.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing descriptive analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Descriptive statistical analysis helps you to understand your data properly.
    Although R provides some functions by default to perform basic statistics, we
    will use two better alternatives, the `DataExplorer` and `fBasics` packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the number of variables in the dataset is high, we will create a list with
    the variable names to use in our descriptive functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'A list of 1,492 variables is created. Pass this list to the `basicStats` function
    included in the `fBasics` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can calculate the following descriptives:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of observations (`nobs`)
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of missing values (`NAs`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum value (`Minimum`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximum value (`Maximum`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: First and third quartiles (`1\. Quartile` and `3\. Quartile`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Median (`Median`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sum of the values in the variable (`Sum`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Standard error of the mean (`SE Mean`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lower Confidence Limit (`LCL Mean`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Upper Confidence Limit (`UCL Mean`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance (`Variance`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Standard deviation (`Stdev`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Skewness (`Skewness`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Kurtosis (`Kurtosis`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In this step, we will detect variables with a high number of missing values,
    the range, and dispersion of variables, even if a variable has only a unique value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the number of variables is high, as in our case, this task is not so easy
    and we need some time to analyze variables. A graphical analysis of variables
    is also important and complementary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `plot_histogram` function is very useful for visualizing variables. This
    function is available in the `DataExplorer` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagrams display the output of the preceding code. These diagrams
    show a histogram for some of the variables in the data. Here''s the first page
    of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7fd1cda-5444-4cdd-a4f9-6ed83a3b549a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is the second page of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a3c76d93-275a-4073-a805-f55e516dcd31.png)'
  prefs: []
  type: TYPE_IMG
- en: This analysis of distribution of variables is needed to not only understand
    the distribution of variables but also to detect potential problems.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with outliers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important issue is the detection of outliers in the data. **Outliers** are
    the values that look different than a certain set of observations. Consider an
    example of a normal distribution, wherein the values at the tail of the distribution
    can be known as outliers. They are not so closely related to the nearest value
    of the sample.
  prefs: []
  type: TYPE_NORMAL
- en: There are some algorithms very sensitive to outliers, so its treatment is not
    a trivial issue. Detecting outliers is easier if the number of variables is low.
  prefs: []
  type: TYPE_NORMAL
- en: The winsorization process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the number of outliers is high, we need to to use automatic procedures
    that help to automatically detect them. One of the most effective ways to avoid
    problems with outliers is the **winsorization** **process**.
  prefs: []
  type: TYPE_NORMAL
- en: According to this approach, outliers values will be replaced with fixed values.
    If a variable takes a value smaller than a specific threshold, this value will
    be replaced for this limit. The same situation occurs for high values in the variable.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, these limits or thresholds are based on percentiles. Some percentiles
    such as 1, 2.5, or 5 on the lower range, and 95, 97.5, and 99 on the upper one,
    can be selected for the winsorization technique, although other approaches can
    be chosen such as the use of the interquartile range.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing winsorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s put the winsorization approach into practice. First, we need to know
    the position of ratios in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: So, we need to apply the technique to all the variables, excluding the first
    and the last two variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the transformations done in the training set should be applied later in
    the test dataset. Modifications in the test sample will be done using the limits
    of the training data. We will do winsorization for both datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: For each variable, this will calculate the first and the ninety-ninth percentiles
    in the training set. Then, values of outliers exceeding the value of the ninety-ninth
    percentile, or a value smaller than the first percentile are replaced with the
    value of these corresponding percentiles. This means that it establishes a maximum
    and minimum value for each value fixed in the first and the ninety-ninth percentiles.
    This procedure is done for both train and test samples.
  prefs: []
  type: TYPE_NORMAL
- en: Distinguishing single valued variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we are going to calculate the number of unique values that a variable takes.
    Thus, if a variable only takes one single value, it can be directly removed from
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sapply` function allows the calculation of the `n_distinct` values of
    each variable. Create a new data frame with the name of the constant variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Rename the name of the variable in this data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a column in the data frame containing the name of the variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then create a list with the name of the constant variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Only `84` variables have a unique distinct value. These variables will be removed
    in the `train` and `test` samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: One of the problems of winsorization is that, if a variable displays a low number
    of different values, it can replace all the values with only one value . That's
    because a variable could take the same value during several percentile levels.
    It is important to be aware of the pros and cons of each procedure and its effect
    on the development.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember to save your workspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Treating missing information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most of the algorithms fail when the data includes missing values or takes a
    predetermined action about how to deal with them in an automatic way. It is important
    to take control when this happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two actions are the most common to deal with missing information: to remove
    the observations with missing values or to replace them with a concrete value,
    usually the median or mean. When a value is imputed, you could be losing important
    information. For example, a missing value of the variable can be always observed
    in one of the classes of the target variable. A typical case is a model where
    we are trying to predict good and bad applicants for a bank loan.'
  prefs: []
  type: TYPE_NORMAL
- en: It is common to have variables related to the number of days with some payment
    problems in the past. Sometimes, and depending on the dataset, these variables
    display a missing value simply because the applicant did not have previous problems.
    This is typically the case when the imputation of a value could lead us to lose
    relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed analysis of missing values is most common when the number of variables
    is low. If the number of variables is high, some automatic alternative could be
    a more efficient approach.
  prefs: []
  type: TYPE_NORMAL
- en: Before taking an action on the missing values, let’s find the number of missing
    values by analyzing columns and rows. You can then remove the variables and rows
    (also known as observations) that have a high number of missing values.
  prefs: []
  type: TYPE_NORMAL
- en: In any case, thresholds to remove variables or observations are subjective,
    and it depends on the specific case of their application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `DataExplorer` package, it is possible to find the percentage of
    missing values in our data. Let’s try it with a small number of variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding line of code will print a graph similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffd51532-474e-4ae0-916f-e9067258bb4e.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding graph is only an example of the representation of missing values
    for some variables using the `DataExplorer` package. This package also provides
    recommendations about the usefulness of using a variable depending on its number
    of missing values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also have another way to determine variables with missing values. This is
    an alternative if you do not have access to the `DataExplorer` package, or simply
    don''t wish to use it. This is more of a manual way. Let''s write the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, we can check variables where missing values represent more than
    99% of the total observations (only a few lines are shown here):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, I prefer not to remove any variables considering its number of
    missing values. There are no empty variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s count the number of missing values by analyzing the rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now plot a histogram to graphically depict the distribution of the missing
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85f13606-976a-43ae-9209-0d0c24447437.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A summary of the percentage of missing values from banks can be obtained using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the number of missing values is high for some banks, it is recommended
    to not remove any observations for now, but to only remove the recently created
    missing variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: An interesting package that we will use to visualize the number of missing values
    in the dataset is the `Amelia` package. It is a package for multiple imputations
    of missing data, which also includes a graphical interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see an example for some variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code generates the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a4025f79-7e3c-4cdc-8017-6a127d559e3e.png)'
  prefs: []
  type: TYPE_IMG
- en: Although the representation is not very pretty, this graph displays some variables
    from the *x* axis and the observations in the dataset from the *y* axis. Black
    points indicate the presence of missing variables in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: As shown, some of variables display a high number of missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the missing value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've already mentioned that it is important to understand the origin of missing
    values and whether they can offer us some information. In the following example,
    we will analyze the missing values presented in the `UBPRE628` variable. This
    variable measures the amount of total long-term debt of a bank divided by the
    total bank equity capital. The capital of a bank is important because in the case
    of losses faced in the operations, this will be used by the bank to absorb them
    and to avoid a future insolvency. The higher the capital, the higher the buffer
    of a bank to face economic problems.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the highest proportion of debt related to the bank capital, the
    more problems the bank could experience in the future if, for example, a new crisis
    occurs. In the event of a new financial crisis, a bank couldn’t repay its debt,
    even by selling its assets.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to our analysis, this variable displays a high percentage of missing
    values, specifically this ratio is not informed for the 23.97% of banks in our
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Understanding the results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we will create an auxiliary data frame to count the number of failed banks
    and check whether this ratio is informed or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will create a flag to check whether the variable is missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s sum up the number of existing defaults in the dataset for both
    the cases: the presence or lack of the missing values in this ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: According to this table, only `14` failed banks displayed a missing value in
    this ratio. Apparently, we could conclude from this that a bank could intentionally
    not report a specific ratio because the calculated ratio could alert others about
    a bad economic situation of this bank. In this case, we don't observe a high proportion
    of bad banks if a missing value is observed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Missing values will be estimated by calculating the mean of the ratio of the
    non-missing observations on the training dataset. This means that, if missing
    values are present in the validation dataset, they may also be present in the
    training dataset. Let''s see an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check whether the process has worked using the `Amelia` package on both
    training and validation samples (it may take a few minutes). For example, you
    can check whether there are missing values in the training sample after the process
    has executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0c603227-368f-48a2-a948-88201fd86bb3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Carry out the same checks for the test sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, a new output is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/41df5e03-9ca2-4ad6-acb1-6683eef9f9b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Two maps are plotted in a gray color, indicating that there are no missing values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are going to make a new backup of our workspace and remove all the unnecessary
    tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned some initial important steps to prepare and
    understand our data. How many variables are available in our dataset? What kind
    of information do we have? Are there some missing values in the data? How can
    I treat missing values and outliers? I hope you can now answer these questions.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in this chapter, we also learned how to split our data to train and
    validate our forthcoming predictive model. In the next chapter, we will advance
    one step ahead, performing a univariate analysis on this data, which means analyzing
    whether variables are useful for predicting bank failures.
  prefs: []
  type: TYPE_NORMAL
