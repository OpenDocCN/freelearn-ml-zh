["```py\npython -c \"import keras;print(keras.__version__)\"\n```", "```py\ndim_x = 1000 # input dims\ndim_y = 2 # output dims\n```", "```py\ndef net(x, w):\n \"\"\"\n A simple neural net that performs non-linear transformation\n Function : 1 / (1 + e^(-w*x)) \n x: inputs \n w: weight matrix\n Returns the function value\n \"\"\"\n return 1/(1+np.exp(-x.dot(w)))\n```", "```py\n # feed forward pass\n y_pred = net(x, w)\n\n # compute loss\n loss = compute_loss(y, y_pred)\n print(\"Loss:\", loss, \"at step:\", i)\n\n # compute grads using backprop on given net\n w_grad = backprop(y, y_pred, w, x) \n\n # update weights with some learning rate\n w -= lr * w_grad\n```", "```py\ndef compute_loss(y, y_pred):\n \"\"\"\n Loss function : sum(y_pred**2 - y**2)\n y: ground truth targets \n y_pred: predicted target values\n \"\"\"\n return np.mean((y_pred-y)**2) \n```", "```py\nimport numpy as np \n\ndim_x = 1000 # input dims\ndim_y = 2 # output dims\nbatch = 10 # batch size for training \nlr = 1e-4 # learning rate for weight update\nsteps = 5000 # steps for learning \n\n# create random input and targets\nx = np.random.randn(batch, dim_x)\ny = np.random.randn(batch, dim_y)\n\n# initialize weight matrix \nw = np.random.randn(dim_x, dim_y)\n\ndef net(x, w):\n \"\"\"\n A simple neural net that performs non-linear transformation\n Function : 1 / (1 + e^(-w*x)) \n x: inputs \n w: weight matrix\n Returns the function value\n \"\"\"\n return 1/(1+np.exp(-x.dot(w)))\n\ndef compute_loss(y, y_pred):\n \"\"\"\n Loss function : sum(y_pred**2 - y**2)\n y: ground truth targets \n y_pred: predicted target values\n \"\"\"\n return np.mean((y_pred-y)**2) \n\ndef backprop(y, y_pred, w, x):\n \"\"\"\n Backpropagation to compute gradients of weights\n y : ground truth targets \n y_pred : predicted targets \n w : weights for the network\n x : inputs to the net \n \"\"\"\n # start from outer most\n y_grad = 2.0 * (y_pred - y)\n\n # inner layer grads \n w_grad = x.T.dot(y_grad * y_pred * (1 - y_pred))\n return w_grad\n\nfor i in range(steps):\n\n # feed forward pass\n y_pred = net(x, w)\n\n # compute loss\n loss = compute_loss(y, y_pred)\n print(\"Loss:\", loss, \"at step:\", i)\n\n # compute grads using backprop on given net\n w_grad = backprop(y, y_pred, w, x) \n\n # update weights with some learning rate\n w -= lr * w_grad\n```", "```py\nkernel = np.ones((5,5),np.float32)/25\ndst = cv2.filter2D(gray,-1,kernel)\n```", "```py\ny = Conv2D(filters=32, \n kernel_size=(5,5), \n strides=1, padding=\"same\")(x)\n```", "```py\nfrom keras.layers import Conv2D, Input\nfrom keras.models import Model\n\ndef print_model():\n \"\"\"\n Creates a sample model and prints output shape\n Use this to analyse convolution parameters\n \"\"\"\n # create input with given shape \n x = Input(shape=(512,512,3))\n\n # create a convolution layer\n y = Conv2D(filters=32, \n kernel_size=(5,5), \n strides=1, padding=\"same\",\n use_bias=False)(x)\n\n # create model \n model = Model(inputs=x, outputs=y)\n\n # prints our model created\n model.summary()\n\nprint_model()\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 512, 512, 32) 2400\n=================================================================\nTotal params: 2,400\nTrainable params: 2,400\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 256, 256, 32) 2400\n=================================================================\nTotal params: 2,400\nTrainable params: 2,400\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 128, 128, 32) 2400\n=================================================================\nTotal params: 2,400\nTrainable params: 2,400\nNon-trainable params: 0\n_________________________________________________________________ \n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 508, 508, 32) 2400\n=================================================================\nTotal params: 2,400\nTrainable params: 2,400\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 512, 512, 32) 2432\n=================================================================\nTotal params: 2,432\nTrainable params: 2,432\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nfrom keras.layers import Conv2D, Input, Activation\nfrom keras.models import Model\n\ndef print_model():\n \"\"\"\n Creates a sample model and prints output shape\n Use this to analyse convolution parameters\n \"\"\"\n # create input with given shape \n x = Input(shape=(512,512,3))\n\n # create a convolution layer\n conv = Conv2D(filters=32, \n kernel_size=(5,5), \n strides=1, padding=\"same\",\n use_bias=True)(x)\n\n # add activation layer\n y = Activation('relu')(conv)\n\n # create model \n model = Model(inputs=x, outputs=y)\n\n # prints our model created\n model.summary()\n\nprint_model()  \n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 512, 512, 32) 2432\n_________________________________________________________________\nactivation_1 (Activation) (None, 512, 512, 32) 0\n=================================================================\nTotal params: 2,432\nTrainable params: 2,432\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nconv = Conv2D(filters=32, \n kernel_size=(5,5), activation=\"relu\", \n strides=1, padding=\"same\",\n use_bias=True)(x)\n```", "```py\nfrom keras.layers import Conv2D, Input, MaxPooling2D\nfrom keras.models import Model\n\ndef print_model():\n \"\"\"\n Creates a sample model and prints output shape\n Use this to analyse Pooling parameters\n \"\"\"\n # create input with given shape \n x = Input(shape=(512,512,3))\n\n # create a convolution layer\n conv = Conv2D(filters=32, \n kernel_size=(5,5), activation=\"relu\", \n strides=1, padding=\"same\",\n use_bias=True)(x)\n\n pool = MaxPooling2D(pool_size=(2,2))(conv)\n\n # create model \n model = Model(inputs=x, outputs=pool)\n\n # prints our model created\n model.summary()\n\nprint_model()\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512, 512, 3) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 512, 512, 32) 2432\n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 256, 256, 32) 0\n=================================================================\nTotal params: 2,432\nTrainable params: 2,432\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\n\ndef print_model():\n \"\"\"\n Creates a sample model and prints output shape\n Use this to analyse dense/Fully Connected parameters\n \"\"\"\n # create input with given shape \n x = Input(shape=(512,))\n\n # create a fully connected layer layer\n y = Dense(32)(x)\n\n # create model \n model = Model(inputs=x, outputs=y)\n\n # prints our model created\n model.summary()\n\nprint_model()\n```", "```py\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 512) 0\n_________________________________________________________________\ndense_1 (Dense) (None, 32) 16416\n=================================================================\nTotal params: 16,416\nTrainable params: 16,416\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nfrom keras.datasets import fashion_mnist\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n```", "```py\ndef conv3x3(input_x,nb_filters):\n \"\"\"\n Wrapper around convolution layer\n Inputs:\n input_x: input layer / tensor\n nb_filter: Number of filters for convolution\n \"\"\"\n return Conv2D(nb_filters, kernel_size=(3,3), use_bias=False,\n activation='relu', padding=\"same\")(input_x)\n```", "```py\nx = MaxPooling2D(pool_size=(2,2))(input)\n```", "```py\npreds = Dense(nb_class, activation='softmax')(x)\n```", "```py\ndef create_model(img_h=28, img_w=28):\n \"\"\"\n Creates a CNN model for training. \n Inputs: \n img_h: input image height\n img_w: input image width\n Returns:\n Model structure \n \"\"\"\n\n inputs = Input(shape=(img_h, img_w, 1))\n\n x = conv3x3(inputs, 32)\n x = conv3x3(x, 32)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = conv3x3(x, 64)\n x = conv3x3(x, 64)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = conv3x3(x, 128)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = Flatten()(x)\n x = Dense(128, activation=\"relu\")(x)\n preds = Dense(nb_class, activation='softmax')(x)\n\n model = Model(inputs=inputs, outputs=preds)\n print(model.summary())\n return model\n```", "```py\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 28, 28, 1) 0\n_________________________________________________________________\nconv2d_1 (Conv2D) (None, 28, 28, 32) 288\n_________________________________________________________________\nconv2d_2 (Conv2D) (None, 28, 28, 32) 9216\n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 32) 0\n_________________________________________________________________\nconv2d_3 (Conv2D) (None, 14, 14, 64) 18432\n_________________________________________________________________\nconv2d_4 (Conv2D) (None, 14, 14, 64) 36864\n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 7, 7, 64) 0\n_________________________________________________________________\nconv2d_5 (Conv2D) (None, 7, 7, 128) 73728\n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 3, 3, 128) 0\n_________________________________________________________________\nflatten_1 (Flatten) (None, 1152) 0\n_________________________________________________________________\ndense_1 (Dense) (None, 128) 147584\n_________________________________________________________________\ndense_2 (Dense) (None, 10) 1290\n=================================================================\nTotal params: 287,402\nTrainable params: 287,402\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nimport keras \nimport keras.backend as K\nfrom keras.layers import Dense, Conv2D, Input, MaxPooling2D, Flatten\nfrom keras.models import Model\nfrom keras.datasets import fashion_mnist\nfrom keras.callbacks import ModelCheckpoint\n```", "```py\n# setup parameters\nbatch_sz = 128  # batch size \nnb_class = 10  # target number of classes\nnb_epochs = 10 # training epochs\nimg_h, img_w = 28, 28  # input dimensions\n```", "```py\ndef get_dataset():\n \"\"\"\n Return processed and reshaped dataset for training\n In this cases Fashion-mnist dataset.\n \"\"\"\n # load mnist dataset\n (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n # test and train datasets\n print(\"Nb Train:\", x_train.shape[0], \"Nb test:\",x_test.shape[0])\n x_train = x_train.reshape(x_train.shape[0], img_h, img_w, 1)\n x_test = x_test.reshape(x_test.shape[0], img_h, img_w, 1)\n in_shape = (img_h, img_w, 1)\n\n # normalize inputs\n x_train = x_train.astype('float32')\n x_test = x_test.astype('float32')\n x_train /= 255.0\n x_test /= 255.0\n\n # convert to one hot vectors \n y_train = keras.utils.to_categorical(y_train, nb_class)\n y_test = keras.utils.to_categorical(y_test, nb_class)\n return x_train, x_test, y_train, y_test\n\nx_train, x_test, y_train, y_test = get_dataset()\n```", "```py\ndef conv3x3(input_x,nb_filters):\n \"\"\"\n Wrapper around convolution layer\n Inputs:\n input_x: input layer / tensor\n nb_filter: Number of filters for convolution\n \"\"\"\n return Conv2D(nb_filters, kernel_size=(3,3), use_bias=False,\n activation='relu', padding=\"same\")(input_x)\n\ndef create_model(img_h=28, img_w=28):\n \"\"\"\n Creates a CNN model for training. \n Inputs: \n img_h: input image height\n img_w: input image width\n Returns:\n Model structure \n \"\"\"\n\n inputs = Input(shape=(img_h, img_w, 1))\n\n x = conv3x3(inputs, 32)\n x = conv3x3(x, 32)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = conv3x3(x, 64)\n x = conv3x3(x, 64)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = conv3x3(x, 128)\n x = MaxPooling2D(pool_size=(2,2))(x) \n x = Flatten()(x)\n x = Dense(128, activation=\"relu\")(x)\n preds = Dense(nb_class, activation='softmax')(x)\n\n model = Model(inputs=inputs, outputs=preds)\n print(model.summary())\n return model\n\nmodel = create_model()\n```", "```py\n# setup optimizer, loss function and metrics for model\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n optimizer=keras.optimizers.Adam(),\n metrics=['accuracy'])\n```", "```py\n# To save model after each epoch of training\ncallback = ModelCheckpoint('mnist_cnn.h5')\n```", "```py\n# start training\nmodel.fit(x_train, y_train,\n batch_size=batch_sz,\n epochs=nb_epochs,\n verbose=1,\n validation_data=(x_test, y_test), \n callbacks=[callback])\n```", "```py\n# Evaluate and print accuracy\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n```", "```py\nfrom keras.applications.vgg16 import VGG16\n\ndef print_model():\n \"\"\"\n Loads VGGNet and prints model structure\n \"\"\"\n\n # create model \n model = VGG16(weights='imagenet')\n\n # prints our model created\n model.summary()\n\nprint_model()\n```", "```py\n_________________________________________________________________\nLayer (type) Output Shape Param #\n=================================================================\ninput_1 (InputLayer) (None, 224, 224, 3) 0\n_________________________________________________________________\nblock1_conv1 (Conv2D) (None, 224, 224, 64) 1792\n_________________________________________________________________\nblock1_conv2 (Conv2D) (None, 224, 224, 64) 36928\n_________________________________________________________________\nblock1_pool (MaxPooling2D) (None, 112, 112, 64) 0\n_________________________________________________________________\nblock2_conv1 (Conv2D) (None, 112, 112, 128) 73856\n_________________________________________________________________\nblock2_conv2 (Conv2D) (None, 112, 112, 128) 147584\n_________________________________________________________________\nblock2_pool (MaxPooling2D) (None, 56, 56, 128) 0\n_________________________________________________________________\nblock3_conv1 (Conv2D) (None, 56, 56, 256) 295168\n_________________________________________________________________\nblock3_conv2 (Conv2D) (None, 56, 56, 256) 590080\n_________________________________________________________________\nblock3_conv3 (Conv2D) (None, 56, 56, 256) 590080\n_________________________________________________________________\nblock3_pool (MaxPooling2D) (None, 28, 28, 256) 0\n_________________________________________________________________\nblock4_conv1 (Conv2D) (None, 28, 28, 512) 1180160\n_________________________________________________________________\nblock4_conv2 (Conv2D) (None, 28, 28, 512) 2359808\n_________________________________________________________________\nblock4_conv3 (Conv2D) (None, 28, 28, 512) 2359808\n_________________________________________________________________\nblock4_pool (MaxPooling2D) (None, 14, 14, 512) 0\n_________________________________________________________________\nblock5_conv1 (Conv2D) (None, 14, 14, 512) 2359808\n_________________________________________________________________\nblock5_conv2 (Conv2D) (None, 14, 14, 512) 2359808\n_________________________________________________________________\nblock5_conv3 (Conv2D) (None, 14, 14, 512) 2359808\n_________________________________________________________________\nblock5_pool (MaxPooling2D) (None, 7, 7, 512) 0\n_________________________________________________________________\nflatten (Flatten) (None, 25088) 0\n_________________________________________________________________\nfc1 (Dense) (None, 4096) 102764544\n_________________________________________________________________\nfc2 (Dense) (None, 4096) 16781312\n_________________________________________________________________\npredictions (Dense) (None, 1000) 4097000\n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n```", "```py\nfrom keras.applications.inception_v3 import InceptionV3\n\ndef print_model():\n \"\"\"\n Loads InceptionV3 model and prints model structure\n \"\"\"\n\n # create model \n model = InceptionV3(weights='imagenet')\n\n # prints our model created\n model.summary()\n\nprint_model()\n```", "```py\nfrom keras.applications.resnet50 import ResNet50\nimport numpy as np \nimport cv2 \nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport time\n```", "```py\ndef get_model():\n \"\"\"\n Loads Resnet and prints model structure\n Returns resnet as model.\n \"\"\"\n\n # create model \n model = ResNet50(weights='imagenet')\n\n # To print our model loaded\n model.summary()\n return model\n```", "```py\ndef preprocess_img(img):\n # apply opencv preprocessing\n img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n img = cv2.resize(img, (224, 224)) \n img = img[np.newaxis, :, :, :]\n # convert to float type\n img = np.asarray(img, dtype=np.float) \n\n # further use imagenet specific preprocessing\n # this applies color channel specific mean normalization\n x = preprocess_input(img)\n print(x.shape)\n return x\n```", "```py\n# read input image and preprocess\nimg = cv2.imread('../figures/train1.png')\ninput_x = preprocess_img(img)\n```", "```py\n# create model with pretrained weights\nresnet_model = get_model()\n\n# run predictions only , no training\nstart = time.time()\npreds = resnet_model.predict(input_x)\nprint(time.time() - start)\n```", "```py\n# decode prediction to index of classes, top 5 predictions\nprint('Predicted:', decode_predictions(preds, top=5)[0]) \n```", "```py\nPredicted: [('n04310018', 'steam_locomotive', 0.89800948), ('n03895866', 'passenger_car', 0.066653267), ('n03599486', 'jinrikisha', 0.0083348891), ('n03417042', 'garbage_truck', 0.0052676937), ('n04266014', 'space_shuttle', 0.0040852665)]\n```"]