- en: Object Detection in Images using Deep Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used basic neural networks in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks* with Neural Networks. Research in neural
    networks is creating some of the most advanced and accurate classification algorithms
    in many areas. The differences between the concepts introduced in this chapter,
    versus those introduced in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks* is around *complexity*. In this chapter,
    we look at deep neural networks, those with many hidden layers, and also at more
    complex layer types for dealing with specific types of information, such as images.
  prefs: []
  type: TYPE_NORMAL
- en: These advances have come on the back of improvements in computational power,
    allowing us to train larger and more complex networks. However, the advances are
    much more than simply throwing more computational power at the problem. New algorithms
    and layer types have drastically improved performance, outside computational power.
    The cost is that these new classifiers need more data to learn from than other
    data mining classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will look at determining what object is represented in an
    image. The pixel values will be used as input, and the neural network will then
    automatically find useful combinations of pixels to form higher-level features.
    These will then be used for the actual classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, in this chapter, we will examine the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Classifying objects in images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different types of deep neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TensorFlow and Keras libraries to build and train neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a GPU to improve the speed of the algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using cloud-based services for added horse-power for data mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer vision is becoming an important part of future technology. For example,
    we will have access to self-driving cars in the very near future - car manufacturers
    are scheduled to be releasing self-driving models in 2017 and are already partially
    self-driving. In order to achieve this, the car's computer needs to be able to
    see around it; identify obstacles, other traffic, and weather conditions; and
    then use that to plan a safe journey.
  prefs: []
  type: TYPE_NORMAL
- en: While we can easily detect whether there is an obstacle, for example using radar,
    it is also important we know what that object is. If it is an animal on the road,
    we can stop and let it move out of the way; if it is a building, this strategy
    won't work very well!
  prefs: []
  type: TYPE_NORMAL
- en: Use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computer vision is used in many scenarios. Following are some examples where
    they applications is very important.
  prefs: []
  type: TYPE_NORMAL
- en: Online map websites, such as Google Maps, use computer vision for a number of
    reasons. One reason is to automatically blur any faces that they find, in order
    to give some privacy to the people being photographed as part of their Street
    View feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face detection is also used in many industries. Modern cameras automatically
    detect faces, as a means to improve the quality of photos taken (the user most
    often wants to focus on a visible face). Face detection can also be used for identification.
    For example, Facebook automatically recognises people in photos, allowing for
    easy tagging of friends.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we stated before, autonomous vehicles are highly dependent on computer vision
    to recognise their path and avoid obstacles. Computer vision is one of the key
    problems that is being addressed not only in research into autonomous vehicles,
    not just for consumer use, but also in mining and other industries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other industries are using computer vision too, including warehouses examining
    goods automatically for defects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The space industry is also using computer vision, helping to automate the collection
    of data. This is critical for effective use of spacecraft, as sending a signal
    from Earth to a rover on Mars can take a long time and is not possible at certain
    times (for instance, when the two planets are not facing each other). As we start
    dealing with space-based vehicles more frequently, and from a greater distance,
    increasing the autonomy of these spacecraft is absolutely necessary and computer
    vision is a key part of this.The following picture shows the Mars rover designed
    and used by NASA; it made significant use of computer vision to identify its surroundings
    on a strange, inhospitable planet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B06162_11_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Application scenario
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will build a system that will take an image as an input
    and give a prediction on what the object in it is. We will take on the role of
    a vision system for a car, looking around at any obstacles in the way or on the
    side of the road. Images are of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162_11_01.png)'
  prefs: []
  type: TYPE_IMG
- en: This dataset comes from a popular dataset called CIFAR-10\. It contains 60,000
    images that are 32 pixels wide and 32 pixels high, with each pixel having a red-green-blue
    (RGB) value. The dataset is already split into training and testing, although
    we will not use the testing dataset until after we complete our training.
  prefs: []
  type: TYPE_NORMAL
- en: The CIFAR-10 dataset is available for download at [http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)
  prefs: []
  type: TYPE_NORMAL
- en: Download the python version, which has already been converted to NumPy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Opening a new Jupyter Notebook, we can see what the data looks like. First,
    we set up the data filenames. We will only worry about the first batch to start
    with, and scale up to the full dataset size towards the end;
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a function that can read the data stored in the batches. The
    batches have been saved using pickle, which is a python library to save objects.
    Usually, we can just call `pickle.load(file)` on the file to get the object. However,
    there is a small issue with this data: it was saved in Python 2, but we need to
    open it in Python 3\. In order to address this, we set the encoding to `latin`
    (even though we are opening it in byte mode):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this function, we can now load the batch dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This batch is a dictionary containing the actual data in NumPy arrays, the corresponding
    labels and filenames, and a note to say which batch it is (this is training batch
    1 of 5, for instance).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can extract an image by using its index in the batch''s data key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The image array is a NumPy array with 3,072 entries, from 0 to 255\. Each value
    is the red, green, or blue intensity at a specific location in the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The images are in a different format than what matplotlib usually uses (to
    display images), so to show the image we first need to reshape the array and rotate
    the matrix. This doesn''t matter so much to train our neural network (we will
    define our network in a way that fits with the data), but we do need to convert
    it for matplotlib''s sake:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can show the image using matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image, a boat, is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162_11_02.png)'
  prefs: []
  type: TYPE_IMG
- en: The resolution of this image is quite poor—it is only 32 pixels wide and 32
    pixels high. Despite that, most people will look at the image and see a boat.
    Can we get a computer to do the same?
  prefs: []
  type: TYPE_NORMAL
- en: You can change the image index to show different images, getting a feel for
    the dataset's properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aim of our project, in this chapter, is to build a classification system
    that can take an image like this and predict what the object in it is. Before
    we do that though, we will take a detour to learn about the classifier we are
    going to use: **Deep neural networks**.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The neural networks we used in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*, have some fantastic *theoretical* properties.
    For example, only a single hidden layer is needed to learn any mapping (although
    the size of the middle layer may need to be very, very big). Neural networks were
    a very active area of research in the 1970s and 1980s due to this theoretical
    perfection. However several issues caused them to fall out of favor, particularly
    compared to other classification algorithms such as support vector machines. A
    few of the major ones are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the main issues was that the computational power needed to run many neural
    networks was more than other algorithms and more than what many people had access
    to.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another issue was training the networks. While the back propagation algorithm
    has been known about for some time, it has issues with larger networks, requiring
    a very large amount of training before the weights settle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these issues has been addressed in recent times, leading to a resurgence
    in popularity of neural networks. Computational power is now much more easily
    available than 30 years ago, and advances in algorithms for training mean that
    we can now readily use that power.
  prefs: []
  type: TYPE_NORMAL
- en: Intuition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aspect that differentiates **deep neural networks** from the more basic
    neural network we saw in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*, is size.
  prefs: []
  type: TYPE_NORMAL
- en: A neural network is considered deep when it has two or more hidden layers. In
    practice, a deep neural network is often much larger, both in the number of nodes
    in each layer and also the number of layers. While some of the research of the
    mid -2000s focused on very large numbers of layers, smarter algorithms are reducing
    the actual number of layers needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The size is one differentiator, but new layer types and neural network structures
    are assisting in creating deep neural networks for specific areas. We have already
    seen a feed-forward neural network composed of **dense layers**. This means we
    have a series of layers, in order, where each neuron from one layer is attached
    to each neuron from another layer. Other types include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks** (**CNN**) for image analysis. In this case,
    a small segment of the image is taken as a single input, and that input is passed
    onto a pooling layer to combine these outputs. This helps with issues such as
    rotation and translation of images. We will use these networks in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent Neural Networks** (**RNN**) for text and time-series analysis.
    In this case, the previous state of the neural network is remembered and used
    to alter the current output. Think of the preceding word in a sentence modifying
    the output for the current word in the phrase: *United States*. One of the most
    popular types is an LSTM recurrent network, standing for **Long-Short Term Memory**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autoencoders**, which learn a mapping from the input, through a hidden layer
    (usually with fewer nodes), back to the input. This finds a compression of the
    input data, and this layer can be reused in other neural networks, reducing the
    amount of labelled training data needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many, many more types of neural networks. Research into applications
    and theory of deep neural networks is finding more and more forms of neural networks
    every month. Some are designed for general purpose learning, some for specific
    tasks. Further, there are multiple ways to combine layers, tweak parameters, and
    otherwise alter the learning strategy. For example, **dropout layers** randomly
    reduce some weights to zero during training, forcing all parts of the neural network
    to learn good weights.
  prefs: []
  type: TYPE_NORMAL
- en: Despite all these differences, a neural network is usually designed to take
    very basic features as inputs—in the case of computer vision, it is simple pixel
    values. As that data is combined and pushed through the network, these basic features
    combine into more complex features. Sometimes, these features have little meaning
    to humans, but they represent the aspects of the sample that the computer looks
    for to make its classification.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing deep neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing these deep neural networks can be quite challenging due to their
    size. A bad implementation will take significantly longer to run than a good one,
    and may not even run at all due to memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: A basic implementation of a neural network might start by creating a node class
    and collecting a set of these into a layer class. Each node is then connected
    to a node in the next layer using an instance of an *Edge* class. This type of
    implementation, a class-based one, is good to show how networks operate but too
    inefficient for larger networks. Neural networks simply have too many moving parts
    for this strategy to be efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, most neural networks operations can be expressed as mathematical expressions
    on matrices. The weights of the connections between one network layer and the
    next can be represented as a matrix of values, where the rows represent nodes
    in the first layer and the columns represent the nodes in the second layer (the
    transpose of this matrix is used sometimes too). The value is the weight of the
    edge between one layer and the next. A network can then be defined as a set of
    these weight matrices. In addition to the nodes, we add a bias term to each layer,
    which is basically a node that is always on and connected to each neuron in the
    next layer.
  prefs: []
  type: TYPE_NORMAL
- en: This insight allows us to use matrix operations to build, train, and use neural
    networks, as opposed to creating a class-based implementation. These mathematical
    operations are great, as many great libraries of highly optimised code have been
    written that we can use to perform these computations as efficiently as we can.
  prefs: []
  type: TYPE_NORMAL
- en: The scikit-learn implementation that we used in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*, does contain some features for building
    neural networks but lacks several recent advances in the field. For larger and
    more customised networks, though, we need a library that gives us a bit more power.
    We will use the **Keras** library instead to create our deep neural network.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will start by implementing a basic neural network with Keras
    and then (nearly) replicate our experiment in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*, on predicting which letter is in an image.
    Finally, we will use a much more complex convolution neural network to perform
    image classification on the CIFAR dataset, which will also include running this
    on GPUs rather than CPUs to improve the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Keras is a high-level interface to using a graph-computation library for implementing
    deep neural networks. Graph-computation libraries outline a series of operations
    and then later compute the values. These are great for matrix operations because
    they can be used to represent data flows, distribute those data flows across multiple
    systems and perform other optimisations. Keras can use either of two graph-computation
    libraries under the hood. The first is called **Theano**, which is a little older
    and has a strong following (and was used in the first edition of this book), and
    the second is **TensorFlow**, released recently by Google and is the library that
    powers much of their deep learning. Ultimately, you can use either library in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: An Introduction to TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a graph computation library designed by engineers at Google, and
    is starting to power many of Google's recent advances in **deep learning** and
    **artificial intelligence**.
  prefs: []
  type: TYPE_NORMAL
- en: 'A graph computation library has two steps. They are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining the sequence (or more complex graphs) of operations that take the input
    data, operate on it, and convert to outputs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute on the graph obtained from step 1 with a given input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Many programmers don't use this type of programming day-to-day, but most of
    them interact with a related system that does. Relational databases, specifically
    SQL-based ones, use a similar concept called the declarative paradigm. While a
    programmer might define a `SELECT` query on a database with a `WHERE` clause,
    the database interprets that and creates an optimised query based on a number
    of factors, such as whether the `WHERE` clause is applied to a primary key, the
    format the data is stored in, and other factors. The programmer defines what they
    want and the system determines how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can install TensorFlow using Anaconda: conda install tensorflow'
  prefs: []
  type: TYPE_NORMAL
- en: For more options, Google has a detailed installation page at [https://www.tensorflow.org/get_started/os_setup](https://www.tensorflow.org/get_started/os_setup)
  prefs: []
  type: TYPE_NORMAL
- en: 'Using TensorFlow, we can define many types of functions working on scalars,
    arrays, and matrices, as well as other mathematical expressions. For instance,
    we can create a graph that computes the values of a given quadratic equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This *y* object is a Tensor object. It does not yet have a value as this hasn''t
    been computed. All we have done is create a graph that states:'
  prefs: []
  type: TYPE_NORMAL
- en: '*When we do compute y, first take the square the value of x and multiply it
    by a, add b times x to it, and then add c to the result.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The graph itself can be viewed through TensorFlow. Here is some code to visualise
    this graph within a Jupyter Notebook, courtesy of  StackOverflow user Yaroslav
    Bulatov (see this answer: [http://stackoverflow.com/a/38192374/307363](http://stackoverflow.com/a/38192374/307363)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then perform the actual visualisation using this code in a new cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The results show how these operations are linked in a directed graph. The visualisation
    platform is called **TensorBoard**, which comes with TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162_11_04.png)'
  prefs: []
  type: TYPE_IMG
- en: When we want to compute a value for y, we need to pass a value for x through
    the other nodes in the graph, these are called OpNodes in the above graph, short
    for *Operation Node*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To this point, we have defined the graph itself. The next step is to compute
    the values. We can do this a number of ways, especially considering x is a Variable.
    To compute y, using the current value of x, we create a TensorFlow Session object
    and then ask it to run y:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first line initialises the variables. TensorFlow lets you specify scopes
    of operations and namespaces. At this point, we are just using the global namespace,
    and this function is a handy shortcut to initialise that scope properly, which
    can be thought of as a step needed for TensorFlow to compile the graph.
  prefs: []
  type: TYPE_NORMAL
- en: The second creates a new session that will run the model itself. The result
    from `tf.global_variables_initializer()` is itself an operation on the graph,
    and must be executed to happen. The next line actually runs the variable y, which
    computes the necessary OpNodes needed to compute the value of y. In our case,
    that is all of the nodes but it is possible that larger graphs might not need
    all nodes computed - TensorFlow will do just enough work to get the answer and
    no more.
  prefs: []
  type: TYPE_NORMAL
- en: If you get an error that `global_variables_initializer` is not defined, replace
    it with `initialize_all_variables` - the interface was recently changed.
  prefs: []
  type: TYPE_NORMAL
- en: Printing the result gives us our value of 3.
  prefs: []
  type: TYPE_NORMAL
- en: We can also do other operations, such as change the value of x. For instance,
    we can create an assign operation, which assigns a new value to an existing Variable.
    In this example, we change the value of x to 10 and then compute y, which results
    in 548.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: While this simple example may not seem much more powerful than what we can already
    do with Python, TensorFlow (and Theano) have large amounts of distribution options
    for computing larger networks over many computers and optimisations for doing
    it efficiently. Both libraries also contain extra tools for saving and loading
    networks, including values, which lets us save models created in these libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Using Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is not a library to directly build neural networks. In a similar
    way, NumPy is not a library to perform data mining; it just does the heavy lifting
    and is generally used from another library. TensorFlow contains a built-in library,
    referred to as TensorFlow Learn to build networks and perform data mining. Other
    libraries, such as Keras, are also built with this in mind and use TensorFlow
    in the backend.
  prefs: []
  type: TYPE_NORMAL
- en: Keras implements a number of modern types of neural network layers and the building
    blocks for building them. In this chapter, we will use convolution layers which
    are designed to mimic the way in which human vision works. They use small collections
    of connected neurons that analyse only a segment of the input values - in this
    case, an image. This allows the network to deal with standard alterations such
    as dealing with translations of images. In the case of vision-based experiments,
    an example of an alteration dealt with by convolution layers is translating the
    image.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, a traditional neural network is often heavily connected—all neurons
    from one layer connect to all neurons in the next layer. This is referred to as
    a dense layer.
  prefs: []
  type: TYPE_NORMAL
- en: The standard model for neural networks in Keras is a **Sequential** model, which
    is created by passing a list of layers. The input (X_train) is given to the first
    layer, and its output given to the next layer and so on, in a standard feed-forward
    configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Building a neural network in Keras is significantly easier than building it
    using just TensorFlow. Unless you are doing highly customised modifications to
    the neural network structure, I strongly recommend using Keras.
  prefs: []
  type: TYPE_NORMAL
- en: To show the basics of using Keras for neural networks, we will implement a basic
    network to lean on the Iris dataset, which we saw in [Chapter 1](3dc86298-cd8c-4d02-a373-6cd303d5c558.xhtml)*,
    Getting Started with Data Mining*. The Iris dataset is great for testing new algorithms,
    even complex ones such as deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: First, open a new Jupyter Notebook. We will come back to the Notebook with the
    CIFAR data, later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we load the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: When dealing with libraries like TensorFlow, it is best to be quite explicit
    about data types. While Python will happily convert from one numerical data type
    to another implicitly, libraries like TensorFlow are wrappers around lower-level
    code (in this case, C++). These libraries are not able to always convert between
    numerical data types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our output is currently a single array of categorical values (0, 1 or 2 depending
    on the class). Neural networks *can *be developed to output data in this format,
    but the *normal convention* is for the neural network to have *n* outputs, where
    *n* in the number of classes. Due to this, we use one-hot encoding to convert
    our categorical y into a one-hot encoded `y_onehot`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We then split into training and testing datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we build our network by creating the different layers. Our dataset contains
    four input variables and three output classes. This gives us the size of the first
    and last layer, but not the layers in between. Playing around with this figure
    will give different results, and it is worth trailing different values to see
    what happens. We will create a small network to start with, with the following
    dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create our hidden layer and our output layer (the input layer is implicit).
    For this example we will use Dense layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: I encourage you to play with the activation value, and see how that affects
    the results. The values here are great defaults if you have no further information
    about your problem. That is, use `relu` for hidden layers, and `sigmoid` for the
    output layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then combine the layers into a Sequential model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: One necessary step from here is to compile the network, which creates the graph.
    In the compile step, we were given information on how the network will be trained
    and evaluated. The values here define what exactly it is that the neural network
    is trying to train to reduce, in the case below, it is the mean squared error
    between the output neurons and their expected values. The choice of optimizer
    largely affects how efficiently it can do this, often with a trade-off between
    speed and memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We then train our model using the `fit` function. Keras models return a history
    object from `fit()`, that allows us see the data at a fine-grained level.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You will get quite a lot of output. The neural network will train 10 epochs,
    which are training cycles of taking the training data, running it through the
    neural network, updating the weights and evaluating the results. If you investigate
    the history object (try `print(history.history)`) you will see the loss function's
    score after each of these epochs (lower is better). Also included is the accuracy,
    where higher is better. You will probably also notice that it hasn't really improved
    that much.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can plot out the history object using `matplotlib`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/B06162_11_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While the training loss is decreasing, it is not decreasing much. This is one
    issue with neural networks - they train slowly. By default, the fit function will
    only perform 10 epochs, which is nowhere near enough for nearly any application.
    To see this, use the neural network to predict the test set and run a classification
    report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are quite poor, with an overall f1-score of 0.07, and the classifier
    only predicting class 2 for all instances. At first, it might seem that neural
    networks are not that great but let''s have a look at what happens when we train
    for 1000 epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Visualizing the loss per epoch again, a very useful visualization when running
    iterative algorithms like neural networks, using the above code shows a very different
    story:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B06162_11_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we perform a classification report again to see the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Perfect.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get started with image analysis with Keras, we are going to reimplement
    the example we used in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*, to predict which letter was represented
    in an image. We will recreate the dense neural network we used in [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*,
    Beating CAPTCHAs with Neural Networks*. To start with, we need to enter our dataset
    building code again in our notebook. For a description of what this code does,
    refer to [Chapter 8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*, Beating CAPTCHAs
    with Neural Networks *(*remember to update the file location of the Coval font*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: After rerunning all of this code, you'll have a dataset similar to [Chapter
    8](ddd1527c-d895-4519-b709-8fe9680518c1.xhtml)*, Beating CAPTCHAs with Neural
    Networks* experiment. Next, instead of using scikit-learn to do our neural network,
    we will use Keras.
  prefs: []
  type: TYPE_NORMAL
- en: First, we create our two **Dense** layers and combine them in a **Sequential**
    model. I've chosen to put 100 neurons in the hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Then, we fit the model. As before, you will want to have quite a larger number
    of epochs. I've used 1000 again, if you want better results, you can increase
    this number.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: You can also collect the resulting history object, like we did with the Iris
    example, to investigate the training further.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Again, perfect.
  prefs: []
  type: TYPE_NORMAL
- en: At least, it was on my machine but your results may differ slightly.
  prefs: []
  type: TYPE_NORMAL
- en: GPU optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks can grow quite large in size. This has some implications for
    memory use; however, efficient structures such as sparse matrices mean that we
    don't generally run into problems fitting a neural network in memory.
  prefs: []
  type: TYPE_NORMAL
- en: The main issue when neural networks grow large is that they take a very long
    time to compute. In addition, some datasets and neural networks will need to run
    many epochs of training to get a good fit for the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The neural network we will train in this chapter takes more than 8 minutes per
    epoch on my reasonably powerful computer, and we expect to run dozens, potentially
    hundreds, of epochs. Some larger networks can take hours to train a single epoch.
    To get the best performance, you may be considering thousands of training cycles.
  prefs: []
  type: TYPE_NORMAL
- en: The scale of neural networks leads to long training times.
  prefs: []
  type: TYPE_NORMAL
- en: One positive is that neural networks are, at their core, full of floating point
    operations. There are also a large number of operations that can be performed
    in parallel, as neural network training is composed of mainly matrix operations.
    These factors mean that computing on GPUs is an attractive option to speed up
    this training.
  prefs: []
  type: TYPE_NORMAL
- en: When to use GPUs for computation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GPUs were originally designed to render graphics for display. These graphics
    are represented using matrices and mathematical equations on those matrices, which
    are then converted into the pixels that we see on our screen. This process involves
    lots of computation in parallel. While modern CPUs may have a number of cores
    (your computer may have 2, 4, or even 16—or more!), GPUs have thousands of small
    cores designed specifically for graphics.
  prefs: []
  type: TYPE_NORMAL
- en: A CPU is better for sequential tasks, as the cores tend to be individually faster
    and tasks such as accessing the computer's memory are more efficient. It is also,
    honestly, easier to just let the CPU do the heavy lifting. Almost every machine
    learning library defaults to using the CPU, and there is extra work involved before
    you can use the GPU for computing. The benefits can be quite significant.
  prefs: []
  type: TYPE_NORMAL
- en: GPUs are therefore better suited for tasks in which there are lots of small
    operations on numbers that can be performed at the same time. Many machine learning
    tasks are like this, lending themselves to efficiency improvements through the
    use of a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Getting your code to run on a GPU can be a frustrating experience. It depends
    greatly on what type of GPU you have, how it is configured, your operating system,
    and whether you are prepared to make some low-level changes to your computer.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, Keras will automatically use a GPU for operations, if the operation
    suits and a GPU can be found (and if you use TensorFlow as the backend). However,
    you still need to setup your computer such that the GPU can be found by Keras
    and TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three main avenues to take:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is to look at your computer, search for tools and drivers for your
    GPU and operating system, explore some of the many tutorials out there, and find
    one that fits your scenario. Whether this works depends on what your system is
    like. That said, this scenario is much easier than it was a few years ago, with
    better tools and drivers available to perform GPU-enabled computation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second avenue is to choose a system, find good documentation on setting
    it up and buy a system to match. This will work better, but can be fairly expensive—in
    most modern computers, the GPU is one of the most expensive parts. This is especially
    true if you want to get great performance out of the system—you'll need a really
    good GPU, which can be very expensive. If you are a business (or have larger amounts
    of money to spend), you can buy high-end GPUs specifically for deep learning and
    talk more directly to vendors to ensure you get the right hardware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third avenue is to use a virtual machine, which is already configured for
    such a purpose. For example, Altoros Systems has created such a system that runs
    on Amazon's Web Services. The system will cost you money to run, but the price
    is much less than that of a new computer. Depending on your location, the exact
    system you get and how much you use it, you are probably looking at less than
    $1 an hour, and often much, much less. If you use spot instances in Amazon's Web
    Services, you can run them for just a few cents per hour (although, you will need
    to develop your code to run on spot instances separately).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you aren't able to afford the running costs of a virtual machine, I recommend
    that you look into the first avenue, with your current system. You may also be
    able to pick up a good second-hand GPU from family or a friend who constantly
    updates their computer (gamer friends are great for this!).
  prefs: []
  type: TYPE_NORMAL
- en: Running our code on a GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are going to take the third avenue in this chapter and create a virtual machine
    based on Altoros Systems' base system. This will run on an Amazon's EC2 service.
    There are many other Web services to use, and the procedure will be slightly different
    for each. In this section, I'll outline the procedure for Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to use your own computer and have it configured to run GPU-enabled
    computation, feel free to skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: You can get more information on how this was set up, see [https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title](https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&sr=0-1&ref_=srh_res_product_title)
  prefs: []
  type: TYPE_NORMAL
- en: 'To start with, go to the AWS console at: [https://console.aws.amazon.com/console/home?region=us-east-1](https://console.aws.amazon.com/console/home?region=us-east-1)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in with your Amazon account. If you don't have one, you will be prompted
    to create one, which you will need to do in order to continue.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, go to the EC2 service console at: [https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.](https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Launch Instance and choose N. California as your location in the drop-down
    menu at the top-right.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Community AMIs and search for Ubuntu x64 AMI with TensorFlow (GPU),
    which is the machine created by Altoros Systems. Then, click on Select. On the
    next screen, choose g2.2xlarge as the machine type and click on Review and Launch.
    On the next screen, click on Launch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, you will be charged, so please remember to shut down your machines
    when you are done with them. You can go to the EC2 service, select the machine,
    and stop it. You won't be charged for machines that are not running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll be prompted with some information on how to connect to your instance.
    If you haven't used AWS before, you will probably need to create a new key pair
    to securely connect to your instance. In this case, give your key pair a name,
    download the pemfile, and store it in a safe place—if lost, you will not be able
    to connect to your instance again!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on Connect for information on using the pem file to connect to your instance.
    The most likely scenario is that you will use ssh with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Setting up the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we need to get our code onto the machine. There are many ways to get this
    file onto your computer, but one of the easiest is to just copy-and-paste the
    contents.
  prefs: []
  type: TYPE_NORMAL
- en: To start with, open the Jupyter Notebook we used before (on your computer, not
    on the Amazon Virtual Machine). On the Notebook itself is a menu. Click on File
    and then Download as. Select Python and save it to your computer. This procedure
    downloads the code in the Jupyter Notebook as a python script that you can run
    from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Open this file (on some systems, you may need to right-click and open with a
    text editor). Select all of the contents and copy them to your clipboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the Amazon Virtual Machine, move to the home directory and open nano with
    a new filename:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The nano program will open, which is a command-line text editor.
  prefs: []
  type: TYPE_NORMAL
- en: With this program open, paste the contents of your clipboard into this file.
    On some systems, you may need to use a file option of the ssh program, rather
    than pressing Ctrl+ V to paste.
  prefs: []
  type: TYPE_NORMAL
- en: In nano, press Ctrl+ O to save the file on the disk and then Ctrl+ X to exit
    the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ll also need the font file. The easiest way to do this is to download
    it again from the original location. To do this, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'While still in the virtual machine, you can run the program with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The program will run through as it would in the Jupyter Notebook and the results
    will print to the command line.
  prefs: []
  type: TYPE_NORMAL
- en: The results should be the same as before, but the actual training and testing
    of the neural network will be much faster. Note that it won't be that much faster
    in the other aspects of the program—we didn't write the CAPTCHA dataset creation
    to use a GPU, so we will not obtain a speedup there.
  prefs: []
  type: TYPE_NORMAL
- en: You may wish to shut down the Amazon virtual machine to save some money; we
    will be using it at the end of this chapter to run our main experiment, but will
    be developing the code on your main computer first.
  prefs: []
  type: TYPE_NORMAL
- en: Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Back on your main computer now, open the first Jupyter Notebook we created in
    this chapter—the one that we loaded the CIFAR dataset with. In this major experiment,
    we will take the CIFAR dataset, create a deep convolution neural network, and
    then run it on our GPU-based virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start with, we will take our CIFAR images and create a dataset with them.
    Unlike previously, we are going to preserve the pixel structure—that is, in rows
    and columns. First, load all the batches into a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The last line, the break, is to test the code—this will drastically reduce the
    number of training examples, allowing you to quickly see if your code is working.
    I'll prompt you later to remove this line after you have tested that the code
    works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create a dataset by stacking these batches on top of each other. We use
    NumPy''s vstack, which can be visualised as adding rows to the end of the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We then normalise the dataset to the range 0 to 1 and then force the type to
    be a 32-bit float (this is the only datatype the GPU-enabled virtual machine can
    run with):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We then do the same with the classes, except we perform a hstack, which is
    similar to adding columns to the end of the array. We could then use the OneHotEncoder
    to turn this into a one-hot array. I''ll show an alternate method here using a
    utility function present in Keras, but the result is the same either way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we split the dataset into training and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Next, we reshape the arrays to preserve the original data structure. The original
    data was 32-by-32-pixel images, with 3 values per pixel (for the red, green, and
    blue values). While standard feed-forward neural networks only take a single array
    of input data (see the CAPTCHA example), Convolutional Neural Networks are built
    for images and accept 3-dimensional image data (2-D image, and another dimension
    containing colour depth).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We now have a familiar training and testing dataset, along with the target classes
    for each. We can now build the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now build the convolutional neural network. I have performed some tinkering
    and found a layout that works well, but feel free to experiment with more layers
    (or fewer), layers of different types and different sizes. Smaller networks train
    faster, but larger networks can achieve better results.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create the layers of our neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We use dense layers for the last three layers as per a normal feed-forward neural
    network, but before that, we use convolution layers combined with pooling layers.
    We have three sets of these.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each pair of Convolution2D and MaxPooling2D layers, the following happens:'
  prefs: []
  type: TYPE_NORMAL
- en: The Convolution2D network fetches patches of the input data. These are passed
    through a filter, a matrix transformation akin to the kernel operator Support
    Vector Machines use. A filter is a smaller matrix, of size k by n (specified as
    3x3 in the Convolution2D initialiser above) that is applied to each k by n pattern
    found in the image. The result is a convolved feature.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The MaxPooling2D layer takes the results from the Convolution2D layer and finds
    the maximum value for each convolved feature.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While this does discard lots of information, this actually helps for image detection.
    If the object of an image is a few pixels to the right, a standard neural network
    will consider it a completely new image. In contrast, the convolution layer will
    find it and report almost the same output (depending, of course, on a wide variety
    of other factors).
  prefs: []
  type: TYPE_NORMAL
- en: After passing through these pairs layers, the features that go into the dense
    part of the network are meta-features that represent abstract concepts of the
    image, rather than specific qualities. Often these can be visualised, resulting
    in features like *a little bit of a line pointing up*.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we put these layers together to build our neural network and train it.
    This training will take substantially longer than previous training. I recommend
    starting with 10 epochs, make sure the code works all the way through, and then
    rerun with 100 epochs. Also, once you have confirmed that the code works and you
    get predictions out, go back and remove the `break` line we put in when creating
    the dataset (it is in the batches loop). This will allow the code to train on
    all of the samples, not just the first batch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can predict with the network and evaluate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: After running for 100 epochs, it is still not quite perfect in this case, but
    still an excellent result. If you have the time (say, overnight), try running
    the code for 1000 epochs. There is an increase in accuracy but a diminishing return
    on time invested. A (not so) good rule of thumb is that to halve the error, you
    need to double the training time.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our network code working, we can train it with our training
    dataset on the remote machine. If you used your local machine to run the neural
    network, you can skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: We need to upload the script to our virtual machine. As with before, click on
    File| Download as, Python, and save the script somewhere on your computer. Launch
    and connect to the virtual machine and upload the script as you did earlier (I
    called my script `chapter11cifar.py`—if you named yours differently, just update
    the following code).
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing we need is for the dataset to be on the virtual machine. The
    easiest way to do this is to go to the virtual machine and type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This will download the dataset. Once that has downloaded, you can extract the
    data to the Data folder by first creating that folder and then unzipping the data
    there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can run our example with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you'll notice is a drastic speedup. On my home computer, each
    epoch took over 100 seconds to run. On the GPU-enabled virtual machine, each epoch
    takes just 16 seconds! If we tried running 100 epochs on my computer, it would
    take nearly three hours, compared to just 26 minutes on the virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: This drastic speedup makes trialing different models much faster. Often with
    trialing machine learning algorithms, the computational complexity of a single
    algorithm doesn't matter too much. An algorithm might take a few seconds, minutes,
    or hours to run. If you are only running one model, it is unlikely that this training
    time will matter too much—especially as prediction, as with most machine learning
    algorithms,  is quite quick and that is where a machine learning model is mostly
    used.
  prefs: []
  type: TYPE_NORMAL
- en: However, when you have many parameters to run, you will suddenly need to train
    thousands of models with slightly different parameters—suddenly, these speed increases
    matter much more.
  prefs: []
  type: TYPE_NORMAL
- en: 'After 100 epochs of training, taking a whole 26 minutes, you will get a printout
    of the final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Not too bad! We can increase the number of epochs of training to improve this
    further or we might try changing the parameters instead; perhaps, more hidden
    nodes, more convolution layers, or an additional dense layer. There are other
    types of layers in Keras that could be tried too; although generally, convolution
    layers are better for vision.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at using deep neural networks, specifically convolution
    networks, in order to perform computer vision. We did this through the Keras package,
    which uses Tensorflow or Theano as its computation backend. The networks were
    relatively easy to build with Kera's helper functions.
  prefs: []
  type: TYPE_NORMAL
- en: The convolution networks were designed for computer vision, so it shouldn't
    be a surprise that the result was quite accurate. The final result shows that
    computer vision is indeed an effective application using today's algorithms and
    computational power.
  prefs: []
  type: TYPE_NORMAL
- en: We also used a GPU-enabled virtual machine to drastically speed up the process,
    by a factor of almost 10 for my machine. If you need extra power to run some of
    these algorithms, virtual machines by cloud providers can be an effective way
    to do this (usually for less than a dollar per hour)—just remember to turn them
    off when you are done!
  prefs: []
  type: TYPE_NORMAL
- en: To extend the work in this chapter, try play with the structure of the network
    to increase the accuracy further than what we obtained here. Another method that
    can be used to improve the accuracy is to create more data, either by taking your
    own pictures (slow) or by modifying the existing ones (much faster). To do the
    modification, you can flip images upside down, rotate, shear and so on. Keras
    has a function for doing this that is quite useful. See the documentation at [https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)
  prefs: []
  type: TYPE_NORMAL
- en: Another area worth investigating is variations in neural network structure,
    more nodes, fewer nodes, more layers and so on. Also experiment with different
    activation types, different layer types and different combinations.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter's focus was on a very complex algorithm. Convolution networks take
    a long time to train and have many parameters to train. Ultimately, the size of
    the data was small in comparison; although it was a large dataset, we can load
    it all in memory without even using sparse matrices. In the next chapter, we go
    for a much simpler algorithm, but a much, much larger dataset that can't fit in
    memory. This is the basis of Big Data and it underpins applications of data mining
    in many large industries such as mining and social networks.
  prefs: []
  type: TYPE_NORMAL
