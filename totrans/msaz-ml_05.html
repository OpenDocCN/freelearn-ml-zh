<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Data Preparation"><div class="titlepage"><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Data Preparation</h1></div></div></div><p>In practical scenarios, most of the time you would find that the data available for predictive analysis is not fit for the purpose. This is primarily because of two reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">In the real world, data is always messy. It usually has lots of unwanted items, such as missing values, duplicate records, data in different formats, data scattered all around, and so on.</li><li class="listitem" style="list-style-type: disc">Quite often, data is either required in a proper format or needs some preprocessing so that it is ready before we apply machine learning algorithms to it for predictive analysis.</li></ul></div><p>So, you need to prepare your data or transform your data to make it fit for the required analysis. ML Studio comes with different options to prepare your data, and in this chapter, you will explore options to preprocess data for some of the common scenarios and ways to prepare data when necessary modules are not readily available with ML Studio. This chapter aims to familiarize you with these options to provide you with an overview of the practical use of most of these options, which you will find in the subsequent chapters.</p><div class="section" title="Data manipulation"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec26"/>Data manipulation</h1></div></div></div><p>You may need to <a id="id134" class="indexterm"/>manipulate data to transform it to the required format. The following are some of the frequently used scenarios and modules available.</p><div class="section" title="Clean Missing Data"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec30"/>Clean Missing Data</h2></div></div></div><p>Clean missing data and missing values in data are probably the most common problems you need to fix before data analysis. When missing values are present, certain algorithms may not work or you may not have the desired result. So, you need to get rid of the missing values either by replacing them with some logical values or by removing the existing row(s) or column(s).</p><p>ML Studio comes with a module, <span class="strong"><strong>Clean Missing Data</strong></span>, to solve this exact problem. It lets you either remove the rows or columns that have missing values or lets you replace the values in the rows and columns with one of the these: mean, median, mode, custom values, a value <a id="id135" class="indexterm"/>that uses the probabilistic form of <span class="strong"><strong>Principal Component Analysis</strong></span> (<span class="strong"><strong>PCA</strong></span>), or <span class="strong"><strong>Multiple Imputation by Chained Equations</strong></span> (<span class="strong"><strong>MICE</strong></span>). MICE is a statistical technique that updates each column using an appropriate <a id="id136" class="indexterm"/>algorithm after initializing the missing entries with a default value. These updates are repeated a number of times and are specified by the <code class="literal">Number of Iterations</code> parameter. The default option is to replace the values of the rows and columns with a custom value, where you can specify a placeholder value, such as <code class="literal">0</code> or <code class="literal">NA</code> that is applied to all missing values. You should be careful that the value you specify matches the data type of the column.</p><p>The first output of the <a id="id137" class="indexterm"/>module is the cleaned dataset while the second one outputs the transformation that is to be passed to the module to clean new data. You can find the <span class="strong"><strong>Clean Missing Data</strong></span> module under <span class="strong"><strong>Data Transformation</strong></span> | <span class="strong"><strong>Manipulation</strong></span> in the module palette.</p><p> </p><div class="mediaobject"><img src="graphics/0792EN_05_01.jpg" alt="Clean Missing Data"/></div><p>
</p><p>In the last parameter, if you select the check box for <span class="strong"><strong>Generate missing value indicator column</strong></span>, then it will add a new column for each <a id="id138" class="indexterm"/>column containing missing values and will indicate the same for each row it finds a missing value for.</p></div><div class="section" title="Removing duplicate rows"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec31"/>Removing duplicate rows</h2></div></div></div><p>You use the <span class="strong"><strong>Remove </strong></span><a id="id139" class="indexterm"/>
<span class="strong"><strong>Duplicate Rows</strong></span> module to remove duplicate rows from the input dataset based on the list of columns you specify. Two rows are considered duplicates if the values of all the included columns are equal. This module also takes an input, that is, the <span class="strong"><strong>Retain first duplicate row</strong></span> checkbox, as an indicator that specifies whether to keep the first row of a set of duplicates and discard others or to keep the last duplicate row encountered and discard the rest.</p><div class="mediaobject"><img src="graphics/0792EN_05_14.jpg" alt="Removing duplicate rows"/></div></div><div class="section" title="Project columns"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec32"/>Project columns</h2></div></div></div><p>You can use the <span class="strong"><strong>Project </strong></span><a id="id140" class="indexterm"/>
<span class="strong"><strong>Columns</strong></span> module when you have to choose specific columns in a dataset for your analysis. Based on your requirements, you can do this either by excluding all columns and including a few columns. Alternatively, you can start with including all the columns and excluding a few.</p><div class="mediaobject"><img src="graphics/0792EN_05_02.jpg" alt="Project columns"/></div><p>The preceding screenshot illustrates how the <span class="strong"><strong>Projects Columns</strong></span> module just excludes one column from the <a id="id141" class="indexterm"/>given dataset. Also notice that you can tick the checkbox on the top, if you like, to keep the duplicate rows' and columns' order in the selection.</p></div><div class="section" title="The Metadata Editor module"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec33"/>The Metadata Editor module</h2></div></div></div><p>The <span class="strong"><strong>Metadata Editor</strong></span> <a id="id142" class="indexterm"/>module allows you to change the metadata of one or more columns in a dataset. You can change the following for a given dataset:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">You can change the Datatype of columns; for example, string to integer</li><li class="listitem" style="list-style-type: disc">You can change the type of columns to categorical or noncategorical; for example, one column may contain user IDs, which are integers, but you may consider them as categorical</li><li class="listitem" style="list-style-type: disc">You can change the <a id="id143" class="indexterm"/>consideration of column(s) as features or a label; for example, if one dataset has a column that contains income of a population you are interested making a prediction, you may want to consider it as a label or target variable</li><li class="listitem" style="list-style-type: disc">You can change the name of a column</li></ul></div><p>Let's take a look at the following screenshot which explains the various functions provided by the <span class="strong"><strong>Metadata Editor</strong></span> module:</p><div class="mediaobject"><img src="graphics/0792EN_05_03.jpg" alt="The Metadata Editor module"/></div></div><div class="section" title="The Add Columns module"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec34"/>The Add Columns module</h2></div></div></div><p>The <span class="strong"><strong>Add Columns</strong></span> <a id="id144" class="indexterm"/>module takes two datasets as input and <a id="id145" class="indexterm"/>concatenates both by combining all columns from the two datasets to create a single dataset. The resulting dataset will have the sum of the columns of both input datasets.</p><p>To add columns of two datasets to a single dataset, you need to keep in mind the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The columns in each dataset must have the same number of rows.</li><li class="listitem" style="list-style-type: disc">All the columns from each dataset are concatenated when you use the <span class="strong"><strong>Add Columns</strong></span> option. If you want to add only a subset of the columns, use the <span class="strong"><strong>Project Columns</strong></span> module on the result set to create a dataset with the columns you want.</li><li class="listitem" style="list-style-type: disc">If there are two <a id="id146" class="indexterm"/>columns with the same name, then a numeric suffix will be added to the column name that comes from the right-hand side input.<div class="mediaobject"><img src="graphics/0792EN_05_04.jpg" alt="The Add Columns module"/></div></li></ul></div></div><div class="section" title="The Add Rows module"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec35"/>The Add Rows module</h2></div></div></div><p>The <span class="strong"><strong>Add Rows</strong></span> <a id="id147" class="indexterm"/>module takes two datasets as input and concatenates them by appending the rows of the second dataset after the first dataset.</p><p>To add rows of two <a id="id148" class="indexterm"/>datasets to a single dataset, you need keep in mind of the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Both the datasets must have the same number of columns</li></ul></div><p>The resulted dataset will have the sum of the number of rows of both the input datasets:</p><div class="mediaobject"><img src="graphics/0792EN_05_05.jpg" alt="The Add Rows module"/></div></div><div class="section" title="The Join module"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec36"/>The Join module</h2></div></div></div><p>The <span class="strong"><strong>Join</strong></span> module lets <a id="id149" class="indexterm"/>you join two datasets. If you are familiar with RDBMS, then you may find it similar to SQL-like join operations; however, no SQL knowledge <a id="id150" class="indexterm"/>is required to use it. You can perform the following kinds of join operation:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Inner Join</strong></span>: This is a <a id="id151" class="indexterm"/>typical join operation. It returns the <a id="id152" class="indexterm"/>combined rows only when the values of the key columns match.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Left Outer Join</strong></span>: This <a id="id153" class="indexterm"/>returns the joined rows for all the <a id="id154" class="indexterm"/>rows from the left-hand side table. When a row in the left-hand side table has no matching rows in the right-hand side table, the returned row contains the missing values of all the columns coming from the right-hand side table.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Full Outer Join</strong></span>: This <a id="id155" class="indexterm"/>returns the joined rows from <a id="id156" class="indexterm"/>both datasets with first the result from the <span class="strong"><strong>Inner Join</strong></span> operation and then appends the rows with a mismatch.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Left Semi-Join</strong></span>: This returns <a id="id157" class="indexterm"/>just the row from the <a id="id158" class="indexterm"/>left-hand side table when the values of <a id="id159" class="indexterm"/>the key column(s) match.<div class="mediaobject"><img src="graphics/0792EN_05_06.jpg" alt="The Join module"/></div></li></ul></div></div></div></div>
<div class="section" title="Splitting data"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec27"/>Splitting data</h1></div></div></div><p>Quite often, you would <a id="id160" class="indexterm"/>need to split your dataset; most commonly, you would need to split a given dataset for analysis into train and test dataset. ML Studio comes with a <span class="strong"><strong>Split</strong></span> module for this purpose. It lets you split your dataset into two datasets based on a specified fraction. So, if you choose <span class="strong"><strong>0.8</strong></span>, it outputs the first dataset with 80 percent of the input dataset, and the rest 20 percent as second output. You also have an option to split the data randomly. You can specify a random seed value other than 0 if you need to get the same result in a random split every time you run it. You can find the <span class="strong"><strong>Split</strong></span> module under <span class="strong"><strong>Data Transformation</strong></span> | <span class="strong"><strong>Sample</strong></span>, and then Split it in the module palette:</p><div class="mediaobject"><img src="graphics/0792EN_05_07.jpg" alt="Splitting data"/></div><p>Notice that the last parameter, <span class="strong"><strong>Stratified split</strong></span>, is <span class="strong"><strong>False</strong></span> by default, and you make it <span class="strong"><strong>True</strong></span> only when you go for a stratified split, which means it groups first and then randomly selects rows from each strata (group). In this case, you need to specify the <span class="strong"><strong>Stratification key</strong></span> column based on which grouping will be made.</p><p>You can also specify different <a id="id161" class="indexterm"/>Splitting modes as the parameter instead of specifying default split rows, such as:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>The Recommender Split</strong></span>: You can choose this when you need to split data to use it as <a id="id162" class="indexterm"/>train and test data in a recommendation model.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>The Regular Expression</strong></span>: You can use this option to specify a regular expression to split the dataset into two sets of rows—rows with values matching the <a id="id163" class="indexterm"/>expression and all the remaining rows. The regular expression is applied only to the specified column in the dataset. This splitting option is helpful for a variety of pre-preprocessing and filtering tasks. For example, you can apply a filter on all rows containing the text <span class="emphasis"><em>Social</em></span> by applying the following regular expression to a string column <span class="emphasis"><em>text Social</em></span>.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>The Relative Expression</strong></span>: You can use this option and create relational expressions that <a id="id164" class="indexterm"/>act as filters on numerical <a id="id165" class="indexterm"/>columns; for example, the following expression selects all rows where the values in the column are greater than 2000, such as <span class="emphasis"><em>ColumnName&gt;2000</em></span>.</li></ul></div></div>
<div class="section" title="Do it yourself"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec28"/>Do it yourself</h1></div></div></div><p>Start a new experiment and drag the sample dataset, the <span class="strong"><strong>Adult Census Income Binary Classification</strong></span> dataset, from the module palette under the <span class="strong"><strong>Saved Datasets</strong></span> group. Then, do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Visualize the dataset and find out all the columns that have missing values</li><li class="listitem" style="list-style-type: disc">Use the <span class="strong"><strong>Clean Missing Data</strong></span> module to replace the missing values with 0</li><li class="listitem" style="list-style-type: disc">On the result dataset of the previously used <span class="strong"><strong>Metadata Editor</strong></span> module, select all the columns except income and identify them as feature fields</li><li class="listitem" style="list-style-type: disc">On the result dataset of the previously used the <span class="strong"><strong>Split</strong></span> module, split the dataset into 80 percent and 20 percent using the same module</li><li class="listitem" style="list-style-type: disc">Run the experiment and visualize the dataset from both the output ports of the <span class="strong"><strong>Split</strong></span> module</li></ul></div><p>Your experiment may look like the following:</p><div class="mediaobject"><img src="graphics/0792EN_05_13.jpg" alt="Do it yourself"/></div></div>
<div class="section" title="The Apply SQL Transformation module"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec29"/>The Apply SQL Transformation module</h1></div></div></div><p>The <span class="strong"><strong>Apply SQL Transformation</strong></span> module lets you run a SQL query on the input dataset(s) and get <a id="id166" class="indexterm"/>the desired result. You can find it under <span class="strong"><strong>Data Transformation</strong></span> | <span class="strong"><strong>Manipulation</strong></span> in the module palette. The module can take one, two, or three datasets as inputs. The dataset coming from input 1 can be referenced as <span class="strong"><strong>t1</strong></span>. Similarly, you can refer to datasets from input 2 and input 3 as <span class="strong"><strong>t2</strong></span> and <span class="strong"><strong>t3</strong></span>, respectively. On the properties of the module, the <span class="strong"><strong>Apply SQL Transformation</strong></span> module takes only a parameter as a SQL query. The syntax of the SQL it supports is based on the SQLite standard.</p><p>In the following illustration, the module takes data from two datasets, joins them, and selects fewer columns. It also generates calculated columns by applying an aggregation function, AVG.</p><div class="mediaobject"><img src="graphics/0792EN_05_15.jpg" alt="The Apply SQL Transformation module"/></div><p>If you are already familiar with SQL, you may find this module very handy for data transformation.</p></div>
<div class="section" title="Advanced data preprocessing"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec30"/>Advanced data preprocessing</h1></div></div></div><p>ML Studio also comes <a id="id167" class="indexterm"/>with advanced data processing options. The following are some of the common options that are discussed in brief.</p><div class="section" title="Removing outliers"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec37"/>Removing outliers</h2></div></div></div><p>Outliers are data <a id="id168" class="indexterm"/>points that are distinctly separate from the rest <a id="id169" class="indexterm"/>of the data. Outliers, if present in your dataset, may cause problems by distorting your predictive model that may result in an unreliable prediction of the data. In many cases, it is a good idea to clip or remove the outliers.</p><p>ML Studio comes with the <span class="strong"><strong>Clip Values</strong></span> module, which detects outliers and lets you clip or replace values with a threshold, mean, median, or missing value. By default, it is applied to all the numeric columns, but you can select one or more columns. You can find it by navigating to <a id="id170" class="indexterm"/>
<span class="strong"><strong>Data Transformation</strong></span> | <span class="strong"><strong>Scale</strong></span> and then <span class="strong"><strong>Reduce</strong></span> <a id="id171" class="indexterm"/>in the module palette.</p><div class="mediaobject"><img src="graphics/0792EN_05_08.jpg" alt="Removing outliers"/></div></div><div class="section" title="Data normalization"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec38"/>Data normalization</h2></div></div></div><p>Often, different <a id="id172" class="indexterm"/>columns in a dataset come in different scales; for <a id="id173" class="indexterm"/>example, you may have a dataset with two columns: age, with values ranging from 15 to 95, and annual income, with values ranging from $30,000 to $300,000. This may be problematic in some cases where certain machine algorithms require data to be in the same scale.</p><p>ML Studio comes with the <span class="strong"><strong>Normalize Data</strong></span> module, which applies a mathematical function to numeric data to make dataset values conform to a common scale; for example, transforming all numeric <a id="id174" class="indexterm"/>columns to have values between 0 to 1. By default, the <a id="id175" class="indexterm"/>module is applied to all numeric columns, but you can select one or more columns. Also, you can choose from the following mathematical functions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Z-Score</li><li class="listitem" style="list-style-type: disc">Min-max</li><li class="listitem" style="list-style-type: disc">Logistic</li><li class="listitem" style="list-style-type: disc">Log-normal</li><li class="listitem" style="list-style-type: disc">Tanh<div class="mediaobject"><img src="graphics/0792EN_05_09.jpg" alt="Data normalization"/></div></li></ul></div></div><div class="section" title="The Apply Math Operation module"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec39"/>The Apply Math Operation module</h2></div></div></div><p>Sometimes, you may need to perform a mathematical operation on your dataset as a part of your data <a id="id176" class="indexterm"/>preparation. In ML Studio, you can use the <span class="strong"><strong>Apply Math Operation</strong></span> module, which takes a dataset as input and returns a data table <a id="id177" class="indexterm"/>where elements of the selected columns have been transformed by the specified math operation. For unary operations, such as Abs(x), the operation is applied to each of the elements. For binary operations, such as Subtract(x, y), two selections of columns are required and the result is computed over pairs of elements between columns. It gives you a range of mathematical functions grouped under different categories. By default, it is applied to all numeric columns, but you can select one or more columns. You can find it under the <span class="strong"><strong>Statistical Functions</strong></span> module in the module palette.</p><div class="mediaobject"><img src="graphics/0792EN_05_10.jpg" alt="The Apply Math Operation module"/></div></div><div class="section" title="Feature selection"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec40"/>Feature selection</h2></div></div></div><p>Not all features or <a id="id178" class="indexterm"/>columns in a dataset have the same predictive power. There are times when data contains many redundant or irrelevant features. Redundant features provide no additional information than the currently selected features, and irrelevant features provide no useful information in any context. So, it's ideal to get rid of redundant or irrelevant features from the dataset before applying predictive analysis.</p><p>ML Studio comes with the following two modules for feature selection, which takes an input dataset and result dataset with filtered columns or features.</p><div class="section" title="The Filter Based Feature Selection module"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec20"/>The Filter Based Feature Selection module</h3></div></div></div><p>The <span class="strong"><strong>Filter </strong></span><a id="id179" class="indexterm"/>
<span class="strong"><strong>Based Feature </strong></span><a id="id180" class="indexterm"/>
<span class="strong"><strong>Selection</strong></span> module uses different statistical tests to determine a subset of features with the highest predictive power. You can find it under <span class="strong"><strong>Feature Selection</strong></span> in the module palette. It takes a dataset as input that contains two or more feature columns. The first output is a dataset containing the top N predictive-powered features (columns). The second output is a dataset containing the scores assigned to the selected columns (scalars). This module selects the important features from a dataset based on the following heuristic option that you've chosen:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Pearson's correlation option</li><li class="listitem" style="list-style-type: disc">Mutual information option</li><li class="listitem" style="list-style-type: disc">Kendall's correlation option</li><li class="listitem" style="list-style-type: disc">Spearman's correlation option</li><li class="listitem" style="list-style-type: disc">Chi squared option</li><li class="listitem" style="list-style-type: disc">Fisher score option</li><li class="listitem" style="list-style-type: disc">Count based option</li></ul></div><p>Pearson's correlation is the default option in the <span class="strong"><strong>Filter Based Feature Selection</strong></span> module. It works with numeric, logical, and categorical string columns. You should note that all the heuristics or <a id="id181" class="indexterm"/>scoring methods don't <a id="id182" class="indexterm"/>work with all types of data. So, your selection of the scoring method depends, in part, on the type of data you have. For more details on these scoring methods, you may refer to the product documentation.</p><div class="mediaobject"><img src="graphics/0792EN_05_11.jpg" alt="The Filter Based Feature Selection module"/></div></div><div class="section" title="The Fisher Linear Discriminant Analysis module"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec21"/>The Fisher Linear Discriminant Analysis module</h3></div></div></div><p>The <span class="strong"><strong>Fisher </strong></span><a id="id183" class="indexterm"/>
<span class="strong"><strong>Linear Discriminant </strong></span><a id="id184" class="indexterm"/>
<span class="strong"><strong>Analysis</strong></span> module finds a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination is usually used for dimensionality reduction before or <a id="id185" class="indexterm"/>after the classification. You <a id="id186" class="indexterm"/>can find it under <span class="strong"><strong>Feature Selection</strong></span> in the module palette.</p><div class="mediaobject"><img src="graphics/0792EN_05_12.jpg" alt="The Fisher Linear Discriminant Analysis module"/></div></div></div><div class="section" title="Data preparation beyond ready-made modules"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec41"/>Data preparation beyond ready-made modules</h2></div></div></div><p>Though ML Studio <a id="id187" class="indexterm"/>comes with many data preprocessing modules, you may come across situations when the available modules don't solve your needs. These are the times you may need to write code in R or Python, run them in ML Studio, and make this part of your experiment. You can find more information on how to write code and extend ML Studio in <a class="link" href="ch10.html" title="Chapter 10. Extensibility with R and Python">Chapter 10</a>, <span class="emphasis"><em>Extensibility with R and Python</em></span>.</p><p>It is recommended, as of now, that you do any data preparation inside ML Studio if your data size is within a couple of gigabytes (GB). If you are dealing with more data, then you should prepare your data outside ML Studio, say, using an SQL database or using big data technologies, such as Microsoft's cloud-based Hadoop service <span class="strong"><strong>HDInsight</strong></span>. Then, you should consume the prepared data inside ML Studio for predictive analytics.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec31"/>Summary</h1></div></div></div><p>In any data analysis task, data preparation consumes most of your time. In this chapter, you learned about different data preparation options in ML Studio, starting with exploring the importance of data preparation. Then, you familiarized yourself with some of the very common data transformation tasks, such as dealing with missing values, duplicate values, concatenating rows or columns of two datasets, SQL-like joining datasets, selecting columns in a dataset, and splitting a dataset. You also learned how to apply SQL queries to transform datasets. You explored some of the advanced options of transforming a dataset by applying math functions, normalization, and feature selection.</p><p>In the next chapter, you can start applying the machine learning algorithm and, in particular, the regression algorithms that come with ML Studio.</p></div></body></html>