["```py\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\n>>> pca = PCA(n_components=10)\n>>> scaler = StandardScaler()\n>>> svc = SVC(kernel='poly', gamma=3)\n\n>>> steps = [\n>>>    ('pca', pca),\n>>>    ('scaler', scaler),\n>>>    ('classifier', svc)\n>>> ]\n\n>>> pipeline = Pipeline(steps)\n```", "```py\nfrom sklearn.datasets import make_classification\n\n>>> nb_samples = 500\n>>> X, Y = make_classification(n_samples=nb_samples, n_informative=15, n_redundant=5, n_classes=2)\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n\n>>> param_grid = {\n>>>    'pca__n_components': [5, 10, 12, 15, 18, 20],\n>>>    'classifier__kernel': ['rbf', 'poly'],\n>>>    'classifier__gamma': [0.05, 0.1, 0.2, 0.5],\n>>>    'classifier__degree': [2, 3, 5]\n>>> }\n\n>>> gs = GridSearchCV(pipeline, param_grid)\n>>> gs.fit(X, Y)\n```", "```py\n>>> print(gs.best_estimator_)\nPipeline(steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=2, gamma=0.2, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))])\n```", "```py\n>>> print(gs.best_score_)\n0.96\n```", "```py\nfrom sklearn.datasets import load_digits\nfrom sklearn.decomposition import NMF\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.linear_model import LogisticRegression\n\n>>> digits = load_digits()\n\n>>> pca = PCA()\n>>> nmf = NMF()\n>>> kbest = SelectKBest(f_classif)\n>>> lr = LogisticRegression()\n\n>>> pipeline_steps = [\n>>>    ('dimensionality_reduction', pca),\n>>>    ('normalization', scaler),\n>>>    ('classification', lr)\n>>> ]\n\n>>> pipeline = Pipeline(pipeline_steps)\n```", "```py\n>>> pca_nmf_components = [10, 20, 30]\n\n>>> param_grid = [\n>>>    {\n>>>        'dimensionality_reduction': [pca],\n>>>        'dimensionality_reduction__n_components': pca_nmf_components,\n>>>        'classification': [lr],\n>>>        'classification__C': [1, 5, 10, 20]\n>>>    },\n>>>    {\n>>>        'dimensionality_reduction': [pca],\n>>>        'dimensionality_reduction__n_components': pca_nmf_components,\n>>>        'classification': [svc],\n>>>        'classification__kernel': ['rbf', 'poly'],\n>>>        'classification__gamma': [0.05, 0.1, 0.2, 0.5, 1.0],\n>>>        'classification__degree': [2, 3, 5],\n>>>        'classification__C': [1, 5, 10, 20]\n>>>    },\n>>>    {\n>>>        'dimensionality_reduction': [nmf],\n>>>        'dimensionality_reduction__n_components': pca_nmf_components,\n>>>        'classification': [lr],\n>>>        'classification__C': [1, 5, 10, 20]\n>>>    },\n>>>    {\n>>>        'dimensionality_reduction': [nmf],\n>>>        'dimensionality_reduction__n_components': pca_nmf_components,\n>>>        'classification': [svc],\n>>>        'classification__kernel': ['rbf', 'poly'],\n>>>        'classification__gamma': [0.05, 0.1, 0.2, 0.5, 1.0],\n>>>        'classification__degree': [2, 3, 5],\n>>>        'classification__C': [1, 5, 10, 20]\n>>>    },\n>>>    {\n>>>        'dimensionality_reduction': [kbest],\n>>>        'classification': [svc],\n>>>        'classification__kernel': ['rbf', 'poly'],\n>>>        'classification__gamma': [0.05, 0.1, 0.2, 0.5, 1.0],\n>>>        'classification__degree': [2, 3, 5],\n>>>        'classification__C': [1, 5, 10, 20]\n>>>    },\n>>> ]\n\n>>> gs = GridSearchCV(pipeline, param_grid)\n>>> gs.fit(digits.data, digits.target)\n```", "```py\n>>> print(gs.best_estimator_)\nPipeline(steps=[('dimensionality_reduction', PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n  svd_solver='auto', tol=0.0, whiten=False)), ('normalization', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classification', SVC(C=5.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=2, gamma=0.05, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))])\n```", "```py\n>>> print(gs.best_score_)\n0.968836950473\n```", "```py\nfrom sklearn.pipeline import FeatureUnion\n\n>>> steps_fu = [\n>>>    ('pca', PCA(n_components=10)),\n>>>    ('kbest', SelectKBest(f_classif, k=5)),\n>>> ]\n\n>>> fu = FeatureUnion(steps_fu)\n\n>>> svc = SVC(kernel='rbf', C=5.0, gamma=0.05)\n\n>>> pipeline_steps = [\n>>>    ('fu', fu),\n>>>    ('scaler', scaler),\n>>>    ('classifier', svc)\n>>> ]\n\n>>> pipeline = Pipeline(pipeline_steps)\n```", "```py\nfrom sklearn.model_selection import cross_val_score\n >>> print(cross_val_score(pipeline, digits.data, digits.target, cv=10).mean())\n0.965464333604\n```"]