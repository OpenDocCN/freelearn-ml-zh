- en: '*Chapter 2:*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploratory Analysis of Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Define a problem statement with industry standard frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform univariate and bivariate analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain multivariate analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform hypothesis testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform data wrangling using the dplyr and reshape2 packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualize data using the ggplot2 package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will acquaint learners with techniques to clean, transform,
    and visualize data in order to get useful insights.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Chapter 1*, *R for Advanced Analytics*, introduced to you the R language and
    its ecosystem for data science. We are now ready to enter a crucial part of data
    science and machine learning, that is, **Exploratory Data Analysis** (**EDA**),
    the art of understanding the data.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will approach EDA with the same banking dataset used in
    the previous chapter, but in a more problem-centric way. We will start by defining
    the problem statement with industry standard artifacts, design a solution for
    the problem, and learn how EDA fits in the larger problem framework. We will then
    tackle the EDA for the direct marketing campaigns (phone calls) of a Portuguese
    banking institution use case using a combination of data engineering, data wrangling,
    and data visualization techniques in R, backed up by a business-centric approach.
  prefs: []
  type: TYPE_NORMAL
- en: In any data science use case, understanding the data consumes the bulk of the
    time and effort. Most data science professionals spend around 80% of their time
    understanding data. Given that this is the most crucial part of your journey,
    it is important to have a macro-view of the overall process for any data science
    use case.
  prefs: []
  type: TYPE_NORMAL
- en: A typical data science use case takes the path of a core business-analytics
    problem or a machine-learning problem. With either path approached, EDA is inevitable.
    *Figure 2.1* demonstrates the life cycle of a basic data science use case. It
    starts by defining the problem statement using one or more standard frameworks,
    and then it delves into data gathering and reaches EDA. The majority of efforts
    and time in any project is consumed in EDA. Once the process of understanding
    the data is complete, a project may take a different path based on the scope of
    the use case. In most business analytics-based use cases, the next step is to
    assimilate all the observed patterns into meaningful insights. Though this might
    sound trivial, it is an iterative and arduous task. This step then evolves into
    story-telling, where the condensed insights are tailored into a meaningful story
    for the business stakeholders. Similarly, in scenarios where the objective is
    to develop a predictive model, the next step would be to actually develop a machine
    learning model and then deploy it into a production system/product.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Life cycle of a data science use case'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.1: Life cycle of a data science use case'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's take a brief look at the first step, *Defining the Problem Statement*.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Problem Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you recollect the data we explored in *Chapter 1*, *R for Advanced Analytics*,
    bank marketing data, we have a dataset that captures the telemarketing campaigns
    conducted by a bank to attract customers.
  prefs: []
  type: TYPE_NORMAL
- en: A large multinational bank is designing a marketing campaign to achieve its
    growth target by enticing customers for bank deposits. The campaign has been ineffective
    in luring customers, and the marketing team wants to understand how the campaign
    can be improved to achieve the growth targets.
  prefs: []
  type: TYPE_NORMAL
- en: We can reframe the problem from the business stakeholders' perspective and try
    to see what kind of solution would best fit here.
  prefs: []
  type: TYPE_NORMAL
- en: Problem-Designing Artifacts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just like there are several frameworks, templates, and artifacts for software
    engineering and other industrial projects, data science and business analytics
    projects can also be effectively represented using industry standard artifacts.
    Some popular choices are available from consulting giants such as McKinsey, BCG,
    and decision sciences giants such as Mu Sigma. We will use a popular framework
    based on the **Minto Pyramid** principle called **Situation - Complication -Question
    Analysis** (**SCQ**).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try defining the problem statement in the following construct:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Situation**: Define the current situation. We can simplify this by answering
    the question—what happened?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large multinational bank is designing a marketing campaign to achieve its
    growth target by enticing customers for bank deposits. The campaign has been ineffective
    in luring customers, and the marketing team wants to understand how the campaign
    can be improved to achieve the growth targets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the previous section, we saw a hypothetical business problem framed for the
    banking data's use case. Though this might be different in reality, we are definitely
    trying to solve a valid use case. By representing the problem statement in the
    format demonstrated as in the previous format, we have a clear area to focus on
    and solve. This solves the first step in the life cycle of a typical data science
    use case. The second step is data gathering, which we explored in the previous
    chapter. We will refer to the same dataset provided by UCI machine learning repository
    at [https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing](https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Moro et al., 2014] S. Moro, P. Cortez, and P. Rita. A Data-Driven Approach
    to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier,
    62:22-31, June 2014.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to the final step: EDA. In this use case, we want to understand
    the various factors that are leading to the poor performance of the campaign.
    Before we delve into the actual exercise, let''s take a moment to understand the
    concept of EDA in a more intuitive way.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Science Behind EDA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In layman's terms, we can define EDA as the science of understanding data. A
    more formal definition is the process of analyzing and exploring datasets to summarize
    its characteristics, properties, and latent relationships using statistical, visual,
    analytical, or a combination of techniques.
  prefs: []
  type: TYPE_NORMAL
- en: To cement our understanding, let's break down the definition further. The dataset
    is a combination of numeric and categorical features. To study the data, we might
    need to explore features individually, and to study relationships, we might need
    to explore features together. Depending on the number of features and the type
    of features, we may cross paths with different types of EDA.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simplify, we can broadly classify the process of EDA as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Univariate analysis**: Studying a single feature'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bivariate analysis**: Studying the relationship between two features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multivariate analysis**: Studying the relationship between more than two
    features'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For now, we will restrict the scope of the chapter to **univariate** and **bivariate**
    analysis. A few forms of multivariate analysis, such as regression, will be covered
    in the upcoming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish each of the previously mentioned analyses, we can use visualization
    techniques such as boxplots, scatter plots, and bar charts; statistical techniques
    such as hypothesis testing; or simple analytical techniques such as averages,
    frequency counts, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking this further down, we have another dimension to cater to, that is,
    the types of features—**numeric** or **categorical**. In each of the type of analysis
    mentioned—**univariate** and **bivariate**—based on the type of the feature, we
    might have a different visual technique to accomplish the study. So, for univariate
    analysis of a numeric variable, we could use a histogram or a boxplot, whereas
    we might use a frequency bar chart for a categorical variable. We will get into
    the details of the overall exercise of EDA using a *lazy programming* approach,
    that is, we will explore the context and details of the analysis as and when it
    occurs in the book.
  prefs: []
  type: TYPE_NORMAL
- en: With the basic background context set for the exercise, let's get ready for
    a specific EDA exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will get started with the dataset available to download from UCI ML Repository
    at [https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing](https://archive.ics.uci.edu/ml/datasets/Bank%20Marketing).
  prefs: []
  type: TYPE_NORMAL
- en: Download the ZIP file and extract it to a folder in your workspace and use the
    file named `bank-additional-full.csv`. Ask the students to start a new Jupyter
    notebook or an IDE of their choice and load the data into memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 18: Studying the Data Dimensions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's quickly ingest the data using the simple commands we explored in the previous
    chapter and take a look at a few essential characteristics of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We are exploring the length and breadth of the data, that is, the number of
    rows and columns, the names of each column, the data type of each column, and
    a high-level view of what is stored in each column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to explore the bank dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import all the required libraries in RStudio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the `option` method to set the `width` and `height` of the plot as
    `12` and `4`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Ensure that you download and place the `bank-additional-full.csv` file in the
    appropriate folder. You can access the file from [http://bit.ly/2DR4P9I](http://bit.ly/2DR4P9I).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a DataFrame object and read the CSV file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the following command to display the data from the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.2: Bank data from the bank-additional-full CSV file'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.2: Bank data from the bank-additional-full CSV file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding example, we used the traditional `read.csv` function that's
    available in R to read the file into memory. We added an argument to the `sep=";"`
    function since the file is semicolon separated. The `str` function prints the
    high-level information we require about the dataset. If you carefully observe
    the output snippet, you can see that the first line denotes the shape of data,
    that is, the number of rows/observations and the number of columns/variables.
  prefs: []
  type: TYPE_NORMAL
- en: The next 21 lines in the output snippet give us a sneak-peek of each variable
    in dataset. It displays the name of the variable, its datatype, and the first
    few values in the dataset. We have one line for each column. The `str` function
    practically gives us a macro-view of the entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the dataset, we have 20 independent variables, such as `age`,
    `job`, and `education`, and one outcome/dependent variable—`y`. Here, the outcome
    variable defines whether the campaign call made to the client resulted in a successful
    deposit sign-up with `yes` or `no`. To understand the overall dataset, we now
    need to study each variable in the dataset. Let's first hop on to univariate analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Univariate Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`age`, `duration`, `nr.employed` (numeric features in the dataset) and many
    others, we look at summary statistics such as min, max, mean, standard deviation,
    and percentile distribution. These measures together help us understand the spread
    of the data. Similarly, for categorical features such as `job`, `marital`, and
    `education`, we need to study the distinct values in the feature and the frequency
    of these values. To accomplish this, we can implement a few analytical, visual,
    and statistical techniques. Let''s take a look at the analytical and visual techniques
    for exploring numeric features.'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Numeric/Continuous Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you explored the previous output snippet, you might have noted that we have
    a mix of numeric and categorical features in the dataset. Let's start by looking
    at the first feature in the dataset, which is a numeric feature named `age`. As
    the name suggests, it denotes the age of the customer being targeted. Let's take
    a look at the summary statistics of the feature and visualize it using a simple
    boxplot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 19: Visualizing Data Using a Box Plot'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will explore using a boxplot for univariate analysis, explain
    how to interpret the boxplot, and walk through the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to visualize the data using a boxplot:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the ggplot2 package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the `age` data, such as `mean` and `max`, using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, print the standard deviation of age as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, plot the boxplot using of age with following parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.3: Boxplot of age.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.3: Boxplot of age.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We first load the `ggplot2` library, which provides handy functions for visualizing
    the data. R provides a simple function called `summary`, which prints summary
    statistics such as min, max, median, mean, 75th percentile, and 25th percentile
    values. The next line uses the `sd` function to compute the standard deviation,
    and, lastly, the final line uses the `ggplot` library to plot the boxplot for
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: If you explore the variable with the output from the summary statistics, we
    can see that age has a minimum value of 17, a max of 98, and a mean of 42\. If
    you take a close look at the gap between the 75th percentile (3rd quartile) and
    the 100th percentile (max), we can see a huge jump. This indicates that there
    are outliers present in the age variable. The presence of outliers will incorrectly
    change your conclusions from the analysis. In some cases, when there is just one
    data point with a value of `1000x` the 75th percentile, your mean will shift toward
    the right. In scenarios where you would use just mean as a ballpark figure to
    give an estimate of the variable, the whole understanding of the feature might
    be misleading.
  prefs: []
  type: TYPE_NORMAL
- en: The boxplot, on the other hand, helps us visually consume this information in
    a simple and lucid way. The boxplot splits the data into three quartiles. The
    lower quartile, that is, the line below the box, represents the min and the 25th
    percentile. The middle quartile represents the 25th to 50th to 75th percentile.
    The upper quartile represents the 75th to the 100th percentile. The dots above
    the 100th percentile are outliers determined by the internal functions. As we
    can see, the observation from the summary statistics are in line with the boxplots.
    We do see outliers, marked as dots above the upper quartile.
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we will perform an EDA on the age variable using a histogram.
    Let's see what insight we can get from the histogram plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 20: Visualizing Data Using a Histogram'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will discuss how to interpret the histogram and outliers.
    Let's continue from the previous exercise.
  prefs: []
  type: TYPE_NORMAL
- en: In order to get a more detailed view of the data and closely understand how
    the `age` variable is organized, we can use histograms. A histogram is a special
    bar plot, where the data is grouped and sequentially arranged into equal intervals
    called `bins`, and the frequency of data points in the respective bins are plotted.
    The histogram helps us to understand the distribution of the data more effectively.
    The exercise plots the histogram to help us visualize the data more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the ggplot2 package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the following command to plot the histogram for age using the provided
    parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.4: Histogram for age'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.4: Histogram for age'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `ggplot` function defines the base layer for visualization, which is then
    followed by the `geom_histogram` function with parameters that define the histogram-related
    aspects such as the number of bins, color to fill, alpha (opacity), and many more.
    The number of bins is also calculated by default, but it can be overridden by
    passing a value to the `bin` parameter, such as `bin=10`. The next function, `ggtitle`,
    is used to add a title to the plot, and the `theme_bw` function is added to change
    the theme to black and white instead of the default. The `theme` function is optional
    and is added here for only visually appealing plots.
  prefs: []
  type: TYPE_NORMAL
- en: As you can clearly see, the histogram gives us a more granular view of the data
    distribution for the feature. We can understand that the number of records drastically
    reduce after 65 and only a few records have values beyond 75\. In some cases,
    choosing the number of bins for the histogram becomes important as higher number
    of bins make the distribution messy and a smaller number of bins make the distribution
    less informative. In scenarios where we would want to see a much more granular
    view of the distribution, instead of increasing the number of bins for the histogram,
    we can opt for visualizing using a density plot that visualizes the plot over
    a continuous interval while using kernel smoothing to smooth out the noise.
  prefs: []
  type: TYPE_NORMAL
- en: We can also visualize the age variable using a density plot rather a histogram.
    The next exercise goes into the details of how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 21: Visualizing Data Using a Density Plot'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will demonstrate the density plot for the same feature,
    `age`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the ggplot2 package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the following command to plot the density plot for age:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.5: Density plot for age.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.5: Density plot for age.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Similar to the previous exercise, we use the same base for the visualization
    with the `ggplot` function and use a different `geom_density` function for the
    density plot. The rest of the additional functions used for the visualization
    remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: Density plots give finer details than a histogram. While this level of detail
    can also be achieved using higher number of bins for a histogram, there is often
    a hit and try method required to get the best number of bins. In such cases, an
    easier option to opt for would be density plots.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have understood the idea of univariate analysis for numeric variables,
    let's speed up the data exploration for other variables. We have a total of 10
    categorical features and 10 numeric columns. Let's try to take a look at four
    numeric variables together using a histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Just like we plotted the histogram for age, we can do it for multiple variables
    at the same time by defining a custom function. The next exercise shows how to
    do this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 22: Visualizing Multiple Variables Using a Histogram'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will combine the four histograms, one for each of the variables
    of interest, into a single plot. We have `campaign`, which indicates the number
    of contacts performed during the campaign, and `pdays`, which indicates the number
    of days since the client was last contacted by the previous campaign; a value
    of 999 indicates that the client was never contacted before. `previous` indicates
    the number of contacts previously made for this client, and lastly, `emp.var.rate`
    indicates the employment variance rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `cowplot` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Ensure that the `cowplot` package is installed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, define a function to plot histograms for all numeric columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, use the `summary` function to print the mean, max, and other parameters
    for the `campaign`, `pdays`, `previous`, and `emp.var.rate` columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the function we defined earlier to plot the histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.6: Visualizing multiple variables using a histogram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.6: Visualizing multiple variables using a histogram'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this exercise, we automated the process of stacking multiple plots of the
    same kind into a consolidated plot. We first load the required `cowplot` library.
    This library provides handy functions for creating a plot grid for plots rendered
    by the `ggplot` library. If you do not have the library loaded, install the packages
    using the `install.packages('cowplot')` command. We then define a function called
    `plot_grid_numeric`, which accepts the parameters dataset, a list of features
    to plot, and the number of columns to be used in the grid. If you observe the
    internals of the function, you will see that we simply traverse through the list
    of provided variables using a `for` loop and collect the individual plots into
    a list called `plt_matrix`. Later, we use the `plot_grid` function provided by
    the `cowplot` library to arrange the plots into a grid with two columns.
  prefs: []
  type: TYPE_NORMAL
- en: The same function can be used to display a grid of any number of histograms;
    use a number based on your screen size. The current number has been restricted
    to 4 for best results. We also use the `summary` function to display the overall
    statistics for the same set of numeric variables in conjunction with the histogram
    plots.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There is no exception handling code used in the previous function. We have ignored
    implementing sophisticated code for now in order to focus on the topic of interest.
    In the event of using the function for non-numeric variables, the error messages
    will not be the most effective to solve it.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the previous plot, we now have four variables together for
    analysis. Studying the summary statistics in tandem with the histogram plots helps
    us uncover the underlying variable better. `Campaign` has 75% of the values below
    or equal to 3\. We can see that there is an outlier at 56, but a significant majority
    of the records have values less than 5\. `pdays` seems to not be a useful variable
    for our analysis as almost all records have the default value of 999\. The tall
    bar in 1000 makes it clear that barely any records will have values other than
    999.
  prefs: []
  type: TYPE_NORMAL
- en: For the `previous` variable, we see the exact opposite of `pdays`; most records
    have a value of 0\. Lastly, `emp.var.rate` shows us an interesting result. Though
    the values range from `-4` to `2`, more than half of the records have a positive
    value.
  prefs: []
  type: TYPE_NORMAL
- en: So, with the analysis of these four variables, we can roughly conclude that
    the previously conducted campaigns didn't communicate very often by phone with
    the clients, or it could also mean that close to none of the clients targeted
    in the previous campaign were contacted for the current campaign. Also, the ones
    who were contacted earlier were contacted seven times at most. The number of days
    since the client was last contacted naturally is in sync with the results from
    the previous campaign, because hardly any have been contacted earlier. However,
    for the current campaign, clients have been contacted an average of 2.5 times,
    75% of the clients have been contacted up to 3 times, and some clients have been
    contacted as high as 56 times. The employment variance rate is an indicator of
    how many people are hired or fired due to macro-economic situations. We understand
    that the economic situation has been fairly steady for most of the time during
    the campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the function created in the previous section to stack histograms
    together, in this activity, we will create another function to stack density plots
    and another for boxplots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4: Plotting Multiple Density Plots and Boxplots'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, we will create a function to stack density plots, and another
    for boxplots. Use the newly created functions to visualize the same set of variables
    as in the previous section and study the most effective way to analyze numeric
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: By end of this activity, you will learn how to plot multiple variables in density
    plot at the same time. Doing so makes it easy to compare the different variables
    in one go and draw insights about the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: First, load the necessary libraries and packages in RStudio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the `bank-additional-full.csv` dataset into a DataFrame named `df`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define the `plot_grid_numeric` function for the density plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the density plot for the `campaign`, `pdays`, `previous`, and `emp.var.rate`
    variables:![Figure 2.7: Density plots for the campaign, pdays, previous, and emp.var.rate
    variables'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/C12624_02_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.7: Density plots for the campaign, pdays, previous, and emp.var.rate
    variables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Observe that the interpretations we obtained using the histogram are visibly
    true in the density plot as well. Hence, this serves as another alternative plot
    for looking at the same trend.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Repeat the steps for the boxplot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The plot is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.8: Boxplots for the campaign, pdays, previous, and emp.var.rate
    variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.8: Boxplots for the campaign, pdays, previous, and emp.var.rate variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: An additional point to note in the boxplot is that it shows the clear presence
    of outliers in the `campaign` variable, which wasn't very visible in the other
    two plots. A similar observation could be made for `previous` and `pdays` variables
    as well. Students should try to plot boxplots after removing the outliers and
    see how different they look then.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can find the solution for this activity on page 442.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 23: Plotting a Histogram for the nr.employed, euribor3m, cons.conf.idx,
    and duration Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will move to the next and the last set of four numeric
    variables. We have `nr.employed`, which indicates the number of employees employed
    at the bank, and `euribor3m`, which indicates the 3-month euro interbank rates
    for average interest rates. Also, we have `cons.conf.index`, which is the consumer
    confidence indicator measured as the degree of optimism on the state by consumers
    by expressing through the activities of savings and spending. Lastly, there is
    `duration`, which indicates the last contact duration. As per the metadata provided
    by UCI, this variable is highly correlated with the outcome and will lead to possible
    data leakage. Therefore, we will drop this variable from our future analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to study the next set of numeric variables:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `cowplot` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the details using the `summary` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the histogram for the defined variables, as illustrated in the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.9: Histogram of count and duration for various variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.9: Histogram of count and duration for various variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Just like *Exercise 5*, *Visualizing Multiple Variables Using a Histogram*,
    we first perform the summary statistics on our desired set of variables with the
    `summary` function, and then plot the combined histogram for all the desired variables
    together by calling the same functions we defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the number of employees employed has been mostly constant at
    `5228`, but it has also decreased during the time period to different values.
    This number is measured quarterly, and hence the frequency is not very dynamic,
    which is why we can see values centered around only a few bins. The euro interbank
    interest rate has been mostly between `2.5` and `5`. There are just 1 or 2 records
    that have values above 5, and we can see that the max value measured for this
    variable is `5.045`. The consumer confidence index is mostly negative, which means
    that the consumers mostly perceived the state of the economy negatively during
    this time. We see two peaks in the bins of the histogram, which calls for the
    most common confidence index during the time and vaguely suggests limited variation
    in the index during the length of the campaign. The duration of the call, in seconds,
    shall be ignored from our analysis for now.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we understand that the bank's number of employees increased and
    decreased during the campaigns in a range of ~250, which is ~5% of the total employees.
    It ranged between `4964` and `5228` and mostly had little variation. The consumer
    confidence index remained mostly negative and with little variation during the
    time period, and the euro interbank rates had an average of 3.6, with most of
    the records between 2.5 and 5.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's move on to study the categorical variables using univariate analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Categorical Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Categorical features differ from numeric or continuous features in nature, and
    therefore the traditional methods used earlier aren't applicable here. We can
    analyze the number of different classes within a categorical variable and the
    frequency associated with each. This can be achieved using either simple analytical
    techniques or visual techniques. Let's explore a list of categorical features
    using a combination of both.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 24: Exploring Categorical Features'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will start with a simple variable, that is, `marital`,
    which indicates the marital status of the client. Let's use the `dplyr` library
    to perform grouped data aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `dplyr` library in the system using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will create an object named `marital_distribution` and store the value
    based on the following condition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print the value stored in the `marital_distribution` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To count the distinct number of classes within the categorical column and to
    get the count of records within each of the individual classes, we use the `group_by`
    functions available under the `dplyr` library. The `%>%`, also called the `marital`
    and then pass the output to the `summarize` function, which aggregates the DataFrame
    to the grouped level using the aggregation function we provide; in this case,
    `n()` is a simple `count` equivalent. Finally, we use the `mutate` function to
    calculate the percentage of counts for each of the individual group members.
  prefs: []
  type: TYPE_NORMAL
- en: We see that majority of the campaign calls were made to married clients, around
    61%, followed by calls to single clients at 28% and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 25: Exploring Categorical Features Using a Bar Chart'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will plot a bar chart with the frequency counts for each
    class visualized. We could also use the bar chart to represent the frequency distribution
    of each of these individual categories with a plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, plot the bar chart of marital status per count using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.10: Bar chart of marital status per count'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.10: Bar chart of marital status per count'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We use the same dataset engineered in the previous snippet, which calculates
    the frequency of each class and its relative percentage. To plot the bar chart,
    we use the same base function of `ggplot`, where we define the aesthetics of the
    *x* and *y* variables and append the bar plot using the `geom_bar` function. The
    `geom_text` function allows us to add labels to each bar in the plot.
  prefs: []
  type: TYPE_NORMAL
- en: We can now see the same numbers displayed in the previous exercise visualized
    here with a bar plot. In scenarios where we have a large number of classes within
    the variable, glancing through each individual class to study them might not be
    the most effective method. A simple plot easily helps us to understand the frequency
    distribution of the categorical variable in an easy-to-consume way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 26: Exploring Categorical Features using Pie Chart'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will define the pie chart and the various components within
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the bar plot, we also have a pie chart that makes understanding
    the percentage distribution of the classes easier. Perform the following steps
    to visualize the same variable, that is, marital status using a pie chart:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, define the label positions using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, define labels for the plots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the plot size for better visuals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the pie chart using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 2.11: Pie chart for the percentage distribution for the marital status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.11: Pie chart for the percentage distribution for the marital status'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We first define a few extra variables that will help us to get the plot in an
    easier way. In order to label the pie chart, we would need the break points and
    the actual labels. The break point should ideally be located in the middle part
    of the pie piece. So, we take a cumulative sum of the percentage distribution
    and subtract half of each category to find the mid-point of the section. We then
    subtract the entire number from 100 to arrange the labels in a clockwise direction.
  prefs: []
  type: TYPE_NORMAL
- en: The next step defines the label for each pie piece; we use the `paste` function
    to concatenate the label name and the actual percentage values. The pie chart
    functionality in `ggplot` works by constructing elements on top of a bar chart.
    We first use the base from `ggplot` and `geom_bar` to render the base for a stacked
    bar plot and use the `coord_polar` function to transform this into the required
    pie chart. The `scale_y_continuous` function helps in placing the labels on the
    pie distribution. The next line adds a rotation angle to the positioning of the
    text. The `size` parameter inside the `element_text` portion of the `theme` function
    defines the font size for the text in the plot. The rest is the same as we studied
    in the earlier plots.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the pie chart provides us with an intuitive way to explore the
    percentage distribution for the categories within each variable. A word of caution
    to choose the pie chart over bar plot would be based on the number of distinct
    categories within a variable. Though pie charts are visually more appealing, with
    many distinct classes, pie charts become overcrowded.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pie charts are best avoided when the number of distinct classes within a categorical
    variable is high. There is no definite rule, but anything that makes visually
    cluttered pie charts would not be ideal to study.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 27: Automate Plotting Categorical Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will automate the plotting of categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Just like numeric variables, we also have 10 categorical variables, excluding
    the target variable. Similar to automating the exploration of numeric features,
    let's now create a function for categorical variables. To keep things simple,
    we will primarily use boxplots with a percentage distribution instead of a pie
    chart. We will start with four categorical features and then move to the next
    remainder set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `cowplot` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to plot histograms for all numeric columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, call the `summary` statistics using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the function we defined earlier to plot the histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.12: Bar plot for categorical variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.12: Bar plot for categorical variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Similar to the earlier function we created for the numeric features visual automation,
    we have created a simple function to explore the percentage distribution for categorical
    features. Some additions to the function are the creation of the temporary aggregation
    dataset and some additional cosmetic enhancements to the plot. We add the labels
    and rotate them by 30 degrees so that they can neatly align with the plot, and
    the rest remains the same. We get the frequency count by calling the `summary`
    function on the `categorical` column. Similar to numeric columns, we explore the
    categorical columns first using the `summary` function and then use the defined
    function to visualize the collated bar plots.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the `job` feature, we can see 12 distinct values, with most of the
    records for admin, blue-collar, and technician. Overall, the `job` category seems
    to have a fairly diverse distribution of values. Education level of the client
    also has a diverse set of values, with ~50% of the values from high school and
    university. For the `default` variable, which indicates whether the client has
    defaulted in credit previously, we have ~80% of the values as `no` and around
    ~20% unknown. This doesn't seem to be useful information. Finally, `contact`,
    which defines the mode of contact used for the campaign communication, shows that
    64% was through cellular phones, and the rest through landlines.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on and repeat the same analysis for the next set of features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 28: Automate Plotting for the Remaining Categorical Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will reuse the same function for the next set of four categorical
    variables. Remember that you need to use the frequency count generated using the
    `summary` command in conjunction with the plots to interpret the value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s perform the following procedure to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `cowplot` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, call the `summary` statistics using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the defined function to plot the histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.13: Automate plotting for the remaining categorical variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.13: Automate plotting for the remaining categorical variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We reuse the previously defined functions to explore the new set of four variables
    just like we explored the previous set of features.
  prefs: []
  type: TYPE_NORMAL
- en: The `loan` variable indicates whether the client has a personal loan. We have
    ~86.6% of clients with no personal loan, 10.3% with a loan, and 3.3% unknown.
    Similarly, the `month` variable indicates the actual month when the campaign calls
    were executed. We see that the majority of communication was conducted in the
    month of `may`, followed by `jul` and `aug`. Overall, the `month` feature also
    seems to be a fairly diverse variable with a good distribution of values. The
    `day_of_week` variable shows a consistent distribution across all days of the
    week. `poutcome` indicates the result of the previously executed campaign; a significant
    majority was non-existent, a small chunk of around 3.3% was successful, and ~10%
    failed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 29: Exploring the Last Remaining Categorical Variable and the Target
    Variable'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, let's explore the last remaining categorical variable and the target
    variable. Since both are categorical, we can continue using the same function
    for the exploration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Repeat the same process for the last independent categorical variable and the
    dependent variable (which is also categorical):'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, after importing the required packages and creating DataFrame object,
    call the summary statistics using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Call the defined function to plot the histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.14: Histogram of housing per count'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.14: Histogram of housing per count'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If we carefully look at the distribution of the outcome variable, we can see
    that a large majority of the clients have negatively responded to the campaign
    calls. Only ~11% of the overall campaign base have positively responded to the
    campaign. Similarly, if we look at the `housing` variable, we can see that roughly
    50% of the clients had a housing loan.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, we can distill our observations as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The campaign was conducted with a major focus of new customers who had not been
    previously contacted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Around 60% of the client base are married and 80% have not defaulted in credit
    history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roughly 50% of the client base has a housing loan and over 80% has never opted
    for a personal loan.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The campaign was the most active during the month of May and demonstrated fairly
    strong momentum in July and August.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More than 60% of the communication of the campaign was through cellular phones,
    and over 50% of the client base at least had a high school degree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, only 11% of the campaign calls had a positive response.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With the univariate analysis of all the numeric and categorical variables complete,
    we now have a fair understanding of the story the data conveys. We almost understand
    each data dimension and its distribution. Let''s move on to explore another interesting
    facet of EDA: bivariate analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Bivariate Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In **bivariate analysis**, we extend our analysis to study two variables together.
    In our use case, we have around 20 independent variables. It is indeed possible
    to study all permutation combinations of the available 20 variables, but we won't
    go to that extent in this chapter. In our use case, we are more interested in
    studying all the factors that led to the poor performance of the campaign. Therefore,
    our primary focus will be to perform bivariate analysis and study the relationship
    between all the independent variables and our dependent target variable. Again,
    depending on the type of variable, we will have a different type of visual or
    analytical technique to analyze the relationship between the two variables. The
    possible combinations are numeric and numeric, and numeric and categorical. Given
    that our dependent variable is a categorical variable, we might have to explore
    the relationship between two independent variables in our list to study the relationship
    between two numeric variables. Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Studying the Relationship between Two Numeric Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand how we can study the relationship between two numeric variables,
    we can leverage scatter plots. It is a 2-dimensional visualization of the data,
    where each variable is plotted on an axis along its length. Relationships between
    the variables are easily identified by studying the trend across the visualization.
    Let's take a look at an example in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 30: Studying the Relationship between Employee Variance Rate and Number
    of Employees'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's study the relationship between employee variance rate and the number of
    employees. Ideally, the number of employees should increase as the variation rate
    increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, plot the scatter plot using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.15: Scatterplot of employment variation versus the number of employees'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.15: Scatterplot of employment variation versus the number of employees'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We use the same base function, `ggplot`, with a new wrapper for the scatterplot.
    The `geom_point` function in `ggplot` provides the necessary constructs for using
    a scatterplot.
  prefs: []
  type: TYPE_NORMAL
- en: We can see an overall increasing trend, that is, as employment variance rate
    increases, we see the number of employees also increases. The fewer number of
    dots are due to repetitive records in `nr.employed`.
  prefs: []
  type: TYPE_NORMAL
- en: Studying the Relationship between a Categorical and a Numeric Variable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's first recall the methods discussed to study the relationship between the
    numeric and categorical variable and discuss the approach to execute it.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss the different aggregation metrics that we can
    use for summarizing the data. So far, we have used `avg`, but a better approach
    would be to use a combination of `avg`, `min`, `max`, and other metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 31: Studying the Relationship between the y and age Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have a categorical dependent variable and nine numeric variables to explore.
    To start small, we will first explore the relationship between our target, `y`,
    and `age`. To study the relationship between a categorical and numeric variable,
    we can choose a simple analytical technique where we calculate the average age
    across each target outcome; if we see stark differences, we can make insights
    from the observations.
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we will calculate the average age across each target outcome
    and also count the number of records in each bucket, followed by a visual representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `temp` object and store the value using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the value stored in the `temp` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a plot using the `ggplot` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.16: Histogram for the average age across target outcome'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.16: Histogram for the average age across target outcome'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first line of code creates the temporary aggregation datasets, which summarizes
    the average age and the number of records in each category. The plotting functionality
    used is on the lines of our previous visuals. We extend the `ggplot` function
    with the `geom_bar` to render the bar plots.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that there is barely any difference between the two outcomes. We
    don't see any interesting patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In bivariate analysis, we need to be careful before concluding any interesting
    patterns as insights. In many cases, due to the skewed distribution of data, the
    patterns would seem surprisingly interesting.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next set of variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 32: Studying the Relationship between the Average Value and the y
    Variable'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will study the relationship between the next set of variables:
    `average` and `y`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, create the `plot_bivariate_numeric_and_categorical` object using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print the distribution of records across target outcomes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, plot the histogram using the following command for the defined variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.17: Histogram of average value versus the y variable'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.17: Histogram of average value versus the y variable'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In order to automate the data exploration task for bivariate analysis between
    a categorical and a numeric variable, we have defined a function similar to the
    one we defined in the previous exercise. We have additionally used the `sym` function,
    which will help us use dynamic column names in the function. Using `!!sym(column)`
    converts a string to a real column name that's analogous to passing the actual
    value. The previous function first aggregates the average value of the target
    across the variable of interest. The `plot` function then uses the information
    to plot the bar chart with the average values across the target outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In bivariate analysis, it is important to carefully validate the patterns observed
    before concluding a specific insight. In some cases, outliers might skew the results
    and therefore deliver incorrect findings. Additionally, fewer of records for a
    particular pattern might also be a risky pattern to conclude. It is always recommended
    to collect all the insights observed and further validate them with additional
    extensive EDA or statistical techniques for significance.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we don't see any prominent results to conclude. In the `campaign` variable,
    the average number of contacts made during the campaign is a bit lower for successful
    campaigns, but the difference is too small to make any possible conclusions. `pdays`,
    which indicate the number of days since the last contact in the previous campaign
    shows a big difference between the outcomes for the target.
  prefs: []
  type: TYPE_NORMAL
- en: However, this difference is purely due to most clients being not contacted in
    the previous campaign. All of those records have values set to 999\. The same
    holds true for `previous`; though there is a decent difference between the two,
    most clients were contacted for the first time in the current campaign. The employment
    variance rate, however, shows counter-intuitive results. We would actually expect
    the variance rate to be higher when the outcome is `yes`, but we see it the other
    way around. This sounds interesting, we will make a note of this insight for now
    and later come back for more validation before making any conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next set of categorical dependent variables to be studied
    with the categorical dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 33: Studying the Relationship between the cons.price.idx, cons.conf.idx,
    curibor3m, and nr.employed Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's move on to the next set of categorical dependent variables to be studied
    with the categorical dependent variable. For this exercise, we will explore the
    relationship between `cons.price.idx`, `cons.conf.idx`, `euribor3m`, and `nr.employed`,
    with the target variable `y` using histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, create a `plot_bivariate_numeric_and_categorical` function and plot the
    histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.18: Histogram of the cons.price.idx, cons.conf.idx, euribor3m, and
    nr.employed variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.18: Histogram of the cons.price.idx, cons.conf.idx, euribor3m, and
    nr.employed variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Again, for most cases, we don't see any prominent patterns. However, the `euribor3m`
    variable demonstrates some good differences between the average values for `yes`
    and `no` outcomes of the campaign and, again, seems counter-intuitive. We ideally
    expected higher bank deposits with higher interest rates. Therefore, let's make
    a note of the insight and validate it later.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, let's now explore the relationship between two categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Studying the Relationship Between Two Categorical Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To study the relationship and patterns that exist between two categorical variables,
    we can first explore the frequency distribution across each category of the variables.
    A higher concentration in any outcome might be a potential insight. The most effective
    way to visualize this is using stacked bar charts.
  prefs: []
  type: TYPE_NORMAL
- en: A stacked bar chart will help us to observe the distribution of the target variable
    across multiple categorical variables. The distribution will reveal whether a
    specific category in a categorical variable dominates the target variable, `y`.
    If yes, we can further explore its influence on our problem.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few exercises, we will explore various categorical variables across
    target variable `y` using stacked bar chart. We will plot absolute count and percentage
    to understand the distribution better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 34: Studying the Relationship Between the Target y and marital status
    Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will demonstrate the study between two categorical variables
    using plain frequency counts and then show how inconvenient it is.
  prefs: []
  type: TYPE_NORMAL
- en: To start simple, let's begin with exploring the relationship between the target,
    `y`, and `marital status`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create a `temp` aggregation dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define plot size, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the chart with frequency distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.19: Using ggplot to study the relationship between the target y
    and marital status variables'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12624_02_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.19: Using ggplot to study the relationship between the target y and
    marital status variables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: We first aggregate the categorical columns using the `group_by` function. This
    would help us cross frequency count for each category combination. We now use
    this temporary dataset to plot the frequency distribution across the independent
    variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As we can see, the `yes` frequency is highest for married clients, but this
    may be true just because the number of married clients is high. To understand
    the relationship better, we can further break this down using a stacked bar chart
    with percentage distribution, where each bar represents the percentage of `yes`
    and `no`, respectively.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a `temp` aggregation dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the plot size using the `options` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the percentage distribution using the `ggplot` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.20: Distribution of target y percentage across marital status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.20: Distribution of target y percentage across marital status'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can now see counter-intuitive results compared to the previous plot. After
    we normalize the results, we see that `single` clients are more responsive to
    the campaign than those who are married. This is true for `unknown` too, but given
    the uncertainty of the value and the extremely low number of records, we should
    ignore this. We cannot directly conclude the result that single customers are
    more effective in responding to campaigns, but we can validate this later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 35: Studying the Relationship between the job and education Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will accelerate our exploration. Let's build a custom function
    where we can combine the two charts, that is, frequency distribution as well percentage
    distribution, for categorical variable's bivariate analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the `ggplot2` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame object, `df`, and use the `bank-additional-full.csv` file
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `temp` aggregation dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the plot size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the chart with a frequency distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the percentage distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the `plot_bivariate_categorical` using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.21: Studying the relationship between the job and education variables'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12624_02_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.21: Studying the relationship between the job and education variables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: We use the same principles to define the function that would plot the charts
    together. The additional difference here would be two plots for each combination.
    The first (left) is the frequency plot across the category combinations, and the
    right-hand side plot showcases the percentage distribution (normalized across
    category) visual. Studying both the plots together helps validate results more
    effectively. The creation of temporary aggregated datasets has an additional step
    with the use of the `ungroup` function. This is used to enable the relative percentage
    distribution of target outcome within the categorical levels of independent variable,
    that is, distribution of `y` across each level within `marital`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If we observe the results from the previous output plots, we can see that the
    highest response rates for the campaign are from student and retired professionals,
    but this comes with a caveat. We see that both of these categories have far less
    observations as compared to the other categories. Therefore, we would need additional
    validation before making further conclusions. We, therefore, make a note of this
    insight too. From education levels, we don't see any interesting trends. Though
    `illiterate` clients have a high response rate, the number of observations are
    far too low to conclude anything tangible.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s take a look at credit default and housing loan categories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.22: Studying the relationship between the default and housing variables'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12624_02_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.22: Studying the relationship between the default and housing variables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Again, we don''t see any interesting trends. Let''s continue the exploration
    for personal loan and contact mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.23: Studying the relationship between the loan and contact variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.23: Studying the relationship between the loan and contact variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, we can see an interesting trend for the mode of contact used. There is
    generally a higher response rate when the mode of campaign communication is cellular
    rather than landline. Let's make a note of this trend too and huddle back with
    further validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'I encourage you to explore the relationships between our target variable and
    the remaining dependent categorical variables: month, day of week, and the previous
    outcome of the campaign.'
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Multivariate analysis is the process of studying the relationships between more
    than two variables; essentially, one dependent variable and more than one independent
    variable. Bivariate analysis is a form of multivariate analysis. There are several
    forms of multivariate analysis that are important, but we will skip the details
    for now to restrict the scope of the chapter. In the next few chapters, we will
    take a closer look at linear and logistic regression, which are two popular multivariate
    analysis techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the most common techniques used in multivariate analysis are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple linear regression (studying the impact of more than one independent
    variable on a numeric/continuous target variable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression (studying the impact of more than one independent variable
    on a categorical target variable)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Factor analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MANOVA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating Insights Using Statistical Tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Throughout the journey of EDA, we have collected and noted some interesting
    patterns for further validation. It is now the right time to test whether whatever
    we observed previously are actually valid patterns or just appeared to be interesting
    due to random chance. The most effective and straightforward way to approach this
    validation is by performing a set of statistical tests and measuring the statistical
    significance of the pattern. We have a ton of options in the available set of
    tests to choose from. The options vary based on the type of independent and dependent
    variable. The following is a handy reference diagram that explains the types of
    statistical test that we can perform to validate our observed patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.24: Validating dependent and independent variables'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_02_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.24: Validating dependent and independent variables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s collect all our interesting patterns into one place here:'
  prefs: []
  type: TYPE_NORMAL
- en: The campaign outcome has a higher chance of `yes` when the employee variance
    rate is low.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The campaign outcome has a higher chance of `yes` when the euro interest rates
    are low.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single clients have a higher chance of responding positively to the campaign.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Student and retired clients have a higher chance of responding positively to
    the campaign.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cellular contacts have a higher chance of responding positively to the campaign.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you try to categorize these hypotheses, we can see that we have a categorical
    dependent variable in all cases. So, we should use a chi-squared test or logistic
    regression test to validate our results.
  prefs: []
  type: TYPE_NORMAL
- en: Let's perform these tests one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical Dependent and Numeric/Continuous Independent Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hypotheses 1 and 2 have a continuous independent variable. Referring to the
    figure in the previous section, we will opt for the chi-squared test. In the process
    of hypothesis testing, we start by defining a null hypothesis and an alternate
    hypothesis. Start with a negative approach, that is, assume the null hypothesis
    to be what we don't want to happen. The hypothesis test examines the chances that
    the pattern observed happens due to random chance or there if is certainty about
    the observation. This measure is quantified as probability. If the probability
    of the significance of the null hypothesis to happen is less than 5% (or a suitable
    cut-off), we reject the null hypothesis and confirm the validity of the alternate
    hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin; for hypothesis 1, we define the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Null hypothesis**: The campaign outcome has no relationship with the employee
    variance rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternate hypothesis**: The campaign outcome has a relationship with employee
    variance rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We test the validity of our null hypothesis with simple logistic regression.
    We will discuss this topic in more detail in the following chapters. For now,
    we will quickly perform a simple check to test our hypothesis. The following exercise
    leverages R's built-in function for performing logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 36: Hypothesis 1 Testing for Categorical Dependent Variables and Continuous
    Independent Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To perform hypothesis testing for categorical dependent variables and continuous
    independent variables, we will use the `glm()` function to fit the logistic regression
    model (more on this in *Chapter 5*, *Classification*). This exercise will help
    us statistically test whether a categorical dependent variable (for example, `y`)
    has any relationship with a continuous independent variable, for example,
  prefs: []
  type: TYPE_NORMAL
- en: '`emp.var.rate`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, convert the dependent variable into a `factor` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, perform logistic regression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the test summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We convert the target variable, `y`, as a `factor` (if it was not already).
    We use the `glm` function provided by R for logistic regression. The `glm` function
    also performs other forms of regression, and we specify the `family = 'binomial'`
    parameter for using the function as a logistic regression. The formula in the
    first place of the function defines the dependent and independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: There are quite a few results shared in the output. We will ignore most of them
    for now and focus only on the final output. One of the results provided is the
    significance probability, which confirms that there is less than a `2e-16` chance
    that our null hypothesis is true, and therefore we can reject it. Therefore, the
    target outcome has a statistically significant relationship with the employee
    variance rate and, as we can see, there is a higher chance of campaign conversion
    as the rate decreases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, let''s repeat the same test for our second hypothesis. We define
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Null hypothesis**: The campaign outcome has no relationship with the euro
    interest rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternate hypothesis**: The campaign outcome has a relationship with the
    euro interest rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exercise 37: Hypothesis 2 Testing for Categorical Dependent Variables and Continuous
    Independent Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once again, we will use logistic regression to statistically test whether there
    is a relationship between the target variable, `y`, and the independent variable.
    In this exercise, we will use the `euribor3m` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, convert the dependent variable into a `factor` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, perform logistic regression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the test summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Focusing exclusively on the previous output, we can confirm that we can reject
    the null hypothesis and accept the alternative hypothesis. Therefore, the target
    outcome has a statistically significant relationship with the Euro Interest rate
    and, as we can see, there is a higher chance of campaign conversion as the rate
    decreases.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical Dependent and Categorical Independent Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Moving on, let's take a look at the third hypothesis. To test the relationship
    between the categorical dependent variable and categorical independent variable,
    we can use the chi squared test.
  prefs: []
  type: TYPE_NORMAL
- en: 'For hypothesis 3, we define the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Null hypothesis**: The campaign outcome has no relationship with clients
    who never married.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternate hypothesis**: The campaign outcome has a relationship with clients
    who never married.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following exercise, we will leverage R's chi-square test function to
    validate the hypothesis..
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 38: Hypothesis 3 Testing for Categorical Dependent Variables and Categorical
    Independent Variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will perform a statistical test using the chi-squared test.
    We use the chi-squared test because both the independent and dependent variables
    are categorical, particularly when testing the relationship between `y` and marital
    status.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, convert the dependent variable into a `factor` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a flag for `single` clients:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `sample` object and print the value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform the chi-squared test:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the test summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We first create a new variable/flag for this test where we define whether a
    client is `single` or not. Since we are exclusively defining our relationship
    between the target and client's `single` marital status, we mask all other classes
    within marital status.
  prefs: []
  type: TYPE_NORMAL
- en: The `table` command creates a new DataFrame with a simple frequency distribution
    between each individual class. Finally, we use this DataFrame to perform the chi-squared
    test.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the p-value or the chance of the null hypothesis being true is
    far less than 5%. Therefore, we can accept our alternate hypothesis, which confirms
    the fact that the campaign's outcome is positively influenced by single clients
    rather than other clients.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, let's take a quick look at the validity of our 4th and 5th hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the 4th and 5th hypotheses, we define the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Null hypothesis**: The campaign outcome has no relationship with clients
    who are students or retired. The campaign outcome has no relationship with the
    contact mode used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternate hypothesis**: The campaign outcome has no relationship with clients
    who are students or retired. The campaign outcome has a relationship with the
    contact mode used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exercise 39: Hypothesis 4 and 5 Testing for a Categorical Dependent Variable
    and a Categorical Independent Variable'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once again, let's use the chi-squared test to statistically check whether there
    is a relationship between the target variable, `y`, the categorical independent
    variable `job_flag`, and `contact`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and create the DataFrame objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, convert the dependent variable into a `factor` type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Prepare the independent variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an object named `sample4` and print the value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform the test for the 4th hypothesis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the test summary for the 4th hypothesis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a new `sample5` object and print the value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform the test on the `test5` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the test summary for the 5th hypothesis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can see that results have been validated in our favor. We can also see that
    there is definitely a relationship between student and retired clients and the
    cellular mode of communication with a positive outcome in the campaign.
  prefs: []
  type: TYPE_NORMAL
- en: Collating Insights – Refine the Solution to the Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have now traversed the length and breadth of EDA. In the different sections,
    we studied the data in varying levels of depth. Now that we have valid answers
    for the data exploration problem, we can touch base again with the initial problem
    defined. If you recall the **complication** and **question** section in the problem
    statement, we had *What are factors that lead to poor performance of the campaign*.
    Well, we now have an answer based on the patterns we discovered during the bivariate
    analysis and validated with statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: Collating all the hypotheses validated with the correct story brings about the
    solution to our problem. Spend good time with the outcome of each of the hypothesis
    test results to knit the story together. Each hypothesis tells us whether an independent
    variable has a relationship with a dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we explored EDA using a practical use case and traversed the
    business problem. We started by understanding the overall process of executing
    a data science problem and then defined our business problem using an industry
    standard framework. With the use case being cemented with appropriate questions
    and complications, we understood the role of EDA in designing the solution for
    the problem. Exploring the journey of EDA, we studied univariate, bivariate, and
    multivariate analysis. We performed the analysis using a combination of analytical
    as well as visual techniques. Through this, we explored the R packages for visualization,
    that is, `ggplot` and some packages for data wrangling through `dplyr`. We also
    validated our insights with statistical tests and, finally, collated the insights
    noted to loop back with the original problem statement.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will lay the foundation for various machine learning
    algorithms, and discuss supervised learning in depth.
  prefs: []
  type: TYPE_NORMAL
