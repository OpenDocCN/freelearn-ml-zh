["```py\n<properties>\n        <spark.version>2.4.0</spark.version>\n        <scala.version>2.11.7</scala.version>\n        <h2o.version>3.22.1.1</h2o.version>\n        <sparklingwater.version>2.4.1</sparklingwater.version>\n        <adam.version>0.23.0</adam.version>\n</properties>\n```", "```py\nval spark:SparkSession = SparkSession\n           .builder()\n            .appName(\"PopStrat\")\n             .master(\"local[*]\")\n              .config(\"spark.sql.warehouse.dir\", \"temp/\") \n               .getOrCreate()\n```", "```py\nval genotypeFile = \"Downloads/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf\"\nval panelFile = \"Downloads/integrated_call_samples_v3.20130502.ALL.panel\"\n```", "```py\nval populations = Set(\"FIN\", \"GBR\", \"ASW\", \"CHB\", \"CLM\")\n```", "```py\ndef extract(file: String, filter: (String, String) => Boolean): Map[String, String] = {\n      Source\n        .fromFile(file)\n        .getLines()\n        .map(line => {\n          val tokens = line.split(Array('\\t', ' ')).toList\n          tokens(0) -> tokens(1)\n        })\n        .toMap\n        .filter(tuple => filter(tuple._1, tuple._2))\n    }\n\nval panel: Map[String, String] = extract(\n      panelFile,(sampleID: String, pop: String) => populations.contains(pop))\n```", "```py\nval allGenotypes: RDD[Genotype] = sc.loadGenotypes(genotypeFile).rdd\nval genotypes: RDD[Genotype] = allGenotypes.filter(genotype => {\n      panel.contains(genotype.getSampleId)\n    })\n```", "```py\n// Convert the Genotype objects to our own SampleVariant objects to try and conserve memory\ncase class SampleVariant(sampleId: String, variantId: Int, alternateCount: Int)\n```", "```py\ndef variantId(genotype: Genotype): String = {\n      val name = genotype.getVariant.getContigName\n      val start = genotype.getVariant.getStart\n      val end = genotype.getVariant.getEnd\n      s\"$name:$start:$end\"\n    }\n```", "```py\ndef alternateCount(genotype: Genotype): Int = {\n        genotype.getAlleles.asScala.count(_ != GenotypeAllele.REF)\n    }\n```", "```py\ndef toVariant(genotype: Genotype): SampleVariant = {\n      new SampleVariant(genotype.getSampleId.intern(),\n        variantId(genotype).hashCode(),\n        alternateCount(genotype))\n    }\n```", "```py\nval variantsRDD: RDD[SampleVariant] = genotypes.map(toVariant)\nval variantsBySampleId: RDD[(String, Iterable[SampleVariant])] = variantsRDD.groupBy(_.sampleId)\nval sampleCount: Long = variantsBySampleId.count()\n\nprintln(\"Found \" + sampleCount + \" samples\")\nval variantsByVariantId: RDD[(Int, Iterable[SampleVariant])] =\n      variantsRDD.groupBy(_.variantId).filter {\n        case (_, sampleVariants) => sampleVariants.size == sampleCount\n      }\n```", "```py\nval variantFrequencies: collection.Map[Int, Int] = variantsByVariantId\n      .map {\n        case (variantId, sampleVariants) =>\n          (variantId, sampleVariants.count(_.alternateCount > 0))\n      }\n      .collectAsMap()\n```", "```py\nval permittedRange = inclusive(11, 11) // variants with less than 12 alternate alleles \nval filteredVariantsBySampleId: RDD[(String, Iterable[SampleVariant])] =\n      variantsBySampleId.map {\n        case (sampleId, sampleVariants) =>\n          val filteredSampleVariants = sampleVariants.filter(\n            variant =>\n              permittedRange.contains(\n                variantFrequencies.getOrElse(variant.variantId, -1)))\n          (sampleId, filteredSampleVariants)\n      }\n```", "```py\nval sortedVariantsBySampleId: RDD[(String, Array[SampleVariant])] =\n      filteredVariantsBySampleId.map {\n        case (sampleId, variants) =>\n          (sampleId, variants.toArray.sortBy(_.variantId))\n      }\n    println(s\"Sorted by Sample ID RDD: \" + sortedVariantsBySampleId.first())\n```", "```py\nval rowRDD: RDD[Row] = sortedVariantsBySampleId.map {\n      case (sampleId, sortedVariants) =>\n        val region: Array[String] = Array(panel.getOrElse(sampleId, \"Unknown\"))\n        val alternateCounts: Array[Int] = sortedVariants.map(_.alternateCount)\n        Row.fromSeq(region ++ alternateCounts)\n    }\n```", "```py\nval header = StructType(\n      Array(StructField(\"Region\", StringType)) ++\n        sortedVariantsBySampleId\n        .first()\n        ._2\n        .map(variant => {\n          StructField(variant.variantId.toString, IntegerType)\n        }))\n```", "```py\n// Create the SchemaRDD from the header and rows and convert the SchemaRDD into a Spark DataFrame\nval sqlContext = sparkSession.sqlContext\nvar schemaDF = sqlContext.createDataFrame(rowRDD, header)\nschemaDF.show(10)\n>>> \n```", "```py\nschemaDF = sqlContext.createDataFrame(rowRDD, header).drop(\"Region\")\nschemaDF.show(10)\n>>> \n```", "```py\nval featureCols = schemaDF.columns\n```", "```py\n// Using vector assembler to create feature vector \nval featureCols = schemaDF.columns\nval assembler = new VectorAssembler()\n    .setInputCols(featureCols)\n    .setOutputCol(\"features\")\n val assembleDF = assembler.transform(schemaDF).select(\"features\")\n```", "```py\nassembleDF.show()\n```", "```py\nval kmeans = new KMeans().setK(5).setSeed(12345L)\nval model = kmeans.fit(assembleDF)\n val WCSS = model.computeCost(assembleDF)\nprintln(\"Within Set Sum of Squared Errors for k = 5 is \" + WCSS)\n }\n```", "```py\nWithin Set Sum of Squared Errors for k = 5 is 59.34564329865\n```", "```py\nval data = Array(\n      Vectors.dense(1.2, 3.57, 6.8, 4.5, 2.25, 3.4),\n      Vectors.dense(4.60, 4.10, 9.0, 5.0, 1.67, 4.75),\n      Vectors.dense(5.60, 6.75, 1.11, 4.5, 2.25, 6.80))\n\nval df = spark.createDataFrame(data.map(Tuple1.apply)).toDF(\"features\")\ndf.show(false)\n```", "```py\nval pca = new PCA()\n      .setInputCol(\"features\")\n      .setOutputCol(\"pcaFeatures\")\n      .setK(4)\n      .fit(df)\n```", "```py\nval result = pca.transform(df).select(\"features\", \"pcaFeatures\")\nresult.show(false)\n```", "```py\nval pcaDF = pca.transform(assembleDF)\n           .select(\"pcaFeatures\")\n           .withColumnRenamed(\"pcaFeatures\", \"features\")\npcaDF.show()\n```", "```py\nval kmeans = new KMeans().setK(5).setSeed(12345L)\nval model = kmeans.fit(pcaDF)\n val WCSS = model.computeCost(pcaDF)\nprintln(\"Within Set Sum of Squared Errors for k = 5 is \" + WCSS)\n    }\n```", "```py\nWithin Set Sum of Squared Errors for k = 5 is 52.712937492025276\n```", "```py\nval iterations = 20\n    for (k <- 2 to iterations) {\n      // Trains a k-means model.\n      val kmeans = new KMeans().setK(k).setSeed(12345L)\n      val model = kmeans.fit(pcaDF)\n\n// Evaluate clustering by computing Within Set Sum of Squared Errors.\nval WCSS = model.computeCost(pcaDF)\nprintln(\"Within Set Sum of Squared Errors for k = \" + k + \" is \" + WCSS)\n    }\n```", "```py\nWithin Set Sum of Squared Errors for k = 2 is 135.0048361804504\nWithin Set Sum of Squared Errors for k = 3 is 90.95271589232344\n...\nWithin Set Sum of Squared Errors for k = 19 is 11.505990055606803\nWithin Set Sum of Squared Errors for k = 20 is 12.26634441065655\n```", "```py\nval evaluator = new ClusteringEvaluator()\nfor (k <- 2 to 20 by 1) {\n      val kmeans = new KMeans().setK(k).setSeed(12345L)\n      val model = kmeans.fit(pcaDF)\n      val transformedDF = model.transform(pcaDF)\n      val score = evaluator.evaluate(transformedDF)\n      println(\"Silhouette with squared Euclidean distance for k = \" + k + \" is \" + score)\n    }\n```", "```py\nSilhouette with squared Euclidean distance for k = 2 is 0.9175803927739566\nSilhouette with squared Euclidean distance for k = 3 is 0.8288633816548874\n....\nSilhouette with squared Euclidean distance for k = 19 is 0.5327466913746908\nSilhouette with squared Euclidean distance for k = 20 is 0.45336547054142284\n```", "```py\nval kmeansOptimal = new KMeans().setK(2).setSeed(12345L)\nval modelOptimal = kmeansOptimal.fit(pcaDF)\n\n// Making predictions\nval predictionsOptimalDF = modelOptimal.transform(pcaDF)\npredictionsOptimalDF.show()    \n\n// Evaluate clustering by computing Silhouette score\nval evaluatorOptimal = new ClusteringEvaluator()\nval silhouette = evaluatorOptimal.evaluate(predictionsOptimalDF)\nprintln(s\"Silhouette with squared Euclidean distance = $silhouette\")\n```"]