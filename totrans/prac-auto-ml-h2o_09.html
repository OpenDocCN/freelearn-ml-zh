<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer273">
<h1 class="chapter-number" id="_idParaDest-141"><a id="_idTextAnchor186"/>9 </h1>
<h1 id="_idParaDest-142"><a id="_idTextAnchor187"/>Exploring Miscellaneous Features in H2O AutoML</h1>
<p>Along with incorporating many <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) algorithms and various features to train them, H2O AutoML has a few miscellaneous features that make it an all-around service capable of catering to all kinds of business requirements.</p>
<p>H2O AutoML’s strength not only lies in its ability to train multiple models automatically but also in providing support for other services and features that are vital for production-grade systems.</p>
<p>In this chapter, we shall explore two unique features of H2O AutoML that are good to know and that can be very useful when required. The first one is H2O AutoML’s compatibility with a popular ML library in Python called scikit-learn. We shall explore how we can use H2O AutoML in a scikit-learn implementation and how it can provide value to the large scikit-learn community.</p>
<p>The second feature is an inbuilt logging system in H2O AutoML. This logging system logs valuable information during the AutoML training process. It can be especially useful if you plan to use the H2O AutoML service in production, where monitoring the health of your systems is of utmost priority.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Understanding H2O AutoML integration in scikit-learn</li>
<li>Understanding H2O AutoML event logging</li>
</ul>
<p>With this in mind, let’s explore H2O AutoML’s first miscellaneous feature compatibility with scikit-learn.</p>
<h1 id="_idParaDest-143"><a id="_idTextAnchor188"/>Technical requirements</h1>
<p>For this chapter, you will require the following:</p>
<ul>
<li>The latest version of your preferred web browser</li>
<li>An <strong class="bold">Integrated Development Environment</strong> (<strong class="bold">IDE</strong>) of your choice</li>
<li>(Optional) Jupyter Notebook by Project Jupyter (<a href="https://jupyter.org/">https://jupyter.org/</a>)</li>
</ul>
<p>All the experiments conducted in this chapter have been performed on Jupyter notebooks to provide you with better visual examples of outputs. You are free to follow along using the same setup. You can also perform the same experiments on any Python environment as the Python code will execute the same on both environments.</p>
<p>All the code examples for this chapter can be found on GitHub at <a href="https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%209">https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%209</a>.</p>
<h1 id="_idParaDest-144"><a id="_idTextAnchor189"/>Understanding H2O AutoML integration in scikit-learn</h1>
<p><strong class="bold">Scikit-learn</strong> is <a id="_idIndexMarker942"/>one of the most commonly used open source ML libraries in the field of ML and data science. It is a library for<a id="_idIndexMarker943"/> the Python programming language and<a id="_idIndexMarker944"/> focuses on ML tooling functions. It involves modules that perform mathematical and statistical analysis, general-purpose ML algorithms, as well as functions to train, test, and evaluate ML models.</p>
<p>Scikit-learn was originally developed by David Cournapeau and was initially called <strong class="bold">scikits.learn</strong>. It was created as a Google Summer of Code project in 2007, which was later picked up as a thesis project by Matthieu Brucher that same year. It was later re-written and further developed by Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, and Vincent Michel from the French Institute of Research in Computer Science and Automation in Rocquencourt, France. Scikit-learn’s first public release of version 1 was made on February 1, 2010.</p>
<p>You can find more details about<a id="_idIndexMarker945"/> scikit-learn here: <a href="https://scikit-learn.org/stable/">https://scikit-learn.org/stable/</a>.</p>
<p>The scikit-learn library is built on the following packages:</p>
<ul>
<li><strong class="bold">NumPy</strong>: NumPy is a <a id="_idIndexMarker946"/>Python library used to work exclusively <a id="_idIndexMarker947"/>with arrays. It is used for scientific computing in Python and provides <a id="_idIndexMarker948"/>functions to work with multi-dimensional arrays. It also provides a wide variety of fast computing mathematical operations on said arrays, making it ideal for data analytics. It can perform array shape manipulation, sorting, searching, discrete Fourier transform operations, linear algebra, and statistics. You can find more details about NumPy here: https://numpy.org/.</li>
<li><strong class="bold">SciPy</strong>: SciPy is a <a id="_idIndexMarker949"/>scientific computational library that is built on<a id="_idIndexMarker950"/> top of NumPy. It provides advanced scientific computational functions. It is used to perform operations such as image processing, clustering, gradient optimization, and much more. All numerical computations in Python are done by SciPy. You<a id="_idIndexMarker951"/> can find more details about SciPy here: <a href="https://scipy.org/">https://scipy.org/</a>.</li>
<li><strong class="bold">Matplotlib</strong>: Matplotlib<a id="_idIndexMarker952"/> is a library that is used for creating <a id="_idIndexMarker953"/>visualizations from data. These visualizations involve various types of graphs and charts that rely on computed data that can be easily expressed and explained visually. It can create plot diagrams that are good for publications in scientific research papers and create interactive diagrams, all of which can be exported into different types of formats. You can find more <a id="_idIndexMarker954"/>details about Matplotlib here: <a href="https://matplotlib.org/">https://matplotlib.org/</a>.</li>
</ul>
<p>Scikit-learn is often used by data scientists when experimenting with data. It provides tons of flexibility when conducting experiments and since its APIs are very easy to use, it is often the go-to library for performing general ML functions.</p>
<p>H2O AutoML can be easily integrated with scikit-learn. You can use H2O AutoML as a scikit-learn <strong class="bold">Estimator</strong> and <a id="_idIndexMarker955"/>use it in conjunction with other scikit-learn functions to use the best of both worlds. H2O AutoML interacts with scikit-learn using<a id="_idIndexMarker956"/> the <strong class="bold">h2o.sklearn</strong> module. The h2o.sklearn module exposes two wrapper functions to perform AutoML:</p>
<ul>
<li><strong class="bold">H2OAutoMLClassifier</strong>: This<a id="_idIndexMarker957"/> function is used to train classification models using H2O AutoML</li>
<li><strong class="bold">H2OAutoMLRegressor</strong>: This<a id="_idIndexMarker958"/> function is used to train regression models using H2O AutoML</li>
</ul>
<p>The functions accept input data of various formats such as H2Oframes, NumPy arrays, or even pandas DataFrames. They also expose standard training and prediction APIs that are similar to how they are used in scikit-learn. This enables scikit-learn to use H2O AutoML, along with other scikit-learn components.</p>
<p>The H2O AutoML Estimators also retain their original functionality, such as leaderboards and training information, among others. Users can still access these details in scikit-learn to extract information from the AutoML training for further experimentation or analysis.</p>
<p>Now that we have a better understanding of the scikit-learn library and what it is used for, let’s learn how to use it alongside H2O AutoML. We will start by understanding the various ways that we can install scikit-learn on our system.</p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor190"/>Building and installing scikit-learn</h2>
<p>Installing scikit-learn <a id="_idIndexMarker959"/>is very easy. There are three different ways to install<a id="_idIndexMarker960"/> scikit-learn on your system:</p>
<ul>
<li>Installing the latest official release of scikit-learn</li>
<li>Installing the scikit-learn version provided by your Python distribution or operating system</li>
<li>Building and installing the scikit-learn package from the source</li>
</ul>
<p>Let’s quickly go through these options one by one so that we have scikit-learn ready to use alongside H2O AutoML.</p>
<h3>Installing the latest official release of scikit-learn</h3>
<p>This process <a id="_idIndexMarker961"/>can vary, depending on what type of Python package manager you are us<a id="_idTextAnchor191"/>ing on your system:</p>
<ul>
<li>Using the <strong class="source-inline">pip</strong> package manager, execute the following command in your Terminal to install the latest release of scikit-learn:<p class="source-code"><strong class="bold">pip install -U scikit-learn</strong></p><ul><li>The following command will show you where scikit-learn is installed, as well as its version:<p class="source-code"><strong class="bold">python -m pip show scikit-learn </strong></p></li></ul></li>
<li>Using<a id="_idIndexMarker962"/> the <strong class="bold">Anaconda</strong> or <strong class="bold">Miniconda</strong> package<a id="_idIndexMarker963"/> manager, execute <a id="_idIndexMarker964"/>the following command in your Terminal to install the latest release of scikit-learn:<p class="source-code"><strong class="bold">conda create -n sklearn-env -c conda-forge scikit-learn</strong></p><p class="source-code"><strong class="bold">conda activate sklearn-env</strong></p></li>
</ul>
<p>The following command will show you the version of scikit-learn installed on your system:</p>
<p class="source-code"><strong class="bold">conda list scikit-learn</strong></p>
<p>You can use the following command to import the installed scikit-learn module to ensure that it is successfully installed and then display its version: </p>
<p class="source-code"><strong class="bold">python -c "import sklearn; sklearn.show_versions()"</strong></p>
<p>Now that we know how to install scikit-learn using <strong class="source-inline">pip</strong>, Anaconda, and Miniconda, let’s look at another way of installing it using the Python distribution that comes packaged with your operating system. </p>
<h3>Installing scikit-learn using your operating system’s Python distribution</h3>
<p>Since scikit-learn <a id="_idIndexMarker965"/>is so commonly used by developers, it is often packaged along with the built-in package manager in various Python distributions or operating systems. This enables users to directly install the available scikit-learn package without needing to download it from the internet. </p>
<p>The following is a list of some of the operating systems that come with their own version of prepackaged scikit-learn and the respective Terminal commands to install it:</p>
<ul>
<li><strong class="bold">Arch Linux</strong>: The <a id="_idIndexMarker966"/>Arch Linux operating system distribution provides the scikit-learn library out of the box in the form of <strong class="source-inline">python-scikit-learn</strong>. To install this library, execute the following command:<p class="source-code"><strong class="bold">sudo pacman -S python-scikit-learn</strong></p></li>
<li><strong class="bold">Debian/Ubuntu</strong>: The<a id="_idIndexMarker967"/> Debian Ubuntu distribution splits the scikit-learn package into three parts:<ul><li><strong class="bold">python3-sklearn</strong>: This <a id="_idIndexMarker968"/>package contains the Python modules for scikit-learn functions</li><li><strong class="bold">python3-sklearn-lib</strong>: This <a id="_idIndexMarker969"/>package contains the low-level implementations and bindings for scikit-learn</li><li><strong class="bold">python3-sklearn-doc</strong>: This<a id="_idIndexMarker970"/> package contains the documentation for scikit-learn</li></ul></li>
</ul>
<p>To install<a id="_idIndexMarker971"/> this library, execute the following command:</p>
<p class="source-code"><strong class="bold">sudo apt-get install python3-sklearn python3-sklearn-lib python3-sklearn-doc</strong></p>
<ul>
<li><strong class="bold">Fedora</strong>: The<a id="_idIndexMarker972"/> Fedora operating system distribution provides the scikit-learn library out of the box in the form of <strong class="source-inline">python3-scikit-learn</strong>. It is the only one available in <strong class="source-inline">Fedora30</strong>:<p class="source-code"><strong class="bold">sudo dnf install python3-scikit-learn</strong></p></li>
<li><strong class="bold">NetBSD</strong>: In <a id="_idIndexMarker973"/>NetBSD, the scikit-learn library can be installed via its portable packaging system, called <strong class="bold">pkgsrc-wip</strong>. You can download the scikit-learn package for <strong class="source-inline">pkgsrc-wip</strong> from <a id="_idIndexMarker974"/>here: <a href="http://pkgsrc.se/math/py-scikit-learn">http://pkgsrc.se/math/py-scikit-learn</a>.</li>
</ul>
<p>The drawback of this process is that it often comes with an older version of scikit-learn. This, however, can be fixed by upgrading the installed packages to the latest versions using the respective package managers.</p>
<h3>Building and installing the scikit-learn package from the source</h3>
<p>Users that want to use the latest experimental features or those who wish to contribute to scikit-learn<a id="_idIndexMarker975"/> can directly build and install scikit-learn’s latest available version.</p>
<p>You can build and install scikit-learn from the source by executing the following steps:</p>
<ol>
<li>Use Git to check out the latest source from the scikit-learn repository on GitHub. The scikit-learn repository can be found here: <a href="https://github.com/scikit-learn/scikit-learn">https://github.com/scikit-learn/scikit-learn</a>. Execute the following command to clone the latest scikit-learn repository:<p class="source-code"><strong class="bold">git clone git://github.com/scikit-learn/scikit-learn.git</strong></p></li>
<li>Use Python to create a<a id="_idIndexMarker976"/> virtual environment and install <strong class="bold">NumPy</strong>, <strong class="bold">SciPy</strong>, and <strong class="bold">Cython</strong>, which <a id="_idIndexMarker977"/>are the build dependencies for <a id="_idIndexMarker978"/>scikit-learn:<p class="source-code"><strong class="bold">python3 -m venv h2o-sklearn</strong></p><p class="source-code"><strong class="bold">source h2o-sklearn/bin/activate</strong></p><p class="source-code"><strong class="bold">pip install wheel numpy scipy cython</strong></p></li>
<li>Use <strong class="source-inline">pip</strong> to build the project by running the following command:<p class="source-code"><strong class="bold">pip install --verbose --no-build-isolation --editable .</strong></p></li>
<li>Once the installation is completed, check if scikit-learn is installed correctly by running the following command:<p class="source-code"><strong class="bold">python -c "import sklearn; sklearn.show_versions()"</strong></p></li>
</ol>
<p>To avoid conflicts with other packages, it is highly recommended to install scikit-learn in a virtual environment or <a id="_idIndexMarker979"/>a <strong class="bold">conda</strong> environment. Also, when installing SciPy and NumPy, it is recommended to<a id="_idIndexMarker980"/> use <strong class="bold">binary wheels</strong> as they are not recompiled from the source.</p>
<h2 id="_idParaDest-146"><a id="_idTextAnchor192"/>Experimenting with scikit-learn</h2>
<p>Now that we<a id="_idIndexMarker981"/> have successfully installed scikit-learn, let’s quickly look at a simple implementation of scikit-learn for training a model. Using this as a reference, we shall then explore how we can incorporate H2O AutoML into it.</p>
<p>The dataset we shall use for this experiment will be the same Iris flower dataset that we have been using throughout this book. This dataset is a good example of using ML to solve a classification problem.</p>
<p>So, let’s begin by implementing it using pure scikit-learn functions.</p>
<p>Follow these steps to train your ML model in Python using scikit-learn:</p>
<ol>
<li value="1">Import the <strong class="source-inline">sklearn</strong> and <strong class="source-inline">numpy</strong> libraries:<p class="source-code"><strong class="bold">import sklearn</strong></p><p class="source-code"><strong class="bold">import numpy</strong></p></li>
<li>The Iris flower dataset is readily available<a id="_idIndexMarker982"/> in the <strong class="source-inline">sklearn</strong> library; it is present in the dataset submodule of <strong class="source-inline">sklearn</strong>. Next, import that dataset by executing the following commands. Let’s also have a closer look at the contents of the DataFrame:<p class="source-code"><strong class="bold">from sklearn.datasets import load_iris</strong></p><p class="source-code"><strong class="bold">dataframe = load_iris()</strong></p><p class="source-code"><strong class="bold">print(dataframe)</strong></p></li>
</ol>
<p>You should get an output displaying the contents of the DataFrame in the form of a dictionary. Let’s investigate the important key-value pairs in the dictionary to understand what we are dealing with:</p>
<ul>
<li><strong class="source-inline">data</strong>: This <a id="_idIndexMarker983"/>key contains all the features of the dataset – that is, the sepal length, sepal width, petal length, and petal width – in the form of a multi-dimensional array. </li>
<li><strong class="source-inline">target_names</strong>: This<a id="_idIndexMarker984"/> key contains the names of the target or labels of the dataset – that is, Iris-setosa, Iris-versicolour, and Iris-virginica. This is an array, and the index of the names is the numerical representation that is used in the actual content of the dataset.</li>
<li><strong class="source-inline">target</strong>: This <a id="_idIndexMarker985"/>key contains all the target values, also called label values, of the dataset. This is also an array that represents the values of the target that would have otherwise been a column in a tabular dataset. The values are numeric, where <strong class="source-inline">0</strong> represents Iris-setosa, <strong class="source-inline">1</strong> represents Iris-versicolour, and <strong class="source-inline">2</strong> represents Iris-virginica, as decided by their index values in <strong class="source-inline">target_names</strong>.</li>
</ul>
<ol>
<li value="3">With this<a id="_idIndexMarker986"/> information in mind, extract the features and labels into separate variables by executing the following command:<p class="source-code"><strong class="bold">features = dataframe.data</strong></p><p class="source-code"><strong class="bold">label = dataframe.target</strong></p></li>
<li>We need to split the dataset into two parts – one for training and the other for testing. Unlike H2O, in scikit-learn, we treat the features and labels as two separate entities. Both of them should have the same dimensional length to match the data contents. To do this split, execute the following commands:<p class="source-code"><strong class="bold">from sklearn.model_selection import train_test_split</strong></p><p class="source-code"><strong class="bold">feature_train, feature_test, label_train, label_test = train_test_split(features, label, test_size=0.30, random_state=5)</strong></p></li>
</ol>
<p>The split functionality splits the features and labels into a 70% to 30% ratio, where 70% of the data is kept for training and the remaining 30% is kept for testing. So, we eventually end up with a total of four DataFrames, as follows:</p>
<ul>
<li><strong class="source-inline">feature_train</strong>: This <a id="_idIndexMarker987"/>DataFrame contains 70% of the feature data to be used for training</li>
<li><strong class="source-inline">label_train</strong>: This <a id="_idIndexMarker988"/>DataFrame contains 70% of the label data to be used for training</li>
<li><strong class="source-inline">feature_test</strong>: This <a id="_idIndexMarker989"/>DataFrame contains 30% of the feature data to be used for testing</li>
<li><strong class="source-inline">label_test</strong>: This<a id="_idIndexMarker990"/> DataFrame contains 30% of the label data to be used for testing</li>
</ul>
<ol>
<li value="5">Once <a id="_idIndexMarker991"/>the training and testing DataFrames are ready, declare and initialize the ML algorithm to be used for model training. Scikit-learn has separate libraries for different types of algorithms. Since we are working with a classification problem, let’s use the <strong class="bold">logistic regression</strong> algorithm <a id="_idIndexMarker992"/>to train a classification model. Execute the following command to initialize a logistic regression function to train a model:<p class="source-code"><strong class="bold">from sklearn.linear_model import LogisticRegression</strong></p><p class="source-code"><strong class="bold">logReg = LogisticRegression(solver='lbfgs', max_iter=1000)</strong></p></li>
<li>Now, let’s train a model using the <strong class="source-inline">feature_train</strong> and <strong class="source-inline">label_train</strong> datasets. Execute the following function:<p class="source-code"><strong class="bold">logReg.fit(feature_train, label_train)</strong></p></li>
<li>Once training is finished, we can use the same logistic regression object to make predictions on the <strong class="source-inline">feature_test</strong> DataFrame. Execute the following command and print out the prediction’s output:<p class="source-code"><strong class="bold">predictions = logReg.predict(feature_test)</strong></p><p class="source-code"><strong class="bold">print(predictions)</strong></p></li>
</ol>
<p>You should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer265">
<img alt="Figure 9.1 – Prediction output from scikit-learn logistic regression " height="56" src="image/B17298_09_001.jpg" width="692"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Prediction output from scikit-learn logistic regression</p>
<ol>
<li value="8">You can also measure the accuracy of your predictions by executing the following command:<p class="source-code"><strong class="bold">score = logReg.score(feature_test, label_test)</strong></p><p class="source-code"><strong class="bold">print(score)</strong></p></li>
</ol>
<p>You should get an accuracy of around <strong class="source-inline">97.77</strong>.</p>
<p>In this experiment, we learned how to use scikit-learn to import a dataset, perform splitting, and then use logistic regression to train a classification model. But as we learned in the previous chapters, there are plenty of ML algorithms to choose from. Each has its own way of dealing<a id="_idIndexMarker993"/> with <strong class="bold">variance</strong> and <strong class="bold">bias</strong>. So, as <a id="_idIndexMarker994"/>expected, the most obvious question remains unanswered: <em class="italic">which ML algorithm should we use?</em></p>
<p>As we saw<a id="_idIndexMarker995"/> in this experiment, scikit-learn may have tons of support for different algorithms, but training all of them can become complicated from a programming point of view. This is where we can integrate H2O AutoML to perform automated model training to train all the ML algorithms.</p>
<p>Now that we have got a good idea of how we can use scikit-learn to train models, let’s see how we can use H2O AutoML with scikit-learn.</p>
<h2 id="_idParaDest-147"><a id="_idTextAnchor193"/>Using H2O AutoML in scikit-learn</h2>
<p>First, we will learn how<a id="_idIndexMarker996"/> to use H2O AutoML in scikit-learn<a id="_idIndexMarker997"/> to perform classification using the <strong class="source-inline">H2OAutoMLClassifier</strong> submodule. We shall use the same classification ML problem using the Iris dataset and see how we can train multiple models using H2O AutoML.</p>
<h3>Experimenting with H2OAutoMLClassifier</h3>
<p>Follow <a id="_idIndexMarker998"/>these steps to train your H2O AutoML classification model in Python using scikit-learn:</p>
<ol>
<li value="1">Implement <em class="italic">steps 1</em> to <em class="italic">4</em> that we followed in the <em class="italic">Experimenting with scikit-learn</em> section.</li>
<li>In the experiment we performed in the <em class="italic">Experimenting with scikit-learn</em> section, after <em class="italic">step 4</em>, we initialized the logistic regression algorithm by importing the <strong class="source-inline">LogisticRegression</strong> submodule from <strong class="source-inline">sklearn.linear_model</strong>. In this experiment, we will import the <strong class="source-inline">H2OAutoMLClassifier</strong> submodule from the <strong class="source-inline">h2o.sklearn</strong> module instead:<p class="source-code"><strong class="bold">from h2o.sklearn import H2OAutoMLClassifier</strong></p><p class="source-code"><strong class="bold">h2o_aml_classifier = H2OAutoMLClassifier(max_models=10, seed=5, max_runtime_secs_per_model=30, sort_metric='logloss')</strong></p></li>
</ol>
<p>Just like how we set the AutoML parameters in the previous chapters, we have set <strong class="source-inline">max_models</strong> to <strong class="source-inline">10</strong>,<strong class="source-inline"> max_runtime_secs_per_model</strong> to <strong class="source-inline">30</strong> seconds, the random <strong class="source-inline">seed</strong> value to <strong class="source-inline">5</strong>, and <strong class="source-inline">sort_metric</strong> to <strong class="source-inline">logloss</strong>.</p>
<ol>
<li value="3">Once <strong class="source-inline">H2OAutoMLClassifier</strong> has been initialized, you can use it to fit – in other words, train – your models. Execute the following command to trigger AutoML training:<p class="source-code"><strong class="bold">h2o_aml_classifier.fit(feature_train, label_train)</strong></p></li>
</ol>
<p>First, the program will check if an H2O instance is already running on localhost:54321. If not, then H2O will spin up an instance of the H2O server; otherwise, it will reuse the already existing one to train the AutoML models. Once training starts, you should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer266">
<img alt="Figure 9.2 – Output from H2O AutoML classifier training " height="253" src="image/B17298_09_002.jpg" width="1073"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Output from H2O AutoML classifier training</p>
<p>From the <a id="_idIndexMarker999"/>output, you can see that H2O first imported and parsed the <strong class="bold">feature_train</strong> and <strong class="bold">label_train</strong> DataFrames. Then, it started the AutoML training.</p>
<ol>
<li value="4">To view the results of the AutoML training, you can<a id="_idIndexMarker1000"/> view the H2O <strong class="bold">leaderboard</strong> by executing the following command:<p class="source-code"><strong class="bold">h2o_aml_classifier.estimator.leaderboard</strong></p></li>
</ol>
<p>You should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer267">
<img alt="Figure 9.3 – H2O AutoML leaderboard " height="294" src="image/B17298_09_003.jpg" width="753"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – H2O AutoML leaderboard</p>
<ol>
<li value="5">Using the same H2O AutoML classifier, you can also make predictions, as follows:<p class="source-code"><strong class="bold">predictions = h2o_aml_classifier.predict(feature_test)</strong></p><p class="source-code"><strong class="bold">print(predictions)</strong></p></li>
</ol>
<p>You should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer268">
<img alt="Figure 9.4 – Output of the prediction using H2OAutoMLClassifier " height="77" src="image/B17298_09_004.jpg" width="755"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Output of the prediction using H2OAutoMLClassifier</p>
<p>By default, the classifier will use the model with the highest rank on the leaderboard<a id="_idIndexMarker1001"/> to make predictions.</p>
<p>With that, you have learned how to implement H2O AutoML in scikit-learn to solve classification problems using <strong class="source-inline">H2OAutoMLClassifier</strong>.</p>
<p>Now that we have a good idea of how we can use <strong class="source-inline">H2OAutoMLClassifier</strong> to perform classification predictions on data, let’s see how we can perform regression predictions using the <strong class="source-inline">H2OAutoMLRegressor</strong> submodule. </p>
<h3>Experimenting with H2OAutoMLRegressor</h3>
<p>Now, let’s see<a id="_idIndexMarker1002"/> how we solve a <strong class="bold">regression</strong> problem using <strong class="source-inline">H2OAutoMLRegressor</strong>. For this experiment, we shall use the Red Wine Quality dataset that we used previously in <a href="B17298_07.xhtml#_idTextAnchor143"><em class="italic">Chapter 7</em></a>, <em class="italic">Working with Model Explainability</em>.</p>
<p>Follow these steps to train your H2O AutoML regression model in Python using scikit-learn:</p>
<ol>
<li value="1">Implement <em class="italic">Steps 1</em> to <em class="italic">4</em> that we followed in the <em class="italic">Experimenting with scikit-learn</em> section.</li>
<li>In the experiment we performed in the <em class="italic">Experimenting with H2OAutoMLClassifier</em> section, we initialized <strong class="source-inline">H2OAutoMLClassifier</strong>. Since we are dealing with a regression problem in this experiment, we shall use the <strong class="source-inline">H2OAutoMLRegressor</strong> submodule. Execute the following command to import and instantiate the <strong class="source-inline">H2OAutoMLRegressor</strong> class object:<p class="source-code"><strong class="bold">from h2o.sklearn import H2OAutoMLRegressor</strong></p><p class="source-code"><strong class="bold">h2o_aml_regressor = H2OAutoMLRegressor(max_models=10, max_runtime_secs_per_model=30, seed=5)</strong></p></li>
<li>Once <strong class="source-inline">H2OAutoMLRegressor</strong> has been initialized, we can trigger AutoML to train our <a id="_idIndexMarker1003"/>regression models. Execute the following command to trigger AutoML:<p class="source-code"><strong class="bold">h2o_aml_regressor.fit(feature_train, label_train)</strong></p></li>
</ol>
<p>Once model training finishes, you should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer269">
<img alt="Figure 9.5 – Output from H2O AutoML regressor training " height="182" src="image/B17298_09_005.jpg" width="752"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Output from H2O AutoML regressor training</p>
<ol>
<li value="4">Similar to <strong class="source-inline">H2OAutoMLClassifier</strong>, you can also view the results of the AutoML training on the <a id="_idIndexMarker1004"/>H2O <strong class="bold">leaderboard</strong> by executing the following command:<p class="source-code"><strong class="bold">h2o_aml_regressor.estimator.leaderboard</strong></p></li>
<li>Making predictions is also very easy. You use the same <strong class="source-inline">H2OAutoMLRegressor</strong> object and call its <strong class="source-inline">predict</strong> method while passing the feature dataset kept aside for testing. Execute the following command to make predictions using the leader model trained by <strong class="source-inline">H2OAutoMLRegressor</strong>:<p class="source-code"><strong class="bold">predictions = h2o_aml_regressor.predict(feature_test)</strong></p><p class="source-code"><strong class="bold">print(predictions)</strong></p></li>
</ol>
<p>You should get the results of the prediction, as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer270">
<img alt="Figure 9.6 – Output of the prediction using H2OAutoMLRegressor " height="417" src="image/B17298_09_006.jpg" width="759"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Output of the prediction using H2OAutoMLRegressor</p>
<p>The <a id="_idIndexMarker1005"/>prediction output is an array containing the <strong class="bold">quality</strong> of the dataset calculated against each data entry in the <strong class="source-inline">feature_test</strong> DataFrame. This is how you can implement H2O AutoML in scikit-learn to solve regression problems using <strong class="source-inline">H2OAutoMLRegressor</strong>.</p>
<p>Now that you know how to use H2O AutoML in scikit-learn, let’s move on to the next miscellaneous feature of H2O AutoML: event logging.</p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor194"/>Understanding H2O AutoML event logging</h1>
<p>Since <a id="_idIndexMarker1006"/>H2O AutoML automates most of the ML process, we have given some control to the machine. Encapsulation means that all the complexities that lie in AutoML are all hidden away, and we are just aware of the inputs and whatever output H2O AutoML gives us. If there is any issue in H2O AutoML and it gives us models that don’t make sense or are not expected, then we will need to dig deeper into how AutoML trained the models. Hence, we need a way to keep track of what’s happening internally in H2O AutoML and whether it is training models as expected or not.</p>
<p>When <a id="_idIndexMarker1007"/>building such software systems that are aimed to be used in <a id="_idIndexMarker1008"/>production, you will always need a logging system to log information. The virtual nature of software makes it difficult for users to keep track of what is going on as the system does its processing and other activities. Any failures or issues can lead to a cascade of underlying problems that developers may end up finding out too late, if ever. </p>
<p>That is why logging systems are always implemented to provide support to your system. Logs generated by your system help developers track down the source of the problem and mitigate it promptly. H2O AutoML can also generate logs containing meta-information about all the underlying processing that happens when it is training models. You can use these logs to keep some sense of control when you are letting H2O take care of all the ML processing.</p>
<p>There are two types of logs that AutoML generates. They are as follows:</p>
<ul>
<li><strong class="bold">Event Logs</strong>: These are <a id="_idIndexMarker1009"/>event logs that are generated in the backend of AutoML as training progresses. All the logs are collected and presented as an H2O DataFrame.</li>
<li><strong class="bold">Training Logs</strong>: These<a id="_idIndexMarker1010"/> are logs that show training and prediction times as AutoML trains models and are in the form of a dictionary of key-value pairs. The training times are in epochs and are mostly useful for post-analysis of model training.</li>
</ul>
<p>Let’s see how we can <a id="_idIndexMarker1011"/>retrieve these logs from H2O AutoML via a practical implementation.</p>
<p>Follow these steps to train models using H2O AutoML. Then, we will learn how to extract the logs and understand what they look like:</p>
<ol>
<li value="1">Import the <strong class="source-inline">h2o</strong> module and initialize H2O to spin up a local H2O server:<p class="source-code"><strong class="bold">import h2o</strong></p><p class="source-code"><strong class="bold">h2o.init()</strong></p></li>
<li>Import the Iris dataset by passing the location of where you downloaded the dataset:<p class="source-code"><strong class="bold">data = h2o.import_file("Dataset/iris.data")</strong></p></li>
<li>Set the<a id="_idIndexMarker1012"/> label and features:<p class="source-code"><strong class="bold">label = "C5"</strong></p><p class="source-code"><strong class="bold">features = data.columns</strong></p><p class="source-code"><strong class="bold">features.remove(label)</strong></p></li>
<li>Initialize the <a id="_idIndexMarker1013"/>H2O AutoML object with parameters, as follows:<p class="source-code"><strong class="bold">aml = h2o.automl.H2OAutoML(max_models=10, seed = 5)</strong></p></li>
<li>Trigger AutoML training by passing in the feature columns, label column, and the DataFrame to use to train the models on:<p class="source-code"><strong class="bold">aml.train(x = features, y = label, training_frame = dataframe)</strong></p></li>
<li>Once training is finished, you can view the event logs by using the <strong class="source-inline">event_log</strong> property of the AutoML object. Let’s retrieve the log DataFrame and have a look at its content:<p class="source-code"><strong class="bold">event_logs = aml.event_log</strong></p><p class="source-code"><strong class="bold">print(event_logs)</strong></p></li>
</ol>
<p>You should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer271">
<img alt="Figure 9.7 – Event log output from H2O AutoML " height="302" src="image/B17298_09_007.jpg" width="1011"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Event log output from H2O AutoML</p>
<p>Similarly, you <a id="_idIndexMarker1014"/>can view the<a id="_idIndexMarker1015"/> event logs in the R programming language by executing the<a id="_idIndexMarker1016"/> following R commands:</p>
<p class="source-code"><strong class="bold">event_log &lt;- aml@event_log</strong></p>
<p>The event log contains the following information:</p>
<ul>
<li><strong class="bold">timestamp</strong>: This <a id="_idIndexMarker1017"/>column is the time of occurrence of a particular event.</li>
<li><strong class="bold">level</strong>: In<a id="_idIndexMarker1018"/> logging systems, logs are generally categorized into certain classes of importance or criticality. In most cases, the levels are as follows based on criticality ranking: <ol><li><strong class="bold">FATAL</strong>: This<a id="_idIndexMarker1019"/> log level indicates that the application is facing a critical issue and will need to stop functioning and shut down.</li><li><strong class="bold">ERROR</strong>: This <a id="_idIndexMarker1020"/>log level indicates that the application is facing an issue performing certain functions. However, the issue is not that critical that the application needs to shut down.</li><li><strong class="bold">WARN</strong>: This<a id="_idIndexMarker1021"/> log level indicates that the application has detected something unusual that is harmless and is not affecting any functionality.</li><li><strong class="bold">INFO</strong>: This <a id="_idIndexMarker1022"/>log level indicates normal behavior updates that can be recorded and stored for future reference if needed. They are usually informative.</li><li><strong class="bold">DEBUG</strong>: This <a id="_idIndexMarker1023"/>log level indicates more detailed diagnostic details that are often needed when developing an application or to gather more information when you are performing diagnostic actions or debugging an issue.</li><li><strong class="bold">TRACE</strong>: This<a id="_idIndexMarker1024"/> log level is similar to <strong class="bold">DEBUG</strong> albeit with finer details, especially when you are tracing the flow of information in a code base.</li></ol></li>
<li><strong class="bold">stage</strong>: This <a id="_idIndexMarker1025"/>column indicates the stage in AutoML training at which the log was generated.</li>
<li><strong class="bold">message</strong>: This<a id="_idIndexMarker1026"/> column contains a descriptive message that provides information about the event that occurred.</li>
<li><strong class="bold">name</strong>: This <a id="_idIndexMarker1027"/>column contains the name of the event log that occurred if it is set.</li>
<li><strong class="bold">value</strong>: This <a id="_idIndexMarker1028"/>column contains the value of the event log that occurred if it is set.</li>
</ul>
<ol>
<li value="7">Now, let’s<a id="_idIndexMarker1029"/> retrieve <a id="_idIndexMarker1030"/>the training logs and look at their content:<p class="source-code"><strong class="bold">info_logs = aml.training_info</strong></p><p class="source-code"><strong class="bold">print(info_logs)</strong></p></li>
</ol>
<p>You should get an output similar to the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer272">
<img alt="Figure 9.8 – Event log output from H2O AutoML " height="335" src="image/B17298_09_008.jpg" width="771"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Event log output from H2O AutoML</p>
<p>Similarly, you can<a id="_idIndexMarker1031"/> view the event logs in the R programming <a id="_idIndexMarker1032"/>language by executing the following R commands:</p>
<p class="source-code"><strong class="bold">info_logs &lt;- aml@training_info</strong></p>
<p>The training log contains the following information:</p>
<ul>
<li><strong class="source-inline">creation_epoch</strong>: This <a id="_idIndexMarker1033"/>key in the training log dictionary contains the epoch value of when the AutoML job was created.</li>
<li><strong class="source-inline">start_epoch</strong>: This<a id="_idIndexMarker1034"/> key in the training log dictionary contains the epoch value of when the AutoML build started.</li>
<li><strong class="source-inline">start_{model_name}</strong>: This<a id="_idIndexMarker1035"/> type of key in the training log dictionary contains the epoch value of when the training of a particular model was started.</li>
<li><strong class="source-inline">stop_epoch</strong>: This <a id="_idIndexMarker1036"/>key in the training log dictionary contains the epoch value of when the AutoML build stopped.</li>
<li><strong class="source-inline">duration_secs</strong>: This <a id="_idIndexMarker1037"/>key in the training log dictionary contains the total time when AutoML was running in seconds.</li>
</ul>
<p>This experiment <a id="_idIndexMarker1038"/>gives us a good example of how H2O generates log events. When building an ML system using H2O AutoML, you can incorporate these logs into your logging system to keep <a id="_idIndexMarker1039"/>an eye on H2O AutoML’s functionality. This will help you identify any issues that may arise promptly and keep your models in production of the highest quality. You will be alerted if there were any issues during training and before you accidentally end up deploying faulty models in production.</p>
<h1 id="_idParaDest-149"><a id="_idTextAnchor195"/>Summary</h1>
<p>In this chapter, we understood some of the miscellaneous features of H2O AutoML. We started by understanding the scikit-learn library and getting an idea of its implementation. Then, we saw how we can use the <strong class="source-inline">H2OAutoMLClassifier</strong> library and the <strong class="source-inline">H2OAutoMLRegressor</strong> library in a scikit-learn implementation to train AutoML models.</p>
<p>Then, we explored H2O AutoML’s logging system. After that, we implemented a simple experiment where we triggered AutoML training; once it was finished, we extracted the event logs and the training logs in both the Python and R programming languages. Then, we understood the contents of those logs and how that information benefits us in keeping an eye on H2O AutoML functionality.</p>
<p>In the next chapter, we shall further focus on using H2O in production and how we can do so using H2O’s Model Object Optimized.</p>
</div>
<div>
<div id="_idContainer274">
</div>
</div>
</div></body></html>