- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensemble Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anyone who works with data analysis and machine learning will understand that
    no method is ideal or universal. This is why there are so many methods. Researchers
    and enthusiasts have been searching for years for a compromise between the accuracy,
    simplicity, and interpretability of various models. Moreover, how can we increase
    the accuracy of the model, preferably without changing its essence? One way to
    improve the accuracy of models is to create and train model **ensembles**—that
    is, sets of models used to solve the same problem. The ensemble training methodology
    is the training of a final set of simple classifiers, with a subsequent merging
    of the results of their predictions into a single forecast of the aggregated algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter describes what ensemble learning is, what types of ensembles exist,
    and how they can help to obtain better predictive performance. In this chapter,
    we will also implement examples of these approaches with different C++ libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of ensemble learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about decision trees and random forests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of using C++ libraries for creating ensembles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The technologies and installations required in the chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Dlib` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `mlpack` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A modern C++ compiler with C++20 support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A CMake build system version >= 3.22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code files for this chapter can be found at the following GitHub repo:
    [https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter09](https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter09)'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of ensemble learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The training of an ensemble of models is understood to be the procedure of training
    a final set of elementary algorithms whose results are then combined to form the
    forecast of an aggregated classifier. The model ensemble’s purpose is to improve
    the accuracy of the prediction of the aggregated classifier, particularly when
    compared with the accuracy of every single elementary classifier. It is intuitively
    clear that combining simple classifiers can give a more accurate result than each
    simple classifier separately. Despite that, simple classifiers can be sufficiently
    accurate on particular datasets, but at the same time, they can make mistakes
    on different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: An example of ensembles is **Condorcet’s jury theorem** (1784). A jury must
    come to a correct or incorrect consensus, and each juror has an independent opinion.
    If the probability of the correct decision of each juror is more than 0.5, then
    the probability of a correct decision from the jury as a whole (tending toward
    1) increases with the size of the jury. If the probability of making the correct
    decision is less than 0.5 for each juror, then the probability of making the right
    decision monotonically decreases (tending toward zero) as the jury size increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The theorem is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*N*: The number of jury members'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_001.png): The probability of the jury member making
    the right decision'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*μ*: The probability of the entire jury making the correct decision'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*m*: The minimum majority of jury members:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/B22503_Formula_003.png): The number of combinations of *N* by *i*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If ![](img/B22503_Formula_005.png) then ![](img/B22503_Formula_006.png)
  prefs: []
  type: TYPE_NORMAL
- en: If ![](img/B22503_Formula_007.png) then ![](img/B22503_Formula_008.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, based on general reasoning, three reasons why ensembles of classifiers
    can be successful can be distinguished, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical**: The classification algorithm can be viewed as a search procedure
    in the space of the **H hypothesis**, concerned with the distribution of data
    in order to find the best hypothesis. By learning from the final dataset, the
    algorithm can find many different hypotheses that describe the training sample
    equally well. By building an ensemble of models, we *average out* the error of
    each hypothesis and reduce the influence of instabilities and randomness in the
    formation of a new hypothesis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computational**: Most learning algorithms use methods for finding the extremum
    of a specific objective function. For example, neural networks use **gradient
    descent** (**GD**) methods to minimize prediction errors. Decision trees use greedy
    algorithms that minimize data entropy. These optimization algorithms can become
    stuck at a local extremum point, which is a problem because their goal is to find
    a global optimum. The ensembles of models combining the results of the prediction
    of simple classifiers, trained on different subsets of the source data, have a
    higher chance of finding a global optimum since they start a search for the optimum
    from different points in the initial set of hypotheses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Representative**: A combined hypothesis may not be in the set of possible
    hypotheses for simple classifiers. Therefore, by building a combined hypothesis,
    we expand the set of possible hypotheses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Condorcet’s jury theorem and the reasons provided previously are not entirely
    suitable for real, practical situations because the algorithms are not independent
    (they solve one problem, they learn on one target vector, and can only use one
    model, or a small number of models).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the majority of techniques in applied ensemble development are aimed
    at ensuring that the ensemble is diverse. This allows the errors of individual
    algorithms in individual objects to be compensated for by the correct operations
    of other algorithms. Overall, building the ensemble results in an improvement
    in both the quality and variety of simple algorithms. The goal is to create a
    diverse set of predictions that complement each other and reduce the overall variance
    and bias of the ensemble’s predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest type of ensemble is model averaging, whereby each member of the
    ensemble makes an equal contribution to the final forecast. The fact that each
    model has an equal contribution to the final ensemble’s forecast is a limitation
    of this approach. The problem is in unbalanced contributions. Despite that, there
    is a requirement that all members of the ensemble have prediction skills higher
    than random chance.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is known that some models work much better or much worse than other
    models. Some improvements can be made to solve this problem, using a weighted
    ensemble in which the contribution of each member to the final forecast is weighted
    by the performance of the model. When the weight of the model is a small positive
    value and the sum of all weights equals 1, the weights can indicate the percentage
    of confidence in (or expected performance from) each model.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this time, the most common approaches to ensemble construction are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bagging**: This is an ensemble of models studying in parallel on different
    random samples from the same training set. The final result is determined by the
    voting of the algorithms of the ensemble. For example, in classification, the
    class that is predicted by the most classifiers is chosen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boosting**: This is an ensemble of models trained sequentially, with each
    successive algorithm being trained on samples in which the previous algorithm
    made a mistake.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stacking**: This is an approach whereby a training set is divided into *N*
    blocks, and a set of simple models is trained on *N-1* of them. An *N-th* model
    is then trained on the remaining block, but the outputs of the underlying algorithms
    (forming the so-called **meta-attribute**) are used as the target variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random forest**: This is a set of decision trees built independently, and
    whose answers are averaged and decided by a majority vote.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following sections discuss the previously described approaches in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Using a bagging approach for creating ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bagging (from the bootstrap aggregation) is one of the earliest and most straightforward
    types of ensembles. Bagging is based on the statistical bootstrap method, which
    aims to obtain the most accurate sample estimates and to extend the results to
    the entire population. The bootstrap method is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose there is an *X* dataset of size *M*. Evenly select from the dataset
    *N* objects and return each object back to the dataset after selection. Before
    selecting the next one, we can generate *N* sub-datasets. This procedure means
    that *N* times, we select an arbitrary sample object (we assume that each object
    is *picked up* with the same probability ![](img/B22503_Formula_009.png)), and
    each time, we choose from all the original *M* objects. Also, this procedure is
    called sampling with replacement, and it means that each element in the dataset
    has an equal chance of being selected multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: We can imagine this as a bag from which balls are taken. The ball selected at
    a given step is returned to the bag following its selection, and the next choice
    is again made with equal probability from the same number of balls. Note that
    due to the ball being returned each time, there are repetitions.
  prefs: []
  type: TYPE_NORMAL
- en: Each new selection is denoted as *X*1\. Repeating the procedure *k* times, we
    generate *k* sub-datasets. Now, we have a reasonably large number of samples,
    and we can evaluate various statistics of the original distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The main descriptive statistics are the sample mean, median, and standard deviation.
    Summary statistics—for example, the sample mean, median, and correlation—can vary
    from sample to sample. The bootstrap idea is to use sampling results as a fictitious
    population to determine the sample distribution of statistics. The bootstrap method
    analyzes a large number of phantom samples, called **bootstrap samples**. For
    each sample, an estimate of the target statistics is calculated, then the estimates
    are averaged. The bootstrap method can be viewed as a modification of the **Monte**
    **Carlo method**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose there is the *X* training dataset. With the help of the bootstrap method,
    we can generate ![](img/B22503_Formula_010.png) sub-datasets. Now, on each sub-dataset,
    we can train our ![](img/B22503_Formula_011.png) classifier. The final classifier
    averages these classifier responses (in the case of classification, this corresponds
    to a vote), as follows: ![](img/B22503_Formula_012.png). The following diagram
    shows this scheme:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Bagging approach scheme](img/B19849_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Bagging approach scheme
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the regression problem by using simple algorithms ![](img/B22503_Formula_013.png).
    Suppose that there is a true answer function for all *y(x)* objects, and there
    is also a distribution on ![](img/B22503_Formula_014.png) objects. In this case,
    we can write the error of each regression function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also write the expectation of the **mean squared error** (**MSE**) as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The average error of the constructed regression functions is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, suppose the errors are unbiased and uncorrelated, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we can write a new regression function that averages the responses of the
    functions we have constructed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let’s find its **root MSE** (**RMSE**) to see the effect of averaging, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, averaging the answers has allowed us to reduce the average square of the
    error by *n* times.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging also allows us to reduce the variance of the trained algorithm and prevent
    overfitting. The effectiveness of bagging is based on the underlying algorithms,
    which are trained on various sub-datasets that are quite different, and their
    errors are mutually compensated during voting. Also, outlying objects may not
    fall into some of the training sub-datasets, which also increases the effectiveness
    of the bagging approach.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging is useful with small datasets when the exclusion of even a small number
    of training objects leads to the construction of substantially different simple
    algorithms. In the case of large datasets, sub-datasets that are significantly
    smaller than the original ones are usually generated.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the assumption about uncorrelated errors is rarely satisfied. If
    this assumption is incorrect, then the error reduction is not as significant as
    we might have assumed.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, bagging provides a good improvement to the accuracy of results
    when compared to simple individual algorithms, particularly if a simple algorithm
    is sufficiently accurate but unstable. Improving the accuracy of the forecast
    occurs by reducing the spread of the error-prone forecasts of individual algorithms.
    The advantage of the bagging algorithm is its ease of implementation, as well
    as the possibility of paralleling the calculations for training each elementary
    algorithm on different computational nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Using a gradient boosting method for creating ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main idea of boosting is that the elementary algorithms are not built independently.
    We build every sequential algorithm so that it corrects the mistakes of the previous
    ones and therefore improves the quality of the whole ensemble. The first successful
    version of boosting was **Adaptive Boosting** (**AdaBoost**). It is now rarely
    used since gradient boosting has supplanted it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that we have a set of pairs, where each pair consists of attribute
    *x* and target variable *y*, ![](img/B22503_Formula_021.png). On this set, we
    restore the dependence of the form ![](img/B22503_Formula_022.png). We restore
    it by the approximation ![](img/B22503_Formula_023.png). To select the best approximation
    solution, we use a specific loss function of the form ![](img/B22503_Formula_024.png),
    which we should optimize as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We also can rewrite the expression in terms of mathematical expectations, since
    the amount of data available for learning is limited, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Our approximation is inaccurate. However, the idea behind boosting is that
    such an approximation can be improved by adding to the model with the result of
    another model that corrects its errors, as illustrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following equation shows the ideal error correction model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can rewrite this formula in the following form, which is more suitable for
    the corrective model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Based on the preceding assumptions listed, the goal of boosting is to approximate
    ![](img/B22503_Formula_030.png) to make its results correspond as closely as possible
    to the *residuals* ![](img/B22503_Formula_031.png). Such an operation is performed
    sequentially—that is, ![](img/B22503_Formula_032.png) improves the results of
    the previous ![](img/B22503_Formula_033.png) function.
  prefs: []
  type: TYPE_NORMAL
- en: A further generalization of this approach allows us to consider the residuals
    as a negative gradient of the loss function, specifically of the form ![](img/B22503_Formula_034.png).
    In other words, gradient boosting is a method of GD with the loss function and
    its gradient replacement.
  prefs: []
  type: TYPE_NORMAL
- en: Now, knowing the expression of the loss function gradient, we can calculate
    its values on our data. Therefore, we can train models so that our predictions
    are better correlated with this gradient (with a minus sign). Hence, we will solve
    the regression problem, trying to correct the predictions for these residuals.
    For classification, regression, and ranking, we always minimize the squared difference
    between the residuals and our predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the gradient boosting method, an approximation of the function of the following
    form is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_035.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is the sum of ![](img/B22503_Formula_036.png) functions of the ![](img/B22503_Formula_037.png)
    class; they are collectively called **weak models** (algorithms). Such an approximation
    is carried out sequentially, starting from the initial approximation, which is
    a certain constant, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_038.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Unfortunately, the choice of the ![](img/B22503_Formula_039.png) optimal function
    at each step for an arbitrary loss function is extremely difficult, so a more
    straightforward approach is used. The idea is to use the GD method by using differentiable
    ![](img/B22503_Formula_040.png) functions and a differentiable loss function,
    as illustrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_041.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The boosting algorithm is then formed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the model with constant values, like this:![](img/B22503_Formula_042.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat the specified number of iterations and do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the pseudo-residuals, as follows:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_043.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *n* is the number of training samples, *m* is the iteration number, and
    *L* is the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: Train the elementary algorithm (regression model) ![](img/B22503_Formula_044.png)
    on pseudo-residuals with data of the form ![](img/B22503_Formula_045.png).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the ![](img/B22503_Formula_046.png) coefficient by solving a one-dimensional
    optimization problem as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_047.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Update the model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_048.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The inputs to this algorithm are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The ![](img/B22503_Formula_049.png) dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of *M* iterations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *L( y, f )* loss function with an analytically written gradient (such a
    form of gradient allows us to reduce the number of numerical calculations)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of the family of functions of the *h (x)* elementary algorithms,
    with the procedure of their training and hyperparameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The constant for the initial approximation, as well as the ![](img/B22503_Formula_050.png)-optimal
    coefficient, can be found by a binary search, or by another line search algorithm
    relative to the initial loss function (rather than the gradient).
  prefs: []
  type: TYPE_NORMAL
- en: 'Examples of loss functions for regression are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_051.png): An *L*2 loss, also called **Gaussian loss**.
    This formula is the classic conditional mean and the most common and simple option.
    If there are no additional information or model sustainability requirements, it
    should be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_052.png): An *L*1 loss, also called **Laplacian loss**.
    This formula, at first glance, is not very differentiable and determines the conditional
    median. The median, as we know, is more resistant to outliers. Therefore, in some
    problems, this loss function is preferable since it does not penalize large deviations
    as much as a quadratic function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_053.png) : An *L*q loss, also called **Quantile loss**.
    If we don’t want a conditional median but do want a conditional 75% quantile,
    we would use this option with ![](img/B22503_Formula_054.png). This function is
    asymmetric and penalizes more observations that turn out to be on the side of
    the quantile we need.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Examples of loss functions for classification are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_055.png): Logistic loss, also known as **Bernoulli loss**.
    An interesting property of this loss function is that we penalize even correctly
    predicted class labels. By optimizing this loss function, we can continue to distance
    classes and improve the classifier even if all observations are correctly predicted.
    This function is the most standard and frequently used loss function in a binary
    classification task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_056.png): **AdaBoost loss**. It so happens that the
    classic AdaBoost algorithm that uses this loss function (different loss functions
    can also be used in the AdaBoost algorithm) is equivalent to gradient boosting.
    Conceptually, this loss function is very similar to logistic loss, but it has
    a stronger exponential penalty for classification errors and is used less frequently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea of bagging is that it can be used with a gradient boosting approach
    too, which is known as **stochastic gradient boosting**. In this way, a new algorithm
    is trained on a sub-sample of the training set. This approach can help us to improve
    the quality of the ensemble and reduce the time it takes to build elementary algorithms
    (whereby each is trained on a reduced number of training samples).
  prefs: []
  type: TYPE_NORMAL
- en: Although boosting itself is an ensemble, other ensemble schemes can be applied
    to it—for example, by averaging several boosting methods. Even if we average boosts
    with the same parameters, they will differ due to the stochastic nature of the
    implementation. This randomness comes from the choice of random sub-datasets at
    each step or selecting different features when we are building decision trees
    (if they are chosen as elementary algorithms).
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, the base **gradient boosting machine** (**GBM**) has many extensions
    for different statistical tasks. These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: GLMBoost and GAMBoost as an enhancement of the existing **generalized additive**
    **model** (**GAM**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoxBoost for survival curves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RankBoost and LambdaMART for ranking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, there are many implementations of the same GBM under different
    names and different platforms, such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stochastic GBM**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradient boosted decision** **trees** (**GBDT**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradient boosted regression** **trees** (**GBRT**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multiple additive regression** **trees** (**MART**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized boosting** **machine** (**GBM**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, boosting can be applied and used over a long period of time in
    the ranking tasks undertaken by search engines. The task is written based on a
    loss function, which is penalized for errors in the order of search results; therefore,
    it becomes convenient to insert it into a GBM.
  prefs: []
  type: TYPE_NORMAL
- en: Using a stacking approach for creating ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of stacking is to use different algorithms trained on the same data
    as elementary models. A meta-classifier is then trained on the results of the
    elementary algorithms or source data, also supplemented by the results of the
    elementary algorithms themselves. Sometimes, a meta-classifier uses the estimates
    of distribution parameters that it receives (for example, estimates of the probabilities
    of each class for classification) for its training, rather than the results of
    elementary algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The most straightforward stacking scheme is blending. For this scheme, we divide
    the training set into two parts. The first part is used to teach a set of elementary
    algorithms. Their results can be considered new features (meta-features). We then
    use them as complementary features with the second part of the dataset and train
    the new meta-algorithm. The problem with such a blending scheme is that neither
    the elementary algorithms nor the meta-algorithm use the entire set of data for
    training. To improve the quality of blending, you can average the results of several
    blends trained at different partitions in the data.
  prefs: []
  type: TYPE_NORMAL
- en: A second way to implement stacking is to use the entire training set. In some
    sources, this is known as *generalization*. The entire set is divided into parts
    (folds), then the algorithm sequentially goes through the folds and teaches elementary
    algorithms on all the folds except the one randomly chosen fold. The remaining
    fold is used for the inference of the elementary algorithms. The output values
    of elementary algorithms are interpreted as the new meta-attributes (or new features)
    calculated from the folds. In this approach, it is also desirable to implement
    several different partitions into folds, and then average the corresponding meta-attributes.
    For a meta-algorithm, it makes sense to apply regularization or add some normal
    noise to the meta-attributes. The coefficient with which this addition occurs
    is analogous to the regularization coefficient. We can summarize that the basic
    idea behind the described approach is to use a set of base algorithms; then, using
    another meta-algorithm, we combine their predictions with the aim of reducing
    the generalization error.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike boosting and traditional bagging, you can use algorithms of a different
    nature (for example, a ridge regression in combination with a random forest) in
    stacking. However, it is essential to remember that for different algorithms,
    different feature spaces are needed. For example, if categorical features are
    used as target variables, then the random forest algorithm can be used as-is,
    but for the regression algorithms, you must first run one-hot encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Since meta-features are the results of already trained algorithms, they strongly
    correlate. This fact is *a priori* one of the disadvantages of this approach;
    the elementary algorithms are often under-optimized during training to combat
    correlation. Sometimes, to combat this drawback, the training of elementary algorithms
    is used not on the target feature, but on the differences between a feature and
    the target.
  prefs: []
  type: TYPE_NORMAL
- en: Using the random forest method for creating ensembles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we move to the random forest method, we need to familiarize ourselves
    with the decision tree algorithm, which is the basis for the random forest ensemble
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree algorithm overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A decision tree is a supervised machine learning algorithm based on how a human
    solves the task of forecasting or classification. Generally, this is a *k*-dimensional
    tree with decision rules in the nodes and a prediction of the objective function
    at the leaf nodes. The decision rule is a function that allows you to determine
    which of the child nodes should be used as a parent for the considered object.
    There can be different types of objects in the decision tree leaf—namely, the
    class label assigned to the object (in the classification tasks), the probability
    of the class (in the classification tasks), and the value of the objective function
    (in the regression task).
  prefs: []
  type: TYPE_NORMAL
- en: In practice, binary decision trees are used more often than trees with an arbitrary
    number of child nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm for constructing a decision tree in its general form is formed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, check the criterion for stopping the algorithm. If this criterion is
    executed, select the prediction issued for the node. Otherwise, we have to split
    the training set into several non-intersecting smaller sets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the general case, a ![](img/B22503_Formula_057.png) decision rule is defined
    at the *t* node, which takes into account a certain range of values. This range
    is divided into *R*t disjoint sets of objects: ![](img/B22503_Formula_058.png),
    where *R*t is the number of descendants of the node, and each ![](img/B22503_Formula_059.png)is
    a set of objects that fall into the ![](img/B22503_Formula_060.png)descendant.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide the set in the node according to the selected rule, and repeat the algorithm
    recursively for each node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Most often, the ![](img/B22503_Formula_061.png) decision rule is simply the
    feature—that is, ![](img/B22503_Formula_062.png). For partitioning, we can use
    the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_063.png) for chosen boundary values ![](img/B22503_Formula_064.png).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_065.png), where ![](img/B22503_Formula_066.png)is a
    vector’s scalar product. In fact, it is a corner value check.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_067.png), where the distance ![](img/B22503_Formula_068.png)
    is defined in some metric space (for example, ![](img/B22503_Formula_069.png)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_070.png), where ![](img/B22503_Formula_071.png) is a
    predicate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, you can use any decision rules, but those that are easiest to interpret
    are better since they are easier to configure. There is no particular point in
    taking something more complicated than predicates since you can create a tree
    with 100% accuracy on the training set with the help of the predicates.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, a set of decision rules is chosen to build a tree. To find the optimal
    one among them for each particular node, we need to introduce a criterion for
    measuring optimality. The ![](img/B22503_Formula_072.png) measure is introduced
    for this and is used to measure how objects are scattered (regression) or how
    the classes are mixed (classification) in a specific ![](img/B22503_Formula_073.png)
    node. This measure is called the **impurity function**. It is required for finding
    a maximum of ![](img/B22503_Formula_074.png) according to all features and parameters
    from a set of decision rules, in order to select a decision rule. With this choice,
    we can generate the optimal partition for the set of objects in the current node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Information gain, ![](img/B22503_Formula_075.png), is how much information
    we can get for the selected split, and is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_076.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding equation, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '*R* is the number of sub-nodes the current node is broken into'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*t* is the current node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_077.png) are the descendant nodes that are obtained
    with the selected partition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_078.png) is the number of objects in the training sample
    that fall into the child *i*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_079.png) is the number of objects trapped in the current
    node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_080.png) are the objects trapped in the *t*ith vertex'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can use the MSE or the **mean absolute error** (**MAE**) as the ![](img/B22503_Formula_081.png)
    impurity function for regression tasks. For classification tasks, we can use the
    following functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Gini criterion ![](img/B22503_Formula_082.png) as the probability of misclassification,
    specifically if we predict classes with probabilities of their occurrence in a
    given node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entropy ![](img/B22503_Formula_083.png) as a measure of the uncertainty of a
    random variable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification error ![](img/B22503_Formula_084.png) as the error rate in the
    classification of the most potent class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the functions described previously, ![](img/B22503_Formula_085.png) is an
    *a priori* probability of encountering an object of class *i* in a node *t*—that
    is, the number of objects in the training sample with labels of class *i* falling
    into *t* divided by the total number of objects in *t* (![](img/B22503_Formula_086.png)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following rules can be applied as stopping criteria for building a decision
    tree:'
  prefs: []
  type: TYPE_NORMAL
- en: Limiting the maximum depth of the tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limiting the minimum number of objects in the sheet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limiting the maximum number of leaves in a tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stopping if all objects in the node belong to the same class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requiring that information gain is improved by at least 8% during splitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is an error-free tree for any training set, which leads to the problem
    of overfitting. Finding the right stopping criterion to solve this problem is
    challenging. One solution is **pruning**—after the whole tree is constructed,
    we can cut some nodes. Such an operation can be performed using a test or validation
    set. Pruning can reduce the complexity of the final classifier and improve predictive
    accuracy by reducing overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pruning algorithm is formed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We build a tree for the training set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we pass a validation set through the constructed tree and consider any
    internal node *t* and its left and right sub-nodes ![](img/B22503_Formula_087.png),
    ![](img/B22503_Formula_088.png).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no one object from the validation sample has reached *t*, then we can say
    that this node (and all its subtrees) is insignificant, and make *t* the leaf
    (set the predicate’s value for this node equal to the set of the majority class
    using the training set).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If objects from the validation set have reached *t*, then we have to consider
    the following three values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The number of classification errors from a subtree of *t*
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of classification errors from the ![](img/B22503_Formula_089.png)
    subtree
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of classification errors from the ![](img/B22503_Formula_090.png)
    subtree
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the value for the first case is zero, then we make node *t* as a leaf node
    with the corresponding prediction for the class. Otherwise, we choose the minimum
    of these values. Depending on which of them is minimal, we do the following, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: If the first is minimal, do nothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the second is minimal, replace the tree from node *t* with a subtree from
    node ![](img/B22503_Formula_091.png)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the third is minimal, replace the tree from node *t* with a subtree from
    node ![](img/B22503_Formula_092.png)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such a procedure regularizes the algorithm to beat overfitting and increase
    the ability to generalize. In the case of a *k*-dimensional tree, different approaches
    can be used to select the forecast in the leaf. We can take the most common class
    among the objects of the training that fall under this leaf for classification.
    Alternatively, we can calculate the average of the objective functions of these
    objects for regression.
  prefs: []
  type: TYPE_NORMAL
- en: We apply a decision rule to a new object starting from the tree root to predict
    or classify new data. Thus, it is determined which subtree the object should go
    into. We recursively repeat this process until we reach some leaf node and, finally,
    we return the value of the leaf node we found as the result of classification
    or regression.
  prefs: []
  type: TYPE_NORMAL
- en: Random forest method overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Decision trees are a suitable family of elementary algorithms for bagging since
    they are quite complicated and can ultimately achieve zero errors on any training
    set. We can use a method that uses random subspaces (such as bagging) to reduce
    the correlation between trees and avoid overfitting. The elementary algorithms
    are trained on different subsets of the feature space, which are also randomly
    selected. An ensemble of decision tree models using the random subspace method
    can be constructed using the following algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Where the number of objects for training is *N* and the number of features
    is ![](img/B22503_Formula_093.png), proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Select ![](img/B22503_Formula_094.png) as the number of individual trees in
    the ensemble.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each individual ![](img/B22503_Formula_095.png) tree, select ![](img/B22503_Formula_096.png)
    as the number of features for ![](img/B22503_Formula_097.png). Typically, only
    one value is used for all trees.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each tree, create an ![](img/B22503_Formula_098.png) training subset using
    the bootstrap method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, build decision trees from ![](img/B22503_Formula_098.png) samples as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Select ![](img/B22503_Formula_100.png) random features from the source, then
    the optimal division of the training set will limit its search to them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: According to a given criterion, we choose the best attribute and make a split
    in the tree according to it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The tree is built until no more than ![](img/B22503_Formula_101.png) objects
    remain in each leaf, until we reach a certain height of the tree, or until the
    training set is exhausted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, to apply the ensemble model to a new object, it is necessary to combine
    the results of individual models by majority voting or by combining *a posteriori*
    probabilities. An example of a final classifier is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22503_Formula_102.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the following fundamental parameters of the algorithm and their properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The number of trees**: The more trees, the better the quality, but the training
    time and the algorithm’s workload also increase proportionally. Often, with an
    increasing number of trees, the quality of the training set rises (it can even
    go up to 100% accuracy), but the quality of the test set is asymptotic (so you
    can estimate the minimum required number of trees).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The number of features for the splitting selection**: With an increasing
    number of features, the forest’s construction time increases too, and the trees
    become more uniform than before. Often, in classification problems, the number
    of attributes is chosen equal to ![](img/B22503_Formula_103.png) and ![](img/B22503_Formula_104.png)
    for regression problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maximum tree depth**: The smaller the depth, the faster the algorithm is
    built and will work. As the depth increases, the quality during training increases
    dramatically. The quality may also increase on the test set. It is recommended
    to use the maximum depth (except when there are too many training objects and
    we obtain very deep trees, the construction of which takes considerable time).
    When using shallow trees, changing the parameters associated with limiting the
    number of objects in the leaf and for splitting does not lead to a significant
    effect (the leaves are already large). Using shallow trees is recommended in tasks
    with a large number of noisy objects (outliers).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The impurity function**: This is a criterion for choosing a feature (decision
    rule) for branching. It is usually MSE/MAE for regression problems. For classification
    problems, it is the Gini criterion, the entropy, or the classification error.
    The balance and depth of trees may vary depending on the specific impurity function
    we choose.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can consider a random forest as bagging decision trees, and during these
    trees’ training, we use features from a random subset of features for each partition.
    This approach is a universal algorithm since random forests exist for solving
    problems of classification, regression, clustering, anomaly search, and feature
    selection, among other tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will see how to use different C++ libraries for
    developing machine learning model ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of using C++ libraries for creating ensembles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following sections will show how to use ensembles within the `Dlib` and
    `mlpack` libraries. There are out-of-the-box implementations of random forest
    and gradient boosting algorithms in these libraries; we will show how to use their
    `mlpack` library.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembles with Dlib
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is only the random forest algorithm implementation in the `Dlib` library,
    and in this section, we will show the specific API for using it in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show the random forest algorithm application, we need to have some dataset
    for this task. Let’s create an artificial dataset that models the cosine function.
    First, we define datatypes to represent samples and label items. The following
    code sample shows how it is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we define the `GenerateData` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `GenerateData` function takes three parameters: the `start` and `end` values
    of the generation range and the `n` numbers of points to generate. The implementation
    simply calculates cosine values in the loop. The function returns a pair of `std::vector`
    type objects containing the `double` values. The result of this function will
    be used for testing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To show that the random forest algorithm really can approximate values, we
    will add some noise to the original data. The following code snippet shows the
    `GenerateNoiseData` function implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `GenerateNoiseData` function also calculates cosine values in the simple
    loop. It takes the same input parameters as the `GenerateData` function. However,
    instead of the sequential value generation, this function samples a random value
    from the specified range on each iteration. For each sample, it calculates the
    cosine value and also adds the noise samples. The noise is generated by random
    distribution. The function also returns two `std::vector` type objects containing
    the `double` values, the first one for training inputs and the second one for
    target values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using these data generation functions, we can create the training and the test
    datasets as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the usage of the Dlib random forest implementation is very simple. The
    following code snippet shows it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the instance of the `random_forest_regression_trainer` class named
    `trainer` to create the `random_forest` object with the `train` method. The `trainer`
    object was configured with the number of trees to use. The `random_forest_regression_trainer`
    class was parametrized with the `dense_feature_extractor` class—this is the only
    feature extractor class provided now by the `Dlib` library, but you can create
    a custom one. The `train` method simply takes two `std::vector` type objects,
    the first one for the input data values and the second one for the target data
    values.
  prefs: []
  type: TYPE_NORMAL
- en: After the training, the `random_forest` object was created, and it was used
    as a functional object to make a prediction for a single value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the result of applying the random forest algorithm
    from the `Dlib` library. The original data is shown as stars and the predicted
    data is shown as lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Regression with random forest and Dlib](img/B19849_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Regression with random forest and Dlib
  prefs: []
  type: TYPE_NORMAL
- en: Note that this method is not very applicable to the regression task on this
    dataset. You can see that global trends were learned successfully but there are
    a lot of errors in small details.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembles with mlpack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two ensemble learning algorithms in the `mlpack` library: the random
    forest and AdaBoost algorithms. For this set of samples, we will use the *Breast
    Cancer Wisconsin (Diagnostic)* dataset located at [https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic).
    It is taken from *D*. *Dua, and C. Graff (2019), UCI Machine Learning* *Repository*
    ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are 569 instances in this dataset, and each instance has 32 attributes:
    the ID, the diagnosis, and 30 real-value input features. The diagnosis can have
    two values: *M =* malignant, and *B =* benign. Other attributes have 10 real-value
    features computed for each cell nucleus, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Radius (mean distance from the center to the perimeter)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Texture (standard deviation of grayscale values)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perimeter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Area
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smoothness (local variation in radius lengths)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compactness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concavity (severity of concave portions of the contour)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concave points (number of concave portions of the contour)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Symmetry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fractal dimension (*coastline approximation*—1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This dataset can be used for a binary classification task.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation for mlpack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is the `DatasetInfo` class in `mlpack` to describe a dataset. An instance
    of this class can be used with different algorithms. Also, there is the `data::Load`
    function in `mlpack` that can automatically load datasets from the `.csv`, `.tsv`,
    and `.txt` files. However, this function assumes that there is only numerical
    data in such files that can be interpreted as a matrix. In our case, the data
    is in the `.csv` format but the `Diagnosis` column contains the string values
    `M` and `B`. So, we simply convert them into `0` and `1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we have the correct `.csv` file, the data can be loaded in the following
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We passed into the `Load` function the dataset filename and references to the
    `data` matrix object and the `info` object. Also, notice that we asked the function
    to generate an exception in the fail case by passing the last parameter as `true`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we split the data into the input and target parts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the `row` method of the matrix object to get the particular row.
    Then we converted its values into the `site_t` type with the `arma::conv_to` function
    because the first row in our dataset consists of labels. Finally, we removed the
    first row from the `data` object to make it usable as input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having input data and labels matrices, we can split them into the training
    and testing parts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We used the `head_cols` method of the matrix object to take the first `train_num`
    columns from the input data and label them as the train values, and we used the
    `tail_cols` method of the matrix object to take the last columns as the test values.
  prefs: []
  type: TYPE_NORMAL
- en: Using random forest with mlpack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The random forest algorithm in the `mlpack` library is located in the `RandomForest`
    class. This class has two main methods: `Train` and `Classify`. The `Train` method
    can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first four parameters are self-descriptive. The last ones are more algorithm-specific.
    The `minimumLeafSize` parameter is the minimum number of points in each tree’s
    leaf nodes. The `minimumGainSplit` parameter is the minimum gain for splitting
    a decision tree node. The `maximumDepth` parameter is the maximum allowed tree
    depth.
  prefs: []
  type: TYPE_NORMAL
- en: After the use of the `Train` method with the training data, the `rf` object
    can be used for the classification with the `Classify` method. This method takes
    as its first parameter the single value or the row matrix as input, and the second
    parameter is the reference to the single prediction value or the vector of predictions
    that will be filled by this method.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is the `Accuracy` class in `mlpack` that can be used to estimate an algorithm’s
    accuracy. It can work with different algorithm objects and have a unified interface.
    We can use it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We used the `Evaluate` method to get the accuracy value for the random forest
    algorithm trained with our data. The printed value is `Random Forest accuracy
    =` `0.971014`.
  prefs: []
  type: TYPE_NORMAL
- en: Using AdaBoost with mlpack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another ensemble-based algorithm in the `mlpack` library is AdaBoost. It is
    based on an ensemble of weak learners that is used to produce a strong learner.
    Let’s define an AdaBoost algorithm object based on simple perceptrons as weak
    learners, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We parametrized the `AdaBoost` class with the `Perceptron` class as the template
    parameter. After the `AdaBoost` object is instantiated, we can use the `Train`
    method to train it with our dataset. The following code snippet shows how to use
    the `Train` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The first three input parameters are pretty obvious—the input data, labels,
    and number of classes for classification. Then we passed the `p` object; it’s
    the instance of the `Perceptron` class, our weak learner. After the weak learner
    object, we passed into the `Train` method the number of iterations to learn and
    the accuracy tolerance to stop learning early.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the strong learner `ab` is trained, we can use the `Classify` method
    to get classification for a new data value. Also, we can use an object of the
    `Accuracy` class to estimate the accuracy of the trained algorithm. We already
    saw how to use `Accuracy` in the previous chapter. Its API is the same for all
    algorithms in `mlpack`. For `AdaBoost`, we can use it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `AdaBoost` algorithm with the same dataset, we got the following output:
    `AdaBoost accuracy = 0.985507`. The accuracy is slightly better than we got with
    the random forest algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Using a stacking ensemble with mlpack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To show the implementation of more ensemble learning techniques, we can develop
    the stacking approach manually. This is not hard with the `mlpack` library, or
    indeed any other library.
  prefs: []
  type: TYPE_NORMAL
- en: 'The stacking approach is based on learning a set of weak learners. Usually,
    the k-fold technique is used to implement this. It means that we learn a weak
    model on `k-1` folds and use the last fold for predictions. Let’s see how we can
    create k-fold-splitting using `mlpack`. We will use the same dataset as we did
    for the previous subsections. The main idea is to repeat the dataset to be able
    to get different folds just by using indices. The following code snippet defines
    the `KfoldDataSet` structure with just one method and constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The constructor takes the input data, labels, and number of folds for splitting.
    The `get_fold` method takes an index of a fold and returns four values:'
  prefs: []
  type: TYPE_NORMAL
- en: The matrix contains `k-1` folds of the input data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The row matrix contains `k-1` folds of labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The matrix contains the last fold of the input data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The row matrix contains the last fold of labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Constructor implementation can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, we calculated the `fold_size` values by dividing the total number of samples
    in the input data by the number of folds. The total number of samples can be unaligned
    with the number of folds, so the last fold size can be different. That is why
    we additionally calculated the `last_fold_size` value to be able to make a correct
    splitting later. Having the fold size values, we used the `arma::join_rows` function
    to repeat training samples. This function joins two matrices; for the first parameter,
    we used the original sample matrices, and for the second, we used reduced ones.
    We took just the `k-1` columns for the second parameter using the `cols` method
    of the matrix object.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we have the repeated data samples, the `get_fold` method implementation
    can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The most important part of the `get_fold` method is to get the correct number
    of samples that belong to the `k-1` subset and the last fold subset. So, at first,
    we checked whether the required fold to be split is last or not because the last
    fold may contain a different size of samples. Having this information, we just
    multiplied the `k-1` or `k-2` numbers by the fold size, and conditionally added
    the last fold size to have the sample subsets. For the last fold, we also conditionally
    got the fold size depending on the required fold-splitting index.
  prefs: []
  type: TYPE_NORMAL
- en: Having the correct subset sizes, we used the `colptr` method to get the pointer
    to the starting column sample from the repeated data. We used such a pointer and
    the subset size to initialize the `arma::mat` object pointing to the existing
    data without copying by setting the `copy_aux_mem` constructor parameter to `false`.
    Using such an approach, we initialized matrices for the `k-1` fold samples and
    the last fold samples and returned them as a tuple.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the `KfoldDataSet` class, we can move further and implement the `StackingClassification`
    function. Its declaration can be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It will take the number of classification classes, the train input and label
    data, and the test input and label data to estimate the accuracy of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `StackingClassification` function implementation can be split into the
    following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create meta-datasets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train meta-model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train weak models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the test data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s take a look at each of them, one by one. The dataset preparation can
    be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We used the `ShuffleData` function to randomize the training and the testing
    data, and we used the `sample_scaler` object of the `StandardScaler` class to
    scale our train and test data to the zero mean and unit variance. Notice that
    we fitted a scaler object on the train data and then used it with the `Transform`
    method. We will use this scaler object later for the test data too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the prepared dataset, we can create a meta-dataset using weak (or elementary)
    algorithms that will be used for the stacking. It will be three weak algorithms’
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: Softmax regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear SVM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The meta-dataset generation is based on the training and the evaluation of
    the weak models on the k-fold splits prepared from the original dataset. We already
    created the `KFoldDataset` class for this purpose and its usage will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we instantiated the `meta_train` dataset object for the 30-fold split.
    The following code snippet shows how the meta dataset can be generated using three
    weak models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The meta-dataset was stored in the `meta_train_inputs` and `meta_train_labels`
    matrix objects. Using the loop, we iterated the 30-fold indices and for each index,
    we called the `get_fold` method of the `meta_train` object. This call gave us
    the *k*th fold split, which contained the four matrices for the training and the
    evaluation. Then we trained the local weak objects, which, in our case, were instances
    of the `LinearSVM`, `SoftmaxRegression`, and `DecisionTree` class objects.
  prefs: []
  type: TYPE_NORMAL
- en: For their training, we used the fold’s training inputs and labels. Having -
    trained weak models(the `LinearSVM`, `SoftmaxRegression`, and `DecisionTree models`),
    we evaluated them using the `Classify` method on the fold’s test input located
    in the `fold_valid_input` object. The classification result was placed in the
    `predictions` object. All three classification results were stacked into the new
    `meta_feature` matrix object using the `join_cols` function. So, we replaced the
    original dataset features with new meta-features. This `meta_feature` object was
    added to the `meta_train_inputs` object using the `join_rows` method. The fold’s
    test labels located in `fold_valid_labels` were added to the meta-dataset using
    the `join_rows` function on the `meta_train_labels` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the meta-dataset was created, we used the `DecisionTree` instance to
    train the meta-model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To be able to use this meta-model, we have to create a weak model again. It
    will be used to generate meta-input features for this meta-model. It can be done
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the whole training dataset for training each of the weak models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having trained the ensemble, we can evaluate it on the test dataset. Since
    we used data preprocessing, we should also transform our test data in the same
    way as we transformed our training data. We scale the testing data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The ensemble evaluation starts by predicting meta-features, using the weak
    models we trained before. We will store predictions from every weak model in the
    following objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Here, we stacked predictions from each of the weak models into the `meta_eval_inputs`
    object as we did for the meta-dataset creation.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we have created the meta-features, we can pass them as input to the `Classify`
    method of the `meta_model` object to generate the real predictions. We can also
    calculate the accuracy, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The output of this code is `Stacking ensemble accuracy = 0.985507`. You can
    see that this ensemble performs better than the random forest implementation,
    even with default settings. In the case of some additional tuning, it could give
    even better results.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we examined various methods for constructing ensembles of machine
    learning algorithms. The main purposes of creating ensembles are to reduce the
    error of the elementary algorithms, expand the set of possible hypotheses, and
    increase the probability of reaching the global optimum during optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'We saw that there are three main approaches to building ensembles: training
    elementary algorithms on various datasets and averaging the errors (bagging),
    consistently improving the results of the previous, weaker algorithms (boosting),
    and learning the meta-algorithm from the results of elementary algorithms (stacking).
    Note that the methods of building ensembles that we’ve covered, except stacking,
    require that the elementary algorithms belong to the same class, and this is one
    of the main requirements for ensembles. It is also believed that boosting gives
    more accurate results than bagging but, at the same time, is more prone to overfitting.
    The main disadvantage of stacking is that it begins to significantly improve the
    results of elementary algorithms only with a relatively large number of training
    samples.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the fundamentals of **artificial neural
    networks** (**ANNs**). We’ll look at the historical aspect of their creation,
    go through the basic mathematical concepts used in ANNs, implement a **multilayer
    perceptron** (**MLP**) network and a simple **convolutional neural network** (**CNN**),
    and discuss what deep learning is and why it is so trendy.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Ensemble methods: Bagging &* *Boosting*: [https://medium.com/@sainikhilesh/difference-between-bagging-and-boosting-f996253acd22](mailto:https://medium.com/@sainikhilesh/difference-between-bagging-and-boosting-f996253acd22)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*How to explain gradient* *boosting*: [https://explained.ai/gradient-boosting/](https://explained.ai/gradient-boosting/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Original article by Jerome Friedman called *Greedy Function Approximation:
    A Gradient Boosting* *Machine*: [https://jerryfriedman.su.domains/ftp/trebst.pdf](https://jerryfriedman.su.domains/ftp/trebst.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ensemble Learning to Improve Machine Learning Results: [https://www.kdnuggets.com/2017/09/ensemble-learning-improve-machine-learning-results.html](https://www.kdnuggets.com/2017/09/ensemble-learning-improve-machine-learning-results.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Introduction to decision trees: [https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/](https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How to visualize decision trees: [https://explained.ai/decision-tree-viz/](https://explained.ai/decision-tree-viz/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Understanding Random* *Forest*: [https://towardsdatascience.com/understanding-random-forest-58381e0602d2](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Advanced Examples'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, we’ll describe what neural networks are and how they can be applied
    to solving image classification tasks. We’ll also describe what modern **large
    language models** (**LLMs**) are and how they assist in solving neural processing
    tasks such as sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19849_10.xhtml#_idTextAnchor539), *Neural Networks for Image
    Classification*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B19849_11.xhtml#_idTextAnchor642), *Sentiment Analysis with
    BERT and Transfer Learning*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
