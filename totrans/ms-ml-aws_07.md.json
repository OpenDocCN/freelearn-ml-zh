["```py\ndf = spark.read.csv(SRC_PATH + 'data.csv', \n                    header=True, \n                    inferSchema=True)\n```", "```py\ndf = df.selectExpr(\"*\",\n                   \"Quantity * UnitPrice as TotalBought\")\n```", "```py\ncustomer_df = df.select(\"CustomerID\",\"TotalBought\")\n   .groupBy(\"CustomerID\")\n   .sum(\"TotalBought\")\n   .withColumnRenamed('sum(TotalBought)','SumTotalBought')\n```", "```py\nfrom pyspark.sql.functions import *\njoined_df = df.join(customer_df, 'CustomerId')\n```", "```py\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import QuantileDiscretizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\n\nstages = [ \n   StringIndexer(inputCol='StockCode', \n                 outputCol=\"stock_code_index\", \n                 handleInvalid='keep'),\n   OneHotEncoder(inputCol='stock_code_index', \n                 outputCol='stock_code_encoded'),\n   StringIndexer(inputCol='Country', \n                 outputCol='country_index', \n                 handleInvalid='keep'),\n   OneHotEncoder(inputCol='country_index', \n                 outputCol='country_encoded'),\n   QuantileDiscretizer(numBuckets=3,\n                       inputCol='SumTotalBought',\n                       outputCol='total_bought_index'),\n   VectorAssembler(inputCols=['stock_code_encoded', \n                              'country_encoded', \n                              'total_bought_index'],\n                   outputCol='features_raw'),\n   Normalizer(inputCol=\"features_raw\",         \n              outputCol=\"features\", p=1.0),\n   KMeans(featuresCol='features').setK(3).setSeed(42) ]\n\npipeline = Pipeline(stages=stages)\nmodel = pipeline.fit(joined_df)\n```", "```py\ndf_with_clusters = model.transform(joined_df).cache()\n```", "```py\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(df_with_clusters)\n```", "```py\ndf_with_clusters\n.groupBy(\"prediction\")\n.count()\n.toPandas()\n.plot(kind='pie',x='prediction', y='count')\n```", "```py\ndf_with_clusters \\\n.where(df_with_clusters.prediction==0) \\\n.groupBy(\"Country\") \\\n.count() \\\n.orderBy(\"count\", ascending=False) \\\n.show()\n\n+--------------+------+\n| Country      | count|\n+--------------+------+\n|United Kingdom|234097|\n+--------------+------+\n```", "```py\ndf_with_clusters \\\n.where(df_with_clusters.prediction==1) \\\n.groupBy(\"Country\") \\\n.count() \\\n.orderBy(\"count\", ascending=False) \\\n.show()\n\n+--------------+------+\n| Country .    | count|\n+--------------+------+\n|United Kingdom|127781|\n+--------------+------+\n```", "```py\ndf_with_clusters \\\n.where(df_with_clusters.prediction==2) \\\n.groupBy(\"Country\") \\\n.count() \\\n.orderBy(\"count\", ascending=False) \\\n.show()\n\n+---------------+-----+\n| Country       |count|\n+---------------+-----+\n| Germany       | 9495|\n| France        | 8491|\n.\n.\n| USA           | 291 |\n+---------------+-----+\n```", "```py\npandas_df = df_with_clusters \\\n   .limit(5000) \\\n   .select('CustomerID','InvoiceNo','StockCode',\n           'Description','Quantity','InvoiceDate',\n           'UnitPrice','Country','TotalBought',\n            'SumTotalBought','prediction') \\\n   .toPandas()\n\npandas_df.groupby('prediction') \\\n.describe()['SumTotalBought']['mean'] \\\n.plot(kind='bar', \n      title = 'Mean total amount bought per cluster')\n```", "```py\nimport itertools\nimport re\nfrom functools import reduce\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef plot_word_cloud(description_column):\n   list_of_word_sets = description_column \\\n        .apply(str.split) \\\n        .tolist()\n   text = list(itertools.chain(*list_of_word_sets))\n   text = map(lambda x: re.sub(r'[^A-Z]', r'', x), text)\n   text = reduce(lambda x, y: x + ' ' + y, text)\n   wordcloud = WordCloud(\n       width=3000,\n       height=2000,\n       background_color='black',\n       stopwords=STOPWORDS,\n       collocations=False).generate(str(text))\n   fig = plt.figure(\n       figsize=(10, 5),\n       facecolor='k',\n       edgecolor='k')\n   plt.imshow(wordcloud, interpolation='bilinear')\n   plt.axis('off')\n   plt.tight_layout(pad=0)\n   plt.show()\n```", "```py\nplot_word_cloud(pandas_df[pandas_df.prediction==0].Description)\n```", "```py\nplot_word_cloud(pandas_df[pandas_df.prediction==1].Description)\n```", "```py\nplot_word_cloud(pandas_df[pandas_df.prediction==2].Description)\n```", "```py\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import Normalizer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml.feature import QuantileDiscretizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom sagemaker_pyspark import IAMRole\nfrom sagemaker_pyspark.algorithms import KMeansSageMakerEstimator\n```", "```py\nrole = 'arn:aws:iam::095585830284:role/EMR_EC2_DefaultRole'\n\nkmeans = KMeansSageMakerEstimator(\n  sagemakerRole=IAMRole(role),\n  trainingInstanceType=\"ml.m4.xlarge\",\n  trainingInstanceCount=1,\n  endpointInstanceType=\"ml.m4.xlarge\",\n  endpointInitialInstanceCount=1)\nkmeans.setK(3)\nkmeans.setFeatureDim(3722)\n\nstages = [\n   StringIndexer(inputCol='StockCode', outputCol=\"stock_code_index\", handleInvalid='keep'),\n   OneHotEncoder(inputCol='stock_code_index', outputCol='stock_code_encoded'),\n   StringIndexer(inputCol='Country', outputCol='country_index', handleInvalid='keep'),\n   OneHotEncoder(inputCol='country_index', outputCol='country_encoded'),\n   QuantileDiscretizer(numBuckets=3, inputCol='SumTotalBought',outputCol='total_bought_index'),\n   VectorAssembler(inputCols=['stock_code_encoded', 'country_encoded', 'total_bought_index'],\n                   outputCol='features_raw'),\n   Normalizer(inputCol=\"features_raw\", \n              outputCol=\"features\", p=1.0),\n              kmeans ]\n\npipeline = Pipeline(stages=stages)\nmodel = pipeline.fit(joined_df)\n```", "```py\ndf_with_clusters = model.transform(joined_df)\n```", "```py\ndf_with_clusters.show(5)\n```", "```py\nevaluator = ClusteringEvaluator()\nevaluator.setPredictionCol(\"closest_cluster\")\nsilhouette = evaluator.evaluate(df_with_clusters)\n```"]