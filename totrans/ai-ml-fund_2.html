<html><head></head><body>
<div id="_idContainer021" class="Content">
<p class="hidden" data-amznremoved-m8="true" data-amznremoved="mobi7">2</p>
</div>
<div id="_idContainer022" class="Content">
<h1 id="_idParaDest-36"><a id="_idTextAnchor040"></a>
 AI with Search Techniques and Games</h1>
</div>
<div id="_idContainer023" class="Content">
<h2>Learning Objectives</h2>
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li class="bullets">Build a simple game AI with Python based on static rules</li>
<li class="bullets">Determine the role of heuristics in Game AI</li>
<li class="bullets">Employ search techniques and pathfinding algorithms</li>
<li class="bullets">Implement game AI for two-player games with the Minmax algorithm</li>
</ul>
<p>In this chapter, we will be looking at creating intelligent agents.</p>
</div>
<div id="_idContainer038" class="Content">
<h2 id="_idParaDest-37"><a id="_idTextAnchor041"></a>
 Introduction</h2>
<p>In the previous chapter, we understood the significance of an intelligent agent. We also examined the game states for a game AI. In this chapter, we will focus on how to create and introduce intelligence into an agent.</p>
<p>We will look at reducing the number of states in the state space and analyze the stages that a game board can undergo and make the environment work in such a way that we win. By the end of this chapter, we will have a Tic-Tac-Toe player who never loses a match.</p>
<h3 id="_idParaDest-38"><a id="_idTextAnchor042"></a>
 Exercise 4: Teaching the Agent to Win</h3>
<p>In this exercise, we will see how the steps needed to win can be reduced. We will be making the agent that we developed in the previous chapter detect situations where it can win a game. Compare the number of possible states to the random play as an example.</p>
<ol>
<li value="1">We will be defining two functions, <strong class="inline _idGenCharOverride-1">ai_move</strong>
 and <strong class="inline _idGenCharOverride-1">all_moves_from_board</strong>
 . We will create <strong class="inline _idGenCharOverride-1">ai_move</strong>
 so that it returns a move that will consider its own previous moves. If the game can be won in that move, <strong class="inline _idGenCharOverride-1">ai_move</strong>
 will select that move.<p class="snippet _idGenParaOverride-1">def ai_move(board):</p>
<p class="snippet _idGenParaOverride-1">    new_boards = all_moves_from_board(board, AI_SIGN)</p>
<p class="snippet _idGenParaOverride-1">    for new_board in new_boards:</p>
<p class="snippet _idGenParaOverride-1">    if game_won_by(new_board) == AI_SIGN:</p>
<p class="snippet _idGenParaOverride-1">    return new_board</p>
<p class="snippet _idGenParaOverride-1">    return choice(new_boards)</p>
</li>
<li value="2">Let's test the application with a game loop. Whenever the AI has the opportunity to win the game, it will always place the X in the right cell:<p class="snippet _idGenParaOverride-1">game_loop()</p>
</li>
<li value="3">The output is as follows:<p class="snippet _idGenParaOverride-1">. X .</p>
<p class="snippet _idGenParaOverride-1">. . .</p>
<p class="snippet _idGenParaOverride-1">. . .</p>
<p class="snippet _idGenParaOverride-1">Enter row: 3</p>
<p class="snippet _idGenParaOverride-1">Enter column: 1</p>
<p class="snippet _idGenParaOverride-1">. X .</p>
<p class="snippet _idGenParaOverride-1">. . .</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1"> </p>
<p class="snippet _idGenParaOverride-1">. X X</p>
<p class="snippet _idGenParaOverride-1">. . .</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1"> </p>
<p class="snippet _idGenParaOverride-1">Enter row: 2</p>
<p class="snippet _idGenParaOverride-1">Enter column: 1</p>
<p class="snippet _idGenParaOverride-1"> </p>
<p class="snippet _idGenParaOverride-1">. X X</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1"> </p>
<p class="snippet _idGenParaOverride-1"> </p>
<p class="snippet _idGenParaOverride-1">X X X</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1">O . .</p>
<p class="snippet _idGenParaOverride-1">Game has been ended.</p>
</li>
<li value="4">To count all the possible moves, we have to change the <strong class="inline _idGenCharOverride-1">all_moves_from_board</strong>
 function to include this improvement. We must do this so that, if the game is won by <strong class="inline _idGenCharOverride-1">AI_SIGN</strong>
 , it will return that value:<p class="snippet _idGenParaOverride-1">def all_moves_from_board(board, sign):</p>
<p class="snippet _idGenParaOverride-1">    move_list = []</p>
<p class="snippet _idGenParaOverride-1">    for i, v in enumerate(board):</p>
<p class="snippet _idGenParaOverride-1">        if v == EMPTY_SIGN:</p>
<p class="snippet _idGenParaOverride-1">            new_board = board[:i] + sign + board[i+1:]</p>
<p class="snippet _idGenParaOverride-1">            move_list.append(new_board)</p>
<p class="snippet _idGenParaOverride-1">            if game_won_by(new_board) == AI_SIGN:</p>
<p class="snippet _idGenParaOverride-1">                return [new_board]</p>
<p class="snippet _idGenParaOverride-1">    return move_list</p>
</li>
<li value="5">We then generate all possible moves. As soon as we find a move that wins the game for the AI, we return it. We do not care whether the AI has multiple options to win the game in one move â€“ we just return the first possibility. If the AI cannot win, we return all possible moves.</li>
<li value="6">Let's see what this means in terms of counting all of the possibilities at each step:<p class="snippet _idGenParaOverride-2">count_possibilities()</p>
<div></div>
</li>
<li value="7">The output is as follows:<p class="snippet _idGenParaOverride-1">step 0. Moves: 1</p>
<p class="snippet _idGenParaOverride-1">step 1. Moves: 9</p>
<p class="snippet _idGenParaOverride-1">step 2. Moves: 72</p>
<p class="snippet _idGenParaOverride-1">step 3. Moves: 504</p>
<p class="snippet _idGenParaOverride-1">step 4. Moves: 3024</p>
<p class="snippet _idGenParaOverride-1">step 5. Moves: 8525</p>
<p class="snippet _idGenParaOverride-1">step 6. Moves: 28612</p>
<p class="snippet _idGenParaOverride-1">step 7. Moves: 42187</p>
<p class="snippet _idGenParaOverride-1">step 8. Moves: 55888</p>
<p class="snippet _idGenParaOverride-1">First player wins: 32395</p>
<p class="snippet _idGenParaOverride-1">Second player wins: 23445</p>
<p class="snippet _idGenParaOverride-1">Draw 35544</p>
<p class="snippet _idGenParaOverride-1">Total 91344</p>
</li>
</ol>
<h3 id="_idParaDest-39"><a id="_idTextAnchor043"></a>
 Activity 2: Teaching the Agent to Realize Situations When It Defends Against Losses</h3>
<p>In this section, we will discuss how to make the computer player play better so that we can reduce the state space and the number of losses. We will force the computer to defend against the player putting their third sign in a row, column, or diagonal line:</p>
<ol>
<li class="ParaOverride-1" value="1">Create a function called <strong class="inline _idGenCharOverride-1">player_can_win</strong>
 that takes all the moves from the board using the <strong class="inline _idGenCharOverride-1">all_moves_from_board</strong>
 function and iterates over it using a variable called <strong class="inline _idGenCharOverride-1">next_move</strong>
 . On each iteration, it checks whether the game can be won by the sign, and then it returns true or false.</li>
<li value="2">Extend the AI's move so that it prefers making safe moves. A move is safe if the opponent cannot win the game in the next step.</li>
<li value="3">Test the new application. You will find that the AI has made the correct move.</li>
<li class="_idGenParaOverride-3" value="4">Place this logic in the state space generator and check how well the computer player is doing by generating all possible games.<div></div>
</li>
</ol>
<p>We not only got rid of almost two thirds of the possible games again, but most of the time, the AI player either wins or settles for a draw. Despite our efforts to make the AI better, it can still lose in 962 ways. We will eliminate all of these losses in the next activity.</p>
<h4>Note</h4>
<p class="callout">The solution for this activity can be found on page 261.</p>
<h3 id="_idParaDest-40"><a id="_idTextAnchor044"></a>
 Activity 3: Fixing the First and Second Moves of the AI to Make it Invincible</h3>
<p>This section will discuss how an exhaustive search can be focused so that it can find moves that are more useful than others. We will be reducing the possible games by hardcoding the first and the second move:</p>
<ol>
<li class="ParaOverride-1" value="1">Count the number of empty fields on the board and make a hardcoded move in case there are 9 or 7 empty fields. You can experiment with different hardcoded moves.</li>
<li value="2">Occupying any corner, and then occupying the opposite corner, leads to no losses. If the opponent occupied the opposite corner, making a move in the middle results in no losses.</li>
<li value="3">After fixing the first two steps, we only need to deal with 8 possibilities instead of 504. We also guided the AI into a state, where the hardcoded rules were enough to never lose a game.<h4 class="_idGenParaOverride-4">Note</h4>
<p class="callout _idGenParaOverride-5">The solution for this activity can be found on page 263.</p>
<div></div>
</li>
</ol>
<p>Let's summarize the important techniques that we applied to reduce the state space:</p>
<ol>
<li class="ParaOverride-1" value="1">
<strong class="keyword _idGenCharOverride-2">Empirical simplification</strong>
 : We accepted that the optimal first move is a corner move. We simply hardcoded a move instead of considering alternatives to focus on other aspects of the game. In more complex games, empirical moves are often misleading. The most famous chess AI victories often contain a violation of the common knowledge of chess grandmasters.</li>
<li value="2">
<strong class="keyword _idGenCharOverride-2">Symmetry</strong>
 : After we started with a corner move, we noticed that positions 1, 3, 7, and 9 are equivalent from the perspective of winning the game. Even though we didn't take this idea further, notice that we could even rotate the table to reduce the state space even further, and consider all four corner moves as the exact same move.</li>
<li value="3">
<strong class="keyword _idGenCharOverride-2">Reduction of different permutations leading to the same state</strong>
 : Suppose we can make the moves A or B and suppose our opponent makes move X, where X is not equal to either move A or B. If we explore the sequence A, X, B, and we start exploring the sequence B, X, then we don't have to consider the sequence B, X, A. This is because the two sequences lead to the exact same game state, and we have already explored a state containing these three moves before.</li>
<li value="4">
<strong class="keyword _idGenCharOverride-2">Forced moves for the player</strong>
 : When a player collects two signs horizontally, vertically, or diagonally, and the third cell in the row is empty, we are forced to occupy that empty cell either to win the game, or to prevent the opponent from winning the game. Forced moves may imply other forced moves, which reduces the state space even further.</li>
<li value="5">
<strong class="keyword _idGenCharOverride-2">Forced moves for the opponent</strong>
 : When a move from the opponent is clearly optimal, it does not make sense to consider scenarios when the opponent does not make the optimal move. When the opponent can win the game by occupying a cell, it does not matter whether we go on a long exploration of the cases when the opponent misses the optimal move. We save a lot less by not exploring cases when the opponent fails to prevent us from winning the game. This is because after the opponent makes a mistake, we will simply win the game.</li>
<li class="_idGenParaOverride-3" value="6">
<strong class="keyword _idGenCharOverride-2">Random move</strong>
 : When we can't decide and don't have the capacity to search, we move randomly. Random moves are almost always inferior to a search-based educated guess, but at times, we have no other choice.<div></div>
</li>
</ol>
<h2 id="_idParaDest-41"><a id="_idTextAnchor045"></a>
 Heuristics</h2>
<p>In this topic, we will formalize informed search techniques by defining and applying heuristics to guide our search.</p>
<h3 id="_idParaDest-42"><a id="_idTextAnchor046"></a>
 Uninformed and Informed Search</h3>
<p>In the Tic-Tac-Toe example, we implemented a greedy algorithm that first focused on winning, and then focused on not losing. When it comes to winning the game immediately, the greedy algorithm is optimal, because there is never a better step than winning the game. When it comes to not losing, it matters how we avoid the loss. Our algorithm simply chose a random safe move without considering how many winning opportunities we have created.</p>
<p>Breadth First Search and Depth First Search are uninform, because they consider all possible states in the game. An informed search explores the space of available states intelligently.</p>
<h3 id="_idParaDest-43"><a id="_idTextAnchor047"></a>
 Creating Heuristics</h3>
<p>If we want to make better decisions, we apply heuristics to guide the search in the right direction by considering longer-term utility. This way, we can make a more informed decision in the present based on what could happen in the future. This can also help us solve problems faster. We can construct heuristics as follows:</p>
<ul>
<li>Educated guesses on the utility of making a move in the game</li>
<li>Educated guesses on the utility of a given game state from the perspective of a player</li>
<li>Educated guesses on the distance from our goal</li>
</ul>
<p>Heuristics are functions that evaluate a game state or a transition to a new game state based on their utility. Heuristics are the cornerstones of making a search problem informed.</p>
<p>In this book, we will use utility and cost as negated terms. Maximizing utility and minimizing the cost of a move are considered synonyms.</p>
<p class="_idGenParaOverride-3">A commonly used example for a heuristic evaluation function occurs in pathfinding problems. Suppose we are looking for a path in the tree of states that leads us to a goal state. Each step has an associated cost symbolizing travel distance. Our goal is to minimize the cost of reaching a goal state.</p>
<div></div>
<p>The following is an example heuristic for solving the pathfinding problem: take the coordinates of the current state and the goal. Regardless of the paths connecting these points, calculate the distance between these points. The distance of two points in a plane is the length of the straight line connecting the points. This heuristic is called the Euclidean distance.</p>
<p>Suppose we define a pathfinding problem in a maze, where we can only move up, down, left, or right. There are a few obstacles in the maze that block our moves. A heuristic we can use to evaluate how close we are from the goal state is called the Manhattan distance, which is defined as the sum of the horizontal and vertical distances between the corresponding coordinates of the current state and the end state.</p>
<h3 id="_idParaDest-44"><a id="_idTextAnchor048"></a>
 Admissible and Non-Admissible Heuristics</h3>
<p>The two heuristics we just defined on pathfinding problems are called admissible heuristics when used on their given problem domain. Admissible means that we may underestimate the cost of reaching the end state but that we never overestimate it. In the next topic, we will explore an algorithm that finds the shortest path between the current state and the goal state. The optimal nature of this algorithm depends on whether we can define an admissible heuristic function.</p>
<p>An example of a non-admissible heuristic is the Manhattan distance applied on a two-dimensional map. Imagine that there is a direct path between our current state and the goal state. The current state is at the coordinates (2, 5), and the goal state is at the coordinates (5, 1).</p>
<p>The Manhattan distance of the two nodes is as follows:</p>
<p class="snippet">abs(5-2) + abs(1-5) = 3 + 4 = 7</p>
<p>As we overestimated the cost of traveling from the current node to the goal, the Manhattan distance is not admissible when we can move diagonally.</p>
<h3 id="_idParaDest-45"><a id="_idTextAnchor049"></a>
 Heuristic Evaluation</h3>
<p>Create a heuristic evaluation of a Tic-Tac-Toe game state from the perspective of the starting player.</p>
<p class="_idGenParaOverride-3">We can define the utility of a game state or the utility of a move. Both work, because the utility of the game state can be defined as the utility of the move leading to it.</p>
<div></div>
<p>
<strong class="bold _idGenCharOverride-2">Heuristic 1: Simple Evaluation of the Endgame</strong>
</p>
<p>Let's define a simple heuristic by evaluating a board: we can define the utility of a game state or the utility of a move. Both work, because the utility of the game state can be defined as the utility of the move leading to it. The utility for the game can be:</p>
<ul>
<li>+1, if the state implies that the AI player will win the game</li>
<li>-1, if the state implies that the AI player will lose the game</li>
<li>0, if a draw has been reached or no clear winner can be identified from the current state</li>
</ul>
<p>This heuristic is simple, because anyone can look at a board and analyze whether a player is about to win.</p>
<p>The utility of this heuristic depends on whether we can play many moves in advance. Notice that we cannot even win the game within five steps. We saw in topic A that by the time we reach step 5, we have 13,680 possible combinations leading to it. In most of these 13,680 cases, our heuristic returns zero.</p>
<p>If our algorithm does not look deeper than these five steps, we are completely clueless on how to start the game. Therefore, we could invent a better heuristic.</p>
<p>
<strong class="bold _idGenCharOverride-2">Heuristic 2: Utility of a Move</strong>
</p>
<ul>
<li>Two AI signs in a row, column, or diagonal, and the third cell is empty: +1000 for the empty cell.</li>
<li>Opponent has two in a row, column, or diagonally, and the third cell is empty: +100 for the empty cell.</li>
<li>One AI signs in a row, column, or diagonal, and the other two cells are empty: +10 for the empty cells.</li>
<li>No AI or opponent signs in a row, column, or diagonal: +1 for the empty cells.</li>
<li class="_idGenParaOverride-3">Occupied cells get a value of minus infinity. In practice, due to the nature of the rules, -1 will also do.</li>
<li style="list-style: none; display: inline"><div></div>
</li>
</ul>
<p>Why do we use a multiplicator factor of 10 for the four rules? Because there are eight possible ways of making three in a row, column, and diagonal. So, even by knowing nothing about the game, we are certain that a lower-level rule may not accumulate to override a higher-level rule. In other words, we will never defend against the opponent's moves if we can win the game.</p>
<h4>Note</h4>
<p class="callout">As the job of our opponent is also to win, we can compute this heuristic from the opponent's point of view. Our task is to maximize this value too so that we can defend against the optimal plays of our opponent. This is the idea behind the Minmax algorithm as well. If we wanted to convert this heuristic to a heuristic describing the current board, we could compute the heuristic value for all open cells and take the maximum of the values for the AI character so that we can maximize our utility.</p>
<p>For each board, we will create a utility matrix. For example, consider the following board:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer024" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00006.jpg" alt="Figure 2.1 Tic-tac-toe game state" />
</div>
</div>
<h6>Figure 2.1: Tic-Tac-Toe game state</h6>
<p>From here, we can construct its utility matrix:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer025" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00007.jpg" alt="Figure 2.2 Tic-Tac-Toe game utility matrix" />
</div>
</div>
<h6 class="_idGenParaOverride-3">Figure 2.2: Tic-Tac-Toe game utility matrix</h6>
<div></div>
<p>On the second row, the left cell is not very useful if we were to select it. Note that if we had a more optimal utility function, we would reward blocking the opponent.</p>
<p>The two cells of the third column both get a 10-point boost for two in a row.</p>
<p>The top-right cell also gets 100 points for defending against the diagonal of the opponent.</p>
<p>From this matrix, it is evident that we should choose the top-right move.</p>
<p>We can use this heuristic both to guide us toward an optimal next move, or to give a more educated score on the current board by taking the maximum of these values. We have technically used parts of this heuristic in Topic A in the form of hardcoded rules. Note, though, that the real utility of heuristics is not the static evaluation of a board, but the guidance it provides on limiting the search space.</p>
<h3 id="_idParaDest-46"><a id="_idTextAnchor050"></a>
 Exercise 5: Tic-Tac-Toe Static Evaluation with a Heuristic Function</h3>
<p>Perform static evaluation on the Tic-Tac-Toe game using heuristic function.</p>
<ol>
<li class="ParaOverride-1" value="1">In this section, we will create a function that takes the Utility vector of possible moves, takes three indices inside the utility vector representing a triple, and returns a function. The returned function expects a points parameter and modifies the Utilities vector such that it adds points to each cell in the (i, j, k) triple, as long as the original value of that cell is non-negative. In other words, we increase the utility of empty cells only.<p class="snippet _idGenParaOverride-1">def init_utility_matrix(board):</p>
<p class="snippet _idGenParaOverride-1">    return [0 if cell == EMPTY_SIGN else -1 for cell in board]</p>
<p class="snippet _idGenParaOverride-1">def generate_add_score(utilities, i, j, k):</p>
<p class="snippet _idGenParaOverride-1">    def add_score(points):</p>
<p class="snippet _idGenParaOverride-1">        if utilities[i] &gt;= 0:</p>
<p class="snippet _idGenParaOverride-1">            utilities[i] += points</p>
<p class="snippet _idGenParaOverride-1">        if utilities[j] &gt;= 0:</p>
<p class="snippet _idGenParaOverride-1">            utilities[j] += points</p>
<p class="snippet _idGenParaOverride-1">        if utilities[k] &gt;= 0:</p>
<p class="snippet _idGenParaOverride-1">            utilities[k] += points</p>
<p class="snippet _idGenParaOverride-2">    return add_score</p>
<div></div>
</li>
<li value="2">We now have everything to create the utility matrix belonging to any board constellation:<p class="snippet _idGenParaOverride-1">def utility_matrix(board):</p>
<p class="snippet _idGenParaOverride-1">    utilities = init_utility_matrix(board)</p>
<p class="snippet _idGenParaOverride-1">    for [i, j, k] in combo_indices:</p>
<p class="snippet _idGenParaOverride-1">        add_score = generate_add_score(utilities, i, j, k)</p>
<p class="snippet _idGenParaOverride-1">        triple = [board[i], board[j], board[k]]</p>
<p class="snippet _idGenParaOverride-1">        if triple.count(EMPTY_SIGN) == 1:</p>
<p class="snippet _idGenParaOverride-1">            if triple.count(AI_SIGN) == 2:</p>
<p class="snippet _idGenParaOverride-1">                add_score(1000)</p>
<p class="snippet _idGenParaOverride-1">            elif triple.count(OPPONENT_SIGN) == 2:</p>
<p class="snippet _idGenParaOverride-1">                add_score(100)</p>
<p class="snippet _idGenParaOverride-1">        elif triple.count(EMPTY_SIGN) == 2 and triple.count(AI_SIGN) == 1:</p>
<p class="snippet _idGenParaOverride-1">            add_score(10)</p>
<p class="snippet _idGenParaOverride-1">        elif triple.count(EMPTY_SIGN) == 3:</p>
<p class="snippet _idGenParaOverride-1">            add_score(1)</p>
<p class="snippet _idGenParaOverride-1">    return utilities</p>
</li>
<li value="3">We will now create a function that strictly selects the move with the highest utility value. If multiple moves have thise same utility, the function returns both moves.<p class="snippet _idGenParaOverride-1">def best_moves_from_board(board, sign):</p>
<p class="snippet _idGenParaOverride-1">    move_list = []</p>
<p class="snippet _idGenParaOverride-1">    utilities = utility_matrix(board)</p>
<p class="snippet _idGenParaOverride-1">    max_utility = max(utilities)</p>
<p class="snippet _idGenParaOverride-1">    for i, v in enumerate(board):</p>
<p class="snippet _idGenParaOverride-1">        if utilities[i] == max_utility:</p>
<p class="snippet _idGenParaOverride-1">            move_list.append(board[:i] + sign + board[i+1:])</p>
<p class="snippet _idGenParaOverride-1">    return move_list</p>
<p class="snippet _idGenParaOverride-1">def all_moves_from_board_list(board_list, sign):</p>
<p class="snippet _idGenParaOverride-1">    move_list = []</p>
<p class="snippet _idGenParaOverride-1">    get_moves = best_moves_from_board if sign == AI_SIGN else all_moves_from_board</p>
<p class="snippet _idGenParaOverride-1">    for board in board_list:</p>
<p class="snippet _idGenParaOverride-1">        move_list.extend(get_moves(board, sign))</p>
<p class="snippet _idGenParaOverride-1">    return move_list</p>
</li>
<li value="4">Let's run the application.<p class="snippet _idGenParaOverride-1">count_possibilities()</p>
<p class="_idGenParaOverride-7">The output will be as follows:</p>
<p class="snippet _idGenParaOverride-1">step 0. Moves: 1</p>
<p class="snippet _idGenParaOverride-1">step 1. Moves: 1</p>
<p class="snippet _idGenParaOverride-1">step 2. Moves: 8</p>
<p class="snippet _idGenParaOverride-1">step 3. Moves: 24</p>
<p class="snippet _idGenParaOverride-1">step 4. Moves: 144</p>
<p class="snippet _idGenParaOverride-1">step 5. Moves: 83</p>
<p class="snippet _idGenParaOverride-1">step 6. Moves: 214</p>
<p class="snippet _idGenParaOverride-1">step 7. Moves: 148</p>
<p class="snippet _idGenParaOverride-1">step 8. Moves: 172</p>
<p class="snippet _idGenParaOverride-1">First player wins: 504</p>
<p class="snippet _idGenParaOverride-1">Second player wins: 12</p>
<p class="snippet _idGenParaOverride-1">Draw 91</p>
<p class="snippet _idGenParaOverride-1">Total 607</p>
</li>
</ol>
<h3 id="_idParaDest-47"><a id="_idTextAnchor051"></a>
 Using Heuristics for an Informed Search</h3>
<p>We have not experienced the real power of heuristics yet, as we made moves without the knowledge of the effects of our future moves, thus effecting reasonable play from our opponents.</p>
<p>This is why a more accurate heuristic leads to more losses than simply hardcoding the first two moves in the game. Note that in previous topic, we selected these two moves based on statistics we generated based on running the game with fixed first moves. This approach is essentially what heuristic search should be all about. Static evaluation cannot compete with generating hundreds of thousands of future states and selecting a play that maximizes our rewards.</p>
<h3 id="_idParaDest-48"><a id="_idTextAnchor052"></a>
 Types of Heuristics</h3>
<p>Therefore, a more accurate heuristic leads to more losses than simply hardcoding the first two moves in the game. Note that in Topic A, we selected these two moves based on statistics I generated based on running the game with fixed first moves. This approach is essentially what a heuristic search should be all about. Static evaluation cannot compete with generating hundreds of thousands of future states and selecting a play that maximizes our rewards.</p>
<ul>
<li class="_idGenParaOverride-3">This is because our heuristics are not exact, and most likely not admissible either.</li>
<li style="list-style: none; display: inline"><div></div>
</li>
</ul>
<p>We saw in the preceding exercise that heuristics are not always optimal: in the first topic, we came up with rules that allowed the AI to always win the game or finish with a draw. These heuristics allowed the AI to win very often, at the expense of losing in a few cases.</p>
<ul>
<li>A heuristic is said to be admissible if we may underestimate the utility of a game state, but we never overestimate it.</li>
</ul>
<p>In the Tic-Tac-Toe example, we likely overestimated the utility in a few game states. Why? Because we ended up with a loss twelve times. A few of the game states that led to a loss had a maximum heuristic score. To prove that our heuristic is not admissible, all we need to do is find a potentially winning game state that we ignored while choosing a game state that led to a loss.</p>
<p>There are two more features that describe heuristics: Optimal and Complete:</p>
<ul>
<li>
<strong class="keyword _idGenCharOverride-2">Optimal heuristics</strong>
 always find the best possible solution.</li>
<li>
<strong class="keyword _idGenCharOverride-2">Complete heuristics</strong>
 have two definitions, depending on how we define the problem domain. In a loose sense, a heuristic is said to be complete if it always finds a solution. In a strict sense, a heuristic is said to be complete if it finds all possible solutions. Our Tic-Tac-Toe heuristic is not complete, because we ignored many possible winning states on purpose, favoring a losing state.</li>
</ul>
<h2 id="_idParaDest-49"><a id="_idTextAnchor053"></a>
 Pathfinding with the A* Algorithm</h2>
<p class="_idGenParaOverride-3">In the first two topics, we learned how to define an intelligent agent, and how to create a heuristic that guides the agent toward a desired state. We learned that this was not perfect, because at times we ignored a few winning states in favor of a few losing states.</p>
<div></div>
<p>We will now learn a structured and optimal approach so that we can execute a search for finding the shortest path between the current state and the goal state: the <strong class="keyword _idGenCharOverride-2">A*</strong>
 (<strong class="keyword _idGenCharOverride-2">"A star" instead of "A asterisk"</strong>
 ) algorithm:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer026" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00008.jpg" alt="Figure 2.3 Shortest pathfinding game board" />
</div>
</div>
<h6>Figure 2.3: Finding the shortest path in a maze</h6>
<p class="_idGenParaOverride-3">For a human, it is simple to find the shortest path, by merely looking at the image. We can conclude that there are two potential candidates for the shortest path: route one starts upwards, and route two starts to the left. However, the AI does not know about these options. In fact, the most logical first step for a computer player would be moving to the square denoted by the number 3 in the following diagram:</p>
<div></div>
<p>Why? Because this is the only step that decreases the distance between the starting state and the goal state. All other steps initially move away from the goal state:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer027" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00009.jpg" alt="Figure 2.4 Shortest pathfinding game board with Utilities" />
</div>
</div>
<h6>Figure 2.4: Shortest pathfinding game board with utilities</h6>
<h3 id="_idParaDest-50"><a id="_idTextAnchor054"></a>
 Exercise 6: Finding the Shortest Path to Reach a Goal</h3>
<p>The steps to find the shortest path are as follows:</p>
<ol>
<li class="ParaOverride-1" value="1">Describe the board, the initial state, and the final state using Python. Create a function that returns a list of possible successor states.</li>
<li value="2">We will use tuples, where the first coordinate denotes the row number from 1 to 7, and the second coordinate denotes the column number from 1 to 9:<p class="snippet _idGenParaOverride-1">size = (7, 9)</p>
<p class="snippet _idGenParaOverride-1">start = (5, 3)</p>
<p class="snippet _idGenParaOverride-1">end = (6, 9)</p>
<p class="snippet _idGenParaOverride-1">obstacles = {</p>
<p class="snippet _idGenParaOverride-1">    (3, 4), (3, 5), (3, 6), (3, 7), (3, 8),</p>
<p class="snippet _idGenParaOverride-1">    (4, 5),</p>
<p class="snippet _idGenParaOverride-1">    (5, 5), (5, 7), (5, 9),</p>
<p class="snippet _idGenParaOverride-1">    (6, 2), (6, 3), (6, 4), (6, 5), (6, 7),</p>
<p class="snippet _idGenParaOverride-1">    (7, 7)</p>
<p class="snippet _idGenParaOverride-2">}</p>
<div></div>
</li>
<li value="3">We will use array comprehension to generate the successor states in the following way. We move one left and one right from the current column, as long as we stay on the board. We move one up and one down from the current row, as long as we stay on the board. We take the new coordinates, generate all four possible tuples, and filter the results so that the new states can't be in the Obstacles list. It also makes sense to exclude moves that return to a field we had visited before to avoid infinite loops:<p class="snippet _idGenParaOverride-1">def successors(state, visited_nodes):</p>
<p class="snippet _idGenParaOverride-1">    (row, col) = state</p>
<p class="snippet _idGenParaOverride-1">    (max_row, max_col) = size</p>
<p class="snippet _idGenParaOverride-1">    succ_states = []</p>
<p class="snippet _idGenParaOverride-1">    if row &gt; 1:</p>
<p class="snippet _idGenParaOverride-1">        succ_states += [(row-1, col)]</p>
<p class="snippet _idGenParaOverride-1">    if col &gt; 1:</p>
<p class="snippet _idGenParaOverride-1">        succ_states += [(row, col-1)]</p>
<p class="snippet _idGenParaOverride-1">    if row &lt; max_row:</p>
<p class="snippet _idGenParaOverride-1">        succ_states += [(row+1, col)]</p>
<p class="snippet _idGenParaOverride-1">    if col &lt; max_col:</p>
<p class="snippet _idGenParaOverride-1">        succ_states += [(row, col+1)]</p>
<p class="snippet _idGenParaOverride-1">    return [s for s in succ_states if s not in visited_nodes if s not in obstacles]</p>
</li>
</ol>
<h3 id="_idParaDest-51"><a id="_idTextAnchor055"></a>
 Exercise 7: Finding the Shortest Path Using BFS</h3>
<p>To find the shortest path, follow these steps:</p>
<p>Find the shortest path by using the BFS algorithm.</p>
<p>Recall the basic BFS implementation.</p>
<ol>
<li class="ParaOverride-1" value="1">We have to modify this implementation to include the cost. Let's measure the cost:<p class="snippet _idGenParaOverride-1">import math</p>
<p class="snippet _idGenParaOverride-1">def initialize_costs(size, start):</p>
<p class="snippet _idGenParaOverride-1">    (h, w) = size</p>
<p class="snippet _idGenParaOverride-1">    costs = [[math.inf] * w for i in range(h)]</p>
<p class="snippet _idGenParaOverride-1">    (x, y) = start</p>
<p class="snippet _idGenParaOverride-1">    costs[x-1][y-1] = 0</p>
<p class="snippet _idGenParaOverride-1">    return costs</p>
<p class="snippet _idGenParaOverride-1">def update_costs(costs, current_node, successor_nodes):</p>
<p class="snippet _idGenParaOverride-1">    new_cost = costs[current_node[0]-1][current_node[1]-1] + 1</p>
<p class="snippet _idGenParaOverride-1">    for (x, y) in successor_nodes:</p>
<p class="snippet _idGenParaOverride-1">        costs[x-1][y-1] = min(costs[x-1][y-1], new_cost)</p>
<p class="snippet _idGenParaOverride-1">def bfs_tree(node):</p>
<p class="snippet _idGenParaOverride-1">    nodes_to_visit = [node]</p>
<p class="snippet _idGenParaOverride-1">    visited_nodes = []</p>
<p class="snippet _idGenParaOverride-1">    costs = initialize_costs(size, start)</p>
<p class="snippet _idGenParaOverride-1">    while len(nodes_to_visit) &gt; 0:</p>
<p class="snippet _idGenParaOverride-1">        current_node = nodes_to_visit.pop(0)</p>
<p class="snippet _idGenParaOverride-1">        visited_nodes.append(current_node)</p>
<p class="snippet _idGenParaOverride-1">        successor_nodes = successors(current_node, visited_nodes)</p>
<p class="snippet _idGenParaOverride-1">        update_costs(costs, current_node, successor_nodes)</p>
<p class="snippet _idGenParaOverride-1">        nodes_to_visit.extend(successor_nodes)</p>
<p class="snippet _idGenParaOverride-1">    return costs</p>
<p class="snippet _idGenParaOverride-1">bfs_tree(start)</p>
</li>
<li value="2">The output will be as follows:<p class="snippet _idGenParaOverride-1">[[6, 5, 4, 5, 6, 7, 8, 9, 10],</p>
<p class="snippet _idGenParaOverride-1">[5, 4, 3, 4, 5, 6, 7, 8, 9],</p>
<p class="snippet _idGenParaOverride-1">[4, 3, 2, inf, inf, inf, inf, inf, 10],</p>
<p class="snippet _idGenParaOverride-1">[3, 2, 1, 2, inf, 12, 13, 12, 11],</p>
<p class="snippet _idGenParaOverride-1">[2, 1, 0, 1, inf, 11, inf, 13, inf],</p>
<p class="snippet _idGenParaOverride-1">[3, inf, inf, inf, inf, 10, inf, 14, 15],</p>
<p class="snippet _idGenParaOverride-1">[4, 5, 6, 7, 8, 9, inf, 15, 16]]</p>
</li>
<li value="3">You can see that a simple BFS algorithm successfully determines the cost from the start node to any nodes, including the target node. Let's measure the number of steps required to find the goal node:<p class="snippet _idGenParaOverride-1">def bfs_tree_verbose(node):</p>
<p class="snippet _idGenParaOverride-1">    nodes_to_visit = [node]</p>
<p class="snippet _idGenParaOverride-1">    visited_nodes = []</p>
<p class="snippet _idGenParaOverride-1">    costs = initialize_costs(size, start)</p>
<p class="snippet _idGenParaOverride-1">    step_counter = 0</p>
<p class="snippet _idGenParaOverride-1">    while len(nodes_to_visit) &gt; 0:</p>
<p class="snippet _idGenParaOverride-1">        step_counter += 1</p>
<p class="snippet _idGenParaOverride-1">        current_node = nodes_to_visit.pop(0)</p>
<p class="snippet _idGenParaOverride-2">        visited_nodes.append(current_node)</p>
<div></div>
<p class="snippet _idGenParaOverride-1">        successor_nodes = successors(current_node, visited_nodes)</p>
<p class="snippet _idGenParaOverride-1">        update_costs(costs, current_node, successor_nodes)</p>
<p class="snippet _idGenParaOverride-1">        nodes_to_visit.extend(successor_nodes)</p>
<p class="snippet _idGenParaOverride-1">        if current_node == end:</p>
<p class="snippet _idGenParaOverride-1">            print(</p>
<p class="snippet _idGenParaOverride-1">                'End node has been reached in ',</p>
<p class="snippet _idGenParaOverride-1">                step_counter, '</p>
<p class="snippet _idGenParaOverride-1">                steps'</p>
<p class="snippet _idGenParaOverride-1">            )</p>
<p class="snippet _idGenParaOverride-1">            return costs</p>
<p class="snippet _idGenParaOverride-1">    return costs</p>
<p class="snippet _idGenParaOverride-1">bfs_tree_verbose(start)</p>
</li>
<li value="4">The end node has been reached in 110 steps:<p class="snippet _idGenParaOverride-1"></p>
<p class="snippet _idGenParaOverride-1">[[6, 5, 4, 5, 6, 7, 8, 9, 10],</p>
<p class="snippet _idGenParaOverride-1">[5, 4, 3, 4, 5, 6, 7, 8, 9],</p>
<p class="snippet _idGenParaOverride-1">[4, 3, 2, inf, inf, inf, inf, inf, 10],</p>
<p class="snippet _idGenParaOverride-1">[3, 2, 1, 2, inf, 12, 13, 12, 11],</p>
<p class="snippet _idGenParaOverride-1">[2, 1, 0, 1, inf, 11, inf, 13, inf],</p>
<p class="snippet _idGenParaOverride-1">[3, inf, inf, inf, inf, 10, inf, 14, 15],</p>
<p class="snippet _idGenParaOverride-1">[4, 5, 6, 7, 8, 9, inf, 15, 16]]</p>
</li>
</ol>
<p>We will now learn an algorithm that can find the shortest path from the start node to the goal node: the A* algorithm.</p>
<h3 id="_idParaDest-52"><a id="_idTextAnchor056"></a>
 Introducing the A* Algorithm</h3>
<p>A* is a complete and optimal heuristic search algorithm that finds the shortest possible path between the current game state and the winning state. The definition of complete and optimal in this state are as follows:</p>
<ul>
<li>Complete means that A* always finds a solution.</li>
<li class="_idGenParaOverride-3">Optimal means that A* will find the best solution.</li>
<li style="list-style: none; display: inline"><div></div>
</li>
</ul>
<p>To set up the A* algorithm, we need the following:</p>
<ul>
<li>An initial state</li>
<li>A description of the goal states</li>
<li>Admissible heuristics to measure progress toward the goal state</li>
<li>A way to generate the next steps toward the goal</li>
</ul>
<p>Once the setup is complete, we execute the A* algorithm using the following steps on the initial state:</p>
<ol>
<li class="ParaOverride-1" value="1">We generate all possible next steps.</li>
<li value="2">We store these children in the order of their distance from the goal.</li>
<li value="3">We select the child with the best score first and repeat these three steps on the child with the best score as the initial state. This is the shortest path to get to a node from the starting node.<p class="_idGenParaOverride-7">
<strong class="inline _idGenCharOverride-1">distance_from_end( node )</strong>
 is an admissible heuristic estimation showing how far we are from the goal node.</p>
</li>
</ol>
<p>In pathfinding, a good heuristic can be the Euclidean distance. If the current node is (x, y) and the goal node is (u, v), then:</p>
<p>
<em class="italics _idGenCharOverride-3">distance_from_end( node ) = sqrt( abs( x â€“ u ) ** 2 + abs( y â€“ v ) ** 2 )</em>
</p>
<p>Where:</p>
<ul>
<li>
<strong class="inline _idGenCharOverride-1">sqrt</strong>
 is the square root function. Don't forget to import it from the math library.</li>
<li>
<strong class="inline _idGenCharOverride-1">abs</strong>
 is the absolute value function. <strong class="inline _idGenCharOverride-1">abs( -2 )</strong>
 = <strong class="inline _idGenCharOverride-1">abs( 2 )</strong>
 = <strong class="inline _idGenCharOverride-1">2</strong>
 .</li>
<li>
<strong class="inline _idGenCharOverride-1">x ** 2</strong>
 is <em class="italics _idGenCharOverride-3">x</em>
 raised to the second power.</li>
</ul>
<p>We will use the <strong class="inline _idGenCharOverride-1">distance_from_start</strong>
 matrix to store the distances from the start node. In the algorithm, we will refer to this costs matrix as <strong class="inline _idGenCharOverride-1">distance_from_start( n1 )</strong>
 . For any node, <strong class="inline _idGenCharOverride-1">n1</strong>
 , that has coordinates <strong class="inline _idGenCharOverride-1">(x1, y1)</strong>
 , this distance is equivalent to <strong class="inline _idGenCharOverride-1">distance_from_start[x1][y1]</strong>
 .</p>
<p class="_idGenParaOverride-3">We will use the <strong class="inline _idGenCharOverride-1">succ( n )</strong>
 notation to generate a list of successor nodes from <strong class="inline _idGenCharOverride-1">n</strong>
 .</p>
<div></div>
<p>Let's see the pseudo-code of the algorithm:</p>
<p class="snippet">frontier = [start], internal = {}</p>
<p class="snippet"># Initialize the costs matrix with each cell set to infinity.</p>
<p class="snippet"># Set the value of distance_from_start(start) to 0.</p>
<p class="snippet">while frontier is not empty:</p>
<p class="snippet">    # notice n has the lowest estimated total</p>
<p class="snippet">    # distance between start and end.</p>
<p class="snippet">    n = frontier.pop()</p>
<p class="snippet">    # We'll learn later how to reconstruct the shortest path</p>
<p class="snippet">    if n == end:</p>
<p class="snippet">        return the shortest path.</p>
<p class="snippet">    internal.add(n)</p>
<p class="snippet">    for successor s in succ(n):</p>
<p class="snippet">        if s in internal:</p>
<p class="snippet">            continue # The node was already examined</p>
<p class="snippet">        new_distance = distance_from_start(n) + distance(n, s)</p>
<p class="snippet">        if new_distance &gt;= distance_from_start(s):</p>
<p class="snippet">            # This path is not better than the path we have</p>
<p class="snippet">            # already examined.</p>
<p class="snippet">            continue</p>
<p class="snippet">        if s is a member of frontier:</p>
<p class="snippet">            update the priority of s</p>
<p class="snippet">        else:</p>
<p class="snippet">            Add s to frontier.</p>
<p>Regarding the retrieval of the shortest path, we can make use of the costs matrix. This matrix contains the distance of each node on the path from the start node. As cost always decreases when walking backward, all we need to do is start with the end node and walk backward greedily toward decreasing costs:</p>
<p class="snippet">path = [end_node], distance = get_distance_from_start( end_node )</p>
<p class="snippet">while the distance of the last element in the path is not 0:</p>
<p class="snippet">    for each neighbor of the last node in path:</p>
<p class="snippet">        new_distance = get_distance_from_start( neighbor )</p>
<p class="snippet">        if new_distance &lt; distance:</p>
<p class="snippet">            add neighbor to path, and break out from the for loop</p>
<p class="snippet _idGenParaOverride-3">return path</p>
<div></div>
<p>A* shines when we have one Start state and one Goal state. The complexity of the A* algorithm is <strong class="inline _idGenCharOverride-1">O( E )</strong>
 , where <strong class="inline _idGenCharOverride-1">E</strong>
 stands for all possible edges in the field. In our example, we have up to four edges leaving any node: up, down, left, and right.</p>
<h4>Note</h4>
<p class="callout">To sort the frontier list in the proper order, we must use a special Python data structure: a priority queue.</p>
<p class="snippet"># Import heapq to access the priority queue</p>
<p class="snippet">import heapq</p>
<p class="snippet"># Create a list to store the data</p>
<p class="snippet">data = []</p>
<p class="snippet"># Use heapq.heappush to push (priorityInt, value) pairs to the queue</p>
<p class="snippet">heapq.heappush(data, (2, 'first item'))</p>
<p class="snippet">heapq.heappush(data, (1, 'second item'))</p>
<p class="snippet"># The tuples are stored in data in the order of ascending priority</p>
<p class="snippet">[(1, 'second item'), (2, 'first item')]</p>
<p class="snippet"># heapq.heappop pops the item with the lowest score from the queue</p>
<p class="snippet">heapq.heappop(data)</p>
<p>The output is as follows:</p>
<p class="snippet">(1, 'second item')</p>
<p class="snippet"># data still contains the second item</p>
<p class="snippet">data</p>
<p>The output is as follows:</p>
<p class="snippet">[(2, 'first item')]</p>
<p>Why is it important that the heuristic used by the algorithm is admissible?</p>
<p class="_idGenParaOverride-3">Because this is how we guarantee the optimal nature of the algorithm. For any node <strong class="inline _idGenCharOverride-1">x</strong>
 , we are measuring the sum of the following: The distances from the start node to <strong class="inline _idGenCharOverride-1">x</strong>
 The estimated distance from <strong class="inline _idGenCharOverride-1">x</strong>
 to the end node. If the estimation never overestimates the distance from <strong class="inline _idGenCharOverride-1">x</strong>
 to the end node, we will never overestimate the total distance. Once we are at the goal node, our estimation is zero, and the total distance from the start to the end becomes an exact number.</p>
<div></div>
<p>We can be sure that our solution is optimal because there are no other items in the priority queue that have a lower estimated cost. Given that we never overestimate our costs, we can be sure that all of the nodes in the frontier of the algorithm have either similar total costs or higher total costs than the path we found.</p>
<p>Implement the A* algorithm to find the path with the lowest cost in the following game field:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer028" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00010.jpg" alt=" Figure 2.5 Shortest pathfinding game board" />
</div>
</div>
<h6>Figure 2.5: Shortest pathfinding game board</h6>
<p>We'll reuse the initialization code from the game-modeling exercise:</p>
<p class="snippet">import math</p>
<p class="snippet">import heapq</p>
<p class="snippet">size = (7, 9)</p>
<p class="snippet">start = (5, 3)</p>
<p class="snippet">end = (6, 9)</p>
<p class="snippet">obstacles = {</p>
<p class="snippet">    (3, 4), (3, 5), (3, 6), (3, 7), (3, 8),</p>
<p class="snippet">    (4, 5),</p>
<p class="snippet">    (5, 5), (5, 7), (5, 9),</p>
<p class="snippet">    (6, 2), (6, 3), (6, 4), (6, 5), (6, 7),</p>
<p class="snippet">    (7, 7)</p>
<p class="snippet">}</p>
<p class="snippet"># Returns the successor nodes of State, excluding nodes in VisitedNodes</p>
<p class="snippet">def successors(state, visited_nodes):</p>
<p class="snippet">    (row, col) = state</p>
<p class="snippet">    (max_row, max_col) = size</p>
<p class="snippet">    succ_states = []</p>
<p class="snippet">    if row &gt; 1:</p>
<p class="snippet">        succ_states += [(row-1, col)]</p>
<p class="snippet">    if col &gt; 1:</p>
<p class="snippet">        succ_states += [(row, col-1)]</p>
<p class="snippet">    if row &lt; max_row:</p>
<p class="snippet">        succ_states += [(row+1, col)]</p>
<p class="snippet">    if col &lt; max_col:</p>
<p class="snippet">        succ_states += [(row, col+1)]</p>
<p class="snippet">    return [s for s in succ_states if s not in visited_nodes if s not in obstacles]</p>
<p>We have also written code to initialize the cost matrix:</p>
<p class="snippet">import math</p>
<p class="snippet">def initialize_costs(size, start):</p>
<p class="snippet">    costs = [[math.inf] * 9 for i in range(7)]</p>
<p class="snippet">    (x, y) = start</p>
<p class="snippet">    costs[x-1][y-1] = 0</p>
<p class="snippet">    return costs</p>
<p class="_idGenParaOverride-3">We will omit the function to update costs because we will do so inside the A* algorithm:</p>
<div></div>
<p>Let's initialize the A* algorithm's frontier and internal lists. For frontier, we will use a Python PriorityQueue. Do not directly execute this code, because we will use these four lines inside the A* search function:</p>
<p class="snippet">frontier = []</p>
<p class="snippet">internal = set()</p>
<p class="snippet">heapq.heappush(frontier, (0, start))</p>
<p class="snippet">costs = initialize_costs(size, start)</p>
<p>Now it is time to implement a heuristic function that measures the distance between the current node and the goal node using the algorithm we saw in the theory section:</p>
<p class="snippet">def distance_heuristic(node, goal):</p>
<p class="snippet">    (x, y) = node</p>
<p class="snippet">    (u, v) = goal</p>
<p class="snippet">    return math.sqrt(abs(x - u) ** 2 + abs(y - v) ** 2)</p>
<p>The last step is the translation of the A* algorithm into the functioning code:</p>
<p class="snippet">def astar(start, end):</p>
<p class="snippet">    frontier = []</p>
<p class="snippet">    internal = set()</p>
<p class="snippet">    heapq.heappush(frontier, (0, start))</p>
<p class="snippet">    costs = initialize_costs(size, start)</p>
<p class="snippet">    def get_distance_from_start(node):</p>
<p class="snippet">        return costs[node[0] - 1][node[1] - 1]</p>
<p class="snippet">    def set_distance_from_start(node, new_distance):</p>
<p class="snippet">        costs[node[0] - 1][node[1] - 1] = new_distance</p>
<p class="snippet">    while len(frontier) &gt; 0:</p>
<p class="snippet _idGenParaOverride-3">        (priority, node) = heapq.heappop(frontier)</p>
<div></div>
<p class="snippet">        if node == end:</p>
<p class="snippet">            return priority</p>
<p class="snippet">        internal.add(node)</p>
<p class="snippet">        successor_nodes = successors(node, internal)</p>
<p class="snippet">        for s in successor_nodes:</p>
<p class="snippet">            new_distance = get_distance_from_start(node) + 1</p>
<p class="snippet">            if new_distance &lt; get_distance_from_start(s):</p>
<p class="snippet">                set_distance_from_start(s, new_distance)</p>
<p class="snippet">                # Filter previous entries of s</p>
<p class="snippet">                frontier = [n for n in frontier if s != n[1]]</p>
<p class="snippet">                heapq.heappush(frontier, (</p>
<p class="snippet">                    new_distance + distance_heuristic(s, end), s</p>
<p class="snippet">                )</p>
<p class="snippet">                )</p>
<p class="snippet">astar(start, end)</p>
<p class="snippet">15.0</p>
<p>There are a few differences between our implementation and the original algorithm:</p>
<p>We defined a <strong class="inline _idGenCharOverride-1">distance_from_start</strong>
 function to make it easier and more semantic to access the <strong class="inline _idGenCharOverride-1">costs</strong>
 matrix. Note that we number the node indices starting with 1, while in the matrix, indices start with zero. Therefore, we subtract 1 from the node values to get the indices.</p>
<p>When generating the successor nodes, we automatically ruled out nodes that are in the Internal set. <strong class="inline _idGenCharOverride-1">successors = succ(node, internal)</strong>
 makes sure that we only get the neighbors whose examination is not yet closed, meaning that their score is not necessarily optimal.</p>
<p>As a consequence, we may skip the step check, as internal nodes will never end up in <strong class="inline _idGenCharOverride-1">succ( n )</strong>
 .</p>
<p class="_idGenParaOverride-3">As we are using a priority queue, we have to determine the estimated priority of node s before inserting it. We will only insert the node to frontier, though, if we know that this node does not have an entry with a lower score.</p>
<div></div>
<p>It may happen that node s is already in the frontier queue with a higher score. In this case, we remove this entry before inserting it to the right place in the priority queue. When we find the end node, we simply return the length of the shortest path instead of the path itself.</p>
<p>To get a bit more information on the execution, let's print this information to the console. To follow what the A* algorithm does, execute this code and study the logs:</p>
<p class="snippet">def astar_verbose(start, end):</p>
<p class="snippet">    frontier = []</p>
<p class="snippet">    internal = set()</p>
<p class="snippet">    heapq.heappush(frontier, (0, start))</p>
<p class="snippet">    costs = initialize_costs(size, start)</p>
<p class="snippet">    def get_distance_from_start(node):</p>
<p class="snippet">        return costs[node[0] - 1][node[1] - 1]</p>
<p class="snippet">    def set_distance_from_start(node, new_distance):</p>
<p class="snippet">        costs[node[0] - 1][node[1] - 1] = new_distance</p>
<p class="snippet">    steps = 0</p>
<p class="snippet">    while len(frontier) &gt; 0:</p>
<p class="snippet">        steps += 1</p>
<p class="snippet">        print('step ', steps, '. frontier: ', frontier)</p>
<p class="snippet">        (priority, node) = heapq.heappop(frontier)</p>
<p class="snippet">        print(</p>
<p class="snippet">            'node ',</p>
<p class="snippet">            node,</p>
<p class="snippet">            'has been popped from frontier with priority',</p>
<p class="snippet">            priority</p>
<p class="snippet">        )</p>
<p class="snippet">        if node == end:</p>
<p class="snippet">            print('Optimal path found. Steps: ', steps)</p>
<p class="snippet">            print('Costs matrix: ', costs)</p>
<p class="snippet">            return priority</p>
<p class="snippet">        internal.add(node)</p>
<p class="snippet">        successor_nodes = successors(node, internal)</p>
<p class="snippet">        print('successor_nodes', successor_nodes)</p>
<p class="snippet">        for s in successor_nodes:</p>
<p class="snippet">            new_distance = get_distance_from_start(node) + 1</p>
<p class="snippet">            print(</p>
<p class="snippet">                's:',</p>
<p class="snippet">                s,</p>
<p class="snippet">                'new distance:',</p>
<p class="snippet">                new_distance,</p>
<p class="snippet">                ' old distance:',</p>
<p class="snippet">                get_distance_from_start(s)</p>
<p class="snippet">            )</p>
<p class="snippet">            if new_distance &lt; get_distance_from_start(s):</p>
<p class="snippet">                set_distance_from_start(s, new_distance)</p>
<p class="snippet">                # Filter previous entries of s</p>
<p class="snippet">                frontier = [n for n in frontier if s != n[1]]</p>
<p class="snippet">                new_priority = new_distance + distance_heuristic(s, end)</p>
<p class="snippet">                heapq.heappush(frontier, (new_priority, s))</p>
<p class="snippet">                print(</p>
<p class="snippet">        'Node',</p>
<p class="snippet">        s,</p>
<p class="snippet">        'has been pushed to frontier with priority',</p>
<p class="snippet">        new_priority</p>
<p class="snippet">    )</p>
<p class="snippet">    print('Frontier', frontier)</p>
<p class="snippet">    print('Internal', internal)</p>
<p class="snippet">    print(costs)</p>
<p class="snippet _idGenParaOverride-3">astar_verbose(start, end)</p>
<div></div>
<p>The output is as follows:</p>
<p class="snippet">step 1 . Frontier: [(0, (5, 3))]</p>
<p class="snippet">Node (5, 3) has been popped from Frontier with priority 0</p>
<p class="snippet">successors [(4, 3), (5, 2), (5, 4)]</p>
<p class="snippet">s: (4, 3) new distance: 1 old distance: inf</p>
<p class="snippet">Node (4, 3) has been pushed to Frontier with priority 7.324555320336759</p>
<p class="snippet">s: (5, 2) new distance: 1 old distance: inf</p>
<p class="snippet">Node (5, 2) has been pushed to Frontier with priority 8.071067811865476</p>
<p class="snippet">s: (5, 4) new distance: 1 old distance: inf</p>
<p class="snippet">Node (5, 4) has been pushed to Frontier with priority 6.0990195135927845</p>
<p class="snippet">step 2 . Frontier: [(6.0990195135927845, (5, 4)), (8.071067811865476, (5, 2)), (7.324555320336759, (4, 3))]</p>
<p class="snippet">Node (5, 4) has been popped from Frontier with priority 6.0990195135927845</p>
<p class="snippet">successors [(4, 4)]</p>
<p class="snippet">s: (4, 4) new distance: 2 old distance: inf</p>
<p class="snippet">Node (4, 4) has been pushed to Frontier with priority 7.385164807134504</p>
<p class="snippet">â€¦</p>
<p class="snippet">step 42 . Frontier: [(15.0, (6, 8)), (15.60555127546399, (4, 6)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7))]</p>
<p class="snippet">Node (6, 8) has been popped from Frontier with priority 15.0</p>
<p class="snippet">successors [(7, 8), (6, 9)]</p>
<p class="snippet">s: (7, 8) new distance: 15 old distance: inf</p>
<p class="snippet">Node (7, 8) has been pushed to Frontier with priority 16.414213562373096</p>
<p class="snippet">s: (6, 9) new distance: 15 old distance: inf</p>
<p class="snippet">Node (6, 9) has been pushed to Frontier with priority 15.0</p>
<p class="snippet">step 43 . Frontier: [(15.0, (6, 9)), (15.433981132056603, (1, 1)), (15.82842712474619, (4, 7)), (16.414213562373096, (7, 8)), (15.60555127546399, (4, 6))]</p>
<p class="snippet">Node (6, 9) has been popped from Frontier with priority 15.0</p>
<p class="snippet _idGenParaOverride-3">Optimal path found. Steps: 43</p>
<div></div>
<p class="snippet">Costs matrix: [[6, 5, 4, 5, 6, 7, 8, 9, 10], [5, 4, 3, 4, 5, 6, 7, 8, 9], [4, 3, 2, inf, inf, inf, inf, inf, 10], [3, 2, 1, 2, inf, 12, 13, 12, 11], [2, 1, 0, 1, inf, 11, inf, 13, inf], [3, inf, inf, inf, inf, 10, inf, 14, 15], [4, 5, 6, 7, 8, 9, inf, 15, inf]]</p>
<p>We have seen that the A * search returns the right values. The question is, how can we reconstruct the whole path?</p>
<p>Remove the print statements from the code for clarity and continue with the A* algorithm that we implemented in step 4. Instead of returning the length of the shortest path, we have to return the path itself. We will write a function that extracts this path by walking backward from the end node, analyzing the costs matrix. Do not define this function globally yet. We will define it as a local function in the A* algorithm that we created previously:</p>
<p class="snippet">def get_shortest_path(end_node):</p>
<p class="snippet">    path = [end_node]</p>
<p class="snippet">    distance = get_distance_from_start(end_node)</p>
<p class="snippet">    while distance &gt; 0:</p>
<p class="snippet">        for neighbor in successors(path[-1], []):</p>
<p class="snippet">            new_distance = get_distance_from_start(neighbor)</p>
<p class="snippet">            if new_distance &lt; distance:</p>
<p class="snippet">                path += [neighbor]</p>
<p class="snippet">                distance = new_distance</p>
<p class="snippet">                break # for</p>
<p class="snippet">    return path</p>
<p>Now that we know how to deconstruct the path, let's return it inside the A* algorithm:</p>
<p class="snippet">def astar_with_path(start, end):</p>
<p class="snippet">    frontier = []</p>
<p class="snippet">    internal = set()</p>
<p class="snippet">    heapq.heappush(frontier, (0, start))</p>
<p class="snippet">    costs = initialize_costs(size, start)</p>
<p class="snippet">    def get_distance_from_start(node):</p>
<p class="snippet">        return costs[node[0] - 1][node[1] - 1]</p>
<p class="snippet">    def set_distance_from_start(node, new_distance):</p>
<p class="snippet">        costs[node[0] - 1][node[1] - 1] = new_distance</p>
<p class="snippet">    def get_shortest_path(end_node):</p>
<p class="snippet">        path = [end_node]</p>
<p class="snippet">        distance = get_distance_from_start(end_node)</p>
<p class="snippet">        while distance &gt; 0:</p>
<p class="snippet">            for neighbor in successors(path[-1], []):</p>
<p class="snippet">                new_distance = get_distance_from_start(neighbor)</p>
<p class="snippet">                if new_distance &lt; distance:</p>
<p class="snippet">                    path += [neighbor]</p>
<p class="snippet">                    distance = new_distance</p>
<p class="snippet">                    break # for</p>
<p class="snippet">        return path</p>
<p class="snippet">    while len(frontier) &gt; 0:</p>
<p class="snippet">        (priority, node) = heapq.heappop(frontier)</p>
<p class="snippet">        if node == end:</p>
<p class="snippet">            return get_shortest_path(end)</p>
<p class="snippet">        internal.add(node)</p>
<p class="snippet">        successor_nodes = successors(node, internal)</p>
<p class="snippet">        for s in successor_nodes:</p>
<p class="snippet">            new_distance = get_distance_from_start(node) + 1</p>
<p class="snippet">            if new_distance &lt; get_distance_from_start(s):</p>
<p class="snippet">                set_distance_from_start(s, new_distance)</p>
<p class="snippet">                # Filter previous entries of s</p>
<p class="snippet">                frontier = [n for n in frontier if s != n[1]]</p>
<p class="snippet">                heapq.heappush(frontier, (</p>
<p class="snippet">                    new_distance + distance_heuristic(s, end), s</p>
<p class="snippet">                )</p>
<p class="snippet">                )</p>
<p class="snippet">astar_with_path( start, end )</p>
<p>The output is as follows:</p>
<p class="snippet"></p>
<p class="snippet">[(6, 9),</p>
<p class="snippet">(6, 8),</p>
<p class="snippet">(5, 8),</p>
<p class="snippet">(4, 8),</p>
<p class="snippet">(4, 9),</p>
<p class="snippet">(3, 9),</p>
<p class="snippet">(2, 9),</p>
<p class="snippet">(2, 8),</p>
<p class="snippet">(2, 7),</p>
<p class="snippet">(2, 6),</p>
<p class="snippet">(2, 5),</p>
<p class="snippet">(2, 4),</p>
<p class="snippet">(2, 3),</p>
<p class="snippet">(3, 3),</p>
<p class="snippet">(4, 3),</p>
<p class="snippet">(5, 3)]</p>
<p>Technically, we do not need to reconstruct the path from the costs matrix. We could record the parent node of each node in a matrix, and simply retrieve the coordinates to save a bit of searching.</p>
<h3 id="_idParaDest-53"><a id="_idTextAnchor057"></a>
 A* Search in Practice Using the simpleai Library</h3>
<p>The <strong class="inline _idGenCharOverride-1">simpleai</strong>
 library is available on GitHub, and contains many popular AI tools and techniques.</p>
<h4>Note</h4>
<p class="callout">You can access the library at <a href="https://github.com/simpleai-team/simpleai">https://github.com/simpleai-team/simpleai</a>
 . The documentation of the Simple AI library can be accessed here: <a href="http://simpleai.readthedocs.io/en/latest/">http://simpleai.readthedocs.io/en/latest/</a>
 .To access the <strong class="inline _idGenCharOverride-4">simpleai</strong>
 library, first you have to install it:</p>
<p class="snippet _idGenParaOverride-3">pip install simpleai</p>
<div></div>
<p>Once simpleai has been installed, you can import classes and functions from the simpleai library in the Jupyter QtConsole of Python:</p>
<p class="snippet">from simpleai.search import SearchProblem, astar</p>
<p>
<strong class="bold _idGenCharOverride-2">Search Problem</strong>
 gives you a frame for defining any search problems. The <strong class="inline _idGenCharOverride-1">astar</strong>
 import is responsible for executing the A* algorithm inside the search problem.</p>
<p>For simplicity, we have not used classes in the previous code examples to focus on the algorithms in a plain old style without any clutter. The <strong class="inline _idGenCharOverride-1">simpleai</strong>
 library will force us to use classes, though.</p>
<p>To describe a search problem, you need to provide the following:</p>
<ul>
<li>
<strong class="bold _idGenCharOverride-2">constructor</strong>
 : This initializes the state space, thus describing the problem. We will make the Size, Start, End, and Obstacles values available in the object by adding it to these as properties. At the end of the constructor, don't forget to call the super constructor, and don't forget to supply the initial state.</li>
<li>
<strong class="bold _idGenCharOverride-2">actions( state )</strong>
 : This returns a list of actions that we can perform from a given state. We will use this function to generate the new states. Semantically, it would make more sense to create action constants such as UP, DOWN, LEFT, and RIGHT, and then interpret these action constants as a result. However, in this implementation, we will simply interpret an action as "move to <strong class="inline _idGenCharOverride-1">(x, y)</strong>
 ", and represent this command as <strong class="inline _idGenCharOverride-1">(x, y)</strong>
 . This function contains more-or-less the logic that we implemented in the <strong class="inline _idGenCharOverride-1">succ</strong>
 function before, except that we won't filter the result based on a set of visited nodes.</li>
<li>
<strong class="bold _idGenCharOverride-2">result( state0, action)</strong>
 : This returns the new state of action applied on the state0.</li>
<li>
<strong class="bold _idGenCharOverride-2">is_goal( state )</strong>
 : This returns true if the state is a goal state. In our implementation, we will have to compare the state to the end state coordinates.</li>
<li>
<strong class="bold _idGenCharOverride-2">cost( self, state, action, newState )</strong>
 : This is the cost of moving from state to <strong class="inline _idGenCharOverride-1">newState</strong>
 via action. In our example, the cost of a move is uniformly 1:<p class="snippet _idGenParaOverride-1">import math</p>
<p class="snippet _idGenParaOverride-1">from simpleai.search import SearchProblem, astar</p>
<p class="snippet _idGenParaOverride-1">class ShortestPath(SearchProblem):</p>
<p class="snippet _idGenParaOverride-1">    def __init__(self, size, start, end, obstacles):</p>
<p class="snippet _idGenParaOverride-1">        self.size = size</p>
<p class="snippet _idGenParaOverride-1">        self.start = start</p>
<p class="snippet _idGenParaOverride-2">        self.end = end</p>
<div></div>
<p class="snippet _idGenParaOverride-1">        self.obstacles = obstacles</p>
<p class="snippet _idGenParaOverride-1">        super(ShortestPath, self).__init__(initial_state=self.start)</p>
<p class="snippet _idGenParaOverride-1">    def actions(self, state):</p>
<p class="snippet _idGenParaOverride-1">        (row, col) = state</p>
<p class="snippet _idGenParaOverride-1">        (max_row, max_col) = self.size</p>
<p class="snippet _idGenParaOverride-1">        succ_states = []</p>
<p class="snippet _idGenParaOverride-1">        if row &gt; 1:</p>
<p class="snippet _idGenParaOverride-1">            succ_states += [(row-1, col)]</p>
<p class="snippet _idGenParaOverride-1">        if col &gt; 1:</p>
<p class="snippet _idGenParaOverride-1">            succ_states += [(row, col-1)]</p>
<p class="snippet _idGenParaOverride-1">        if row &lt; max_row:</p>
<p class="snippet _idGenParaOverride-1">            succ_states += [(row+1, col)]</p>
<p class="snippet _idGenParaOverride-1">        if col &lt; max_col:</p>
<p class="snippet _idGenParaOverride-1">            succ_states += [(row, col+1)]</p>
<p class="snippet _idGenParaOverride-1">        return [s for s in succ_states if s not in self._obstacles]</p>
<p class="snippet _idGenParaOverride-1">    def result(self, state, action):</p>
<p class="snippet _idGenParaOverride-1">        return action</p>
<p class="snippet _idGenParaOverride-1">    def is_goal(self, state):</p>
<p class="snippet _idGenParaOverride-1">        return state == end</p>
<p class="snippet _idGenParaOverride-1">    def cost(self, state, action, new_state):</p>
<p class="snippet _idGenParaOverride-1">        return 1</p>
<p class="snippet _idGenParaOverride-1">    def heuristic(self, state):</p>
<p class="snippet _idGenParaOverride-1">        (x, y) = state</p>
<p class="snippet _idGenParaOverride-1">        (u, v) = self.end</p>
<p class="snippet _idGenParaOverride-1">        return math.sqrt(abs(x-u) ** 2 + abs(y-v) ** 2)</p>
<p class="snippet _idGenParaOverride-1">size = (7, 9)</p>
<p class="snippet _idGenParaOverride-1">start = (5, 3)</p>
<p class="snippet _idGenParaOverride-1">end = (6, 9)</p>
<p class="snippet _idGenParaOverride-1">obstacles = {</p>
<p class="snippet _idGenParaOverride-1">    (3, 4), (3, 5), (3, 6), (3, 7), (3, 8),</p>
<p class="snippet _idGenParaOverride-1">    (4, 5),</p>
<p class="snippet _idGenParaOverride-1">    (5, 5), (5, 7), (5, 9),</p>
<p class="snippet _idGenParaOverride-1">    (6, 2), (6, 3), (6, 4), (6, 5), (6, 7),</p>
<p class="snippet _idGenParaOverride-1">    (7, 7)</p>
<p class="snippet _idGenParaOverride-1">}</p>
<p class="snippet _idGenParaOverride-1">searchProblem = ShortestPath(Size, Start, End, Obstacles)</p>
<p class="snippet _idGenParaOverride-1">result = astar( searchProblem, graph_search=True )</p>
<p class="snippet _idGenParaOverride-1">result</p>
<p class="snippet _idGenParaOverride-1">Node &lt;(6, 9)&gt;</p>
<p class="snippet _idGenParaOverride-1">result.path()</p>
<p class="snippet _idGenParaOverride-1">[(None, (5, 3)),</p>
<p class="snippet _idGenParaOverride-1">((4, 3), (4, 3)),</p>
<p class="snippet _idGenParaOverride-1">((3, 3), (3, 3)),</p>
<p class="snippet _idGenParaOverride-1">((2, 3), (2, 3)),</p>
<p class="snippet _idGenParaOverride-1">((2, 4), (2, 4)),</p>
<p class="snippet _idGenParaOverride-1">((2, 5), (2, 5)),</p>
<p class="snippet _idGenParaOverride-1">((2, 6), (2, 6)),</p>
<p class="snippet _idGenParaOverride-1">((2, 7), (2, 7)),</p>
<p class="snippet _idGenParaOverride-1">((2, 8), (2, 8)),</p>
<p class="snippet _idGenParaOverride-1">((2, 9), (2, 9)),</p>
<p class="snippet _idGenParaOverride-1">((3, 9), (3, 9)),</p>
<p class="snippet _idGenParaOverride-1">((4, 9), (4, 9)),</p>
<p class="snippet _idGenParaOverride-1">((4, 8), (4, 8)),</p>
<p class="snippet _idGenParaOverride-1">((5, 8), (5, 8)),</p>
<p class="snippet _idGenParaOverride-1">((6, 8), (6, 8)),</p>
<p class="snippet _idGenParaOverride-1">((6, 9), (6, 9))]</p>
</li>
</ul>
<p>The <strong class="inline _idGenCharOverride-1">simpleai</strong>
 library made the search description a lot easier than the manual implementation. All we need to do is define a few basic methods, and then we have access to an effective search implementation.</p>
<h2 id="_idParaDest-54"><a id="_idTextAnchor058"></a>
 Game AI with the Minmax Algorithm and Alpha-Beta Pruning</h2>
<p>In the first two topics, we saw how hard it was to create a winning strategy for a simple game such as Tic-Tac-Toe. The last topic introduced a few structures for solving search problems with the A* algorithm. We also saw that tools such as the <strong class="inline _idGenCharOverride-1">simpleai</strong>
 library help us reduce the effort we put in to describe a task with code.</p>
<p class="_idGenParaOverride-3">We will use all of this knowledge to supercharge our game AI skills and solve more complex problems.</p>
<div></div>
<h3 id="_idParaDest-55"><a id="_idTextAnchor059"></a>
 Search Algorithms for Turn-Based Multiplayer Games</h3>
<p>Turn-based multiplayer games such as Tic-Tac-Toe are similar to pathfinding problems. We have an initial state, and we have a set of end states, where we win the game.</p>
<p>The challenge with turn-based multiplayer games is the combinatoric explosion of the opponent's possible moves. This difference justifies treating turn-based games differently than a regular pathfinding problem.</p>
<p>For instance, in the Tic-Tac-Toe game, from an empty board, we can select one of the nine cells and place our sign there, assuming we start the game. Let's denote this algorithm with the function <strong class="inline _idGenCharOverride-1">succ</strong>
 , symbolizing the creation of successor states. Consider we have the initial state denoted by <strong class="inline _idGenCharOverride-1">Si</strong>
 .</p>
<p>
<strong class="inline _idGenCharOverride-1">succ(Si) returns [ S1, S2, ..., Sn ]</strong>
 , where <strong class="inline _idGenCharOverride-1">S1, S2, ..., Sn</strong>
 are successor states:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer029" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00011.jpg" alt="Figure 2.6 Tree diagram denoting the successor states of the function" />
</div>
</div>
<h6>Figure 2.6: Tree diagram denoting the successor states of the function</h6>
<p>Then, the opponent also makes a move, meaning that from each possible state, we have to examine even more states:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer030" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00012.jpg" alt="Figure 2.7 Tree diagram denoting parent-successor relationships" />
</div>
</div>
<h6 class="_idGenParaOverride-3">Figure 2.7: Tree diagram denoting parent-successor relationships</h6>
<div></div>
<p>The expansion of possible future states stops in one of two cases:</p>
<ul>
<li>The game ends</li>
<li>Due to resource limitations, it is not worth explaining any more moves beyond a certain depth for a state with a certain utility</li>
</ul>
<p>Once we stop expanding, we have to make a static heuristic evaluation of the state. This is exactly what we did in the first two topics, when choosing the best move; however, we never considered future states.</p>
<p>Therefore, even though our algorithm became more and more complex, without using the knowledge of possible future states, we had a hard time detecting whether our current move would likely be a winner or a loser. The only way for us to take control of the future was to change our heuristic knowing how many games we would win, lose, or tie in the future. We could either maximize our wins or minimize our losses. We still didn't dig deeply enough to see whether our losses could have been avoided through smarter play on the AI's end.</p>
<p>All of these problems can be avoided by digging deeper into future states and recursively evaluating the utility of the branches. To consider future states, we will learn the Minmax algorithm and its variant, the Negamax algorithm.</p>
<h3 id="_idParaDest-56"><a id="_idTextAnchor060"></a>
 The Minmax Algorithm</h3>
<p>Suppose there's a game where a heuristic function can evaluate a game state from the perspective of the AI player. For instance, we used a specific evaluation for the Tic-Tac-Toe exercise:</p>
<ul>
<li>+1,000 points for a move that won the game</li>
<li>+100 points for a move preventing the opponent from winning the game</li>
<li>+10 points for a move creating two in a row, column, or diagonal</li>
<li>+1 point for a move creating one in a row, column, or diagonal</li>
</ul>
<p class="_idGenParaOverride-3">This static evaluation is very easy to implement on any node. The problem is, as we go deep into the tree of all possible future states, we don't know what to do with these scores yet. This is where the Minmax algorithm comes into play.</p>
<div></div>
<p>Suppose we construct a tree with each possible move that could be performed by each player up to a certain depth. At the bottom of the tree, we evaluate each option. For the sake of simplicity, let's assume that we have a search tree that looks as follows:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer031" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00013.jpg" alt="Figure 2.8 Example of search tree up to a certain depth" />
</div>
</div>
<h6>Figure 2.8: Example of search tree up to a certain depth</h6>
<p>The AI plays with X, and the player plays with O. A node with X means that it's X's turn to move. A node with O means it's O's turn to act.</p>
<p>Suppose there are all O leaves at the bottom of the tree, and we didn't compute any more values because of resource limitations. Our task is to evaluate the utility of the leaves:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer032" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00014.jpg" alt="Figure 2.9 Example of search tree with possible moves" />
</div>
</div>
<h6 class="_idGenParaOverride-3">Figure 2.9: Example of search tree with possible moves</h6>
<div></div>
<p>We have to select the best possible move from our perspective, because our goal is to maximize the utility of our move. This aspiration to maximize our gains represents the Max part in the Minmax algorithm:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer033" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00015.jpg" alt="Figure 2.10 Example of search tree with best possible move" />
</div>
</div>
<h6>Figure 2.10: Example of search tree with best possible move</h6>
<p>If we move one level higher, it is our opponent's turn to act. Our opponent picks the value that is the least beneficial to us. This is because our opponent's job is to minimize our chances of winning the game. This is the Min part of the Minmax algorithm:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer034" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00016.jpg" alt="Figure 2.11 Example of search tree demonstrating MinMax algorithm" />
</div>
</div>
<h6 class="_idGenParaOverride-3">Figure 2.11: Minimizing the chances of winning the game</h6>
<div></div>
<p>At the top, we can choose between a move with utility 101 and another move with utility 21. As we are maximizing our value, we should pick 101.</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer035" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00017.jpg" alt="Figure 2.12 Search tree maximizing the utility" />
</div>
</div>
<h6>Figure 2.12: Maximizing the chances of winning the game</h6>
<p>Let's see how we can implement this idea:</p>
<p class="snippet">def min_max( state, depth, is_maximizing):</p>
<p class="snippet">    if depth == 0 or is_end_state( state ):</p>
<p class="snippet">    &amp;#9;return utility( state )</p>
<p class="snippet">    if is_maximizing:</p>
<p class="snippet">        utility = 0</p>
<p class="snippet">        for s in successors( state ):</p>
<p class="snippet">            score = MinMax( s, depth - 1, false )</p>
<p class="snippet">            utility = max( utility, score )</p>
<p class="snippet">        return utility</p>
<p class="snippet">    else</p>
<p class="snippet">        utility = infinity</p>
<p class="snippet">        for s in successors( state ):</p>
<p class="snippet">            score = MinMax( s, depth - 1, true )</p>
<p class="snippet">            utility = min( utility, score )</p>
<p class="snippet _idGenParaOverride-3">        return utility</p>
<div></div>
<p>This is the Minmax algorithm. We evaluate the leaves from our perspective. Then, from the bottom-up, we apply a recursive definition:</p>
<ul>
<li>Our opponent plays optimally by selecting the worst possible node from our perspective.</li>
<li>We play optimally by selecting the best possible node from our perspective.</li>
</ul>
<p>We need a few more considerations to understand the application of the Minmax algorithm on the Tic-Tac-Toe game:</p>
<ul>
<li>
<strong class="inline _idGenCharOverride-1">is_end_state</strong>
 is a function that determines whether the state should be evaluated instead of digging deeper, either because the game has ended, or because the game is about to end using forced moves. Using our utility function, it is safe to say that as soon as we reach a score of 1,000 or higher, we have effectively won the game. Therefore, <strong class="inline _idGenCharOverride-1">is_end_state</strong>
 can simply check the score of a node and determine whether we need to dig deeper.</li>
<li>Although the <strong class="inline _idGenCharOverride-1">successors</strong>
 function only depends on the state, it is practical to pass the information of whose turn it is to make a move. Therefore, don't hesitate to add an argument if needed; you don't have to follow the pseudocode.</li>
<li>We want to minimize our efforts in implementing the Minmax algorithm. For this reason, we will evaluate existing implementations of the algorithm, and we will also simplify the duality of the description of the algorithm in the rest of this topic.</li>
<li>The suggested utility function is quite accurate compared to utility functions that we could be using in this algorithm. In general, the deeper we go, the less accurate our utility function has to be. For instance, if we could go nine steps deep into the Tic-Tac-Toe game, all we would need to do is award 1 point for a win, zero for a draw, and -1 point for a loss. Given that, in nine steps, the board is complete, and we have all of the necessary information to make the evaluation. If we could only look four steps deep, this utility function would be completely useless at the start of the game, because we need at least five steps to win the game.</li>
<li class="_idGenParaOverride-3">The Minmax algorithm could be optimized further by pruning the tree. Pruning is an act where we get rid of branches that don't contribute to the end result. By eliminating unnecessary computations, we save precious resources that could be used to go deeper into the tree.</li>
<li style="list-style: none; display: inline"><div></div>
</li>
</ul>
<h3 id="_idParaDest-57"><a id="_idTextAnchor061"></a>
 Optimizing the Minmax Algorithm with Alpha-Beta Pruning</h3>
<p>The last consideration in the previous thought process primed us to explore possible optimizations on reducing the search space by focusing our attention on nodes that matter.</p>
<p>There are a few constellations of nodes in the tree, where we can be sure that the evaluation of a subtree does not contribute to the end result. We will find, examine, and generalize these constellations to optimize the Minmax algorithm.</p>
<p>Let's examine pruning through the previous example of nodes:</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer036" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00018.jpg" alt="Figure 2.12 Search tree demonstrating pruning nodes" />
</div>
</div>
<h6>Figure 2.13: Search tree demonstrating pruning nodes</h6>
<p>After computing the nodes with values 101, 23, and 110, we can conclude that two levels above, the value 101 will be chosen. Why?</p>
<ul>
<li>Suppose X &lt;= 110. Then the maximum of 110 and X will be chosen, which is 110, and X will be omitted.</li>
<li>Suppose X &gt; 110. Then the maximum of 110 and X is X. One level above, the algorithm will choose the lowest value out of the two. The minimum of 101 and X will always be 101, because X &gt; 110. Therefore, X will be omitted a level above.</li>
</ul>
<p>This is how we prune the tree.</p>
<p class="_idGenParaOverride-3">On the right-hand side, suppose we computed branches 10 and 21. Their maximum is 21. The implication of computing these values is that we can omit the computation of nodes Y1, Y2, and Y3, and we will know that the value of Y4 is less than or equal to 21. Why?</p>
<div></div>
<p>The minimum of 21 and Y3 is never greater than 21. Therefore, Y4 will never be greater than 21.</p>
<p>We can now choose between a node with utility 101, and another node with a maximal utility of 21. It is obvious that we have to choose the node with utility 101.</p>
<div class="_idGenObjectLayout-1">
<div id="_idContainer037" class="IMG---Figure"><img class="_idGenObjectAttribute-1" src="Image00019.jpg" alt="Figure 2.13 Example of pruning a tree" />
</div>
</div>
<h6>Figure 2.14: Example of pruning a tree</h6>
<p>This is the idea behind alpha-beta pruning. We prune subtrees that we know are not going to be needed.</p>
<p>Let's see how we can implement alpha-beta pruning in the Minmax algorithm.</p>
<p>First, we will add an alpha and a beta argument to the argument list of Minmax:</p>
<p class="snippet">def min_max(state, depth, is_maximizing, alpha, beta):</p>
<p class="snippet">    if depth == 0 or is_end_state(state):</p>
<p class="snippet">    &amp;#9;return utility(state)</p>
<p class="snippet">    if is_maximizing:</p>
<p class="snippet">        utility = 0</p>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = MinMax(s, depth - 1, false, alpha, beta)</p>
<p class="snippet">            utility = max(utility, score)</p>
<p class="snippet">        return utility</p>
<p class="snippet _idGenParaOverride-3">    else</p>
<div></div>
<p class="snippet">        utility = infinity</p>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = MinMax(s, depth - 1, true, alpha, beta)</p>
<p class="snippet">            utility = min(utility, score)</p>
<p class="snippet">        return utility</p>
<p>For the <strong class="inline _idGenCharOverride-1">isMaximizing</strong>
 branch, we calculate the new alpha score, and break out of the loop whenever <strong class="inline _idGenCharOverride-1">beta &lt;= alpha</strong>
 :</p>
<p class="snippet">def min_max(state, depth, is_maximizing, alpha, beta):</p>
<p class="snippet">    if depth == 0 or is_end_state(state):</p>
<p class="snippet">    &amp;#9;return utility(state)</p>
<p class="snippet">    if is_maximizing:</p>
<p class="snippet">        utility = 0</p>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = MinMax(s, depth - 1, false, alpha, beta)</p>
<p class="snippet">            utility = max(utility, score)</p>
<p class="snippet">            alpha = max(alpha, score)</p>
<p class="snippet">            if beta &lt;= alpha:</p>
<p class="snippet">                break</p>
<p class="snippet">        return utility</p>
<p class="snippet">    else</p>
<p class="snippet">        utility = infinity</p>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = MinMax(s, depth - 1, true, alpha, beta)</p>
<p class="snippet">            utility = min(utility, score)</p>
<p class="snippet">        return utility</p>
<p>We need to do the dual for the minimizing branch:</p>
<p class="snippet">def min_max(state, depth, is_maximizing, alpha, beta):</p>
<p class="snippet">    if depth == 0 or is_end_state( state ):</p>
<p class="snippet">    &amp;#9;return utility(state)</p>
<p class="snippet">    if is_maximizing:</p>
<p class="snippet _idGenParaOverride-3">        utility = 0</p>
<div></div>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = min_max(s, depth - 1, false, alpha, beta)</p>
<p class="snippet">            utility = max(utility, score)</p>
<p class="snippet">            alpha = max(alpha, score)</p>
<p class="snippet">            if beta &lt;= alpha: break</p>
<p class="snippet">        return utility</p>
<p class="snippet">    else</p>
<p class="snippet">        utility = infinity</p>
<p class="snippet">        for s in successors(state):</p>
<p class="snippet">            score = min_max(s, depth - 1, true, alpha, beta)</p>
<p class="snippet">            utility = min(utility, score)</p>
<p class="snippet">            beta = min(beta, score)</p>
<p class="snippet">            if beta &lt;= alpha: break</p>
<p class="snippet">        return utility</p>
<p>We are done with the implementation. It is recommended that you mentally execute the algorithm on our example tree step-by-step to get a feel for the implementation.</p>
<p>One important piece is missing that's preventing us from doing the execution properly: the initial values for alpha and beta. Any number that's outside the possible range of utility values will do. We will use positive and negative infinity as initial values to call the Minmax algorithm:</p>
<p class="snippet">alpha = infinity</p>
<p class="snippet">beta = -infinity</p>
<h3 id="_idParaDest-58"><a id="_idTextAnchor062"></a>
 DRYing up the Minmax Algorithm â€“ The NegaMax Algorithm</h3>
<p>The Minmax algorithm works great, especially with alpha-beta pruning. The only problem is that we have an if and an else branch in the algorithm that essentially negate each other.</p>
<p class="_idGenParaOverride-3">As we know, in computer science, there is DRY code and WET code. DRY stands for Don't Repeat Yourself. Wet stands for We Enjoy Typing. When we write the same code twice, we double our chance of making a mistake while writing it. We also double our chances of each maintenance effort being executed in the future. Hence, it's better to reuse our code.</p>
<div></div>
<p>When implementing the Minmax algorithm, we always compute the utility of a node from the perspective of the AI player. This is why we have to have a utility-maximizing branch and a utility-minimizing branch in the implementations that are dual in nature. As we prefer clean code that describes the problem only once, we could get rid of this duality by changing the point of view of the evaluation.</p>
<p>Whenever the AI player's turn comes, nothing changes in the algorithm.</p>
<p>Whenever the opponent's turn comes, we negate the perspective. Minimizing the AI player's utility is equivalent to maximizing the opponent's utility.</p>
<p>This simplifies the Minmax algorithm:</p>
<p class="snippet">def Negamax(state, depth, is_players_point_of_view):</p>
<p class="snippet">    if depth == 0 or is_end_state(state):</p>
<p class="snippet">        return utility(state, is_players_point_of_view)</p>
<p class="snippet">    utility = 0</p>
<p class="snippet">    for s in successors(state):</p>
<p class="snippet">        score = Negamax(s,depth-1,not is_players_point_of_view)</p>
<p class="snippet">    return score</p>
<p>There are necessary conditions for using the Negamax algorithm: the evaluation of the board state has to be symmetric. If a game state is worth +20 from the first player's perspective, it is worth -20 from the second player's perspective. Therefore, we often normalize the scores around zero.</p>
<h3 id="_idParaDest-59"><a id="_idTextAnchor063"></a>
 Using the EasyAI Library</h3>
<p>We have seen the <strong class="inline _idGenCharOverride-1">simpleai</strong>
 library that helped us execute searches on pathfinding problems. We will now use the EasyAI library, which can easily handle AI search on two player games, reducing the implementation of the Tic-Tac-Toe problem to writing a few functions on scoring the utility of a board and determining when the game ends.</p>
<p class="_idGenParaOverride-3">You can read the documentation of the library on GitHub at <a href="https://github.com/Zulko/easyAI">https://github.com/Zulko/easyAI</a>
 .</p>
<div></div>
<p>To install the EasyAI library, run the following command:</p>
<p class="snippet">pip install easyai</p>
<h4>Note</h4>
<p class="callout">As always, if you are using Anaconda, you must execute this command in the Anaconda prompt, and not in the Jupyter QtConsole.</p>
<p>Once EasyAI is available, it makes sense to follow the structure of the documentation to describe the Tic-Tac-Toe problem.This implementation was taken from <a href="https://zulko.github.io/easyAI/examples/games.html">https://zulko.github.io/easyAI/examples/games.html</a>
 , where the Tic-Tac-Toe problem is described in a compact and elegant way:</p>
<p class="snippet">from easyAI import TwoPlayersGame</p>
<p class="snippet">from easyAI.Player import Human_Player</p>
<p class="snippet">class TicTacToe( TwoPlayersGame ):</p>
<p class="snippet">    """ The board positions are numbered as follows:</p>
<p class="snippet">            7 8 9</p>
<p class="snippet">            4 5 6</p>
<p class="snippet">            1 2 3</p>
<p class="snippet">    """    </p>
<p class="snippet">    def __init__(self, players):</p>
<p class="snippet">        self.players = players</p>
<p class="snippet">        self.board = [0 for i in range(9)]</p>
<p class="snippet">        self.nplayer = 1 # player 1 starts.</p>
<p class="snippet">    </p>
<p class="snippet">    def possible_moves(self):</p>
<p class="snippet">        return [i+1 for i,e in enumerate(self.board) if e==0]</p>
<p class="snippet _idGenParaOverride-3">    </p>
<div></div>
<p class="snippet">    def make_move(self, move):</p>
<p class="snippet">        self.board[int(move)-1] = self.nplayer</p>
<p class="snippet">    def unmake_move(self, move): # optional method (speeds up the AI)</p>
<p class="snippet">        self.board[int(move)-1] = 0</p>
<p class="snippet">    </p>
<p class="snippet">    def lose(self):</p>
<p class="snippet">        """ Has the opponent "three in line ?" """</p>
<p class="snippet">        return any( [all([(self.board[c-1]== self.nopponent)</p>
<p class="snippet">                      for c in line])</p>
<p class="snippet">                      for line in [[1,2,3],[4,5,6],[7,8,9],</p>
<p class="snippet">                                   [1,4,7],[2,5,8],[3,6,9],</p>
<p class="snippet">                                   [1,5,9],[3,5,7]]])</p>
<p class="snippet">        </p>
<p class="snippet">    def is_over(self):</p>
<p class="snippet">        return (self.possible_moves() == []) or self.lose()</p>
<p class="snippet">        </p>
<p class="snippet">    def show(self):</p>
<p class="snippet">        print ('\n'+'\n'.join([</p>
<p class="snippet">                        ' '.join([['.','O','X'][self.board[3*j+i]]</p>
<p class="snippet">                        for i in range(3)])</p>
<p class="snippet">                 for j in range(3)]) )</p>
<p class="snippet">                </p>
<p class="snippet">    def scoring(self):</p>
<p class="snippet">        return -100 if self.lose() else 0</p>
<p class="snippet">    </p>
<p class="snippet">if __name__ == "__main__":</p>
<p class="snippet">    </p>
<p class="snippet">    from easyAI import AI_Player, Negamax</p>
<p class="snippet">    ai_algo = Negamax(6)</p>
<p class="snippet">    TicTacToe( [Human_Player(),AI_Player(ai_algo)]).play()</p>
<p>In this implementation, the computer player never loses thanks to the Negamax algorithm exploring the search criterion in a depth of 6.</p>
<p>Notice the simplicity of the scoring function. Wins or losses can guide the AI player to reach the goal of never losing a game.</p>
<h3 id="_idParaDest-60"><a id="_idTextAnchor064"></a>
 Activity 4: Connect Four</h3>
<p>In this section, we will practice using the <strong class="bold _idGenCharOverride-2">EasyAI</strong>
 library and develop a heuristic. We will be using the game Connect 4 for this. The game board is seven cells wide and seven cells high. When you make a move, you can only select the column in which you drop your token. Then, gravity pulls the token down to the lowest possible empty cell. Your objective is to connect four of your own tokens horizontally, vertically, or diagonally, before your opponent does, or you run out of empty spaces. The rules of the game can be found at <a href="https://en.wikipedia.org/wiki/Connect_Four">https://en.wikipedia.org/wiki/Connect_Four</a>
 .</p>
<p>We can leave a few functions from the definition intact. We have to implement the following methods:</p>
<ul>
<li>
<strong class="inline _idGenCharOverride-1">__init__</strong>
</li>
<li>
<strong class="inline _idGenCharOverride-1">possible_moves</strong>
</li>
<li>
<strong class="inline _idGenCharOverride-1">make_move</strong>
</li>
<li>
<strong class="inline _idGenCharOverride-1">unmake_move (optional)</strong>
</li>
<li>
<strong class="inline _idGenCharOverride-1">lose</strong>
</li>
<li>
<strong class="inline _idGenCharOverride-1">show</strong>
</li>
</ul>
<ol>
<li class="ParaOverride-1" value="1">We will reuse the basic scoring function from Tic-Tac-Toe. Once you test out the game, you will see that the game is not unbeatable, but plays surprisingly well, even though we are only using basic heuristics.</li>
<li value="2">Then, let's write the <strong class="inline _idGenCharOverride-1">init</strong>
 method. We will define the board as a one-dimensional list, like the Tic-Tac-Toe example. We could use a two-dimensional list too, but modeling will not get much easier or harder. We will generate all of the possible winning combinations in the game and save them for future use.</li>
<li class="_idGenParaOverride-3" value="3">Let's handle the moves. The possible moves function is a simple enumeration. Notice that we are using column indices from 1 to 7 in the move names, because it is more convenient to start column indexing with 1 in the human player interface than with zero. For each column, we check whether there is an unoccupied field. If there is one, we will make the column a possible move.<div></div>
</li>
<li value="4">Making a move is similar to the possible moves function. We check the column of the move and find the first empty cell, starting from the bottom. Once we find it, we occupy it. You can also read the implementation of the dual of the <strong class="inline _idGenCharOverride-1">make_move</strong>
 function: <strong class="inline _idGenCharOverride-1">unmake_move</strong>
 . In the <strong class="inline _idGenCharOverride-1">unmake_move</strong>
 function, we check the column from top to bottom, and we remove the move at the first non-empty cell. Notice that we rely on the internal representation of <strong class="inline _idGenCharOverride-1">easyAi</strong>
 so that it does not undo moves that it has not made. If we didn't, this function would remove one of the other player's tokens without checking whose token was removed.</li>
<li value="5">As we already have the tuples that we have to check, we can mostly reuse the lose function from the Tic-Tac-Toe example.</li>
<li value="6">Our last task is to implement the show method that prints the board. We will reuse the Tic-Tac-Toe implementation and just change the variables.</li>
<li value="7">Now that all of the functions are complete, you can try out the example. Feel free to play a round or two against the opponent. You can see that the opponent is not perfect, but it plays reasonably well. If you have a strong computer, you can increase the parameter of the Negamax algorithm. I encourage you to come up with a better heuristic.<h4 class="_idGenParaOverride-4">Note</h4>
<p class="callout _idGenParaOverride-4">The solution for this activity can be found on page 265.</p>
</li>
</ol>
<h2 id="_idParaDest-61"><a id="_idTextAnchor065"></a>
 Summary</h2>
<p>In this chapter, we learned how to apply search techniques to play games.</p>
<p>First, we created a static approach that played the Tic-Tac-Toe game based on predefined rules without looking ahead. Then, we quantified these rules into a number we called heuristics. In the next topic, we learned how to use heuristics in the A* search algorithm to find an optimal solution to a problem.</p>
<p>Finally, we got to know the Minmax and the NegaMax algorithms so that the AI could win two-player games.</p>
<p>Now that you know the fundamentals of writing game AI, it is time to learn about a different field within artificial intelligence: machine learning. In the next chapter, you will learn about regression.</p>
</div>
</body></html>