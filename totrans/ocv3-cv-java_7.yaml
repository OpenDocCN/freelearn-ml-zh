- en: Chapter 7. OpenCV on the Server Side
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the Internet gets more and more interactive, a subject of great interest
    is how to deal with image processing on the server side that enables you to create
    web applications dealing with OpenCV. As Java is among the languages of choice
    when developing web apps, this chapter shows the entire architecture of an application
    that lets users upload an image and add a fedora hat on top of detected faces
    using techniques learned throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an OpenCV web application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mixed reality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image uploading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with HTTP requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter you will know how to create a complete web application
    with image processing, obtain input from the user, process the image on the server
    side, and return the processed image to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up an OpenCV web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since this chapter covers the development of a web application using Java OpenCV,
    it is important to address a couple of differences when going to the server side.
    The first thing is to tell the web container, generally Tomcat, Jetty, JBoss,
    or Websphere, about the location of native libraries. Other details deal with
    loading the native code. This should happen as soon as the web server goes up
    and should not occur again.
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of using the web architecture are significant. As certain image-processing
    tasks are compute intensive, they could easily drain the device's battery in no
    time, so, taking them to a more robust hardware on the cloud would relieve local
    processing. Besides that, there's no need for users to install anything more than
    the web browser, and the updates happening on the server side are also very handy.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, there are a few drawbacks. If, instead of hosting the web
    application on the administrator infrastructure, one intends to host it on Java
    servers online, it should be clear whether it allows native code to be run or
    not. At the time of writing, Google's App Engine does not allow it, but it is
    easy to set up a Linux server on Amazon EC2 or Google's Compute Engine that smoothly
    runs it although this won't be covered in this book. Another thing to be considered
    is that several computer vision applications need to be run in real time, even
    at the rate of 20 frames per second, for instance, which would be impractical
    in a web architecture, due to long upload times, and this type of application
    should be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create our web application, we will go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Maven-based web application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding OpenCV dependencies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running the web application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Importing the project to Eclipse.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following sections, we will cover these steps in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Maven-based web application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are several ways to create web applications in Java. Spring MVC, Apache
    Wicket, and Play Framework are all great options among others. Also, on top of
    these frameworks, we can put JavaServer Faces, PrimeFaces, or RichFaces as component-based
    user interfaces for these web applications. For this chapter though, instead of
    addressing all these technologies, the approach will be to only use servlets for
    you to choose your frameworks. You should notice that a servlet is simply a Java
    class used to extend the capabilities of a server, and this is generally used
    to process or store data that was submitted through an HTML form. The servlet
    API has been around since 1997, so it has been exhaustively used, and there are
    several books and samples about it. Although this chapter focuses on Servlet 2.x
    for simplicity, we need to be aware that the API is synchronous and that it might
    be better to use an asynchronous one, such as Servlet 3.x, for applications that
    will receive several clients together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although any IDE can easily generate a web application through a wizard—such
    as going to Eclipse and navigating to **File** | **New** | **Project…** | **Web**
    | **Dynamic Web Project**—we''ll focus on starting it with the help of Maven since
    we can easily get native dependencies. As long as it has been installed correctly
    according to instructions in [Chapter 1](ch01.html "Chapter 1. Setting Up OpenCV
    for Java"), *Setting Up OpenCV for Java*, Maven can set up a web application through
    the use of a prototype. This is achieved through the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This command will call the `generate` goal from the `archetype` plugin. Think
    of `archetype` as a project template. This Maven plugin will generate a web application
    from a template because we have set `archetypeArtifactId` as `maven-archetype-webapp`
    through the `-DarchetypeArtifactId=maven-archetype-webapp` option. The other option,
    `DartifactId=my-webapp`, will simply set the folder name of the web application
    as defined in this option, while `groupId` is Maven's universally unique identifier
    for a project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the following structure will be created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Maven-based web application](img/3972OS_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding is a simple structure for a web application. You should pay attention
    to the `web.xml` file, which is used for mapping servlets, as well as `index.jsp`,
    which is a simple Java Server Page file. By now you should be able to run this
    web application in Tomcat, for instance, with little effort. Simply type the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if the you access the address `http://localhost:8080/my-webapp/`, the
    following response should be seen in the browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating a Maven-based web application](img/3972OS_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that it means that we have successfully created a web project, we are
    running it through a Tomcat web container, and it is available through `localhost`
    server, in port `8080`, through the name `my-webapp`. The `Hello World!` message
    can be seen in `index.jsp`. In the following section, you are going to customize
    the `pom` file in order to add OpenCV dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Adding OpenCV dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since the web application archetype has created a project structure for us,
    we are going to add OpenCV dependencies for the generated `pom.xml`. If you open
    it, you will see the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the only dependency is on `junit`. Now add the following to the
    dependencies tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The first two dependencies, `opencvjar` and `opencvjar-runtime`, are the same
    ones that have been discussed in [Chapter 1](ch01.html "Chapter 1. Setting Up
    OpenCV for Java"), *Setting Up OpenCV for Java*. Now, the dependency on `javax.servlet-api`
    refers to the servlet API version 3.0.1, which is used to make files upload more
    easily. Besides using these dependencies, all other configurations are mentioned
    in [Chapter 1](ch01.html "Chapter 1. Setting Up OpenCV for Java"), *Setting Up
    OpenCV for Java*, such as adding the `JavaOpenCVBook` repository, `maven-jar-plugin`,
    `maven-dependency-plugin`, and `maven-nativedependencies-plugin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only new plugin is `tomcat7` as we would require it to use the file upload
    API from `servlet 3.0`. In order to add the `tomcat7` plugin, look for the `<plugins>`
    section in `pom.xml` and add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Besides adding the ability to run `tomcat7` from Maven, it will also configure
    port `9090` as the default port for our server, but you can use another one. The
    final `pom.xml` file can be found in this chapter's source code project. Running
    an `mvn package` command will show that everything's been fine in the project
    setup. In the next section, we are going to check all the processes through a
    simple OpenCV call from the .`jsp` file.
  prefs: []
  type: TYPE_NORMAL
- en: Running the web application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that all the dependencies have been set up, it should be straightforward
    to run our web application. One detail should be noticed, though. Since our application
    relies on native code, the `opencv_java300.dll` file, or the shared object, we
    should put it in the Java library path prior to running the Tomcat server. There
    are several approaches to doing this, depending on your deployment strategy, but
    a simple one could be setting the path through the `MAVEN_OPTS` environment variable.
    You should type the following command in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Please remember to change `your_path` to the place you are setting up your
    project, the parent folder of `my-webapp`. In order to check that the application
    server can correctly load OpenCV native libraries, we are going to set up a simple
    servlet which is able to output the correct installed version. Change the `index.jsp`
    file generated in your `my-webapp\src\main\webapp` folder to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Now, run your server typing `mvn tomcat7:run`. Try loading your application
    in your web browser at the address `http://localhost:9090`, and you should see
    the page outputting your loaded OpenCV version. Although this code doesn't really
    load native libraries, since `Core.VERSION` can be retrieved from pure Java JAR,
    it's not a good practice to mix business code—the one that really does your image
    processing—with your presentation code, that is, the Java Server Page we just
    edited. In order to deal with image processing, we are going to concentrate the
    code in a servlet that only deals with it.
  prefs: []
  type: TYPE_NORMAL
- en: Importing the project to Eclipse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that the project is all set up with Maven, it should be easy to import
    it to Eclipse. Simply issue the following Maven command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember to add the `-Dwtpversion=2.0` flag to add support for WTP version
    2.0, which is Eclipse''s Web Tools platform. If you have not set up your `M2_REPO`
    as explained in [Chapter 1](ch01.html "Chapter 1. Setting Up OpenCV for Java"),
    *Setting Up OpenCV for Java*, a simple trick can automate it for you. Type the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `YOUR_WORKSPACE_PATH` path should be changed to something similar to `C:\Users\baggio\workspace`
    if that is where your Eclipse workspace is located.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Eclipse, navigate through **File** | **Import** | **General** | **Existing
    Projects** into the workspace and point to your `my-webapp` folder. Notice that
    your Eclipse should have WTP support. In case you receive a `Java compiler level
    does not match the version of the installed Java project facet` message, simply
    right-click it and in the **Quick Fix** menu, choose **Change Java Project Facet
    version to Java 1.8**. Now you can run it by right-clicking in your project, navigating
    to **Run as** | **Run on Server**, selecting **Apache** | **Tomcat v7.0 Server**,
    and hitting **Next**. If you don''t have an existing Tomcat 7 installation, select
    **Download and Install**, as shown in the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Importing the project to Eclipse](img/3972OS_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Select a folder for your Tomcat7 installation and click on **Next** and **Finish**.
    Now, you can run your application directly from Eclipse, by right-clicking on
    your project and clicking on **Run as** | **Run on Server**. In case you receive
    a "java.lang.UnsatisfiedLinkError: no opencv_java300 in java.library.path", right-click
    your project, "Run As ->Run Configurations..." and in the Arguments tab, in the
    VM arguments text box, add the -Djava.library.path="C:\path_to_your\target\natives".
    Click in "Apply" and restart your server by going to the Server tab and right-clicking
    your Tomcat7 execution -> Restart.'
  prefs: []
  type: TYPE_NORMAL
- en: Mixed reality web applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The web application we are going to develop draws Fedora hats on top of the
    detected heads in a given image. In order to do this, the user uploads the image
    through a simple form, and then it is converted to an OpenCV matrix in memory.
    After conversion, a cascade classifier looking for faces is run over the matrix.
    A simple scale and a translation are applied to estimate the hat's position and
    scale. A transparent fedora image is then drawn on the specified position for
    each of the detected faces. The result is then returned through HTTP by giving
    the mixed reality picture to the user. Notice that all the processing happens
    on the server side, so the client is only left to upload and download the image,
    which is very useful for clients that rely on batteries, such as smartphones.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Mixed reality (MR), sometimes referred to as hybrid reality (encompassing
    both augmented reality and augmented virtuality), refers to the merging of real
    and virtual worlds to produce new environments and visualisations where physical
    and digital objects co-exist and interact in real time. Not taking place only
    in the physical world or the virtual world, but a mix of reality and virtual reality,
    encompassing augmented reality and augmented virtuality.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Source: Fleischmann, Monika; Strauss, Wolfgang (eds.) (2001). Proceedings
    of »CAST01//Living in Mixed Realities« Intl. Conf. On Communication of Art, Science
    and Technology, Fraunhofer IMK 2001, 401\. ISSN 1618–1379 (Print), ISSN 1618–1387
    (Internet).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This web application can be divided into a couple of simpler steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Image upload.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Image processing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Response image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following sections will cover these steps in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Image upload
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Firstly, we are going to turn our dummy Java Server Page into a form that will
    require the user to choose a local file, similar to the one seen in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image upload](img/3972OS_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following code shows the complete Java Server Page. Note the form element,
    which states that it will call a `post` method being processed in the `doPost`
    part of the servlet and requests that the web server to accept the data enclosed
    in the form for storage. The `enctype= "multipart/form-data"` states that no characters
    are going to be encoded, as can be seen in the `"text/plain"` encryption type,
    which converts spaces to `+` symbols. Another important attribute is `action="upload"`.
    It makes sure that the data encoded in the form is sent to the "`/upload`" URL.
    The input element with the type "file" simply works as a call to the operating
    system''s file dialog, which pops up and lets the user specify the file location.
    Finally, the input element with the "submit" type deals with sending the request
    with form data when the button is clicked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'When pressing the **Submit** button, a stream of bytes is sent to the server,
    which will forward them to a servlet called `Upload`. Note that mapping from the
    `/upload` URL to the `Upload` servlet happens in the `/src/main/webapp/WEB-INF/web.xml`
    file, as shown in the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Pay attention to the fact that, when the user hits the **Submit** button from
    the form, the `doPost` method from the mapped servlet class, `UploadServlet`,
    is called. This method is the core of this web application, and we are going to
    see it in detail in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The main action in the `doPost` method starts by loading the OpenCV library,
    as seen in the previous chapters, and then loading the cascade which will be used
    later for face detection. For the sake of brevity, the initialization is made
    here, but in actual code, you should use `ServletContextListener` in order to
    initialize it. Then, the `receiveImage` method deals with receiving bytes from
    the upload and converting it to an OpenCV matrix. So, the other methods take care
    of loading the fedora hat image and detecting people''s faces so that the overlay
    can be drawn through the `detectFaceAndDrawHat` method. Finally, the `writeResponse`
    method answers the request. We will cover `receiveImage` in more detail in the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `receiveImage` simply grabs bytes from an upload request in `receiveImageBytes`
    and then converts them to a matrix. The following is the code for `receiveImageBytes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the default code to receive an upload. It accesses the "file" field
    from the form and gets its stream through `request.getPart("file").getInputStream()`.
    Then, a buffer is created, so all data from the input stream is written through
    the `write()` method as long as there''s data from the upload. The byte array
    is then returned through the `ByteArrayOutputStream` class''s `toByteArray()`
    method. Since what we have received at this point is just a bunch of bytes, there
    is a need to decode the image format and convert it to an OpenCV matrix. Fortunately,
    there''s already a method that does that, `imdecode`, from the `Imgcodecs` package,
    the signature of which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `buf` argument is a `Mat` buffer that we will create from the byte array,
    and `flags` is an option used to convert the `Mat` buffer returned to grayscale
    or color, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The complete code for the decoding can be seen in the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now it's done, we have received the user's image upload, and it is converted
    to our well-known `Mat` class. It's now time to create the mixed reality.
  prefs: []
  type: TYPE_NORMAL
- en: Image processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to describe how to process the received image
    in order to draw an image file on top of it. Now, a cascade classifier is run
    just as in the previous chapter. It is important to pay attention to the XML cascade
    file location. Throughout the code, we have used a helper function called `getResourcePath`,
    and we have used the convention of storing all the resources in the `src/main/resources/`
    folder. This way, the helper function works in a manner similar to that of the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this function, one can load a cascade through the following call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After the cascade has been correctly loaded, we are all set, and now it is
    time to explain how the hat''s position is estimated. When running the face classifier,
    we have a good idea not only of the face''s position, but also of the face''s
    bounding rectangle. We will use this width to estimate the width of the hat. We
    can suppose that the width of the hat would be three times the face''s bounding
    rectangle width. This way, we still need to keep the hat''s aspect ratio. This
    is done with a simple rule of three, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image processing](img/3972OS_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that the virtual hat's dimensions are defined, we still need to estimate
    its location. From a couple of tests, we could infer that 60 percent above the
    face's bounding rectangle should be fine for most of the pictures. Now, we have
    the hat's dimensions and position. In the end, instead of using the hat's width
    as three times the face's width, a value of 2.3 times the face's width seemed
    to work better. The following code shows the math used to set the **region of
    interest** (**ROI**) to draw the fedora as implemented in the method `detectFaceAndDrawHat`.
    A simple adjustment is made to the hat's dimensions when it goes beyond the bounds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot gives us an overview of the widths and the process
    of drawing the fedora overlay:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image processing](img/3972OS_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It is time to draw the hat! This should be as simple as locating the hat''s
    position in the picture and copying the submatrix. We need to be careful, though,
    to correctly draw transparent pixels and not draw outside the picture. Mat''s
    `copyTo` method is used to copy a submatrix into another one. This method also
    accepts a mask Mat parameter, the nonzero elements of which indicate which matrix
    elements must be copied. Notice that the hat image itself is passed as the mask
    parameter, and it actually works because all transparent pixels are made zero
    in all channels and all other pixels will have some value, working like a mask.
    The code to resize the fedora and copy it to the main image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The response image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have successfully received an image and drawn hats over identified faces.
    Now, it''s time to send the result back to the user. We do this by setting the
    content type of our response as `image/jpeg`, for instance. We then encode our
    response with the same format as defined in our header—if it is jpeg, we will
    encode it in JPEG—and write the bytes in our response servlet object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The input image and the output result appear in the following screenshot. Some
    fedora hats are distributed to Einstein and his friends in our augmented reality
    web application. The left-hand side photo is the uploaded image, while the right-hand
    side photo shows the hats drawn over the detected faces. According to our loop,
    hats will be drawn in the same order that detected faces are returned. This way,
    we can''t grant a correct Z-order, which is what hat is drawn on top of another
    although we could try to infer it from face size. This is shown in the following
    images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The response image](img/3972OS_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[http://www.nobelprize.org/nobel_prizes/physics/laureates/1921/einstein-photo.html](http://www.nobelprize.org/nobel_prizes/physics/laureates/1921/einstein-photo.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we sent our computer vision applications to the server-side
    world. We started covering the basics of a simple servlet-based web application
    configuration using Maven, which provided us with a general application structure.
    We then added OpenCV dependencies to our `pom.xml` configuration file as used
    in a standard OpenCV desktop application. We then checked other runtime configurations
    as we deployed our web server using Maven.
  prefs: []
  type: TYPE_NORMAL
- en: With every webapp configuration aspect solved, we moved on to the development
    of our mixed reality application that explored the details of image uploading,
    converting it to an OpenCV Mat object and then writing a response to our clients
    with a processed image.
  prefs: []
  type: TYPE_NORMAL
- en: It seems that all aspects of creating basic computer vision applications have
    been covered now. We dealt with setting up OpenCV for Java and then learned how
    to work with matrices. We then touched on the basics of creating Java Swing desktop
    applications and worked with image-processing algorithms to filter, change image
    morphology, and do essential thresholding. You also learned tools that are in
    every computer vision researcher's toolkit, such as Hough transformations to find
    lines and circles as well as special kernel convolution. We covered the important
    Fourier transform and warp operations. We then dived into machine learning and
    used handy OpenCV cascades, and you also learned how to create new object classifiers.
    Besides this, we studied certain background removal approaches and tested the
    incredible Kinect device to perform depth-based processing. We finally finished
    the book with a complete server-side example, and now, you are ready to count
    on Java for your own computer vision projects!
  prefs: []
  type: TYPE_NORMAL
