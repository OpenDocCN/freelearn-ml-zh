- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building Regression Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about classification models. In this chapter,
    we will learn about building **linear regression** models where we predict numeric
    variables. Unlike classification models, linear regression models are used to
    predict a **continuous numeric value**. Similar to the previous chapter, here
    also you will learn about various methods that Redshift provides for creating
    linear regression models.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will provide several detailed examples of business problems that
    can be solved with these modeling techniques. In this chapter, we will walk through
    how you can try different algorithms to get the best regression model.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be in a position to identify whether a
    business problem is a linear regression or not and then be able to identify the
    right method that Redshift provides to train and build the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go through the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing regression algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a simple regression model using the XGBoost algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating multi-input regression models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires a web browser and access to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift Serverless endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Redshift Query Editor v2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find the code used in this chapter here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter7/chapter7.sql](https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter7/chapter7.sql)'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing regression algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regression models are used where you are trying to predict a numeric outcome
    such as what price an item will sell for. The outcome variable is your target
    and your input variables are used to determine the relationship between the variables
    so that you can predict the unknown target on sets of data without the target
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: You can have a single input variable, also known as **simple linear regression**.
    For example, years of experience and salary usually have a relationship.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple linear regression** is when you have multiple input variables. For
    example, predicting the selling price of homes in a particular zip code by using
    the relationship between the target (price) and various inputs such as square
    footage, number of bedrooms, pool, basement, lot size, and year built.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A good linear regression model has a small amount of vertical distance between
    the line and the data points. Refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Linear regression line](img/B19071_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Linear regression line
  prefs: []
  type: TYPE_NORMAL
- en: 'Common use cases where regression models are useful are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Price and revenue prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting customer lifetime value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the weather
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring the effectiveness of marketing campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will show you how to build regression models in Amazon Redshift
    ML using the XGBoost and Linear Learner algorithms, which you used in [*Chapter
    6*](B19071_06.xhtml#_idTextAnchor083). As you will see, you can use the same algorithms
    on different machine learning problems.
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at the regression problem; now let’s look at the Redshift `CREATE
    MODEL` command to create a regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Redshift’s CREATE MODEL with user guidance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using the `CREATE MODEL` command in Redshift, the system will automatically
    search for the best combination of preprocessing and model for your specific dataset.
    However, in some cases, you may want additional control over the model creation
    process or to incorporate domain-specific knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Redshift offers flexibility to guide the `CREATE MODEL` process so the time
    taken by the AutoML job is reduced.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to explore the model type and problem type parameters of the `CREATE
    MODEL` statement in this chapter. As part of `CREATE MODEL` with user guidance,
    you also have the option of setting a preprocessor, but we will leave that topic
    for [*Chapter 10*](B19071_10.xhtml#_idTextAnchor178).
  prefs: []
  type: TYPE_NORMAL
- en: When you are guiding the AutoML job, as a machine learning model creator, you
    are going to decide what algorithm to use and what problem type to address. Redshift
    ML still performs the feature engineering of independent variables behind the
    scenes – for example, out of 20 features, Redshift ML will automatically identify
    the categorical variables and numeric variables and create a one-hot-encoded value
    or standardization of numerical variables where applicable, along with various
    other tasks required to complete the model training.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, you are letting Redshift ML handle the bulk of data preparation
    tasks for machine learning. As a model creator, you have the option to specify
    the algorithm and problem type to be used in the `CREATE MODEL` statement, which
    has the benefit of reduced training time, since SageMaker does not need to spend
    time determining which algorithm or problem type to use.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned what `CREATE MODEL` with user guidance is, let’s start
    creating a simple regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple linear regression model using XGBoost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To build our simple linear regression problem, we are going to take a look at
    a dataset that includes predicting weight based on height. This dataset has only
    one independent variable, which is height in inches, and is used to predict weight
    in pounds. Since there is only one independent variable, we call this the **simple
    linear** **regression** model.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will upload the data, analyze it, prepare it for training
    the model, and then lastly, we will create the model and run prediction queries
    using the function created by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Uploading and analyzing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to work on a height and weight dataset in this section.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains 25,000 synthetic records of human heights and weights of
    18-year-old participants. This data was generated based on a 1993 Growth Survey,
    which was conducted on 25,000 children from their birth to 18 years of age. The
    participants were recruited from **Maternal and Child Health Centers** (**MCHCs**)
    and schools, and the data collected was used to develop Hong Kong’s current growth
    charts for weight, height, weight-for-age, weight-for-height, and **body mass**
    **index** (**BMI**).
  prefs: []
  type: TYPE_NORMAL
- en: 'More details about this dataset can be found here: [http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights](http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_Dinov_020108_HeightsWeights).'
  prefs: []
  type: TYPE_NORMAL
- en: Dataset citation
  prefs: []
  type: TYPE_NORMAL
- en: 'Hung-Kwan So, Edmund AS Nelson, Albert M Li, Eric MC Wong, Joseph TF Lau, Georgia
    S Guldan, Kwok-Hang Mak, Youfa Wang, Tai-Fai Fok, and Rita YT Sung. (2008) *Secular
    changes in height, weight, and body mass index in Hong Kong Children*. BMC Public
    Health. 2008; 8: 320\. doi: 10.1186/1471-2458-8-320\. PMCID: PMC2572616'
  prefs: []
  type: TYPE_NORMAL
- en: 'Leung SS, Lau JT, Tse LY, Oppenheimer SJ. *Weight-for-age and weight-for-height
    references for Hong Kong children from birth to 18 years*. J Paediatr Child Health.
    1996;32:103–109\. doi: 10.1111/j.1440-1754.1996.tb00904.x.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Leung SS, Lau JT, Xu YY, Tse LY, Huen KF, Wong GW, Law WY, Yeung VT, Yeung
    WK, et al. *Secular changes in standing height, sitting height and sexual maturation
    of Chinese–the Hong Kong Growth Study, 1993*. Ann Hum Biol. 1996;23:297–306\.
    doi: 10.1080/03014469600004532.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following subsections, we will discuss the prediction goals we are trying
    to achieve using this dataset and then analyze the data.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction goal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The goal is to predict the weight of children as a numeric value based on supplied
    height as a numeric value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset has the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Column** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Index | Sequential number |'
  prefs: []
  type: TYPE_TB
- en: '| Height in Inches | Height of a child as a numerical value |'
  prefs: []
  type: TYPE_TB
- en: '| Weight in Pounds | Weight of a child as a numerical value |'
  prefs: []
  type: TYPE_TB
- en: Table 7.1 – Data definition
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After successfully connecting to Redshift as an admin or database developer,
    create the schema and load data into Amazon Redshift as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to **Redshift query editor v2** and connect to the **Serverless** endpoint
    and then the **dev** database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the untitled query editor by saving it as `Chapter7`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows a serverless connection, the database set to
    `Chapter7`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Connecting to the Serverless endpoint](img/B19071_07_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Connecting to the Serverless endpoint
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the schema as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a table using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the sample data by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Analyze the height and weight dataset table by creating a histogram chart.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the Query Editor v2 **Chart** feature to create a graph. First, run the
    following command and then click on the **Chart** option found on the right-hand
    side in the **Results** pane:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To generate the following chart, you need to add two traces to your chart. By
    default, the chart is loaded with one trace, so you need to add one additional
    trace. You can add it by clicking on the **+** **Trace** button.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following chart shows both variables. For *trace 1*, select **heightinches**
    on the *y* axis, leaving the *x* axis empty. For *trace 2*, select **weightpounds**
    on the *y* axis, leaving the *x* axis empty. The resulting chart should look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Weights and heights](img/B19071_07_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Weights and heights
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there is a slight upward trend in weights along with heights.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have analyzed our dataset, we will split it into training and validation
    sets. The training set will be used to train our model and the validation set
    will be used to evaluate the model’s accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting data into training and validation sets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since we have only one dataset, let’s write a query that splits data into two
    logical sets: training and validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the model, let’s use the syntax *where id%8 is not equal* *to 0*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To validate the model, let’s use *where id%8 is equal* *to 0*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We have analyzed and prepared our input data, now let’s create a machine learning
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a simple linear regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will use `CREATE MODEL` with user guidance to create a
    simple linear regression model using the XGBoost algorithm. We will address the
    weight prediction problem by training a machine learning model. The goal of this
    model is to predict a weight based on a given height.
  prefs: []
  type: TYPE_NORMAL
- en: 'We set `MODEL_TYPE` as `xgboost` and `PROBLEM_TYPE` as `regression`. We leave
    other options as default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Let’s take a look at the options we provided in the `CREATE MODEL` statement
    and discuss how they affect the actions taken by Amazon SageMaker
  prefs: []
  type: TYPE_NORMAL
- en: In the `CREATE MODEL` statement, we are guiding Redshift ML to use XGBoost as
    an algorithm by setting `MODEL_TYPE`. The Amazon SageMaker Autopilot job will
    not train the model using other supported algorithms – for example, **Linear Learner**
    or **multilayer perceptron** (**MLP**). When this option is left as default, Amazon
    SageMaker will train the model using all the algorithms supported by Autopilot.
  prefs: []
  type: TYPE_NORMAL
- en: Next, when we set `PROBLEM_TYPE` to `regression`, we are guiding Redshift ML
    to search for a model to solve a regression problem type.
  prefs: []
  type: TYPE_NORMAL
- en: We set `OBJECTIVE` to `mse` (**mean squared error**), which is commonly used
    to evaluate the performance of a regression model. It is a measure of the average
    of the squared differences between the predicted values and the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: With these three guiding options, we are creating boundaries for Amazon SageMaker
    Autopilot. The end result would be less training time bundled with other benefits
    of the Autopilot algorithm – for example, adjusting hyperparameters and data preprocessing
    steps, which are all auto-handled by Amazon SageMaker Autopilot.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check the status of the model, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of the `SHOW` `MODEL` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – SHOW MODEL output](img/B19071_07_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: The model is still under training, but you will notice that Redshift ML is picking
    up `CREATE` `MODEL` statement.
  prefs: []
  type: TYPE_NORMAL
- en: The `predict_weight`, is used to generate predictions and is used in the `SELECT`
    statement, which we will cover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the `SHOW MODEL` command again after some time to check whether the model
    training is complete or not. From the following screenshot, you can see that model
    training has finished and MSE has been selected as the objective for model evaluation.
    This is auto-selected by the Redshift ML and is the correct evaluation method
    for linear regression models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – SHOW MODEL output – model ready state](img/B19071_07_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – SHOW MODEL output – model ready state
  prefs: []
  type: TYPE_NORMAL
- en: We have trained and created the model; in the next step, we will generate the
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Running predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since our model has been successfully trained, let’s run some predictions against
    unseen datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following query to find records where the model is exactly predicting
    weight in pounds for a given height in inches where `id%8=0`. By using `WHERE
    id%8=0`, we are looking at ~20% of our dataset. These are records that were not
    included in model training. If you recall, in the `CREATE MODEL` statement, we
    specified `WHERE` `id%8 !=0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Showing predicted weight results](img/B19071_07_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Showing predicted weight results
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s check the MSE and **root mean square** **error** (**RMSE**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – MSE and RMSE values](img/B19071_07_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – MSE and RMSE values
  prefs: []
  type: TYPE_NORMAL
- en: Our MSE value is high; it represents data that may have outliers or for which
    we do not have enough variables. For example, adding age and gender may improve
    the prediction score.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare predicted scores and original scores in a line chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Once a response is returned, click on the **Chart** option found on the right-hand
    side in the Query Editor, add a trace for the line, and select **Predicted_Weightpounds**.
    Add another trace for the line chart and select **Original_Weightpounds**, then
    add a third trace, but this time, select **Bar graph** and add a **Difference**
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following chart, you will notice that the predicted scores are following
    the original scores. The difference is shown at the bottom of the graph, which
    gives information about the variance or error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – Predicted versus original weights](img/B19071_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – Predicted versus original weights
  prefs: []
  type: TYPE_NORMAL
- en: We have learned about how a simple regression model is created using Redshift
    ML. Now let’s learn about the multi-input regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating multi-input regression models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this exercise, you will learn how to build a regression model using multiple
    input variables in Amazon Redshift ML.
  prefs: []
  type: TYPE_NORMAL
- en: In this use case, we will use a dataset containing the sales history of online
    sporting events. A sporting event management company wants to review the data
    for the latest football and baseball seasons to figure out which games underperformed
    for revenue, and what the revenue projections look like for the season.
  prefs: []
  type: TYPE_NORMAL
- en: Your task is to build and train a model to predict revenue for upcoming events
    in order to proactively take action to increase ticket sales to ensure revenue
    numbers meet the company’s targets.
  prefs: []
  type: TYPE_NORMAL
- en: After successfully connecting to Redshift as an admin or database developer,
    load data into Amazon Redshift.
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to **Redshift query editor v2** and connect to the **Serverless** endpoint
    and the **dev** database.
  prefs: []
  type: TYPE_NORMAL
- en: Use the same schema and **query editor** page you created for the previous exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create your input table and load the data using the following SQL commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s analyze our dataset and get a historical trend of ticket sales over the
    last few months:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Ticket revenue by month](img/B19071_07_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Ticket revenue by month
  prefs: []
  type: TYPE_NORMAL
- en: We can see that sales are spiky and fall off dramatically in months **7** and
    **8**. Let’s create a model so we can predict teams that will have lower ticket
    revenue. Before creating our model, we need to split the dataset into training,
    validation, and testing datasets, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following code in Query Editor v2 to create the `training` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next step is to insert ~70% of the data into the `training` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, you will create the `validation` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, insert ~10% of the data into the `validation` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, create the `testing` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, insert ~20% of the data into the `testing` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We have prepared the dataset to train and test the ML model; now let’s create
    a regression model using the Linear Learner algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Learner algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in [*Chapter 6*](B19071_06.xhtml#_idTextAnchor083), you can use the
    Linear Learner model type to solve classification or regression problems. This
    is a supervised learning algorithm. For regression problems, we are trying to
    predict a numerical outcome and, in this exercise, we will be using multiple inputs;
    SageMaker will choose the best modes based on continuous objectives using MSE.
  prefs: []
  type: TYPE_NORMAL
- en: We provide a training set with data that contains our inputs or observations
    about the data and the label, which represents the value we want to predict. Our
    goal is to accurately predict future ticket sales.
  prefs: []
  type: TYPE_NORMAL
- en: We set `MODEL_TYPE` as `LINEAR_LEARNER`, `PROBLEM_TYPE` as `regression`, and
    `OBJECTIVE` as `mse`. We leave out other options as default.
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in Query Editor v2 to train the model. Be sure to replace
    the following S3 bucket using the bucket you created previously. You will need
    to input the S3 bucket you created previously to store the Redshift ML artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to train the regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model state is **READY**, you are ready to proceed. To check the status
    of the model, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the MSE score you see; it will be similar to the output in *Figure 7**.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – SHOW MODEL output](img/B19071_07_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: We have now created the ML model; let’s validate its performance.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding model evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You measure the model performance of regression problems through the MSE and/or
    RMSE. This is the distance between the predicted numeric target and the actual
    numeric answer, also known as `SHOW MODEL` output, we see the MSE. We can also
    calculate this ourselves by squaring the differences between the actual and predicted
    values and then finding the average. Then, take the square root of MSE to get
    the RMSE. The lower the MSE and RMSE scores, the better.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we see from the `SHOW MODEL` output, our MSE score is over 681 – let’s check
    this and the RMSE score against our validation by running the following SQL command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output of the query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – MSE and RMSE values](img/B19071_07_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – MSE and RMSE values
  prefs: []
  type: TYPE_NORMAL
- en: 'While the MSE scores seem a little high, we can also run a validation query
    to check our accuracy rates. You will notice in the following query that it uses
    the function that was generated by our `CREATE MODEL` command to get the predicted
    price revenue for us to compare to the actual price revenue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output of the query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Predicted price versus actual price](img/B19071_07_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 – Predicted price versus actual price
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the results, the model is not performing as well as we would like.
    You can run the validation query against the training data and see that the model
    is not performing very well on the training data either – this is called **underfitting**.
  prefs: []
  type: TYPE_NORMAL
- en: One solution would be to add more features, but we have already used all the
    available features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try running the model again, but this time, we will use the `auto` option
    and let SageMaker pick the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'After letting the model train for some time, check the status of the model
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how it appears:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – SHOW MODEL output](img/B19071_07_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – SHOW MODEL output
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding figure, we see that two things stand out:'
  prefs: []
  type: TYPE_NORMAL
- en: The MSE score is much better
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon SageMaker chose to use the XGBoost algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can check the MSE and RMSE scores for our new model using our validation
    dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – MSE and RMSE scores](img/B19071_07_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 – MSE and RMSE scores
  prefs: []
  type: TYPE_NORMAL
- en: These MSE and RMSE values show that we have a good model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run a validation query using the `predict_ticket_price_auto` function
    from the new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output for this query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.15 – Predicted price versus actual price](img/B19071_07_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 – Predicted price versus actual price
  prefs: []
  type: TYPE_NORMAL
- en: You can see we have much better results when comparing the differences between
    the actual and predicted ticket price revenue. We will use this model to do our
    prediction queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following query to see which inputs contributed most to the model prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'To make the result set easier to read, right-click on the result set and choose
    **Copy rows**. You can then paste that into the editor as shown in *Figure 7**.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16 – Model explainability report](img/B19071_07_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 – Model explainability report
  prefs: []
  type: TYPE_NORMAL
- en: This shows that `list_ticket_price` contributed the most weight and `sport`
    contributed the least weight.
  prefs: []
  type: TYPE_NORMAL
- en: We have validated the model with a validation dataset, checked the MSE values,
    and determined feature importance. Now let’s run the prediction query against
    test data.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction query
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have our model and have done validation, we can run our prediction
    query against our test dataset to determine which teams and events will need a
    proactive approach to increase ticket sales. Let’s check for teams with a predicted
    revenue of less than 200K:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17 – Predicted price against the test dataset](img/B19071_07_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 – Predicted price against the test dataset
  prefs: []
  type: TYPE_NORMAL
- en: There are 16 teams that are predicted to have reduced ticket revenue. You can
    share this information with your marketing teams to create a focused strategy
    to ensure ticket revenues can remain on track.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed regression models in detail and saw how to create
    single-input and multi-input regression models. We learned how easy it is to predict
    a numeric value. We also learned how to validate regression models, take actions
    to improve our model’s accuracy, and do prediction queries with our regression
    models. We walked through options for using XGBoost, Linear Learner and `auto`
    options to train your model.
  prefs: []
  type: TYPE_NORMAL
- en: We also saw how we can check and validate the MSE score from the `SHOW MODEL`
    output using SQL commands in Redshift.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will show you how to create unsupervised models using
    the K-means algorithm.
  prefs: []
  type: TYPE_NORMAL
