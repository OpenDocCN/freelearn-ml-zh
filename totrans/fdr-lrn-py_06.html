<html><head></head><body>
		<div id="_idContainer063">
			<h1 id="_idParaDest-151" class="chapter-number"><a id="_idTextAnchor156"/>6</h1>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor157"/>Running the Federated Learning System and Analyzing the Results</h1>
			<p>In this chapter, you will run the <strong class="bold">federated learning</strong> (<strong class="bold">FL</strong>) system that has been discussed in previous chapters and analyze the system behaviors and the outcomes of the aggregated models. We will start by explaining the configuration of the FL system components in order to run the systems properly. Basically, after installing the simple FL system provided by our GitHub sample, you first need to pick up the server machines or instances to run the database and aggregator modules. Then, you can run agents to connect to the aggregator that is already running. The IP address of the aggregator needs to be correctly set up in each agent-side configuration. Also, there is a simulation mode so that you can run all the components on the same machine or laptop to just test the functionality of the FL system. After successfully running all the modules of the FL system, you will be able to see the data folder and a database created under the path that you set up in the database server as well as on the agent side. You will be able to check both the local and global models, trained and aggregated, so that you can download the recent or best-performing models from the data folders.</p>
			<p>In addition, you can also see examples of running the FL system on a minimal engine and image classification. By reviewing the outcomes of the generated models and the performance data, you can understand the aggregation algorithms as well as the actual interaction of the models between an aggregator and agents.</p>
			<p>In this chapter, we will cover the following main topics:</p>
			<ul>
				<li>Configuring and running the FL system</li>
				<li>Understanding what happens when the minimal example runs</li>
				<li>Running image classification and analyzing the results</li>
			</ul>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor158"/>Technical requirements</h1>
			<p>All the code files introduced in this chapter can be found on GitHub (https://github.com/tie-set/simple-fl).</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You can use the code files for personal or educational purposes. Please note that we will not support deployments for commercial use and will not be responsible for any errors, issues, or damages caused by using the code.</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor159"/>Configuring and running the FL system</h1>
			<p>Configuring the FL system<a id="_idIndexMarker475"/> and installing its<a id="_idIndexMarker476"/> environment are simple enough to do. Follow the instructions in the next subsections.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor160"/>Installing the FL environment</h2>
			<p>First, to run the FL system <a id="_idIndexMarker477"/>discussed in the previous chapter, clone the following repository to the machines that you want to run FL on using the following command:</p>
			<p class="source-code"><strong class="bold">git clone https://github.com/tie-set/simple-fl</strong></p>
			<p>Once done with the cloning process, change the directory to the <strong class="source-inline">simple-fl</strong> folder in the command line. The simulation run can be carried out using just one machine or using multiple systems. In order to run the FL process on one or multiple machines that include the FL server (aggregator), FL client (agent), and database server, you should create a <strong class="source-inline">conda</strong> virtual environment and activate it.</p>
			<p>To create a <strong class="source-inline">conda</strong> environment in macOS, you will need to type the following command:</p>
			<p class="source-code">conda env create -n federatedenv -f ./setups/federatedenv.yaml</p>
			<p>If you’re using a Linux machine, you can create the <strong class="source-inline">conda</strong> environment by using the following command:</p>
			<p class="source-code">conda env create -n federatedenv -f ./setups/federatedenv_linux.yaml</p>
			<p>Then, activate the <strong class="source-inline">conda</strong> environment <strong class="source-inline">federatedenv</strong> when you run the code. For your information, the <strong class="source-inline">federatedenv.yaml</strong> and <strong class="source-inline">federatedenv_linux.yaml</strong> files can be found in the <strong class="source-inline">setups</strong> folder of the <strong class="source-inline">simple-fl</strong> GitHub repository and include the libraries that are used in the code examples throughout this book.</p>
			<p>As noted in the <strong class="source-inline">README</strong> file of the GitHub repo, there are mainly three components to run: the database server, aggregator, and agent(s). If you want to conduct a simulation within one machine, you can just install a <strong class="source-inline">conda</strong> environment (<strong class="source-inline">federatedenv</strong>) on that machine.</p>
			<p>If you want to create a distributed <a id="_idIndexMarker478"/>environment, you need to install the <strong class="source-inline">conda</strong> environment on all the machines you want to use, such as the database server on a cloud instance, the aggregator server on a cloud instance, and the local client machine.</p>
			<p>Now that the installation process for the entire FL process is ready, let’s move on to configuring the FL system with configuration files.</p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor161"/>Configuring the FL system with JSON files for each component </h2>
			<p>First, edit the configuration<a id="_idIndexMarker479"/> JSON files in the <strong class="source-inline">setups</strong> folder of the provided GitHub repository. These JSON files are read by a database server, aggregator, and agents to configure their initial setups. Again, the configuration details are explained as follows.</p>
			<h3>config_db.json</h3>
			<p>The <strong class="source-inline">config_db.json</strong> file deals with configuring a database server. Use the following information to properly <a id="_idIndexMarker480"/>operate the server:</p>
			<ul>
				<li><strong class="source-inline">db_ip</strong>: The database server’s IP address (for example, <strong class="source-inline">localhost</strong>). If you want to run the database server on a cloud<a id="_idIndexMarker481"/> instance, such as an <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) EC2 instance, you can specify the private IP address of the instance. </li>
				<li><strong class="source-inline">db_socket</strong>: The socket number used between the database and aggregator (for example, <strong class="source-inline">9017</strong>).</li>
				<li><strong class="source-inline">db_name</strong>: The name of the SQLite database (for example, <strong class="source-inline">sample_data</strong>).</li>
				<li><strong class="source-inline">db_data_path</strong>: The path to the SQLite database (for example, <strong class="source-inline">./db</strong>).</li>
				<li><strong class="source-inline">db_model_path</strong>: The<a id="_idIndexMarker482"/> path to the directory to save all <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) models (for example, <strong class="source-inline">./db/models</strong>).</li>
			</ul>
			<h3>config_aggregator.json</h3>
			<p>The <strong class="source-inline">config_aggregator.json</strong> file deals with configuring an aggregator in the FL server. Use the following<a id="_idIndexMarker483"/> information to properly operate the aggregator:</p>
			<ul>
				<li><strong class="source-inline">aggr_ip</strong>: The aggregator’s IP address (for example, <strong class="source-inline">localhost</strong>). If you want to run the aggregator server on a cloud instance, such as an AWS EC2 instance, you can specify the private IP address of the instance.</li>
				<li><strong class="source-inline">db_ip</strong>: The database server’s IP address (for example, <strong class="source-inline">localhost</strong>). If you want to connect to the database server hosted on a different cloud instance, you can specify the public IP address of the database instance. If you host the database server on the same cloud instance as the aggregator’s instance, you can specify the same private IP address of the instance.</li>
				<li><strong class="source-inline">reg_socket</strong>: The socket number used by agents to connect to an aggregator for the first time (for example, <strong class="source-inline">8765</strong>).</li>
				<li><strong class="source-inline">recv_socket</strong>: The socket number used to upload local models or poll to an aggregator from an agent. Agents will learn this socket information by communicating with an aggregator (for example, <strong class="source-inline">7890</strong>).</li>
				<li><strong class="source-inline">exch_socket</strong>: The socket number used to send global models back to an agent from an aggregator when a push method is used. Agents will learn this socket information by communicating with an aggregator (for example, <strong class="source-inline">4321</strong>).</li>
				<li><strong class="source-inline">db_socket</strong>: The socket number used between the database and an aggregator (for example, <strong class="source-inline">9017</strong>).</li>
				<li><strong class="source-inline">round_interval</strong>: The period of time after which an agent checks whether there are enough models to start an aggregation step (unit: seconds; for example, <strong class="source-inline">5</strong>).</li>
				<li><strong class="source-inline">aggregation_threshold</strong>: The percentage of collected local models required to start an aggregation step (for example, <strong class="source-inline">0.85</strong>).</li>
				<li><strong class="source-inline">polling</strong>: The flag to<a id="_idIndexMarker484"/> specify whether to use a polling method or not. If the flag is <strong class="source-inline">1</strong>, use the polling method; if the flag is <strong class="source-inline">0</strong>, use a push method. This value needs to be the same between the aggregator and agent.</li>
			</ul>
			<h3>config_agent.json</h3>
			<p>The <strong class="source-inline">config_agent.json</strong> file deals with configuring an agent in the FL client. Use the following information to properly operate the agent:</p>
			<ul>
				<li><strong class="source-inline">aggr_ip</strong>: The aggregator<a id="_idIndexMarker485"/> server’s IP address (for example, <strong class="source-inline">localhost</strong>). If you want to connect to the aggregator server hosted on a cloud instance, such as an AWS EC2 instance, you can specify the public IP address of the aggregator instance.</li>
				<li><strong class="source-inline">reg_socket</strong>: The socket number used by agents to join an aggregator for the first time (for example, <strong class="source-inline">8765</strong>).</li>
				<li><strong class="source-inline">model_path</strong>: The path to a local director in the agent machine to save local and global models and some state information (for example, <strong class="source-inline">./data/agents</strong>).</li>
				<li><strong class="source-inline">local_model_file_name</strong>: The filename to save local models in the agent machine (for example, <strong class="source-inline">lms.binaryfile</strong>).</li>
				<li><strong class="source-inline">global_model_file_name</strong>: The filename to save local models in the agent machine (for example, <strong class="source-inline">gms.binaryfile</strong>).</li>
				<li><strong class="source-inline">state_file_name</strong>: The filename to store the agent state in the agent machine (for example, <strong class="source-inline">state</strong>).</li>
				<li><strong class="source-inline">init_weights_flag</strong>: <strong class="source-inline">1</strong> if the weights are initialized with certain values, <strong class="source-inline">0</strong> otherwise, where weights are initialized with zeros.</li>
				<li><strong class="source-inline">polling</strong>: The flag to specify whether to use a polling method or not. If the flag is <strong class="source-inline">1</strong>, use the polling method; if the flag is <strong class="source-inline">0</strong>, use a push method. This value needs to be<a id="_idIndexMarker486"/> the same between the aggregator and agent.</li>
			</ul>
			<p>Now, the FL systems can be configured using the configuration files explained in this section. Next, you will run the database and aggregator on the FL server side.</p>
			<h2 id="_idParaDest-157"><a id="_idTextAnchor162"/>Running the database and aggregator on the FL server</h2>
			<p>In this section, you will <a id="_idIndexMarker487"/>configure the database and aggregator on the FL server side. Then, you will edit the configuration files in the <strong class="source-inline">setups</strong> folder of the <strong class="source-inline">simple-fl</strong> GitHub repo. After that, you will run <strong class="source-inline">pseudo_db</strong> first, and<a id="_idIndexMarker488"/> then <strong class="source-inline">server_th</strong>, as follows:</p>
			<p class="source-code">python -m fl_main.pseudodb.pseudo_db</p>
			<p class="source-code">python -m fl_main.aggregator.server_th</p>
			<p class="callout-heading">Important note </p>
			<p class="callout">If the database server and aggregator server are running on different machines, you will need to specify the IP address of the database server or instance of the aggregator. The IP address of the database server can be modified in the <strong class="source-inline">config_aggregator.json</strong> file in the <strong class="source-inline">setups</strong> folder. Also, if both the database and aggregator instances are running in public cloud environments, the IP address of the configuration files of those servers needs to be the private IP address. Agents need to connect to the aggregator using the public IP address and the connecting socket (port number) needs to be open to accept inbound messages.</p>
			<p>After you start the database and aggregator servers, you will see a message such as the following in the console:</p>
			<pre class="source-code">
# Database-side Console Example
INFO:root:--- Pseudo DB Started ---</pre>
			<p>On the aggregator <a id="_idIndexMarker489"/>side of the console, you will see something like the following:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Aggregator Started ---</pre>
			<p>Behind this aggregator <a id="_idIndexMarker490"/>server, the model synthesis module is running every 5 seconds, where it starts checking whether the number of collected local models is more than the number that the aggregation threshold defines. </p>
			<p>We have now run the database and aggregator modules and are ready to run a minimal example with the FL client.</p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor163"/>Running a minimal example with the FL client</h2>
			<p>In the previous<a id="_idIndexMarker491"/> chapter, we talked about the integration of local ML engines into the FL system. Here, using a minimal sample that does not have actual training data, we will try to run the FL systems that have been discussed. This minimal example can be used as a template when implementing any locally distributed ML engine.</p>
			<p>Before running the minimal example, you should check whether the database and aggregator servers are running already. Then, run the following command: </p>
			<p class="source-code">python -m examples.minimal.minimal_MLEngine</p>
			<p>In this case, only one agent with a minimal ML engine is connected. Thus, the aggregation happens every time this default agent uploads the local model. </p>
			<p>Note that if the aggregator server is running on a different machine, you will need to specify the public IP address of the aggregator server or instance. The IP address of the aggregator can be modified in the <strong class="source-inline">config_agent.json</strong> file in the <strong class="source-inline">setups</strong> folder. We also recommend setting the <strong class="source-inline">polling</strong> flag to <strong class="source-inline">1</strong> when running the aggregator and database in a cloud instance.</p>
			<p><em class="italic">Figure 6.1</em> shows an example<a id="_idIndexMarker492"/> of the console screen when running a database server:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B18369_06_01.jpg" alt="Figure 6.1 – Example of a database-side console&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Example of a database-side console</p>
			<p><em class="italic">Figure 6.2</em> shows an example of the console screen when running an aggregator:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B18369_06_02.jpg" alt="Figure 6.2 – Example of an aggregator-side console&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Example of an aggregator-side console</p>
			<p><em class="italic">Figure 6.3</em> shows an <a id="_idIndexMarker493"/>example of the console screen when running an agent:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B18369_06_03.jpg" alt="Figure 6.3 – Example of an agent-side console&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Example of an agent-side console</p>
			<p>Now we know how to<a id="_idIndexMarker494"/> run all the FL components: a database, aggregator, and agent. In the next section, we will examine how outputs are generated by running the FL system.</p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor164"/>Data and database folders</h2>
			<p>After running the FL system, you<a id="_idIndexMarker495"/> will notice that the database folder and data folder are created under the locations that you specified in the config files of the database and agent.</p>
			<p>For example, the <strong class="source-inline">db</strong> folder is created under <strong class="source-inline">db_data_path</strong>, written in the <strong class="source-inline">config_db.json</strong> file. In the database folder, you will find the SQLite database, such as <strong class="source-inline">model_data12345.db</strong>, where the metadata of local and cluster global models is stored, as well as a <strong class="source-inline">models</strong> folder that contains all the actual local models uploaded by the agents and global models created by the aggregator.</p>
			<p><em class="italic">Figure 6.4</em> shows the SQLite database and ML model files in a binary file format stored in the <strong class="source-inline">db</strong> folder created by running the minimal example code:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B18369_06_04.jpg" alt="Figure 6.4 – The SQLite database and ML model files in a binary file format stored in the db folder&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.4 – The SQLite database and ML model files in a binary file format stored in the db folder</p>
			<p>The <strong class="source-inline">data</strong> folder is created under an agent device at the location of the <strong class="source-inline">model_path</strong>, a string value <a id="_idIndexMarker496"/>defined in <strong class="source-inline">config_agent.json</strong>. In the example run of the minimal example, the following files are created under the <strong class="source-inline">data/agents/default-agent</strong> folder:</p>
			<ul>
				<li><strong class="source-inline">lms.binaryfile</strong>: A binary file containing a local model created by the agent</li>
				<li><strong class="source-inline">gms.binaryfile</strong>: A binary file containing a global model created by the aggregator sent back to the agent</li>
				<li><strong class="source-inline">state</strong>: A file that has an integer value that indicates the state of the client itself</li>
			</ul>
			<p><em class="italic">Figure 6.5</em> shows the structure of the agent-side data, which includes global and local ML models represented with a binary file format, as well as the file reflecting the FL client state:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B18369_06_05.jpg" alt="Figure 6.5 – Data of the agents including global and local ML models with a binary file format as well as the client state&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Data of the agents including global and local ML models with a binary file format as well as the client state</p>
			<p>Now we understand where the key data, such as global and local models, is stored. Next, we will take a closer<a id="_idIndexMarker497"/> look at the database using SQLite.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor165"/>Databases with SQLite</h2>
			<p>The database<a id="_idIndexMarker498"/> created in the <strong class="source-inline">db</strong> folder can be viewed using any tool to show the SQLite database that can open files with the <strong class="source-inline">***.db</strong> format. The database tables are defined in the following sections. </p>
			<h3>Local models in a database</h3>
			<p><em class="italic">Figure 6.6</em> shows sample database<a id="_idIndexMarker499"/> entries related to uploaded local models where each entry lists the local model ID, the time that the model was generated, the ID of the agent that uploaded the local model, round information, performance metrics, and the number of data samples:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B18369_06_06.jpg" alt="Figure 6.6 – Sample database entries related to uploaded local models&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.6 – Sample database entries related to uploaded local models</p>
			<h3>Cluster models in a database</h3>
			<p><em class="italic">Figure 6.7</em> shows sample database entries related to uploaded cluster models where each entry lists the cluster model ID, the time that the model was created, the ID of the aggregator that created this cluster model, round information, and the number of data samples:</p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B18369_06_07.jpg" alt="Figure 6.7 – Sample database entries related to uploaded cluster models&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.7 – Sample database entries related to uploaded cluster models</p>
			<p>Now we have learned <a id="_idIndexMarker500"/>how to configure and run the FL system with a minimal example and how to examine the results. In the next section, you will learn about the behavior of the FL system and what happens when the minimal example is run.</p>
			<h1 id="_idParaDest-161"><a id="_idTextAnchor166"/>Understanding what happens when the minimal example runs</h1>
			<p>Understanding the behavior of the entire FL system step by step will help you design applications with FL enabled and further enhance the FL system itself. Let us first look into what happens when we run just one agent by printing some procedures of the agent and aggregator modules.</p>
			<h2 id="_idParaDest-162"><a id="_idTextAnchor167"/>Running just one minimal agent</h2>
			<p>Let’s run the minimal<a id="_idIndexMarker501"/> agent after running the database and aggregator servers and see what happens. When the agent is started with the minimal ML engine, you will see the following messages in the agent console: </p>
			<pre class="source-code">
# Agent-side Console Example
INFO:root:--- This is a minimal example ---
INFO:root:--- Agent initialized —
INFO:root:--- Your IP is xxx.xxx.1.101 ---</pre>
			<p>When the agent initializes the model to be used for FL, it shows this message, and if you look at the <strong class="source-inline">state</strong> file, it has entered the <strong class="source-inline">sending</strong> state, which will trigger sending models to the aggregator when the FL client is started:</p>
			<pre class="source-code">
# Agent-side Console Example
INFO:root:--- Model template generated ---
INFO:root:--- Local (Initial/Trained) Models saved ---
INFO:root:--- Client State is now sending ---</pre>
			<p>Then, after the client is started with the <strong class="source-inline">start_fl_client</strong> function, the participation message is <a id="_idIndexMarker502"/>sent to the aggregator. Here is the participation message sent to the aggregator:</p>
			<pre class="source-code">
[
        &lt;AgentMsgType.participate: 0&gt;, # Agent Message Type
        'A89fd1c2d9*****', # Agent ID
        '047b18ddac*****',    # Model ID
        {
                'model1': array([[1, 2, 3], [4, 5, 6]]), 
                'model2': array([[1, 2], [3, 4]])
        }, # ML Models
        True,    # Init weights flag
        False, # Simulation flag
        0, # Exch Port
        1645141807.846751, # Generated Time of the models
        {'accuracy': 0.0, 'num_samples': 1}, # Meta information 
        'xxx.xxx.1.101' # Agent's IP Address
]</pre>
			<p>The participation message to the aggregator includes the message type, agent ID, model ID, ML model with NumPy, initialization weights flag, simulation flag, exchange port number, time the models were generated, and meta information such as performance metrics and the agent’s IP address. </p>
			<p>The agent receives the <a id="_idIndexMarker503"/>welcome message from an aggregator confirming the connection of this agent, which also includes the following information:</p>
			<pre class="source-code">
# Agent-side Console Example
INFO:root:--- Init Response: [
        &lt;AggMsgType.welcome: 0&gt;, # Message Type
        '4e2da*****', # Aggregator ID
        '23487*****', # Model ID 
        {'model1': array([[1, 2, 3], [4, 5, 6]]), 
         'model2': array([[1, 2], [3, 4]])}, # Global Models
        1, # FL Round
        'A89fd1c2d9*****', # Agent ID
        '7890', # exch_socket number
        '4321' # recv_socket number
] ---</pre>
			<p>On the aggregator side, after this agent sends a participation message to the aggregator, the aggregator confirms the participation and pushes this initial model to the database:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Participate Message Received ---
INFO:root:--- Model Formats initialized, model names: ['model1', 'model2'] ---
INFO:root:--- Models pushed to DB: Response ['confirmation'] ---
INFO:root:---  Global Models Sent to A89fd1c2d9***** ---
INFO:root:--- Aggregation Threshold (Number of agents needed for aggregation): 1 ---
INFO:root:--- Number of collected local models: 0 ---
INFO:root:--- Waiting for more local models to be collected ---</pre>
			<p>In the database server-side <a id="_idIndexMarker504"/>console, you can also check that the local model is sent from the aggregator and the model is saved in the database:</p>
			<pre class="source-code">
# DB-side Console Example
INFO:root:Request Arrived
INFO:root:--- Model pushed: ModelType.local ---
INFO:root:--- Local Models are saved ---</pre>
			<p>After the aggregator sends the global model back to the agent, the agent receives and saves it and changes the client state from <strong class="source-inline">waiting_gm</strong> to <strong class="source-inline">gm_ready</strong>, indicating the global model is ready for retraining locally:</p>
			<pre class="source-code">
# Agent-side Console Example
INFO:root:--- Global Model Received ---
INFO:root:--- Global Models Saved ---
INFO:root:--- Client State is now gm_ready ---</pre>
			<p>Here is the message sent to the agent from an aggregator, including the global model. The contents of the message include the message type, aggregator ID, cluster model ID, FL round, and ML models with NumPy:</p>
			<pre class="source-code">
[
        &lt;AggMsgType.sending_gm_models: 1&gt;, # Message Type
        '8c6c946472*****', # Aggregator ID
        'ab633380f6*****', # Global Model ID
        1, # FL Round Info 
        {     
                'model1': array([[1., 2., 3.],[4., 5., 6.]]), 
                'model2': array([[1., 2.],[3., 4.]])
        } # ML models
]</pre>
			<p>Then, the agent reads the <a id="_idIndexMarker505"/>global models to proceed with using them for local training and changes the client state to <strong class="source-inline">training</strong>:</p>
			<pre class="source-code">
# Agent-side Console Example
INFO:root:--- Global Models read by Agent ---
INFO:root:--- Client State is now training ---
INFO:root:--- Training ---
INFO:root:--- Training is happening ---
INFO:root:--- Training is happening ---
INFO:root:--- Training Done ---
INFO:root:--- Local (Initial/Trained) Models saved ---
INFO:root:--- Client State is now sending ---
INFO:root:--- Local Models Sent ---
INFO:root:--- Client State is now waiting_gm ---
INFO:root:--- Polling to see if there is any update (shown only when polling) ---
INFO:root:--- Global Model Received ---
INFO:root:--- The global models saved ---</pre>
			<p>After the preceding local training process, the agent proceeds with <strong class="source-inline">sending</strong> the trained local models to the aggregator and changes the client state to <strong class="source-inline">waiting_gm</strong>, which means it waits for the global model with the polling mechanism. </p>
			<p>Here is the message<a id="_idIndexMarker506"/> sent to the aggregator as a trained local model message. The contents of the message include message type, agent ID, model ID, ML models, generated time of the models, and metadata such as performance data:</p>
			<pre class="source-code">
[
        &lt;AgentMsgType.update: 1&gt;, # Agent's Message Type
        'a1031a737f*****', # Agent ID
        'e89ccc5dc9*****', # Model ID
        {
                'model1': array([[1, 2, 3],[4, 5, 6]]), 
                'model2': array([[1, 2],[3, 4]])
        }, # ML Models
            1645142806.761495, # Generated Time of the models
        {'accuracy': 0.5, 'num_samples': 1} # Meta information
]</pre>
			<p>Then, in the aggregator, after the local model is pushed to the database, it shows the change in the buffer, that the number of collected local models is up to 1 from 0, thus indicating that enough local models are collected to start the aggregation:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Models pushed to DB: Response ['confirmation'] ---
INFO:root:--- Local Model Received ---
INFO:root:--- Aggregation Threshold (Number of agents needed for aggregation): 1 ---
INFO:root:--- Number of collected local models: 1 ---
INFO:root:--- Enough local models are collected. Aggregation will start. ---</pre>
			<p>Then, aggregation for round 1 happens and the cluster global models are formed, pushed to the database, and<a id="_idIndexMarker507"/> sent to the agent once the polling message arrives from the agent. The aggregator can also push the message back to the agent via a push method:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:Round 1
INFO:root:Current agents: [{'agent_name': 'default_agent', 'agent_id': 'A89fd1c2d9*****', 'agent_ip': 'xxx.xxx.1.101', 'socket': 7890}]
INFO:root:--- Cluster models are formed ---
INFO:root:--- Models pushed to DB: Response ['confirmation'] ---
INFO:root:--- Global Models Sent to A89fd1c2d9***** ---</pre>
			<p>On the database server side, the cluster global model is received and pushed to the database:</p>
			<pre class="source-code">
# DB-side Console Example
INFO:root:Request Arrived
INFO:root:--- Model pushed: ModelType.cluster ---
INFO:root:--- Cluster Models are saved ---</pre>
			<p>This process in this section is repeated after cluster models are generated and saved for the upcoming FL round and the round of FL proceeds with this interaction mechanism.</p>
			<p>If you look at both the local and cluster global models, they are as follows:</p>
			<pre class="source-code">
{
        'model1': array([[1, 2, 3],[4, 5, 6]]), 
        'model2': array([[1, 2],[3, 4]])
}</pre>
			<p>This means only one fixed model is used all the time even if aggregation happens, so the global model is exactly the same as the initial one as the dummy training process is used here.</p>
			<p>We will now look into the<a id="_idIndexMarker508"/> results when running two minimal agents in the next section.</p>
			<h2 id="_idParaDest-163"><a id="_idTextAnchor168"/>Running two minimal agents</h2>
			<p>With the database and aggregator<a id="_idIndexMarker509"/> servers running, you can run many agents using the <strong class="source-inline">minimal_MLEngine.py</strong> file in the <strong class="source-inline">simple-fl/examples/minimal</strong> folder.</p>
			<p>You should run the two individual agents from different local machines by specifying the IP address of the aggregator to connect those agents with the minimal ML example.</p>
			<p>You can also run multiple agents from the same machine for simulation purposes by specifying the different port numbers for the individual agents.</p>
			<p>In the code provided in the <strong class="source-inline">simple-fl</strong> repository on GitHub, you can run the multiple agents by using the following command:</p>
			<p class="source-code">python -m examples.minimal.minimal_MLEngine [simulation_flag] [gm_recv_port] [agent_name]</p>
			<p>To conduct the simulation, <strong class="source-inline">simulation_flag</strong> should be set to <strong class="source-inline">1</strong>. <strong class="source-inline">gm_recv_port</strong> is the port number to receive the global models from the aggregator. The agent will be notified of the port number by the aggregator through the response of a participation message. Also, <strong class="source-inline">agent_name</strong> is the name of the local agent and the directory name storing the state and model files. This needs to be unique for every agent.</p>
			<p>For instance, you can run the first and second agents with the following commands:</p>
			<p class="source-code"># First agent</p>
			<p class="source-code">python -m examples.minimal.minimal_MLEngine 1 50001 a1</p>
			<p class="source-code"># Second agent</p>
			<p class="source-code">python -m examples.minimal.minimal_MLEngine 1 50002 a2</p>
			<p>You can edit the configuration JSON files in the <strong class="source-inline">setups</strong> folder if needed. In this case, <strong class="source-inline">agg_threshold</strong> is set to <strong class="source-inline">1</strong>.</p>
			<p>When you run the simulation in the database server running a minimal example with multiple agents, the console screen will look similar to that in <em class="italic">Figure 6.1</em>.</p>
			<p><em class="italic">Figure 6.8</em> shows the console screen of a simulation in the aggregator server running a minimal example using dummy ML models:</p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B18369_06_08.jpg" alt="Figure 6.8 – Example of an aggregator-side console running a minimal example connecting two agents&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.8 – Example of an aggregator-side console running a minimal example connecting two agents</p>
			<p><em class="italic">Figure 6.9</em> shows the<a id="_idIndexMarker510"/> console screen of a simulation in one of the agents running a minimal example using dummy ML models:</p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B18369_06_09.jpg" alt="Figure 6.9 – Example of agent 1’s console running a minimal example using dummy ML models&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.9 – Example of agent 1’s console running a minimal example using dummy ML models</p>
			<p><em class="italic">Figure 6.10</em> shows the <a id="_idIndexMarker511"/>console screen of a simulation in another agent running a minimal example using dummy ML models:</p>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B18369_06_10.jpg" alt="Figure 6.10 – Example of agent 2’s console running a minimal example using dummy ML models &#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.10 – Example of agent 2’s console running a minimal example using dummy ML models </p>
			<p>Now we know how to run the<a id="_idIndexMarker512"/> minimal example with two agents. In order to further look into the FL procedure using this example, we will answer the following questions:</p>
			<ul>
				<li>Has aggregation been done correctly for the simple cases?</li>
				<li>Has the <strong class="source-inline">FedAvg</strong> algorithm been applied correctly?</li>
				<li>Does aggregation threshold work with connected agents?</li>
			</ul>
			<p>After running and connecting the two agents, the aggregator will wait to receive two models from the two connected agents, as follows:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Aggregation Threshold (Number of agents needed for aggregation): 2 ---
INFO:root:--- Number of collected local models: 0 ---
INFO:root:--- Waiting for more local models to be collected ---</pre>
			<p>In this case, the aggregation threshold is set to <strong class="source-inline">1.0</strong> in the <strong class="source-inline">config_aggregator.json</strong> file in the <strong class="source-inline">setups</strong> folder, so the aggregator needs to collect all the models from connected agents, meaning it needs to receive local ML models from all the agents that are connected to the aggregator.</p>
			<p>Then, it receives one model<a id="_idIndexMarker513"/> from one of the agents and the number of collected local models is increased to 1. However, as the aggregator is still missing one local model, it does not start aggregation yet: </p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Local Model Received ---
INFO:root:--- Aggregation Threshold (Number of agents needed for aggregation): 2 ---
INFO:root:--- Number of collected local models: 1 ---
INFO:root:--- Waiting for more local models to be collected ---</pre>
			<p>On the agent side, after the local models are sent to the aggregator, it will wait until the cluster global model to be created in the aggregator and sent back to the agent. In this way, you can synchronize the FL process at the agent side and automate the local training procedure when the global model is sent back to the agent and ready for retraining. </p>
			<p>After the aggregator receives another local model, enough models are collected to start the aggregation process:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:--- Local Model Received ---
INFO:root:--- Aggregation Threshold (Number of agents needed for aggregation): 2 ---
INFO:root:--- Number of collected local models: 2 ---
INFO:root:--- Enough local models are collected. Aggregation will start. ---</pre>
			<p>It will finally start the aggregation for the first round, as follows:</p>
			<pre class="source-code">
# Aggregator-side Console Example
INFO:root:Round 1
INFO:root:Current agents: [{'agent_name': 'a1', 'agent_id': '1f503*****', 'agent_ip': 'xxx.xxx.1.101', 'socket': 50001}, {'agent_name': 'a2', 'agent_id': '70de8*****', 'agent_ip': 'xxx.xxx.1.101', 'socket': 50002}]
INFO:root:--- Cluster models are formed ---
INFO:root:--- Models pushed to DB: Response ['confirmation'] ---
INFO:root:--- Global Models Sent to 1f503***** ---
INFO:root:--- Global Models Sent to 70de8***** ---</pre>
			<p>Here, let’s look at the agent-side <a id="_idIndexMarker514"/>ML models that are locally trained:</p>
			<pre class="source-code">
# Agent 1's Console Example
INFO:root:--- Training ---
INFO:root:--- Training is happening ---
INFO:root:--- Training Done ---
Trained models: {'model1': array([[1, 2, 3],
             [4, 5, 6]]), 'model2': array([[1, 2],
             [3, 4]])}
INFO:root:--- Local (Initial/Trained) Models saved ---</pre>
			<p>Also, let’s look at another agent’s ML models that are locally trained:</p>
			<pre class="source-code">
# Agent 2's Console Example
INFO:root:--- Training ---
INFO:root:--- Training is happening ---
INFO:root:--- Training Done ---
Trained models: {'model1': array([[3, 4, 5],
             [6, 7, 8]]), 'model2': array([[3, 4],
             [5, 6]])}
INFO:root:--- Local (Initial/Trained) Models saved ---</pre>
			<p>As in the models sent to the aggregator from agents 1 and 2, if <strong class="source-inline">FedAvg</strong> is correctly applied, the global model should be the averaged value of these two models. In this case, the number of data samples is the<a id="_idIndexMarker515"/> same for both agents 1 and 2, so the global model should just be an average of the two models.</p>
			<p>So, let’s look at the global models that are generated in the aggregator:</p>
			<pre class="source-code">
# Agent 1 and 2's Console Example
Global Models: {'model1': array([[2., 3., 4.],
             [5., 6., 7.]]), 'model2': array([[2., 3.],
             [4., 5.]])}</pre>
			<p>The received model is the average of the two local models and thus averaging has been correctly conducted.</p>
			<p>The database and data folders are created in the <strong class="source-inline">model_path</strong> specified in the agent configuration file. You can look at the database values with an SQLite viewer application and look for some models based on the model ID.</p>
			<p>Now that we understand what’s happening with minimal example runs, in the next section, we will run a real ML application using an image classification model using a <strong class="bold">Convolutional Neural Network</strong> (<strong class="bold">CNN</strong>).</p>
			<h1 id="_idParaDest-164"><a id="_idTextAnchor169"/>Running image classification and analyzing the results</h1>
			<p>This example demonstrates the <a id="_idIndexMarker516"/>use of this FL framework for image <a id="_idIndexMarker517"/>classification tasks. We will use a famous image dataset, CIFAR-10 (URL: <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a>), to show how an ML model grows through the FL process over time. However, this example is only given for the purposes of using the FL system we have discussed so far and is not focused on maximizing the performance of the image classification task.</p>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor170"/>Preparing the CIFAR-10 dataset</h2>
			<p>The following is the <a id="_idIndexMarker518"/>information required related to the dataset size, the training and test data, the number of classes, and the image size:</p>
			<ul>
				<li>Dataset size: 60,000 images</li>
				<li>Training data: 50,000 images</li>
				<li>Test data: 10,000 images</li>
				<li>Number of classes: 10 (<strong class="source-inline">airplane</strong>, <strong class="source-inline">automobile</strong>, <strong class="source-inline">bird</strong>, <strong class="source-inline">cat</strong>, <strong class="source-inline">deer</strong>, <strong class="source-inline">dog</strong>, <strong class="source-inline">frog</strong>, <strong class="source-inline">horse</strong>, <strong class="source-inline">ship</strong>, and <strong class="source-inline">truck</strong>)</li>
				<li>Each class has 6,000 images</li>
				<li>Image size: 32x32 pixels, in color</li>
			</ul>
			<p><em class="italic">Figure 6.11</em> shows a collection of sample pictures of 10 different classes in the dataset with 10 random images for each:</p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B18369_06_11.jpg" alt="Figure 6.11 – The classes in the dataset as well as 10 random images for each category (the images are adapted from https://www.cs.toronto.edu/~kriz/cifar.html)&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.11 – The classes in the dataset as well as 10 random images for each category (the images are adapted from https://www.cs.toronto.edu/~kriz/cifar.html)</p>
			<p>Now that the dataset is<a id="_idIndexMarker519"/> prepared, we will look into a CNN model used for the FL process.</p>
			<h2 id="_idParaDest-166"><a id="_idTextAnchor171"/>The ML model used for FL with image classification</h2>
			<p>Here is the <a id="_idIndexMarker520"/>description of the ML model architecture of the CNN model used in this image classification example. To learn more about what the CNN is, you can find many useful study resources, such as <a href="https://cs231n.github.io/convolutional-networks/">https://cs231n.github.io/convolutional-networks/</a>:</p>
			<ul>
				<li>Conv2D</li>
				<li>MaxPool2D (maximum pooling)</li>
				<li>Conv2D</li>
				<li>3 fully-connected layers</li>
			</ul>
			<p>The script to define the CNN model is already designed and can be found in <strong class="source-inline">cnn.py</strong> in <strong class="source-inline">examples/image_classification</strong> in the <strong class="source-inline">simple-fl</strong> repository on GitHub. Next, we will run the image classification application with the FL system.</p>
			<h2 id="_idParaDest-167"><a id="_idTextAnchor172"/>How to run the image classification example with CNN</h2>
			<p>As mentioned in the installation<a id="_idIndexMarker521"/> steps at the beginning of this chapter, we first install the necessary libraries with <strong class="source-inline">federatedenv</strong>, and then install <strong class="source-inline">torch</strong> and <strong class="source-inline">torchvision</strong> after that:</p>
			<p class="source-code">pip install torch</p>
			<p class="source-code">pip install torchvision</p>
			<p>You can configure many settings through the JSON config files in the <strong class="source-inline">setups</strong> folder of the <strong class="source-inline">simple-fl</strong> repo of GitHub. For more details, you can read the general description of the config files in our <strong class="source-inline">setups</strong> documentation (<a href="https://github.com/tie-set/simple-fl/tree/master/setups">https://github.com/tie-set/simple-fl/tree/master/setups</a>).</p>
			<p>First, you can run two agents. You can increase the number of agents running on the same device by specifying the appropriate port numbers. </p>
			<p>As you already know, the first thing you can do is run the database and aggregator:</p>
			<pre class="source-code">
# FL server side
python -m fl_main.pseudodb.pseudo_db
python -m fl_main.aggregator.server_th</pre>
			<p>Then, start the first and second agents to run the image classification example:</p>
			<pre class="source-code">
# First agent
python -m examples.image_classification.classification
_engine 1 50001 a1
# Second agent
python -m examples.image_classification.classification
_engine 1 50002 a2</pre>
			<p>To simulate the actual FL<a id="_idIndexMarker522"/> scenarios, the amount of training data accessible from each agent can be limited to a specific number. This should be specified with the <strong class="source-inline">num_training_data</strong> variable in <strong class="source-inline">classification_engine.py</strong>. By default, it uses 8,000 images (2,000 batches) for each round.</p>
			<p>Now that we can run the two agents to test the FL process using CNN models, let us look further into the results by running the image classification example.</p>
			<h2 id="_idParaDest-168"><a id="_idTextAnchor173"/>Evaluation of running the image classification with CNN </h2>
			<p>The performance<a id="_idIndexMarker523"/> data (the accuracy of each local model cluster model) is stored in our database. You can access the corresponding <strong class="source-inline">.db</strong> file to see the performance history.</p>
			<p>The <strong class="source-inline">DataManager</strong> instance (defined in <strong class="source-inline">ic_training.py</strong>) has a function to return one batch of images and their labels (<strong class="source-inline">get_random_images</strong>). You can use this function to show the actual labels and the predicted labels by the trained CNN on specific images.</p>
			<p><em class="italic">Figure 6.12</em> shows a plot of the learning performance from our experimental runs on our side; the results may look different when you run it with your own settings:</p>
			<div>
				<div id="_idContainer059" class="IMG---Figure">
					<img src="image/B18369_06_12.jpg" alt="Figure 6.12 – Plot of the learning performance from the experimental runs for FL using CNN for image classification &#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.12 – Plot of the learning performance from the experimental runs for FL using CNN for image classification </p>
			<p>Again, as we only <a id="_idIndexMarker524"/>use two agents here, the results just look slightly different. However, with the proper hyperparameter settings, data amount, and the number of agents, you will be able to carry out an FL evaluation that produces meaningful results, which we would like you to explore on your own, as the focus here is just how to connect the actual ML models to this FL environment.</p>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor174"/>Running five agents</h2>
			<p>You can easily run five<a id="_idIndexMarker525"/> agents for the image classification application by just specifying different port numbers and agent names in the terminal. The results look similar to what we discussed in the previous section except the real ML models are connected (in this case, the ML model being aggregated is CNN). After running the five agents, the data and database folders look like in <em class="italic">Figure 6.13</em>:</p>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B18369_06_13.jpg" alt="Figure 6.13 – Results to be stored in each folder with the agent’s unique name&#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.13 – Results to be stored in each folder with the agent’s unique name</p>
			<p><em class="italic">Figure 6.14</em> shows the uploaded local <a id="_idIndexMarker526"/>models in the database with information about the local model ID, the time the models were generated, the ID of the agent that uploaded the local model, performance metrics, and round information:</p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B18369_06_14.jpg" alt="Figure 6.14 – Information about the local models in the database &#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.14 – Information about the local models in the database </p>
			<p>If you look at the database in <em class="italic">Figure 6.14</em>, there are five models collected by the five agents with local performance data.</p>
			<p>For each round, those five local models are aggregated to produce a cluster global model, as in the <strong class="source-inline">cluster_models</strong> table in the database, as shown in <em class="italic">Figure 6.15</em>. The database storing cluster models has information about the cluster model ID, the time the models were<a id="_idIndexMarker527"/> generated, the ID of the aggregator that created the cluster model, and round information:</p>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/B18369_06_15.jpg" alt="Figure 6.15 – Information about the cluster models in the database &#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.15 – Information about the cluster models in the database </p>
			<p>In this way, you can connect as many agents as possible. It is up to you to optimize the settings of the local ML algorithms to obtain the best-performing federated models out of the FL system.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor175"/>Summary</h1>
			<p>In this chapter, we discussed the execution of FL systems in detail and how the system will behave according to the interactions between the aggregator and agents. The step-by-step explanation of the FL system behavior based on the outcomes of the console examples guides you to understand the aggregation process of the <strong class="source-inline">FedAvg</strong> algorithm. Furthermore, the image classification example showed how CNN models are connected to the FL system and how the FL process increases the accuracy through aggregation, although this was not optimized to maximize the training results but simplified to validate the integration using CNN. </p>
			<p>With what you have learned in this chapter, you will be able to design your own FL applications integrating the principles and framework introduced in this book, and furthermore, will be able to assess the FL behavior on your own to see whether the whole flow of the FL process and model aggregation is happening correctly and consistently.</p>
			<p>In the next chapter, we will cover a variety of model aggregation methods and show how FL works well with those aggregation algorithms.</p>
		</div>
	</body></html>