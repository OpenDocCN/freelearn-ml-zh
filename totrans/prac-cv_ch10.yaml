- en: Machine Learning for Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will get an overview of the relevant machine learning theory
    and tools that are useful when developing applications such as image classification,
    object detection, and so on. With widespread communication tools and the wide
    availability of camera sensors, we are now bombarded with large amounts of image
    data. Utilizing this data to create computer vision applications requires an understanding
    of some basic machine learning concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin by first explaining what machine learning is, and then we will see
    the different types of algorithms in it.
  prefs: []
  type: TYPE_NORMAL
- en: What is machine learning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say we have scanned images of several handwritten digits and want to
    make a piece of software that would recognize handwritten digits from an image
    scan. For simplicity, let''s assume that we have only one digit. The target software
    that we develop takes in this image and outputs a number corresponding to that
    image. We can create an algorithm with several checks, such as: if there is a
    single vertical line, then output it as 1, or if there is an oval shape, then
    show it as zero. However, this is very naive and is a bad solution because we
    can have vertical lines for other digits too: 7, 9, and so on. The following figure
    explains the overall process, taking in one of the samples from the MNIST handwritten
    digit dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf938706-48ba-400d-94a7-79e814034409.png)'
  prefs: []
  type: TYPE_IMG
- en: There are several ways to model such a problem. We know that an image is made
    up of arrays of pixels and each pixel stores a value. In the previous figure,
    the value of each pixel is binary and an initial approach would be to compute
    the mean value of the image. Based on this mean value, we can define a function
    such that if the mean value lies between a range, then the image is of **9**;
    we can do the same for other digits. In this whole process, our parameters are
    the ranges for each digit image, and these ranges can be either add intuitively
    or learned through experience.
  prefs: []
  type: TYPE_NORMAL
- en: However, such a method of detecting digits in an image is prone to errors and
    is not efficient. The parameters for the model may work only on a specific set
    of images and it is hard to find the right set of values for the ranges just from
    experience. The machine learning technique plays an important role here. In this
    setup, let's use a function that will output an array of size 10, corresponding
    to the digits we are trying to find. Each array value represents the probability
    of that digit in the image. The highest probability digit will be the identified
    digit. Now, we have modeled the output but our input is still the mean value of
    the image, which may not vary much between different images. So, instead of using
    the mean value, we can use whole image pixels and map the pixel values directly
    to the output probabilities. This way, we can capture more variations in the image,
    and this is the usual way in computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our understanding of machine learning can be further strengthened by a mathematical
    method for modeling the problem, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/40276c5c-ba1f-447d-804e-1262a44c0ef8.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/e24f0411-0c91-4ab1-8328-8ea8e8c34690.png) is the input and ![](img/4eb00261-1f31-4629-81fc-b0c15fb3caad.png) is
    the output of the model. In our previous case, these are the images and probability
    array respectively. ![](img/ef19589b-5035-4772-a341-ce0efd0cbe69.png) is the machine
    learning model that we would like to create and ![](img/c006ccff-daaa-4f7e-b8b3-cf819d4d8be0.png) are
    the parameters of ![](img/03c68248-56f1-4e10-b3b2-ac59a911dc5b.png).
  prefs: []
  type: TYPE_NORMAL
- en: Kinds of machine learning techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw an introduction to machine learning and an example
    modeling of a digit image. Now, we will see the different styles of machine learning
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In supervised learning, we are given a dataset of both the inputs and required
    outputs for the model; our goal is to create a model that will take any previously
    unseen data and output values that are true to the actual as much as possible.
    There are two kinds of supervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the term for cases when the output of the model is categorical. For
    example, in the case of digit classification, the output is one of the 10 different
    digits.
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the term for cases when the output has continuous values, for example,
    a line fitting model. In it, the goal is to approximate the curve as much as possible
    so that the output of the model would be a value within a certain range.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this type of machine learning, we are not given any dataset with specific
    outputs; instead, the model should be able to find the possible outputs given
    an input. For example, in the previous handwritten digit image, we would like
    to estimate all possible digits in some ancient text. The assumption here is that
    we don't know how many different kinds of digits exist in that text. In such a
    case, the model should understand what a digit looks like. An example approach
    could be to segment the regions of the digit in the image and fit approximately
    basic shapes like lines, circles, rectangles, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality's curse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given the different kinds of machine learning techniques, it is highly important
    to know the challenges in modeling. We will use the previous digit classification
    method. We previously tried to model it using all pixels as the available input.
    The dimensions for the input are the image size, that is, h x w. It ranges from
    several hundreds to a few thousand. This size is considered as the input dimension,
    and as it increases, the computation as well as uncertainty in estimation increase.
    We need a bigger model to perform better estimation if the input dimension increases.
    This is termed **curse of dimensionality**.
  prefs: []
  type: TYPE_NORMAL
- en: In order to resolve this curse, it is highly recommended to reduce the input
    dimensions. For example, instead of using pixel values as input, we can extract
    strong features and use them as input to the model. This will reduce the input
    dimensions significantly and may improve the overall performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: A rolling-ball view of learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To learn the parameters of the model, we create a `cost` function or `objective`
    function and minimize its value. The minimum value of `objective` will give the
    best parameters for the model. For example, let model ![](img/cbda72ff-a37b-4353-9215-6f0c6cdfde00.png) predicts
    a value ![](img/12d1df00-4788-46bf-bca4-9450dc4f17fb.png)and also let we are given
    with the dataset of both the model input and the output. Then, learning a model
    requires updating the parameters ![](img/d9580831-a1bf-44ea-a416-3b243393d3a8.png) such
    that we get the best performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make the model learn, we use parameter update rule. It works by estimating
    how far the model-estimated values are away from the target values and then updates
    the parameter such that this difference reduces. After several iterations, the
    difference gets smaller, and once it is small enough, we say our model has learnt
    the parameters. A figurative explanation is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2fb6a99e-0246-4322-9ca8-4aaeacdf2bbe.png)'
  prefs: []
  type: TYPE_IMG
- en: The learning of the model is similar to a rolling ball. It is an iterative process,
    and after each process, the parameters are updated. The update pushes the parameters
    to minimize an `objective` function. This minimization is represented as pushing
    the ball downwards on the slope. The best parameters are equivalent to model state
    at the bottom of the slope.
  prefs: []
  type: TYPE_NORMAL
- en: Useful tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see some of the tools that are used while creating
    machine learning models. Here, we will be using the scikit-learn package, but
    these are available in many other libraries too. The overall functioning and the
    purpose remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Preprocessing the input as well as target labels in settings such as classification
    or regression is as important as the model itself. Some of the techniques used
    are explained as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the ease of the model to learn proper parameters through a training set,
    it is highly essential to normalize the values in a small range, usually 0 to
    1.
  prefs: []
  type: TYPE_NORMAL
- en: Noise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For making the system more robust, the input can also be added with small Gaussian
    noise. In the case of images as input, the noise corresponds to salt and pepper
    noise.
  prefs: []
  type: TYPE_NORMAL
- en: Postprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the case of classification, the output of the model is an array of probabilities.
    To compute the predicted label for the input, we use an index with the maximum
    value of the array.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of regression, the output of the model is usually normalized values
    between the range 0-1\. This requires rescaling of the output to the original
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have trained a model, to evaluate, it is highly necessary to check
    its overall validity. In a binary classification problem, setting the evaluation
    is done by using the following output values. Here, we want to evaluate the model''s
    performance for category A:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True positive **(**TP**): Given a sample from label A, the output is also
    categorized as A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True negative** (**TN**): Given a sample from label A, the output is categorized
    into B'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False positive** (**FP**): Given a sample from label B, the output is categorized
    into A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False negative** (**FN**): Given a sample from B, the output is also categorized
    into B'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is done for the evaluation set, and based on it, we compute the following
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Precision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The precision value tells us how much the result is relevant to our goal in
    accuracy. This is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8cf6d9d-c869-4f16-bf21-5d8d3491f5bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using scikit-learn, we can do this as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall tells us how many of the results are truly relevant. This is computed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9587bbf1-945e-4ecb-832b-aaba7a2fbab2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: F-measure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using both the precision and recall values, F-measure (specifically F1-score
    for the overall evaluation) is computed. This is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5088628f-e014-46f3-8e86-6b3cbcada60f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using scikit-learn, this can be computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, an overview of machine learning was explained with relevant
    tools. The explanation here complements several algorithms presented in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Taking into account the curse of dimensionality, learning overview, and evaluation
    of the model, we can create better computer vision applications that use machine
    learning techniques.
  prefs: []
  type: TYPE_NORMAL
