- en: Building Recommendation Engines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建推荐引擎
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Building function compositions for data processing
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建数据处理的功能组合
- en: Building machine learning pipelines
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建机器学习管道
- en: Finding the nearest neighbors
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最近邻
- en: Constructing a k-nearest neighbors classifier
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建k最近邻分类器
- en: Constructing a k-nearest neighbors regressor
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建k最近邻回归器
- en: Computing the Euclidean distance score
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算欧几里得距离得分
- en: Computing the Pearson correlation score
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算皮尔逊相关得分
- en: Finding similar users in the dataset
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据集中寻找相似用户
- en: Generating movie recommendations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成电影推荐
- en: Implementing ranking algorithms
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现排名算法
- en: Building a filtering model using TensorFlow
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建过滤模型
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To address the recipes in this chapter, you will need the following files (which
    are available on GitHub):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理本章中的食谱，你需要以下文件（这些文件可在GitHub上找到）：
- en: '`function_composition.py`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`function_composition.py`'
- en: '`pipeline.py`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pipeline.py`'
- en: '`knn.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`knn.py`'
- en: '`nn_classification.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn_classification.py`'
- en: '`nn_regression.py`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn_regression.py`'
- en: '`euclidean_score.py`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`euclidean_score.py`'
- en: '`pearson_score.py`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pearson_score.py`'
- en: '`find_similar_users.py`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`find_similar_users.py`'
- en: '`movie_recommendations.py`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movie_recommendations.py`'
- en: '`LambdaMARTModel.py`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LambdaMARTModel.py`'
- en: '`train.txt`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.txt`'
- en: '`vali.txt`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vali.txt`'
- en: '`test.txt`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test.txt`'
- en: '`TensorFilter.py`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorFilter.py`'
- en: Introducing the recommendation engine
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍推荐引擎
- en: A recommendation engine is a model that can predict what a user may be interested
    in. When we apply this to the context of movies, for example, this becomes a movie
    recommendation engine. We filter items in our database by predicting how the current
    user might rate them. This helps us in connecting the user to the right content
    in our dataset. Why is this relevant? If you have a massive catalog, then the
    user may or may not find all the content that is relevant to them. By recommending
    the right content, you increase consumption. Companies such as Netflix heavily
    rely on recommendations to keep the user engaged.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎是一个可以预测用户可能感兴趣的内容的模型。当我们将其应用于电影等场景时，这变成了电影推荐引擎。我们通过预测当前用户可能会如何评分来过滤数据库中的项目。这有助于我们将用户与数据集中的正确内容相连接。这有什么相关性？如果你有一个庞大的目录，那么用户可能或可能找不到所有与他们相关的所有内容。通过推荐正确的内容，你可以增加消费。像Netflix这样的公司严重依赖推荐来保持用户的参与度。
- en: Recommendation engines usually produce a set of recommendations using either
    collaborative filtering or content-based filtering. The difference between the
    two approaches is in the way that the recommendations are mined. Collaborative
    filtering builds a model from the past behavior of the current user, as well as
    ratings given by other users. We then use this model to predict what this user
    might be interested in. Content-based filtering, on the other hand, uses the characteristics
    of the item itself in order to recommend more items to the user. The similarity
    between items is the main driving force here. In this chapter, we will focus on
    collaborative filtering.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎通常使用协同过滤或基于内容的过滤来生成一组推荐。两种方法之间的区别在于推荐挖掘的方式。协同过滤从当前用户的过去行为以及其他用户的评分构建模型。然后我们使用这个模型来预测这个用户可能会感兴趣的内容。另一方面，基于内容的过滤使用项目本身的特征来向用户推荐更多项目。项目之间的相似性是这里的驱动力。在本章中，我们将重点介绍协同过滤。
- en: Building function compositions for data processing
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建数据处理的功能组合
- en: One of the major parts of any machine learning system is the data processing
    pipeline. Before data is fed into the machine learning algorithm for training,
    we need to process it in different ways to make it suitable for that algorithm.
    Having a robust data processing pipeline goes a long way in building an accurate
    and scalable machine learning system. There are a lot of basic functionalities
    available, and data processing pipelines usually consist of a combination of these.
    Instead of calling these functions in a nested or loopy way, it's better to use
    the functional programming paradigm to build the combination.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习系统的主要部分之一是数据处理管道。在数据被输入到机器学习算法进行训练之前，我们需要以不同的方式对其进行处理，使其适合该算法。拥有一个健壮的数据处理管道对于构建准确和可扩展的机器学习系统至关重要。有很多基本功能可用，数据处理管道通常是由这些功能的组合构成的。与其以嵌套或循环的方式调用这些函数，不如使用函数式编程范式来构建组合。
- en: Getting ready
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Let's take a look at how to combine these basic functions to form a reusable
    function composition. In this recipe, we will create three basic functions and
    look at how to compose a pipeline.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何将这些基本函数组合成一个可重用的函数组合。在这个菜谱中，我们将创建三个基本函数，并查看如何构建一个管道。
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s take a look at how to build function compositions for data processing:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建数据处理的功能组合：
- en: 'Create a new Python file and add the following line (the full code is in the `function_composition.py`
    file that''s already provided for you):'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并添加以下行（完整的代码在提供的`function_composition.py`文件中）：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s define a function to add `3` to each element of the array:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，将`3`加到数组的每个元素上：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s define a second function to multiply `2` with each element of the
    array:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义第二个函数，将`2`乘以数组的每个元素：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s now define a third function to subtract `5` from each element of
    the array:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们再定义一个函数，从数组的每个元素中减去`5`：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s define a function composer that takes functions as input arguments and
    returns a composed function. This composed function is basically a function that
    applies all the input functions in a sequence:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个函数组合器，它接受函数作为输入参数，并返回一个组合函数。这个组合函数基本上是一个按顺序应用所有输入函数的函数：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We use the `reduce` function to combine all the input functions by successively
    applying the functions in a sequence.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`reduce`函数通过依次应用序列中的函数来组合所有输入函数。
- en: 'We are now ready to play with this function composer. Let''s define some data
    and a sequence of operations:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好使用这个函数组合器了。让我们定义一些数据和一系列操作：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we use the regular method, we apply this successively, as follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们使用常规方法，我们会依次应用，如下所示：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, let''s use the function composer to achieve the same thing in a single
    line:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用函数组合器在单行中实现相同的功能：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can do the same thing in a single line with the previous method as well,
    but the notation becomes very nested and unreadable. Also, it is not reusable;
    you will have to write the whole thing again if you want to reuse this sequence
    of operations:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以用前一种方法在单行中做同样的事情，但符号会变得非常嵌套和难以阅读。此外，它不可重用；如果你想重用这个操作序列，你必须再次写下整个内容：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you run this code, you will get the following output on the Terminal:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端上得到以下输出：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we have created three basic functions and have learned how to
    compose a pipeline. To do this, the `reduce()` function was used. This function
    accepts a function and a sequence and returns a single value.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们创建了三个基本函数，并学习了如何组合一个管道。为此，我们使用了`reduce()`函数。这个函数接受一个函数和一个序列，并返回一个单一值。
- en: 'The `reduce ()` function calculates the return value, as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`reduce()`函数计算返回值，如下所示：'
- en: To start, the function calculates the result by using the first two elements
    of the sequence.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，函数通过使用序列的前两个元素来计算结果。
- en: Next, the function uses the result obtained in the previous step and the next
    value in the sequence.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，函数使用上一步得到的结果和序列中的下一个值。
- en: This process is repeated until the end of the sequence.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程会一直重复，直到序列的末尾。
- en: There's more...
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The three basic functions used at the beginning of the recipe make use of the
    `map()` function. This function is used to apply a function on all the elements
    of a specific value. As a result, a map object is returned; this object is an
    iterator, so we can iterate over its elements. To print this object, we have converted
    the map object to sequence objects as a list.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在菜谱开头使用的三个基本函数利用了`map()`函数。这个函数用于将一个函数应用于特定值的所有元素。结果返回一个map对象；这个对象是一个迭代器，因此我们可以遍历其元素。为了打印这个对象，我们将map对象转换为序列对象，即列表。
- en: See also
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to Python's official documentation of the `map()` function: [https://docs.python.org/3/library/functions.html#map](https://docs.python.org/3/library/functions.html#map)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Python官方文档中的`map()`函数：[https://docs.python.org/3/library/functions.html#map](https://docs.python.org/3/library/functions.html#map)
- en: Refer to Python's official documentation of the `reduce()` function: [https://docs.python.org/3/library/functools.html?highlight=reduce#functools.reduce](https://docs.python.org/3/library/functools.html?highlight=reduce#functools.reduce)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Python官方文档中的`reduce()`函数：[https://docs.python.org/3/library/functools.html?highlight=reduce#functools.reduce](https://docs.python.org/3/library/functools.html?highlight=reduce#functools.reduce)
- en: Building machine learning pipelines
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建机器学习管道
- en: The `scikit-learn` library is used to build machine learning pipelines. When
    we define the functions, the library will build a composed object that makes the
    data go through the entire pipeline. This pipeline can include functions, such
    as preprocessing, feature selection, supervised learning, and unsupervised learning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '` scikit-learn`库用于构建机器学习管道。当我们定义函数时，库将构建一个组合对象，使数据通过整个管道。这个管道可以包括函数，如预处理、特征选择、监督学习和无监督学习。'
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will be building a pipeline to take the input feature vector,
    select the top *k* features, and then classify them using a random forest classifier.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将构建一个管道，用于获取输入特征向量，选择前* k* 个特征，然后使用随机森林分类器进行分类。
- en: How to do it...
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s take a look at how to build machine learning pipelines:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建机器学习管道：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `pipeline.py` file that''s already provided for you):'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在您已经提供的` pipeline.py`文件中）：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s generate some sample data to play with, as follows:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成一些样本数据来玩耍，如下所示：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This line generated `20` dimensional feature vectors because this is the default
    value. You can change it using the `n_features` parameter in the previous line.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这行生成了` 20` 维的特征向量，因为这是默认值。您可以使用上一行中的` n_features`参数来更改它。
- en: 'Our first step of the pipeline is to select the *k* best features before the
    datapoint is used further. In this case, let''s set `k` to `10`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们管道的第一步是在数据点进一步使用之前选择* k* 个最佳特征。在这种情况下，让我们将` k` 设置为` 10`：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The next step is to use a random forest classifier method to classify the data:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是使用随机森林分类器方法对数据进行分类：
- en: '[PRE13]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We are now ready to build the pipeline. The `Pipeline()` method allows us to
    use predefined objects to build the pipeline:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好构建管道。` Pipeline()`方法允许我们使用预定义的对象来构建管道：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can also assign names to the blocks in our pipeline. In the preceding line,
    we'll assign the `selector` name to our feature selector, and `rf` to our random
    forest classifier. You are free to use any other random names here!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为管道中的块分配名称。在上行中，我们将` selector` 名称分配给我们的特征选择器，将` rf`分配给我们的随机森林分类器。您可以使用任何其他随机名称！
- en: 'We can also update these parameters as we go along. We can set the parameters
    using the names that we assigned in the previous step. For example, if we want
    to set `k` to `6` in the feature selector and set `n_estimators` to `25` in the
    random forest classifier, we can do so as demonstrated in the following code.
    Note that these are the variable names given in the previous step:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以在过程中更新这些参数。我们可以使用之前步骤中分配的名称来设置参数。例如，如果我们想在特征选择器中将` k` 设置为` 6`，在随机森林分类器中将`
    n_estimators`设置为` 25`，我们可以像以下代码所示那样做。请注意，这些是之前步骤中给出的变量名称：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s go ahead and train the classifier:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们继续训练分类器：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let''s now predict the output for the training data, as follows:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们预测训练数据的输出，如下所示：
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, let''s estimate the performance of this classifier, as follows:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们估计这个分类器的性能，如下所示：
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can also see which features will get selected, so let''s go ahead and print
    them:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以查看哪些特征将被选择，所以让我们继续并打印它们：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If you run this code, you will get the following output on your Terminal:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您运行此代码，您将在您的终端上得到以下输出：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The advantage of selecting the *k* best features is that we will be able to
    work with low-dimensional data. This is helpful in reducing the computational
    complexity. The way in which we select the *k* best features is based on univariate
    feature selection. This performs univariate statistical tests and then extracts
    the top performing features from the feature vector. Univariate statistical tests
    refer to analysis techniques where a single variable is involved.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 选择* k* 个最佳特征的优势在于我们将能够处理低维数据。这有助于减少计算复杂性。我们选择* k* 个最佳特征的方式基于单变量特征选择。这执行单变量统计测试，然后从特征向量中提取表现最好的特征。单变量统计测试是指只涉及一个变量的分析技术。
- en: There's more...
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: Once these tests are performed, each feature in the feature vector is assigned
    a score. Based on these scores, we select the top *k*features. We do this as a
    preprocessing step in our classifier pipeline. Once we extract the top *k*features,
    a k-dimensional feature vector is formed, and we use it as the input training
    data for the random forest classifier.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进行这些测试，特征向量中的每个特征都会被分配一个分数。基于这些分数，我们选择前*k*个特征。我们将此作为分类器管道中的预处理步骤。一旦我们提取了前*k*个特征，就形成了一个k维特征向量，我们将其用作随机森林分类器的输入训练数据。
- en: See also
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'Refer to the official documentation of the `sklearn.ensemble.RandomForestClassifier()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅`sklearn.ensemble.RandomForestClassifier()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- en: 'Refer to the official documentation of the `sklearn.feature_selection.SelectKBest()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅`sklearn.feature_selection.SelectKBest()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)
- en: 'Refer to the official documentation of the `sklearn.pipeline.Pipeline()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅`sklearn.pipeline.Pipeline()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
- en: 'Refer to the official documentation of the `sklearn.feature_selection.f_regression()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅`sklearn.feature_selection.f_regression()`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html)
- en: Finding the nearest neighbors
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找最近邻
- en: The nearest neighbors model refers to a general class of algorithms that aim
    to make a decision based on the number of nearest neighbors in the training dataset. The
    nearest neighbors method consists of finding a predefined number of training samples
    that are close to the distance from the new point and predicting the label. The
    number of samples can be user defined, consistent, or differ from each other –
    it depends on the local density of points. The distance can be calculated with
    any metric measure – the standard Euclidean distance is the most common choice.
    Neighbor-based methods simply remember all training data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻模型指的是一类旨在根据训练数据集中最近邻的数量做出决策的算法。最近邻方法包括找到与新的点距离相近的预定义数量的训练样本，并预测标签。样本的数量可以是用户定义的、一致的或不同的，这取决于点的局部密度。距离可以用任何度量标准来计算——标准欧几里得距离是最常见的选项。基于邻居的方法只是简单地记住所有训练数据。
- en: Getting ready
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will find the nearest neighbors using a series of points
    on a Cartesian plane.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们将使用笛卡尔平面上的一系列点来寻找最近邻。
- en: How to do it...
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to find the nearest neighbors, as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何找到最近邻，如下所示：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `knn.py` file that''s already provided for you):'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码已包含在您提供的`knn.py`文件中）：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s create some sample two-dimensional data:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一些二维样本数据：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Our goal is to find the three closest neighbors to any given point, so let''s
    define this parameter:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的目标是找到任何给定点的三个最近邻，所以让我们定义这个参数：
- en: '[PRE23]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let''s define a random datapoint that''s not present in the input data:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个不在输入数据中的随机数据点：
- en: '[PRE24]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We need to see what this data looks like; let''s plot it, as follows:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要看看这些数据看起来像什么；让我们按如下方式绘制它：
- en: '[PRE25]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In order to find the nearest neighbors, we need to define the `NearestNeighbors`
    object with the right parameters and train it on the input data:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了找到最近邻，我们需要定义具有正确参数的`NearestNeighbors`对象，并在输入数据上对其进行训练：
- en: '[PRE26]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can now find the `distances` parameter of the input point to all the points
    in the input data:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以找到输入点到输入数据中所有点的`distances`参数：
- en: '[PRE27]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can print `k nearest neighbors`, as follows:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以打印`k最近邻`，如下所示：
- en: '[PRE28]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `indices` array is already sorted, so we just need to parse it and print
    the datapoints.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`indices`数组已经排序，所以我们只需要解析它并打印数据点。'
- en: 'Now, let''s plot the input datapoint and highlight the k-nearest neighbors:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制输入数据点和突出显示k个最近邻：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you run this code, you will get the following output on your Terminal:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上得到以下输出：
- en: '[PRE30]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here is the plot of the input datapoints:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输入数据点的图示：
- en: '![](img/1f5c2f9d-5498-4c6d-8eb3-4e0d0c9f9346.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f5c2f9d-5498-4c6d-8eb3-4e0d0c9f9346.png)'
- en: 'The second output diagram depicts the location of the test datapoint and the
    three nearest neighbors, as shown in the following screenshot:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个输出图显示了测试数据点的位置和三个最近邻，如下面的截图所示：
- en: '![](img/87cc760b-f611-4cb4-90c1-862b9e9f6b2d.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87cc760b-f611-4cb4-90c1-862b9e9f6b2d.png)'
- en: How it works...
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we looked for the nearest neighbors by using a series of points
    on a Cartesian plane. To do this, the space is partitioned into regions based
    on the positions and characteristics of the training objects. This can be considered
    as the training set for the algorithm even if it is not explicitly required by
    the initial conditions. To calculate the distance, the objects are represented
    through position vectors in a multidimensional space. Finally, a point is assigned
    to a class if it is the most frequent of the *k* examples closest to the object
    under examination. The proximity is measured by the distance between points. Neighbors
    are taken from a set of objects for which the correct classification is known.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们通过使用笛卡尔平面上的点来寻找最近邻。为此，根据训练对象的位置和特征将空间划分为区域。即使它不是初始条件所明确要求的，这也可以被认为是算法的训练集。为了计算距离，对象通过多维空间中的位置向量来表示。最后，如果一个点是最接近被考察对象的k个例子中最频繁的，则将其分配到某个类别。邻近性是通过点之间的距离来衡量的。邻居是从一组已知正确分类的对象中选取的。
- en: There's more...
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: To build the nearest neighbors model, the `BallTree` algorithm was used. `BallTree`
    is a data structure that organizes points in a multidimensional space. The algorithm
    gets its name because it partitions datapoints into a nested set of hyperspheres,
    known as **balls**. It's useful for a number of applications, most notably, the
    nearest neighbor search.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建最近邻模型，使用了`BallTree`算法。`BallTree`是一种在多维空间中组织点的数据结构。该算法之所以得名，是因为它将数据点划分为一系列嵌套的超球体，称为**球体**。它在许多应用中很有用，尤其是最近邻搜索。
- en: See also
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'Refer to the official documentation of the `sklearn.neighbors.NearestNeighbors()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.neighbors.NearestNeighbors()`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)
- en: 'Refer to the official documentation of the `sklearn.neighbors.BallTree()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.neighbors.BallTree()`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree)
- en: 'Refer to *Nearest Neighbors* (from Texas A&M University College of Engineering):
    [https://www.nada.kth.se/~stefanc/DATORSEENDE_AK/l8.pdf](https://www.nada.kth.se/~stefanc/DATORSEENDE_AK/l8.pdf)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自德克萨斯A&M大学工程学院的*最近邻*（[https://www.nada.kth.se/~stefanc/DATORSEENDE_AK/l8.pdf](https://www.nada.kth.se/~stefanc/DATORSEENDE_AK/l8.pdf)）
- en: Constructing a k-nearest neighbors classifier
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建k最近邻分类器
- en: The k-nearest neighbors algorithm is an algorithm that uses k-nearest neighbors
    in the training dataset to find the category of an unknown object. When we want
    to find the class that an unknown point belongs to, we find the k-nearest neighbors
    and take a majority vote.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: k最近邻算法是一种使用训练数据集中的k个最近邻来寻找未知对象类别的算法。当我们想要找到未知点所属的类别时，我们找到k个最近邻并进行多数投票。
- en: Getting ready
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will create a k-nearest neighbors classifier starting from
    the input data that contains a series of points arranged on a Cartesian plane
    that shows a grouping within three areas.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将从包含一系列在笛卡尔平面上排列的点输入数据开始创建一个k最近邻分类器，这些点显示了三个区域内的分组。
- en: How to do it...
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s take a look at how to build a k-nearest neighbors classifier:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建k-最近邻分类器：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `nn_classification.py` file that''s already provided for you):'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已为你提供的`nn_classification.py`文件中）：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We will use the `data_nn_classifier.txt` file for input data. Let''s load this
    input data:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`data_nn_classifier.txt`文件作为输入数据。让我们加载这个输入数据：
- en: '[PRE32]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The first two columns contain input data, and the last column contains the labels.
    Hence, we separated them into `X` and `y`, as shown in the preceding code.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 前两列包含输入数据，最后一列包含标签。因此，我们将它们分离成`X`和`y`，如前述代码所示。
- en: 'Now, let''s visualize the input data, as follows:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们可视化输入数据，如下所示：
- en: '[PRE33]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We iterate through all the datapoints and use the appropriate markers to separate
    the classes.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历所有数据点，并使用适当的标记来区分类别。
- en: 'In order to build the classifier, we need to specify the number of nearest
    neighbors that we want to consider. Let''s define this parameter:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了构建分类器，我们需要指定我们想要考虑的最近邻数量。让我们定义这个参数：
- en: '[PRE34]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In order to visualize the boundaries, we need to define a grid and evaluate
    the classifier on that grid. Let''s define the step size:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了可视化边界，我们需要定义一个网格并在该网格上评估分类器。让我们定义步长：
- en: '[PRE35]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We are now ready to build the k-nearest neighbors classifier. Let''s define
    this and train it, as follows:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好构建k-最近邻分类器。让我们定义它并训练它，如下所示：
- en: '[PRE36]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We need to create a mesh to plot the boundaries. Let''s define this, as follows:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要创建一个网格来绘制边界。让我们定义如下：
- en: '[PRE37]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, let''s evaluate the `classifier` output for all the points:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们评估所有点的`classifier`输出：
- en: '[PRE38]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s plot it, as follows:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制它，如下所示：
- en: '[PRE39]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now that we have plotted the color mesh, let''s overlay the training datapoints
    to see where they lie in relation to the boundaries:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经绘制了颜色网格，让我们叠加训练数据点以查看它们相对于边界的位置：
- en: '[PRE40]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we can consider a test datapoint and see whether the classifier performs
    correctly. Let''s define it and plot it, as follows:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以考虑一个测试数据点并查看分类器是否表现正确。让我们定义它并绘制它，如下所示：
- en: '[PRE41]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We need to extract the k-nearest neighbors classifier using the following model:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要使用以下模型提取k-最近邻分类器：
- en: '[PRE42]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let''s plot the k-nearest neighbors classifier and highlight it:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制k-最近邻分类器并突出显示它：
- en: '[PRE43]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, let''s print the `classifier` output on the Terminal:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在终端上打印`classifier`输出：
- en: '[PRE44]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The following result is printed:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出以下结果：
- en: '[PRE45]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Furthermore, a series of diagrams are shown. The first output diagram depicts
    the distribution of the input datapoints:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，展示了一系列图表。第一个输出图表描述了输入数据点的分布：
- en: '![](img/9f7bfe09-977b-4b0f-bf5e-5427fa2ef23a.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9f7bfe09-977b-4b0f-bf5e-5427fa2ef23a.png)'
- en: 'The second output diagram depicts the boundaries obtained using the `k-nearest
    neighbors` classifier:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个输出图表描述了使用`k-最近邻`分类器获得的边界：
- en: '![](img/e34cdba7-455f-4eeb-973d-81be00b44cbf.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e34cdba7-455f-4eeb-973d-81be00b44cbf.png)'
- en: 'The third output diagram depicts the location of the test datapoint:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个输出图表描述了测试数据点的位置：
- en: '![](img/1b7d05a3-6f5b-4fa9-8e28-4024c34dd5a7.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1b7d05a3-6f5b-4fa9-8e28-4024c34dd5a7.png)'
- en: 'The fourth output diagram depicts the location of the 10 nearest neighbors:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个输出图表描述了10个最近邻的位置：
- en: '![](img/169f394f-96e0-471d-a2c2-78c02098a65b.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/169f394f-96e0-471d-a2c2-78c02098a65b.png)'
- en: How it works...
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The k-nearest neighbors classifier stores all the available datapoints and classifies
    new datapoints based on a similarity metric. This similarity metric usually appears
    in the form of a distance function. This algorithm is a nonparametric technique,
    which means that it doesn't need to find out any underlying parameters before
    formulation. All we need to do is select a value of `k` that works for us.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: k-最近邻分类器存储所有可用的数据点，并根据相似性度量对新数据点进行分类。这个相似性度量通常以距离函数的形式出现。这个算法是一种非参数技术，这意味着在制定之前不需要找出任何潜在参数。我们只需要选择一个对我们来说合适的`k`值。
- en: Once we find out the k-nearest neighbors classifier, we take a majority vote.
    A new datapoint is classified by this majority vote of the k-nearest neighbors classifier.
    This datapoint is assigned to the class that is most common among its k-nearest
    neighbors. If we set the value of `k` to `1`, then this simply becomes a case
    of a nearest neighbor classifier where we just assign the datapoint to the class
    of its nearest neighbor in the training dataset.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们找到了k近邻分类器，我们就进行多数投票。新的数据点通过k近邻分类器的多数投票进行分类。这个数据点被分配给其k个最近邻中最常见的类别。如果我们把`k`的值设为`1`，那么这仅仅是一个最近邻分类器的案例，我们只需将数据点分配给训练数据集中其最近邻的类别。
- en: There's more...
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The k-nearest neighbor algorithm is based on the concept of classifying an unknown
    sample by considering the class of *k* samples closest to the training set. The
    new sample will be assigned to the class that most of the *k* nearest samples
    belong to. The choice of *k* is, therefore, very important for the sample to be
    assigned to the correct class. If k is too small, the classification may be sensitive
    to noise; if *k* is too large, the classification may be computationally expensive,
    and the neighborhood may include samples belonging to other classes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: k近邻算法基于通过考虑训练集最接近的k个样本的类别来对未知样本进行分类的概念。新的样本将被分配给大多数k个最近样本所属的类别。因此，k的选择对于将样本分配到正确的类别非常重要。如果k太小，分类可能对噪声敏感；如果k太大，分类可能计算成本高，并且邻域可能包括属于其他类别的样本。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: Refer to *kNN classifiers* (from the Faculty of Humanities, University of Amsterdam): [http://www.fon.hum.uva.nl/praat/manual/kNN_classifiers_1__What_is_a_kNN_classifier_.html](http://www.fon.hum.uva.nl/praat/manual/kNN_classifiers_1__What_is_a_kNN_classifier_.html)
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容（来自阿姆斯特丹大学人文学院）：[http://www.fon.hum.uva.nl/praat/manual/kNN_classifiers_1__What_is_a_kNN_classifier_.html](http://www.fon.hum.uva.nl/praat/manual/kNN_classifiers_1__What_is_a_kNN_classifier_.html)
- en: 'Refer to the official documentation of the `sklearn.neighbors()` module: [https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.neighbors()`模块：[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors)
- en: 'Refer to *Nearest neighbor methods* (from New York University): [http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture11.pdf](http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture11.pdf)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容（来自纽约大学）：[http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture11.pdf](http://people.csail.mit.edu/dsontag/courses/ml13/slides/lecture11.pdf)
- en: 'Refer to the official documentation of the `sklearn.neighbors.KNeighborsClassifier()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档中的`sklearn.neighbors.KNeighborsClassifier()`函数：[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
- en: Constructing a k-nearest neighbors regressor
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个k近邻回归器
- en: We learned how to use the k-nearest neighbors algorithm to build a classifier.
    The good thing is that we can also use this algorithm as a regressor. The object's
    output is represented by its property value, which is the average of the values
    of its k-nearest neighbors.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何使用k近邻算法构建分类器。好事是，我们也可以将此算法用作回归器。对象的输出由其属性值表示，这是其k个最近邻的值的平均值。
- en: Getting ready
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to use the k-nearest neighbors algorithm to
    build a regressor.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何使用k近邻算法构建回归器。
- en: How to do it...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s take a look at how to build a k-nearest neighbors regressor:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建一个k近邻回归器：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `nn_regression.py` file that''s already provided for you):'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '创建一个新的Python文件并导入以下包（完整的代码在提供的`nn_regression.py`文件中）： '
- en: '[PRE46]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s generate some sample Gaussian-distributed data:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成一些样本高斯分布数据：
- en: '[PRE47]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We need to add some noise to the data to introduce some randomness into it.
    The goal of adding noise is to see whether our algorithm can get past it and still
    function in a robust way:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要向数据中添加一些噪声，以引入一些随机性。添加噪声的目的是看看我们的算法是否能够克服它，并且仍然以鲁棒的方式运行：
- en: '[PRE48]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, let''s visualize it, as follows:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们可视化它，如下所示：
- en: '[PRE49]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We just generated some data and evaluated a continuous-valued function on all
    these points. Let''s define a denser grid of points:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们刚刚生成了一些数据，并在所有这些点上评估了一个连续值函数。让我们定义一个更密集的点网格：
- en: '[PRE50]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We defined this denser grid because we want to evaluate our regressor on all
    of these points and look at how well it approximates our function.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义这个更密集的网格是因为我们想要评估我们的回归器在这些所有点上，并查看它如何近似我们的函数。
- en: 'Let''s now define the number of nearest neighbors that we want to consider:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义我们想要考虑的最近邻的数量：
- en: '[PRE51]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s initialize and train the k-nearest neighbors regressor using the parameters
    that we defined earlier:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用之前定义的参数初始化并训练 k 近邻回归器：
- en: '[PRE52]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s see how the regressor performs by overlapping the input and output data
    on top of each other:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过将输入和输出数据重叠在一起来查看回归器的表现：
- en: '[PRE53]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'If you run this code, the first diagram depicts the input datapoints:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，第一个图表描述了输入数据点：
- en: '![](img/b7a60e11-8e5a-4fb0-9f15-53ecb8bfe37b.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b7a60e11-8e5a-4fb0-9f15-53ecb8bfe37b.png)'
- en: 'The second diagram depicts the values predicted by the regressor:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个图表展示了回归器预测的值：
- en: '![](img/789d6996-9492-43c9-a5ac-a2ac90b7654c.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/789d6996-9492-43c9-a5ac-a2ac90b7654c.png)'
- en: How it works...
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The goal of a regressor is to predict continuous valued outputs. We don''t
    have a fixed number of output categories in this case. We just have a set of real-valued
    output values, and we want our regressor to predict the output values for unknown
    datapoints. In this case, we used a `sinc` function to demonstrate the k-nearest
    neighbors regressor. This is also referred to as the **cardinal sine function**.
    A `sinc` function is defined by the following equation:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 回归器的目标是预测连续值输出。在这种情况下，我们没有固定数量的输出类别。我们只有一组实值输出值，我们希望我们的回归器预测未知数据点的输出值。在这种情况下，我们使用
    `sinc` 函数来演示 k 近邻回归器。这也被称为 **卡丹尔正弦函数**。`sinc` 函数由以下方程定义：
- en: '![](img/5aa5578d-f46b-4180-9d59-43cc7205db19.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5aa5578d-f46b-4180-9d59-43cc7205db19.png)'
- en: When `x` is `0`, *sin(x)/x* takes the indeterminate form of *0/0*. Hence, we
    have to compute the limit of this function as `x` tends to be `0`. We used a set
    of values for training, and we defined a denser grid for testing. As you can see
    in the preceding diagram, the output curve is close to the training outputs.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `x` 为 `0` 时，*sin(x)/x* 取得不定形 *0/0*。因此，我们必须计算当 `x` 趋近于 `0` 时该函数的极限。我们使用一组值进行训练，并为测试定义了一个更密集的网格。如图所示，输出曲线接近训练输出。
- en: There's more...
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The main advantages of this method are that it does not require learning or
    the construction of a model; it can adapt its decision boundaries in an arbitrary
    way, producing a representation of the most flexible model; and it also guarantees
    the possibility of increasing the training set. However, this algorithm also has
    many drawbacks, including being susceptible to data noise, being sensitive to
    the presence of irrelevant features, and requiring a similarity measure to evaluate
    proximity.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要优点是它不需要学习或构建模型；它可以以任意方式调整其决策边界，产生最灵活的模型表示；并且它还保证了增加训练集的可能性。然而，此算法也有许多缺点，包括易受数据噪声的影响、对无关特征的敏感，以及需要相似度度量来评估邻近性。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'Refer to the official documentation of the `sklearn.neighbors.KNeighborsRegressor()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方文档的 `sklearn.neighbors.KNeighborsRegressor()` 函数：[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)
- en: Refer to *Regression Analysis with R*, Giuseppe Ciaburro, Packt Publishing
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考书籍 *使用 R 进行回归分析*，作者 Giuseppe Ciaburro，Packt 出版
- en: 'Refer to *Comparison of Linear Regression with K-Nearest Neighbors* (from Duke
    University): [http://www2.stat.duke.edu/~rcs46/lectures_2017/03-lr/03-knn.pdf](http://www2.stat.duke.edu/~rcs46/lectures_2017/03-lr/03-knn.pdf)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考杜克大学的 *线性回归与 K 近邻比较*（[http://www2.stat.duke.edu/~rcs46/lectures_2017/03-lr/03-knn.pdf](http://www2.stat.duke.edu/~rcs46/lectures_2017/03-lr/03-knn.pdf)）
- en: Computing the Euclidean distance score
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算欧几里得距离得分
- en: Now that we have sufficient background in machine learning pipelines and the
    nearest neighbors classifier, let's start the discussion on recommendation engines.
    In order to build a recommendation engine, we need to define a similarity metric
    so that we can find users in the database who are similar to a given user. The
    Euclidean distance score is one such metric that we can use to compute the distance
    between datapoints. We will shift the discussion toward movie recommendation engines.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对机器学习管道和最近邻分类器有了足够的背景知识，让我们开始讨论推荐引擎。为了构建推荐引擎，我们需要定义一个相似性度量，这样我们就可以找到与给定用户相似的数据库中的用户。欧几里得距离得分就是这样一种度量，我们可以用它来计算数据点之间的距离。我们将讨论转向电影推荐引擎。
- en: Getting ready
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to compute the Euclidean score between two users.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将了解如何计算两个用户之间的欧几里得得分。
- en: How to do it...
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to compute the Euclidean distance score:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何计算欧几里得距离得分：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `euclidean_score.py` file that''s already provided for you):'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已经为你提供的`euclidean_score.py`文件中）：
- en: '[PRE54]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We will now define a function to compute the Euclidean score between two users. The
    first step is to check whether the users are present in the database:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将定义一个函数来计算两个用户之间的欧几里得得分。第一步是检查用户是否存在于数据库中：
- en: '[PRE55]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'In order to compute the score, we need to extract the movies that both the
    users rated:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算得分，我们需要提取两个用户都评价过的电影：
- en: '[PRE56]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'If there are no common movies, then there is no similarity between the users
    (or at least, we cannot compute it given the ratings in the database):'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有共同的电影，那么用户之间没有相似性（或者至少，根据数据库中的评分我们无法计算它）：
- en: '[PRE57]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'For each of the common ratings, we just compute the square root of the sum
    of squared differences and normalize it, so that the score is between 0 and 1:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个共同评分，我们只计算平方差的和的平方根并归一化，使得得分在0到1之间：
- en: '[PRE58]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: If the ratings are similar, then the sum of squared differences will be very
    low. Hence, the score will become high, which is what we want from this metric.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如果评分相似，则平方差的和将非常低。因此，得分将变得很高，这正是我们想要的这个度量标准。
- en: 'We will use the `movie_ratings.json` file as our data file. Let''s load it,
    as follows:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`movie_ratings.json`文件作为我们的数据文件。让我们按照以下方式加载它：
- en: '[PRE59]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Let''s consider two random users and compute the Euclidean distance score:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们考虑两个随机用户并计算欧几里得距离得分：
- en: '[PRE60]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'When you run this code, you will see the following Euclidean distance score
    printed on the Terminal:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你运行此代码时，你将在终端上看到以下欧几里得距离得分：
- en: '[PRE61]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: How it works...
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In most cases, the distance used in the nearest neighbors algorithm is defined
    as the Euclidean distance between two
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，最近邻算法中使用的距离定义为两个点之间的欧几里得距离
- en: 'points, calculated according to the following formula:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下公式计算点数：
- en: '![](img/de18fb90-9e22-492e-ac02-1ce2a95fe7e2.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de18fb90-9e22-492e-ac02-1ce2a95fe7e2.png)'
- en: On a bidimensional plane, the Euclidean distance represents the minimum distance
    between two points, hence the straight line connecting two points. This distance
    is calculated as the square root of the sum of the squared difference between
    the elements of two vectors, as indicated in the previous formula.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维平面上，欧几里得距离表示两点之间的最小距离，因此是连接两点的直线。这个距离是两个向量元素平方差的和的平方根，如前一个公式所示。
- en: There's more...
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: There are other types of metrics for calculating distances. All of these types
    generally try to avoid the square roots, since they are expensive in computational
    terms, and are the source of several errors. Metrics include **Minkowski**, **Manhattan**,
    and the **cosine** distance.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他类型的度量用于计算距离。所有这些类型通常试图避免平方根，因为它们在计算上很昂贵，并且是几个错误的原因。度量包括**闵可夫斯基**、**曼哈顿**和**余弦**距离。
- en: See also
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: Refer to *MATLAB for Machine Learning*, Giuseppe Ciaburro, Packt Publishing
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考书籍《MATLAB for Machine Learning》，作者Giuseppe Ciaburro，Packt Publishing出版社
- en: 'Refer to *Similarities, Distances, and Manifold Learning* (from The University
    of York): [http://simbad-fp7.eu/images/tutorial/02-ECCV2012Tutorial.pdf](http://simbad-fp7.eu/images/tutorial/02-ECCV2012Tutorial.pdf)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '参考来自约克大学的《相似性、距离和流形学习》: [http://simbad-fp7.eu/images/tutorial/02-ECCV2012Tutorial.pdf](http://simbad-fp7.eu/images/tutorial/02-ECCV2012Tutorial.pdf)'
- en: 'Refer to *The Euclidean distance* (from Wikipedia): [https://en.wikipedia.org/wiki/Euclidean_distance](https://en.wikipedia.org/wiki/Euclidean_distance)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自维基百科的*欧几里得距离*：[https://en.wikipedia.org/wiki/Euclidean_distance](https://en.wikipedia.org/wiki/Euclidean_distance)
- en: Computing the Pearson correlation score
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算皮尔逊相关系数
- en: The Euclidean distance score is a good metric, but it has some shortcomings.
    Hence, the Pearson correlation score is frequently used in recommendation engines.
    The Pearson correlation score between two statistical variables is an index that
    expresses a possible linear relation between them. It measures the tendency of
    two numerical variables to vary simultaneously.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离得分是一个好的度量标准，但它有一些缺点。因此，皮尔逊相关系数在推荐引擎中经常被使用。两个统计变量之间的皮尔逊相关系数是一个指数，表示它们之间可能存在的线性关系。它衡量两个数值变量同时变化的趋势。
- en: Getting ready
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to compute the Pearson correlation score.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何计算皮尔逊相关系数。
- en: How to do it...
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s take a look at how to compute the Pearson correlation score:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何计算皮尔逊相关系数：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `pearson_score.py` file that''s already provided for you):'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码已包含在为你提供的`pearson_score.py`文件中）：
- en: '[PRE62]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We will define a function to compute the Pearson correlation score between
    two users in the database. Our first step is to confirm that these users exist
    in the database:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义一个函数来计算数据库中两个用户之间的皮尔逊相关系数。我们的第一步是确认这些用户存在于数据库中：
- en: '[PRE63]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The next step is to get the movies that both of these users rated:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是获取这两位用户都评分的电影：
- en: '[PRE64]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'If there are no common movies, then there is no discernible similarity between
    these users; hence, we return `0`:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有共同的电影，那么这些用户之间没有可识别的相似性；因此，我们返回`0`：
- en: '[PRE65]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We need to compute the sum of squared values of common movie ratings:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要计算共同电影评分的平方值之和：
- en: '[PRE66]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Now, let''s compute the sum of squared ratings of all the common movie ratings:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们计算所有共同电影评分的平方值之和：
- en: '[PRE67]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Let''s now compute the sum of the products:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们计算乘积之和：
- en: '[PRE68]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We are now ready to compute the various elements that we require to calculate
    the Pearson correlation score:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备计算计算皮尔逊相关系数所需的各种元素：
- en: '[PRE69]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We need to take care of the case where the denominator becomes `0`:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要处理分母变为`0`的情况：
- en: '[PRE70]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'If everything is good, we `return` the Pearson correlation score, as follows:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一切正常，我们`返回`皮尔逊相关系数，如下所示：
- en: '[PRE71]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Let''s now define the `main` function and compute the Pearson correlation score
    between two users:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们定义`main`函数并计算两个用户之间的皮尔逊相关系数：
- en: '[PRE72]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'If you run this code, you will see the following Pearson correlation score
    printed on the Terminal:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端上看到以下皮尔逊相关系数：
- en: '[PRE73]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: How it works...
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The *r* correlation coefficient of Pearson measures the correlation between
    variables at intervals or equivalent ratios. It is given by the sum of the products
    of the standardized scores of the two variables (z[x] * z[y]) divided by the number
    of subjects (or observations), as follows:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数的*r*系数衡量的是变量在间隔或等效比率之间的相关性。它由两个变量的标准化分数的乘积之和（z[x] * z[y]）除以受试者（或观察）的数量得出，如下所示：
- en: '![](img/5ea3ed8d-7463-47fc-9550-ebfc7eaf7d12.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ea3ed8d-7463-47fc-9550-ebfc7eaf7d12.png)'
- en: This coefficient can assume values ranging between -1.00 (between the two variables,
    there is a perfect negative correlation) and + 1.00 (between the two variables,
    there is a perfect positive correlation). A correlation of 0 indicates that there
    is no relationship between the two variables.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这个系数可以取介于-1.00（两个变量之间存在完美的负相关）和+1.00（两个变量之间存在完美的正相关）之间的值。相关性为0表示两个变量之间没有关系。
- en: There's more...
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It is necessary to remember that Pearson's formula is related to a linear relationship,
    and therefore, all the different forms of relationship can produce anomalous results.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 必须记住，皮尔逊公式与线性关系相关，因此，所有不同形式的关系都可能产生异常结果。
- en: See also
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料还包括
- en: Refer to *Regression Analysis with R*, Giuseppe Ciaburro, Packt Publishing
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Giuseppe Ciaburro的《使用R进行回归分析》，Packt出版社
- en: 'Refer to *The Pearson Correlation* (from Ken State University): [https://libguides.library.kent.edu/spss/pearsoncorr](https://libguides.library.kent.edu/spss/pearsoncorr)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自肯特州立大学的*皮尔逊相关*：[https://libguides.library.kent.edu/spss/pearsoncorr](https://libguides.library.kent.edu/spss/pearsoncorr)
- en: Finding similar users in the dataset
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据集中找到相似的用户
- en: One of the most important tasks in building a recommendation engine is finding
    users who are similar. This is useful in creating the recommendations that will
    be provided to these users.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建推荐引擎时，最重要的任务之一是找到相似的用户。这在创建提供给这些用户的推荐时非常有用。
- en: Getting ready
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to build a model to find users who are similar.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何构建一个模型来查找相似用户。
- en: How to do it...
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s take a look at how to find similar users in the dataset:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在数据集中查找相似用户：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `find_similar_users.py` file that''s already provided for you):'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 Python 文件并导入以下包（完整的代码在已为你提供的 `find_similar_users.py` 文件中）：
- en: '[PRE74]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Let''s define a function to find users who are similar to the input user. It
    takes three input arguments: the database, the input user, and the number of similar
    users that we are looking for. Our first step is to check whether the user is
    present in the database. If the user exists, we need to compute the Pearson correlation
    score between this user and all the other users in the database:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个函数来查找与输入用户相似的用户。它接受三个输入参数：数据库、输入用户以及我们正在寻找的相似用户数量。我们的第一步是检查用户是否存在于数据库中。如果用户存在，我们需要计算该用户与数据库中所有其他用户的皮尔逊相关得分：
- en: '[PRE75]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The next step is to sort these scores in descending order:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是将这些分数按降序排列：
- en: '[PRE76]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Let''s extract the *k* top scores and then return them:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们提取 *k* 个最高得分并返回它们：
- en: '[PRE77]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Let''s now define the main function and load the input database:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义主函数并加载输入数据库：
- en: '[PRE78]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We want to find three similar users to, `John Carson`, for example. We do this
    by using the following steps:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们想找到与 `John Carson` 相似的三个用户。我们通过以下步骤来完成：
- en: '[PRE79]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'If you run this code, you will see the following printed on your Terminal:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上看到以下输出：
- en: '[PRE80]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: How it works...
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we are looking for similar users to the input user. Given the
    database, the input user, and the number of similar users that we are looking
    for, we first check whether the user is present in the database. If the user exists,
    the Pearson correlation score between this user and all the other users in the
    database is computed.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们正在寻找与输入用户相似的用户。给定数据库、输入用户以及我们正在寻找的相似用户数量，我们首先检查用户是否存在于数据库中。如果用户存在，计算该用户与数据库中所有其他用户的皮尔逊相关得分。
- en: There's more...
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: To calculate the Pearson correlation score, the `pearson_score()` function was
    used. This function was defined in the previous *Computing the Pearson correlation
    score* recipe.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算皮尔逊相关得分，使用了 `pearson_score()` 函数。这个函数在之前的 *计算皮尔逊相关得分* 菜谱中定义。
- en: See also
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'Refer to *Pearson''s Correlation Coefficient* (from the University of the West
    of England): [http://learntech.uwe.ac.uk/da/default.aspx?pageid=1442](http://learntech.uwe.ac.uk/da/default.aspx?pageid=1442)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自西英格兰大学的 *皮尔逊相关系数*（[http://learntech.uwe.ac.uk/da/default.aspx?pageid=1442](http://learntech.uwe.ac.uk/da/default.aspx?pageid=1442)）
- en: 'Refer to *Pearson correlation coefficient* (from Wikipedia): [https://en.wikipedia.org/wiki/Pearson_correlation_coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考来自维基百科的 *皮尔逊相关系数*（[https://en.wikipedia.org/wiki/Pearson_correlation_coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)）
- en: Generating movie recommendations
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成电影推荐
- en: In this recipe, we will generate movie recommendations.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将生成电影推荐。
- en: Getting ready
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use all the functionality that we built in the previous
    recipes to build a movie recommendation engine. Let's take a look at how to build
    it.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用之前菜谱中构建的所有功能来构建一个电影推荐引擎。让我们看看如何构建它。
- en: How to do it...
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s take a look at how to generate movie recommendations:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何生成电影推荐：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `movie_recommendations.py` file that''s already provided for you):'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 Python 文件并导入以下包（完整的代码在已为你提供的 `movie_recommendations.py` 文件中）：
- en: '[PRE81]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We will define a function to generate movie recommendations for a given user. The
    first step is to check whether the user exists in the dataset:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义一个函数来为给定用户生成电影推荐。第一步是检查该用户是否存在于数据集中：
- en: '[PRE82]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Let''s now compute the Pearson score of this user with all the other users
    in the dataset:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来计算该用户与数据集中所有其他用户的皮尔逊得分：
- en: '[PRE83]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'We need to find the movies that haven''t been rated by this user:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要找到该用户尚未评分的电影：
- en: '[PRE84]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'If the user has watched every single movie in the database, then we cannot
    recommend anything to this user. Let''s take care of this condition:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果用户观看了数据库中的每一部电影，那么我们无法为该用户推荐任何内容。让我们处理这个条件：
- en: '[PRE85]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'We now have a list of these scores. Let''s create a normalized list of movie
    ranks:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了这些分数的列表。让我们创建一个电影排名的归一化列表：
- en: '[PRE86]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'We need to sort the list in descending order based on the score:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要根据分数按降序对列表进行排序：
- en: '[PRE87]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'We are finally ready to extract the movie recommendations:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们终于准备好提取电影推荐了：
- en: '[PRE88]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Now, let''s define the `main` function and load the dataset:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义`main`函数并加载数据集：
- en: '[PRE89]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Let''s now generate recommendations for `Michael Henry`, as follows:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为`Michael Henry`生成推荐，如下所示：
- en: '[PRE90]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The `John Carson` user has watched all the movies. Therefore, if we try to
    generate recommendations for him, it should display 0 recommendations. Let''s
    see whether this happens, as follows:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`John Carson`用户观看了所有电影。因此，如果我们尝试为他生成推荐，应该显示0个推荐。让我们看看这是否会发生，如下所示：'
- en: '[PRE91]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'If you run this code, you will see the following output on your Terminal:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上看到以下输出：
- en: '[PRE92]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: How it works...
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this recipe, we have built a movie recommendation engine. To generate recommendations
    for a given user, the following steps are performed:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们已经构建了一个电影推荐引擎。要为特定用户生成推荐，将执行以下步骤：
- en: First, we check whether the user is present in the database
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们检查用户是否存在于数据库中
- en: Then, we calculate the Person correlation score
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们计算皮尔逊相关系数
- en: We then create the normalized list
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建归一化列表
- en: Then, we sort this list in decreasing order based on the first column
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们根据第一列按降序排序这个列表
- en: Finally, we extract the recommended movies
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们提取推荐的电影
- en: There's more...
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: To build a movie recommendation engine, the `pearson_score()` function was used.
    This function was defined in the previous *Computing the Pearson correlation score* recipe.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建电影推荐引擎，使用了`pearson_score()`函数。该函数在之前的*计算皮尔逊相关系数评分*菜谱中定义。
- en: See also
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'Refer to *Introduction to Correlation and Regression Analysis* (from Boston
    University School of Public Health): [http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/bs704_multivariable5.html](http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/bs704_multivariable5.html)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考*相关性和回归分析导论*（来自波士顿大学公共卫生学院）：[http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/bs704_multivariable5.html](http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_multivariable/bs704_multivariable5.html)
- en: 'Refer to *Pearson Correlation Coefficient r* (From Penn State University):
    [https://newonlinecourses.science.psu.edu/stat501/node/256/](https://newonlinecourses.science.psu.edu/stat501/node/256/)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考*皮尔逊相关系数r*（来自宾夕法尼亚州立大学）：[https://newonlinecourses.science.psu.edu/stat501/node/256/](https://newonlinecourses.science.psu.edu/stat501/node/256/)
- en: 'Refer to *Correlation and Causation* (from the Australian Bureau of Statistics):
    [http://www.abs.gov.au/websitedbs/a3121120.nsf/home/statistical+language+-+correlation+and+causation](http://www.abs.gov.au/websitedbs/a3121120.nsf/home/statistical+language+-+correlation+and+causation)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考*相关性与因果关系*（来自澳大利亚统计局）：[http://www.abs.gov.au/websitedbs/a3121120.nsf/home/statistical+language+-+correlation+and+causation](http://www.abs.gov.au/websitedbs/a3121120.nsf/home/statistical+language+-+correlation+and+causation)
- en: Implementing ranking algorithms
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现排名算法
- en: '**Learning to rank** (**LTR**) is a method that is used in the construction
    of classification models for information retrieval systems. The training data
    consists of lists of articles with an induced partial order that gives a numerical
    or ordinal score, or a binary judgment for each article. The purpose of the model
    is to order the elements into new lists according to the scores that take into
    account the judgments obtained from the articles.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习排名**（LTR）是一种用于构建信息检索系统分类模型的方法。训练数据由包含诱导部分顺序的文章列表组成，该顺序为每篇文章提供一个数值或序数评分，或一个二元判断。模型的目的是根据从文章中获得的判断来考虑的评分，将元素重新排序到新的列表中。'
- en: Getting ready
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the `pyltr` package, which is a Python LTR toolkit
    with ranking models, evaluation metrics, and data-wrangling helpers.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用`pyltr`包，这是一个Python LTR工具包，包含排名模型、评估指标和数据整理助手。
- en: How to do it...
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s take a look at how to implement ranking algorithms:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何实现排名算法：
- en: 'Create a new Python file and import the following package (the full code is
    in the `LambdaMARTModel.py` file that''s already provided for you):'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整代码在已提供的`LambdaMARTModel.py`文件中）：
- en: '[PRE93]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'We will load the data contained in the Letor dataset that''s already provided
    for you (`train.txt`, `vali.txt`, and `test.txt`):'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将加载Letor数据集中包含的数据（`train.txt`，`vali.txt`和`test.txt`）：
- en: '[PRE94]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Let''s now perform a validation of the data:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们对数据进行验证：
- en: '[PRE95]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'We will build the model, as follows:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤构建模型：
- en: '[PRE96]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Now, we can fit the model using the text data:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用文本数据来拟合模型：
- en: '[PRE97]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Next, we can predict the data, as follows:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以按照以下方式预测数据：
- en: '[PRE98]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Finally, we print the results, as follows:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们按照以下方式打印结果：
- en: '[PRE99]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'The following results are printed:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果将被打印：
- en: '[PRE100]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: How it works...
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: LambdaMART is the enhanced tree version of LambdaRank, which is, in turn, based
    on RankNet. RankNet, LambdaRank, and LambdaMART are algorithms that are used to
    solve classification problems in many contexts. RankNet, LambdaRank, and LambdaMART
    have been developed by Chris Burges and his group at Microsoft Research. RankNet
    was the first one to be developed, followed by LambdaRank, and then LambdaMART.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: LambdaMART是LambdaRank的增强树版本，而LambdaRank又是基于RankNet的。RankNet、LambdaRank和LambdaMART是用于解决许多上下文中的分类问题的算法。RankNet、LambdaRank和LambdaMART是由微软研究小组的Chris
    Burges及其团队开发的。RankNet是第一个被开发的，随后是LambdaRank，然后是LambdaMART。
- en: RankNet is based on the use of neural networks, but the underlying model is
    not limited to neural networks alone. The cost function for RankNet aims to minimize
    the number of reversals in the ranking. RankNet optimizes the cost function using
    the stochastic gradient descent.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: RankNet基于神经网络的使用，但其底层模型并不仅限于神经网络。RankNet的成本函数旨在最小化排序中的反转次数。RankNet使用随机梯度下降来优化成本函数。
- en: The researchers found that during the RankNet training procedure, the costs
    are not required, only the gradients (λ) of the cost compared to the model score.
    You can think of these gradients as small arrows attached to each document in
    the classified list, indicating the direction in which we could move those documents.
    LambdaRank is based on this assumption.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员发现，在RankNet训练过程中，不需要成本，只需要与模型分数相比的成本梯度（λ）。你可以将这些梯度想象成附加在分类列表中每个文档上的小箭头，指示我们可以移动这些文档的方向。LambdaRank基于这个假设。
- en: There's more...
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Finally, LambdaMART combines the methods contained in LambdaRank and those present
    in **multiple regression additive trees** (**MART**). While MART uses decision
    trees with enhanced gradient for forecasting, LambdaMART uses enhanced gradient
    decision trees using a cost function derived from LambdaRank to solve a ranking
    task. LambdaMART proved to be more efficient than LambdaRank and the original
    RankNet.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，LambdaMART结合了LambdaRank中的方法和**多重回归加性树**（**MART**）中的方法。虽然MART使用增强梯度的决策树进行预测，但LambdaMART使用来自LambdaRank的成本函数的增强梯度决策树来解决排序任务。LambdaMART证明比LambdaRank和原始RankNet更有效。
- en: See also
  id: totrans-412
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'Refer to *Learning to Rank using Gradient Descent*: [https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文档：*使用梯度下降进行排序学习*：[https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2005/08/icml_ranking.pdf)
- en: 'Refer to the Python LTR toolkit: [https://github.com/jma127/pyltr](https://github.com/jma127/pyltr)'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Python LTR工具包：[https://github.com/jma127/pyltr](https://github.com/jma127/pyltr)
- en: 'Refer to *LETOR: Learning to Rank for Information Retrieval*: [https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fbeijing%2Fprojects%2Fletor%2F](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fbeijing%2Fprojects%2Fletor%2F)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文档：*LETOR：信息检索中的排序学习*：[https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fbeijing%2Fprojects%2Fletor%2F](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fbeijing%2Fprojects%2Fletor%2F)
- en: Building a filtering model using TensorFlow
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建过滤模型
- en: Collaborative filtering refers to a class of tools and mechanisms that allow
    the retrieval of predictive information regarding the interests of a given set
    of users starting from a large and yet undifferentiated mass of knowledge. Collaborative
    filtering is widely used in the context of recommendation systems. A well-known
    category of collaborative algorithms is matrix factorization.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤是指一类工具和机制，它允许从大量未区分的知识中检索有关给定用户兴趣的预测信息。协同过滤在推荐系统环境中被广泛使用。协同算法的一个知名类别是矩阵分解。
- en: The fundamental assumption behind the concept of collaborative filtering is
    that every single user who has shown a certain set of preferences will continue
    to show them in the future. A popular example of collaborative filtering can be
    a system of suggested movies starting from a set of basic knowledge of the tastes
    and preferences of a given user. It should be noted that although this information
    is referring to a single user, they derive this from the knowledge that has been
    processed throughout the whole system of users.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤概念背后的基本假设是，每个表现出一定偏好集合的用户将继续在未来表现出这些偏好。协同过滤的一个流行例子是从给定用户的基本口味和偏好知识开始的电影推荐系统。应注意的是，尽管这些信息是针对单个用户的，但他们是从整个用户系统中处理过的知识中推导出来的。
- en: Getting ready
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will see how to build a collaborative filtering model for
    personalized recommendations using TensorFlow. We will use the MovieLens 1M dataset,
    which contains 1 million ratings from approximately 6,000 users for approximately
    4,000 movies.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将看到如何使用TensorFlow构建用于个性化推荐的协同过滤模型。我们将使用MovieLens 1M数据集，该数据集包含大约6,000名用户对大约4,000部电影的大约100万条评分。
- en: How to do it...
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s take a look at how to build a filtering model using TensorFlow:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用TensorFlow构建过滤模型：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `TensorFilter.py` file that''s already provided for you):'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在您已经提供的`TensorFilter.py`文件中）：
- en: '[PRE101]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'We will load the data contained in the MovieLens 1M dataset that''s already
    provided for you (`ratings.csv`):'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将加载您已经提供的MovieLens 1M数据集中包含的数据（`ratings.csv`）：
- en: '[PRE102]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'The following returns are returned:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 以下返回结果：
- en: '[PRE103]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'Now, let''s perform data scaling, as follows:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们进行数据缩放，如下所示：
- en: '[PRE104]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'We will build the user item matrix, as follows:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将构建用户物品矩阵，如下所示：
- en: '[PRE105]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Now, we can set some network parameters, as follows:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以设置一些网络参数，如下所示：
- en: '[PRE106]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Now, we will initialize the TensorFlow placeholder. Then, `weights` and `biases`
    are randomly initialized:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将初始化TensorFlow占位符。然后，`权重`和`偏置`被随机初始化：
- en: '[PRE107]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Now, we can build the encoder and decoder model, as follows:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以构建编码器和解码器模型，如下所示：
- en: '[PRE108]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'We will construct the model and predict the value, as follows:'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将构建模型并预测值，如下所示：
- en: '[PRE109]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'We will now define `loss` and `optimizer`, and minimize the squared error and
    the evaluation metrics:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将定义`损失`和`优化器`，并最小化平方误差和评估指标：
- en: '[PRE110]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Let''s now initialize the variables, as follows:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们现在初始化变量，如下所示：
- en: '[PRE111]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Finally, we can start to train our model:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以开始训练我们的模型：
- en: '[PRE112]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'The following results are returned:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果返回：
- en: '[PRE113]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: These are the top 10 results for the `1` user.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 这是针对`1`个用户的top 10结果。
- en: How it works...
  id: totrans-450
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The collaborative filter approach focuses on finding users who have made similar
    judgments to the same objects, thus creating a link between users, to whom will
    be suggested objects that one of the two has reviewed in a positive way, or simply
    with which they have interacted. In this way, we look for associations between
    users, and no longer between objects.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤方法侧重于寻找对相同对象做出相似判断的用户，从而在用户之间建立联系，向他们推荐两个用户中任何一个都正面评价或与之互动的对象。这样，我们寻找的是用户之间的关联，而不是对象之间的关联。
- en: There's more...
  id: totrans-452
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The user item matrix represents a user's preferences for an object, but, if
    read by columns, highlights who a certain movie was liked or disliked by. In this
    way, you can see how a similarity between two objects can also be expressed without
    the object matrix, simply by observing that the films that are liked by the same
    people are probably similar in some way.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 用户物品矩阵代表用户对某个对象的偏好，但如果按列读取，则突出显示某个电影是被喜欢还是不喜欢的。这样，你可以看到两个对象之间的相似性也可以通过观察喜欢相同电影的同一群人，以某种方式相似地表达出来。
- en: See also
  id: totrans-454
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'Refer to *Collaborative filtering* (from The University of Texas at Dallas):
    [https://www.utdallas.edu/~nrr150130/cs6375/2015fa/lects/Lecture_23_CF.pdf](https://www.utdallas.edu/~nrr150130/cs6375/2015fa/lects/Lecture_23_CF.pdf)'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考德克萨斯大学达拉斯分校的*协同过滤*：[https://www.utdallas.edu/~nrr150130/cs6375/2015fa/lects/Lecture_23_CF.pdf](https://www.utdallas.edu/~nrr150130/cs6375/2015fa/lects/Lecture_23_CF.pdf)
- en: 'Refer to *Matrix Factorization and Collaborative Filtering* (from Carnegie
    Mellon University): [https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf](https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf)'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考卡内基梅隆大学的*矩阵分解与协同过滤*：[https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf](https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf)
- en: 'Refer to the *TensorFlow Tutorial* (from Stanford University): [https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf](https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考斯坦福大学的*TensorFlow教程*：[https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf](https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf)
