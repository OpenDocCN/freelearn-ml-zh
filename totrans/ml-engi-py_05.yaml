- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Deployment Patterns and Tools
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署模式和工具
- en: In this chapter, we will dive into some important concepts around the deployment
    of your **machine learning** (**ML**) solution. We will begin to close the circle
    of the ML development lifecycle and lay the groundwork for getting your solutions
    out into the world.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨围绕部署您的**机器学习**（**ML**）解决方案的一些重要概念。我们将开始闭合机器学习开发生命周期的闭环，并为将您的解决方案推向世界打下基础。
- en: The act of deploying software, of taking it from a demo you can show off to
    a few stakeholders to a service that will ultimately impact customers or colleagues,
    is a very exhilarating but often challenging exercise. It also remains one of
    the most difficult aspects of any ML project and getting it right can ultimately
    make the difference between generating value or just hype.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 将软件部署的过程，即从您可以向少数利益相关者展示的演示版本到最终影响客户或同事的服务，是一项非常令人兴奋但往往具有挑战性的练习。这也一直是任何机器学习项目中最困难的部分之一，而且做对它最终可能是在创造价值或仅仅炒作之间产生差异的关键。
- en: We are going to explore some of the main concepts that will help your ML engineering
    team cross the chasm between a fun proof-of-concept to solutions that can run
    on scalable infrastructure in an automated way. This will require us to first
    cover questions of how to design and architect your ML systems, particularly if
    you want to develop solutions that can be scaled and extended seamlessly. We will
    then discuss the concept of containerization and how this allows your application
    code to be abstracted from the specific infrastructure it is being built or run
    on, allowing for portability in many different cases. We will then move on to
    a concrete example of using these ideas to deploy an ML microservice on AWS. The
    rest of the chapter will then return to the question of how to build effective
    and robust pipelines for your end-to-end ML solution, which was introduced in
    *Chapter 4*, *Packaging Up*. We will introduce and explore **Apache Airflow**
    for building and orchestrating any generic Python process, including your data
    preparation and ML pipelines. Then we will finish up with a similar deep dive
    on **ZenML** and **Kubeflow**, two open-source advanced ML pipelining tools that
    are now extensively used in industry. This collection of tools means that you
    should finish this chapter feeling very confident that you can deploy and orchestrate
    quite complex ML solutions using a variety of software.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨一些主要概念，这些概念将帮助您的机器学习（ML）工程团队能够跨越从有趣的证明概念到可以在可扩展基础设施上以自动化方式运行的解决方案之间的鸿沟。这要求我们首先讨论如何设计和架构您的机器学习（ML）系统，尤其是如果您想开发可以无缝扩展和扩展的解决方案。然后我们将讨论容器化的概念以及它如何允许您的应用程序代码从它正在构建或运行的特定基础设施中抽象出来，从而在许多不同情况下实现可移植性。然后我们将继续到一个具体的例子，使用这些想法在AWS上部署机器学习（ML）微服务。本章的其余部分将回到如何构建有效且健壮的管道以用于您的端到端机器学习（ML）解决方案的问题，这在*第4章*，*打包*中已介绍。我们将介绍并探索**Apache
    Airflow**，用于构建和编排任何通用的Python过程，包括您的数据准备和机器学习（ML）管道。然后我们将以类似的方式深入研究**ZenML**和**Kubeflow**，这两个开源的高级机器学习（ML）管道工具现在在工业界得到了广泛的应用。这些工具的集合意味着您应该在本章结束时非常有信心，可以使用各种软件部署和编排相当复杂的机器学习（ML）解决方案。
- en: 'This will all be broken down into the following sections:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都将分为以下几部分：
- en: Architecting systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统架构
- en: Exploring some standard ML patterns
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索一些标准的机器学习（ML）模式
- en: Containerizing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器化
- en: Hosting your own microservice on **Amazon Web Services** (**AWS**)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**亚马逊网络服务**（**AWS**）上托管您的微服务
- en: Building general pipelines with Airflow
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Airflow构建通用管道
- en: Building advanced ML pipelines
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建高级机器学习（ML）管道
- en: The next section will kick things off with a discussion of how we can architect
    and design our ML systems with deployment in mind. Let’s go!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将开始讨论如何考虑部署来架构和设计我们的机器学习（ML）系统。让我们开始吧！
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: As with the other chapters, you can set up your Python development environment
    to be able to run the examples in this chapter by using the supplied Conda environment
    `yml` file or the `requirements.txt` files from the book repository, under *Chapter05*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他章节一样，您可以通过使用提供的Conda环境`yml`文件或从书库中的*Chapter05*目录下的`requirements.txt`文件来设置您的Python开发环境，以便能够运行本章中的示例。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You will also require some non-Python tools to be installed to follow the examples
    from end to end. Please see the respective documentation for each tool:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要安装一些非Python工具才能从头到尾跟随示例。请参阅每个工具的相关文档：
- en: AWS CLI v2
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI v2
- en: Postman
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Postman
- en: Docker
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker
- en: Architecting systems
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统架构
- en: No matter how you are working to build your software, it is always important
    to have a design in mind. This section will highlight the key considerations we
    must bear in mind when architecting ML systems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你如何努力构建你的软件，始终有一个设计在心中是非常重要的。本节将强调我们在设计机器学习系统时必须牢记的关键考虑因素。
- en: Consider a scenario where you are contracted to organize the building of a house.
    We would not simply go out and hire a team of builders, buy all the supplies,
    hire all the equipment, and just tell everyone to *start building*. We would also
    not assume we knew exactly what the client who hired us wants without first speaking
    to them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这样一个场景，你被雇佣来组织建造房屋。我们不会简单地出去雇佣一支建筑队，购买所有材料，雇佣所有设备，然后告诉每个人开始建造。我们也不会在没有先与他们交谈的情况下就假设我们确切地知道雇佣我们的客户想要什么。
- en: Instead, we would likely try to understand what the client wanted in detail,
    and then try to design the solution that would fit their requirements. We would
    potentially iterate this plan a few times with them and with appropriate experts
    who knew the details of pieces that fed into the overall design. Although we are
    not interested in building houses (or maybe you are, but there will not be any
    in this book!), we can still see the analogy with software. Before building anything,
    we should create an effective and clear design. This design provides the direction
    of travel for the solution and helps the build team know exactly what components
    they will work on. This means that we will be confident that what we build will
    solve the end user’s problem.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可能会试图详细了解客户的需求，然后尝试设计符合他们要求的解决方案。我们可能会与他们以及了解整体设计细节的适当专家一起迭代这个计划几次。尽管我们可能不感兴趣建造房屋（或者也许你感兴趣，但本书中不会有任何房屋的例子！），但我们仍然可以将其与软件进行类比。在建造任何东西之前，我们应该创建一个有效且清晰的设计。这个设计为解决方案提供了方向，并帮助构建团队确切地知道他们将工作的组件。这意味着我们将有信心，我们所建造的东西将解决最终用户的问题。
- en: This, in a nutshell, is what software architecture is all about.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这就是软件架构的全部内容。
- en: If we did the equivalent of the above example for our ML solution, some of the
    following things may happen. We could end up with a very confusing code base,
    with some ML engineers in our team building elements and functionality that are
    already covered by the work that other engineers have done. We may also build
    something that fundamentally cannot work later in the project; for example, if
    we have selected a tool that has specific environmental requirements we cannot
    meet due to another component. We may also struggle to anticipate what infrastructure
    we need to be provisioned ahead of time, leading to a disorganized scramble within
    the project to get the correct resource. We may also underestimate the amount
    of work required and miss our deadline. All of these are outcomes we wish to avoid
    and can be avoided if we are following a good design.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对我们的机器学习解决方案做了上述类似的事情，以下一些事情可能会发生。我们可能会得到一个非常混乱的代码库，我们团队中的某些机器学习工程师可能会构建已经被其他工程师的工作所覆盖的元素和功能。我们也可能会构建在项目后期基本无法工作的东西；例如，如果我们选择了一个具有特定环境要求，而我们无法满足这些要求的工具。我们也可能难以预测需要提前配置的基础设施，导致项目内部混乱地争夺正确的资源。我们也可能低估所需的工作量，错过截止日期。所有这些都是我们希望避免的结果，如果我们遵循良好的设计，这些结果是可以避免的。
- en: 'In order to be effective, the architecture of a piece of software should provide
    at least the following things to the team working on building the solution:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效，软件的架构应该至少为构建解决方案的团队提供以下东西：
- en: It should define the functional components required to solve the problem in
    totality.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该定义解决整个问题的所需功能组件。
- en: It should define how these functional components will interact, usually through
    the exchange of some form of data.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该定义这些功能组件如何交互，通常是通过交换某种形式的数据。
- en: It should show how the solution can be extended in the future to include further
    functionality the client may require.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该展示解决方案如何在未来扩展，以包括客户可能需要的进一步功能。
- en: It should provide guidance on which tools should be selected to implement each
    of the components outlined in the architecture.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该提供关于应选择哪些工具来实现架构中概述的每个组件的指导。
- en: It should stipulate the process flow for the solution, as well as the data flow.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该规定解决方案的过程流程以及数据流程。
- en: This is what a piece of good architecture should do, but what does this actually
    mean in practice?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是一件好的架构应该做的事情，但实际上这意味着什么呢？
- en: There is no strict definition of how an architecture has to be compiled. The
    key point is that it acts as a design against which building can progress. So,
    for example, this might take the form of a nice diagram with boxes, lines, and
    some text, or it could be a several-page document. It might be compiled using
    a formal modeling language such as **Unified Modeling Language** (**UML**), or
    not. This often depends on the business context in which you operate and what
    requirements are placed on the people writing the architecture. The key is that
    it checks off the points above and gives the engineers clear guidance on what
    to build and how it will all stick together.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如何构建架构并没有严格的定义。关键点在于它作为一个设计，建筑可以在此基础上进行。例如，这可能是一个带有框、线和一些文本的漂亮图表，或者可能是一份多页文档。它可能使用形式化的建模语言，如**统一建模语言**（**UML**），也可能不使用。这通常取决于你所在的企业环境以及对你编写架构的人提出的要求。关键是它检查了上述要点，并为工程师提供了关于要构建什么以及如何将这些部分组合在一起的明确指导。
- en: Architecture is a vast and fascinating subject in itself, so we will not go
    much further into the details of this here, but we will now focus on what architecture
    means in an ML engineering context.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 架构本身是一个广泛而迷人的主题，所以我们不会在这里深入探讨其细节，但我们将现在关注在ML工程背景下的架构含义。
- en: Building with principles
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建筑原则
- en: The field of architecture is vast but no matter where you look, like any mature
    discipline, there are always consistent principles that are presented. The good
    news is that some of them are actually the same as some of the principles we met
    when discussing good Python programming in *Chapter 4*, *Packaging Up*. In this
    section, we will discuss some of these and how they can be used for architecting
    ML systems.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 架构领域非常广泛，但无论你往哪里看，就像任何成熟的学科一样，总有始终如一的原则被提出。好消息是，其中一些原则实际上与我们讨论第4章“打包”时遇到的原则相同。在本节中，我们将讨论这些原则以及它们如何用于架构ML系统。
- en: '**Separation of Concerns** has already been mentioned in this book as a good
    way to ensure that software components inside your applications are not unnecessarily
    complex and that your solutions are extensible and can be easily interfaced with.
    This principle holds true of systems in their entirety and as such is a good architecture
    principle to bear in mind. In practice, this often manifests in the idea of separate
    “layers” within your applications that have distinct responsibilities. For example,
    let’s look at the architecture shown in *Figure 5.1*. This shows how to use tools
    to create an automated deployment and orchestration process for ML pipelines and
    is taken from the AWS Solutions Library, [https://aws.amazon.com/solutions/implementations/mlops-workload-orchestrator/](https://aws.amazon.com/solutions/implementations/mlops-workload-orchestrator/).
    We can see that there are distinct “areas” within the architecture corresponding
    to provisioning, pipeline deployment, and pipeline serving. These blocks show
    that there are distinct pieces of the solution that have specific functionalities
    and that the interaction between these different pieces is handled by an interface.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**关注点分离**已经在本书中提到，是确保应用程序内部软件组件不必要复杂以及解决方案可扩展且易于接口的一种好方法。这个原则对整个系统都适用，因此是一个值得记住的良好架构原则。在实践中，这通常表现为应用程序内部有不同职责的“层”的概念。例如，让我们看看图5.1所示的架构。这展示了如何使用工具创建自动化部署和编排过程，它来自AWS解决方案库，[https://aws.amazon.com/solutions/implementations/mlops-workload-orchestrator/](https://aws.amazon.com/solutions/implementations/mlops-workload-orchestrator/)。我们可以看到，架构中有对应于资源分配、管道部署和管道服务的“区域”。这些块表明解决方案中有具有特定功能的独立部分，而这些不同部分之间的交互由接口处理。'
- en: '![](img/B19525_05_01.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_01.png)'
- en: 'Figure 5.1: An ML workload orchestrator architecture from the AWS Solutions
    Library MLOps Workload Orchestrator.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：AWS解决方案库中的ML工作负载编排器架构。
- en: The **Principle of Least Surprise** is a rule of thumb that essentially captures
    the fact that the first time any reasonably knowledgeable person in your domain,
    such as a developer, tester, or data scientist, encounters your architecture,
    it should not have anything within it that should stand out as unorthodox or surprising.
    This may not always be possible, but it is a good principle to keep in mind as
    it forces you to consider what those who are likely to be working with your architecture
    already know and how you can leverage that to both make a good design and have
    it followed. Using *Figure 5.1* as an example again, the architecture embodies
    the principle very nicely, as the design has clear logic building blocks for provisioning,
    promoting, and running the ML pipelines. At a lower level in the architecture,
    we can see that data is consistently being sourced from S3 buckets, that Lambdas
    are interacting with API gateways, and so on and so forth. This means that ML
    engineers, data scientists, and cloud platform engineers will both understand
    and leverage this architecture well when implementing it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小惊讶原则**是一个经验法则，它本质上捕捉了这样一个事实：当你领域中的任何合理有知识的人，比如开发者、测试员或数据科学家，第一次遇到你的架构时，其中不应该有任何不寻常或令人惊讶的东西。这可能并不总是可能的，但这是一个值得记住的好原则，因为它迫使你考虑那些可能与你架构一起工作的人已经知道什么，以及你如何利用这一点来做出良好的设计并使其得到遵循。再次以*图5.1*为例，架构很好地体现了这一原则，因为设计有清晰的逻辑构建块，用于提供、提升和运行机器学习管道。在架构的较低层面，我们可以看到数据始终来自S3存储桶，Lambda与API网关进行交互，等等。这意味着机器学习工程师、数据科学家和云平台工程师在实施时都会很好地理解和利用这个架构。'
- en: The **Principle of Least Effort** is a bit more subtle than the previous one,
    in that it captures the idea that developers, being human, will follow the path
    of least resistance and not create more work unless necessary. I interpret this
    principle as emphasizing the importance of taking the time to consider your architecture
    thoughtfully and building it with care, as it could be used for a long time after
    it has been developed, by engineer after engineer!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小努力原则**比前一个原则更微妙，因为它捕捉了这样一个想法：开发者作为人类，会遵循阻力最小的路径，除非必要，否则不会创造更多的工作。我解读这个原则为强调花时间深思熟虑地考虑你的架构并小心构建它的重要性，因为它在开发后可能会被工程师长时间使用！'
- en: So far, we have only discussed high-level architecture principles. Now we will
    look at some design principles that – while they can still be used at the system
    design level – are also very powerful when used at the level of your code.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了高级架构原则。现在我们将探讨一些设计原则，虽然它们在系统设计层面仍然可以使用，但在你的代码层面使用时也非常强大。
- en: 'The **SOLID** principles (**Single Responsibility**, **Open/Closed**, **Liskov
    Substitution**, **Interface Segregation**, **Dependency Inversion**) are a set
    that is often applied to the code base but can also be extrapolated up to system
    design and architecture quite nicely. Once we adapt these principles to the architecture
    level, they can be explained in the following way:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**SOLID原则**（**单一职责**、**开放/封闭**、**里氏替换**、**接口隔离**、**依赖倒置**）是一组通常应用于代码库的原则，但也可以很好地扩展到系统设计和架构。一旦我们将这些原则应用到架构层面，它们可以这样解释：'
- en: '**Single Responsibility**: This is very similar, perhaps identical, to the
    idea of separation of concerns. Specifically, this states that if a module only
    has one reason to change at any one time, or it only has one job to do, then this
    makes it more resilient and easier to maintain. If you have one box in your architecture
    diagram that is going to have to do ten different things, then you have violated
    this principle and it means that whenever any one of those processes or interfaces
    has to change, you have to go into that box and poke around, potentially creating
    more issues or drastically increasing the likelihood of downtime.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单一职责**：这与关注点分离的概念非常相似，也许可以说是相同的。具体来说，这表明如果一个模块在任何时候只有一个改变的理由，或者只有一个任务要做，那么这会使它更加健壮且更容易维护。如果你在架构图中有一个盒子需要做十件事，那么你就违反了这个原则，这意味着每当这些流程或接口中的任何一个需要改变时，你都必须进入那个盒子四处摸索，可能会产生更多问题或极大地增加停机时间。'
- en: '**Open/Closed**: This refers to the fact that it is a really good idea to architect
    in a way that components are “open for extension but closed for modification.”
    This also works at the level of the entire design. If you design your system so
    that new functionality can be tagged on and does not require going back and rewiring
    the core, then you will likely build something that will stand the test of time.
    A great example from ML would be that if we try and build our system so that if
    we want to add in new processing pipelines we can just do that, and we don’t have
    to go back into some obscure section of the code and severely modify things.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放/封闭原则**：这指的是以组件“对扩展开放但对修改封闭”的方式进行架构设计是一个非常不错的想法。这在整个设计层面也是适用的。如果你设计你的系统，使得新的功能可以添加而不需要回过头去重新布线核心部分，那么你很可能会构建出能够经受时间考验的东西。在机器学习领域的一个很好的例子是，如果我们尝试构建我们的系统，以便我们想要添加新的处理管道时，我们可以直接这样做，而不必回到代码的某个晦涩部分进行严重修改。'
- en: '**Liskov Substitution**: When the SOLID principles were written, they originally
    referred to object-oriented programming in languages like Java. This principle
    then stated that objects should be able to be replaced by their subtypes and still
    maintain application behavior. At the system level, this now basically states
    that if two components are supposed to have the same interface and contract with
    other components, you can swap them for one another.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**里氏替换原则**：当SOLID原则被编写时，它们最初是指Java等语言中的面向对象编程。这个原则当时指出，对象应该能够被它们的子类型替换，同时仍然保持应用程序的行为。在系统层面，这现在基本上表示，如果两个组件应该具有相同的接口并与其他组件进行交互，你可以互相替换它们。'
- en: '**Interface Segregation**: I interpret this one as “don’t have multiple ways
    for components to talk to one another.” So, in your application, try and ensure
    that the ways of handing off between different pieces of the solution are pretty
    narrow. Another way of phrasing this is that making your interfaces as client
    specific as possible is a good idea.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**接口隔离原则**：我理解这个原则为“不要让组件之间有多个交流方式。”所以，在你的应用程序中，尽量确保不同解决方案部分之间的交接方式非常狭窄。另一种表述方式是，尽可能使你的接口针对客户端是好的想法。'
- en: '**Dependency Inversion**: This is very similar to the Liskov Substitution principle
    but is a bit more general. The idea here is that the communications between modules
    or parts of your solution should be taken care of by abstractions and not by a
    concrete, specific implementation. A good example would be that instead of calling
    an ML microservice directly from another process, you instead place the requisite
    job data in a queue, for example, AWS Simple Queue Service, and then the microservice
    picks up the work from the queue. This ensures that the client and the serving
    microservice do not need to know details about each other’s interface, and also
    that the downstream application can be extended with more services reading from
    the queue. This would then also embody the Open/Closed principle, and can be seen
    in the architecture in *Figure 5.1* through the use of the Lambda function calling
    into AWS CloudFormation.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖倒置原则**：这与里氏替换原则非常相似，但更为通用。这里的想法是，模块或你解决方案的部分之间的通信应该由抽象来处理，而不是由具体的、特定的实现来处理。一个很好的例子是，与其直接从另一个进程调用机器学习微服务，你不如将必要的作业数据放入队列中，例如AWS简单队列服务，然后微服务从队列中提取工作。这确保了客户端和提供服务的微服务不需要了解彼此的接口细节，同时也确保下游应用程序可以通过读取队列来扩展更多的服务。这也就体现了开放/封闭原则，并且可以在*图5.1*的架构中通过Lambda函数调用AWS
    CloudFormation来看到这一点。'
- en: A final favorite of mine is the concept of **Bounded Contexts**, where we have
    to seek to ensure that data models, or other important data or metadata, are aligned
    within specific conceptual models and are not a “free-for-all.” This applies particularly
    well to Domain-Driven Design and applies very well to large, complex solutions.
    A great example would be if you have a large organization with multiple business
    units and they want a series of very similar services that run ML on business
    data stored in a database. It would be better for there to be several databases
    hosting the information, one for each business unit, rather than having a shared
    data layer across multiple applications. More concretely, your data model shouldn’t
    contain information specific to the sales and marketing function and the engineering
    function and the human resources function, and so on. Instead, each should have
    their own database with their own models, and there should be explicit contracts
    for joining any information between them later if needed. I believe that this
    idea can still be applied to Data Lakes, which are discussed later in this chapter.
    In this case, the bounded contexts could apply to specific folders within the
    lake, or they could actually refer to the context of entire lakes, each segregated
    into different domains. This is very much the idea behind the so-called Data Mesh.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人的一个最喜欢的概念是**边界上下文**，我们必须努力确保数据模型或其他重要的数据或元数据与特定的概念模型保持一致，而不是“自由放任”。这一点特别适用于领域驱动设计，并且非常适合大型、复杂的解决方案。一个很好的例子是，如果你有一个大型组织，拥有多个业务单元，并且他们希望运行在存储在数据库中的业务数据上的非常相似的服务。最好是有几个数据库来托管信息，每个业务单元一个，而不是在多个应用程序之间共享数据层。更具体地说，你的数据模型不应该包含特定于销售和营销职能、工程职能和人力资源职能等信息。相反，每个职能都应该有自己的数据库和自己的模型，如果需要，应该有明确的合同来连接它们之间的任何信息。我相信这个想法仍然可以应用于后面章节中讨论的数据湖。在这种情况下，边界上下文可以应用于湖中的特定文件夹，或者它们实际上可以指整个湖的上下文，每个都被隔离在不同的领域。这正是所谓的数据网格背后的理念。
- en: We have just mentioned some of the most used ML patterns, so let’s now move
    on to explore this concept in a bit more detail as we look to apply the principles
    we have been discussing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚提到了一些最常用的机器学习模式，现在让我们更详细地探讨这个概念，因为我们正在寻找应用我们一直在讨论的原则。
- en: Exploring some standard ML patterns
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索一些标准的机器学习模式
- en: In this book, we have already mentioned a few times that we should not attempt
    to *reinvent* the wheel and we should reuse, repeat, and recycle what works according
    to the wider software and ML community. This is also true about your deployment
    architectures.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们已经多次提到，我们不应该试图*重新发明轮子*，而应该重用、重复和回收更广泛的软件和机器学习社区中行之有效的方法。这同样适用于你的部署架构。
- en: When we discuss architectures that can be reused for a variety of different
    use cases with similar characteristics, we often refer to these as *patterns*.
    Using standard (or at least well-known) patterns can really help you speed up
    the time to value of your project and help you engineer your ML solution in a
    way that is robust and extensible.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论可以用于具有相似特性的各种不同用例的架构时，我们通常将这些称为*模式*。使用标准（或者至少是众所周知的）模式确实可以帮助你加快项目的价值实现时间，并帮助你以稳健和可扩展的方式构建机器学习解决方案。
- en: Given this, we will spend the next few sections summarizing some of the most
    important architectural patterns that have become increasingly successful in the
    ML space over the past few years.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，在接下来的几节中，我们将总结一些在过去几年中在机器学习领域越来越成功的最重要的架构模式。
- en: Swimming in data lakes
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据湖中游泳
- en: The single most important asset for anyone trying to use ML is, of course, the
    data that we can analyze and train our models on. The era of **big data** meant
    that the sheer size and variability in the format of this data became an increasing
    challenge. If you are a large organization (or even not so large), it is not viable
    to store all of the data you will want to use for ML applications in a structured
    relational database. Just the complexity of modeling the data for storage in such
    a format would be very high. So, what can you do?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何试图使用机器学习（ML）的人来说，最重要的资产当然是我们可以分析和训练模型的数据。大数据时代意味着数据的规模和格式多样性成为了一个日益增长的挑战。如果你是一个大型组织（或者甚至不是那么大），将所有你希望用于ML应用的数据存储在结构化关系数据库中是不可行的。仅仅是为了存储这种格式中的数据而建模的复杂性就非常高。那么，你能做什么呢？
- en: Well, this problem was initially tackled with the introduction of **data warehouses**,
    which let you bring all of your relational data storage into one solution and
    create a single point of access. This helps alleviate, to some extent, the problem
    of data volumes, as each database can store relatively small amounts of data even
    if the total is large. These warehouses were designed with the integration of
    multiple data sources in mind. However, they are still relatively restrictive
    as they usually bundle together the infrastructure for compute and storage. This
    means they can’t be scaled very well, and they can be expensive investments that
    create vendor lock-in. Most importantly for ML, data warehouses cannot store raw
    and semi-structured or unstructured data (for example, images). This automatically
    rules out a lot of good ML use cases if warehouses are used as your main data
    store. Now, with tools such as **Apache Spark**, which we’ve already used extensively
    throughout this book, if we have the clusters available, we can feasibly analyze
    and model any size or structure of data. The question then becomes, how should
    we store it?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这个问题最初是通过引入**数据仓库**来解决的，它允许你将所有关系型数据存储整合到一个解决方案中，并创建一个单一的访问点。这在一定程度上有助于缓解数据量的问题，因为即使总量很大，每个数据库也能存储相对较小的数据量。这些仓库在设计时考虑了多个数据源的集成。然而，它们仍然相对受限，因为它们通常将计算和存储的基础设施捆绑在一起。这意味着它们很难进行扩展，并且可能成为昂贵的投资，导致供应商锁定。最重要的是，对于机器学习来说，数据仓库无法存储原始的、半结构化或非结构化数据（例如，图像）。如果使用仓库作为主要数据存储，这会自动排除许多好的机器学习用例。现在，有了像**Apache
    Spark**这样的工具，我们在整本书中已经广泛使用，如果我们有可用的集群，我们实际上可以分析和建模任何大小或结构的数据。那么问题就变成了，我们应该如何存储它？
- en: '**Data lakes** are technologies that allow you to store any type of data at
    any scale you feasibly need. There are a variety of providers of data lake solutions,
    including the main public cloud providers, such as **Microsoft Azure**, **Google
    Cloud Platform** (**GCP**), and AWS. Since we have met AWS before, let’s focus
    on that.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据湖**是允许你在任何可操作的规模下存储任何类型数据的技术。有各种各样的数据湖解决方案提供商，包括主要的公共云提供商，如**Microsoft
    Azure**、**Google Cloud Platform**（**GCP**）和AWS。由于我们之前已经接触过AWS，让我们专注于它。'
- en: The main storage solution in AWS is called the **Simple Storage Service**, or
    **S3**. Like all of the core data lake technologies, you can effectively load
    anything into it since it is based on the concept of *object storage*. This means
    that every instance of data you load is treated as its own object with a unique
    identifier and associated metadata.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: AWS中的主要存储解决方案被称为**简单存储服务**，或**S3**。像所有核心数据湖技术一样，你可以有效地将其中的任何内容加载进去，因为它基于**对象存储**的概念。这意味着你加载的每个数据实例都被视为一个具有唯一标识符和相关元数据的独立对象。
- en: It allows your S3 bucket to simultaneously contain photographs, JSON files,
    `.txt` files, Parquet files, and any other number of data formats.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许你的S3存储桶同时包含照片、JSON文件、`.txt`文件、Parquet文件以及其他多种数据格式。
- en: If you work in an organization that does not have a data lake, this does not
    automatically exclude you from doing ML, but it can definitely make it a more
    difficult journey since with a lake you always know how you can store the data
    you need for your problem, no matter the format.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个没有数据湖的组织工作，这并不意味着你无法进行机器学习，但确实可能会使这个过程变得更加困难，因为有了数据湖，你总是知道如何存储你为解决问题所需的数据，无论其格式如何。
- en: Microservices
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务
- en: Your ML project’s code base will start small – just a few lines at first. But
    as your team expends more and more effort in building the solution required, this
    will quickly grow. If your solution has to have a few different capabilities and
    perform some quite distinct actions and you keep all of this in the same code
    base, your solution can become incredibly complex. In fact, software in which
    the components are all tightly coupled and non-separable like this is called **monolithic**,
    as it is akin to single big blocks that can exist independently of other applications.
    This sort of approach may fit the bill for your use case, but as the complexity
    of solutions continues to increase, a much more resilient and extensible design
    pattern is often required.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你的机器学习项目的代码库最初会很小——最初只有几行。但随着你的团队在构建所需解决方案上投入越来越多的努力，这会迅速增长。如果你的解决方案需要具备几种不同的能力并执行一些相当不同的操作，而你又把所有这些都放在同一个代码库中，你的解决方案可能会变得极其复杂。实际上，这种所有组件都紧密耦合且不可分离的软件被称为**单体**，因为它类似于可以独立于其他应用程序存在的单个大块。这种方法可能适合你的用例，但随着解决方案复杂性的持续增加，通常需要一个更具弹性和可扩展的设计模式。
- en: 'Microservice architectures are those in which the functional components of
    your solution are cleanly separated, potentially in completely different code
    bases or running on completely different infrastructure. For example, if we are
    building a user-facing web application that allows users to browse, select, and
    purchase products, we may have a variety of ML capabilities we wish to deploy
    in quick succession. We may want to recommend new products based on what they
    have just been looking at, we may want to retrieve forecasts of when their recently
    ordered items will arrive, and we may want to highlight some discounts we think
    they will benefit from (based on our analysis of their historic account behavior).
    This would be a very tall order, maybe even impossible, for a monolithic application.
    However, it is something that quite naturally falls into microservice architecture
    like that in *Figure 5.2*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构是指你的解决方案的功能组件被干净地分离，可能完全在不同的代码库中或运行在不同的基础设施上。例如，如果我们正在构建一个面向用户的Web应用程序，允许用户浏览、选择和购买产品，我们可能希望快速连续部署各种机器学习能力。我们可能希望根据他们刚刚查看的内容推荐新产品，我们可能希望检索他们最近订购的项目何时到达的预测，我们可能还希望突出一些我们认为他们将从中获得好处的折扣（基于我们对他们历史账户行为的分析）。这对于一个单体应用程序来说可能是一个非常高的要求，甚至可能是不可能的。然而，这恰好是像*图5.2*中那样的微服务架构所自然适应的：
- en: '![Figure 5.1 – An example of some ML microservices ](img/B19525_05_02.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – 一些机器学习微服务的示例](img/B19525_05_02.png)'
- en: 'Figure 5.2: An example of some ML microservices.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：一些机器学习微服务的示例。
- en: The implementation of a microservice architecture can be accomplished using
    a few tools, some of which we will cover in the *Hosting your own microservice
    on AWS* section. The main idea is that you always separate out the elements of
    your solution into their own services that are not tightly coupled together.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构的实现可以使用一些工具来完成，其中一些我们将在*在AWS上托管自己的微服务*部分中介绍。主要思想是始终将你的解决方案的元素分离成它们自己的服务，这些服务不是紧密耦合在一起的。
- en: 'Microservice architectures are particularly good at allowing our development
    teams to achieve the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构特别擅长让我们的开发团队能够实现以下目标：
- en: Independently debug, patch, or deploy individual services rather than tearing
    down the whole system.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立调试、修补或部署单个服务，而不是整个系统。
- en: Avoid a single point of failure.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免单点故障。
- en: Increase maintainability.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高可维护性。
- en: Allow separate services to be owned by distinct teams with clearer responsibilities.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许不同的服务由不同的团队拥有，并有更清晰的责任。
- en: Accelerate the development of complex products.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速复杂产品的开发。
- en: Like every architecture pattern or design style, it is, of course, not a silver
    bullet, but we would do well to remember the microservice architecture when designing
    our next solution.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 就像每个架构模式或设计风格一样，它当然不是万能的银弹，但当我们设计下一个解决方案时，记住微服务架构会大有裨益。
- en: Next, we will discuss event-based designs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论基于事件的设计。
- en: Event-based designs
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于事件的设计
- en: You do not always want to operate in scheduled batches. As we have seen, even
    just in the previous section, *Microservices*, not all use cases align with running
    a large batch prediction from a model on a set schedule, storing the results,
    and then retrieving them later. What happens if the data volumes you need are
    not there for a training run? What if no new data to run predictions on has arrived?
    What if other systems could make use of a prediction based on individual data
    points at the earliest time they become available rather than at a specific time
    every day?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您并不总是想以预定批次的方式运行。正如我们之前所看到的，即使是上一个部分，*微服务*，并不是所有用例都与在预定时间表上从模型运行大型批次预测、存储结果然后稍后检索它们相匹配。如果所需的训练运行数据量不存在怎么办？如果没有新的数据用于运行预测怎么办？如果其他系统可以在数据点最早可用时而不是每天特定时间基于单个数据点进行预测，它们能利用预测怎么办？
- en: In an event-based architecture, individual actions produce results that then
    trigger other individual actions in the system, and so on and so forth. This means
    that processes can happen as early as they can and no earlier. It also allows
    for a more dynamic or stochastic data flow, which can be beneficial if other systems
    are not running on scheduled batches either.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件驱动的架构中，单个操作产生结果，然后触发系统中其他单个操作，如此类推。这意味着过程可以在尽可能早的时候发生，而不是更早。这也允许有更动态或随机的数据流，如果其他系统不是在预定批次上运行，这可能是有益的。
- en: Event-based patterns could be mixed with others, for example, microservices
    or batch processing. The benefits still stand, and, in fact, event-based components
    allow for more sophisticated orchestration and management of your solution.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动模式可以与其他模式混合，例如微服务或批量处理。这些好处仍然存在，实际上，事件驱动组件允许更复杂的解决方案编排和管理。
- en: 'There are two types of event-based patterns:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种基于事件的模式：
- en: '**Pub/sub**: In this case, event data is published to a message broker or event
    bus to be consumed by other applications. In one variant of the pub/sub pattern,
    the broker or buses used are organized by some appropriate classification and
    are designated as **topics**. An example of a tool that does this is **Apache
    Kafka**.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布/订阅**：在这种情况下，事件数据被发布到消息代理或事件总线，以便由其他应用程序消费。在发布/订阅模式的一个变体中，使用的代理或总线根据某些适当的分类组织，并指定为**主题**。执行此操作的示例工具是**Apache
    Kafka**。'
- en: '**Event streaming**: Streaming use cases are ones where we want to process
    a continuous flow of data in something very close to real time. We can think of
    this as working with data as it *moves through* the system. This means it is not
    persisted *at rest* in a database but processed as it is created or received by
    the streaming solution. An example tool to use for event streaming applications
    is **Apache Storm**.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件流**：流用例是我们希望在非常接近实时的情况下处理连续数据流的情况。我们可以将其视为在数据*通过*系统时处理数据。这意味着数据不是在数据库中静态持久化，而是在创建或接收时由流解决方案处理。用于事件流应用的示例工具是**Apache
    Storm**。'
- en: '*Figure 5.3* shows an example event-based architecture applied to the case
    of **IoT** and mobile devices that have their data passed into classification
    and anomaly detection algorithms:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5.3* 展示了一个应用于**物联网**和移动设备的事件驱动架构示例，这些设备的数据被传递到分类和异常检测算法中：'
- en: '![Figure 5.2 – A basic event-based architecture where a stream of data is accessed
    by different services via a broker ](img/B19525_05_03.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 一个基本的事件驱动架构，其中数据流通过代理被不同的服务访问](img/B19525_05_03.png)'
- en: 'Figure 5.3: A basic event-based high-level design where a stream of data is
    accessed by different services via a broker.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：一个基本的事件驱动高级设计，其中数据流通过代理被不同的服务访问。
- en: The next section will touch on designs where we do the opposite of processing
    one data point at a time and instead work with large chunks or batches at any
    one time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将涉及设计，其中我们做的是一次处理一个数据点，而不是同时处理大量数据或批次。
- en: Batching
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量处理
- en: Batches of work may not sound like the most sophisticated concept, but it is
    one of the most common pattern flavors out there in the world of ML.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 工作批次可能听起来不是最复杂的概念，但在机器学习的世界中，它是最常见的模式之一。
- en: If the data you require for prediction comes in at regular time intervals in
    batches, it can be efficient to schedule your prediction runs with a similar cadence.
    This type of pattern can also be useful if you do not have to create a low-latency
    solution.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您用于预测的数据以固定的时间间隔以批次形式到来，那么安排您的预测运行以类似的节奏可能是高效的。如果不需要创建低延迟解决方案，这种模式也可能很有用。
- en: 'This concept can also be made to run quite efficiently for a few reasons:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于几个原因，这个概念也可以运行得相当高效：
- en: Running in scheduled batches means that we know exactly when we will need compute
    resources, so we can plan accordingly. For example, we may be able to shut down
    our clusters for most of the day or repurpose them for other activities.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在预定批次中运行意味着我们知道何时需要计算资源，因此我们可以相应地计划。例如，我们可能能够关闭我们的集群大部分时间，或者将它们用于其他活动。
- en: Batches allow for the use of larger numbers of data points at runtime, so you
    can run things such as anomaly detection or clustering at the batch level if desired.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批次允许在运行时使用更多的数据点，因此如果你希望的话，可以在批次级别运行异常检测或聚类等操作。
- en: The size of your batches of data can often be chosen to optimize some criterion.
    For example, using large batches and running parallelized logic and algorithms
    on it could be more efficient.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的数据批次的大小通常可以选择以优化某些标准。例如，使用大型批次并在其上运行并行化的逻辑和算法可能更有效。
- en: Software solutions where ML algorithms are run in batches often look very similar
    to classic **Extract**, **Transform**, **Load** (**ETL**) systems. These are systems
    where data is extracted from a source or sources, before being processed on route
    to a target system where it is then uploaded. In the case of an ML solution, the
    processing is not standard data transformation such as joins and filters but is
    instead the application of feature engineering and ML algorithm pipelines. This
    is why, in this book, we will term these designs **Extract, Transform, Machine
    Learning** (**ETML**) patterns. ETML will be discussed more in *Chapter 9*, *Building
    an Extract, Transform, Machine Learning Use Case*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在批次中运行ML算法的软件解决方案通常看起来与经典的**提取**、**转换**、**加载**（**ETL**）系统非常相似。这些系统是从源或多个源提取数据，然后在路由到目标系统之前进行处理，然后上传。在ML解决方案的情况下，处理不是标准的数据转换，如连接和筛选，而是应用特征工程和ML算法管道。这就是为什么在这本书中，我们将这些设计称为**提取、转换、机器学习**（**ETML**）模式。ETML将在第9章*构建提取、转换、机器学习用例*中进一步讨论。
- en: We will now discuss a key piece of technology that is critical to making modern
    architectures applicable to a wide range of platforms – containers.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将讨论一项关键技术，这对于使现代架构适用于广泛的平台至关重要——容器。
- en: Containerizing
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器化
- en: If you develop software that you want to deploy somewhere, which is the core
    aim of an ML engineer, then you have to be very aware of the environmental requirements
    of your code, and how different environments might affect the ability of your
    solution to run. This is particularly important for Python, which does not have
    a core capability for exporting programs as standalone executables (although there
    are options for doing this). This means that Python code needs a Python interpreter
    to run and needs to exist in a general Python environment where the relevant libraries
    and supporting packages have been installed.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开发软件并将其部署到某个地方，这是ML工程师的核心目标，那么你必须非常了解你的代码的环境要求，以及不同的环境可能会如何影响你的解决方案的运行能力。这对于Python尤其重要，Python没有将程序作为独立可执行文件导出的核心功能（尽管有选项可以这样做）。这意味着Python代码需要Python解释器来运行，并且需要存在于一个通用的Python环境中，其中已安装相关的库和支持包。
- en: 'A great way to avoid headaches from this point of view is to ask the question:
    *Why can’t I just put everything I need into something that is relatively isolated
    from the host environment, which I can ship and then run as a standalone application
    or program?* The answer to this question is that you can and that you do this
    through **containerization**. This is a process whereby an application and its
    dependencies can be packaged together in a standalone unit that can effectively
    run on any computing platform.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 避免从这个角度来看头痛的一个好方法是问自己：*为什么我不能把所有需要的东西都放入一个相对隔离主机环境的东西中，然后我可以将其发送并作为一个独立的应用程序或程序运行？*
    这个问题的答案是你可以，而且你通过**容器化**来实现这一点。这是一个过程，其中应用程序及其依赖项可以打包在一个独立的单元中，该单元可以在任何计算平台上有效地运行。
- en: 'The most popular container technology is **Docker**, which is open-source and
    very easy to use. Let’s learn about it by using it to containerize a simple **Flask**
    web application that could act as an interface to a forecasting model like that
    created in the *Example 2*: *Forecasting API* section in *Chapter 1*, *Introduction
    to ML Engineering*.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '最受欢迎的容器技术是**Docker**，它是开源的，非常易于使用。让我们通过使用它来容器化一个简单的**Flask**网络应用程序来了解它，这个应用程序可以作为类似在*示例2*：*第1章，机器学习工程简介*中的*预测API*部分的预测模型的接口。 '
- en: The next few sections will use a similar simple Flask application that has a
    forecast serving endpoint. As a proxy for a full ML model, we will first work
    with a skeleton application that simply returns a short list of random numbers
    when requested for a forecast. The detailed code for the application can be found
    in this book’s GitHub repo at [https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter05/microservices/mlewp2-web-service](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter05/microservices/mlewp2-web-service).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几节将使用一个类似的简单Flask应用程序，它有一个提供预测的端点。作为一个完整ML模型的代理，我们首先将与一个简单的骨架应用程序一起工作，该应用程序在请求预测时简单地返回一个随机数字的短列表。应用程序的详细代码可以在本书的GitHub仓库中找到，地址为[https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter05/microservices/mlewp2-web-service](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter05/microservices/mlewp2-web-service)。
- en: The web application creates a basic app where you can supply a store ID and
    forecast a start date for the system and it will return the dummy forecast. To
    get this, you hit the `/forecast` endpoint.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 网络应用程序创建了一个基本的应用程序，你可以提供存储ID并预测系统的开始日期，然后它会返回虚拟预测。要获取这个，你需要点击`/forecast`端点。
- en: 'An example is shown in *Figure 5.4*:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子在*图5.4*中展示：
- en: '![](img/B19525_05_04.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19525_05_04.png)'
- en: 'Figure 5.4: The result of querying our skeleton ML microservice.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：查询我们的骨骼ML微服务的结果。
- en: 'Now, we’ll move on to discuss how to containerize this application. First,
    you need to install Docker on your platform by using the documentation at [https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续讨论如何容器化这个应用程序。首先，你需要通过使用[https://docs.docker.com/engine/install/](https://docs.docker.com/engine/install/)上的文档在你的平台上安装Docker：
- en: 'Once you have Docker installed, you need to tell it how to build the container
    image, which you do by creating a `Dockerfile` in your project. The `Dockerfile`
    specifies all of the build steps in text so that the process of building the image
    is automated and easily configurable. We will now walk through building a simple
    example `Dockerfile`, which will be built on in the next section, *Hosting your
    own microservice on AWS*. First, we need to specify the base image we are working
    from. It usually makes sense to use one of the official Docker images as a base,
    so here we will use the `python:3.10-slim` environment to keep things lean and
    mean. This base image will be used in all commands following the `FROM` keyword,
    which signifies we are entering a build stage. We can actually name this stage
    for later use, calling it `builder` using the `FROM … as` syntax:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你安装了Docker，你需要告诉它如何构建容器镜像，这通过在你的项目中创建一个`Dockerfile`来完成。`Dockerfile`以文本形式指定所有构建步骤，以便构建镜像的过程自动化且易于配置。现在，我们将通过构建一个简单的示例`Dockerfile`来演示，这个示例将在下一节中继续，即*在AWS上托管自己的微服务*。首先，我们需要指定我们工作的基本镜像。通常使用官方Docker镜像作为基础是有意义的，所以我们在这里将使用`python:3.10-slim`环境来保持事情简洁。这个基本镜像将在所有跟随`FROM`关键字的命令中使用，这表示我们正在进入构建阶段。我们实际上可以用`FROM
    … as`语法命名这个阶段，以便以后使用，将其命名为`builder`：
- en: '[PRE1]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we copy all the files we need from the current directory to a directory
    labeled `src` in the build stage and install all of our requirements using our
    `requirements.txt` file (if you want to run this step without specifying any requirements,
    you can just use an empty `requirements.txt` file):'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将从当前目录复制所有需要的文件到构建阶段的`src`目录，并使用我们的`requirements.txt`文件安装所有需求（如果你想在未指定任何需求的情况下运行此步骤，你可以只使用一个空的`requirements.txt`文件）：
- en: '[PRE2]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next stage involves similar steps but is aliased to the word `app` since
    we are now creating our application. Notice the reference to the `builder` stage
    from steps *1* and *2* here:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个阶段涉及类似的步骤，但被别名为单词`app`，因为我们现在正在创建我们的应用程序。注意这里对步骤*1*和*2*中的`builder`阶段的引用：
- en: '[PRE3]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can define or add to environment variables as we are used to in a bash environment:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以像在bash环境中一样定义或添加环境变量：
- en: '[PRE4]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Since in this example we are going to be running a simple Flask web application,
    we need to tell the system which port to expose:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于在这个例子中我们将运行一个简单的 Flask Web 应用程序，我们需要告诉系统要公开哪个端口：
- en: '[PRE5]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can execute commands during the Docker build using the `CMD` keyword. Here,
    we use this to run `app.py`, which is the main entry point to the Flask app, and
    will start the service we will call via REST API to get ML results later:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在 Docker 构建过程中使用 `CMD` 关键字来执行命令。在这里，我们使用它来运行 `app.py`，这是 Flask 应用程序的主入口点，并且将启动我们稍后通过
    REST API 调用来获取 ML 结果的服务：
- en: '[PRE6]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then we can build the image with the `docker build` command. Here, we create
    an image named `basic-ml-microservice` and tag it with the `latest` label:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 `docker build` 命令来构建镜像。在这里，我们创建一个名为 `basic-ml-microservice` 的镜像，并使用
    `latest` 标签对其进行标记：
- en: '[PRE7]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To check the build was successful, run the following command in the Terminal:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查构建是否成功，请在终端中运行以下命令：
- en: '[PRE8]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should see an output like that in *Figure 5.5*:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该会在 *图 5.5* 中看到类似的输出：
- en: '![](img/B19525_05_05.png)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B19525_05_05.png)'
- en: 'Figure 5.5: Output from the docker images command.'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.5：`docker images` 命令的输出。
- en: 'Finally, you can run your Docker image with the following command in your Terminal:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您可以在终端中使用以下命令运行您的 Docker 镜像：
- en: '[PRE9]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that you have containerized some basic applications and can run your Docker
    image, we need to answer the question of how we can use this to build an ML solution
    hosted on an appropriate platform. The next section covers how we can do this
    on AWS.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经容器化了一些基本的应用程序并且可以运行您的 Docker 镜像，我们需要回答如何使用它来构建一个托管在适当平台上的 ML 解决方案的问题。下一节将介绍我们如何在
    AWS 上做到这一点。
- en: Hosting your own microservice on AWS
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS 上托管自己的微服务
- en: A classic way to surface your ML models is via a lightweight web service hosted
    on a server. This can be a very flexible pattern of deployment.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一个将您的 ML 模型公开的经典方式是通过在服务器上托管一个轻量级的 Web 服务。这可以是一个非常灵活的部署模式。
- en: You can run a web service on any server with access to the internet (roughly)
    and, if designed well, it is often easy to add further functionality to your web
    service and expose it via new endpoints.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在任何可以访问互联网（大致上）的服务器上运行 Web 服务，并且如果设计得当，通常很容易向您的 Web 服务添加更多功能，并通过新的端点公开。
- en: In Python, the two most used web frameworks have always been **Django** and
    **Flask**. In this section, we will focus on Flask as it is the simpler of the
    two and has been written about extensively for ML deployments on the web, so you
    will be able to find plenty of material to build on what you learn here.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，最常用的两个 Web 框架一直是 **Django** 和 **Flask**。在本节中，我们将重点关注 Flask，因为它比 Django
    更简单，并且已经广泛地讨论了其在 Web 上的 ML 部署，因此您将能够找到大量材料来构建您在这里学到的内容。
- en: On AWS, one of the simplest ways you can host your Flask web solution is as
    a containerized application on an appropriate platform. We will go through the
    basics of doing this here, but we will not spend time on the detailed aspects
    of maintaining good web security for your service. To fully discuss this may require
    an entire book in itself, and there are excellent, more focused resources elsewhere.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 上，您可以托管 Flask Web 解决方案的最简单方法之一是将它作为一个容器化应用程序在适当平台上运行。我们将在本节中介绍如何做到这一点的基础知识，但我们将不会花费时间在维护良好
    Web 安全性的详细方面。这可能需要一本完整的书来充分讨论，并且在其他地方有很好的、更专注的资源。
- en: We will assume that you have your AWS account set up from *Chapter 2*, *The
    Machine Learning Development Process*. If you do not, then go back and refresh
    yourself on what you need to do.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将假设您已经从 *第 2 章*，*机器学习开发过程* 中设置了您的 AWS 账户。如果没有，请返回并复习您需要做什么。
- en: We will need the AWS **Command Line Interface** (**CLI**). You can find the
    appropriate commands for installing and configuring the AWS CLI, as well as a
    lot of other useful information, on the AWS CLI documentation pages at [https://docs.aws.amazon.com/cli/index.xhtml](https://docs.aws.amazon.com/cli/index.xhtml).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要 AWS **命令行界面**（**CLI**）。您可以在 AWS CLI 文档页面 [https://docs.aws.amazon.com/cli/index.xhtml](https://docs.aws.amazon.com/cli/index.xhtml)
    上找到安装和配置 AWS CLI 的适当命令，以及大量其他有用的信息。
- en: 'Specifically, configure your Amazon CLI by following the steps in this tutorial:
    [https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.xhtml](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.xhtml).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，请按照本教程中的步骤配置您的 Amazon CLI：[https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.xhtml](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.xhtml)。
- en: The documentation specifies how to install the CLI for a variety of different
    computer architectures, so follow along for your given platform and then you will
    be ready to have fun with the AWS examples used in the rest of the book!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 文档指定了如何为各种不同的计算机架构安装CLI，所以按照你的平台进行操作，然后你就可以准备好享受本书中使用的AWS示例了！
- en: In the following example, we will use Amazon **Elastic Container Registry**
    (**ECR**) and **Elastic Container Service** (**ECS**) to host a skeleton containerized
    web application. In *Chapter 8*, *Building an Example ML Microservice*, we will
    discuss how to build and scale an ML microservice in more detail and using a lower-level
    implementation based on Kubernetes. These two approaches complement each other
    nicely and will help you widen your ML engineering toolkit.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将使用Amazon **弹性容器注册库**（**ECR**）和**弹性容器服务**（**ECS**）来托管一个基本的容器化Web应用程序。在*第8章*，*构建示例ML微服务*中，我们将更详细地讨论如何构建和扩展ML微服务，并使用基于Kubernetes的低级别实现。这两种方法相辅相成，将帮助你扩展ML工程工具箱。
- en: 'Deploying our service on ECS will require a few different components, which
    we will walk through in the next few sections:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在ECS上部署我们的服务需要几个不同的组件，我们将在接下来的几节中介绍：
- en: Our container hosted inside a repository on ECR
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在ECR仓库内部托管的容器
- en: A cluster and service created on ECS
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在ECS上创建的集群和服务
- en: An application load balancer created via the **Elastic Compute Cloud** (**EC2**)
    service
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过**弹性计算云**（**EC2**）服务创建的应用程序负载均衡器
- en: First, let’s tackle pushing the container to ECR.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解决将容器推送到ECR的问题。
- en: Pushing to ECR
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推送到ECR
- en: 'Let’s look at the following steps:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: 'We have the following Dockerfile defined within the project directory from
    the *Containerizing* section:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在*容器化*部分的项目目录中定义了以下Dockerfile：
- en: '[PRE10]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can then use the AWS `CLI` to create an ECR repository for hosting our container.
    We will call the repository `basic-ml-microservice` and will set the region as
    `eu-west-1`, but this should be changed to what region seems most appropriate
    for your account. The command below will return some metadata about your ECR repository;
    keep this for later steps:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用AWS `CLI`创建一个ECR仓库来托管我们的容器。我们将把这个仓库命名为`basic-ml-microservice`，并将区域设置为`eu-west-1`，但这个应该根据你的账户最合适的区域来更改。下面的命令将返回一些关于你的ECR仓库的元数据；保留这些信息以供后续步骤使用：
- en: '[PRE11]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can then log in to the container registry with the following command in
    the Terminal. Note that the repository URI will have been in the metadata provided
    after running step *2*. You can also retrieve this by running `aws ecr describe-repositories
    --region eu-west-1`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以在终端中使用以下命令登录到容器注册库。注意，仓库URI将在运行步骤*2*后提供的元数据中。你也可以通过运行`aws ecr describe-repositories
    --region eu-west-1`来检索这个信息：
- en: '[PRE12]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, if we navigate to the directory containing the `Dockerfile` (`app`),
    we can run the following command to build the container:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，如果我们导航到包含`Dockerfile`（`app`）的目录，我们可以运行以下命令来构建容器：
- en: '[PRE13]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The next step tags the image:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步为镜像打标签：
- en: '[PRE14]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We then deploy the Docker image we have just built to the container registry
    with the following command:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下命令将我们刚刚构建的Docker镜像部署到容器注册库：
- en: '[PRE15]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If successful, this last command will have pushed the locally built Docker image
    to your remotely hosted ECR repository. You can confirm this by navigating to
    the AWS management console, going to the ECR service, and selecting the basic-ml-microservice
    repository. You should then see something like what is shown in *Figure 5.6*.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果成功，这个最后的命令将把本地构建的Docker镜像推送到你的远程托管ECR仓库。你可以通过导航到AWS管理控制台，进入ECR服务，并选择basic-ml-microservice仓库来确认这一点。你应该会看到类似于*图5.6*中所示的内容。
- en: '![](img/B19525_05_06.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19525_05_06.png)'
- en: 'Figure 5.6: Succesful push of the locally built Docker image to the ECR repository.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：本地构建的Docker镜像成功推送到ECR仓库。
- en: The steps we have just gone through are actually quite powerful in general,
    as you are now able to build cross-platform Docker images and share them in a
    central repository under your AWS account. You can share Docker containers and
    images via DockerHub as well, [https://hub.docker.com/](https://hub.docker.com/),
    but this gives you more control if you want to do this inside your own organization.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚走过的步骤在一般情况下是非常强大的，因为你现在能够构建跨平台的Docker镜像，并在你的AWS账户下的中央仓库中共享它们。你也可以通过DockerHub共享Docker容器和镜像，[https://hub.docker.com/](https://hub.docker.com/)，但如果你想在你的组织内部做这件事，这会给你更多的控制权。
- en: Now that we have built the container that hosts the Flask app, we will now look
    to deploy this on scalable infrastructure. To do this, in the next section, we
    will set up our cluster on ECS.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了托管 Flask 应用的容器，接下来我们将考虑将其部署到可伸缩的基础设施上。为了做到这一点，在下一节中，我们将在 ECS 上设置我们的集群。
- en: Hosting on ECS
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 ECS 中托管
- en: 'Now, let’s start with the setup! At the time of writing in mid-2023, AWS has
    recently introduced a revamped ECS console that allows for a far smoother setup
    than previously. So, if you read the first edition of this book, you will find
    this a far smoother experience:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始设置！截至 2023 年中旬，AWS 最近推出了一款全新的 ECS 控制台，它允许比之前更平滑的设置。因此，如果您阅读的是这本书的第一版，您会发现这是一个更加流畅的体验：
- en: First, navigate to **ECS** on the AWS Management Console and click **Create
    Cluster**. You will be provided with a form that asks for details about networking,
    infrastucture, monitoring, and the provision of any tags on the resources we are
    about to create. This should look like *Figure 5.7*.![](img/B19525_05_07.png)
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导航到 AWS 管理控制台中的**ECS**，然后点击**创建集群**。您将看到一个表单，要求您提供有关网络、基础设施、监控以及我们即将创建的资源上的任何标签的详细信息。这应该看起来像*图
    5.7*。![](img/B19525_05_07.png)
- en: 'Figure 5.7: Creating a cluster in Elastic Container Service.'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.7：在弹性容器服务中创建集群。
- en: First, we can name the cluster `mlewp2-ecs-cluster`, or indeed whatever you
    want! Then when you expand the **Networking** section, you should see that many
    of the **VPC** and subnet details are auto-populated with defaults based on your
    AWS account setup. If you need to set these up, the form points to the relevant
    documentation. See *Figure 5.8* for an example.![](img/B19525_05_08.png)
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们可以将集群命名为 `mlewp2-ecs-cluster`，或者您想要的任何名称！然后当您展开**网络**部分时，您应该会看到许多**VPC**和子网细节都是基于您的
    AWS 账户设置自动填充的默认值。如果您需要设置这些，表单会指向相关的文档。请参见*图 5.8*以获取示例。![](img/B19525_05_08.png)
- en: 'Figure 5.8: Networking configuration for our cluster in AWS ECS.'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.8：我们集群在 AWS ECS 中的网络配置。
- en: The **Infrastructure** section contains three options, with the use of **AWS
    Fargate** being the pre-selected default option. We do not need to know the details
    of how Fargate works but suffice it to say that this provides a very high-level
    abstraction for managing container workloads across multiple servers. The introduction
    of Fargate has meant that you do not need to worry about details of the provisioning
    and running of clusters of virtual machines to run your container workloads. According
    to the AWS documentation, the Fargate service is ideal for dynamic bursts of work
    or large workloads with low operational overhead. If you know you are going to
    be running large jobs that have to be price optimized, you can then look to the
    other infra options provided, for example, **EC2 instances**. We will not need
    these for the purposes of this example. *Figure 5.9* shows the **Infrastructure**
    section for reference.![](img/B19525_05_09.png)
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基础设施**部分包含三个选项，其中使用**AWS Fargate**是预选的默认选项。我们不需要了解 Fargate 的工作细节，但可以说这为跨多台服务器管理容器工作负载提供了一个非常高级的抽象层。Fargate
    的引入意味着您不需要担心为运行容器工作负载的虚拟机集群的配置和运行细节。根据 AWS 文档，Fargate 服务非常适合动态工作突增或具有低运营开销的大规模工作负载。如果您知道您将要运行需要价格优化的大型作业，那么您可以查看提供的其他基础设施选项，例如**EC2
    实例**。在这个示例中我们不需要这些。*图 5.9*显示了**基础设施**部分以供参考。![](img/B19525_05_09.png)'
- en: 'Figure 5.9: Configuring the infrastructure options in the ECS service.'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.9：在 ECS 服务中配置基础设施选项。
- en: The **Monitoring** and **Tags** sections are relatively self-explanatory and
    allow you to toggle on **container insights** and provide your own string tags
    for the ECS resources that will be created. Let’s leave these as the default for
    now and click **Create** at the bottom of the page. You should then see that the
    cluster was successfully created after a few minutes, as shown in *Figure 5.10*.![](img/B19525_05_10.png)
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控**和**标签**部分相对容易理解，允许您开启**容器洞察**并为即将创建的 ECS 资源提供自己的字符串标签。现在我们先保持这些默认设置，然后点击页面底部的**创建**按钮。然后您应该会看到集群在几分钟内成功创建，如图
    5.10 所示。![](img/B19525_05_10.png)'
- en: 'Figure 5.10: The successful creation of the ECS cluster.'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.10：ECS 集群成功创建。
- en: The previous steps were all about setting up the ECS cluster, the infrastructure
    on which our containerized application can run. To actually tell ECS how to run
    the solution, we need to define **tasks**, which are simply processes we wish
    to be executed on the cluster. There is a related concept of **Services** in ECS,
    which refers to a process for managing your tasks, for example, by ensuring a
    certain number of tasks are always running on the cluster. This is useful if you
    have certain uptime requirements for your solution, such as, if it needs to be
    available for requests 24/7\. We can create the task definition in the cluster
    by first navigating to the cluster review page in the AWS management console,
    and then selecting **Task Definitions** on the left-hand side. We will then click
    on **Create New Task Definition**. Follow the steps below to create this task
    definition.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的步骤都是关于设置 ECS 集群，这是我们的容器化应用程序可以运行的基础设施。要实际告诉 ECS 如何运行解决方案，我们需要定义**任务**，这些任务简单来说就是希望在集群上执行的过程。在
    ECS 中有一个相关的概念叫做**服务**，它指的是管理你的任务的过程，例如，确保集群上始终运行一定数量的任务。如果你对解决方案有特定的正常运行时间要求，例如，如果它需要全天候可用，那么这很有用。我们可以通过首先在
    AWS 管理控制台中导航到集群审查页面，然后在左侧选择**任务定义**来在集群中创建任务定义。然后我们将点击**创建新任务定义**。按照以下步骤创建此任务定义。
- en: We have to name the task definition family, which is just the collection of
    versions of the task definition. Let’s call ours `basic-ml-microservice-tasks`
    for simplicity. We then need to provide some container details such as the URI
    for the image we want to use. This is the URI for the image we pushed to the ECR
    repository previously, which is formatted something like `<YOUR_AWS_ID>.dkr.ecr.eu-west-1.amazonaws.com/basic-ml-microservice:latest`.
    You can give the container a new name. Here, I have called it **mlmicro**. Finally,
    you need to supply appropriate port mappings to allow the container and the application
    it contains to be accessible to external traffic. I have mapped `port 5000`, which
    you may recall is the port we exposed in the original Dockerfile using the TCP
    protocol. This is all shown in *Figure 5.11*. You can leave the rest of the optional
    settings for this first section as the default just now and click **Next** to
    move on to the next page of settings.![](img/B19525_05_11.png)
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们必须命名任务定义家族，这仅仅是任务定义的版本集合。为了简单起见，让我们将其命名为 `basic-ml-microservice-tasks`。然后我们需要提供一些容器细节，例如我们想要使用的镜像的
    URI。这是我们之前推送到 ECR 仓库的镜像的 URI，格式类似于 `<YOUR_AWS_ID>.dkr.ecr.eu-west-1.amazonaws.com/basic-ml-microservice:latest`。你可以给容器起一个新的名字。在这里，我将其命名为**mlmicro**。最后，你需要提供适当的端口映射，以便容器及其包含的应用程序能够被外部流量访问。我已经映射了`端口
    5000`，你可能记得这是我们在原始 Dockerfile 中使用 TCP 协议暴露的端口。所有这些都在*图 5.11*中显示。你现在可以保留此第一部分的其余可选设置为默认值，然后点击**下一步**进入下一页设置。![img/B19525_05_11.png](img/B19525_05_11.png)
- en: 'Figure 5.11: Defining the container image to use for the task definition in
    ECS.'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.11：定义用于 ECS 任务定义的容器镜像。
- en: The next page in the console asks for information about the environment and
    infrastructure you will be running the solution on. Based on the settings we used
    for the ECS cluster, we will be using Fargate as the infrastructure option, running
    on a **Linux x86_64** environment. The tasks we are running are very small in
    this case (we’re just returning some numbers for demo purposes) so we can keep
    the default options of **1 vCPU** with **3 GB** memory. You can also add container-level
    memory and CPU requirements if necessary, but we can leave this blank for now.
    This is particularly useful if you have a computationally heavy service, or it
    contains an application that is pre-loaded with some large model or configuration
    data. You can see this in *Figure 5.12*.![](img/B19525_05_12.png)
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制台中的下一页会要求你提供关于你将在其上运行解决方案的环境和基础设施的信息。根据我们为 ECS 集群使用的设置，我们将使用 Fargate 作为基础设施选项，在**Linux
    x86_64**环境中运行。在这种情况下，我们运行的任务非常小（我们只是为了演示目的返回一些数字），因此我们可以保留默认的**1 vCPU**和**3 GB**内存选项。如果你需要，也可以添加容器级别的内存和
    CPU 要求，但现在我们可以留空。这特别有用，如果你有一个计算密集型的服务，或者它包含一个预先加载了一些大型模型或配置数据的应用程序。你可以在*图 5.12*中看到这一点。![img/B19525_05_12.png](img/B19525_05_12.png)
- en: 'Figure 5.12: Configuring our application environment for the AWS ECS task definition
    used for our ML microservice.'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.12：配置用于我们的 ML 微服务 AWS ECS 任务定义的应用程序环境。
- en: Next, IAM roles need to be configured. We will not be calling other AWS services
    from our application, so at this point, we do not need an IAM task role, but you
    can create one if you need this at a later point, for example, if you wish to
    call another data or ML service. For executing the tasks we need an execution
    role, which by default is created for you, so let’s use that. The IAM configuration
    section is shown in *Figure 5.13*.![](img/B19525_05_13.png)
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，需要配置IAM角色。我们不会从我们的应用程序中调用其他AWS服务，因此在此阶段，我们不需要IAM任务角色，但如果您稍后需要此功能，例如，如果您希望调用其他数据或ML服务，您可以创建一个。执行任务我们需要一个执行角色，默认情况下为您创建，所以让我们使用它。IAM配置部分在*图5.13*中显示。![img/B19525_05_13.png](img/B19525_05_13.png)
- en: 'Figure 5.13: The IAM roles defined for use by the AWS ECS task definition.'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.13：为AWS ECS任务定义定义的IAM角色。
- en: The rest of this section contains optional sections for storage, monitoring,
    and tagging. The storage subsection refers to ephemeral storage used to decompress
    and host your Docker container. Again, for larger containers, you may need to
    consider increasing this size from the default 21 GiB. Monitoring can be enabled
    using **Amazon CloudWatch**, which is useful when you need infrastructure monitoring
    as part of your solution, but we will not cover that here and focus more on the
    core deployment. Keep these sections as is for now and click **Next** at the bottom
    of the page.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本节剩余部分包含存储、监控和标记的可选部分。存储子部分指的是用于解压缩和托管您的Docker容器的临时存储。再次提醒，对于更大的容器，您可能需要考虑将此大小从默认的21
    GiB增加。监控可以使用**Amazon CloudWatch**启用，这在您需要将基础设施监控作为解决方案的一部分时很有用，但在此处我们将不涉及此内容，而是更多地关注核心部署。目前请保持这些部分不变，并在页面底部点击**下一步**。
- en: We are almost there. Now we’ll review and create the task definition. If you
    are happy with the selections upon reviewing, then create the task definition
    and you will be taken to a summary page like that shown in *Figure 5.14*.![](img/B19525_05_14.png)
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们几乎完成了。现在，我们将审查并创建任务定义。如果您在审查后对选择满意，那么创建任务定义，您将被带到类似于*图5.14*所示的摘要页面。![img/B19525_05_14.png](img/B19525_05_14.png)
- en: 'Figure 5.14: Successful creation of the ML microservice task definition.'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.14：成功创建的ML微服务任务定义。
- en: 'Now, the final step of setting up our ECS-hosted solution is the creation of
    a service. We will now walk through how to do this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，设置我们的ECS托管解决方案的最后一步是创建一个服务。我们将现在说明如何进行此操作：
- en: First, navigate to the task definition we have just created in the previous
    steps and select the **Deploy** button. This will provide a dropdown where you
    can select **Create service**. *Figure 5.15* shows you what this looks like as
    it may be easy to miss.![](img/B19525_05_15.png)
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导航到之前步骤中创建的任务定义，并选择**部署**按钮。这将提供一个下拉菜单，您可以选择**创建服务**。*图5.15*显示了此操作的外观，因为它可能很容易错过。![img/B19525_05_15.png](img/B19525_05_15.png)
- en: 'Figure 5.15: Selecting the Create service option for the task definition we
    have just created in the previous steps.'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.15：选择创建服务选项，用于之前步骤中创建的任务定义。
- en: You will then be taken to another page where we need to fill in the details
    of the service we wish to create. For **Existing cluster**, select the ECS cluster
    we defined before, which for this example was called **mlewp2-ecs-cluster**. For
    **Compute configuration**, we will just use the **Launch type** option, which
    means we can just allow Fargate to manage the infrastructure requirements. If
    you have multiple infrastructure options that you want to blend together, then
    you can use the **Capacity provider strategy** option. Note that this is more
    advanced and so I encourage you to read more in the AWS documentation about your
    options here if you need to use this route. For reference, my selections are shown
    in *Figure 5.16*.![](img/B19525_05_16.png)
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您将被带到另一个页面，我们需要填写我们希望创建的服务详情。对于**现有集群**，选择之前定义的ECS集群，在这个例子中被称为**mlewp2-ecs-cluster**。对于**计算配置**，我们将仅使用**启动类型**选项，这意味着我们可以仅允许Fargate管理基础设施需求。如果您想将多个基础设施选项混合在一起，则可以使用**容量提供者策略**选项。请注意，这更高级，所以我鼓励您在需要使用此路径时，在AWS文档中了解更多关于您选项的信息。为了参考，我的选择在*图5.16*中显示。![img/B19525_05_16.png](img/B19525_05_16.png)
- en: 'Figure 5.16: AWS ECS selections for the environment that we will run our ECS
    service on. This service will enable the task definition we defined before, and
    therefore our application, to run continuously.'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.16：在我们要运行ECS服务的环境中选择的AWS ECS选项。此服务将启用我们之前定义的任务定义，因此我们的应用程序可以持续运行。
- en: Next is the deployment configuration, which refers to how the service runs in
    terms of the number of replicas and what actions to take upon failures of the
    solution. I have defined the service name simply as **basic-ml-microservice-service**,
    and have used the **Replica** service type, which specifies how many tasks should
    be maintained across the cluster. We can leave this as **1** for now as we only
    have one task in our task definition. This is shown in *Figure 5.17*.![](img/B19525_05_17.png)
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是部署配置，它指的是服务在副本数量和解决方案故障时采取的操作方面如何运行。我已经简单地定义服务名称为**basic-ml-microservice-service**，并使用了**Replica**服务类型，该类型指定了应在集群中维护多少个任务。现在我们可以将其保留为**1**，因为我们只有一个任务在我们的任务定义中。这如图5.17所示。![](img/B19525_05_17.png)
- en: 'Figure 5.17: Configuring the AWS ECS service name and type.'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.17：配置AWS ECS服务名称和类型。
- en: The **Deployment options** and **Deployment failure detection** subsections
    will be auto-populated with some defaults. A rolling deployment type refers to
    the replacement of the container with the latest version when that is available.
    The failure detection options ensure that deployments that run into errors fail
    to proceed and that rollbacks to previous versions are enabled. We do not need
    to enable **CloudWatch alarms** at this stage as we have not configured CloudWatch,
    but this could be added in future iterations of your project. See *Figure 5.18*
    for reference.![](img/B19525_05_18.png)
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署选项**和**部署故障检测**子部分将自动填充一些默认值。滚动部署类型指的是当有最新版本可用时，用最新版本替换容器。故障检测选项确保遇到错误的部署无法继续进行，并且可以回滚到之前的版本。在此阶段，我们不需要启用**CloudWatch警报**，因为我们尚未配置CloudWatch，但可以在项目的未来迭代中添加。参见*图5.18*以供参考.![](img/B19525_05_18.png)'
- en: 'Figure 5.18: Deployment and failure detection options for the AWS ECS service
    we are about to deploy.'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.18：即将部署的AWS ECS服务的部署和故障检测选项。
- en: As in the other examples, there is a **Networking** section that should be prepopulated
    with the VPC and subnet information appropriate for your account. As before, you
    can switch these out for specific VPCs and subnets according to your requirements.
    *Figure 5.19* shows what this looks like for reference.![](img/B19525_05_19.png)
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如其他示例所示，有一个**网络**部分，应该预先填充适合您账户的VPC和子网信息。与之前一样，您可以根据需要将这些信息切换为特定的VPC和子网。*图5.19*显示了参考示例。![](img/B19525_05_19.png)
- en: 'Figure 5.19: The networking section for the AWS ECS service that we are defining
    for hosting the ML microservice.'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.19：为我们定义的托管ML微服务的AWS ECS服务的网络部分。
- en: The remaining sections are optional and contain configuration elements for load
    balancing, auto-scaling, and tagging. Although we do not necessarily need it for
    such a simple application, we will use this section to create an application load
    balancer, which is one of the options available. An application load balancer
    routes HTTP and HTTPS requests and supports useful capabilities like path-based
    routing and dynamic host port mapping, which allows for multiple tasks from a
    single service to run on the same container. We can name the load balancer `basic-ml-microservice-lb`
    and configure the **listener** for this load balancer to listen on `port 80` with
    the HTTP protocol, as shown in *Figure 5.20*. This listener checks for connection
    requests at the given port and uses the specified protocol so that requests can
    then be routed by the load balancer to the downstream system.![](img/B19525_05_20.png)
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 剩余部分是可选的，包含用于负载均衡、自动扩展和标记的配置元素。尽管对于如此简单的应用程序我们可能不需要它，但我们将使用此部分创建一个应用程序负载均衡器，这是可用的选项之一。应用程序负载均衡器路由HTTP和HTTPS请求，并支持诸如基于路径的路由和动态主机端口映射等有用功能，这允许单个服务中的多个任务在同一个容器上运行。我们可以将负载均衡器命名为`basic-ml-microservice-lb`，并配置此负载均衡器的**监听器**以监听`端口80`并使用HTTP协议，如图5.20所示。此监听器检查给定端口的连接请求，并使用指定的协议，以便请求可以被负载均衡器路由到下游系统。![](img/B19525_05_20.png)
- en: 'Figure 5.20: Defining the load balancer name and listener details for the AWS
    ECS service.'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.20：定义AWS ECS服务的负载均衡器名称和监听器详细信息。
- en: Finally, we must specify a target group for the load balancer, which as the
    name suggests is basically the collection of target endpoints for the tasks in
    your service. AWS ECS ensures that this updates as task definitions are updated
    through the lifetime of your service. *Figure 5.21* shows the configurations for
    the target group, which just specifies the HTTP protocol and home path for health
    checks.![](img/B19525_05_21.png)
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们必须为负载均衡器指定一个目标组，正如其名称所暗示的，这基本上是您服务中任务的目标端点集合。AWS ECS确保在您服务的整个生命周期中，随着任务定义的更新，此更新也会进行。*图5.21*显示了目标组的配置，它仅指定了用于健康检查的HTTP协议和主页路径。![图5.21](img/B19525_05_21.png)
- en: 'Figure 5.21: Target group definition for the application load balancer.'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.21：应用程序负载均衡器的目标组定义。
- en: After filling in these details, hit the **Create** button. This will then deploy
    your service. If all has gone well, then you should be able to see the service
    in your cluster details on the AWS ECS console page. You can navigate to this
    service and find the load balancer. This will have a **Domain Name System** (**DNS**)
    address that will be the root of the target URL for sending requests. *Figure
    5.22* shows what this page with the DNS looks like. Copy or save this DNS value.![](img/B19525_05_22.png)
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在填写这些详细信息后，点击**创建**按钮。然后，您的服务将被部署。如果一切顺利，您应该能够在AWS ECS控制台页面的集群详细信息中看到该服务。您可以导航到该服务并找到负载均衡器。这将有一个**域名系统**（**DNS**）地址，这将作为发送请求的目标URL的根。*图5.22*显示了带有DNS的此页面的外观。复制或保存此DNS值。![图5.22](img/B19525_05_22.png)
- en: 'Figure 5.22: The deployed load balancer for our service with the DNS name in
    the bottom right-hand corner.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.22：我们服务的已部署负载均衡器，DNS名称位于右下角。
- en: Finally, to test the service, we can run the same request we had for local testing
    in Postman, but now update the URL to contain the load balancer DNS name and the
    port we have specified that the load balancer will receive oncoming traffic with
    . For us, this is port 80\. This is shown with the application response in *Figure
    5.23*.![](img/B19525_05_23.png)
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了测试服务，我们可以在Postman中运行与本地测试相同的请求，但现在更新URL以包含负载均衡器DNS名称和我们指定的负载均衡器将接收的端口。对我们来说，这是端口80。这在与应用程序响应的*图5.23*中显示。![图5.23](img/B19525_05_23.png)
- en: 'Figure 5.23: A valid result is returned by our simple forecasting service from
    the hosted application AWS ECS.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.23：我们的简单预测服务从托管应用程序AWS ECS返回有效结果。
- en: And that’s it! We have now successfully built and deployed a simplified forecasting
    service using Flask, Docker, AWS Elastic Container Registry, AWS Elastic Container
    Service, and an application load balancer. These components can all be adapted
    for deploying your future ML microservices.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经成功使用Flask、Docker、AWS弹性容器注册库、AWS弹性容器服务和应用程序负载均衡器构建并部署了一个简化的预测服务。所有这些组件都可以适应部署您未来的ML微服务。
- en: The first half of this chapter has been about architectural and design principles
    that apply at the system and code level, as well as showing you how some of this
    comes together in one mode of deployment that is very common for ML systems, that
    of the ML microservice. Now that we have done this, we will move on to discuss
    some tools and techniques that allow us to build, deploy, and host complex ML
    workflows as pipelines, a concept we briefly introduced earlier in the book. The
    tools and concepts we will cover in the second half of this chapter are crucial
    for any modern ML engineer to have a strong grasp of, as they are starting to
    form the backbone of so many deployed ML systems.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前半部分主要介绍了适用于系统和代码级别的架构和设计原则，以及向您展示如何在一种非常常见的ML系统部署模式中实现这些原则，即ML微服务。现在我们已经完成了这个，我们将继续讨论一些工具和技术，它们允许我们以管道的形式构建、部署和托管复杂的ML工作流程，这是我们之前在书中简要介绍过的概念。本章后半部分我们将涵盖的工具和概念对于任何现代ML工程师来说都是至关重要的，因为它们正在成为许多已部署ML系统的骨架。
- en: The next section will start this discussion with an exploration of how we can
    use Airflow to create and orchestrate flexible, general-purpose, production-ready
    pipelines, before we move on to some tools aimed specifically at advanced ML pipelining
    and orchestration.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将首先通过探讨如何使用Airflow创建和编排灵活、通用、生产就绪的管道来开始这次讨论，然后我们将转向一些专门针对高级ML管道编排的工具。
- en: Building general pipelines with Airflow
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Airflow构建通用管道
- en: In *Chapter 4*, *Packaging Up*, we discussed the benefits of writing our ML
    code as pipelines. We discussed how to implement some basic ML pipelines using
    tools such as `sklearn` and **Spark ML**. The pipelines we were concerned with
    there were very nice ways of streamlining your code and making several processes
    available to use within a single object to simplify an application. However, everything
    we discussed then was very much focused on one Python file and not necessarily
    something we could extend very flexibly outside the confines of the package we
    were using. With the techniques we discussed, for example, it would be very difficult
    to create pipelines where each step was using a different package or even where
    they were entirely different programs. They did not allow us to build much sophistication
    into our data flows or application logic either, as if one of the steps failed,
    the pipeline failed, and that was that.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第4章*，*打包* 中，我们讨论了将我们的ML代码作为管道编写的优势。我们讨论了如何使用`sklearn`和 **Spark ML** 等工具实现一些基本的ML管道。我们当时关注的管道是非常好的简化代码和将多个过程作为单个对象内可用的方法，以简化应用程序。然而，我们当时讨论的每一件事都非常专注于单个Python文件，并且不一定是我们能够在使用该包的限制之外灵活扩展的东西。例如，使用我们讨论的技术，创建每个步骤都使用不同包的管道或者它们是完全不同的程序将会非常困难。它们也不允许我们在数据流或应用程序逻辑中构建太多的复杂性，就像如果其中一个步骤失败，管道就会失败，事情就这样结束了。
- en: The tools we are about to discuss take these concepts to the next level. They
    allow you to manage the workflows of your ML solutions so that you can organize,
    coordinate, and orchestrate elements with the appropriate level of complexity
    to get the job done.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将讨论的工具将这些概念提升到下一个层次。它们允许您管理您的ML解决方案的工作流程，以便您可以组织、协调和编排具有适当复杂性的元素以完成任务。
- en: Airflow
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Airflow
- en: '**Apache Airflow** is the workflow management tool that was initially developed
    by **Airbnb** in the 2010s and has been open-source since its inception. It gives
    data scientists, data engineers, and ML engineers the capability of programmatically
    creating complex pipelines through Python scripts. Airflow’s task management is
    based on the definition and then execution of a **Directed Acyclic Graph** (**DAG**)
    with nodes as the tasks to be run. DAGs are also used in **TensorFlow** and **Spark**,
    so you may have heard of them before.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Airflow** 是一个工作流管理工具，最初由 **Airbnb** 在2010年代开发，自那时起就是开源的。它为数据科学家、数据工程师和ML工程师提供了通过Python脚本编程创建复杂管道的能力。Airflow的任务管理基于定义和执行一个
    **有向无环图** (**DAG**)，其中节点是要运行的任务。DAGs也被用于 **TensorFlow** 和 **Spark**，所以您可能之前已经听说过。'
- en: 'Airflow contains a variety of default operators to allow you to define DAGs
    that can call and use multiple components as tasks, without caring about the specific
    details of a task. It also provides functionality for scheduling your pipelines.
    As an example, let’s build an Apache Airflow pipeline that will get data, perform
    some feature engineering, train a model, and then persist the model. We won’t
    cover the detailed implementation of each command, but simply show you how your
    ML processes hang together in an Airflow DAG. In *Chapter 9*, *Building an Extract,
    Transform, Machine Learning Use Case*, we will build out a detailed end-to-end
    example discussing these lower-level details. This first example is more concerned
    with understanding the high level of how to write, deploy, and manage your DAGs
    in the cloud:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow包含各种默认操作符，允许您定义可以调用和使用多个组件作为任务的DAG，而不必关心任务的具体细节。它还提供了调度您的管道的功能。例如，让我们构建一个Apache
    Airflow管道，该管道将获取数据，执行一些特征工程，训练一个模型，然后持久化模型。我们不会涵盖每个命令的详细实现，只是简单地展示您的ML过程如何在Airflow
    DAG中组合在一起。在 *第9章*，*构建一个提取、转换、机器学习用例* 中，我们将构建一个详细的端到端示例，讨论这些低级细节。这个第一个示例更关注于理解如何编写、部署和管理您在云中的DAGs的高级方法：
- en: 'First, in a file called `classification_pipeline_dag.py`, we can import the
    relevant Airflow packages and any utility packages we need:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在一个名为`classification_pipeline_dag.py`的文件中，我们可以导入相关的Airflow包和我们需要的任何实用包：
- en: '[PRE16]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, Airflow allows you to define default arguments that can be referenced
    by all of the following tasks, with the option to overwrite at the same level:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，Airflow允许您定义默认参数，这些参数可以被所有以下任务引用，并且可以选择在相同级别进行覆盖：
- en: '[PRE17]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then have to instantiate our DAG and provide the relevant metadata, including
    our scheduling interval:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来需要实例化我们的DAG并提供相关的元数据，包括我们的调度间隔：
- en: '[PRE18]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, all that is required is to define your tasks within the `DAG` definition.
    First, we define an initial task that gets our dataset. This next piece of code
    assumes there is a Python executable, for example, a function or class method,
    called `get_data` that we can pass to the task. This could have been imported
    from any submodule or package we want. Note that *steps* *3*-*5* assume we are
    inside the code block of the DAG instantiation, so we assume another indent that
    we don’t show here to save space:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，所需的所有操作就是定义您在`DAG`定义中的任务。首先，我们定义一个初始任务来获取我们的数据集。此段代码假设有一个名为`get_data`的Python可执行文件，例如一个函数或类方法，我们可以将其传递给任务。这可以从我们想要的任何子模块或包中导入。请注意，*步骤3*-*5*假设我们处于DAG实例化的代码块中，所以我们假设另一个缩进，这里我们没有显示以节省空间：
- en: '[PRE19]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We then perform a task that takes this data and performs our model training
    steps. This task could, for example, encapsulate one of the pipeline types we
    covered in *Chapter 3*, *From Model to Model Factory*; for example, a Spark ML
    pipeline, **Scikit-Learn** pipeline, or any other ML training pipeline we looked
    at. Again, we assume there is a Python executable called `train_model` that can
    be used in this step:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们执行一个任务，该任务使用这些数据并执行我们的模型训练步骤。例如，这个任务可以封装我们在*第3章*，“从模型到模型工厂”中讨论的管道类型之一；例如，Spark
    ML管道、**Scikit-Learn**管道或我们查看的任何其他ML训练管道。再次强调，我们假设有一个名为`train_model`的Python可执行文件，可以在这一步中使用：
- en: '[PRE20]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The final step of this process is a placeholder for taking the resultant trained
    model and persisting it to our storage layer. This means that other services or
    pipelines can use this model for prediction:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此过程的最后一步是用于将训练好的模型持久化到我们的存储层的一个占位符。这意味着其他服务或管道可以使用此模型进行预测：
- en: '[PRE21]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, we define the running order of the task nodes that we have defined
    in the DAG using the `>>` operator. The tasks above could have been defined in
    any order, but the following syntax stipulates how they must run:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用`>>`运算符定义在DAG中定义的任务节点的运行顺序。上述任务可以按任何顺序定义，但以下语法规定了它们的运行顺序：
- en: '[PRE22]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the next sections, we will briefly cover how to set up an Airflow pipeline
    on AWS using the **Managed Workflows for Apache Airflow** (**MWAA**) service.
    The section after will then show how you can use **CI/CD** principles to continuously
    develop and update your Airflow solutions. This will bring together some of the
    setup and work we have been doing in previous chapters of the book.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将简要介绍如何在AWS上使用**Apache Airflow托管工作流**（**MWAA**）服务设置Airflow管道。下一节将展示如何使用**CI/CD**原则持续开发和更新您的Airflow解决方案。这将汇集我们在本书前几章中进行的设置和工作。
- en: Airflow on AWS
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS上的Airflow
- en: AWS provides a cloud-hosted service called **Managed Workflows for Apache Airflow**
    (**MWAA**) that allows you to deploy and host your Airflow pipelines easily and
    robustly. Here, we will briefly cover how to do this.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了一个名为**Apache Airflow托管工作流**（**MWAA**）的云托管服务，允许您轻松且稳健地部署和托管您的Airflow管道。在这里，我们将简要介绍如何做到这一点。
- en: 'Complete the following steps:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 完成以下步骤：
- en: Select **Create an environment** on the MWAA landing page. You can find this
    by searching for MWAA in the AWS Management Console.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在MWAA登录页面上选择**创建环境**。您可以在AWS管理控制台中搜索MWAA找到它。
- en: You will then be provided with a screen asking for the details of your new Airflow
    environment. *Figure 5.24* shows the high-level steps that the website takes you
    through:![Figure 5.29 – The high-level steps for setting up an MWAA environment
    and associated managed Airflow runs ](img/B19525_05_24.png)
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后，您将看到一个屏幕，要求您提供新Airflow环境的详细信息。*图5.24*显示了网站引导您完成的高级步骤：![图5.29 – 设置MWAA环境和相关管理的Airflow运行的高级步骤](img/B19525_05_24.png)
- en: 'Figure 5.24: The high-level steps for setting up an MWAA environment and associated
    managed Airflow runs.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.24：设置MWAA环境和相关管理的Airflow运行的高级步骤。
- en: '**Environment details**, as shown in *Figure 5.25*, is where we specify our
    environment name. Here, we have called it **mlewp2-airflow-dev-env**:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**环境详细信息**，如图*图5.25*所示，是我们指定环境名称的地方。在这里，我们将其命名为**mlewp2-airflow-dev-env**：'
- en: '![](img/B19525_05_25.png)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B19525_05_25.png)'
- en: 'Figure 5.25: Naming your MWAA environment.'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.25：命名您的MWAA环境。
- en: For MWAA to run, it needs to be able to access code defining the DAG and any
    associated requirements or plugin files. The system then asks for an AWS S3 bucket
    where these pieces of code and configuration reside. In this example, we create
    a bucket called `mlewp2-ch5-airflow-example` that will contain these pieces. *Figure
    5.26* shows the creation of the bucket:![](img/B19525_05_26.png)
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了MWAA能够运行，它需要能够访问定义DAG以及任何相关需求或插件文件的代码。系统随后会要求我们提供一个AWS S3桶，这些代码和配置就存储在这个桶中。在这个例子中，我们创建了一个名为`mlewp2-ch5-airflow-example`的桶，将包含这些代码。*图5.26*
    展示了创建该桶的过程！[](img/B19525_05_26.png)
- en: 'Figure 5.26: The successful creation of our AWS S3 bucket for storing our Airflow
    code and supporting configuration elements.'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.26：成功创建我们的AWS S3桶以存储我们的Airflow代码和支持配置元素。
- en: '*Figure 5.27* shows how we point MWAA to the correct bucket, folders, and plugins
    or requirement files if we have them too:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图5.27* 展示了如果我们也需要指定桶、文件夹、插件或需求文件时，如何将MWAA指向正确的桶、文件夹和插件或需求文件：'
- en: '![](img/B19525_05_27.png)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B19525_05_27.png)'
- en: 'Figure 5.27: We reference the bucket we created in the previous step in the
    configuration of the MWAA instance.'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.27：在MWAA实例的配置中引用我们之前创建的桶。
- en: We then have to define the configuration of the network that the managed instance
    of Airflow will use, similar to the other AWS examples in this chapter. This can
    get a bit confusing if you are new to networking, so it might be good to read
    around the topics of subnets, IP addresses, and VPCs. Creating a new MWAA VPC
    is the easiest approach for getting started in terms of networking here, but your
    organization will have networking specialists who can help you use the appropriate
    settings for your situation. We will go with this simplest route and click **Create
    MWAA VPC**, which opens a new window where we can quickly spin up a new VPC and
    network setup based on a standard stack definition provided by AWS. You will be
    asked for a stack name. I have called mine `MLEWP-2-MWAA-VPC`. The networking
    information will be populated with something like that shown in *Figure 5.28*:![](img/B19525_05_28.png)
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须定义Airflow托管实例将使用的网络配置，这与本章中其他AWS示例类似。如果您对网络不熟悉，可能会有些困惑，因此阅读有关子网、IP地址和VPC的主题可能会有所帮助。在网络上，创建新的MWAA
    VPC是入门的最简单方法，但您的组织将有网络专家可以帮助您根据您的具体情况使用适当的设置。我们将采用这条最简单的路线，点击**创建MWAA VPC**，这将打开一个新窗口，我们可以根据AWS提供的标准堆栈定义快速启动一个新的VPC和网络设置。您将被要求输入堆栈名称。我将其命名为`MLEWP-2-MWAA-VPC`。网络信息将被填充为类似于*图5.28*
    中所示的内容：![](img/B19525_05_28.png)
- en: 'Figure 5.28: An example stack template for creating your new VPC.'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.28：创建新VPC的示例堆栈模板。
- en: We are then taken to a page where we are asked for more details on networking.
    We can select **Public network (No additional setup)** for this example as we
    will not be too concerned with creating an organizationally aligned security model.
    For deployments in an organization, work with your security team to understand
    what additional security you need to put in place. We can also select **Create
    new security group**. This is shown in *Figure 5.29*.![](img/B19525_05_29.png)
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将被带到一页，需要我们提供更多关于网络细节的信息。在这个例子中，我们可以选择**公共网络（无需额外设置）**，因为我们不会太关心创建一个组织对齐的安全模型。对于组织内部的部署，请与您的安全团队合作，了解您需要实施哪些额外的安全措施。我们还可以选择**创建新的安全组**。这如图5.29所示。![](img/B19525_05_29.png)
- en: 'Figure 5.29: Finalizing the networking for our MWAA setup.'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.29：完成MWAA设置的最终网络配置。
- en: Next, we have to define the **Environment class** that we want to spin up. Currently,
    there are three options. Here, we’ll use the smallest, but you can choose the
    environment that best suits your needs (always ask the billpayer’s permission!).
    *Figure 5.30* shows that we can select the **mw1.small** environment class with
    a min to max worker count of 1-10\. MWAA does allow you to change the environment
    class after instantiating if you need to, so it can often be better to start small
    and scale up as needed from a cost point of view. You will also be asked about
    the number of schedulers you want for the environment. Let’s leave this as the
    default, **2**, for now, but you can go up to 5.![](img/B19525_05_30.png)
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须定义我们想要启动的**环境类**。目前有三个选项。在这里，我们将使用最小的，但你可以选择最适合你需求的选项（始终询问账单支付者的许可！）。*图5.30*显示我们可以选择**mw1.small**环境类，最小到最大工作器数量为1-10。MWAA允许你在实例化后更改环境类，所以从成本角度来看，通常最好从小规模开始，根据需要扩展。你还会被问到你想要为环境设置多少调度器。现在让我们将其保留为默认值，**2**，但你可以增加到5。![](img/B19525_05_30.png)
- en: 'Figure 5.30: Selecting an environment class and worker sizes.'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.30：选择环境类和工作器大小。
- en: Now, if desired, we confirm some optional configuration parameters (or leave
    these blank, as done here) and confirm that we are happy for AWS to create and
    use a new execution role. We can also just proceed with the default monitoring
    settings. *Figure 5.31* shows an example of this (and don’t worry, the security
    group will have long been deleted by the time you are reading this page!):![](img/B19525_05_31.png)
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果你需要的话，我们可以确认一些可选的配置参数（或者像这里一样留空），并确认我们愿意让AWS创建并使用一个新的执行角色。我们也可以直接使用默认的监控设置。*图5.31*展示了这样一个例子（而且不用担心，安全组在你阅读这个页面的时候可能已经被删除很久了！）：![](img/B19525_05_31.png)
- en: 'Figure 5.31: The creation of the execution role used by AWS for the MWAA environment.'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.31：AWS用于MWAA环境的执行角色的创建。
- en: The next page will supply you with a final summary before allowing you to create
    your MWAA environment. Once you do this, you will be able to see your newly created
    environment in the MWAA service, as in *Figure 5.32*. This process can take some
    time, and for this example it took around 30 minutes:![](img/B19525_05_32.png)
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一页将在你创建MWAA环境之前提供一个最终总结。一旦你这样做，你将能够在MWAA服务中看到你新创建的环境，就像*图5.32*所示。这个过程可能需要一些时间，在这个例子中大约需要30分钟：![](img/B19525_05_32.png)
- en: 'Figure 5.32: Our newly minted MWAA environment.'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.32：我们新创建的MWAA环境。
- en: Now that you have this MWAA environment and you have supplied your DAG to the
    S3 bucket that it points to, you can open the Airflow UI and see the scheduled
    jobs defined by your DAG. You have now deployed a basic running service that we
    can build upon in later work.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经拥有了这个MWAA环境，并且已经将你的DAG提交到了它指向的S3桶中，你可以打开Airflow UI来查看由你的DAG定义的预定任务。你现在已经部署了一个基本的运行服务，我们可以在后续工作中在此基础上进行构建。
- en: 'Now we will want to see the DAGs in the Airflow UI so that we can orchestrate
    and monitor the jobs. To do this, you may need to configure access for your own
    account to the MWAA UI using the details outlined on the AWS documentation pages.
    As a quick summary, you need to go to the IAM service on AWS. You will need to
    be logged in as a root user, and then create a new policy title, **AmazonMWAAWebServerAccess**.
    Give this policy the following JSON body:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将想要在Airflow UI中查看DAGs，以便我们可以编排和监控作业。为此，你可能需要配置你的账户对MWAA UI的访问权限，使用AWS文档页面上的详细信息。作为一个简要总结，你需要前往AWS的IAM服务。你需要以root用户登录，然后创建一个新的策略标题，**AmazonMWAAWebServerAccess**。给这个策略以下JSON体：
- en: '[PRE23]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For this definition, the Airflow role refers to one of the five roles of **Admin**,
    **Op**, **Viewer**, **User**, or **Public**, as defined in the Airflow documentation
    at [https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.xhtml](https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.xhtml).
    I have used the Admin role for this example. If you add this policy to the permissions
    of your account, you should be able to access the Airflow UI by clicking the **Open
    Airflow UI** button in the MWAA service. You will then be directed to the Airflow
    UI, as shown in *Figure 5.33*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个定义，Airflow 角色指的是 Airflow 文档中定义的五个角色之一：**管理员**、**操作员**、**查看者**、**用户**或**公共**，具体请参阅
    [https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.xhtml](https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.xhtml)。我在这个例子中使用了管理员角色。如果您将此策略添加到您的账户权限中，您应该能够通过在
    MWAA 服务中点击 **打开 Airflow UI** 按钮来访问 Airflow UI。然后，您将被引导到 Airflow UI，如图 *图 5.33*
    所示。
- en: '![](img/B19525_05_33.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_33.png)'
- en: 'Figure 5.33: The Airflow UI accessed via the AWS MWAA service. This view shows
    the classification DAG that we wrote earlier in the example.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.33：通过 AWS MWAA 服务访问的 Airflow UI。此视图显示了我们在示例中早先编写的分类 DAG。
- en: The Airflow UI allows you to trigger DAG runs, manage the jobs that you have
    scheduled, and monitor and troubleshoot your pipelines. As an example, upon a
    successful run, you can see summary information for the runs, as shown in *Figure
    5.34*, and can use the different views to understand the time taken for each of
    the pipeline steps and diagnose where any issues have arisen if there are errors
    raised.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow UI 允许您触发 DAG 运行，管理您已安排的工作，以及监控和调试您的管道。例如，在运行成功后，您可以看到运行的摘要信息，如图 *图 5.34*
    所示，并且可以使用不同的视图来了解每个管道步骤所花费的时间，并在出现错误时诊断问题所在。
- en: '![](img/B19525_05_34.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_34.png)'
- en: 'Figure 5.34: Example run summary for our simple classification DAG in the Airflow
    UI.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.34：Airflow UI 中我们简单分类 DAG 的示例运行摘要。
- en: The pipeline we have built and run in this example is obviously very simple,
    with only core Python functionality being used. If you want to leverage other
    AWS services, for example, by submitting a Spark job to an EMR cluster, then you
    will need to configure further access policies like the one we did above for the
    UI access. This is covered in the MWAA documentation.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们构建和运行的管道显然非常简单，只使用了核心 Python 功能。如果您想利用其他 AWS 服务，例如通过提交 Spark 作业到 EMR
    集群，那么您将需要配置额外的访问策略，就像我们上面为 UI 访问所做的那样。这将在 MWAA 文档中介绍。
- en: IMPORTANT NOTE
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Once you have created this MWAA environment, you cannot pause it, as it costs
    a small amount to run per hour (around 0.5 USD per hour for the environment configuration
    above). MWAA does not currently contain a feature for pausing and resuming an
    environment, so you will have to delete the environment and re-instantiate a new
    one with the same configuration when required. This can be automated using tools
    such as **Terraform** or **AWS** **CloudFormation**, which we will not cover here.
    So, a word of warning – *DO NOT ACCIDENTALLY LEAVE YOUR ENVIRONMENT RUNNING*.
    For example, definitely do not leave it running for a week, like I may or may
    not have done.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了此 MWAA 环境，您就不能暂停它，因为它每小时运行的成本很小（对于上述环境配置，大约为每小时 0.5 美元）。目前 MWAA 不包含暂停和恢复环境的特性，因此当需要时，您必须删除环境并重新实例化一个具有相同配置的新环境。这可以使用
    **Terraform** 或 **AWS CloudFormation** 等工具自动化，这里我们不会涉及。所以，提醒一句——**千万不要意外地让您的环境持续运行**。例如，绝对不要像可能或可能没有做过的那样，让它连续运行一周。
- en: Revisiting CI/CD for Airflow
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回顾 Airflow 的 CI/CD
- en: We introduced the basics of CI/CD in *Chapter 2*, *The Machine Learning Development
    Process*, and discussed how this can be achieved by using **GitHub Actions**.
    We will now take this a step further and start to set up CI/CD pipelines that
    deploy code to the cloud.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 *第 2 章*，*机器学习开发过程* 中介绍了 CI/CD 的基础知识，并讨论了如何通过使用 **GitHub Actions** 来实现这一点。现在，我们将更进一步，开始设置部署代码到云的
    CI/CD 管道。
- en: First, we will start with an important example where we will push some code
    to an AWS S3 bucket. This can be done by creating a `.yml` file in your GitHub
    repo under your `.github./workflows` directory called `aws-s3-deploy.yml`. This
    will be the nucleus around which we will form our CI/CD pipeline.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从一个重要的例子开始，在这个例子中，我们将把一些代码推送到 AWS S3 桶。这可以通过在您的 GitHub 仓库的 `.github/workflows`
    目录下创建一个名为 `aws-s3-deploy.yml` 的 `.yml` 文件来完成。这将是我们将围绕其构建 CI/CD 管道的核心。
- en: 'The .`yml` file, in our case, will upload the Airflow DAG and contain the following
    pieces:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，`.yml` 文件将上传 Airflow DAG，并包含以下内容：
- en: 'We name the process using the syntax for `name` and express that we want the
    deployment process to be triggered on a push to the main branch or a pull request
    to the main branch:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `name` 的语法命名该过程，并表达我们希望在主分支的推送或主分支的拉取请求时触发部署过程：
- en: '[PRE24]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We then define the jobs we want to occur during the deployment process. In
    this case, we want to upload our DAG files to an S3 bucket we have already created,
    and we want to use the appropriate AWS credentials we have configured in our GitHub
    secrets store:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随后定义了在部署过程中希望发生的作业。在这种情况下，我们希望将我们的 DAG 文件上传到我们已创建的 S3 桶，并希望使用我们在 GitHub 密钥存储中配置的适当
    AWS 凭据：
- en: '[PRE25]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, as part of the job, we run the step that copies the relevant files to
    our specified AWS S3 bucket. In this case, we are also specifying some details
    about how to make the copy using the AWS CLI. Specifically, here we want to copy
    over all the Python files to the `dags` folder of the repo:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，作为工作的一部分，我们运行步骤，将相关文件复制到我们指定的 AWS S3 桶。在这种情况下，我们还指定了如何使用 AWS CLI 进行复制的一些细节。具体来说，我们希望将所有
    Python 文件复制到存储库的 `dags` 文件夹：
- en: '[PRE26]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Once we perform a `git push` command with updated code, this will then execute
    the action and push the `dag` Python code to the specified S3 bucket. In the GitHub
    UI, you will be able to see something like *Figure 5.35* on a successful run:![Figure
    5.38 – A successful CI/CD process run via GitHub Actions and using the AWS CLI
    ](img/B19525_05_35.png)
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们执行了带有更新代码的 `git push` 命令，这将执行操作并将 `dag` Python 代码推送到指定的 S3 桶。在 GitHub UI
    中，您将能够看到一个成功的运行示例，类似于 *图 5.35*：![图 5.38 – 通过 GitHub Actions 和 AWS CLI 运行的成功的 CI/CD
    流程](img/B19525_05_35.png)
- en: 'Figure 5.35: A successful CI/CD process run via GitHub Actions and using the
    AWS CLI.'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.35：通过 GitHub Actions 和 AWS CLI 运行的成功的 CI/CD 流程。
- en: This process then allows you to successfully push new updates to your Airflow
    service into AWS to be run by your MWAA instance. This is real CI/CD and allows
    you to continually update the service you are providing without downtime.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程允许您成功地将新的更新推送到您的 Airflow 服务到 AWS，以便由您的 MWAA 实例运行。这是真正的 CI/CD，并允许您在不中断服务的情况下持续更新您提供的服务。
- en: Building advanced ML pipelines
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建高级机器学习（ML）管道
- en: We have already discussed in this chapter how **SciKit-learn** and **Spark ML**
    provide mechanisms for creating ML pipelines. You can think of these as the basic
    way to do this and to get started. There are a series of tools now available,
    both open-source and enterprise, that take this concept to the next level.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中已经讨论了 **SciKit-learn** 和 **Spark ML** 如何提供创建 ML 管道的机制。您可以将这些视为基本的方法来做到这一点，并开始入门。现在有一系列的工具可供使用，包括开源和商业的，它们将这一概念提升到了新的水平。
- en: For awareness, the three main public cloud providers have tools in this area
    you may want to be aware of and try out. **Amazon SageMaker** is one of the giants
    of this space and contains within it a large ecosystem of tools and capabilities
    to help take your ML models into production. This book could have been entirely
    about Amazon SageMaker, but since that was done elsewhere, in *Learn Amazon SageMaker*,
    [https://tinyurl.com/mr48rsxp](https://tinyurl.com/mr48rsxp), we will leave the
    details for the reader to discover. The key thing you need to know is that this
    is AWS’s managed service for building up ML pipelines, as well as monitoring,
    model registry, and a series of other capabilities in a way that lets you develop
    and promote your models all the way through the ML lifecycle. **Google Vertex
    AI** is the Google Cloud Platform ML pipelining, development, and deployment tool.
    It brings tons of functionality under one UI and API, like Sagemaker, but seems
    to have less flexibility on the types of models you can train. **Azure ML** is
    the Microsoft cloud provider’s offering.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让大家了解，三大主要公共云提供商在这个领域都有您可能想要了解并尝试的工具。**Amazon SageMaker** 是这个领域的巨头之一，它包含了一个庞大的工具和功能生态系统，可以帮助您将
    ML 模型投入生产。这本书本可以完全关于 Amazon SageMaker，但由于那已经在其他地方完成，在 *Learn Amazon SageMaker*
    [https://tinyurl.com/mr48rsxp](https://tinyurl.com/mr48rsxp) 中，我们将细节留给读者去发现。您需要知道的关键是，这是
    AWS 的托管服务，用于构建 ML 管道，以及监控、模型注册和其他一系列功能，让您能够在整个 ML 生命周期中开发和推广您的模型。**Google Vertex
    AI** 是 Google 云平台的 ML 管道、开发和部署工具。它将大量的功能集成在一个 UI 和 API 中，就像 Sagemaker 一样，但在可训练的模型类型上似乎灵活性较低。**Azure
    ML** 是微软云提供商的解决方案。
- en: These are all enterprise-grade solutions that you can try for free, but you
    should be prepared to have your credit card ready when things scale up. The solutions
    above are also naturally tied into specific cloud providers and therefore can
    create “vendor lock-in,” where it becomes difficult to switch later. Thankfully,
    there are solutions that help with this and allow ML engineers to work with a
    less complex setup and then migrate to more complex infrastructure and environments
    later. The first one of these that we will discuss is **ZenML**.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是可以免费尝试的企业级解决方案，但当你需要扩展时，你应该准备好准备好你的信用卡。上述解决方案也自然地与特定的云提供商相关联，因此可能会产生“供应商锁定”，这会使得后续切换变得困难。幸运的是，有一些解决方案可以帮助解决这个问题，并允许机器学习工程师使用更简单的设置进行工作，然后在以后迁移到更复杂的基础设施和环境。我们将首先讨论的这些解决方案之一是**ZenML**。
- en: Finding your ZenML
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找你的ZenML
- en: '**ZenML** is a completely open-source framework that helps you write ML pipelines
    in a way that is totally abstracted from the underlying infrastructure. This means
    that your local development environment and your eventual production environment
    can be very different, and can be changed through changes in configuration without
    altering the core of your pipelines. This is a very powerful idea and is one of
    ZenML’s key strengths.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**ZenML**是一个完全开源的框架，它帮助你以完全抽象底层基础设施的方式编写机器学习管道。这意味着你的本地开发环境和最终的生产环境可以非常不同，并且可以通过配置更改来改变，而不需要改变管道的核心。这是一个非常强大的想法，也是ZenML的关键优势之一。'
- en: 'ZenML has some core concepts that you need to understand in order to get the
    best out of the tool:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从ZenML中获得最佳效果，你需要了解一些核心概念：
- en: '**Pipelines**: As you might expect given the discussion in the rest of this
    chapter, these are the definitions of the steps in the ML workflow. Pipelines
    consist of “steps” chained together in a specified order.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**: 如同本章其余部分的讨论所预期的那样，这些是机器学习工作流程中步骤的定义。管道由按指定顺序连接的“步骤”组成。'
- en: '**Stacks**: Configurations specifying the environment and infrastructure that
    the pipeline is to run on.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆栈**: 指定管道要运行的环境和基础设施的配置。'
- en: '**Orchestrator**: Within the stack definition, there are two key components,
    the first of which is an orchestrator. Its job is to coordinate the steps in the
    pipeline that are executed on the infrastructure. This could be the default orchestrator
    that comes with the distribution or it could be something like Airflow or the
    Kubeflow orchestrator. Airflow is described in the *Building general pipelines
    with Airflow* section in this chapter and Kubeflow is covered in the *Going with
    the Kubeflow* section.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编排器**: 在堆栈定义中，有两个关键组件，第一个是一个编排器。其任务是协调在基础设施上执行的管道步骤。这可能是由发行版提供的默认编排器，也可能是类似Airflow或Kubeflow编排器。Airflow在本章的“使用Airflow构建通用管道”部分有所描述，而Kubeflow则在“跟随Kubeflow”部分进行介绍。'
- en: '**Artifact store**: This is the stack component responsible for data and metadata
    storage. ZenML has a series of different compatible artifact stores out of the
    box, specifically AWS S3, Azure Blob Storage, and Google Cloud Storage. The assumption
    here is that the artifact store is really just a storage layer, and nothing too
    complex on top of that.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工件存储**: 这是负责数据和元数据存储的堆栈组件。ZenML自带一系列兼容的工件存储，具体包括AWS S3、Azure Blob Storage和Google
    Cloud Storage。这里的假设是工件存储实际上只是一个存储层，其上没有太多复杂的功能。'
- en: 'So far, so straightforward. Let’s get on and start setting ZenML up. You can
    install it with:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切都很直接。让我们开始设置ZenML。你可以使用以下命令安装它：
- en: '[PRE27]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will also want to use the React dashboard that comes with ZenML, but to
    run this locally you also need to install a different repository:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望使用ZenML附带的React仪表板，但为了在本地运行它，你还需要安装一个不同的存储库：
- en: '[PRE28]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'ZenML also comes with a series of existing templates you can leverage, which
    you can install with:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ZenML还提供了一系列你可以利用的现有模板，你可以使用以下命令安装：
- en: '[PRE29]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can then start working with a template by running:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过运行以下命令开始使用模板：
- en: '[PRE30]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This will then start a terminal-based wizard to help you generate the ZenML
    template. See *Figure 5.36*.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个基于终端的向导，帮助你生成ZenML模板。参见*图5.36*。
- en: '![](img/B19525_05_36.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_36.png)'
- en: 'Figure 5.36: The ZenML template wizard.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.36：ZenML模板向导。
- en: Hit *Enter*; then you will be asked a series of questions to help configure
    the template. Some are shown with their answers in *Figure 5.37*.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 按*Enter*键；然后你将回答一系列问题以帮助配置模板。其中一些在*图5.37*中显示出了它们的答案。
- en: '![](img/B19525_05_37.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_37.png)'
- en: 'Figure 5.37: Providing responses for the ZenML template definition.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.37*：为ZenML模板定义提供响应。'
- en: The next series of questions start to get very interesting as we are asked about
    the details of the information we wish to be logged and made visible in the CLI,
    as well as selecting the dataset and model type. Here we will work with the `Wine`
    dataset, again using a `RandomForestClassifier`, as can be seen in *Figure 5.38*.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们被问到我们希望记录和显示在CLI中的信息的细节，以及选择数据集和模型类型，接下来的问题系列开始变得非常有趣。在这里，我们将使用`Wine`数据集，再次使用`RandomForestClassifier`，如*图5.38*所示。
- en: '![](img/B19525_05_38.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_38.png)'
- en: 'Figure 5.38: Selecting a model for the ZenML template instantiation.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.38*：为ZenML模板实例化选择模型。'
- en: ZenML will then start initializing the template for you. You can see that this
    process generates a lot of new files to use, as shown in *Figure 5.39*.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ZenML将开始为你初始化模板。你可以看到这个过程生成了许多新文件来使用，如*图5.39*所示。
- en: '![](img/B19525_05_39.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_39.png)'
- en: 'Figure 5.39: File and folder structure generated after using the ZenML template
    generation wizard.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.39*：使用ZenML模板生成向导后生成的文件和文件夹结构。'
- en: 'Let’s start to explore some of these elements for the ZenML solution. First,
    let’s look at `pipelines/model_training.py`. This is a short script that is there
    to give you a starting point. Omitting the comments in the file, we have the following
    code present:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始探索ZenML解决方案的一些元素。首先，让我们看看`pipelines/model_training.py`。这是一个简短的脚本，旨在为你提供一个起点。省略文件中的注释，我们有以下代码存在：
- en: '[PRE31]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can already start to appreciate some of the features that are available in
    ZenML and how it works. First, we see that the use of the `@pipeline` decorator
    signals that the function following will contain the main pipeline logic. We can
    also see that the pipeline is actually written in pure Python syntax; all you
    need is the decorator to make it “Zen.” This is a very powerful feature of ZenML
    as it provides you the flexibility to work as you want but still leverage the
    downstream abstraction we will see soon for deployment targets. The steps inside
    the pipeline are just dummy function calls created when the template was initialized
    to help guide you in what you should develop.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经开始欣赏ZenML中可用的某些功能以及它是如何工作的。首先，我们看到使用`@pipeline`装饰器表示随后的函数将包含主要的管道逻辑。我们还可以看到管道实际上是用纯Python语法编写的；你只需要装饰器来使其“Zen”。这是ZenML的一个非常强大的功能，因为它为你提供了按自己的意愿工作的灵活性，同时仍然可以利用我们很快将看到的用于部署目标的下游抽象。管道内的步骤只是当模板初始化时创建的虚拟函数调用，以帮助你了解你应该开发什么。
- en: 'Now, we will look at the pipeline steps, which have been defined in the `steps/data_loaders.py`
    and `steps/model_trainers.py` files. In our discussions of these modules, we will
    not discuss the helper classes and utility functions used; these are left for
    the reader to play around with. Instead, we will focus on the pieces that show
    the most important ZenML functionality. Before we do that, let us briefly discuss
    some important ZenML modules that are imports at the top of the module:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看管道步骤，这些步骤已在`steps/data_loaders.py`和`steps/model_trainers.py`文件中定义。在我们对这些模块的讨论中，我们不会讨论使用的辅助类和实用函数；这些留给读者去探索。相反，我们将专注于展示最重要的ZenML功能的片段。在我们这样做之前，让我们简要讨论一些重要的ZenML模块，这些模块在模块顶部导入：
- en: '[PRE32]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The first import brings in `StrEnum` from the `enums` module of ZenML. This
    is a collection of Python enumerations that have been defined to help with specific
    elements of building ZenML workflows.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个导入从ZenML的`enums`模块中引入了`StrEnum`。这是一个Python枚举的集合，已被定义为帮助构建ZenML工作流程的特定元素。
- en: IMPORTANT NOTE
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Recall that a Python enumeration (or `enum`) is a collection of members with
    unique values that can be iterated over to return the values in their order of
    definition. You can think of these as somewhere between a class and a dictionary.
    First, in the `data_loaders.py` module, we can see that the first step wraps simple
    logic for pulling in different datasets from `scikit-learn`, depending on the
    parameters supplied. This is a very basic example but can be updated to incorporate
    much more sophisticated behavior like calling out to databases or pulling from
    cloud-hosted object storage. The method looks like the following:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，Python 枚举（或`enum`）是一组具有唯一值的成员集合，可以通过迭代返回它们的定义顺序。你可以把它们看作介于类和字典之间。首先，在`data_loaders.py`模块中，我们可以看到第一步包装了从`scikit-learn`拉取不同数据集的简单逻辑，这取决于提供的参数。这是一个非常基础的例子，但可以更新以包含更复杂的行为，如调用数据库或从云托管对象存储中拉取。方法看起来如下：
- en: '[PRE33]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Note that the output of this function is a pandas DataFrame, and in the language
    of ZenML this is an artifact. The next important step given is data processing.
    The example given in the template looks like the following:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个函数的输出是一个 pandas DataFrame，在 ZenML 的语言中这是一个工件。接下来的重要步骤是数据处理。模板中给出的示例看起来如下：
- en: '[PRE34]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We can see that, here, the processing is relatively standard and will drop `NULL`
    values in the dataset, remove columns we have labeled in the `DataProcessingStepParameters`
    classes (not shown here), and apply some normalization using standard scaling
    – the steps given are in fact identical to applying the `sklearn.preprocessing.StandardScaler`
    method.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在这里，处理相对标准，将在数据集中删除`NULL`值，移除我们在`DataProcessingStepParameters`类中标记的列（此处未展示），并使用标准缩放应用一些归一化——给出的步骤实际上等同于应用`sklearn.preprocessing.StandardScaler`方法。
- en: 'The final method in the data loaders module performs train/test splitting of
    the data, using methods we have already seen in this book:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载器模块中的最后一个方法执行数据的训练/测试分割，使用的是我们在本书中已经看到的方法：
- en: '[PRE35]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, moving back into the `steps` folder, we can see that there is also a module
    entitled `model_trainers.py`. At the top of this folder are some more important
    imports we should understand before we proceed:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到`steps`文件夹，我们可以看到还有一个名为`model_trainers.py`的模块。在这个文件夹的顶部有一些我们在继续之前应该理解的重要导入：
- en: '[PRE36]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In particular, we can see that ZenML provides a wrapper to the Python logging
    library and that there are two modules being used here, called `artifacts` and
    `materializers`. These are defined within the template repo and show how you can
    create custom code to work with the artifact store. Specifically, in the `artifacts/model_metadata.py`
    module, there is a class that allows you to store model metadata in a format of
    your choosing for later serialization and deserialization. Once again, all docstrings
    and most imports are omitted for brevity:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我们可以看到 ZenML 提供了对 Python 日志库的包装，并且这里使用了两个模块，分别称为`artifacts`和`materializers`。这些在模板仓库中定义，展示了如何创建自定义代码来与工件存储库一起工作。具体来说，在`artifacts/model_metadata.py`模块中，有一个类允许你以你选择的格式存储模型元数据，以便稍后进行序列化和反序列化。再次强调，为了简洁，省略了所有文档字符串和大多数导入：
- en: '[PRE37]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In ZenML, materializers are the objects that contain the logic for the serialization
    and deserialization of the artifacts. They define how your pipelines interact
    with the artifact store. When defining materializers, you can create custom code
    but you have to inherit from the `BaseMaterializer` class in order to ensure that
    ZenML knows how to persist and read in data between steps and at the beginning
    and end of pipelines. This is shown below in important code from `materializers/model_metadata.py`:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ZenML 中，materializers 是包含工件序列化和反序列化逻辑的对象。它们定义了你的管道如何与工件存储库交互。在定义 materializers
    时，你可以创建自定义代码，但必须从`BaseMaterializer`类继承，以确保 ZenML 知道如何在步骤之间以及管道的开始和结束时持久化和读取数据。这在下面的`materializers/model_metadata.py`中的重要代码中展示：
- en: '[PRE38]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now that we have discussed all the key pieces of the ZenML template, we want
    to run the pipeline. This is done via runner `run.py` at the utmost level of the
    repository. You can then run the pipeline with:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了 ZenML 模板的所有关键部分，我们想要运行管道。这是通过仓库最高级别的`runner/run.py`执行的。然后你可以使用以下命令运行管道：
- en: '[PRE39]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'After the pipeline successfully runs (you will see a series of outputs in the
    terminal), you can run the following command to spin up a locally hosted ZenML
    dashboard:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道成功运行后（你将在终端中看到一系列输出），你可以运行以下命令来启动一个本地托管的 ZenML 仪表板：
- en: '[PRE40]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Now, if you navigate to the URL that is returned as output, usually something
    like `http://127.0.0.1:8237/login`, you will see a home screen like that shown
    in *Figure 5.40*.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你导航到作为输出返回的URL，通常像`http://127.0.0.1:8237/login`这样的URL，你会看到一个像*图5.40*中显示的主屏幕。
- en: '![](img/B19525_05_40.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_40.png)'
- en: 'Figure 5.40: The ZenML UI login page.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.40：ZenML UI登录页面。
- en: In the output that gave you the URL is also a default username and password,
    conveniently **default** and a blank. Fill these in and you will see the home
    page shown in *Figure 5.41*.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供URL的输出中还有一个默认用户名和密码，方便地**默认**和空白。填写这些信息，你将看到*图5.41*中显示的主页。
- en: '![](img/B19525_05_41.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_41.png)'
- en: 'Figure 5.41: The ZenML UI home page.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.41：ZenML UI首页。
- en: If you then click through into the **Pipelines** section on the left and then
    click the pipeline created by your first run, you will be able to see all of the
    times that it has been run since then. This view is shown in *Figure 5.42*.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你点击左侧的**管道**部分，然后点击你第一次运行创建的管道，你将能够看到自那时起它运行的所有时间。这个视图在*图5.42*中显示。
- en: '![](img/B19525_05_42.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_42.png)'
- en: 'Figure 5.42: The pipelines view in the ZenML UI.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.42：ZenML UI中的管道视图。
- en: You can then also get really detailed information about the specifics of each
    run by clicking through. This gives you information like a graphical representation
    of the pipeline as a DAG at the time of the run. See *Figure 5.43*.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过点击来获取每个运行的详细信息。这会给你提供诸如在运行时作为DAG的管道图形表示等信息。见*图5.43*。
- en: '![](img/B19525_05_43.png)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_43.png)'
- en: 'Figure 5.43: An example DAG for a ZenML pipeline shown in the UI.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.43：ZenML UI中显示的ZenML管道示例DAG。
- en: 'If you click through on the pipeline name in any of these views, you can also
    retrieve the configuration of the run at the time of its execution in YAML format,
    which you can download and then use in subsequent pipeline runs:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在这任何视图上点击管道名称，你还可以检索执行时的配置，以YAML格式，你可以下载并在后续管道运行中使用：
- en: '![](img/B19525_05_44.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_44.png)'
- en: 'Figure 5.44: An example YAML configuration for a ZenML pipeline run, shown
    in the ZenML UI.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.44：ZenML UI中显示的ZenML管道运行示例YAML配置。
- en: This has only begun to scratch the surface of what is possible with ZenML, but
    hopefully, you can already see how it is a very flexible way to define and execute
    your ML pipelines. This becomes even more powerful when you leverage its ability
    to deploy the same pipeline across different stacks and different artifact stores.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是ZenML可能实现功能的一小部分，但希望你已经看到了它如何是一种非常灵活的方式来定义和执行你的ML管道。当你利用其跨不同堆栈和不同工件存储部署相同管道的能力时，它变得更加强大。
- en: In the next section, we will discuss another pipelining tool that focuses on
    creating cross-platform compatibility and standardization for your ML pipelines,
    **Kubeflow**.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论另一个关注创建跨平台兼容性和标准化ML管道的管道工具，**Kubeflow**。
- en: Going with the Kubeflow
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按照Kubeflow进行
- en: '**Kubeflow** is an open-source solution aimed at providing portable methods
    for building end-to-end ML systems. This tool has a particular focus on giving
    developers the ability to quickly create pipelines for data processing, ML model
    training, prediction, and monitoring that are platform agnostic. It does all this
    by leveraging Kubernetes, allowing you to develop your solution on very different
    environments from where you eventually deploy. Kubeflow is agnostic about the
    particular programming and ML frameworks you use, so you can leverage everything
    you like out there in the open-source community but still stitch it together in
    a way you can trust.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubeflow**是一个开源解决方案，旨在提供构建端到端ML系统的便携式方法。这个工具特别关注为开发者提供快速创建数据预处理、ML模型训练、预测和监控管道的能力，这些管道是平台无关的。它通过利用Kubernetes来实现所有这些，允许你在最终部署的环境之外的不同环境中开发你的解决方案。Kubeflow对特定的编程和ML框架不敏感，因此你可以利用开源社区中的所有你喜欢的工具，但仍然以你信任的方式将它们组合在一起。'
- en: The Kubeflow documentation provides a great wealth of detail on the architecture
    and design principles behind the tool at [https://www.kubeflow.org/docs/](https://www.kubeflow.org/docs/).
    We will focus instead on understanding the most salient points and getting started
    with some practical examples. This will allow you to compare to the other tools
    we have discussed in this chapter and make your own decisions around which to
    take forward in future projects.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 文档提供了关于该工具背后的架构和设计原则的大量详细信息，请参阅 [https://www.kubeflow.org/docs/](https://www.kubeflow.org/docs/)。我们将专注于理解最显著的观点，并通过一些实际示例开始。这将使您能够将此与其他我们在本章中讨论的工具进行比较，并让您在未来项目中做出自己的决定。
- en: 'Kubeflow is a platform that consists of multiple modular components, each one
    playing a role in the ML development lifecycle. Specifically, there are:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 是一个由多个模块化组件组成的平台，每个组件在机器学习开发生命周期中都扮演着角色。具体来说，有：
- en: The Jupyter Notebook web app and controller for exploratory data analysis and
    initial modeling.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook 网页应用和控制器，用于数据探索分析和初步建模。
- en: Training operators like PyTorch, TFJob, and XGBoost operators, among others,
    to build a variety of models.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 PyTorch、TFJob 和 XGBoost 操作员等训练操作员，用于构建各种模型。
- en: Hyperparameter tuning and neural network architecture search capabilities using
    Katib.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Katib 进行超参数调整和神经网络架构搜索功能。
- en: Spark operators for data transformation, including an option for AWS EMR clusters.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据转换的 Spark 操作员，包括 AWS EMR 集群的选项。
- en: Dashboard for interfacing with your Kubernetes cluster and for managing your
    Kubeflow workloads.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于与您的 Kubernetes 集群交互以及管理您的 Kubeflow 工作负载的仪表板。
- en: 'Kubeflow Pipelines: its own platform for building, running, and managing end-to-end
    ML workflows. This includes an orchestration engine for workflows with multiple
    steps and an SDK for working with your pipelines. You can install Kubeflow Pipelines
    as a standalone platform.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines：它自己的平台，用于构建、运行和管理端到端机器学习工作流程。这包括用于具有多个步骤的工作流程的编排引擎以及用于与您的管道一起工作的
    SDK。您可以将 Kubeflow Pipelines 作为独立平台进行安装。
- en: 'The installation steps for getting Kubeflow up and running can be quite involved
    and so it is best to look at the official documentation and run the appropriate
    steps for your platform and needs. We will proceed via the following steps:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Kubeflow 安装并运行起来的步骤可能相当复杂，因此最好查看官方文档，并运行适合您平台和需求的相关步骤。我们将按照以下步骤进行：
- en: 'Install Kind, a tool that facilitates easy building and running of local Kubernetes
    clusters. On Linux, this is done with:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Kind，这是一个便于轻松构建和运行本地 Kubernetes 集群的工具。在 Linux 上，这是通过以下方式完成的：
- en: '[PRE41]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'And on MacOS this is done by:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 MacOS 上，这是通过以下方式完成的：
- en: '[PRE42]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Install the Kubernetes command-line tool `kubectl`, which allows you to interact
    with your cluster. On Linux, this is done with:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Kubernetes 命令行工具 `kubectl`，它允许您与您的集群进行交互。在 Linux 上，这是通过以下方式完成的：
- en: '[PRE43]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Or on MacOS:'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，在 MacOS 上：
- en: '[PRE44]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To check this has worked, you can run the following command in the terminal:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查是否成功，您可以在终端中运行以下命令：
- en: '[PRE45]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'And you should receive an output like this:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该会收到类似以下的输出：
- en: '[PRE46]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Use Kind to create your local cluster. As the default, the name of the cluster
    will be `kind`, but you can provide your own name as a flag:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kind 创建您的本地集群。默认情况下，集群的名称将是 `kind`，但您可以通过标志提供自己的名称：
- en: '[PRE47]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You will then see output that is something like this:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到类似以下的输出：
- en: '[PRE48]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'You then have to deploy Kubeflow pipelines to the cluster. The commands for
    doing this have been brought into a script called `deploy_kubeflow_pipelines.zsh`
    in the book’s GitHub repository and it contains the following code (the `PIPELINE_VERSION`
    number can be updated as needed to match your installation):'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您需要将 Kubeflow 管道部署到集群中。为此的命令已被包含在本书 GitHub 仓库中名为 `deploy_kubeflow_pipelines.zsh`
    的脚本中，并包含以下代码（`PIPELINE_VERSION` 数字可以根据需要更新以匹配您的安装）：
- en: '[PRE49]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: After running these commands, you can verify that the installation was a success
    through port forwarding and opening the Kubeflow Pipelines UI at `http://localhost:8080/:`
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这些命令后，您可以通过端口转发并在 `http://localhost:8080/` 打开 Kubeflow Pipelines UI 来验证安装是否成功：
- en: '[PRE50]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This should then give you a landing page like the one shown in *Figure 5.45*.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会为您提供类似 *图 5.45* 中所示的登录页面。
- en: '![](img/B19525_05_45.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.45](img/B19525_05_45.png)'
- en: 'Figure 5.45: The Kubeflow UI landing page.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.45：Kubeflow UI 登录页面。
- en: 'Now that you have initiated port-forwarding with the previous command, you
    will use this to allow the Kubeflow Pipelines SDK to talk to the cluster via the
    following Python code (note that you cannot do this until you have installed the
    Kubeflow Pipelines SDK, which is covered in the next step):'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经使用之前的命令启动了端口转发，你将使用这个命令通过以下Python代码允许Kubeflow Pipelines SDK通过集群进行通信（注意，你必须在安装了Kubeflow
    Pipelines SDK之后才能这样做，这将在下一步介绍）：
- en: '[PRE51]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'To install the Kubeflow Pipelines SDK, run:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Kubeflow Pipelines SDK，请运行：
- en: '[PRE52]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'To check that everything is in order, you can run this command:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查一切是否正常，你可以运行以下命令：
- en: '[PRE53]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Which gives output that should be similar to:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出类似于以下输出的结果：
- en: '[PRE54]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: And that’s it! We are now ready to start building some Kubeflow pipelines. Let’s
    get started with a basic example.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们现在准备好开始构建一些Kubeflow管道了。让我们从一个基本示例开始。
- en: 'We can now start building out some basic pipelines using the SDK and then we
    can deploy them to our cluster. Let’s assume for the next few steps we are working
    in a file called `pipeline_basic.py`:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始使用SDK构建一些基本的管道，然后我们可以将它们部署到我们的集群中。假设接下来几步我们在一个名为`pipeline_basic.py`的文件中工作：
- en: 'First, we import what is known as the KFP **Domain-Specific Language** (**DSL**),
    which is a set of Python packages with various utilities for defining KFP steps.
    We also import the client package for interacting with the cluster. We’ll also
    import several DSL sub-modules that we will use later. An important point to note
    here is that some functionality we will leverage is in fact contained in the `V2`
    of the Kubeflow pipelines SDK and so we will need to import some of those specific
    modules as well:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入所谓的KFP **领域特定语言**（**DSL**），这是一个包含用于定义KFP步骤的各种实用工具的Python包集。我们还导入用于与集群交互的客户端包。我们还将导入我们稍后将要使用的几个DSL子模块。在这里需要注意的一个重要点是，我们将利用的一些功能实际上包含在Kubeflow
    pipelines SDK的`V2`中，因此我们需要导入一些这些特定模块：
- en: '[PRE55]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The next step is to define the steps in the pipeline. These are called “components”
    and are functions wrapped with `dsl` decorators. In this first step, we retrieve
    the Iris dataset and write it to CSV. In the first line, we will use the `dsl`
    decorator and also define what packages need to be installed in the container
    that will run that step:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是定义管道中的步骤。这些被称为“组件”，是带有`dsl`装饰器的函数。在这个第一步中，我们检索Iris数据集并将其写入CSV。在第一行，我们将使用`dsl`装饰器，并定义将运行该步骤的容器中需要安装的包：
- en: '[PRE56]'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Now that we have retrieved a dataset, and remembering what we learned in *Chapter
    3*, *From Model to Model Factory*, we want to feature engineer this data. So,
    we will normalize the data in another component. Most of the code should be self-explanatory,
    but note that we have had to add the `scikit-learn` dependency in the `packages_to_install`
    keyword argument and that we have again had to write the result of the component
    out to a CSV file:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经检索到了数据集，并回忆起我们在*第3章*中学到的知识，*从模型到模型工厂*，我们想要对数据进行特征工程。因此，我们将在另一个组件中规范化数据。大部分代码应该是自解释的，但请注意，我们不得不在`packages_to_install`关键字参数中添加`scikit-learn`依赖项，并且我们再次不得不将组件的结果写入CSV文件：
- en: '[PRE57]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We will now train a K-nearest neighbors classifier on the data. Instead of
    outputting a dataset in this component, we will output the trained model artifact,
    a `.pkl` file:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将在数据上训练一个K最近邻分类器。在这个组件中，我们不会输出数据集，而是输出训练好的模型工件，一个`.pkl`文件：
- en: '[PRE58]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We now have all the components for the work we want to do, so now we can finally
    bring it together into a Kubeflow pipeline. To do this, we use the `@dsl.pipeline`
    decorator and as an argument to that decorator, we provide the name of the pipeline:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在有了我们想要做的所有组件，所以现在我们可以最终将它们组合成一个Kubeflow管道。为此，我们使用`@dsl.pipeline`装饰器，并将管道的名称作为该装饰器的参数：
- en: '[PRE59]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The final stage is to submit the pipeline to run. This is done by instantiating
    a Kubeflow Pipelines client class and feeding in the appropriate arguments. `<KFP_UI_URL`>
    is the URL for the host of your instance of Kubeflow Pipelines – in this case,
    the one that we got from performing port-forwarding earlier. It is also important
    to note that since we are using several features from the `V2` Kubeflow Pipelines
    API, we should pass in the `kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE` flag
    for the mode argument:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后的阶段是将管道提交运行。这是通过实例化一个Kubeflow Pipelines客户端类并输入适当的参数来完成的。《KFP_UI_URL》是Kubeflow
    Pipelines实例的主机URL - 在这种情况下，是我们之前通过端口转发得到的那个。还重要的是要注意，由于我们正在使用`V2` Kubeflow Pipelines
    API的几个功能，我们应该为模式参数传递`kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE`标志：
- en: '[PRE60]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'To build and deploy this pipeline and run it, you can then execute:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要构建和部署此管道并运行它，你可以执行以下操作：
- en: '[PRE61]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'After running this last step, you will see the URL of the run is printed to
    the terminal, and should look something like this:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行最后一步后，你将看到运行的URL打印到终端，看起来可能像这样：
- en: '[PRE62]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: If you navigate to that link and the pipeline has successfully run, you should
    see a view in the Kubeflow dashboard showing the steps of the pipeline, with a
    sidebar that allows you to navigate through a series of metadata about your pipeline
    and its run. An example from running the above code is shown in *Figure 5.46*.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你导航到该链接，并且管道已成功运行，你应该在Kubeflow仪表板中看到一个视图，显示管道的步骤，还有一个侧边栏允许你浏览关于你的管道及其运行的元数据系列。上述代码运行的一个示例显示在*图5.46*中。
- en: '![](img/B19525_05_46.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_05_46.png)'
- en: 'Figure 5.46: The Kubeflow UI showing the successful run of the training pipeline
    defined in the main text.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.46：Kubeflow UI显示了主文中定义的训练管道的成功运行。
- en: And that’s it, you have now built and run your first Kubeflow pipeline!
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，你现在已经构建并运行了你的第一个Kubeflow管道！
- en: IMPORTANT NOTE
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'You can also compile your Kubeflow pipelines to serialized YAML, which can
    then be read by the Kubeflow backend. You would do this by running a command like
    the following, where `pipeline` is the same pipeline object used in the previous
    example:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将Kubeflow管道编译成序列化的YAML，然后可以被Kubeflow后端读取。你可以通过运行以下类似命令来完成此操作，其中`pipeline`是之前示例中使用的相同管道对象：
- en: '[PRE63]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: One reason to do this is it is then super easy to run the pipeline. You can
    just upload it to the Kubeflow Pipelines UI, or you can send the YAML to the cluster
    programmatically.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 做这件事的一个原因是运行管道变得非常简单。你只需将其上传到Kubeflow管道UI，或者你可以通过编程方式将YAML发送到集群。
- en: As in the *Finding your ZenML* section, we have only begun to scratch the surface
    of this tool and have focused initially on getting to know the basics in a local
    environment. The beauty of Kubeflow being based on Kubernetes is that platform
    agnosticism is very much at its core and so these pipelines can be effectively
    run anywhere that supports containers.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 如同在*寻找你的ZenML*部分所述，我们只是刚刚开始探索这个工具的表面，最初的重点是在本地环境中了解基础知识。Kubeflow基于Kubernetes的优点在于平台无关性是其核心所在，因此这些管道可以在支持容器的任何地方有效运行。
- en: IMPORTANT NOTE
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'That although I have presented ZenML and Kubeflow as two different pipelining
    tools, they can actually be viewed as complementary, so much so that ZenML provides
    the ability to deploy Kubeflow pipelines through the use of the ZenML Kubeflow
    orchestrator. This means you can leverage the higher-level abstractions provided
    by ZenML but still get the scaling behavior and robustness of Kubeflow as a deployment
    target. We will not cover the details here but the ZenML documentation provides
    an excellent guide: [https://docs.zenml.io/stacks-and-components/component-guide/orchestrators/kubeflow](https://docs.zenml.io/stacks-and-components/component-guide/orchestrators/kubeflow).'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我已将ZenML和Kubeflow作为两个不同的管道工具进行介绍，但实际上它们可以被视为互补的，以至于ZenML通过使用ZenML Kubeflow编排器提供了部署Kubeflow管道的能力。这意味着你可以利用ZenML提供的更高级别的抽象，同时仍然获得Kubeflow作为部署目标的扩展性和健壮性。我们在此不详细讨论，但ZenML文档提供了一个优秀的指南：[https://docs.zenml.io/stacks-and-components/component-guide/orchestrators/kubeflow](https://docs.zenml.io/stacks-and-components/component-guide/orchestrators/kubeflow)。
- en: The next section will finish the chapter with a brief note on some different
    deployment strategies that you should be aware of when you aim to put all of these
    tools and techniques into practice with real solutions.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将简要介绍一些不同的部署策略，当你旨在将所有这些工具和技术应用于实际解决方案时，你应该了解这些策略。
- en: Selecting your deployment strategy
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择你的部署策略
- en: We have discussed many of the technical details of ways to take ML solutions
    into production in this chapter. The missing piece, however, is that we have not
    defined how you deal with existing infrastructure and how you introduce your solution
    to real traffic and requests. This is what is defined by your deployment strategy,
    and selecting an appropriate one is an important part of being an ML engineer.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了许多将机器学习解决方案投入生产的详细技术。然而，缺失的部分是我们没有定义如何处理现有基础设施，以及如何将你的解决方案引入真实流量和请求。这正是由你的部署策略所定义的，选择一个合适的策略是成为一名机器学习工程师的重要部分。
- en: Most deployment strategies are, like many of the concepts in this book, inherited
    from the world of **software engineering** and **DevOps**. Two of the most important
    to know about are listed below with some discussion about when they can be particularly
    useful in an ML context.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数部署策略，就像本书中的许多概念一样，是从**软件工程**和**DevOps**领域继承而来的。以下列出两个最重要的策略，并附带一些讨论，说明在机器学习（ML）环境中它们何时特别有用。
- en: '**Blue/green deployments** are deployments where the new version of your software
    runs alongside your existing solution until some predefined criteria are met.
    After this point, you then switch all incoming traffic/requests to the new system
    before decommissioning the old one or leave it there for use as a potential rollback
    solution. The method was originally developed by two developers, Daniel North
    and Jez Humble, who were working on an e-commerce site in 2005\.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '**蓝绿部署**是一种部署方式，其中新版本的软件与现有的解决方案并行运行，直到满足某些预定义的标准。在此之后，您将所有传入的流量/请求切换到新系统，然后退役旧系统，或者将其保留作为潜在的回滚解决方案。这种方法最初是由两位开发者Daniel
    North和Jez Humble开发的，他们在2005年正在为一个电子商务网站工作。'
- en: The origin of the name is described in this GitHub Gist, [https://gitlab.com/-/snippets/1846041](https://gitlab.com/-/snippets/1846041),
    but essentially boils down to the fact that any other naming convention they could
    come up with always implied one of the candidate solutions or environments was
    “better” or “worse” than the other, for example with “A and B” or “Green and Red.”
    The strategy has since become a classic.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 该名称的起源描述在这个GitHub Gist中，[https://gitlab.com/-/snippets/1846041](https://gitlab.com/-/snippets/1846041)，但基本上可以归结为这样一个事实：他们能想到的任何其他命名约定都隐含着候选解决方案或环境中的一个“更好”或“更差”于另一个，例如“A和B”或“绿色和红色”。这种策略已经成为了经典。
- en: In an ML engineering context, this is particularly useful in scenarios where
    you want to gather model and solution performance data over a known period of
    time before trusting full deployment. It also helps with giving stakeholders evidence
    that the ML solution will perform as expected “in the wild.” It also plays particularly
    well with batch jobs, as you are just effectively running another batch at the
    same time. This may have some cost implications for you to consider if the job
    is big or complex, or if your production environment is costly to maintain.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习工程环境中，这在您希望在完全部署之前收集模型和解决方案性能数据一段时间的情况下特别有用。它还帮助利益相关者提供证据，证明机器学习解决方案将在“野外”按预期表现。它还与批量作业配合得很好，因为您实际上是在同一时间运行另一个批量作业。如果作业很大或复杂，或者您的生产环境维护成本高昂，这可能对您有一些成本影响，需要您考虑。
- en: The next strategy is known as **canary deployments** and involves a similar
    setup to the blue/green method but involves a more gradual switching of traffic
    between the two solutions. Here the idea is that the new system is deployed and
    receives some percentage of the traffic initially, say 5% or 10%, before stability
    and performance are confirmed, and then the next increment of traffic is added.
    The total always remains at 100% so as the new system gains more traffic, the
    old system receives less. The name originates from the old coal mining technique
    of using canaries as a test of toxicity in the atmosphere in mines. Release the
    canaries and if they survive, all is well. Thankfully, no birds are harmed in
    the usage of this deployment technique. This strategy makes a lot of sense when
    you are able to divide the data you need to score and still get the information
    you need for progression to the next stage. As an example, an ML microservice
    that is called in the backend of a website would fit the bill nicely, as you can
    just gradually change the routing to the new service on your load balancer. This
    may make less sense for large batch jobs, as there may be no natural way to split
    your data into different increments, whereas with web traffic there definitely
    is.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个策略被称为**金丝雀部署**，其设置与蓝/绿方法类似，但涉及在两个解决方案之间更渐进地切换流量。这里的想法是，新系统部署后，最初接收一定比例的流量，比如5%或10%，在稳定性和性能得到确认后，然后添加下一增量流量。总量始终保持在100%，因此随着新系统获得更多流量，旧系统接收的流量就会减少。这个名称起源于古老的煤矿技术，即使用金丝雀作为测试矿井大气中毒性的测试。释放金丝雀，如果它们存活，那么一切正常。幸运的是，在这个部署技术的使用过程中，没有伤害到任何鸟类。当你能够将需要评分的数据分割开来，同时仍然获得进入下一阶段所需的信息时，这种策略非常有意义。例如，一个被网站后端调用的ML微服务非常适合，因为你可以在负载均衡器上逐渐更改路由到新服务。对于大型批量作业来说，这可能不太合理，因为没有自然的方法将数据分割成不同的增量，而网络流量则肯定有。
- en: '*Chapter 8*, *Building an Example ML Microservice*, will show you how to use
    these strategies when building a custom ML endpoint using Kubernetes.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '*第8章*，*构建示例ML微服务*，将向你展示如何在使用Kubernetes构建自定义ML端点时使用这些策略。'
- en: No matter what deployment strategy you use, always remember that the key is
    to strike the balance between cost-effectiveness, the uptime of your solution,
    and trust in the outputs it produces. If you can do all of these, then you will
    have deployed a winning combination.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用什么部署策略，始终要记住关键是要在成本效益、解决方案的运行时间和输出的信任度之间取得平衡。如果你能完成所有这些，那么你就已经部署了一个成功的组合。
- en: Summary
  id: totrans-427
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have discussed some of the most important concepts when
    it comes to deploying your ML solutions. In particular, we focused on the concepts
    of architecture and what tools we could potentially use when deploying solutions
    to the cloud. We covered some of the most important patterns used in modern ML
    engineering and how these can be implemented with tools such as containers and
    AWS Elastic Container Registry and Elastic Container Service, as well as how to
    create scheduled pipelines in AWS using Managed Workflows for Apache Airflow.
    We also explored how to hook up the MWAA example with GitHub Actions, so that
    changes to your code can directly trigger updates of running services, providing
    a template to use in future CI/CD processes.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了部署你的机器学习解决方案时的一些重要概念。特别是，我们关注了架构的概念以及部署到云中时可能使用的工具。我们涵盖了现代机器学习工程中使用的最重要的模式，以及如何使用容器和AWS弹性容器注册表和弹性容器服务以及如何使用Apache
    Airflow的托管工作流来实施这些模式。我们还探讨了如何将MWAA示例与GitHub Actions连接起来，以便代码的更改可以直接触发运行服务的更新，为未来的CI/CD流程提供了一个模板。
- en: We then moved on to a discussion of more advanced pipelining tools to build
    on the discussion in *Chapter 4*, *Packaging Up*. This focused on how to use Apache
    Airflow to build and orchestrate your generic pipelines for running your data
    engineering, ML, and MLOps pipelines. We then moved on to a detailed introduction
    to ZenML and Kubeflow, two powerful tools for developing and deploying ML and
    MLOps pipelines at scale.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续讨论更高级的管道工具，以在*第4章*，*打包*的基础上进行讨论。这侧重于如何使用Apache Airflow构建和编排你的通用管道，以运行你的数据工程、机器学习和MLOps管道。然后，我们转向ZenML和Kubeflow的详细介绍，这两个工具是开发和大规模部署机器学习和MLOps管道的强大工具。
- en: In the next chapter, we will look at the question of other ways to scale up
    our solutions so that we can deal with large volumes of data and high-throughput
    calculations.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨其他扩大我们解决方案的方法，以便我们能够处理大量数据和高速计算。
- en: Join our community on Discord
  id: totrans-431
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussion with the author and other
    readers:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mle](https://packt.link/mle)'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mle](https://packt.link/mle)'
- en: '![](img/QR_Code102810325355484.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code102810325355484.png)'
