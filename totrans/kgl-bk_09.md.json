["```py\ndef seed_everything(seed, \n                    tensorflow_init=True, \n                    pytorch_init=True):\n    \"\"\"\n    Seeds basic parameters for reproducibility of results\n    \"\"\"\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    if tensorflow_init is True:\n        tf.random.set_seed(seed)\n    if pytorch_init is True:\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False \n```", "```py\npip install git+git://github.com/AutoViML/AutoViz.git \n```", "```py\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', \n                'float16', 'float32', 'float64']'\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df \n```", "```py\ncycle = 7\ndf['weekday_sin'] = np.sin(2 * np.pi * df['col1'].dt.dayofweek / cycle)\ndf['weekday_cos'] = np.cos(2 * np.pi * df['col1'].dt.dayofweek / cycle) \n```", "```py\nimport pandas as pd\ntrain = pd.read_csv(\"../input/amazon-employee-access-challenge/train.csv\")\n# Frequency count of a feature\nfeature_counts = train.groupby('ROLE_TITLE').size()\nprint(train['ROLE_TITLE'].apply(lambda x: feature_counts[x])) \n```", "```py\nfeature_counts = train.groupby(['ROLE_DEPTNAME', 'ROLE_TITLE']).size()\nprint(train[['ROLE_DEPTNAME', 'ROLE_TITLE']].apply(lambda x: feature_counts[x[0]][x[1]], axis=1)) \n```", "```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nclass TargetEncode(BaseEstimator, TransformerMixin):\n\n    def __init__(self, categories='auto', k=1, f=1, \n                 noise_level=0, random_state=None):\n        if type(categories)==str and categories!='auto':\n            self.categories = [categories]\n        else:\n            self.categories = categories\n        self.k = k\n        self.f = f\n        self.noise_level = noise_level\n        self.encodings = dict()\n        self.prior = None\n        self.random_state = random_state\n\n    def add_noise(self, series, noise_level):\n        return series * (1 + noise_level *   \n                         np.random.randn(len(series)))\n\n    def fit(self, X, y=None):\n        if type(self.categories)=='auto':\n            self.categories = np.where(X.dtypes == type(object()))[0]\n        temp = X.loc[:, self.categories].copy()\n        temp['target'] = y\n        self.prior = np.mean(y)\n        for variable in self.categories:\n            avg = (temp.groupby(by=variable)['target']\n                       .agg(['mean', 'count']))\n            # Compute smoothing \n            smoothing = (1 / (1 + np.exp(-(avg['count'] - self.k) /                 \n                         self.f)))\n            # The bigger the count the less full_avg is accounted\n            self.encodings[variable] = dict(self.prior * (1 -  \n                             smoothing) + avg['mean'] * smoothing)\n\n        return self\n\n    def transform(self, X):\n        Xt = X.copy()\n        for variable in self.categories:\n            Xt[variable].replace(self.encodings[variable], \n                                 inplace=True)\n            unknown_value = {value:self.prior for value in \n                             X[variable].unique() \n                             if value not in \n                             self.encodings[variable].keys()}\n            if len(unknown_value) > 0:\n                Xt[variable].replace(unknown_value, inplace=True)\n            Xt[variable] = Xt[variable].astype(float)\n            if self.noise_level > 0:\n                if self.random_state is not None:\n                    np.random.seed(self.random_state)\n                Xt[variable] = self.add_noise(Xt[variable], \n                                              self.noise_level)\n        return Xt\n\n    def fit_transform(self, X, y=None):\n        self.fit(X, y)\n        return self.transform(X) \n```", "```py\nte = TargetEncode(categories='ROLE_TITLE')\nte.fit(train, train['ACTION'])\nte.transform(train[['ROLE_TITLE']]) \n```"]