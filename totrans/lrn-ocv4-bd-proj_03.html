<html><head></head><body>
        

                            
                    <h1 class="header-title">Learning Graphical User Interfaces</h1>
                
            
            
                
<p>In <a href="37cf2702-b8c6-41ff-a935-fd4030f8ce64.xhtml">Chapter 2</a>, <em>An Introduction to the Basics of OpenCV</em>, we learned the basic classes and structures of OpenCV and the most important class, called <kbd>Mat</kbd>. We learned how to read and save images and videos and the internal structure in the memory of images. We are now ready to work with OpenCV, but, in most cases, we need to show our image results and retrieve user interaction with our images using a number of user interfaces. OpenCV provides us with a few basic user interfaces to facilitate the creation of our applications and prototypes. To better understand how the user interface works, we are going to create a small application called <strong>PhotoTool</strong> at the end of this chapter. In this application, we will learn how to use filters and color conversions.</p>
<p>This chapter introduces the following topics:</p>
<ul>
<li>The OpenCV basic user interface</li>
<li>The OpenCV Qt interface</li>
<li>Sliders and buttons</li>
<li>An advanced user interface – OpenGL</li>
<li>Color conversion</li>
<li>Basic filters</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires familiarity with the basic C++ programming language. All the code used in this chapter can be downloaded from the following GitHub link: <a href="https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_03">https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_03</a>. The code can be executed on any operating system, although it has only been tested on Ubuntu.</p>
<p class="mce-root">Check out the following video to see the code in action:<br/>
<a href="http://bit.ly/2KH2QXD">http://bit.ly/2KH2QXD</a></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Introducing the OpenCV user interface</h1>
                
            
            
                
<p>OpenCV has its own cross-OS user interface that allows developers to create their own applications without the need to learn complex user interface libraries. The OpenCV user interface is basic, but it gives computer vision developers the basic functions to create and manage their software developments. All of them are native and optimized for real-time use.</p>
<p>OpenCV provides two user interface options:</p>
<ul>
<li>A basic interface based on native user interfaces, cocoa or carbon for Mac OS X, and GTK for Linux or Windows user interfaces, selected by default when compiling OpenCV.</li>
<li>A slightly more advanced interface based on Qt library that is a cross-platform interface. You have to enable the Qt option manually in CMake before compiling OpenCV.</li>
</ul>
<p>In the following screenshot, you can see the basic user interface window on the left, and the Qt user interface on the right:</p>
<div><img class="alignnone size-full wp-image-798 image-border" src="img/70ba76a2-6e26-440a-9a0c-9db64f284983.png" style="width:41.67em;height:22.83em;"/></div>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Basic graphical user interface with OpenCV</h1>
                
            
            
                
<p>We are going to create a basic user interface with OpenCV. The OpenCV user interface allows us to create windows, add images to it, and move, resize, and destroy it. The user interface is in OpenCV's <kbd>highui</kbd> module. In the following code, we are going to learn how to create and show two images by pressing a key to display multiple windows with the image moving in the window on our desktop.</p>
<p>Don't worry about reading the full code; we are going to explain it in small chunks:</p>
<pre>#include &lt;iostream&gt; 
#include &lt;string&gt; 
#include &lt;sstream&gt; 
using namespace std; 
 
// OpenCV includes 
#include &lt;opencv2/core.hpp&gt; 
#include &lt;opencv2/highgui.hpp&gt; 
using namespace cv; 
 
int main(int argc, const char** argv) 
{ 
   // Read images 
   Mat lena= imread("../lena.jpg"); <br/>   # Checking if Lena image has been loaded<br/>   if (!lena.data) {<br/> cout &lt;&lt; "Lena image missing!" &lt;&lt; enld;<br/> return -1;<br/>   }
   Mat photo= imread("../photo.jpg"); <br/>   # Checking if Lena image has been loaded<br/>   if (!photo.data) {<br/> cout &lt;&lt; "Lena image missing!" &lt;&lt; enld;<br/> return -1;<br/> }
    
   // Create windows 
   namedWindow("Lena", WINDOW_NORMAL); 
   namedWindow("Photo", WINDOW_AUTOSIZE); 
 
   // Move window 
   moveWindow("Lena", 10, 10); 
   moveWindow("Photo", 520, 10); 
    
   // show images 
   imshow("Lena", lena); 
   imshow("Photo", photo);  
 
   // Resize window, only non autosize 
   resizeWindow("Lena", 512, 512);  
 
   // wait for any key press 
   waitKey(0); 
 
   // Destroy the windows 
   destroyWindow("Lena"); 
   destroyWindow("Photo"); 
 
   // Create 10 windows 
   for(int i =0; i&lt; 10; i++) 
   { 
         ostringstream ss; 
         ss &lt;&lt; "Photo" &lt;&lt; i; 
         namedWindow(ss.str()); 
         moveWindow(ss.str(), 20*i, 20*i); 
         imshow(ss.str(), photo); 
   } 
 
   waitKey(0); 
   // Destroy all windows 
   destroyAllWindows(); 
   return 0; 
} 
 </pre>
<p>Let's understand the code:</p>
<ol>
<li>The first task we have to do in order to facilitate a graphical user interface is to import OpenCV's <kbd>highui</kbd> module:</li>
</ol>
<pre style="padding-left: 60px">#include &lt;opencv2/highgui.hpp&gt; </pre>
<ol start="2">
<li>Now that we are prepared to create our new windows, we have to load some images:</li>
</ol>
<pre style="padding-left: 60px">// Read images 
Mat lena= imread("../lena.jpg"); 
Mat photo= imread("../photo.jpg"); </pre>
<ol start="3">
<li>To create the windows, we use the <kbd>namedWindow</kbd> function. This function has two parameters; the first is a constant string with the window's name, and the second is the flags that we require. This second parameter is optional:</li>
</ol>
<pre style="padding-left: 60px">namedWindow("Lena", WINDOW_NORMAL); 
namedWindow("Photo", WINDOW_AUTOSIZE);</pre>
<ol start="4">
<li>In our case, we create two windows: the first is called <kbd>Lena</kbd>, and the second is called <kbd>Photo</kbd>.</li>
</ol>
<p style="padding-left: 60px">There are three flags by default for Qt and native:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>WINDOW_NORMAL</kbd>: This flag allows the user to resize the window</li>
<li><kbd>WINDOW_AUTOSIZE</kbd>: If this flag is set, the window size is automatically adjusted to fit the display image and it is not possible to resize the window</li>
<li><kbd>WINDOW_OPENGL</kbd>: This flag enables the OpenGL support</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">Qt has a number of additional flags:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>WINDOW_FREERATIO</kbd> or <kbd>WINDOW_KEEPRATIO</kbd>: If <kbd>WINDOW_FREERATIO</kbd> is set, the image is adjusted with no respect for its ratio. If <kbd>WINDOW_FREERATIO</kbd> is set, the image is adjusted with respect to its ratio.</li>
<li><kbd>WINDOW_GUI_NORMAL</kbd> or <kbd>WINDOW_GUI_EXPANDED</kbd>: The first flag facilitates a basic interface without the status bar and the toolbar. The second flag facilitates the most advanced graphical user interface, with the status bar and the toolbar.</li>
</ul>
</li>
</ul>
<p>If we compile OpenCV with Qt, all the windows that we create are, by default, in the expanded interface, but we can use native interfaces and more basic ones adding the <kbd>CV_GUI_NORMAL</kbd> flag. By default, the flags are <kbd>WINDOW_AUTOSIZE</kbd>, <kbd>WINDOW_KEEPRATIO</kbd>, and <kbd>WINDOW_GUI_EXPANDED</kbd>.</p>
<ol start="5">
<li>When we create multiple windows, they are superimposed, but we can move the windows to any area of our desktop using the <kbd>moveWindow</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">// Move window 
moveWindow("Lena", 10, 10); 
moveWindow("Photo", 520, 10); </pre>
<ol start="6">
<li>In our code, we move the <kbd>Lena</kbd> window <kbd>10</kbd> pixels to the left, and <kbd>10</kbd> pixels up, and the <kbd>Photo</kbd> window <kbd>520</kbd> pixels to the left, and <kbd>10</kbd> pixels up:</li>
</ol>
<pre style="padding-left: 60px">// show images 
imshow("Lena", lena); 
imshow("Photo", photo);  
// Resize window, only non autosize 
resizeWindow("Lena", 512, 512);</pre>
<p class="mce-root"/>
<ol start="7">
<li>After showing the images that we loaded previously using the <kbd>imshow</kbd> function, we resize the <kbd>Lena</kbd> window to <kbd>512</kbd> pixels, calling the <kbd>resizeWindow</kbd> function. This function has three parameters: the <kbd>window name</kbd>, <kbd>width</kbd>, and <kbd>height</kbd>.</li>
</ol>
<p>The specific window size is for the image area. Toolbars are not counted. Only windows without the <kbd>WINDOW_AUTOSIZE</kbd> flag enabled can be resized.</p>
<ol start="8">
<li>After waiting for a key press with the <kbd>waitKey</kbd> function, we are going to remove or delete our windows using the <kbd>destroyWindow</kbd> function, where the name of the window is the only parameter required:</li>
</ol>
<pre style="padding-left: 60px">waitKey(0); 
 
// Destroy the windows 
destroyWindow("Lena"); 
destroyWindow("Photo"); </pre>
<ol start="9">
<li>
<p>OpenCV has a function to remove all windows that we create in only one call. The function is called <kbd>destroyAllWindows</kbd>. To demonstrate how this works, we create 10 windows in our sample and await a key press. When the user presses any key, it destroys all the windows:</p>
</li>
</ol>
<pre style="padding-left: 60px"> // Create 10 windows 
for(int i =0; i&lt; 10; i++) 
{ 
   ostringstream ss; 
   ss &lt;&lt; "Photo" &lt;&lt; i; 
   namedWindow(ss.str()); 
   moveWindow(ss.str(), 20*i, 20*i); 
   imshow(ss.str(), photo); 
} 
 
waitKey(0); 
// Destroy all windows 
destroyAllWindows(); </pre>
<p>In any event, OpenCV handles the destruction of all windows automatically when the application is terminated, and it is not necessary to call this function at the end of our application.</p>
<p>The result of all this code can be seen in the following images across two steps. First, it shows two windows:</p>
<div><img class="alignnone size-full wp-image-799 image-border" src="img/7b6c21b3-4b79-4f6d-93e1-784f372b2f4f.png" style="width:80.42em;height:44.08em;"/></div>
<p>After pressing any key, the application continues and draws several windows changing their positions:</p>
<div><img class="alignnone size-full wp-image-800 image-border" src="img/d52ca1f9-d77c-4b18-9146-1a24d4d79bc0.png" style="width:36.08em;height:38.67em;"/></div>
<p>With a few lines of code, we are able to create and manipulate windows and show images. We are now ready to facilitate user interaction with images and add user interface controls.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding slider and mouse events to our interfaces</h1>
                
            
            
                
<p>Mouse events and slider control are very useful in computer vision and OpenCV. Using these control users, we can interact directly with the interface and change the properties of the input images or variables. In this section, we are going to introduce the mouse events and slider controls for basic interactions. To facilitate proper understanding, we have created the following code, by means of which we are going to paint green circles in an image, using mouse events, and blur the image with the slider:</p>
<pre>// Create a variable to save the position value in track 
int blurAmount=15; 
 
// Trackbar call back function 
static void onChange(int pos, void* userInput); 
 
//Mouse callback 
static void onMouse(int event, int x, int y, int, void* userInput); 
 
int main(int argc, const char** argv) 
{ 
   // Read images 
   Mat lena= imread("../lena.jpg"); 
    
   // Create windows 
   namedWindow("Lena"); 
    
   // create a trackbar 
   createTrackbar("Lena", "Lena", &amp;blurAmount, 30, onChange, &amp;lena); 
    
   setMouseCallback("Lena", onMouse, &amp;lena); 
 
   // Call to onChange to init 
   onChange(blurAmount, &amp;lena); 
          
   // wait app for a key to exit 
   waitKey(0); 
    
   // Destroy the windows 
   destroyWindow("Lena"); 
    
   return 0; 
} </pre>
<p>Let's understand the code!</p>
<p>First, we create a variable to save the slider position. We need to save the slider position for access from other functions:</p>
<pre>// Create a variable to save the position value in track 
int blurAmount=15;</pre>
<p class="mce-root"/>
<p>Now, we define our callbacks for our slider and mouse event, required for the OpenCV functions <kbd>setMouseCallback</kbd> and <kbd>createTrackbar</kbd>:</p>
<pre>// Trackbar call back function 
static void onChange(int pos, void* userInput); 
 
//Mouse callback 
static void onMouse(int event, int x, int y, int, void* userInput); 
 </pre>
<p>In the main function, we load an image and create a new window called <kbd>Lena</kbd>:</p>
<pre>int main(int argc, const char** argv) 
{ 
   // Read images 
   Mat lena= imread("../lena.jpg"); 
    
   // Create windows 
   namedWindow("Lena"); </pre>
<p>Now is the time to create the slider. OpenCV has the <kbd>createTrackbar</kbd> function to generate a slider with the following parameters in order:</p>
<ol>
<li>Trackbar name.</li>
<li>Window name.</li>
<li>Integer pointer to use as a value; this parameter is optional. If it is set, the slider attains this position when created.</li>
<li>Maximum position on slider.</li>
<li>Callback function when the position of the slider changes.</li>
<li>User data to send to callback. It can be used to send data to callbacks without using global variables.</li>
</ol>
<p>To this code, we add <kbd>trackbar</kbd> for the <kbd>Lena</kbd> window and call the <kbd>Lena</kbd> trackbar too in order to blur the image. The value of the trackbar is stored in the <kbd>blurAmount</kbd> integer that we pass as a pointer and set the maximum value of the bar to <kbd>30</kbd>. We set up <kbd>onChange</kbd> as a callback function and send the lena mat image as user data:</p>
<pre>   // create a trackbar 
   createTrackbar("Lena", "Lena", &amp;blurAmount, 30, onChange, &amp;lena);</pre>
<p>After creating the slider, we add the mouse events to paint circles when a user clicks the left button on the mouse. OpenCV has the <kbd>setMouseCallback</kbd> function. This function has three parameters:</p>
<ul>
<li>
<p>A window name where we get mouse events.</p>
</li>
<li>
<p>A callback function to call when there is any mouse interaction.</p>
</li>
<li>
<p><strong>User data</strong>: this is any data that will be sent to the callback function when it's fired. In our example, we'll send the entire <kbd>Lena</kbd> image.</p>
</li>
</ul>
<p>Using the following code, we can add a mouse callback to the <kbd>Lena</kbd> window and set up <kbd>onMouse</kbd> as a callback function, passing the lena mat image as user data:</p>
<pre>setMouseCallback("Lena", onMouse, &amp;lena); </pre>
<p>To finalize the main function only, we need to initialize the image with the same parameter as the slider. To carry out the initialization, we only need to call the <kbd>onChange</kbd> callback function and wait for events before closing the windows with <kbd>destroyWindow</kbd><em>,</em> as can be seen in the following code:</p>
<pre>// Call to onChange to init   <br/>onChange(blurAmount, &amp;lena); 
          
// wait app for a key to exit 
waitKey(0); 
    
// Destroy the windows 
destroyWindow("Lena"); </pre>
<p>The slider callback applies a basic blur filter to the image using the slider value as a blur quantity:</p>
<pre>// Trackbar call back function <br/>static void onChange(int pos, void* userData) { <br/>    if(pos &lt;= 0) return; <br/>    // Aux variable for result <br/>    Mat imgBlur; <br/>    // Get the pointer input image     <br/>    Mat* img= (Mat*)userInput; <br/>    // Apply a blur filter <br/>    blur(*img, imgBlur, Size(pos, pos)); <br/>    // Show the result <br/>    imshow("Lena", imgBlur); <br/>}</pre>
<p>This function checks whether the slider value is <kbd>0</kbd> using the variable <kbd>pos</kbd>. In this case, we do not apply the filter because it generates a bad execution. We cannot apply a <kbd>0</kbd> pixel blur either. After checking the slider value, we create an empty matrix called <kbd>imgBlur</kbd> to store the blur result. To retrieve the image sent through user data in the callback function, we have to cast <kbd>void* userData</kbd> to the correct image type pointer <kbd>Mat*</kbd>.</p>
<p>Now we have the correct variables to apply the blur filter. The blur function applies a basic median filter to an input image, <kbd>*img</kbd> in our case; to an output image, the last required parameter is the size of the blur kernel (a kernel is a small matrix used to calculate the means of convolution between the kernel and the image) that we want to apply. In our case, we are using a squared kernel of <kbd>pos</kbd> size. Finally, we only need to update the image interface using the <kbd>imshow</kbd> function.</p>
<p>The mouse events callback has five input parameters: the first parameter defines the event type; the second and third define the mouse position; the fourth parameter defines the wheel movement; and the fifth parameter defines the user input data.</p>
<p>The mouse event types are as follows:</p>
<table style="border-collapse: collapse" class="table" border="1">
<tbody>
<tr>
<td>
<p class="TableColumnHeadingPACKT">Event type</p>
</td>
<td>
<p class="TableColumnHeadingPACKT">Description</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_MOUSEMOVE</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user moves the mouse.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_LBUTTONDOWN</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user clicks the left mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_RBUTTONDOWN</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user clicks the right mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_MBUTTONDOWN</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user clicks the middle mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_LBUTTONUP</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user releases the left mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_RBUTTONUP</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user releases the right mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_MBUTTONUP</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user releases the middle mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_LBUTTONDBLCLK</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user double-clicks the left mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_RBUTTONDBLCLK</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user double-clicks the right mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_MBUTTONDBLCLK</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user double-clicks the middle mouse button.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENTMOUSEWHEEL</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user executes a vertical scroll with the mousewheel.</p>
</td>
</tr>
<tr>
<td>
<p><kbd>EVENT_MOUSEHWHEEL</kbd></p>
</td>
<td>
<p class="TableColumnContentPACKT">When the user executes a horizontal scroll with the mousewheel.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>In our sample, we only manage events that result from a left-click of the mouse, and any event other than <kbd>EVENT_LBUTTONDOWN</kbd> is discarded. After discarding other events, we obtain the input image like that with the slider callback, and with a circle in the image using the circle OpenCV function:</p>
<pre>//Mouse callback 
static void onMouse(int event, int x, int y, int, void* userInput) 
{ 
   if(event != EVENT_LBUTTONDOWN) 
           return; 
 
   // Get the pointer input image 
   Mat* img= (Mat*)userInput; 
    
   // Draw circle 
   circle(*img, Point(x, y), 10, Scalar(0,255,0), 3); 
 
   // Call on change to get blurred image 
   onChange(blurAmount, img); 
 
} </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Graphic user interface with Qt</h1>
                
            
            
                
<p>The Qt user interface gives us more control and options to work with our images.</p>
<p>The interface is divided into the following three main areas:</p>
<ul>
<li>Toolbar</li>
<li>Image area</li>
<li>Status bar</li>
</ul>
<p>We can see these three areas in the following picture. At the top of the image is the toolbar, the image is the main area, and the status bar can be seen at the bottom of the image:</p>
<div><img class="alignnone size-full wp-image-801 image-border" src="img/61d3f74e-02a7-4f53-be89-ec396b28a42f.png" style="width:33.83em;height:38.17em;"/></div>
<p>The toolbar has the following buttons from left to right:</p>
<ul>
<li>Four buttons for panning</li>
<li>Zoom x1</li>
<li>Zoom x30, show labels</li>
<li>Zoom in</li>
<li>Zoom out</li>
<li>Save current image</li>
<li>Show properties</li>
</ul>
<p>These options can be seen clearly in the following image:</p>
<div><img src="img/ffab5642-1bf2-44d6-8cfc-386776bed0b1.png"/></div>
<p>The image area shows an image and a contextual menu when we push the right mouse button over the image. This area can show an overlay message at the top of the area using the <kbd>displayOverlay</kbd> function. This function accepts three parameters: the window name, the text that we want to show, and the period in milliseconds for which the overlay text is displayed. If this time is set to <kbd>0</kbd>, the text never disappears:</p>
<pre>// Display Overlay 
displayOverlay("Lena", "Overlay 5secs", 5000);</pre>
<p>We can see the result of the preceding code in the following image. You can see a small black box at the top of the image with the sentence Overlay 5secs:</p>
<div><img class="alignnone size-full wp-image-802 image-border" src="img/9e96283c-36bf-42fb-8b99-2594c1145a0a.png" style="width:33.50em;height:33.33em;"/></div>
<p>Finally, the status bar shows the bottom part of the window and shows the pixel value and position of the coordinates in the image:</p>
<div><img class="alignnone size-full wp-image-803 image-border" src="img/73c772f0-ffb3-4b30-a8a2-e44f9b447069.png" style="width:31.25em;height:13.50em;"/></div>
<p>We can use the status bar to show messages like an overlay. The function that can change the status bar message is <kbd>displayStatusBar</kbd>. This function has the same parameters as those of the overlay functions: the window name, the text to show, and the period of time for which to show it:</p>
<div><img class="alignnone size-full wp-image-804 image-border" src="img/812fe575-7b2a-4d1f-92f7-e5fb119638ff.png" style="width:31.75em;height:14.08em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding buttons to the user interface</h1>
                
            
            
                
<p>In the previous sections, we learned how to create normal or Qt interfaces and interact with them using the mouse and sliders, but we can create different types of buttons too.</p>
<p>Buttons are only supported in Qt windows.</p>
<p class="mce-root"/>
<p>The types of buttons supported by OpenCV Qt are as follows:</p>
<ul>
<li>Push button</li>
<li>Checkbox</li>
<li>RadioBox</li>
</ul>
<p>The buttons only appear in the control panel. The control panel is an independent window per program where we can attach buttons and trackbars. To show the control panel, we can push the last toolbar button, right-click in any part of the Qt window and select the Display properties window, or use the <em>Ctrl </em>+ <em>P</em> shortcut. Let's create a basic sample with buttons. The code is extensive, and we are going to explain the main function first and later each callback separately so as to understand everything better. The following code shows us the main code function that generates the user interface:</p>
<pre>Mat img; 
bool applyGray=false; 
bool applyBlur=false; 
bool applySobel=false; 
... 
int main(int argc, const char** argv) 
{ 
   // Read images 
   img= imread("../lena.jpg"); 
    
   // Create windows 
   namedWindow("Lena"); 
    
   // create Buttons 
   createButton("Blur", blurCallback, NULL, QT_CHECKBOX, 0); 
 
   createButton("Gray",grayCallback,NULL,QT_RADIOBOX, 0); 
   createButton("RGB",bgrCallback,NULL,QT_RADIOBOX, 1); 
 
   createButton("Sobel",sobelCallback,NULL,QT_PUSH_BUTTON, 0); 
    
   // wait app for a key to exit 
   waitKey(0); 
    
   // Destroy the windows 
   destroyWindow("Lena"); 
    
   return 0; 
} 
 </pre>
<p>We are going to apply thee types of filters: blur, a sobel filter, and a color conversion to gray. All these are optional and the user can choose each one using the buttons that we are going to create. Then, to get the status of each filter, we create three global Boolean variables:</p>
<pre>bool applyGray=false; 
bool applyBlur=false; 
bool applySobel=false;</pre>
<p>In the main function, after loading the image and creating the window, we have to use the <kbd>createButton</kbd> function to create each button.</p>
<p>There are three button types defined in OpenCV:</p>
<ul>
<li><kbd>QT_CHECKBOX</kbd></li>
<li><kbd>QT_RADIOBOX</kbd></li>
<li><kbd>QT_PUSH_BUTTON</kbd></li>
</ul>
<p>Each button has five parameters with the following order:</p>
<ol>
<li>The button name</li>
<li>A callback function</li>
<li>A pointer to user variable data passed to callback</li>
<li>The button type</li>
<li>The default initialized state used for the checkbox and RadioBox button types</li>
</ol>
<p>Then, we create a blur checkbox button, two radio buttons for color conversion, and a push button for a sobel filter, as you can see in the following code:</p>
<pre>   // create Buttons 
   createButton("Blur", blurCallback, NULL, QT_CHECKBOX, 0); 
 
   createButton("Gray",grayCallback,NULL,QT_RADIOBOX, 0); 
   createButton("RGB",bgrCallback,NULL,QT_RADIOBOX, 1); 
 
   createButton("Sobel",sobelCallback,NULL,QT_PUSH_BUTTON, 0); 
    </pre>
<p>These are the most important parts of the main function. We are going to explore the <kbd>Callback</kbd> functions. Each <kbd>Callback</kbd> changes its status variable to call another function called <kbd>applyFilters</kbd> in order to add the filters activated to the input image:</p>
<pre>void grayCallback(int state, void* userData) 
{ 
   applyGray= true; 
   applyFilters(); 
} 
void bgrCallback(int state, void* userData) 
{ 
   applyGray= false; 
   applyFilters(); 
} 
 
void blurCallback(int state, void* userData) 
{ 
   applyBlur= (bool)state; 
   applyFilters(); 
} 
 
void sobelCallback(int state, void* userData) 
{ 
   applySobel= !applySobel; 
   applyFilters(); 
} 
 </pre>
<p>The <kbd>applyFilters</kbd> function checks the status variable for each filter:</p>
<pre>void applyFilters(){ 
   Mat result; 
   img.copyTo(result); 
   if(applyGray){ 
         cvtColor(result, result, COLOR_BGR2GRAY); 
   } 
   if(applyBlur){ 
         blur(result, result, Size(5,5));     
   } 
   if(applySobel){ 
         Sobel(result, result, CV_8U, 1, 1);  
   } 
   imshow("Lena", result); 
} </pre>
<p>To change the color to gray, we use the <kbd>cvtColor</kbd> function which accepts three parameters: input image, output image, and the color conversion type.</p>
<p>The most useful color space conversions are as follows:</p>
<ul>
<li>RGB or BGR to gray (<kbd>COLOR_RGB2GRAY</kbd>, <kbd>COLOR_BGR2GRAY</kbd>)</li>
<li>RGB or BGR to YcrCb (or YCC) (<kbd>COLOR_RGB2YCrCb</kbd>, <kbd>COLOR_BGR2YCrCb</kbd>)</li>
<li>RGB or BGR to HSV (<kbd>COLOR_RGB2HSV</kbd>, <kbd>COLOR_BGR2HSV</kbd>)</li>
<li>RGB or BGR to Luv (<kbd>COLOR_RGB2Luv</kbd>, <kbd>COLOR_BGR2Luv</kbd>)</li>
<li>Gray to RGB or BGR (<kbd>COLOR_GRAY2RGB</kbd>, <kbd>COLOR_GRAY2BGR</kbd>)</li>
</ul>
<p>We can see that the codes are easy to memorize.</p>
<p>OpenCV works by default with the BGR format, and the color conversion is different for RGB and BGR, even when converted to gray. Some developers think that <em>R</em>+<em>G</em>+<em>B</em>/<em>3</em> is true for gray, but the optimal gray value is called <strong>luminosity</strong> and has the formula <em>0</em>,<em>21</em>*<em>R</em> + <em>0</em>,<em>72</em>*<em>G</em> + <em>0</em>,<em>07</em>*<em>B.</em></p>
<p>The blur filter was described in the previous section, and finally, if the <kbd>applySobel</kbd> variable is true, we apply the sobel filter. The sobel filter is an image derivate obtained using the sobel operator, commonly used to detect edges. OpenCV allows us to generate different derivates with kernel size, but the most common is a 3x3 kernel to calculate the <em>x</em> derivates or <em>y</em> derivate.</p>
<p>The most important sobel parameters are the following:</p>
<ul>
<li>Input image</li>
<li>Output image</li>
<li>Output image depth (<kbd>CV_8U</kbd>, <kbd>CV_16U</kbd>, <kbd>CV_32F</kbd>, <kbd>CV_64F</kbd>)</li>
<li>Order of the derivate <em>x</em></li>
<li>Order of the derivate <em>y</em></li>
<li>Kernel size (a value of 3 by default)</li>
</ul>
<p>To generate a 3 x 3 kernel and a first <em>x</em> order derivate, we have to use the following parameters:</p>
<pre>Sobel(input, output, CV_8U, 1, 0);</pre>
<p>The following parameters are used for <em>y</em> order derivates:</p>
<pre>Sobel(input, output, CV_8U, 0, 1);      </pre>
<p>In our example, we use the <em>x</em> and <em>y</em> derivate simultaneously, overwriting the input. The following snippet shows how to generate the <em>x</em> and <em>y</em> derivates simultaneously, adding <kbd>1</kbd> in the fourth and fifth parameters:</p>
<pre>Sobel(result, result, CV_8U, 1, 1); </pre>
<p>The result of applying <em>x</em> and <em>y</em> derivatives simultaneously looks like following image applied to the Lena picture:</p>
<div><img class="alignnone size-full wp-image-805 image-border" src="img/d97827fe-df6a-4482-904c-d438ae87db5a.png" style="width:47.67em;height:35.83em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">OpenGL support</h1>
                
            
            
                
<p>OpenCV includes OpenGL support. OpenGL is a graphical library integrated in almost all graphical cards as a standard. OpenGL allows us to draw 2D up to complex 3D scenes. OpenCV includes OpenGL support due to the importance of representing 3D spaces in a number of tasks. To allow window support in OpenGL, we have to set up the <kbd>WINDOW_OPENGL</kbd> flag when we create the window using the <kbd>namedWindow</kbd> call.</p>
<p>The following code creates a window with OpenGL support and draws a rotate plane where we are going to show the web camera frames:</p>
<pre>Mat frame; 
GLfloat angle= 0.0; 
GLuint texture;  
VideoCapture camera; 
 
int loadTexture() { 
 
    if (frame.data==NULL) return -1; 

   glBindTexture(GL_TEXTURE_2D, texture);  
   glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR); 
   glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR); 
   glPixelStorei(GL_UNPACK_ALIGNMENT, 1); 
 
   glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, frame.cols, frame.rows,0, GL_BGR, GL_UNSIGNED_BYTE, frame.data); 
   return 0; 
 
} 
 
void on_opengl(void* param) 
{ 
    glLoadIdentity();   
    // Load frame Texture 
    glBindTexture(GL_TEXTURE_2D, texture);  
    // Rotate plane before draw 
    glRotatef(angle, 1.0f, 1.0f, 1.0f); 
    // Create the plane and set the texture coordinates 
    glBegin (GL_QUADS); 
        // first point and coordinate texture 
     glTexCoord2d(0.0,0.0);  
     glVertex2d(-1.0,-1.0);  
        // second point and coordinate texture 
     glTexCoord2d(1.0,0.0);  
     glVertex2d(+1.0,-1.0);  
        // third point and coordinate texture 
     glTexCoord2d(1.0,1.0);  
     glVertex2d(+1.0,+1.0); 
        // last point and coordinate texture 
     glTexCoord2d(0.0,1.0);  
     glVertex2d(-1.0,+1.0); 
    glEnd(); 
 
} 
 
int main(int argc, const char** argv) 
{ 
    // Open WebCam 
    camera.open(0); 
    if(!camera.isOpened()) 
        return -1; 
 
    // Create new windows 
    namedWindow("OpenGL Camera", WINDOW_OPENGL); 
     
    // Enable texture 
    glEnable( GL_TEXTURE_2D );<br/>    glGenTextures(1, &amp;texture); <br/>    setOpenGlDrawCallback("OpenGL Camera", on_opengl); <br/>    while(waitKey(30)!='q'){ <br/>        camera &gt;&gt; frame; <br/>        // Create first texture <br/>        loadTexture();     <br/>        updateWindow("OpenGL Camera"); <br/>        angle =angle+4; <br/>    } <br/>    // Destroy the windows <br/>    destroyWindow("OpenGL Camera"); <br/>    return 0; <br/>}</pre>
<p>Let's understand the code!</p>
<p>The first task is to create the required global variables, where we store the video capture, save the frames, and control the animation angle plane and the OpenGL texture:</p>
<pre>Mat frame; 
GLfloat angle= 0.0; 
GLuint texture;  
VideoCapture camera; </pre>
<p>In our main function, we have to create the video camera capture to retrieve the camera frames:</p>
<pre>camera.open(0); 
    if(!camera.isOpened()) 
        return -1; </pre>
<p>If the camera is opened correctly, we can create our window with OpenGL support using the <kbd>WINDOW_OPENGL</kbd> flag:</p>
<pre>// Create new windows 
namedWindow("OpenGL Camera", WINDOW_OPENGL);</pre>
<p>In our example, we want to draw the images that come from the web camera in a plane; then, we need to enable the OpenGL textures:</p>
<pre>// Enable texture 
glEnable(GL_TEXTURE_2D); </pre>
<p>Now we are ready to draw with OpenGL in our window, but we need to set up a draw OpenGL callback like a typical OpenGL application. OpenCV gives us the <kbd>setOpenGLDrawCallback</kbd> function which has two parameters – the window name and the callback function:</p>
<pre>setOpenGlDrawCallback("OpenGL Camera", on_opengl); </pre>
<p>With the OpenCV window and callback function defined, we need to create a loop to load the texture, update the window content calling the OpenGL draw callback, and finally update the angle position. To update the window content, we use the OpenCV function update window with the window name as a parameter:</p>
<pre>while(waitKey(30)!='q'){ 
        camera &gt;&gt; frame; 
        // Create first texture 
        loadTexture(); 
        updateWindow("OpenGL Camera"); 
        angle =angle+4; 
    } </pre>
<p>We are in the loop when the user presses the <em>Q</em> key. Before compiling our application sample, we need to define the <kbd>loadTexture</kbd> function and our <kbd>on_opengl</kbd> callback draw function. The <kbd>loadTexture</kbd> function converts our <kbd>Mat</kbd> frame to an OpenGL texture image ready to load and use in each callback drawing. Before loading the image as a texture, we have to ensure that we have data in our frame matrix, checking that the data variable object is not empty:</p>
<pre>if (frame.data==NULL) return -1; </pre>
<p>If we have data in our matrix frame, then we can create the OpenGL texture binding and set the OpenGL texture parameter as a linear interpolation:</p>
<pre>glGenTextures(1, &amp;texture); 
 
glBindTexture(GL_TEXTURE_2D, texture); 
    glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR); 
    glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR);</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="CDPAlignLeft CDPAlign">Now, we have to define how the pixels are stored in our matrix and generate the pixels with the OpenGL <kbd>glTexImage2D</kbd> function. It's very important to note that OpenGL uses the RGB format, and OpenCV the BGR format, by default, and we have to set up the correct format in this function:</p>
<pre>glPixelStorei(GL_UNPACK_ALIGNMENT, 1); 
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, frame.cols, frame.rows,0, GL_BGR, GL_UNSIGNED_BYTE, frame.data); 
    return 0; </pre>
<p>Now, we only need to finish drawing our plane on every callback when we call <kbd>updateWindow</kbd> in the main loop. We use the common OpenGL functions, and then we load the identity OpenGL matrix to reset all our previous changes:</p>
<pre>glLoadIdentity();   </pre>
<p>We also have to bring the frame texture to memory:</p>
<pre>    // Load Texture 
    glBindTexture(GL_TEXTURE_2D, texture);  </pre>
<p>Before drawing our plane, we apply all transformations to our scene. In our case, we are going to rotate our plane in the <kbd>1,1,1</kbd> axis:</p>
<pre>    // Rotate plane 
    glRotatef(angle, 1.0f, 1.0f, 1.0f); </pre>
<p>Now that we have the scene correctly set to draw our plane, we are going to draw quads faces (faces with four vertices) and use <kbd>glBegin (GL_QUADS)</kbd> for this purpose:</p>
<pre>// Create the plane and set the texture coordinates 
    glBegin (GL_QUADS); </pre>
<p>Next, we will draw a plane centered in the <kbd>0,0</kbd> position, which is 2 units in size. Then, we have to define the texture coordinate to use and the vertex position using the <kbd>glTextCoord2D</kbd> and <kbd>glVertex2D</kbd> functions:</p>
<pre>    // first point and coordinate texture 
 glTexCoord2d(0.0,0.0);  
 glVertex2d(-1.0,-1.0);  
    // seccond point and coordinate texture 
 glTexCoord2d(1.0,0.0);  
 glVertex2d(+1.0,-1.0);  
    // third point and coordinate texture 
 glTexCoord2d(1.0,1.0);  
 glVertex2d(+1.0,+1.0); 
    // last point and coordinate texture 
 glTexCoord2d(0.0,1.0);  
 glVertex2d(-1.0,+1.0); 
    glEnd(); </pre>
<p>This OpenGL code becomes obsolete, but it is appropriated to understand better the OpenCV and OpenGL integration without complex OpenGL code. By way of an introduction to modern OpenGL, read <em>Introduction to Modern OpenGL</em>, from <em>Packt Publishing</em>.</p>
<p>We can see the result in the following image:</p>
<div><img class="alignnone size-full wp-image-806 image-border" src="img/07b18665-27b6-4cdc-b90a-5eb71ea48db6.png" style="width:25.17em;height:20.67em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we learned how to create different types of user interfaces to show images or 3D interfaces using OpenGL. We learned how to create sliders and buttons or draw in 3D. We learned some basic image processing filters too with native OpenCV, but there are new open source alternatives that allow us to add more functionalities, such as cvui (<a href="https://dovyski.github.io/cvui/">https://dovyski.github.io/cvui/</a>) or OpenCVGUI (<a href="https://damiles.github.io/OpenCVGUI/">https://damiles.github.io/OpenCVGUI/</a>).</p>
<p>In the next chapter, we are going to construct a complete photo tool application where we will be applying all the knowledge that we have learned thus far. With the graphical user interface, we are going to learn how to apply multiple filters to an input image.</p>


            

            
        
    </body></html>