<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;14.&#xA0;Deep Learning" id="30A8Q1-c6198d576bbb4f42b630392bd61137d7"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch14" class="calibre1"/>Chapter 14. Deep Learning</h1></div></div></div><p class="calibre8">The purpose of this chapter is to tackle the very important topic of <span class="strong"><em class="calibre9">deep learning</em></span> and the how and why of how it has been growing in importance to the statistical field in recent years.</p><p class="calibre8">We will start by providing a bit of an explanation of what <span class="strong"><em class="calibre9">machine</em></span> learning is then move on with some discussion around what <span class="strong"><em class="calibre9">deep</em></span> learning is, how it compares to machine learning, and the reasoning behind how it has been continually growing in importance almost day by day. For clarification of the concepts, we will then present two hallmark sample use cases: <span class="strong"><em class="calibre9">word embedding</em></span> with some <a id="id978" class="calibre1"/>talk about natural language processing or NLP application logic, and <span class="strong"><strong class="calibre2">recurrent neural networks</strong></span> (<span class="strong"><strong class="calibre2">RNNs</strong></span>) which is an interesting and more advanced and efficient type of artificial neural network.</p></div>

<div class="book" title="Chapter&#xA0;14.&#xA0;Deep Learning" id="30A8Q1-c6198d576bbb4f42b630392bd61137d7">
<div class="book" title="Machine learning or deep learning"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch14lvl1sec94" class="calibre1"/>Machine learning or deep learning</h1></div></div></div><p class="calibre8">With <span class="strong"><em class="calibre9">machine learning</em></span>, algorithm options are selected and used to analyze data and data sources and, rather than make decisions on them, they learn from them so that they can use patterns or results <a id="id979" class="calibre1"/>found in the data to make decisions or predictions about a certain topic, or to solve a specific problem.</p><p class="calibre8">What this <a id="id980" class="calibre1"/>translates to is that instead of you programming or writing out each rule and instruction that needs to be used for a specific task such as making a prediction, the computer is trained using large amounts of data and algorithms which give it the ability to actually learn how to perform a task, make a prediction, solve a problem, or meet an objective in mind.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note56" class="calibre1"/>Note</h3><p class="calibre8">
<span class="strong"><strong class="calibre2">Just how much data qualifies as enough data for successful machine learning?</strong></span>
</p><p class="calibre8">Usually <span class="strong"><em class="calibre9">the bigger, the better</em></span>, but in practice, you must gather a <span class="strong"><em class="calibre9">sufficient</em></span> amount of data, based upon your intended purpose or need. Given a shortage of quantity, the wise data scientist should always focus on the <span class="strong"><em class="calibre9">quality</em></span> or suitability of the data.</p></div><p class="calibre8">An example commonly used by experts within the field of statistics to illustrate how machine <a id="id981" class="calibre1"/>learning works is the scenario of an algorithm or model predicting a person's body weight based upon what their height happens to be. In this example, given a decent amount of experience (or actual data cases that provide a person's actual physical height and body weight), a model can be built to predict a person's body weight given their height measurements.</p><p class="calibre8">Obviously, the <span class="strong"><em class="calibre9">more experience</em></span> (or more actual data consumed and analyzed by the model), the <span class="strong"><em class="calibre9">better</em></span> the results (or predictions).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note57" class="calibre1"/>Note</h3><p class="calibre8">It is common for data scientists to refer to a model's experience as the amount of raw data it has been trained on over time.</p></div><p class="calibre8">There are many kinds, or methods of machine learning, and we find that over time, the industry experts have categorized them by the <span class="strong"><em class="calibre9">type</em></span> of learning the algorithm or model uses.</p><p class="calibre8">The typical or most common types of machine learning usually include the following:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Supervised</li><li class="listitem">Unsupervised</li><li class="listitem">Semi-supervised</li><li class="listitem">Reinforcement</li><li class="listitem">Transduction and so on</li></ul></div><p class="calibre8">Deep learning is different; even though machine learning is grouped by type, deep learning is <span class="strong"><em class="calibre9">not</em></span> a type. <span class="strong"><em class="calibre9">Deep learning</em></span> is considered a method or way of implementing machine learning.</p><p class="calibre8">The next section will take a closer look at that concept.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="What is deep learning?"><div class="book" id="318PC2-c6198d576bbb4f42b630392bd61137d7"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch14lvl1sec95" class="calibre1"/>What is deep learning?</h1></div></div></div><p class="calibre8">Deep <a id="id982" class="calibre1"/>learning (also known <a id="id983" class="calibre1"/>by some within the industry as <span class="strong"><strong class="calibre2">deep structured learning</strong></span> or <span class="strong"><strong class="calibre2">hierarchical learning</strong></span>, among other titles) is <a id="id984" class="calibre1"/>really part of a wider family, or branch, of machine learning methods, as mentioned earlier. These methods are based on learning what is known as <span class="strong"><em class="calibre9">representations</em></span> (that is, where the model discovers from the data the representations, patterns, or rules needed to carry out a desired task or meet an objective), as <a id="id985" class="calibre1"/>opposed to <span class="strong"><em class="calibre9">task specific algorithms</em></span> (that is, detailed rules written out or predefined, describing how to perform a specific task).</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note58" class="calibre1"/>Note</h3><p class="calibre8">Representations or feature representations are critical to all types of learning. Feature representations can be learned and predefined <span class="strong"><em class="calibre9">manually</em></span> or defined <span class="strong"><em class="calibre9">automatically</em></span> by the model while analyzing the data.</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="An alternative to manual instruction"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch14lvl2sec125" class="calibre1"/>An alternative to manual instruction</h2></div></div></div><p class="calibre8">As an <a id="id986" class="calibre1"/>alternative to the process of manually creating rules, instructions, or equations deemed essential to solving a problem and then organizing data to be run through them, the process of deep learning simply sets up fundamental parameters about the problem to be solved and then trains the computer to learn on its own by recognizing patterns within that data.</p><p class="calibre8">This is accomplished by using multiple layers of processing. For example, the first layer may establish the most basic feature or features by finding a simple or basic pattern. The next layer is then fed this identified information, which then works to break out the next level of information and feed that to another layer and so on, until the final layer can determine an outcome or make a prediction.</p><p class="calibre8">This process is typically illustrated using the tree-like flow of a decision tree or decision flow diagram. This graphical representation can visually show decisions and their possible consequences, including chance event outcomes, and so on.</p><p class="calibre8">If we again exploit our previously mentioned physical height and body weight example, using machine learning, one would have to define features, instructions, or rules based upon whether an individual was male or female, their age and ethnicity, and perhaps their BMI or body mass index. In short, you would outline the physical attributes to be used to meet the objective (guess the correct body weight) and then let the system use the more important features to determine a subject's suspected body weight.</p><p class="calibre8">So, deep learning automatically discovers or finds out the features that are important to be used for making the prediction. This finding out process might be described as following the steps listed as follows (again, if we use the body height and weight use case example):</p><div class="book"><ul class="itemizedlist"><li class="listitem">First the process attempts to identify which physical attributes are most relevant to determining body weight</li><li class="listitem">Next, it builds a hierarchy rather like that decision flowchart we mentioned earlier which it can use to determine a subject's body weight (for example, whether a subject is male or female or is within a certain height range, and so on)</li><li class="listitem">After consecutive hierarchical identification (or classification) of these combinations, it then decides which of these features are responsible for predicting the answer (that is, the subjects body weight)</li></ul></div><p class="calibre8">To summarize, while classical machine learning requires the extraction and establishment of rules or features from data, followed by the preprocessing or organizing of the data (and these steps <a id="id987" class="calibre1"/>are typically 85 to 90 percent a human effort) before the model can be used to make predictions, deep learning uses deep learning algorithms to perform its own feature learning and then is able to make its predictions.</p><p class="calibre8">At the time of writing, deep learning is typically assumed to be one of four fundamental architectures.</p><p class="calibre8">These are:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Unsupervised Pre-Trained</li><li class="listitem">Convolutional Neural</li><li class="listitem">Recurrent Neural</li><li class="listitem">Recursive Neural</li></ul></div><p class="calibre8">These <a id="id988" class="calibre1"/>deep learning architectures have been successfully applied to various fields and have produced results comparable to (and in some cases superior to) appropriately skilled human <span class="strong"><strong class="calibre2">subject matter experts</strong></span> (<span class="strong"><strong class="calibre2">SMEs</strong></span>):</p><div class="book"><ul class="itemizedlist"><li class="listitem">Computer vision</li><li class="listitem">Speech recognition</li><li class="listitem">Natural language processing</li><li class="listitem">Audio recognition</li><li class="listitem">Social network filtering</li><li class="listitem">Machine translation</li><li class="listitem">Bioinformatics</li></ul></div></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Growing importance"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch14lvl2sec126" class="calibre1"/>Growing importance</h2></div></div></div><p class="calibre8">Today, deep <a id="id989" class="calibre1"/>learning has been established as a key instrument for practical machine learning use cases. Since computers are ever more powerful, using deep learning techniques to learn from the ever growing data sources (even <span class="strong"><em class="calibre9">big data</em></span>), we can expect to process and predict quicker and with higher rates of accuracy than ever before.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note59" class="calibre1"/>Note</h3><p class="calibre8">
<span class="strong"><em class="calibre9">Big data</em></span> is a term being used for data that is so large or complex that traditional algorithms and system software is insufficient to deal with it.</p></div><p class="calibre8">Furthermore, the concept of deep learning has been described many times in the media as more than a method or practice of machine learning (as we mentioned earlier in this chapter), but more of a ground-breaking attitude to learning, using cognitive skills such <a id="id990" class="calibre1"/>as the ability to analyze, produce, solve problems, and thinking meta-cognitively in order to construct long-term understanding.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note60" class="calibre1"/>Note</h3><p class="calibre8">Cognitive skills usually refers to the capacity to develop a meaning and/or certain knowledge from reviewing data (also called experience or information).</p></div><p class="calibre8">The use of deep learning techniques promotes understanding and application for life at a much more advanced, more effective, and quicker proportion than other forms of learning, therefore it is an area with extremely high potential to impact the world as we know it.</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Deeper data?"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch14lvl2sec127" class="calibre1"/>Deeper data?</h2></div></div></div><p class="calibre8">Pretty <a id="id991" class="calibre1"/>much everyone, everywhere has heard of the term <span class="strong"><em class="calibre9">big data</em></span>. Although there may still be some debate or disagreement as to what the term actually means, the bottom line is that there is a lot more data available today then there was yesterday (and there will be even more tomorrow!).</p><p class="calibre8">What this means is that this data is available to build more neural networks with many deeper layers, providing even more accurate (or at least perhaps more interesting) outcomes.</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Deep learning for IoT"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch14lvl2sec128" class="calibre1"/>Deep learning for IoT</h2></div></div></div><p class="calibre8">Also, new <a id="id992" class="calibre1"/>and exciting, is the fascinating world of the <span class="strong"><strong class="calibre2">internet of things</strong></span> (<span class="strong"><strong class="calibre2">IoT</strong></span>). The acronym IoT describes the way devices, vehicles, buildings, and many, many other items speak or communicate with each other. Almost all devices these <a id="id993" class="calibre1"/>days and into the future have or will have the ability to be smart devices or become connected devices, capturing information about their usage and surrounding environments and conditions, and then connecting and sharing the information and events they collect.</p><p class="calibre8">Machine and deep learning models and algorithms will play a significant role in the IoT analytics. Data from IoT devices is sparse and/or has a temporal element in it, and deep learning <a id="id994" class="calibre1"/>algorithms can be trained with this information to yield significant insights.</p><p class="calibre8">The many, many recent advances in the area of distributed cloud computing and graphics processing units have made incredible computing power available for use, which in turn advances the ability for maximum positive effectiveness of deep learning applications.</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Use cases"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_5"><a id="ch14lvl2sec129" class="calibre1"/>Use cases</h2></div></div></div><p class="calibre8">Many <a id="id995" class="calibre1"/>real-life use cases exist today for applying deep learning <a id="id996" class="calibre1"/>algorithms, including (just to name a few):</p><div class="book"><ul class="itemizedlist"><li class="listitem">Fraud detection</li><li class="listitem">Image recognition</li><li class="listitem">Voice recognition</li><li class="listitem">Natural language processing</li></ul></div><p class="calibre8">Now becoming more main stream, the growing field of <span class="strong"><em class="calibre9">predictive analysis</em></span> and <span class="strong"><em class="calibre9">predictive analytics</em></span> is using deep learning in the areas of finance, accounting, government, security, hardware manufacturing, search engines, e-commerce, and medicine.</p><p class="calibre8">One newer, very exciting, and perhaps growing ever more important use case for deep learning is with motion detection for <span class="strong"><em class="calibre9">situation evaluation</em></span>, security, and defense.</p><div class="book" title="Word embedding"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch14lvl3sec21" class="calibre1"/>Word embedding</h3></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Natural language processing</strong></span> (<span class="strong"><strong class="calibre2">NLP</strong></span>) is <a id="id997" class="calibre1"/>an area of <a id="id998" class="calibre1"/>computer science (or more specifically, computational linguistics) that focuses on the interactions between computers and the human language.</p><p class="calibre8">In a <a id="id999" class="calibre1"/>natural language application, there is an attempt to process an extreme amount of real-world text, formally called a natural language corpora data source.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note61" class="calibre1"/>Note</h3><p class="calibre8">Corpora is equivalent to the word samples. In this context, a natural language corpora data source would be a database or file filled with actual words and phrases of text, in an expected language.</p></div><p class="calibre8">Speech recognition is one of the most well-known and perhaps most developed applications of NLP, even so, challenges are many and typically include:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Natural language understanding</li><li class="listitem">Natural language generation</li><li class="listitem">Connecting language and machine perception</li><li class="listitem">Dialog systems</li><li class="listitem">Some combination of all of these</li></ul></div><p class="calibre8">Word <a id="id1000" class="calibre1"/>embedding is a very popular method of language modeling and feature learning techniques used in many natural language processing applications.</p><p class="calibre8">This is the practice of using words or phrases from a vocabulary and mapping them to vectors of real numbers. Simply speaking, word embedding is the process of turning text into numbers and this text-to-numeric transformation is required because most deep learning algorithms require their input to be vectors of continuous numeric values (they don't work on strings of plain text) and, well, computers just unsurprisingly process numbers better.</p><p class="calibre8">So, with the preceding definition in mind, word embedding is used to map words or phrases from a vocabulary to a corresponding vector of real numbers that also provides the following benefits:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Dimensionality Reduction</strong></span>: Reducing <a id="id1001" class="calibre1"/>phrases to numbers obviously is a more efficient representation</li><li class="listitem"><span class="strong"><strong class="calibre2">Contextual Similarity</strong></span>: Numerics can <a id="id1002" class="calibre1"/>be a more expressive representation</li></ul></div><div class="blockquote"><blockquote class="blockquote1"><p class="calibre29">"Contextual Word Similarity is nothing but identifying different types of similarities between words. It is one of the goals of NLP. Statistical approaches are used for computing the degree of similarity between words."</p><p class="calibre29">                                                                         – Robin, December 10th, 2012</p></blockquote></div></div><div class="book" title="Word prediction"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch14lvl3sec22" class="calibre1"/>Word prediction</h3></div></div></div><p class="calibre8">For a <a id="id1003" class="calibre1"/>statistical <span class="strong"><em class="calibre9">language model</em></span> to be able to predict the <a id="id1004" class="calibre1"/>meaning of some text, it needs to be conscious of the <span class="strong"><em class="calibre9">contextual similarity of words</em></span>.</p><p class="calibre8">For example, you would probably agree that you would expect to find words such as <span class="strong"><em class="calibre9">martini</em></span> or <span class="strong"><em class="calibre9">cosmopolitan</em></span> within sentences where they're <span class="strong"><em class="calibre9">dry</em></span>, <span class="strong"><em class="calibre9">shaken</em></span>, <span class="strong"><em class="calibre9">stirred</em></span>, and <span class="strong"><em class="calibre9">chilled</em></span>, but would not expect to find those same concepts in such close proximity to, say, the word automobile.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note62" class="calibre1"/>Note</h3><p class="calibre8">Another form of word prediction is <span class="strong"><em class="calibre9">Autocomplete or word completion</em></span>. This is when an algorithm can predict the rest of a word a user is typing.</p></div></div><div class="book" title="Word vectors"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch14lvl3sec23" class="calibre1"/>Word vectors</h3></div></div></div><p class="calibre8">The word <a id="id1005" class="calibre1"/>vectors (actually they are <span class="strong"><em class="calibre9">numeric vectors</em></span>) that are produced by applying the logic and reason of word embedding expose these similarities, so <a id="id1006" class="calibre1"/>words that regularly occur nearby in text will also be in close proximity within a vector space.</p><p class="calibre8">It is <a id="id1007" class="calibre1"/>very important to understand how these words or numeric vectors work, so let's go over a short (and hopefully simple), explanation of this notion.</p><p class="calibre8">If a word vector is divided into several hundred elements, each word in a vocabulary is represented by a distribution of weights across those elements (in that vector). So instead of a one-to-one mapping between an element in the vector and a word, the representation of that word is spread across all of the elements in that vector, and each element in the vector <span class="strong"><em class="calibre9">contributes</em></span> to the definition of many words. Such a vector comes to represent in some abstract way the meaning of a word.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note63" class="calibre1"/>Note</h3><p class="calibre8">A really easy to understand tutorial along with some nice illustrations on word or numeric vectors can be found online at: <a class="calibre1" href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/">https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/</a>.</p></div><p class="calibre8">So, again, let's answer the question of what is word embedding?</p><p class="calibre8">
<span class="strong"><em class="calibre9">"…Word Embedding is a means of creating a low-dimensional vector representation from corpus of text, which preserves the contextual similarity of words…"</em></span>
</p></div><div class="book" title="Numerical representations of contextual similarities"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch14lvl3sec24" class="calibre1"/>Numerical representations of contextual similarities</h3></div></div></div><p class="calibre8">An additional <a id="id1008" class="calibre1"/>bonus of <a id="id1009" class="calibre1"/>implementing <span class="strong"><em class="calibre9">word</em></span> vectors is that they can be manipulated arithmetically (just like any other numeric vector can). Since words in a vocabulary are translated into <span class="strong"><em class="calibre9">numerical</em></span> vectors, and there are semantic relationships in the position of those vectors, one can use or apply <span class="strong"><em class="calibre9">simple arithmetic</em></span> on the vectors to find additional meanings and insights.</p><p class="calibre8">Many examples do exist to illustrate this concept, including the operation of moving across in embedding space from <span class="strong"><em class="calibre9">Man</em></span> to <span class="strong"><em class="calibre9">Queen</em></span> by subtracting <span class="strong"><em class="calibre9">King</em></span> and adding <span class="strong"><em class="calibre9">Woman</em></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note64" class="calibre1"/>Note</h3><p class="calibre8">The arithmetic manipulation performed on word or numeric vectors is known within the field as <span class="strong"><em class="calibre9">vector math</em></span>.</p></div><p class="calibre8">By exploiting <a id="id1010" class="calibre1"/>this technique, groupings <a id="id1011" class="calibre1"/>of words are not simply close variations or <span class="strong"><em class="calibre9">synonyms</em></span>, but rather unique words that make up a contextual collection or just belong together.</p></div><div class="book" title="Netflix learns"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch14lvl3sec25" class="calibre1"/>Netflix learns</h3></div></div></div><p class="calibre8">One of <a id="id1012" class="calibre1"/>my most favorite machine learning use case examples is Netflix (a website that specializes in and provides streaming media and video-on-demand online).</p><p class="calibre8">A typical <a id="id1013" class="calibre1"/>view of Netflix services (movies and videos available for streaming) provides over 40 rows of possible selections. Just like any other business, a consumer loses interest after about two minutes of window shopping for a video to watch so Netflix has very little time to catch the customer's attention.</p><p class="calibre8">Rather than rely on customer ratings and surveys, Netflix leverages a very broad set of data assets: what each member watches, when they watch, the place on the Netflix screen the customer found the video, recommendations the customer didn't pick, and the popularity of videos in the catalogue.</p><div class="blockquote"><blockquote class="blockquote1"><p class="calibre29">"All of this data is read by numerous algorithms powered by machine-learning techniques. Approaches use both supervised (classification, regression) and unsupervised (dimensionality reduction through clustering or compression) approaches…,"</p><p class="calibre29">                                                                               - C. Raphel.</p></blockquote></div><div class="informalexample" title="Note"><h3 class="title2"><a id="note65" class="calibre1"/>Note</h3><p class="calibre8">The report mentioned is available online here: <a class="calibre1" href="https://www.rtinsights.com/netflix-recommendations-machine-learning-algorithms">https://www.rtinsights.com/netflix-recommendations-machine-learning-algorithms</a>.</p></div><div class="blockquote"><blockquote class="blockquote1"><p class="calibre29">A video-to-video similarity algorithm, or Sims, makes recommendations in the <span class="strong"><em class="calibre9">"Because You Watched"</em></span> row </p><p class="calibre29">                                                                                                       - <span class="strong"><em class="calibre9">C. Raphel</em></span>.</p></blockquote></div><p class="calibre8">One may discern that selections are made by genre alone, but the idea of contextual similarities surely plays a role in mining selections that fit the consumer or viewers mindset. Words that fit together can spawn ideas for films that might be enjoyed by the viewer. Manipulating word vectors can produce an almost endless list of ideas.</p><p class="calibre8">As the following paragraph reports, results from the Netflix algorithms actually have a better <a id="id1014" class="calibre1"/>success rate in making recommendations that what is intuitively believed:</p><div class="blockquote"><blockquote class="blockquote1"><p class="calibre29">"…as an example, the authors describe recommendations for shows similar to "House of Cards." While one might think that political or business dramas such as "The West Wing" or "Mad Men" would increase customer engagement, it turns out that popular but outside-of-genre titles such as "Parks and Recreation" and "Orange Is the New Black" fared better. The authors call this a case of "intuition failure..."</p><p class="calibre29">                                                                                  – C. Raphel</p></blockquote></div></div></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Implementations"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_6"><a id="ch14lvl2sec130" class="calibre1"/>Implementations</h2></div></div></div><p class="calibre8">So how <a id="id1015" class="calibre1"/>do we implement word or numeric vectors in a typical word embedding application?</p><p class="calibre8">One of <a id="id1016" class="calibre1"/>the most popular algorithms available for producing <a id="id1017" class="calibre1"/>word embedding models is <span class="strong"><strong class="calibre2">word2vec</strong></span>, created by Google in 2013. Word2vec, written in C++, but also has been implemented in Java/Scala and Python, accepts a text corpus (or speaking informally, expects a sequence of sentences as its input and each sentence a list of words) as input and produces word vectors as output.</p><p class="calibre8">Another note about the input to word2vec, it only requires that your input data be provided as sequential sentences, you do not have to worry about storing it all in memory at one time to process it. This means that you can:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Provide one sentence</li><li class="listitem">Process it</li><li class="listitem">Load another sentence</li><li class="listitem">Process it</li><li class="listitem">Repeat…</li></ul></div><p class="calibre8">This means large data, such as those that qualify as big data, sources (discussed in <a class="calibre1" title="Chapter 11. Topic Modeling" href="part0082_split_000.html#2E6E41-c6198d576bbb4f42b630392bd61137d7">Chapter 11</a>, <span class="strong"><em class="calibre9">Topic Modeling</em></span> of this book), which may consist of data spread over several files in multiple locations, can be processed by one sentence per line (instead of loading everything into an in-memory list, input file by file, line by line). This kind of architecture also allows preprocessing such as converting to Unicode, lowercase, removing numbers, extracting named entities, and so on, to occur without word2vec even being aware of it.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note66" class="calibre1"/>Note</h3><p class="calibre8">Word2vec isn't a good choice for data that is very small in size. For real results, as reported through trials, you should have a minimum of a million words. Small data files or sources are not enough for a concise word similarity or proper word vector creation.</p></div><p class="calibre8">Word2vec is also set up to accept some parameters such as <code class="email">min_count</code>.</p><p class="calibre8">This parameter is very effective for setting the lower limit for words to appear in the data. For example, any words that appear only a few times in a million-word data source are probably <a id="id1018" class="calibre1"/>typos and garbage and should be ignored in word vector creation. This parameter allows you to automatically drop uninteresting or unimportant words. The default is set to <code class="email">5</code>.</p><p class="calibre8">Word2vec first constructs a vocabulary from the text data provided as input and then learns vector representation of words. The resulting word vector file can be used as featured in many natural language processing and machine learning applications.</p><p class="calibre8">The following is a partial word vector image created by word2vec:</p><div class="mediaobject"><img src="../images/00218.jpeg" alt="Implementations" class="calibre10"/></div><p class="calibre11"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="note67" class="calibre1"/>Note</h3><p class="calibre8">Even though word2vec is a powerful tool, even Google declares that it is not user-friendly and various open source packages have been developed over time to add a user friendly interface to the algorithm. You can go online and access word2vec at <a class="calibre1" href="https://code.google.com/p/word2vec">https://code.google.com/p/word2vec</a>.</p></div><p class="calibre8">As with <a id="id1019" class="calibre1"/>many implementations in statistics, there is some disagreement as to exactly what word2vec is or how the logic has ultimately been implemented. Is it an example of the classical machine learning model? An example of implemented deep learning? Or, can we say that it is some sort of hybrid model?</p><p class="calibre8">A bit of <a id="id1020" class="calibre1"/>online research reveals numerous opinions, for example, A.Thakker, June 18, 2017:</p><div class="blockquote"><blockquote class="blockquote1"><p class="calibre29">"…Word2Vec is considered (by some within the industry) as a starter of "Deep Learning in NLP". However, Word2Vec is not deep. But the output of Word2Vec is what Deep Learning models can easily understand. Word2vec is basically a computationally efficient predictive model for learning word embeddings from raw text. The purpose of Word2Vec is to group words that are semantically similar in vector space. It computes similarities mathematically. Given a huge amount of data…."</p></blockquote></div><p class="calibre8">Let's go over the architectures of deep learning, starting in the next section.</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Deep learning architectures"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_7"><a id="ch14lvl2sec131" class="calibre1"/>Deep learning architectures</h2></div></div></div><p class="calibre8">We indicated <a id="id1021" class="calibre1"/>earlier in this chapter, under the Deep Learning section that there are currently (or at least at the time of writing) four basic deep learning architectures. We'll fleetingly look at three (Unsupervised Pre-Trained, Convolutional Neural, and Recursive Neural) now and then do a deeper dive into one of the most stimulating and effective (at least for appropriate use cases) <span class="strong"><em class="calibre9">Recurrent Neural Networks</em></span>:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1"><span class="strong"><strong class="calibre2">Unsupervised pre-trained neural networks</strong></span>: Think of stacking the deck by making <a id="id1022" class="calibre1"/>weighting adjustments before the model training actually begins.</li><li class="listitem" value="2"><span class="strong"><strong class="calibre2">Convolutional neural networks</strong></span>: A feed-forward model, that uses a variation <a id="id1023" class="calibre1"/>of multilayer perceptrons (or individual learning units) designed to require minimal preprocessing, used for visual imagery processing and natural language processing.</li><li class="listitem" value="3"><span class="strong"><strong class="calibre2">Recursive neural networks</strong></span>: These are created by applying the same set of weights <a id="id1024" class="calibre1"/>recursively over a structure, in an attempt to produce a <span class="strong"><em class="calibre9">structured prediction</em></span> (that is, <span class="strong"><em class="calibre9">the ability to predict</em></span> structured objects rather than discreet or real values).</li></ol><div class="calibre13"/></div></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Artificial neural networks"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_8"><a id="ch14lvl2sec132" class="calibre1"/>Artificial neural networks</h2></div></div></div><p class="calibre8">
<span class="strong"><strong class="calibre2">Artificial neural networks</strong></span> (<span class="strong"><strong class="calibre2">ANNs</strong></span>) systems are computing systems, algorithms, or models that <a id="id1025" class="calibre1"/>are inspired by and based upon how biological neural networks in our human brains work.</p><p class="calibre8">These systems learn to perform work and solve problems by considering patterns found in data (referred to as gaining experience), generally without having to program specific logic prompts.</p><p class="calibre8">ANNs <a id="id1026" class="calibre1"/>are a <span class="strong"><em class="calibre9">big part</em></span> of deep learning.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note68" class="calibre1"/>Note</h3><p class="calibre8">Most artificial neural networks bear only a slight resemblance to their more complex biological counterparts, but are very effective at intended tasks such as classification or segmentation. For more information, refer to: <a class="calibre1" href="https://en.wikipedia.org/wiki/Types_of_artificial_neural_networks">https://en.wikipedia.org/wiki/Types_of_artificial_neural_networks</a>.</p></div><p class="calibre8">In <a class="calibre1" title="Chapter 5. Neural Networks" href="part0045_split_000.html#1AT9A1-c6198d576bbb4f42b630392bd61137d7">Chapter 5</a>, <span class="strong"><em class="calibre9">Neural Networks</em></span>, we covered <span class="strong"><em class="calibre9">Neural Networks</em></span> in some detail, specifically, ANNs. In the <a id="id1027" class="calibre1"/>next section of this chapter we pick up that thread again and move onto the topic of <span class="strong"><strong class="calibre2">Recurrent neural networks</strong></span> (<span class="strong"><strong class="calibre2">RNNs</strong></span>).</p></div></div>

<div class="book" title="What is deep learning?">
<div class="book" title="Recurrent neural networks"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_9"><a id="ch14lvl2sec133" class="calibre1"/>Recurrent neural networks</h2></div></div></div><p class="calibre8">Generally <a id="id1028" class="calibre1"/>speaking, it is accepted within the industry that there really are just two chief types of neural networks.</p><p class="calibre8">These are:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Feed forward</li><li class="listitem">Recurrent</li></ul></div><p class="calibre8">The feed forward neural network was the first and simplest type that was developed.</p><p class="calibre8">In a <span class="strong"><em class="calibre9">feed forward</em></span> network, activation is pushed through the network from the input layers to the output layers. In this network the information moves only from the input layer <span class="strong"><em class="calibre9">straight through</em></span> any hidden layers to the output layer without cycles or looping.</p><p class="calibre8">In other words, feed forward neural networks are a one-way street.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note69" class="calibre1"/>Note</h3><p class="calibre8">Most all of the types of neural networks are organized in layers. Layers are made up of interconnected nodes which contain what is known as an activation function. <span class="strong"><em class="calibre9">Patterns</em></span> are presented to the network by the input layer, which then communicates to one or more <span class="strong"><strong class="calibre2">hidden layers</strong></span>. Hidden layers are where the real work is done using a system of weighted connections.</p></div><p class="calibre8">Let's continue on with our dialogue by stating that a <span class="strong"><strong class="calibre2">recurrent neural network</strong></span> (or <span class="strong"><strong class="calibre2">RNN</strong></span>) is an interesting and unique <span class="strong"><em class="calibre9">class</em></span> of ANN.</p><p class="calibre8">The objective of using RNN logic is to make use of <span class="strong"><em class="calibre9">sequential or chronological </em></span>data. This is much different to the logic used by a traditional neural network, where it is assumed <a id="id1029" class="calibre1"/>that all inputs and outputs are independent of each other, or have no relevance to each others. This kind of presumption (or limitation) works or is at least sufficient for some applications, but for many tasks this is not an acceptable premise. For example, if you are trying to predict the next word someone is typing in a search engine, you need to know which words were typed before it.</p><p class="calibre8">RNNs are called <span class="strong"><em class="calibre9">recurrent</em></span> because they perform the <span class="strong"><em class="calibre9">same task</em></span> for <span class="strong"><em class="calibre9">every element in a sequence</em></span>, with the output being dependent on all of the previous computations.</p><p class="calibre8">Another way to think about RNNs is that they can remember information about what has been calculated thus far within a sequence. This allows it to exhibit <span class="strong"><em class="calibre9">dynamic temporal (or related) behaviors</em></span>.</p><p class="calibre8">Remember, RNNs use a special layer that is called a state layer, which is updated not only with the external input information of the network, but also with activation information from the previous forward propagation.</p><p class="calibre8">There <a id="id1030" class="calibre1"/>is an interesting blog that provides valuable insight into how RNNs work. The following figure is based upon that information. The reader can review the information at: <a class="calibre1" href="https://shapeofdata.wordpress.com/2015/10/20/recurrent-neural-networks">https://shapeofdata.wordpress.com/2015/10/20/recurrent-neural-networks</a>.</p><div class="mediaobject"><img src="../images/00219.jpeg" alt="Recurrent neural networks" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">To show how much this is a valuable feature, as an example, the word <span class="strong"><em class="calibre9">aliens</em></span> might have a different meaning if it was part of the sequence <span class="strong"><em class="calibre9">ancient aliens</em></span>.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note70" class="calibre1"/>Note</h3><p class="calibre8">In theory, RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps.</p></div><p class="calibre8">As we <a id="id1031" class="calibre1"/>stated earlier in this section, unlike an artificial neural network where connections between logic layers do not form a loop (technically referred to as a feed forward neural network), RNNs can use their internal memory to process <span class="strong"><em class="calibre9">arbitrary sequences of inputs</em></span>. This makes them a great choice for applications such as handwriting recognition or speech recognition.</p></div></div>
<div class="book" title="Summary" id="3279U1-c6198d576bbb4f42b630392bd61137d7"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch14lvl1sec96" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we discussed the topics of machine and deep learning and the difference between the two. We also mentioned how deep learning has the capacity to drive change in the world.</p><p class="calibre8">We saw how deep learning reduces the effort required by humans and listed some of the current applications where these algorithms have been successfully applied. We then looked at using <span class="strong"><em class="calibre9">word embedding</em></span> for a use case such as NLP applications, and explained how it works.</p><p class="calibre8">Finally, we wrapped up with a discussion on neural networks, specifically RNNs.</p><p class="calibre8">With this chapter, we bring our journey to its end, having provided in-depth information around performance metrics and learning curves, polynomial regression, Poisson, and negative binomial regression, back-propagation, radial basis function networks, and others. We also discussed the process of working with very large datasets.</p><p class="calibre8">Hopefully you have enjoyed exploring and testing these popular modeling techniques and mastered a range of predictive analytics styles.</p></div></body></html>