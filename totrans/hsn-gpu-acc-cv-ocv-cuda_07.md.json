["```py\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main()\n{\n  VideoCapture cap(0); //capture the video from web cam\n  // if webcam is not available then exit the program\n  if ( !cap.isOpened() ) \n  {\n    cout << \"Cannot open the web cam\" << endl;\n    return -1;\n  }\n  while (true)\n  {\n    Mat frame;\n    // read a new frame from webcam\n    bool flag = cap.read(frame); \n    if (!flag) \n    {\n      cout << \"Cannot read a frame from webcam\" << endl;\n      break;\n    }\n\n    cuda::GpuMat d_frame, d_frame_hsv,d_intermediate,d_result;\n    cuda::GpuMat d_frame_shsv[3];\n    cuda::GpuMat d_thresc[3];\n    Mat h_result;\n    d_frame.upload(frame);\n\n    d_result.download(h_result);\n    imshow(\"Thresholded Image\", h_result); \n    imshow(\"Original\", frame); \n\n    if (waitKey(1) == 'q') \n    {\n      break; \n    }\n  }\n  return 0;\n}\n}\n```", "```py\nlower_range = [110,50,50]\nupper_range = [130,255,255]\n```", "```py\n//Transform image to HSV\ncuda::cvtColor(d_frame, d_frame_hsv, COLOR_BGR2HSV);\n\n//Split HSV 3 channels\ncuda::split(d_frame_hsv, d_frame_shsv);\n\n//Threshold HSV channels for blue color according to range\ncuda::threshold(d_frame_shsv[0], d_thresc[0], 110, 130, THRESH_BINARY);\ncuda::threshold(d_frame_shsv[1], d_thresc[1], 50, 255, THRESH_BINARY);\ncuda::threshold(d_frame_shsv[2], d_thresc[2], 50, 255, THRESH_BINARY);\n\n//Bitwise AND the channels\ncv::cuda::bitwise_and(d_thresc[0], d_thresc[1],d_intermediate);\ncv::cuda::bitwise_and(d_intermediate, d_thresc[2], d_result);\n```", "```py\n#include <cmath>\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n\nusing namespace std;\nusing namespace cv;\nusing namespace cv::cuda;\n\nint main()\n{\n  Mat h_image = imread(\"images/drawing.JPG\",0);\n  if (h_image.empty())\n  {\n    cout << \"can not open image\"<< endl;\n    return -1;\n  }\n  GpuMat d_edge,d_image;\n  Mat h_edge;\n  d_image.upload(h_image);\n  cv::Ptr<cv::cuda::CannyEdgeDetector> Canny_edge = cv::cuda::createCannyEdgeDetector(2.0, 100.0, 3, false);\n  Canny_edge->detect(d_image, d_edge);\n  d_edge.download(h_edge);\n  imshow(\"source\", h_image);\n  imshow(\"detected edges\", h_edge);\n  waitKey(0);\n\n  return 0;\n}\n```", "```py\n#include <cmath>\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n\nusing namespace std;\nusing namespace cv;\nusing namespace cv::cuda;\n\nint main()\n{\n  Mat h_image = imread(\"images/drawing.JPG\",0);\n  if (h_image.empty())\n  {\n    cout << \"can not open image\"<< endl;\n    return -1;\n  }\n\n  Mat h_edge;\n  cv::Canny(h_image, h_edge, 100, 200, 3);\n\n  Mat h_imagec;\n  cv::cvtColor(h_edge, h_imagec, COLOR_GRAY2BGR);\n  Mat h_imageg = h_imagec.clone();\n  GpuMat d_edge, d_lines;\n  d_edge.upload(h_edge);\n  {\n    const int64 start = getTickCount();\n    Ptr<cuda::HoughSegmentDetector> hough = cuda::createHoughSegmentDetector(1.0f, (float) (CV_PI / 180.0f), 50, 5);\n    hough->detect(d_edge, d_lines);\n\n    const double time_elapsed = (getTickCount() - start) / getTickFrequency();\n    cout << \"GPU Time : \" << time_elapsed * 1000 << \" ms\" << endl;\n    cout << \"GPU FPS : \" << (1/time_elapsed) << endl;\n  }\n  vector<Vec4i> lines_g;\n  if (!d_lines.empty())\n  {\n    lines_g.resize(d_lines.cols);\n    Mat h_lines(1, d_lines.cols, CV_32SC4, &lines_g[0]);\n    d_lines.download(h_lines);\n  }\n  for (size_t i = 0; i < lines_g.size(); ++i)\n  {\n    Vec4i line_point = lines_g[i];\n    line(h_imageg, Point(line_point[0], line_point[1]), Point(line_point[2], line_point[3]), Scalar(0, 0, 255), 2, LINE_AA);\n  }\n\n  imshow(\"source\", h_image);\n  imshow(\"detected lines [GPU]\", h_imageg);\n  waitKey(0);\n  return 0;\n}\n```", "```py\nMat h_imagec; \nvector<Vec4i> h_lines;\n{\n  const int64 start = getTickCount();\n  HoughLinesP(h_edge, h_lines, 1, CV_PI / 180, 50, 60, 5);\n  const double time_elapsed = (getTickCount() - start) / getTickFrequency();\n  cout << \"CPU Time : \" << time_elapsed * 1000 << \" ms\" << endl;\n  cout << \"CPU FPS : \" << (1/time_elapsed) << endl;\n}\n\nfor (size_t i = 0; i < h_lines.size(); ++i)\n{\n  Vec4i line_point = h_lines[i];\n  line(h_imagec, Point(line_point[0], line_point[1]), Point(line_point[2], line_point[3]), Scalar(0, 0, 255), 2, LINE_AA);\n}\nimshow(\"detected lines [CPU]\", h_imagec);\n```", "```py\n#include \"opencv2/opencv.hpp\"\n#include <iostream>\n\nusing namespace cv;\nusing namespace std;\n\nint main(int argc, char** argv)\n{\n  Mat h_image = imread(\"images/eight.tif\", IMREAD_COLOR);\n  Mat h_gray;\n  cvtColor(h_image, h_gray, COLOR_BGR2GRAY);\n  cuda::GpuMat d_gray,d_result;\n  std::vector<cv::Vec3f> d_Circles;\ncv::Ptr<cv::cuda::HoughCirclesDetector> detector = cv::cuda::createHoughCirclesDetector(1, 100, 122, 50, 1, max(h_image.size().width, h_image.size().height));\n  d_gray.upload(h_gray);\n  detector->detect(d_gray, d_result);\n  d_Circles.resize(d_result.size().width);\n  if (!d_Circles.empty())\n    d_result.row(0).download(cv::Mat(d_Circles).reshape(3, 1));\n\n  cout<<\"No of circles: \" <<d_Circles.size() <<endl;\n  for( size_t i = 0; i < d_Circles.size(); i++ )\n  {\n    Vec3i cir = d_Circles[i];\n    circle( h_image, Point(cir[0], cir[1]), cir[2], Scalar(255,0,0), 2, LINE_AA);\n  }\n  imshow(\"detected circles\", h_image);\n  waitKey(0);\n\n  return 0;\n}\n```", "```py\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main()\n{\n  Mat h_image = imread( \"images/drawing.JPG\", 0 );\n\n  //Detect the key-points using FAST Detector\n  cv::Ptr<cv::cuda::FastFeatureDetector> detector = cv::cuda::FastFeatureDetector::create(100,true,2);\n  std::vector<cv::key point> key-points;\n  cv::cuda::GpuMat d_image;\n  d_image.upload(h_image);\n  detector->detect(d_image, key-points);\n  cv::drawkey-points(h_image,key-points,h_image);\n  //Show detected key-points\n  imshow(\"Final Result\", h_image );\n  waitKey(0);\n  return 0;\n}\n```", "```py\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main()\n{\n  Mat h_image = imread( \"images/drawing.JPG\", 0 );\n  cv::Ptr<cv::cuda::ORB> detector = cv::cuda::ORB::create();\n  std::vector<cv::key point> key-points;\n  cv::cuda::GpuMat d_image;\n  d_image.upload(h_image);\n  detector->detect(d_image, key-points);\n  cv::drawkey-points(h_image,key-points,h_image);\n  imshow(\"Final Result\", h_image );\n  waitKey(0);\n  return 0;\n}\n```", "```py\n#include <stdio.h>\n#include <iostream>\n#include \"opencv2/opencv.hpp\"\n#include \"opencv2/features2d.hpp\"\n#include \"opencv2/xfeatures2d.hpp\"\n#include \"opencv2/xfeatures2d/nonfree.hpp\"\n#include \"opencv2/xfeatures2d/cuda.hpp\"\n\nusing namespace cv;\nusing namespace cv::xfeatures2d;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n  Mat h_object_image = imread( \"images/object1.jpg\", 0 ); \n  Mat h_scene_image = imread( \"images/scene1.jpg\", 0 );\n  cuda::GpuMat d_object_image;\n  cuda::GpuMat d_scene_image;\n  cuda::GpuMat d_key-points_scene, d_key-points_object; \n  vector< key point > h_key-points_scene, h_key-points_object;\n  cuda::GpuMat d_descriptors_scene, d_descriptors_object;\n  d_object_image.upload(h_object_image);\n  d_scene_image.upload(h_scene_image);\n  cuda::SURF_CUDA surf(150);\n  surf( d_object_image, cuda::GpuMat(), d_key-points_object, d_descriptors_object );\nsurf( d_scene_image, cuda::GpuMat(), d_key-points_scene, d_descriptors_scene );\n\nPtr< cuda::DescriptorMatcher > matcher = cuda::DescriptorMatcher::createBFMatcher();\nvector< vector< DMatch> > d_matches;\nmatcher->knnMatch(d_descriptors_object, d_descriptors_scene, d_matches, 3);\nsurf.downloadkey-points(d_key-points_scene, h_key-points_scene);\nsurf.downloadkey-points(d_key-points_object, h_key-points_object);\nstd::vector< DMatch > good_matches;\nfor (int k = 0; k < std::min(h_key-points_object.size()-1, d_matches.size()); k++)\n{\n  if ( (d_matches[k][0].distance < 0.75*(d_matches[k][1].distance)) &&\n      ((int)d_matches[k].size() <= 2 && (int)d_matches[k].size()>0) )\n  {\n    good_matches.push_back(d_matches[k][0]);\n  }\n}\nstd::cout << \"size:\" <<good_matches.size();\nMat h_image_result;\ndrawMatches( h_object_image, h_key-points_object, h_scene_image, h_key-points_scene,\n      good_matches, h_image_result, Scalar::all(-1), Scalar::all(-1),\n      vector<char>(), DrawMatchesFlags::DEFAULT );\nimshow(\"Good Matches & Object detection\", h_image_result);\nwaitKey(0);\nreturn 0;\n}\n```", "```py\nstd::vector<Point2f> object;\nstd::vector<Point2f> scene;\nfor (int i = 0; i < good_matches.size(); i++) {\n  object.push_back(h_key-points_object[good_matches[i].queryIdx].pt);\n  scene.push_back(h_key-points_scene[good_matches[i].trainIdx].pt);\n}\nMat Homo = findHomography(object, scene, RANSAC);\nstd::vector<Point2f> corners(4);\nstd::vector<Point2f> scene_corners(4);\ncorners[0] = Point(0, 0);\ncorners[1] = Point(h_object_image.cols, 0);\ncorners[2] = Point(h_object_image.cols, h_object_image.rows);\ncorners[3] = Point(0, h_object_image.rows);\nperspectiveTransform(corners, scene_corners, Homo);\nline(h_image_result, scene_corners[0] + Point2f(h_object_image.cols, 0),scene_corners[1] + Point2f(h_object_image.cols, 0), Scalar(255, 0, 0), 4);\nline(h_image_result, scene_corners[1] + Point2f(h_object_image.cols, 0),scene_corners[2] + Point2f(h_object_image.cols, 0),Scalar(255, 0, 0), 4);\nline(h_image_result, scene_corners[2] + Point2f(h_object_image.cols, 0),scene_corners[3] + Point2f(h_object_image.cols, 0),Scalar(255, 0, 0), 4);\nline(h_image_result, scene_corners[3] + Point2f(h_object_image.cols, 0),scene_corners[0] + Point2f(h_object_image.cols, 0),Scalar(255, 0, 0), 4);\n```", "```py\n#include \"opencv2/objdetect/objdetect.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include \"opencv2/cudaobjdetect.hpp\" \n#include <iostream>\n#include <stdio.h>\n\nusing namespace std;\nusing namespace cv;\n\nint main( )\n{\n  Mat h_image;\n  h_image = imread(\"images/lena_color_512.tif\", 0); \n  Ptr<cuda::CascadeClassifier> cascade = cuda::CascadeClassifier::create(\"haarcascade_frontalface_alt2.xml\");\n  cuda::GpuMat d_image;\n  cuda::GpuMat d_buf;\n  d_image.upload(h_image);\n  cascade->detectMultiScale(d_image, d_buf);\n  std::vector<Rect> detections;\n  cascade->convert(d_buf, detections);\n  if (detections.empty())\n    std::cout << \"No detection.\" << std::endl;\n  cvtColor(h_image,h_image,COLOR_GRAY2BGR);\n  for(int i = 0; i < detections.size(); ++i)\n  {\n    rectangle(h_image, detections[i], Scalar(0,255,255), 5);\n  }\n  imshow(\"Result image\", h_image);\n  waitKey(0); \n  return 0;\n}\n```", "```py\ncascade->setMinNeighbors(0);\ncascade->setScaleFactor(1.01);\n```", "```py\n#include <iostream>\n#include <opencv2/opencv.hpp>\nusing namespace cv;\nusing namespace std;\n\nint main()\n{\n  VideoCapture cap(0);\n  if (!cap.isOpened()) {\n    cerr << \"Can not open video source\";\n    return -1;\n  }\n  std::vector<cv::Rect> h_found;\n  cv::Ptr<cv::cuda::CascadeClassifier> cascade = cv::cuda::CascadeClassifier::create(\"haarcascade_frontalface_alt2.xml\");\n  cv::cuda::GpuMat d_frame, d_gray, d_found;\n  while(1)\n  {\n    Mat frame;\n    if ( !cap.read(frame) ) {\n      cerr << \"Can not read frame from webcam\";\n      return -1;\n    }\n    d_frame.upload(frame);\n    cv::cuda::cvtColor(d_frame, d_gray, cv::COLOR_BGR2GRAY);\n\n    cascade->detectMultiScale(d_gray, d_found);\n    cascade->convert(d_found, h_found);\n\n    for(int i = 0; i < h_found.size(); ++i)\n    {\n      rectangle(frame, h_found[i], Scalar(0,255,255), 5);\n    }\n\n    imshow(\"Result\", frame);\n    if (waitKey(1) == 'q') {\n      break;\n    }\n  }\n\n  return 0;\n}\n```", "```py\n#include <iostream>\n#include <stdio.h>\n #include <opencv2/opencv.hpp>\n\nusing namespace std;\nusing namespace cv;\n\nint main( )\n{\n  Mat h_image;\n  h_image = imread(\"images/lena_color_512.tif\", 0); \n  Ptr<cuda::CascadeClassifier> cascade = cuda::CascadeClassifier::create(\"haarcascade_eye.xml\");\n  cuda::GpuMat d_image;\n  cuda::GpuMat d_buf;\n  d_image.upload(h_image);\n  cascade->setScaleFactor(1.02);\n  cascade->detectMultiScale(d_image, d_buf);\n  std::vector<Rect> detections;\n  cascade->convert(d_buf, detections);\n  if (detections.empty())\n    std::cout << \"No detection.\" << std::endl;\n    cvtColor(h_image,h_image,COLOR_GRAY2BGR);\n    for(int i = 0; i < detections.size(); ++i)\n    {\n      rectangle(h_image, detections[i], Scalar(0,255,255), 5);\n    }\n\n    imshow(\"Result image\", h_image);\n\n    waitKey(0); \n    return 0;\n  }\n}\n```", "```py\n#include <iostream>\n#include <string>\n#include \"opencv2/opencv.hpp\"\nusing namespace std;\nusing namespace cv;\nusing namespace cv::cuda;\nint main()\n{\n  VideoCapture cap(\"abc.avi\");\n  if (!cap.isOpened())\n  {\n    cerr << \"can not open camera or video file\" << endl;\n    return -1;\n  }\n  Mat frame;\n  cap.read(frame);\n  GpuMat d_frame;\n  d_frame.upload(frame);\n  Ptr<BackgroundSubtractor> mog = cuda::createBackgroundSubtractorMOG();\n  GpuMat d_fgmask,d_fgimage,d_bgimage;\n  Mat h_fgmask,h_fgimage,h_bgimage;\n  mog->apply(d_frame, d_fgmask, 0.01);\n  while(1)\n  {\n    cap.read(frame);\n    if (frame.empty())\n      break;\n    d_frame.upload(frame);\n    int64 start = cv::getTickCount();\n    mog->apply(d_frame, d_fgmask, 0.01);\n    mog->getBackgroundImage(d_bgimage);\n    double fps = cv::getTickFrequency() / (cv::getTickCount() - start);\n    std::cout << \"FPS : \" << fps << std::endl;\n    d_fgimage.create(d_frame.size(), d_frame.type());\n    d_fgimage.setTo(Scalar::all(0));\n    d_frame.copyTo(d_fgimage, d_fgmask);\n    d_fgmask.download(h_fgmask);\n    d_fgimage.download(h_fgimage);\n    d_bgimage.download(h_bgimage);\n    imshow(\"image\", frame);\n    imshow(\"foreground mask\", h_fgmask);\n    imshow(\"foreground image\", h_fgimage);\n    imshow(\"mean background image\", h_bgimage);\n    if (waitKey(1) == 'q')\n      break;\n  }\n\n  return 0;\n}\n```", "```py\n#include <iostream>\n#include <string>\n#include \"opencv2/opencv.hpp\"\n#include \"opencv2/core.hpp\"\n#include \"opencv2/core/utility.hpp\"\n#include \"opencv2/cudabgsegm.hpp\"\n#include \"opencv2/cudalegacy.hpp\"\n#include \"opencv2/video.hpp\"\n#include \"opencv2/highgui.hpp\"\n\nusing namespace std;\nusing namespace cv;\nusing namespace cv::cuda;\n\nint main()\n{\n  VideoCapture cap(\"abc.avi\");\n  if (!cap.isOpened())\n  {\n    cerr << \"can not open video file\" << endl;\n    return -1;\n  }\n  Mat frame;\n  cap.read(frame);\n  GpuMat d_frame;\n  d_frame.upload(frame);\n  Ptr<BackgroundSubtractor> gmg = cuda::createBackgroundSubtractorGMG(40);\n  GpuMat d_fgmask,d_fgimage,d_bgimage;\n  Mat h_fgmask,h_fgimage,h_bgimage;\n  gmg->apply(d_frame, d_fgmask);\n  while(1)\n  {\n    cap.read(frame);\n    if (frame.empty())\n      break;\n    d_frame.upload(frame);\n    int64 start = cv::getTickCount();\n    gmg->apply(d_frame, d_fgmask, 0.01);\n    double fps = cv::getTickFrequency() / (cv::getTickCount() - start);\n    std::cout << \"FPS : \" << fps << std::endl;\n    d_fgimage.create(d_frame.size(), d_frame.type());\n    d_fgimage.setTo(Scalar::all(0));\n    d_frame.copyTo(d_fgimage, d_fgmask);\n    d_fgmask.download(h_fgmask);\n    d_fgimage.download(h_fgimage);\n    imshow(\"image\", frame);\n    imshow(\"foreground mask\", h_fgmask);\n    imshow(\"foreground image\", h_fgimage);\n    if (waitKey(30) == 'q')\n      break;\n  }\n  return 0;\n}\n```"]