- en: Chapter 7. Extracting Lines, Contours, and Components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting image contours with the Canny operator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting lines in images with the Hough transform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting a line to a set of points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting connected components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing components' shape descriptors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to perform content-based analysis of an image, it is necessary to extract
    meaningful features from the collection of pixels that constitute the image. Contours,
    lines, blobs, and so on, are fundamental image primitives that can be used to
    describe the elements contained in an image. This chapter will teach you how to
    extract some of these image primitives.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting image contours with the Canny operator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how it is possible to detect the edges of
    an image. In particular, we showed you that by applying a threshold to the gradient
    magnitude, a binary map of the main edges of an image can be obtained. Edges carry
    important visual information since they delineate the image elements. For this
    reason, they can be used, for example, in object recognition. However, simple
    binary edge maps suffer from two main drawbacks. First, the edges that are detected
    are unnecessarily thick; this makes the object's limits more difficult to identify.
    Second, and more importantly, it is often impossible to find a threshold that
    is sufficiently low in order to detect all important edges of an image and is,
    at the same time, sufficiently high in order to not include too many insignificant
    edges. This is a trade-off problem that the **Canny** algorithm tries to solve.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Canny algorithm is implemented in OpenCV by the `cv::Canny` function. As
    will be explained, this algorithm requires the specification of two thresholds.
    The call to the function is, therefore, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When the algorithm is applied on the preceding image, the result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that here we have inverted the contour representation since the normal
    result represents contours by non-zero pixels. The displayed image is simply `255-contours`.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Canny operator is generally based on the Sobel operator that was presented
    in [Chapter 6](ch06.html "Chapter 6. Filtering the Images") , *Filtering the Images*,
    although other gradient operators can also be used. The key idea here is to use
    two different thresholds in order to determine which point should belong to a
    contour: a low and a high threshold.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The low threshold should be chosen in a way that it includes all edge pixels
    that are considered to belong to a significant image contour. For example, using
    the low-threshold value specified in the example of the preceding section and
    applying it on the result of a Sobel operator, the following edge map is obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As can be seen, the edges that delineate the road are very well defined. However,
    because a permissive threshold was used, more edges than what is ideally needed
    are also detected. The role of the second threshold, then, is to define the edges
    that belong to all important contours. It should exclude all edges considered
    as outliers. For example, the Sobel edge map that corresponds to the high threshold
    used in our example is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We now have an image that contains broken edges, but the ones that are visible
    certainly belong to the significant contours of the scene. The Canny algorithm
    combines these two edge maps in order to produce an optimal map of contours. It
    operates by keeping only the edge points of the low-threshold edge map for which
    a continuous path of edges exists, linking those edge points to an edge that belongs
    to the high-threshold edge map. Consequently, all edge points of the high-threshold
    map are kept, while all isolated chains of edge points in the low-threshold map
    are removed. The solution that is obtained constitutes a good compromise, allowing
    good quality contours to be obtained as long as appropriate threshold values are
    specified. This strategy, based on the use of two thresholds to obtain a binary
    map, is called **hysteresis thresholding**, and can be used in any context where
    a binary map needs to be obtained from a thresholding operation. However, this
    is done at the cost of higher computational complexity.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the Canny algorithm uses an extra strategy to improve the quality
    of the edge map. Prior to the application of the hysteresis thresholding, all
    edge points for which the gradient magnitude is not a maximum in the gradient
    direction are removed (recall that the gradient orientation is always perpendicular
    to the edge). Therefore, the local maximum of the gradient in this direction corresponds
    to the point of maximum strength of the contour. This is a contour thinning operation
    that creates edges having a width of 1 pixel. This explains why thin edges are
    obtained in the Canny contour maps.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The classic article by *J. Canny*, *A computational approach to edge detection,
    IEEE Transactions on Pattern Analysis and Image Understanding, vol. 18, issue
    6, 1986*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting lines in images with the Hough transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our human-made world, planar and linear structures abound. As a result, straight
    lines are frequently visible in images. These are meaningful features that play
    an important role in object recognition and image understanding. The **Hough transform**
    is a classic algorithm that is often used to detect these particular features
    in images. It was initially developed to detect lines in images and, as we will
    see, it can also be extended to detect other simple image structures.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the Hough transform, lines are represented using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/image_07_005-2-300x54.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `ρ` parameter is the distance between the line and the image origin (the
    upper-left corner), and `θ` is the angle of the perpendicular to the line. In
    this representation, the lines visible in an image have a `θ` angle between `0`
    and `π` radians, while the `ρ` radius can have a maximum value that equals the
    length of the image diagonal. Consider, for example, the following set of lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/image_07_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A vertical line such as line **1** has a `θ` angle value equal to zero, while
    a horizontal line (for example, line **5**) has its `θ` value equal to `π/2`.
    Therefore, line **3** has an angle `θ` equal to `π/4`, and line **4** is at `0.7π`
    approximately. In order to be able to represent all possible lines with `θ` in
    the `[0, π]` interval, the radius value can be made negative. This is the case
    with line **2**, which has a `θ` value equal to `0.8π` with a negative value for
    `ρ`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV offers two implementations of the Hough transform for line detection.
    The basic version is `cv::HoughLines`. Its input is a binary map that contains
    a set of points (represented by non-zero pixels), some of which are aligned to
    form lines. Usually, this is an edge map obtained, for example, from the Canny
    operator. The output of the `cv::HoughLines` function is a vector of `cv::Vec2f`
    elements, each of them being a pair of floating point values, representing the
    parameters of a detected line, `(ρ,θ)`. The following is an example of using this
    function where we first apply the Canny operator to obtain the image contours
    and then detect the lines using the Hough transform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Parameters 3 and 4 correspond to the step size for the line search. In our
    example, the function will search for lines of all possible radii by steps of
    `1` and all possible angles by steps of `π/180`. The role of the last parameter
    will be explained in the next section. With this particular choice of parameter
    values, several lines are detected on the road image of the preceding recipe.
    In order to visualize the result of the detection, it is interesting to draw these
    lines on the original image. However, it is important to note that this algorithm
    detects lines in an image and not line segments, since the endpoints of each line
    are not given. Consequently, we will draw lines that traverse the entire image.
    To do this, for a vertically oriented line, we calculate its intersection with
    the horizontal limits of the image (that is, the first and last rows) and draw
    a line between these two points. We proceed similarly with horizontally-oriented
    lines but using the first and last columns. Lines are drawn using the `cv::line`
    function. Note that this function works well even with point coordinates outside
    the image limits. Therefore, there is no need to check whether the computed intersection
    points fall within the image. Lines are then drawn by iterating over the line
    vector as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen, the Hough transform simply looks for an alignment of edge pixels
    across the image. This can potentially create some false detections due to incidental
    pixel alignments or multiple detections when several lines with slightly different
    parameter values pass through the same alignment of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'To overcome some of these problems, and to allow line segments to be detected
    (that is, with endpoints), a variant of the transform has been proposed. This
    is the Probabilistic Hough transform, and it is implemented in OpenCV as the `cv::HoughLinesP`
    function. We use it here to create our `LineFinder` class, which encapsulates
    the function parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the corresponding setter methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'With the preceding method, the method that performs Hough line segment detection
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This method returns a vector of `cv::Vec4i`, which contains the start and endpoint
    coordinates of each detected segment. The detected lines can then be drawn on
    an image with the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, using the same input image, lines can be detected with the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code gives the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The objective of the Hough transform is to find all lines in a binary image
    that pass through a sufficient number of points. It proceeds by considering each
    individual pixel point in the input binary map and identifying all possible lines
    that pass through it. When the same line passes through many points, it means
    that this line is significant enough to be considered.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Hough transform uses a two-dimensional accumulator in order to count how
    many times a given line is identified. The size of this accumulator is defined
    by the specified step sizes (as mentioned in the preceding section) of the `(ρ,θ)`
    parameters of the adopted line representation. To illustrate the functioning of
    the transform, let''s create a `180` by `200` matrix (corresponding to a step
    size of `π/180` for `θ` and `1` for `ρ`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This accumulator is a mapping of different `(ρ,θ)` values. Therefore, each
    entry of this matrix corresponds to one particular line. Now, if we consider one
    point, let''s say one at `(50,30)`, then it is possible to identify all lines
    that pass through this point by looping over all possible `θ` angles (with a step
    size of `π/180`) and computing the corresponding (rounded) `ρ` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The entries of the accumulator corresponding to the computed `(ρ,θ)` pairs
    are then incremented, signifying that all of these lines pass through one point
    of the image (or, to say it another way, each point votes for a set of possible
    candidate lines). If we display the accumulator as an image (inverted and multiplied
    by `100` to make the count of `1` visible), we obtain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding curve represents the set of all lines that pass through the specified
    point. Now, if we repeat the same exercise with, let''s say, point `(30,10)`,
    we now have the following accumulator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As can be seen, the two resulting curves intersect at one point: the point
    that corresponds to the line that passes through these two points. The corresponding
    entry of the accumulator receives two votes, indicating that two points pass through
    this line.'
  prefs: []
  type: TYPE_NORMAL
- en: If the same process is repeated for all points of a binary map, then points
    aligned along a given line will increase a common entry of the accumulator many
    times. At the end, you just need to identify the local maxima in this accumulator
    that receives a significant number of votes in order to detect the lines (that
    is, point alignments) in the image. The last parameter specified in the `cv::HoughLines`
    function corresponds to the minimum number of votes that a line must receive to
    be considered as detected. This means that the lower this minimum number of votes
    is, then the higher the number of detected lines will be.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we lower this value to `50` in the case of our road example,
    then the following lines are now detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Probabilistic Hough transform adds a few modifications to the basic algorithm.
    First, instead of systematically scanning the image row-by-row, points are chosen
    in random order in the binary map. Whenever an entry of the accumulator reaches
    the specified minimum value, the image is scanned along the corresponding line
    and all points that pass through it are removed (even if they have not voted yet).
    This scanning also determines the length of the segments that will be accepted.
    For this, the algorithm defines two additional parameters. One is the minimum
    length for a segment to be accepted, and the other is the maximum pixel gap that
    is permitted to form a continuous segment. This additional step increases the
    complexity of the algorithm, but this is partly compensated by the fact that fewer
    points will be involved in the voting process, as some of them are eliminated
    by the line-scanning process.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Hough transform can also be used to detect other geometrical entities. In
    fact, any entity that can be represented by a parametric equation is a good candidate
    for the Hough transform. There is also a Generalized Hough transform that can
    detect objects of any shape.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting circles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the case of circles, the corresponding parametric equation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting circles](img/B05388_07_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This equation includes three parameters (the circle radius and center coordinates),
    which means that a three-dimensional accumulator would be required. However, it
    is generally found that the Hough transform becomes more complex and less reliable
    as the dimensionality of its accumulator increases. Indeed, in this case, a large
    number of entries of the accumulator will be incremented for each point and, as
    a consequence, the accurate localization of local peaks becomes more difficult.
    Different strategies have been proposed in order to overcome this problem. The
    strategy used in the OpenCV implementation of the Hough circle detection uses
    two passes. During the first pass, a two-dimensional accumulator is used to find
    candidate circle locations. Since the gradient of points on the circumference
    of a circle should point in the direction of the radius, for each point, only
    the entries in the accumulator along the gradient direction are incremented (based
    on predefined minimum and maximum radius values). Once a possible circle center
    is detected (that is, has received a predefined number of votes), a 1D histogram
    of a possible radius is built during the second pass. The peak value in this histogram
    corresponds to the radius of the detected circles.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cv::HoughCircles` function that implements the preceding strategy integrates
    both the Canny detection and the Hough transform. It is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that it is always recommended that you smooth the image before calling
    the `cv::HoughCircles` function in order to reduce the image noise that could
    cause several false circle detections. The result of the detection is given in
    a vector of `cv::Vec3f` instances. The first two values are the circle center
    coordinates and the third is the radius.
  prefs: []
  type: TYPE_NORMAL
- en: The `cv::HOUGH_GRADIENT` argument was the only option available at the time
    of writing. It corresponds to the two-pass circle detection method. The fourth
    parameter defines the accumulator resolution. It is a divider factor; specifying
    a value of `2`, for example, makes the accumulator half the size of the image.
    The next parameter is the minimum distance in pixels between two detected circles.
    The other parameter corresponds to the high threshold of the Canny edge detector.
    The low-threshold value is always set at half this value. The seventh parameter
    is the minimum number of votes that a center location must receive during the
    first pass to be considered as a candidate circle for the second pass. Finally,
    the last two parameters are the minimum and maximum radius values for the circles
    to be detected. As can be seen, the function includes many parameters that make
    it difficult to tune.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the vector of detected circles is obtained, these circles can be drawn
    on the image by iterating over the vector and calling the `cv::circle` drawing
    function with the obtained parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the result obtained on a test image with the chosen arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Detecting circles](img/image_07_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following article, *Gradient-based Progressive Probabilistic Hough Transform*
    by *C. Galambos*, *J. Kittler*, and *J. Matas, IEE Vision Image and Signal Processing*,
    *vol. 148 no 3, pp. 158-165, 2002*, is one of the numerous references on the Hough
    transform and describes the probabilistic algorithm implemented in OpenCV.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following article, *Comparative Study of Hough Transform Methods for Circle
    Finding, Image and Vision Computing*, *vol. 8 no 1, pp. 71-77, 1990*, by *H.K.
    Yuen*, *J. Princen*, *J. Illingworth*, and *J Kittler*, describes different strategies
    for circle detection using the Hough transform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting a line to a set of points
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some applications, it could be important to not only detect lines in an image,
    but also to obtain an accurate estimate of the line's position and orientation.
    This recipe will show you how to estimate the exact line that best fits a given
    set of points.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing to do is to identify points in an image that seem to be aligned
    along a straight line. Let''s use one of the lines we detected in the preceding
    recipe. The lines detected using `cv::HoughLinesP` are contained in `std::vector<cv::Vec4i>`
    called `lines`. To extract the set of points that seem to belong to, let''s say,
    the first of these lines, we can proceed as follows. We draw a white line on a
    black image and intersect it with the Canny image of `contours` used to detect
    our lines. This is simply achieved by the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The result is an image that contains points that could be associated with the
    specified line. In order to introduce some tolerance, we draw a line of a certain
    thickness (here, `3`). All points inside the defined neighborhood are, therefore,
    accepted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the image that is obtained (inverted for better viewing):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The coordinates of the points in this set can then be inserted in a `std::vector`
    of `cv::Point` objects (floating point coordinates, that is, `cv::Point2f`, can
    also be used) with the following double loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a list of points and we want to fit a line passing through these
    points. This best fitting line is easily found by calling the `cv::fitLine` OpenCV
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code gives us the parameters of the line equation in the form
    of a unit-directional vector (the first two values of `cv::Vec4f`) and the coordinates
    of one point on the line (the last two values of `cv::Vec4f`). The last two parameters
    specify the requested accuracy for the line parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the line equation will be used in the calculation of some properties
    (calibration is a good example where precise parametric representation is required).
    As an illustration, and to make sure we calculated the right line, let''s draw
    the estimated line on the image. Here, we simply draw an arbitrary black segment
    that has a length of `100` pixels and a thickness of `2` pixels (to make it visible):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image shows this line well aligned with one of the road''s sides:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fitting lines to a set of points is a classic problem in mathematics. The OpenCV
    implementation proceeds by minimizing the sum of the distances from each point
    to the line. Several distance functions are proposed, and the fastest option is
    to use the Euclidean distance, which is specified by `cv::DIST_L2`. This choice
    corresponds to the standard least-squares line fitting. When outliers (that is,
    points that don't belong on the line) are included in the point set, other distance
    functions that give less influence to far points can be selected. The minimization
    is based on the M-estimator technique, which iteratively solves a weighted least-squares
    problem with weights that are inversely proportional to the distance from the
    line.
  prefs: []
  type: TYPE_NORMAL
- en: Using this function, it is also possible to fit a line to a 3D point set. The
    input is, in this case, a set of `cv::Point3i` or `cv::Point3f` objects, and the
    output is a `std::Vec6f` instance.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `cv::fitEllipse` function fits an ellipse to a set of 2D points. This returns
    a rotated rectangle (a `cv::RotatedRect` instance), inside which the ellipse is
    inscribed. In this case, you would write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `cv::ellipse` function is the one you would use to draw the computed ellipse.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting connected components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Images generally contain representations of objects. One of the goals of image
    analysis is to identify and extract these objects. In object detection/recognition
    applications, the first step is often to produce a binary image that shows you
    where certain objects of interest could be located. No matter how this binary
    map is obtained (for example, from the histogram back projection we performed
    in [Chapter 4](ch04.html "Chapter 4. Counting the Pixels with Histograms") , *Counting
    the Pixels with Histograms*, or from motion analysis as we will learn in [Chapter
    12](ch12.html "Chapter 12. Processing Video Sequences") , *Processing Video Sequences*),
    the next step is to extract the objects that are contained in this collection
    of 1s and 0s.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider, for example, the image of buffaloes in a binary form that we manipulated
    in [Chapter 5](ch05.html "Chapter 5. Transforming Images with Morphological Operations")
    , *Transforming Images with Morphological Operations*, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Extracting connected components](img/image_07_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We obtained this image from a simple thresholding operation followed by the
    application of morphological filters. This recipe will show you how to extract
    the objects of such images. More specifically, we will extract the connected components,
    that is, shapes made of a set of connected pixels in a binary image.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV offers a simple function that extracts the contours of the connected
    components of an image. This is the `cv::findContours` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The input is obviously the binary image. The output is a vector of contours,
    each contour being represented by a vector of `cv::Point` objects. This explains
    why the output parameter is defined as a `std::vector` instance of the `std::vector`
    instances. In addition, two flags are specified. The first one indicates that
    only the external contours are required, that is, holes in an object will be ignored
    (the *There's more...* section will discuss the other options).
  prefs: []
  type: TYPE_NORMAL
- en: The second flag is there to specify the format of the contour. With the current
    option, the vector will list all of the points in the contour. With the `cv::CHAIN_APPROX_SIMPLE`
    flag, only the endpoints for horizontal, vertical, or diagonal contours will be
    included. Other flags would give a more sophisticated chain approximation of the
    contours in order to obtain a more compact representation. With the preceding
    image, nine connected components are obtained as given by `contours.size()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, there is a very convenient function that can draw the contours
    of those components on an image (here, a white image):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If the third parameter of this function is a negative value, then all contours
    are drawn. Otherwise, it is possible to specify the index of the contour to be
    drawn. The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The contours are extracted by a simple algorithm that consists of systematically
    scanning the image until a component is hit. From this starting point on the component,
    its contour is followed, marking the pixels on its border. When the contour is
    completed, the scanning resumes at the last position until a new component is
    found.
  prefs: []
  type: TYPE_NORMAL
- en: 'The identified connected components can then be individually analyzed. For
    example, if some prior knowledge is available about the expected size of the objects
    of interest, it becomes possible to eliminate some of the components. Let''s then
    use a minimum and a maximum value for the perimeter of the components. This is
    done by iterating over the vector of contours and eliminating the invalid components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note that this loop could have been made more efficient since each erasing operation
    in a `std::vector` instance is O(N). However, considering the small size of this
    vector, the overall cost is not too high.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we draw the remaining contours on the original image and obtain
    the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/image_07_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We were lucky enough to find a simple criterion that allowed us to identify
    all objects of interest in this image. In more complex situations, a more refined
    analysis of the components' properties is required. This is the object of the
    next recipe, *Computing components' shape descriptors*.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the `cv::findContours` function, it is also possible to include all closed
    contours in the binary map, including the ones formed by holes in the components.
    This is done by specifying another flag in the function call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With this call, the following contours are obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more...](img/image_07_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice the extra contours that were added in the background forest. It is also
    possible to have these contours organized into a hierarchy. The main component
    is the parent, holes in it are its children, and if there are components inside
    these holes, they become the children of the previous children, and so on. This
    hierarchy is obtained by using the `cv::RETR_TREE` flag, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In this case, each contour has a corresponding hierarchy element at the same
    index, made of four integers. The first two integers give you the index of the
    next and the previous contours of the same level, and the next two integers give
    you the index of the first child and the parent of this contour. A negative index
    indicates the end of a contour list. The `cv::RETR_CCOMP` flag is similar but
    limits the hierarchy at two levels.
  prefs: []
  type: TYPE_NORMAL
- en: Computing components' shape descriptors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A connected component often corresponds to the image of an object in a pictured
    scene. To identify this object, or to compare it with other image elements, it
    can be useful to perform some measurements on the component in order to extract
    some of its characteristics. In this recipe, we will look at some of the shape
    descriptors available in OpenCV that can be used to describe the shape of a connected
    component.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many OpenCV functions are available when it comes to shape description. We will
    apply some of them on the components that we have extracted in the preceding recipe.
    In particular, we will use our vector of four contours corresponding to the four
    buffaloes we previously identified. In the following code snippets, we compute
    a shape descriptor on the contours (`contours[0]` to `contours[3]`) and draw the
    result (with a thickness of `2`) over the image of the contours (with a thickness
    of `1`). This image is shown at the end of this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is the bounding box, which is applied to the bottom-right component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The minimum enclosing circle is similar. It is applied to the upper-right component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The polygonal approximation of a component''s contour is computed as follows
    (on the left-hand component):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Notice the polygon drawing function, `cv::polylines`. This operates similarly
    to the other drawing functions. The third Boolean parameter is used to indicate
    whether the contour is closed or not (if yes, the last point is linked to the
    first one).
  prefs: []
  type: TYPE_NORMAL
- en: 'The convex hull is another form of polygonal approximation (on the second component
    from the left):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the computation of the moments is another powerful descriptor (the
    center of mass is drawn inside all components):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/image_07_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bounding box of a component is probably the most compact way to represent
    and localize a component in an image. It is defined as the upright rectangle of
    minimum size that completely contains the shape. Comparing the height and width
    of the box gives you an indication about the vertical or horizontal dimensions
    of the object (for example, one could use a height-to-width ratio in order to
    distinguish an image of a car from one of a pedestrian). The minimum enclosing
    circle is generally used when only the approximate component size and location
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: The polygonal approximation of a component is useful when one wants to manipulate
    a more compact representation that resembles the component's shape. It is created
    by specifying an accuracy parameter, giving you the maximal acceptable distance
    between a shape and its simplified polygon. It is the fourth parameter in the
    `cv::approxPolyDP` function. The result is a vector of `cv::Point`, which corresponds
    to the vertices of the polygon. To draw this polygon, we need to iterate over
    the vector and link each point with the next one by drawing a line between them.
  prefs: []
  type: TYPE_NORMAL
- en: The convex hull, or convex envelope, of a shape is the minimal convex polygon
    that encompasses a shape. It can be visualized as the shape that an elastic band
    would take if placed around the component. As can be seen, the convex hull contour
    will deviate from the original one at the concave locations of the shape contour.
  prefs: []
  type: TYPE_NORMAL
- en: 'These locations are often designated as convexity defects, and a special OpenCV
    function is available to identify them: the `cv::convexityDefects` function. It
    is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `contour` and `hull` arguments are, respectively, the original and the convex
    hull contours (both represented with `std::vector<cv::Point>` instances). The
    output is a vector of four integer elements. The first two integers are the indices
    of the points on the contour, delimiting the defect; the third integer corresponds
    to the farthest point inside the concavity, and finally, the last integer corresponds
    to the distance between this farthest point and the convex hull.
  prefs: []
  type: TYPE_NORMAL
- en: Moments are commonly used mathematical entities in the structural analysis of
    shapes. OpenCV has defined a data structure that encapsulates all computed moments
    of a shape. It is the object returned by the `cv::moments` function. Together,
    the moments represent a compact description of the shape of an object. They are
    commonly used, for example, in character recognition. We simply use this structure
    to obtain the mass center of each component that is computed from the first three
    spatial moments here.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Other structural properties can be computed using the available OpenCV functions.
    The `cv::minAreaRect` function computes the minimum enclosed rotated rectangle
    (this was used in [Chapter 5](ch05.html "Chapter 5. Transforming Images with Morphological
    Operations") , *Transforming Images with Morphological Operations*, in the *Extracting
    distinctive regions using MSER* recipe). The `cv::contourArea` function estimates
    the area of (the number of pixels inside) a contour. The `cv::pointPolygonTest`
    function determines whether a point is inside or outside a contour, and `cv::matchShapes`
    measures the resemblance between two contours. All these property measures can
    be advantageously combined in order to perform more advanced structural analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Quadrilateral detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The MSER features presented in [Chapter 5](ch05.html "Chapter 5. Transforming
    Images with Morphological Operations") , *Transforming Images with Morphological
    Operations*, constitutes an efficient tool to extract shapes in an image. Considering
    the MSER result obtained in the preceding chapter, we will now build an algorithm
    to detect quadrilateral components in an image. In the case of the current image,
    this detection will allow us to identify the building''s windows. A binary version
    of the MSER image is easily obtained, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, we cleaned the image with a morphological filter. The image is
    then as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Quadrilateral detection](img/image_07_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next step is to obtain the contours:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we go over all the contours and roughly approximate them with a polygon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The quadrilaterals are those polygons that have four edges. The detected ones
    are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Quadrilateral detection](img/image_07_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To detect rectangles, you can simply measure the angles between adjacent edges
    and reject the quadrilaterals that have angles that deviate too much from 90 degrees.
  prefs: []
  type: TYPE_NORMAL
