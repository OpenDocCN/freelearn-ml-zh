<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-133"><a id="_idTextAnchor137"/>8</h1>
<h1 id="_idParaDest-134"><a id="_idTextAnchor138"/>Discrete Models</h1>
<p><a id="_idTextAnchor139"/>In the previous two chapters, we discussed models for predicting a continuous response variable. In this chapter, we will begin discussing models for predicting discrete response variables. We <a id="_idIndexMarker641"/>will start by discussing the probit and logit models for predicting binary outcome variables (categorical variables with two levels). Then, we will extend this idea to predicting categorical variables with multiple levels. Finally, we will look at predicting count variables, which are like categorical variables but only take values of integers and have an infinite number of levels.</p>
<p>In this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>Probit and logit models</li>
<li>Multinomial logit model</li>
<li>Poisson model</li>
<li>The negative binomial regression model</li>
</ul>
<h1 id="_idParaDest-135"><a id="_idTextAnchor140"/>Probit and logit models</h1>
<p>Previously, we <a id="_idIndexMarker642"/>discussed different types of problems that can be solved with regression models. In particular, the dependent variable is continuous, such as house prices, salaries, and so on. A <a id="_idIndexMarker643"/>natural question is if dependent variables are not continuous – in other words, if they are categorical – how would we adapt our regression equation to predict a categorical response variable? For instance, a human resources department in a company wants to conduct an attrition study to predict whether an employee will stay with the company or a car dealership wants to know if one car can be sold or not based on prices, car models, colors, and so on.</p>
<p>First, we will <a id="_idIndexMarker644"/>study <strong class="bold">binary classification</strong>. Here, the outcome (dependent variable) is a binary response such as yes/no or to do/not to do. Let’s look back at the simple linear regression model:</p>
<p>y = β 0 + β 1 x+ ϵ</p>
<p>Here, the predicted<a id="_idIndexMarker645"/> outcome is a line crossing data points. With this model, we could build a model to predict house prices (the dependent variable) based on different<a id="_idIndexMarker646"/> independent variables, such as districts, units, stories, or distances. The same idea cannot be applied to a binary classification problem. Let’s consider a simple example that we want to predict if a house is sold only based on its price. Let’s build a model based on linear regression:</p>
<p>Sold = β 0 + β 1 * Price + ϵ             (1)</p>
<p>Here, Sold = 1 if the house is sold and Sold=0 if it was not sold. By performing visualization using linear regression, we can draw a line of best fit through the data points. It looks like when the price increases, the chance of selling a house decreases:</p>
<div><div><img alt="Figure 8.1 – Line of best fit using linear regression" height="505" src="img/B18945_08_01.jpg" width="1106"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Line of best fit using linear regression</p>
<p>So, instead of considering the equation model (<em class="italic">1</em>), we will be considering the following:</p>
<p>Prob(Sold) = β 0 + β 1 * Price + ϵ</p>
<p>Here, Prob(Sold) is the probability of selling a house. The probability value will be between 0 and 1; the midpoint of its range is 0.5 when the probability of selling a house is equal to the probability of not selling a house. However, when the price of a house is very high, then the value of Prob(Sold) can be negative. To avoid this problem, we can model the problem with the following equation:</p>
<p> P _ 1 − P = β 0 + β 1 * Price+ ϵ  (2)</p>
<p>Here, P is the <a id="_idIndexMarker647"/>probability of selling a house and 1 − P is the probability of not selling a house. The value of  P _ 1 − P is in the range of [0, ∞) and when the probability of selling a car is the same as the probability of not selling a car, (P=0.5), then  P _ 1 − P = 1, or the midpoint of its range is 1. This is also <a id="_idIndexMarker648"/>called the <strong class="bold">odds ratio</strong>. To interpret the odds ratio, when  P _ 1 − P = 1, for every house that is sold, there is a house that is not sold. When P = 0.75, then <a id="_idIndexMarker649"/>the odds ratio is 3. In this case, the interpretation is that the odds of being able to sell the house are three times higher than the odds of not being able to sell the house. Going back to the equation (<em class="italic">2</em>), the range of the odds ratio is [0, ∞) and its lower limit is 0, but as we discussed previously for equation (<em class="italic">1</em>), when the price of a house is really high, then the estimate of the odds ratio could be negative, which contradicts the probability properties. In addition, because the midpoint is 1 but the range of the odds ratio is from 0 to infinity, then the distribution is very skewed with a long right tail. However, we expected it to be normally distributed per one of the assumptions of linear regression. So, instead of using equation (<em class="italic">2</em>), we will consider the following:</p>
<p>log( P _ 1 − P) = β 0 + β 1 * Price + ϵ</p>
<p>The value of log( P _ 1 − P)  is in the range of (− ∞ , ∞) and the midpoint is 0. Similar to linear regression, we can use the following formula:</p>
<p>log(odds) = log( P _ 1 − P) = β 0 + β 1 X 1 + β 2 X 2 + … = z    (3)</p>
<p>We can use this to interpret how the explanatory variables are associated with the categorical outcome. We can rewrite the previous equation (<em class="italic">3</em>) as follows:</p>
<p>F(z) = P =  e z _ 1 + e z ,</p>
<p>The preceding formula is bounded below by 0 and above by 1 (the predicted probability, <em class="italic">P</em>, of the outcome takes place) and is called the logit model. It is the cumulative distribution function <a id="_idIndexMarker650"/>of the <strong class="bold">logistic distribution</strong>.</p>
<p>Another approach to model the probability of a binary dependent<a id="_idIndexMarker651"/> variable is <strong class="bold">probit regression</strong>. Instead<a id="_idIndexMarker652"/> of using the cumulative distribution function of logistic regression, we use the cumulative distribution function of the standard normal distribution:</p>
<p>F(z) =  ∫ −∞ zϕ(u)du = ϕ(z).</p>
<p>The preceding formula is <a id="_idIndexMarker653"/>bounded below by 0 and above by 1 (the predicted probability, <em class="italic">P</em>, of the outcome takes place), and is called the <strong class="bold">probit model</strong>. Remember the following:</p>
<p>ϕ(z) = P(Z ≤ z),   Z~𝒩(0,1).</p>
<p>Both the logit and probit models are estimated by using<a id="_idIndexMarker654"/> the <code>statsmodels</code>, we have classes for the probit and logit models. The documentation for these classes can be found at <a href="https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Probit.xhtml">https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Probit.xhtml</a> and <a href="https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.xhtml">https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.xhtml</a>.</p>
<p>Now, let’s create a training dataset to illustrate how to use the <code>Logit</code> class from <code>statsmodels</code> to conduct a logit study:</p>
<pre class="source-code">
import pandas as pd
# create gpa train data
train = pd.DataFrame({'Admitted': [1, 1, 1,1, 1, 0, 1, 1, 0, 1,1,1, 1,1,0, 1, 0, 0, 0, 0, 0, 0, 0, 0 ,0 ,0, 1,1,1,1, 0],
                    'GPA': [2.8, 3.3, 3.7, 3.7, 3.7, 3.3, 3.7, 3, 1.7, 3.6, 3.3, 4, 3.2, 3.4, 2.8, 4, 1.5, 2.7, 2.3, 2.3, 2.7, 2.2, 3.3,3.3, 4, 2.3, 3.6, 3.4, 4, 3.7, 2.3],
                    'Exp': [8, 6, 5, 5, 6, 3, 4, 2, 1, 5, 5, 3, 6,5, 4, 4, 4, 1, 1, 2, 2, 2, 1, 4, 4, 4, 5, 2, 4, 6, 3]})
train.head()</pre>
<p>Here, <code>Admitted</code> is the dependent variable and has two possibilities (1 – admitted and 0 – not admitted). <code>GPA</code> is the GPA grade and <code>Exp</code> is the number of years of experience. The output of the preceding code is as follows:</p>
<div><div><img alt="Figure 8.2 – Training dataset on GPA grades and years of experience" height="200" src="img/B18945_08_002.jpg" width="200"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.2 – Training dataset on GPA grades and years of experience</p>
<p>We must also<a id="_idIndexMarker655"/> create a <a id="_idIndexMarker656"/>testing dataset for this model:</p>
<pre class="source-code">
test = pd.DataFrame({'Admitted': [1, 0, 1, 0, 1],
                    'GPA': [2.9, 2.4, 3.8, 3, 3.3],
                    'Exp': [9, 1, 6, 1,4 ]})
test.head()</pre>
<p>The resulting output is as follows:</p>
<div><div><img alt="Figure 8.3 – Testing dataset on GPA grades and years of experience" height="197" src="img/B18945_08_003.jpg" width="195"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Testing dataset on GPA grades and years of experience</p>
<p>We will use <code>logit</code> from <code>statsmodels</code>:</p>
<pre class="source-code">
import statsmodels.formula.api as smf
#fit logistic regression
model = smf.logit('Admitted ~ GPA + Exp', data =train).fit()
#summary
model.summary()</pre>
<p>This will <a id="_idIndexMarker657"/>print<a id="_idIndexMarker658"/> the following summary:</p>
<div><div><img alt="Figure 8.4 – Logit Regression Output" height="314" src="img/B18945_08_004.jpg" width="460"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Logit Regression Output</p>
<p>From this output, we can see that <code>GPA</code> and <code>Exp</code> are significant at the α = 0.05 significance level.</p>
<p>The values under the <code>[0.025 0.975]</code> heading are the 95% confidence interval for <code>Intercept</code>, <code>GPA</code>, and <code>Exp</code>, respectively. The next step is to use <code>confusion_matrix</code> and <code>accuracy_score</code> to compute the accuracy of the model on the test set:</p>
<pre class="source-code">
from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay
# X_test and y_test
X_test = test[['GPA', 'Exp']]
y_test = test['Admitted']
#
y_hat = model.predict(X_test)
pred = list(map(round, y_hat))
# confusion matrix
cm = confusion_matrix(y_test, pred)
ConfusionMatrixDisplay(cm).plot()
# Accuracy
print('Test accuracy = ', accuracy_score(y_test, pred))</pre>
<p>The <a id="_idIndexMarker659"/>output<a id="_idIndexMarker660"/> is as follows:</p>
<div><div><img alt="Figure 8.5 – Confusion matrix on testing dataset" height="300" src="img/B18945_08_005.jpg" width="323"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Confusion matrix on testing dataset</p>
<p>By using these<a id="_idIndexMarker661"/> train <a id="_idIndexMarker662"/>and test datasets, the model can predict the outcome perfectly. In the next section, we will <a id="_idIndexMarker663"/>discuss <strong class="bold">multi-class regression</strong> using a similar idea as in binary logistic regression.</p>
<h1 id="_idParaDest-136"><a id="_idTextAnchor141"/>Multinomial logit model</h1>
<p>In practice, there are<a id="_idIndexMarker664"/> many situations where the outcomes (dependent variables) are not binary but have more than two possibilities. <code>MNLogit</code> class from <code>statsmodels</code>: <a href="https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.MNLogit.xhtml">https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.MNLogit.xhtml</a>.</p>
<p>Iris data (<a href="https://archive.ics.uci.edu/ml/datasets/iris">https://archive.ics.uci.edu/ml/datasets/iris</a>) is<a id="_idIndexMarker666"/> one of the best-known statistical and machine learning datasets for education. The independent variables are sepal length (in cm), sepal width (in cm), petal length (in cm), and petal width (in cm). The dependent variable is a categorical variable with three levels: Iris Setosa (0), Iris Versicolor (1), and Iris Virginia (2). The following Python codes illustrate how to conduct<a id="_idIndexMarker667"/> this using <code>sklearn</code> and <code>statsmodels</code>:</p>
<pre class="source-code">
# import packages
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score,  ConfusionMatrixDisplay
import statsmodels.discrete.discrete_model as sm
# import Iris data
iris = datasets.load_iris()
print(iris.feature_names)
print(iris.target_names)
#create dataframe
df = pd.DataFrame(iris.data, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])
df['target'] = iris.target
df.head()
# check missing values
df.isna().sum()
# create train and test data
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state =1)
# fit the model using sklearn
model_sk = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')
model_sk.fit(X_train, y_train)
y_hat_sk = model_sk.predict(X_test)
pred_sk = list(map(round, y_hat_sk))
# confusion matrix
cm_sk = confusion_matrix(y_test, pred_sk)
ConfusionMatrixDisplay(cm_sk).plot()
# Accuracy
print('Test accuracy = ', accuracy_score(y_test, pred_sk))
#fit the model using statsmodels
model_stat = sm.MNLogit(y_train, X_train).fit(method='bfgs')
model_stat.summary()
y_hat_stat = model_stat.predict(X_test)
pred_stat = np.asarray(y_hat_stat).argmax(1)
# confusion matrix
cm_stat = confusion_matrix(y_test, pred_stat)
ConfusionMatrixDisplay(cm_stat).plot()
# Accuracy
print('Test accuracy = ', accuracy_score(y_test, pred_stat))</pre>
<p>Both<a id="_idIndexMarker668"/> methods give us the same test accuracy value (96.67%), with the confusion matrix produced as follows:</p>
<div><div><img alt="Figure 8.6 – Confusion matrices using sklearn (left) and statsmodels (right)" height="693" src="img/B18945_08_06.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.6 – Confusion matrices using sklearn (left) and statsmodels (right)</p>
<h1 id="_idParaDest-137"><a id="_idTextAnchor142"/>Poisson model</h1>
<p>In the <a id="_idIndexMarker669"/>previous section, we discussed models where the response variable was categorical. In this section, we will look at a model for count data. Count data is like categorical data (the categories are integers), but there are an infinite number of levels (0, 1, 2, 3, and so on). We model count data with the <strong class="bold">Poisson distribution</strong>. In this section, we will start by examining the Poisson distribution and its properties. Then, we will model a count variable with explanatory variables using the Poisson model.</p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor143"/>The Poisson distribution</h2>
<p>The Poisson distribution<a id="_idIndexMarker670"/> is given by the following formula:</p>
<p>P(k) =  λ k e −λ _ k ! </p>
<p>Here, λ is the average number of events and k is the number of events for which we would like the probability. P(k) is the probability that the k events occur. This distribution is used to calculate the probability of k events occurring in a fixed time interval or a defined space.</p>
<p>The shape of the <a id="_idIndexMarker671"/>distribution changes with the value of λ. When λ is greater than 10, the distribution appears approximately normal. However, as λ approaches 0, the distribution becomes right-skewed. This is because count data cannot be negative. Three example Poisson distributions are shown in <em class="italic">Figure 8</em><em class="italic">.7</em> with means of 12, 5, and 2. Notice that the distribution with the mean of 12 is approximately normally distributed, while the distributions of 5 and 2 are right-skewed:</p>
<div><div><img alt="Figure 8.7 – Example Poisson distributions with means of 12, 5, and 2" height="1019" src="img/B18945_08_007.jpg" width="536"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.7 – Example Poisson distributions with means of 12, 5, and 2</p>
<p>Another <a id="_idIndexMarker672"/>interesting aspect of the distribution is that the mean and variance are equal. This means that as the mean increases, the spread of the distribution also increases. We can see this in action in the examples in <em class="italic">Figure 8</em><em class="italic">.7</em>. The distribution with a mean of 2 has a small spread with a large peak at the mean, while the distribution with a mean of 12 has a much wider spread with a lower peak at the mean.</p>
<p>Now that we have discussed the Poisson distribution, let’s look at how to set up a Poisson model.</p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor144"/>Modeling count data</h2>
<p>Now, let’s <a id="_idIndexMarker673"/>look at how to model the response variable of counts with the Poisson model. As mentioned previously, count data often follows a Poisson distribution. The Poisson model is expressed mathematically as follows:</p>
<p>y = e b 0+b 1x 1+…+b nx n</p>
<p>Here, y is the response variable, b values are model coefficients, and x variables represent explanatory variables. This should appear similar to the equation we used in the previous chapter but with the addition of the exponentiation of the explanatory variables. This type of model is <a id="_idIndexMarker674"/>called a <strong class="bold">log-linear</strong> model, which is a model where the logarithm of the response variable is modeled by a linear combination of variables. We can rewrite this equation by applying the natural logarithm to both sides of the equation to make it explicit:</p>
<p>ln(y) = b 0 + b 1 x 1 + … + b n x n</p>
<p>Now, we have the logarithm of the response variable ( ln(y) ) expressed as a linear combination of explanatory variables.</p>
<p class="callout-heading">The natural logarithm</p>
<p class="callout">The Poisson model <a id="_idIndexMarker675"/>uses a special logarithm called the natural logarithm. The natural logarithm of a number is the logarithm of that number using the mathematical constant e as the base. The natural logarithm is generally written as ln(x), log e(x), or log(x) (the first two options are explicit, but the third option can be ambiguous). The logarithm operation is the inverse of exponentiation. In this case, the natural logarithm is the inverse of the exponential function: ln(e x) = x = e ln(x). The natural logarithm and exponential function are commonly used in statistics, mathematics, and science.</p>
<p>Let’s look at an example. We will be using the Bike Sharing Dataset from UCI (<a href="https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset">https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset</a>.). In this dataset, we have counts of bikes rented each day. There are two types of rentals: pre-registered (registered) and on-demand at a location (causal). In this example, we will model the weekly mean count of casually rented bikes over a given year. The dataset provides several explanatory variables, including environmental factors such as temperature and calendar information such as whether a holiday occurred.</p>
<p>We will <a id="_idIndexMarker676"/>start by setting up the equation for our model and then take a look at the results from fitting the model with <code>statsmodels</code>. The model equation follows the form we discussed previously:</p>
<p>ln(weekly _ mean _ rental _ count) = b 0 + b 1(temperature) + b 1(season)</p>
<p>+ b 2(weather _ situation) + b 3(humidity) + b 4(wind _ speed) + b 5(holiday)</p>
<p>We can fit this model with the given data using <code>statsmodels</code>, similar to how we did in the previous chapter. An excerpt of the code to fit the model is shown here (see the Jupyter Notebook for details on preprocessing):</p>
<pre class="source-code">
# select variables
X = df.groupby('isoweek').mean()[['atemp', 'season', 'weathersit','hum','windspeed', 'holiday']]
# transform holiday variable as an indicator that a holiday occurs within that week
X['holiday'] = X['holiday'].apply(lambda x: 1 if x &gt; 0.1 else 0)
# add a constant for the model
X = sm.add_constant(X)
# get the response variable
y = df.groupby('isoweek').mean()['casual']
fit_model = sm.Poisson(y, X).fit()
fit_model.summary()</pre>
<p>After fitting the model, we can get details on the coefficients using the <code>summary()</code> method. For this model, we get the following output for the coefficients:</p>
<div><div><img alt="Figure 8.8 – Poisson model summary" height="338" src="img/B18945_08_08.jpg" width="757"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.8 – Poisson model summary</p>
<p>Just like the <a id="_idIndexMarker677"/>modeling example for linear regression, these coefficient values are estimates of the parameters listed in our model. All the explanatory variables in the model appear to be significant in the model. Interestingly, based on the value of the coefficient estimates, temperature (<code>atemp</code>) appears to be the most influential factor, followed by humidity (<code>hum</code>) and wind speed. With the model fit and no need to remove insignificant variables, we can assess the model’s performance. This model has an MAE of 155, which corresponds to a MAPE of 36%.</p>
<p>The Poisson model depends strongly on the assumption that the response variable has a Poisson distribution. In the next section, we will look at a similar type of model for count data, but with weaker distributional assumptions.</p>
<h1 id="_idParaDest-140"><a id="_idTextAnchor145"/>The negative binomial regression model</h1>
<p>Another <a id="_idIndexMarker678"/>useful approach to <strong class="bold">discrete regression</strong> is <a id="_idIndexMarker679"/>the <strong class="bold">log-linear negative binomial regression</strong> model, which <a id="_idIndexMarker680"/>uses the negative binomial probability distribution. At a high level, negative binomial regression is useful with <em class="italic">over-dispersed count data</em> where the <em class="italic">conditional mean of the count is smaller than the conditional variance of the count</em>. Model <strong class="bold">over-dispersion</strong> is<a id="_idIndexMarker681"/> where the variance of the target variable is greater than the mean assumed by the model. In a regression model, the mean is the regression line. We make the determination of using the negative binomial model based on target variable counts analysis (mean versus variance) and supply a measure of model over-dispersion to the negative binomial model to adjust for the over-dispersion, which we will discuss here.</p>
<p>It is important to note that the negative binomial model is not for modeling simply discrete data, but specifically <strong class="bold">count data</strong> associated with a fixed number of <strong class="bold">random</strong> trials, such as modeling the number of attempts before an event occurs – or failing to occur – in a<a id="_idIndexMarker682"/> random sampling scenario. The model operates only on count data, where each count response of the target variable is based on a finite set of outcomes. Additionally, because the count data is the result of repeated binomial trials, the order of count arrangement does not matter.</p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor146"/>Negative binomial distribution</h2>
<p>The <a id="_idIndexMarker683"/>following is an example of the negative binomial distribution of failure counts with a conditional mean of 17 and a conditional variance of 52:</p>
<div><div><img alt="Figure 8.9 – Negative binomial distribution example" height="730" src="img/B18945_08_009.jpg" width="1264"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.9 – Negative binomial distribution example</p>
<p>The binomial distribution is a construct of counts of successes in a fixed count of random trials (X = ( X 1, X 2, … )) of a Bernoulli random variable, which is a variable that has one of two outcome values: 0 or 1. The negative binomial distribution is a construct of the count of failures in a fixed count of random draws of the Bernoulli random variable. This distinction is important because a model using binomial regression models a binary outcome across observations, whereas a negative binomial regression model models a count outcome across observations. The negative binomial distribution is the inverse of the binomial distribution. The probability mass function for the negative binomial distribution is as follows:</p>
<p>P(X − x) = (x + n − 1 n − 1 ) p n (1 − p) x</p>
<p>Here, there are x failures and n − 1 successes in a set of x + n − 1 trials reaching success at trial x + n.</p>
<p>Concerning<a id="_idIndexMarker684"/> the Poisson distribution, the negative binomial <em class="italic">does not require strict adherence to the assumption that conditional variance is equal to the conditional mean</em> as it includes an additional parameter, <em class="italic">α</em>, to explain the extra variance, whereas the Poisson model assumes the variance is equal to the mean, <em class="italic">μ</em>. The negative binomial model assumes the variance, here based on the Poisson-gamma mixture distribution, is equal to the following:</p>
<p>μ(1 + αμ)</p>
<p>This reduces to the following:</p>
<p>(μ + α μ 2)</p>
<p>Stated in terms of the probability of success, <em class="italic">p</em>, the negative binomial variance is calculated as follows:</p>
<p>n  1 − p _ p 2 </p>
<p>It has the following mean:</p>
<p>n  1 − p _ p </p>
<p>Because the variance is not expected to equal the mean with the negative binomial model, the negative binomial is likely to outperform the Poisson approach <em class="italic">when the counts are large enough that the variance in response exceeds the mean</em>. Similarly, to Poisson, a negative binomial is a log-linear model with confidence intervals being based on the Wald and drop-in-deviance likelihood ratio. The form of the negative binomial model’s regression equation, shown here, is the same as that for Poisson regression:</p>
<p>ln(y) = b 0 + b 1 x 1 + … + b n x n</p>
<p>It reduces to the following:</p>
<p>y = e b 0 + e b 1x 1 + … + e b nx n</p>
<p>The <strong class="bold">maximum likelihood estimate</strong> of the probability of success for a given sample of the distribution is as follows:</p>
<p> n _ n +  _ x  ′  </p>
<p class="callout-heading">Maximum likelihood estimation</p>
<p class="callout"><strong class="bold">Maximum likelihood estimation</strong> (<strong class="bold">MLE</strong>) is an underpinning of the log-odds (or logit) and <a id="_idIndexMarker685"/>log-likelihood approaches to statistical modeling. Likelihood is the probability of the known outcome of a regression model being observed given specific regression coefficient values. By default, a set of variables will have a higher likelihood than another set of variables if the set provides a higher probability of the observed outcome being obtained. The logarithm of the likelihood is taken as a measure of goodness-of-fit for a regression model. Out of a set of potential coefficient values for each variable, the set of coefficients with the maximum log-likelihood values for each variable are referred to as the <strong class="bold">maximum likelihood estimates</strong>. These values are obtained through an iterative approach that generates multiple possible values. If the sample size is sufficiently large and an appropriate set of variables has been obtained for the model, the maximum likelihood estimates can be considered unbiased.</p>
<p>Calculating <a id="_idIndexMarker686"/>the confidence intervals for negative binomial regression is similar to that for logistic regression. The <strong class="bold">Wald</strong> approach<a id="_idIndexMarker687"/> to the calculation leverages a <strong class="bold">z-ratio</strong>. Where<a id="_idIndexMarker688"/> there are <em class="italic">j</em> variables in the model, the z-ratio is calculated as follows:</p>
<p> (  ˆ β  j− β j) _ SE(  ˆ β  j) </p>
<p>Here, <em class="italic">SE</em> is the standard error. The confidence interval is the variable’s coefficient estimate plus and minus the half-width confidence interval percentile multiplied by the standard error of the coefficient estimate. The z-ratio can be used because it is assumed the estimates have standard normal sampling distributions. Therefore, we can derive the 95% confidence interval for the variable’s estimated coefficient as follows:</p>
<p>Lower 95% confidence limit:</p>
<p> ˆ β  j − 0.475 × SE( ˆ β  j)</p>
<p>Upper 95% confidence limit:</p>
<p> ˆ β  j + 0.475 × SE( ˆ β  j)</p>
<p>There are three required assumptions specific to negative binomial regression:</p>
<ol>
<li>Independence between samples.</li>
<li>A linear relationship between the log of the target variable and input variables (log-linear model).</li>
<li>Conditional variance is greater than or equal to the conditional mean.</li>
</ol>
<p>Independence between<a id="_idIndexMarker689"/> samples means there is no serial correlation nor any cluster or other conditional dependence between samples. A linear relationship between the log of the target variable and input variables means that the relationship between the logarithm of the target variable and changes in each input variable scales linearly. Except for requirement 3, which we discussed at the start of this section, the requirements are essentially the same as for the Poisson model.</p>
<p>Let’s walk through an example in Python using statsmodels. For this, let’s load the statsmodels affairs dataset to model child count (the <code>children</code> variable) using the remaining variables. In line three, we must add the constant required to generate an intercept coefficient:</p>
<pre class="source-code">
import statsmodels.api as sm
data = sm.datasets.fair.load().data
data = sm.add_constant(data, prepend=False)</pre>
<p>First, let’s numerically confirm there is over-dispersion present in the target variable:</p>
<pre class="source-code">
print('Mean count of children per marriage: ', data['children'].mean())
print('Variance of the count of children per marriage: ', data['children'].var())</pre>
<p>We can see the variance is greater than the mean:</p>
<p><code>Mean count of children per marriage:  </code><code>1.3968740182218033</code></p>
<p><code>Variance of the count of children per marriage:  </code><code>2.054838616333698</code></p>
<p>Here, we <a id="_idIndexMarker690"/>can see that the conditional mean per marriage is smaller than the conditional variance. While not a massive difference, it is enough to consider using negative binomial regression. Let’s visually observe the distribution of the response:</p>
<div><div><img alt="Figure 8.10 – Distribution of children" height="748" src="img/B18945_08_010.jpg" width="1031"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.10 – Distribution of children</p>
<p>The first five rows of the data can be seen here. Note that the first column of the design matrix should always contain the constant:</p>
<div><div><img alt="Figure 8.11 – First five records of example data set, including the added constant" height="347" src="img/B18945_08_11.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.11 – First five records of example data set, including the added constant</p>
<p>In our <a id="_idIndexMarker691"/>visual inspection of the distribution of children in <em class="italic">Figure 8</em><em class="italic">.10</em>, we identified that there is a value of 5.5 for children. This may be the result of averaging or an error. A subject matter expert may help determine this, but for our analysis, let’s assume it was a mistake and round to a whole number of children since people are not fractional. Let’s set up the target array, <em class="italic">y</em>, and design matrix, <em class="italic">X</em>:</p>
<pre class="source-code">
y = round(data['children'])
X = data[['const','age','religious','yrs_married','educ','occupation','occupation_husb','affairs','rate_marriage']]</pre>
<p>Now, let’s create a train and test split for regression modeling. Note that <code>shuffle=True</code> will provide different results. To obtain a representative sample, the data should be randomly shuffled:</p>
<pre class="source-code">
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True)</pre>
<p>Because the negative binomial model is based on a Poisson-gamma mixture model, we need to estimate the model’s measure of over-dispersion using a Poisson model. A method referred to <a id="_idIndexMarker692"/>as <strong class="bold">auxiliary OLS regression (without constant)</strong> is provided by A. Colin Cameron and Pravin K. Trivedi in <em class="italic">Microeconometrics: Methods and Applications</em>. The authors propose the creation of an over-dispersion test statistic where the null hypothesis is α=0 and the alternate hypothesis is α ≠ 0, where <em class="italic">α</em> is the estimate of over-dispersion. The auxiliary OLS regression formula is as follows:</p>
<p> ( y i −  ˆ μ  i) 2 − y i  _  ˆ μ  i  = α  g(  ˆ μ  i) _  ˆ μ  i  + μ i</p>
<p>Here, μ i is an error term and g(  ˆ μ  i) is  ˆ μ  i 2. Thus, the right-hand operand reduces to α  ˆ μ  i + μ i. In terms of negative binomial regression, we consider the error to equal zero, so we can factor α in as the over-dispersion estimate.</p>
<p>In the<a id="_idIndexMarker693"/> following code, we have fit our training data to a generalized linear model using the Poisson model for the linkage. Then, we used the regression mean of the model to build the estimated auxiliary target variable. Because the method is “without constant,” we subtract 1 to remove the constant from the process:</p>
<pre class="source-code">
from statsmodels.formula.api import ols as OLS
import statsmodels.api as sm
poisson_model = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()
df_aux = pd.DataFrame()
df_aux['y_mu_hat'] = poisson_model.mu
df_aux['children'] = y_train
df_aux['y_auxiliary'] = df_aux.apply(lambda x: ((x['children'] - x['y_mu_hat'])**2 - x['y_mu_hat']) / x['y_mu_hat'], axis=1)
ols_model = OLS('y_auxiliary ~ y_mu_hat - 1', df_aux).fit()
print(ols_model.params)</pre>
<p>As we can see, the estimated dispersion for the negative binomial model is <code>0.622034</code>. Now, we need to assess if the auxiliary estimate is statistically significant. We can do this using the p-value from the OLS model:</p>
<pre class="source-code">
print(ols_model.summary())</pre>
<p>This will print the following output:</p>
<div><div><img alt="Figure 8.12 – OLS regression results" height="190" src="img/B18945_08_12.jpg" width="699"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.12 – OLS regression results</p>
<p>Because the<a id="_idIndexMarker694"/> coefficient is significant and greater than 0, we can confirm the model has over-dispersion based on the target. The coefficient can be used as the measure for that over-dispersion in the negative binomial model, which we can use to adjust the variance in the <code>alpha</code> argument here:</p>
<pre class="source-code">
from statsmodels.genmod.families.family import NegativeBinomial
negative_binomial_model = sm.GLM(y_train, X_train, family=NegativeBinomial(alpha=ols_model.params.values)).fit()
print(negative_binomial_model.summary())</pre>
<p>The output is generated as follows:</p>
<div><div><img alt="Figure 8.13 – Generalized linear model regression results" height="446" src="img/B18945_08_13.jpg" width="691"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 8.13 – Generalized linear model regression results</p>
<p>Finally, let’s <a id="_idIndexMarker695"/>use the model we built on the training data to predict the training data, then again to predict on the test data so that we can compare generalizability on unseen data using residual error as a basis of comparison:</p>
<pre class="source-code">
from sklearn.metrics import mean_squared_error as RMSE
print('Training Root Mean Squared Error: ', RMSE(y_train, negative_binomial_model.predict(X_train)) )
print('Testing Root Mean Squared Error: ', RMSE(y_test, negative_binomial_model.predict(X_test)))</pre>
<p>We can observe from the root mean squared error that the model’s performance is approximately constant across training and test data, indicating a consistent model:</p>
<p><code>Training Root Mean Squared </code><code>Error: 1.2553439918425695</code></p>
<p><code>Testing Root Mean Squared </code><code>Error: 1.266620561303553</code></p>
<h1 id="_idParaDest-142"><a id="_idTextAnchor147"/>Summary</h1>
<p>In this chapter, we explained the issue of encountering negative raw probabilities that are generated by building a binary classification probability model based strictly on linear regression, where probabilities in a range of [0, 1] are expected. We provided an overview of the log-odds ratio and probit and logit modeling using the cumulative distribution function of both the standard normal distribution and logistic distribution, respectively. We also demonstrated methods for applying logistic regression to solve binary and multinomial classification problems. Lastly, we covered count-based regression using the log-linear Poisson and negative binomial models, which can also be logically extended to rate data without modification. We provided examples of their implementations.</p>
<p>In the following chapter, we will introduce conditional probability using Bayes’ theorem in addition to dimension reduction and classification modeling using linear discriminant analysis and quadratic discriminant analysis.</p>
</div>
</div></body></html>