- en: Scala for Learning Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scala学习分类
- en: In the previous chapter, we saw how to develop a predictive model for analyzing
    insurance severity claims as a regression analysis problem. We applied very simple
    linear regression, as well as **generalized linear regression** (**GLR**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了如何将分析保险严重索赔的预测模型作为回归分析问题来开发。我们应用了非常简单的线性回归，以及**广义线性回归**（**GLR**）。
- en: In this chapter, we'll learn about another supervised learning task, called
    classification. We'll use widely used algorithms such as logistic regression, **Naive
    Bayes** (**NB**), and **Support Vector Machines** (**SVMs**) to analyze and predict
    whether a customer is likely to cancel the subscription of their telecommunication
    contract or not.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将学习另一个监督学习任务，称为分类。我们将使用广泛使用的算法，如逻辑回归、**朴素贝叶斯**（**NB**）和**支持向量机**（**SVMs**），来分析和预测客户是否可能取消其电信合同的订阅。 '
- en: 'In particular, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将涵盖以下主题：
- en: Introduction to classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类简介
- en: Learning classification with a real-life example
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过实际案例学习分类
- en: Logistic regression for churn prediction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于流失预测的逻辑回归
- en: SVM for churn prediction
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于流失预测的支持向量机（SVM）
- en: NB for prediction
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测的NB
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Scala 2.11.x和Java 1.8.x已安装并配置在您的机器上。
- en: 'The code files of this chapters can be found on GitHub:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter03](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter03)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter03](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter03)'
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2ZKVrxH](http://bit.ly/2ZKVrxH)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2ZKVrxH](http://bit.ly/2ZKVrxH)'
- en: Overview of classification
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类概述
- en: As a supervised learning task, classification is the problem of identifying
    which set of observations (sample) belongs to what based on one or more independent
    variables. This learning process is based on a training set containing observations
    (or instances) about the class or label of membership. Typically, classification
    problems are when we are training a model to predict quantitative (but discrete)
    targets, such as *s*pam detection, churn prediction, sentiment analysis, cancer
    type prediction, and so on.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为监督学习任务，分类是根据一个或多个独立变量识别哪些观测集（样本）属于哪个集合的问题。这个过程基于包含关于类别或标签成员资格的观测（或实例）的训练集。通常，分类问题是我们训练模型来预测定量（但离散）目标的情况，例如垃圾邮件检测、流失预测、情感分析、癌症类型预测等。
- en: 'Suppose we want to develop a predictive model, which will predict whether a
    student is competent enough to get admission into computer science based on his/her
    competency in TOEFL and GRE. Also, suppose we have some historical data in the
    following range/format:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要开发一个预测模型，该模型将根据学生的托福和GRE能力预测其是否有足够的竞争力被录取到计算机科学专业。此外，假设我们有一些以下范围/格式的历史数据：
- en: '**TOEFL**: Between 0 and 100'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**托福成绩**：介于0到100之间'
- en: '**GRE**: Between 0 and 100'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GRE**：介于0到100之间'
- en: '**Admission**: 1 for admitted, 0 if not admitted'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**录取**：如果录取则为1，如果不录取则为0'
- en: 'Now, to understand whether we can use such simple data to make predictions,
    let''s create a scatter plot by putting all the records with **Admitted** and
    **Rejected** as the dependent variables and **TOEFL** and **GRE** as the independent
    variables, like so:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了了解我们是否可以使用如此简单的数据来做出预测，让我们创建一个散点图，将所有记录的**录取**和**拒绝**作为因变量，**托福**和**GRE**作为自变量，如下所示：
- en: '![](img/004d677c-7313-4a40-bf44-90ee1afbcda1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/004d677c-7313-4a40-bf44-90ee1afbcda1.png)'
- en: By looking at the data points (imagine that the diagonal line in the graph is
    not there), we can reasonably develop a linear model to separate most of the data
    points. Now, if we draw a straight line between two classes of data, those almost
    get separated. Such a line (green, in our case) is called the decision boundary.
    So, if the decision boundary has reasonably separate maximal data points, it can
    be used for making predictions on unseen data, and we can also say that the data
    point above the line we predicted is competent for admission, and below the line
    we predict that the students are not competent enough.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察数据点（想象一下图中没有对角线），我们可以合理地开发一个线性模型来分离大部分数据点。现在，如果我们在这两类数据之间画一条直线，它们几乎就能被分开。这样的线（在我们的例子中是绿色）被称为决策边界。因此，如果决策边界合理地分离了最大数据点，它可以用于对未见数据做出预测，我们也可以说，我们预测的线上方的数据点是合格的，而线下方的学生则不够合格。
- en: Although this example is for a basic head-start into regression analysis, separating
    missions of data points is not very easy. Thus, to calculate where to draw the
    line for separating such a huge number of data points, we can use logistic regression
    or other classification algorithms that we will discuss in upcoming sections.
    We'll also see that drawing an ordinary straight line might not be the right one,
    and therefore we often have to draw curved lines.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个例子是为了对回归分析有一个基本的入门，但分离数据点并不容易。因此，为了计算在哪里画线来分离如此大量的数据点，我们可以使用逻辑回归或其他分类算法，我们将在接下来的章节中讨论。我们还将看到，画一条普通的直线可能不是正确的选择，因此我们通常不得不画曲线。
- en: 'If we look at the admission-related data plot carefully, maybe a straight line
    is not the best way of separating each data point—a curved line would be better,
    as shown in the following graph:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仔细观察与录取相关的数据图，可能一条直线并不是分离每个数据点的最佳方式——曲线会更好，如下面的图表所示：
- en: '![](img/8513e773-de23-4536-b7f1-7daa4b32d5e0.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8513e773-de23-4536-b7f1-7daa4b32d5e0.png)'
- en: However, to get a curved decision boundary, we have to change not only the function
    (called the decision boundary function) that's responsible from being linear to
    some high-order polynomial, but also the data to be a second-degree polynomial.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要得到曲线的决策边界，我们必须不仅改变负责从线性到某些高阶多项式的函数（称为决策边界函数），还要将数据改为二次多项式。
- en: 'This means that we have to model our problem as a logistic regression model.
    That is, we need to change the data from *{GRE, TOEFL**}* format to a quadratic
    function format, *{GRE, GRE^2, TOEFL, TOEFL^2, GRE∗TOEFL**}*. However, doing so
    in a hand-crafted way is cumbersome and will not be possible for large datasets. Fortunately,
    Spark MLlib has numerous algorithms implemented for modeling such problems and
    for solving other classification problems, including the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们必须将我们的问题建模为一个逻辑回归模型。也就是说，我们需要将数据从 *{GRE, TOEFL**}* 格式转换为二次函数格式， *{GRE,
    GRE^2, TOEFL, TOEFL^2, GRE∗TOEFL**}*. 然而，以手工方式这样做是繁琐的，并且对于大数据集来说将不可行。幸运的是，Spark
    MLlib实现了许多用于建模此类问题以及解决其他分类问题的算法，包括以下内容：
- en: '**Logistic regression** (**LR**)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**（**LR**）'
- en: SVM
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM
- en: NB
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NB
- en: '**Multilayer perceptron** (**MLP**)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多层感知器**（**MLP**）'
- en: '**Decision tree** (**DT**)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**（**DT**）'
- en: '**Random forest** (**RF**)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**（**RF**）'
- en: '**Gradient boosted trees** (**GBT**)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升树**（**GBT**）'
- en: 'For a classification problem, actual (that is, true) labels (that is, class)
    and the predicted label (that is, class) exist for the samples that are used to
    train or test a classifier; this can be assigned to one of the following categories:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个分类问题，实际（即真实）标签（即类别）和预测标签（即类别）存在于用于训练或测试分类器的样本中；这可以分配到以下类别之一：
- en: '**True positive (TP)**: The true label is positive and the prediction made
    by the classifier is also positive'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性（TP**）：真实标签为正，且分类器做出的预测也是正'
- en: '**True negative (TN)**: The true label is negative and the prediction made
    by the classifier is also negative'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性（TN**）：真实标签为负，且分类器做出的预测也是负'
- en: '**False positive (FP)**: The true label is negative but the prediction made
    by the classifier is positive'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性（FP**）：真实标签为负，但分类器做出的预测为正'
- en: '**False negative (FN)**: The true label is positive but the prediction made
    by the classifier is negative'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性（FN**）：真实标签为正，但分类器做出的预测为负'
- en: 'These metrics (TP, FP, TN, and FN) are the building blocks of the evaluation
    metrics for most of the classifiers we listed previously. However, the pure accuracy
    that is often used for identifying how many predictions were correct is not generally
    a good metric, so other metrics such as precision, recall, F1 score, AUC, and
    **Matthew''s correlation coefficient** (**MCC**) are used:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标（TP、FP、TN 和 FN）是我们之前列出的大多数分类器评估指标的基础。然而，通常用于识别正确预测数量的纯准确率并不是一个好的指标，因此使用其他指标，如精度、召回率、F1
    分数、AUC 和 **Matthew 的相关系数**（**MCC**）：
- en: '*Accuracy* is the fraction of samples that the classifier correctly predicted
    (both positive and negative), divided by the total number of samples:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准确率*是指分类器正确预测的样本数（包括正负样本）与总样本数的比例：'
- en: '![](img/f75a674d-2f5c-4d02-b65d-6d52bfd3b3fb.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f75a674d-2f5c-4d02-b65d-6d52bfd3b3fb.png)'
- en: '*Precision* is the number of samples correctly predicted that belong to a positive
    class (true positives), divided by the total number of samples actually belonging
    to the positive class:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*精度*是指属于正类（真阳性）的正确预测样本数除以实际属于正类的总样本数：'
- en: '![](img/acf55427-ec4f-415e-974f-eb47fd364dc4.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/acf55427-ec4f-415e-974f-eb47fd364dc4.png)'
- en: '*Recall* is the number of samples that were correctly predicted to belong to
    a negative class, divided by the total number of elements actually belonging to
    the negative class:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*召回率*是指正确预测属于负类的样本数除以实际属于负类的总元素数：'
- en: '![](img/2c2e3301-f478-4212-8034-c27a95f8855e.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c2e3301-f478-4212-8034-c27a95f8855e.png)'
- en: 'F1 score is the harmonic mean of precision and recall. Since the F1 score is
    a balance between recall and precision, it can be considered as an alternative
    to accuracy:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 分数是精度和召回率的调和平均数。由于 F1 分数是召回率和精度的平衡，它可以被认为是准确率的替代品：
- en: '![](img/21df9705-5b82-4f30-8758-c7c0bfa23a7f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21df9705-5b82-4f30-8758-c7c0bfa23a7f.png)'
- en: '**Receiver Operating Characteristics** (**ROC**) is a curve that''s drawn by
    plotting **FPR** (to *x*-axis) and **TPR** (to *y*-axis) for different threshold
    values. So, for different thresholds for your classifier, we calculate the **TPR**
    and **FPR**, draw the **ROC** curve, and calculate the area under the **ROC**
    curve (also known as **AUC**). This can be visualized as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（**ROC**）是通过绘制不同阈值值的 **FPR**（到 *x* 轴）和 **TPR**（到 *y* 轴）而得到的曲线。因此，对于分类器的不同阈值，我们计算
    **TPR** 和 **FPR**，绘制 **ROC** 曲线，并计算 **ROC** 曲线下方的面积（也称为 **AUC**）。这可以如下可视化：'
- en: '![](img/ed60cca4-db3c-4239-a13f-054b24e18629.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed60cca4-db3c-4239-a13f-054b24e18629.png)'
- en: 'MCC is regarded as a balanced measure of a binary classifier, even for a dataset
    that has very imbalanced classes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: MCC 被视为二元分类器的平衡度量，即使对于具有非常不平衡类别的数据集也是如此：
- en: '![](img/e1e62338-9246-4eb7-8cb6-9f51f6b31057.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1e62338-9246-4eb7-8cb6-9f51f6b31057.png)'
- en: Let's discuss a more real-life example of a classification problem, which is
    churn analysis. Customer churn is the loss of clients or customers in any business,
    which is becoming a prime concern in different area of business, such as banks,
    internet service providers, insurance companies, and so on*.* Customer dissatisfaction
    and better offers from the competitor are the primary reasons behind this*.* In
    the telecommunications industry, when many subscribers switch to another service
    provider, the company not only loses those customers and revenue—this also creates
    a bad impression for other, regular customers, or people who were planning to
    start using their service.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一个更贴近现实生活的分类问题示例，即客户流失分析。客户流失是指任何业务中客户或客户的流失，这正在成为商业不同领域的首要关注点，如银行、互联网服务提供商、保险公司等。客户不满和竞争对手的更好报价是这一现象背后的主要原因。在电信行业，当许多用户转而使用其他服务提供商时，公司不仅会失去那些客户和收入——这也会给其他，常规客户或计划开始使用他们服务的人留下坏印象。
- en: Eventually, the full cost of customer churn includes both the lost revenue and
    the telemarketing costs involved with replacing those customers with new ones.
    However, these types of loss can cause a huge loss for a business. Remember the
    time when Nokia was the dominator in the cell phone market? All of a sudden, Apple
    announced iPhone 3G, which was a revolution in the smartphone era. Then, around
    10% to 12% customers discontinued using Nokia and switched to iPhone. Although
    Nokia also tried to release a smartphone later on, they could not compete with
    Apple.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，客户流失的全部成本包括失去的收入以及用新客户替换这些客户所涉及的电话营销成本。然而，这类损失可能对一家企业造成巨大损失。还记得诺基亚曾是手机市场的霸主吗？突然之间，苹果发布了iPhone
    3G，这在智能手机时代引发了一场革命。随后，大约有10%到12%的客户停止使用诺基亚，转而使用iPhone。尽管诺基亚后来也尝试发布智能手机，但他们无法与苹果竞争。
- en: In short, churn prediction is essential for businesses as it helps you detect
    different kinds of customers who are likely to cancel a subscription, product,
    or service. In short, the idea is to predict whether an existing customer will
    unsubscribe from an existing service or not, that is, a binary classification
    problem.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，客户流失预测对商业至关重要，因为它可以帮助你检测那些可能取消订阅、产品或服务的不同类型的客户。简而言之，这个想法是预测现有客户是否会取消现有服务的订阅，即一个二元分类问题。
- en: Developing predictive models for churn
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发客户流失预测模型
- en: 'Accurate identification of churn possibility can minimize customer defection
    if you first identify which customers are likely to cancel a subscription to an
    existing service, and offering a special offer or plan to those customers. When
    it comes to employee churn prediction and developing a predictive model, where
    the process is heavily data-driven, machine learning can be used to understand
    a customer''s behavior. This is done by analyzing the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您首先确定哪些客户可能取消现有服务的订阅，并提供特别优惠或计划给这些客户，那么准确识别流失的可能性可以最小化客户流失。当涉及到员工流失预测和开发预测模型时，这个过程高度依赖数据驱动，可以使用机器学习来理解客户的行为。这是通过分析以下内容来完成的：
- en: Demographic data, such as age, marital status, and job status
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计数据，如年龄、婚姻状况和就业状况
- en: Sentiment analysis based on their social media data
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于社交媒体数据的情感分析
- en: Behavior analysis using their browsing clickstream logs
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用他们的浏览点击流日志进行行为分析
- en: Calling-circle data and support call center statistics
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 呼叫圈数据和客服中心统计数据
- en: 'An automated churn analytics pipeline can be developed by following three steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下三个步骤可以开发一个自动化的客户流失分析流程：
- en: First, identify typical tasks to analyze the churn, which will depend on company
    policy
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，确定分析客户流失的典型任务，这将取决于公司政策
- en: Then, collect and analyze data and develop a predictive model
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，收集和分析数据，并开发预测模型
- en: Finally, deploy the model in a production-ready environment
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将模型部署到生产就绪的环境中
- en: Eventually, telecom companies will be able to predict and enhance customer experience,
    prevent churn, and tailor marketing campaigns. In practice, such an analysis will
    be helpful to retain the customers who are most likely to leave. This means that
    we don't need to worry about the customers who are likely to stay.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，电信公司能够预测并提升客户体验，防止客户流失，并定制营销活动。在实践中，这种分析将有助于保留那些最有可能离开的客户。这意味着我们不需要担心那些可能留下的客户。
- en: Description of the dataset
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集描述
- en: 'We can use the Orange Telecom''s Churn Dataset to develop a predictive model,
    which will predict which customers would like to cancel their subscription to
    existing services. The dataset is well studied, comprehensive, and used for developing
    small prototypes. It contains both churn-80 and churn-20 datasets, which can be
    downloaded from the following links:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Orange电信的客户流失数据集来开发预测模型，该模型将预测哪些客户可能希望取消现有服务的订阅。该数据集经过充分研究，内容全面，用于开发小型原型。它包含churn-80和churn-20数据集，可以从以下链接下载：
- en: 'churn-80: [https://bml-data.s3.amazonaws.com/churn-bigml-80.csv](https://bml-data.s3.amazonaws.com/churn-bigml-80.csv)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'churn-80: [https://bml-data.s3.amazonaws.com/churn-bigml-80.csv](https://bml-data.s3.amazonaws.com/churn-bigml-80.csv)'
- en: 'churn-20: [https://bml-data.s3.amazonaws.com/churn-bigml-20.csv](https://bml-data.s3.amazonaws.com/churn-bigml-20.csv)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'churn-20: [https://bml-data.s3.amazonaws.com/churn-bigml-20.csv](https://bml-data.s3.amazonaws.com/churn-bigml-20.csv)'
- en: 'Since both datasets came from the same distribution, which has the same structure,
    we will use the churn-80 dataset for the training and 10-fold cross-validation.
    Then, churn-20 will be used to evaluate the trained model. Both datasets have
    a similar structure, and therefore have the following schema:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这两个数据集都来自具有相同结构的同一分布，我们将使用churn-80数据集进行训练和10折交叉验证。然后，将使用churn-20评估训练好的模型。这两个数据集具有相似的结构，因此具有以下模式：
- en: '**State**: `String`'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**州**: `字符串`'
- en: '**Account length**: `Integer`'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**账户长度**: `整数`'
- en: '**Area code**: `Integer`'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**区号**: `整数`'
- en: '**International plan**: `String`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**国际计划**: `字符串`'
- en: '**Voicemail plan**: `String`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音邮件计划**: `字符串`'
- en: '**Number email messages**: `Integer`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件消息数量**: `整数`'
- en: '**Total day minutes**: `Double`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总白天分钟数**: `双精度浮点数`'
- en: '**Total day calls**: `Integer`'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总白天通话次数**: `整数`'
- en: '**Total day charge**: `Double`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总白天费用**: `双精度浮点数`'
- en: '**Total evening minutes**: `Double`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总晚上分钟数**: `双精度浮点数`'
- en: '**Total evening calls**: `Integer`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总晚上通话次数**: `整数`'
- en: '**Total evening charge**: `Double`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总晚上费用**: `双精度浮点数`'
- en: '**Total night minutes**: `Double`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总夜间分钟数**: `双精度浮点数`'
- en: '**Total night calls**: `Integer`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总夜间通话次数**: `整数`'
- en: '**Total night charge**: `Double`'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总夜间费用**: `双精度浮点数`'
- en: '**Total international minutes**: `Double`'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总国际分钟数**: `双精度浮点数`'
- en: '**Total international calls**: `Integer`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总国际通话次数**: `整数`'
- en: '**Total international charge**: `Double`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总国际费用**: `双倍`'
- en: '**Customer service calls**: `Integer`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户服务电话次数**: `整数`'
- en: Exploratory analysis and feature engineering
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性分析和特征工程
- en: 'First, we specify exactly the same schema (that is, a custom schema) before
    loading the data as a Spark DataFrame, as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在将数据作为Spark DataFrame加载之前，我们指定完全相同的模式（即自定义模式），如下所示：
- en: '[PRE0]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we have to create a Scala case class with all the fields specified and
    align the preceding schema (variable names are self-explanatory):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须创建一个包含所有指定字段的Scala case class，并使前面的模式（变量名称是自解释的）对齐：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s create a Spark session and import the `implicit._` package, which allows
    us to specify a DataFrame operation, as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个Spark会话并导入`implicit._`包，它允许我们指定DataFrame操作，如下所示：
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s create the training set. We read the CSV file with Spark''s recommended
    format, `com.databricks.spark.csv`. We do not need any explicit schema inference;
    hence, we are making the `inferSchema` `false`, but we are using our own schema,
    which we created previously. Then, we load the data file from our desired location,
    and finally specify our data source so that our DataFrame looks exactly the same
    as what we specified:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建训练集。我们使用Spark推荐的格式`com.databricks.spark.csv`读取CSV文件。我们不需要任何显式的模式推断；因此，我们将`inferSchema`设置为`false`，但使用我们之前创建的自己的模式。然后，我们从我们希望的位置加载数据文件，并最终指定我们的数据源，以便我们的DataFrame看起来与我们指定的完全相同：
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As we can see in the following screenshot, the schema of the Spark DataFrame
    has been correctly identified. However, some of the features are non-numeric but
    categorical. However, as expected by ML algorithms, all the features have to be
    numeric (that is, `integer` or `double` format):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，Spark DataFrame的模式已被正确识别。然而，一些特征是非数字的，而是分类的。然而，正如机器学习算法所期望的，所有特征都必须是数字的（即，`整数`或`双精度浮点数`格式）：
- en: '![](img/0a954d3d-1355-4db4-b697-46555926af92.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a954d3d-1355-4db4-b697-46555926af92.png)'
- en: 'Excellent! It looks exactly the same as the data structure. Now, let''s look
    at some sample data by using the `show()` method, as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！它看起来与数据结构完全相同。现在，让我们使用`show()`方法查看一些样本数据，如下所示：
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the preceding line of code shows the first 20 samples of the
    DataFrame:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 前一行代码的输出显示了DataFrame的前20个样本：
- en: '![](img/d567b228-865e-4c27-9d1f-99b719fb9c49.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d567b228-865e-4c27-9d1f-99b719fb9c49.png)'
- en: 'In the preceding screenshot, column names are made shorter for visibility.
    We can also see related statistics of the training set by using the `describe()`
    method:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，为了提高可见性，列名被缩短了。我们还可以通过使用`describe()`方法查看训练集的相关统计信息：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following summary statistics not only give us some idea on the distribution
    with mean and standard deviation of the data, but also some descriptive statistics,
    such as number samples (that is, count), minimum value, and maximum value for
    each feature in the DataFrame:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以下摘要统计不仅让我们对数据的分布有了些了解，包括均值和标准差，还提供了一些描述性统计，如DataFrame中每个特征的样本数（即计数）、最小值和最大值：
- en: '![](img/9d3a2a16-f183-424e-85d9-6faca2aeb658.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d3a2a16-f183-424e-85d9-6faca2aeb658.png)'
- en: 'If this dataset can fit into RAM, we can cache it for quick and repeated access
    by using the `cache()` method from Spark:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个数据集可以适应RAM，我们可以使用Spark的`cache()`方法将其缓存，以便快速和重复访问：
- en: '[PRE6]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let''s look at some useful properties such as variable correlation with `churn`.
    For example, let''s see how the `churn` is related with total number of international
    calls:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些有用的属性，例如变量与`churn`的相关性。例如，让我们看看`churn`与总国际通话次数之间的关系：
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As we can see from the following output, customers who make more international
    calls are less likely (that is, `False`) to change operator:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下输出所示，通话更多国际电话的客户不太可能（即，`False`）更换运营商：
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s see how the `churn` is related to total international call charges:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`churn`与总国际通话费用之间的关系：
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As we can see from the following output, customers who make more international
    calls (as shown earlier) are charged more, but are still less likely (that is,
    `False`) to change operator:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下输出所示，通话更多国际电话的客户（如前所述）被收取更多费用，但仍然不太可能（即，`False`）更换运营商：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now that we also need to have the test set prepared to evaluate the model,
    let''s prepare the same set, similar to the train set, as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们还需要准备测试集来评估模型，让我们准备与训练集相似的相同集，如下所示：
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, let''s cache them for faster and quick access for further manipulation:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将它们缓存起来，以便更快地进行进一步的操作：
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s look at some of the related properties of the training set to understand
    how suitable it is for our purposes. First, let''s create a temp view for persistence
    for this session. Nevertheless, we can create a catalog as an interface that can
    be used to create, drop, alter, or query underlying databases, tables, functions,
    and so on:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些与训练集相关的属性，以了解它是否适合我们的目的。首先，让我们为这个会话创建一个临时视图以进行持久化。尽管如此，我们可以创建一个目录作为接口，用于创建、删除、修改或查询底层数据库、表、函数等：
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can now group the data by the `churn` label and count the number of instances
    in each group, as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以按`churn`标签对数据进行分组，并计算每个组中的实例数量，如下所示：
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding line should show that only `388` customers are likely to switch
    to another operator. However, `2278` customers still have their current operator
    as their preferred one:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 前一行应该显示只有`388`名客户可能更换到另一个运营商。然而，`2278`名客户仍然将当前运营商作为他们首选的运营商：
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So, we have roughly seven times more `False` churn samples than `True` churn
    samples. Since the target is to retain the customers who are most likely to leave,
    we will prepare our training set so that it ensures that the predictive ML model
    is sensitive to the `True` churn samples.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有大约七倍的`False` churn样本比`True` churn样本。由于目标是保留最有可能离开的客户，我们将准备我们的训练集，以确保预测机器学习模型对`True`
    churn样本敏感。
- en: 'Also, since the training set is highly unbalanced, we should downsample the
    `False` `churn` class to a fraction of 388/2278, which gives us `0.1675`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于训练集高度不平衡，我们应该将`False` churn类别下采样到388/2278的分数，这给我们`0.1675`：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This way, we are also mapping only `True` churn samples. Now, let''s create
    a new DataFrame for the training set containing the samples from the downsample
    one only using the `sampleBy()` method:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们也在映射仅包含`True` churn样本。现在，让我们创建一个新的DataFrame，用于训练集，只包含使用`sampleBy()`方法从下采样中提取的样本：
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The third parameter is the seed that''s used for reproducibility purposes.
    Let''s take a look at this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个参数是用于可重复性的种子。让我们看看这个：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, we can see that the classes are almost balanced:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到类别几乎平衡：
- en: '[PRE19]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let''s see how the variables are related to each other. Let''s see how
    the day, night, evening, and international voice calls contribute to the `churn`
    class:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这些变量是如何相互关联的。让我们看看白天、晚上、傍晚和国际语音通话是如何对`churn`类别做出贡献的：
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This, however, doesn''t give any clear correlation because customers who are
    likely to stay make more day, night, evening, and international voice calls than
    the other customers who want to leave:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并没有给出任何明显的相关性，因为可能留下的客户比想要离开的其他客户在白天、晚上、傍晚和国际语音通话上通话更多：
- en: '![](img/270ed293-4589-43ff-9b37-c742898c2e8d.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/270ed293-4589-43ff-9b37-c742898c2e8d.png)'
- en: 'Now, let''s see how many minutes of voice calls on day, night, evening, and
    international voice calls have contributed to the preceding `Total_charge` for
    the `churn` class:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看白天、晚上、傍晚和国际语音通话的通话分钟数是如何对`churn`类别的`Total_charge`做出贡献的：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'From the preceding two tables, it is clear that the total day minutes and total
    day charge are a highly correlated feature in this training set, which is not
    beneficial for our ML model training. Therefore, it would be better to remove
    them altogether. Let''s drop one column of each pair of correlated fields, along
    with the `state_code` and `area_code` columns too since those won''t be used:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的两个表中可以看出，总日分钟数和总日费用是这个训练集中高度相关的特征，这对我们的ML模型训练没有好处。因此，最好完全删除它们。让我们删除每对相关字段中的一列，以及`state_code`和`area_code`列，因为那些将不会被使用：
- en: '[PRE22]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Excellent! Finally, we have our training DataFrame, which can be used for better,
    predictive modeling. Let''s take a look at some of the columns of the resulting
    DataFrame:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 极好！最后，我们有了我们的训练DataFrame，它可以用于更好的预测建模。让我们看看结果DataFrame的一些列：
- en: '[PRE23]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'However, we are not done yet—the current DataFrame cannot be fed to the model.
    This is known as an estimator. As we described earlier, our data needs to be converted
    into a Spark DataFrame format consisting of labels (in `Double`) and features
    (in `Vector`):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还没有完成——当前的DataFrame不能直接输入到模型中。这被称为估算器。正如我们之前所描述的，我们的数据需要转换为Spark DataFrame格式，包括标签（在`Double`中）和特征（在`Vector`中）：
- en: '![](img/596a64fd-2b61-4725-95a9-d7d111d75fe7.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/596a64fd-2b61-4725-95a9-d7d111d75fe7.png)'
- en: Now, we need to create a pipeline to pass the data through by chaining several
    transformers and estimators. The pipeline then works as a feature extractor. More
    specifically, we have prepared two `StringIndexer` transformers and a `VectorAssembler`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要创建一个管道，通过链式连接多个转换器和估算器来传递数据。然后，该管道作为一个特征提取器工作。更具体地说，我们已经准备了两个`StringIndexer`转换器和一个`VectorAssembler`。
- en: 'The first `StringIndexer` converts the `String` categorical feature `international_plan`
    and labels into number indices. The second `StringIndexer` converts the categorical
    label (that is, `churn`) into numeric format. This way, indexing categorical features
    allows decision trees and random forest-like classifiers to treat categorical
    features appropriately, thus improving performance:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个`StringIndexer`将`String`分类特征`international_plan`和标签转换为数字索引。第二个`StringIndexer`将分类标签（即`churn`）转换为数值格式。这样，通过索引分类特征，允许决策树和随机森林等分类器适当地处理分类特征，从而提高性能：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we need to extract the most important features that contribute to the
    classification. Since we have dropped some columns already, the resulting column
    set consists of the following fields:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要提取对分类有贡献的最重要特征。由于我们已经删除了一些列，结果列集包括以下字段：
- en: 'Label → churn: `True` or `False`'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签 → 活跃度：`True` 或 `False`
- en: Features → {`account_length`, `iplanIndex`, `num_voice_mail`, `total_day_mins`,
    `total_day_calls`, `total_evening_mins`, `total_evening_calls`, `total_night_mins`,
    `total_night_calls`, `total_international_mins`, `total_international_calls`, `total_international_num_calls`}
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征 → `{`账户时长`，`iplanIndex`，`num_voice_mail`，`total_day_mins`，`total_day_calls`，`total_evening_mins`，`total_evening_calls`，`total_night_mins`，`total_night_calls`，`total_international_mins`，`total_international_calls`，`total_international_num_calls`}`
- en: 'Since we have already converted categorical labels into numeric ones using
    `StringIndexer`, the next task is to extract the features:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在`StringIndexer`的帮助下将分类标签转换为数值，下一个任务是提取特征：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, let''s transform the features into feature vectors using `VectorAssembler()`,
    which takes all the `featureCols` and combines/transforms them into a single column
    called features:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`VectorAssembler()`将特征转换为特征向量，它接受所有的`featureCols`并将它们组合/转换成一个名为`features`的单列：
- en: '[PRE26]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now that we have the real training set, which consists of label and feature
    vectors ready, the next task is to create an estimator—the third element of a
    pipeline. We will start with a very simple but powerful LR classifier.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了真实的训练集，其中包含准备好的标签和特征向量，接下来的任务是创建一个估算器——管道的第三个元素。我们将从一个非常简单但强大的LR分类器开始。
- en: LR for churn prediction
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 活跃度预测的LR
- en: 'LR is an algorithm for classification, which predicts a binary response. It
    is similar to linear regression, which we described in [Chapter 2](f649db9f-aea9-4509-b9b8-e0b7d5fb726a.xhtml), *Scala
    for Regression Analysis*, except that it does not predict continuous values—it
    predicts discrete classes. The loss function is the sigmoid function (or logistic
    function):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: LR是一种分类算法，它预测二元响应。它与我们在[第2章](f649db9f-aea9-4509-b9b8-e0b7d5fb726a.xhtml)中描述的线性回归类似，即*Scala
    for Regression Analysis*，但它不预测连续值——它预测离散类别。损失函数是sigmoid函数（或逻辑函数）：
- en: '![](img/29b314c7-58a8-45bc-bb3f-1d5aca687aed.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29b314c7-58a8-45bc-bb3f-1d5aca687aed.png)'
- en: 'Similar to linear regression, the intuition behind the cost function is to
    penalize models that have large errors between the real response and the predicted
    response:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归类似，成本函数背后的直觉是惩罚那些实际响应与预测响应之间误差大的模型：
- en: '![](img/9008c370-be7a-40c3-b97d-e0a9ec94501e.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9008c370-be7a-40c3-b97d-e0a9ec94501e.png)'
- en: 'For a given new data point, **x***,* the LR model makes predictions using the
    following equation:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的新的数据点**x**，LR模型使用以下方程进行预测：
- en: '![](img/8193a7b2-cee1-4ccc-86f3-365b682b6739.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8193a7b2-cee1-4ccc-86f3-365b682b6739.png)'
- en: In the preceding equation, the logistic function is applied to the regression
    to get the probabilities of it belonging in either class, where *z = w^T x* and
    if *f(w^T x) > 0.5*, the outcome is positive; otherwise, it is negative. This
    means that the threshold for the classification line is assumed to be at *0.5*.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，对回归应用了逻辑函数以得到它属于任一类的概率，其中*z = w^T x*，如果*f(w^T x) > 0.5*，结果为正；否则为负。这意味着分类线的阈值被假定为*0.5*。
- en: 'Now that we know how the LR algorithm works, let''s start using Spark ML-based
    LR estimator development, which will predict whether a customer is likely to get
    churn or not. First, we need to define some hyperparameters to train a LR-based
    pipeline:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了LR算法是如何工作的，让我们开始使用基于Spark ML的LR估计器开发，这将预测客户是否可能发生流失。首先，我们需要定义一些超参数来训练基于LR的流水线：
- en: '[PRE27]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`RegParam` is a scalar that helps us adjust the strength of the constraints:
    a small value implies a soft margin, while a large value implies a hard margin.
    The `Tol` parameter is used for the convergence tolerance for iterative algorithms,
    such as LR or linear SVM. Once we have the hyperparameters defined and initialized,
    our next task is to instantiate a LR estimator, as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`RegParam`是一个标量，帮助我们调整约束的强度：小值表示软边界，而大值表示硬边界。`Tol`参数用于迭代算法（如LR或线性SVM）的收敛容差。一旦我们定义并初始化了超参数，我们的下一个任务就是实例化一个LR估计器，如下所示：'
- en: '[PRE28]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, let''s build a pipeline estimator using the `Pipeline()` method to chain
    three transformers (the `ipindexer`, `labelindexer`, and `assembler` vectors)
    and the LR estimator (that is, `lr`) in a single pipeline—that is, each of them
    acts as a stage:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`Pipeline()`方法构建一个流水线估计器，将三个转换器（`ipindexer`、`labelindexer`和`assembler`向量）和LR估计器（即`lr`）链接到一个单一的流水线中——即它们各自作为一个阶段：
- en: '[PRE29]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A Spark ML pipeline can have the following components:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML流水线可以包含以下组件：
- en: '**DataFrame**: To hold original data and intermediate transformed ones.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DataFrame**：用于存储原始数据和中间转换后的数据。'
- en: '**Transformer**: Used to transform one DataFrame into another by adding additional
    feature columns.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer**：用于通过添加额外的特征列将一个DataFrame转换为另一个DataFrame。'
- en: '**Estimator**: An estimator is an ML model, such as linear regression.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Estimator**：估计器是一个ML模型，例如线性回归。'
- en: '**Pipeline**: Used to chain the preceding components, DataFrame, transformer,
    and estimator together.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipeline**：用于将前面的组件、DataFrame、转换器和估计器链接在一起。'
- en: '**Parameter**: An ML algorithm has many knobs to tweak. These are called hyperparameters,
    and the values learned by an ML algorithm to fit the data are called parameters.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Parameter**：ML算法有许多可调整的旋钮。这些被称为超参数，而ML算法学习以适应数据的值被称为参数。'
- en: 'In order to perform such a grid search over the hyperparameter space, we need
    to define it first. Here, the functional programming properties of Scala are quite
    handy because we just add function pointers and the respective parameters to be
    evaluated to the parameter grid. Here, a cross-validation evaluator will search
    through LR''s max iteration, regularization param, tolerance, and elastic net
    for the best model:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在超参数空间上执行此类网格搜索，我们首先需要定义它。在这里，Scala的函数式编程特性非常有用，因为我们只需将函数指针和相应的参数添加到参数网格中。在这里，交叉验证评估器将搜索LR的最大迭代次数、正则化参数、容差和弹性网络以找到最佳模型：
- en: '[PRE30]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Note that the hyperparameters form an *n*-dimensional space, where *n* is the
    number of hyperparameters. Every point in this space is one particular hyperparameter
    configuration, which is a hyperparameter vector. Of course, we can''t explore
    every point in this space, so what we basically do is a grid search over an (ideally
    evenly distributed) subset in that space. We then need to define a `BinaryClassificationEvaluator`
    evaluator, since this is a binary classification problem:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，超参数形成一个*n*-维空间，其中*n*是超参数的数量。这个空间中的每一个点代表一个特定的超参数配置，即一个超参数向量。当然，我们无法探索这个空间中的每一个点，所以我们基本上是在这个空间的一个（理想情况下均匀分布的）子集上进行网格搜索。然后我们需要定义一个`BinaryClassificationEvaluator`评估器，因为这是一个二元分类问题：
- en: '[PRE31]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We use a `CrossValidator` by using `ParamGridBuilder` to iterate through the
    max iteration, regression param, tolerance, and elastic net parameters of LR with
    10-fold cross-validation:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用`ParamGridBuilder`来迭代LR的最大迭代次数、回归参数、容差和弹性网络参数，并通过10折交叉验证来使用`CrossValidator`：
- en: '[PRE32]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The preceding code is meant to perform cross-validation. The validator itself
    uses the `BinaryClassificationEvaluator` estimator to evaluate the training in
    the progressive grid space on each fold and make sure that no overfitting occurs.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码旨在执行交叉验证。验证器本身使用`BinaryClassificationEvaluator`估计器在每一折的渐进网格空间上评估训练，并确保不会发生过度拟合。
- en: 'Although there is so much stuff going on behind the scenes, the interface of
    our `CrossValidator` object stays slim and well known as `CrossValidator` also
    extends from the estimator and supports the `fit` method. This means that, after
    calling the `fit` method, the complete predefined pipeline, including all feature
    preprocessing and the LR classifier, is executed multiple times—each time with
    a different hyperparameter vector:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然幕后有很多事情在进行，但我们的`CrossValidator`对象接口仍然保持简洁且广为人知，因为`CrossValidator`也扩展了估计器并支持`fit`方法。这意味着在调用`fit`方法后，包括所有特征预处理和LR分类器在内的完整预定义管道将被多次执行——每次使用不同的超参数向量：
- en: '[PRE33]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, it''s time to evaluate the LR model using the test dataset. First, we
    need to transform the test set, similar to the training set we described previously:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候使用测试数据集评估LR模型了。首先，我们需要转换测试集，类似于我们之前描述的训练集：
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code block shows the `Predicted_label` and the raw `probability` that
    were generated by the model. Additionally, it shows the actual labels. As we can
    see, for some instances, the model predicted correctly, but for other instances,
    it got confused:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块显示了模型生成的`Predicted_label`和原始`probability`，此外还显示了实际标签。正如我们所见，对于某些实例，模型预测正确，但对于其他实例，它却感到困惑：
- en: '![](img/4046ceff-8ab9-4903-8201-afe6a5b67485.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4046ceff-8ab9-4903-8201-afe6a5b67485.png)'
- en: 'The prediction probabilities can also be very useful in ranking customers according
    to their likeliness of imperfection. This way, a limited number of resources can
    be utilized in telecommunication business that can be focused on the most valuable
    customers. However, by looking at the preceding prediction DataFrame, it is difficult
    to guess the classification accuracy. However, in the second step, the evaluator
    evaluates itself using `BinaryClassificationEvaluator`, as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 预测概率也可以非常有用，可以根据客户的不完美可能性对客户进行排名。这样，在电信业务中，可以有限地利用资源，专注于最有价值的客户。然而，通过查看前面的预测DataFrame，很难猜测分类准确率。然而，在第二步中，评估器使用`BinaryClassificationEvaluator`进行自我评估，如下所示：
- en: '[PRE35]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This should show around 77% classification accuracy from our binary classification
    model:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该显示我们的二元分类模型的约77%分类准确率：
- en: '[PRE36]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We compute another performance metric called area under the precision-recall
    curve and the area under the ROC curve. For this, we can construct an RDD containing
    the raw scores on the test set:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算另一个性能指标，称为精确率-召回率曲线下的面积和ROC曲线下的面积。为此，我们可以构建一个包含测试集上原始得分的RDD：
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, the preceding RDD can be used to compute the aforementioned performance
    metrics:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，前面的RDD可以用来计算上述性能指标：
- en: '[PRE38]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In this case, the evaluation returns 77% accuracy, but only 58% precision:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，评估结果显示77%的准确率，但只有58%的精确率：
- en: '[PRE39]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'In the following code, we are calculating some more metrics. False and true
    positive and negative predictions are also useful to evaluate the model''s performance.
    Then, we print the results to see the metrics, as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们正在计算更多的指标。假阳性和假阴性预测对于评估模型性能也是有用的。然后，我们将结果打印出来以查看指标，如下所示：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The preceding code segment shows the true positive, false positive, true negative,
    and false negative rates, which we will use to compute the MCC score later on:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码段显示了真正例、假正例、真负例和假负例的比率，我们将使用这些比率来计算后续的 MCC 分数：
- en: '[PRE41]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, we also compute the MCC score, as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们也计算了 MCC 分数，如下所示：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The preceding line gives a Matthews correlation coefficient of `0.41676531680973805`.
    This is a positive value, which gives us some sign of a robust model. However,
    we have not received good accuracy yet, so let's move on and try other classifiers,
    such as NB. This time, we will use the liner NB implementation from the Apache
    Spark ML package.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 上述行给出了马修斯相关系数为 `0.41676531680973805`。这是一个正值，表明我们的模型具有一定的鲁棒性。然而，我们还没有获得良好的准确率，所以让我们继续尝试其他分类器，例如
    NB。这次，我们将使用 Apache Spark ML 包中的线性 NB 实现。
- en: NB for churn prediction
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NB 用于客户流失预测
- en: 'The NB classifier is based on Bayes'' theorem, with the following assumptions:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: NB 分类器基于贝叶斯定理，具有以下假设：
- en: Independence between every pair of features
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每对特征之间的独立性
- en: Feature values are non-negative, such as counts
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征值是非负的，例如计数
- en: 'For example, if cancer is related to age, this can be used to assess the probability
    that a patient might have cancer*.* Bayes'' theorem is stated mathematically as
    follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果癌症与年龄有关，这可以用来评估患者可能患有癌症的概率*.* 贝叶斯定理可以用以下数学公式表示：
- en: '![](img/ff5bdc71-63cf-4e09-b271-1b58ec82a648.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ff5bdc71-63cf-4e09-b271-1b58ec82a648.png)'
- en: 'In the preceding equation, *A* and *B* are events with *P (B) ≠ 0*. The other
    terms can be described as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方程中，*A* 和 *B* 是具有 *P (B) ≠ 0* 的事件。其他项可以描述如下：
- en: '*P* (*A* | *B*) is called the posterior or the conditional probability of observing
    event *A*, given that *B* is true'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P* (*A* | *B*) 被称为在 *B* 为真的条件下观察事件 *A* 的后验概率或条件概率'
- en: '*P* (*B*| *A*) is the likelihood of event *B* given that *A* is true'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P* (*B*| *A*) 是在 *A* 为真的条件下事件 *B* 发生的可能性'
- en: '*P(A)* is the prior and *P(B)* is the prior probability, also called marginal
    likelihood or marginal probability'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(A)* 是先验，*P(B)* 是先验概率，也称为边缘似然或边缘概率'
- en: 'Gaussian NB is a generalized version of NB that''s used for classification,
    which is based on the binomial distribution of data. For example, our churn prediction
    problem can be formulated as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯 NB 是 NB 的一个推广版本，用于分类，它基于数据的二项分布。例如，我们的客户流失预测问题可以表述如下：
- en: '![](img/27623093-baba-475e-9920-c07b85deede3.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27623093-baba-475e-9920-c07b85deede3.png)'
- en: 'The preceding list can be adopted to solve our problem as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表可以用来解决我们的问题如下：
- en: '*P(class|data)* is the posterior probability of the *class* to be predicted
    by modelling with an independent variable (*data*)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(class|data)* 是使用独立变量 (*data*) 建模预测 *class* 的后验概率'
- en: '*P(data|class)* is the likelihood or the probability of the predictor, given
    *class*'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(data|class)* 是给定 *class* 的预测因子似然或概率'
- en: '*P(class)* is the prior probability of *class* and *P(data)* of the predictor
    or marginal likelihood'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(class)* 是 *class* 的先验概率和预测因子的 *P(data)* 或边缘似然'
- en: 'The well-known Harvard study on happiness shows that only 10% of happy people
    are rich. Although you might think that this statistic is very compelling, you
    might be somewhat interested in knowing the percentage of rich people who are
    also really happy. Bayes'' theorem helps you out with calculating this reserving
    statistic using two additional clues:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知的哈佛幸福研究显示，只有 10% 的快乐人是富人。虽然你可能认为这个统计数据非常有说服力，但你可能对真正快乐的人中富人的百分比也感兴趣。贝叶斯定理帮助你通过使用两个额外的线索来计算这个保留统计：
- en: The percentage of people overall who are happy—that is, *P(A)*
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总体中快乐的人的百分比—that is, *P(A)*
- en: The percentage of people overall who are rich—that is, *P(B)*
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总体中富有的人的百分比—that is, *P(B)*
- en: 'The key idea behind Bayes'' theorem is reversing the statistic by considering
    the overall rates. Suppose the following pieces of information are available prior:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理背后的关键思想是通过考虑整体比率来反转统计。假设以下信息是可用的先验信息：
- en: 40% of people are happy => *P(A)*
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 40% 的人感到快乐 => *P(A)*
- en: 5% of people are rich => *P(B)*
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5% 的人是富人 => *P(B)*
- en: 'Now, let''s consider that the Harvard study is correct—that is, *P(B|A) = 10%*.
    Now that we know the fraction of rich people who are happy, *P(A|B)* can be calculated
    as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设哈佛研究是正确的—that is, *P(B|A) = 10%*。既然我们知道快乐的人中富有的比例， *P(A|B)* 可以计算如下：
- en: '*P(A|B) = {P(A)* P(B|A)} / P(B) = (40%*10%)/5% = 80%*'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(A|B) = {P(A)* P(B|A)} / P(B) = (40%*10%)/5% = 80%*'
- en: 'Consequently, a majority of people are also happy! Nice. To make this clearer,
    let''s assume that the population of the whole world is 5,000, for simplicity.
    According to our calculation, two facts exist:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，大多数人也是快乐的！太好了。为了使这一点更清晰，让我们假设整个世界的人口为5,000，为了简单起见。根据我们的计算，存在两个事实：
- en: '**Fact 1**: This tells us there are 500 people are happy, and the Harvard study
    tells us that 50 of these happy people are also rich'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实1**：这告诉我们有500人感到快乐，哈佛的研究告诉我们其中50个快乐的人也是富有的'
- en: '**Fact 2**: There are 60 rich people altogether, so the fraction of them who
    are happy is 50/60 ~ 83%'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实2**：总共有60个富人，因此其中快乐的人的比例是50/60 ~ 83%'
- en: 'This proves Bayes theorem and its effectiveness. To use NB, we need to instantiate
    an NB estimator, as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这证明了贝叶斯定理及其有效性。要使用NB，我们需要实例化一个NB估计器，如下所示：
- en: '[PRE43]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now that we have transformers and an estimator ready, the next task is to chain
    in a single pipeline—that is, each of them acts as a stage:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了转换器和估计器，下一个任务是链式连接一个单一的管道——也就是说，它们中的每一个都充当一个阶段：
- en: '[PRE44]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s define the `paramGrid` to perform such a grid search over the hyperparameter
    space. Then the cross-validator will search for the best model through the NB''s
    `smoothing` parameter. Unlike LR or SVM, there is no hyperparameter in the NB
    algorithm:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义`paramGrid`以在超参数空间中进行网格搜索。然后交叉验证器将通过NB的`smoothing`参数搜索最佳模型。与LR或SVM不同，NB算法中没有超参数：
- en: '[PRE45]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Additive smoothing, or Laplace smoothing, is a technique that's used to smooth
    categorical data.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 加权平滑，或拉普拉斯平滑，是一种用于平滑分类数据的技巧。
- en: 'Let''s define a `BinaryClassificationEvaluator` evaluator to evaluate the model:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个`BinaryClassificationEvaluator`评估器来评估模型：
- en: '[PRE46]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We use a `CrossValidator` to perform 10-fold cross-validation for best model
    selection:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`CrossValidator`执行10折交叉验证以进行最佳模型选择：
- en: '[PRE47]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let''s call the `fit()` method so that the complete predefined `pipeline`,
    including all feature preprocessing and the LR classifier, is executed multiple
    times—each time with a different hyperparameter vector:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调用`fit()`方法，这样就可以执行完整的预定义`pipeline`，包括所有特征预处理和LR分类器，每次都使用不同的超参数向量：
- en: '[PRE48]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, it''s time to evaluate the predictive power of the SVM model on the test
    dataset. First, we need to transform the test set with the model pipeline, which
    will map the features according to the same mechanism we described in the preceding
    feature engineering step:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候评估SVM模型在测试数据集上的预测能力了。首先，我们需要使用模型管道转换测试集，这将根据我们在前面的特征工程步骤中描述的相同机制映射特征：
- en: '[PRE49]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'However, by looking at the preceding prediction DataFrame, it is difficult
    to guess the classification accuracy. However, in the second step, the evaluator
    evaluates itself using `BinaryClassificationEvaluator`, as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过查看前面的预测DataFrame，很难猜测分类精度。然而，在第二步中，评估器使用`BinaryClassificationEvaluator`评估自己，如下所示：
- en: '[PRE50]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding line of code should show 75% classification accuracy for our
    binary classification model:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码行应该显示我们的二元分类模型的75%分类准确率：
- en: '[PRE51]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Like we did previously, we construct an RDD containing the raw scores on the
    test set:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前做的那样，我们构建了一个包含测试集上原始得分的RDD：
- en: '[PRE52]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Now, the preceding RDD can be used to compute the aforementioned performance
    metrics:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，前面提到的RDD可以用来计算上述性能指标：
- en: '[PRE53]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'In this case, the evaluation returns 75% accuracy but only 55% precision:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，评估返回了75%的准确率，但只有55%的精确率：
- en: '[PRE54]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In the following code, again, we calculate some more metrics. False and true
    positive and negative predictions are also useful to evaluate the model''s performance:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们再次计算了一些更多的指标。错误的和真正的正负预测对于评估模型性能也是有用的：
- en: '[PRE55]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The preceding code segment shows the true positive, false positive, true negative,
    and false negative rates, which we will use to compute the MCC score later on:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段显示了真正例、假正例、真反例和假反例的比率，我们将使用这些比率来计算MCC评分：
- en: '[PRE56]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Finally, we also compute the MCC score, as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们也计算了MCC评分，如下所示：
- en: '[PRE57]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The preceding line gives a Matthews correlation coefficient of `0.14114315409796457`
    and this time, we experienced even worse performance in terms of accuracy and
    MCC scores. So, it's worth trying this with another classifier, such as SVM. We
    will use the linear SVM implementation from the Spark ML package.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 前一行给出了马修斯相关系数为`0.14114315409796457`，这次我们在准确性和MCC评分方面表现得更差。因此，尝试使用另一个分类器，如SVM是值得的。我们将使用Spark
    ML包中的线性SVM实现。
- en: SVM for churn prediction
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM用于客户流失预测
- en: 'SVM is also a population algorithm for classification. SVM is based on the
    concept of decision planes, which defines the decision boundaries we discussed
    at the beginning of this chapter. The following diagram shows how the SVM algorithm
    works:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: SVM也是分类的一种流行算法。SVM基于决策平面的概念，它定义了我们本章开头讨论的决策边界。以下图表显示了SVM算法的工作原理：
- en: '![](img/b56682ec-0673-457c-abc0-bb7d2e504bbf.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b56682ec-0673-457c-abc0-bb7d2e504bbf.png)'
- en: 'SVM uses kernel function, which finds the linear hyperplane that separates
    classes with the maximum margin. The following diagram shows how the data points
    (that is, support vectors) belonging to two different classes (red versus blue)
    are separated using the decision boundary based on the maximum margin:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: SVM使用核函数，它找到具有最大边界的线性超平面来分离类别。以下图表显示了使用基于最大边界的决策边界如何将属于两个不同类别（红色与蓝色）的数据点（即支持向量）分开：
- en: '![](img/bb7dd951-c399-42d4-bddb-f43ae3fd151c.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bb7dd951-c399-42d4-bddb-f43ae3fd151c.png)'
- en: 'The preceding support vector classifier can be represented as a dot product
    mathematically, as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 上述支持向量分类器可以用以下数学方式表示为点积：
- en: '![](img/d6931a67-3fe2-4fb8-90b5-61ff9a5c4db2.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d6931a67-3fe2-4fb8-90b5-61ff9a5c4db2.png)'
- en: 'If the data to be separated is very high-dimensional, the kernel trick uses
    the kernel function to transform the data into a higher-dimensional feature space
    so that they can be linearly separable for classification. Mathematically, the
    kernel trick is to replace the dot product with the kernel, which will allow for
    non-linear decision boundaries and computational efficiency:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要分离的数据非常高维，核技巧使用核函数将数据转换到更高维的特征空间，以便它们可以用于分类的线性可分。从数学上讲，核技巧是用核替换点积，这将允许非线性决策边界和计算效率：
- en: '![](img/295208ef-c737-4e7c-9c4a-31742453c623.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/295208ef-c737-4e7c-9c4a-31742453c623.png)'
- en: 'Now that we already know about SVMs, let''s start using the Spark-based implementation
    of SVM. First, we need to define some hyperparameters to train an LR-based pipeline:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了SVM，让我们开始使用基于Spark的SVM实现。首先，我们需要定义一些超参数来训练一个基于LR的pipeline：
- en: '[PRE58]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Once we have the hyperparameters defined and initialized, the next task is
    to instantiate an SVM estimator, as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义并初始化了超参数，下一个任务就是实例化一个SVM估计器，如下所示：
- en: '[PRE59]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now that we have transformers and an estimator ready, the next task is to chain
    in a single pipeline—that is, each of them acts as a stage:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了转换器和估计器，下一个任务是链式连接一个单一的pipeline——也就是说，它们中的每一个都充当一个阶段：
- en: '[PRE60]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let''s define the `paramGrid` to perform such a grid search over the hyperparameter
    space. This searches through SVM''s max iteration, regularization param, tolerance,
    and elastic net for the best model:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义`paramGrid`以在超参数空间中进行网格搜索。这搜索SVM的最大迭代次数、正则化参数、容差和弹性网络以找到最佳模型：
- en: '[PRE61]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let''s define a `BinaryClassificationEvaluator` evaluator to evaluate the model:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个`BinaryClassificationEvaluator`评估器来评估模型：
- en: '[PRE62]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We use a `CrossValidator` to perform 10-fold cross-validation for best model
    selection:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`CrossValidator`进行10折交叉验证以选择最佳模型：
- en: '[PRE63]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Now, let''s call the fit method so that the complete predefined `pipeline`,
    including all feature preprocessing and the LR classifier, is executed multiple
    times—each time with a different hyperparameter vector:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们调用fit方法，以便执行完整的预定义`pipeline`，包括所有特征预处理和LR分类器，多次执行——每次使用不同的超参数向量：
- en: '[PRE64]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now, it''s time to evaluate the predictive power of the SVM model on the test
    dataset:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候评估SVM模型在测试数据集上的预测能力了：
- en: '[PRE65]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The preceding code block shows the predicted label and the raw probability generated
    by the model. Additionally, it shows the actual labels.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块显示了模型生成的预测标签和原始概率，以及实际标签。
- en: 'As we can see, for some instances, the model predicted correctly, but for some
    other instances, it got confused:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，对于某些实例，模型预测正确，但对于某些其他实例，它感到困惑：
- en: '![](img/525773ae-dfca-4d02-ac7d-5e9ccfd6a72e.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/525773ae-dfca-4d02-ac7d-5e9ccfd6a72e.png)'
- en: 'However, by looking at the preceding prediction DataFrame, it is difficult
    to guess the classification accuracy. However, in the second step, the evaluator
    evaluates itself using `BinaryClassificationEvaluator`, as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过查看前面的预测DataFrame，很难猜测分类准确率。然而，在第二步中，评估器使用`BinaryClassificationEvaluator`评估自己，如下所示：
- en: '[PRE66]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Therefore, we get about 75% classification accuracy from our binary classification
    model:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们从我们的二分类模型中获得了大约75%的分类准确率：
- en: '[PRE67]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Now, we construct an RDD containing the raw scores on the test set, which will
    be used to compute performance metrics such as area under the precision-recall
    curve (AUC) and are under the received operating characteristic curve (ROC):'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们构建一个包含测试集原始分数的RDD，它将被用来计算性能指标，如精确度-召回率曲线下的面积（AUC）和接收机操作特征曲线下的面积（ROC）：
- en: '[PRE68]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now, the preceding RDD can be used to compute the aforementioned performance
    metrics:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以使用前面的 RDD 来计算上述性能指标：
- en: '[PRE69]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'In this case, the evaluation returns 75% accuracy, but only 55% precision:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，评估返回了75%的准确率，但只有55%的精确度：
- en: '[PRE70]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'We can also calculate some more metrics; for example, false and true positive
    and negative predictions are also useful to evaluate the model''s performance:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算一些更多的指标；例如，错误和正确预测的正负样本也是评估模型性能的有用信息：
- en: '[PRE71]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The preceding code segment shows the true positive, false positive, true negative,
    and false negative rates, which we will use to compute the MCC score later on:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段显示了真正例、假正例、真反例和假反例的比率，我们将使用这些比率来计算MCC分数：
- en: '[PRE72]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Finally, we also compute the MCC score, as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还计算了MCC分数，如下所示：
- en: '[PRE73]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: This gave me a Matthews correlation coefficient of `0.3888239300421191`. Although
    we have tried to use as many as three classification algorithms, we still haven't
    received good accuracy. Considering that SVM managed to give us an accuracy of
    76%, this is still considered to be low. Moreover, there is no option for most
    suitable feature selection, which helps us train our model with the most appropriate
    features. To improve classification accuracy, we will need to use tree-based approaches,
    such as DT, RF, and GBT, which are expected to provide more powerful responses.
    We will do this in the next chapter.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 这给了我一个马修斯相关系数为`0.3888239300421191`。尽管我们尝试使用尽可能多的三个分类算法，但我们仍然没有获得良好的准确率。考虑到SVM设法给我们带来了76%的准确率，这仍然被认为是较低的。此外，没有最适合的特征选择选项，这有助于我们使用最合适的特征来训练模型。为了提高分类准确率，我们需要使用基于树的算法，如DT、RF和GBT，这些算法预计将提供更强大的响应。我们将在下一章中这样做。
- en: Summary
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned about different classical classification algorithms,
    such as LR, SVM, and NB. Using these algorithms, we predicted whether a customer
    is likely to cancel their telecommunications subscription or not. We've also discussed
    what types of data are required to build a successful churn predictive model.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了不同的经典分类算法，如LR、SVM和NB。使用这些算法，我们预测客户是否可能取消他们的电信订阅。我们还讨论了构建成功的客户流失预测模型所需的数据类型。
- en: Tree-based and tree ensemble classifiers are really useful and robust, and are
    widely used for solving both classification and regression tasks. In the next
    chapter, we will look into developing such classifiers and regressors using tree-based
    and ensemble techniques such as DT, RF, and GBT, for both classification and regression.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的分类器和树集成分类器非常实用且稳健，并且广泛应用于解决分类和回归任务。在下一章中，我们将探讨如何使用基于树和集成技术（如DT、RF和GBT）来开发这样的分类器和回归器，用于分类和回归。
