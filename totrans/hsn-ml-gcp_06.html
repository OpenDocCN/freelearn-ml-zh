<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Essential Machine Learning</h1>
                </header>
            
            <article>
                
<p>So far, in previous chapters, we went through the various ETL processes available in GCP. In this chapter, we will start our journey of machine learning and deep learning through the following topics:</p>
<ul>
<li>Applications of machine learning</li>
<li>Supervised and unsupervised machine learning</li>
<li>Overview of major machine learning techniques</li>
<li>Data splitting</li>
<li>Measuring the accuracy of a model</li>
<li>The difference between machine learning and deep learning</li>
<li>Applications of deep learning</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications of machine learning</h1>
                </header>
            
            <article>
                
<p>Machine learning encompasses a set of techniques that learn from historical data. Based on the patterns learned from historical data, the machine learning technique predicts the probability of an event happening on a future dataset. Given the way in which machine learning works, there are multiple applications of the set of techniques. Let's explore some of them in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Financial services</h1>
                </header>
            
            <article>
                
<p>Some applications in the field of finance are as follows:</p>
<ul>
<li>Identifying the riskiness of a loan/credit card applicant</li>
<li>Estimating the credit limit of a given customer</li>
<li>Predicting whether a card transaction is a fraudulent transaction</li>
<li>Identifying the customer segments that need to be targeted for a campaign</li>
<li>Predicting whether a customer is likely to default in the next few months</li>
<li>Recommending the right financial product that a customer should buy</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Retail industry</h1>
                </header>
            
            <article>
                
<p>The following are some applications of the different techniques of machine learning in the retail industry:</p>
<ul>
<li>Predicting the next product that a customer is likely to buy</li>
<li>Estimat<span>ing</span> the optimal price point for a given product</li>
<li>Forecast<span>ing</span> the number of units a product will sell over time</li>
<li>Target<span>ing</span> customers by bundling products for promotion</li>
<li>Estimat<span>ing</span> a customer lifetime value</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Telecom industry</h1>
                </header>
            
            <article>
                
<p>Here are a few applications of machine learning in the telecom industry:</p>
<ul>
<li>Predicting the likelihood of a call drop before the start of a call</li>
<li>Predicting if a customer is likely to churn in the next few months</li>
<li>Identifying add-ons to monthly usage that could be sold to a customer</li>
<li>Identifying the customers who are less likely to pay for postpaid services</li>
<li>Workforce optimization for field force effectiveness</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Supervised and unsupervised machine learning</h1>
                </header>
            
            <article>
                
<p>Supervised machine learning constitutes the set of techniques that work towards building a model that approximate a function. The function takes a set of input variables, which are alternatively called independent variables, and tries to map the input variables to the output variable, alternatively called the dependent variable or the label.</p>
<p>Given that we know the label (or the value) we are trying to predict, for a set of input variables, the technique becomes a supervised learning problem.</p>
<p>In a similar manner, in an unsupervised learning problem, we do not have the output variable that we have to predict. However, in unsupervised learning, we try to group the data points so that they form logical groups.</p>
<p>A distinction between supervised and unsupervised learning at a high level can be obtained as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7c8d6266-8c0c-45ae-b8c1-2efa36c973b2.png" style=""/></div>
<p>In the preceding diagram, the supervised learning approach can distinguish between the two classes, as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ac66330c-2d9a-48a1-8038-60bad3a57ace.png" style=""/></div>
<p>In supervised learning, there are two major objectives that can be achieved:</p>
<ul>
<li>Predict the probability of an event happening—classification</li>
<li>Estimate the value of the continuous dependent variable—regression</li>
</ul>
<p>The major methods that can help in classification are as follows:</p>
<ul>
<li>Logistic regression</li>
<li>Decision tree</li>
<li>Random forest</li>
<li>Gradient boosting</li>
<li>Neural network</li>
</ul>
<p>Along with these (except logistic regression), linear regression also helps in estimating a continuous variable (regression).</p>
<p>While these techniques help in estimating a continuous variable or in predicting the probability of an event happening (discrete variable prediction), unsupervised learning helps in grouping. Grouping can be either of rows (which is a typical clustering technique) or of columns (a dimensionality reduction technique). The major methods of row groupings are:</p>
<ul>
<li>K-means clustering</li>
<li>Hierarchical clustering</li>
<li>Density-based clustering</li>
</ul>
<p>The major methods of column groupings are:</p>
<ul>
<li>Principal component analysis</li>
<li><strong>t-Distributed Stochastic Neighbor Embedding</strong> (<strong>t-SNE</strong>)</li>
</ul>
<p>Row groupings result in identifying the segments of customers (observations) that are there in our dataset.</p>
<p>Column groupings result in reducing the number of columns. This comes in handy when the number of independent variables is high. Typically when this is the case, there could be an issue in building the model, as the number of weights that need to be estimated could be high. Also, there could be an issue in interpreting the model, as some of the independent variables could be highly correlated with each other. Principal component analysis or t-SNE comes in handy in such a scenario, where we reduce the number of independent variables without losing too much of the information that is present in the dataset.</p>
<p>In the next section, we will go through an overview of all the major machine learning algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overview of machine learning techniques</h1>
                </header>
            
            <article>
                
<p>Before going through an overview of the major machine learning techniques, let's go through the function that we would want to optimize in a regression technique or a classification technique.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Objective function in regression</h1>
                </header>
            
            <article>
                
<p>In a regression exercise, we estimate the continuous variable value. In such a scenario, our predictions can be lower than the actual value or higher; that is, the error value could be either positive or negative. In such a scenario, the objective function translates to minimizing the sum of squared values of the difference between the actual and predicted values of each of the observations in the dataset.</p>
<p>In mathematical terms, the preceding is written as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/42d4aba6-3c58-462f-a211-fb58ffc73338.png" style="width:13.25em;height:4.50em;"/></div>
<p>In the given equation:</p>
<ul>
<li><em>SSE</em> stands for the <em>sum of squared errors</em></li>
<li><em>y</em> refers to the actual value of the dependent variable</li>
<li><em>y'</em> refers to the estimated value of the dependent variable</li>
<li>∑ refers to the summation of the squared errors across all the observations in the dataset</li>
</ul>
<p>Given the objective function, let's understand how linear regression works at a high level.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear regression</h1>
                </header>
            
            <article>
                
<p>In linear regression, we assume a linear relationship between the independent variables and the dependent variable. Linear regression is represented as follows:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/7c3f054d-cbcf-4906-9e71-32069d48bac5.png" style="width:10.67em;height:1.42em;"/></div>
<p>In the given equation:</p>
<ul>
<li><em>Y</em> is the dependent variable</li>
<li><em>W</em> is the weight associated with the independent variable <em>X</em></li>
<li><em>b</em> is the intercept value</li>
</ul>
<p>If there are multiple independent variables (let's say two independent variables, <em>x1</em> and <em>x2</em>), the equation is as follows:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/e42934ac-8357-4e22-b5c4-380b299582dc.png" style="width:18.33em;height:1.42em;"/></div>
<p><span>In the given equation</span>:</p>
<ul>
<li><em>w1</em> is the weight associated with variable <em>x1</em></li>
<li><em>w2</em> is the weight associated with variable <em>x2</em></li>
</ul>
<p>A typical linear regression looks as follows, where the <em>x</em> axis is the independent variable and the <em>y</em> axis is the dependent variable:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8eb8d1b7-4303-4ee3-88d2-5b99a27c004b.png"/></div>
<p>The straight line (with a certain slope and intercept) is the equation of linear regression.</p>
<p>Note that the line in the graph is the one that minimizes the overall squared error.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Decision tree</h1>
                </header>
            
            <article>
                
<p>Decision tree is a technique that helps us in deriving rules from data. A rule-based technique is very helpful in explaining how the model is supposed to work in estimating a dependent variable value.</p>
<p>A typical decision tree looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/12b92c36-714f-4dfe-a7de-4c0b3dd14e52.png" style=""/></div>
<p>The preceding diagram is explained as follows:</p>
<ul>
<li><strong>ROOT Node:</strong> This represents the entire population or a sample, and it is further divided into two or more further nodes.</li>
<li><strong>Splitting</strong>: A process of dividing a node into two or more subnodes based on a certain rule.</li>
<li><strong>Decision Node: </strong>When a subnode splits into further subnodes, it is called <strong>decision node.</strong></li>
<li><strong>Leaf/Terminal Node: </strong>The final node in a decision tree is a leaf or terminal node.</li>
<li><strong>Pruning: </strong>When we remove the subnodes of a decision node, this process is called <strong>pruning</strong>. You can say it is the opposite process of splitting.</li>
<li><strong>Branch/Sub-Tree:</strong> A subsection of the entire tree is called a <strong>branch</strong> or a <strong>sub-tree</strong>.</li>
<li><strong>Parent and child node:</strong> A node that is divided into subnodes is called the <strong>parent node</strong> of subnodes, whereas the subnodes are the children of the parent node.</li>
</ul>
<p>Given a dependent variable and an independent variable value, we will go through how a decision tree works using the following dataset:</p>
<table>
<tbody>
<tr>
<td><strong>var2</strong></td>
<td><strong>response</strong></td>
</tr>
<tr>
<td><kbd>0.1</kbd></td>
<td><kbd>1996</kbd></td>
</tr>
<tr>
<td><kbd>0.3</kbd></td>
<td><kbd>839</kbd></td>
</tr>
<tr>
<td><kbd>0.44</kbd></td>
<td><kbd>2229</kbd></td>
</tr>
<tr>
<td><kbd>0.51</kbd></td>
<td><kbd>2309</kbd></td>
</tr>
<tr>
<td><kbd>0.75</kbd></td>
<td><kbd>815</kbd></td>
</tr>
<tr>
<td><kbd>0.78</kbd></td>
<td><kbd>2295</kbd></td>
</tr>
<tr>
<td><kbd>0.84</kbd></td>
<td><kbd>1590</kbd></td>
</tr>
</tbody>
</table>
<p> </p>
<p>In the preceding dataset, the variable <kbd>var2</kbd> is the input variable and the <kbd>response</kbd> variable is the dependent variable.</p>
<p>In the first step of the decision tree, we sort the input variable from lowest to highest and test multiple rules, one at a time.</p>
<p>In the first instance, all the observations of the dataset that have a <kbd>var2</kbd> value of less than <kbd>0.3</kbd> belong to the left node of a decision tree, and the other observations belong to the right node of the decision tree.</p>
<p>In a regression exercise, the predicted value of the left node is the average of the <kbd>response</kbd> variable for all the observations that belong to the left node. Similarly, the predicted value of the right node is the average of <kbd>response</kbd> for all the observations that belong to the right node.</p>
<p>Given a predicted value for the left node and a different predicted value for the observations that belong to the right node, the squared error can be calculated for each of the left and right nodes. The overall error for a probable rule is the sum of squared error in both left and right nodes.</p>
<p>The decision rule that is implemented is the rule that has the minimum squared error among all the possible rules.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest</h1>
                </header>
            
            <article>
                
<p>Random forest is an extension of decision trees. It is a forest as it is a combination of multiple trees, and is random as we randomly sample different observations for each of the decision trees.</p>
<p>A random forest works by averaging the prediction of each of the decision trees (which work on a sample of the original dataset).</p>
<p>Typically, a random forest works better than a single decision tree, as the influence of outliers is reduced in it (because in some samples, outliers might not have occurred), whereas, in a decision tree, an outlier would have definitely occurred (if the original dataset contained an outlier).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gradient boosting</h1>
                </header>
            
            <article>
                
<p>While a random forest works in a framework where multiple parallel trees are built, gradient boosting takes a different approach—building a deep framework.</p>
<p>The gradient in gradient boosting refers to the difference between actual and predicted values, and boosting refers to improvement, that is, improving the error over different iterations.</p>
<p>Gradient boosting also leverages the way in which decision trees work in the following way:</p>
<ul>
<li>Build a decision tree to estimate the dependent variable</li>
<li>Calculate the error, that is, the difference between actual and predicted value</li>
<li>Build another decision tree that predicts the error</li>
<li>Update the prediction by taking the prediction of error of the previous decision tree into account</li>
</ul>
<p>This way, gradient boosting continuously builds a decision tree that predicts the error of the previous decision tree and thus a depth-based framework in gradient boosting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural network</h1>
                </header>
            
            <article>
                
<p>A neural network provides a way to approximate nonlinear functions. Nonlinearity is achieved by applying activation functions on top of the summation of weighted input variables.</p>
<p>A neural network looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/046bc137-9809-4623-95c1-3c16eda6b6d3.png" style=""/></div>
<p>The input level contains the inputs and the hidden layer contains the summation of the weighted input values, where each connection is associated with a weight.</p>
<p>The nonlinearity is applied to the hidden layer. Typical non-linear activation functions could be sigmoid, tanh, or rectified linear unit.</p>
<p>The output level is associated with the summation of weights associated with each hidden unit. The optimal value of weights associated with each connection is obtained by adjusting the weights in such a way that the overall squared error value is minimized. More details of how a neural network works are provided in a later chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression</h1>
                </header>
            
            <article>
                
<p>As discussed before, logistic regression is used to classify a prediction to one class or another depending on the input dataset. Logistic regression uses the sigmoid function to attain the probability of an event happening.</p>
<p>The sigmoid curve looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ba322a10-423e-4a95-8e72-2a137a06009c.png" style=""/></div>
<p>Note that the output is a high probability when the <em>x</em> axis value is greater than 3 and the output is a very low probability when the <em>x</em> axis value is less than 3.</p>
<p>Logistic regression differs from linear regression in the usage of the activation function. While a linear regression equation would be <em>Y = a + b * X</em>, a logistic regression equation would be:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/6aba77a4-c022-44f6-9801-87670cbd67b5.png" style="width:20.25em;height:1.83em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Objective function in classification</h1>
                </header>
            
            <article>
                
<p>In a regression technique, we minimize the overall squared error. However, in a classification technique, we minimize the overall cross-entropy error.</p>
<p>A binary cross-entropy error is as follows:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/0336cc5f-d283-4c29-b27a-79ee9c4e4a73.png" style="width:22.00em;height:1.83em;"/></div>
<p>In the given equation:</p>
<ul>
<li>y is the actual dependent variable</li>
<li><em>p</em> is the probability of an event happening</li>
</ul>
<p>For a classification exercise, all the preceding algorithms work; it's just that the objective function changes to cross-entropy error minimization instead of squared error.</p>
<p>In the case of a decision tree, the variable that belongs to the root node is the variable that provides the highest information gain when compared to all the rest of the independent variables. Information gain is defined as the improvement in overall entropy when the tree is split by a given variable when compared to no splitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data splitting</h1>
                </header>
            
            <article>
                
<p>One of the key problems that need to be addressed while working on any machine learning model is: <em>how accurate can this model be once it is implemented in production on a future dataset?</em></p>
<p>It is not possible to answer this question straight away. However, it is really important to obtain the buy-in from commercial teams that ultimately get benefited from the model build. Dividing the dataset into training and testing datasets comes in handy in such a scenario.</p>
<p>The training dataset is the data that is used to build the model. The testing dataset is the dataset that is not seen by the model; that is, the data points are not used in building the model. Essentially, one can think of the testing dataset as the dataset that is likely to come in future. Hence, the accuracy that we see on the testing dataset is likely to be the accuracy of the model on the future dataset.</p>
<p>Typically, in regression, we deal with the problem of generalization/overfitting. The overfitting problem arises when the model is so complex that it perfectly fits all the data points—thus resulting in a minimal possible error rate. A typical example of an overfitted dataset looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d0795b03-7685-41c0-ae81-a4de6b6a53c2.png" style=""/></div>
<p>From the graph dataset, one can observe that the line (colored in black) does not fit all the data points perfectly, while the curve (colored in blue) fits the points perfectly and hence has minimal error on the data points on which it is trained.</p>
<p>However, the line has a better chance of being more generalizable when compared to the curve on a new dataset. Thus, in practice, regression/classification is a trade-off between generalizability and complexity of <span>the</span> <span>model.</span></p>
<p>The lower the generalizability of the model, the higher the error rate on unseen data points.</p>
<p>This phenomenon can be observed in the following graph. As the complexity of the model increases, the error rate of unseen data points keeps reducing till a point, after which it starts increasing again:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ae560c6a-9894-4e43-a8f4-a4594c219b6f.png" style=""/></div>
<p>The curve colored in blue is the error rate on the training dataset, and the curve colored in red is the testing dataset error rate.</p>
<p>The validation dataset is used to obtain the optimal hyperparameters of the model. For example, in techniques such as random forest or GBM, the number of trees needed to build or the depth of a tree is a hyper parameter. As we keep changing the hyperparameter, the accuracy on unseen datasets changes.</p>
<p>However, we cannot go on varying the hyperparameter until the test dataset accuracy is the highest, as we would have seen the practically future dataset (testing dataset) in such a scenario.</p>
<p>The validation dataset comes in handy in such scenarios, where we keep varying the hyperparameters on the training dataset until we see that the accuracy on the validation dataset is the highest. That would thus form the optimal hyperparameter combination for the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Measuring the accuracy of a model</h1>
                </header>
            
            <article>
                
<p>The methods of evaluating the accuracy of a model differ between supervised learning and unsupervised learning.</p>
<p>In a typical linear regression (where continuous values are predicted), there are a couple of ways of measuring the error of the model. Typically, error is measured on the validation and testing datasets, as measuring error on a training dataset (the dataset using which a model is built) is misleading. Hence, error is always measured on the dataset that is not used to build a model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Absolute error</h1>
                </header>
            
            <article>
                
<p>Absolute error is defined as the absolute value of the difference between the forecast value and actual value. Let's imagine a scenario as follows:</p>
<table>
<tbody>
<tr>
<td>
<p> </p>
</td>
<td>
<p><strong>Actual value</strong></p>
</td>
<td>
<p><strong>Predicted value</strong></p>
</td>
<td>
<p><strong>Error</strong></p>
</td>
<td>
<p><strong>Absolute error</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong>Data point 1</strong></p>
</td>
<td>
<p>100</p>
</td>
<td>
<p>120</p>
</td>
<td>
<p>20</p>
</td>
<td>
<p>20</p>
</td>
</tr>
<tr>
<td>
<p><strong>Data point 2</strong></p>
</td>
<td>
<p>100</p>
</td>
<td>
<p>80</p>
</td>
<td>
<p>-20</p>
</td>
<td>
<p>20</p>
</td>
</tr>
<tr>
<td>
<p><strong>Overall</strong></p>
</td>
<td>
<p>200</p>
</td>
<td>
<p>200</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>40</p>
</td>
</tr>
</tbody>
</table>
<p>In the preceding scenario, we see that the overall error is 0 (as one error is +20 and the other is -20). If we assume that the overall error of the model is 0, we are missing out the fact that the model is not working well on individual data points.</p>
<p>Hence, in order to avoid the issue of a positive error and negative error canceling each other <span>out</span> <span>and thus resulting in minimal error, we consider the absolute error of a model, which in this case is 40; and the absolute error rate is 40/200 = 20%</span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Root mean square error</h1>
                </header>
            
            <article>
                
<p>Another approach of solving the problem of inconsistent signs of error is to square the error (the square of a negative number is a positive number). The scenario discussed previously can be translated as follows:</p>
<table>
<tbody>
<tr>
<td>
<p> </p>
</td>
<td>
<p><strong>Actual value</strong></p>
</td>
<td>
<p><strong>Predicted value</strong></p>
</td>
<td>
<p><strong>Error</strong></p>
</td>
<td>
<p><strong>Squared error</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong>Data point 1</strong></p>
</td>
<td>
<p>100</p>
</td>
<td>
<p>120</p>
</td>
<td>
<p>20</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p><strong>Data point 2</strong></p>
</td>
<td>
<p>100</p>
</td>
<td>
<p>80</p>
</td>
<td>
<p>-20</p>
</td>
<td>
<p>400</p>
</td>
</tr>
<tr>
<td>
<p><strong>Overall</strong></p>
</td>
<td>
<p>200</p>
</td>
<td>
<p>200</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>800</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>In this case, the overall squared error is 800 and root mean squared error is the square root of (800/2), which is 20.</p>
<p>The accuracy in the case of a classification exercise is measured as follows: absolute error and RMSE are applicable when predicting continuous variables. However, predicting an event with discrete outcomes is a different process. Discrete event prediction happens in terms of probabilities; that is, the result of the model is a probability that certain event happens. In such cases, even though absolute error and RMSE can be theoretically used, there are other metrics of relevance.</p>
<p>A confusion matrix counts the number of instances when the model predicted the outcome of an event and measures it against the actual values, as follows:</p>
<table>
<tbody>
<tr>
<td>
<p> </p>
</td>
<td>
<p><strong>Predicted fraud</strong></p>
</td>
<td>
<p><strong>Predicted non-fraud</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong>Actual fraud</strong></p>
</td>
<td>
<p><strong>True positive</strong> (<strong>TP</strong>)</p>
</td>
<td>
<p><strong>False negative</strong> (<strong>FN</strong>)</p>
</td>
</tr>
<tr>
<td>
<p><strong>Actual non-fraud</strong></p>
</td>
<td>
<p><strong>False positive</strong> (<strong>FP</strong>)</p>
</td>
<td>
<p><strong>True negative</strong> (<strong>TN</strong>)</p>
</td>
</tr>
</tbody>
</table>
<div class="mce-root CDPAlignCenter CDPAlign"><em>Sensitivity or TP rate or recall = TP/ (total positives) = TP/ (TP+FN)</em></div>
<div class="mce-root CDPAlignCenter CDPAlign"><em>Specificity or TN rate = TN/ (total negative) = TP/(FP + TN)</em></div>
<div class="mce-root CDPAlignCenter CDPAlign"><em>Precision or positive predicted value = TP/(TP + FP)</em></div>
<div class="mce-root CDPAlignCenter CDPAlign"><em>Accuracy = (TP + TN)/(TP + FN + FP + TN)</em></div>
<div class="mce-root CDPAlignCenter CDPAlign"><em>F1 score = 2TP/ (2TP + FP + FN)</em></div>
<p>A <strong>receiver operating characteristic</strong> (<strong>ROC</strong>) curve gives the relation between the true positive rate and false positive rate of various cutoffs. Let's say the model prediction is &gt;0.8. We assume that we should classify the prediction as positive. The 0.8 here is the cutoff point. Cutoffs come into the picture here as a model's prediction will always be a probability number—a value between 0 and 1. Hence, an analyst needs to bring his/her judgment in ascertaining the optimal cutoff.</p>
<p>An ROC curve is a curve where (1-specificity) is on the <em>x</em> axis and sensitivity is on the <em>y</em> axis. The curve is generated by plotting the various combinations of sensitivity and (1-specificity) by changing the cutoff, which decides whether the predicted value should be a 1 or a 0.</p>
<p>In an ideal scenario, where data can be clearly segregated and accuracy is 100%, there lies a cutoff of the probability, after which the predicted value is of one class; it belongs to the other class for values below the cutoff. In such a scenario, for certain values of cutoffs, the ROC curve would be on the <em>y</em> axis only, that is, specificity=1. For the rest of its length, the curve is going to be parallel to the <em>x</em> axis.</p>
<p>A typical example of an ROC curve looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3e0d298b-6836-409b-a46c-2b08334744a8.png" style=""/></div>
<p>An ROC curve is a measure of how much better the model's performance is over a random guess. A random guess is where in case of a churn of 5% customers, the random guesser guesses that for every twenty customers, one among them will be labeled as a potential churner. In such a scenario, the random guess is going to capture 20% of all churners after randomly labeling 20% of all the customers.</p>
<p>A model's predictive power is in being able to move as close to 100% accuracy as possible, that is, moving away from random guesses as much as possible.</p>
<p><strong>Area under the curve</strong> (<strong>AUC</strong>) is a measure of the area between the model curve and the random guess curve. The higher the AUC, the higher the predictive accuracy of the model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The difference between machine learning and deep learning</h1>
                </header>
            
            <article>
                
<p>So far, we have looked at how various machine learning algorithms work at a high level. In this section, we will understand how deep learning differs from machine learning.</p>
<p>One of the key attributes of a machine learning task is that the inputs are given by the analyst or data scientist. Quite often, feature engineering plays a key role in improving the accuracy of the model. Moreover, if the input dataset is an unstructured one, feature engineering gets a lot more tricky. More often than not, it boils down to the knowledge of individual in deriving relevant features to build a more accurate model.</p>
<p>For example, let's imagine a scenario where, given a set of words in a sentence, we are trying to predict the next word. In such a scenario, traditional machine learning algorithms work as follows:</p>
<ul>
<li>One-hot encode each word in a sentence</li>
<li>Represent the input sequence of words using the one-hot encoded vector</li>
<li>Represent the output word, also using a one-hot encoded vector</li>
<li>Build a model to predict the output word vector given the set of input words by optimizing for the relevant loss function</li>
</ul>
<p>While the preceding method works, we face three major challenges in building the model:</p>
<ul>
<li>Dimension of the one-hot encoded vector:
<ul>
<li>A piece of text is likely to have hundreds or thousands of unique words</li>
<li>High-dimensional data is likely to result in multiple issues—such as multicollinearity and the time taken to build a model</li>
</ul>
</li>
<li>Order of words is missing in the input dataset</li>
<li>Distance between two words is the same, irrespective of whether the words are similar to each other or not:
<ul>
<li>For example, in a one-hot encoded vector scenario, the distance between king and prince would be the same as the distance between king and cheese</li>
</ul>
</li>
</ul>
<p>Deep learning comes in handy in such a scenario. Using some of the techniques in deep learning (for example, Word2vec), we would be able to solve the following among the issues listed just now:</p>
<ul>
<li>Represent each word in a lower-dimensional space in such a way that words that are similar to each other have similar word vectors and words that are not similar to each other do not have similar vectors</li>
<li>Moreover, by representing a word in a lower-dimensional space (let’s say 100), we would have solved the problem of high dimensionality of data</li>
</ul>
<p>There are multiple variants of the Word2vec technique, such as the continuous bag-of-words model and the continuous skip-gram model.</p>
<p>The architecture of a CBOW model is as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/be7b10e6-7f0d-40fa-af6d-da43a40231fe.png" style=""/></div>
<p>Note that the input vector is the one-hot encoded version (as we would have used in a typical machine learning model). The hidden layer neurons ensure that we represent the 10,000-dimensional input vector in a 300-dimensional word vector.</p>
<p>The actual values in the output layer represent the one-hot encoded versions of the surrounding words (which form the context).</p>
<p>Another technique in deep learning that comes in handy to solve the preceding problem is the <strong>recurrent neural network</strong> (<strong>RNN</strong>). An RNN works towards solving the sequence-of-words problem that traditional machine learning faced in the scenario laid out previously.</p>
<p>RNN provides each word vector in order to predict the next word in the sequence. More details of how RNN works will be provided in a different chapter. The popular variants of the RNN technique are <strong>long short-term memory</strong> (<strong>LSTM</strong>) and <strong>gated recurrent unit</strong> (<strong>GRU</strong>):</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1e155073-cb6b-4175-9799-111cc8f80cba.png" style=""/></div>
<p>The preceding diagram represents a typical RNN, where <em>x<sub>(t-1)</sub></em>, <em>x<sub>(t)</sub></em> and <em>x<sub>(t+1)</sub></em> represent the words in each time period, <em>W</em> is the weightage associated with a previous word in predicting the next word, and <em>O<sub>(t)</sub></em> is the output in time <em>t</em>.</p>
<p>LSTM comes in handy when the weightage that needs to be associated with a word that occurred much earlier in sequence would have be high in predicting the next word.</p>
<p>A combination of Word2vec and RNN, which are variants of neural networks, helps in avoiding the challenge of feature engineering with the given text data.</p>
<p>In order to solidify our understanding of the difference between machine learning and deep learning, let's go through another example: predicting the label of an image.</p>
<p>We will use a classic example—the MNIST dataset (we will be using MNIST a lot more in future chapters).</p>
<p>The MNIST dataset contains images of various digits, from zero to nine. Each image is 28 x 28 pixels in size. The task is to predict the label of the image by analyzing the various pixel values. A sample image in the MNIST dataset looks like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/afa8a2ff-8930-4e86-9c80-dc690995f794.png" style=""/></div>
<p>Traditional machine learning solves the preceding problem as follows:</p>
<ul>
<li>Treat each pixel as a separate variable; that is, we have a total of 784 variables</li>
<li>One-hot encode the label column</li>
<li>Predict the probability of a label occurring</li>
</ul>
<p>The challenge with the way in which we solve the preceding problem is as follows:</p>
<ul>
<li>The model will not take pixel adjacencies into account</li>
<li>The model will not account for translation or rotation of the image</li>
</ul>
<p>For example, when the image is shifted appropriately, a zero could look like a six or vice versa. Similarly, if all the images are trained using a dataset that had all the numbers centered in the image but the test dataset has an image that is shifted slightly to the right or left, the prediction is likely to be inaccurate. This is because the model would have placed a weightage for each pixel.</p>
<p>In order to solve the preceding problem, a deep learning technique named <strong>convolutional neural network</strong> (<strong>CNN</strong>) comes in handy. A CNN works in such a way that it assigns weightages at a region level rather than at a pixel level. Essentially, this forms the convolution part of convolutional neural networks. In this way, pixel adjacencies are taken into account by using deep learning.</p>
<p>Similarly, translation of an image is accounted for by a technique called <strong>max pooling</strong> that is used in CNN.</p>
<p>The typical architecture of a CNN looks as follows, and more details of it will be explained in a later chapter:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e774be9a-699f-4669-aa70-65924337e3b8.png"/></div>
<p>In the preceding diagram, the input is the image that we consider. <strong>conv1</strong> is the output when a convolution is applied between filters and input. Given that we apply multiple filters, we would have multiple convolutions, and <strong>pool1</strong> is the output of applying pooling on the convolution output. The process of convolution and pooling is applied repeatedly until we obtain the final fully connected unit, which is then linked to the output.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications of deep learning</h1>
                </header>
            
            <article>
                
<p>In the previous section, we understood why deep learning shines over machine learning in some applications. Let's go through some of the applications of deep learning:</p>
<ul>
<li>Translation from one language to another</li>
<li>Speech-to-text conversion</li>
<li>Image analysis in multiple industries</li>
<li>Identifying text present in images</li>
<li>Image and audio synthesis</li>
<li>Personalization to predict the next movie/product that a user is likely to watch/buy</li>
<li>Time series analysis</li>
<li>Detecting rare events</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we understood the major difference between supervised and unsupervised learning and got an overview of the major machine learning algorithms. We also understood the areas where deep learning algorithms shine over traditional machine learning algorithms, through examples of text and image analysis.</p>


            </article>

            
        </section>
    </body></html>