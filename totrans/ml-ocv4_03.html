<html><head></head><body><div><h1 class="header-title">Working with Data in OpenCV</h1>
                
            
            
                
<p>Now that we have whetted our appetite for machine learning, it is time to delve a little deeper into the different parts that make up a typical machine learning system.</p>
<p>Far too often, you hear someone throw around the phrase, <em>J</em><em>ust apply machine learning to your data!</em>, as if that will instantly solve all of your problems. You can imagine that the reality of this is much more intricate, although, I will admit that nowadays, it is incredibly easy to build your own machine learning system simply by cutting and pasting a few lines of code from the internet. However, to build a system that is truly powerful and effective, it is essential to have a firm grasp of the underlying concepts and an intimate knowledge of the strengths and weaknesses of each method. So, don't worry if you don't consider yourself a machine learning expert just yet. Good things take time.</p>
<p>Earlier, I described machine learning as a subfield of artificial intelligence. This might be true—mainly for historical reasons—but most often, machine learning is simply about making sense of data. Therefore, it might be more suitable to think of machine learning as a subfield of data science, where we build mathematical models to help us to understand data.</p>
<p>Hence, this chapter is all about data. We want to learn how data fits in with machine learning and how to work with data using the tools of our choice: OpenCV and Python.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Understanding the machine learning workflow</li>
<li>Understanding training data and test data</li>
<li>Learning how to load, store, edit, and visualize data with OpenCV and Python</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>You can refer to the code for this chapter from the following link: <a href="https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter02">https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter02</a>.</p>
<p>Here is a summary of the software and hardware requirements:</p>
<ul>
<li>You will need OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).</li>
<li>You will need Python version 3.6 (any Python version 3.x will be fine).</li>
<li>You will need Anaconda Python 3 for installing Python and the required modules.</li>
<li>You can use any OS—macOS, Windows, and Linux-based OSes along with this book. We recommend you have at least 4 GB RAM in your system.</li>
<li>You don't need to have a GPU to run the code provided along with this book.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding the machine learning workflow</h1>
                
            
            
                
<p>As mentioned earlier, machine learning is all about building mathematical models to understand data. The learning aspect enters this process when we give a machine learning model the capability to adjust its <strong>internal parameters</strong>; we can tweak these parameters so that the model explains the data better. In a sense, this can be understood as the model learning from the data. Once the model has learned enough—whatever that means—we can ask it to explain newly observed data.</p>
<p>A typical classification process is illustrated in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-800 image-border" src="img/f30a037e-5be4-4b0f-ad02-06e546ea42f3.png" style="width:42.25em;height:25.25em;" width="1429" height="853"/></p>
<p>Let's break it down step by step.</p>
<p>The first thing to notice is that machine learning problems are always split into (at least) two distinct phases:</p>
<ul>
<li>A <strong>training phase</strong>, during which we aim to train a machine learning model on a set of data that we call the <strong>training dataset</strong></li>
<li>A test phase, during which we evaluate the learned (or finalized) machine learning model on a new set of never-before-seen data that we call the <strong>test dataset</strong></li>
</ul>
<p>The importance of splitting our data into a training set and test set cannot be understated. We always evaluate our models on an independent test set because we are interested in knowing how well our models <strong>generalize to new data</strong>. In the end, isn't this what learning is all about—be it machine learning or human learning? Think back to school, when you were a learner yourself: the problems you had to solve as part of your homework would never show up in exactly the same form in the final exam. The same scrutiny should be applied to a machine learning model; we are not so much interested in how well our models can memorize a set of data points (such as a homework problem), but we want to know how our models will use what they have learned to solve new problems (such as the ones that show up in a final exam) and explain new data points.</p>
<p>The workflow of an advanced machine learning problem will typically include a third set of data termed a <strong>validation dataset</strong>. For now, this distinction is not important. A validation set is typically formed by further partitioning the training dataset. It is used in advanced concepts such as model selection, which we will talk about in <a href="904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml" target="_blank">Chapter 11</a>, <em>Selecting the Right Model with Hyperparameter Tuning</em>, when we have become proficient in building machine learning systems.</p>
<p>The next thing to notice is that machine learning is really all about the <strong>data</strong>. Data enters the previously described workflow diagram in its raw form—whatever that means—and is used in both training and test phases. Data can be anything from images and movies to text documents and audio files. Therefore, in its raw form, data might be made of pixels, letters, words, or even worse: pure bits. It is easy to see that data in such a raw form might not be very convenient to work with. Instead, we have to find ways to <strong>preprocess</strong> the data to bring it into a form that is easy to <strong>parse or use the data</strong>.</p>
<p>Data preprocessing comes in two stages:</p>
<ul>
<li><strong>Feature selection</strong>: This is the process of identifying important attributes (or features) in the data. Possible features of an image might be the location of edges, corners, or ridges. You might already be familiar with some more advanced feature descriptors that OpenCV provides, such as <strong>Speeded Up Robust Features</strong> (<strong>SURF</strong>) or the <strong>Histogram of Oriented Gradients</strong> (<strong>HOG</strong>). Although these features can be applied to any image, they might not be that important (or work that well) for our specific task. For example, if our task was to distinguish between clean and dirty water, the most important feature might turn out to be the color of the water, and the use of SURF or HOG features might not help us much.</li>
<li><strong>Feature extraction</strong>: This is the actual process of transforming the raw data into the desired <strong>feature space</strong>. An example would be the <strong>Harris operator</strong>, which allows us to extract corners (that is, a selected feature) in an image.</li>
</ul>
<p>A more advanced topic is the process of inventing informative features, which is known as <strong>feature engineering</strong>. After all, before people could select from popular features, someone had to invent them first. This is often more important for the success of our algorithm than the choice of the algorithm itself. We will talk about feature engineering extensively in <a href="142fec63-a847-4cde-9de9-c34805d2bb84.xhtml" target="_blank">Chapter 4</a>, <em>Representing Data and Engineering Features</em>.</p>
<p>Don't let naming <strong>conventions</strong> confuse you! Sometimes, feature selection and feature extraction are hard to distinguish, mainly because of how things are named. For example, SURF stands for both the feature extractor as well as the actual name of the features. The same is true for the <strong>S</strong><strong>cale-Invariant Feature Transform</strong> (<strong>SIFT</strong>), which is a feature extractor that yields what is known as <strong>SIFT</strong> <strong>features</strong>. Unfortunately, both the algorithms are patented and cannot be used for commercial purposes. We won't be sharing any code about either algorithms. </p>
<p>The last point to be made is that, in supervised learning, every data point must have a <strong>label</strong>. A label identifies a data point either of belonging to a certain class of things (such as cat or dog) or of having a certain value (such as the price of a house). At the end of the day, the goal of a supervised machine learning system is to predict the label of all data points in the test set (as shown in the previous diagram). We do this by learning regularities in the training data, using the labels that come with it, and then testing our performance on the test set.</p>
<p>Therefore, to build a functioning machine learning system, we first have to cover how to load, store, and manipulate data. How do you even do that in OpenCV with Python?</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Dealing with data using OpenCV and Python</h1>
                
            
            
                
<p>The world of data is full of various kinds of data types. This, at times, makes it very difficult for users to distinguish between the data type to use for a particular value. Here, we will try to keep it simple by treating everything as an array, except the scalar values, which will retain their standard data types. So, images will become 2D arrays because they have width and height. A 1D array could be a sound clip with intensity varying over time. </p>
<p>If you have mostly been using OpenCV's C++ <strong>Application Programming Interface</strong> (<strong>API</strong>) and plan on continuing to do so, you might find that dealing with data in C++ can be a bit of a pain. Not only will you have to deal with the syntactic overhead of the ...</p></div>



  
<div><h1 class="header-title">Starting a new IPython or Jupyter session</h1>
                
            
            
                
<p>Before we can get our hands on NumPy, we need to open an IPython shell or start a Jupyter Notebook:</p>
<ol>
<li>Open a Terminal as we did in the previous chapter and navigate to the <kbd>OpenCV-ML</kbd> directory:</li>
</ol>
<pre><strong>      $ cd Desktop/OpenCV-ML</strong></pre>
<ol start="2">
<li>Activate the <kbd>conda</kbd> environment we created in the previous chapter:</li>
</ol>
<pre><strong>      $ source activate OpenCV-ML  # Mac OS X / Linux</strong><br/><strong>      $ activate OpenCV-ML         # Windows</strong></pre>
<ol start="3">
<li>Start a new IPython or Jupyter session:</li>
</ol>
<pre><strong>      $ ipython           # for an IPython session<br/>      $ jupyter notebook  # for a Jupyter session</strong></pre>
<p>If you chose to start an IPython session, the program should have greeted you with a welcome message like the following:</p>
<pre><strong>$ ipython<br/>Python 3.6.0 | packaged by conda-forge | (default, Feb 9 2017, 14:36:55) <br/>Type 'copyright', 'credits' or 'license' for more information<br/>IPython 7.2.0 -- An enhanced Interactive Python. Type '?' for help.<br/><br/>In [1]: <br/></strong></pre>
<p>The line starting with <kbd>In [1]</kbd> is where you type in your regular Python commands. In addition, you can also use the <em>Tab</em> key while typing the names of variables and functions to have IPython automatically complete them.</p>
<p>A limited number of Unix and macOS system shell commands work too—such as <kbd>ls</kbd> and <kbd>pwd</kbd>. You can run any shell command by prefixing it with <kbd>!</kbd>, such as <kbd>!ping www.github.com</kbd>. For more information, check out the official IPython reference at <a href="https://ipython.org/ipython-doc/3/interactive/tutorial.html">https://ipython.org/ipython-doc/3/interactive/tutorial.html</a>.</p>
<p>If you chose to start a Jupyter session, a new window should have opened in your web browser that is pointing to <kbd>http://localhost:8888</kbd>. You want to create a new notebook by clicking on New in the top-right corner and selecting Notebooks (Python 3):</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-801 image-border" src="img/9e67e509-0fd8-4871-bee8-3ef9963f27bf.png" style="width:43.92em;height:21.67em;" width="852" height="421"/></p>
<p>This will open a new window that looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-802 image-border" src="img/8ed28073-144e-4935-929d-3b781ce55abd.png" style="width:46.25em;height:14.58em;" width="1093" height="345"/></p>
<p>The cell (which looks like the preceding textbox) labeled with <kbd>In [ ]</kbd> is the same as the command line in an IPython session. Now you can start typing your Python code!</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Dealing with data using Python's NumPy package</h1>
                
            
            
                
<p>I am assuming that you already have NumPy installed in your virtual environment if you have installed Anaconda. If you have used Python's standard distribution or any other distribution, you can go to <a href="http://www.numpy.org">http://www.numpy.org</a> and follow the installation instructions provided there.</p>
<p>As mentioned previously, it's okay if you aren't a Python expert yet. Who knows, perhaps you're just now switching from OpenCV's C++ API. This is all fine. I wanted to give you a quick overview of how to get started with NumPy. If you are a more advanced Python user, you can simply skip this section.</p>
<p>Once you are familiar with NumPy, you will find that most scientific computing tools in the Python world are built around ...</p></div>



  
<div><h1 class="header-title">Importing NumPy</h1>
                
            
            
                
<p>Once you start a new IPython or Jupyter session, you can import the NumPy module and verify its version as follows:</p>
<pre>In [1]: import numpy<br/>In [2]: numpy.__version__<br/>Out[2]: '1.15.4'</pre>
<p>Recall that in the Jupyter Notebook, you can hit <em>Ctrl</em> + <em>Enter</em> to execute a cell once you have typed the command. Alternatively, <em>Shift</em> + <em>Enter</em> executes the cell and automatically inserts or selects the cell below it. Check out all of the keyboard shortcuts by clicking on Help | Keyboard Shortcut or take a quick tour by clicking on Help | User Interface Tour.</p>
<p>For the parts of the package discussed here, I would recommend using NumPy version 1.8 or later. By convention, you'll find that most people in the scientific Python world will import NumPy using <kbd>np</kbd> as an alias:</p>
<pre>In [3]: import numpy as np<br/>In [4]: np.__version__<br/>Out[4]: '1.15.4'</pre>
<p>Throughout this chapter and the rest of this book, we will stick to the same convention.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding NumPy arrays</h1>
                
            
            
                
<p>You might already know that Python is a <strong>weakly typed language</strong>. This means that you do not have to specify a data type whenever you create a new variable. For example, the following will automatically be represented as an integer:</p>
<pre><strong>In [5]: a = 5</strong></pre>
<p>You can double-check this by typing the following:</p>
<pre>In [6]: type(a)Out[6]: int</pre>
<p>As the standard Python implementation is written in C, every Python object is basically a C structure in disguise. This is true even for integers in Python, which are actually pointers to compound C structures that contain more than just the <strong>raw</strong> integer value. Therefore, the default C data type used to represent Python integers will depend on your system architecture (that is, whether it is a 32-bit ...</p></div>



  
<div><h1 class="header-title">Accessing single array elements by indexing</h1>
                
            
            
                
<p>If you have used Python's standard list indexing before, then you won't find many issues with indexing in NumPy. In a 1D array, the <em>i</em><sup>th</sup> value (counting from zero) can be accessed by specifying the desired index in square brackets, just as with Python lists:</p>
<pre>In [13]: int_arr<br/>Out[13]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])<br/>In [14]: int_arr[0]<br/>Out[14]: 0<br/>In [15]: int_arr[3]<br/>Out[15]: 3</pre>
<p>To index from the end of the array, you can use negative indices:</p>
<pre>In [16]: int_arr[-1]<br/>Out[16]: 9<br/>In [17]: int_arr[-2]<br/>Out[17]: 8</pre>
<p>There are a few other cool tricks for <strong>slicing arrays</strong>, as follows:</p>
<pre>In [18]: int_arr[2:5]  # from index 2 up to index 5 - 1<br/>Out[18]: array([2, 3, 4])<br/>In [19]: int_arr[:5]    # from the beginning up to index 5 - 1<br/>Out[19]: array([0, 1, 2, 3, 4])<br/>In [20]: int_arr[5:]    # from index 5 up to the end of the array<br/>Out[20]: array([5, 6, 7, 8, 9])<br/>In [21]: int_arr[::2]   # every other element<br/>Out[21]: array([0, 2, 4, 6, 8])<br/>In [22]: int_arr[::-1]  # the entire array in reverse order<br/>Out[22]: array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])</pre>
<p>I encourage you to play around with these arrays yourself!</p>
<p>The general form of slicing arrays in NumPy is the same as it is for standard Python lists. To access a slice of an array, <kbd>x</kbd>, use <kbd>x[start:stop:step]</kbd>. If any of these are unspecified, they default to the <kbd>start=0</kbd>, <kbd>stop=size of dimension</kbd>, <kbd>step=1</kbd> values. </p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating multidimensional arrays</h1>
                
            
            
                
<p>Arrays need not be limited to lists. In fact, they can have an arbitrary number of dimensions. In machine learning, we will often deal with at least 2D arrays, where the column index stands for the values of a particular feature and the rows contain the actual feature values.</p>
<p>With NumPy, it is easy to create multidimensional arrays from scratch. Let's say that we want to create an array with three rows and five columns, with all of the elements initialized to zero. If we don't specify a data type, NumPy will default to using floats:</p>
<pre>In [23]: arr_2d = np.zeros((3, 5))...      arr_2dOut[23]: array([[0., 0., 0., 0., 0.],                [0., 0., 0., 0., 0.],                [0., 0., 0., 0., 0.]])</pre>
<p>As you probably know from your OpenCV days, this ...</p></div>



  
<div><h1 class="header-title">Loading external datasets in Python</h1>
                
            
            
                
<p>Thanks to the SciPy community, there are many resources out there for getting our hands on some data.</p>
<p>A particularly useful resource comes in the form of the <kbd>sklearn.datasets</kbd> package of <strong>scikit-learn</strong>. This package comes preinstalled with some small datasets that do not require us to download any files from external websites. These datasets include the following:</p>
<ul>
<li><kbd>load_boston</kbd>: The Boston dataset contains housing prices in different suburbs of Boston along with several interesting features such as per capita crime rate by town, proportion of residential land, and number of non-retail business</li>
<li><kbd>load_iris</kbd>: The Iris dataset contains three different types of Iris flowers (Setosa, Versicolor, and Virginica), along with four features describing the width and length of the sepals and petals</li>
<li><kbd>load_diabetes</kbd>: The diabetes dataset lets us classify patients as having diabetes or not, based on features such as patient age, sex, body mass index, average blood pressure, and six blood serum measurements</li>
<li><kbd>load_digits</kbd>: The digits dataset contains 8 x 8 pixel images of the digits <em>0-9</em></li>
<li><kbd>load_linnerud</kbd>: The Linnerud dataset contains 3 physiological variables and 3 exercise variables measured on 20 middle-aged men in a fitness club</li>
</ul>
<p>Also, scikit-learn allows us to download datasets directly from external repositories, such as the following:</p>
<ul>
<li><kbd>fetch_olivetti_faces</kbd>: The Olivetti faces dataset contains 10 different images each of 40 distinct subjects</li>
<li><kbd>fetch_20newsgroups</kbd>: The 20 newsgroup dataset contains around 18,000 newsgroup posts on 20 topics</li>
</ul>
<p>Even better, it is possible to download datasets directly from the machine learning database at <a href="http://mldata.org">http://openml.org</a>. For example, to download the Iris flower dataset, simply type the following:</p>
<pre>In [1]: from sklearn import datasets<br/>In [2]: iris = datasets.fetch_openml('iris', version=1)<br/>In [3]: iris_data = iris['data']<br/>In [4]: iris_target = iris['target']</pre>
<p>The Iris flower database contains a total of <kbd>150</kbd> samples with <kbd>4</kbd> features—sepal length, sepal width, petal length, and petal width. The data is divided into three classes—Iris Setosa, Iris Versicolour, and Iris Virginica. Data and labels are delivered in two separate containers, which we can inspect as follows:</p>
<pre>In [5]: iris_data.shape <br/>Out[5]: (150, 4)<br/>In [6]: iris_target.shape <br/>Out[6]: (150,)</pre>
<p>Here, we can see that <kbd>iris_data</kbd> contains <kbd>150</kbd> samples, each with <kbd>4</kbd> features (and that's why the number 4 is in the shape). Labels are stored in <kbd>iris_target</kbd>, where there is only one label per sample.</p>
<p>We can further inspect the values of all targets, but we don't just want to print them all. Instead, we are interested to see all distinct target values, which is easy to do with NumPy:</p>
<pre>In [7]: import numpy as np<br/>In [8]: np.unique(iris_target) # Find all unique elements in array<br/>Out[8]: array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)</pre>
<p>Another Python library for data analysis that you should have heard about is <strong>pandas</strong> (<a href="http://pandas.pydata.org">http://pandas.pydata.org</a>). pandas implements several powerful data operations for both databases and spreadsheets. However great the library, at this point, pandas is a bit too advanced for our purposes.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Visualizing the data using Matplotlib</h1>
                
            
            
                
<p>Knowing how to load data is of limited use if we don't know how to look at the data. Thankfully, there is <strong>Matplotlib</strong>!</p>
<p>Matplotlib is a multiplatform data visualization library built on NumPy arrays—see, I promised you NumPy would show up again. It was conceived by John Hunter in 2002, originally designed as a patch to IPython to enable interactive MATLAB-style plotting from the command line. In more recent years, newer and shinier tools have popped up to eventually replace Matplotlib (such as <kbd>ggplot</kbd> and <kbd>ggvis</kbd> in the R language), but Matplotlib remains essential as a well-tested, cross-platform graphics engine.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Importing Matplotlib</h1>
                
            
            
                
<p>You might be in luck again: if you followed the advice outlined in the previous chapter and installed the Python Anaconda stack, you already have Matplotlib installed and are ready to go. Otherwise, you might want to visit <a href="http://matplotlib.org/">http://matplotlib.org</a> for installation instructions.</p>
<p>Just as we used the <kbd>np</kbd> shorthand for NumPy, we will use some standard shorthand for the Matplotlib imports:</p>
<pre>In [1]: import matplotlib as mpl<br/>In [2]: import matplotlib.pyplot as plt</pre>
<p>The <kbd>plt</kbd> interface is what we will use most often, as we shall see throughout this book.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Producing a simple plot</h1>
                
            
            
                
<p>Without further ado, let's create our first plot.</p>
<p>Let's say that we want to produce a simple line plot of the sine function, <kbd>sin(x)</kbd>. We want the function to be evaluated at all points on the <em>x </em>axis where <kbd>0 &lt; x &lt; 10</kbd>. We will use NumPy's <kbd>linspace</kbd> function to create a linear spacing on the <em>x</em> axis, from <kbd>x</kbd> values <kbd>0</kbd> to <kbd>10</kbd>, and a total of <kbd>100</kbd> sampling points:</p>
<pre>In [3]: import numpy as npIn [4]: x = np.linspace(0, 10, 100)</pre>
<p>We can evaluate the <kbd>sin</kbd> function at all points, <kbd>x</kbd>, using NumPy's <kbd>sin</kbd> function, and visualize the result by calling the <kbd>plot</kbd> function of <kbd>plt</kbd>:</p>
<pre>In [5]: plt.plot(x, np.sin(x))</pre>
<p>Did you try it yourself? What happened? Did anything show up?</p>
<p>The thing is, depending on where you are running this script, you might not ...</p></div>



  
<div><h1 class="header-title">Visualizing data from an external dataset</h1>
                
            
            
                
<p>As a final test for this chapter, let's visualize some data from an external dataset, such as the <kbd>digits</kbd> dataset from scikit-learn.</p>
<p>Specifically, we will need three tools for visualization:</p>
<ul>
<li>scikit-learn for the actual data</li>
<li>NumPy for data processing</li>
<li>Matplotlib</li>
</ul>
<p>So, let's start by importing all of these:</p>
<pre>In [1]: import numpy as np<br/>...     from sklearn import datasets<br/>...     import matplotlib.pyplot as plt<br/>...     %matplotlib inline</pre>
<p>The first step is to actually load the data:</p>
<pre>In [2]: digits = datasets.load_digits()</pre>
<p>If we remember correctly, <kbd>digits</kbd> is supposed to have two different fields: a <kbd>data</kbd> field containing the actual image data and a <kbd>target</kbd> field containing the image labels. Rather than trusting our memory, we should simply investigate the <kbd>digits</kbd> object. We do this by typing out its name, adding a period, and then hitting the <em>Tab</em> key: <kbd>digits.&lt;TAB&gt;</kbd>. This will reveal that the <kbd>digits</kbd> object also contains some other fields, such as one called <kbd>images</kbd>. The two fields, <kbd>images</kbd> and <kbd>data</kbd>, seem to simply differ by shape:</p>
<pre>In [3]: print(digits.data.shape)<br/>... print(digits.images.shape)<br/>Out[3]: (1797, 64)<br/> (1797, 8, 8)</pre>
<p>In both cases, the first dimension corresponds to the number of images in the dataset. However, <kbd>data</kbd> has all of the pixels lined up in one big vector, whereas <kbd>images</kbd> preserves the 8 x 8 spatial arrangement of each image.</p>
<p>Hence, if we wanted to plot a single image, the <kbd>images</kbd> field would be more appropriate. First, we grab a single image from the dataset using NumPy's array slicing:</p>
<pre>In [4]: img = digits.images[0, :, :]</pre>
<p>Here, we are saying that we want to grab the first row in the 1,797-item-long array and all of the corresponding <em>8 x 8 = 64</em> pixels. We can then plot the image using the <kbd>imshow</kbd> function of <kbd>plt</kbd>:</p>
<pre>In [5]: plt.imshow(img, cmap='gray') <br/>...     plt.savefig('figures/02.04-digit0.png') <br/>Out[5]: &lt;matplotlib.image.AxesImage at 0x7efcd27f30f0&gt;</pre>
<p>The preceding command gives the following output. Note that the image is blurred because we have resized it to a larger size. The original image's size is just 8 x 8:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-804 image-border" src="img/6a72066a-c69e-45d7-9756-b26d35d259a3.png" style="width:16.42em;height:16.33em;" width="261" height="259"/></p>
<p>In addition, I also specified a colormap with the <kbd>cmap</kbd> argument. By default, Matplotlib uses MATLAB's default colormap <strong>jet</strong>. However, in the case of grayscale images, the <strong>gray</strong> colormap makes more sense.</p>
<p>Finally, we can plot a whole number of digit samples using the <kbd>subplot</kbd> function of <kbd>plt</kbd>. The <kbd>subplot</kbd> function is the same as in MATLAB, where we specify the number of rows, number of columns, and current subplot index (starts counting at <kbd>1</kbd>). We will use a <kbd>for</kbd> loop to iterate over the first 10 images in the dataset and every image gets assigned its own subplot:</p>
<pre>In [6]: plt.figure(figsize=(14,4))<br/>...<br/>...     for image_index in range(10):<br/>...         # images are 0-indexed, but subplots are 1-indexed<br/>...         subplot_index = image_index + 1<br/>...         plt.subplot(2, 5, subplot_index)<br/>...         plt.imshow(digits.images[image_index, :, :], cmap='gray')</pre>
<p>This leads to the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-805 image-border" src="img/30a0d81b-b5e2-49c8-8801-99dc8677959b.png" style="width:52.00em;height:17.50em;" width="795" height="267"/></p>
<p>Another great resource for all sorts of datasets is the machine learning repository of my alma mater, the University of California, Irvine: <a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Dealing with data using OpenCV's TrainData container in C++</h1>
                
            
            
                
<p>For the sake of completeness and for those who insist on using the C++ API of OpenCV, let's do a quick detour on OpenCV's <kbd>TrainData</kbd> container, which allows us to load numerical data from <kbd>.csv</kbd> files.</p>
<p>Among other things, in C++, the <kbd>ml</kbd> module contains a class called <kbd>TrainData</kbd>, which provides a container to work with data in C++. Its functionality is limited to reading (preferably) numerical data from <kbd>.csv</kbd> files (containing comma-separated values). Hence, if the data that you want to work with comes in a neatly organized <kbd>.csv</kbd> file, this class will save you a lot of time. If your data comes from a different source, I'm afraid your best option might be to create a <kbd>.csv</kbd> file by hand, using ...</p></div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we talked about a typical workflow to deal with machine learning problems: how we can extract informative features from raw data, how we can use data and labels to train a machine learning model, and how we can use the finalized model to predict new data labels. We learned that it is essential to split data into a training set and test set, as this is the only way to know how well a model will generalize to new data points.</p>
<p>On the software side of things, we significantly improved our Python skills. We learned how to use NumPy arrays to store and manipulate data and how to use Matplotlib for data visualization. We talked about scikit-learn and its many useful data resources. Finally, we also addressed OpenCV's own <kbd>TrainData</kbd> container, which provides some relief for users of OpenCV's C++ API.</p>
<p>With these tools in hand, we are now ready to implement our first real machine learning model! In the next chapter, we will focus on supervised learning and its two main problem categories, classification and regression.</p>


            

            
        
    </div>



  </body></html>