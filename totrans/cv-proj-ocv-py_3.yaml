- en: Reading License Plates with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provides an overview of how to extract and display license plate
    characters in any sample photo with a license plate in it. OpenCV and its plate
    utility functions help us find the characters on a license plate, and give us
    a good taste of how computer vision and image processing work.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The steps needed to read license plates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plate utility functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding plate characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding and reading license plates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the license plate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this project, we are going to detect and read license plates in photos of
    cars. We will be performing multiple steps, from locating the license plate to
    displaying the characters in the located license plate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s refer to the code in Jupyter Notebook needed to analyze our sample images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following photo when we run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fcf031dc-bfee-453c-8480-c869cd11721f.png)'
  prefs: []
  type: TYPE_IMG
- en: We have a photo of a car, with its license plate clearly visible and readable.
    The challenge is to locate the license plate, isolate it from the rest of the
    photo, and extract the characters from it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now take a closer look at the license plate using the available utility
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8b01357-ab91-49a4-898d-bdaab043cde7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are many algorithms that can help us carry out both these tasks. For
    example, object detectors such as YOLO: Real-Time Object Detection can do a very
    good job using the relevant machine learning methods for performing such tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: However, we will be looking at a straightforward approach, using conventional
    image processing and computer vision techniques, instead of complex machine learning
    techniques such as deep learning and TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm we will be using will help us learn computer vision and image
    processing techniques, giving us a better understanding of the project. Let's
    start with our code and check the plate utility functions we will be using.
  prefs: []
  type: TYPE_NORMAL
- en: Plate utility functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's jump to our code in Jupyter Notebook, in order to understand plate utility
    functions. We will first embed the imports with our utilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be importing the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV (version 3.4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pickle, which lets us save Python data and case functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Import the libraries as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We will be using these libraries to load the k-nearest neighbors classifier
    for reading characters, which implicitly depends on scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: We will now discuss the utilities that will be used in our code.
  prefs: []
  type: TYPE_NORMAL
- en: The gray_thresh_img function and morphological functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `gray_thresh_img` function takes an input image and converts it to grayscale.
    We need the image in grayscale, as color images may cause ambiguity, given that
    the color of license plates differs depending on the area. The `gray_thres_img`
    function gives us a binarized image.
  prefs: []
  type: TYPE_NORMAL
- en: We can use morphological operations for pre-processing, as this will help us
    reduce noise and gaps. This will de-noise our image and remove extraneous features.
  prefs: []
  type: TYPE_NORMAL
- en: Kernels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A kernel is a three-by-three square on which we will be using `tophat`, `blackhat`,
    and `graytop` operations to create a grayscale image. This will also help us to
    de-noise the image—noise is usually present in natural images, and is not preferable
    for computer vision. The image can also be de-noised using Gaussian blur.
  prefs: []
  type: TYPE_NORMAL
- en: We will use adaptive thresholding, which looks at local statistics and averages
    in an image to check whether it is bright or dim relative to its neighborhood.
    This is preferred over hard thresholding, as it will binarize our images in a
    better way.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the `return` function to get the gray image and binarized image, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The matching character function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at our next function to get the matching characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `getmatchingchars` function helps us find our character candidate based
    on the following criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: Size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relative distance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Angle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Area
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the potential character is a reasonable distance from its neighbors, the
    angle is not too large compared to the JSON characters, and the area is not too
    big, we say that the possible character is a *character candidate*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will return a list of characters that are part of a license
    plate, and then create a container class that will contain objects such as the
    width, height, center, diagonal distance or hypotenuse, and aspect ratio of the
    character sub-images within our complete image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The k-nearest neighbors digit classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pre-trained scikit-learn **k-nearest neighbors** (**k-nn**) digit classifier
    also needs to be loaded, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The k-nn classifier compares a small image to a series of images already known
    to it, to find the closest match.
  prefs: []
  type: TYPE_NORMAL
- en: We are not using complex algorithms for this, because characters in a license
    plate are similar. This is why we can use the k-nn method, which will make a pixel-by-pixel
    comparison to find the closest match. The characters on a license plate are not
    handwritten digits where the font might differ, which would need more computation.
  prefs: []
  type: TYPE_NORMAL
- en: In the classifier, `p` stands for Pickle, which is how Python stores data.
  prefs: []
  type: TYPE_NORMAL
- en: Finding plate characters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we carry out our initial search to find plate characters. First, we find
    characters roughly, and then find candidates based on specific criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the following line in our Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now execute our function cell for imports, utilities, and to load our
    libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We can now load our input image, which will be used for analysis. We use the
    `plt` function here instead of OpenCV, as OpenCV by default loads images in **blue
    green red** (**BGR**) format rather than **red green blue** (**RGB**) format.
    This is important for your custom projects, but it does not matter for our project
    since we will be converting the image to grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s load our image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output photo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/644c259c-32e2-4af2-bb38-54331f147e32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a closer look at the license plate of this car:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/baf74a28-f1b2-4e53-af3b-cad48e8a11ce.png)'
  prefs: []
  type: TYPE_IMG
- en: We will find the characters from this image. However, we first need to remove
    the background, which is not important for us. Here, we need to carry out initial
    pre-processing on the image, using the `gray_thresh_img`, `blurred`, and `morphology`
    functions, which will help us get rid of the background.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for the initial pre-processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at our main code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We will give the image shape, which is going to return the height, width, and
    RGB depth of the photo. We don't need RGB depth right now, so we will extract
    only `2` elements; height and width. Since we will be working on grayscale images
    and not colored ones, we'll call our handy `gray_thresh_img` function, which will
    return the gray and binarized thresholded image.
  prefs: []
  type: TYPE_NORMAL
- en: To find the contours, we need sub-images within the image that correspond to
    the character and then correspond to contours. We will use the `findContours`
    built-in algorithm from OpenCV to find details of complex shapes such as contours
    that could possibly be characters and work as our k-nn. We will then initialize
    our `char_cands` and `plate_candidates` variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take our first pass at finding the characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We will be using the characters to find the license plate, which is a different
    approach to other machine learning algorithms. This approach will help us understand
    the process of finding characters better.
  prefs: []
  type: TYPE_NORMAL
- en: We will iterate over all the contours and use the `charclass` class (which we
    have already defined). This automatically extracts centers, diagonal length, and
    aspect ratio to determine whether the image is too big or too small, or if the
    aspect ratio is too skewed From this, we can infer that the character is not a
    letter or number that will be on the license plate. This helps us consider only
    contours that meet the geometric criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Finding matches and groups of characters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the first pass is done, we will refine our matches to find a group of
    characters that potentially could belong to a license plate. Refer to the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We will iterate over all the potential characters by calling the `getmatchingchars`
    function we used before, which provides additional filtering based on the criteria.
    It depends on the angles, trigonometry, width, and height compared to neighboring
    characters, and also on the kind of neighbors. These criteria help us achieve
    uniformity.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have our plate candidates, we can create a `blank` object. So, we have
    a `blank` object with no attributes and create a list of them. We first sort from
    the center of those characters, which will help us sort from leftmost to rightmost
    going through the matches.
  prefs: []
  type: TYPE_NORMAL
- en: The `sum_char_h` summation will help us find the average height and width of
    the characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The ideal position of the license plate is perpendicular to the camera. If the
    license plate is at an angle greater than a particular acceptable angle, or upside
    down, there is a possibility that we will not be able to read the license plate.
  prefs: []
  type: TYPE_NORMAL
- en: We find our `x` and `y` from the code, and correct the angle for the license
    plate if it is within a reasonable angle.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then figure out the plate location, and store it for computation later using
    `rotationMatrix`. We can do this in one step, based on the angle that we found
    here. We want to rotate it about the center of the plate, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We create our rotated image here, and the `cv2.wrapAffine` function will help
    us with stretching, skewing, rotating, and translation, as well as higher-order
    transformations such as scaling, stretching, and rotating:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Once we have our sub-image, which is rotated and centered around plate candidates,
    we save it to our plate candidates list, which we initiated earlier. We now have
    our characters and our initial guess for our plate candidates, using which we
    are ready to find and read our license plate candidates.
  prefs: []
  type: TYPE_NORMAL
- en: Finding and reading license plates with OpenCV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already found our characters, which are license plate candidates. Now
    we need to determine which characters match, so that we can extract the text data
    and map the characters within the license plates.
  prefs: []
  type: TYPE_NORMAL
- en: First, we run each plate candidate through our `gray_thresh_img` function, which
    does our de-noising and binarization. In this case, we get a cleaner output because
    we are using a sub-image and not the complete image.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the extraction code we will use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We will need our characters to be of the same size, since we will be using the
    k-nn approach, which is case-sensitive. If the size differs, we will receive garbage
    values. After we have the images sized, we need to perform thresholding, for which
    we will use the `OTSU` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then need to find contours within our sub-image, and do a sanity check to
    make sure that the contours we found within our sub-image meet certain criteria
    where the size and aspect ratio are reasonable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If the contours do not meet the criteria, it means that we are either not looking
    at a license plate or not getting good characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the sanity check is complete, we run our `getmatchingchars` function,
    which will ensure we get a good group of characters that are roughly of the same
    size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This is a redundancy check, but is necessary for achieving clean and reliable
    results. We iterate over all the characters from left to right, in order, to check
    that the characters are sufficiently far apart. We do this because, conceivably,
    near contours that overlap each other could be characters that overlap, which
    would never happen in a real license plate.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to make sure that the characters are far apart, as we''re not detecting
    the same thing over and over again; we are doing multiple `for` loops here and
    comparing characters to each other as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We need to make sure that everything is centered within our region of interest,
    so that characters are not lost when we perform actions such as scaling, rotation,
    and translation while we find our k-nn.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this code, we go through each character in our character list and each thresholded
    region, to make sure we resize the region to `20` by `30`, which matches our k-nn
    prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now, all these regions are of length 600\. NumPy's `reshape` function will map
    the region by some dimensions for a two-dimensional input, to get 1/600.
  prefs: []
  type: TYPE_NORMAL
- en: The `thischar` function is actually an empty string at the start, but will keep
    getting populated as we find our k-nn.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we need to make sure that our `plate_candidates` are not blank, while
    we find our best candidate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You may find multiple plate candidates for a given image, but often they're
    the same thing. You might have just found something with four characters, when
    there are actually six, or something like that. The one that has the most characters
    is probably right, but you can take a look at the other candidates as well.
  prefs: []
  type: TYPE_NORMAL
- en: We'll extract and sort by the length of the string again, find the `best_plate`,
    and print out the results.
  prefs: []
  type: TYPE_NORMAL
- en: Result analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we run our code using the best candidate code block, we get the following
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we get our output, we can display our result using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The displayed image will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29224956-b4cf-4893-8da4-65719bf221b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Although there is an extra character, we can see that our displayed image is
    very close to the plate characters. We can, check it with our other possible plate
    characters to get the closest result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try one more license plate, to check how our code works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'And here''s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/57f183fe-8a9b-4ad1-8ba9-ffb6f0a7792e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The photo displayed is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b28522d-8233-4afb-878e-0093dadb36d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you just want the sub-image of the plate, you can get it using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/11243ab0-18fc-481a-bf19-2fa2ebb7ed64.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can find the location of the result as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'You get the following location in the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb45ca54-91ea-4b91-9409-287cfeeaa58e.png)'
  prefs: []
  type: TYPE_IMG
- en: So, here we have the `x` and `y` coordinates, width, height, and some offset
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try other available functions, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1a092ba-ec2b-41ae-ba6e-b1bb4da83729.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at another example where the license plate is not clearly visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/065f0342-9089-4974-baa9-8e318f920fbd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a closer look at the license plate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/450aade3-a977-4687-8bdc-380bf9ff769f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Our `display` function gives us a pretty good result, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3ae5a073-5b57-4c78-9103-5542367fa5d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at our final example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cfe4a47-732f-4e28-afa4-3846c3e99449.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following screenshot shows the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ee92e1c-609b-4dbb-ab44-7b1d24bcb9e3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And the resulting photo is displayed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cf337289-29d2-427e-9641-7c8d1098083c.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to perform license plate recognition using OpenCV,
    giving us a good taste of how computer vision and image processing work.
  prefs: []
  type: TYPE_NORMAL
- en: We first learned the different plate utility functions, which helped us find
    our plate characters. We then found possible candidates for our license plate
    characters using OpenCV. Finally, we analyzed our results to check the efficiency
    of our algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, [Chapter 4](489ca4bf-4851-4f79-9de8-0b326ab68a70.xhtml),
    *Human Pose Estimation with TensorFlow*, we're going to use the DeeperCut algorithm,
    and ArtTrack models for human pose estimation.
  prefs: []
  type: TYPE_NORMAL
