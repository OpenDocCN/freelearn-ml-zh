<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building Deep Learning Solutions</h1>
                </header>
            
            <article>
                
<p class="mce-root">Deep learning is a superset of machine learning incorporating algorithms influenced by the design and functionality of the human brain, known as the artificial intelligent neural network. It's represented in the form of supervised, semi-supervised, and unsupervised algorithms, where architectures profoundly concentrate on deep neural networks, deep belief networks, and recurrent neural networks. Deep learning today is widely accepted and utilized in industry as well as in R and D sectors in the field of computer vision, speech recognition, audio synthesis, image recognition, natural language processing, social media content moderation, and so on.</p>
<p class="mce-root">In this chapter, we will learn about the following topics:</p>
<ul>
<li class="mce-root">An overview of Microsoft CNTK and the MMLSpark framework, along with third-party deep learning tools</li>
<li class="mce-root">TensorFlow and Keras, and the steps of deployment on Azure compute</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What is deep learning?</h1>
                </header>
            
            <article>
                
<p>Deep learning is a subclass of traditional machine learning algorithms that utilizes a series of non-linear processing layers for feature extraction, transformation, and, finally, analysis over the successive layers of output from the previous layers of input.</p>

<p>The first layer of the deep learning neural network consists of an input layer, an output layer (the outermost layer), and a hidden layer, which is a complex layer in-between the input and output layers:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/e92c8ffa-5be6-43bf-91bc-83648a72fdfc.png" style="width:37.42em;height:23.58em;" width="604" height="381"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Differences between traditional machine learning and deep learning</h1>
                </header>
            
            <article>
                
<p>The comparison between traditional machine learning and deep learning are as follows:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td><strong>Traditional Machine learning</strong></td>
<td><strong>Deep learning</strong></td>
</tr>
<tr>
<td>Traditional machine learning needs manual features of data extraction/engineering.</td>
<td>Deep learning learns automatically from the data features.</td>
</tr>
<tr>
<td>For unstructured data, feature extraction is difficult.</td>
<td>
<p class="mce-root">Deep learning updates learned network weights and bias in each layer.</p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Common Deep Learning Neural Networks (DNNs)</h1>
                </header>
            
            <article>
                
<p>There are a diverse set of deep learning neural networks available that are used to solve deep learning problems in the data science platform. Some of them are as follows:</p>
<ul>
<li><strong>Deep Convolutional Neural Network </strong>(<strong>DCNN</strong>): Used for the extraction of images representation</li>
<li><strong>Recurrent Neural Network</strong> (<strong>RNN</strong>): Used for the extraction of sequential data representation</li>
<li><strong>Deep Belief Neural Network</strong> (<strong>DBN</strong>): Applied for the extraction of hierarchical dataset representation</li>
<li><strong>Deep Reinforcement Learning</strong> (<strong>DRL</strong>): Prediction of agent behaviors to maximize the future cumulative reward</li>
</ul>
<p>The traditional manner of working on various deep learning frameworks and tools comes with a lot of challenges as it consists of various dependencies ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Overview of the Azure Notebook service</h1>
                </header>
            
            <article>
                
<p>The Azure Notebook service is a managed service that basically provides easy access to Jupyter Notebooks by using the computational power of R, Python, and F#, and users can utilize its numerous visual libraries and share the notebooks both publicly and in a private manner with a shareable link.</p>
<p>Microsoft's <strong>Cognitive Toolkit</strong> (<strong>CNTK</strong>) has native support for Azure Notebook services so that Python-based Jupyter Notebooks can be executed with the CNTK framework. For execution in other DL frameworks like TensorFlow, Keras, or Theano, users need to install the respective framework components by using Miniconda or Pip/wheel.</p>
<p class="mce-root"/>
<p>The Azure Notebook services are available at <a href="https://notebooks.azure.com/">https://notebooks.azure.com/</a>, and leverage the features of free, cloud-based, web-based Jupyter Notebook environments, including facilities for the creation of libraries and numerous interactive graphics that are built using data science languages like Python 2, Python 3, R, and F#. You can create your own libraries and build interactive notebooks, and you can simply upload your existing Jupyter Notebooks as well:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/e2cfe591-4e0c-4560-88fa-6df493d4ce44.png" width="1177" height="937"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Microsoft CNTK notebooks have built-in support in Azure Notebooks. All of the notebooks in Azure Notebooks can be organized into individual groups known as libraries that are shareable but non-editable. Notebooks can be cloned from other repositories as well. </p>
<p>Data can be uploaded with ease to Azure Notebooks by using the <span class="packt_screen">Data</span> menu and loading it into memory with function cells. It can also be downloaded, as demonstrated in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/7f7c1d77-c8b9-44b2-9f5c-6733a77c69ab.png" width="1346" height="308"/></p>
<p class="CDPAlignLeft CDPAlign"> Azure Notebook services provide the ability to implement interactive IPython notebooks by using libraries like matplotlib, scikit-learn, scipy, numpy, pandas, and so on. In the following demo, an interactive IPython notebook on the World's Population Growth rate analytics has been implemented:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/1dd41b8b-7895-44b3-b3be-1f74130df022.png" width="970" height="426"/></p>
<p class="mce-root"/>
<p>First, data exploration is performed by importing the raw data into a DataFrame:</p>
<pre>import pandas as pd<br/> df_population_density = pd.read_csv('/home/nbuser/library/World_Population_Growth.csv')<br/> df_population_density.head(10)</pre>
<p>Then, we implement the filtering in order to build a more concise pivot table:</p>
<pre>filtered_cells_df = df_population_density[['Location','Time','Births','Deaths','GrowthRate']].dropna(how="any")<br/> filtered_cells_df</pre>
<p><span><span>The output of the preceding code snippet is as follows:</span></span></p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/cd079e1d-1cac-492a-95a7-9cf5033954f6.png" width="1459" height="739"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Pivot table formation with Azure Notebook</h1>
                </header>
            
            <article>
                
<p>The Pivot table can be populated using function like <kbd>pivot_table()</kbd>: </p>
<pre>df_population_pivot = filtered_cells_df.pivot_table('GrowthRate','Location','Time') df_population_pivot.head(100)</pre>
<p class="mceNonEditable"><span>Finally, we can build interactive Python-based visuals by using</span> visualization <span>libraries, such as</span> <kbd>matplotlib</kbd><span>,</span> <kbd>seaborn</kbd><span>,</span> <kbd>pandas</kbd><span>,</span> <kbd>folium</kbd><span> and so on:</span><strong> </strong></p>
<pre>import numpy as np import matplotlib.pyplot as plot plot.figure(figsize=(15,10),dpi = 80) plot.plot(df_population_pivot.ix[:,0:1], label="Net Growth rate, both sexes males and females") plot.plot(df_population_pivot.ix[:,1:2], label="Net migration rate (per 1000 population distribution)") plot.plot(df_population_pivot.ix[:,2:3],label="Population growth rate (%)") plot.xlabel('Location') ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Overview of Azure Deep Learning Virtual Machine toolkits</h1>
                </header>
            
            <article>
                
<p>The <strong>Deep Learning Virtual Machine </strong>(<strong>DLVM</strong>) is a superset variant of the traditional Azure data science VM which consists of pre-configured environments that are mainly used to develop and deploy deep learning models on top of GPU instances (for example, a Azure GPU NC series VM), and is available on two OSes—Windows Server 2016 and Ubuntu Linux edition. </p>
<p>The DSVM on Azure contains several AI tools that have been pre-built, including CNTK, Keras, Caffe2, and Chainer to pre-process and extract visual data, text, audio, or video data. You can perform data science modelling and use implementation operations by using tools like Microsoft R server, Anaconda Python, Jupyter Notebooks for Python /2.x , R , SQL Server 2017, Azure ML workbench, Julia,  F# SDK and so on.</p>
<p class="mce-root"/>
<p>You can provision the Deep Learning VM in the Azure portal from the marketplace as an Azure Resource Manager (ARM) and by providing various details like the type of OS, user credentials, and the instance size of the GPU that's been accelerated on a deep learning machine:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/96f16dad-8a88-4eea-85fe-404480779449.png" width="1643" height="895"/></p>
<p>More details on the Azure DLVM from the marketplace can be found at the following link:<q> </q><a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.dsvm-deep-learning">https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.dsvm-deep-learning</a>.<a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/microsoft-ads.dsvm-deep-learning"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Open source deep learning frameworks</h1>
                </header>
            
            <article>
                
<p><span><span>The details of various open source deep learning frameworks that are used in enterprise situations can be seen in the following table:</span></span></p>
<table style="border-collapse: collapse" border="1">
<tbody>
<tr>
<td><strong>Software</strong></td>
<td><strong>Innovator</strong></td>
<td><strong>Platform</strong></td>
<td><strong>Software license</strong></td>
<td><strong>Open source?</strong></td>
<td><strong>CUDA (GPU) support</strong></td>
<td><strong>Platform interface</strong></td>
</tr>
<tr>
<td>CNTK</td>
<td>Microsoft research</td>
<td>Windows and Linux</td>
<td>MIT</td>
<td>Yes</td>
<td>Yes </td>
<td>Python, C++ , C#, and CLI support</td>
</tr>
<tr>
<td>TensorFlow</td>
<td>Google Brain</td>
<td>Linux, macOS, and Windows</td>
<td>Apache 2.0</td>
<td>Yes</td>
<td>Yes</td>
<td>Python(NumPy) and C/C++</td>
</tr>
<tr>
<td>Theano</td>
<td>University of Montreal</td>
<td>Cross-platform</td>
<td>Apache 2.0</td>
<td>BSD license</td>
<td>Yes</td>
<td>Python</td>
</tr>
<tr>
<td>Caffe</td>
<td>Berkeley AI </td>
<td>Linux, macOS, and Windows</td>
<td>BSD license</td>
<td>Yes</td>
<td>Yes</td>
<td>Python and Matlab</td>
</tr>
<tr>
<td>Apache MXNet</td>
<td>Distributed ML community</td>
<td>Ubuntu, macOS, Windows, AWS, Android, and iOS</td>
<td>Apache 2.0</td>
<td>Yes</td>
<td>Yes</td>
<td><span>C++ , Python, Matlab, ...</span></td></tr></tbody></table></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">In-depth analysis of Microsoft deep learning tools </h1>
                </header>
            
            <article>
                
<p>Microsoft has brought out extensive new deep learning toolkits which can be utilized to speed up advances in areas like text analysis, speech/voice recognition, and image classification by applying the cognitive toolkit known as CNTK, which can be run on-premise or in Azure GPU instances. The Azure Cognitive toolkit has support for binding to BrainScript and Python (versions 2.7, 3.5, and 3.6 at the time of writing), C++, and the .NET managed C# platform. </p>
<p>The following are the features of CNTK 2.0 in deep learning:</p>
<ul>
<li>An extension facility for the CNTK function for the extraction, feature engineering, and scoring of optimizer ML algorithms in a variety of languages like Python, C#, and C++.</li>
<li>The integration of TensorFlow models for visualization in CNTK.</li>
<li>Several pre-trained models are available as samples.</li>
<li>Support for image recognition via the use of the FAST R-CNN algorithm on GPU instances (for example, Nvidia Tesla CUDA, and cuDNN).</li>
<li>The availability of a performance profiler for Python and BrainScript.</li>
<li>Autoscaling feasibility of deep learning projects on Azure by running on kubernetes clusters. The autoscaling facility on Kubernetes provides both pod-level scaling (out of the box) as well as node-level scaling. <strong>Horizontal pod scaling</strong> (<strong>HPA</strong>) is a major feature of running CNTK models on AKS, as this automatically scales the number of pods in the clusters based on your requirements and also takes care to specify several node metrics like the percentage of CPU utilization and % of memory availability based on being scaled out or in.</li>
<li>Support of VS tools for AIs, which provides easy local installation for most, if not all, deep learning libraries (for example, Tensorflow, MXNet, Keras, Caffe2, Theano, Torch, Pytorch, Chainer (with GPU cuda support as cuPy), XG-Boost, Scikit-learn, LIBSVM, <span><strong>Open Neural Network Exchange</strong> (</span><strong>ONNX</strong>), Core ML Community Tools (coremltools), Microsoft ML tools, tf2onnx, Netron, and so on). </li>
</ul>
<p class="mce-root"/>
<p>More details on AI tools for Visual Studio and its supported ML/DL libraries can be found at the following GitHub link: <a href="https://github.com/Microsoft/vs-tools-for-ai/blob/master/docs/prepare-localmachine.md">https://github.com/Microsoft/vs-tools-for-ai/blob/master/docs/</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Overview of Microsoft CNTK</h1>
                </header>
            
            <article>
                
<p>Microsoft CNTK is a commercial-grade open source toolkit that's used for deep learning and specifies the neural network structure as a series of computational directed graphs. It was introduced by Microsoft speech researchers (Dong Yu et al.) in 2012, open sourced in 2015, and published on Codeplex. On GitHub, the source code base of CNTK has been available under a permissions license from 2016. CNTK provides the flexibility of ease of use, is fast, and composes simple building blocks into complex networks. This deep learning toolkit is 100% production ready and gives state-of-the-art accuracy, making it efficient and scalable to any CPU/GPU processing platform. It incorporates the popular training models of feed-forward ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The architecture building blocks of CNTK</h1>
                </header>
            
            <article>
                
<p>The <strong>open neural network exchange</strong> (<strong>ONNX</strong>) format that's supported by CNTK  as the first deep learning toolkit has a shared open source model representation for framework interoperability and optimization. ONNX also extends support for moving trained models between frameworks such as CNTK, Caffe2, Apache MXNet, and PyTorch. </p>
<p>The top-level command blocks of CNTK, which are CNTK configuration files, define what actions are to be carried out with related information. The configuration parameter classifies what command blocks are to be implemented, and in what order context, if more than one command block is defined.</p>
<p>Architecture-wise, CNTK configuration parameter command blocks consists of the following:</p>
<ul>
<li><strong>Input reader block</strong>: Specifies the building concepts of the network from the corpus and by loading an existing model</li>
<li><strong>Network layer</strong>: Defines the specified training algorithm to use</li>
</ul>
<ul>
<li><strong>Learner layer</strong>: Specifies the <em>where</em> and <em>how</em> to load the training modules and labels:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="Images/05fb49a2-b118-4b00-98ae-6e43018d402f.png" width="785" height="449"/></p>
<p>The most widely used configuration blocks of CNTK are as follows:</p>
<ul>
<li>Network layer building block:
<ul>
<li><strong>SimpleNetwork Builder</strong>: Executes one of the network models with constrained customization</li>
<li><strong>BrainScriptNetwork Builder</strong>: Implements a network based on the CNTK network description language (BrainScript), which provides benefits in network designs and neural network configurations</li>
</ul>
</li>
<li>Learners:
<ul>
<li><strong>SGD model</strong>: It mainly applies the stochastic gradient descent algorithm for the training of the model.</li>
</ul>
</li>
<li>Input readers:
<ul>
<li><strong>CNTK Text format Reader</strong>: Reads input text files which merge multiple input text files in the same format.</li>
<li><strong>LM Sequence Reader</strong>: Reads input text files containing word sequences for predicting word sequences.</li>
<li><strong>LU Sequence Reader</strong>: Accepts input text-based files as word sequences, as well as its associated labels. This is mainly used for language understanding API building.</li>
<li><strong>HTKMLF Reader</strong>: Reads the input files in the format of HTK/MLF for speech recognition and voice synthesis applications. </li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Concepts on CNTK</h1>
                </header>
            
            <article>
                
<p>The input, output, and parameters of CNTK are organized as <em>tensors</em>, where rank classifies each tensor. A tensor of rank 0 is associated as Scalar, a tensor of <em>rank 1</em> is specified as a Vector, and a tensor of <em>rank 2</em> is defined as a Matrix. There are some static and dynamic axes available for every CNTK. Static axes have the same length throughout the lifetime of the network. The dynamic network's static axes are defined as a meaningful grouping of  tensors where a) their axes' lengths can differentiate from instance to instance, b) their axes lengths are typically unknown before each minibatch is represented, and c) the dynamic axes are ordered. The minibatch is called a tensor, and is called a dynamic axis or batch axis if ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Developing and deploying CNTK layers in the Azure Deep Learning VM to implement a neural network</h1>
                </header>
            
            <article>
                
<p>Microsoft CNTK is flexible and easy to use, and mainly applies simple building blocks to build complex layers quickly. One of the major utilities of CNTK is that it can be used as a backend for the Keras framework as well. From a few benchmark results, we can see that CNTK is generally faster than Google's TensorFlow and up to 5-10 times faster than recurrent/LSTM networks. </p>
<p>To get started and build the CNTK building blocks of Azure Deep Learning GPU instances, we need to provision the DLVM from an Azure portal that supports GPU instances. You can provision the DLVM from the Azure Marketplace by selecting <span class="packt_screen">Create a Resource | New</span>, and then typing <kbd>Deep Learning Virtual Machine</kbd> in the search bar, as demonstrated in the following screenshot:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="Images/ceb43971-110f-4801-998e-28a3ece752ea.png" width="970" height="541"/></p>
<p>Next, by providing the appropriate VM details, such as OS type (Windows/Linux), user credentials, and resource group, you may choose the required GPU instance size, for example, NV6 or NV12, or, if a sufficient quota is available in your Azure subscription, then you can try out the instance sizes such as NC6sv3 (for example, 6 core GPU, 112 GB RAM, and 12 data disks) and NC12sv3 (for example, 12 core GPU, 224 GB of RAM, 24 data disks, and 40k disk IOPS availability).</p>
<p>Azure deep learning is accessible either through the remote desktop (RDP) mode (port <kbd>3389</kbd>), or SSH mode (port <kbd>22</kbd>).</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">CNTK inputs and variables declaration</h1>
                </header>
            
            <article>
                
<p>The foremost exceptional thing about the deep learning framework is its ability to handle input datasets, declared variables, and performance management on computational graphs. In this CNTK demo on the Azure Deep Learning VM, three layers will be associated so that they can recognize a MNIST dataset of handwritten digits. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">CNTK variables section</h1>
                </header>
            
            <article>
                
<p>In the MNIST dataset classification problem, a flattened 28 x 28 pixel value scale input and its associated ten labels are present for classification. In CNTK, the variables could be declared to capture data, as follows:</p>
<pre>import cntk as Cognitive<br/> from cntk.train import Trainer<br/> from cntk.io import MinibatchSource, CTFDeserializer, StreamDef, StreamDefs<br/> from cntk.learners import adadelta, learning_rate_schedule, UnitType<br/> from cntk.ops import RELU, element_times, constant<br/> from cntk.layers import Dense, Sequential, For, default_options<br/> from cntk.losses import cross_entropy_with_softmax<br/> from cntk.metrics import classification_error<br/> from cntk.train.training_session import *<br/> from cntk.logging import ProgressPrinter<br/><br/><br/> input_dimension = 784<br/> number_output_classes = 10<br/> number_hidden_layers = 2<br/> hidden_layers_dimension=200<br/> feature_val = Cognitive.input_variable(input_dimension)<br/> label_val = Cognitive.input_variable(number_output_classes)</pre>
<p>These types of <kbd>input_variable</kbd> functions are declared, just like the placeholder variables in TensorFlow. However, Microsoft CNTK eliminates the necessity to identify the number of sample/batch sizes and users can also supply the dimensions for each evaluation sample. In the case of a convolution neural network task, users can assign <kbd>input_dimension = (1,28,28)</kbd> for a flattened 28 x 28 = 784 pixel input and 10 output labels or classes. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Data readers for CNTK</h1>
                </header>
            
            <article>
                
<p>Microsoft CNTK provides a few helper modules to assist in getting training data into an acceptable format and having it read into the model in a minibatch context. <kbd>CTFDeserializer()</kbd> is a type of function in CNTK that can read input text files in a special CNTK format (where data comes in a sample per line with a pipe/delimiter). Another one is the <kbd>StreamDef()</kbd> function, which acts like a dictionary object. </p>


<p>Using the <kbd>CTFDeserializer()</kbd> function, the CNTK file format is read in the following way:</p>
<pre>from cntk.io import MinibatchSource, CTFDeserializer, StreamDef, StreamDefspath =  "C:\\Users\\CNTK\\Examples\\Image\\DataSets\\MNIST\Train-28x28_cntk_text.txt"reader_train_val = MinibatchSource(CTFDeserializer(path, StreamDefs( ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Operations in CNTK</h1>
                </header>
            
            <article>
                
<p>Similar to TensorFlow, Microsoft CNTK allows operations that are nodes in a computational graph. These nodes and operations provide support for flows. CNTK specifies operations from graph multiplication and division to softmax and convolutional operations. There is a need for the explicit evaluation of the operation code via the <kbd>eval()</kbd> method on the operation runtime. Though most of these operations are not explicitly evaluated, it's evaluated implicitly during the final layer's network execution. </p>
<p>For example, in the MNIST dataset, a simple CNTK operation is performed to scale input features. This scaling is achieved by using 1/256 ~ 0.00390625:</p>
<pre> # Instantiate the feed forward classification model<br/> scaled_input = element_times(constant(0.00390625), feature_val)</pre>
<p>Here, a constant of 0.00390 is declared, as well as the usage of <kbd>element_times()</kbd> operations for multiplying it by the input variable features. The input dataset is scaled between 0 and 1. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Layers of the Microsoft CNTK </h1>
                </header>
            
            <article>
                
<p>The Microsoft Cognitive Toolkit provides us with the capability to provision neural network layers, which provides many layer features such as Dense, Convolution, MaxPooling, Recurrentm, and LSTM. For example, in an MNIST dataset, the standard neural network classifier consists of some densely connected layers such as the input layer, the first hidden layer, the second hidden layer, and the final output layer:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/a4fe8523-fd91-4c16-9c71-172ad89a5fe7.png" style="width:38.00em;height:40.17em;" width="502" height="530"/></p>
<p>Fundamentally, the input layer consists of 784 flattened pixel input layers that are proceeded by two hidden layers of size 200 and a final output layer on which a softmax has been activated. The layers ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">CNTK layer provision helpers</h1>
                </header>
            
            <article>
                
<p>To make network definitions more streamlined, CNTK provides some helper functions/object classes, such as the <kbd>Sequential()</kbd> module, which is similar to the <kbd>Sequential( )</kbd> paradigm in Keras. It also allows you to sequentially stack layer after layer on top without specifying output, which is then passed to the next layer as the input of the next:</p>
<pre>from cntk.layers import Dense, Sequential, For, default_options<br/><br/>with default_options(activation=relu, init=Cognitive.glorot_uniform()):<br/> z = Sequential([For(range(number_hidden_layers),<br/><br/>lambda i: Dense(hidden_layers_dimension)),<br/> Dense(number_output_classes, activation=None)])(scaled_input)</pre>
<p>There is the presence of the <kbd>layers.default_options()</kbd> module in CNTK, which can assist in streamlining, and which is used in more complicated networks. Activation functions are no longer required here, but <kbd>default_option</kbd> is used for the output layer since it allows us to apply softmax in the loss function. The same initialization of the <kbd>glorot_uniform()</kbd> function is specified in each layer:</p>
<pre><br/> def simple_mnist():<br/> input_dimension = 784<br/> number_output_classes = 10<br/> number_hidden_layers = 2<br/> hidden_layers_dimension = 200</pre>
<pre class="mce-root"># Instantiate the feedforward classification model<br/> scaled_input = element_times(constant(0.00390625), feature_val)<br/><br/>with default_options(activation=relu, init=Cognitive.glorot_uniform()):<br/> z = Sequential([For(range(number_hidden_layers),<br/> lambda i: Dense(hidden_layers_dimension)),<br/> Dense(number_output_classes, activation=None)])(scaled_input)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">CNTK modules for losses and error handling</h1>
                </header>
            
            <article>
                
<p>The CNTK library has a full set of loss functions and error handling modules to train the model. This range classifies from standard cross entropy and squared error to cosine distances such as lambda ranks. For classification purposes, the <kbd>cross_entropy_with_softmax</kbd> option can be applied:</p>
<pre class="mce-root">ce = cross_entropy_with_softmax(z, label_val)</pre>
<p class="mce-root">Here, the output layer, <kbd>z</kbd>, is supplied with a labelled output variable value and the cross entropy loss is calculated with softmax precision on <kbd>z</kbd>.</p>
<p class="mce-root">Next, for accessing errors on the test set, the training model has to be used. For the classification task, the <kbd>classification_error()</kbd> function has to be used: </p>
<pre class="mce-root">pe = classification_error(z, label_val)</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Input training models in CNTK</h1>
                </header>
            
            <article>
                
<p>CNTK has various options for performing training, such as simply calling a dictionary containing input and output training sets: </p>
<pre>input_map = {<br/> feature_val: reader_train_val.streams.features,<br/> label_val: reader_train_val.streams.labels<br/> }</pre>
<p>The <kbd>MinibatchSource()</kbd> object that's been used here calls <kbd>reader_train</kbd>, and is where you can access the streams/data by using the dot notation. </p>
<p>A <kbd>ProgressPrinter</kbd> also needs to be defined, and this is where an object allows you to design output metrices such as loss and classification errors. The progress writers can be instantiated as well:</p>
<pre># Instantiate progress writers.<br/> progress_writers_val = [ProgressPrinter(<br/> tag='Training',<br/> num_epochs=number_sweeps_to_train_with)]</pre>
<p>The <kbd>tag</kbd> argument specifies the demonstration of a value in the log that's been attached in each update. The total number of epochs during model training is counted by a counter, and is declared by <kbd>num_epochs</kbd>. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Instantiating the Trainer object   </h1>
                </header>
            
            <article>
                
<p>In order to set up the <kbd>Trainer</kbd> object, we need a module that trains the model and feeds it into a number of information layers, such as the output layer and the prior layer, which is used to train a computational graph structure. Then, we need to utilize the loss function that's going to be used for computing gradients where optimizers such as stochastic descent, and Ada Grad can be used:</p>
<pre>#Instantiate the trainer object to drive the model training lr = learning_rate_schedule(1, UnitType.sample) trainer = Trainer(z, (ce, pe), [adadelta(z.parameters, lr)], progress_writers_val)  </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Defining the training session object</h1>
                </header>
            
            <article>
                
<p>The CNTK library has a marvellous way of expressing the <kbd>training_session()</kbd> object and its minibatch initialization. It associates defining the input data, logging, <kbd>num_sweeps_to_train</kbd>, samples per sweep, and so on:</p>
<pre># Training config<br/> minibatch_size_val = 64<br/> number_samples_per_sweep = 60000<br/> number_sweeps_to_train_with = 10<br/><br/>training_session(<br/> trainer=trainer,<br/> mb_source=reader_train_val,<br/> mb_size=minibatch_size_val,<br/> model_inputs_to_streams=input_map,<br/> max_samples=number_samples_per_sweep * number_sweeps_to_train_with,<br/> progress_frequency=number_samples_per_sweep<br/> ).train()</pre>
<p>In this <kbd>training_session()</kbd> object, all of the optimization and parameter learning is going to occur in the source, and is where we can extract minibatch data that's used as the <kbd>reader_main</kbd> <kbd>MinibatchSource</kbd> object. </p>
<p>Once you execute the training, the output is shown on the progress writer, as shown in the following screenshot:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="Images/0db99f30-730c-431d-895c-e649b42cae03.png" width="979" height="512"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The CNTK testing model</h1>
                </header>
            
            <article>
                
<p>For testing the CNTK training model, we need to load <kbd>Test-28x28_cntk__text.txt</kbd> in the path retrieved from the MNIST dataset. We need to set up <kbd>MinibatchSource</kbd> to read our test data, and we also need to assign input maps to the test data:</p>
<pre># Load test data path = "C:\\Users\\CNTK\\Examples\\Image\\DataSets\\MNIST\\Test-28x28_cntk_text.txt"#Reading of data using MinibatchSourcereader_test_val = MinibatchSource(CTFDeserializer(path, StreamDefs( features=StreamDef(field='features', shape=input_dimension), labels=StreamDef(field='labels', shape=number_output_classes))))#mapping of input dataset using feature &amp; labelinput_map = { feature_val: reader_test_val.streams.features, label_val: reader_test_val.streams.labels }</pre>
<p>The ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Deploying CNTK tools by using Azure Containers (Docker)</h1>
                </header>
            
            <article>
                
<p>For running CNTK Jupyter Notebooks on Docker containers and pulling CNTK images from Docker, make sure that you use a Linux-based VM or Azure Linux Data Science/DLVM. </p>
<p>The latest build of CNTK can be pulled using a Docker container that's using Azure DSVM via the following command:</p>
<pre><strong>docker pull microsoft/cntk </strong></pre>
<p><kbd>docker pull microsoft/cntk:2.6-gpu-python3.6</kbd> can be used for a GPU-specific version of Python. The Nvidia-docker driver is required for the execution of GPU versions of CNTK Jupyter Notebooks:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/0c9a7652-5903-42f5-9c1c-d13be0152867.png" style="width:33.58em;height:19.50em;" width="471" height="273"/></p>
<p>To run CNTK Jupyter Notebooks in the Docker container of the Azure Deep Learning VM, the CNTK container needs to be created and started with the IP port exposed in detached mode in the default port <kbd>8888:8888</kbd>:</p>
<pre><strong>docker run -d -p 8888:8888 --name cntk-jupyter-notebooks -t microsoft/cntk</strong></pre>
<p>Then, the following command starts and activates the CNTK for Jupyter Notebooks. You need to expose port <kbd>8888</kbd> in the <strong>network security group</strong> (<strong>NSG</strong>) configuration settings for inbound network rules:</p>
<pre>docker exec -it cntk-jupyter-notebooks bash -c "source /cntk/activate-cntk andand jupyter-notebook --no-browser --port=8888 --ip=0.0.0.0 --notebook-dir=/cntk/Tutorials --allow-root"</pre>
<p>The output screenshot looks like it does in the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/026a31dd-ec8a-44c6-870b-ec329890e10e.png" width="1320" height="531"/></p>
<p> </p>
<p>More details on executing CNTK in GPU mode on Docker containers in a Linux environment can be found at the following link: <a href="https://docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Docker-Containers">https://docs.microsoft.com/en-us/cognitive-toolkit/CNTK-Docker-Containers</a>.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Keras as a backend for Microsoft CNTK</h1>
                </header>
            
            <article>
                
<p>Keras is a high-level neural network API that's written in Python that abstracts complex configurations and builds production grade training models using matrix algebra. Keras is capable of executing on top of Microsoft CNTK, Google TensorFlow, or Theano, and has been developed with aim of enabling fast experimentation in a sequence or a graph of standalone, fully configurable modules:</p>
<ul>
<li>Keras supports both convolutional and recurrent networks and executes on CPU/GPU. </li>
<li>After CNTK activation, Keras can be simply installed by using <kbd>pip</kbd>. The <kbd>keras.json</kbd> file can be used as the backend of CNTK. </li>
<li>Update <kbd>keras.json</kbd> at <kbd>%USERPROFILE%/.keras</kbd> on Windows, or <kbd>$HOME/.keras</kbd> on Linux:</li>
</ul>
<pre>{    "epsilon": 1e-07, "image_data_format": ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">An overview of the Microsoft Machine Learning Library for Apache Spark (MMLSpark)</h1>
                </header>
            
            <article>
                
<p>The Microsoft <strong>Machine Learning Library for Apache Spark</strong> (<strong>MMLSpark</strong>) assists in provisioning scalable machine learning models for large datasets, especially for building deep learning problems. MMLSpark works with SparkML pipelines, including Microsoft CNTK and the OpenCV library, which provide end-to-end support for the ingress and processing of image input data, categorization of images, and text analytics using pre-trained deep learning algorithms. They also train and retrieve scores from classification and regression models by applying featurization. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Environment setup for MMLSpark</h1>
                </header>
            
            <article>
                
<p>The following prerequisites are mandatory for setting up MMLSpark library for deep learning projects on Azure:</p>
<ul>
<li>The <kbd>MMLSpark</kbd> library can be used with the Azure ML workbench</li>
<li><kbd>MMLSpark</kbd> can also be integrated with the Azure HDInsight Spark cluster</li>
<li>Use of a Databricks Cloud</li>
<li>Use of an Azure GPU VM</li>
<li>Use of the Spark/pyspark/Scala(SBT) package</li>
<li>Use of a Docker container</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Execution of MMLSpark notebooks using a Docker container </h1>
                </header>
            
            <article>
                
<p>In order to execute <kbd>MMLSpark</kbd> Jupyter Notebooks by using a Docker container, you can run the following command in a PowerShell prompt:</p>
<pre><strong>docker run -d --name my-mmlsparkbook -p 8888:8888 -e ACCEPT_EULA=yes microsoft/MMLSpark</strong></pre>
<p>The execution output of the MMLSpark Jupyter Notebook running on a Docker container appear as in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/7861d68b-1759-415a-a60c-da45977edac1.png" width="782" height="70"/></p>
<p>Here, the notebook is tagged with the name <kbd>mmlsparkbook</kbd> and is accepting the EULA agreement by default. Next, the Docker container needs to be started and activated for <kbd>mmlsparkbook</kbd>, which opens the MMLSpark notebooks at the following URL: <kbd>http://localhost:8888</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/f4a40dce-4e83-47eb-acef-82ad9efa53f2.png" style="width:63.83em;height:43.42em;" width="988" height="672"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure HDInsight Spark cluster setup for MMLSpark</h1>
                </header>
            
            <article>
                
<p>The MMLSpark library can be installed by using an existing Spark cluster and applying the <kbd>--packages</kbd> options, as follows:</p>
<ul>
<li><kbd>spark-shell --packages Azure:MMLSpark:0.13</kbd></li>
<li><kbd>pyspark --packages Azure:MMLSpark:0.13</kbd></li>
<li><kbd>spark-submit --packages Azure:MMLSpark:0.13 MyMMLSparkApp.jar</kbd></li>
</ul>
<p>Similarly, it can be applied for Spark contexts as well, which can be done by using MMLSpark in AZTK in the <kbd>.aztk/spark-default.conf</kbd> file.</p>
<p>More details on the MMLSpark library can be found at the following GitHub link: <a href="https://github.com/Azure/mmlspark">https://github.com/Azure/MMLSpark</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Overview of TensorFlow on Azure </h1>
                </header>
            
            <article>
                
<p>TensorFlow is an open source, deep learning library that was introduced by Google and is used for solving a range of tasks. TensorFlow was introduced to fulfill the requirement of building and training complex neural networks in order to detect and decipher patterns, recognitions, and correlations, similar to that of the learning process of the human brain. Google introduced the TPU (Tensor Processing Unit) cloud platform for running the TensorFlow Python API and utilizing TensorFlow graph units. </p>
<p>In order to get started on TensorFlow with Azure, the two easiest options are as follows:</p>
<ul>
<li><strong>Using Deep Learning toolkit for Data Science VM (Deep Learning VM)</strong>: Provides a Windows GPU version of mxnet, CNTK, TensorFlow, and Keras that's able to run on a GPU-NC, N-series, or FPGA infrastructure. </li>
<li><strong>Using Data Science VM for Azure</strong>: Support for CNTK, TensorFlow, MXNet, Caffe, Caffe2, DIGITS, H2O, Keras, Theano, and PyTorch is installed by default, and has been configured so that it's ready to use along with the support of NVidia CUDA, and cuDNN. Jupyter Notebooks and VS tools with AI are preconfigured as well. </li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Simple computation graph on TensorFlow</h1>
                </header>
            
            <article>
                
<p>The TensorFlow library is based on computational graphs, such as <em>a = d * e</em>,<em> </em><em>d = b + c</em>, and <em>e = c+ 2</em>, and so this formula can be written as <em>a = (b+c) * (c+2)</em>, as shown in the following diagram: </p>

<p class="CDPAlignCenter CDPAlign"><img src="Images/4ca8392b-d8f0-4ad7-93fe-8727e2590e80.png" style="width:34.17em;height:37.83em;" width="482" height="533"/></p>
<p>The preceding graph computation can be parallelized by executing (<em>d = b + c</em> and <em>e = c + 2</em>) and by splitting the calculations on both CPUs and GPUs. For complex deep learning problems, especially in Convolutional Neural Network (CNNs) and <strong>Recurrent Neural Network</strong> (<strong>RNNs</strong>) architectures, this is essential. The concept behind TensorFlow is to have the capability to provision these computational graphs in code and allow ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">TensorFlow operations </h1>
                </header>
            
            <article>
                
<p>TensorFlow supports a bunch of operations so that it can initialize the graph's structure:</p>
<pre>#Declare few TensorFlow operations<br/> d = tensorf.add(b, c, name='d')<br/> e = tensorf.add(c, 2, nname='e')<br/> a = tensorf.multiply(d, e, nname='a')</pre>
<pre class="mce-root">#setup the initialization of variables<br/> init_operation = ttensorf.global_variable_initializer()</pre>
<p>In order to run the operations between the variables, we need to start a TensorFlow session, such as <kbd>tensorf.Session</kbd>. The TensorFlow session is an object where all such operations can run. In the TensorFlow session <kbd>run</kbd> function, the operation initializes variables that need to be initialized. Next is an operation. This needs to be run and can be executed with the <kbd>tfsess.run(a)</kbd> command. We can assign the output to <kbd>a_graphout</kbd> so that it can be printed:</p>
<pre>#Start the Tensorflow Session<br/> with tensorf.Session() as tfsess:<br/> #initialize the variables<br/> tfsess.run(init_operation)<br/> #computation of the output from the graph<br/> a_graphOut = tfsess.run(a)<br/> print("Variable a is the value of {}".format(a_graphOut))</pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Declaration of the TensorFlow placeholder </h1>
                </header>
            
            <article>
                
<p>TensorFlow assigns the basic structure of data by using a placeholder variable declaration such as the following:</p>
<pre>def run_simple_tensorGraph_multiple(): #first lets create a constant for TensorFlow constant = tensorf.constant(2.0, name="constant")</pre>
<pre class="mce-root">#Next create those TensorFlow variables b = tensorf.placeholder(tensorf.float32,[None, 1], NameError='b') c = tensorf.Variable(1.0, name='c')</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Neural Network Formation using TensorFlow </h1>
                </header>
            
            <article>
                
<p>TensorFlow specifies the Neural Network Formation for solving complex real-life problems, especially on CNNs or RNNS. For example, we can use the MNIST dataset TensorFlow package, where the dataset contains a 28 x 28 pixel grayscale image with approximately 55k rows, 10k testing rows, and 5k validation handwritten digit rows: </p>
<pre>def nn_example():<br/> mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)</pre>
<pre class="mce-root"># Python optimisation variables<br/> learning_rate = 0.5<br/> epochs = 10<br/> batch_size = 100</pre>
<p>For training data and parameters, the placeholder variables can be provisioned:</p>
<pre> # declare the training data placeholders<br/> # input x - for 28 x 28 pixels = 784<br/> x = tensorf.placeholder(tensorf.float32, [None, 784])<br/> # now declare the output data placeholder - 10 digits<br/> y = tensorf.placeholder(tensorf.float32, [None, 10])</pre>
<p>Here, the <kbd>x</kbd> input data layer consists of 28 x 28 = 784 pixels and y nodes like 10 digits. Also, for a neural network, the weight and bias also need to be initialized. In TensorFlow, there is the possibility of an L-1 number of weights/bias tensors or graphs: </p>
<pre># now declare the weights connecting the input to the hidden layer<br/> W1 = tensorf.Variable(tensorf.random_normal([784, 300], stddev=0.03), name='W1')<br/> b1 = tensorf.Variable(tensorf.random_normal([300]), name='b1')<br/> # and the weights connecting the hidden layer to the output layer<br/> W2 = tensorf.Variable(tensorf.random_normal([300, 10], stddev=0.03), name='W2')<br/> b2 = tensorf.Variable(tensorf.random_normal([10]), name='b2') </pre>
<p>First, we need to declare some variables for <kbd>W1</kbd> and <kbd>b1</kbd> for the weights and bias for the connections between the input and hidden layer, where the neural network will have 300 nodes in the hidden layer. The size of the weight tensor, <kbd>W1</kbd>, is <kbd>[784, 300]</kbd>. Similarly, TensorFlow supports the NumPy random normal function, which assigns to provision a matrix of a given size that's populated with random samples. In a similar manner, the weight variable, <kbd>W2</kbd>, and the bias variable, <kbd>b2</kbd>, connect the hidden layer to the output of the neural network. </p>
<p>The output of the hidden layer is calculated by using the <kbd>relu</kbd> function (by applying the rectified linear unit):</p>
<pre># calculate the output of the hidden layer<br/> hidden_out = tensorf.add(tensorf.matmul(x, W1), b1)<br/> hidden_out = tensorf.nn.relu(hidden_out)</pre>
<p>The weight multiplication with the output from the hidden layer, and the addition of a <kbd>b2</kbd> bias value, is applied by using the softmax activation for the output layer. This can be found via the TensorFlow softmax function <kbd>tf.nn.softmax</kbd>:</p>
<pre> # now calculate the hidden layer output - in this case, let's use a softmax activated<br/> # output layer<br/> y_ = tensorf.nn.softmax(tensorf.add(tensorf.matmul(hidden_out, W2), b2))</pre>
<p>For the optimizer, we need to include a cost or loss function. The cross entropy cost function is used for this purpose. Here is how we set up the optimizer in TensorFlow: </p>
<pre class="mce-root"># add an optimiser<br/> optimiser = tensorf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)</pre>
<p>The gradient descent optimizer is supplied by TensorFlow alongside a learning rate that's used to specify the minimized cross entropy cost operation that has been provisioned. The function is going to perform gradient descent and back propagation as follows:</p>
<pre># finally setup the initialisation operator<br/> init_operation = tensorf.global_variables_initializer()</pre>
<pre># define an accuracy assessment operation<br/> correct_prediction = tensorf.equal(tensorf.argmax(y, 1), tensorf.argmax(y_, 1))<br/> accuracy = tensorf.reduce_mean(tensorf.cast(correct_prediction, tensorf.float32))</pre>
<pre class="mce-root"># add a summary to store the accuracy<br/> tensorf.summary.scalar('accuracy', accuracy)</pre>
<pre class="mce-root">merged = tensorf.summary.merge_all()<br/> writer = tensorf.summary.FileWriter('c:\\users\\anbasa\\source\\repos')</pre>
<p>The correct prediction operation provides <kbd>correct_prediction</kbd>, which utilizes TensorFlow. <kbd>tensorf.equal</kbd> provides a true/false reading depending on the arguments of the Boolean value. <kbd>tensorf.argmax</kbd> works in the same way as the NumPy <kbd>argmax</kbd> function, since it returns the index of the maximum value in a particular tensor or vector. </p>
<p>Henceforth, the <kbd>correct_prediction</kbd> operation assigns a tensor of size (<kbd>mx1</kbd>) true or false, designating whether the neural network is correctly predicting the digit value. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">TensorFlow training </h1>
                </header>
            
            <article>
                
<p>For provisioning the TensorFlow training, first, the TensorFlow session needs to be set up and initialize the variables.</p>
<p>It also provides the details from a minibatch training scheme that can be executed for the neural network. It also calculates the number of batches to run through in each epoch by calculating each training epoch and initializing an <kbd>avg_cost</kbd> variable. TensorFlow supplies an MNIST dataset that has a utility function, such as <kbd>next_batch</kbd>, which makes it easier to extract batches of training data:</p>
<pre># start the session with tensorf.Session() as tfsess: # initialise the variables tfsess.run(init_operation) total_batch = int(len(mnist.train.labels) / batch_size) for epoch in range(epochs): avg_cost = 0 for i ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Execution of TensorFlow on Azure using Docker container services</h1>
                </header>
            
            <article>
                
<p>TensorFlow can be executed using Docker container services on top of Azure Linux virtual machines. The endpoint needs to be exposed in the NSG port <kbd>8888</kbd>, and the following command, which initializes a Docker container running TensorFlow inside a Jupyter Notebook, needs to be executed:</p>
<pre><strong>docker run -d -p <span class="m">8888</span>:8888 -v /notebook:/notebook xblaster/TensorFlow-jupyter</strong></pre>
<p class="CDPAlignCenter CDPAlign"><img src="Images/a2afbfff-6672-406f-8a1b-d6028b910a37.png" width="875" height="82"/></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Running TensorFlow containers on an Azure Kubernetes Cluster (AKS)</h1>
                </header>
            
            <article>
                
<p>A sample Kubernetes cluster on the <strong>Azure container service</strong> (<strong>AKS</strong>) is provisioned by using the open source toolkit DLWorkspace (<a href="https://microsoft.github.io/DLWorkspace/" target="_blank">https://microsoft.github.io/DLWorkspace/</a>). The repository provides standard Azure VMs on CPU/GPU. The sample k8 cluster and Alluxio-FUSE-enabled k8 pods can be created. </p>
<div class="mce-root packt_infobox">The sample pod configuration is available at the following GitHub link: <a href="https://github.com/jichang1/TensorFlowonAzure/tree/master/Alluxio">https://github.com/jichang1/TensorFlowonAzure/tree/master/Alluxio</a>.</div>
<p>TensorFlow jobs can be executed on the parameter server pods and worker pods by using the following commands:</p>
<pre>python tf_cnn_benchmarks.py --local_parameter_device=gpu --num_gpus=2 --batch_size=128 --model=googlenet --variable_update=parameter_server ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Other deep learning libraries  </h1>
                </header>
            
            <article>
                
<p>Microsoft provides samples of deep learning tools across Theano, Caffe, MXNet, Chainer, PyTorch, and Keras on datasets such as MNIST and CIFAR10. The following are the prerequisites to run these samples:</p>
<ul>
<li>You need Visual Studio 2017 with VS tools for AI and the MNIST dataset. The VS tools for AI are available to download from <span class="packt_screen">Extensions and Updates</span> under <span class="packt_screen">Tools</span>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="Images/17aba079-166e-4747-993d-319890d26abb.png" width="588" height="131"/></p>
<ul>
<li>An NVIDIA GPU driver/CUDA 9.0/cuDNN 7.0, as applicable, and Python 3.5/3.6. Python 2.x is still not supported (as of the time of writing).</li>
<li>The deep learning libraries that need to be installed include NumPy, SciPy, Matplotlib, ONNX, CNTK, TensorFlow, Caffe2 , MXNet, Keras, theano, and PyTorch:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="Images/a2655502-f1b4-43ac-801d-5ef11f740bbd.png" width="1297" height="567"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<ul>
<li>The GitHub link for the AI samples repository is available at <a href="https://github.com/Microsoft/samples-for-ai">https://github.com/Microsoft/samples-for-ai</a>.<a href="https://github.com/Microsoft/samples-for-ai"/></li>
<li><strong>Apache MXNet</strong>: Apache MXNet is a scalable deep learning library that's used to train and deploy deep neural networks  that are available to scale across GPU or CPU. MXNet offers support for Azure. More details on MXNet are available at <a href="https://mxnet.incubator.apache.org/">https://mxnet.incubator.apache.org/</a>.</li>
<li><strong>Caffe</strong><span>: This deep learning framework provides expressions, speed, scalability, modularity, openness, and huge community support for building and training complex neural networks. Caffe 2.0 is pre-installed in Azure Deep Learning toolkits and DSVM. </span></li>
<li><strong>Theano</strong>: <span>This is a Python-based deep learning library that's used for the evaluation of complex mathematical, statistical expressions by using the NumPy-esque syntax and is compiled by using CPU/GPU architectures. </span></li>
<li><strong>Pytorch</strong>:<span> Pytorch is again a Python-based scientific computing framework that's used for Numpy executions on GPU and Deep Learning interactive research. Pytorch allows for interactive debugging with clean dynamic graphs with a mixture of high-level and low-level API support. This works for <strong>Artificial Neural Networks</strong> (<strong>ANNs</strong>), Regression, and <strong>Convolution Neural Networks</strong> (<strong>CNNs</strong>). </span></li>
<li><strong>Chainer</strong>: <span>An open source deep learning library based on Python that's used for NumPy and CuPy <kbd>libraries.supports</kbd> CUDA implementations and intuitive, flexible DL frameworks that allow the use of feed-forward nets, convnets, recurrent nets, and recursive nets. More details can be found at </span><a href="https://chainer.org/">https://chainer.org/</a>.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned about deep learning methodology and the tools that are supported on the Microsoft Azure AI platform. We have demonstrated various AI tools, such as CNTK, MMLSpark, and TensorFlow, as well as its execution process on Azure deep learning toolkits/data science VMs, along with other open source deep learning libraries and utilities.</p>
<p>In the next chapter, we will be looking at a step-by-step overview of<span> integrating other</span> Azure services with the Microsoft AI platform. </p>


            </article>

            
        </section>
    </div>



  </body></html>