<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer014">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor014"/>1</h1>
<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>Introduction to Machine Learning with Qlik</h1>
<p>Machine learning and artificial intelligence are two of the most powerful technology trends in the 21<span class="superscript">st</span> century. Usage of these technologies is rapidly growing since the need for faster insights and forecasts has become crucial for companies. Qlik<a id="_idIndexMarker000"/> is a leading vendor in the analytics space and has heavily invested in machine learning and <span class="No-Break">AI tools.</span></p>
<p>This first chapter will introduce the different machine learning tools in the Qlik ecosystem and provide basic information about the statistical models and principles behind these tools. It will also cover the concepts of correct sample size and how to analyze model performance <span class="No-Break">and reliability.</span></p>
<p>Here is what we will cover in this <span class="No-Break">first chapter:</span></p>
<ul>
<li>An overview of the Qlik tools <span class="No-Break">and platform</span></li>
<li>The basic statistical concepts of <span class="No-Break">machine learning</span></li>
<li>Proper sample size and the defining factors of <span class="No-Break">a sample</span></li>
<li>How to evaluate model performance <span class="No-Break">and reliability</span></li>
</ul>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Introduction to Qlik tools</h1>
<p>Qlik Sense<a id="_idIndexMarker001"/> is a leading data analytics and business intelligence platform and contains many tools and features for data analytics relating to machine learning. In this chapter, we will take a closer look at the key features of the <span class="No-Break">Qlik platform.</span></p>
<p>Machine learning and AI capabilities on the Qlik platform can be divided into three <span class="No-Break">different components:</span></p>
<ul>
<li><span class="No-Break">Insight Advisor</span></li>
<li><span class="No-Break">Qlik AutoML</span></li>
<li>Advanced <span class="No-Break">Analytics Integration</span></li>
</ul>
<h2 id="_idParaDest-18"><a id="_idTextAnchor017"/>Insight Advisor</h2>
<p>Qlik Insight Advisor is <a id="_idIndexMarker002"/>a feature of Qlik Sense that uses <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) and<a id="_idIndexMarker003"/> machine learning to help users explore and analyze data more effectively. It allows users to ask questions about their data in natural language and to receive insights and recommendations in real time. It also auto-generates advanced analytics and visualizations and assists with analytics creation and <span class="No-Break">data preparation.</span></p>
<p>Insight Advisor utilizes a combination of Qlik’s associative engine and augmented intelligence engine and supports a wide range of use cases, as seen in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer008">
<img alt="Figure 1.1: Qlik Insight Advisor and different scenarios" height="611" src="image/B19863_01_01.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1: Qlik Insight Advisor and different scenarios</p>
<p class="callout-heading">Did you know?</p>
<p class="callout">The Qlik associative engine<a id="_idIndexMarker004"/> is the core technology that powers the Qlik data analytics and business intelligence platform. It is a powerful in-memory engine that uses an associative data model, which allows users to explore data in a way that is more intuitive and natural than traditional <span class="No-Break">query-based tools.</span></p>
<p class="callout">Instead of pre-defined queries or data models, the engine automatically associates data across multiple tables and data sources based on common fields or attributes and uses a patented indexing technology that stores all the data in memory, enabling real-time analysis and exploration of even the largest datasets. It is a powerful and innovative technology that underpins the entire <span class="No-Break">Qlik platform.</span></p>
<p>Insight Advisor has the following <span class="No-Break">key features:</span></p>
<ul>
<li><strong class="bold">Advanced insight generation</strong>: Insight Advisor <a id="_idIndexMarker005"/>provides a way to surface new and hidden insights. It uses AI-generated analyses that are delivered in multiple forms. Users can select from a full range of analysis types, which are auto-generated. These types include visualizations, narrative insights, and entire dashboards. Advanced analytics is also supported, and Insight Advisor can generate comparison, ranking, trending, clustering, geographical analysis, time series forecasts, <span class="No-Break">and more.</span></li>
<li><strong class="bold">Search-based visual discovery</strong>: Insight Advisor auto-generates the most relevant and impactful visualizations for the users, based on natural language queries. It provides a set of charts that users can edit and fine-tune before adding to the dashboard. It is context-aware and reflects the selections with generated visualizations. It also suggests the most significant data relationships to <span class="No-Break">explore further.</span></li>
<li><strong class="bold">Conversational analytics</strong>: Conversational analytics in Insight Advisor allows users to interact using natural language. Insight Advisor Chat offers a fully conversational analytics experience for the entire Qlik platform. It understands user intent and delivers additional insights for <span class="No-Break">deeper understanding.</span></li>
<li><strong class="bold">Accelerated creation and data preparation</strong>: Accelerated creation and data preparation helps users to create analytics using a traditional build process. It gives recommendations about associations and relationships in data. It also gives chart suggestions and renders the best types of visualizations for each use case, which allows non-technical users to get the most out of the analyzed data. Part of the data preparation also involves an intelligent profiling that provides descriptive<a id="_idIndexMarker006"/> statistics about <span class="No-Break">the data.</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">A hands-on example with Insight Advisor can be found in <a href="B19863_09.xhtml#_idTextAnchor109"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, where you will be given a practical example of the most important functionalities <span class="No-Break">in action.</span></p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>Qlik AutoML</h2>
<p>Qlik AutoML is an <a id="_idIndexMarker007"/>automated machine learning tool that makes AI-generated machine learning models and predictive analytics available for all users. It allows users to easily generate machine learning models, make predictions, and plan decisions using an intuitive, code-free <span class="No-Break">user interface.</span></p>
<p>AutoML connects and profiles data, identifies key drivers in the dataset, and generates and refines models. It allows users to create future predictions and test what-if scenarios. Results are returned with prediction-influencer data (Shapley values) at the record level, which allows users to understand why predictions were made. This is critical to take the correct actions based on <span class="No-Break">the outcome.</span></p>
<p>Predictive data can be published in Qlik Sense for further analysis and models can be integrated using Advanced Analytics Integration for real-time <span class="No-Break">exploratory analysis.</span></p>
<p>Using AutoML is simple and does not require comprehensive data science skills. Users must first select the target field and then AutoML will run through various steps, as seen in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer009">
<img alt="Figure 1.2: The AutoML process flow" height="1056" src="image/B19863_01_02.jpg" width="1651"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2: The AutoML process flow</p>
<p>With the model established <a id="_idIndexMarker008"/>and trained, AutoML lets users make predictions on current datasets. Deployed models can be used both from Qlik tools and other analytics tools. AutoML also provides a REST API to consume the <span class="No-Break">deployed models.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">More information about AutoML, including hands-on examples, can be found in <a href="B19863_08.xhtml#_idTextAnchor101"><span class="No-Break"><em class="italic">Chapter 8</em></span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>Advanced Analytics Integration</h2>
<p><strong class="bold">Advanced Analytics Integration</strong> is the<a id="_idIndexMarker009"/> ability to integrate advanced analytics and machine learning models directly into the Qlik data analytics platform. This integration allows users to combine the power of advanced analytics with the data exploration and visualization capabilities of Qlik to gain deeper insights from <span class="No-Break">their data.</span></p>
<p>Advanced Analytics Integration<a id="_idIndexMarker010"/> is based on open APIs that provide direct, engine-level integration between Qlik’s Associative Engine and third-party data science tools. Data is being exchanged and calculations are made in real time as the user interacts with the software. Only relevant data is passed from the Associative Engine to third-party tools, based on user selections and context. The workflow is explained in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<img alt="Figure 1.3: Advanced analytics integration dataflow" height="699" src="image/B19863_01_03.jpg" width="1589"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3: Advanced analytics integration dataflow</p>
<p>Advanced analytics integration can be used with any external calculation engine, but native connectivity is provided for Amazon SageMaker, Amazon Comprehend, Azure ML, Data Robot, and custom models made with R and Python. Qlik AutoML can also utilize advanced <span class="No-Break">analytics</span><span class="No-Break"><a id="_idIndexMarker011"/></span><span class="No-Break"> integration.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">More information, including practical examples about advanced analytics integration, can be found in <a href="B19863_07.xhtml#_idTextAnchor096"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>. Installing the needed components for the on-premises environment is described in <a href="B19863_05.xhtml#_idTextAnchor071"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-21"><a id="_idTextAnchor020"/>Basic statistical concepts with Qlik solutions</h1>
<p>Now that we have been introduced to Qlik tools, we will explore some of the statistical concepts that are used with them. Statistical principles<a id="_idIndexMarker012"/> play a crucial role in the development of machine-learning algorithms. These principles provide the mathematical framework for analyzing and modeling data, making predictions, and improving the accuracy of machine-learning models over time. In this section, we will become familiar with some of the key concepts that will be needed when building <span class="No-Break">machine-learning solutions.</span></p>
<h2 id="_idParaDest-22"><a id="_idTextAnchor021"/>Types of data</h2>
<p>Different data types<a id="_idIndexMarker013"/> are handled differently, and each requires different techniques. There are two major data types in typical machine-learning solutions: categorical <span class="No-Break">and numerical.</span></p>
<p>Categorical data<a id="_idIndexMarker014"/> typically defines a group or category using a name or a label. Each<a id="_idIndexMarker015"/> piece of a categorical dataset is assigned to only one category and each category is mutually exclusive. Categorical data can be further divided into nominal data and ordinal data. Nominal data<a id="_idIndexMarker016"/> is the data category that names or labels a category. Ordinal data<a id="_idIndexMarker017"/> is constructed from elements with rankings, orders, or rating scales. Ordinal data can be ordered or counted but not measured. Some machine-learning algorithms can’t handle categorical variables unless these are converted (encoded) to <span class="No-Break">numerical values.</span></p>
<p>Numerical data<a id="_idIndexMarker018"/> can be divided into discrete data that is countable numerical data. It is<a id="_idIndexMarker019"/> formed using natural numbers, for example, age, number of employees in a company, etc. Another form of numerical data is continuous data. An example of this type of data can be a person’s height or a student’s score. One type of data to pay attention to is datetime information. Dates and times are typically useful in machine-learning models but will require some work to turn them into <span class="No-Break">numerical data.</span></p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/>Mean, median, and mode</h2>
<p>The <strong class="bold">mean</strong> is <a id="_idIndexMarker020"/>calculated by dividing the sum of all values in a dataset by the number of values. The simplified equation can be formed <span class="No-Break">like this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Variable">b</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>The following is a simple example to calculate the mean of a set of <span class="No-Break">data points:</span></p>
<p><em class="italic">X = [</em><span class="No-Break"><em class="italic">5,15,30,45,50]</em></span></p>
<p><em class="italic">X</em><span class="_-----MathTools-_Math_Symbol_Extended">̅</span><em class="italic"> = <a id="_idTextAnchor023"/>(</em><span class="No-Break"><em class="italic">5+15+30+45+50)/5</em></span></p>
<p><em class="italic">X</em><span class="_-----MathTools-_Math_Symbol_Extended">̅</span><em class="italic"> = </em><span class="No-Break"><em class="italic">29</em></span></p>
<p>The mean is<a id="_idIndexMarker021"/> sensitive to outliers and these can significantly affect its value. The mean is typically written <span class="No-Break">as </span><span class="No-Break"><em class="italic">X</em></span><span class="No-Break"><span class="_-----MathTools-_Math_Symbol_Extended">̅</span></span><span class="No-Break"><em class="italic">.</em></span></p>
<p>The <strong class="bold">median</strong> is the<a id="_idIndexMarker022"/> middle value of the sorted dataset. Using the dataset in the previous example, our median is 30. The main advantage of the median over the mean is that the median is less affected by outliers. If there is a high chance for outliers, it’s better to use the median instead of the mean. If we have an even number of data points in our dataset, the median is the average of two <span class="No-Break">middle points.</span></p>
<p>The <strong class="bold">mode</strong> represents<a id="_idIndexMarker023"/> the most common value in a dataset. It is mostly used when there is a need to understand clustering or, for example, encoded categorical data. Calculating the mode is quite simple. First, we need to order all values and count how many times each value appears in a set. The value that appears the most is the mode. Here is a <span class="No-Break">simple example:</span></p>
<p><em class="italic">X = [</em><span class="No-Break"><em class="italic">1,4,4,5,7,9]</em></span></p>
<p>The mode = 4 since it appears two times and all other values appear only one time. A dataset can also have multiple modes (multimodal dataset). In this case, two or more values occur with the <span class="No-Break">highest frequency.</span></p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor024"/>Variance</h2>
<p><strong class="bold">Variance</strong> (<em class="italic">σ2</em>) is a<a id="_idIndexMarker024"/> statistical measure that describes the degree of variability or spread in a set of data. It is the average of the squared differences from the mean of <span class="No-Break">the dataset.</span></p>
<p>In other words, variance measures how much each data point deviates from the mean of the dataset. A low variance indicates that the data points are closely clustered around the mean, while a high variance indicates that the data points are more widely spread out from <span class="No-Break">the mean.</span></p>
<p>The formula for variance is <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable_v-normal">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Σ</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Symbol_Extended">̅</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Symbol">²</span><span class="_-----MathTools-_Math_Symbol"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span></p>
<p>where <em class="italic">σ2</em> is the variance of the dataset, <em class="italic">n</em> is the number of data points in the set, and <em class="italic">Σ</em> is the sum of the squared differences between each data point (<em class="italic">xi</em>) and the mean (<em class="italic">x </em><em class="italic">̅</em>). The square root of the variance is the <span class="No-Break">standard deviation.</span></p>
<p>Variance is an important concept in statistics and machine learning, as it is used in the calculation of many other statistical measures, including standard deviation and covariance. It is also commonly used to evaluate the performance of models and to compare <span class="No-Break">different datasets.</span></p>
<p>Variance<a id="_idIndexMarker025"/> is used to see how individual values relate to each other within a dataset. The advantage is that variance treats all deviations from the mean as the same, regardless <span class="No-Break">of direction.</span></p>
<p class="callout-heading">Example</p>
<p class="callout">We have a stock that returns 15% in year 1, 25% in year 2, and -10% in year 3. The mean of the returns is 10%. The difference of each year’s return to mean is 5%, 15%, and -20%. Squaring these will give 0.25%, 2.25%, and 4%. If we add these together, we will get 6.5%. When divided by 2 (3 observations – 1), we get a variance <span class="No-Break">of 3.25%.</span></p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor025"/>Standard deviation</h2>
<p><strong class="bold">Standard deviation</strong> is a <a id="_idIndexMarker026"/>statistical measure that quantifies the amount of variation or dispersion in a set of data. It measures how much the individual data points deviate from the mean of <span class="No-Break">the dataset.</span></p>
<p>A low standard deviation indicates that the data points are close to the mean, while a high standard deviation indicates that the data points are more spread out from <span class="No-Break">the mean.</span></p>
<p>The formula for standard deviation is <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable_v-normal">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Σ</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">̅</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Symbol">²</span><span class="_-----MathTools-_Math_Symbol"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>where <em class="italic">σ</em> is the <a id="_idIndexMarker027"/>standard deviation, <em class="italic">Σ</em> is the sum of the squared differences between each data point (<em class="italic">xi</em>), and the mean (<em class="italic">x </em><em class="italic">̅</em>), and <em class="italic">n</em> is the number of <span class="No-Break">data points.</span></p>
<p class="callout-heading">Example</p>
<p class="callout">Continuing from our previous example, we got the variance of 3.25% for our stock. Taking the square root of the variance yields a standard deviation <span class="No-Break">of 18%.</span></p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor026"/>Standardization</h2>
<p><strong class="bold">Standardization</strong> or <strong class="bold">Z-score normalization</strong> is the <a id="_idIndexMarker028"/>concept of normalizing <a id="_idIndexMarker029"/>different variables to the same scale. This method allows comparison of scores between different types of variables. Z-score is a fractional representation of standard deviations from the mean value. We can calculate the z-score using the <span class="No-Break">following formula:</span></p>
<p><span class="_-----MathTools-_Math_Variable">z</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">̅</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal">σ</span><span class="_-----MathTools-_Math_Variable_v-normal"> </span></p>
<p>In the formula, <em class="italic">x</em> is the observed value, <em class="italic">x</em><em class="italic">̅</em> is the mean, and <em class="italic">σ</em> is the standard deviation of <span class="No-Break">the data.</span></p>
<p>Basically, the z-score describes how many standard deviations away a specific data point is from the mean. If the z-score of a data point is high, it indicates that the data point is most likely an outlier. Z-score normalization is one of the most popular feature-scaling techniques in data science and is an important preprocessing step. Many machine-learning algorithms attempt to find trends in data and compare features of data points. It is problematic if features are on a different scales, which is why we <span class="No-Break">need standardization.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Standardized datasets will have a mean of 0 and standard deviation of 1, but there are no specific boundaries for maximum and <span class="No-Break">minimum values.</span></p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor027"/>Correlation</h2>
<p><strong class="bold">Correlation</strong> is a <a id="_idIndexMarker030"/>statistical measure that describes the relationship between two variables. It measures the degree to which changes in one variable are associated with changes in <span class="No-Break">another variable.</span></p>
<p>There are two types of <a id="_idIndexMarker031"/>correlation: positive and negative. Positive correlation<a id="_idIndexMarker032"/> means that the two variables move in the same direction, while negative correlation<a id="_idIndexMarker033"/> means that the two variables move in<a id="_idIndexMarker034"/> opposite directions. A correlation of 0 indicates that there is no relationship between <span class="No-Break">the variables.</span></p>
<p>The most used measure of correlation is <a id="_idIndexMarker035"/>the <strong class="bold">Pearson correlation coefficient</strong>, which ranges from -1 to 1. A value of -1 indicates a perfect negative correlation, a value of 0 indicates no correlation, and a value of 1 indicates a perfect <span class="No-Break">positive correlation.</span></p>
<p>The Pearson correlation coefficient can be used when the relationship of variables is linear and both variables are quantitative and normally distributed. There should be no outliers in <span class="No-Break">the dataset.</span></p>
<p>Correlation can be calculated using the <strong class="source-inline">cor()</strong> function in R or the <strong class="source-inline">scipy.stats</strong> or <strong class="source-inline">NumPy</strong> libraries <span class="No-Break">in Python.</span></p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor028"/>Probability</h2>
<p><strong class="bold">Probability</strong> is a fundamental<a id="_idIndexMarker036"/> concept in machine learning that is used to quantify the uncertainty associated with events or outcomes. Basic concepts of probability include <span class="No-Break">the following:</span></p>
<ul>
<li><strong class="bold">Random variables</strong>: A variable <a id="_idIndexMarker037"/>whose value is determined by chance. Random <a id="_idIndexMarker038"/>variables can be discrete <span class="No-Break">or continuous.</span></li>
<li><strong class="bold">Probability distribution</strong>: A function that describes the likelihood of different values for a random variable. Common<a id="_idIndexMarker039"/> probability distributions<a id="_idIndexMarker040"/> include the normal distribution, the binomial distribution, and the <span class="No-Break">Poisson distribution.</span></li>
<li><strong class="bold">Bayes’ theorem</strong>: A <a id="_idIndexMarker041"/>fundamental theorem in probability theory that describes the relationship between conditional<a id="_idIndexMarker042"/> probabilities. Bayes’ theorem is used in many machine-learning algorithms, including naive Bayes classifiers and <span class="No-Break">Bayesian networks.</span></li>
<li><strong class="bold">Conditional probability</strong>: The <a id="_idIndexMarker043"/>probability of an event occurring given that another event has occurred. Conditional probability<a id="_idIndexMarker044"/> is used in many machine-learning algorithms, including decision trees and <span class="No-Break">Markov models.</span></li>
<li><strong class="bold">Expected value</strong>: The<a id="_idIndexMarker045"/> average value of a random variable, weighted by its probability distribution. Expected value<a id="_idIndexMarker046"/> is used in many machine-learning algorithms, including <span class="No-Break">reinforcement learning.</span></li>
<li><strong class="bold">Maximum likelihood estimation</strong>: A method of estimating the parameters of a probability distribution based on <a id="_idIndexMarker047"/>observed data. Maximum likelihood <a id="_idIndexMarker048"/>estimation is used in many machine-learning algorithms, including logistic regression and hidden <span class="No-Break">Markov models.</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">Probability is a wide concept on its own and many books have been written about this area. In this book, we are not going deeper into the details but it is important to understand the terms at a <span class="No-Break">high level.</span></p>
<p>We have now investigated the basic principles of the statistics that play a crucial role in Qlik tools. Next, we will focus on the concept of defining a proper sample size. This is an important step, since we are not always able to train our model with all the data and we want our training dataset to represent the full data as much <span class="No-Break">as possible.</span></p>
<h1 id="_idParaDest-29"><a id="_idTextAnchor029"/>Defining a proper sample size and population</h1>
<p>Defining a proper sample size for machine learning is crucial to get accurate results. It is also a common problem that we don’t know how much training data is needed. Having a correct sample size is important for <span class="No-Break">several reasons:</span></p>
<ul>
<li><strong class="bold">Generalization:</strong> Machine-learning models are trained on a sample of data with the expectation that they will generalize to new, unseen data. If the sample size is too small, the model<a id="_idIndexMarker049"/> may not capture the full complexity of the problem, resulting in poor <span class="No-Break">generalization performance.</span></li>
<li><strong class="bold">Overfitting: </strong>Overfitting<a id="_idIndexMarker050"/> occurs when a model fits the training data too closely, resulting in poor generalization performance. Overfitting is more likely to occur when the sample size is small because the model has fewer examples to learn from and may be more likely to fit the noise in <span class="No-Break">the data.</span></li>
<li><strong class="bold">Statistical significance:</strong> In statistical inference, sample size is an important factor in determining the <a id="_idIndexMarker051"/>statistical significance of the results. A larger sample size provides more reliable estimates of model parameters and reduces the likelihood of errors due to <span class="No-Break">random variation.</span></li>
<li><strong class="bold">Resource efficiency:</strong> Machine-learning models can be computationally expensive to train, especially <a id="_idIndexMarker052"/>with large datasets. Having a correct sample size can help optimize the use of computing resources by reducing the time and computational resources required to train <span class="No-Break">the model.</span></li>
<li><strong class="bold">Decision-making:</strong> Machine-learning models<a id="_idIndexMarker053"/> are often used to make decisions that have real-world consequences. Having a correct sample size ensures that the model is reliable and trustworthy, reducing the risk of making incorrect or biased decisions based on faulty or <span class="No-Break">inadequate data.</span></li>
</ul>
<h2 id="_idParaDest-30"><a id="_idTextAnchor030"/>Defining a sample size</h2>
<p>The sample size <a id="_idIndexMarker054"/>depends on several factors, including the complexity of the problem, the quality of the data, and the algorithm being used. <strong class="bold">“How much training data do I need?”</strong> is a common question at the beginning of a machine-learning project. Unfortunately, there is no correct answer to that question, since it depends on various factors. However, there are <span class="No-Break">some guidelines.</span></p>
<p>Generally, the following factors should be addressed when defining <span class="No-Break">a sample:</span></p>
<ul>
<li><strong class="bold">Have a representative sample</strong>: It is essential to have a representative sample of the population to train a machine-learning model. The sample size should be large enough to capture the variability in the data and ensure that the model is not biased toward a particular subset of <span class="No-Break">the population.</span></li>
<li><strong class="bold">Avoid overfitting</strong>: Overfitting occurs when a model is too complex and fits the training data too closely. To avoid overfitting, it is important to have a sufficient sample size to ensure that the model generalizes well to <span class="No-Break">new data.</span></li>
<li><strong class="bold">Consider the number of features</strong>: The number of features or variables in the dataset also affects the sample size. As the number of features increases, the sample size required to train the model <span class="No-Break">also increases.</span></li>
<li><strong class="bold">Use power analysis</strong>: Power analysis is a statistical technique used to determine the sample size required to detect a significant effect. It can be used to determine the sample size needed for a machine-learning model to achieve a certain level of accuracy or <span class="No-Break">predictive power.</span></li>
<li><strong class="bold">Cross-validation</strong>: Cross-validation is a technique used to evaluate the performance of a machine-learning model. It involves splitting the data into training and testing sets and using the testing set to evaluate the model’s performance. The sample size should be large enough to ensure that the testing set is representative of the population and provides a reliable estimate of the <span class="No-Break">model’s</span><span class="No-Break"><a id="_idIndexMarker055"/></span><span class="No-Break"> performance.</span></li>
</ul>
<p>There are several statistical heuristic methods available to estimate a sample size. Let’s take a closer look at some <span class="No-Break">of these.</span></p>
<h3>Power analysis</h3>
<p><strong class="bold">Power analysis</strong> is one of the <a id="_idIndexMarker056"/>key concepts in machine learning. Power analysis is mainly used to determine whether a statistical test has sufficient probability to find an effect and to estimate the sample size required for an experiment considering the significance level, effect size, and <span class="No-Break">statistical power.</span></p>
<p>The definition of a power in this concept is the probability that a statistical test will reject a false null hypothesis (<em class="italic">H0</em>) or the probability of detecting an effect (depending on whether the effect is there). A bigger sample size will result in a larger power. The main output of power analysis is the estimation of an appropriate <span class="No-Break">sample size.</span></p>
<p>To understand the basics of power analysis, we need to get familiar with the <span class="No-Break">following concepts:</span></p>
<ul>
<li>A type I error (<em class="italic">α</em>) is rejecting a <em class="italic">H0</em><span class="subscript"> </span>or a null hypothesis in the data when it’s true (<span class="No-Break">false positive).</span></li>
<li>A type II error (<em class="italic">β</em>) is the failure to reject a false <em class="italic">H0</em><span class="subscript"> </span>or, in other words, a probability of missing an effect that is in the data (<span class="No-Break">false negative).</span></li>
<li>The power is the probability of detecting an effect that is in <span class="No-Break">the data.</span></li>
<li>There is a direct relationship between the power and type <span class="No-Break">II error:</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">w</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol">–</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">β</span></p><p class="list-inset">Generally, <em class="italic">β</em> should never be more than 20%, which gives us the minimum approved power level <span class="No-Break">of 80%.</span></p></li>
<li>The significance level (<em class="italic">α</em>) is the maximum risk of rejecting a true null hypothesis (<em class="italic">H0</em>) that you are willing to take. This is typically set to 5% (p &lt; <span class="No-Break">0.05).</span></li>
<li>The effect size is the measure of the strength of a phenomenon in the dataset (independent of sample size). The effect size is typically the hardest to determine. An example of an effect size would be the height difference between men and women. The greater the effect size, the greater the height difference will be. The effect size is typically marked with the letter <em class="italic">d</em> <span class="No-Break">in formulas.</span></li>
</ul>
<p>Now that we have defined the <a id="_idIndexMarker057"/>key concepts, let’s look how to use power analysis in R and Python to calculate the sample size for an experiment with a simple example. In R we will utilize a package called <strong class="source-inline">pwr</strong> and with Python we will utilize the <strong class="source-inline">NumPy</strong> and <span class="No-Break"><strong class="source-inline">statsmodels.stats.power</strong></span><span class="No-Break"> libraries.</span></p>
<p>Let’s assume that we would like to create a model of customer behavior. We are interested to know whether there is a difference in the mean price of what our preferred customers and other customers pay at our online shop. How many transactions in each group should we <a id="_idIndexMarker058"/>investigate to get the power level <span class="No-Break">of 80%?</span></p>
<p><span class="No-Break"><strong class="bold">R:</strong></span></p>
<pre class="source-code">
library(pwr)
ch &lt;- cohen.ES(test = "t", size = "medium")
print(ch)
test &lt;- pwr.t.test(d = 0.5, power = 0.80, sig.level = 0.05)
print(test)</pre> <p>The model will give us the <span class="No-Break">following result:</span></p>
<pre class="source-code">
     Two-sample t test power calculation
              n = 63.76561
              d = 0.5
      sig.level = 0.05
          power = 0.8
    alternative = two.sided
NOTE: n is number in *each* group</pre> <p>So, we will <a id="_idIndexMarker059"/>need a sample of 64 transactions in <span class="No-Break">each group.</span></p>
<p><span class="No-Break"><strong class="bold">Python:</strong></span></p>
<pre class="source-code">
import numpy as np
from statsmodels.stats.power import TTestIndPower
analysis = TTestIndPower()
sample_size = analysis.solve_power(effect_size = 0.5, alpha = 0.05, power = 0.8)
print(str(sample_size))</pre> <p>Our<a id="_idIndexMarker060"/> Python code will produce the same result as our earlier R code, giving us 64 transactions in <span class="No-Break">each group.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Power analysis is<a id="_idIndexMarker061"/> a wide and complex topic, but it’s important to understand the basics, since it is widely utilized in many machine-learning tools. In this chapter, we have only scratched the surface of <span class="No-Break">this topic.</span></p>
<h3>Sampling</h3>
<p><strong class="bold">Sampling</strong> is a method<a id="_idIndexMarker062"/> that makes it possible to get information about the population (dataset) based on the statistics from a subset of population (sample), without having to investigate every individual value. Sampling is particularly useful if a dataset is large and can’t be analyzed in full. In this case, identifying and analyzing a representative sample is important. In some cases, a small sample can be enough to reveal the most important information, but generally, using a larger sample can increase the likelihood of representing the data as <span class="No-Break">a whole.</span></p>
<p>When performing sampling, there are some aspects <span class="No-Break">to consider:</span></p>
<ul>
<li><strong class="bold">Sample goal</strong>: A<a id="_idIndexMarker063"/> property that you wish to estimate <span class="No-Break">or predict</span></li>
<li><strong class="bold">Population</strong>: A<a id="_idIndexMarker064"/> domain from which observations <span class="No-Break">are made</span></li>
<li><strong class="bold">Selection criteria</strong>: A<a id="_idIndexMarker065"/> method to determine whether an individual value will be accepted as a part of <span class="No-Break">the sample</span></li>
<li><strong class="bold">Sample size</strong>: The number<a id="_idIndexMarker066"/> of data points that will form the final <span class="No-Break">sample data</span></li>
</ul>
<p>Sampling methods can be divided into two <span class="No-Break">main categories:</span></p>
<p><strong class="bold">Probability sampling</strong> is a<a id="_idIndexMarker067"/> technique where every element of the dataset has an equal chance of being selected. These methods typically give the best chance of creating<a id="_idIndexMarker068"/> a sample that truly represents the population. Examples of probability sampling algorithms are <em class="italic">simple random sampling</em>, <em class="italic">cluster sampling</em>, <em class="italic">systematic sampling</em>, and <em class="italic">stratified </em><span class="No-Break"><em class="italic">random sampling</em></span><span class="No-Break">.</span></p>
<p><strong class="bold">Non-probability sampling </strong>is a <a id="_idIndexMarker069"/>method where all elements are not equally <a id="_idIndexMarker070"/>qualified for being selected. With these methods, there is a significant risk that the sample is non-representative. Examples of non-probability sampling algorithms are <em class="italic">convenience sampling</em>, <em class="italic">selective sampling</em>, <em class="italic">snowball sampling</em>, and <span class="No-Break"><em class="italic">quota sampling</em></span><span class="No-Break">.</span></p>
<p>When using sampling as a methodology for training set creation, it is recommended to utilize a specialized sampling library in either R or Python. This will automate the process and produce a sample based on selected algorithms and specifications. In R, we can utilize the standard <strong class="source-inline">sample</strong> library and in Python there is a package called <strong class="source-inline">random.sample</strong>. Here is a simple <a id="_idIndexMarker071"/>example of random sampling with <span class="No-Break">both languages:</span></p>
<p><span class="No-Break"><strong class="bold">R:</strong></span></p>
<pre class="source-code">
dataset &lt;- data.frame(id = 1:20, fact = letters[1:20])
set.seed(123)
sample &lt;- dataset[sample(1:nrow(dataset), size=5), ]</pre> <p>The content of the sample frame will look <span class="No-Break">like this:</span></p>
<pre class="source-code">
   id fact
15 15    o
19 19    s
14 14    n
3   3    c
10 10    j</pre> <p><span class="No-Break">Python:</span></p>
<pre class="source-code">
import random
random.seed(123)
dataset = [[1,'v'],[5,'b'],[7,'f'],[4,'h'],[0,'l']]
sample = random.sample(dataset, 3)
print(sample)</pre> <p>The result of the<a id="_idIndexMarker072"/> sample vector will look like <span class="No-Break">the following:</span></p>
<pre class="source-code">
[[1, 'v'], [7, 'f'], [0, 'l']]</pre> <p class="callout-heading">Note</p>
<p class="callout">There is a lot of material covering different sampling techniques and how to use those with R and Python on the internet. Take some time to practice these techniques with <span class="No-Break">simple datasets.</span></p>
<h3>Sampling errors</h3>
<p>In all sampling methods, errors are bound <a id="_idIndexMarker073"/>to occur. There are two types of <span class="No-Break">sampling errors:</span></p>
<ul>
<li><strong class="bold">Selection bias</strong> is<a id="_idIndexMarker074"/> introduced by the selection of values that are not random to be part of the sample. In this case, the sample is not representative of the dataset that we are looking <span class="No-Break">to analyze.</span></li>
<li><strong class="bold">Sampling error</strong> is a <a id="_idIndexMarker075"/>statistical error that occurs when we don’t select the sample that represents the entire population of data. In this case, the results of the prediction or model will not represent the actual results that are generalized to cover the <span class="No-Break">entire dataset.</span></li>
</ul>
<p>Training datasets will always contain a sampling error, since it cannot represent the entire dataset. Sample errors in the context of binary classification can be calculated using the following <span class="No-Break">simplified formula:</span></p>
<p><span class="_-----MathTools-_Math_Variable_v-bold-italic">S</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">a</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">m</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">p</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">l</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">r</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">r</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">o</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-bold">F</span><span class="_-----MathTools-_Math_Variable_v-bold">a</span><span class="_-----MathTools-_Math_Variable_v-bold">l</span><span class="_-----MathTools-_Math_Variable_v-bold">s</span><span class="_-----MathTools-_Math_Variable_v-bold">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold">p</span><span class="_-----MathTools-_Math_Variable_v-bold">o</span><span class="_-----MathTools-_Math_Variable_v-bold">s</span><span class="_-----MathTools-_Math_Variable_v-bold">i</span><span class="_-----MathTools-_Math_Variable_v-bold">t</span><span class="_-----MathTools-_Math_Variable_v-bold">i</span><span class="_-----MathTools-_Math_Variable_v-bold">v</span><span class="_-----MathTools-_Math_Variable_v-bold">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-bold">F</span><span class="_-----MathTools-_Math_Variable_v-bold">a</span><span class="_-----MathTools-_Math_Variable_v-bold">l</span><span class="_-----MathTools-_Math_Variable_v-bold">s</span><span class="_-----MathTools-_Math_Variable_v-bold">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold">n</span><span class="_-----MathTools-_Math_Variable_v-bold">e</span><span class="_-----MathTools-_Math_Variable_v-bold">g</span><span class="_-----MathTools-_Math_Variable_v-bold">a</span><span class="_-----MathTools-_Math_Variable_v-bold">t</span><span class="_-----MathTools-_Math_Variable_v-bold">i</span><span class="_-----MathTools-_Math_Variable_v-bold">v</span><span class="_-----MathTools-_Math_Variable_v-bold">e</span><span class="_-----MathTools-_Math_Variable_v-bold">   </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">___________________________________________</span><span class="_-----MathTools-_Math_Base">     </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">T</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">r</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">u</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">p</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">o</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">s</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">t</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">v</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">F</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">a</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">l</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">s</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">p</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">o</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">s</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">t</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">v</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">T</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">r</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">u</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">n</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">g</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">a</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">t</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">v</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">F</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">a</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">l</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">s</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-bold-italic">n</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">g</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">a</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">t</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">i</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">v</span><span class="_-----MathTools-_Math_Variable_v-bold-italic">e</span><span class="_-----MathTools-_Math_Variable_v-bold-italic"> </span></p>
<p>If we have, for example, a dataset containing 45 values and out of these 12 are false values, we will get a sample error of 12/45 = <span class="No-Break">26.67%.</span></p>
<p>The above formula can be only utilized in context of binary classification. When estimating the population mean (<em class="italic">μ</em>) from a sample mean (<span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span>), the standard error is calculated <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Variable">E</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<ul>
<li><strong class="bold">SE (Standard Error)</strong>: The<a id="_idIndexMarker076"/> standard error is a measure of the variability or uncertainty in a sample statistic. It quantifies how much the sample statistic is expected to vary from the true population parameter. In other words, it gives you an idea of how reliable or precise your sample <span class="No-Break">estimate is.</span></li>
<li><strong class="bold">σ</strong><strong class="bold"> (population standard deviation)</strong>: This is the <a id="_idIndexMarker077"/>standard deviation of the entire population you’re trying to make inferences about. It represents the amount of variability or spread in the population data. In practice, the population standard deviation is often unknown, so you may estimate it using the sample standard deviation (<em class="italic">s</em>) when working with <span class="No-Break">sample data.</span></li>
<li><strong class="bold">n (sample size)</strong>: The number<a id="_idIndexMarker078"/> of observations or data points in <span class="No-Break">your sample.</span></li>
</ul>
<h3>Example</h3>
<p>We are conducting a survey to e<a id="_idIndexMarker079"/>stimate the average age (mean) of residents in a small town. We collect a random sample of 50 residents and find the <span class="No-Break">following statistics:</span></p>
<ul>
<li>Sample mean (<span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span>): <span class="No-Break">35 years</span></li>
<li>Sample standard deviation (<em class="italic">s</em>): 10 years (an estimate of the population <span class="No-Break">standard deviation)</span></li>
<li>Sample size (<em class="italic">n</em>): <span class="No-Break">50 residents</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Variable">E</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">50</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">1.42</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">y</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">e</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">a</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">r</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">s</span></span></p></li>
</ul>
<p>So, the standard error of the sample mean is approximately 1.42 years. This means that if you were to take multiple random samples of the same size from the population and calculate the mean for each sample, you would expect those sample means to vary around 35 years, with an average amount of variation of <span class="No-Break">1.42 years.</span></p>
<p>Standard error is often used to construct confidence intervals. For instance, you might use this standard error to calculate a 95% confidence interval for the average age of residents in the town, which would allow you to estimate the range within which the true population mean age is likely to fall with <span class="No-Break">95% confidence.</span></p>
<p>As we can see, sample error, often referred to as “sampling error,” is not represented by a single formula. Instead, it is a concept that reflects the variability or uncertainty in the estimates or measurements made on a sample of data when trying to infer information about a larger population. The specific formula for sampling error depends on the statistic or parameter you are estimating and the characteristics of your data. In practice, you would use statistical <a id="_idIndexMarker080"/>software or tools to calculate the standard error for the specific parameter or estimate you are <span class="No-Break">interested in.</span></p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor031"/>Training and test data in machine learning</h2>
<p>The preceding methods for defining a sample size will work well if we need to define the amount of needed data without a large collection of historic data covering the phenomenon that we are investigating. In many cases, we have a large dataset and we would like to produce training and test datasets from that historical data. Training datasets are used to train our machine-learning model and test datasets are used to validate the accuracy of our model. Training and<a id="_idIndexMarker081"/> test datasets are the key concepts in <span class="No-Break">machine learning.</span></p>
<p>We can utilize power analysis and sampling to create training and testing datasets, but sometimes there is no need to make a complex analysis if our sample is already created. The training dataset is the biggest subset of the original dataset and will be used to fit the machine-learning model. The test dataset is another subset of original data and is always independent of the <span class="No-Break">training dataset.</span></p>
<p>Test data should be well organized and contain data for each type of scenario that the model would be facing in the production environment. Usually it is 20–25% of the total original dataset. An exact split can be adjusted based on the requirements of a problem or the <span class="No-Break">dataset characteristics.</span></p>
<p>Generating a training<a id="_idIndexMarker082"/> and testing dataset from an original dataset can also be done using R or Python. Qlik functions can be used to perform this action in <span class="No-Break">load script.</span></p>
<p>Now that we have investigated some of the concepts to define a good sample, we can focus on the concepts used to analyze model performance and reliability. These concepts are important, since using these techniques allow us to develop our model further and make sure that it gives <span class="No-Break">proper results.</span></p>
<h1 id="_idParaDest-32"><a id="_idTextAnchor032"/>Concepts to analyze model performance and reliability</h1>
<p>Analyzing the performance and reliability of our machine-learning model is an important development step and should be done before implementing the model to production. There are several metrics that you can use to analyze the performance and reliability of a machine learning model, depending on the specific task and problem you are trying to solve. In this section, we will cover some of these techniques, focusing on ones that Qlik tools <span class="No-Break">are using.</span></p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor033"/>Regression model scoring</h2>
<p>The following concepts can be<a id="_idIndexMarker083"/> used to score and verify <strong class="bold">regression models</strong>. Regression models <a id="_idIndexMarker084"/>predict outcomes as a number, indicating the model’s best estimate of the target variable. We will learn more about regression models in <a href="B19863_02.xhtml#_idTextAnchor037"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><span class="No-Break">.</span></p>
<h3>R<span class="superscript">2</span> (R-squared)</h3>
<p><strong class="bold">R-squared</strong> is a statistical <a id="_idIndexMarker085"/>measure that represents the proportion of the variance in a dependent variable that is explained by an independent variable (or variables) in a regression model. In other words, it measures the goodness of fit of a regression model to <span class="No-Break">the data.</span></p>
<p>R-squared ranges from 0 to 1, where 0 indicates that the model does not explain any of the variability in the dependent variable, and 1 indicates that the model perfectly explains all the variability in the <span class="No-Break">dependent variable.</span></p>
<p>R-squared is an important measure of the quality of a regression model. A high R-squared value indicates that the model fits the data well and that the independent variable(s) have a strong relationship with the dependent variable. A low R-squared value indicates that the model does not fit the data well and that the independent variable(s) do not have a strong relationship with the dependent variable. However, it is important to note that a high R-squared value does not necessarily mean that the model is the best possible model, so other factors such as overfitting should also be taken into consideration when evaluating the performance of a model. R-squared is often used together with other metrics and it should be interpreted in the context of the problem. The formula for R-squared is <span class="No-Break">the following:</span></p>
<p><span class="_-----MathTools-_Math_Variable">R</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">V</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">b</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">h</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">   </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">______________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>There are some limitations for <a id="_idIndexMarker086"/>R-squared. It cannot be used to check whether the prediction is biased or not and it doesn’t tell us whether the regression model has an adequate fit or not. Bias refers to systematic errors in predictions. To check for bias, you should analyze residuals (differences between predicted and observed values) or use bias-specific metrics such<a id="_idIndexMarker087"/> as <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>) and <strong class="bold">Mean Bias Deviation</strong> (<strong class="bold">MBD</strong>). R-squared <a id="_idIndexMarker088"/>primarily addresses model variance, <span class="No-Break">not bias.</span></p>
<p>Sometimes it is better to <a id="_idIndexMarker089"/>utilize <strong class="bold">adjusted R-squared</strong>. Adjusted R-squared is a modified version of the standard R-squared used in regression analysis. We can use adjusted R-squared when dealing with multiple predictors to assess model fit, control overfitting, compare models with different predictors, and aid in feature selection. It accounts for the number of predictors, penalizing unnecessary complexity. However, it should be used alongside other evaluation metrics and domain knowledge for a comprehensive <span class="No-Break">model assessment.</span></p>
<h3>Root mean squared error (RMSE), mean absolute error (MAE), and mean squared error (MSE)</h3>
<p><strong class="bold">Root mean squared error</strong> is the <a id="_idIndexMarker090"/>average difference that can be expected <a id="_idIndexMarker091"/>between predicted and actual value. It is the standard deviation of the <strong class="bold">residuals</strong> (prediction errors) and tells us how concentrated the data is around the “line of best fit.” It is a standard way to measure the error of a model when predicting quantitative data. RMSE is always measured in the same unit as the <span class="No-Break">target value.</span></p>
<p>As an example of RMSE, if we have a model that predicts house value in a certain area and we get an RMSE of 20,000, it means that, on average, the predicted value differs 20,000 USD from the <span class="No-Break">actual value.</span></p>
<p><strong class="bold">Mean absolute error</strong> is defined as<a id="_idIndexMarker092"/> an average of all absolute prediction errors in all data points. In MAE, different errors are not weighted but the scores increase linearly with the increase in error. MAE is always a positive value since we are using an absolute value of error. MAE is useful when the errors are symmetrically distributed and there are no <span class="No-Break">significant outliers.</span></p>
<p><strong class="bold">Mean squared error</strong> is a<a id="_idIndexMarker093"/> squared average difference between the predicted and actual value. Squaring eliminates the negative values and ensures that MSE is always positive or 0. The smaller the MSE, the closer our model to the “line of best fit.” RMSE can be calculated using MSE. RMSE is a square root <span class="No-Break">of MSE.</span></p>
<h4>When to use the above metrics in practice</h4>
<p>MAE<a id="_idIndexMarker094"/> is robust to outliers and provides a straightforward interpretation of the average <span class="No-Break">error magnitude.</span></p>
<p>MSE<a id="_idIndexMarker095"/> penalizes large errors more heavily and is suitable when you want to minimize the impact of outliers on the <span class="No-Break">error metric.</span></p>
<p>RMSE is<a id="_idIndexMarker096"/> similar to MSE but provides a more interpretable error metric in the same units as the <span class="No-Break">target variable.</span></p>
<p>The choice between these metrics should align with your specific problem and objectives. Its also good practice to consider the nature of your data and the impact of outliers when selecting an error metric. Additionally, you can use these metrics in conjunction with other evaluation techniques to get a comprehensive view of your <span class="No-Break">model’s performance.</span></p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor034"/>Multiclass classification scoring and binary classification scoring</h2>
<p>The following concepts <a id="_idIndexMarker097"/>can be used to score and verify multiclass and binary models. Binary classification models distribute outcomes into two categories, typically<a id="_idIndexMarker098"/> denoted as Yes or No. Multiclass classification models are similar, but there are more than two categories as an outcome. We will learn more about both models in <a href="B19863_02.xhtml#_idTextAnchor037"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><span class="No-Break">.</span></p>
<h3>Recall</h3>
<p>Recall measures the<a id="_idIndexMarker099"/> percentage of correctly classified positive instances over the total number of actual positive instances. In other words, recall represents the ability of a model to correctly capture all <span class="No-Break">positive instances.</span></p>
<p>Recall is calculated <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">R</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_____________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">g</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>A high<a id="_idIndexMarker100"/> recall indicates that the model is able to accurately capture all positive instances and has a low rate of false negatives. On the other hand, a low recall indicates that the model is missing many positive instances, resulting in a high rate of <span class="No-Break">false negatives.</span></p>
<h3>Precision</h3>
<p>Precision measures <a id="_idIndexMarker101"/>the percentage of correctly classified positive instances over the total number of predicted positive instances. In other words, precision represents the ability of the model to correctly identify <span class="No-Break">positive instances.</span></p>
<p>Precision is calculated <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>A high precision indicates that the model is able to accurately identify positive instances and has a low rate of false positives. On the other hand, a low precision indicates that the model is incorrectly classifying many instances as positive, resulting in a high rate of <span class="No-Break">false positives.</span></p>
<p>Precision is particularly useful in situations where false positives are costly or undesirable, such as in medical diagnosis or fraud detection. Precision should be used in conjunction with other metrics, such<a id="_idIndexMarker102"/> as <strong class="bold">recall</strong> and <strong class="bold">F1 score</strong>, to get a more complete picture of the <a id="_idIndexMarker103"/><span class="No-Break">model’s performance.</span></p>
<h3>F1 score</h3>
<p>The F1 score<a id="_idIndexMarker104"/> is defined as the harmonic mean of precision and recall, and it ranges from 0 to 1, with higher values indicating better performance. The formula for F1 score is <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal">*</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Space"> </span></p>
<p>The F1 score gives equal importance to both precision and recall, making it a useful metric for evaluating models when the distribution of positive and negative instances is uneven. A high F1 score indicates that the model has a good balance between precision and recall and can accurately classify both positive and <span class="No-Break">negative instances.</span></p>
<p>In general, the more imbalanced the dataset is, the lower the F1 score is likely to be. It’s crucial to recognize that, when dealing with highly imbalanced datasets where one class greatly outnumbers the other, the F1 score may be influenced. A more imbalanced dataset can result in a reduced F1 score. Being aware of this connection can assist in interpreting <a id="_idIndexMarker105"/>F1 scores within the context of particular data distributions and problem domains. If the F1 value is high, all other metrics will be high as well, and if it is low, there is a need for <span class="No-Break">further analysis.</span></p>
<h3>Accuracy</h3>
<p><strong class="bold">Accuracy</strong> measures the<a id="_idIndexMarker106"/> percentage of correctly classified instances over the total number of instances. In other words, accuracy represents the ability of the model to correctly classify both positive and <span class="No-Break">negative instances.</span></p>
<p>Accuracy is calculated in the <span class="No-Break">following way:</span></p>
<p><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">g</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">   </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">___________________________________________</span><span class="_-----MathTools-_Math_Base">    </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">g</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">g</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Space"> </span></p>
<p>A high accuracy indicates that the model is able to accurately classify both positive and negative instances and has a low rate of false positives and false negatives. However, accuracy can be misleading in situations where the distribution of positive and negative instances is uneven. In such cases, other metrics such as precision, recall, and F1 score may provide a more accurate representation of the <span class="No-Break">model’s performance.</span></p>
<p>Accuracy can mislead in imbalanced datasets where one class vastly outnumbers the others. This is because accuracy doesn’t consider the class distribution and can be high even if the model predicts the majority class exclusively. To address this, use metrics such as precision, recall, F1-score, <strong class="bold">AUC-ROC</strong>, and <strong class="bold">AUC-PR</strong>, which provide a more accurate evaluation of model<a id="_idIndexMarker107"/> performance<a id="_idIndexMarker108"/> by focusing on the correct identification of the minority class, which is often the class of interest in <span class="No-Break">such datasets.</span></p>
<h3>Example scenario</h3>
<p>Suppose we <a id="_idIndexMarker109"/>are developing a machine-learning model to detect a rare disease that occurs in only 1% of the population. We collect a dataset of 10,000 <span class="No-Break">patient records:</span></p>
<ul>
<li>100 patients have the rare disease (<span class="No-Break">positive class)</span></li>
<li>9,900 patients do not have the disease (<span class="No-Break">negative class)</span></li>
</ul>
<p>Now, let’s say our model predicts all 10,000 patients as not having the disease. Here’s <span class="No-Break">what happens:</span></p>
<ul>
<li>True Positives (correctly predicted patients with the <span class="No-Break">disease): 0</span></li>
<li>False Positives (incorrectly predicted patients with the <span class="No-Break">disease): 0</span></li>
<li>True Negatives (correctly predicted patients without the <span class="No-Break">disease): 9,900</span></li>
<li>False Negatives (incorrectly predicted patients without the <span class="No-Break">disease): 100</span></li>
</ul>
<p>Using accuracy as our evaluation metric produces the <span class="No-Break">following result:</span></p>
<p><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">g</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Variable">v</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Variable">l</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">9900</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10000</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">99</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Symbol">%</span></span></p>
<p>Our model appears to have an impressive 99% accuracy, which might lead to the misleading conclusion that it’s performing exceptionally well. However, it has completely failed to detect any cases of the rare disease (True Positives = 0), which is the most critical aspect of <span class="No-Break">the problem.</span></p>
<p>In this example, accuracy doesn’t provide an accurate picture of the model’s performance because it doesn’t account for the severe class imbalance and the importance of correctly identifying the minority class (patients with <span class="No-Break">the disease).</span></p>
<h3>Confusion matrix</h3>
<p>A confusion matrix is a <a id="_idIndexMarker110"/>table used to evaluate the performance of a classification model. It displays the number of true positive, false positive, true negative, and false negative predictions made by the model for a set of <span class="No-Break">test data.</span></p>
<p>The four elements in the confusion matrix represent <span class="No-Break">the following:</span></p>
<ul>
<li>True positives (TP) are actual true values that were correctly predicted <span class="No-Break">as true</span></li>
<li>False positives (FP) are actual false values that were incorrectly predicted <span class="No-Break">as true</span></li>
<li>False negatives (FN) are actual true values that were incorrectly predicted <span class="No-Break">as false</span></li>
<li>True negatives (TN) are actual false values that were correctly predicted <span class="No-Break">as false</span></li>
</ul>
<p>Qlik AutoML presents a confusion matrix as part of the experiment view. Below the numbers in each quadrant, you can also see percentage values for the metrics recall (TP), fallout (FP), miss rate (FN), and <span class="No-Break">specificity (TN).</span></p>
<p>An example of the<a id="_idIndexMarker111"/> confusion matrix of Qlik AutoML can be seen in the <span class="No-Break">following figure:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<img alt="Figure 1.4: Confusion matrix as seen in Qlik AutoML" height="742" src="image/B19863_01_04.jpg" width="815"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4: Confusion matrix as seen in Qlik AutoML</p>
<p>By analyzing the <a id="_idIndexMarker112"/>confusion matrix, we can calculate various performance metrics such as accuracy, precision, recall, and F1 score, which can help us understand how well the model is performing on the test data. The confusion matrix can also help us identify any patterns or biases in the model’s predictions and adjust the <span class="No-Break">model accordingly.</span></p>
<h3>Matthews Correlation Coefficient (MCC)</h3>
<p><strong class="bold">The Matthews Correlation Coefficient</strong> metric<a id="_idIndexMarker113"/> can be used to evaluate the performance of a binary classification model, particularly when dealing with <span class="No-Break">imbalanced data.</span></p>
<p>MCC takes into account all four elements of the confusion matrix (true positives, false positives, true negatives, and false negatives) to provide a measure of the quality of a binary classifier’s predictions. It ranges between -1 and +1, with a value of +1 indicating perfect classification performance, 0 indicating a random classification, and -1 indicating complete disagreement between predicted and <span class="No-Break">actual values.</span></p>
<p>The formula for MCC is <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">M</span><span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">   </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________________________</span><span class="_-----MathTools-_Math_Base">    </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________________________________</span><span class="_-----MathTools-_Math_Base">    </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">T</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Space"> </span></p>
<p>MCC is particularly useful when dealing with imbalanced datasets where the number of positive and negative instances is not equal. It provides a better measure of classification performance than accuracy in such cases, since accuracy can be biased toward the <span class="No-Break">majority class.</span></p>
<h3>AUC and ROC curve</h3>
<p><strong class="bold">The ROC</strong> (<strong class="bold">Receiver Operating Characteristic</strong>) <strong class="bold">curve</strong> is a<a id="_idIndexMarker114"/> graphical representation of the performance of a binary classification model that allows us to evaluate and compare different models based on their ability to discriminate between positive and negative classes. AUC describes the area under <span class="No-Break">the </span><span class="No-Break"><a id="_idIndexMarker115"/></span><span class="No-Break">curve.</span></p>
<p>An ROC curve plots the <strong class="bold">True Positive Rate </strong>(<strong class="bold">TPR</strong>)<a id="_idIndexMarker116"/> against the <strong class="bold">False Positive Rate </strong>(<strong class="bold">FPR</strong>) at<a id="_idIndexMarker117"/> various classification thresholds. The <a id="_idIndexMarker118"/>TPR is the ratio of true positive predictions to the total number of actual positive instances, while the <a id="_idIndexMarker119"/>FPR is the ratio of false positive predictions to the total number of actual <span class="No-Break">negative instances.</span></p>
<p>By varying the classification threshold, we can obtain different TPR and FPR pairs and plot them on the ROC curve. The area under the ROC curve (AUC-ROC) is used as a performance metric for binary classification models, with higher AUC-ROC indicating <span class="No-Break">better performance.</span></p>
<p>A perfect classifier would have an AUC-ROC<a id="_idIndexMarker120"/> of 1.0, indicating that it has a high TPR and low FPR across all possible classification thresholds. A random classifier would have an AUC-ROC of 0.5, indicating that its TPR and FPR are equal and its performance is no better <span class="No-Break">than chance.</span></p>
<p>The ROC curve and AUC-ROC are useful for evaluating and comparing binary classification models, especially when the positive and negative classes are imbalanced or when the cost of false positive and false negative errors <span class="No-Break">is different.</span></p>
<p>The following figure represents an ROC curve as seen in Qlik AutoML. The figure shows a pretty good ROC curve (it is good since the curve should be as close to 1 as possible). The dotted line is 50:50 <span class="No-Break">random chance.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<img alt="Figure 1.5: ROC curve for a good model in Qlik AutoML" height="468" src="image/B19863_01_05.jpg" width="468"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5: ROC curve for a good model in Qlik AutoML</p>
<h3>Threshold</h3>
<p>In binary classification, a <strong class="bold">threshold</strong> is a<a id="_idIndexMarker121"/> value that is used to decide whether an instance should be classified as positive or negative by <span class="No-Break">a model.</span></p>
<p>When a model makes a prediction, it generates a probability score between 0 and 1 that represents the likelihood of an instance belonging to the positive class. If the score is above a certain threshold value, the instance is classified as positive, and if it is below the threshold, it is classified <span class="No-Break">as negative.</span></p>
<p>The choice of threshold can significantly impact the performance of a classification model. If the threshold is set too high, the model may miss many positive instances, leading to a low recall and high precision. Conversely, if the threshold is set too low, the model may classify many negative instances as positive, leading to a high recall and <span class="No-Break">low precision.</span></p>
<p>Therefore, selecting an appropriate threshold for a classification model is important in achieving the desired balance between precision and recall. The optimal threshold depends on the specific application and the cost of false positive and false <span class="No-Break">negative errors.</span></p>
<p>Qlik AutoML computes the precision and recall for hundreds of possible threshold values from 0 to 1. A <a id="_idIndexMarker122"/>threshold achieving the highest F1 score is chosen. By selecting a threshold, the produced predictions are more robust for <span class="No-Break">imbalanced datasets.</span></p>
<h2 id="_idParaDest-35"><a id="_idTextAnchor035"/>Feature importance</h2>
<p><strong class="bold">Feature importance</strong> is a<a id="_idIndexMarker123"/> measure of the contribution of each input variable (feature) in a model to the output variable (prediction). It is a way to understand which features have the most impact on the model’s prediction, and which features can be ignored or removed without significantly affecting the <span class="No-Break">model’s performance.</span></p>
<p>Feature importance can be computed using various methods, depending on the type of model used. Some common methods for calculating feature importance include <span class="No-Break">the following:</span></p>
<ul>
<li><strong class="bold">Permutation importance:</strong> This method<a id="_idIndexMarker124"/> involves shuffling the values of each feature in the test data, one at a time, and measuring the impact on the model’s performance. The features that cause the largest drop in performance when shuffled are considered <span class="No-Break">more important.</span></li>
<li><strong class="bold">Feature importance from tree-based models:</strong> In decision tree-based models such as Random Forest or<a id="_idIndexMarker125"/> Gradient Boosting, feature importance can be calculated based on how much each feature decreases the impurity of the tree. The features that reduce impurity the most are considered <span class="No-Break">more important.</span></li>
<li><strong class="bold">Coefficient magnitude:</strong> In linear<a id="_idIndexMarker126"/> models such as Linear Regression or Logistic Regression, feature importance can be calculated based on the magnitude of the coefficients assigned to each feature. The features with larger coefficients are considered <span class="No-Break">more important.</span></li>
</ul>
<p>Feature importance<a id="_idIndexMarker127"/> can help in understanding the relationship between the input variables and the model’s prediction and can guide feature selection and engineering efforts to improve the model’s performance. It can also provide insights into the underlying problem and the data being used and can help in identifying potential biases or data <span class="No-Break">quality issues.</span></p>
<p>In Qlik AutoML, the permutation importance<a id="_idIndexMarker128"/> of each feature is represented as a graph. This can be used to estimate feature importance. Another method that is visible in AutoML is SHAP importance values. The next section will cover the principles of SHAP <span class="No-Break">importance values.</span></p>
<h3>SHAP values</h3>
<p><strong class="bold">SHAP</strong> (<strong class="bold">SHapley Additive exPlanations</strong>) <strong class="bold">values</strong> are <a id="_idIndexMarker129"/>a technique for interpreting the output of machine-learning models by assigning an importance score to each <span class="No-Break">input feature.</span></p>
<p>SHAP values are based on game theory and the concept of Shapley values, which provide a way to fairly distribute the value of a cooperative game among its players. In the context of machine learning, the game is the prediction task, and the players are the input features. The SHAP values represent the contribution of each feature to the difference between a specific prediction and the expected value of the <span class="No-Break">output variable.</span></p>
<p>The SHAP values approach involves computing the contribution of each feature by evaluating the model’s output for all possible combinations of features, with and without the feature of interest. The contribution of the feature is the difference in the model’s output between the two cases averaged over all <span class="No-Break">possible combinations.</span></p>
<p>SHAP values provide a more nuanced understanding of the relationship between the input features and the model’s output than other feature importance measures, as they account for interactions between features and the potential correlation <span class="No-Break">between them.</span></p>
<p>SHAP values <a id="_idIndexMarker130"/>can be visualized using a SHAP plot, which shows the contribution of each feature to the model’s output for a specific prediction. This plot can help in understanding the relative importance of each feature and how they are influencing the <span class="No-Break">model’s prediction.</span></p>
<h3>Difference between SHAP and permutation importance</h3>
<p>Permutation importance <a id="_idIndexMarker131"/>and<a id="_idIndexMarker132"/> SHAP are alternative ways of measuring feature importance. The main difference between the two is that permutation importance is based on the decrease in model performance. It is a simpler and more computationally efficient approach to compute feature importance but may not accurately reflect the true importance of features in <span class="No-Break">complex models.</span></p>
<p>SHAP importance is based on the magnitude of feature attributions. SHAP values provide a more nuanced understanding of feature importance but can be computationally expensive and may not be feasible for very large datasets or <span class="No-Break">complex models.</span></p>
<p>Permutation importance<a id="_idIndexMarker133"/> can be used to do <span class="No-Break">the following:</span></p>
<ul>
<li>Understand which features to keep and which <span class="No-Break">to abandon</span></li>
<li>Understand the feature importance for <span class="No-Break">model accuracy</span></li>
<li>Understand if there is a data leakage, meaning information from outside the training dataset is used to create or evaluate a model, resulting in over-optimistic performance estimates or <span class="No-Break">incorrect predictions</span></li>
</ul>
<p>SHAP importance <a id="_idIndexMarker134"/>can be used to do <span class="No-Break">the following:</span></p>
<ul>
<li>Understand which features have greatest influence to the <span class="No-Break">predicted outcome</span></li>
<li>Understand how the different values of the feature affect the <span class="No-Break">model prediction</span></li>
<li>Understand <a id="_idIndexMarker135"/>what the most influential rows are in <span class="No-Break">the dataset</span></li>
</ul>
<p>We can see an example of a permutation importance graph and SHAP graph in the following figure, as seen in <span class="No-Break">Qlik AutoML:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer013">
<img alt="Figure 1.6: Permutation importance and SHAP importance graphs" height="722" src="image/B19863_01_06.jpg" width="1513"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6: Permutation importance and SHAP importance graphs</p>
<p class="callout-heading">Note</p>
<p class="callout">We will utilize both permutation importance and SHAP importance in our hands-on examples later in <span class="No-Break">this book.</span></p>
<h1 id="_idParaDest-36"><a id="_idTextAnchor036"/>Summary</h1>
<p>In this chapter, we first got an introduction of Qlik tools for machine learning. We discovered the key features of the platform and how different components can be utilized. Understanding the key components is important since we will be utilizing Insight Advisor, AutoML, and Advanced Analytics Integration later in <span class="No-Break">this book.</span></p>
<p>We also discovered some of the key concepts of statistics. Understanding the basics of the underlying mathematics is crucial to understanding the models. We only scratched the surface of the mathematics, but this should be enough to familiarize you with the terminology. We also touched on the important topic of sample and sample size. When creating a model, we need to train it with training data. Determining a reasonable sample size will help us to get an accurate model without <span class="No-Break">wasting resources.</span></p>
<p>At the end of this chapter, we got familiar with some of the techniques to validate the model’s performance and reliability. These are important concepts, since Qlik tools are using the introduced methods to communicate the metrics of <span class="No-Break">the model.</span></p>
<p>In the next chapter, we will augment our background knowledge by getting familiar with some of the most common machine-learning algorithms. These algorithms will be used in later parts of <span class="No-Break">this book.</span></p>
</div>
</div></body></html>