- en: Biometric Face Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Capturing and processing video from a webcam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a face detector using Haar cascades
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building eye and nose detectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing principal component analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing kernel principal component analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing blind source separation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a face recognizer using a local binary pattern histogram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing faces using a HOG-based model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facial landmarks recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User authentication by face recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To address the recipes in this chapter, you need the following files (available
    on GitHub):'
  prefs: []
  type: TYPE_NORMAL
- en: '`video_capture.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`face_detector.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eye_nose_detector.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pca.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kpca.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`blind_source_separation.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mixture_of_signals.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`face_recognizer.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FaceRecognition.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FaceLandmarks.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`UserAuthentification.py`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Face recognition** refers to the task of identifying a person in a given
    image. This is different from face detection where we locate the face in a given
    image. During face detection, we don''t care who the person is; we just identify
    the region of the image that contains the face. Therefore, in a typical biometric
    face recognition system, we need to determine the location of the face before
    we can recognize it.'
  prefs: []
  type: TYPE_NORMAL
- en: Face recognition is very easy for humans. We seem to do it effortlessly, and
    we do it all the time! How do we get a machine to do the same thing? We need to
    understand what parts of the face we can use to uniquely identify a person. Our
    brain has an internal structure that seems to respond to specific features, such
    as edges, corners, motion, and so on. The human visual cortex combines all these
    features into a single coherent inference. If we want our machine to recognize
    faces with accuracy, we need to formulate the problem in a similar way. We need
    to extract features from the input image and convert them into a meaningful representation.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing and processing video from a webcam
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Webcams are certainly not an innovative technological innovation; their appearance
    dates back to the beginning of the 1990s and from then on, they gained increasing
    popularity thanks to the spread of video chat programs, street cams, and broadband
    internet connections. Currently, webcams are objects for everyone and are almost
    always integrated into the display frames of monitors, netbooks, and notebooks.
    The most common uses of a webcam are to transmit video streaming and record.
  prefs: []
  type: TYPE_NORMAL
- en: In the first case, webcams are used in video chat programs, television broadcasting,
    and street cams—cameras that film a fixed point of a given location. In the second
    case, webcams are used for creating photos and videos that you can then upload
    to the internet, for example, to YouTube or social networking sites. The advantage
    of these types of webcams is that they can replace the more classic uses of the
    camera, even if they are characterized by much poorer video quality.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use a webcam to capture video data. Let's see how we
    can capture video footage from a webcam using OpenCV-Python.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can capture and process video from a webcam by following
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `video_capture.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'OpenCV provides a video capture object that we can use to capture images from
    the webcam. The `0` input argument specifies the ID of the webcam. If you connect
    a USB camera, then it will have a different ID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the scaling factor for frames that are captured using the webcam:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Start an infinite loop and keep capturing frames until you press the *Esc*
    key. Read the frame from the webcam:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Resizing the frame is optional but still a useful thing to have in your code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for 1ms before capturing the next frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Release the video capture object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Close all active windows before exiting the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If you run this code, you will see the video from the webcam.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we used a webcam to capture video data via OpenCV-Python. To
    do this, the following operations have been performed:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize video capture object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the image size scaling factor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Loop until you hit the *Esc* key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Capture the current frame.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Resize the frame.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Detect whether the *Esc* key has been pressed.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Release the video capture object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Close all active windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCV provides a very simple interface to capture live streaming with webcams.
    To capture a video, you need to create a `VideoCapture` object. Its argument can
    be the device index or the name of a video file. Then we can acquire them frame
    by frame. However, we must not forget to release the capture.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The official documentation of the OpenCV library: [https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a face detector using Haar cascades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed earlier, face detection is the process of determining the location
    of a face in an input image. In this recipe, we will use **Haar cascades** for
    face detection. This works by extracting many simple features from the image at
    multiple scales. These simple features are edge, line, and rectangle features
    that are very easy to compute. They are then trained by creating a cascade of
    simple classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will learn how to determine the location of a face in the
    video frames that are captured by our webcam. The **adaptive boosting** technique
    is used to make this process robust.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can build a face detector using Haar cascades:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `face_detector.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the face detector cascade file. This is a trained model that we can use
    as a detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Check whether the cascade file loaded properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the video capture object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the scaling factor for image downsampling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep looping until you hit the *Esc* key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Resize the frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the image to grayscale. We need grayscale images to run the face detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the face detector on the grayscale image. The `1.3` parameter refers to
    the scale multiplier for each stage. The `5` parameter refers to the minimum number
    of neighbors that each candidate rectangle should have so that we can retain it.
    This candidate rectangle is basically a potential region where there is a chance
    of a face being detected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw a rectangle around each detected face region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the output image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for 1ms before going to the next iteration. If the user presses the Esc
    key, break out of the loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Release and destroy the objects before exiting the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: If you run this code, you will see the face being detected in the webcam video.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we learned how to determine the location of a face in video
    frames that were captured by the webcam. To do this, the following operations
    were performed:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the face cascade file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the face cascade file has been loaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the video capture object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the scaling factor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Loop until you hit the *Esc* key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Capture the current frame and resize it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert into grayscale.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the face detector on the grayscale image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw rectangles on the image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Check if the *Esc* key has been pressed.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Release the video capture object and close all windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Haar cascades is an approach, based on machine learning, in which a cascade
    function is trained by many positive and negative images. It is then used to detect
    objects in other images.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Face Detection using Haar Cascades*:[ https://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0](https://docs.opencv.org/3.1.0/d7/d8b/tutorial_py_face_detection.html#gsc.tab=0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Rapid Object Detection using a Boosted Cascade of Simple Features*: [https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building eye and nose detectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, *Building a face detector using Haar cascades*, we used
    the Haar cascades method to detect the location of a face in video frames that
    were captured by a webcam. This method can be extended to detect all types of
    object. This is what we will be covering here.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can use the Haar cascades method to detect
    the eyes and nose of a person in an input video.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can build eye and nose detectors:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `eye_nose_detector.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the face, eyes, and nose cascade files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Check whether the files have loaded correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the video capture object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the scaling factor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep looping until the user presses the *Esc* key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Resize the frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the image into grayscale:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the face detector on the grayscale image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we know that faces always have eyes and noses, we can run these detectors
    only in the face region:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the face ROI:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the eye detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the nose detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw circles around the eyes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw a rectangle around the nose:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Display the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for 1ms before going to the next iteration. If the user presses the *Esc*
    key, then break the loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Release and destroy the objects before exiting the code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If you run this code, you will see the eyes and nose of the person being detected
    in the webcam video.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we learned how to detect the eyes and nose of a person in the
    input video. To do this, the following operations have been performed:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the face, eye, and nose cascade files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the face, eye, and nose cascade files have been loaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize a video capture object and define the scaling factor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Loop on the frame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the current frame, resize it, and convert it into grayscale.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the face detector on the grayscale image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the eye and nose detectors within each face rectangle.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the image.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Check whether the *Esc* key has been pressed.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Release the video capture object and close all windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identifying facial elements in a webcam can be useful for recognizing subjects.
    Both global visual information and local characteristics (eye and nose morphology)
    are fundamental in the perception and recognition of the face. In fact, studies
    on facial recognition document that men more easily identify faces with predominant
    elements such as aquiline nose, squinting eyes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Classifier case study – *Viola-Jones Face Detector*: [http://www.cse.psu.edu/~rtc12/CSE586/lectures/violaJonesDetector.pdf ](http://www.cse.psu.edu/~rtc12/CSE586/lectures/violaJonesDetector.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing principal component analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Principal component analysis** (**PCA**) is a dimensionality reduction technique
    that''s used frequently in computer vision and machine learning. When we deal
    with features with large dimensionalities, training a machine learning system
    becomes prohibitively expensive. Therefore, we need to reduce the dimensionality
    of the data before we can train a system. However, when we reduce the dimensionality,
    we don''t want to lose the information that''s present in the data. This is where
    PCA comes into the picture! PCA identifies the important components of the data
    and arranges them in order of importance.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can perform PCA on input data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform a PCA on some input data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `pca.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define five dimensions for our input data. The first two dimensions
    will be independent, but the next three dimensions will be dependent on the first
    two dimensions. This basically means that we can live without the last three dimensions
    because they do not give us any new information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a dataset with these features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a PCA object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Fit a PCA model on the input data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the variances of the dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'If a particular dimension is useful, then it will have a meaningful value for
    the variance. Let''s set a threshold and identify the important dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like we discussed earlier, PCA has identified that only two dimensions
    are important in this dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s convert the dataset from a five-dimensional set into a two-dimensional
    set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code, you will see the following on your Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the first two components contain all of the variance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PCA generates a new set of variables, among which there are uncorrelated variables,
    also known as principal components. Each main component is a linear combination
    of the original variables. All principal components are orthogonal to each other,
    so there is no redundant information.
  prefs: []
  type: TYPE_NORMAL
- en: The principal components as a whole constitute an orthogonal basis for the data
    space. The goal of PCA is to explain the maximum amount of variance with the lowest
    number of principal components. PCA is a type of multidimensional scaling wherein
    the variables are linearly transformed into a lower dimensional space, thereby
    retaining the maximum amount of information possible about the variables. A principal
    component is therefore a combination of the original variables after a linear
    transformation.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The variance measures how far a set of numbers are spread out from their mean.
    It represents the mean of the squares of deviations of individual values from
    their arithmetic mean.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Official documentation of the `sklearn.decomposition.PCA` function: [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principal components analysis* (by Andrew Ng from Stanford University): [http://cs229.stanford.edu/notes/cs229-notes10.pdf](http://cs229.stanford.edu/notes/cs229-notes10.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Principle Component Analysis* (from Indiana University): [http://scholarwiki.indiana.edu/Z604/slides/week4-PCA.pdf](http://scholarwiki.indiana.edu/Z604/slides/week4-PCA.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing kernel principal component analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PCA is good at reducing the number of dimensions, but it works in a linear manner.
    If the data is not organized in a linear fashion, PCA fails to do the required
    job. This is where kernel PCA enters the picture.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can perform a kernel PCA on the input data
    and compare the result to how PCA performs on the same data.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform a kernel PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `kpca.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the `seed` value for the random number generator. This is needed to
    generate data samples for analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Generate data that is distributed in concentric circles to demonstrate how
    PCA doesn''t work in this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform PCA on this data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform kernel PCA on this data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the original input data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the PCA-transformed data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the kernel PCA-transformed data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Transform the data back to the original space using the Kernel method to show
    that the inverse is maintained:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The full code is given in the `kpca.py` file that''s already provided to you
    for reference. If you run this code, you will see four diagrams. The first diagram
    is the original data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9a76365f-eae9-4d62-8bd7-850626d661e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second diagram depicts the data that was transformed using PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67ef1a63-4853-4dcd-ac04-6f0abd5a4c19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The third diagram depicts the data that was transformed using the kernel PCA.
    Note how the points are clustered on the right-hand side of the diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a2fbe42c-caea-4940-8512-59f4cd768dcd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The fourth diagram depicts the inverse transform of the data back to the original
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03aa5817-7804-42a6-b4c0-2183452e54eb.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Kernel principal component analysis** (**kernel PCA**) is based on PCA while
    using the techniques of kernel methods. In PCA, the originally linear PCA operations
    are performed in a reproducing kernel Hilbert space.'
  prefs: []
  type: TYPE_NORMAL
- en: Kernel methods are a class of algorithms used for the analysis of patterns and
    schemes, and whose most well-known element are SVMs. Kernel methods solve a problem
    by mapping data into a multidimensional feature space, and in this space each
    coordinate corresponds to a feature of the element's data, transforming the data
    into a set of Euclidean space points.  Since the mapping can be general (for example,
    not necessarily linear), the relations that are found in this way are consequently
    very general.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kernel methods are named after kernel functions, which are used to operate on
    the characteristic space without calculating the data coordinates in space, but
    rather by calculating the internal product among the images of all copies of data
    in the function space. Kernel methods are often computationally cheaper than the
    explicit calculation of coordinates. The kernel trick refers to this approach
    as **problem resolution**.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Official documentation of the `sklearn.decomposition.KernelPCA` function: [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kernel Principal Components Analysis* (by Max Welling from the University
    of Toronto): [https://www.ics.uci.edu/~welling/classnotes/papers_class/Kernel-PCA.pdf](https://www.ics.uci.edu/~welling/classnotes/papers_class/Kernel-PCA.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*KERNEL PCA* (by Rita Osadchy from Haifa University): [http://www.cs.haifa.ac.il/~rita/uml_course/lectures/KPCA.pdf](http://www.cs.haifa.ac.il/~rita/uml_course/lectures/KPCA.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing blind source separation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Blind source separation** refers to the process of separating signals from
    a mixture. Let''s say a bunch of different signal generators generate signals
    and a common receiver receives all of these signals. Now, our job is to separate
    these signals from this mixture using the properties of these signals. We will
    use **independent component analysis** (**ICA**) to achieve this.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will use the data from a `.txt` file to separate the signals
    contained in it using **ICA**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform a blind source separation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `blind_source_separation.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use data from the `mixture_of_signals.txt` file that''s already provided
    for you. Let''s load the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the ICA object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Reconstruct the signals based on ICA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the mixing matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform PCA for comparison:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a list of signals to plot them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the colors of the plots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the input signal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the ICA-separated signals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot subplots with different colors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot the PCA-separated signals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Use a different color in each subplot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code, you will see three diagrams. The first diagram depicts
    the input, which is a mixture of signals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6630815-f97e-4984-9dee-d55cfd91dd36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second diagram depicts the signals, separated using ICA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/021cd718-0d49-4cdb-9ef6-7d77696e5967.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The third diagram depicts the signals, separated using PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02599066-72d7-4313-9bcd-6c8be9fdc2bd.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ICA is a computational processing method that's used to separate a multivariant
    signal into its additive subcomponents, assuming that there is a mutual statistical
    independence of the source of non-Gaussian signals. This is a special case of
    blind source separation. This method finds the independent components, maximizing
    the statistical independence of the estimated components.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An example of the application of ICA algorithms is in the field of **electroencephalography**
    (**EEG**), but it has also been widely exploited in the separation of the **electrocardiogram**
    (**ECG**) of the fetus from that of the `mother.ICA` techniques. This can be extended
    to the analysis of non-physical data that's either semantic or linguistic. For
    example, the ICA has been applied to make a computer understand the topic of discussion
    in a set of archives of news lists.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Official documentation of the `sklearn.decomposition.FastICA` function: [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*BLIND SOURCE SEPARATION: Principal and Independent Component Analysis* (from
    Massachusetts Institute of Technology): [http://www.mit.edu/~gari/teaching/6.555/LECTURE_NOTES/ch15_bss.pdf](http://www.mit.edu/~gari/teaching/6.555/LECTURE_NOTES/ch15_bss.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a face recognizer using a local binary patterns histogram
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now ready to build a face recognizer. We need a face dataset for training,
    so we've provided you with a folder called `faces_dataset` that contains a small
    number of images that are sufficient for training. This dataset is a subset of
    the dataset that is available at [http://www.vision.caltech.edu/Image_Datasets/faces/faces.tar](http://www.vision.caltech.edu/Image_Datasets/faces/faces.tar).
    This dataset contains a good number of images that we can use to train a face
    recognition system.
  prefs: []
  type: TYPE_NORMAL
- en: We will use a **local binary patterns histogram** to build our face recognition
    system. In our dataset, you will see different people. Our job is to build a system
    that can learn to separate these people from one another. When we see an unknown
    image, our system will assign it to one of the existing classes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can build a face recognizer using a **local
    binary patterns histogram** and use a face dataset to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can build a face recognizer using a local binary patterns
    histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `face_recognizer.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define a class to handle all of the tasks that are related to label
    encoding for the classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to encode the labels. In the input training data, labels are
    represented by words. However, we need numbers to train our system. This method
    will define a preprocessor object that can convert words into numbers in an organized
    fashion by maintaining forward and backward mapping:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to convert a word into a number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to convert the number back into the original word:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to extract the images and labels from the input folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Recursively iterate through the input folder and extract all of the image paths:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize the variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Parse the input directory for training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Read the current image in grayscale format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the label from the folder path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Perform face detection on this image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the ROIs and return them, along with the label encoder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Define the main function and the path to the face cascade file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the face cascade file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Create local binary patterns histogram for face recognizer objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the images, labels, and label encoder for this input path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Train the face recognizer using the data that we extracted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Test the face recognizer on unknown data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Determine the location of the face using the face detector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'For each face ROI, run the face recognizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the label into a word:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Overlay the text on the output image and display it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Check whether the user pressed the *Esc* key. If so, break out of the loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: If you run this code, you will get an output window that displays the predicted
    outputs for test images. You can press the *Space* button to keep looping. There
    are three different people in the test images.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Local Binary Patterns Histogram algorithm is based on a non-parametric operator
    that synthesizes the local structure of an image. At a particular pixel, the LBP
    operator associates an ordered binary sequence of color intensity comparisons
    between that pixel and the pixels belonging to the considered neighborhood. In
    particular, if the intensity of the central pixel is greater than or equal to
    the intensity of the adjacent pixel, then a value of 1 is assigned. Otherwise,
    0 is assigned. Therefore, for a neighborhood of 8 pixels, for example, there will
    be 2⁸ possible combinations.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To apply this operator to the face recognition problem, the idea is to divide
    the image into *m* local regions and extract a histogram from each of them. The
    vector of the features to be extracted consists of the concatenation of these
    local histograms.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Local Binary Patterns* *Histogram*: [http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html#local-binary-patterns-histograms](http://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html#local-binary-patterns-histograms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing faces using the HOG-based model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By face recognition, we mean the process that returns the position of the faces
    that are present in an image. In the *Building a face detector using Haar cascades*
    recipe, we already addressed this topic. In this recipe, we will use the `face_recognition`
    library to perform a series of operations on these faces.
  prefs: []
  type: TYPE_NORMAL
- en: 'The focal objective of face recognition consists of detecting the characteristics
    of a face and ignoring everything else that surrounds it. This is a feature on
    multiple commercial devices, and it allows you to establish when and how to apply
    focus in an image so that you can capture it. In the world of computer vision,
    it is customary to divide the family of face detection algorithms into two major
    categories. What distinguishes these two categories is their different uses of
    information, derived from a priori knowledge of the structure and properties of
    the face:'
  prefs: []
  type: TYPE_NORMAL
- en: The first category includes methods based on the extraction of specification
    features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second category adopts a global approach to image analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can use the `face_recognition` library to
    perform face recognition from a complex image. Before proceeding, install the `face_recognition`
    library. This library is based on the `dlib` library, which must be installed
    before we can go any further. `dlib` is a modern C++ toolkit that contains machine
    learning algorithms and tools for creating complex software in C++ to solve real-world
    problems. You can find information on installing the package at [https://pypi.org/project/face_recognition/](https://pypi.org/project/face_recognition/).
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can recognize faces using a HOG-based model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `FaceRecognition.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The **Python Imaging Library** (**PIL**) is a free library for the Python programming
    language that adds support for opening, manipulating, and saving many different
    image file formats. `face_recognition` is a Python library that recognizes and
    manipulates faces from Python scripts or from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s load the `family.jpg` file into a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now find all of the faces in the image using the default HOG-based
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Define a method to convert words into numbers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the location of each face in this image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we need to access the actual face itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: A thumbnail of each recognized face will be returned.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Histogram of Oriented Gradients** (**HOG**) is a feature descriptor that''s
    used for object recognition. The algorithm counts the occurrences of the orientation
    of the gradient in localized portions of an image. It differs from other techniques
    that are used for the same purpose (scale-invariant feature transforms, edge orientation
    histograms, shape contexts) because it uses a dense grid of uniformly spaced cells
    and uses localized superimposed normalization to improve accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first to introduce this technology were Navneet Dalal and Bill Triggs (2005),
    researchers of the **Institut national de recherche en informatique et en automatique** (**INRIA**),
    while they were studying the problem of pedestrian detection in static images.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Official documentation of the `face_recognition` library: [https://github.com/ageitgey/face_recognition](https://github.com/ageitgey/face_recognition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Histograms of Oriented Gradients for Human Detection* (by Navneet Dalal and
    Bill Triggs from INRIA): [https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Facial landmark recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Face recognition is also complicated because of its orientation. The same face,
    directed in different directions from that of the observer, can induce the algorithm
    to identify it as a different face. To solve this problem, we can use facial landmarks,
    which are specific points on the face such as eyes, eyebrows, lips, nose, and
    so on. By using this technique, you can identify as many as 68 points on any face.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can extract facial features as facial landmarks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform facial landmark recognition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `FaceLandmarks.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s load the `ciaburro.jpg` file into a NumPy array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s find all facial features in all of the faces in the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Print the number of faces that were recognized in the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a PIL imagedraw object so that we can draw on the picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we will insert a cycle that returns the position of the points
    for each facial feature that''s included in the list and trace a line to the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we print the location of each facial feature in this image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we trace out each facial feature in the image with a line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we draw the image with the highlighted landmarks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following image, we can see the input image and the image with highlighted
    landmarks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/009c45a4-9604-4d87-88ed-674d94796546.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In addition, the positions of the landmarks are printed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1aceb22e-4627-4676-ab75-4edfa0edce47.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we learned how to extract facial landmarks from an image and
    how to draw these points on the same image. The following landmarks were detected:'
  prefs: []
  type: TYPE_NORMAL
- en: '`chin`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`left_eyebrow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`right_eyebrow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nose_bridge`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nose_tip`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`left_eye`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`right_eye`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_lip`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bottom_lip`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each feature that was detected, connecting lines of the detection points
    were drawn to show the contours.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To extract facial landmarks, the `face_recognition` library was used. This
    library performed this task by using the method that was introduced by Vahid Kazemi
    and Josephine Sullivan in the following paper: *One Millisecond Face Alignment
    with an Ensemble of Regression Trees*. To estimate the face''s landmark positions,
    an ensemble of regression trees was used.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Official documentation of the `face_recognition` library: [https://github.com/ageitgey/face_recognition](https://github.com/ageitgey/face_recognition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*One Millisecond Face Alignment with an Ensemble of Regression Trees* (by Vahid
    Kazemi and Josephine Sullivan): [http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf](http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User authentication by face recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Authentication technologies based on facial recognition have been a consolidated
    reality for several decades now. We no longer have to carry pocket cards, store
    it on the phone, or use mnemonics to remember a different one each time, if we
    are so considerate to change it often. What we need to do is authenticate that
    which we already had it with us. To do this, we just look at our webcam. An identification
    system based on facial recognition tries to identify a person by comparing the
    image of the face that was just acquired with those present in a database to find
    a possible correspondence. This leads to either allowing or prohibiting access.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will see how we can build an identification system based
    on facial recognition using the `face_recognition`  library.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can perform user authentication by using face recognition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `UserAuthentification.py` file that is provided for you):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s load all of the image files into NumPy arrays:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'Three images have been loaded: the first two images refer to the faces we''ve
    already seen, while the third is the image to be compared (`tiziana`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the face encodings for each face in each image file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s define the known faces:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compare the known faces with the unknown face we just loaded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will print the results of the comparison:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the authentication system recognized the user as Tiziana.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we learned how to build an identification system based on facial
    recognition. To do this, we extracted some basic measures from every face in the
    known database. In doing so, we were able to compare these basic measures with
    the basic measures of other faces that require authentication.
  prefs: []
  type: TYPE_NORMAL
- en: 'These measurements were made using a deep convolutional neural network. The
    learning process works by analyzing three images simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: An image that contains the face of a known person (anchor)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another image of the same known person (positive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An image of a completely different person (negative)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this point, the algorithm examines the measures it is generating for each
    of these three images. Then it adjusts the weights of the neural network to make
    sure that the measurements that were generated for faces 1 and 2 are slightly
    closer, while the measures for faces 2 and 3 are slightly more distant. This technique
    is called `Triplet Loss`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have said that the secret to the success of an algorithm based on
    machine learning lies in the number of examples that are used in the learning
    phase. The greater the number, the greater the accuracy of the model. In the cases
    that we dealt with in this chapter, this cannot be considered valid. This is because,
    in the algorithms for facial recognition, the examples at our disposal were very
    limited.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the construction and formation of a typical convolutional neural
    network will not work because it cannot learn the required functionality with
    the amount of data that's available. In these cases, we use a **one-shot learning**
    approach in which we construct a similarity function that compares two images
    and tells you if there is a match.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Official documentation of the `face_recognition` library: [https://github.com/ageitgey/face_recognition](https://github.com/ageitgey/face_recognition)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*One-shot learning* (from Wikipedia): [https://en.wikipedia.org/wiki/One-shot_learning](https://en.wikipedia.org/wiki/One-shot_learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*One-shot learning of simple visual concepts* (from MIT): [https://web.mit.edu/jgross/Public/lake_etal_cogsci2011.pdf](https://web.mit.edu/jgross/Public/lake_etal_cogsci2011.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Siamese/Triplet Networks* (from Virginia Tech University): [https://filebox.ece.vt.edu/~jbhuang/teaching/ece6554/sp17/lectures/Lecture_08_Siamese_Triplet_Networks.pdf](https://filebox.ece.vt.edu/~jbhuang/teaching/ece6554/sp17/lectures/Lecture_08_Siamese_Triplet_Networks.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
