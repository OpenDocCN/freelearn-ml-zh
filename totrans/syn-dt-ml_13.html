<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer087">
<h1 class="chapter-number" id="_idParaDest-213"><a id="_idTextAnchor216"/>13</h1>
<h1 id="_idParaDest-214"><a id="_idTextAnchor217"/>Best Practices for Applying Synthetic Data</h1>
<p>Synthetic data<a id="_idIndexMarker541"/> indeed has many advantages and has been successfully and extensively utilized recently in various domains and applications. However, many general issues limit the usability of synthetic data. In this chapter, you will learn about these issues that present a bottleneck for synthetic data. Then, we will delve into domain-related issues that make deploying synthetic data even more challenging. You will explore these issues in various fields, such as healthcare, finance, and self-driving cars. Following this, you will be introduced to an excellent set of good practices that improve the usability of synthetic data <span class="No-Break">in practice.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Unveiling the challenges of generating and utilizing <span class="No-Break">synthetic data</span></li>
<li>Domain-specific issues limiting the usability of <span class="No-Break">synthetic data</span></li>
<li>Best practices for the effective utilization of <span class="No-Break">synthetic data</span></li>
</ul>
<h1 id="_idParaDest-215"><a id="_idTextAnchor218"/>Unveiling the challenges of generating and utilizing synthetic data</h1>
<p>In this section, you will understand the main common issues usually seen across different domains that limit the benefits and usability of <span class="No-Break">synthetic data.</span></p>
<p>We can roughly categorize these limiting<a id="_idIndexMarker542"/> factors into four <span class="No-Break">main categories:</span></p>
<ul>
<li><span class="No-Break">Domain gap</span></li>
<li><span class="No-Break">Data representation</span></li>
<li>Privacy, security, <span class="No-Break">and validation</span></li>
<li>Trust <span class="No-Break">and credibility</span></li>
</ul>
<p>They can be represented<a id="_idIndexMarker543"/> as shown in <span class="No-Break"><em class="italic">Figure 13</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<img alt="Figure 13.1 – Main factors that limit the usability of synthetic data in practice" height="465" src="image/B18494_13_01.jpg" width="915"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1 – Main factors that limit the usability of synthetic data in practice</p>
<p>Next, let’s delve into each of these categories in <span class="No-Break">more detail.</span></p>
<h2 id="_idParaDest-216"><a id="_idTextAnchor219"/>Domain gap</h2>
<p>While neural networks<a id="_idIndexMarker544"/> are very successful at learning hidden patterns, correlations, and structures<a id="_idIndexMarker545"/> in large datasets, they can suffer from the domain gap problem. <strong class="bold">Domain gap</strong> usually refers to the difference between the source and target domains’ data. The source domain<a id="_idIndexMarker546"/> refers to the training data’s domain on which the ML model was trained. On the other hand, the target domain<a id="_idIndexMarker547"/> refers to the domain on which the model will be tested, evaluated, or used <span class="No-Break">in practice.</span></p>
<p>In many scenarios, you may achieve excellent results on one dataset but dramatically unsatisfactory performance on another dataset. Both datasets can be real, synthetic, or a mixture of both. However, we focus here on the synthetic source domain and real target domain<a id="_idIndexMarker548"/> as it is usually the main and most frequent setup. Training your <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) models on a large-scale synthetic dataset and achieving excellent performance in the synthetic domain may not necessarily guarantee the same performance on a real dataset. Thus, it is usually recommended to validate your ML model on a dataset collected from your <span class="No-Break">target domain.</span></p>
<p>Now, let’s dig deeper<a id="_idIndexMarker549"/> into the main reasons<a id="_idIndexMarker550"/> behind the domain gap between synthetic and real domains. In general, we can identify the following <span class="No-Break">principal factors:</span></p>
<ul>
<li>Lack <span class="No-Break">of realism</span></li>
<li><span class="No-Break">Distributional differences</span></li>
<li>Lack of noise <span class="No-Break">and artifacts</span></li>
</ul>
<h3>Lack of realism</h3>
<p>Using a simulator, game engine, or generative<a id="_idIndexMarker551"/> model may generate appealing and semirealistic synthetic data but not exactly realistic data. Synthetic data generators cannot capture all the details of the complex real world. It is not necessary for ML models to be trained on data that captures all real-world nuances. However, it needs to be trained on synthetic data that captures and reflects the essential and auxiliary task-relevant details. It is crucial to acknowledge the substantial disparity between both scenarios. Additionally, identifying what is relevant to your ML task may not be a straightforward process. Thus, in general, if you do not train your ML model on sufficiently realistic data, you will end up with a domain gap between your training data and the real world. Thus, your model may not perform well <span class="No-Break">in practice.</span></p>
<h3>Distributional differences</h3>
<p>The essence of the training process of <strong class="bold">d</strong><strong class="bold">eep learning</strong> (<strong class="bold">DL</strong>) and ML models is learning how to make associations between<a id="_idIndexMarker552"/> input features and output labels. In other words, for a classification problem, the ML model learns to link certain patterns in pixels colors and locations with the target class label. Thus, when the ML model receives a new image, it may correctly classify it based on the patterns that the ML model learned in the training stage. As you can see, there is a clear assumption that data distributions between source and target domains are identical or close to each other. If the synthetic data distribution is not sufficiently close to the real one, this will make the learned associations, patterns, and correlations from synthetic data not applicable to <span class="No-Break">real data.</span></p>
<p>For demonstration, let us imagine a scenario that captures the main idea, although it may not reflect the exact reality. If you trained your ML model to do a cats-dogs classification task on synthetic labeled images collected from the <em class="italic">The Secret Life of Pets</em> animated movie, you would not expect your model to perform well on real data because of the distributional differences problem. For example, the dimensions of the cats and dogs, colors, variations, and densities concerning other objects in the scenes in this movie may not match the ones in the real dataset even though they still may look partially realistic. It is essential to recognize that the issue here is not photorealism but <span class="No-Break">distributional differences.</span></p>
<h3>Lack of noise and artifacts</h3>
<p>While synthetic data may be generated<a id="_idIndexMarker553"/> to approximate or represent real data, it is usually extremely challenging to model noise and artifacts (anomalies and imperfections) of complex real-world data. The real world is full of imperfections, anomalies, noise, and artifacts. This is due to many reasons, such as random event occurrences, interactions and emergence among complex processes, limitations and errors in sensors and measurement procedures, and even errors because of human intervention. Thus, synthetic data may successfully present the central portion of the distribution, but it may fail to capture anomalies, outliers, and artifacts. Therefore, when the ML model does not observe these scenarios in the training process, it will simply fail when it encounters similar situations in the <span class="No-Break">real world.</span></p>
<p>For more details about how to bridge the gap between synthetic and real domains, please refer to <a href="B18494_14.xhtml#_idTextAnchor230"><span class="No-Break"><em class="italic">Chapter 14</em></span></a><span class="No-Break">.</span></p>
<p>Let’s now explore the next primary category that restricts the usability of <span class="No-Break">synthetic data.</span></p>
<h2 id="_idParaDest-217"><a id="_idTextAnchor220"/>Data representation</h2>
<p>Training data is usually<a id="_idIndexMarker554"/> collected or generated to be a proxy of the real<a id="_idIndexMarker555"/> world. The human element is always present in this process. Thus, to some extent, our decisions, assumptions, and biases are explicitly or implicitly reflected in how we choose to represent the real world for the ML model. Nevertheless, while it is an issue with real data, it is more<a id="_idIndexMarker556"/> vital and problematic<a id="_idIndexMarker557"/> with synthetic data, as we will <span class="No-Break">see next.</span></p>
<h3>Biases and distortions</h3>
<p>As we know, one<a id="_idIndexMarker558"/> of the main methods of generating synthetic data is using generative models, which are trained on real data (for more information, please refer to <a href="B18494_07.xhtml#_idTextAnchor120"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>). If the generative model is trained on biased and distorted real data, it will also generate biased data. Then, when the ML models are trained on this data, the decisions will also be biased. Thus, it is very important to thoroughly comprehend and focus on the quality and procedures of our decision-making methodology and assumptions as we generate <span class="No-Break">synthetic data.</span></p>
<h3>Limited coverage and overfitting</h3>
<p>The second main issue under this category is synthetic data diversity. Imagine you want to build a 3D virtual world using a game engine to generate synthetic data for a semantic segmentation problem. For your synthetic data to be useful, you need to diversify scene elements such as 3D models, materials, textures, lighting, and camera parameters. Otherwise, your ML model will overfit to a few variations and will fail to generalize well when tested on real data. It should be noted that diversifying these scene elements requires more 3D assets to buy or design, more work and effort, more budget to spend, and more engineers, designers, <span class="No-Break">and programmers.</span></p>
<h3>Lack of context</h3>
<p>Unlike real data that is generated by real-world processes, synthetic data is generated artificially by algorithms or systems. Thus, it lacks contextual information that can be essential for learning the phenomenon or task <span class="No-Break">under consideration.</span></p>
<p>For example, let’s say we have created a system to generate synthetic data for the cats-dogs classification problem. Indeed, we can generate thousands of labeled cat and dog images under various attributes, such as lighting conditions, backgrounds, and weather conditions. However, what is vital and much harder to capture with synthetic data is context – in other words, where, when, and how dogs and cats usually appear in the real world. For example, we can usually see them in parks, streets, and residential areas. On the other hand, it is unlikely to see them in hospitals and laboratories. Thus, as you can see, if we are not fully aware of the context of the problem, we may end up generating synthetic training data that lacks context. In this simple scenario, it may be easy to understand the context, but in other<a id="_idIndexMarker559"/> scenarios, the context may not be clear <span class="No-Break">and straightforward.</span></p>
<h2 id="_idParaDest-218"><a id="_idTextAnchor221"/>Privacy, security, and validation</h2>
<p>As we saw earlier, one<a id="_idIndexMarker560"/> of the main issues with real data is privacy (for more information, please<a id="_idIndexMarker561"/> refer to <a href="B18494_03.xhtml#_idTextAnchor049"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>). Unfortunately, even with synthetic data, it is still <span class="No-Break">a concern.</span></p>
<p>There is usually a trade-off<a id="_idIndexMarker562"/> between data usefulness and privacy when dealing with sensitive<a id="_idIndexMarker563"/> data. Synthetic data generators for certain problems in fields such as healthcare and finance are usually trained on sensitive data. Thus, there is a chance that the generated synthetic data may reveal <span class="No-Break">sensitive information.</span></p>
<p>While generating the synthetic data is the main challenge, there are still other tasks to be performed before deploying synthetic data for your ML problem. Synthetic data needs to be evaluated<a id="_idIndexMarker564"/> and validated. Therefore, an effective risk assessment procedure<a id="_idIndexMarker565"/> should be performed to ensure that synthetic data is anonymous and still represents the phenomenon under consideration. As privacy attacks evolve, synthetic data generation procedures need to be assessed and monitored continuously to ensure that the generated synthetic data does not breach regulations or disclose <span class="No-Break">sensitive information.</span></p>
<p>Next, let’s explore another interesting factor, which is associated with the sociology <span class="No-Break">of customers.</span></p>
<h2 id="_idParaDest-219"><a id="_idTextAnchor222"/>Trust and credibility</h2>
<p>ML in general<a id="_idIndexMarker566"/> is still a new, emerging field and synthetic data has only been utilized recently. Thus, it requires time for companies, customers, and ML practitioners to understand and trust synthetic data. Let’s discuss the main two elements under this category that usually limit the usability of synthetic data <span class="No-Break">in practice.</span></p>
<h3>Consumer skepticism and lack of familiarity</h3>
<p>As companies<a id="_idIndexMarker567"/> have just started to deploy<a id="_idIndexMarker568"/> more synthetic data-based ML solutions, customers have also started to question the usability of this new approach. One of the main reasons behind this is their misunderstanding of or unfamiliarity with synthetic data <span class="No-Break">generation approaches.</span></p>
<h3>Perception of artificiality</h3>
<p>Synthetic data<a id="_idIndexMarker569"/> is not collected from the real world. Rather, it is generated artificially. Its synthetic nature causes customers to question its usability and genuineness. Thus, they may question and not trust this new data source or any ML solution based <span class="No-Break">on it.</span></p>
<p>Now that you have understood the key general issues that limit the usability of synthetic data, let’s examine a wide range of domain-specific issues commonly seen in certain fields, such as healthcare <span class="No-Break">and finance.</span></p>
<h1 id="_idParaDest-220"><a id="_idTextAnchor223"/>Domain-specific issues limiting the usability of  synthetic data</h1>
<p>In addition to general issues<a id="_idIndexMarker570"/> that limit the usability of synthetic data in practice, there are also domain-specific issues related to that. In this section, we explore these common domain-specific issues limiting the usability of synthetic data. Let’s study synthetic data usability issues in the following three fields: healthcare, finance, and <span class="No-Break">autonomous cars.</span></p>
<h2 id="_idParaDest-221"><a id="_idTextAnchor224"/>Healthcare</h2>
<p>ML in healthcare requires<a id="_idIndexMarker571"/> large-scale training data. Usually, the data is unstructured, comes from different sensors and sources, is longitudinal (data collected over a long period), is highly imbalanced, and contains sensitive information. The illnesses and diseases that patients suffer from are diverse and complex and depend on a multitude of factors, such as genes, geographic location, medical conditions, and occupation. Thus, to generate useful synthetic training data in the healthcare field, domain experts are usually needed to assess the quality of the generated training data and the validity of the assumptions made by ML engineers. For more<a id="_idIndexMarker572"/> information, please refer to <em class="italic">Amplifying Domain Expertise in Clinical Data </em><span class="No-Break"><em class="italic">Pipelines</em></span><span class="No-Break"> (</span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7677017"><span class="No-Break">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7677017</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-222"><a id="_idTextAnchor225"/>Finance</h2>
<p>This field is usually<a id="_idIndexMarker573"/> associated with rapid changes, being influenced by a huge number of factors and elements that are usually very hard to predict, such as politics, regulations, competitions, new technologies, and natural catastrophes. Thus, it is not easy to generate synthetic data that takes into consideration the dynamics of the market and other factors. Consequently, applying domain knowledge to the synthetic generation pipeline may significantly improve the usability of the generated synthetic data for this field. For more details, please refer to <em class="italic">Expectations, competencies and domain knowledge in data- and machine-driven </em><span class="No-Break"><em class="italic">finance</em></span><span class="No-Break"> (</span><a href="https://www.tandfonline.com/doi/full/10.1080/03085147.2023.2216601"><span class="No-Break">https://www.tandfonline.com/doi/full/10.1080/03085147.2023.2216601</span></a><span class="No-Break">).</span></p>
<h2 id="_idParaDest-223"><a id="_idTextAnchor226"/>Autonomous cars</h2>
<p>Simulating 3D virtual worlds<a id="_idIndexMarker574"/> is a hard task. However, what is more challenging is simulating drivers’ and pedestrians’ behaviors. In the real world, human behaviors are complex, hard to anticipate, and highly dependent on the environment and situation. For example, drivers and pedestrians may not obey traffic regulations and rules in the events of natural disasters and evacuations. Generating synthetic data that incorporates and anticipates similar scenarios is very complex and not easy to achieve. Additionally, simulators usually need to make many assumptions to simplify computations. However, the consequences of these assumptions may not always be clear and may cause ML models to fail in critical and <span class="No-Break">rare situations.</span></p>
<p>Next, let’s learn some best practices to unlock the full potential of <span class="No-Break">synthetic data.</span></p>
<h1 id="_idParaDest-224"><a id="_idTextAnchor227"/>Best practices for the effective utilization of synthetic data</h1>
<p>In this section, we will learn<a id="_idIndexMarker575"/> about some common good practices that can improve the usability of your synthetic data-based ML solution <span class="No-Break">in practice:</span></p>
<ul>
<li><strong class="bold">Understand the problem</strong>: Before you start deploying synthetic data, you need to understand what the problem with your ML model and data is and why the available real datasets are not suitable. Do not jump directly to the synthetic data solution if you are not fully aware of the problem and the limitations of the available real <span class="No-Break">data-based solutions.</span></li>
<li><strong class="bold">Understand the synthetic data generation pipeline</strong>: We should not consider the synthetic data generation pipeline as a black box. However, we need a good understanding of the generation process to avoid biases and artifacts. For example, suppose we are generating synthetic data for an application to flag fraudulent transactions. If our synthetic data generator often generates the majority of fraudulent transactions with certain attributes, such as a transaction amount between 10K and 12K and the transaction location being some specific country, our ML model, trained on this biased data, will tend to mistakenly identify any transaction with these attributes to be fraudulent regardless of other crucial attributes! As expected, this will make our ML model perform poorly <span class="No-Break">in practice.</span></li>
<li><strong class="bold">Diversity, variability, and realism</strong>: For synthetic data to be useful in practice, it should usually be diverse, rich, and realistic and match the distribution of real dataset counterparts. Please refer to <em class="italic">Diversity in Machine Learning</em> (<a href="https://arxiv.org/pdf/1807.01477.pdf">https://arxiv.org/pdf/1807.01477.pdf</a>) and <em class="italic">Enhancing Photorealism Enhancement</em> (<a href="https://arxiv.org/abs/2105.04619">https://arxiv.org/abs/2105.04619</a>). It is always recommended that you analyze the available real data (if any) and identify the key variabilities and properties that you wish your synthetic dataset <span class="No-Break">to address.</span></li>
<li><strong class="bold">Continuously validate and evaluate</strong>: You should always and frequently compare and assess the quality of the generated synthetic data to ensure that the data generation pipeline is working as expected. For example, if you are working with sensitive data, you should continuously assess the generated synthetic data to ensure that it does not disclose any sensitive information and to ensure a high-quality <span class="No-Break">anonymization procedure.</span></li>
<li><strong class="bold">Combine synthetic with real data</strong>: It is often suggested to combine synthetic with real data to achieve the best results. Training on a mixture of both or pre-training on synthetic data and fine-tuning on real data are well-known approaches to improve the usability of synthetic data. Please refer to <em class="italic">Semantic Segmentation under Adverse Conditions: A Weather and Nighttime-aware Synthetic Data-based Approach</em> (<a href="https://bmvc2022.mpi-inf.mpg.de/0977.pdf">https://bmvc2022.mpi-inf.mpg.de/0977.pdf</a>) and <em class="italic">Using synthetic data for person tracking under adverse weather </em><span class="No-Break"><em class="italic">conditions</em></span><span class="No-Break"> (</span><a href="https://doi.org/10.1016/j.imavis.2021.104187"><span class="No-Break">https://doi.org/10.1016/j.imavis.2021.104187</span></a><span class="No-Break">).</span></li>
<li><strong class="bold">Noise and anomalies</strong>: One of the main common issues is ignoring or underestimating the benefits of outliers and rare scenarios when generating synthetic data. Try to always include these circumstances as they are essential to ensure that your ML <a id="_idIndexMarker576"/>model does not fail in these situations in the <span class="No-Break">real world.</span></li>
</ul>
<h1 id="_idParaDest-225"><a id="_idTextAnchor228"/>Summary</h1>
<p>In this chapter, we discussed the primary challenges of deploying synthetic data. Then, we delved into domain-specific issues. We learned why synthetic data is inherently challenging, especially in fields such as healthcare and finance. Finally, we explored a list of best practices to improve the usability of your synthetic data in practice. Next, we will focus in more detail on enhancing and improving synthetic data usability through synthetic-to-real domain <span class="No-Break">adaptation techniques.</span></p>
</div>
</div>

<div id="sbo-rt-content"><div class="Content" id="_idContainer088">
<h1 id="_idParaDest-226" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor229"/>Part 5:Current Challenges and Future Perspectives</h1>
<p>In this part, you learn about a well-known issue that usually limits the usability of synthetic data. You will learn about the domain gap problem and why diversity and photorealism are some of the main challenges toward generating useful and large-scale synthetic data in practice. You will learn about various approaches to bridge the domain gap and improve the diversity and photorealism of your synthetic data. Then, we will recap the benefits of synthetic data-based solutions, challenges, and limitations. Finally, we will highlight some interesting <span class="No-Break">future </span><span class="No-Break">perspectives</span><span class="No-Break">.</span></p>
<p>This part has the <span class="No-Break">following chapters:</span></p>
<ul>
<li><a href="B18494_14.xhtml#_idTextAnchor230"><em class="italic">Chapter 14</em></a>, <em class="italic">Synthetic-to-Real Domain Adaptation</em></li>
<li><a href="B18494_15.xhtml#_idTextAnchor247"><em class="italic">Chapter 15</em></a>, <em class="italic">Diversity Issues in Synthetic Data</em></li>
<li><a href="B18494_16.xhtml#_idTextAnchor269"><em class="italic">Chapter 16</em></a>, <em class="italic">Photorealism in Computer Vision</em></li>
<li><a href="B18494_17.xhtml#_idTextAnchor287"><em class="italic">Chapter 17</em></a>, <em class="italic">Conclusion</em></li>
</ul>
</div>
<div>
<div id="_idContainer089">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer090">
</div>
</div>
</div></body></html>