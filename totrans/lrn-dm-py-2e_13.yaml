- en: Next Steps...
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步...
- en: During the course, there were lots of avenues not taken, options not presented,
    and subjects not fully explored. In this appendix, I've created a collection of
    next steps for those wishing to undertake extra learning and progress their data
    mining with Python.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在课程中，有很多未被探索的途径、未提出的选项和未充分研究的主题。在本附录中，我为那些希望进行额外学习并使用 Python 推进数据挖掘的人创建了一系列下一步行动。
- en: This appendix is for learning more about data mining. Also included are some
    challenges to extend the work performed. Some of these will be small improvements;
    some will be quite a bit more work—I've made a note of those more tasks that are
    noticeably more difficult and involved than the others.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录旨在学习更多关于数据挖掘的知识。还包括一些扩展所做工作的挑战。其中一些将是小的改进；有些工作会更多——我已经记下了那些比其他任务明显更困难、更复杂的工作。
- en: Getting Started with Data Mining
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘入门
- en: 'In this chapter following are a few avenues that reader can explore:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，读者可以探索以下途径：
- en: Scikit-learn tutorials
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-learn 教程
- en: 'URL: [http://scikit-learn.org/stable/tutorial/index.html](http://scikit-learn.org/stable/tutorial/index.html)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 'URL: [http://scikit-learn.org/stable/tutorial/index.html](http://scikit-learn.org/stable/tutorial/index.html)'
- en: Included in the scikit-learn documentation is a series of tutorials on data
    mining. The tutorials range from basic introductions to toy datasets, all the
    way through to comprehensive tutorials on techniques used in recent research.
    The tutorials here will take quite a while to get through—they are very comprehensive—but
    are well worth the effort to learn.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 文档中包含了一系列关于数据挖掘的教程。这些教程从基本介绍到玩具数据集，再到最近研究中所用技术的全面教程。这些教程需要花费相当长的时间才能完成——它们非常全面——但学习起来非常值得。
- en: There are also a large number of algorithms that have been implemented for compatability
    with scikit-learn. These algorithms are not always included in scikit-learn itself
    for a number of reasons, but a list of many of these is maintained at [https://github.com/scikit-learn/scikit-learn/wiki/Third-party-projects-and-code-snippets](https://github.com/scikit-learn/scikit-learn/wiki/Third-party-projects-and-code-snippets).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 还有大量算法已经实现，以与 scikit-learn 兼容。由于许多原因，这些算法并不总是包含在 scikit-learn 本身中，但许多这些算法的列表维护在
    [https://github.com/scikit-learn/scikit-learn/wiki/Third-party-projects-and-code-snippets](https://github.com/scikit-learn/scikit-learn/wiki/Third-party-projects-and-code-snippets)。
- en: Extending the Jupyter Notebook
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展 Jupyter Notebook
- en: 'URL: [http://ipython.org/ipython-doc/1/interactive/public_server.html](http://ipython.org/ipython-doc/1/interactive/public_server.html)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 'URL: [http://ipython.org/ipython-doc/1/interactive/public_server.html](http://ipython.org/ipython-doc/1/interactive/public_server.html)'
- en: The Jupyter Notebook is a powerful tool. It can be extended in many ways, and
    one of those is to create a server to run your Notebooks, separately from your
    main computer. This is very useful if you use a low-power main computer, such
    as a small laptop, but have more powerful computers at your disposal. In addition,
    you can set up nodes to perform parallelized computations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 是一个强大的工具。它可以以多种方式扩展，其中之一是创建一个服务器来运行你的笔记本，与你的主要计算机分开。如果你使用的是低功耗的主计算机，如小型笔记本电脑，但手头上有更强大的计算机，这将非常有用。此外，你可以设置节点以执行并行计算。
- en: More datasets
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多数据集
- en: URL: [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'URL: [http://archive.ics.uci.edu/ml/](http://archive.ics.uci.edu/ml/)'
- en: There are many datasets available on the Internet from a number of different
    sources. These include academic, commercial, and government datasets. A collection
    of well-labelled datasets is available at the UCI ML library, which is one of
    the best options to find datasets for testing your algorithms. Try out the OneR
    algorithm with some of these different datasets.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上有许多来自不同来源的数据集。这些包括学术、商业和政府数据集。在 UCI ML 图书馆有一个包含良好标签的数据集集合，这是寻找测试你的算法的最佳选择之一。尝试使用
    OneR 算法测试这些不同的数据集之一。
- en: Other Evaluation Metrics
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他评估指标
- en: 'There is a wide range of evaluation metrics for other takes. Some notable ones
    to investigate are:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他方法有很多种评估指标。一些值得研究的著名指标包括：
- en: The Lift Metric: [https://en.wikipedia.org/wiki/Lift_(data_mining)](https://en.wikipedia.org/wiki/Lift_(data_mining))
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升值指标：[https://en.wikipedia.org/wiki/Lift_(data_mining)](https://en.wikipedia.org/wiki/Lift_(data_mining))
- en: Segment evaluation metrics: [http://segeval.readthedocs.io/en/latest/](http://segeval.readthedocs.io/en/latest/)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分段评估指标：[http://segeval.readthedocs.io/en/latest/](http://segeval.readthedocs.io/en/latest/)
- en: Pearson's Correlation Coefficient: [https://en.wikipedia.org/wiki/Pearson_correlation_coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数：[https://en.wikipedia.org/wiki/Pearson_correlation_coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)
- en: Area under the ROC Curve: [http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC曲线下的面积：[http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm)
- en: Normalized Mutual Information: [http://scikit-learn.org/stable/modules/clustering.html#mutual-info-score](http://scikit-learn.org/stable/modules/clustering.html#mutual-info-score)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归一化互信息：[http://scikit-learn.org/stable/modules/clustering.html#mutual-info-score](http://scikit-learn.org/stable/modules/clustering.html#mutual-info-score)
- en: Each of these metrics was developed with a particular application in mind. For
    example, the segment evaluation metrics evaluate how accurate breaking a document
    of text into chunks is, allowing for some variation between chunk boundaries.
    A good understanding of where evaluation metrics can be applied and where they
    can not is critical to ongoing success in data mining.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标中的每一个都是针对特定应用开发的。例如，段落评估指标评估将文本文档分割成块时的准确性，允许块边界之间有一定的变化。了解评估指标可以应用在哪里以及不能应用在哪里对于数据挖掘的持续成功至关重要。
- en: More application ideas
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多应用想法
- en: URL: [https://datapipeline.com.au/](https://datapipeline.com.au/)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://datapipeline.com.au/](https://datapipeline.com.au/)
- en: If you are looking for more ideas on data mining applications, specifically
    those for businesses, check out my company's blog. I post regularly about applications
    of data mining, focusing on practical outcomes for businesses.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在寻找更多数据挖掘应用的想法，特别是针对商业的，请查看我的公司博客。我经常发布有关数据挖掘应用的文章，重点关注商业的实际成果。
- en: Classifying with scikit-learn Estimators
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn估计器进行分类
- en: A naïve implementation of the nearest neighbor algorithm is quite slow—it checks
    all pairs of points to find those that are close together. Better implementations
    exist, with some implemented in scikit-learn.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻算法的简单实现相当慢——它检查所有点对以找到彼此靠近的点。存在更好的实现，其中一些已经在scikit-learn中实现。
- en: Scalability with the nearest neighbor
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与最近邻的扩展性
- en: 'URL: [https://github.com/jnothman/scikit-learn/tree/pr2532](https://github.com/jnothman/scikit-learn/tree/pr2532)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://github.com/jnothman/scikit-learn/tree/pr2532](https://github.com/jnothman/scikit-learn/tree/pr2532)
- en: For instance, a kd-tree can be created that speeds up the algorithm (and this
    is already included in scikit-learn).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以创建一个kd树来加快算法（这已经包含在scikit-learn中）。
- en: Another way to speed up this search is to use locality-sensitive hashing,  Locality-Sensitive
    Hashing (LSH). This is a proposed improvement for scikit-learn, and hasn't made
    it into the package at the time of writing. The preceding link gives a development
    branch of scikit-learn that will allow you to test out LSH on a dataset. Read
    through the documentation attached to this branch for details on doing this.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种加快此搜索的方法是使用局部敏感哈希，局部敏感哈希（LSH）。这是对scikit-learn的提议改进，但在写作时尚未包含在包中。前面的链接提供了一个scikit-learn的开发分支，您可以在其中测试数据集上的LSH。阅读此分支附带的文档，了解如何进行此操作。
- en: To install it, clone the repository and follow the instructions to install the
    Bleeding Edge code available at[ http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html) on
    your computer. Remember to use the repository's code rather than the official
    source. I recommend that you use Anaconda for playing around with bleeding-edge
    packages so that they don't interfere with other libraries on your system.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装它，克隆存储库并按照说明在您的计算机上安装可在[http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html)找到的Bleeding
    Edge代码。请记住使用存储库的代码而不是官方源。我建议您使用Anaconda来尝试 bleeding-edge 包，以免与系统上的其他库发生冲突。
- en: More complex pipelines
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更复杂的管道
- en: URL: [http://scikit-learn.org/stable/modules/pipeline.html#featureunion-composite-feature-spaces](http://scikit-learn.org/stable/modules/pipeline.html#featureunion-composite-feature-spaces)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://scikit-learn.org/stable/modules/pipeline.html#featureunion-composite-feature-spaces](http://scikit-learn.org/stable/modules/pipeline.html#featureunion-composite-feature-spaces)
- en: The Pipelines we have used here follow a single stream—the output of one step
    is the input of another step.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的管道遵循单一流程——一个步骤的输出是另一个步骤的输入。
- en: 'Pipelines follow the transformer and estimator interfaces as well—this allows
    us to embed Pipelines within Pipelines. This is a useful construct for very complex
    models, but becomes very powerful when combined with Feature Unions, as shown
    in the preceding link.This allows us to extract multiple types of features at
    a time and then combine them to form a single dataset. For more details, see this
    example: [http://scikit-learn.org/stable/auto_examples/feature_stacker.html](http://scikit-learn.org/stable/auto_examples/feature_stacker.html).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 管道遵循转换器和估计器接口，这使我们能够在管道中嵌入管道。这对于非常复杂的模型来说是一个有用的结构，但当与特征联合（Feature Unions）结合使用时，它变得非常强大，如前一个链接所示。这允许我们一次提取多种类型的特征，然后将它们组合成一个单一的数据集。更多详情，请参阅此示例：[http://scikit-learn.org/stable/auto_examples/feature_stacker.html](http://scikit-learn.org/stable/auto_examples/feature_stacker.html)。
- en: Comparing classifiers
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较分类器
- en: There are lots of classifiers in scikit-learn that are ready to use. The one
    you choose for a particular task is going to be based on a variety of factors.
    You can compare the f1-score to see which method is better, and you can investigate
    the deviation of those scores to see if that result is statistically significant.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 中有许多现成的分类器。您为特定任务选择的分类器将基于各种因素。您可以通过比较 f1 分数来查看哪种方法更好，并且您可以调查这些分数的偏差，以查看结果是否具有统计学意义。
- en: An important factor is that they are trained and tested on the same data—that
    is, the test set for one classifier is the test set for all classifiers. Our use
    of random states allows us to ensure that this is the case—an important factor
    for replicating experiments.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要因素是它们在相同的数据上进行了训练和测试——也就是说，一个分类器的测试集是所有分类器的测试集。我们使用随机状态确保这一点——这是复制实验的一个重要因素。
- en: Automated Learning
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动学习
- en: URL: [http://rhiever.github.io/tpot/](http://rhiever.github.io/tpot/)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: URL: [http://rhiever.github.io/tpot/](http://rhiever.github.io/tpot/)
- en: URL: [https://github.com/automl/auto-sklearn](https://github.com/automl/auto-sklearn)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: URL: [https://github.com/automl/auto-sklearn](https://github.com/automl/auto-sklearn)
- en: It's almost cheating, but these packages will investigate a wide range of possible
    models for your data mining experiments for you. This removes the need to create
    a workflow testing a large number of parameters for a larger number of classifier
    types, and lets you focus on other things, such as feature extract--still critically
    important and not yet automated!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎是一种作弊行为，但这些包会为您调查数据挖掘实验中可能的各种模型。这消除了创建一个工作流程以测试大量参数和分类器类型的需要，并让您可以专注于其他事情，例如特征提取——尽管仍然至关重要，但尚未实现自动化！
- en: The general idea is that you extract your features and pass the resulting matrix
    onto one of these automated classification algorithms (or regression algorithms).
    It does the search for you and even exports the best model for you. In the case
    of TPOT, it even gives you Python code to create the model from scratch without
    having to install TPOT on your server.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通用思路是提取您的特征，然后将结果矩阵传递给这些自动化分类算法（或回归算法）之一。它会为您进行搜索，甚至为您导出最佳模型。在 TPOT 的情况下，它甚至为您提供从头开始创建模型的
    Python 代码，而无需在您的服务器上安装 TPOT。
- en: Predicting Sports Winners with Decision Trees
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树预测体育比赛赢家
- en: URL: [http://pandas.pydata.org/pandas-docs/stable/tutorials.html](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: URL: [http://pandas.pydata.org/pandas-docs/stable/tutorials.html](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)
- en: The pandas library is a great package—anything you normally write to do data
    loading is probably already implemented in pandas. You can learn more about it
    from their tutorial.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库是一个非常好的包——您通常用于数据加载的任何内容，在 pandas 中可能已经实现了。您可以从他们的教程中了解更多信息。
- en: 'There is also a great blog post written by Chris Moffitt that overviews common
    tasks people do in Excel and how to do them in pandas: [http://pbpython.com/excel-pandas-comp.html](http://pbpython.com/excel-pandas-comp.html)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 克里斯·莫菲特（Chris Moffitt）也撰写了一篇优秀的博客文章，概述了人们在 Excel 中执行的一些常见任务以及如何在 pandas 中完成这些任务：[http://pbpython.com/excel-pandas-comp.html](http://pbpython.com/excel-pandas-comp.html)
- en: 'You can also handle large datasets with pandas; see the answer, from user Jeff,
    to this StackOverflow question for an extensive overview of the process: [http://stackoverflow.com/a/14268804/307363](http://stackoverflow.com/a/14268804/307363).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用 pandas 处理大型数据集；请参阅用户 Jeff 的回答，了解 StackOverflow 问题的广泛概述：[http://stackoverflow.com/a/14268804/307363](http://stackoverflow.com/a/14268804/307363)。
- en: Another great tutorial on pandas is written by Brian Connelly: [http://bconnelly.net/2013/10/summarizing-data-in-python-with-pandas/](http://bconnelly.net/2013/10/summarizing-data-in-python-with-pandas/).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: More complex features
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [http://www.basketball-reference.com/teams/ORL/2014_roster_status.html](http://www.basketball-reference.com/teams/ORL/2014_roster_status.html)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Larger exercise!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Sports teams change regularly from game to game. An easy win for a team can
    turn into a difficult game if a couple of the best players are suddenly injured.
    You can get the team rosters from basketball-reference as well. For example, the
    roster for the 2013-2014 season for the Orlando Magic is available at the preceding
    link. Similar data is available for all NBA teams.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Writing code to integrate how much a team changes and using that to add new
    features can improve the model significantly. This task will take quite a bit
    of work though!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Dask
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [http://dask.pydata.org/en/latest/](http://dask.pydata.org/en/latest/)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: If you want to take the features of pandas and increase its scalability, then
    Dask is for you. Dask provides parallelized versions of NumPy arrays, Pandas DataFrames,
    and task scheduling. Often, the interface is *nearly *the same as the original
    NumPy or Pandas versions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Research
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'URL: [https://scholar.google.com.au/](https://scholar.google.com.au/)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Larger exercise!As you might imagine, there has been a lot of work performed
    on predicting NBA games, as well as for all sports. Search "<SPORT> prediction"
    in Google Scholar to find research on predicting your favorite <SPORT>.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Recommending Movies Using Affinity Analysis
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many recommendation-based datasets that are worth investigating, each
    with its own issues.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: New datasets
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Larger exercise!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many recommendation-based datasets that are worth investigating,
    each with its own issues. For example, the Book-Crossing dataset contains more
    than 278,000 users and over a million ratings. Some of these ratings are explicit
    (the user did give a rating), while others are more implicit. The weighting to
    these implicit ratings probably shouldn''t be as high as for explicit ratings.
    The music website www.last.fm has released a great dataset for music recommendation:
    [http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/.](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/.)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also a joke recommendation dataset! See here: [http://eigentaste.berkeley.edu/dataset/.](http://eigentaste.berkeley.edu/dataset/.)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The Eclat algorithm
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [http://www.borgelt.net/eclat.html](http://www.borgelt.net/eclat.html)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: The APriori algorithm implemented here is easily the most famous of the association
    rule mining graphs, but isn't necessarily the best. Eclat is a more modern algorithm
    that can be implemented relatively easily.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative Filtering
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [https://github.com/python-recsys](https://github.com/python-recsys)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://github.com/python-recsys](https://github.com/python-recsys)
- en: For those wanting to got much further with recommendation engines, it is necessary
    to investigate other formats for recommendations, such as collaborative filtering.
    This library provides some background into the algorithms and implementations,
    along with some tutorials. There is also a good overview at [http://blogs.gartner.com/martin-kihn/how-to-build-a-recommender-system-in-python/](http://blogs.gartner.com/martin-kihn/how-to-build-a-recommender-system-in-python/).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些想要在推荐引擎方面走得更远的人来说，调查其他推荐格式是必要的，例如协同过滤。这个库提供了一些关于算法和实现的背景信息，以及一些教程。在[http://blogs.gartner.com/martin-kihn/how-to-build-a-recommender-system-in-python/](http://blogs.gartner.com/martin-kihn/how-to-build-a-recommender-system-in-python/)上也有一个很好的概述。
- en: Extracting Features with Transformers
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Transformer提取特征
- en: Following topics, according to me, are also relevant when it comes to deeper
    understanding of Extracting Features with Transformers
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的看法，以下主题在深入了解使用Transformer提取特征时也是相关的
- en: Adding noise
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加噪声
- en: We covered removing noise to improve features; however, improved performance
    can be obtained for some datasets by adding noise. The reason for this is simple—it
    helps stop overfitting by forcing the classifier to generalize its rules a little
    (although too much noise will make the model too general). Try implementing a
    Transformer that can add a given amount of noise to a dataset. Test that out on
    some of the datasets from UCI ML and see if it improves test-set performance.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了通过去除噪声来提高特征；然而，通过添加噪声，对于某些数据集可以获得更好的性能。原因很简单——这有助于通过迫使分类器稍微泛化其规则来防止过拟合（尽管过多的噪声会使模型过于泛化）。尝试实现一个可以将给定数量的噪声添加到数据集的Transformer。在UCI
    ML的一些数据集上测试它，看看是否提高了测试集的性能。
- en: Vowpal Wabbit
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vowpal Wabbit
- en: URL: [http://hunch.net/~vw/](http://hunch.net/~vw/)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://hunch.net/~vw/](http://hunch.net/~vw/)
- en: Vowpal Wabbit is a great project, providing very fast feature extraction for
    text-based problems. It comes with a Python wrapper, allowing you to call it from
    with Python code. Test it out on large datasets.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Vowpal Wabbit是一个很棒的项目，为基于文本的问题提供了非常快速的特征提取。它附带一个Python包装器，允许您从Python代码中调用它。在大型数据集上测试它。
- en: word2vec
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: word2vec
- en: URL: [https://radimrehurek.com/gensim/models/word2vec.html](https://radimrehurek.com/gensim/models/word2vec.html)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://radimrehurek.com/gensim/models/word2vec.html](https://radimrehurek.com/gensim/models/word2vec.html)
- en: 'Word embeddings are receiving a lot of interest from research and industry,
    for a good reason: they perform very well on many text mining tasks. They are
    a big more complicated than the bag-of-words model and create larger models. Word
    embeddings are great features when you have lots of data and can even help in
    some cases with smaller amounts.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入因其在许多文本挖掘任务中表现良好而受到研究和行业的广泛关注，这是有充分理由的：它们在许多文本挖掘任务中表现非常好。它们比词袋模型复杂得多，并创建更大的模型。当您拥有大量数据时，词嵌入是很好的特征，甚至在某些情况下还可以帮助处理更小的数据量。
- en: Social Media Insight Using Naive Bayes
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯进行社交媒体洞察
- en: Do consider the following points after finishing with Social Media Insight Using
    Native Bayes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成使用朴素贝叶斯进行社交媒体洞察后，请考虑以下要点。
- en: Spam detection
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾邮件检测
- en: URL: [http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)
- en: Using the concepts here, you can create a spam detection method that is able
    to view a social media post and determine whether it is spam or not. Try this
    out by first creating a dataset of spam/not-spam posts, implementing the text
    mining algorithms, and then evaluating them.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这里的概念，您可以创建一个能够查看社交媒体帖子并确定其是否为垃圾邮件的垃圾邮件检测方法。通过首先创建垃圾邮件/非垃圾邮件帖子数据集，实现文本挖掘算法，然后评估它们来尝试这个方法。
- en: One important consideration with spam detection is the false-positive/false-negative
    ratio. Many people would prefer to have a couple of spam messages slip through,
    rather than miss out on a legitimate message because the filter was too aggressive
    in stopping the spam. In order to turn your method for this, you can use a Grid
    Search with the f1-score as the evaluation criteria. See the preceding link for
    information on how to do this.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在垃圾邮件检测中，一个重要的考虑因素是误报/漏报比率。许多人宁愿让几条垃圾邮件消息溜走，也不愿错过一条合法消息，因为过滤器在阻止垃圾邮件时过于激进。为了转换你的方法，你可以使用带有f1分数作为评估标准的网格搜索。参见前面的链接，了解如何进行此操作。
- en: Natural language processing and part-of-speech tagging
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理和词性标注
- en: URL: [http://www.nltk.org/book/ch05.html](http://www.nltk.org/book/ch05.html)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://www.nltk.org/book/ch05.html](http://www.nltk.org/book/ch05.html)
- en: The techniques we used here are quite lightweight compared to some of the linguistic
    models employed in other areas. For example, part-of-speech tagging can help disambiguate
    word forms, allowing for higher accuracy. It comes with NLTK.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的技术与其他领域使用的某些语言模型相比相当轻量级。例如，词性标注可以帮助消除词形歧义，从而提高准确性。它随NLTK提供。
- en: Discovering Accounts to Follow Using Graph Mining
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图挖掘发现要关注的账户
- en: Do give the following a read when done with the chapter.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成本章后，请务必阅读以下内容。
- en: More complex algorithms
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更复杂的算法
- en: 'URL: [https://www.cs.cornell.edu/home/kleinber/link-pred.pdf](https://www.cs.cornell.edu/home/kleinber/link-pred.pdf)Larger
    exercise!'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://www.cs.cornell.edu/home/kleinber/link-pred.pdf](https://www.cs.cornell.edu/home/kleinber/link-pred.pdf)更大的练习！
- en: There has been extensive research on predicting links in graphs, including for
    social networks. For instance, David Liben-Nowell and Jon Kleinberg published
    a paper on this topic that would serve as a great place for more complex algorithms,
    linked previously.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测图中的链接方面已经进行了广泛的研究，包括社交网络。例如，David Liben-Nowell和Jon Kleinberg发表了关于这个主题的论文，这将是一个更复杂算法的好起点，之前已经链接过。
- en: NetworkX
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NetworkX
- en: URL: [https://networkx.github.io/](https://networkx.github.io/)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://networkx.github.io/](https://networkx.github.io/)
- en: If you are going to be using graphs and networks more, going in-depth into the
    NetworkX package is well worth your time—the visualization options are great and
    the algorithms are well implemented. Another library called SNAP is also available
    with Python bindings, at [http://snap.stanford.edu/snappy/index.html](http://snap.stanford.edu/snappy/index.html).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算更多地使用图表和网络，深入研究NetworkX包是非常值得你花时间的——可视化选项很棒，算法实现得很好。还有一个名为SNAP的库，它也提供了Python绑定，网址为[http://snap.stanford.edu/snappy/index.html](http://snap.stanford.edu/snappy/index.html)。
- en: Beating CAPTCHAs with Neural Networks
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络击败CAPTCHA
- en: 'You may find the following topics interesting as well:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还会对以下主题感兴趣：
- en: Better (worse?) CAPTCHAs
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更好（更糟？）的CAPTCHA
- en: URL: [http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html](http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html](http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html)
- en: Larger exercise!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的练习！
- en: 'The CAPTCHAs we beat in this example were not as complex as those normally
    used today. You can create more complex variants using a number of techniques
    as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中我们击败的CAPTCHA并不像今天通常使用的那么复杂。你可以使用以下多种技术创建更复杂的变体：
- en: Applying different transformations such as the ones in scikit-image (see the
    preceding link)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用不同的转换，如scikit-image中的那些（见前一个链接）
- en: Using different colors and colors that don't translate well to grayscale
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同的颜色和难以转换为灰度的颜色
- en: 'Adding lines or other shapes to the image: [http://scikit-image.org/docs/dev/api/skimage.draw.html](http://scikit-image.org/docs/dev/api/skimage.draw.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向图像添加线条或其他形状：[http://scikit-image.org/docs/dev/api/skimage.draw.html](http://scikit-image.org/docs/dev/api/skimage.draw.html)
- en: Deeper networks
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度网络
- en: These techniques will probably fool our current implementation, so improvements
    will need to be made to make the method better. Try some of the deeper networks
    we used. Larger networks need more data, though, so you will probably need to
    generate more than the few thousand samples we did here in order to get good performance.
    Generating these datasets is a good candidate for parallelization—lots of small
    tasks that can be performed independently.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术可能会欺骗我们当前的实现，因此需要改进以使方法更好。尝试我们使用的深度网络。然而，更大的网络需要更多的数据，所以你可能需要生成比这里所做的那几千个样本更多的样本才能获得良好的性能。生成这些数据集是并行化的好候选——有很多可以独立执行的小任务。
- en: A good idea for increasing your dataset size, which applies to other datasets
    as well, is to create variants of existing images. Flip images upside down, crop
    them weirdly, add noise, blur the image, make some random pixels black and so
    on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 增加数据集大小的良好方法，同样适用于其他数据集，是创建现有图像的变体。将图像上下颠倒，奇怪地裁剪，添加噪声，模糊图像，将一些随机像素变为黑色等等。
- en: Reinforcement learning
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: URL: [http://pybrain.org/docs/tutorial/reinforcement-learning.html](http://pybrain.org/docs/tutorial/reinforcement-learning.html)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[http://pybrain.org/docs/tutorial/reinforcement-learning.html](http://pybrain.org/docs/tutorial/reinforcement-learning.html)
- en: Reinforcement learning is gaining traction as the next big thing in data mining—although
    it has been around a long time! PyBrain has some reinforcement learning algorithms
    that are worth checking out with this dataset (and others!).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习正在成为数据挖掘下一个大趋势——尽管它已经存在很长时间了！PyBrain有一些强化学习算法，值得用这个数据集（以及其他数据集）检查。
- en: Authorship Attribution
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作者归属
- en: When it comes to Authorship Attribution do give the following topics a read.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到作者归属时，确实应该阅读以下主题。
- en: Increasing the sample size
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增加样本量
- en: The Enron application we used ended up using just a portion of the overall dataset.
    There is lots more data available in this dataset. Increasing the number of authors
    will likely lead to a drop in accuracy, but it is possible to boost the accuracy
    further than was achieved here, using similar methods. Using a Grid Search, try
    different values for n-grams and different parameters for support vector machines,
    in order to get better performance on a larger number of authors.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的安然应用最终只使用了整体数据集的一部分。这个数据集中还有大量其他数据可用。增加作者数量可能会降低准确性，但使用类似的方法，有可能进一步提高准确性，超过这里所达到的水平。使用网格搜索，尝试不同的n-gram值和不同的支持向量机参数，以在更多作者上获得更好的性能。
- en: Blogs dataset
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 博客数据集
- en: The dataset used, provides authorship-based classes (each blogger ID is a separate
    author). This dataset can be tested using this kind of method as well. In addition,
    there are the other classes of gender, age, industry, and star sign that can be
    tested—are authorship-based methods good for these classification tasks?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的这个数据集，提供了基于作者的分类（每个博客ID代表一个单独的作者）。这个数据集也可以使用这种方法进行测试。此外，还有其他可以测试的类别，如性别、年龄、行业和星座——基于作者的方法对这些分类任务有效吗？
- en: Local n-grams
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地n-gram
- en: URL: [https://github.com/robertlayton/authorship_tutorials/blob/master/LNGTutorial.ipynb](https://github.com/robertlayton/authorship_tutorials/blob/master/LNGTutorial.ipynb)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: URL：[https://github.com/robertlayton/authorship_tutorials/blob/master/LNGTutorial.ipynb](https://github.com/robertlayton/authorship_tutorials/blob/master/LNGTutorial.ipynb)
- en: Another form of classifier is local n-gram, which involves choosing the best
    features per-author, not globally for the entire dataset. I wrote a tutorial on
    using local n-grams for authorship attribution, available at the preceding link.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种分类器形式是本地n-gram，它涉及为每个作者选择最佳特征，而不是为整个数据集全局选择。我编写了一个关于使用本地n-gram进行作者归属的教程，可在前面的链接中找到。
- en: Clustering News Articles
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新闻文章聚类
- en: It won't hurt to read a little on the following topics
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 了解一下以下主题不会有任何坏处
- en: Clustering Evaluation
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类评估
- en: The evaluation of clustering algorithms is a difficult problem—on the one hand,
    we can sort of tell what good clusters look like; on the other hand, if we really
    know that, we should label some instances and use a supervised classifier! Much
    has been written on this topic. One slideshow on the topic that is a good introduction
    to the challenges follows: [http://www.cs.kent.edu/~jin/DM08/ClusterValidation.pdf](http://www.cs.kent.edu/~jin/DM08/ClusterValidation.pdf).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法的评估是一个难题——一方面，我们可以说出好的聚类看起来是什么样子；另一方面，如果我们真的知道这一点，我们应该标记一些实例并使用监督分类器！关于这个主题已经有很多论述。以下是一个关于这个主题的幻灯片，它是一个很好的挑战介绍：[http://www.cs.kent.edu/~jin/DM08/ClusterValidation.pdf](http://www.cs.kent.edu/~jin/DM08/ClusterValidation.pdf)。
- en: 'In addition, a very comprehensive (although now a little dated) paper on this
    topic is here: [http://web.itu.edu.tr/sgunduz/courses/verimaden/paper/validity_survey.pdf.](http://web.itu.edu.tr/sgunduz/courses/verimaden/paper/validity_survey.pdf.)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这里有一篇关于这个主题的非常全面的（尽管现在有点过时）论文：[http://web.itu.edu.tr/sgunduz/courses/verimaden/paper/validity_survey.pdf.](http://web.itu.edu.tr/sgunduz/courses/verimaden/paper/validity_survey.pdf.)
- en: 'The scikit-learn package does implement a number of the metrics described in
    those links, with an overview here: [http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn包实现了那些链接中描述的许多度量，这里有一个概述：[http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)。
- en: Using some of these, you can start evaluating which parameters need to be used
    for better clusterings. Using a Grid Search, we can find parameters that maximize
    a metric—just like in classification.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用其中的一些，你可以开始评估哪些参数需要使用以获得更好的聚类。使用网格搜索，我们可以找到最大化度量的参数——就像在分类中一样。
- en: Temporal analysis
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间分析
- en: Larger exercise!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的练习！
- en: The code we developed here can be rerun over many months. By adding some tags
    to each cluster, you can track which topics stay active over time, getting a longitudinal
    viewpoint of what is being discussed in the world news. To compare the clusters,
    consider a metric such as the adjusted mutual information score, which was linked
    to the scikit-learn documentation earlier. See how the clusters change after one
    month, two months, six months, and a year.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里开发的代码可以在数月内重新运行。通过给每个聚类添加一些标签，您可以跟踪哪些主题随着时间的推移保持活跃，从而获得对世界新闻中讨论内容的纵向视角。为了比较聚类，可以考虑一个指标，例如之前提到的调整互信息得分。看看聚类在一个月后、两个月后、六个月后和一年后的变化。
- en: Real-time clusterings
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时聚类
- en: The k-means algorithm can be iteratively trained and updated over time, rather
    than discrete analyses at given time frames. Cluster movement can be tracked in
    a number of ways—for instance, you can track which words are popular in each cluster
    and how much the centroids move per day. Keep the API limits in mind—you probably
    only need to do one check every few hours to keep your algorithm up-to-date.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法可以在给定时间框架的离散分析之外，随着时间的推移迭代训练和更新。可以通过多种方式跟踪聚类移动——例如，您可以跟踪每个聚类中哪些单词流行，以及每天质心移动了多少。请记住API限制——您可能只需要每隔几个小时检查一次，以保持您的算法更新。
- en: Classifying Objects in Images Using Deep Learning
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习在图像中分类对象
- en: The following topics are also important when deeper study into Classifying objects
    is considered.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑更深入地研究分类对象时，以下主题也非常重要。
- en: Mahotas
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mahotas
- en: 'URL: [http://luispedro.org/software/mahotas/](http://luispedro.org/software/mahotas/)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 'URL: [http://luispedro.org/software/mahotas/](http://luispedro.org/software/mahotas/)'
- en: Another package for image processing is Mahotas, including better and more complex
    image processing techniques that can help achieve better accuracy, although they
    may come at a high computational cost. However, many image processing tasks are
    good candidates for parallelization. More techniques on image classification can
    be found in the research literature, with this survey paper as a good start: [http://ijarcce.com/upload/january/22-A%20Survey%20on%20Image%20Classification.pdf](http://ijarcce.com/upload/january/22-A%20Survey%20on%20Image%20Classification.pdf).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个图像处理包是Mahotas，包括更好、更复杂的图像处理技术，可以帮助实现更高的精度，尽管它们可能带来较高的计算成本。然而，许多图像处理任务都是并行化的良好候选。更多关于图像分类的技术可以在研究文献中找到，这篇综述论文是一个很好的起点：[http://ijarcce.com/upload/january/22-A%20Survey%20on%20Image%20Classification.pdf](http://ijarcce.com/upload/january/22-A%20Survey%20on%20Image%20Classification.pdf)。
- en: Other image datasets are available at [http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 其他图像数据集可在[http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)找到。
- en: There are many datasets of images available from a number of academic and industry-based
    sources. The linked website lists a bunch of datasets and some of the best algorithms
    to use on them. Implementing some of the better algorithms will require significant
    amounts of custom code, but the payoff can be well worth the pain.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 许多学术和基于行业的来源提供了大量的图像数据集。链接的网站列出了许多数据集和一些在它们上使用的最佳算法。实现一些较好的算法可能需要大量的自定义代码，但回报可能非常值得。
- en: Magenta
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Magenta
- en: URL: [https://github.com/tensorflow/magenta/tree/master/magenta/reviews](https://github.com/tensorflow/magenta/tree/master/magenta/reviews)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 'URL: [https://github.com/tensorflow/magenta/tree/master/magenta/reviews](https://github.com/tensorflow/magenta/tree/master/magenta/reviews)'
- en: This repository contains a few high-quality deep learning papers that are worth
    reading, along with in-depth reviews of the paper and their techniques. If you
    want to go deep into deep learning, check out these papers first before expanding
    outwards.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此存储库包含一些值得阅读的高质量深度学习论文，以及论文及其技术的深入评论。如果您想深入研究深度学习，请首先查看这些论文，然后再向外扩展。
- en: Working with Big Data
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理大数据
- en: The following resources on Big Data would be helpful
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下关于大数据的资源可能会有所帮助
- en: Courses on Hadoop
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop课程
- en: Both Yahoo and Google have great tutorials on Hadoop, which go from beginner
    to quite advanced levels. They don't specifically address using Python, but learning
    the Hadoop concepts and then applying them in Pydoop or a similar library can
    yield great results.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Yahoo和Google都提供了关于Hadoop的优秀教程，从入门到相当高级的水平。它们没有专门针对Python的使用，但学习Hadoop概念然后在Pydoop或类似库中应用它们可以产生很好的效果。
- en: 'Yahoo''s tutorial: [https://developer.yahoo.com/hadoop/tutorial/](https://developer.yahoo.com/hadoop/tutorial/)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Google''s tutorial: [https://cloud.google.com/hadoop/what-is-hadoop](https://cloud.google.com/hadoop/what-is-hadoop)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Pydoop
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [http://crs4.github.io/pydoop/tutorial/index.html](http://crs4.github.io/pydoop/tutorial/index.html)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Pydoop is a python library to run Hadoop jobs. Pydoop also works with HDFS,
    the Hadoop File System, although you can get that functionality in mrjob as well.
    Pydoop will give you a bit more control over running some jobs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation engine
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building a large recommendation engine is a good test of your Big data skills.
    A great blog post by Mark Litwintschik covers an engine using Apache Spark, a
    big data technology: [http://tech.marksblogg.com/recommendation-engine-spark-python.html](http://tech.marksblogg.com/recommendation-engine-spark-python.html)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: W.I.L.L
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'URL: [https://github.com/ironman5366/W.I.L.L](https://github.com/ironman5366/W.I.L.L)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Very large project!
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: This open source personal assistant can be your next JARVIS from Iron Man. You
    can add to this project using data mining techniques to allow it to learn to do
    some tasks that you need to do regularly. This is not easy, but the potential
    productivity gains are worth it.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: More resources
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following would serve as a really good resource for additional information:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Kaggle competitions
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [www.kaggle.com/](http://www.kaggle.com/)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Kaggle runs data mining competitions regularly, often with monetary prizes.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Testing your skills on Kaggle competitions is a fast and great way to learn
    to work with real-world data mining problems. The forums are nice and share environments—often,
    you will see code released for a top-10 entry during the competition!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Coursera
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: URL: [www.coursera.org](http://www.coursera.org)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'Coursera contains many courses on data mining and data science. Many of the
    courses are specialized, such as big data and image processing. A great general
    one to start with is Andrew Ng''s famous course: [https://www.coursera.org/learn/machine-learning/](https://www.coursera.org/learn/machine-learning/).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: It is a bit more advanced than this and would be a great next step for interested
    readers.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'For neural networks, check out this course: [https://www.coursera.org/course/neuralnets](https://www.coursera.org/course/neuralnets).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: If you complete all of these, try out the course on probabilistic graphical
    models at [https://www.coursera.org/course/pgm](https://www.coursera.org/course/pgm).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
