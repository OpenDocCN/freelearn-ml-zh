- en: Chapter 7. Detecting and Recognizing Objects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 检测和识别对象
- en: This chapter will introduce the concept of detecting and recognizing objects,
    which is one of the most common challenges in computer vision. You've come this
    far in the book, so at this stage, you're wondering how far are you from mounting
    a computer in your car that will give you information about cars and people surrounding
    you through the use of a camera. Well, You're not too far from your goal, actually.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍检测和识别对象的概念，这是计算机视觉中最常见的挑战之一。你在本书中已经走得很远了，所以在这个阶段，你可能想知道你离在车内安装一个通过摄像头使用信息来告诉你周围汽车和人的位置还有多远。实际上，你离你的目标并不远。
- en: In this chapter, we will expand on the concept of object detection, which we
    initially explored when talking about recognizing faces, and adapt it to all sorts
    of real-life objects, not just faces.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展我们在讨论识别人脸时最初探讨的目标检测概念，并将其应用于各种现实生活中的对象，而不仅仅是人脸。
- en: Object detection and recognition techniques
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测和识别技术
- en: 'We made a distinction in [Chapter 5](part0043.xhtml#aid-190861 "Chapter 5. Detecting
    and Recognizing Faces"), *Detecting and Recognizing Faces*, which we''ll reiterate
    for clarity: detecting an object is the ability of a program to determine if a
    certain region of an image contains an unidentified object, and recognizing is
    the ability of a program to identify this object. Recognizing normally only occurs
    in areas of interest where an object has been detected, for example, we have attempted
    to recognize faces on the areas of an image that contained a face in the first
    place.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第5章](part0043.xhtml#aid-190861 "第5章. 检测和识别人脸")中区分了“检测和识别人脸”，我们将为了清晰起见重申：检测一个对象是程序确定图像的某个区域是否包含未识别对象的能力，而识别是程序识别此对象的能力。通常只在检测到对象的感兴趣区域中发生识别，例如，我们尝试在最初包含人脸的图像区域识别人脸。
- en: 'When it comes to recognizing and detecting objects, there are a number of techniques
    used in computer vision, which we''ll be examining:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到识别和检测对象时，计算机视觉中使用了多种技术，我们将对其进行探讨：
- en: Histogram of Oriented Gradients
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方向梯度直方图
- en: Image pyramids
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像金字塔
- en: Sliding windows
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滑动窗口
- en: Unlike feature detection algorithms, these are not mutually exclusive techniques,
    rather, they are complimentary. You can perform a **Histogram of Oriented Gradients**
    (**HOG**) while applying the sliding windows technique.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与特征检测算法不同，这些技术不是相互排斥的，而是互补的。你可以在应用滑动窗口技术的同时执行**方向梯度直方图**（**HOG**）。
- en: So, let's take a look at HOG first and understand what it is.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先看看HOG，并了解它是什么。
- en: HOG descriptors
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HOG描述符
- en: HOG is a feature descriptor, so it belongs to the same family of algorithms,
    such as SIFT, SURF, and ORB.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: HOG是一种特征描述符，因此它属于与SIFT、SURF和ORB相同的算法家族。
- en: It is used in image and video processing to detect objects. Its internal mechanism
    is really clever; an image is divided into portions and a gradient for each portion
    is calculated. We've observed a similar approach when we talked about face recognition
    through LBPH.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 它用于图像和视频处理以检测对象。其内部机制非常巧妙；图像被分成部分，并为每个部分计算梯度。当我们谈论通过LBPH进行人脸识别时，我们观察到了类似的方法。
- en: HOG, however, calculates histograms that are not based on color values, rather,
    they are based on gradients. As HOG is a feature descriptor, it is capable of
    delivering the type of information that is vital for feature matching and object
    detection/recognition.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，HOG计算的是不基于颜色值的直方图，而是基于梯度。由于HOG是一种特征描述符，它能够提供对特征匹配和目标检测/识别至关重要的信息。
- en: 'Before diving into the technical details of how HOG works, let''s first take
    a look at how HOG *sees* the world; here is an image of a truck:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨HOG的工作原理的技术细节之前，让我们首先看看HOG是如何“看”世界的；这是一张卡车的图片：
- en: '![HOG descriptors](img/image00231.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![HOG描述符](img/image00231.jpeg)'
- en: 'This is its HOG version:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的HOG版本：
- en: '![HOG descriptors](img/image00232.jpeg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![HOG描述符](img/image00232.jpeg)'
- en: You can easily recognize the wheels and the main structure of the vehicle. So,
    what is HOG *seeing*? First of all, you can see how the image is divided into
    cells; these are 16x16 pixels cells. Each cell contains a visual representation
    of the calculated gradients of color in eight directions (N, NW, W, SW, S, SE,
    E, and NE).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松地识别车轮和车辆的主要结构。那么，HOG“看到”的是什么？首先，你可以看到图像是如何被分成单元格的；这些是16x16像素的单元格。每个单元格包含八个方向（N、NW、W、SW、S、SE、E和NE）计算出的颜色梯度的视觉表示。
- en: 'These eight values contained in each cell are the famous histograms. Therefore,
    a single cell gets a unique *signature*, which you can mentally visualize to be
    somewhat like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![HOG descriptors](img/image00233.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: The extrapolation of histograms into descriptors is quite a complex process.
    First, local histograms for each cell are calculated. The cells are grouped into
    larger regions called blocks. These blocks can be made of any number of cells,
    but Dalal and Triggs found that 2x2 cell blocks yielded the best results when
    performing people detection. A block-wide vector is created so that it can be
    normalized, accounting for variations in illumination and shadowing (a single
    cell is too small a region to detect such variations). This improves the accuracy
    of detection as it reduces the illumination and shadowing difference between the
    sample and the block being examined.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Simply comparing cells in two images would not work unless the images are identical
    (both in terms of size and data).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main problems to resolve:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Location
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scale issue
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Imagine, for example, if your sample was a detail (say, a bike) extrapolated
    from a larger image, and you're trying to compare the two pictures. You would
    not obtain the same gradient signatures and the detection would fail (even though
    the bike is in both pictures).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: The location issue
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once we''ve resolved the scale problem, we have another obstacle in our path:
    a potentially detectable object can be anywhere in the image, so we need to scan
    the entire image in portions to make sure we can identify areas of interest, and
    within these areas, try to detect objects. Even if a sample image and object in
    the image are of identical size, there needs to be a way to instruct OpenCV to
    locate this object. So, the rest of the image is discarded and a comparison is
    made on potentially matching regions.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: To obviate these problems, we need to familiarize ourselves with the concepts
    of image pyramid and sliding windows.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Image pyramid
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many of the algorithms used in computer vision utilize a concept called **pyramid**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'An image pyramid is a multiscale representation of an image. This diagram should
    help you understand this concept:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![Image pyramid](img/image00234.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: A multiscale representation of an image, or an image pyramid, helps you resolve
    the problem of detecting objects at different scales. The importance of this concept
    is easily explained through real-life hard facts, such as it is extremely unlikely
    that an object will appear in an image at the exact scale it appeared in our sample
    image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, you will learn that object classifiers (utilities that allow you to
    detect objects in OpenCV) need *training*, and this training is provided through
    image databases made up of positive matches and negative matches. Among the positives,
    it is again unlikely that the object we want to identify will appear in the same
    scale throughout the training dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: We've got it, Joe. We need to take scale out of the equation, so now let's examine
    how an image pyramid is built.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们明白了，乔。我们需要从等式中去除比例，现在让我们看看图像金字塔是如何构建的。
- en: 'An image pyramid is built through the following process:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图像金字塔是通过以下过程构建的：
- en: Take an image.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拿一个图像来说。
- en: Resize (smaller) the image using an arbitrary scale parameter.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用任意的尺度参数调整图像的大小（更小）。
- en: Smoothen the image (using Gaussian blurring).
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平滑图像（使用高斯模糊）。
- en: If the image is larger than an arbitrary minimum size, repeat the process from
    step 1.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果图像大于一个任意的最小尺寸，则重复步骤1。
- en: Despite exploring image pyramids, scale ratio, and minimum sizes only at this
    stage of the book, you've already dealt with them. If you recall [Chapter 5](part0043.xhtml#aid-190861
    "Chapter 5. Detecting and Recognizing Faces"), *Detecting and Recognizing Faces*,
    we used the `detectMultiScale` method of the `CascadeClassifier` object.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在本书的这一阶段只探讨了图像金字塔、尺度比和最小尺寸，但你已经处理了它们。如果你还记得[第5章](part0043.xhtml#aid-190861
    "第5章. 识别和检测人脸")，*识别和检测人脸*，我们使用了`CascadeClassifier`对象的`detectMultiScale`方法。
- en: Straight away, `detectMultiScale` doesn't sound so obscure anymore; in fact,
    it has become self-explanatory. The cascade classifier object attempts at detecting
    an object at different scales of an input image. The second piece of information
    that should become much clearer is the `scaleFactor` parameter of the `detectMultiScale()`
    method. This parameter represents the ratio at which the image will be resampled
    to a smaller size at each step of the pyramid.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 立刻，`detectMultiScale`不再那么晦涩难懂了；事实上，它已经变得不言自明。级联分类器对象试图在输入图像的不同尺度上检测对象。第二件应该变得非常清楚的信息是`detectMultiScale()`方法的`scaleFactor`参数。此参数表示图像在金字塔的每一步中将被重采样到较小尺寸的比例。
- en: The smaller the `scaleFactor` parameter, the more layers in the pyramid, and
    the slower and more computationally intensive the operation will be, although—to
    an extent—more accurate in results.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`scaleFactor`参数越小，金字塔的层数越多，操作的速度越慢，计算量越大，尽管在一定程度上结果更准确。'
- en: So, by now, you should have an understanding of what an image pyramid is, and
    why it is used in computer vision. Let's now move on to sliding windows.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，到目前为止，你应该已经理解了图像金字塔是什么，以及为什么它在计算机视觉中使用。现在让我们继续讨论滑动窗口。
- en: Sliding windows
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 滑动窗口
- en: '**Sliding windows** is a technique used in computer vision that consists of
    examining the shifting portions of an image (sliding windows) and operating detection
    on those using image pyramids. This is done so that an object can be detected
    at a multiscale level.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**滑动窗口**是计算机视觉中的一种技术，它包括检查图像的移动部分（滑动窗口）并在这些部分上使用图像金字塔进行检测。这样做是为了在多尺度级别上检测到对象。'
- en: Sliding windows resolves location issues by scanning smaller regions of a larger
    image, and then repeating the scanning on different scales of the same image.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 滑动窗口通过扫描较大图像的较小区域来解决位置问题，然后在同一图像的不同尺度上重复扫描。
- en: With this technique, each image is decomposed into portions, which allows discarding
    portions that are unlikely to contain objects, while the remaining portions are
    classified.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术，每个图像被分解成部分，这允许丢弃不太可能包含对象的区域，而剩余的部分则被分类。
- en: 'There is one problem that emerges with this approach, though: **overlapping
    regions**.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法有一个问题出现：**重叠区域**。
- en: Let's expand a little bit on this concept to clarify the nature of the problem.
    Say, you're operating face detection on an image and are using sliding windows.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微扩展一下这个概念，以阐明问题的本质。比如说，你正在对图像进行人脸检测，并使用滑动窗口。
- en: Each window slides off a few pixels at a time, which means that a sliding window
    happens to be a positive match for the same face in four different positions.
    Naturally, we don't want to report four matches, rather only one; furthermore,
    we're not interested in the portion of the image with a good score, but simply
    in the portion with the highest score.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 每个窗口每次滑动几个像素，这意味着滑动窗口恰好是同一张脸在四个不同位置的正匹配。自然地，我们不想报告四个匹配，而只想报告一个；此外，我们对具有良好分数的图像部分不感兴趣，而只是对具有最高分数的部分感兴趣。
- en: 'Here''s where non-maximum suppression comes into play: given a set of overlapping
    regions, we can suppress all the regions that are not classified with the maximum
    score.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是非极大值抑制发挥作用的地方：给定一组重叠区域，我们可以抑制所有未被赋予最大分数的区域。
- en: Non-maximum (or non-maxima) suppression
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非极大值（或非极大值）抑制
- en: Non-maximum (or non-maxima) suppression is a technique that suppresses all the
    results that relate to the same area of an image, which are not the maximum score
    for a particular area. This is because similarly colocated windows tend to have
    higher scores and overlapping areas are significant, but we are only interested
    in the window with the best result, and discarding overlapping windows with lower
    scores.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 非极大值抑制（或非极大值）是一种技术，它会抑制与图像中同一区域相关的所有结果，这些结果不是特定区域的最高得分。这是因为类似位置的对齐窗口往往具有更高的得分，并且重叠区域是显著的，但我们只对具有最佳结果的窗口感兴趣，并丢弃得分较低的重叠窗口。
- en: When examining an image with sliding windows, you want to make sure to retain
    the best window of a bunch of windows, all overlapping around the same subject.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用滑动窗口检查图像时，你想要确保保留围绕同一主题的一组窗口中的最佳窗口。
- en: To do this, you determine that all the windows with more than a threshold, *x*,
    in common will be thrown into the non-maximum suppression operation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，你确定所有与阈值*x*以上共有窗口都将被投入非极大值抑制操作。
- en: This is quite complex, but it's also not the end of this process. Remember the
    image pyramid? We're scanning the image at smaller scales iteratively to make
    sure to detect objects in different scales.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当复杂，但这还不是这个过程的结束。还记得图像金字塔吗？我们正在迭代地以较小的尺度扫描图像，以确保检测到不同尺度的对象。
- en: This means that you will obtain a series of windows at different scales, then,
    compute the size of a window obtained in a smaller scale as if it were detected
    in the original scale, and, finally, throw this window into the original mix.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你将获得一系列不同尺度的窗口，然后，将较小尺度获得的窗口大小计算为在原始尺度上检测到的，最后，将这个窗口投入原始混合中。
- en: It does sound a bit complex. Thankfully, we're not the first to come across
    this problem, which has been resolved in several ways. The fastest algorithm in
    my experience was implemented by Dr. Tomasz Malisiewicz at [http://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html](http://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html).
    The example is in MATLAB, but in the application example, we will obviously use
    a Python version of it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来有点复杂。幸运的是，我们不是第一个遇到这个问题的人，这个问题已经以几种方式得到了解决。在我经验中，最快的算法是由Tomasz Malisiewicz博士在[http://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html](http://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html)实现的。示例是用MATLAB编写的，但在应用示例中，我们显然将使用它的Python版本。
- en: 'The general approach behind non-maximum suppression is as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 非极大值抑制背后的通用方法如下：
- en: Once an image pyramid has been constructed, scan the image with the sliding
    window approach for object detection.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦构建了图像金字塔，就使用滑动窗口方法扫描图像以进行对象检测。
- en: Collect all the current windows that have returned a positive result (beyond
    a certain arbitrary threshold), and take a window, `W`, with the highest response.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集所有返回了正结果（超过某个任意阈值）的当前窗口，并取一个响应最高的窗口`W`。
- en: Eliminate all windows that overlap `W` significantly.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消除与`W`显著重叠的所有窗口。
- en: Move on to the next window with the highest response and repeat the process
    for the current scale.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将窗口移动到下一个响应最高的窗口，并重复当前尺度的过程。
- en: When this process is complete, move up the next scale in the image pyramid and
    repeat the preceding process. To make sure windows are correctly represented at
    the end of the entire non-maximum suppression process, be sure to compute the
    window size in relation to the original size of the image (for example, if you
    detect a window at 50 percent scale of the original size in the pyramid, the detected
    window will actually be four times the size in the original image).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个过程完成时，将图像金字塔中的下一个尺度向上移动并重复前面的过程。为了确保窗口在整个非极大值抑制过程结束时得到正确表示，务必计算与图像原始大小相关的窗口大小（例如，如果在金字塔中检测到原始大小的50%的窗口，则检测到的窗口实际上在原始图像中将是四倍大）。
- en: At the end of this process, you will have a set of maximum scored windows. Optionally,
    you can check for windows that are entirely contained in other windows (like we
    did for the people detection process at the beginning of the chapter) and eliminate
    those.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程结束时，你将有一组得分最高的窗口。可选地，你可以检查完全包含在其他窗口中的窗口（就像我们在本章开头进行的人体检测过程那样）并消除那些窗口。
- en: Now, how do we determine the score of a window? We need a classification system
    that determines whether a certain feature is present or not and a confidence score
    for this classification. This is where **support vector machines** (**SVM**) comes
    into play.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何确定窗口的分数？我们需要一个分类系统，该系统确定某个特征是否存在，并为这个分类提供一个置信度分数。这就是**支持向量机**（**SVM**）发挥作用的地方。
- en: Support vector machines
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持向量机
- en: 'Explaining in detail what an SVM is and does is beyond the scope of this book,
    but suffice it to say, SVM is an algorithm that—given labeled training data–enables
    the classification of this data by outputting an optimal *hyperplane*, which,
    in plain English, is the optimal plane that divides differently classified data.
    A visual representation will help you understand this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 详细解释SVM是什么以及它做什么超出了本书的范围，但简单来说，SVM是一种算法——给定标记的训练数据，它可以通过输出一个最优的*超平面*来使这些数据分类，用简单的话说，这就是一个最优的平面，它将不同分类的数据分开。一个视觉表示将有助于你理解这一点：
- en: '![Support vector machines](img/image00235.jpeg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![支持向量机](img/image00235.jpeg)'
- en: Why is it so helpful in computer vision and object detection in particular?
    This is due to the fact that finding the optimal division line between pixels
    that belong to an object and those that don't is a vital component of object detection.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么它在计算机视觉和特别是对象检测中如此有用？这是因为找到属于对象和不属于对象的像素之间的最优分割线是对象检测的一个关键组成部分。
- en: The SVM model has been around since the early 1960s; however, the current form
    of its implementation originates in a 1995 paper by Corinna Cortes and Vadimir
    Vapnik, which is available at [http://link.springer.com/article/10.1007/BF00994018](http://link.springer.com/article/10.1007/BF00994018).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SVM模型自20世纪60年代初以来一直存在；然而，其当前形式的实现起源于Corinna Cortes和Vadimir Vapnik于1995年发表的一篇论文，该论文可在[http://link.springer.com/article/10.1007/BF00994018](http://link.springer.com/article/10.1007/BF00994018)找到。
- en: Now that we have a good understanding of the concepts involved in object detection,
    we can start looking at a few examples. We will start from built-in functions
    and evolve into training our own custom object detectors.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经很好地理解了对象检测中涉及的概念，我们可以开始查看一些示例。我们将从内置函数开始，然后发展到训练我们自己的自定义对象检测器。
- en: People detection
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人体检测
- en: OpenCV comes with `HOGDescriptor` that performs people detection.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV自带`HOGDescriptor`，它可以进行人体检测。
- en: 'Here''s a pretty straightforward example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个相当直接的例子：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After the usual imports, we define two very simple functions: `is_inside` and
    `draw_person`, which perform two minimal tasks, namely, determining whether a
    rectangle is fully contained in another rectangle, and drawing rectangles around
    detected people.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规导入之后，我们定义了两个非常简单的函数：`is_inside`和`draw_person`，它们执行两个最小任务，即确定一个矩形是否完全包含在另一个矩形内，以及在检测到的人周围绘制矩形。
- en: 'We then load the image and create `HOGDescriptor` through a very simple and
    self-explanatory code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们加载图像并通过一个非常简单且易于理解的代码创建`HOGDescriptor`：
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After this, we specify that `HOGDescriptor` will use a default people detector.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们指定`HOGDescriptor`将使用默认的人体检测器。
- en: This is done through the `setSVMDetector()` method, which—after our introduction
    to SVM—sounds less obscure than it may have if we hadn't introduced SVMs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过`setSVMDetector()`方法实现的，在我们介绍了SVM之后，它听起来可能没有我们未介绍SVM时那么晦涩。
- en: Next, we apply `detectMultiScale` on the loaded image. Interestingly, unlike
    all the face detection algorithms, we don't need to convert the original image
    to grayscale before applying any form of object detection.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在加载的图像上应用`detectMultiScale`。有趣的是，与所有的人脸检测算法不同，我们在应用任何形式的对象检测之前不需要将原始图像转换为灰度。
- en: 'The detection method will return an array of rectangles, which would be a good
    enough source of information for us to start drawing shapes on the image. If we
    did this, however, you would notice something strange: some of the rectangles
    are entirely contained in other rectangles. This clearly indicates an error in
    detection, and we can safely assume that a rectangle entirely inside another one
    can be discarded.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 检测方法将返回一个矩形数组，这将是我们开始在图像上绘制形状的良好信息来源。如果我们这样做，然而，你会注意到一些奇怪的事情：一些矩形完全包含在其他矩形内。这明显表明检测有误，我们可以安全地假设完全包含在另一个矩形内的矩形可以被丢弃。
- en: This is precisely the reason why we defined an `is_inside` function, and why
    we iterate through the result of the detection to discard false positives.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们定义`is_inside`函数的原因，也是我们遍历检测结果以丢弃假阳性的原因。
- en: If you run the script yourself, you will see rectangles around people in the
    image.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你亲自运行脚本，你将看到图像中人的周围有矩形。
- en: Creating and training an object detector
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和训练对象检测器
- en: Using built-in features makes it easy to come up with a quick prototype for
    an application, and we're all very grateful to the OpenCV developers for making
    great features, such as face detection or people detection readily available (truly,
    we are).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内置特征使得为应用程序快速构建原型变得容易，我们非常感谢OpenCV开发者为我们提供了诸如人脸检测或人体检测等优秀功能（真的，我们非常感激）。
- en: However, whether you are a hobbyist or a computer vision professional, it's
    unlikely that you will only deal with people and faces.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，无论你是业余爱好者还是计算机视觉专业人士，你很可能不会只处理人和脸。
- en: Moreover, if you're like me, you wonder how the people detector feature was
    created in the first place and if you can improve it. Furthermore, you may also
    wonder whether you can apply the same concepts to detect the most diverse type
    of objects, ranging from cars to goblins.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你像我一样，你会想知道人们检测功能最初是如何创建的，以及你是否可以改进它。此外，你可能还会想知道你是否可以将相同的概念应用于检测从汽车到哥布林等各种不同类型的物体。
- en: In an enterprise environment, you may have to deal with very specific detection,
    such as registration plates, book covers, or whatever your company may deal with.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业环境中，你可能必须处理非常具体的检测，例如车牌、书封面，或者你公司可能处理的任何东西。
- en: So, the question is, how do we come up with our own classifiers?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，问题是，我们如何提出自己的分类器？
- en: The answer lies in SVM and bag-of-words technique.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在于SVM和词袋技术。
- en: We've already talked about HOG and SVM, so let's take a closer look at bag-of-words.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了HOG和SVM，现在让我们更详细地看看词袋模型。
- en: Bag-of-words
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词袋
- en: '**Bag-of-words** (**BOW**) is a concept that was not initially intended for
    computer vision, rather, we use an evolved version of this concept in the context
    of computer vision. So, let''s first talk about its basic version, which—as you
    may have guessed— originally belongs to the field of language analysis and information
    retrieval.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**词袋**（**BOW**）这个概念最初并不是为计算机视觉设计的，相反，我们在计算机视觉的背景下使用这个概念的演变版本。所以，让我们首先谈谈它的基本版本，正如你可能猜到的，它最初属于语言分析和信息检索领域。'
- en: 'BOW is the technique by which we assign a count weight to each word in a series
    of documents; we then rerepresent these documents with vectors that represent
    these set of counts. Let''s look at an example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: BOW是一种技术，通过它我们为一系列文档中的每个单词分配一个计数权重；然后我们用代表这些计数的向量重新表示这些文档。让我们看一个例子：
- en: '**Document 1**: `I like OpenCV and I like Python`'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档1**：`我喜欢OpenCV和Python`'
- en: '**Document 2**: `I like C++ and Python`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档2**：`我喜欢C++和Python`'
- en: '**Document 3**: `I don''t like artichokes`'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档3**：`我不喜欢洋蓟`'
- en: 'These three documents allow us to build a dictionary (or codebook) with these
    values:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个文档使我们能够构建一个包含这些值的词典（或代码簿）：
- en: '[PRE2]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We have eight entries. Let''s now rerepresent the original documents using
    eight-entry vectors, each vector containing all the words in the dictionary with
    values representing the count for each term in the document. The vector representation
    of the preceding three sentences is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有八个条目。现在让我们使用八个条目向量重新表示原始文档，每个向量包含词典中的所有单词，其中的值表示文档中每个术语的计数。前三个句子的向量表示如下：
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This kind of representation of documents has many effective applications in
    the real world, such as spam filtering.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这种文档表示在现实世界中有很多有效的应用，例如垃圾邮件过滤。
- en: These vectors can be conceptualized as a histogram representation of documents
    or as a feature (the same way we extracted features from images in previous chapters),
    which can be used to train classifiers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些向量可以被视为文档的直方图表示，或者作为特征（就像我们在前几章中从图像中提取特征一样），可以用来训练分类器。
- en: Now that we have a grasp of the basic concept of BOW or **bag of visual words**
    (**BOVW**) in computer vision, let's see how this applies to the world of computer
    vision.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了计算机视觉中BOW或**视觉词袋**（**BOVW**）的基本概念，让我们看看它如何应用于计算机视觉领域。
- en: BOW in computer vision
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机视觉中的BOW
- en: We are by now familiar with the concept of image features. We've used feature
    extractors, such as SIFT, and SURF, to extract features from images so that we
    could match these features in another image.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们已经熟悉了图像特征的概念。我们使用了特征提取器，如SIFT和SURF，从图像中提取特征，以便我们可以在另一张图像中匹配这些特征。
- en: We've also familiarized ourselves with the concept of codebook, and we know
    about SVM, a model that can be fed a set of features and utilizes complex algorithms
    to classify train data, and can predict the classification of new data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也已经熟悉了代码簿的概念，并且了解SVM，这是一个可以输入一组特征并利用复杂算法对训练数据进行分类的模型，并且可以预测新数据的分类。
- en: 'So, the implementation of a BOW approach will involve the following steps:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，实现BOW方法将涉及以下步骤：
- en: Take a sample dataset.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取一个样本数据集。
- en: For each image in the dataset, extract descriptors (with SIFT, SURF, and so
    on).
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于数据集中的每一张图像，提取描述符（使用SIFT、SURF等）。
- en: Add each descriptor to the BOW trainer.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个描述符添加到BOW训练器中。
- en: Cluster the descriptors to *k* clusters (okay, this sounds obscure, but bear
    with me) whose centers (centroids) are our visual words.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将描述符聚类到*k*个簇中（好吧，这听起来有些晦涩，但请耐心听我解释）其中心（质心）是我们的视觉词。
- en: At this point, we have a dictionary of visual words ready to be used. As you
    can imagine, a large dataset will help make our dictionary richer in visual words.
    Up to an extent, the more words, the better!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有一个准备使用的视觉词字典。正如你所想象的那样，一个大的数据集将有助于使我们的字典在视觉词方面更加丰富。在一定程度上，词越多，越好！
- en: 'After this, we are ready to test our classifier and attempt detection. The
    good news is that the process is very similar to the one outlined previously:
    given a test image, we can extract features and quantize them based on their distance
    to the nearest centroid to form a histogram.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们就可以测试我们的分类器并尝试检测了。好消息是这个过程与之前概述的非常相似：给定一个测试图像，我们可以提取特征并根据它们与最近质心的距离进行量化，从而形成一个直方图。
- en: 'Based on this, we can attempt to recognize visual words and locate them in
    the image. Here''s a visual representation of the BOW process:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们可以尝试识别视觉词并在图像中定位它们。以下是BOW过程的视觉表示：
- en: '![BOW in computer vision](img/image00236.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![计算机视觉中的BOW](img/image00236.jpeg)'
- en: This is the point in the chapter when you have built an appetite for a practical
    example, and are rearing to code. However, before proceeding, I feel that a quick
    digression into the theory of the k-means clustering is necessary so that you
    can fully understand how visual words are created, and gain a better understanding
    of the process of object detection using BOW and SVM.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在本章中你渴望一个实际例子，并准备好编码的时候。然而，在继续之前，我觉得有必要对k-means聚类的理论进行简要的探讨，这样你就可以完全理解视觉词是如何创建的，并且更好地理解使用BOW和SVM进行对象检测的过程。
- en: The k-means clustering
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: k-means聚类
- en: The k-means clustering is a method of vector quantization to perform data analysis.
    Given a dataset, *k* represents the number of clusters in which the dataset is
    going to be divided. The term "means" refers to the mathematical concept of mean,
    which is pretty basic, but for the sake of clarity, it's what people commonly
    refer to as average; when visually represented, the mean of a cluster is its **centroid**
    or the geometrical center of points in the cluster.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: k-means聚类是一种向量量化方法，用于数据分析。给定一个数据集，*k*代表数据集将要被划分成的簇的数量。"means"这个词指的是数学中的均值概念，这相当基础，但为了清晰起见，这就是人们通常所说的平均值；在视觉上表示时，簇的均值是其**质心**或簇中点的几何中心。
- en: Note
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Clustering** refers to the grouping of points in a dataset into clusters.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**指的是将数据集中的点分组到簇中。'
- en: 'One of the classes we will be using to perform object detection is called `BagOfWordsKMeansTrainer`;
    by now, you should able to deduce what the responsibility of this class is to
    create:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的一个用于执行对象检测的类叫做`BagOfWordsKMeansTrainer`；到现在你应该能够推断出这个类的职责是创建：
- en: '*"`kmeans()` -based class to train a visual vocabulary using the bag-of-words
    approach"*'
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“基于`kmeans()`的类，用于使用词袋方法训练视觉词汇”*'
- en: This is as per the OpenCV documentation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是根据OpenCV文档的。
- en: 'Here''s a representation of a k-means clustering operation with five clusters:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个具有五个簇的k-means聚类操作的表示：
- en: '![The k-means clustering](img/image00237.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![k-means聚类](img/image00237.jpeg)'
- en: After this long theoretical introduction, we can look at an example, and start
    training our object detector.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这漫长的理论介绍之后，我们可以看一个例子，并开始训练我们的对象检测器。
- en: Detecting cars
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测汽车
- en: There is no virtual limit to the type of objects you can detect in your images
    and videos. However, to obtain an acceptable level of accuracy, you need a sufficiently
    large dataset, containing train images that are identical in size.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的图像和视频中，你可以检测到的对象类型没有虚拟限制。然而，为了获得可接受的准确度，你需要一个足够大的数据集，其中包含大小相同的训练图像。
- en: This would be a time consuming operation if we were to do it all by ourselves
    (which is entirely possible).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们全部自己来做，这将是一个耗时的操作（这是完全可能的）。
- en: 'We can avail of ready-made datasets; there are a number of them freely downloadable
    from various sources:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用现成的数据集；有许多可以从各种来源免费下载：
- en: '**The University** **of Illinois**: [http://l2r.cs.uiuc.edu/~cogcomp/Data/Car/CarData.tar.gz](http://l2r.cs.uiuc.edu/~cogcomp/Data/Car/CarData.tar.gz)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伊利诺伊大学**：[http://l2r.cs.uiuc.edu/~cogcomp/Data/Car/CarData.tar.gz](http://l2r.cs.uiuc.edu/~cogcomp/Data/Car/CarData.tar.gz)'
- en: '**Stanford** **University**: [http://ai.stanford.edu/~jkrause/cars/car_dataset.html](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**斯坦福大学**：[http://ai.stanford.edu/~jkrause/cars/car_dataset.html](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)'
- en: Note
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that training images and test images are available in separate files.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，训练图像和测试图像分别存储在不同的文件中。
- en: I'll be using the UIUC dataset in my example, but feel free to explore the Internet
    for other types of datasets.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在我的例子中使用UIUC数据集，但请自由探索互联网上的其他类型的数据集。
- en: 'Now, let''s take a look at an example:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一个例子：
- en: '[PRE4]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: What did we just do?
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们刚才做了什么？
- en: 'This is quite a lot to assimilate, so let''s go through what we''ve done:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要相当多的吸收，所以让我们回顾一下我们所做的：
- en: First of all, our usual imports are followed by the declaration of the base
    path of our training images. This will come in handy to avoid rewriting the base
    path every time we process an image in a particular folder on our computer.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们的常规导入之后是声明我们训练图像的基础路径。这将很有用，可以避免每次在电脑上特定文件夹中处理图像时重写基础路径。
- en: 'After this, we declare a function, `path`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们声明一个函数，`path`：
- en: '[PRE5]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**More on the path function**'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**关于路径函数的更多内容**'
- en: 'This function is a utility method: given the name of a class (in our case,
    we have two classes, `pos` and `neg`) and a numerical index, we return the full
    path to a particular testing image. Our car dataset contains images named in the
    following way: `pos-x.pgm` and `neg-x.pgm`, where `x` is a number.'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个函数是一个实用方法：给定一个类的名称（在我们的案例中，我们有两个类，`pos`和`neg`）和一个数值索引，我们返回特定测试图像的完整路径。我们的汽车数据集包含以下命名的图像：`pos-x.pgm`和`neg-x.pgm`，其中`x`是一个数字。
- en: Immediately, you will find the usefulness of this function when iterating through
    a range of numbers (say, 20), which will allow you to load all images from `pos-0.pgm`
    to `pos-20.pgm`, and the same goes for the negative class.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 立即，你会发现这个函数在迭代一系列数字（比如，20）时的有用性，这将允许你加载从`pos-0.pgm`到`pos-20.pgm`的所有图像，对于负类也是如此。
- en: 'Next up, we''ll create two SIFT instances: one to extract keypoints, the other
    to extract features:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建两个SIFT实例：一个用于提取关键点，另一个用于提取特征：
- en: '[PRE6]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Whenever you see SIFT involved, you can be pretty sure some feature matching
    algorithm will be involved too. In our case, we''ll create an instance for a FLANN
    matcher:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每当你看到SIFT时，你可以相当肯定会有一些特征匹配算法也涉及其中。在我们的案例中，我们将创建一个FLANN匹配器的实例：
- en: '[PRE7]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that currently, the `enum` values for FLANN are missing from the Python
    version of OpenCV 3, so, number `1`, which is passed as the algorithm parameter,
    represents the `FLANN_INDEX_KDTREE` algorithm. I suspect the final version will
    be `cv2.FLANN_INDEX_KDTREE`, which is a little more helpful. Make sure to check
    the `enum` values for the correct flags.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前，OpenCV 3的Python版本中缺少FLANN的`enum`值，因此，作为算法参数传递的数字`1`代表的是`FLANN_INDEX_KDTREE`算法。我怀疑最终版本将是`cv2.FLANN_INDEX_KDTREE`，这会更有帮助。请确保检查`enum`值以获取正确的标志。
- en: 'Next, we mention the BOW trainer:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们提到BOW训练器：
- en: '[PRE8]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This BOW trainer utilizes 40 clusters. After this, we''ll initialize the BOW
    extractor. This is the BOW class that will be fed a vocabulary of visual words
    and will try to detect them in the test image:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个BOW训练器使用了40个簇。之后，我们将初始化BOW提取器。这是一个BOW类，它将接收视觉词汇表并尝试在测试图像中检测它们：
- en: '[PRE9]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To extract the SIFT features from an image, we build a utility method, which
    takes the path to the image, reads it in grayscale, and returns the descriptor:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从图像中提取SIFT特征，我们构建了一个实用方法，它接受图像的路径，以灰度读取它，并返回描述符：
- en: '[PRE10]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: At this stage, we have everything we need to start training the BOW trainer.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经拥有了开始训练BOW训练器所需的一切。
- en: 'Let''s read eight images per class (eight positives and eight negatives) from
    our dataset:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按类别读取每个类别中的八张图像（八个正例和八个负例）：
- en: '[PRE11]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To create the vocabulary of visual words, we''ll call the `cluster()` method
    on the trainer, which performs the k-means classification and returns the said
    vocabulary. We''ll assign this vocabulary to `BOWImgDescriptorExtractor` so that
    it can extract descriptors from test images:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了创建视觉词的词汇表，我们将调用训练器的`cluster()`方法，该方法执行k-means分类并返回所说的词汇表。我们将这个词汇表分配给`BOWImgDescriptorExtractor`，以便它可以从测试图像中提取描述符：
- en: '[PRE12]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In line with other utility functions declared in this script, we''ll declare
    a function that takes the path to an image and returns the descriptor as computed
    by the BOW descriptor extractor:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与在此脚本中声明的其他实用函数一样，我们将声明一个函数，该函数接受图像的路径并返回由BOW描述符提取器计算出的描述符：
- en: '[PRE13]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s create two arrays to accommodate the train data and labels, and populate
    them with the descriptors generated by `BOWImgDescriptorExtractor`, associating
    labels to the positive and negative images we''re feeding (`1` stands for a positive
    match, `-1` for a negative):'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建两个数组来容纳训练数据和标签，并用`BOWImgDescriptorExtractor`生成的描述符填充它们，将标签与我们要提供的正负图像关联起来（`1`代表正匹配，`-1`代表负匹配）：
- en: '[PRE14]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s create an instance of an SVM:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个SVM的实例：
- en: '[PRE15]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, train it by wrapping the train data and labels into the NumPy arrays:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过将训练数据和标签包装成NumPy数组来对其进行训练：
- en: '[PRE16]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We're all set with a trained SVM; all that is left to do is to feed the SVM
    a couple of sample images and see how it behaves.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了一个训练好的SVM；剩下要做的就是给SVM提供一些样本图像并观察它的表现。
- en: 'Let''s first define another utility method to print the result of our `predict`
    method and return it:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先定义另一个实用方法来打印我们`predict`方法的结果并返回它：
- en: '[PRE17]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s define two sample image paths and read them as the NumPy arrays:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义两个样本图像路径并将它们作为NumPy数组读取：
- en: '[PRE18]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We''ll pass these images to the trained SVM, and get the result of the prediction:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将这些图像传递给训练好的SVM，并获取预测结果：
- en: '[PRE19]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Naturally, we're hoping that the car image will be detected as a car (result
    of `predict()` should be `1.0`), and that the other image will not (result should
    be `-1.0`), so we will only add text to the images if the result is the expected
    one.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自然地，我们希望汽车图像被检测为汽车（`predict()`的结果应该是`1.0`），而其他图像则不是（结果应该是`-1.0`），因此我们只有在结果符合预期时才会在图像上添加文本。
- en: 'At last, we''ll present the images on the screen, hoping to see the correct
    caption on each:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将图像显示在屏幕上，希望看到每个图像上都有正确的标题：
- en: '[PRE20]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding operation produces the following result:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的操作会产生以下结果：
- en: '![What did we just do?](img/image00238.jpeg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![我们刚才做了什么？](img/image00238.jpeg)'
- en: 'It also results in this:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这也导致了以下结果：
- en: '![What did we just do?](img/image00239.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![我们刚才做了什么？](img/image00239.jpeg)'
- en: SVM and sliding windows
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SVM和滑动窗口
- en: 'Having detected an object is an impressive achievement, but now we want to
    push this to the next level in these ways:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到一个对象是一个令人印象深刻的成就，但现在我们想以以下方式将其提升到下一个层次：
- en: Detecting multiple objects of the same kind in an image
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中检测同一类别的多个对象
- en: Determining the position of a detected object in an image
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定检测到的对象在图像中的位置
- en: 'To accomplish this, we will use the sliding windows approach. If it''s not
    already clear from the previous explanation of the concept of sliding windows,
    the rationale behind the adoption of this approach will become more apparent if
    we take a look at a diagram:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个任务，我们将使用滑动窗口方法。如果从之前对滑动窗口概念的解释中还不清楚，那么通过查看图表，采用这种方法的原因将变得更加明显：
- en: '![SVM and sliding windows](img/image00240.jpeg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![SVM和滑动窗口](img/image00240.jpeg)'
- en: 'Observe the movement of the block:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 观察块的运动：
- en: We take a region of the image, classify it, and then move a predefined step
    size to the right-hand side. When we reach the rightmost end of the image, we'll
    reset the *x* coordinate to `0` and move down a step, and repeat the entire process.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们取图像的一个区域，对其进行分类，然后向右移动一个预定义的步长。当我们到达图像的最右边时，我们将*x*坐标重置为`0`并向下移动一个步长，然后重复整个过程。
- en: At each step, we'll perform a classification with the SVM that was trained with
    BOW.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个步骤中，我们将使用用BOW训练的SVM进行分类。
- en: Keep a track of all the blocks that have *passed* the SVM predict test.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录所有通过SVM预测测试的块。
- en: When you've finished classifying the entire image, scale the image down and
    repeat the entire sliding windows process.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你完成整个图像的分类后，缩小图像并重复整个滑动窗口过程。
- en: Continue rescaling and classifying until you get to a minimum size.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 继续缩放和分类，直到达到最小尺寸。
- en: This gives you the chance to detect objects in several regions of the image
    and at different scales.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这给了你在图像的多个区域和不同尺度上检测对象的机会。
- en: 'At this stage, you will have collected important information about the content
    of the image; however, there''s a problem: it''s most likely that you will end
    up with a number of overlapping blocks that give you a positive score. This means
    that your image may contain one object that gets detected four or five times,
    and if you were to report the result of the detection, your report would be quite
    inaccurate, so here''s where non-maximum suppression comes into play.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你将收集有关图像内容的重要信息；然而，有一个问题：你很可能会得到许多重叠的块，这些块给你一个正分数。这意味着你的图像可能包含一个被检测四次或五次的对象，如果你报告检测结果，你的报告将非常不准确，所以这就是非极大值抑制发挥作用的地方。
- en: Example – car detection in a scene
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例 - 场景中的车辆检测
- en: We are now ready to apply all the concepts we learned so far to a real-life
    example, and create a car detector application that scans an image and draws rectangles
    around cars.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将迄今为止学到的所有概念应用到实际例子中，并创建一个车辆检测应用程序，该程序扫描图像并在车辆周围绘制矩形。
- en: 'Let''s summarize the process before diving into the code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入代码之前，让我们总结一下这个过程：
- en: Obtain a train dataset.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取训练数据集。
- en: Create a BOW trainer and create a visual vocabulary.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 BOW 训练器并创建一个视觉词汇表。
- en: Train an SVM with the vocabulary.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用词汇表训练 SVM。
- en: Attempt detection using sliding windows on an image pyramid of a test image.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试图像的图像金字塔上使用滑动窗口尝试检测。
- en: Apply non-maximum suppression to overlapping boxes.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对重叠的框应用非极大值抑制。
- en: Output the result.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出结果。
- en: Let's also take a look at the structure of the project, as it is a bit more
    complex than the classic standalone script approach we've adopted until now.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也看看项目结构，因为它比我们迄今为止采用的经典独立脚本方法要复杂一些。
- en: 'The project structure is as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 项目结构如下：
- en: '[PRE21]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The main program is in `car_sliding_windows.py`, and all the utilities are contained
    in the `car_detector` folder. As we're using Python 2.7, we'll need an `__init__.py`
    file in the folder for it to be detected as a module.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 主要程序位于 `car_sliding_windows.py`，所有实用工具都包含在 `car_detector` 文件夹中。由于我们使用 Python
    2.7，我们需要在文件夹中创建一个 `__init__.py` 文件，以便将其检测为模块。
- en: 'The four files in the `car_detector` module are as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`car_detector` 模块中的四个文件如下：'
- en: The SVM training model
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM 训练模型
- en: The non-maximum suppression function
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非极大值抑制函数
- en: The image pyramid
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像金字塔
- en: The sliding windows function
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滑动窗口函数
- en: 'Let''s examine them one by one, starting from the image pyramid:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一检查它们，从图像金字塔开始：
- en: '[PRE22]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This module contains two function definitions:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块包含两个函数定义：
- en: Resize takes an image and resizes it by a specified factor
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Resize 接受一个图像，并按指定因子进行缩放。
- en: Pyramid takes an image and returns a resized version of it until the minimum
    constraints of width and height are reached
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pyramid 接受一个图像，并返回一个直到达到最小宽度和高度约束的缩放版本。
- en: Note
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You will notice that the image is not returned with the `return` keyword but
    with the `yield` keyword. This is because this function is a so-called generator.
    If you are not familiar with generators, take a look at [https://wiki.python.org/moin/Generators](https://wiki.python.org/moin/Generators).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到图像不是通过 `return` 关键字返回，而是通过 `yield` 关键字返回。这是因为这个函数是一个所谓的生成器。如果你不熟悉生成器，请查看[https://wiki.python.org/moin/Generators](https://wiki.python.org/moin/Generators)。
- en: This will allow us to obtain a resized image to process in our main program.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们能够获得一个用于主程序处理的重缩放图像。
- en: 'Next up is the sliding windows function:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是滑动窗口函数：
- en: '[PRE23]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Again, this is a generator. Although a bit deep-nested, this mechanism is very
    simple: given an image, return a window that moves of an arbitrary sized step
    from the left margin towards the right, until the entire width of the image is
    covered, then goes back to the left margin but down a step, covering the width
    of the image repeatedly until the bottom right corner of the image is reached.
    You can visualize this as the same pattern used for writing on a piece of paper:
    start from the left margin and reach the right margin, then move onto the next
    line from the left margin.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这同样是一个生成器。虽然有点深层次嵌套，但这种机制非常简单：给定一个图像，返回一个从左边缘开始，以任意大小的步长向右移动的窗口，直到覆盖整个图像宽度，然后回到左边缘但向下移动一个步长，重复覆盖图像宽度，直到达到图像的右下角。你可以将这想象成在一张纸上写字时使用的相同模式：从左边缘开始，达到右边缘，然后从左边缘开始移动到下一行。
- en: 'The last utility is non-maximum suppression, which looks like this (Malisiewicz/Rosebrock''s
    code):'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个实用工具是非最大值抑制，它看起来像这样（Malisiewicz/Rosebrock 的代码）：
- en: '[PRE24]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This function simply takes a list of rectangles and sorts them by their score.
    Starting from the box with the highest score, it eliminates all boxes that overlap
    beyond a certain threshold by calculating the area of intersection and determining
    whether it is greater than a certain threshold.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数简单地接受一个矩形列表，并按其分数排序。从分数最高的盒子开始，通过计算交集面积并确定是否大于某个阈值来消除所有超出一定阈值的重叠盒子。
- en: Examining detector.py
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 检查 detector.py
- en: Now, let's examine the heart of this program, which is `detector.py`. This a
    bit long and complex; however, everything should appear much clearer given our
    newfound familiarity with the concepts of BOW, SVM, and feature detection/extraction.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查这个程序的核心，即 `detector.py`。这有点长且复杂；然而，鉴于我们对 BOW、SVM 和特征检测/提取概念的新认识，一切应该会变得更加清晰。
- en: 'Here''s the code:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE25]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Let's go through it. First, we'll import our usual modules, and then set a path
    for the training images.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下。首先，我们将导入我们常用的模块，然后设置训练图像的路径。
- en: 'Then, we''ll define a number of utility functions:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将定义多个实用函数：
- en: '[PRE26]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This function returns the path to an image given a base path and a class name.
    In our example, we're going to use the `neg-` and `pos-` class names, because
    this is what the training images are called (that is, `neg-1.pgm`). The last argument
    is an integer used to compose the final part of the image path.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数根据基路径和类别名称返回图像的路径。在我们的例子中，我们将使用 `neg-` 和 `pos-` 类名称，因为这就是训练图像的名称（即 `neg-1.pgm`）。最后一个参数是一个整数，用于组成图像路径的最后部分。
- en: 'Next, we''ll define a utility function to obtain a FLANN matcher:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个实用函数来获取 FLANN 匹配器：
- en: '[PRE27]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Again, it's not that the integer, `1`, passed as an algorithm argument represents
    `FLANN_INDEX_KDTREE`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，传递给算法参数的整数 `1` 并不代表 `FLANN_INDEX_KDTREE`。
- en: 'The next two functions return the SIFT feature detectors/extractors and a BOW
    trainer:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下两个函数返回 SIFT 特征检测器/提取器以及一个 BOW 训练器：
- en: '[PRE28]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The next utility is a function used to return features from an image:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个实用工具是一个从图像中返回特征的函数：
- en: '[PRE29]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A SIFT detector detects features, while a SIFT extractor extracts and returns
    them.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: SIFT 检测器检测特征，而 SIFT 提取器提取并返回它们。
- en: 'We''ll also define a similar utility function to extract the BOW features:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将定义一个类似的实用函数来提取 BOW 特征：
- en: '[PRE30]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the `main car_detector` function, we''ll first create the necessary object
    used to perform feature detection and extraction:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `main car_detector` 函数中，我们首先创建用于执行特征检测和提取的必要对象：
- en: '[PRE31]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, we''ll add features taken from training images to the trainer:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将从训练图像中提取的特征添加到训练器中：
- en: '[PRE32]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: For each class, we'll add a positive image to the trainer and a negative image.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个类别，我们将向训练器添加一个正图像和一个负图像。
- en: After this, we'll instruct the trainer to cluster the data into *k* groups.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将指示训练器将数据聚类成 *k* 个组。
- en: 'The clustered data is now our vocabulary of visual words, and we can set the
    `BOWImgDescriptorExtractor` class'' vocabulary in this way:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类后的数据现在是我们视觉词汇的词汇表，我们可以这样设置 `BOWImgDescriptorExtractor` 类的词汇表：
- en: '[PRE33]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Associating training data with classes
  id: totrans-266
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将训练数据与类别关联
- en: 'With a visual vocabulary ready, we can now associate train data with classes.
    In our case, we have two classes: `-1` for negative results and `1` for positive
    ones.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好视觉词汇表后，我们现在可以将训练数据与类别关联起来。在我们的例子中，我们有两个类别：`-1` 表示负结果，`1` 表示正结果。
- en: 'Let''s populate two arrays, `traindata` and `trainlabels`, containing extracted
    features and their corresponding labels. Iterating through the dataset, we can
    quickly set this up with the following code:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们填充两个数组，`traindata` 和 `trainlabels`，包含提取的特征及其相应的标签。通过迭代数据集，我们可以快速使用以下代码设置：
- en: '[PRE34]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You will notice that at each cycle, we'll add one positive and one negative
    image, and then populate the labels with a `1` and a `-1` value to keep the data
    synchronized with the labels.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，在每次循环中，我们会添加一个正图像和一个负图像，然后使用 `1` 和 `-1` 的值填充标签，以保持数据与标签同步。
- en: 'Should you wish to train more classes, you could do that by following this
    pattern:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望训练更多类别，你可以按照以下模式进行：
- en: '[PRE35]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: For example, you could train a detector to detect cars and people and perform
    detection on these in an image containing both cars and people.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以训练一个检测器来检测汽车和人，并在包含汽车和人的图像上进行检测。
- en: 'Lastly, we''ll train the SVM with the following code:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用以下代码训练SVM：
- en: '[PRE36]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'There are two parameters in particular that I''d like to focus your attention
    on:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个特定的参数我想引起你的注意：
- en: '**C**: With this parameter, you could conceptualize the strictness or severity
    of the classifier. The higher the value, the less chances of misclassification,
    but the trade-off is that some positive results may not be detected. On the other
    hand, a low value may over-fit, so you risk getting false positives.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C**: 使用此参数，你可以概念化分类器的严格性或严重性。值越高，误分类的机会越少，但代价是可能无法检测到一些阳性结果。另一方面，低值可能导致过拟合，因此你可能会得到假阳性。'
- en: '**Kernel**: This parameter determines the nature of the classifier: `SVM_LINEAR`
    indicates a linear *hyperplane*, which, in practical terms, works very well for
    a binary classification (the test sample either belongs to a class or it doesn''t),
    while `SVM_RBF` (**radial basis function**) separates data using the Gaussian
    functions, which means that the data is split into several kernels defined by
    these functions. When training the SVM to classify for more than two classes,
    you will have to use RBF.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核函数**：此参数决定了分类器的性质：`SVM_LINEAR` 表示线性 **超平面**，在实际情况中，对于二元分类（测试样本要么属于一个类别，要么不属于）非常有效，而
    `SVM_RBF`（**径向基函数**）使用高斯函数来分离数据，这意味着数据被分割成由这些函数定义的多个核。当训练SVM进行超过两个类别的分类时，你必须使用RBF。'
- en: Finally, we'll pass the `traindata` and `trainlabels` arrays into the SVM `train`
    method, and return the SVM and BOW extractor object. This is because in our applications,
    we don't want to have to recreate the vocabulary every time, so we expose it for
    reuse.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将 `traindata` 和 `trainlabels` 数组传递给SVM的 `train` 方法，并返回SVM和BOW提取器对象。这是因为在我们的应用中，我们不希望每次都要重新创建词汇表，所以我们将其公开以供重用。
- en: Dude, where's my car?
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嘿，我的车在哪里？
- en: We are ready to test our car detector!
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好测试我们的汽车检测器了！
- en: 'Let''s first create a simple program that loads an image, and then operates
    detection using the sliding windows and image pyramid techniques, respectively:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先创建一个简单的程序，该程序加载一张图片，然后分别使用滑动窗口和图像金字塔技术进行检测：
- en: '[PRE37]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The notable part of the program is the function within the pyramid/sliding
    window loop:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的显著部分是位于金字塔/滑动窗口循环内的函数：
- en: '[PRE38]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Here, we extract the features of the **region of interest** (**ROI**), which
    corresponds to the current sliding window, and then we call `predict` on the extracted
    features. The `predict` method has an optional parameter, `flags`, which returns
    the score of the prediction (contained at the `[0][0]` value).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提取了**感兴趣区域**（**ROI**）的特征，这对应于当前的滑动窗口，然后我们对提取的特征调用 `predict` 方法。`predict`
    方法有一个可选参数 `flags`，它返回预测的分数（位于 `[0][0]` 的值）。
- en: Note
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'A word on the score of the prediction: the lower the value, the higher the
    confidence that the classified element really belongs to the class.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 关于预测分数的一番话：值越低，分类元素真正属于该类的置信度越高。
- en: So, we'll set an arbitrary threshold of `-1.0` for classified windows, and all
    windows with less than `-1.0` are going to be taken as good results. As you experiment
    with your SVMs, you may tweak this to your liking until you find a golden mean
    that assures best results.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将为分类窗口设置一个任意的阈值 `-1.0`，所有小于 `-1.0` 的窗口将被视为良好结果。随着你对你的SVM进行实验，你可以调整这个值，直到找到最佳的结果。
- en: Finally, we add the computed coordinates of the sliding window (meaning, we
    multiply the current coordinates by the scale of the current layer in the image
    pyramid so that it gets correctly represented in the final drawing) to the array
    of rectangles.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将滑动窗口的计算坐标（即，我们将当前坐标乘以图像金字塔中当前层的缩放比例，以便在最终绘图中得到正确表示）添加到矩形数组中。
- en: 'There''s one last operation we need to perform before drawing our final result:
    non-maximum suppression.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在绘制最终结果之前，我们需要执行最后一个操作：非极大值抑制。
- en: 'We turn the rectangles array into a NumPy array (to allow certain kind of operations
    that are only possible with NumPy), and then apply NMS:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将矩形数组转换为NumPy数组（以便进行某些只有NumPy才能执行的操作），然后应用NMS：
- en: '[PRE39]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we proceed with displaying all our results; for the sake of convenience,
    I''ve also printed the score obtained for all the remaining windows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们继续显示所有结果；为了方便起见，我还打印了所有剩余窗口获得的分数：
- en: '![Dude, where''s my car?](img/image00241.jpeg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![ dude, where''s my car?](img/image00241.jpeg)'
- en: This is a remarkably accurate result!
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常准确的结果！
- en: 'A final note on SVM: you don''t need to train a detector every time you want
    to use it, which would be extremely impractical. You can use the following code:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 关于支持向量机（SVM）的最后一句话：您不需要每次使用检测器时都对其进行训练，这会非常不切实际。您可以使用以下代码：
- en: '[PRE40]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: You can subsequently reload it with a load method and feed it test images or
    frames.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用加载方法重新加载它，并为其提供测试图像或帧。
- en: Summary
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we talked about numerous object detection concepts, such as
    HOG, BOW, SVM, and some useful techniques, such as image pyramid, sliding windows,
    and non-maximum suppression.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了许多目标检测概念，例如HOG、BOW、SVM以及一些有用的技术，例如图像金字塔、滑动窗口和非极大值抑制。
- en: We introduced the concept of machine learning and explored the various approaches
    used to train a custom detector, including how to create or obtain a training
    dataset and classify data. Finally, we put this knowledge to good use by creating
    a car detector from scratch and verifying its correct functioning.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了机器学习的概念，并探讨了用于训练自定义检测器的各种方法，包括如何创建或获取训练数据集以及如何对数据进行分类。最后，我们通过从头创建一个车辆检测器并验证其正确功能，将这一知识应用于实践。
- en: All these concepts form the foundation of the next chapter, in which we will
    utilize object detection and classification techniques in the context of making
    videos, and learn how to track objects to retain information that can potentially
    be used for business or application purposes.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些概念构成了下一章的基础，我们将利用视频制作中的目标检测和分类技术，并学习如何跟踪对象以保留可能用于商业或应用目的的信息。
