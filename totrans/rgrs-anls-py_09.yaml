- en: Chapter 9. Real-world Applications for Regression Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have arrived at the concluding chapter of the book. In respect of the previous
    chapters, the present one is very practical in its essence, since it mostly contains
    lots of code and no math or other theoretical explanation. It comprises four practical
    examples of real-world data science problems solved using linear models. The ultimate
    goal is to demonstrate how to approach such problems and how to develop the reasoning
    behind their resolution, so that they can be used as blueprints for similar challenges
    you'll encounter.
  prefs: []
  type: TYPE_NORMAL
- en: For each problem, we will describe the question to be answered, provide a short
    description of the dataset, and decide the metric we strive to maximize (or the
    error we want to minimize). Then, throughout the code, we will provide ideas and
    intuitions that are key to successfully completing each one. In addition, when
    run, the code will produce verbose output from the modeling, in order to provide
    the reader with all the information needed to decide the next step. Due to space
    restrictions, output will be truncated so it just contains the key lines (the
    truncated lines are represented by `[…]` in the output) but, on your screen, you'll
    get the complete picture.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, each section was provided with a separate IPython Notebook.
    They are different problems, and each of them is developed and presented independently.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section of the book, we will download all the datasets that are going
    to be used in the examples in this chapter. We chose to store them in separate
    subdirectories of the same folder where the IPython Notebook is contained. Note
    that some of them are quite big (100+ MB).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We would like to thank the maintainers and the creators of the UCI dataset
    archive. Thanks to such repositories, modeling and achieving experiment repeatability
    are much easier than before. The UCI archive is from Lichman, M. (2013). UCI Machine
    Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For each dataset, we first download it, and then we present the first couple
    of lines. First, this will help demonstrate whether the file has been correctly
    downloaded, unpacked, and placed into the right location; second, it will show
    the structure of the file itself (header, fields, and so on):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Time series problem dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dataset from: Brown, M. S., Pelosi, M. & Dirska, H. (2013). Dynamic-radius
    Species-conserving Genetic Algorithm for the Financial Forecasting of Dow Jones
    Index Stocks. Machine Learning and Data Mining in Pattern Recognition, 7988, 27-41.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![Time series problem dataset](img/00131.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Regression problem dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dataset from: Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and
    Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International
    Society for Music Information Retrieval Conference (ISMIR), 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Regression problem dataset](img/00132.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Multiclass classification problem dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dataset from: Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis,
    and Philip K. Chan. Cost-based Modeling and Evaluation for Data Mining With Application
    to Fraud and Intrusion Detection: Results from the JAM Project.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Multiclass classification problem dataset](img/00133.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Ranking problem dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creator/Donor: Jeffrey C. Schlimmer'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Ranking problem dataset](img/00134.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A regression problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given some descriptors of a song, the goal of this problem is to predict the
    year when the song was produced. That's basically a regression problem, since
    the target variable to predict is a number in the range between 1922 and 2011.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each song, in addition to the year of production, 90 attributes are provided.
    All of them are related to the timbre: 12 of them relate to the timbre average
    and 78 attributes describe the timbre''s covariance; all the features are numerical
    (integer or floating point numbers).'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is composed of more than half a million observations. As for the
    competition behind the dataset, the authors tried to achieve the best results
    using the first 463,715 observations as a training set and the remaining 51,630
    for testing.
  prefs: []
  type: TYPE_NORMAL
- en: The metric used to evaluate the results is the **Mean Absolute Error** (**MAE**)
    between the predicted year and the real year of production for the songs composing
    the testing set. The goal is to minimize the error measure.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The complete description of this problem and additional information (about
    the feature extraction phase) can be found at the website: [https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s start with some Python code. First of all, we load the dataset
    (remember, if that operation fails it means you should download the dataset by
    yourself before running the program in the previous section). Then, we split the
    training and testing parts according to the guidelines provided with the dataset.
    Finally, we print the size (in Megabytes) of the resulting DataFrame, in order
    to have an indication of the memory footprint of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Our dataset is not all that small, since it's almost 400 MB. We should, therefore,
    be very smart and use any appropriate trick to cope with it without running out
    of memory (and becoming heavily reliant on the swap file) or even crashing our
    operating system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now get a baseline for comparisons: we will use the plain vanilla linear
    regression (vanilla means that there''s no additional flavor to it; as with plain
    ice cream, our model uses the standard hyper-parameters). We then print the training
    time (in seconds), the MAE in the train set, and the MAE in the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Using linear regression, we can achieve a MAE of 6.8 in around 10 seconds.
    In addition, the learner seems stable and robust since there is no difference
    between MAE in the train set and MAE in the test set (thanks to the generalization
    power of linear regression). Let''s now try to do even better. We test a stochastic
    gradient descent variation, to see if we can achieve a better MAE more rapidly
    (eventually). We experiment with both a small and a high number of iterations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The results seem to suggest that SGD Regression is not appropriate for the
    shape of the dataset: getting better results may require much perseverance and
    take a very long time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we have two options: the first is to resort to an advanced classifier
    (such as an ensemble); otherwise, we can fine-tune the model with feature engineering.
    For this problem, let''s go for the second choice, since the main goal of this
    book is to work on linear models. Readers are strongly advised to try the first
    approach as comparison.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's now try to use the polynomial expansion of the features, followed by a
    feature selection step. This ensures that we have all the features, built on top
    on the features of the problem, in order to select the best and run through a
    linear regressor.
  prefs: []
  type: TYPE_NORMAL
- en: Since we don't know a-priori which is the optimum number of features, let's
    treat that as a parameter and plot the MAE for the training and the testing set
    as a variable. Furthermore, since we're undertaking a regression task, feature
    selection should be targeting the best regression features; therefore the F-score
    for regression is used to rank and select the top K features.
  prefs: []
  type: TYPE_NORMAL
- en: 'We immediately encounter a problem: polynomial feature expansion creates so
    many additional features. Since we are operating on a quite big dataset, we might
    have to subsample the training set. Let''s first count how many features are after
    the polynomial expansion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With more than 4,000 features, we should select at least 10 times more observations,
    in order not to risk overfitting. We shuffle the dataset, and select one twelfth
    of it (so the number of observations is around 40,000). To manage that, we can
    use K-fold, and select just the indexes composing the test set of the first piece:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![A regression problem](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'It seems that we have found the optimal value for K, the number of selected
    features, in K=900\. At this point:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The training MAE and the testing MAE diverge: if we are to use more than 900
    features, we may have start overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The testing MAE is at its minimum. The reading for the MAE in the test set is
    6.70.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the best tradeoff between performance and training time (23 seconds).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a better machine (with 16 GB of RAM or more), you can re-run the
    last two cells, increasing the size of the training set (moving, for example,
    the number of folds from 12 to 8 or 4). The result should improve by some decimal
    places, although the training will be longer.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a classifier instead of a regressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As an open problem (we''re not providing a solution), we could have solved
    this problem as a classification task, since the number of target variables is
    *just* 89 (which is higher than the majority of the classification problems, though).
    Following this path, you will encounter different kinds of problems (the MAE is
    wrongly defined on a classification problem). We encourage readers to have a go
    at this, and try to match the result we obtained with the regression learner;
    here is the first step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: An imbalanced and multiclass classification problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given some descriptors of a sequence of packets, flowing to/from a host connected
    to the Internet, the goal of this problem is to detect whether that sequence signals
    a malicious attack or not. If it does, we should also classify the type of attack.
    That's a multiclass classification problem, since the possible labels are multiple
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each observation, 42 features are revealed: please note that some of them
    are categorical, whereas others are numerical. The dataset is composed of almost
    5 million observations (but in this exercise we''re using just the first million,
    to avoid memory constraints), and the number of possible labels is 23\. One of
    them represents a non-malicious situation (*normal*); all the others represent
    22 different network attacks. Some attention should be paid to the fact that the
    frequencies of response classes are imbalanced: for some attacks there are multiple
    observations, for others just a few.'
  prefs: []
  type: TYPE_NORMAL
- en: 'No instruction is given about how to split the train/test, or how to evaluate
    results. In this problem, we will adopt an exploratory goal: trying to reveal
    accurate information for all the labels. We warmly advise readers to take some
    further steps and tune the learner to maximize the precision of the detection,
    just for the malicious activities in the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The full description of this problem can be found at the website: [https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data](https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data).'
  prefs: []
  type: TYPE_NORMAL
- en: 'First at all, let''s load the data. The file doesn''t contain the header; therefore
    we have to specify the column names while loading it with pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now check the first few lines of the loaded dataset (in order to understand
    the overall shape of the dataset), its size (in terms of observations and features),
    and the types of features (to separate categorical from numerical ones):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems we''re operating on a very big dataset, since it has 1M rows and 42
    columns, with some of them being categorical. Now, let''s separate the target
    variable from the features, encoding the strings (containing attack names) with
    ordinal numbers. To do so, we can use the `LabelEncoder` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Targets, variables are now in a separate array, encoded as integers. Let''s
    now remove the target column from the dataset, and one-hot encode all the categorical
    features. To do so, we can simply use the Pandas `get_dummies` function. The new
    shape of the dataset is therefore *larger*, because each level composing a categorical
    feature is now a binary feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we have many available observations and many classes contain just a few
    samples, we can shuffle and split the dataset in two portions: one to be used
    in training, the other for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Given the exploratory nature of our task, let''s now define a function to print
    the confusion matrix, normalized by the number of occurrences per each class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Let's now create a baseline for this task. We will use a simple `SGDClassifier`,
    with logistic loss, in this first step. For both training and test sets we will
    print the overall accuracy of the solution, the normalized confusion matrix, and
    the classification report (containing the precision, recall, F1-score, and support
    for each class).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![An imbalanced and multiclass classification problem](img/00136.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![An imbalanced and multiclass classification problem](img/00137.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the output is very long, some points are immediately visible in this
    baseline:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy is low (0.80), but the classification is resilient to overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just two vertical lines dominate the confusion matrix. This indicates that the
    classifier fits only two classes during the training phase. Not surprisingly,
    they are the most populated ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can reach the same conclusion (that the class imbalance has influenced
    the results) by looking at the classification report: just a few classes have
    non-zero scores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such a problem is a very frequent one, and it happens when you try to fit a
    linear learner on a strongly imbalanced dataset. Let's now try to oversample small
    classes, and sub-sample the most popular ones. In the following function, we implemented
    a bootstrap algorithm with replacement, where each class gets, in the output data,
    at least `min_samples_out` observations and up to `max_samples_out`. This should
    force the learning algorithm to *take account of* all classes with a similar weight.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can try to do better than the baseline, training out the learner on
    this modified (balanced) training set, and then applying it on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The results suggest we''re heading toward the right direction. The confusion
    matrix looks more diagonal (meaning that matches between rows and columns occur
    more on the diagonal), and the accuracy increases to 0.72 in the test set. Let''s
    now try some values to achieve hyperparameter optimization, and boost the score
    to its max. For that, we run a grid-search cross-validation, using three folds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Although we run a grid-search cross-validation, the results look the same as
    in the previous experiment. We now try a different approach: since there are many
    output classes, let''s try to use a `OneVsOne` strategy: instead of fitting one
    classifier per class, we fit a classifier for each pair of classes. That should
    result in a more accurate, although longer to train, model. Even here, each learner
    is cross-validated with a grid search and three folds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are better, in both the training set and testing set. Let''s now
    try a logistic regressor instead of `SGDClassifier`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![An imbalanced and multiclass classification problem](img/00138.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![An imbalanced and multiclass classification problem](img/00139.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The results look much better than the baseline and the previous solution. In
    fact:'
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy measured on the balanced training set is close to the one recorded
    on the test set. This ensures the generalization capabilities of the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The confusion matrix is *almost* diagonal. It means that all the classes have
    been included in the fitting (and the prediction) phase.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The precision/recall and F1 score are non-zero for many classes, even for those
    with little support.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, we're satisfied with the solution. If you would like to dig further
    and test more model hypotheses on the full 5-million dataset, it's time now to
    move to non-linear classifiers. When doing so, please note in advance both the
    complexity and the running time required to get a prediction (after all, you're
    using a dataset containing more than 100 million values).
  prefs: []
  type: TYPE_NORMAL
- en: A ranking problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given some descriptors of a car and its price, the goal of this problem is
    to predict the degree to which the car is riskier than its price indicates. Actuaries
    in the insurance business call this process *symboling*, and the outcome is a
    rank: a value of +3 indicates the car is risky; -3 indicates that it''s pretty
    safe (although the lowest value in the dataset is -2).'
  prefs: []
  type: TYPE_NORMAL
- en: The description of the car includes its specifications in terms of various characteristics
    (brand, fuel type, body style, length, and so on). Moreover, you get its price
    and normalized loss in use as compared to other cars (this represents the average
    loss per car per year, normalized for all cars within a certain car segment).
  prefs: []
  type: TYPE_NORMAL
- en: There are 205 cars in the dataset, and the number of features is 25; some of
    them are categorical, and others are numerical. In addition, the dataset expressively
    states that there are some missing values, encoded using the string `"?"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although it is not stated directly on the presentation page, the goal of our
    task is to minimize the *label ranking loss*, a measure that indicates how well
    we performed the ranking. This score works on probabilities, and a perfect rank
    gives a loss of zero. Using regression scores, such as MAE or MSE, has little
    relevance to this task, since the prediction must be an integer; also, a classification
    score such as `accuracy` makes no sense either, since it doesn''t tell us how
    far we are from the perfect solution. Another score we will see in the code is
    **label ranking average precision** (**LRAP**). In this case, a perfect ranked
    output has a score of one (exactly like precision in the sense of classification).
    More information about the metrics is available on the Scikit-learn website: [http://scikit-learn.org/stable/modules/model_evaluation.html](http://scikit-learn.org/stable/modules/model_evaluation.html)
    or in the *Ranking Measures and Loss Functions in Learning to Rank* paper, presented
    in 2009 at the Advances in Neural Information Processing Systems Conference.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A full description of this problem can be found at: [https://archive.ics.uci.edu/ml/datasets/Automobile](https://archive.ics.uci.edu/ml/datasets/Automobile).'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, let''s load the data. The CSV file has no header; therefore we
    will manually set the column names. Also, since the author of the dataset has
    released the information, all the `"?"` strings will be handled as missing data—that
    is, Pandas `NaN` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Although it doesn''t guarantee everything is perfect, let''s look at the first
    lines of the dataset. Here we''re able to identify the missing data (containing
    `NaN` values) and understand which features are categorical and which numerical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems we have many categorical features. Here, we have to think carefully
    about what to do. The dataset contains only 205 observations; therefore transforming
    all the categorical features to dummy features is not a great idea (we may end
    up with more features than observations). Let''s try to be very conservative with
    the number of features created. Carefully checking the features, we can use the
    following approach:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some categorical features are actually (wordy) numerical: they contain numbers
    indicating a number. For them, we just need to map words to numbers. In this case,
    no additional features are created.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Some other categorical features are actually binary (two doors versus four doors,
    diesel versus gas, and so on). For them, we can map the two levels to different
    values (0 and 1). Even here, we don't need to create additional features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the remaining should be dummy-encoded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This procedure is shown in the following cell. To create the first map, we
    simply use the `map` method provided by Pandas. For the second mapping, we use
    the `LabelEncoder` object provided by Scikit-learn; for the last one, we use the
    `get_dummies` function, as seen in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Adopting this conservative approach, the final number of columns is 66 (previously
    it was 26). Now, let's extract the target value vector out of the DataFrame, and
    then map every `NaN` value to the median of the feature, creating the observation
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why did we use the median (instead of the mean)? Because the dataset is so
    small that we don''t want to introduce new values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now, it's time to split the observations into training and testing. Since the
    dataset is very small, we decided to have the testing set made up of 25% of the
    observations (around 51 samples). Also, we tried to achieve a testing set containing
    the same percentage of samples for each class. For this purpose, we've used the
    `StratifiedKFold` class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is creating two functions: the first should map classes to vectors
    of probability for each class (for example, class -2 becomes the vector `[1.0,
    0.0, 0.0, 0.0, 0.0, 0.0]`; class +3 becomes the vector `[0.0, 0.0, 0.0, 0.0, 0.0,
    1.0]`, and so on). This step is required by the scoring function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second function we need is to check whether the classifier is trained on
    a dataset that includes all the classes (since we''re operating on a training
    set composed of only 153 samples, and we will use cross validation, it''s better
    to carefully check every step). To do so, we use a simple `assert` equality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it''s time to classify. We will initially use a simple `LogisticRegression`.
    Since we have a multiclass problem, we can use more than one CPU in the training
    process. After training the classifier, we print the `Ranking loss` and the `Ranking
    avg precision score` to have a baseline for comparison purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The baseline result is already not too bad. The `Ranking loss` is close to zero
    (and, in this case, the average label precision is close to `1`). Now we try to
    improve the solution, using a grid-search cross-validation. Since we have very
    few samples in the training set, we have to use a boosted validation, where each
    fold may contain samples appearing in other folds. `StratifiedShuffleSplit` is
    the best option, ensuring as well that the validation set contains the same percentage
    of samples for each class. We will create five folds, each of them containing
    70% of the training set as training, and the remaining 30 as testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we should create is a scoring function for the cross validation:
    Scikit-learn doesn''t include any learn-to-rank scoring function out of the box
    in the `GridSearchCV` object, therefore we have to build it. We decide to build
    it as the label ranking loss multiplied by `-1`: since the goal of the grid search
    is to maximize the score, we have to invert it to find its minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'With the hyper parameter optimization procedure, combined with the cross-validation,
    we''ve been able to improve the performance. Now, let''s check how the confusion
    matrix looks for this solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![A ranking problem](img/00140.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: It looks pretty diagonal, except for the -2 class (where we have indeed very
    few samples). Overall, we consider a ranking loss lower than 0.1 to be an excellent
    result.
  prefs: []
  type: TYPE_NORMAL
- en: A time series problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last problem we're going to see in this chapter is about prediction in time.
    The standard name for these problems is time series analysis, since the prediction
    is made on descriptors extracted in the past; therefore, the outcome at the current
    time will become a feature for the prediction of the next point in time. In this
    exercise, we're using the closing values for several stocks composing the Dow
    Jones index in 2011.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several features compose the dataset, but in this problem (to make a short
    and complete exercise) we''re just using the closing values of each week for each
    of the 30 measured stocks, ordered in time. The dataset spans six months: we''re
    using the first half of the dataset (corresponding to the first quarter of the
    year under observation, with 12 weeks) to train our algorithm, and the second
    half (containing the second quarter of the year, with 13 weeks) to test the predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, since we don't expect readers to have a background in economics, we've
    tried to make things as simple as possible. In a real-life situation, such a prediction
    will be too simple to get money out of the market, but in this short example we've
    tried to keep the focus on the time series analysis, dropping all the other inputs
    and sources.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The full description of this problem can be found at: [https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index](https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index).'
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the readme file distributed along with the dataset, there are
    no missing values; therefore, the loading operation is quite straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now try to decode the rows we''re interested in (stock and close): it
    seems that the closing values are all strings, starting with `$` and followed
    by the floating point value relative to the closing price. We should then select
    the correct columns and cast the closing price to the right data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now create a feature vector for each stock. In the simplest instance,
    it''s just a row containing the sorted closing prices for the 25 weeks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now build a baseline: we can try the regressor on the first 12 weeks,
    and then test it by recursively offsetting the data—that is, to predict the 13th
    week, we use the first 12 weeks; to predict the value at the 14th week, we use
    12 weeks ending with the 13th one. And so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, in this very simple approach, we build just a classifier for all
    the stocks, independently by their price, and we use both R² and MAE to score
    our learner for each week of analysis (a score for the 13^(th) week, one for the
    14^(th), and so on). Finally, we compute mean and variance of these scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'On the 13 testing weeks, the R² is 0.99 on average (with a variance of 0.0000157)
    and the MAE is 1.64 on average (with a variance of 0.48). That''s the baseline;
    let''s plot it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '![A time series problem](img/00141.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Are we sure that the value of 12 weeks ago is still a good predictor for the
    current week? Let''s now try to improve our scores by decreasing the training
    weeks. As an additional advantage, we will also have more training data. Let''s
    try using `5` (a little more than a month):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'With this approach, both R² and MAE have improved, on average, and their variance
    is perceptibly lower:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![A time series problem](img/00142.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since the approach seems to be working better, let''s now try to grid-search
    the best training length, spanning from 1 to 12:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The best trade-off is with `training_len=3`.
  prefs: []
  type: TYPE_NORMAL
- en: Open questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you've seen, in this example we didn't normalize the data, using stocks with
    high and low prices together. This fact may confuse the learner, since the observations
    don't have the same center. With a bit of preprocessing, we may obtain better
    results, applying a per-stock normalization. Can you think what else could we
    do, and how could we test the algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've explored four practical data science examples involving
    classifiers and regressors. We strongly encourage readers to read, understand,
    and try to add further steps, in order to boost performance.
  prefs: []
  type: TYPE_NORMAL
