- en: Chapter 9. Real-world Applications for Regression Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章。回归模型的实际应用
- en: We have arrived at the concluding chapter of the book. In respect of the previous
    chapters, the present one is very practical in its essence, since it mostly contains
    lots of code and no math or other theoretical explanation. It comprises four practical
    examples of real-world data science problems solved using linear models. The ultimate
    goal is to demonstrate how to approach such problems and how to develop the reasoning
    behind their resolution, so that they can be used as blueprints for similar challenges
    you'll encounter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到达了本书的结尾章节。与前面的章节相比，本章在本质上非常实用，因为它主要包含大量代码，而没有数学或其他理论解释。它包括使用线性模型解决的实际数据科学问题的四个实例。最终目标是展示如何处理此类问题以及如何发展其解决方案背后的推理，以便它们可以作为类似挑战的蓝图使用。
- en: For each problem, we will describe the question to be answered, provide a short
    description of the dataset, and decide the metric we strive to maximize (or the
    error we want to minimize). Then, throughout the code, we will provide ideas and
    intuitions that are key to successfully completing each one. In addition, when
    run, the code will produce verbose output from the modeling, in order to provide
    the reader with all the information needed to decide the next step. Due to space
    restrictions, output will be truncated so it just contains the key lines (the
    truncated lines are represented by `[…]` in the output) but, on your screen, you'll
    get the complete picture.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个问题，我们将描述要回答的问题，提供数据集的简要描述，并决定我们力求最大化的指标（或我们想要最小化的错误）。然后，在代码中，我们将提供成功完成每个问题的关键思想和直觉。此外，当运行代码时，模型将产生详细的输出，以便为读者提供决定下一步所需的所有信息。由于空间限制，输出将被截断，只包含关键行（截断的行在输出中用`[…]`表示），但在您的屏幕上，您将看到完整的画面。
- en: Tip
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In this chapter, each section was provided with a separate IPython Notebook.
    They are different problems, and each of them is developed and presented independently.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，每个部分都提供了一个独立的 IPython Notebook。它们是不同的问题，每个都是独立开发和展示的。
- en: Downloading the datasets
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载数据集
- en: In this section of the book, we will download all the datasets that are going
    to be used in the examples in this chapter. We chose to store them in separate
    subdirectories of the same folder where the IPython Notebook is contained. Note
    that some of them are quite big (100+ MB).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分，我们将下载本章示例中将要使用的所有数据集。我们选择将它们存储在包含 IPython Notebook 的同一文件夹的单独子目录中。请注意，其中一些相当大（100+
    MB）。
- en: Tip
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'We would like to thank the maintainers and the creators of the UCI dataset
    archive. Thanks to such repositories, modeling and achieving experiment repeatability
    are much easier than before. The UCI archive is from Lichman, M. (2013). UCI Machine
    Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢 UCI 数据集存档的维护者和创建者。多亏了这样的存储库，建模和实现实验可重复性比以前容易得多。UCI 存档来自 Lichman, M. (2013)。UCI
    机器学习仓库 [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]。加州大学欧文分校，信息与计算机科学学院，加州，欧文市。
- en: 'For each dataset, we first download it, and then we present the first couple
    of lines. First, this will help demonstrate whether the file has been correctly
    downloaded, unpacked, and placed into the right location; second, it will show
    the structure of the file itself (header, fields, and so on):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据集，我们首先下载它，然后展示前几行。首先，这有助于证明文件是否已正确下载、解包并放置在正确的位置；其次，它将展示文件本身的结构（标题、字段等）：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Time series problem dataset
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列问题数据集
- en: 'Dataset from: Brown, M. S., Pelosi, M. & Dirska, H. (2013). Dynamic-radius
    Species-conserving Genetic Algorithm for the Financial Forecasting of Dow Jones
    Index Stocks. Machine Learning and Data Mining in Pattern Recognition, 7988, 27-41.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来源：Brown, M. S., Pelosi, M. & Dirska, H. (2013)。用于道琼斯指数股票财务预测的动态半径物种保守遗传算法。模式识别中的机器学习和数据挖掘，7988，27-41。
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Time series problem dataset](img/00131.jpeg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![时间序列问题数据集](img/00131.jpeg)'
- en: Regression problem dataset
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归问题数据集
- en: 'Dataset from: Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and
    Paul Lamere. The Million Song Dataset. In Proceedings of the 12th International
    Society for Music Information Retrieval Conference (ISMIR), 2011.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来源：Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, 和 Paul Lamere.
    《百万歌曲数据集》。在2011年第12届国际音乐信息检索学会（ISMIR）会议论文集中。
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Regression problem dataset](img/00132.jpeg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![回归问题数据集](img/00132.jpeg)'
- en: Multiclass classification problem dataset
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类问题数据集
- en: 'Dataset from: Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis,
    and Philip K. Chan. Cost-based Modeling and Evaluation for Data Mining With Application
    to Fraud and Intrusion Detection: Results from the JAM Project.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来源：Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, 和 Philip
    K. Chan. 基于成本的建模与评估用于数据挖掘：应用于欺诈和入侵检测的JAM项目结果。
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Multiclass classification problem dataset](img/00133.jpeg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![多类分类问题数据集](img/00133.jpeg)'
- en: Ranking problem dataset
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排名问题数据集
- en: 'Creator/Donor: Jeffrey C. Schlimmer'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 创建者/捐赠者：Jeffrey C. Schlimmer
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Ranking problem dataset](img/00134.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![排名问题数据集](img/00134.jpeg)'
- en: A regression problem
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归问题
- en: Given some descriptors of a song, the goal of this problem is to predict the
    year when the song was produced. That's basically a regression problem, since
    the target variable to predict is a number in the range between 1922 and 2011.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一些歌曲的描述符，这个问题的目标是预测歌曲的生产年份。这基本上是一个回归问题，因为要预测的目标变量是一个介于1922年和2011年之间的数字。
- en: 'For each song, in addition to the year of production, 90 attributes are provided.
    All of them are related to the timbre: 12 of them relate to the timbre average
    and 78 attributes describe the timbre''s covariance; all the features are numerical
    (integer or floating point numbers).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每首歌曲，除了生产年份外，还提供了90个属性。所有这些都与音色相关：其中12个与音色平均值相关，78个属性描述了音色的协方差；所有特征都是数值（整数或浮点数）。
- en: The dataset is composed of more than half a million observations. As for the
    competition behind the dataset, the authors tried to achieve the best results
    using the first 463,715 observations as a training set and the remaining 51,630
    for testing.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集由超过五十万个观测值组成。至于数据集背后的竞赛，作者尝试使用前463,715个观测值作为训练集，剩余的51,630个用于测试。
- en: The metric used to evaluate the results is the **Mean Absolute Error** (**MAE**)
    between the predicted year and the real year of production for the songs composing
    the testing set. The goal is to minimize the error measure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估结果的指标是预测年份与测试集中歌曲的实际生产年份之间的**平均绝对误差**（**MAE**）。目标是使误差度量最小化。
- en: Note
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete description of this problem and additional information (about
    the feature extraction phase) can be found at the website: [https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的完整描述和附加信息（关于特征提取阶段）可以在以下网站上找到：[https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)
- en: 'Now, let''s start with some Python code. First of all, we load the dataset
    (remember, if that operation fails it means you should download the dataset by
    yourself before running the program in the previous section). Then, we split the
    training and testing parts according to the guidelines provided with the dataset.
    Finally, we print the size (in Megabytes) of the resulting DataFrame, in order
    to have an indication of the memory footprint of the dataset:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从一些Python代码开始。首先，我们加载数据集（记住，如果这个操作失败，意味着你应在运行上一节中的程序之前自行下载数据集）。然后，我们根据数据集提供的指南分割训练和测试部分。最后，我们打印出结果DataFrame的大小（以兆字节为单位），以便了解数据集的内存占用情况：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Our dataset is not all that small, since it's almost 400 MB. We should, therefore,
    be very smart and use any appropriate trick to cope with it without running out
    of memory (and becoming heavily reliant on the swap file) or even crashing our
    operating system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集接近400 MB，因此它并不算特别小。因此，我们应该非常聪明地使用任何适当的技巧来处理它，以免耗尽内存（并且严重依赖交换文件）或甚至使我们的操作系统崩溃。
- en: 'Let''s now get a baseline for comparisons: we will use the plain vanilla linear
    regression (vanilla means that there''s no additional flavor to it; as with plain
    ice cream, our model uses the standard hyper-parameters). We then print the training
    time (in seconds), the MAE in the train set, and the MAE in the test set:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们为比较设定一个基线：我们将使用普通的线性回归（vanilla表示没有额外的风味；就像普通的冰淇淋一样，我们的模型使用标准的超参数）。然后我们打印训练时间（以秒为单位），训练集的MAE和测试集的MAE：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Using linear regression, we can achieve a MAE of 6.8 in around 10 seconds.
    In addition, the learner seems stable and robust since there is no difference
    between MAE in the train set and MAE in the test set (thanks to the generalization
    power of linear regression). Let''s now try to do even better. We test a stochastic
    gradient descent variation, to see if we can achieve a better MAE more rapidly
    (eventually). We experiment with both a small and a high number of iterations:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性回归，我们可以在大约10秒内实现6.8的MAE。此外，学习器似乎稳定且健壮，因为训练集和测试集的MAE之间没有差异（归功于线性回归的泛化能力）。现在让我们尝试做得更好。我们测试了一种随机梯度下降的变化，看看我们是否能够更快地实现更好的MAE（最终）。我们尝试了少量和大量迭代：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The results seem to suggest that SGD Regression is not appropriate for the
    shape of the dataset: getting better results may require much perseverance and
    take a very long time.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 结果似乎表明，随机梯度下降回归不适用于数据集的形状：要获得更好的结果可能需要极大的毅力，并且需要非常长的时间。
- en: 'Now, we have two options: the first is to resort to an advanced classifier
    (such as an ensemble); otherwise, we can fine-tune the model with feature engineering.
    For this problem, let''s go for the second choice, since the main goal of this
    book is to work on linear models. Readers are strongly advised to try the first
    approach as comparison.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有两种选择：第一种是求助于高级分类器（如集成分类器）；否则，我们可以通过特征工程微调模型。对于这个问题，让我们选择第二种选择，因为本书的主要目标是研究线性模型。强烈建议读者尝试第一种方法进行比较。
- en: Let's now try to use the polynomial expansion of the features, followed by a
    feature selection step. This ensures that we have all the features, built on top
    on the features of the problem, in order to select the best and run through a
    linear regressor.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试使用特征的多项式展开，然后进行特征选择步骤。这确保了我们拥有所有基于问题特征构建的特征，以便选择最佳特征并通过线性回归器运行。
- en: Since we don't know a-priori which is the optimum number of features, let's
    treat that as a parameter and plot the MAE for the training and the testing set
    as a variable. Furthermore, since we're undertaking a regression task, feature
    selection should be targeting the best regression features; therefore the F-score
    for regression is used to rank and select the top K features.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们事先不知道最佳特征数量，让我们将其视为一个参数，并绘制训练集和测试集的MAE作为变量。此外，由于我们正在进行回归任务，特征选择应该针对最佳的回归特征；因此，使用回归的F分数来对和选择前K个特征进行排序。
- en: 'We immediately encounter a problem: polynomial feature expansion creates so
    many additional features. Since we are operating on a quite big dataset, we might
    have to subsample the training set. Let''s first count how many features are after
    the polynomial expansion:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立即遇到了一个问题：多项式特征扩展创建了如此多的额外特征。由于我们在处理一个非常大的数据集，我们可能不得不对训练集进行子采样。让我们首先计算多项式扩展后的特征数量：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'With more than 4,000 features, we should select at least 10 times more observations,
    in order not to risk overfitting. We shuffle the dataset, and select one twelfth
    of it (so the number of observations is around 40,000). To manage that, we can
    use K-fold, and select just the indexes composing the test set of the first piece:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当特征超过4,000个时，我们应该选择至少多10倍的数据观察，以避免过度拟合的风险。我们打乱数据集，并选择其十二分之一（因此观察数量约为40,000）。为了管理这一点，我们可以使用K折交叉验证，并仅选择第一部分的测试集索引：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![A regression problem](img/00135.jpeg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![回归问题](img/00135.jpeg)'
- en: 'It seems that we have found the optimal value for K, the number of selected
    features, in K=900\. At this point:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎我们已经找到了K的最佳值，即所选特征的数量，在K=900。在这个时候：
- en: 'The training MAE and the testing MAE diverge: if we are to use more than 900
    features, we may have start overfitting.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集的MAE和测试集的MAE发生了分歧：如果我们使用超过900个特征，我们可能开始过度拟合。
- en: The testing MAE is at its minimum. The reading for the MAE in the test set is
    6.70.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集的MAE达到了最低点。测试集MAE的读数为6.70。
- en: This is the best tradeoff between performance and training time (23 seconds).
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是性能和训练时间之间最佳的交易（23秒）。
- en: If you have a better machine (with 16 GB of RAM or more), you can re-run the
    last two cells, increasing the size of the training set (moving, for example,
    the number of folds from 12 to 8 or 4). The result should improve by some decimal
    places, although the training will be longer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一台更好的机器（具有16GB或更多RAM），你可以重新运行最后两个单元格，增加训练集的大小（例如，将折数从12改为8或4）。结果应该会提高几个小数位，尽管训练会变得更长。
- en: Testing a classifier instead of a regressor
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试分类器而不是回归器
- en: 'As an open problem (we''re not providing a solution), we could have solved
    this problem as a classification task, since the number of target variables is
    *just* 89 (which is higher than the majority of the classification problems, though).
    Following this path, you will encounter different kinds of problems (the MAE is
    wrongly defined on a classification problem). We encourage readers to have a go
    at this, and try to match the result we obtained with the regression learner;
    here is the first step:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个问题（我们不提供解决方案），我们可以将这个问题作为一个分类任务来解决，因为目标变量的数量“仅仅”是89（虽然这比大多数分类问题都要多）。沿着这条路径，你将遇到不同类型的问题（在分类问题中MAE被错误地定义了）。我们鼓励读者尝试一下，并尝试将我们获得的结果与回归学习者的结果相匹配；这里是第一步：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: An imbalanced and multiclass classification problem
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个不平衡的多类分类问题
- en: Given some descriptors of a sequence of packets, flowing to/from a host connected
    to the Internet, the goal of this problem is to detect whether that sequence signals
    a malicious attack or not. If it does, we should also classify the type of attack.
    That's a multiclass classification problem, since the possible labels are multiple
    ones.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个从连接到互联网的主机流向/来自的包序列的描述，这个问题的目标是检测该序列是否表示恶意攻击。如果是，我们还应该对攻击类型进行分类。这是一个多类分类问题，因为可能的标签有多个。
- en: 'For each observation, 42 features are revealed: please note that some of them
    are categorical, whereas others are numerical. The dataset is composed of almost
    5 million observations (but in this exercise we''re using just the first million,
    to avoid memory constraints), and the number of possible labels is 23\. One of
    them represents a non-malicious situation (*normal*); all the others represent
    22 different network attacks. Some attention should be paid to the fact that the
    frequencies of response classes are imbalanced: for some attacks there are multiple
    observations, for others just a few.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个观测，揭示了42个特征：请注意，其中一些是分类的，而其他的是数值的。数据集由近500万个观测组成（但在本练习中我们只使用前100万个，以避免内存限制），可能的标签数量为23。其中之一代表非恶意情况（*正常*）；其余的代表了22种不同的网络攻击。应该注意，响应类别的频率是不平衡的：对于某些攻击有多个观测，而对于其他攻击则只有几个。
- en: 'No instruction is given about how to split the train/test, or how to evaluate
    results. In this problem, we will adopt an exploratory goal: trying to reveal
    accurate information for all the labels. We warmly advise readers to take some
    further steps and tune the learner to maximize the precision of the detection,
    just for the malicious activities in the dataset.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 没有提供关于如何分割训练/测试集或如何评估结果的具体说明。在这个问题中，我们将采用探索性目标：尝试为所有标签揭示准确的信息。我们强烈建议读者采取一些额外步骤，调整学习器以最大化检测恶意活动的精确度。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The full description of this problem can be found at the website: [https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data](https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该问题的完整描述可以在网站上找到：[https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data](https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data).
- en: 'First at all, let''s load the data. The file doesn''t contain the header; therefore
    we have to specify the column names while loading it with pandas:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载数据。该文件不包含标题；因此，在用pandas加载时，我们必须指定列名：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s now check the first few lines of the loaded dataset (in order to understand
    the overall shape of the dataset), its size (in terms of observations and features),
    and the types of features (to separate categorical from numerical ones):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来检查加载的数据集的前几行（为了了解数据集的整体形状），其大小（以观测和特征计），以及特征类型（以区分分类和数值类型）：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'It seems we''re operating on a very big dataset, since it has 1M rows and 42
    columns, with some of them being categorical. Now, let''s separate the target
    variable from the features, encoding the strings (containing attack names) with
    ordinal numbers. To do so, we can use the `LabelEncoder` object:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它有1M行和42列，其中一些是分类的，看起来我们正在处理一个非常大的数据集。现在，让我们将目标变量从特征中分离出来，用序数编码包含攻击名称的字符串。为此，我们可以使用`LabelEncoder`对象：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Targets, variables are now in a separate array, encoded as integers. Let''s
    now remove the target column from the dataset, and one-hot encode all the categorical
    features. To do so, we can simply use the Pandas `get_dummies` function. The new
    shape of the dataset is therefore *larger*, because each level composing a categorical
    feature is now a binary feature:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 目标和变量现在在一个单独的数组中，编码为整数。现在让我们从数据集中删除目标列，并对所有分类特征进行独热编码。为此，我们可以简单地使用Pandas的`get_dummies`函数。因此，数据集的新形状因此更大，因为现在构成分类特征的每个级别都是一个二进制特征：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Since we have many available observations and many classes contain just a few
    samples, we can shuffle and split the dataset in two portions: one to be used
    in training, the other for testing:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有许多可用的观察结果，并且许多类别只包含少量样本，我们可以对数据集进行洗牌并分成两部分：一部分用于训练，另一部分用于测试：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Given the exploratory nature of our task, let''s now define a function to print
    the confusion matrix, normalized by the number of occurrences per each class:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的任务具有探索性，现在让我们定义一个函数来打印按每个类别的发生次数归一化的混淆矩阵：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Let's now create a baseline for this task. We will use a simple `SGDClassifier`,
    with logistic loss, in this first step. For both training and test sets we will
    print the overall accuracy of the solution, the normalized confusion matrix, and
    the classification report (containing the precision, recall, F1-score, and support
    for each class).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为这个任务创建一个基线。在这个第一步中，我们将使用一个简单的`SGDClassifier`，带有逻辑损失。对于训练集和测试集，我们将打印解决方案的整体准确率、归一化混淆矩阵和分类报告（包含每个类别的精确率、召回率、F1分数和支持）。
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![An imbalanced and multiclass classification problem](img/00136.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![一个不平衡的多类分类问题](img/00136.jpeg)'
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![An imbalanced and multiclass classification problem](img/00137.jpeg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![一个不平衡的多类分类问题](img/00137.jpeg)'
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Although the output is very long, some points are immediately visible in this
    baseline:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管输出非常长，但在这个基线中，一些要点立即显现：
- en: Accuracy is low (0.80), but the classification is resilient to overfitting.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率低（0.80），但分类对过拟合具有弹性。
- en: Just two vertical lines dominate the confusion matrix. This indicates that the
    classifier fits only two classes during the training phase. Not surprisingly,
    they are the most populated ones.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵中只有两条垂直线。这表明在训练阶段，分类器只拟合了两个类别。不出所料，它们是最多的。
- en: 'You can reach the same conclusion (that the class imbalance has influenced
    the results) by looking at the classification report: just a few classes have
    non-zero scores.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查看分类报告，你可以得出相同的结论（即类别不平衡影响了结果）：只有少数几个类别的得分不为零。
- en: Such a problem is a very frequent one, and it happens when you try to fit a
    linear learner on a strongly imbalanced dataset. Let's now try to oversample small
    classes, and sub-sample the most popular ones. In the following function, we implemented
    a bootstrap algorithm with replacement, where each class gets, in the output data,
    at least `min_samples_out` observations and up to `max_samples_out`. This should
    force the learning algorithm to *take account of* all classes with a similar weight.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这种问题非常常见，当你尝试在一个严重不平衡的数据集上拟合线性学习器时会发生。现在，让我们尝试对小的类别进行过采样，并对最流行的类别进行子采样。在下面的函数中，我们实现了一个带有替换的bootstrap算法，其中每个类别在输出数据中至少有`min_samples_out`个观察结果，最多有`max_samples_out`个。这应该迫使学习算法以相似权重考虑所有类别。
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we can try to do better than the baseline, training out the learner on
    this modified (balanced) training set, and then applying it on the test set:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以尝试比基线做得更好，通过在这个修改后的（平衡的）训练集上训练学习器，然后将其应用于测试集：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The results suggest we''re heading toward the right direction. The confusion
    matrix looks more diagonal (meaning that matches between rows and columns occur
    more on the diagonal), and the accuracy increases to 0.72 in the test set. Let''s
    now try some values to achieve hyperparameter optimization, and boost the score
    to its max. For that, we run a grid-search cross-validation, using three folds:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明我们正在朝着正确的方向前进。混淆矩阵看起来更接近对角线（这意味着行和列之间的匹配更多地发生在对角线上），测试集中的准确率提高到0.72。现在让我们尝试一些值来实现超参数优化，并将分数提升到最大。为此，我们运行网格搜索交叉验证，使用三折：
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Although we run a grid-search cross-validation, the results look the same as
    in the previous experiment. We now try a different approach: since there are many
    output classes, let''s try to use a `OneVsOne` strategy: instead of fitting one
    classifier per class, we fit a classifier for each pair of classes. That should
    result in a more accurate, although longer to train, model. Even here, each learner
    is cross-validated with a grid search and three folds:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们运行了网格搜索交叉验证，但结果看起来与之前的实验相同。我们现在尝试不同的方法：由于存在许多输出类别，让我们尝试使用`OneVsOne`策略：而不是为每个类别拟合一个分类器，我们为每一对类别拟合一个分类器。这应该会产生一个更准确、但训练时间更长的模型。即使在这里，每个学习器也是通过网格搜索和三折进行交叉验证的：
- en: '[PRE23]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The results are better, in both the training set and testing set. Let''s now
    try a logistic regressor instead of `SGDClassifier`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 结果在训练集和测试集中都更好。现在让我们尝试使用逻辑回归而不是`SGDClassifier`：
- en: '[PRE24]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![An imbalanced and multiclass classification problem](img/00138.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![一个不平衡的多类分类问题](img/00138.jpeg)'
- en: '[PRE25]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![An imbalanced and multiclass classification problem](img/00139.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![一个不平衡的多类分类问题](img/00139.jpeg)'
- en: '[PRE26]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The results look much better than the baseline and the previous solution. In
    fact:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来比基线和之前的解决方案都要好。事实上：
- en: The accuracy measured on the balanced training set is close to the one recorded
    on the test set. This ensures the generalization capabilities of the model.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在平衡的训练集上测量的准确率接近在测试集上记录的准确率。这确保了模型的泛化能力。
- en: The confusion matrix is *almost* diagonal. It means that all the classes have
    been included in the fitting (and the prediction) phase.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混淆矩阵几乎是对角线。这意味着所有类别都已包含在拟合（和预测）阶段。
- en: The precision/recall and F1 score are non-zero for many classes, even for those
    with little support.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于许多类别，包括支持度较小的类别，精确率/召回率和F1分数都不是零。
- en: At this point, we're satisfied with the solution. If you would like to dig further
    and test more model hypotheses on the full 5-million dataset, it's time now to
    move to non-linear classifiers. When doing so, please note in advance both the
    complexity and the running time required to get a prediction (after all, you're
    using a dataset containing more than 100 million values).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们对解决方案感到满意。如果您想进一步挖掘并测试整个五百万数据集上的更多模型假设，现在是时候转向非线性分类器了。在这样做的时候，请提前注意获取预测所需的复杂性和运行时间（毕竟，您正在使用包含超过一亿个值的数据库）。
- en: A ranking problem
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个排名问题
- en: 'Given some descriptors of a car and its price, the goal of this problem is
    to predict the degree to which the car is riskier than its price indicates. Actuaries
    in the insurance business call this process *symboling*, and the outcome is a
    rank: a value of +3 indicates the car is risky; -3 indicates that it''s pretty
    safe (although the lowest value in the dataset is -2).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一辆车及其价格的一些描述符，这个问题的目标是预测这辆车比其价格所表明的风险程度。保险行业的精算师称这个过程为*符号化*，结果是排名：+3表示这辆车有风险；-3表示它相当安全（尽管数据集中的最低值是-2）。
- en: The description of the car includes its specifications in terms of various characteristics
    (brand, fuel type, body style, length, and so on). Moreover, you get its price
    and normalized loss in use as compared to other cars (this represents the average
    loss per car per year, normalized for all cars within a certain car segment).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 车辆的描述包括其各种特征（品牌、燃料类型、车身风格、长度等）的规格。此外，您还可以获得与其他车辆相比的价格和标准化损失（这代表每辆车每年平均损失的均值，针对一定范围内的所有车辆进行了标准化）。
- en: There are 205 cars in the dataset, and the number of features is 25; some of
    them are categorical, and others are numerical. In addition, the dataset expressively
    states that there are some missing values, encoded using the string `"?"`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有205辆车，特征数量为25；其中一些是分类的，而另一些是数值的。此外，数据集明确指出存在一些缺失值，使用字符串`"?"`进行编码。
- en: 'Although it is not stated directly on the presentation page, the goal of our
    task is to minimize the *label ranking loss*, a measure that indicates how well
    we performed the ranking. This score works on probabilities, and a perfect rank
    gives a loss of zero. Using regression scores, such as MAE or MSE, has little
    relevance to this task, since the prediction must be an integer; also, a classification
    score such as `accuracy` makes no sense either, since it doesn''t tell us how
    far we are from the perfect solution. Another score we will see in the code is
    **label ranking average precision** (**LRAP**). In this case, a perfect ranked
    output has a score of one (exactly like precision in the sense of classification).
    More information about the metrics is available on the Scikit-learn website: [http://scikit-learn.org/stable/modules/model_evaluation.html](http://scikit-learn.org/stable/modules/model_evaluation.html)
    or in the *Ranking Measures and Loss Functions in Learning to Rank* paper, presented
    in 2009 at the Advances in Neural Information Processing Systems Conference.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'A full description of this problem can be found at: [https://archive.ics.uci.edu/ml/datasets/Automobile](https://archive.ics.uci.edu/ml/datasets/Automobile).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, let''s load the data. The CSV file has no header; therefore we
    will manually set the column names. Also, since the author of the dataset has
    released the information, all the `"?"` strings will be handled as missing data—that
    is, Pandas `NaN` values:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Although it doesn''t guarantee everything is perfect, let''s look at the first
    lines of the dataset. Here we''re able to identify the missing data (containing
    `NaN` values) and understand which features are categorical and which numerical:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'It seems we have many categorical features. Here, we have to think carefully
    about what to do. The dataset contains only 205 observations; therefore transforming
    all the categorical features to dummy features is not a great idea (we may end
    up with more features than observations). Let''s try to be very conservative with
    the number of features created. Carefully checking the features, we can use the
    following approach:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Some categorical features are actually (wordy) numerical: they contain numbers
    indicating a number. For them, we just need to map words to numbers. In this case,
    no additional features are created.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Some other categorical features are actually binary (two doors versus four doors,
    diesel versus gas, and so on). For them, we can map the two levels to different
    values (0 and 1). Even here, we don't need to create additional features.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the remaining should be dummy-encoded.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This procedure is shown in the following cell. To create the first map, we
    simply use the `map` method provided by Pandas. For the second mapping, we use
    the `LabelEncoder` object provided by Scikit-learn; for the last one, we use the
    `get_dummies` function, as seen in the previous example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Adopting this conservative approach, the final number of columns is 66 (previously
    it was 26). Now, let's extract the target value vector out of the DataFrame, and
    then map every `NaN` value to the median of the feature, creating the observation
    matrix.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Why did we use the median (instead of the mean)? Because the dataset is so
    small that we don''t want to introduce new values:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now, it's time to split the observations into training and testing. Since the
    dataset is very small, we decided to have the testing set made up of 25% of the
    observations (around 51 samples). Also, we tried to achieve a testing set containing
    the same percentage of samples for each class. For this purpose, we've used the
    `StratifiedKFold` class.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The next step is creating two functions: the first should map classes to vectors
    of probability for each class (for example, class -2 becomes the vector `[1.0,
    0.0, 0.0, 0.0, 0.0, 0.0]`; class +3 becomes the vector `[0.0, 0.0, 0.0, 0.0, 0.0,
    1.0]`, and so on). This step is required by the scoring function.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The second function we need is to check whether the classifier is trained on
    a dataset that includes all the classes (since we''re operating on a training
    set composed of only 153 samples, and we will use cross validation, it''s better
    to carefully check every step). To do so, we use a simple `assert` equality:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, it''s time to classify. We will initially use a simple `LogisticRegression`.
    Since we have a multiclass problem, we can use more than one CPU in the training
    process. After training the classifier, we print the `Ranking loss` and the `Ranking
    avg precision score` to have a baseline for comparison purposes:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The baseline result is already not too bad. The `Ranking loss` is close to zero
    (and, in this case, the average label precision is close to `1`). Now we try to
    improve the solution, using a grid-search cross-validation. Since we have very
    few samples in the training set, we have to use a boosted validation, where each
    fold may contain samples appearing in other folds. `StratifiedShuffleSplit` is
    the best option, ensuring as well that the validation set contains the same percentage
    of samples for each class. We will create five folds, each of them containing
    70% of the training set as training, and the remaining 30 as testing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we should create is a scoring function for the cross validation:
    Scikit-learn doesn''t include any learn-to-rank scoring function out of the box
    in the `GridSearchCV` object, therefore we have to build it. We decide to build
    it as the label ranking loss multiplied by `-1`: since the goal of the grid search
    is to maximize the score, we have to invert it to find its minimum:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'With the hyper parameter optimization procedure, combined with the cross-validation,
    we''ve been able to improve the performance. Now, let''s check how the confusion
    matrix looks for this solution:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![A ranking problem](img/00140.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
- en: It looks pretty diagonal, except for the -2 class (where we have indeed very
    few samples). Overall, we consider a ranking loss lower than 0.1 to be an excellent
    result.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: A time series problem
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last problem we're going to see in this chapter is about prediction in time.
    The standard name for these problems is time series analysis, since the prediction
    is made on descriptors extracted in the past; therefore, the outcome at the current
    time will become a feature for the prediction of the next point in time. In this
    exercise, we're using the closing values for several stocks composing the Dow
    Jones index in 2011.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Several features compose the dataset, but in this problem (to make a short
    and complete exercise) we''re just using the closing values of each week for each
    of the 30 measured stocks, ordered in time. The dataset spans six months: we''re
    using the first half of the dataset (corresponding to the first quarter of the
    year under observation, with 12 weeks) to train our algorithm, and the second
    half (containing the second quarter of the year, with 13 weeks) to test the predictions.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, since we don't expect readers to have a background in economics, we've
    tried to make things as simple as possible. In a real-life situation, such a prediction
    will be too simple to get money out of the market, but in this short example we've
    tried to keep the focus on the time series analysis, dropping all the other inputs
    and sources.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The full description of this problem can be found at: [https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index](https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the readme file distributed along with the dataset, there are
    no missing values; therefore, the loading operation is quite straightforward:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s now try to decode the rows we''re interested in (stock and close): it
    seems that the closing values are all strings, starting with `$` and followed
    by the floating point value relative to the closing price. We should then select
    the correct columns and cast the closing price to the right data type:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s now create a feature vector for each stock. In the simplest instance,
    it''s just a row containing the sorted closing prices for the 25 weeks:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s now build a baseline: we can try the regressor on the first 12 weeks,
    and then test it by recursively offsetting the data—that is, to predict the 13th
    week, we use the first 12 weeks; to predict the value at the 14th week, we use
    12 weeks ending with the 13th one. And so on.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, in this very simple approach, we build just a classifier for all
    the stocks, independently by their price, and we use both R² and MAE to score
    our learner for each week of analysis (a score for the 13^(th) week, one for the
    14^(th), and so on). Finally, we compute mean and variance of these scores:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'On the 13 testing weeks, the R² is 0.99 on average (with a variance of 0.0000157)
    and the MAE is 1.64 on average (with a variance of 0.48). That''s the baseline;
    let''s plot it:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![A time series problem](img/00141.jpeg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![时间序列问题](img/00141.jpeg)'
- en: 'Are we sure that the value of 12 weeks ago is still a good predictor for the
    current week? Let''s now try to improve our scores by decreasing the training
    weeks. As an additional advantage, we will also have more training data. Let''s
    try using `5` (a little more than a month):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能确定12周前的价值仍然是当前周的优良预测因子吗？现在让我们尝试通过减少训练周数来提高我们的分数。作为一个额外的优势，我们也将拥有更多的训练数据。让我们尝试使用`5`（略多于一个月）：
- en: '[PRE41]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'With this approach, both R² and MAE have improved, on average, and their variance
    is perceptibly lower:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，R²和MAE的平均值都有所提高，并且它们的方差明显降低：
- en: '[PRE42]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![A time series problem](img/00142.jpeg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![时间序列问题](img/00142.jpeg)'
- en: 'Since the approach seems to be working better, let''s now try to grid-search
    the best training length, spanning from 1 to 12:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种方法似乎效果更好，我们现在尝试网格搜索最佳训练长度，范围从1到12：
- en: '[PRE43]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The best trade-off is with `training_len=3`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳折衷方案是`training_len=3`。
- en: Open questions
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开放性问题
- en: As you've seen, in this example we didn't normalize the data, using stocks with
    high and low prices together. This fact may confuse the learner, since the observations
    don't have the same center. With a bit of preprocessing, we may obtain better
    results, applying a per-stock normalization. Can you think what else could we
    do, and how could we test the algorithm?
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，在这个例子中，我们没有对数据进行归一化处理，使用了价格高低不同的股票。这个事实可能会让学习者感到困惑，因为观察值没有相同的中心。通过一些预处理，我们可能会获得更好的结果，应用每只股票的归一化。你能想到我们还能做些什么，以及我们如何测试这个算法吗？
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've explored four practical data science examples involving
    classifiers and regressors. We strongly encourage readers to read, understand,
    and try to add further steps, in order to boost performance.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了涉及分类器和回归器的四个实际数据科学示例。我们强烈鼓励读者阅读、理解，并尝试添加更多步骤，以提高性能。
