["```py\nbt_model.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')\n```", "```py\ncurl -X POST \\\n> https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/blazingtext-endpoint-2019-01-04-01/invocations \\\n> -H 'cache-control: no-cache' \\\n> -H 'content-type: application/json' \\\n> -H 'postman-token: 7hsjkse-f24f-221e-efc9-af4c654d677a' \\\n> -d '{\"instances\": [\"This new deal will be the most modern, up-to-date, and balanced trade agreement in the history of our country, with the most advanced protections for workers ever developed\"]}'\n```", "```py\nimport sagemaker\nfrom sagemaker import get_execution_role\n\nsess = sagemaker.Session()\nrole = get_execution_role()\n```", "```py\nfrom sagemaker.predictor import json_serializer, RealTimePredictor\n\npredictor = RealTimePredictor(endpoint='blazingtext-endpoint-2019-01-04-01', serializer=json_serializer)\n```", "```py\npredictor.predict({\"instances\": [\"This new deal will be the most modern, up-to-date, and balanced trade agreement in the history of our country, with the most advanced protections for workers ever developed\"]})\n```", "```py\nb'[{\"prob\": [0.5000401735305786], \"label\": [\"__label__1\"]}]'\n```", "```py\nhousing_df = sql.read.csv(SRC_PATH + 'train.csv', \n                          header=True, inferSchema=True)\n```", "```py\nreduced_housing_df = housing_df.select(['crim', 'zn', 'indus', 'medv'])\n```", "```py\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\n\ntraining_features = ['crim', 'zn', 'indus']\nvector_assembler = VectorAssembler(inputCols=training_features,           \n               outputCol=\"features\")\nlinear = LinearRegression(featuresCol=\"features\", labelCol=\"medv\")\npipeline = Pipeline(stages=[vector_assembler, linear])\nmodel = pipeline.fit(reduced_housing_df)\n```", "```py\nmodel.save(\"file:///tmp/linear-model\")\n```", "```py\nfrom pyspark.ml import PipelineModel\nloaded_model = PipelineModel.load('/tmp/linear-model')\n```", "```py\nloaded_model.transform(reduced_housing_df.limit(3)).show()\n```", "```py\n+-------+----+-----+----+-------------------+------------------+\n| crim  | zn |indus|medv| features          | prediction       |\n+-------+----+-----+----+-------------------+------------------+\n|0.00632|18.0| 2.31|24.0|[0.00632,18.0,2.31]|27.714445239256854|\n|0.02731| 0.0| 7.07|21.6| [0.02731,0.0,7.07]|24.859566163416336|\n|0.03237| 0.0| 2.18|33.4| [0.03237,0.0,2.18]| 26.74953947801712|\n+-------+----+-----+----+-------------------+------------------+\n```", "```py\nfrom pyspark.sql.types import *\n\nschema = StructType([StructField('crim', DoubleType(), True),\n                    StructField('zn', DoubleType(), True),\n                    StructField('indus', DoubleType(), True)])\n```", "```py\nfrom pyspark.sql import Row\n\npredict_df = \nsql.createDataFrame([Row\n(crim=0.00632, zn=18.0,\nindus=2.31)],\nschema=schema)\n```", "```py\n+-------+----+-----+\n| crim  | zn |indus|\n+-------+----+-----+\n|0.00632|18.0| 2.31|\n+-------+----+-----+\n```", "```py\nloaded_model.transform(predict_df).show()\n```", "```py\n+-------+----+-----+-------------------+------------------+\n| crim  | zn |indus| features          |        prediction|\n+-------+----+-----+-------------------+------------------+\n|0.00632|18.0| 2.31|[0.00632,18.0,2.31]|27.714445239256854|\n+-------+----+-----+-------------------+------------------+\n```", "```py\ncurl 'http://127.0.0.1:5000/predict?crim=0.00632&zn=18.0&indus=2.31'\n```", "```py\n27.71\n```", "```py\nfrom flask import Flask\nfrom flask import request\nfrom pyspark.ml import PipelineModel\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SQLContext\nfrom pyspark.context import SparkContext\n\nsc = SparkContext('local', 'test')\nsql = SQLContext(sc)\napp = Flask(__name__)\nloaded_model = PipelineModel.load('/tmp/linear-model')\n\nschema = StructType([StructField('crim', DoubleType(), True),\n                    StructField('zn', DoubleType(), True),\n                    StructField('indus', DoubleType(), True)])\n\n@app.route('/predict', methods=['GET'])\ndef predict():\n   crim = float(request.args.get('crim'))\n   zn = float(request.args.get('zn'))\n   indus = float(request.args.get('indus'))\n   predict_df = sql.createDataFrame([Row(crim=crim, zn=zn, indus=indus)],schema=schema)\n   prediction = loaded_model.transform(predict_df).collect()[0].prediction\n   return str(prediction)\n```", "```py\nexport FLASK_APP=deploy_flask.py\nflask run\n```", "```py\n* Serving Flask app \"deploy_flask.py\"\n* Environment: production\n  WARNING: Do not use the development server in a production environment.\n  Use a production WSGI server instead.\n* Debug mode: off\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\n* Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n127.0.0.1 - - [13/Apr/2019 19:13:03] \"GET /predict?crim=0.00632&zn=18.0&indus=2.31 HTTP/1.1\" 200 -\n```"]