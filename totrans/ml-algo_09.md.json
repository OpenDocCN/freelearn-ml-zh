["```py\nfrom sklearn.datasets import make_blobs\n\nnb_samples = 1000\nX, _ = make_blobs(n_samples=nb_samples, n_features=2, centers=3, cluster_std=1.5)\n```", "```py\nfrom sklearn.cluster import KMeans\n\n>>> km = KMeans(n_clusters=3)\n>>> km.fit(X)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n random_state=None, tol=0.0001, verbose=0)\n\n>>> print(km.cluster_centers_)\n[[ 1.39014517,  1.38533993]\n [ 9.78473454,  6.1946332 ]\n [-5.47807472,  3.73913652]]\n```", "```py\nfrom sklearn.datasets import make_circles\n\n>>> nb_samples = 1000\n>>> X, Y = make_circles(n_samples=nb_samples, noise=0.05)\n```", "```py\n>>> km = KMeans(n_clusters=2)\n>>> km.fit(X)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n random_state=None, tol=0.0001, verbose=0)\n```", "```py\n>>> nb_clusters = [2, 3, 5, 6, 7, 8, 9, 10]\n\n>>> inertias = []\n\n>>> for n in nb_clusters:\n>>>    km = KMeans(n_clusters=n)\n>>>    km.fit(X)\n>>>    inertias.append(km.inertia_)\n```", "```py\nfrom sklearn.metrics import silhouette_score\n\n>>> nb_clusters = [2, 3, 5, 6, 7, 8, 9, 10]\n\n>>> avg_silhouettes = []\n\n>>> for n in nb_clusters:\n>>>    km = KMeans(n_clusters=n)\n>>>    Y = km.fit_predict(X)\n>>>    avg_silhouettes.append(silhouette_score(X, Y))\n```", "```py\nfrom sklearn.metrics import silhouette_samples\n\n>>> fig, ax = subplots(2, 2, figsize=(15, 10))\n\n>>> nb_clusters = [2, 3, 4, 8]\n>>> mapping = [(0, 0), (0, 1), (1, 0), (1, 1)]\n\n>>> for i, n in enumerate(nb_clusters):\n>>>    km = KMeans(n_clusters=n)\n>>>    Y = km.fit_predict(X)\n\n>>>    silhouette_values = silhouette_samples(X, Y)\n\n>>>    ax[mapping[i]].set_xticks([-0.15, 0.0, 0.25, 0.5, 0.75, 1.0])\n>>>    ax[mapping[i]].set_yticks([])\n>>>    ax[mapping[i]].set_title('%d clusters' % n)\n>>>    ax[mapping[i]].set_xlim([-0.15, 1])\n>>>    ax[mapping[i]].grid()\n>>>    y_lower = 20\n\n>>>    for t in range(n):\n>>>        ct_values = silhouette_values[Y == t]\n>>>        ct_values.sort()\n\n>>>        y_upper = y_lower + ct_values.shape[0]\n\n>>>        color = cm.Accent(float(t) / n)\n>>>        ax[mapping[i]].fill_betweenx(np.arange(y_lower, y_upper), 0, \n>>>                                     ct_values, facecolor=color, edgecolor=color)\n\n>>>        y_lower = y_upper + 20\n```", "```py\nfrom sklearn.metrics import calinski_harabaz_score\n\n>>> nb_clusters = [2, 3, 5, 6, 7, 8, 9, 10]\n\n>>> ch_scores = []\n\n>>> km = KMeans(n_clusters=n)\n>>> Y = km.fit_predict(X)\n\n>>> for n in nb_clusters:\n>>>    km = KMeans(n_clusters=n)\n>>>    Y = km.fit_predict(X)\n>>>    ch_scores.append(calinski_harabaz_score(X, Y))\n```", "```py\n>>> nb_noisy_datasets = 4\n\n>>> X_noise = []\n\n>>> for _ in range(nb_noisy_datasets):\n>>>    Xn = np.ndarray(shape=(1000, 2))\n>>>    for i, x in enumerate(X):\n>>>        if np.random.uniform(0, 1) < 0.25:\n>>>            Xn[i] = X[i] + np.random.uniform(-2.0, 2.0)\n>>>        else:\n>>>            Xn[i] = X[i]\n>>>    X_noise.append(Xn)\n```", "```py\nfrom sklearn.metrics.pairwise import pairwise_distances\n\n>>> instabilities = []\n\n>>> for n in nb_clusters:\n>>>    Yn = []\n>>> \n>>>    for Xn in X_noise:\n>>>        km = KMeans(n_clusters=n)\n>>>        Yn.append(km.fit_predict(Xn))\n\n>>> distances = []\n\n>>> for i in range(len(Yn)-1):\n>>>        for j in range(i, len(Yn)):\n>>>            d = pairwise_distances(Yn[i].reshape(-1, 1), Yn[j].reshape(-1, -1), 'hamming')\n>>>            distances.append(d[0, 0])\n\n>>>    instability = (2.0 * np.sum(distances)) / float(nb_noisy_datasets ** 2)\n>>>    instabilities.append(instability)\n```", "```py\nfrom sklearn.datasets import make_moons\n\n>>> nb_samples = 1000\n>>> X, Y = make_moons(n_samples=nb_samples, noise=0.05)\n```", "```py\nfrom sklearn.cluster import DBSCAN\n\n>>> dbs = DBSCAN(eps=0.1)\n>>> Y = dbs.fit_predict(X)\n```", "```py\nfrom sklearn.cluster import SpectralClustering\n\n>>> Yss = []\n>>> gammas = np.linspace(0, 12, 4)\n\n>>> for gamma in gammas:\n sc = SpectralClustering(n_clusters=2, affinity='rbf', gamma=gamma)\n Yss.append(sc.fit_predict(X))\n```", "```py\n>>> sc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors')\n>>> Ys = sc.fit_predict(X)\n```", "```py\nfrom sklearn.metrics import homogeneity_score\n\n>>> km = KMeans(n_clusters=4)\n>>> Yp = km.fit_predict(X)\n>>> print(homogeneity_score(Y, Yp))\n0.806560739827\n```", "```py\nfrom sklearn.metrics import completeness_score\n\n>>> km = KMeans(n_clusters=4)\n>>> Yp = km.fit_predict(X)\n>>> print(completeness_score(Y, Yp))\n0.807166746307\n```", "```py\nfrom sklearn.metrics import adjusted_rand_score\n\n>>> km = KMeans(n_clusters=4)\n>>> Yp = km.fit_predict(X)\n>>> print(adjusted_rand_score(Y, Yp))\n0.831103137285\n```"]