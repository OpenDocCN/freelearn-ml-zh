["```py\n    from azureml.train.hyperdrive import \\ \n      GridParameterSampling\n    from azureml.train.hyperdrive.parameter_expressions \\ \n      import *\n    grid_sampling = GridParameterSampling({\n        \"--first-layer-neurons\": choice(16, 32, 64, 128),\n        \"--second-layer-neurons\": choice(16, 32, 64, 128),\n        \"--batch-size\": choice(16, 32)\n    })\n    ```", "```py\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch-size', type=int, \n      default=50)\n    parser.add_argument('--epochs', type=int, default=30)\n    parser.add_argument('--first-layer-neurons', type=int, \n      dest='n_hidden_1', default=100)\n    parser.add_argument('--second-layer-neurons', \n      type=int, \n      dest='n_hidden_2', default=100)\n    parser.add_argument('--learning-rate', type=float, \n      default=0.1)\n    parser.add_argument('--momentum', type=float, \n      default=0.9)\n    args = parser.parse_args()\n    ```", "```py\n    from azureml.train.hyperdrive import PrimaryMetricGoal\n    primary_metric_name = \"accuracy\"\n    primary_metric_goal = PrimaryMetricGoal.MAXIMIZE\n    ```", "```py\n    from azureml.core.run import Run\n    run = Run.get_context()\n    run.log(\"accuracy\", float(val_accuracy))\n    ```", "```py\n    src = ScriptRunConfig(source_directory=\"train\", \n        script=\"train.py\",\n        compute_target=aml_cluster,\n        environment=tf_env) \n    ```", "```py\n    from azureml.train.hyperdrive import HyperDriveConfig\n    hyperdrive_run_config = HyperDriveConfig(\n        run_config=src,\n        hyperparameter_sampling=grid_sampling, \n        primary_metric_name=primary_metric_name, \n        primary_metric_goal=primary_metric_goal,\n        max_total_runs=32,\n        max_concurrent_runs=4)\n    ```", "```py\n    from azureml.core.experiment import Experiment\n    experiment = Experiment(workspace, experiment_name)\n    hyperdrive_run = experiment.submit(hyperdrive_run_config)\n    print(hyperdrive_run.get_portal_url())\n    ```", "```py\n    from azureml.train.hyperdrive import \\ \n      RandomParameterSampling\n    from azureml.train.hyperdrive.parameter_expressions \\\n       import *\n    random_sampling = RandomParameterSampling({\n        \"--learning-rate\": normal(10, 3),\n        \"--momentum\": uniform(0.5, 1.0),\n        \"--batch-size\": choice(16, 32, 64)\n    })\n    ```", "```py\n    max_total_runs = 25\n    max_duration_minutes = 60\n    ```", "```py\n    from azureml.train.hyperdrive import HyperDriveConfig\n    hyperdrive_run_config = HyperDriveConfig(\n        run_config=src,\n        hyperparameter_sampling=random_sampling, \n        primary_metric_name=primary_metric_name, \n        primary_metric_goal=primary_metric_goal,\n        max_total_runs=max_total_runs,\n        max_duration_minutes=max_duration_minutes)\n    ```", "```py\n    from azureml.core.experiment import Experiment\n    experiment = Experiment(workspace, experiment_name)\n    hyperdrive_run = experiment.submit(hyperdrive_run_config)\n    print(hyperdrive_run.get_portal_url())\n    ```", "```py\nevaluation_interval = 1\ndelay_evaluation = 10\n```", "```py\nfrom azureml.train.hyperdrive import MedianStoppingPolicy\nearly_termination_policy = MedianStoppingPolicy(\n    evaluation_interval=evaluation_interval,\n    delay_evaluation=delay_evaluation)\n```", "```py\ntruncation_percentage = 10\nevaluation_interval = 5\ndelay_evaluation = 10\n```", "```py\nfrom azureml.train.hyperdrive import TruncationSelectionPolicy\nearly_termination_policy = TruncationSelectionPolicy(\n    truncation_percentage=truncation_percentage,\n    evaluation_interval=evaluation_interval,\n    delay_evaluation=delay_evaluation)\n```", "```py\nslack_factor = 0.2\nevaluation_interval = 5\ndelay_evaluation = 10\nfrom azureml.train.hyperdrive import BanditPolicy\nearly_termination_policy = BanditPolicy(\n    slack_factor = slack_factor,\n    evaluation_interval=evaluation_interval,\n    delay_evaluation=delay_evaluation)\n```", "```py\nfrom azureml.train.hyperdrive import HyperDriveConfig\nhyperdrive_run_config = HyperDriveConfig(\n    run_config=src,\n    hyperparameter_sampling=grid_sampling, \n    policy=early_termination_policy,\n    primary_metric_name=\"accuracy\", \n    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE)\n```", "```py\nfrom azureml.widgets import RunDetails\nhyperdrive_run = exp.submit(hyperdrive_run_config)\nRunDetails(hyperdrive_run).show()\n```", "```py\nfrom azureml.train.hyperdrive import BayesianParameterSampling\nfrom azureml.train.hyperdrive.parameter_expressions import *\nbayesian_sampling = BayesianParameterSampling({\n    \"--learning-rate\": normal(10, 3),\n    \"--momentum\": uniform(0.5, 1.0),\n    \"--batch-size\": choice(16, 32, 64)\n})\n```", "```py\nmax_concurrent_runs = 4\nmax_total_runs = 100\n```", "```py\nfrom azureml.train.hyperdrive import HyperDriveConfig\nfrom azureml.core.experiment import Experiment\nhyperdrive_run_config = HyperDriveConfig(\n    estimator=estimator,\n    hyperparameter_sampling=bayesian_sampling, \n    primary_metric_name=primary_metric_name, \n    primary_metric_goal=primary_metric_goal,\n    max_total_runs=max_total_runs,\n    max_concurrent_runs=max_concurrent_runs)\nexperiment = Experiment(workspace, experiment_name)\nhyperdrive_run = experiment.submit(hyperdrive_run_config)\nprint(hyperdrive_run.get_portal_url())\n```", "```py\nautoml_settings = {\n  \"experiment_timeout_minutes\": 15,\n  \"n_cross_validations\": 3,\n  \"primary_metric\": 'accuracy',\n  \"featurization\": 'auto',\n  \"preprocess\": True,\n  \"verbosity\": logging.INFO,\n}\n```", "```py\nimport pandas as pd\ndf = pd.read_csv(\"train.csv\")\ntarget_column = \"survival\"\n```", "```py\nfrom sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.2)\n```", "```py\nfrom azureml.train.automl import AutoMLConfig\nautoml_config = AutoMLConfig(\n    task='classification',\n    debug_log='debug.log',\n    compute_target=aml_cluster,\n    training_data=df_train,\n    label_column_name=target_column,\n    **automl_settings)\n```", "```py\nfrom azureml.widgets import RunDetails\nautoml_run = experiment.submit(automl_config,\n    show_output=False)\nRunDetails(automl_run).show()\n```", "```py\nbest_run, best_model = remote_run.get_output()\n```", "```py\nfrom sklearn.metrics import accuracy_score\ny_test = df_test[target_column]\nX_test = df_test.drop(target_column, axis=1)\ny_pred = fitted_model.predict(X_test)\naccuracy_score(y_test, y_pred)\n```"]