- en: Heterogeneous Ensemble for Text Classification Using NLP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Spam filtering using an ensemble of heterogeneous algorithms
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis of movie reviews using an ensemble model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text classification is a widely studied area of language processing and text
    mining. Using text classification mechanisms, we can classify documents into predefined
    categories based on their content.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll take a look at how to classify short text messages that
    get delivered to our mobile phones. While some messages we receive are important,
    others might represent a serious threat to our privacy. We want to be able to
    classify the text messages correctly in order to avoid spam and to avoid missing
    important messages.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Spam filtering using an ensemble of heterogeneous algorithms
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the SMS Spam Collection dataset from the UCI ML repository to create
    a spam classifier. Using the spam classifier, we can estimate the polarity of
    these messages. We can use various classifiers to classify the messages either
    as spam or ham.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we opt for algorithms such as Naive Bayes, random forest, and
    support vector machines to train our models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'We prepare our data using various data-cleaning and preparation mechanisms.
    To preprocess our data, we will perform the following sequence:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Convert all text to lowercase
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove punctuation
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove stop words
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform stemming
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tokenize the data
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We also process our data using **t****erm frequency-inverse data frequency**
    (**TF-IDF**), which tells us how often a word appears in a message or a document.
    TF is calculated as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '`TF = No. of times a word appears in a document / Total No. of words in the
    document`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'TF-IDF numerically scores the importance of a word based on how often the word
    appears in a document or a collection of documents. Simply put, the higher the
    TF-IDF score, the rarer the term. The lower the score, the more common it is.
    The mathematical representation of TD-IDF would be as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '`tfidf(w,d,D)= tf(t,d) × idf(t,D)`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: where w represents the word, d represents a document and D represents the collection
    of documents.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we'll use the SMS spam collection dataset, which has labelled
    messages that have been gathered for cellphone spam research. This dataset is
    available in the UCI ML repository and is also provided in the GitHub repository.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We start by importing the required libraries:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that for this example we import libraries such as `nltk` to prepare our
    data. We also import the `CountVectorizer` and `TfidVectorizer` modules from `sklearn.feature_extraction`.
    These modules are used for feature extraction in ML algorithms.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'We reuse `plot_confusion_matrix` from the scikit-learn website to plot our
    confusion matrix. This is the same function that we''ve used in earlier chapters
    as well:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We set our working directory and read the dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that we use `encoding='utf8'`. This is to instruct the `read_csv()` method
    to use UTF encoding to read the file. Python comes with a number of codecs. An
    exhaustive list is available at [https://docs.python.org/3/library/codecs.html#standard-encodings](https://docs.python.org/3/library/codecs.html#standard-encodings).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用`encoding='utf8'`。这是为了指导`read_csv()`方法使用UTF编码来读取文件。Python附带了许多编解码器。完整的列表可在[https://docs.python.org/3/library/codecs.html#standard-encodings](https://docs.python.org/3/library/codecs.html#standard-encodings)找到。
- en: 'After reading the data, we check whether it has been loaded properly:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取数据后，我们检查它是否已正确加载：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We also check the number of observations and features in the dataset with `dataframe.shape`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用`dataframe.shape`检查数据集中的观测值和特征数量：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We take a look at the counts of spam and ham messages:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们查看垃圾邮件和正常邮件的数量：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can also visualize the proportion of spam and ham messages:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以可视化垃圾邮件和正常邮件的比例：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With the preceding code, we see the following plot:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的代码，我们看到以下图表：
- en: '![](img/9d71f67d-1ed3-4372-a211-55d2e492354f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9d71f67d-1ed3-4372-a211-55d2e492354f.png)'
- en: 'We also define a function to remove punctuation, convert the text to lowercase,
    and remove stop words:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一个函数来删除标点符号，将文本转换为小写，并删除停用词：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We apply the defined `process_text()` function to our text variable in the
    dataset:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义的`process_text()`函数应用于数据集中的文本变量：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We separate our feature and target variables, and split our data into `train`
    and `test` subsets:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将特征和目标变量分开，并将数据分为`train`和`test`子集：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We use the `CountVectorizer` module to convert the text into vectors:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`CountVectorizer`模块将文本转换为向量：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We also use the `TfidfVectorizer` module to convert the text into TF-IDF vectors:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用`TfidfVectorizer`模块将文本转换为TF-IDF向量：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s now move on to training our models. We use the following algorithms
    both on the count data and the TF-IDF data and see how the individual models perform:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续训练我们的模型。我们在计数数据和TF-IDF数据上使用以下算法，并查看单个模型的表现：
- en: Naive Bayes
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: Support vector machine
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Random forest
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: We also combine the model predictions to see the result from the ensemble.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还结合模型预测以查看集成结果。
- en: How to do it...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s begin with training our models, and see how they perform in this section:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从训练我们的模型开始，看看它们在本节中的表现：
- en: Train the model using the Naive Bayes algorithm. Apply this algorithm to both
    the count data and the TF-IDF data.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯算法训练模型。将此算法应用于计数数据和TF-IDF数据。
- en: 'The following is the code to train the Naive Bayes on the count data:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码用于在计数数据上训练朴素贝叶斯：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Take a look at the `train` and `test` accuracy for the preceding model:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 查看前面模型的`train`和`test`准确率：
- en: '![](img/2ffd5dab-de2d-49a5-927c-ab6c7608e50c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2ffd5dab-de2d-49a5-927c-ab6c7608e50c.png)'
- en: 'Print the classification report using the `classification_report()` method.
    Pass `Y_test` and `nb_pred_test` to the `classification_report()` method:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`classification_report()`方法打印分类报告。将`Y_test`和`nb_pred_test`传递给`classification_report()`方法：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This gives us the following output, which shows the `precision`, `recall`,
    `f1-score`, and `support` for each class in the target variable:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出，显示了目标变量中每个类的`precision`、`recall`、`f1-score`和`support`：
- en: '![](img/0befb29a-c9bb-40fa-9f71-95dd23122c88.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0befb29a-c9bb-40fa-9f71-95dd23122c88.png)'
- en: 'Pass `Y_test` and `nb_pred_test` to the `plot_confusion_matrix()` function
    to plot the confusion matrix, as follows:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Y_test`和`nb_pred_test`传递给`plot_confusion_matrix()`函数以绘制混淆矩阵，如下所示：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following plot shows us the true negative, false positive, false negative,
    and true positive values:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表显示了真正的负例、假正例、假负例和真正例的值：
- en: '![](img/c2c7b305-a462-4611-8e53-6bfe868ce3d4.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c2c7b305-a462-4611-8e53-6bfe868ce3d4.png)'
- en: Note that in the *Getting ready* section earlier, we used the `TfidfVectorizer` module
    to convert text into TF-IDF vectors.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在之前的*准备*部分中，我们使用了`TfidfVectorizer`模块将文本转换为TF-IDF向量。
- en: 'Fit the Naive Bayes model to the TF-IDF train data:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将朴素贝叶斯模型拟合到TF-IDF训练数据：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Check the performance statistics of the TF-IDF test data:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查TF-IDF测试数据的性能统计信息：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the following screenshot, we can see the output from the preceding code
    block:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图，我们可以看到前面代码块的结果：
- en: '![](img/b77d827c-6163-446d-ad09-b4efab591e6d.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b77d827c-6163-446d-ad09-b4efab591e6d.png)'
- en: 'Fit the model with the support vector machine classifier with the count data.
    Use `GridSearchCV` to perform a search over the specified parameter values for
    the estimator:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用支持向量机分类器对计数数据进行模型拟合。使用`GridSearchCV`在估计器的指定参数值范围内进行搜索：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The grid-search provides us with the optimum model. We get to see the parameter
    values and the score of the optimum model:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索为我们提供了最佳模型。我们可以看到最佳模型的参数值和得分：
- en: '![](img/ecdb5b29-7e5f-410e-94f2-3e40a8426650.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ecdb5b29-7e5f-410e-94f2-3e40a8426650.png)'
- en: 'Take a look at the `test` accuracy of the count data with the following code:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码查看计数数据的`test`准确率：
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here''s the output from `classification_report()` and the confusion matrix:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`classification_report()`和混淆矩阵的输出：
- en: '![](img/9c07bc83-17ce-42e4-96df-7056ff7fe50d.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c07bc83-17ce-42e4-96df-7056ff7fe50d.png)'
- en: 'Use SVM with the TF-IDF data:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TF-IDF数据使用SVM：
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following output shows the best score of the model trained with the SVM
    and RBF kernel on the TF-IDF data:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了使用SVM和RBF核在TF-IDF数据上训练的模型的最佳得分：
- en: '![](img/ece4a414-3e4f-4767-8574-665c1e7a94fd.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ece4a414-3e4f-4767-8574-665c1e7a94fd.png)'
- en: 'Print the classification report and the confusion matrix for the preceding
    model:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印前一个模型的分类报告和混淆矩阵：
- en: '![](img/ba4c57e8-fb26-4d52-9d83-62b8d47b5bf9.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ba4c57e8-fb26-4d52-9d83-62b8d47b5bf9.png)'
- en: 'Fit the random forest model on the count data with grid search cross-validation,
    as we did for SVM:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网格搜索交叉验证在计数数据上拟合随机森林模型，就像我们对SVM所做的那样：
- en: '[PRE20]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'A grid search of the random forest with the grid parameters returns the best
    parameters and the best score, as seen in the following screenshot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索随机森林的网格参数返回最佳参数和最佳得分，如下截图所示：
- en: '![](img/c25f7a64-fd07-4365-92f9-5213bfc47fe8.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c25f7a64-fd07-4365-92f9-5213bfc47fe8.png)'
- en: 'Using a classification report and a confusion matrix, take a look at the performance
    metrics of the random forest model with the count data on our test data:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分类报告和混淆矩阵，查看我们在测试数据上使用计数数据的随机森林模型的性能指标：
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The report is shown in the following screenshot:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 报告如下所示：
- en: '![](img/e81e861e-fe2f-4d73-80a0-abc8eae6df88.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e81e861e-fe2f-4d73-80a0-abc8eae6df88.png)'
- en: 'Build a model on a random forest with a grid-search on the TF-IDF data:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TF-IDF数据上使用网格搜索在随机森林上构建模型：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Take the output of the `predict_proba()` methods to gather the predicted probabilities
    from each model to plot the ROC curves. The full code is provided in the code
    bundle.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`predict_proba()`方法的输出取出来，收集每个模型的预测概率以绘制ROC曲线。完整的代码在代码包中提供。
- en: 'Here''s a sample of the code to plot the ROC curve from the Naive Bayes model
    on the count data:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是绘制基于朴素贝叶斯模型在计数数据上的ROC曲线的代码示例：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'With the complete code provided in the code bundle, we can view the ROC plot
    from all the models and compare them:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码包中提供了完整的代码后，我们可以查看所有模型的ROC图并进行比较：
- en: '![](img/385bf4df-cbb8-4f7d-a2f4-552a662169c1.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/385bf4df-cbb8-4f7d-a2f4-552a662169c1.png)'
- en: 'Average the probabilities from all the models and plot the ROC curves:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有模型的概率平均值并绘制ROC曲线：
- en: '[PRE24]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can see the average result of the ROC and AUC scores in the following screenshot:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下屏幕截图中看到ROC和AUC得分的平均值：
- en: '![](img/9c5a656e-c8ec-432c-b6c1-352c8a384032.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c5a656e-c8ec-432c-b6c1-352c8a384032.png)'
- en: 'Check the accuracy of the ensemble result. Create an array of the predicted
    results, as follows:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查集成结果的准确性。创建一个包含预测结果的数组，如下所示：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Calculate the mode of the predicted values for the respective observations
    to perform max-voting in order to get the final predicted result:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算各个观测值的预测值的众数，以执行最大投票以获得最终的预测结果：
- en: '[PRE26]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Plot the test accuracy for the models trained on the count data and TF-IDF
    data, respectively:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分别绘制在计数数据和TF-IDF数据上训练的模型的测试准确率：
- en: '![](img/9c36b9ad-7304-436c-9e63-8f6ddd2f907f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c36b9ad-7304-436c-9e63-8f6ddd2f907f.png)'
- en: How it works...
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the *Getting ready* section, we imported all the required libraries and defined
    the function to plot the confusion matrix. We read our dataset, using UTF8 encoding.
    We checked the proportion of spam and ham messages in our dataset and used the `CountVectorizer`
    and `TfidfVectorizer` modules to convert the texts into vectors and TF-IDF vectors,
    respectively.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在*准备就绪*部分，我们导入了所有必需的库并定义了绘制混淆矩阵的函数。我们使用UTF8编码读取我们的数据集。我们检查了数据集中垃圾邮件和正常邮件的比例，并使用`CountVectorizer`和`TfidfVectorizer`模块将文本转换为向量以及TF-IDF向量。
- en: After that, we built multiple models using various algorithms. We also applied
    each algorithm on both the count data and the TF-IDF data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们使用各种算法构建了多个模型。我们还对计数数据和TF-IDF数据都应用了每个算法。
- en: 'The models need to be built in the following order:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模型需要按照以下顺序构建：
- en: Naive Bayes on count data
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计数数据上的朴素贝叶斯
- en: Naive Bayes on TF-IDF data
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TF-IDF数据上的朴素贝叶斯
- en: SVM with RBF kernel on count data
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计数数据上的RBF核SVM
- en: SVM with RBF kernel on TF-IDF data
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于RBF核的SVM在TF-IDF数据上
- en: Random forest on count data
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计数数据的随机森林
- en: Random forest on TF-IDF data
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TF-IDF数据的随机森林
- en: The Naive Bayes classifier is widely used for text classification in machine
    learning. The Naive Bayes algorithm is based on the conditional probability of
    features belonging to a class. In *Step 1*, we built our first model with the
    Naive Bayes algorithm on the count data. In *Step 2*, we checked the performance
    metrics using `classification_report()` to see the `precision`, `recall`, `f1-score`,
    and `support`. In *Step 3*, we called `plot_confusion_matrix()` to plot the confusion
    matrix.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基于朴素贝叶斯分类器在机器学习中的文本分类被广泛使用。朴素贝叶斯算法基于特征属于一个类的条件概率。在**步骤 1**中，我们使用朴素贝叶斯算法在计数数据上构建了我们的第一个模型。在**步骤
    2**中，我们使用`classification_report()`检查性能指标，以查看`precision`、`recall`、`f1-score`和`support`。在**步骤
    3**中，我们调用`plot_confusion_matrix()`绘制混淆矩阵。
- en: Then, in *Step 4*, we built the Naive Bayes model on the TF-IDF data and evaluated
    the performance in *Step 5*. In *Step 6* and *Step 7*, we trained our model using
    the support vector machine on the count data, evaluated its performance using
    the output from `classification_report`, and plotted the confusion matrix. We
    trained our SVM model using the RBF kernel. We also showcased an example of using
    `GridSearchCV` to find the best parameters. In *Step 8* and *Step 9*, we repeated
    what we did in *Step* 6 and *Step* 7, but this time, we trained the SVM on TF-IDF
    data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在**步骤 4**中，我们在TF-IDF数据上构建了朴素贝叶斯模型，并在**步骤 5**中评估了其性能。在**步骤 6**和**步骤 7**中，我们使用支持向量机在计数数据上训练模型，使用`classification_report`的输出评估其性能，并绘制了混淆矩阵。我们使用RBF核训练了SVM模型。我们还展示了使用`GridSearchCV`寻找最佳参数的示例。在**步骤
    8**和**步骤 9**中，我们重复了**步骤 6**和**步骤 7**中的操作，但这次我们在TF-IDF数据上训练了SVM。
- en: In *Step 10*, we trained a random forest model using grid search on the count
    data. We set **gini** and **entropy** for the `criterion` hyperparameter. We also
    set multiple values for the parameters, such as `min_samples_split`, `max_depth`, 
    and `min_samples_leaf`. In *Step 11*, we evaluated the model's performance.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 10**中，我们使用网格搜索在计数数据上训练了一个随机森林模型。我们将`criterion`超参数设置为**gini**和**entropy**。我们还为参数设置了多个值，例如`min_samples_split`、`max_depth`和`min_samples_leaf`。在**步骤
    11**中，我们评估了模型的表现。
- en: We then trained another random forest model on the TF-IDF data in *Step 12*. Using
    the `predic_proba()` function, we got the class probabilities on our test data.
    We used the same in *Step 13* to plot the ROC curves with AUC scores annotated
    on the plots for each of the models. This helps us to compare the performance
    of the models.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在**步骤 12**中，我们在TF-IDF数据上训练了另一个随机森林模型。使用`predict_proba()`函数，我们在测试数据上得到了类别概率。我们在**步骤
    13**中使用相同的方法绘制了带有AUC分数的ROC曲线，标注在每个模型的图表上。这有助于我们比较模型的表现。
- en: In *Step 14*, we averaged the probabilities, which we got from the models for
    both the count and TF-IDF data. We then plotted the ROC curves for the ensemble
    results. From *Step 15* through to *Step 17*, we plotted the test accuracy for
    each of the models built on the count data as well as the TF-IDF data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 14**中，我们平均了从计数和TF-IDF数据模型中得到的概率，然后绘制了集成结果的ROC曲线。从**步骤 15**到**步骤 17**，我们绘制了基于计数数据和TF-IDF数据构建的每个模型的测试准确率。
- en: Sentiment analysis of movie reviews using an ensemble model
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用集成模型对电影评论进行情感分析
- en: Sentiment analysis is another widely studied research area in **natural language
    processing** (**NLP**). It's a popular task performed on reviews to determine
    the sentiments of comments provided by reviewers. In this example, we'll focus
    on analyzing movie review data from the **Internet Movie Database** (**IMDb**)
    and classifying it according to whether it is positive or negative.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是**自然语言处理**（**NLP**）中另一个广泛研究的研究领域。它是一个流行的任务，用于分析评论以确定评论者提供的评论的情感。在这个例子中，我们将专注于分析来自**互联网电影数据库**（**IMDb**）的电影评论数据，并根据其是正面还是负面进行分类。
- en: 'We have movie reviews in `.txt` files that are separated into two folders:
    negative and positive. There are 1,000 positive reviews and 1,000 negative reviews.
    These files can be retrieved from GitHub.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有存储在`.txt`文件中的电影评论，这些文件被分成了两个文件夹：负面和正面。有1,000条正面评论和1,000条负面评论。这些文件可以从GitHub获取。
- en: 'We have divided this case study into two parts:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这个案例研究分成了两部分：
- en: The first part is to prepare the dataset. We'll read the review files that are
    provided in the `.txt` format, append them, label them as positive or negative
    based on which folder they have been put in, and create a `.csv` file that contains
    the label and text.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一部分是准备数据集。我们将读取提供的 `.txt` 格式的评论文件，将它们附加起来，根据它们被放入哪个文件夹来标记为正面或负面，并创建一个包含标签和文本的
    `.csv` 文件。
- en: In the second part, we'll build multiple base learners on both the count data
    and on the TF-IDF data. We'll evaluate the performance of the base learners and
    then evaluate the ensemble of the predictions.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二部分，我们将在计数数据和 TF-IDF 数据上构建多个基础学习器。我们将评估基础学习器的性能，然后评估预测的集成。
- en: Getting ready
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We start by importing the required libraries:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库：
- en: '[PRE27]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We set our working folder as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将工作文件夹设置如下：
- en: '[PRE28]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We set our path variable and iterate through the `.txt` files in the folders.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置路径变量并遍历文件夹中的 `.txt` 文件。
- en: Note that we have a subfolder, `/txt_sentoken/pos`, which holds the TXT files
    for the positive reviews. Similarly, we have a subfolder, `/txt_sentoken/neg`,
    which holds the TXT files for the negative reviews.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们有一个子文件夹 `/txt_sentoken/pos`，其中包含正面评论的 TXT 文件。同样，我们还有一个子文件夹 `/txt_sentoken/neg`，其中包含负面评论的
    TXT 文件。
- en: The TXT files for the positive reviews are read and the reviews are appended
    in an array. We use the array to create a DataFrame, `df_pos`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正面评论的 TXT 文件被读取，评论被附加到一个数组中。我们使用这个数组创建一个 DataFrame，`df_pos`。
- en: '[PRE29]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: With the `head()` method, we take a look at the positive reviews.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `head()` 方法，我们查看正面评论。
- en: 'We also iterate through the TXT files in the negative folder to read the negative
    reviews and append them in an array. We use the array to create a DataFrame, `df_neg`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还遍历负文件夹中的 TXT 文件来读取负面评论，并将它们附加到一个数组中。我们使用这个数组创建一个 DataFrame，`df_neg`：
- en: '[PRE30]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Finally, we merge the positive and negative DataFrames into a single DataFrame
    using the `concat()` method:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 `concat()` 方法将正面和负面的 DataFrame 合并成一个单一的 DataFrame：
- en: '[PRE31]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can take a look at the prepared DataFrame with the `head()` and `tail()`
    methods:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `head()` 和 `tail()` 方法查看准备好的 DataFrame：
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding code gives us the following output:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码给出了以下输出：
- en: '![](img/d92dc9a6-754b-4c3f-ba5c-aec37b8ab46d.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d92dc9a6-754b-4c3f-ba5c-aec37b8ab46d.png)'
- en: From the preceding image, we notice that the positive and negative reviews have
    been added sequentially. The first half of the DataFrame holds the positive reviews,
    while the next half holds the negative reviews.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图像中，我们注意到正面和负面评论是顺序添加的。DataFrame 的前半部分包含正面评论，而后半部分包含负面评论。
- en: 'Let''s shuffle the data so that it doesn''t stay in sequential order:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打乱数据，使其不保持顺序：
- en: '[PRE33]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can now see that the data in the DataFrame is shuffled:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到 DataFrame 中的数据已经被打乱了：
- en: '![](img/5b4555d1-3c8c-4439-bff5-51dc0357469f.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b4555d1-3c8c-4439-bff5-51dc0357469f.png)'
- en: 'We validate the dimensions of the merged DataFrame to see whether it holds
    2,000 observations, which would be the result of combining the 1,000 negative
    and 1,000 positive reviews:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证合并后的 DataFrame 的维度，看看它是否包含 2,000 个观测值，这将是我们将 1,000 个负面评论和 1,000 个正面评论合并的结果：
- en: '[PRE34]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: From the preceding code, we notice that we have 2,000 observations and 2 columns.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的代码中，我们注意到我们有 2,000 个观测值和 2 列。
- en: 'We may also write the resulting DataFrame into another `.csv` file in order
    to avoid recreating the CSV file from the TXT files as we did in the preceding
    steps:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将结果 DataFrame 写入另一个 `.csv` 文件，以避免像之前步骤那样从 TXT 文件重新创建 CSV 文件：
- en: '[PRE35]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Next, we'll define the `plot_confusion_matrix()` method that we have used earlier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义之前使用过的 `plot_confusion_matrix()` 方法。
- en: 'We can now see the share of the positive and negative reviews in our data.
    In our case, the proportion is exactly 50:50:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到我们数据中正面和负面评论的占比。在我们的案例中，比例正好是 50:50：
- en: '[PRE36]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output of the preceding code can be seen in the following screenshot:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 之前代码的输出可以在以下屏幕截图中看到：
- en: '![](img/b9162d18-91d9-4185-a16e-967abbd75d46.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b9162d18-91d9-4185-a16e-967abbd75d46.png)'
- en: 'We will now replace the "positive" label with "1" and the "negative" label"
    with "0":'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将“正面”标签替换为“1”，“负面”标签替换为“0”：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We prepare our data using various data-cleaning and preparation mechanisms.
    We''ll follow the same sequence as we followed in the previous recipe to preprocess
    our data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用各种数据清理和准备机制来准备我们的数据。我们将遵循与之前配方中相同的顺序来预处理我们的数据：
- en: Convert all text to lowercase
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有文本转换为小写
- en: Remove punctuation
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除标点符号
- en: Remove stop words
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除停用词
- en: Perform stemming
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行词干提取
- en: Tokenize the data
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词数据
- en: 'Next, we''ll define a function to perform the preceding clean-up steps:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个函数来执行前面的清理步骤：
- en: '[PRE38]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We call the preceding function to process our text data:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用前面的函数来处理我们的文本数据：
- en: '[PRE39]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We'll now build our base learners and evaluate the ensemble result.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将构建我们的基础学习器并评估集成结果。
- en: How to do it...
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We start by importing the remaining libraries we need:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入我们需要的剩余库：
- en: 'Import the required libraries:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE40]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Separate the target and predictor variables:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分离目标变量和预测变量：
- en: '[PRE41]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Perform the train-test split of the data:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行数据的训练集-测试集划分：
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Use `CountVectorizer()` to convert the text into vectors:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`CountVectorizer()`将文本转换为向量：
- en: '[PRE43]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Use `TfidfVectorizer()` to convert the text into TF-IDF vectors:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`TfidfVectorizer()`将文本转换为TF-IDF向量：
- en: '[PRE44]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We proceed by training the base learners on the count data and on the TF-IDF data.
    We train the base learners with random forest models, Naive Bayes models, and
    the support-vector classifier models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续在计数数据和TF-IDF数据上训练基础学习器。我们使用随机森林模型、朴素贝叶斯模型和支持向量分类器模型训练基础学习器。
- en: 'Train the random forest model using grid-search on the count data:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网格搜索在计数数据上训练随机森林模型：
- en: '[PRE45]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Evaluate `precision`, `recall`, `f1-score`, `support`, and `accuracy`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估`precision`、`recall`、`f1-score`、`support`和`accuracy`：
- en: '[PRE46]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In the following screenshot, we can see the output of the preceding code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们可以看到前面代码的输出：
- en: '![](img/197e72d5-407a-4560-a910-694b77fdc3af.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/197e72d5-407a-4560-a910-694b77fdc3af.png)'
- en: 'Train a random forest model on the TF-IDF data using grid-search:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网格搜索在TF-IDF数据上训练随机森林模型：
- en: '[PRE47]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Evaluate the model''s performance:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型的性能：
- en: '[PRE48]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Train the Naive Bayes model on the count data and check the accuracy of the
    test data:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计数数据上训练朴素贝叶斯模型，并检查测试数据的准确率：
- en: '[PRE49]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Evaluate the other model''s performance parameters with `classification_report()`
    and the confusion matrix:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`classification_report()`和混淆矩阵评估其他模型的性能参数：
- en: '[PRE50]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Train the Naive Bayes model on the TF-IDF data and evaluate its performance
    the same way we did for earlier models:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TF-IDF数据上训练朴素贝叶斯模型，并按我们之前对早期模型所做的方式评估其性能：
- en: '[PRE51]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Train a model with a support vector classifier algorithm with the linear kernel
    on the count data. We also grid-search the `C` parameter for the SVC:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计数数据上使用具有线性核的支持向量分类器算法训练模型。我们还对SVC的`C`参数进行了网格搜索：
- en: '[PRE52]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Train a model with the support vector classifier algorithm with the linear
    kernel on the TF-IDF data. We also grid-search the `C` parameter for the SVC:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TF-IDF数据上使用具有线性核的支持向量分类器算法训练模型。我们还对SVC的`C`参数进行了网格搜索：
- en: '[PRE53]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Plot the ROC curve for each of the models. The code for one of the plots is
    shown here (the complete code is provided in this book''s code bundle):'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制每个模型的ROC曲线。以下是一个绘图代码示例（完整代码包含在本书的代码包中）：
- en: '[PRE54]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'In the following screenshot, we can compare the ROC curves of all the models
    we''ve trained:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们可以比较我们已训练的所有模型的ROC曲线：
- en: '![](img/9041a0b7-65de-4953-8d62-d9f33d01c47a.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9041a0b7-65de-4953-8d62-d9f33d01c47a.png)'
- en: 'Plot the ROC curves for the ensemble results on the count and TF-IDF data:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计数和TF-IDF数据上绘制集成结果的ROC曲线：
- en: '![](img/fc14287a-bf2c-4069-b5a0-5547aa7d1817.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fc14287a-bf2c-4069-b5a0-5547aa7d1817.png)'
- en: 'Calculate the accuracy of the ensemble with max-voting:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最大投票计算集成模型的准确率：
- en: '[PRE55]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Plot the test accuracy for each of the models trained on the count data and
    the TF-IDF data:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制在计数数据和TF-IDF数据上训练的每个模型的测试准确率：
- en: '[PRE56]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The following plot shows the accuracy comparison between the count data and
    the TF-IDF data across all models and the ensemble result:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了所有模型和集成结果在计数数据和TF-IDF数据上的准确率比较：
- en: '![](img/145caddb-b65c-419c-a1d2-a5ab4350fe56.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/145caddb-b65c-419c-a1d2-a5ab4350fe56.png)'
- en: How it works...
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We started by importing the required libraries. In this chapter, we used a module
    called `glob`. The `glob` module is used to define the techniques to match a specified
    pattern to a path, a directory, and a filename. We used the glob module to look
    for all the files in a specified path. After that, we used the `open()` method
    to open each file in read mode. We read each file and appended it to form a dataset
    with all the review comments. We also created a label column to tag each review
    with a positive or negative tag.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库。在本章中，我们使用了一个名为`glob`的模块。`glob`模块用于定义匹配指定模式到路径、目录和文件名的技术。我们使用glob模块来查找指定路径中的所有文件。之后，我们使用`open()`方法以读取模式打开每个文件。我们读取每个文件，并将其追加到形成包含所有评论的评论数据集。我们还创建了一个标签列，用于标记每个评论为正面或负面标签。
- en: However, after we appended all the positive and negative reviews, we noticed
    that they were added sequentially, which means the first half held all the positive
    reviews and the second half contained the negative reviews. We shuffled the data
    using the `shuffle()` method.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们添加了所有正面和负面评论之后，我们注意到它们是按顺序添加的，这意味着前半部分包含了所有正面评论，而后半部分包含了负面评论。我们使用`shuffle()`方法对这些数据进行随机排序。
- en: We cleaned our data by converting it to lowercase, removing the punctuation
    and stop words, performing stemming, and tokenizing the texts to create feature
    vectors.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将其转换为小写、删除标点符号和停用词、执行词干提取和分词来清理数据，以创建特征向量。
- en: In the *How to do it...* section, we started by importing the libraries in *Step
    1*. In *Step 2*, we separated our target and feature variables into *X* and *Y*.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在**如何做...**部分，我们首先在**第1步**中导入了库。在**第2步**中，我们将目标变量和特征变量分别分离到**X**和**Y**。
- en: We split our data into train and test subsets in S*tep 3*. We used `test_size=.3`
    to split the data into train and test subsets.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在**第3步**中将数据分为训练集和测试集。我们使用`test_size=.3`将数据分为训练集和测试集。
- en: In S*tep 4* and S*tep 5*, we used `CountVectorizer()` and `TfidfVectorizer()`
    to convert the text into vectors and the text into TF-IDF vectors, respectively.
    Note that with `CountVectorizer()`, we generated the `count_train` and `count_test`
    datasets. With `TfidfVectorizer()`, we generated the `tfidf_train` and `tfidf_test`
    datasets.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第4步**和**第5步**中，我们使用了`CountVectorizer()`和`TfidfVectorizer()`将文本转换为向量，并将文本转换为TF-IDF向量。注意，使用`CountVectorizer()`，我们生成了`count_train`和`count_test`数据集。使用`TfidfVectorizer()`，我们生成了`tfidf_train`和`tfidf_test`数据集。
- en: In *Step 6*, we set our hyperparameters for grid-search to train a random forest
    model. We trained our random forest model on the count data and checked our train
    and test accuracy.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第6步**中，我们设置了网格搜索的超参数来训练一个随机森林模型。我们在计数数据上训练了我们的随机森林模型，并检查了我们的训练和测试准确率。
- en: We used the `predict()` and `predict_proba()` methods on our test data for all
    the models we built to predict the class as well as the class probabilities.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对构建的所有模型在测试数据上使用了`predict()`和`predict_proba()`方法来预测类别以及类别概率。
- en: In *Step 7*, we generated the confusion matrix to evaluate the model's performance
    for the random forest model we built in the preceding step. In *Step 8* and *Step
    9*, we repeated the training for another random forest model on the TF-IDF data
    and evaluated the performance. We trained the Naive Bayes model on the count data
    and the TF-IDF data from *Step 10* through to *Step 12*.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第7步**中，我们生成了混淆矩阵来评估我们在前一步构建的随机森林模型的表现。在**第8步**和**第9步**中，我们在TF-IDF数据上对另一个随机森林模型进行了重复训练，并评估了其性能。从**第10步**到**第12步**，我们在计数数据和TF-IDF数据上训练了朴素贝叶斯模型。
- en: In *Step 13* and *Step 14*, we trained the support vector classifier algorithm
    with the linear kernel on the count data and the TF-IDF data, respectively. In
    *Step 15*, we plotted the ROC curves with the AUC score for each of the base learners
    we built. We also plotted the RUC curves for the ensemble in *Step 16* to compare
    the performance with the base learners. Finally, in *Step 17*, we plotted the
    test accuracy of each of the models on the count and TF-IDF data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第13步**和**第14步**中，我们分别使用线性核在计数数据和TF-IDF数据上训练了支持向量机分类算法。在**第15步**中，我们为构建的每个基本学习器绘制了ROC曲线和AUC分数。在**第16步**中，我们还绘制了集成模型的RUC曲线，以比较与基本学习器的性能。最后，在**第17步**中，我们绘制了每个模型在计数和TF-IDF数据上的测试准确率。
- en: There's more...
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In today’s world, the availability and flow of textual information are limitless.
    This means we need various techniques to deal with these textual matters to extract
    meaningful information. For example, **parts-of-speech (POS) tagging** is one
    of the fundamental tasks in the NLP space. **POS tagging** is used to label words
    in a text with their respective parts of speech. These tags may then be used with more
    complex tasks, such as syntactic and semantic parsing, **machine translation**
    (**MT**), and question answering.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今世界，文本信息的可用性和流动是无限的。这意味着我们需要各种技术来处理这些文本问题，以提取有意义的信息。例如，**词性标注（POS）**是自然语言处理（NLP）空间中的基本任务之一。**词性标注**用于将文本中的单词标注为它们各自的词性。这些标签可以用于更复杂的任务，如句法和语义解析、**机器翻译（MT**）和问答。
- en: 'There are eight main parts of speech:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有八个主要词性：
- en: Nouns
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名词
- en: Pronouns
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代词
- en: Adjectives
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形容词
- en: Verbs
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动词
- en: Adverbs
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 副词
- en: Prepositions
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介词
- en: Conjunctions
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连词
- en: 'Interjections:'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 呼语：
- en: '![](img/6ab29f62-59f4-4509-99e2-976ee50b21b6.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6ab29f62-59f4-4509-99e2-976ee50b21b6.png)'
- en: 'The NLTK library has functions to get POS tags that can be applied to texts
    after tokenization. Let''s import the required libraries:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK 库有在分词后应用于文本的获取词性标注的功能。让我们导入所需的库：
- en: '[PRE57]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We take our previously created DataFrame `df_moviereviews`. We convert text
    into lowercase:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用之前创建的 DataFrame `df_moviereviews`。我们将文本转换为小写：
- en: '[PRE58]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We preprocess the text by removing stop words, punctuation, lemmatization,
    and tokenization:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过去除停用词、标点符号、词形还原和分词来预处理文本：
- en: '[PRE59]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We take a look at the list of the first 10 tokens from the first movie review:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下第一篇电影评论的前10个标记词列表：
- en: '[PRE60]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'This generates the following output:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下输出：
- en: '![](img/5c975229-a885-4037-afc2-c6d12b525fbd.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c975229-a885-4037-afc2-c6d12b525fbd.png)'
- en: 'We perform POS tagging:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行词性标注：
- en: '[PRE61]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We print the first 10 POS tags for the first movie review:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们打印出第一篇电影评论的前10个词性标注：
- en: '[PRE62]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We see the POS tagged words:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到词性标注的单词：
- en: '![](img/089f0a97-2f31-4b4b-8e9a-c4f8d5165df3.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/089f0a97-2f31-4b4b-8e9a-c4f8d5165df3.png)'
- en: '**Chunking** is another process that can add more structure to POS tagging. Chunking
    is used for entity detection; it tags multiple tokens to recognize them as meaningful
    entities. There are various chunkers available; `NLTK` provides `ne_chunk`, which
    recognizes people (names), places, and organizations. Other frequently used chunkers
    include `OpenNLP`, `Yamcha`, and `Lingpipe`. It''s also possible to use a combination
    of chunkers and apply max-voting on the results to improve the classification''s
    performance.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**分块处理**是另一个可以增加词性标注结构性的过程。分块处理用于实体检测；它将多个标记词标记为有意义的实体。有多种分块器可供选择；`NLTK` 提供了
    `ne_chunk`，它可以识别人名（姓名）、地点和组织。其他常用的分块器包括 `OpenNLP`、`Yamcha` 和 `Lingpipe`。还可以使用分块器的组合，并对结果应用最大投票法来提高分类性能。'
