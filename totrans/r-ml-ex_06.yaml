- en: Chapter 5. Credit Risk Detection and Prediction – Descriptive Analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last two chapters, you saw some interesting problems revolving around
    the retail and e-commerce domains. You now know how to detect and predict shopping
    trends from shopping patterns as well as how to build recommendation systems.
    If you remember from [Chapter 1](part0014_split_000.html#DB7S2-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 1. Getting Started with R and Machine Learning"), *Getting started with
    R and Machine Learning* that the applications of machine learning are diverse,
    we can apply the same concepts and techniques to solve a wide variety of problems
    in the real world. We will be tackling a completely new problem here, but hold
    on to what you have learnt because several concepts you learnt previously will
    come in handy soon!
  prefs: []
  type: TYPE_NORMAL
- en: In the next couple of chapters, we will be tackling a new problem related to
    the financial domain. We will be looking at the bank customers of a particular
    German bank who could be credit risks for the bank, based on some data that has
    been previously collected. We will perform descriptive and exploratory analysis
    on this data to highlight different potential features in the dataset and also
    look at their relationship with credit risk. In the next step, we will be building
    predictive models using machine learning algorithms and these data features to
    detect and predict customers who could be potential credit risks. You may remember
    that the two main things that we need to do this analysis to remain unchanged
    are data and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: You might be surprised to know that risk analysis is one of the top most focus
    areas of financial organizations including in banks, investment firms, insurance
    firms, and brokerage firms. Each of these organizations often has dedicated teams
    for solving problems revolving around risk analysis. Some examples of risk which
    are frequently analyzed include credit risk, sales risk, fraud related risks,
    and many more.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be focusing on the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive analytics of our credit risk dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domain knowledge of the credit risk problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed analysis of dataset features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploratory analysis of the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizations on various data features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical tests to determine feature significance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Always remember that domain knowledge is essential before solving any machine
    learning problem because otherwise we will end up applying random algorithms and
    techniques blindly which may not give the right results.
  prefs: []
  type: TYPE_NORMAL
- en: Types of analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start tackling our next challenge, it will be useful to get an idea
    of the different types of analytics which broadly encompass the data science domain.
    We use a variety of data mining and machine learning techniques to solve different
    data problems. However, depending on the mechanism of the technique and its end
    result, we can broadly classify analytics into four different types which are
    explained next:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Descriptive analytics**: This is what we use when we have some data to analyze.
    We start with looking at the different attributes of the data, extract meaningful
    features, and use statistics and visualizations to understand what has already
    happened. The main aim of descriptive analytics is to get a broad idea of what
    kind of data we are dealing with and summarize what has happened in the past.
    Above almost 80% of all analytics in businesses today are descriptive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diagnostic analytics**: This is sometimes clubbed together with descriptive
    analytics. Here the main objective is to delve deeper into the data to find specific
    patterns and answer questions such as why did this occur. Usually, it involves
    root-cause analysis to come to the root of why something happened and what were
    the main factors involved in doing during its occurrence. Sometimes techniques
    such as regression modeling help in achieving this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictive analytics**: This is the final step in any analytics pipeline.
    Once you have built consistent and stable predictive models with a good flow of
    clean data for predictions, you can build systems which utilize this and start
    prescribing actions which you might take to improve your business. Do remember
    that predictive modeling can only predict what might happen in the future because
    all models are probabilistic in nature and nothing is 100 percent certain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prescriptive analytics**: This is the final step in any analytics pipeline
    if you are in the stage that you have built consistent predictive models with
    a good flow of clean data such that you are able to predict what might happen
    in the future. Then you can build systems which utilize this and start prescribing
    actions which you might take to improve your business. Do remember that you need
    working predictive models with good data and an excellent feedback mechanism to
    achieve this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most organizations do a lot of descriptive analytics and some amount of predictive
    analytics. However, it is really difficult to implement prescriptive analytics
    due to the ever changing business conditions and data streams and problems associated
    with that, the most common one being data sanitization issues. We will be touching
    upon descriptive analytics in this chapter before moving on to predictive analytics
    in the next chapter to solve our problem related to credit risk analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Our next challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have dealt with some interesting applications of machine learning in the
    e-commerce domain in the last couple of chapters. For the next two chapters, our
    big challenge will be in the financial domain. We will be using data analysis
    and machine learning techniques to analyze financial data from a German bank.
    This data will contain a lot of information regarding customers of that bank.
    We will be analyzing that data in two stages which include descriptive and predictive
    analytics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Descriptive**: Here we will look closely at the data and its various attributes.
    We will perform descriptive analysis and visualizations to see the kind of features
    we are dealing with and how they might be related to credit risk. The data we
    will be dealing with here consists of labeled data already and we will be able
    to see how many customers were credit risks and how many weren''t. We will also
    look closely at each feature in the data and understand its significance which
    will be useful in the next step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictive**: Here we will focus more on the machine learning algorithms
    used in predictive modeling to build predictive models using the data we have
    already acquired in the previous step. We will be using various machine learning
    algorithms and testing the accuracy of the models when predicting if a customer
    could be a potential credit risk. We will be using labeled data to train the model
    and then test the models on several data instances, comparing our predicted result
    with the actual result to see how well our models perform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The significance of predicting credit risks is quite useful for financial organizations,
    such as banks that have to often deal with loan applications from their customers.
    They have to then make the decision to approve or deny the loan based on information
    they have about the customer. If they have a robust machine learning system built
    in place which can analyze the data about the customer and say which customers
    might be credit risks, then they can prevent losses to their business by not approving
    loans to such customers.
  prefs: []
  type: TYPE_NORMAL
- en: What is credit risk?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have been using this term **credit risk** since the start of this chapter
    and many of you might be wondering what exactly does this mean, even though you
    might have guessed it after reading the previous section. Here, we will be explaining
    this term clearly so that you will have no problem in understanding the data and
    its features in the subsequent sections when we will be analyzing the data.
  prefs: []
  type: TYPE_NORMAL
- en: The standard definition of credit risk is the risk of defaulting on a debt which
    takes place due to the borrower failing to make the required debt payments in
    time. This risk is taken by the lender since the lender incurs losses of both
    the principal amount as well as the interest on it.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we will be dealing with a bank which acts as the financial organization
    giving out loans to customers who apply for them. Hence, customers who might default
    on the loan payment would be credit risks for the bank. By analyzing customer
    data and applying machine learning algorithms on it, the bank will be able to
    predict in advance which customers might be potential credit risks. This will
    help in risk mitigation and in minimizing losses by not giving away loans to customers
    who could be credit risks for the bank.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first step in our data analysis pipeline is to get the dataset. We have
    actually cleaned the data and provided meaningful names to the data attributes
    and you can check that out by opening the `german_credit_dataset.csv` file. You
    can also get the actual dataset from the source which is from the Department of
    Statistics, University of Munich through the following URL: [http://www.statistik.lmu.de/service/datenarchiv/kredit/kredit_e.html](http://www.statistik.lmu.de/service/datenarchiv/kredit/kredit_e.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the data and then run the following commands by firing up
    R in the same directory with the data file, to get a feel of the data we will
    be dealing with in the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The following figure shows the first six rows of the data. Each column indicates
    an attribute of the dataset. We will be focusing on each attribute in more detail
    later.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting the data](img/00139.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To get detailed information about the dataset and its attributes, you can use
    the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will enable you to get a quick look at the total number of
    data points you are dealing with, which includes the number of records, the number
    of attributes, and the detailed information about each attribute including things
    such as the attribute name, type, and some samples of attribute values, as you
    can see in the following screenshot. Using this, we can get a good idea about
    the different attributes and their data types so that we know what transformations
    to apply on them and what statistical methods to use during descriptive analytics.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting the data](img/00140.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding output, you can see that our dataset has a total of 1000
    records, where each record deals with data points pertaining to one bank customer.
    Each record has various data points or attributes describing the data and we have
    a total of 21 attributes for each record. The data type and sample values for
    each attribute are also shown in the previous image.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do note that by default R has assigned the `int` datatype to the variables based
    on their values but we will be changing some of that in our data preprocessing
    phase based on their actual semantics.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be focusing on data preprocessing which includes data
    cleaning, transformation, and normalizations if required. Basically, we perform
    operations to get the data ready before we start performing any analysis on it.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with missing values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There will be situations when the data you are dealing with will have missing
    values, which are often represented as `NA` in R. There are several ways to detect
    them and we will show you a couple of ways next. Note that there are several ways
    in which you can do this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `is.na` function is really useful as it helps in finding out if any element
    has an `NA` value in the dataset. There is another way of doing the same by using
    the `complete.cases` function, which essentially returns a logical vector saying
    whether the rows are complete and if they have any `NA` values. You can check
    if the total records count has decreased compared to the original dataset as then
    you will know that you have some missing values in the dataset. Fortunately, in
    our case, we do not have any missing values. However, in the future if you are
    dealing with missing values, there are various ways to deal with that. Some of
    them include removing the rows with missing values by using functions such as
    `complete.cases`, or filling them up with a value which could be the most frequent
    value or the mean, and so on. This is also known as missing value imputation and
    it depends on the variable attribute and the domain you are dealing with. Hence,
    we won't be focusing too much in this area here.
  prefs: []
  type: TYPE_NORMAL
- en: Datatype conversions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We had mentioned earlier that by default all the attributes of the dataset
    had been declared as `int`, which is a numeric type by R, but it is not so in
    this case and we have to change that based on the variable semantics and values.
    If you have taken a basic course on statistics, you might know that usually we
    deal with two types of variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Numeric variables**: The values of these variables carry some mathematical
    meaning. This means that you can carry out mathematical operations on them, such
    as addition, subtraction, and so on. Some examples can be a person''s age, weight,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorical variables**: The values of these variables do not have any mathematical
    significance and you cannot perform any mathematical operations on them. Each
    value in this variable belongs to a specific class or category. Some examples
    can be a person''s gender, job, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since all the variables in our dataset have been converted to numeric by default,
    we will only need to convert the categorical variables from numeric data types
    to factors, which is a nice way to represent categorical variables in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'The numeric variables in our dataset include `credit.duration.months`, `credit.amount`,
    and age and we will not need to perform any conversions. However, the remaining
    18 variables are all categorical and we will be using the following utility function
    to convert their data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This function will be used on our existing data frame `credit.df` as follows
    for transforming the variable data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now we can see the attribute details in the data frame with the transformed
    data types for the selected categorical variables in the following output. You
    will notice that out of the 21 variables/attributes of the dataset, 18 of them
    have been successfully transformed into categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![Datatype conversions](img/00141.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This brings an end to the data preprocessing step and we will now dive into
    analyzing our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do note that several of our dataset attributes/features have a lot of classes
    or categories and we will need to do some more data transformations and feature
    engineering in the analysis phase to prevent overfitting of our predictive models,
    which we shall discuss later.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis and transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have processed our data, it is ready for analysis. We will be carrying
    out descriptive and exploratory analysis in this section, as mentioned earlier.
    We will analyze the different dataset attributes and talk about their significance,
    semantics, and relationship with the credit risk attribute. We will be using statistical
    functions, contingency tables, and visualizations to depict all of this.
  prefs: []
  type: TYPE_NORMAL
- en: Besides this, we will also be doing data transformation for some of the features
    in our dataset, namely the categorical variables. We will be doing this to combine
    the category classes which have similar semantics and remove the classes having
    very less proportion by merging them with a similar class. Some reasons for doing
    this include preventing the overfitting of our predictive models, which we will
    be building in [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics*, linking semantically similar
    classes together and also because modeling techniques like logistic regression
    do not handle categorical variables with a large number of classes very well.
    We will analyze each feature/variable in the dataset first and then perform any
    transformations if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Building analysis utilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we begin our analysis, we will be developing some utility functions which
    we will be using to analyze the dataset features. Do note that all the utility
    functions are defined in a separate `.R` file called `descriptive_analytics_utils.R`.
    You can load all the functions in memory or in any other R script file by using
    the command `source('descriptive_analytics_utils.R')` and then start using them.
    We will be talking about these utility functions now.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now talk about the various packages we have used. We have used some
    packages such as `pastecs` and `gmodels` for getting summary statistics of features
    and for building contingency tables. The packages `gridExtra` and `ggplot2` have
    been used for grid layouts and building visualizations respectively. If you do
    not have them installed, you can use the `install.packages` command to install
    them. Next, load the packages as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will build some functions for visualizing the numeric variables. We
    will be doing that by using `histograms\density` plots and `box plots` to depict
    the attribute distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We have used the `qplot` function from the `ggplot2` package for building the
    visualizations which we will be seeing in action soon. Now we will be shifting
    our focus to `categorical variables`. We will start with building a function to
    get summary statistics of any `categorical variable`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding function will summarize the categorical variable and talk about
    how many classes or categories are present in it and some other details such as
    frequency and proportion. If you remember, we had mentioned earlier that we will
    also be depicting the relationship of categorical variables with the class/dependent
    variable `credit.risk`. The following function will help us achieve the same in
    the form of contingency tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also build some functions for depicting visualizations. We will be
    visualizing `categorical variable` distribution using bar charts by using the
    following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use mosaic plots to depict visualizations of the previously mentioned
    contingency tables using the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have built all the necessary utilities, we will begin analyzing
    our data in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be analyzing each feature of the dataset in this section and depicting
    our analysis in the form of summary statistics, relationships, statistical tests,
    and visualizations wherever necessary. We will denote necessary analysis which
    will be carried out for each variable in a table. An important point to remember
    is that the dependent feature denoted in code by `dep.var` will always be `credit.rating`
    since this is the variable which is dependent on the other features; these features
    are independent variables and will be denoted as `indep.var` in the tables and
    plots often.
  prefs: []
  type: TYPE_NORMAL
- en: We will carry out detailed analysis and transformations for some of the important
    features which have a lot of significance, especially data features having a large
    number of classes, so that we can clearly understand data distributions and how
    they change on transformation of the data. For the remaining features, we will
    not focus too much on the summary statistics but emphasize more on feature engineering
    through transformations and their relationships with the dependent `credit.rating`
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will attach the data frame so that we can access the individual features
    easily. You can do that using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now we will be starting our analysis with the dependent variable `credit.risk`,
    also known as the class variable in our dataset, which we will be trying to predict
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet helps us in getting the required summary statistics
    for this feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The following visualizations tell us that `credit.rating` has two classes, `1`
    and `0`, and gives the necessary statistics. Basically, customers with a credit
    rating of `1` are credit worthy and those with a rating of `0` are not credit
    worthy. We also observe from the bar chart that the proportion of credit worthy
    customers in the bank is significantly high compared to the rest.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00142.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Next, we will analyze the `account.balance` feature. Basically, this attribute
    indicates the current balance of the current account of the customer.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with getting the summary statistics and plotting a bar-chart using
    the following code snippet. We will include both the outputs together for better
    understanding.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: From the following visualizations, you can see that there are four distinct
    classes for `account.balance` and they each have some specific semantics which
    we will be talking about soon.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00143.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From the preceding output you can see that there are four distinct classes for
    `account.balance`, and they each have some semantics, as defined next. The currency
    DM indicates Deutsche Mark, the old currency name of Germany.
  prefs: []
  type: TYPE_NORMAL
- en: 'The four classes indicate the following as the main semantics or checking account
    held for at least a year:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No running bank account'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: No balance or debit'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Balance of `< 200` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Balance of `>=200` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The currency DM indicates Deutsche Mark, the old currency name of Germany. We
    will be doing some feature engineering here and will combine classes 3 and 4 together
    to indicate customers who have a positive balance in their account. We will do
    this because the proportion of class 3 is quite small compared to the rest and
    we don't want to unnecessarily keep too many classes per feature unless they are
    critical. We will achieve this by using the following code snippets.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will load the necessary package for doing this. Install it using the
    command `install.packages("car")` in case you do not have the package installed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will recode the necessary classes, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We will now see the relationship between `new.account.balance` and `credit.rating`
    using a contingency table, as discussed earlier, and visualize it using a mosaic
    plot by using the following code snippet. We will also perform some statistical
    tests which I will explain in brief later.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the following figure, you can now see how the various classes for `account.balance`
    are distributed with regards to `credit.rating` in both the table and the plot.
    An interesting thing to see is that 90% of people with funds in their account
    are not potential credit risks, which sounds reasonable.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00144.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We also perform two statistical tests here: the Chi-squared test and Fisher''s
    test, both relevant tests in contingency tables used extensively for hypothesis
    testing. Going into details of the statistical calculations involved in these
    tests is out of scope of this chapter. I will put it in a way which is easy to
    understand. Usually, we start with a null hypothesis that between the two variables
    as depicted previously, there exists no association or relationship, as well as
    an alternative hypothesis that there is a possibility of a relationship or association
    between the two variables. If the p-value obtained from the test is less than
    or equal to `0.05`, only then can we reject the null hypothesis in favor of the
    alternative hypothesis. In this case, you can clearly see that both the tests
    give p-values `< 0.05`, which definitely favors the alternative hypothesis that
    there is some association between `credit.rating` and `account.balance`. These
    types of tests are extremely useful when we build statistical models. You can
    look up the preceding tests on the internet or any statistics book to get a deeper
    insight into what p-values signify and how they work.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do note that going forward we will show only the most important analysis results
    for each feature. However, you can always try getting relevant information for
    the various analysis techniques using the functions we explained earlier. For
    contingency tables, use the `get.contingency.table()` function. Statistical tests
    can be performed by setting the `stat.tests` parameter as `TRUE` in the `get.contingency.table()`
    function. You can also use the `visualize.contingency.table()` function to view
    mosaic plots.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will look at `credit.duration.months`, which signifies the duration of
    the credit in months. This is a numerical variable and the analysis will be a
    bit different from the other categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the same from the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00145.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The values we see are in months and we get the typical summary statistics for
    this feature, including the mean, median, and quartiles. We will now visualize
    the overall distribution of the values for this feature using both `histograms/density`
    plots and `boxplots`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We now visualize the same in the form of box plots, including the one showing
    associations with `credit.rating` next.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Interestingly, from the following plots we see that the median credit duration
    for people who have a bad credit rating is higher than those who have a good credit
    rating. This seems to be plausible if we assume that many customers with long
    credit durations defaulted on their payments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00147.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Moving on to the next variable, `previous.credit.payment.status` indicates
    what is the status of the customer with regards to paying his previous credits.
    This is a `categorical variable` and we get the statistics for it as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following table and bar chart depicting the data distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00148.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The classes indicate the following as the main semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**0**: Hesitant payment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1**: Problematic running account'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: No previous credits left'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: No problem with the current credits at this bank'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Paid back the previous credits at this bank'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be applying the following transformations to this feature, so the new
    semantics will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Some problems with payment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: All credits paid'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: No problems and credits paid in this bank only'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will perform the transformations in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The contingency table for the transformed feature is obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We observe from the following table that maximum people who have a good credit
    rating have paid their previous credits without any problem and those who do not
    have a good credit rating had some problem with their payments, which makes sense!
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00149.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next feature we will look at is `credit.purpose`, which signifies the purpose
    of the credit amount. This is also a categorical variable and we get its summary
    statistics and plot the bar chart showing the frequency of its various classes
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following table and bar chart depicting the data distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00150.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We observe that there are a staggering 11 classes just for this feature. Besides
    this, we also observe that several classes have extremely low proportions compared
    to the top 5 classes and class **label 7** doesn't even appear in the dataset!
    This is exactly why we need to do feature engineering by grouping some of these
    classes together, as we did previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'The classes indicate the following as the main semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**0**: Others'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1**: New car'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Used car'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Furniture items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Radio or television'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5**: Household appliances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**6**: Repair'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**7**: Education'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**8**: Vacation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**9**: Retraining'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**10**: Business'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be transforming this feature by combining some of the existing classes
    and the new semantics after transformation will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: New car'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Used car'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Home related items'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Others'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will do this by using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The contingency table for the transformed feature is then obtained by the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the following table, we see that the customers who have credit purposes
    of home related items or other items seem to have the maximum proportion in the
    bad credit rating category:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00151.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next feature we will analyze is `credit.amount`, which basically signifies
    the amount of credit in DM being asked from the bank by the customer. This is
    a numerical variable and we use the following code for getting the summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/00152.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We see the normal statistics, such as the average credit amount as 3270 DM
    and the median as around 3270 DM. We will now visualize the distribution of the
    preceding data using a histogram and density plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the histogram and density plot for `credit.amount`, and you
    can see that it is a right-skewed distribution in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00153.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will visualize the data using boxplots to see the data distribution
    and its relationship with `credit.rating` using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This generates the following boxplots where you can clearly see the right skew
    in the distribution shown by the numerous dots in the boxplots. We also see an
    interesting insight that the median credit rating was bad for those customers
    who asked for a higher credit amount, which seems likely assuming many of them
    may have failed to make all the payments required to pay off the credit amount.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00154.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Now that you have a good idea about how to perform descriptive analysis for
    categorical and numerical variables, going forward we will not be showing outputs
    of all the different analysis techniques for each feature. Feel free to experiment
    with the functions we used earlier on the remaining variables to obtain the summary
    statistics and visualizations if you are interested in digging deeper into the
    data!
  prefs: []
  type: TYPE_NORMAL
- en: 'The next feature is savings, which is a categorical variable having the following
    semantics for the 5 class labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No savings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: `< 100` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[100, 499]` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Between `[500, 999]` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5**: `>= 1000` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The feature signifies the average amount of savings/stocks belonging to the
    customer. We will be transforming it to the following four class labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No savings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: `< 100` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[100, 999]` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: `>= 1000` DM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we analyze the relationship between savings and `credit.rating` using the
    following code for the contingency table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This generates the following contingency table. On observing the table values,
    it is clear that people with no savings have the maximum proportion among customers
    who have a bad credit rating, which is not surprising! This number is also high
    for customers with a good credit rating since the total number of good credit
    rating records is also high compared to the total records in bad credit rating.
    However, we also see that the proportion of people having `> 1000` DM and a good
    credit rating is quite high in comparison to the proportion of people having both
    a bad credit rating and `> 1000` DM in their savings account.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00155.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will now look at the feature named `employment.duration`, which is a categorical
    variable signifying the duration for which the customer has been employed until
    present. The semantics for the five classes of the feature are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Unemployed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: `< 1` year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[1, 4]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Between `[4, 7]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5**: `>= 7` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be transforming it to the following four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Unemployed or `< 1` year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Between `[1,4]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[4,7]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: `>= 7` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we analyze its relationship using the contingency table, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: What we observe from the following table is that the proportion of customers
    having none or a significantly low number of years in employment and a bad credit
    rating is much higher than similar customers having a good credit rating. In the
    case of `employment.duration` feature, the value 1 indicates the people who are
    unemployed or have `< 1` year of employment. The proportion of these people having
    a bad credit rating in 93 out of 300 people. This gives 31% which is lot higher
    compared to the same metric for the customers having a good credit rating which
    is 141 out of 700 customers, or 20%.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00156.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We now move on to the next feature named `installment.rate`, which is a categorical
    variable with the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: `>=35%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Between `[25, 35]%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[20, 25]%`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: `< 20%` for the four classes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There wasn't too much information in the original metadata for this attribute
    so there is some ambiguity, but what we assumed is that it indicates the percentage
    of the customer's salary which was used to pay the credit loan as monthly installments.
    We won't be doing any transformations here so we will directly go to the relationships.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '![Analyzing the dataset](img/00157.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next variable we will analyze is `marital.status`, which indicates the
    marital status of the customer and is a categorical variable. It has four classes
    with the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Male divorced'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Male single'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Male married/widowed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Female'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be transforming them into three classes with the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Male divorced/single'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Male married/widowed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Female'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We now observe the relationship between `marital.status` and `credit.rating`
    by building a contingency table using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: From the following table, we notice that the ratio of single men to married
    men for customers with a good credit rating is **1:2** compared to nearly **1:1**
    for customers with a bad credit rating. Does this mean that maybe more married
    men tend to pay their credit debts in time? That could be a possibility for this
    dataset, but do remember that correlation does not imply causation in general.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00158.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The p-values from the statistical tests give us a value of `0.01`, indicating
    that there might be some association between the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next feature is guarantor, which signifies if the customer has any further
    debtors or guarantors. This is a categorical variable with three classes having
    the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: None'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Co-applicant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Guarantor'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We transform them into two variables with the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Yes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the transformation, we use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Performing statistical tests on this yield a p-value of `1`, which is much greater
    than `0.05`, thus ruling the null hypothesis in favor and implying that there
    is probably no association between guarantor and `credit.rating`.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also run the statistical tests using direct functions instead of calling
    the `get.contingency.table(…)` function each time. For Fisher's exact test, call
    `fisher.test(credit.rating, guarantor)`, and for Pearson's Chi-squared test, call
    `chisq.test(credit,rating, guarantor)`. Feel free to substitute guarantor with
    any of the other independent variables to carry out these tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next feature is `residence.duration`, which signifies how long the customer
    has been residing at his current address.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a categorical variable with the following semantics for the four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: `< 1` year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Between `[1,4]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Between `[4,7]` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: `>= 7` years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will not be doing any transformations and will be directly doing statistical
    tests to see if this feature has any association with `credit,rating`. From in
    the previous tip, using the functions `fisher.test` and `chisq.test` both give
    us a p-value of `0.9`, which is significantly `> 0.05` and thus there is no significant
    relationship between them. We will show the outputs of both the statistical tests
    here, just so you can get an idea of what they depict.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see from the following outputs that we get the same p-value from both
    the tests we talked about earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00159.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We now shift our focus to `current.assets,` which is a categorical variable
    having the following semantics for the four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No assets'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Car/other'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Life insurance/savings contract'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: House/land ownership'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will not be doing any transformations on this data and will directly run
    the same statistical tests to check if it has any association with `credit.rating`.
    We get a p-value of `3 x 10-5`, which is definitely `< 0.05`, and thus we can
    conclude that the alternative hypothesis holds good that there is some association
    between the variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next variable we will analyze is `age`. This is a numeric variable and
    we will get its summary statistics as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '**Output**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00160.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can observe that the average age of customers is 35.5 years and the median
    age is 33 years. To view the feature distributions, we will visualize it using
    a histogram and density plot using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'We can observe from the following plots that the distribution is a right-skewed
    distribution with the majority of customer ages ranging from 25 to 45 years:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00161.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will now observe the relationship between `age` and `credit.rating` by visualizing
    it through boxplots, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The right-skew from the following plots is clearly distinguishable in the boxplots
    by the cluster of dots we see at the extreme end. The interesting observation
    we can make from the right plot is that people who have a bad credit rating have
    a lower median age than people who have a good credit rating.
  prefs: []
  type: TYPE_NORMAL
- en: '![Analyzing the dataset](img/00162.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: One reason for this association could be that younger people who are still not
    well settled and employed have failed to repay the credit loans which they had
    taken from the bank. But, once again, this is just an assumption which we cannot
    verify unless we look into the full background of each customer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will look at the feature `other.credits`, which has the following
    semantics for the three classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: At other banks'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: At stores'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: No further credits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This feature indicates if the customer has any other pending credits elsewhere.
    We will transform this to two classes with the following semantics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Yes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: No'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: On performing statistical tests on the newly transformed feature, we get a p-value
    of `0.0005`, which is `< 0.05`, and thus favors the alternative hypothesis over
    the null, indicating that there is some association between this feature and `credit.rating`,
    assuming there is no influence from anything else.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next feature `apartment.type` is a categorical variable having the following
    semantics for the three classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Free apartment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Rents flat'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Owns occupied flat'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This feature basically signifies the type of apartment in which the customer
    resides. We will not be doing any transformation to this variable and will be
    directly moving on to the statistical tests. Both the tests give us a p-value
    of `< 0.05`, which signifies that some association is present between `apartment.type`
    and `credit.rating`, assuming no other factors affect it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will look at the feature `bank.credits`, which is a categorical variable
    having the following semantics for the four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: One'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Two/three'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Four/five'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Six or more'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This feature signifies the total number of credit loans taken by the customer
    from this bank including the current one. We will transform this into a binary
    feature with the following semantics for the two classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: One'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: More than one'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will be using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Carrying out statistical tests on this transformed feature gives us a p-value
    of `0.2`, which is much `> 0.05`, and hence we know that the null hypothesis still
    holds good that there is no significant association between `bank.credits` and
    `credit.rating`. Interestingly, if you perform statistical tests with the untransformed
    version of `bank.credits`, you will get an even higher p-value of `0.4`, which
    indicates no significant association.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next feature is `occupation`, which obviously signifies the present job
    of the customer. This is a categorical variable with the following semantics for
    its four classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Unemployed with no permanent residence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Unskilled with permanent residence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3**: Skilled worker/minor civil servant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4**: Executive/self-employed/higher civil servant'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We won't be applying any transformations on this feature since each class is
    quite distinct in its characteristics. Hence, we will be moving on directly to
    analyzing the relationships with statistical tests. Both the tests yield a p-value
    of `0.6`, which is definitely `> 0.05`, and the null hypothesis holds good that
    there is no significant relationship between the two features.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look at the next feature dependents, which is a categorical variable
    having the following semantics for its two class labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Zero to two'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Three or more'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This feature signifies the total number of people who are dependents for the
    customer. We will not be applying any transformations since it is already a binary
    variable. Carrying out statistical tests on this feature yields a p-value of `1`,
    which tells us that this feature does not have a significant relationship with
    `credit.rating`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next up is the feature telephone, which is a binary categorical variable which
    has two classes with the following semantics indicating whether the customer has
    a telephone:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: No'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: Yes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We do not need any further transformations here since it is a binary variable.
    So, we move on to the statistical tests which give us a p-value of `0.3`, which
    is `> 0.05`, ruling the null hypothesis in favor of the alternative, thus indicating
    that no significant association exists between telephone and `credit.rating`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final feature in the dataset is `foreign.worker`, which is a binary categorical
    variable having two classes with the following semantics indicating if the customer
    is a foreign worker:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1**: Yes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2**: No'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We do not perform any transformations since it is already a binary variable
    with two distinct classes and move on to the statistical tests. Both the tests
    give us a p-value of `< 0.05`, which might indicate that this variable has a significant
    relationship with `credit.rating`.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we come to an end of our data analysis phase for the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Saving the transformed dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have performed a lot of feature engineering using data transformations for
    several categorical variables and since we will be building predictive models
    on the transformed feature sets, we need to store this dataset separately to disk.
    We use the following code snippet for the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We can load the above file into R directly the next time start building predictive
    models, which we will be covering in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have analyzed our dataset, performed necessary feature engineering and statistical
    tests, built visualizations, and gained substantial domain knowledge about credit
    risk analysis and what kind of features are considered by banks when they analyze
    customers. The reason why we analyzed each feature in the dataset in detail was
    to give you an idea about each feature that is considered by banks when analyzing
    credit rating for customers. This was to give you good domain knowledge understanding
    and also to help you get familiar with the techniques of performing an exploratory
    and descriptive analysis of any dataset in the future. So, what next? Now comes
    the really interesting part of using this dataset; building feature sets from
    this data and feeding them into predictive models to predict which customers can
    be potential credit risks and which of them are not. As mentioned previously,
    there are two steps to this: data and algorithms. In fact, we will go a step further
    and say that there are feature sets and algorithms which will help us in achieving
    our main objective.'
  prefs: []
  type: TYPE_NORMAL
- en: Feature sets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A dataset is basically a file consisting of several records of observation where
    each tuple or record denotes one complete set of observations and the columns
    are specific attributes or features in that observation which talk about specific
    characteristics. In predictive analytics, usually there is one attribute or feature
    in the dataset whose class or category has to be predicted. This variable is `credit.rating`
    in our dataset, also known as the dependent variable. All the other features on
    which this depends are the independent variables. Taking a combination of these
    features forms a feature vector, which is also known popularly as a feature set.
    There are various ways of identifying what feature sets we should consider for
    predictive models, and you will see going ahead that for any dataset there is
    never a fixed feature set. It keeps changing based on feature engineering, the
    type of predictive model we are building, and the significance of the features
    based on statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: Each property in the feature set is termed as a feature or attribute and these
    are also known as independent or explanatory variables in statistics. Features
    can be of various types, as we saw in our dataset. We can have categorical features
    with several classes, binary features with two classes, ordinal features which
    are basically categorical features but have some order inherent in them (for example,
    low, medium, high), and numerical features which could be integer values or real
    values. Features are highly important in building predictive models and more often
    than not, the data scientists spend a lot of time in building the perfect feature
    sets to highly boost the accuracy of predictive models. This is why domain knowledge
    is highly essential, besides knowing about the machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we get the feature sets ready, we can start using predictive models to
    use them and start predicting the credit rating of customers based on their features.
    An important thing to remember is that this is an iterative process and we have
    to keep modifying our feature sets based on outputs and feedback obtained from
    our predictive models to further improve them. Several methods which are relevant
    in our scenario, which belong to the class of supervised machine learning algorithms,
    are explained briefly in this section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear classification algorithms**: These algorithms perform classification
    in terms of a linear function which assigns scores to each class by performing
    a dot product of the feature set and some weights associated with them. The predicted
    class is the one which has the highest score. The optimal weights for the feature
    set are determined in various ways and differ based on the chosen algorithms.
    Some examples of algorithms include logistic regression, support vector machines,
    and perceptrons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision trees**: Here we use decision trees as predictive models that map
    various observations from the data points to the observed class of the record
    we are to predict. A decision tree is just like a flowchart structure, where each
    internal nonleaf node denotes a check on a feature, each branch represents an
    outcome of that check, and each terminal leaf node contains a class label which
    we predict finally.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensemble learning methods**: These include using multiple machine learning
    algorithms to obtain better predictive models. An example is the Random Forest
    classification algorithm which uses an ensemble of decision trees during the model
    training phase, and at each stage it takes the majority output decision from the
    ensemble of decision trees as its output. This tends to reduce overfitting, which
    occurs frequently when using decision trees.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boosting algorithms**: This is also an ensemble learning technique in the
    supervised learning family of algorithms. It consists of an iterative process
    of training several weak classification models and learning from them before adding
    them to a final classifier which is stronger than them. A weighted approach is
    followed when adding the classifiers, which is based on their accuracy. Future
    weak classifiers focus more on the records which were previously misclassified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural networks**: These algorithms are inspired by the biological neural
    networks which consist of systems of interconnected neurons that exchange messages
    with each other. In predictive modeling, we deal with artificial neural networks
    which consist of interconnected groups of nodes. Each node consists of a function
    which is usually a mathematical function (that is, sigmoid function) and has an
    adaptive weight associated with it which keeps changing based on inputs fed to
    the nodes and constantly checking the error obtained from the outputs in several
    iterations also known as **epochs**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will be covering several of these algorithms when building predictive models
    in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations on staying until the end of this chapter! You have learnt several
    important things by now which we have covered in this chapter. You now have an
    idea about one of the most important areas in the financial domain, that is, Credit
    Risk analysis. Besides this, you also gained significant domain knowledge about
    how banks analyze customers for their credit ratings and what kind of attributes
    and features are considered by them. Descriptive and exploratory analysis of the
    dataset also gave you an insight into how to start working from scratch when you
    just have a problem to solve and a dataset given to you! You now know how to perform
    feature engineering, build beautiful publication quality visualizations using
    `ggplot2`, and perform statistical tests to check feature associations. Finally,
    we wrapped up our discussion by talking about feature sets and gave a brief introduction
    to several supervised machine learning algorithms which will help us in the next
    step of predicting credit risks. The most interesting part is yet to come, so
    stay tuned!
  prefs: []
  type: TYPE_NORMAL
