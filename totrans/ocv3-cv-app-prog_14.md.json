["```py\n    cv::Ptr<cv::face::FaceRecognizer> recognizer =\n           cv::face::createLBPHFaceRecognizer(1, // radius of LBP pattern \n                   8,       // the number of neighboring pixels to consider \n                   8, 8,    // grid size \n                   200.8);  // minimum distance to nearest neighbor \n\n```", "```py\n    // vectors of reference image and their labels \n    std::vector<cv::Mat> referenceImages; \n    std::vector<int> labels; \n    // open the reference images \n    referenceImages.push_back(cv::imread(\"face0_1.png\",\n                              cv::IMREAD_GRAYSCALE)); \n    labels.push_back(0); // person 0 \n    referenceImages.push_back(cv::imread(\"face0_2.png\",\n                              cv::IMREAD_GRAYSCALE)); \n    labels.push_back(0); // person 0 \n    referenceImages.push_back(cv::imread(\"face1_1.png\",\n                              cv::IMREAD_GRAYSCALE)); \n    labels.push_back(1); // person 1 \n    referenceImages.push_back(cv::imread(\"face1_2.png\",\n                              cv::IMREAD_GRAYSCALE)); \n    labels.push_back(1); // person 1 \n\n    // train the recognizer by computing the LBPHs \n    recognizer->train(referenceImages, labels); \n\n```", "```py\n    // predict the label of this image \n    recognizer->predict(inputImage,      // face image  \n                        predictedLabel,  // predicted label of this image  \n                        confidence);     // confidence of the prediction \n\n```", "```py\n    //compute the Local Binary Patterns of a gray-level image \n    void lbp(const cv::Mat &image, cv::Mat &result) { \n\n      result.create(image.size(), CV_8U); // allocate if necessary \n\n      for (int j = 1; j<image.rows - 1; j++) { \n        //for all rows (except first and last) \n\n        // pointers to the input rows \n        const uchar* previous = image.ptr<const uchar>(j - 1);    \n        const uchar* current  = image.ptr<const uchar>(j);       \n        const uchar* next     = image.ptr<const uchar>(j + 1);   \n        uchar* output = result.ptr<uchar>(j);        //output row \n\n        for (int i = 1; i<image.cols - 1; i++) { \n\n          // compose local binary pattern \n          *output =  previous[i - 1] > current[i] ? 1 : 0; \n          *output |= previous[i] > current[i] ?     2 : 0; \n          *output |= previous[i + 1] > current[i] ? 4 : 0; \n          *output |= current[i - 1] > current[i] ?  8 : 0; \n          *output |= current[i + 1] > current[i] ? 16 : 0; \n          *output |= next[i - 1] > current[i] ?    32 : 0; \n          *output |= next[i] > current[i] ?        64 : 0; \n          *output |= next[i + 1] > current[i] ?   128 : 0; \n          output++; // next pixel \n        } \n      } \n      // Set the unprocess pixels to 0 \n      result.row(0).setTo(cv::Scalar(0)); \n      result.row(result.rows - 1).setTo(cv::Scalar(0)); \n      result.col(0).setTo(cv::Scalar(0)); \n      result.col(result.cols - 1).setTo(cv::Scalar(0)); \n    } \n\n```", "```py\n    stop00.png 1 0 0 64 64 \n    stop01.png 1 0 0 64 64 \n    stop02.png 1 0 0 64 64 \n    stop03.png 1 0 0 64 64 \n    stop04.png 1 0 0 64 64 \n    stop05.png 1 0 0 64 64 \n    stop06.png 1 0 0 64 64 \n    stop07.png 1 0 0 64 64 \n\n```", "```py\n opencv_createsamples -info stop.txt -vec stop.vec -w 24 -h 24 -num 8\n\n```", "```py\n     opencv_traincascade  -data classifier -vec stop.vec   \n                     -bg neg.txt -numPos 9  -numNeg 20 \n                     -numStages 20 -minHitRate 0.95  \n                     -maxFalseAlarmRate 0.5 -w 24 -h 24 \n\n```", "```py\n    cv::CascadeClassifier cascade; \n    if (!cascade.load(\"stopSamples/classifier/cascade.xml\")) { \n      std::cout << \"Error when loading the cascade classfier!\"  \n                << std::endl;   \n      return -1; \n    } \n\n```", "```py\n    cascade.detectMultiScale(inputImage, // input image \n              detections,           // detection results \n              1.1,                  // scale reduction factor \n              2,                 // number of required neighbor detections \n              0,                    // flags (not used) \n              cv::Size(48, 48),     // minimum object size to be detected \n              cv::Size(128, 128));  // maximum object size to be detected \n\n```", "```py\n    for (int i = 0; i < detections.size(); i++) \n     cv::rectangle(inputImage, detections[i],  \n                   cv::Scalar(255, 255, 255), 2); \n\n```", "```py\n    cv::CascadeClassifier faceCascade; \n    if (!faceCascade.load(\"haarcascade_frontalface_default.xml\")) { \n      std::cout << \"Error when loading the face cascade classfier!\"  \n                << std::endl; \n      return -1; \n    } \n\n```", "```py\n    faceCascade.detectMultiScale(picture, // input image \n               detections,           // detection results \n               1.1,                  // scale reduction factor \n               3,                 // number of required neighbor detections \n               0,                    // flags (not used) \n               cv::Size(48, 48),     // minimum object size to be detected \n               cv::Size(128, 128));  // maximum object size to be detected \n\n    // draw detections on image \n    for (int i = 0; i < detections.size(); i++) \n      cv::rectangle(picture, detections[i],  \n                    cv::Scalar(255, 255, 255), 2); \n\n```", "```py\n    cv::HOGDescriptor hogDesc(positive.size(), // size of the window \n                              cv::Size(8, 8),  // block size \n                              cv::Size(4, 4),  // block stride \n                              cv::Size(4, 4),  // cell size \n                              9);              // number of bins \n\n```", "```py\n    // compute first descriptor  \n    std::vector<float> desc; \n    hogDesc.compute(positives[0], desc); \n\n    // the matrix of sample descriptors \n    int featureSize = desc.size(); \n    int numberOfSamples = positives.size() + negatives.size(); \n\n    // create the matrix that will contain the samples HOG \n    cv::Mat samples(numberOfSamples, featureSize, CV_32FC1); \n    // fill first row with first descriptor \n    for (int i = 0; i < featureSize; i++) \n      samples.ptr<float>(0)[i] = desc[i]; \n\n    // compute descriptor of the positive samples \n    for (int j = 1; j < positives.size(); j++) { \n      hogDesc.compute(positives[j], desc); \n      // fill the next row with current descriptor \n      for (int i = 0; i < featureSize; i++) \n        samples.ptr<float>(j)[i] = desc[i]; \n    } \n    // compute descriptor of the negative samples \n    for (int j = 0; j < negatives.size(); j++) { \n      hogDesc.compute(negatives[j], desc); \n      // fill the next row with current descriptor \n      for (int i = 0; i < featureSize; i++) \n        samples.ptr<float>(j + positives.size())[i] = desc[i]; \n    } \n\n```", "```py\n    // Create the labels \n    cv::Mat labels(numberOfSamples, 1, CV_32SC1); \n    // labels of positive samples \n    labels.rowRange(0, positives.size()) = 1.0; \n    // labels of negative samples \n    labels.rowRange(positives.size(), numberOfSamples) = -1.0; \n\n```", "```py\n    // create SVM classifier \n    cv::Ptr<cv::ml::SVM> svm = cv::ml::SVM::create(); \n    svm->setType(cv::ml::SVM::C_SVC); \n    svm->setKernel(cv::ml::SVM::LINEAR); \n\n```", "```py\n    // prepare the training data \n    cv::Ptr<cv::ml::TrainData> trainingData = \n           cv::ml::TrainData::create(samples,\n                              cv::ml::SampleTypes::ROW_SAMPLE, labels); \n    // SVM training \n    svm->train(trainingData); \n\n```", "```py\n    cv::Mat queries(4, featureSize, CV_32FC1); \n\n    // fill the rows with query descriptors \n    hogDesc.compute(cv::imread(\"stop08.png\",  \n                           cv::IMREAD_GRAYSCALE), desc); \n    for (int i = 0; i < featureSize; i++) \n      queries.ptr<float>(0)[i] = desc[i]; \n    hogDesc.compute(cv::imread(\"stop09.png\",  \n                           cv::IMREAD_GRAYSCALE), desc); \n    for (int i = 0; i < featureSize; i++) \n      queries.ptr<float>(1)[i] = desc[i]; \n    hogDesc.compute(cv::imread(\"neg08.png\",  \n                           cv::IMREAD_GRAYSCALE), desc); \n    for (int i = 0; i < featureSize; i++) \n      queries.ptr<float>(2)[i] = desc[i]; \n    hogDesc.compute(cv::imread(\"neg09.png\",  \n                           cv::IMREAD_GRAYSCALE), desc); \n    for (int i = 0; i < featureSize; i++) \n      queries.ptr<float>(3)[i] = desc[i]; \n    cv::Mat predictions; \n\n    // Test the classifier  \n    svm->predict(queries, predictions); \n    for (int i = 0; i < 4; i++) \n      std::cout << \"query: \" << i << \": \" <<  \n               ((predictions.at<float>(i,) < 0.0)?  \n                   \"Negative\" : \"Positive\") << std::endl; \n\n```", "```py\n    //draw one HOG over one cell \n    void drawHOG(std::vector<float>::const_iterator hog,  \n                       // iterator to the HOG \n                 int numberOfBins,       // number of bins inHOG \n                 cv::Mat &image,         // image of the cell \n                 float scale=1.0) {      // length multiplier \n\n      const float PI = 3.1415927; \n      float binStep = PI / numberOfBins; \n      float maxLength = image.rows; \n      float cx = image.cols / 2.; \n      float cy = image.rows / 2.; \n\n      // for each bin \n      for (int bin = 0; bin < numberOfBins; bin++) { \n\n        // bin orientation \n        float angle = bin*binStep; \n        float dirX = cos(angle); \n        float dirY = sin(angle); \n        // length of line proportion to bin size \n        float length = 0.5*maxLength* *(hog+bin); \n\n        // drawing the line \n        float x1 = cx - dirX * length * scale; \n        float y1 = cy - dirY * length * scale; \n        float x2 = cx + dirX * length * scale; \n        float y2 = cy + dirY * length * scale; \n        cv::line(image, cv::Point(x1, y1), cv::Point(x2, y2),  \n                 CV_RGB(255, 255, 255), 1); \n      } \n    } \n\n```", "```py\n    // Draw HOG over an image \n    void drawHOGDescriptors(const cv::Mat &image,  // the input image  \n             cv::Mat &hogImage, // the resulting HOG image \n             cv::Size cellSize, // size of each cell (blocks are ignored) \n             int nBins) {       // number of bins \n\n      // block size is image size \n      cv::HOGDescriptor hog( \n              cv::Size((image.cols / cellSize.width) * cellSize.width,     \n                       (image.rows / cellSize.height) * cellSize.height), \n              cv::Size((image.cols / cellSize.width) * cellSize.width,   \n                       (image.rows / cellSize.height) * cellSize.height),  \n              cellSize,    // block stride (ony 1 block here) \n              cellSize,    // cell size \n              nBins);      // number of bins \n\n      //compute HOG \n      std::vector<float> descriptors; \n      hog.compute(image, descriptors); \n      ... \n      float scale= 2.0 / * \n                  std::max_element(descriptors.begin(),descriptors.end()); \n      hogImage.create(image.rows, image.cols, CV_8U); \n      std::vector<float>::const_iterator itDesc= descriptors.begin(); \n\n      for (int i = 0; i < image.rows / cellSize.height; i++) { \n        for (int j = 0; j < image.cols / cellSize.width; j++) { \n          //draw each cell \n             hogImage(cv::Rect(j*cellSize.width, i*cellSize.height,  \n                      cellSize.width, cellSize.height)); \n           drawHOG(itDesc, nBins,  \n                   hogImage(cv::Rect(j*cellSize.width,                  \n                                     i*cellSize.height,  \n                                     cellSize.width, cellSize.height)),  \n                   scale); \n          itDesc += nBins; \n        } \n      } \n    } \n\n```", "```py\n    // create the detector \n    std::vector<cv::Rect> peoples; \n    cv::HOGDescriptor peopleHog; \n    peopleHog.setSVMDetector( \n    cv::HOGDescriptor::getDefaultPeopleDetector()); \n    // detect peoples oin an image \n    peopleHog.detectMultiScale(myImage, // input image \n               peoples,           // ouput list of bounding boxes  \n               0,       // threshold to consider a detection to be positive \n               cv::Size(4, 4),    // window stride  \n               cv::Size(32, 32),  // image padding \n               1.1,               // scale factor \n               2);                // grouping threshold \n\n```"]