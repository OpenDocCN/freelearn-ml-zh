<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Unsupervised Learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Unsupervised Learning</h1></div></div></div><p>In this chapter, we will cover the following recipes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Self-organizing map </strong></span>- visualizing heatmaps</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Vector quantization</strong></span>--Image clustering</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec37"/>Introduction</h1></div></div></div><p>
<span class="strong"><strong>Self-organizing map (SOM)</strong></span>: The self-organizing map belongs to a class of unsupervised learning that is based on competitive learning, in which output neurons compete amongst themselves to be activated, with the result that only one is activated at any one time. This activated neuron is called the winning neuron. Such competition can be induced/implemented by having lateral inhibition connections (negative feedback paths) between the neurons, resulting in the neurons organizing themselves. SOM can be imagined as a sheet-like neural network, with nodes arranged as regular, usually two-dimensional grids. The principal goal of a SOM is to transform an incoming arbitrary dimensional signal into a one- or two-dimensional discrete map, and to perform this transformation adaptively in a topologically ordered fashion. The neurons are selectively tuned to various input patterns (stimuli) or classes of input patterns during the course of the competitive learning. The locations of the neurons so tuned (the winning neurons) become ordered, and a meaningful coordinate system for input features is created on the lattice. The SOM thus forms the required topographic map of the input patterns.</p><p>
<span class="strong"><strong>Vector quantization</strong></span>: Quantization is the process of mapping an infinite set of scalar or vector quantities by a finite set of scalar or vector quantities. Quantization has applications in the areas of signal processing, speech processing, and image processing. Vector quantization performs quantization over blocks of data, instead of a single scalar value. The quantization output is an index value that indicates another data block (vector) from a finite set of vectors, called the codebook. The selected vector is usually an approximation of the input data block. Reproduction vectors are known as encoders and decoders. The encoder takes an input vector, which determines the best representing reproduction vector, and transmits the index of that vector. The decoder takes that index and forms the reproduction vector.</p></div></div>
<div class="section" title="Self-organizing map - visualizing&#xA0;of heatmaps"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec38"/>Self-organizing map - visualizing of heatmaps</h1></div></div></div><p>Over the past decade, there has been exponential growth in information. Gaining new knowledge from such databases is difficult, costly, and time-consuming if done manually. It may even be impossible when the data exceeds certain limits of size and complexity. As a result, the automated analysis and visualization of massive multidimensional datasets have been the focus of much scientific research over the last few years. The principal objective of this analysis and visualization is to find regularities and relationships in the data, thereby gaining access to hidden and potentially useful knowledge. A self-organizing map (SOM) is an unsupervised neural network algorithm that projects high-dimensional data onto a two-dimensional map. The projection preserves the topology of the data so that similar data items will be mapped to nearby locations on the map.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec46"/>How to do it...</h2></div></div></div><p>Let's get into the details.</p><div class="section" title="Step 1 - exploring data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec117"/>Step 1 - exploring data</h3></div></div></div><p>The following packages first need to be loaded:</p><pre class="programlisting">
<span class="strong"><strong>&gt; install.packages("kohonen")
&gt; library(kohonen)</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note20"/>Note</h3><p>Version info: Code for this page was tested in R version 3.3.2 (2016-10-31)</p></div></div><p>Create a sample dataset:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; training_frame &lt;- data[, c(2,4,5,8)]</strong></span>
</pre><p>Changing the data frame with training data to a matrix: <code class="literal">scale()</code> as a function centers and scales the columns of a <code class="literal">training_frame</code> matrix. The <code class="literal">as.matrix()</code> function creates a matrix from the result of <code class="literal">scale(training_frame)</code>.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; training_matrix &lt;- as.matrix(scale(training_frame))</strong></span>
</pre><p>Printing the <code class="literal">training_matrix</code>:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; training_matrix</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_001.jpg" alt="Step 1 - exploring data"/></div><p>
</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_002.jpg" alt="Step 1 - exploring data"/></div><p>
</p></div><div class="section" title="Step 2 - training the model"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec118"/>Step 2 - training the model</h3></div></div></div><p>Creating the SOM Grid: <code class="literal">somgrid()</code> plots the functions of the self-organizing map's grids. <code class="literal">xdim = 20</code> and <code class="literal">ydim=20</code> are the dimensions of the grid, while <code class="literal">topo="hexagonal"</code> represents the topology of the grid:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; som_grid &lt;- somgrid(xdim = 20, ydim=20, topo="hexagonal")</strong></span>
</pre><p>Training the Self Organizing Maps: <code class="literal">som()</code> is a function of self-organizing maps that is used to map high-dimensional spectra or patterns to 2D. The Euclidean distance measure is used. <code class="literal">training_matrix</code> is the data matrix, <code class="literal">rlen=1000</code> is the number of times the complete dataset will be presented to the network for training, and alpha is the learning rate. <code class="literal">keep.data = TRUE</code> means that the data needs to be saved in the return object and <code class="literal">n.hood="circular"</code> indicates the shape of the neighborhood:</p><pre class="programlisting">
<span class="strong"><strong>&gt; som_model &lt;- som(training_matrix,</strong></span>
<span class="strong"><strong>+ grid=som_grid,</strong></span>
<span class="strong"><strong>+ rlen=1000,</strong></span>
<span class="strong"><strong>+ alpha=c(0.05,0.01),</strong></span>
<span class="strong"><strong>+ keep.data = TRUE,</strong></span>
<span class="strong"><strong>+ n.hood="circular")</strong></span>
</pre></div><div class="section" title="Step 3 - plotting the model"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec119"/>Step 3 - plotting the model</h3></div></div></div><p>Plotting the <code class="literal">som_model</code> object:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; plot(som_model, main ="Training Progress", type="changes", col = "red")</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_003.jpg" alt="Step 3 - plotting the model"/></div><p>
</p><p>Plotting the model based on node count:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; plot(som_model, main ="Node Count", type="count")</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_004.jpg" alt="Step 3 - plotting the model"/></div><p>
</p><p>Plotting the model based on the neighborhood distance.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; plot(som_model, main ="Neighbour Distances", type="dist.neighbours")</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_005.jpg" alt="Step 3 - plotting the model"/></div><p>
</p><p>The following code plots the model based on the <code class="literal">type = "codes"</code>.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; plot(som_model, type="codes")</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_006.jpg" alt="Step 3 - plotting the model"/></div><p>
</p><p>The following code plots the model based on property plot.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; plot(som_model, type = "property", property = som_model$codes[,4], main=names(som_model$data)[4])</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_007.jpg" alt="Step 3 - plotting the model"/></div><p>
</p></div></div></div>
<div class="section" title="Vector quantization - image clustering"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec39"/>Vector quantization - image clustering</h1></div></div></div><p>The development of technology in the field of digital media generates huge amounts of non-textual information in the form of images. If programs could comprehend the significance of these images and understand what they mean, this could result in a vast number of different applications. One such application could be the use of robots to extract malign tissue from hospital patients using body scan images to interpret the location of the tissue. Images are considered one of the most important media for conveying information. The potential for the retrieval of information is vast, so much so that users may be overwhelmed by the sheer amount of information retrieved. The unstructured format of images challenges classification and clustering techniques. Machine learning algorithms are used to extract information to understand images. One of the first steps towards understanding images is to segment them and identify the different objects within them. To do this, features like histogram plots and frequency domain transform can be used.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec47"/>Getting ready</h2></div></div></div><p>Let's get started.</p><div class="section" title="Step 1 - collecting and describing data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec120"/>Step 1 - collecting and describing data</h3></div></div></div><p>The JPEG file is used.</p></div></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec48"/>How to do it...</h2></div></div></div><p>Let's get into the details.</p><div class="section" title="Step 2 - exploring data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec121"/>Step 2 - exploring data</h3></div></div></div><p>The following packages first need to be loaded:</p><pre class="programlisting">
<span class="strong"><strong>&gt; install.packages("jpeg")
&gt; install.packages("ggplot2")
&gt; library(jpeg)
&gt; library(ggplot2)</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note21"/>Note</h3><p>Version info: Code for this page was tested in R version 3.3.2</p></div></div><p>The <code class="literal">readJPEG()</code> function is used to read an image in the JPEG file format, and converts it into a raster array:.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; img &lt;- readJPEG("d:/Image.jpg")</strong></span>
</pre></div><div class="section" title="Step 3 - data cleaning"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec122"/>Step 3 - data cleaning</h3></div></div></div><p>Exploring the dimensions of the <code class="literal">img</code>: the <code class="literal">dim()</code> function returns the dimensions of the <code class="literal">img</code> frame. The <code class="literal">img</code> data frame is passed as an input parameter:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; img_Dim &lt;- dim(img)</strong></span>
</pre><p>Now let's print the <code class="literal">img_Dim</code>:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; img_Dim</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_008.jpg" alt="Step 3 - data cleaning"/></div><p>
</p><p>Now, we are assigning RGB (red, green, and blue--RGB channels roughly follow the color receptors in the human eye) channels to the data frame. The result is then stored in the <code class="literal">img_RGB_channels</code> data frame:</p><pre class="programlisting">
<span class="strong"><strong>&gt; img_RGB_channels &lt;- data.frame(
+ x = rep(1:img_Dim[2], each = img_Dim[1]),
+ y = rep(img_Dim[1]:1, img_Dim[2]),
+ R = as.vector(img[,,1]),
+ G = as.vector(img[,,2]),
+ B = as.vector(img[,,3])
+ )</strong></span>
</pre></div><div class="section" title="Step 4 - visualizing cleaned data"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec123"/>Step 4 - visualizing cleaned data</h3></div></div></div><p>Let's plot the original image:</p><pre class="programlisting">
<span class="strong"><strong>&gt; plotTheme &lt;- function() {
theme(
panel.background = element_rect(
size = 3,
colour = "black",
fill = "white"),
axis.ticks = element_line(
size = 2),
panel.grid.major = element_line(
colour = "gray80",
linetype = "dotted"),
panel.grid.minor = element_line(
colour = "gray90",
linetype = "dashed"),
axis.title.x = element_text(
size = rel(1.2),
face = "bold"),
axis.title.y = element_text(
size = rel(1.2),
face = "bold"),
plot.title = element_text(
size = 20,
face = "bold",
Unsupervised Learning
[ 327 ]
vjust = 1.5)
)
}
&gt; ggplot(data = img_RGB_channels, aes(x = x, y = y)) +
+ geom_point(colour = rgb(img_RGB_channels[c("R", "G", "B")])) +
+ labs(title = "Original Image: Colorful Bird") +
+ xlab("x") +
+ ylab("y") +
+ plotTheme()</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_009.jpg" alt="Step 4 - visualizing cleaned data"/></div><p>
</p></div><div class="section" title="Step 5 - building the model and visualizing it"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec124"/>Step 5 - building the model and visualizing it</h3></div></div></div><p>Assigning the clustering colors:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kClusters &lt;- 3</strong></span>
</pre><p>Performing k-means clustering: <code class="literal">kmeans()</code> as a function performs clustering on the data matrix <code class="literal">img_RGB_channels</code>. <code class="literal">centers = kClusters</code> signifies the number of initial clusters:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kMeans_clst &lt;- kmeans(img_RGB_channels[, c("R", "G", "B")], centers = kClusters)</strong></span>
</pre><p>Creating colours corresponding to the given intensities of red, green and blue primaries.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kColours &lt;- rgb(kMeans_clst$centers[kMeans_clst$cluster,])</strong></span>
</pre><p>Plotting the image with three clusters:</p><pre class="programlisting">
<span class="strong"><strong>&gt; ggplot(data = img_RGB_channels, aes(x = x, y = y)) +
+ geom_point(colour = kColours) +
+ labs(title = paste("k-Means Clustering of", kClusters, "Colours"))
+
+ xlab("x") +
+ ylab("y") +
+ plotTheme()</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_010.jpg" alt="Step 5 - building the model and visualizing it"/></div><p>
</p><p>Assigning the clustering colors:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kClusters &lt;- 5</strong></span>
</pre><p>Performing k-means clustering:</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kMeans_clst &lt;- kmeans(img_RGB_channels[, c("R", "G", "B")], centers = kClusters)</strong></span>
</pre><p>Creating colours corresponding to the given intensities of red, green and blue primaries.</p><pre class="programlisting">
<span class="strong"><strong>    &gt; kColours &lt;- rgb(kMeans_clst$centers[kMeans_clst$cluster,])</strong></span>
</pre><p>Plotting the image with five clusters:</p><pre class="programlisting">
<span class="strong"><strong>&gt; ggplot(data = img_RGB_channels, aes(x = x, y = y)) +
+ geom_point(colour = kColours) +
+ labs(title = paste("k-Means Clustering of", kClusters, "Colours"))
+
+ xlab("x") +
+ ylab("y") +
+ plotTheme()</strong></span>
</pre><p>The result is as follows:</p><p>
</p><div class="mediaobject"><img src="graphics/image_07_011.jpg" alt="Step 5 - building the model and visualizing it"/></div><p>
</p></div></div></div></body></html>