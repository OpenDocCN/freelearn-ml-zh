# 第12章

量子生成对抗网络

*假装做到你就能做到*

—— 某人，某地

到目前为止，我们只讨论了在监督学习背景下量子机器学习模型。在我们量子机器学习（QML）之旅的最后一章中，我们将讨论一个QML模型的奇妙和神秘之处，这将引领我们进入无监督学习的领域。我们将讨论著名的**生成对抗网络**（通常缩写为**GANs**）的量子版本，称为**量子生成对抗网络**、**量子GANs**或**QGANs**。

在本章中，你将了解什么是经典和量子生成对抗网络（GANs），它们有什么用途，以及如何使用它们。我们将从基础知识开始，探讨导致GAN概念直观想法的原理。然后，我们将深入一些细节，并讨论量子生成对抗网络（QGANs）。特别是，我们将讨论现有的不同类型的QGANs及其（可能的）优势。你还将学习如何使用PennyLane（及其TensorFlow接口）和Qiskit与它们一起工作。

本章我们将涵盖以下主题：

+   GANs及其量子对应物

+   PennyLane中的量子GANs

+   Qiskit中的量子GANs

对最后一章感到兴奋吗？让我们先了解这些GANs究竟是什么。

# 12.1 GANs及其量子对应物

量子GANs是**生成模型**，可以以完全无监督的方式训练。我们所说的生成模型是指量子GANs将能够生成可以模仿训练数据集的数据；例如，如果你有一个包含大量人物图片的大数据集，一个好的生成模型将能够生成新的人物图片，这些图片与原始分布中的图片难以区分。QGANs可以以无监督方式训练的事实仅仅意味着我们的数据集将不需要标记；我们不需要告诉生成器其输出是好是坏，模型将自行解决这个问题。具体如何？请耐心等待！

这就是GANs的大致情况，但在我们探索所有细节之前，我们需要讨论一些事情。让我们谈谈如何伪造货币。

## 12.1.1 关于钱的一个看似无关的故事

当然，所有阅读这些文字的人都是守法公民——现在不需要报警——但为了知识上的说明，让我们假设我们自己是坏蛋一天。在伪造货币的过程中，涉及两个主要角色：

+   我们，那些试图制作尽可能接近真币的假币的坏蛋

+   一些权威机构，通常是中央银行，负责设计工具和技术来辨别真币和假币

这在*图* [*12.1*](#Figure12.1) 中有所展示。顺便说一句，我们自己绘制了假美元。图形设计是我们的热情所在。

![图12.1：参与伪造货币生成的代理的示意图](img/file1438.png)

**图12.1**：参与伪造货币生成的代理的示意图

现在我们已经准备好了，我们可以想象我们的伪造生涯可能是什么样子。由于我们中没有人有这方面的经验，我们伪造纸币的第一次尝试可能会非常灾难性：我们生成的任何纸币都很容易被央行识别为假币。然而，这仅仅是故事的开头。在这个过程中——假设我们没有被捕——我们总是可以尝试研究央行如何区分真币和假币，并利用它来欺骗其检测机制。然而，自然地，这只是一个临时解决方案，因为央行很快就会注意到我们改进的假币并设计出更好的检测系统，这将使我们回到起点，重新开始这个过程。

纸币有有限数量的定义特征，因此，经过足够多的迭代后，在某个时刻，我们可能会最终生产出与真实纸币完全相同的纸币。因此，将达到一个美丽的平衡点，其中央行将无法再检测到我们的假币。遗憾的是，对我们来说，这次冒险很可能会以央行完全更换纸币并将我们送交法官为结局。但让我们忽略那些小细节！

重要提示

就算不明显，我们谈论想象自己从事伪造时是在开玩笑。伪造货币，正如你希望知道的，是一种严重的刑事犯罪，我们当然不会以任何方式鼓励或支持这种行为。请，不要做违法的事情。编辑团队认为——有充分的理由！——这值得一个免责声明；所以，这就是它！

现在，你可能想知道我们为什么讨论这个。好吧，因为，正如事实所证明的，训练GAN的过程就像伪造货币一样——只是没有入狱的风险。让我们看看它是如何工作的！

## 12.1.2 什么是GAN？

GANs是在2014年由Goodfellow等人发表的一篇非常有影响力的论文[[46](ch030.xhtml#Xgoodfellow2014generative)]中引入的。正如我们在引言中提到的，GAN是一种机器学习模型，可以训练生成与给定数据集的模式和属性非常相似的数据。为了实现这一点，GAN有两个主要组件：

+   一个“生成”型神经网络（生成器），它将只是一个以任意种子作为输入并返回与原始数据集中元素数据类型匹配的输出的神经网络。这个神经网络的目的是，在训练结束时，生成新的数据，这些数据与原始数据集中的数据无法区分。

+   一个判别器神经网络，它将是一个二元分类神经网络，输入为数据集中的原始数据和生成网络的输出。这个判别器网络将负责尝试区分生成数据和原始数据。

这些组件在*图* [*12.2*](#Figure12.2) 中进行了展示。顺便说一下，我们自己是画了这些假树。图形设计是我们的激情。

![图 12.2：生成对抗网络中涉及的代理的示意图](img/file1439.png)

**图 12.2**：生成对抗网络中涉及的代理的示意图

要了解更多……

GANs已经在实际的生成任务中取得了非常成功的应用。例如，NVIDIA研究人员引入的StyleGANs是一种GAN，能够生成极其逼真的人类面孔。他们的代码是开源的（你可以在[https://github.com/NVlabs/stylegan](https://github.com/NVlabs/stylegan)找到），并且为迷人的网站”This Person Does Not Exist”([https://www.thispersondoesnotexist.com/](https://www.thispersondoesnotexist.com/))提供动力。

这个描述解决了GAN是什么的问题，但现在我们需要了解这些GAN是如何实际训练的。本质上，整个训练过程是这样的：

1.  你将生成器和判别器初始化为某种随机配置。

1.  你训练判别器来区分生成器的输出和真实数据。在这个初始阶段，这对判别器来说应该是一个非常简单的任务。

1.  然后，你训练生成器来欺骗判别器：你以这种方式训练它，使得判别器——在之前步骤中训练的——将尽可能多的生成输出分类为真实。一旦训练完成，你就用它来生成一大堆假数据。

1.  而这里就是乐趣开始的地方。你使用新的生成数据集重新训练判别器，然后重新训练生成器来欺骗新的判别器。你可以重复这个过程，直到你想要的次数。理想情况下，在每次迭代中，判别器将更难区分生成数据和真实数据。最终，将达到一个平衡点，其中生成数据将无法与原始数据区分开来。就像我们之前的伪造冒险一样——而且没有法律问题在眼前！

这个过程在*图* [*12.3*](#Figure12.3) 中以示意图的形式进行了展示，其中我们展示了旨在生成可爱猫咪图片的生成对抗网络（GAN）的训练过程。当GAN初始化时，生成器仅产生随机噪声。经过后续的训练迭代后，生成器的输出将更接近原始数据集中的图像——在这个例子中，应该是一个包含猫咪图片的数据集。顺便说一下，我们自己是画了这些假猫。我们提到过图形设计是我们的激情吗？

我们应该强调，这个方案非常简化。实际上，你通常不会“完全”交替训练判别器和生成器，而是交替优化它们。例如，如果你使用给定批量大小的梯度下降法，那么在每个epoch和每个batch中，你会在单个优化器步骤中优化判别器的权重，然后你会对生成器的权重做同样的操作。

![图12.3：旨在生成可爱猫咪图片的GAN训练过程的示意图](img/file1440.png)

**图12.3**：旨在生成可爱猫咪图片的GAN训练过程的示意图

通过对训练过程的描述，我们现在可以理解GAN这个术语。这些模型是“生成”的，因为它们旨在生成数据。它们是“网络”，因为，嗯，它们使用了神经网络。而且它们是“对抗”的，因为整个训练过程都包含生成器网络和判别器网络之间的竞争。这些网络在激烈的竞争中展开，而我们，它们的程序员和创造者，将是唯一的真正赢家。

要了解更多...

所有这些时间，我们一直在谈论GAN如何在判别器和生成器中使用神经网络。然而，这些神经网络并不总是像我们在本书中讨论的那样。

我们所研究的神经网络被称为“密集”神经网络。在这些网络中，所有层都是密集的，这意味着后续层的神经元是完全连接的。然而，当神经网络被设计来处理图像——无论是生成、分类还是操作图像时——通常会使用不同类型的层：卷积层。我们不会深入探讨这些层的工作原理（详细解释请参考Gerón的书中第14章 [[104](ch030.xhtml#Xhandsonml)]），但你至少应该知道它们的存在。

GAN通常用于图像生成任务，所以，如果你决定研究经典GAN，请注意你肯定会在某个时候处理这些层。是的，还有卷积层和卷积网络的量子版本 [[114](ch030.xhtml#Xquantum-conv), [52](ch030.xhtml#Xhavlivcek2019supervised)]，遗憾的是，我们没有时间在这本书中涵盖。

关于GAN的训练过程，有几个细节我们应该强调。首先也是最重要的一点是，在整个训练过程中，生成器网络“暴露”或提供原始数据的情况从未发生。生成器网络了解它必须复制的唯一方式是通过判别器。这样，我们不必告诉生成器网络其输出应该是什么样子，判别器就承担了我们的角色，使我们能够以完全无监督的方式训练整个网络。

另一个我们应该注意的问题是，GANs，像任何其他机器学习模型一样，容易在训练过程中出现问题。例如，我们如何保证生成的输出不是原始数据的略微扭曲的副本，而不是与原始数据集中的模式相匹配的新数据元素？例如，在我们考虑的 *图* [*12.3*](#Figure12.3) 中的猫 GAN，我们如何保证生成的图像是新的猫图片，而不是，比如说，我们原始图像的模糊副本，这些图像已经失去了与猫的相似性，但仍然能够欺骗判别器网络？这可能发生，例如，如果我们的判别器与生成器相比不够强大。

要了解更多...

如果生成的 GAN 无法生成数据集中所有可能的变化（或**模式**），GAN 的训练也可能失败。例如，在我们考虑的例子中，如果我们的 GAN 只能生成一小部分猫的图片，甚至可能只有一张！这种情况被称为**模式坍塌**。为了尝试避免这种情况，已经提出了几种修改后的 GAN，包括**Wasserstein GANs**（**WGANs**）[[7](ch030.xhtml#Xarjovsky2017wasserstein)]，它们从称为 Wasserstein 距离的度量中推导出其损失函数。

在我们之前章节中考虑的模型中，始终有一个简单直接的方法来有效地评估它们的性能——即在测试数据集上评估损失函数。当与 GAN 一起工作时，事情可能会更加微妙。一般来说，你应该始终查看生成的数据，并检查结果是否令人满意。

重要提示

GAN 由两个神经网络组成：一个生成器和判别器。它们在迭代训练过程中相互竞争。判别器的任务是区分真实数据集和生成器网络输出的数据，而生成器网络的任务是生成判别器会错误地识别为真实的数据。

仅为了总结一下关于经典 GANs 的概述，让我们讨论一下关于生成器和判别器网络训练的一些技术细节。

## 12.1.3 关于 GANs 的技术细节

我们已经提到，生成器和判别器网络是普通的神经网络模型——即使它们可能与我们之前讨论的不同——它们在迭代过程中不断重新训练。现在我们将简要谈谈这种训练是如何进行的。

设![X](img/file9.png "X")为一个真实数据集，设![S](img/file73.png "S")为我们提供给生成器的“种子”集合。在判别器神经网络的情况下，我们只是在训练一个二元分类器，并且按照惯例，这个分类器将返回一个介于![0](img/file12.png "0")和![1](img/file13.png "1")之间的输出。不失一般性，我们将假设接近![1](img/file13.png "1")的值表示来自真实数据集的输入，而接近![0](img/file12.png "0")的值被标记为生成的输入——这是一个任意的选择；它完全可以相反。

就像任何其他二元分类器一样，最自然的损失函数将是二元交叉熵损失，因此这个分类器将像监督学习一样进行训练：将“真实标签”![1](img/file13.png "1")分配给来自真实数据集的任何输入，将“真实标签”![0](img/file12.png "0")分配给任何生成的输入。这样，如果我们让![G](img/file1441.png "G")和![D](img/file1101.png "D")表示生成器和判别器的动作，判别器训练损失![L_{D}](img/file1442.png "L_{D}")将被计算为

| ![L_{D} = - \frac{1}{ | X | + | S | }\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right),](img/file1443.png "L_{D} = - \frac{1}{ | X | + | S | }\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right),") |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |

其中我们使用![|X|](img/file1444.png "|X|")和![|S|](img/file1445.png "|S|")分别表示集合![X](img/file9.png "X")和![S](img/file73.png "S")的大小。判别器的工作是使这个损失最小化。

现在，关于生成器网络呢？我们希望在它的训练过程中最小化的损失函数应该是什么？当我们训练生成器时，我们的目标是欺骗判别器，让它将我们的生成数据分类为真实数据。因此，生成器训练中的目标是最大化判别器的损失函数，即最小化

| ![- L_{D} = \frac{1}{ | X | + | S | }\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right).](img/file1446.png "- L_{D} = \frac{1}{ | X | + | S | }\left( {\sum\limits_{x \in X}\log D(x) + \sum\limits_{s \in S}\log\left( {1 - D(G(s)} \right)} \right).") |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |

然而，由于第一个项在生成器训练中必然是常数，因为它以任何方式都不依赖于生成器。因此，等价地，我们可以考虑生成器训练的目标是最小化生成器损失函数

| ![L_{G}^{\prime} = \frac{1}{ | S | }\sum\limits_{s \in S}\log\left( {1 - D(G(s))} \right).](img/file1447.png "L_{G}^{\prime} = \frac{1}{ | S | }\sum\limits_{s \in S}\log\left( {1 - D(G(s))} \right).") |
| --- | --- | --- | --- | --- |

理论上事情就是这样。然而，在实践中，已经证明 [[46](ch030.xhtml#Xgoodfellow2014generative)]，通常将生成器训练的目标设定为损失最小化会更稳定。

| ![L_{G} = - \frac{1}{ | S | }\sum\limits_{s \in S}\log\left( {D(G(s))} \right).](img/file1448.png "L_{G} = - \frac{1}{ | S | }\sum\limits_{s \in S}\log\left( {D(G(s))} \right).") |
| --- | --- | --- | --- | --- |

在这里的关键是，使用这两种定义，如果在训练生成器时这些生成器损失函数下降，那么我们的生成数据被我们的分类器（错误地）分类为真实数据的可能性会更大。这反过来意味着，我们的数据应该逐渐变得更加类似于原始数据集中的数据。

还已经证明，在生成器和判别器之间的最佳均衡状态下，判别器分配的值 ![D(x)](img/file1449.png "D(x)") 和 ![G(D(s))](img/file1450.png "G(D(s))") 等于 ![\left. \frac{1}{2} \right.](img/file136.png "\left. \frac{1}{2} \right.")（因为它无法区分真实和生成数据），因此，当 ![\left. L_{D} = L_{G} = - \log \frac{1}{2} = \log 2 \approx 0.6931 \right.](img/file1451.png "\left. L_{D} = L_{G} = - \log \frac{1}{2} = \log 2 \approx 0.6931 \right.")。你可以在原始 GANs 论文中找到证明（使用略有不同但等效的损失函数）[[46](ch030.xhtml#Xgoodfellow2014generative)]。

要了解更多…

可以证明，GAN 的最佳配置是生成器和判别器之间对抗游戏的纳什均衡（例如，参见 Goodfellow 在 NIPS 上提供的有用教程 [[47](ch030.xhtml#Xgoodfellow2016nips)]）。在这个均衡中，GAN 的配置是生成器和判别器损失的（局部）最小化者。

这应该是对经典 GAN 的足够介绍。现在让我们看看量子 GAN 是什么，以及它们能提供什么。

## 12.1.4 量子 GAN

什么是量子 GAN？它只是一个 GAN，具有其竞争的判别器和生成器，其中模型的一部分由量子模型（通常是某种形式的量子神经网络）实现，并且它就像经典 GAN 一样进行训练。换句话说，训练量子 GAN 就像伪造货币——但你不会冒坐牢的风险，而且你可以玩量子东西。

要了解更多…

顺便说一句，你知道有无法伪造的量子货币的提案吗？最初的想法是由斯蒂芬·威斯纳[[97](ch030.xhtml#Xwiesner1983conjugate)]提出的，并成为著名的BB84量子密码协议的灵感，该协议由本内特和布拉萨德[[13](ch030.xhtml#Xbennett84quantum)]提出。

事实上，这已经是我们能得到的接近精确定义的程度，因为可以适应QGAN类别模型范围非常广泛。根据你想要解决的问题类型，你可能希望使用具有完全不同架构的量子GANs，这些架构仍然会共享竞争判别器和生成器的相同核心元素。以下章节中的例子将帮助我们说明这一点。

从广义上讲，任何量子GAN都可以适应以下类别之一：

+   **使用量子数据和生成器以及** **判别器都是量子**：这种量子数据将只是某些量子状态，生成器和判别器将通过量子电路实现。

    这种情况允许一个非常特殊的QGAN架构，具有完全量子模型。由于我们处理的是量子数据（状态），并且GAN的所有组件都是量子电路，它们可以完美地连接在一起，而无需在模型中间使用特征图或测量操作。

    在本章的后面部分，我们将研究PennyLane上纯量子架构的例子。

+   **使用量子数据和经典** **判别器**：如果判别器是经典的，我们的QGANs架构将与经典GANs的架构更加相似。生成器将产生量子状态，但最终，它们将通过某种测量操作转换成经典数据，以便输入到分类器中。当然，原始的量子数据也必须进行测量。

+   **使用经典数据和量子** **生成器或判别器**：这是QGANs可以最好地匹配其经典对应物的场景。在这些情况下使用QGANs本质上相当于用具有经典输入和输出的量子模型替换生成器或判别器（或两者）。例如，在量子判别器的情况下，我们不得不使用特征图将经典数据加载到量子状态中。

    由于经典数据的可用性远大于量子数据，这种架构类型已经被量子计算社区更广泛地研究。

    在本章的后面部分，我们将考虑一个具有经典数据和经典分类器，但具有量子生成器的QGAN。那将在我们的Qiskit部分。

要了解更多...

在文献中，有许多关于GAN量子版本的不同的提议。其中一些最早的包括Lloyd和Weedbrook的工作 [[64](ch030.xhtml#Xlloyd2018quantum)]，Dallaire-Demers和Killoran的工作 [[28](ch030.xhtml#Xdallaire2018quantum)]，以及Zoufal、Lucchi和Woerner的工作 [[101](ch030.xhtml#Xzoufal2019quantum)]。

练习12.1

在这本书中，我们讨论了四种不同的QML模型：量子支持向量机、量子神经网络、混合QNN和量子GAN。决定以下任务中哪个模型是合适的：

1.  区分猫的图片和狗的图片。

1.  生成狗的图片。

1.  根据其元数据判断一笔金融交易是否欺诈。

1.  评估患者病历和心电图数据中心脏衰竭的风险。

1.  创建随机心电图图像数据集，以训练未来的医生。

我们应该给你一个警告。GAN不是最容易训练的模型。正如我们之前提到的，当你训练一个GAN时，你没有一个单一且直接的损失函数来衡量你的训练是否成功。训练GAN不是一个简单的优化问题，而是一个更复杂的过程。当然，使用量子模型只会使问题更加困难，训练量子GAN可能会很…复杂。

现在，我们将考虑几个有趣的QGAN示例，包括PennyLane和Qiskit。自然地，因为我们选择了它们，所以我们的量子GAN将顺利学习。但是，你已经被告知了：量子GAN通常是野性的生物。

# 12.2 PennyLane中的量子GAN

在本节中，我们将训练一个纯量子GAN，它将学习一个单量子比特状态。在我们之前的伪造示例中，我们想象自己像GAN一样行为，以复制一些训练数据（纸币）来生产假钞，理想情况下，每次迭代都会越来越接近真实物品。在这种情况下，我们的训练数据将是一个单量子比特状态，由一些振幅特征，我们的QGAN的任务将是复制该状态，而生成器没有直接访问它。因此，我们的数据集将包括多个单量子比特状态的副本，我们的目标将是训练一个能够准备该状态（或非常接近该状态）的生成器。

要了解更多…

注意，这种设置并没有违反我们在*第1.4.5节* [(*1.4.5*](ch008.xhtml#x1-320001.4.5)] 中证明的不克隆定理。我们将有多个相同的量子状态的副本，并且将对它们执行操作，包括测量它们（因此，它们的态会坍缩）。从这些操作中，我们将学习一些关于状态的属性，我们将使用这些属性来使用生成器重现它。但我们将不会有一个单位操作（量子门）来创建给定状态的额外、独立的副本。事实上，我们在过程中会销毁原始副本！*

*我们在这里要做的事情更类似于**量子态****全息术**（例如，参见Altepeter、James和Kwiat的综述[[6](ch030.xhtml#Xaltepeter2005photonic)]），这可以被定义为对状态的多份副本应用量子操作和测量，并从结果中学习重建原始状态。* *对于这个例子，我们将使用PyTorch机器学习包。如果您还没有看过，请参阅*子节*[*11.3.1*](ch020.xhtml#x1-20500011.3.1)。

我们选择使用PyTorch的原因很简单。尽管我们到目前为止已经使用了TensorFlow，但我们只知道如何使用它的基础级别，严重依赖于Keras界面。另一方面，我们在上一章中广泛研究了PyTorch，这使得它在我们处理更复杂的架构时成为一个更好的工具。换句话说，这个选择并不是基于任何包在技术上的优越性，而是基于我们在这本书中涵盖的内容中最实用的选择。事实上，几乎任何可以在PyTorch上构建和训练的模型也可以在TensorFlow上处理，反之亦然。

在这些预备知识之外，让我们进入我们的模型。

## 12.2.1 准备QGAN模型

我们寻求实现和训练的纯量子生成对抗网络（GAN）将在具有两个量子比特的设备上运行，并且它将由以下组件组成：

+   一个量子电路，它将能够准备我们想要我们的QGAN学习的单量子比特状态![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")。这个电路将在设备的第一个量子比特上运行。我们应该将其视为一个黑盒，其内部工作对我们模型是完全透明的。

    状态![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")，我们将称之为“真实状态”，是我们将在QGAN中使用的量子训练数据。这个电路将仅仅为我们提供访问训练数据的方法：在训练过程中可能需要的任何数量的![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")状态副本。这模拟了例如一个产生我们想要学习的某些量子状态的物理实验。

+   一个量子生成器，它也将运行在设备的第一个量子比特上，并且旨在在第一个量子比特上准备一个类似于![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")的状态。量子生成器将通过依赖于一些可训练参数的变分形式来实现。

+   一个量子判别器，它将在设备的第一个和第二个量子比特上运行。它的“输入”将是第一个量子比特上的状态，这可以是我们要我们的QGAN学习的状态或生成器准备的状态。当然，判别器的任务将是尝试区分这两种状态。我们用两个量子比特（而不是一个）来实现它，以确保它有足够的判别能力。

    由于这个判别器已经接受量子输入，它只需要由一个变分形式后跟一个测量操作组成——将不需要使用特征图，正如我们在处理经典数据时必须做的那样。像往常一样，我们将测量操作放在第一个量子比特上。

我们刚刚描述的所有组件都在 *图* [*12.4*](#Figure12.4) 中展示。

![(a) 准备我们想要我们的QGAN学习的状态的电路。](img/file1453.jpg)

**(a)** 准备我们想要我们的QGAN学习的状态 ![img](img/file1452.png) 的电路。

![(b) 生成器电路输出状态 。我们的目标是让 与 相似。](img/file1455.jpg)

**(b)** 生成器电路输出状态 ![img](img/file1454.png)。我们的目标是让 ![img](img/file1454.png) 与 ![img](img/file1452.png) 相似。

![(c) 判别器电路，负责判断状态是否是状态 或生成器的输出。](img/file1457.jpg)

**(c)** 判别器电路，负责判断状态 ![img](img/file1456.png) 是否是状态 ![img](img/file1452.png) 或生成器的输出。

**图12.4**：我们将训练以生成 ![img](img/file1452.png) 的量子GAN的组件

现在我们已经知道了我们的方向，让我们准备编写一些代码。首先，我们将进行我们通常的导入，并设置一些种子以确保结果的再现性：

[PRE0]

我们将使用通用单量子比特门 ![U_{3}(\varphi,\theta,\delta)](img/file1458.png "U_{3}(\varphi,\theta,\delta)") 来构建状态 ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")，因为，正如我们在 *第* [*1*](ch008.xhtml#x1-180001) *章* *量子计算基础* 中所学到的，它允许我们创建任何单量子比特状态。特别是，我们将输入值 ![\left. \varphi = \pi\slash 3 \right.](img/file1459.png "\left. \varphi = \pi\slash 3 \right.")、![\left. \theta = \pi\slash 4 \right.](img/file1460.png "\left. \theta = \pi\slash 4 \right.") 和 ![\left. \delta = \pi\slash 5 \right.](img/file1461.png "\left. \delta = \pi\slash 5 \right."):

[PRE1]

设置这些值后，我们可以定义一个函数来构建准备 ![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle") 的电路：

[PRE2]

注意，我们将其定义为函数而不是量子节点。这是因为，为了训练的目的，我们并不感兴趣于单独运行量子 GAN 的任何组件。我们反而需要将它们组合起来运行。例如，我们必须运行我们刚刚定义的电路与判别器组合后的电路。

现在我们已经有一个可以制备![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")的电路，是我们考虑我们 QGAN 的两个核心组件的时候了：生成器和判别器。具体来说，我们必须为它们找到一些合适的可变形式。

对于生成器，我们将简单地使用一个参数化的 U3 门，而对于判别器，我们将使用两种局部可变形式的变体。这些可以按照以下方式实现：

[PRE3]

你可以在*图* [*12.5*](#Figure12.5) 中看到判别器可变形式的图形表示；其实现方式与两种局部可变形式类似，只是有一些细微的差别。在非常小的细节上，我们将可优化参数的向量重命名为 `weights`（而不是 `theta`），以避免与定义![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")的角度 `theta` 产生混淆。

![图 12.5：两个量子比特和两次重复的判别器可变形式](img/file1462.jpg)

**图 12.5**：两个量子比特和两次重复的判别器可变形式

利用这些新定义的可变形式，我们将定义生成器和判别器的电路如下：

[PRE4]

我们现在可以定义我们将在训练中使用的量子节点。在分类器中，我们将测量操作定义为在第一个量子比特上计算![M = \left| 0 \right\rangle\left\langle 0 \right|](img/file1388.png "M = \left| 0 \right\rangle\left\langle 0 \right|")的期望值。为此，我们可能构造矩阵![M](img/file704.png "M")如下：

[PRE5]

我们现在可以定义两个量子节点：一个将状态![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")的生成与判别器连接起来，另一个将生成器与判别器连接起来。我们可以通过以下代码片段实现这一点：

[PRE6]

测量操作是在两个节点中第一个量子比特上计算![M](img/file704.png "M")的期望值；由于这个操作是判别器的输出，这些测量操作需要是相同的。顺便说一下，由于判别器作用于我们设备上的两个量子比特，我们也可以使用第二个量子比特上![M](img/file704.png "M")的期望值。

### 训练过程

现在我们已经完全设置了我们的模型，并定义了我们在其训练中将要使用的所有节点。但还有一件重要的事情我们还没有定义：判别器和生成器的损失函数。

正如我们之前讨论的，对于GAN的判别器的损失函数，一个合理的选择是二元交叉熵。在我们的情况下，我们的判别器只需要分类两个数据点：具有预期标签![1](img/file13.png "1")的真实状态![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")，以及具有预期标签![0](img/file12.png "0")的生成状态![\left| \psi_{g} \right\rangle](img/file1463.png "\left| \psi_{g} \right\rangle")。因此，如果我们让![D](img/file1101.png "D")表示判别器在某种配置下的作用，二元交叉熵损失将是

| ![L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left&#124; \psi_{g} \right\rangle)} \right) + \log\left( {D(\left&#124; \psi_{1} \right\rangle)} \right)} \right).](img/file1464.png "L_{D} = - \frac{1}{2}\left( {\log\left( {1 - D(\left&#124; \psi_{g} \right\rangle)} \right) + \log\left( {D(\left&#124; \psi_{1} \right\rangle)} \right)} \right).") |
| --- |

这个损失函数可以使用我们之前定义的节点如下实现：

[PRE7]

现在，关于生成器的损失呢？我们已经知道生成器的目标是欺骗判别器将生成的状态错误地分类为真实状态。此外，我们还提到了一个合理的生成器损失函数是

| ![L_{G} = - \log\left( {D(\left&#124; \psi_{g} \right\rangle)} \right).](img/file1465.png "L_{G} = - \log\left( {D(\left&#124; \psi_{g} \right\rangle)} \right).") |
| --- |

如果判别器被要求将生成的状态分类为真实状态，这将是对判别器的二元交叉熵损失。

我们可以轻松地实现这个损失如下：

[PRE8]

这就定义了我们所有的损失。现在让我们为训练过程做好准备。首先，让我们初始化生成器和判别器的权重为一个具有随机值的张量：

[PRE9]

这些数组的维度可以从以下事实中得到证明：生成器使用了![3](img/file472.png "3")个权重，判别器的变分形式有![3 + 1](img/file1466.png "3 + 1")组参数化的门，其中![3](img/file472.png "3")个参数被用于每个形式作用的![2](img/file302.png "2")个量子比特上。另外，记住我们需要将`requires_grad`设置为`True`，以便PyTorch能够在稍后对这些权重计算梯度。

现在，我们可以定义在训练中使用的优化器。对于这个问题，我们将依赖于随机梯度下降算法，这是我们在前几章中使用的 Adam 优化器的一个更简单的版本（见 *第8.2.3节* [ch017.xhtml#x1-1520008.2.3] 以获取复习）。在调用优化器时，我们必须提供一个数组或字典，其中包含我们希望优化器关注的参数。当我们以前将 PyTorch 模型定义为 `nn.Module` 的子类时，我们可以通过 `parameters` 方法直接获取这些参数，但在这个情况下，我们将自己创建这个列表。这可以按照以下方式完成：

[PRE10]

在这次调用优化器时，我们将它们的学习率设置为![0.5](img/file1166.png "0.5")。

这些就是训练我们模型所需的所有成分。我们可以执行以下代码片段来完成这项工作：

[PRE11]

在这里有很多东西需要消化。在代码的前几行中，我们只是在定义一些数组，我们将随着训练的进行在这些数组中存储数据。数组 `dis_losses` 和 `gen_losses` 将在每个训练周期中保存判别器和生成器的损失，而数组 `log_weights` 将存储在每个训练周期结束时获得的生成器权重。我们将在以后使用这些信息来评估训练的有效性。

我们已经将训练设置为运行![150](img/file1467.png "150")次优化周期。在每个周期中，我们将优化判别器的值，然后优化生成器的值，最后记录所有结果。让我们一步一步来：

1.  当我们优化判别器时，我们重置其优化器（`optd`），然后计算判别器损失函数并将其存储在 `lossd` 中。注意，当我们发送生成器权重时，我们通过 `detach` 方法传递它们。这个方法消除了对这些权重计算梯度的需要。无论怎样，判别器优化器都不会触及这些权重，这将为我们节省一些计算时间。一旦我们有了损失，我们就使用 `backward` 方法计算其梯度，并运行判别器优化器的一步。

1.  生成器的优化是完全相似的。我们只需在从生成器损失 `lossg` 获得的梯度上使用生成器优化器 `optg`。当然，在调用生成器损失函数时，我们移除了判别器权重，而不是生成器权重。

1.  最后，我们记录损失值。为此，我们只需存储在训练周期中计算的损失值。这些值可能不同于周期末的值，但它们仍然足够有信息量。

    之后，我们存储生成器的权重。请注意对`clone`方法的调用。这个调用确保我们得到权重的一个副本，而不是权重张量的引用。如果我们没有调用这个方法，`log_weights`中的所有权重数组都会引用同一个张量，它们的值都会相同，并且会（同时）随着训练的进行而改变！

    最后，我们打印一些关于训练的信息。由于我们将执行这个循环![150](img/file1467.png "150")个训练周期，并且训练将会很快，所以我们每![15](img/file599.png "15")个周期只打印一次信息。

注意，我们不是交替地完全训练判别器和生成器，而是在每个训练周期中交替优化它们。

运行前面的代码后得到的输出如下：

[PRE12]

只需看一下这个原始输出，我们就可以看出，我们的训练可能已经成功：判别器损失和生成器损失都在接近![\left. - \log 1\slash 2 \right.](img/file1468.png "\left. - \log 1\slash 2 \right.")，正如它们应该在最佳点所做的那样。这是一个好兆头！

为了更好地了解这些损失的演变，我们可以使用`gen_losses`和`dis_losses`数组来绘制它们的演变。这可以按以下方式完成：

[PRE13]

结果图可以在*图* [*12.6*](#Figure12.6) 中找到，实际上，我们可以看到一个很好的趋势，从中我们可以得出一些乐观的结论。

![图 12.6：判别器和生成器在训练过程中的损失演变](img/file1469.png)

**图 12.6**：判别器和生成器在训练过程中的损失演变

但现在到了检验真伪的时刻。让我们看看我们的模型是否真的像我们希望的那样学习了。在上一节中，我们提到，在训练生成对抗网络时，确定训练过程是否成功的最佳标准取决于具体问题。在我们的情况下，如果生成器返回的状态接近![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")，则我们的训练将成功。

现在，我们如何确定一个量子比特的状态向量？事实证明，量子比特的状态（除了一个不重要的全局相位之外，正如我们在*第 1.3.4 节*中看到的那样）完全由其布洛赫球坐标来表征。既然我们已经遇到了这些坐标，让我们通过一个希望你会觉得有趣的练习来学习如何计算它们——尽管，诚实地讲，这个练习与本章内容略有不相关。*

*练习 12.2

证明一个单比特态的布洛赫球坐标是三个泡利矩阵![X](img/file9.png "X")、![Y](img/file11.png "Y")和![Z](img/file8.png "Z")给出的可观测量的期望值。

我们可以准备两个量子节点，这些节点返回这两个期望值：![\left| \psi_{1} \right\rangle](img/file177.png "\left| \psi_{1} \right\rangle")和训练后生成器返回的状态。这可以按以下方式完成：

[PRE14]

我们得到的输出如下：

[PRE15]

输出是相同的，因此我们可以安全地说，我们的训练取得了巨大的成功！

为了结束本节，我们将通过视觉方式探索生成器在整个训练过程中创建的状态是如何演变的。我们可以使用我们刚刚定义的`log_weights`权重数组和`generated_coordinates`函数来完成这项工作。这个函数将生成器的权重作为输入，因此我们可以使用保存的权重在任何训练阶段获取生成的状态的Bloch坐标。

我们可以这样完成：

[PRE16]

这个函数将为任何训练周期绘制一个表示生成的状态的Bloch坐标的图，并将其叠加到我们希望我们的QGAN学习的状态的坐标上。在*图* [*12.7*](#Figure12.7)中，你可以看到对应于广泛周期的绘图。

![图12.7：随着训练的进行，生成的状态的Bloch坐标的演变](img/file1470.png)

**图12.7**：随着训练的进行，生成的状态的Bloch坐标的演变

练习12.3

尝试在不同的状态上复制这个例子（在某些情况下，你可能需要增加训练周期数以达到收敛）。

这就结束了这个例子。现在让我们考虑一个不同的QGAN，这次是在Qiskit中实现的。

# 12.3 Qiskit中的量子GAN

量子GAN的一个早期提议是由IBM研究人员Zoufal、Lucchi和Woerner提出的 [[101](ch030.xhtml#Xzoufal2019quantum)]，他们使用具有量子生成器和经典判别器的QGAN来学习概率分布。在本节中，我们将讨论如何使用Qiskit实现这种类型的QGAN，因此让我们更精确地定义所有这些。

这种类型的量子GAN被给定了遵循某种概率分布的实数数据集。这种分布可能是连续的，但也可能被离散化以取一些值 ![m,m + 1,m + 2,\ldots,M - 1,M](img/file1471.png "m,m + 1,m + 2,\ldots,M - 1,M")，其中 ![m < M](img/file1472.png "m < M")；这通常是通过固定值 ![m](img/file259.png "m") 和 ![M](img/file704.png "M")，四舍五入样本并忽略小于 ![m](img/file259.png "m") 或大于 ![M](img/file704.png "M") 的样本来完成的。每个结果标签 ![j = m,\ldots,M](img/file1473.png "j = m,\ldots,M") 都将有一定的概率 ![p_{j}](img/file1474.png "p_{j}") 出现在数据集中。这就是我们希望我们的QGAN中的生成器学习到的分布。

那么，这些QGAN的生成器看起来是什么样子呢？它是一个依赖于一些经典参数的量子生成器。它需要设计成具有![n](img/file244.png "n")个量子位，这样![M - m < 2^{n}](img/file1475.png "M - m < 2^{n}")，以便我们可以在生成器的计算基中测量后，为每个可能的输出![r](img/file1337.png "r")分配一个![m,\ldots M](img/file1477.png "m,\ldots M")中的标签![\alpha(r)](img/file1476.png "\alpha(r)")。因此，训练的目标将是使生成器返回的状态尽可能接近

| ![\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left&#124; r \right\rangle.](img/file1478.png "\sum\limits_{r}\sqrt{p_{\alpha(r)}}\left&#124; r \right\rangle.") |
| --- |

以这种方式，从训练好的生成器中测量的样本应该等同于从原始分布中提取更多的数据样本，因为测量![\left| r \right\rangle](img/file1479.png "\left| r \right\rangle")（与标签![\alpha(r)](img/file1476.png "\alpha(r)"))相关联）的概率正好是![\left| \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}](img/file1480.png "\left| \sqrt{p_{\alpha(r)}} \right|^{2} = p_{\alpha(r)}").

使QGAN训练成为可能的判别器是一个经典的神经网络，其任务是区分输入数据是否属于原始数据集或是由判别器生成的。

因此，这就是我们将要工作的QGAN：一个混合QGAN，其中生成器是量子化的，而判别器是经典的。听起来很有趣？让我们看看我们如何使用Qiskit实现和训练它。

为了开始，让我们导入NumPy和Qiskit，同时设置一些种子以确保我们结果的复现性：

[PRE17]

我们将考虑之前概述的通用问题的特定例子。我们将使用一个包含![1000](img/file790.png "1000")个样本的数据集，这些样本是从![n = 3](img/file1481.png "n = 3")次试验和概率![\left. p = 1\slash 2 \right.](img/file1482.png "\left. p = 1\slash 2 \right.")的二项分布中生成的。这些分布只能取![4 = 2^{2}](img/file1483.png "4 = 2^{2}")个可能值 (![0,1,2,3](img/file1484.png "0,1,2,3"))，因此我们的生成器将需要使用![2](img/file302.png "2")个量子位。我们可以使用以下方式使用NumPy生成数据集的样本：

[PRE18]

Qiskit框架已经集成了`QGAN`类，可以创建和训练我们之前讨论过的QGAN架构——它几乎是为这个问题量身定制的！我们可以从`qiskit_machine_learning``.``algorithms`模块导入该类，并定义我们的QGAN如下：

[PRE19]

在调用`QGAN`初始化器时，我们必须指定我们想要学习的数据集的分布，我们想要“切割”数据集的界限（在这种情况下，我们只指定了我们分布的实际界限），包含生成器电路量子比特数的数组，批处理大小，我们希望QGAN运行的训练周期数，QGAN将运行的量子实例，最后是一个可选的种子。

你可能会对我们不得不以数组形式发送量子生成器的量子比特数感到困惑。这是因为这个`QGAN`类可以支持生成任何维度![d](img/file1485.png "d")（使用![d](img/file1485.png "d")个生成器）的样本；在我们的情况下，我们有![d = 1](img/file1486.png "d = 1")，因此我们只需要传递一个包含单个元素的数组。

这个QGAN对象已经包含了生成器和判别器的默认实现，我们将依赖它们。

要了解更多信息...

在此默认实现中，判别器是一个具有两个连续中间层的密集神经网络，每个中间层有![50](img/file1390.png "50")和![20](img/file588.png "20")个神经元；这些中间层的激活函数是漏ReLU函数，输出层的激活函数是sigmoid函数。生成器使用一个变分形式，包括在每个量子比特上应用一个Hadamard门，然后是具有一次重复和圆周纠缠的两个局部变分形式。

这些细节在文档中未指定，但可以在源代码中找到。

为了训练QGAN，我们可以运行以下指令：

[PRE20]

训练完成可能需要几分钟，具体取决于你电脑的硬件配置。为了在整个训练过程中绘制生成器和判别器损失的演变，我们可以运行以下代码：

[PRE21]

这产生了*图* [*12.8*](#Figure12.8)中所示的图表。我们可以看到，两个损失都接近![\left. - \log 1\slash 2 \right.](img/file1468.png "\left. - \log 1\slash 2 \right.")，这可以给我们训练成功的希望。

![图12.8：QGAN训练过程中生成器和判别器损失的演变，学习分布](img/file1487.png)

**图12.8**：QGAN训练过程中生成器和判别器损失的演变，学习分布

为了检查我们的训练是否成功，我们将绘制生成器测量结果的分布与原始分布的对比图。我们可以按照以下方式生成此图的所需数据：

[PRE22]

在这段代码中，我们首先让我们的QGAN生成一个具有它所学习分布的样本。然后，我们创建了一个包含分布中值相对频率的数组 `real_distr`（条目 `j` 对应于值 ![j](img/file258.png "j") 的相对频率）。最后，我们将真实分布与我们的生成分布进行了对比绘图。输出可以在 *图* [*12.9*](#Figure12.9) 中找到。

![图12.9：比较真实分布（较粗的柱状图）与QGAN生成的分布（较细的柱状图）的直方图](img/file1488.png)

**图12.9**：比较真实分布（较粗的柱状图）与QGAN生成的分布（较细的柱状图）

当然，就这个例子而言，这种可视化已经足够让我们相信训练确实有效。在更复杂的例子中，人们可能更希望依赖更多量化的成功指标。其中一个指标是从一个分布到另一个分布的**相对熵**或**库尔巴克-莱布勒****散度**。用通俗的话说，这个熵度衡量了两个分布“不同”的程度，如果两个分布 ![P_{0}](img/file1489.png "P_{0}") 和 ![P_{1}](img/file1490.png "P_{1}") 是相同的，那么从 ![P_{0}](img/file1489.png "P_{0}") 到 ![P_{1}](img/file1490.png "P_{1}") 的相对熵是 ![0](img/file12.png "0")。当 ![P_{1}](img/file1490.png "P_{1}") 与 ![P_{0}](img/file1489.png "P_{0}") 的差异越来越大时，相对熵也会增加。

要了解更多信息…

当你被给出两个在空间 ![X](img/file9.png "X") 上的离散概率分布 ![P_{0}](img/file1489.png "P_{0}") 和 ![P_{1}](img/file1490.png "P_{1}") 时，从 ![P_{0}](img/file1489.png "P_{0}") 到 ![P_{1}](img/file1490.png "P_{1}") 的相对熵可以定义为

| ![D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left( \frac{P_{1}(x)}{P_{0}(x)} \right).](img/file1491.png "D(P_{1} \parallel P)0) = \sum\limits_{x \in X}P_{1}(x)\log\left( \frac{P_{1}(x)}{P_{0}(x)} \right).") |
| --- |

Qiskit的QGAN实现记录了QGAN训练过程中相对熵的值。这样，我们可以使用以下指令绘制QGAN训练过程中相对熵的变化：

[PRE23]

输出显示在 *图* [*12.10*](#Figure12.10) 中。

![图12.10：QGAN训练过程中相对熵的变化](img/file1492.png)

**图12.10**：QGAN训练过程中学习分布的相对熵变化

可以清楚地看到，随着训练的进行，相对熵趋近于 ![0](img/file12.png "0")，正如我们所期望的那样。这标志着我们例子的结束。现在是时候总结一下了！

# 概述

在本章中，我们探索了一种全新的量子机器学习模型：量子 GANs。与之前考虑的模型不同，这些模型主要用于生成任务。而且，与之前的模型不同，它们是以完全无监督的方式进行训练的。

在了解 GANs 的一般概念之后，我们介绍了 QGAN 的一般概念，然后我们学习了如何使用 PennyLane 和 Qiskit 实现几个 QGAN 模型。

因此，我们也完成了这本书对量子机器学习的探讨。我们希望你在学习所有这些使量子计算机学习的方法时过得愉快！但你的量子之旅并不需要在这里结束。请继续阅读，提前一瞥你可以在不久的将来在量子计算领域期待的内容。**
