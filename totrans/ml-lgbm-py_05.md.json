["```py\nparams = {\"learning_rate\": [0.001, 0.01, 0.1],\n          \"num_leaves\": [10, 20, 50, 100],\n          \"num_estimators\": [100, 200, 500]}\n```", "```py\ndef objective(trial):\n        boosting_type = trial.suggest_categorical(\n            \"boosting_type\", [\"dart\", \"gbdt\"])\n        lambda_l1= trial.suggest_float(\n            'lambda_l1', 1e-8, 10.0, log=True),\n...\n        min_child_samples= trial.suggest_int(\n            'min_child_samples', 5, 100),\n        learning_rate = trial.suggest_float(\n            \"learning_rate\", 0.0001, 0.5, log=True),\n        max_bin = trial.suggest_int(\n            \"max_bin\", 128, 512, 32)\n        n_estimators =  trial.suggest_int(\n            \"n_estimators\", 40, 400, 20)\n```", "```py\nn_estimators =  trial.suggest_int(\n            name=\"n_estimators\", low=40, high=400, step=20)\n```", "```py\npruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"binary\")\n```", "```py\nmodel = lgb.LGBMClassifier(\n    force_row_wise=True,\n    boosting_type=boosting_type,\n    n_estimators=n_estimators,\n    lambda_l1=lambda_l1,\n    lambda_l2=lambda_l2,\n    num_leaves=num_leaves,\n    feature_fraction=feature_fraction,\n    bagging_fraction=bagging_fraction,\n    bagging_freq=bagging_freq,\n    min_child_samples=min_child_samples,\n    learning_rate=learning_rate,\n    max_bin=max_bin,\n    callbacks=[pruning_callback],\n    verbose=-1)\nscores = cross_val_score(model, X, y, scoring=\"f1_macro\")\nreturn scores.mean()\n```", "```py\nsampler = optuna.samplers.TPESampler()\npruner = optuna.pruners.HyperbandPruner(\n    min_resource=10, max_resource=400, reduction_factor=3)\nstudy = optuna.create_study(\n    direction='maximize', sampler=sampler,\n    pruner=pruner\n)\nstudy.optimize(objective(), n_trials=100, gc_after_trial=True, n_jobs=-1)\n```", "```py\nprint(study.best_trial)\n```", "```py\njoblib.dump(study, \"lgbm-optuna-study.pkl\")\n```", "```py\nstudy = joblib.load(\"lgbm-optuna-study.pkl\")\nstudy.optimize(objective(), n_trials=20, gc_after_trial=True, n_jobs=-1)\n```", "```py\nstudy_name = \"lgbm-tpe-rdb-study\"\nstorage_name = f\"sqlite:///{study_name}.db\"\nstudy = optuna.create_study(\n    study_name=study_name,\n    storage=storage_name,\n    load_if_exists=False,\n    sampler=sampler,\n    pruner=pruner)\n```", "```py\nstudy = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n```", "```py\nfig = optuna.visualization.plot_param_importances(study)\nfig.show()\n```", "```py\nfig = optuna.visualization.plot_parallel_coordinate(study, params=[\"boosting_type\", \"feature_fraction\", \"learning_rate\", \"n_estimators\"])\nfig.show()\n```", "```py\ndef moo_objective(trial):\n    learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.5, log=True),\n    model = lgb.LGBMClassifier(\n        force_row_wise=True,\n        boosting_type='gbdt',\n        n_estimators=200,\n        num_leaves=6,\n        bagging_freq=7,\n        learning_rate=learning_rate,\n        max_bin=320,\n    )\n    scores = cross_val_score(model, X, y, scoring=\"f1_macro\")\n    return learning_rate[0], scores.mean()\n```", "```py\nstudy = optuna.create_study(directions=[\"maximize\", \"maximize\"])\nstudy.optimize(moo_objective, n_trials=100)\n```"]