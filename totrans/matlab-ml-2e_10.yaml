- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: MATLAB Tools for Recommender Systems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MATLAB推荐系统工具
- en: A recommender system is a model that’s designed to anticipate the preferences
    of a specific user. When applied to the domain of movies, it transforms into a
    movie recommendation engine. The process involves filtering items in a database
    by predicting the user’s potential ratings and facilitating the connection of
    users with the most suitable content in the dataset. This holds significance because,
    in extensive catalogs, users might not discover all pertinent content. Effective
    recommendations enhance content consumption and major platforms such as Netflix
    heavily depend on them to maintain user engagement. In this chapter, we will learn
    the basic concepts of recommender systems and how to build a **network intrusion
    detection system** (**NIDS**) using MATLAB.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是一种旨在预测特定用户偏好的模型。当应用于电影领域时，它转变为电影推荐引擎。这个过程涉及通过预测用户的潜在评分来过滤数据库中的项目，并促进用户与数据集中最合适内容的连接。这具有重要意义，因为在庞大的目录中，用户可能无法发现所有相关内容。有效的推荐可以增强内容消费，并且像Netflix这样的主要平台高度依赖它们来维持用户参与度。在本章中，我们将学习推荐系统的基础概念以及如何使用MATLAB构建**网络入侵检测系统**（**NIDS**）。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introducing the basic concepts of recommender systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍推荐系统的基本概念
- en: Finding similar users in data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据中寻找相似用户
- en: Creating recommender systems for network intrusion detection using MATLAB
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MATLAB创建用于网络入侵检测的推荐系统
- en: Deploying machine learning models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署机器学习模型
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will introduce basic machine learning concepts. To understand
    these topics, a basic knowledge of algebra and mathematical modeling is needed.
    You will also required working knowledge of MATLAB.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍基本的机器学习概念。为了理解这些主题，需要具备代数和数学建模的基本知识。您还需要具备MATLAB的实际操作能力。
- en: 'To work with the MATLAB code in this chapter, you’ll need the following files
    (available on GitHub at [https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用本章中的MATLAB代码，您需要以下文件（可在GitHub上找到，网址为[https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)）：
- en: '`CreditCardData.xlsx`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CreditCardData.xlsx`'
- en: '`CreditCardFraudDet.m`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CreditCardFraudDet.m`'
- en: '`NDISdata.csv`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NDISdata.csv`'
- en: '`NDISEnsemble.m`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NDISEnsemble.m`'
- en: Introducing the basic concepts of recommender systems
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍推荐系统的基本概念
- en: 'A **recommender system** is a type of information filtering system that’s designed
    to suggest items or content to users based on their preferences, historical behavior,
    or other relevant factors. These systems are widely used in various online platforms
    to help users discover products, services, content, and more. Recommender systems
    involve two primary entities: **users** and **items**. Users are individuals for
    whom recommendations are generated, and items are the products, content, or services
    to be recommended. These items can include movies, books, products, news articles,
    and more.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐系统**是一种旨在根据用户的偏好、历史行为或其他相关因素向用户建议物品或内容的信息过滤系统。这些系统在各种在线平台上被广泛使用，以帮助用户发现产品、服务、内容等。推荐系统涉及两个主要实体：**用户**和**物品**。用户是生成推荐的个体，而物品是要推荐的产物、内容或服务。这些物品可以包括电影、书籍、产品、新闻文章等。'
- en: Recommender systems rely on data that captures the interaction between users
    and items. This interaction data can include user ratings, purchase history, clicks,
    views, likes, and any other form of user engagement with items.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统依赖于捕捉用户和物品之间交互的数据。这种交互数据可以包括用户评分、购买历史、点击、查看、点赞以及任何其他形式的用户与物品的互动。
- en: 'There are different types of recommender systems:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的推荐系统：
- en: '**Collaborative filtering** (**CF**): CF methods make recommendations based
    on the preferences and behavior of other users.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同过滤**（**CF**）：CF方法基于其他用户的偏好和行为进行推荐。'
- en: '**Content-based filtering**: This approach recommends items to users based
    on the attributes of the items and the user’s historical preferences. It focuses
    on the content and descriptions of items.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**：这种方法根据物品的属性和用户的历 史偏好向用户推荐物品。它侧重于物品的内容和描述。'
- en: '**Hybrid recommender systems**: These systems integrate various recommendation
    techniques to furnish recommendations that are both more accurate and diverse.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合推荐系统**：这些系统整合了各种推荐技术，以提供更准确和多样化的推荐。'
- en: Understanding CF
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 CF
- en: CF is a popular technique that’s used in recommender systems to make personalized
    recommendations to users based on their interactions and behaviors, as well as
    the behaviors of similar users. CF assumes that users who have interacted with
    items in a similar way in the past will have similar preferences in the future.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CF 是一种流行的技术，在推荐系统中使用，根据用户的交互和行为以及类似用户的行 为，为用户做出个性化推荐。CF 假设过去以相似方式与物品交互的用户在未来将会有相似
    的偏好。
- en: 'There are also two main types of CF:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，CF 主要有两种类型：
- en: '**User-based**: This type of CF recommends items to a user based on the preferences
    and behaviors of users who are like them. Compute a similarity score between the
    target user and all other users in the system. Common similarity metrics include
    cosine similarity or Pearson correlation. Identify a set of neighbor users who
    are most like the target user. Recommend items that the target user’s neighbors
    have interacted with, but the target user has not.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于用户的**：这种类型的 CF 根据与目标用户相似的用户偏好和行为向用户推荐物品。计算目标用户与系统中所有其他用户之间的相似度得分。常见的相似度指标包括余弦相似度或皮尔逊相关系数。识别出一组与目标用户最相似的邻居用户。推荐目标用户的邻居已经交互过但目标用户尚未交互过的物品。'
- en: '**Item-based**: This type of CF recommends items to a user based on the similarity
    of items they have interacted with in the past. It calculates the similarity between
    all pairs of items in the system based on user interactions. Common similarity
    metrics include cosine similarity and the Jaccard index. For a target user, it
    can identify the items they have interacted with. It can recommend items that
    are like the items the user has interacted with.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于物品的**：这种类型的 CF 根据用户过去交互过的物品的相似性向用户推荐物品。它根据用户交互计算系统中所有物品对之间的相似度。常见的相似度指标包括余弦相似度和
    Jaccard 指数。对于目标用户，它可以识别出他们已经交互过的物品。它可以推荐与用户交互过的物品相似的物品。'
- en: CF matrices are often sparse because users interact with only a small fraction
    of available items. Techniques such as matrix factorization can help address this
    issue by finding latent factors in the data. As the number of users and items
    grows, the computation of user-user or item-item similarity becomes more computationally
    expensive. Optimizations are required for scalability. CF can struggle to make
    recommendations for new users or items with little to no interaction history.
    Techniques such as content-based recommendations or hybrid models are often used
    to address this problem.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CF 矩阵通常很稀疏，因为用户只与可用物品的一小部分进行交互。通过在数据中找到潜在因素，如矩阵分解等技术可以帮助解决这一问题。随着用户和物品数量的增加，用户-用户或物品-物品相似度的计算变得更加昂贵。为了可扩展性，需要进行优化。CF
    在为新用户或几乎没有交互历史的物品做出推荐时可能会遇到困难。通常使用基于内容的推荐或混合模型等技术来解决这个问题。
- en: CF often relies on user behavior data, which raises privacy concerns. Privacy-preserving
    methods such as differential privacy may be employed to protect user information.
    Various metrics, including **mean absolute error** (**MAE**), **root mean squared
    error** (**RMSE**), and ranking-based metrics such as precision and recall, are
    used to evaluate the performance of CF algorithms.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: CF 通常依赖于用户行为数据，这引发了隐私问题。可以使用差分隐私等隐私保护方法来保护用户信息。使用各种指标来评估 CF 算法的性能，包括 **平均绝对误差**（**MAE**）、**均方根误差**（**RMSE**）以及基于排名的指标，如精确率和召回率。
- en: CF has been widely used in recommendation systems in various domains, including
    e-commerce, movie and music recommendations, social networks, and more. While
    it is effective at capturing user preferences, it does have limitations, such
    as the cold start problem and the need for a sufficient volume of user interactions.
    Hybrid approaches that combine CF with other recommendation techniques can overcome
    some of these limitations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: CF 已被广泛应用于各种领域的推荐系统，包括电子商务、电影和音乐推荐、社交网络等。虽然它能够有效地捕捉用户偏好，但它确实存在一些局限性，例如冷启动问题和需要足够的用户交互量。将
    CF 与其他推荐技术相结合的混合方法可以克服一些这些局限性。
- en: Content-based filtering explained
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于内容的过滤解释
- en: '**Content-based filtering** is a recommendation technique that’s used in recommender
    systems to provide personalized recommendations to users based on the characteristics
    and features of the items and the user’s preferences. Unlike CF, which relies
    on user-item interactions, content-based filtering focuses on the content of items
    and attempts to match them with user profiles.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**是一种推荐技术，在推荐系统中用于根据物品的特征和用户偏好为用户提供个性化推荐。与依赖于用户-物品交互的协同过滤（CF）不同，基于内容的过滤专注于物品的内容，并试图将其与用户档案相匹配。'
- en: Each item in the system is described by a set of features or attributes. These
    features can vary widely based on the domain but may include things such as genres,
    keywords, actors, directors (for movies), authors (for books), and more. For text-based
    content, natural language processing techniques may be used to extract keywords
    or topics. The system maintains a user profile or preference vector for each user,
    which reflects their preferences for different features or attributes. This user
    profile is built based on the items the user has interacted with or explicitly
    rated.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 系统中的每个物品都由一组特征或属性描述。这些特征可以根据领域广泛变化，可能包括如流派、关键词、演员、导演（对于电影）、作者（对于书籍）等。对于基于文本的内容，可以使用自然语言处理技术提取关键词或主题。系统为每个用户维护一个用户档案或偏好向量，它反映了他们对不同特征或属性的偏好。这个用户档案是基于用户互动过的物品或明确评分构建的。
- en: To generate recommendations for a user, the system calculates a similarity score
    between the user’s profile and the features of items. The similarity score is
    often computed using techniques such as cosine similarity, **Term Frequency-Inverse
    Document Frequency** (**TF-IDF**), or other distance metrics. Items with the highest
    similarity scores are recommended to the user. These are the items that are most
    in line with the user’s historical preferences and interests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为用户生成推荐，系统计算用户档案与物品特征之间的相似度得分。相似度得分通常使用余弦相似度、**词频-逆文档频率**（**TF-IDF**）或其他距离度量技术来计算。具有最高相似度得分的物品被推荐给用户。这些是符合用户历史偏好和兴趣的物品。
- en: Content-based filtering is effective at providing personalized recommendations
    because it considers the individual user’s preferences based on item features.
    It doesn’t rely on user-to-user or item-to-item comparisons, making it suitable
    for new or less active users who might not have much interaction history. The
    quality of recommendations heavily depends on the accuracy and richness of item
    descriptions and features. Note that ensuring high-quality metadata is crucial.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的过滤在提供个性化推荐方面非常有效，因为它根据物品特征考虑了个人用户的偏好。它不依赖于用户间或物品间的比较，因此适合新用户或互动较少的用户。推荐的质量很大程度上取决于物品描述和特征的准确性和丰富性。请注意，确保高质量的元数据至关重要。
- en: While content-based filtering is good at recommending items such as those a
    user has interacted with before, it may not introduce as much serendipity or novelty
    in recommendations compared to CF. It can also help address the cold start problem
    for new items if there is sufficient information available about their features.
    Many recommender systems combine content-based filtering with CF or other recommendation
    techniques to improve recommendation quality and address the limitations of each
    approach.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于内容的过滤擅长推荐用户之前互动过的物品，但与CF相比，它可能不会在推荐中引入太多的偶然性或新颖性。如果关于其特征有足够的信息，它还可以帮助解决新物品的冷启动问题。许多推荐系统将基于内容的过滤与CF或其他推荐技术相结合，以提高推荐质量并解决每种方法的局限性。
- en: Content-based filtering is commonly used in various domains such as news recommendation,
    music recommendation, and e-commerce for suggesting products. When implemented
    correctly, it can offer valuable recommendations tailored to individual user preferences
    and needs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的过滤在新闻推荐、音乐推荐和电子商务等各个领域被广泛使用，用于建议产品。当正确实施时，它可以根据个人用户的偏好和需求提供有价值的推荐。
- en: Hybrid recommender systems
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合推荐系统
- en: Hybrid recommender systems are recommendation systems that combine multiple
    recommendation techniques to provide more accurate and diverse recommendations.
    These systems aim to leverage the strengths of different recommendation approaches,
    such as CF, content-based filtering, and more, while mitigating their weaknesses.
    Hybrid recommender systems are commonly used in various applications to improve
    recommendation quality and address the limitations of individual methods.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 混合推荐系统是结合多种推荐技术以提供更准确和多样化推荐的推荐系统。这些系统旨在利用不同推荐方法的优势，如CF、基于内容的过滤等，同时减轻它们的弱点。混合推荐系统在多种应用中普遍使用，以提高推荐质量并解决个别方法的局限性。
- en: In weighted hybrid systems, different recommendation techniques are assigned
    weights that determine their influence on the final recommendations. For example,
    you might assign a higher weight to CF if historical user interactions are more
    critical, and a lower weight to content-based filtering for item features. Recommendations
    are generated by combining the scores from each technique, weighted by their importance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在加权混合系统中，不同的推荐技术被分配权重，这些权重决定了它们对最终推荐的影响。例如，如果历史用户交互更为关键，可能会给CF分配更高的权重，而对于项目特征的内容过滤则分配较低的权重。通过结合每种技术的得分并按其重要性加权，生成推荐。
- en: In switching hybrid systems, the recommendation approach is dynamically chosen
    based on certain conditions or user characteristics. For instance, if a user has
    a substantial interaction history, CF might be used, but if they are a new user
    with minimal history, content-based filtering might be employed. In this approach,
    the features or scores generated by different recommendation techniques are combined
    to create a unified feature vector for items or users. This combined feature vector
    is then used to generate recommendations using any single recommendation method.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在切换混合系统中，推荐方法根据某些条件或用户特征动态选择。例如，如果一个用户有大量的交互历史，可能会使用CF，但如果他们是一个历史记录很少的新用户，可能会采用基于内容的过滤。在此方法中，不同推荐技术生成的特征或得分被组合，以创建用于项目或用户的统一特征向量。然后，使用任何单一推荐方法利用这个组合特征向量生成推荐。
- en: Cascade hybrids use the output of one recommendation technique as input to another.
    For example, content-based filtering may be used to generate an initial set of
    recommendations. These recommendations can be further refined using CF to improve
    accuracy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 级联混合系统使用一个推荐技术的输出作为另一个推荐技术的输入。例如，基于内容的过滤可能被用来生成一组初始推荐。这些推荐可以通过CF进一步优化以提高准确性。
- en: In meta-level hybrid systems, different recommendation methods are applied independently,
    and their outputs are combined using a meta-learner or meta-classifier. The meta-learner
    takes the outputs of individual recommendation methods as inputs and provides
    the final recommendations. Machine learning algorithms such as decision trees,
    neural networks, or ensemble methods such as stacking can be used as meta-learners.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在元级混合系统中，不同的推荐方法独立应用，并且它们的输出通过元学习器或元分类器进行组合。元学习器将个别推荐方法的输出作为输入，并提供最终的推荐。可以使用决策树、神经网络或集成方法如堆叠等机器学习算法作为元学习器。
- en: In the realm of data analysis and user profiling, the process of finding similar
    users holds immense significance. Let’s delve into the techniques and methodologies
    that are employed for identifying and categorizing users with similar patterns
    and behaviors within a dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析和使用户画像的领域，寻找相似用户的过程具有重大意义。让我们深入了解用于在数据集中识别和分类具有相似模式和行为的用户的技巧和方法。
- en: Finding similar users in data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据中寻找相似用户
- en: Fraud has consistently been a pervasive issue in various forms, but the emergence
    of new technological tools, such as **virtual intelligence** (**VI**), has expanded
    the avenues for fraudulent activities. In today’s world, the use of credit and
    debit cards has become the standard for making purchases, and as a result, fraud
    associated with these payment methods is on the rise. The repercussions of such
    fraud extend beyond impacting just merchants and banks, who are often left shouldering
    the financial burden.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈一直以各种形式普遍存在，但新技术的出现，如**虚拟智能**（**VI**），扩大了欺诈活动的途径。在当今世界，使用信用卡和借记卡进行购买已成为标准，因此，与这些支付方式相关的欺诈正在增加。这种欺诈的后果不仅影响商家和银行，他们通常承担着财务负担，而且影响范围更广。
- en: When a customer falls victim to fraud, they may find themselves burdened with
    higher interest rates imposed by the bank as they could be categorized as a higher
    risk profile. Additionally, fraud incidents can tarnish a merchant’s reputation
    and image. If a customer experiences fraud during a transaction, it can erode
    their trust in the seller, potentially driving them to seek alternatives from
    competitors for future purchases.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户成为欺诈的受害者时，他们可能会发现自己被银行征收更高的利率，因为他们可能被归类为高风险客户。此外，欺诈事件可能会损害商家的声誉和形象。如果客户在交易过程中遭遇欺诈，这可能会侵蚀他们对卖家的信任，可能促使他们在未来的购买中寻求竞争对手的替代品。
- en: Given a set of credit card transaction data, fraud recognition is the process
    of identifying whether a new transaction belongs to the class of fraudulent or
    legitimate transactions. Such a system should not only detect fraudulent transactions
    but should do so in a cost-effective manner.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组信用卡交易数据，欺诈识别是识别新交易是否属于欺诈交易或合法交易的过程。这样的系统不仅应该能够检测欺诈交易，而且应该以成本效益的方式完成。
- en: 'Examining a transaction with the goal of classification can be carried out
    through distinct methods, and two specific approaches are suggested:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过不同的方法对交易进行分类分析，以下建议了两种具体的方法：
- en: User-level analysis
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户级别分析
- en: Single transaction analysis
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个交易分析
- en: These two approaches represent unique strategies, each having its own set of
    advantages and limitations. Each approach entails certain assumptions, varying
    in their degree of validity. Regardless, both approaches can yield valuable outcomes.
    There are situations where the choice between these methods is determined by the
    nature of the available data as it may not permit an alternative approach.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法代表了独特的策略，每种方法都有其自身的优势和局限性。每种方法都包含某些假设，这些假设的有效程度各不相同。无论如何，这两种方法都可以产生有价值的成果。在某些情况下，选择这些方法之间的差异取决于可用数据的性质，因为它可能不允许采用替代方法。
- en: Analyzing transactions at the individual transaction level refers to an approach
    where the classification of a transaction is determined by its relationship with
    all the transactions within the dataset. Various machine learning algorithms can
    be employed for this purpose. For instance, consider the **k-nearest neighbors**
    (**k-NN**) algorithm, which classifies a transaction based on its similarity to
    other transactions in the dataset. If a transaction closely resembles known fraudulent
    transactions, there’s a likelihood it will be categorized as fraudulent, and conversely,
    it would be deemed a legitimate transaction. This mechanism facilitates the identification
    of data patterns by leveraging similarities among objects of the same class.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个交易级别分析交易是指一种方法，其中交易的分类是由其与数据集中所有其他交易的关系决定的。可以采用各种机器学习算法来完成这项任务。例如，考虑**k-最近邻**（**k-NN**）算法，该算法根据交易与数据集中其他交易的相似性来分类交易。如果一个交易与已知的欺诈交易非常相似，那么它很可能被归类为欺诈交易，反之，则被视为合法交易。这种机制通过利用同一类对象之间的相似性来识别数据模式。
- en: In a nearest neighbors algorithm, a record is categorized by examining all the
    data in the training set and assigning it the same class as the nearest element.
    The underlying assumption is that in a multidimensional space, if two records
    are “close,” they likely belong to the same class. To gauge this proximity, it’s
    important to employ a distance metric. One example is the Euclidean distance or,
    more broadly, the Minkowski metric, as we introduced in [*Chapter 4*](B21156_04.xhtml#_idTextAnchor084),
    *Clustering Analysis and* *Dimensionality Reduction*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近邻算法中，通过检查训练集中的所有数据并将记录分配给与最近元素相同的类别来对记录进行分类。其基本假设是在多维空间中，如果两个记录“接近”，它们很可能属于同一类别。为了衡量这种接近性，重要的是要采用距离度量。一个例子是欧几里得距离，或者更广泛地说，Minkowski度量，正如我们在[*第4章*](B21156_04.xhtml#_idTextAnchor084)中介绍的，*聚类分析和*
    *降维*。
- en: 'The nearest neighbor rule results in a space division known as **Voronoi tessellation**.
    Each element in the training set delineates a region in which patterns will be
    classified into the same class. To enhance the robustness of this mechanism, one
    approach is to classify a record by considering the k closest records. The record
    can then be assigned to the class that has the largest representation among the
    selected examples. To reduce sensitivity to the choice of k, each record can contribute
    to the classification based on a weighted scheme determined by its distance from
    the element to be classified. For this process to work effectively, the attributes
    must possess consistent value scales, which typically necessitates prior normalization
    during the data preprocessing phase. Let’s learn how to build a credit card fraud
    detection system:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻规则导致了一种称为**Voronoi划分**的空间划分。训练集中的每个元素都划定了这样一个区域，其中模式将被分类到相同的类别。为了增强这种机制的鲁棒性，一种方法是通过考虑k个最近的记录来分类一个记录。然后，该记录可以被分配到在所选示例中具有最大代表性的类别。为了减少对k的选择的敏感性，每个记录可以根据其与要分类的元素的距离，通过一个加权方案对分类做出贡献。为了使此过程有效，属性必须具有一致的价值尺度，这通常需要在数据预处理阶段进行先前的归一化。让我们学习如何构建信用卡欺诈检测系统：
- en: 'As usual, we will start by importing the data into the MATLAB workspace. For
    this, we will utilize the credit card fraud detection dataset, which comprises
    anonymized credit card transactions classified as fraudulent or legitimate:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同往常，我们将首先将数据导入MATLAB工作空间。为此，我们将使用信用卡欺诈检测数据集，该数据集包含匿名信用卡交易，被分类为欺诈或合法：
- en: '[PRE0]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The dataset exclusively consists of numerical input variables, derived from
    a PCA transformation. Among the features, `V1` to `V28` represent the principal
    components obtained through PCA. The `Class` feature serves as the response variable
    and holds a value of `1` in cases of fraud and `0` otherwise. To understand how
    the data is distributed, we can count the occurrences in the `class` column:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集仅由数值输入变量组成，这些变量来自PCA转换。在特征中，`V1`到`V28`代表通过PCA获得的主成分。`Class`特征作为响应变量，在欺诈情况下值为`1`，否则为`0`。为了了解数据的分布情况，我们可以计算`class`列中的出现次数：
- en: '[PRE1]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `groupcounts()` function provides the distinct combinations of grouping
    variables for the table or timetable denoted as `T`. It also offers the count
    of members within each group and the corresponding data percentage, ranging from
    `0` to `100`. Groups are established based on rows in the variables contained
    within `groupvars` that share identical unique value combinations. Each entry
    in the result table corresponds to an individual group.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`groupcounts()`函数提供了表示为`T`的表或时间表的分组变量的独特组合。它还提供了每个组内的成员数和相应的数据百分比，范围从`0`到`100`。组是根据包含在`groupvars`中的变量的行建立的，这些行具有相同的唯一值组合。结果表中的每个条目都对应于一个单独的组。'
- en: The dataset is unbalanced on one of the binary classes, we should take this
    into account when evaluating the results. Classifying imbalanced data is a common
    challenge in machine learning when one class significantly outnumbers the other(s).
    The primary class (majority class) often dominates, making it challenging for
    the model to correctly predict the minority class.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集在其中一个二进制类别上是不平衡的，我们在评估结果时应考虑这一点。在机器学习中，当一个类别显著多于其他类别时，对不平衡数据进行分类是一个常见的挑战。主要类别（多数类别）通常占主导地位，这使得模型难以正确预测少数类别。
- en: 'To check how the data is distributed, we can draw a boxplot of the features:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了检查数据的分布情况，我们可以绘制特征的箱线图：
- en: '[PRE2]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following graph will be output (*Figure 10**.1*):'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图形将被输出（*图10**.1*）：
- en: '![Figure 10.1 – Boxplot of the features](img/B21156_10_01.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 特征的箱线图](img/B21156_10_01.jpg)'
- en: Figure 10.1 – Boxplot of the features
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 特征的箱线图
- en: From the analysis of *Figure 10**.1*, we can see that the variables are skewed.
    We can also see that some of them present potential outliers. It is recommended
    to conduct data scaling. Keep in mind that it’s a best practice to standardize
    or normalize the data before training a machine learning model. Through scaling,
    the data’s units are standardized, making it simpler to compare data from various
    sources or locations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图10**.1*的分析中，我们可以看到变量是偏斜的。我们还可以看到其中一些变量存在潜在的异常值。建议进行数据缩放。请记住，在训练机器学习模型之前对数据进行标准化或归一化是一种最佳实践。通过缩放，数据的单位被标准化，这使得比较来自不同来源或位置的数据变得更容易。
- en: Data scaling, also known as data normalization or standardization, is a preprocessing
    technique in machine learning and data analysis that involves transforming the
    data into a standardized range or distribution. The primary purpose of data scaling
    is to make different features or variables in your dataset comparable and to help
    machine learning algorithms perform better.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据缩放，也称为数据归一化或标准化，是机器学习和数据分析中的预处理技术，涉及将数据转换到标准化的范围或分布。数据缩放的主要目的是使你的数据集中的不同特征或变量可比较，并帮助机器学习算法表现更好。
- en: The choice between scaling and standardization depends on the specific requirements
    of your dataset and the machine learning algorithm you plan to use. In general,
    it is advisable to apply data scaling to your features to prevent certain variables
    from dominating the learning process, especially in algorithms that are sensitive
    to feature scales, such as kNN or support vector machines.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在缩放和标准化之间进行选择取决于你的数据集的具体要求和计划使用的机器学习算法。一般来说，建议对特征应用数据缩放，以防止某些变量主导学习过程，尤其是在对特征尺度敏感的算法中，如kNN或支持向量机。
- en: Data scaling helps in improving the convergence of optimization algorithms,
    makes features more interpretable, and can also enhance the performance of some
    machine learning models. However, it’s important to note that not all algorithms
    require data scaling, and there are cases where the natural scale of the data
    is meaningful and should not be altered. The decision to scale the data should
    be made with careful consideration of your specific problem and the characteristics
    of your dataset.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据缩放有助于提高优化算法的收敛性，使特征更易于解释，并且还可以提高某些机器学习模型的性能。然而，需要注意的是，并非所有算法都需要数据缩放，有些情况下数据的自然尺度是有意义的，不应被改变。是否缩放数据应谨慎考虑你的具体问题和数据集的特征。
- en: 'We will perform a standardization with a range of `-1` to `1`:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将执行范围在`-1`到`1`之间的标准化：
- en: '[PRE3]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Standardization with a range of `-1` to `1`, also known as min-max scaling with
    a specific range, is a method of data scaling that transforms your data to fit
    within the range of `-1` to `1`. This approach is useful when you want to normalize
    your data while maintaining the possibility of negative values.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 范围在`-1`到`1`之间的标准化，也称为具有特定范围的min-max缩放，是一种数据缩放方法，将你的数据转换到`-1`到`1`的范围内。当你想要标准化数据同时保持负值可能性时，这种方法很有用。
- en: 'To check how the data is distributed after we performed data scaling, we can
    draw a boxplot of the features:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了检查我们执行数据缩放后数据的分布情况，我们可以绘制特征的箱线图：
- en: '[PRE4]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following graph is shown (*Figure 10**.2*):'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图表显示的是（*图10*.*2*）：
- en: '![Figure 10.2 – Boxplot of the scaled data](img/B21156_10_02.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2 – 缩放数据的箱线图](img/B21156_10_02.jpg)'
- en: Figure 10.2 – Boxplot of the scaled data
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 缩放数据的箱线图
- en: Now, it is clear that the data has been scaled so that we have the same existence
    intervals.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，很明显数据已经被缩放，以便我们拥有相同的存在区间。
- en: 'Before training the model based on machine learning, it is necessary to carry
    out data splitting. Data splitting refers to the process of dividing a dataset
    into separate subsets for training, testing, and validation purposes. We will
    perform train-test splitting, which involves dividing the dataset into two parts,
    typically with a 70-30 or 80-20 split. The larger portion is used for training
    the model, while the smaller portion is used for testing its performance:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在基于机器学习的模型训练之前，进行数据拆分是必要的。数据拆分是指将数据集划分为用于训练、测试和验证的单独子集的过程。我们将执行训练-测试拆分，这涉及将数据集分为两部分，通常为70-30或80-20的拆分。较大的部分用于训练模型，而较小的一部分用于测试其性能：
- en: '[PRE5]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We initiated the process by obtaining the number of observations within our
    dataset using the `length()` function. This function returns the size of the largest
    dimension in the array, `X`. In the context of vectors, this size corresponds
    to the total number of elements. Subsequently, we employed the `cvpartition()`
    function to create a random partition for the dataset. This partition serves as
    the foundation for constructing essential training and test subsets, which are
    instrumental in evaluating a statistical model. To extract the training data index
    and the test data index from the original dataset, we utilized the `training`
    and `test` object functions. These indices were then applied to extract the corresponding
    data subsets.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过使用`length()`函数获取数据集中观察值的数量来启动这个过程。此函数返回数组`X`中最大维度的尺寸，在向量的上下文中，这个尺寸对应于元素的总数。随后，我们使用了`cvpartition()`函数来创建数据集的随机分区。这个分区是构建基本训练集和测试集的基础，这些集对于评估统计模型至关重要。为了从原始数据集中提取训练数据索引和测试数据索引，我们使用了`training`和`test`对象函数。然后，将这些索引应用于提取相应的数据子集。
- en: 'k-NN is a versatile algorithm that’s used not only for classification and regression
    tasks but also in recommender systems. It can be adapted for building CF-based
    recommender systems. We will use the `fitcknn()` function, as follows:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: k-NN是一种多用途算法，不仅用于分类和回归任务，还用于推荐系统。它可以适应构建基于CF的推荐系统。我们将使用`fitcknn()`函数，如下所示：
- en: '[PRE6]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following arguments were passed:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下参数被传递：
- en: '`TrainData(:,1:28)`'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainData(:,1:28)`'
- en: '`TrainData(:,29)`'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainData(:,29)`'
- en: '`cosine` (the expression represents the complement of the cosine of the angle
    included between observations, treating them as vectors):'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`余弦`（该表达式表示观察值之间夹角的余弦的补数，将它们视为向量）：'
- en: Minkowski distance exponent
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minkowski距离指数
- en: 'Number of nearest neighbors to find: `10`'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要找到的最近邻数量：`10`
- en: 'Distance weighting function: `SquaredInverse` (`Weight` is 1/distance)'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 距离加权函数：`SquaredInverse`（`Weight`是距离的倒数）
- en: We applied weighted k-NN, a variation of the k-NN algorithm that assigns different
    weights to the neighbors when making predictions or classifications. In traditional
    k-NN, each neighbor has an equal influence on the final decision, but in weighted
    k-NN, the influence of each neighbor is adjusted based on certain factors, typically
    the proximity or similarity between the neighbors and the query point. This allows
    for more accurate and context-aware predictions.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们应用了加权k-NN算法，这是k-NN算法的一种变体，在预测或分类时为邻居分配不同的权重。在传统的k-NN中，每个邻居对最终决策的影响是相等的，但在加权k-NN中，每个邻居的影响会根据某些因素进行调整，通常是邻居与查询点之间的接近度或相似度。这允许进行更准确和上下文感知的预测。
- en: We start by choosing a distance metric to measure the similarity or dissimilarity
    between data points. We used the `cosine` metric, also known as cosine similarity,
    which is a similarity measure that’s used to determine the similarity between
    two non-zero vectors in a high-dimensional space. It is widely used in various
    fields, including information retrieval, natural language processing, and recommendation
    systems. The `cosine` metric measures the cosine of the angle between two vectors,
    and it provides a value between -1 and 1, where 1 indicates that the vectors are
    identical, 0 means that they are orthogonal (completely dissimilar), and -1 implies
    they are opposed.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先选择一个距离度量来衡量数据点之间的相似度或差异度。我们使用了`cosine`度量，也称为余弦相似度，这是一种用于确定高维空间中两个非零向量之间相似度的相似度度量。它在各个领域都得到广泛应用，包括信息检索、自然语言处理和推荐系统。`cosine`度量衡量两个向量之间的夹角的余弦值，它提供一个介于-1和1之间的值，其中1表示向量是相同的，0表示它们是正交的（完全不同），-1表示它们是相反的。
- en: The algorithm then determines the value of *k*, which represents the number
    of nearest neighbors to consider when making a prediction. The choice of k depends
    on your dataset and the specific problem you’re trying to solve. You must compute
    the distances between the query point (the point you want to classify or predict)
    and all other data points in your dataset, then calculate weights for each neighbor
    based on their proximity or similarity to the query point. Common methods for
    assigning weights include inverse distance, where closer neighbors have higher
    weights, or similarity-based weighting, where more similar neighbors are given
    higher weights. You can also choose the k neighbors with the highest weights.
    These neighbors will have a more significant impact on the final prediction. For
    classification tasks, assign class labels to the query point based on the majority
    class among the selected neighbors, with the weights influencing the voting process.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here are the advantages of using weighted k-NN:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Weighted k-NN can provide more accurate predictions because it considers the
    influence of each neighbor on the final decision
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It allows for better handling of imbalanced datasets, where some neighbors may
    be more informative than others
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted k-NN is particularly useful when the neighbors are not equally informative
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted k-NN is a flexible and widely used machine learning technique that
    can be applied to a variety of problems, including classification, regression,
    and recommendation systems. It allows you to adapt the algorithm to the specific
    characteristics of your data and the problem you are trying to solve.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After training the model, we must evaluate its performance. We will start by
    using the trained model to predict data labels:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we employed the `predict()` function, which furnishes the anticipated
    response values produced by the generalized linear regression model.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can assess the model’s accuracy, which gauges the extent to which a
    predictive model’s forecasts match the real or observed values. It serves as an
    indicator of the model’s performance in accurately predicting outcomes:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result is excellent, confirming that the choice of the algorithm and training
    parameters were correct.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the ever-evolving landscape of cybersecurity, the development of effective
    tools for network intrusion detection is paramount. The next section will explore
    how to utilize MATLAB to create advanced recommender systems tailored for enhancing
    network intrusion detection capabilities.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Creating recommender systems for network intrusion detection using MATLAB
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A NIDS serves as a security mechanism that’s employed to identify and prevent
    unauthorized access, malicious activities, and potential threats within a computer
    network. It involves monitoring network traffic and analyzing it to identify any
    suspicious or abnormal behaviors. The main objective of network intrusion detection
    is to protect the network from various types of attacks, such as **denial-of-service**
    (**DoS**) attacks, malware infections, data leakage, unauthorized access, and
    other cyber threats.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two primary methods of network intrusion detection:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '**Signature-based detection**: This method involves comparing network traffic
    patterns with a database of known signatures or patterns of known attacks. If
    a match is found, an alert is generated to notify the network administrator.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly-based detection**: This method focuses on identifying abnormal or
    suspicious network behavior that deviates from the normal patterns. It uses machine
    learning algorithms to analyze network traffic and detect any anomalies that could
    potentially indicate an ongoing or imminent attack.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A NIDS can be implemented at different levels within a network architecture,
    such as at the perimeter, on individual hosts, or within specific network segments.
    They collect and analyze network packets, logs, and other network data to identify
    and alert the system administrators about potential intrusions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some common techniques that are used in network intrusion
    detection:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '**Packet analysis**: For examining individual network packets to identify specific
    attack signatures or anomalies'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protocol analysis**: For analyzing network protocols to detect any abnormal
    or unauthorized activities'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic analysis**: For monitoring network traffic patterns to identify any
    sudden spikes or unusual patterns'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Behavior analysis**: For analyzing user or host behavior to detect any unusual
    or malicious activities'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NIDS play a crucial role in safeguarding computer networks against unauthorized
    access and potential threats. They help identify and respond to security incidents
    promptly, minimizing any potential damage or data breaches.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Recommender system for NIDS
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will adopt a new approach to identifying and preventing
    network attacks: network intrusion detection using a recommender system. Traditional
    NIDS rely on fixed rules and signatures to detect known attack patterns. However,
    attackers are continually evolving their techniques, making it challenging for
    these systems to keep up. By incorporating a recommender system into the network
    intrusion detection process, it becomes possible to leverage machine learning
    and data mining techniques to enhance detection capabilities. The primary objective
    is to utilize historical network traffic data to build a model that can predict
    whether a particular network event is normal or malicious.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an overview of how network intrusion detection using a recommender
    system works:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '**Data collection**: Network traffic data is collected and stored for analysis.
    This data consists of various network parameters, such as IP addresses, port numbers,
    protocols, packet sizes, and more.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature extraction**: Relevant features are extracted from the collected
    data. These features can include traffic volume, connection duration, packet headers,
    and other characteristics that provide insights into network behavior.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data preprocessing**: The gathered data undergoes preprocessing to eliminate
    noise, address missing values, and normalize the features. This step ensures that
    the data is in a suitable format for analysis.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training the recommender system**: The preprocessed data is used to train
    a recommender system algorithm, such as CF, matrix factorization, or association
    rule mining. This algorithm learns the patterns and relationships within the data.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Building a recommendation model**: The trained algorithm generates a recommendation
    model based on the network traffic data. This model can identify the normal network
    behavior and detect any deviations from it.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Real-time monitoring**: The recommendation model is then used to monitor
    incoming network traffic in real time. It analyzes the network events and predicts
    whether they are normal or potentially malicious.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert generation**: When the recommendation model detects a potentially malicious
    network event, it triggers an alert to notify network administrators. The alert
    can include information about the detected attack type and recommended countermeasures.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuous learning**: The recommendation model can continuously update itself
    over time by incorporating new data and adjusting its detection capabilities.
    This ensures that the system remains effective against emerging threats.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, network intrusion detection using a recommender system offers a more
    dynamic and adaptive approach to identifying network attacks. It leverages machine
    learning techniques to learn from historical data and make intelligent predictions
    about the network’s security status. This can enhance the accuracy and efficiency
    of network security operations by reducing false positives and detecting emerging
    attack patterns.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: NIDS using a recommender system in MATLAB
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this practical example, we will build a NIDS-adopting recommender system
    using **ensemble methods**. Ensemble methods are techniques that combine multiple
    individual models to form a more powerful and accurate predictor. These individual
    models, also known as base models or weak models, can be of any type, such as
    decision trees, support vector machines, or neural networks. By combining the
    predictions of these base models, ensemble methods aim to improve the overall
    performance and generalization ability of the model. There are several popular
    ensemble methods, including the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '**Bagging**: Bagging, short for **bootstrap aggregating**, involves training
    multiple base models on different subsets of the training data, with replacement.
    The final prediction is made by averaging or voting the predictions of the individual
    models.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boosting**: Boosting algorithms train base models sequentially, with each
    subsequent model focusing more on the samples that were previously misclassified.
    The predictions of multiple models are combined using weighted voting or averaging
    to make the final prediction.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random forest**: Random forest is an ensemble method that amalgamates bagging
    and decision trees. Numerous decision trees, each trained on a random subset of
    the features, are integrated through majority voting to formulate the final prediction.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive boosting** (**AdaBoost**): AdaBoost is a boosting algorithm that
    assigns weights to the training samples based on their classification errors.
    Weak models are trained iteratively, with each subsequent model focusing more
    on the misclassified samples. The final prediction is made by combining the predictions
    of multiple models using weighted voting.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gradient boosting**: Gradient boosting is another boosting algorithm that
    sequentially trains weak models, with each subsequent model minimizing the loss
    function using gradient descent. The predictions of multiple models are combined
    using weighted averaging to make the final prediction.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensemble methods have proven to be effective in improving the performance and
    robustness of predictive models in various domains, including classification,
    regression, and anomaly detection. They are widely used in machine learning and
    data mining applications.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, we start by importing the dataset into the MATLAB environment. We
    will use the Network Intrusion Detection dataset, which is available in the Kaggle
    dataset repository ([https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection](https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection)).
    The dataset contains a diverse range of simulated intrusions in a military network
    setting. The objective was to create a realistic environment resembling a US Air
    Force LAN, which was then exposed to multiple attacks. Each connection in this
    environment represents a sequence of TCP packets, with data flowing between a
    source IP address and a target IP address under a predefined protocol. Every connection
    is classified as either normal or as an attack, with a specific attack type assigned
    to it. A connection record contains approximately 100 bytes of data. For each
    TCP/IP connection, a total of 41 features, both quantitative and qualitative,
    are collected from both normal and attack data. These features include three qualitative
    features and 38 quantitative features. The class variable in the dataset has two
    categories – normal and anomalous:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by importing the dataset into the MATLAB environment:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This function prints a summary of the table, displaying the properties description
    of the variables and some statistics such as min, median, and max for numeric
    features.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As we did in the *Finding similar users in data* section, we have to split
    the data into two subsets: train and test. We will use the `cvpartition()` function
    for this, as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We began by using the `length()` function to determine the number of observations
    in our dataset. This function gives us the size of the largest dimension in the
    array, `X`, which in the case of vectors represents the total number of elements.
    Next, we utilized the `cvpartition()` function to randomly split the dataset into
    training and test subsets. This partition forms the basis for evaluating a statistical
    model. We extracted the indices for the training and test data using the training
    and test object functions and then used these indices to obtain the respective
    data subsets.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, it’s time to train the algorithm for NDIS. To do this, we will use an
    algorithm based on ensemble methods:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We started by setting the data used for the training and divided the subset
    into predictors and response variables. These terms are used in statistical analysis
    to describe the relationship between independent variables (predictors) and dependent
    variables (response). Predictors are variables that are used to predict, explain,
    or account for the variation in the response variable. They can be continuous
    or categorical and may have various levels or values. The response variable, on
    the other hand, is the outcome or variable that is being predicted or explained
    by the predictors. It is also known as the dependent variable. In our case, it
    is the label of the network intrusion detection classification (anomaly, normal).
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can train the model:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As a classification method, we used `AdaBoostM1`. `AdaBoostM1`, also known as
    adaptive boosting, is a machine learning algorithm that can be used for both classification
    and regression problems. It is particularly effective in handling complex datasets
    and improving weak learning algorithms. The fundamental concept behind `AdaBoostM1`
    is to amalgamate multiple weak classifiers to form a robust classifier. A weak
    classifier is a basic model that performs marginally better than random guessing.
    `AdaBoostM1` accomplishes this by iteratively training weak classifiers on varied
    weighted versions of the dataset. The main idea behind `AdaBoostM1` is to combine
    multiple weak classifiers to create a strong classifier. A weak classifier is
    a simple model that performs slightly better than random guessing. `AdaBoostM1`
    achieves this by iteratively training weak classifiers on different weighted versions
    of the dataset.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In each iteration, the algorithm assigns increased weights to instances misclassified
    in the previous iteration. This compels the weak classifiers to prioritize the
    most challenging instances, enhancing their focus on difficult cases. These weighted
    weak classifiers are then combined using a weighted majority voting scheme to
    make final predictions. In classification tasks, the final prediction is obtained
    by assigning a class label based on the weighted majority vote of the weak classifiers.
    In regression tasks, the final prediction is obtained by averaging the weighted
    predictions of the weak classifiers.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`AdaBoostM1` has several advantages. It is robust to overfitting and can handle
    datasets with many features. It can also handle imbalanced datasets by adjusting
    the weights of the instances. Additionally, `AdaBoostM1` can be easily parallelized,
    making it suitable for distributed computing environments. However, `AdaBoostM1`
    may be sensitive to noisy data and outliers, as it assigns higher weights to misclassified
    instances. It also requires careful selection of weak classifiers, as too complex
    or too weak classifiers may not yield good results. Overall, `AdaBoostM1` is a
    powerful algorithm that has been widely used in many applications, including face
    detection, object recognition, and financial forecasting.'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s take a look at the model that was trained:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Some information about the model is shown in the preceding code.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After training the algorithm, it is time to evaluate its performance:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `predict()` function was utilized to obtain the expected response values
    generated by the generalized linear regression model. By evaluating the accuracy
    of the model, we can measure how well the predictive model’s predictions align
    with the actual observed values. This assessment serves as a performance indicator
    in accurately forecasting outcomes:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These are amazing results that demonstrate that ensemble methods are very effective
    in classifying network intrusion.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Embarking on the final frontier of the data science journey, the deployment
    of machine learning models marks the critical phase where theoretical prowess
    transforms into real-world impact. The next section delves into the intricacies
    and best practices of deploying machine learning models, ensuring their seamless
    integration into operational environments.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Deploying machine learning models
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying machine learning models refers to the process of making a trained
    model available for making predictions on new, unseen data. It involves taking
    the trained model and integrating it into a production environment where it can
    receive input data, perform predictions, and return the results. The trained model
    needs to be organized and packaged into a format suitable for deployment. This
    may involve exporting the model into a file format that can be easily loaded and
    used by other systems. An **application programming interface** (**API**) is typically
    created to expose the machine learning model’s functionality. The API acts as
    the interface that other systems or applications can use to send data and receive
    predictions from the model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: If the model is expected to handle many concurrent requests, the deployment
    environment may need to be scaled to accommodate the increased load. This may
    involve setting up clusters of servers or using cloud-based infrastructure. Once
    the model has been deployed, it is important to monitor its performance and behavior
    to ensure it continues to provide accurate predictions. Monitoring can involve
    tracking metrics such as response time, throughput, or error rates to identify
    any issues or performance degradation. Machine learning models often need updates
    or retraining as new data becomes available. Therefore, it is important to have
    processes in place for continuous integration and delivery to easily deploy new
    versions of the model and ensure it stays up to date.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Understanding model compression
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model compression refers to the process of diminishing the size of a machine
    learning model without significantly compromising its performance. The need for
    model compression arises in scenarios where the size or computational requirements
    of a model become critical, such as when deploying models on resource-constrained
    devices such as smartphones or edge devices.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several techniques for model compression:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '**Pruning**: Pruning involves removing unnecessary connections or parameters
    from the model. Typically, connections with small weights are pruned based on
    a certain threshold, resulting in a sparser model with fewer parameters.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantization**: Quantization is the process of reducing the precision of
    the weights and activations in a model. For example, instead of using 32-bit floating-point
    values, weights can be represented using 8-bit integers. This reduces memory requirements
    and improves computational efficiency.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Knowledge distillation**: Knowledge distillation involves training a smaller,
    “student” model to mimic the predictions of a larger, “teacher” model. The teacher
    model’s knowledge is transferred to the student model, allowing for a compact
    representation of the original model while maintaining performance.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low-rank approximation**: Low-rank approximation techniques aim to approximate
    the weights of a model using low-rank matrices or tensors. This reduces the number
    of parameters required to represent the model, leading to a smaller memory footprint
    and faster computations.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compact architectures**: This involves designing or using compact architectures,
    such as MobileNet or SqueezeNet, that are specifically built to be lightweight
    and efficient.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These compression techniques enable models to be deployed on devices with limited
    resources or used in scenarios with strict latency or memory constraints. However,
    it is important to consider trade-offs as model compression may lead to slight
    performance degradation in terms of accuracy or inference speed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Discovering model pruning techniques
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model pruning is a machine learning technique that aims to decrease the size
    and complexity of a trained model by eliminating unnecessary or redundant parameters,
    connections, or nodes. The objective of model pruning is to enhance the efficiency
    and computational performance of the model without significantly compromising
    accuracy.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several methods of model pruning, including the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '**Weight pruning**: In weight pruning, individual weights in the model are
    set to zero or removed entirely based on their magnitude. This reduces the number
    of parameters and can result in a sparser model.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neuron pruning**: Neuron pruning entails the removal of entire neurons from
    the model, guided by their contribution to the overall performance. Neurons with
    low activation or minimal impact on the output are pruned.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filter pruning**: This technique is commonly used in **convolutional neural
    networks** (**CNNs**). Filters are groups of feature detectors that are applied
    across an image during the convolution operation. Filter pruning involves removing
    unnecessary filters that do not contribute significantly to the model’s accuracy.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured pruning**: Structured pruning involves removing entire layers
    or blocks of the model, rather than individual weights or neurons. This method
    often results in more efficient implementations since removing entire layers reduces
    both computational complexity and memory requirements.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model pruning can be performed during training or as a post-training optimization
    step. It is often combined with other techniques such as regularization methods
    or quantization to further improve the efficiency of the pruned model. Pruning
    can provide significant benefits in terms of model size, speed, and memory usage,
    making it a useful technique for deploying models on resource-constrained devices
    or in real-time applications.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'In MATLAB, you can perform model pruning using various techniques and tools
    such as Neural Network Toolbox. The following steps outline a general approach
    to model pruning in MATLAB:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Load or create your initial neural network model using Neural Network Toolbox
    in MATLAB.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the neural network model to achieve a reasonably good performance on a
    given task or dataset.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the pruning algorithm or technique of your choice to identify and remove
    unnecessary weights, connections, or nodes from the trained model. Some commonly
    used pruning techniques include magnitude-based pruning, sensitivity-based pruning,
    and weight-decay pruning.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the pruned model’s performance by testing it on a validation or test
    dataset. Make sure that the pruning process does not significantly degrade the
    model’s performance.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fine-tune or retrain the pruned model, if necessary, to recover any performance
    degradation due to pruning. Adjust the learning rate or other training parameters
    to optimize the pruned model’s performance.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *s**teps 3* to *5* until the desired level of model compression or performance
    trade-off is achieved.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remember that model pruning is a dynamic and iterative process, and it requires
    careful consideration of the trade-off between model size, performance, and computational
    requirements.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Introducing quantization for efficient inference on edge devices
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Quantization is a technique that’s used in model compression to reduce the memory
    footprint and computational requirements of deep neural networks. It involves
    converting the weights and activations of a network from floating-point representation
    into lower precision representation, such as 8-bit or even lower.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Quantization reduces the precision of the model, which can lead to a loss in
    model accuracy. However, it has been observed that many neural networks are robust
    to quantization and can still achieve similar performance with reduced precision
    representation. This is especially true for deep neural networks with large numbers
    of parameters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different approaches to quantization in model compression:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '**Weight-only quantization**: In this approach, only the weights of the neural
    network are quantized, while the activations remain in the original precision.
    This reduces the memory requirements significantly as weights typically consume
    the majority of the memory in a neural network.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Full quantization**: In this approach, both the weights and activations are
    quantized to lower precision. This provides further reduction in memory requirements
    and computational complexity but can result in a larger loss in model accuracy
    compared to weight-only quantization.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dynamic quantization**: Dynamic quantization techniques adaptively adjust
    the precision of weights and activations during inference based on the input data.
    This allows for more flexibility in the precision used, leading to potential accuracy
    improvements compared to static quantization.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantization-aware training**: Instead of quantizing the model after training,
    quantization-aware training incorporates the quantization process during the training
    phase itself. This ensures that the model learns to be robust to quantization
    and results in better accuracy when quantized.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantization is a widely used technique in model compression and is particularly
    useful when deploying deep neural networks on resource-constrained devices such
    as edge devices or mobile phones. It allows for efficient deployment of models
    with reduced memory requirements and improved computational efficiency, without
    sacrificing significant model accuracy.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with knowledge distillation
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Knowledge distillation is a technique that’s used in model compression that
    refers to the process of reducing the size and complexity of a machine learning
    model without significant loss in performance. In knowledge distillation, a large
    “teacher” model is trained on a dataset and used as a reference to train a smaller
    “student” model. The goal is to transfer the knowledge, or the learned representations,
    from the teacher model to the student model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge transfer is achieved by training the student model to mimic the outputs
    of the teacher model. Typically, this involves using the teacher model’s soft
    targets or logits instead of the hard labels during training. Soft targets refer
    to the probabilities assigned to each class by the teacher model, which can provide
    more nuanced information compared to the one-hot encoded hard labels.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: During the training process, the student model tries to minimize the difference
    between its predictions and the soft targets provided by the teacher model. This
    enables the student model to learn from the richer information provided by the
    teacher, improving its understanding of the data and increasing its performance.
    Knowledge distillation can lead to significant model compression as the smaller
    student model can capture the knowledge of the larger teacher model, often with
    fewer parameters. Additionally, the student model can be more efficient in terms
    of inference time and resource usage, making it suitable for deployment on resource-constrained
    platforms.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: In summary, knowledge distillation is a technique that’s used in model compression
    to transfer knowledge from a larger teacher model to a smaller student model,
    thereby compressing the model size while maintaining performance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Learning low-rank approximation
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Low-rank approximation is a technique that’s used in model compression to reduce
    the size of a given model. It involves approximating a high-dimensional weight
    matrix or tensor by a lower-rank approximation, which significantly reduces the
    number of parameters needed to represent the model. In low-rank approximation,
    a factorization of the weight matrix is performed to decompose it into two or
    more smaller matrices or tensors. The rank of the approximation determines the
    number of smaller matrices or tensors used. By choosing a lower rank, the resulting
    approximation will have fewer parameters, making it more compact and efficient.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Low-rank approximation can be applied to various types of models, including
    neural networks, deep learning models, and other machine learning algorithms.
    It is especially useful for reducing the computational and memory requirements
    of large models. This enables their deployment on resource-constrained devices,
    such as mobile phones or embedded systems. One common approach for low-rank approximation
    is **singular value decomposition** (**SVD**), which decomposes a matrix into
    three matrices representing the left singular vectors, singular values, and right
    singular vectors. Selecting a subset of the singular values and their corresponding
    singular vectors allows for the creation of a low-rank approximation.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Other techniques for low-rank approximation include Tucker decomposition, which
    decomposes a tensor into smaller tensors, and tensor-train decomposition, which
    represents a tensor as a series of matrix products. These techniques can be applied
    to higher-order tensors typically found in deep learning models.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Overall, low-rank approximation is a powerful technique for model compression,
    enabling the reduction of model size without sacrificing too much performance.
    It allows for the efficient deployment of models on resource-constrained devices
    and faster inference times.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we learned the basic concepts of recommender systems, starting
    with the definition of these systems and then understanding how the problem is
    approached. We analyzed the different types of recommender systems: CF, content-based
    filtering, and hybrid recommender systems.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Next, we saw how to use similarities in the data to identify possible fraudulent
    uses of credit cards. To do this, we trained a model based on the nearest neighbor
    algorithm but using a modified version of the traditional k-NN algorithm, where
    neighbors are given varying weights during the prediction or classification process.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Then, we saw how to implement a NIDS based on ensemble methods in MATLAB. Specifically,
    we adopted an AdaBoost algorithm to identify intrusions in a LAN network.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we introduced the techniques of deploying machine learning models regarding
    model compression. We analyzed the most popular model compression techniques,
    including pruning, quantization, knowledge distillation, and low-rank approximation.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn the basic concepts of anomaly detection and
    fault diagnosis systems. We will understand how to identify anomaly functioning
    using deep learning, as well as how to implement a fault diagnosis system in MATLAB.
    Finally, we will discover dropout, L1 and L2 regularization, and early stopping.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
