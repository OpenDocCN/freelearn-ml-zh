- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: MATLAB Tools for Recommender Systems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MATLAB推荐系统工具
- en: A recommender system is a model that’s designed to anticipate the preferences
    of a specific user. When applied to the domain of movies, it transforms into a
    movie recommendation engine. The process involves filtering items in a database
    by predicting the user’s potential ratings and facilitating the connection of
    users with the most suitable content in the dataset. This holds significance because,
    in extensive catalogs, users might not discover all pertinent content. Effective
    recommendations enhance content consumption and major platforms such as Netflix
    heavily depend on them to maintain user engagement. In this chapter, we will learn
    the basic concepts of recommender systems and how to build a **network intrusion
    detection system** (**NIDS**) using MATLAB.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是一种旨在预测特定用户偏好的模型。当应用于电影领域时，它转变为电影推荐引擎。这个过程涉及通过预测用户的潜在评分来过滤数据库中的项目，并促进用户与数据集中最合适内容的连接。这具有重要意义，因为在庞大的目录中，用户可能无法发现所有相关内容。有效的推荐可以增强内容消费，并且像Netflix这样的主要平台高度依赖它们来维持用户参与度。在本章中，我们将学习推荐系统的基础概念以及如何使用MATLAB构建**网络入侵检测系统**（**NIDS**）。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introducing the basic concepts of recommender systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍推荐系统的基本概念
- en: Finding similar users in data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据中寻找相似用户
- en: Creating recommender systems for network intrusion detection using MATLAB
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MATLAB创建用于网络入侵检测的推荐系统
- en: Deploying machine learning models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署机器学习模型
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will introduce basic machine learning concepts. To understand
    these topics, a basic knowledge of algebra and mathematical modeling is needed.
    You will also required working knowledge of MATLAB.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍基本的机器学习概念。为了理解这些主题，需要具备代数和数学建模的基本知识。您还需要具备MATLAB的实际操作能力。
- en: 'To work with the MATLAB code in this chapter, you’ll need the following files
    (available on GitHub at [https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用本章中的MATLAB代码，您需要以下文件（可在GitHub上找到，网址为[https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition](https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition)）：
- en: '`CreditCardData.xlsx`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CreditCardData.xlsx`'
- en: '`CreditCardFraudDet.m`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CreditCardFraudDet.m`'
- en: '`NDISdata.csv`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NDISdata.csv`'
- en: '`NDISEnsemble.m`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NDISEnsemble.m`'
- en: Introducing the basic concepts of recommender systems
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍推荐系统的基本概念
- en: 'A **recommender system** is a type of information filtering system that’s designed
    to suggest items or content to users based on their preferences, historical behavior,
    or other relevant factors. These systems are widely used in various online platforms
    to help users discover products, services, content, and more. Recommender systems
    involve two primary entities: **users** and **items**. Users are individuals for
    whom recommendations are generated, and items are the products, content, or services
    to be recommended. These items can include movies, books, products, news articles,
    and more.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐系统**是一种旨在根据用户的偏好、历史行为或其他相关因素向用户建议物品或内容的信息过滤系统。这些系统在各种在线平台上被广泛使用，以帮助用户发现产品、服务、内容等。推荐系统涉及两个主要实体：**用户**和**物品**。用户是生成推荐的个体，而物品是要推荐的产物、内容或服务。这些物品可以包括电影、书籍、产品、新闻文章等。'
- en: Recommender systems rely on data that captures the interaction between users
    and items. This interaction data can include user ratings, purchase history, clicks,
    views, likes, and any other form of user engagement with items.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统依赖于捕捉用户和物品之间交互的数据。这种交互数据可以包括用户评分、购买历史、点击、查看、点赞以及任何其他形式的用户与物品的互动。
- en: 'There are different types of recommender systems:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的推荐系统：
- en: '**Collaborative filtering** (**CF**): CF methods make recommendations based
    on the preferences and behavior of other users.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同过滤**（**CF**）：CF方法基于其他用户的偏好和行为进行推荐。'
- en: '**Content-based filtering**: This approach recommends items to users based
    on the attributes of the items and the user’s historical preferences. It focuses
    on the content and descriptions of items.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**：这种方法根据物品的属性和用户的历 史偏好向用户推荐物品。它侧重于物品的内容和描述。'
- en: '**Hybrid recommender systems**: These systems integrate various recommendation
    techniques to furnish recommendations that are both more accurate and diverse.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合推荐系统**：这些系统整合了各种推荐技术，以提供更准确和多样化的推荐。'
- en: Understanding CF
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 CF
- en: CF is a popular technique that’s used in recommender systems to make personalized
    recommendations to users based on their interactions and behaviors, as well as
    the behaviors of similar users. CF assumes that users who have interacted with
    items in a similar way in the past will have similar preferences in the future.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CF 是一种流行的技术，在推荐系统中使用，根据用户的交互和行为以及类似用户的行 为，为用户做出个性化推荐。CF 假设过去以相似方式与物品交互的用户在未来将会有相似
    的偏好。
- en: 'There are also two main types of CF:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，CF 主要有两种类型：
- en: '**User-based**: This type of CF recommends items to a user based on the preferences
    and behaviors of users who are like them. Compute a similarity score between the
    target user and all other users in the system. Common similarity metrics include
    cosine similarity or Pearson correlation. Identify a set of neighbor users who
    are most like the target user. Recommend items that the target user’s neighbors
    have interacted with, but the target user has not.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于用户的**：这种类型的 CF 根据与目标用户相似的用户偏好和行为向用户推荐物品。计算目标用户与系统中所有其他用户之间的相似度得分。常见的相似度指标包括余弦相似度或皮尔逊相关系数。识别出一组与目标用户最相似的邻居用户。推荐目标用户的邻居已经交互过但目标用户尚未交互过的物品。'
- en: '**Item-based**: This type of CF recommends items to a user based on the similarity
    of items they have interacted with in the past. It calculates the similarity between
    all pairs of items in the system based on user interactions. Common similarity
    metrics include cosine similarity and the Jaccard index. For a target user, it
    can identify the items they have interacted with. It can recommend items that
    are like the items the user has interacted with.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于物品的**：这种类型的 CF 根据用户过去交互过的物品的相似性向用户推荐物品。它根据用户交互计算系统中所有物品对之间的相似度。常见的相似度指标包括余弦相似度和
    Jaccard 指数。对于目标用户，它可以识别出他们已经交互过的物品。它可以推荐与用户交互过的物品相似的物品。'
- en: CF matrices are often sparse because users interact with only a small fraction
    of available items. Techniques such as matrix factorization can help address this
    issue by finding latent factors in the data. As the number of users and items
    grows, the computation of user-user or item-item similarity becomes more computationally
    expensive. Optimizations are required for scalability. CF can struggle to make
    recommendations for new users or items with little to no interaction history.
    Techniques such as content-based recommendations or hybrid models are often used
    to address this problem.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CF 矩阵通常很稀疏，因为用户只与可用物品的一小部分进行交互。通过在数据中找到潜在因素，如矩阵分解等技术可以帮助解决这一问题。随着用户和物品数量的增加，用户-用户或物品-物品相似度的计算变得更加昂贵。为了可扩展性，需要进行优化。CF
    在为新用户或几乎没有交互历史的物品做出推荐时可能会遇到困难。通常使用基于内容的推荐或混合模型等技术来解决这个问题。
- en: CF often relies on user behavior data, which raises privacy concerns. Privacy-preserving
    methods such as differential privacy may be employed to protect user information.
    Various metrics, including **mean absolute error** (**MAE**), **root mean squared
    error** (**RMSE**), and ranking-based metrics such as precision and recall, are
    used to evaluate the performance of CF algorithms.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: CF 通常依赖于用户行为数据，这引发了隐私问题。可以使用差分隐私等隐私保护方法来保护用户信息。使用各种指标来评估 CF 算法的性能，包括 **平均绝对误差**（**MAE**）、**均方根误差**（**RMSE**）以及基于排名的指标，如精确率和召回率。
- en: CF has been widely used in recommendation systems in various domains, including
    e-commerce, movie and music recommendations, social networks, and more. While
    it is effective at capturing user preferences, it does have limitations, such
    as the cold start problem and the need for a sufficient volume of user interactions.
    Hybrid approaches that combine CF with other recommendation techniques can overcome
    some of these limitations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: CF 已被广泛应用于各种领域的推荐系统，包括电子商务、电影和音乐推荐、社交网络等。虽然它能够有效地捕捉用户偏好，但它确实存在一些局限性，例如冷启动问题和需要足够的用户交互量。将
    CF 与其他推荐技术相结合的混合方法可以克服一些这些局限性。
- en: Content-based filtering explained
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于内容的过滤解释
- en: '**Content-based filtering** is a recommendation technique that’s used in recommender
    systems to provide personalized recommendations to users based on the characteristics
    and features of the items and the user’s preferences. Unlike CF, which relies
    on user-item interactions, content-based filtering focuses on the content of items
    and attempts to match them with user profiles.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**是一种推荐技术，在推荐系统中用于根据物品的特征和用户偏好为用户提供个性化推荐。与依赖于用户-物品交互的协同过滤（CF）不同，基于内容的过滤专注于物品的内容，并试图将其与用户档案相匹配。'
- en: Each item in the system is described by a set of features or attributes. These
    features can vary widely based on the domain but may include things such as genres,
    keywords, actors, directors (for movies), authors (for books), and more. For text-based
    content, natural language processing techniques may be used to extract keywords
    or topics. The system maintains a user profile or preference vector for each user,
    which reflects their preferences for different features or attributes. This user
    profile is built based on the items the user has interacted with or explicitly
    rated.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 系统中的每个物品都由一组特征或属性描述。这些特征可以根据领域广泛变化，可能包括如流派、关键词、演员、导演（对于电影）、作者（对于书籍）等。对于基于文本的内容，可以使用自然语言处理技术提取关键词或主题。系统为每个用户维护一个用户档案或偏好向量，它反映了他们对不同特征或属性的偏好。这个用户档案是基于用户互动过的物品或明确评分构建的。
- en: To generate recommendations for a user, the system calculates a similarity score
    between the user’s profile and the features of items. The similarity score is
    often computed using techniques such as cosine similarity, **Term Frequency-Inverse
    Document Frequency** (**TF-IDF**), or other distance metrics. Items with the highest
    similarity scores are recommended to the user. These are the items that are most
    in line with the user’s historical preferences and interests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为用户生成推荐，系统计算用户档案与物品特征之间的相似度得分。相似度得分通常使用余弦相似度、**词频-逆文档频率**（**TF-IDF**）或其他距离度量技术来计算。具有最高相似度得分的物品被推荐给用户。这些是符合用户历史偏好和兴趣的物品。
- en: Content-based filtering is effective at providing personalized recommendations
    because it considers the individual user’s preferences based on item features.
    It doesn’t rely on user-to-user or item-to-item comparisons, making it suitable
    for new or less active users who might not have much interaction history. The
    quality of recommendations heavily depends on the accuracy and richness of item
    descriptions and features. Note that ensuring high-quality metadata is crucial.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的过滤在提供个性化推荐方面非常有效，因为它根据物品特征考虑了个人用户的偏好。它不依赖于用户间或物品间的比较，因此适合新用户或互动较少的用户。推荐的质量很大程度上取决于物品描述和特征的准确性和丰富性。请注意，确保高质量的元数据至关重要。
- en: While content-based filtering is good at recommending items such as those a
    user has interacted with before, it may not introduce as much serendipity or novelty
    in recommendations compared to CF. It can also help address the cold start problem
    for new items if there is sufficient information available about their features.
    Many recommender systems combine content-based filtering with CF or other recommendation
    techniques to improve recommendation quality and address the limitations of each
    approach.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于内容的过滤擅长推荐用户之前互动过的物品，但与CF相比，它可能不会在推荐中引入太多的偶然性或新颖性。如果关于其特征有足够的信息，它还可以帮助解决新物品的冷启动问题。许多推荐系统将基于内容的过滤与CF或其他推荐技术相结合，以提高推荐质量并解决每种方法的局限性。
- en: Content-based filtering is commonly used in various domains such as news recommendation,
    music recommendation, and e-commerce for suggesting products. When implemented
    correctly, it can offer valuable recommendations tailored to individual user preferences
    and needs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的过滤在新闻推荐、音乐推荐和电子商务等各个领域被广泛使用，用于建议产品。当正确实施时，它可以根据个人用户的偏好和需求提供有价值的推荐。
- en: Hybrid recommender systems
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合推荐系统
- en: Hybrid recommender systems are recommendation systems that combine multiple
    recommendation techniques to provide more accurate and diverse recommendations.
    These systems aim to leverage the strengths of different recommendation approaches,
    such as CF, content-based filtering, and more, while mitigating their weaknesses.
    Hybrid recommender systems are commonly used in various applications to improve
    recommendation quality and address the limitations of individual methods.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 混合推荐系统是结合多种推荐技术以提供更准确和多样化推荐的推荐系统。这些系统旨在利用不同推荐方法的优势，如CF、基于内容的过滤等，同时减轻它们的弱点。混合推荐系统在多种应用中普遍使用，以提高推荐质量并解决个别方法的局限性。
- en: In weighted hybrid systems, different recommendation techniques are assigned
    weights that determine their influence on the final recommendations. For example,
    you might assign a higher weight to CF if historical user interactions are more
    critical, and a lower weight to content-based filtering for item features. Recommendations
    are generated by combining the scores from each technique, weighted by their importance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在加权混合系统中，不同的推荐技术被分配权重，这些权重决定了它们对最终推荐的影响。例如，如果历史用户交互更为关键，可能会给CF分配更高的权重，而对于项目特征的内容过滤则分配较低的权重。通过结合每种技术的得分并按其重要性加权，生成推荐。
- en: In switching hybrid systems, the recommendation approach is dynamically chosen
    based on certain conditions or user characteristics. For instance, if a user has
    a substantial interaction history, CF might be used, but if they are a new user
    with minimal history, content-based filtering might be employed. In this approach,
    the features or scores generated by different recommendation techniques are combined
    to create a unified feature vector for items or users. This combined feature vector
    is then used to generate recommendations using any single recommendation method.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在切换混合系统中，推荐方法根据某些条件或用户特征动态选择。例如，如果一个用户有大量的交互历史，可能会使用CF，但如果他们是一个历史记录很少的新用户，可能会采用基于内容的过滤。在此方法中，不同推荐技术生成的特征或得分被组合，以创建用于项目或用户的统一特征向量。然后，使用任何单一推荐方法利用这个组合特征向量生成推荐。
- en: Cascade hybrids use the output of one recommendation technique as input to another.
    For example, content-based filtering may be used to generate an initial set of
    recommendations. These recommendations can be further refined using CF to improve
    accuracy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 级联混合系统使用一个推荐技术的输出作为另一个推荐技术的输入。例如，基于内容的过滤可能被用来生成一组初始推荐。这些推荐可以通过CF进一步优化以提高准确性。
- en: In meta-level hybrid systems, different recommendation methods are applied independently,
    and their outputs are combined using a meta-learner or meta-classifier. The meta-learner
    takes the outputs of individual recommendation methods as inputs and provides
    the final recommendations. Machine learning algorithms such as decision trees,
    neural networks, or ensemble methods such as stacking can be used as meta-learners.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在元级混合系统中，不同的推荐方法独立应用，并且它们的输出通过元学习器或元分类器进行组合。元学习器将个别推荐方法的输出作为输入，并提供最终的推荐。可以使用决策树、神经网络或集成方法如堆叠等机器学习算法作为元学习器。
- en: In the realm of data analysis and user profiling, the process of finding similar
    users holds immense significance. Let’s delve into the techniques and methodologies
    that are employed for identifying and categorizing users with similar patterns
    and behaviors within a dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析和使用户画像的领域，寻找相似用户的过程具有重大意义。让我们深入了解用于在数据集中识别和分类具有相似模式和行为的用户的技巧和方法。
- en: Finding similar users in data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据中寻找相似用户
- en: Fraud has consistently been a pervasive issue in various forms, but the emergence
    of new technological tools, such as **virtual intelligence** (**VI**), has expanded
    the avenues for fraudulent activities. In today’s world, the use of credit and
    debit cards has become the standard for making purchases, and as a result, fraud
    associated with these payment methods is on the rise. The repercussions of such
    fraud extend beyond impacting just merchants and banks, who are often left shouldering
    the financial burden.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈一直以各种形式普遍存在，但新技术的出现，如**虚拟智能**（**VI**），扩大了欺诈活动的途径。在当今世界，使用信用卡和借记卡进行购买已成为标准，因此，与这些支付方式相关的欺诈正在增加。这种欺诈的后果不仅影响商家和银行，他们通常承担着财务负担，而且影响范围更广。
- en: When a customer falls victim to fraud, they may find themselves burdened with
    higher interest rates imposed by the bank as they could be categorized as a higher
    risk profile. Additionally, fraud incidents can tarnish a merchant’s reputation
    and image. If a customer experiences fraud during a transaction, it can erode
    their trust in the seller, potentially driving them to seek alternatives from
    competitors for future purchases.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户成为欺诈的受害者时，他们可能会发现自己被银行征收更高的利率，因为他们可能被归类为高风险客户。此外，欺诈事件可能会损害商家的声誉和形象。如果客户在交易过程中遭遇欺诈，这可能会侵蚀他们对卖家的信任，可能促使他们在未来的购买中寻求竞争对手的替代品。
- en: Given a set of credit card transaction data, fraud recognition is the process
    of identifying whether a new transaction belongs to the class of fraudulent or
    legitimate transactions. Such a system should not only detect fraudulent transactions
    but should do so in a cost-effective manner.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组信用卡交易数据，欺诈识别是识别新交易是否属于欺诈交易或合法交易的过程。这样的系统不仅应该能够检测欺诈交易，而且应该以成本效益的方式完成。
- en: 'Examining a transaction with the goal of classification can be carried out
    through distinct methods, and two specific approaches are suggested:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过不同的方法对交易进行分类分析，以下建议了两种具体的方法：
- en: User-level analysis
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户级别分析
- en: Single transaction analysis
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个交易分析
- en: These two approaches represent unique strategies, each having its own set of
    advantages and limitations. Each approach entails certain assumptions, varying
    in their degree of validity. Regardless, both approaches can yield valuable outcomes.
    There are situations where the choice between these methods is determined by the
    nature of the available data as it may not permit an alternative approach.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法代表了独特的策略，每种方法都有其自身的优势和局限性。每种方法都包含某些假设，这些假设的有效程度各不相同。无论如何，这两种方法都可以产生有价值的成果。在某些情况下，选择这些方法之间的差异取决于可用数据的性质，因为它可能不允许采用替代方法。
- en: Analyzing transactions at the individual transaction level refers to an approach
    where the classification of a transaction is determined by its relationship with
    all the transactions within the dataset. Various machine learning algorithms can
    be employed for this purpose. For instance, consider the **k-nearest neighbors**
    (**k-NN**) algorithm, which classifies a transaction based on its similarity to
    other transactions in the dataset. If a transaction closely resembles known fraudulent
    transactions, there’s a likelihood it will be categorized as fraudulent, and conversely,
    it would be deemed a legitimate transaction. This mechanism facilitates the identification
    of data patterns by leveraging similarities among objects of the same class.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个交易级别分析交易是指一种方法，其中交易的分类是由其与数据集中所有其他交易的关系决定的。可以采用各种机器学习算法来完成这项任务。例如，考虑**k-最近邻**（**k-NN**）算法，该算法根据交易与数据集中其他交易的相似性来分类交易。如果一个交易与已知的欺诈交易非常相似，那么它很可能被归类为欺诈交易，反之，则被视为合法交易。这种机制通过利用同一类对象之间的相似性来识别数据模式。
- en: In a nearest neighbors algorithm, a record is categorized by examining all the
    data in the training set and assigning it the same class as the nearest element.
    The underlying assumption is that in a multidimensional space, if two records
    are “close,” they likely belong to the same class. To gauge this proximity, it’s
    important to employ a distance metric. One example is the Euclidean distance or,
    more broadly, the Minkowski metric, as we introduced in [*Chapter 4*](B21156_04.xhtml#_idTextAnchor084),
    *Clustering Analysis and* *Dimensionality Reduction*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近邻算法中，通过检查训练集中的所有数据并将记录分配给与最近元素相同的类别来对记录进行分类。其基本假设是在多维空间中，如果两个记录“接近”，它们很可能属于同一类别。为了衡量这种接近性，重要的是要采用距离度量。一个例子是欧几里得距离，或者更广泛地说，Minkowski度量，正如我们在[*第4章*](B21156_04.xhtml#_idTextAnchor084)中介绍的，*聚类分析和*
    *降维*。
- en: 'The nearest neighbor rule results in a space division known as **Voronoi tessellation**.
    Each element in the training set delineates a region in which patterns will be
    classified into the same class. To enhance the robustness of this mechanism, one
    approach is to classify a record by considering the k closest records. The record
    can then be assigned to the class that has the largest representation among the
    selected examples. To reduce sensitivity to the choice of k, each record can contribute
    to the classification based on a weighted scheme determined by its distance from
    the element to be classified. For this process to work effectively, the attributes
    must possess consistent value scales, which typically necessitates prior normalization
    during the data preprocessing phase. Let’s learn how to build a credit card fraud
    detection system:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻规则导致了一种称为**Voronoi划分**的空间划分。训练集中的每个元素都划定了这样一个区域，其中模式将被分类到相同的类别。为了增强这种机制的鲁棒性，一种方法是通过考虑k个最近的记录来分类一个记录。然后，该记录可以被分配到在所选示例中具有最大代表性的类别。为了减少对k的选择的敏感性，每个记录可以根据其与要分类的元素的距离，通过一个加权方案对分类做出贡献。为了使此过程有效，属性必须具有一致的价值尺度，这通常需要在数据预处理阶段进行先前的归一化。让我们学习如何构建信用卡欺诈检测系统：
- en: 'As usual, we will start by importing the data into the MATLAB workspace. For
    this, we will utilize the credit card fraud detection dataset, which comprises
    anonymized credit card transactions classified as fraudulent or legitimate:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同往常，我们将首先将数据导入MATLAB工作空间。为此，我们将使用信用卡欺诈检测数据集，该数据集包含匿名信用卡交易，被分类为欺诈或合法：
- en: '[PRE0]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The dataset exclusively consists of numerical input variables, derived from
    a PCA transformation. Among the features, `V1` to `V28` represent the principal
    components obtained through PCA. The `Class` feature serves as the response variable
    and holds a value of `1` in cases of fraud and `0` otherwise. To understand how
    the data is distributed, we can count the occurrences in the `class` column:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集仅由数值输入变量组成，这些变量来自PCA转换。在特征中，`V1`到`V28`代表通过PCA获得的主成分。`Class`特征作为响应变量，在欺诈情况下值为`1`，否则为`0`。为了了解数据的分布情况，我们可以计算`class`列中的出现次数：
- en: '[PRE1]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `groupcounts()` function provides the distinct combinations of grouping
    variables for the table or timetable denoted as `T`. It also offers the count
    of members within each group and the corresponding data percentage, ranging from
    `0` to `100`. Groups are established based on rows in the variables contained
    within `groupvars` that share identical unique value combinations. Each entry
    in the result table corresponds to an individual group.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`groupcounts()`函数提供了表示为`T`的表或时间表的分组变量的独特组合。它还提供了每个组内的成员数和相应的数据百分比，范围从`0`到`100`。组是根据包含在`groupvars`中的变量的行建立的，这些行具有相同的唯一值组合。结果表中的每个条目都对应于一个单独的组。'
- en: The dataset is unbalanced on one of the binary classes, we should take this
    into account when evaluating the results. Classifying imbalanced data is a common
    challenge in machine learning when one class significantly outnumbers the other(s).
    The primary class (majority class) often dominates, making it challenging for
    the model to correctly predict the minority class.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集在其中一个二进制类别上是不平衡的，我们在评估结果时应考虑这一点。在机器学习中，当一个类别显著多于其他类别时，对不平衡数据进行分类是一个常见的挑战。主要类别（多数类别）通常占主导地位，这使得模型难以正确预测少数类别。
- en: 'To check how the data is distributed, we can draw a boxplot of the features:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了检查数据的分布情况，我们可以绘制特征的箱线图：
- en: '[PRE2]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following graph will be output (*Figure 10**.1*):'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图形将被输出（*图10**.1*）：
- en: '![Figure 10.1 – Boxplot of the features](img/B21156_10_01.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 特征的箱线图](img/B21156_10_01.jpg)'
- en: Figure 10.1 – Boxplot of the features
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 特征的箱线图
- en: From the analysis of *Figure 10**.1*, we can see that the variables are skewed.
    We can also see that some of them present potential outliers. It is recommended
    to conduct data scaling. Keep in mind that it’s a best practice to standardize
    or normalize the data before training a machine learning model. Through scaling,
    the data’s units are standardized, making it simpler to compare data from various
    sources or locations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图10**.1*的分析中，我们可以看到变量是偏斜的。我们还可以看到其中一些变量存在潜在的异常值。建议进行数据缩放。请记住，在训练机器学习模型之前对数据进行标准化或归一化是一种最佳实践。通过缩放，数据的单位被标准化，这使得比较来自不同来源或位置的数据变得更容易。
- en: Data scaling, also known as data normalization or standardization, is a preprocessing
    technique in machine learning and data analysis that involves transforming the
    data into a standardized range or distribution. The primary purpose of data scaling
    is to make different features or variables in your dataset comparable and to help
    machine learning algorithms perform better.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据缩放，也称为数据归一化或标准化，是机器学习和数据分析中的预处理技术，涉及将数据转换到标准化的范围或分布。数据缩放的主要目的是使你的数据集中的不同特征或变量可比较，并帮助机器学习算法表现更好。
- en: The choice between scaling and standardization depends on the specific requirements
    of your dataset and the machine learning algorithm you plan to use. In general,
    it is advisable to apply data scaling to your features to prevent certain variables
    from dominating the learning process, especially in algorithms that are sensitive
    to feature scales, such as kNN or support vector machines.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在缩放和标准化之间进行选择取决于你的数据集的具体要求和计划使用的机器学习算法。一般来说，建议对特征应用数据缩放，以防止某些变量主导学习过程，尤其是在对特征尺度敏感的算法中，如kNN或支持向量机。
- en: Data scaling helps in improving the convergence of optimization algorithms,
    makes features more interpretable, and can also enhance the performance of some
    machine learning models. However, it’s important to note that not all algorithms
    require data scaling, and there are cases where the natural scale of the data
    is meaningful and should not be altered. The decision to scale the data should
    be made with careful consideration of your specific problem and the characteristics
    of your dataset.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据缩放有助于提高优化算法的收敛性，使特征更易于解释，并且还可以提高某些机器学习模型的性能。然而，需要注意的是，并非所有算法都需要数据缩放，有些情况下数据的自然尺度是有意义的，不应被改变。是否缩放数据应谨慎考虑你的具体问题和数据集的特征。
- en: 'We will perform a standardization with a range of `-1` to `1`:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将执行范围在`-1`到`1`之间的标准化：
- en: '[PRE3]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Standardization with a range of `-1` to `1`, also known as min-max scaling with
    a specific range, is a method of data scaling that transforms your data to fit
    within the range of `-1` to `1`. This approach is useful when you want to normalize
    your data while maintaining the possibility of negative values.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 范围在`-1`到`1`之间的标准化，也称为具有特定范围的min-max缩放，是一种数据缩放方法，将你的数据转换到`-1`到`1`的范围内。当你想要标准化数据同时保持负值可能性时，这种方法很有用。
- en: 'To check how the data is distributed after we performed data scaling, we can
    draw a boxplot of the features:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了检查我们执行数据缩放后数据的分布情况，我们可以绘制特征的箱线图：
- en: '[PRE4]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following graph is shown (*Figure 10**.2*):'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图表显示的是（*图10*.*2*）：
- en: '![Figure 10.2 – Boxplot of the scaled data](img/B21156_10_02.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2 – 缩放数据的箱线图](img/B21156_10_02.jpg)'
- en: Figure 10.2 – Boxplot of the scaled data
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 缩放数据的箱线图
- en: Now, it is clear that the data has been scaled so that we have the same existence
    intervals.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，很明显数据已经被缩放，以便我们拥有相同的存在区间。
- en: 'Before training the model based on machine learning, it is necessary to carry
    out data splitting. Data splitting refers to the process of dividing a dataset
    into separate subsets for training, testing, and validation purposes. We will
    perform train-test splitting, which involves dividing the dataset into two parts,
    typically with a 70-30 or 80-20 split. The larger portion is used for training
    the model, while the smaller portion is used for testing its performance:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在基于机器学习的模型训练之前，进行数据拆分是必要的。数据拆分是指将数据集划分为用于训练、测试和验证的单独子集的过程。我们将执行训练-测试拆分，这涉及将数据集分为两部分，通常为70-30或80-20的拆分。较大的部分用于训练模型，而较小的一部分用于测试其性能：
- en: '[PRE5]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We initiated the process by obtaining the number of observations within our
    dataset using the `length()` function. This function returns the size of the largest
    dimension in the array, `X`. In the context of vectors, this size corresponds
    to the total number of elements. Subsequently, we employed the `cvpartition()`
    function to create a random partition for the dataset. This partition serves as
    the foundation for constructing essential training and test subsets, which are
    instrumental in evaluating a statistical model. To extract the training data index
    and the test data index from the original dataset, we utilized the `training`
    and `test` object functions. These indices were then applied to extract the corresponding
    data subsets.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过使用`length()`函数获取数据集中观察值的数量来启动这个过程。此函数返回数组`X`中最大维度的尺寸，在向量的上下文中，这个尺寸对应于元素的总数。随后，我们使用了`cvpartition()`函数来创建数据集的随机分区。这个分区是构建基本训练集和测试集的基础，这些集对于评估统计模型至关重要。为了从原始数据集中提取训练数据索引和测试数据索引，我们使用了`training`和`test`对象函数。然后，将这些索引应用于提取相应的数据子集。
- en: 'k-NN is a versatile algorithm that’s used not only for classification and regression
    tasks but also in recommender systems. It can be adapted for building CF-based
    recommender systems. We will use the `fitcknn()` function, as follows:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: k-NN是一种多用途算法，不仅用于分类和回归任务，还用于推荐系统。它可以适应构建基于CF的推荐系统。我们将使用`fitcknn()`函数，如下所示：
- en: '[PRE6]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following arguments were passed:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下参数被传递：
- en: '`TrainData(:,1:28)`'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainData(:,1:28)`'
- en: '`TrainData(:,29)`'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainData(:,29)`'
- en: '`cosine` (the expression represents the complement of the cosine of the angle
    included between observations, treating them as vectors):'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`余弦`（该表达式表示观察值之间夹角的余弦的补数，将它们视为向量）：'
- en: Minkowski distance exponent
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minkowski距离指数
- en: 'Number of nearest neighbors to find: `10`'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要找到的最近邻数量：`10`
- en: 'Distance weighting function: `SquaredInverse` (`Weight` is 1/distance)'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 距离加权函数：`SquaredInverse`（`Weight`是距离的倒数）
- en: We applied weighted k-NN, a variation of the k-NN algorithm that assigns different
    weights to the neighbors when making predictions or classifications. In traditional
    k-NN, each neighbor has an equal influence on the final decision, but in weighted
    k-NN, the influence of each neighbor is adjusted based on certain factors, typically
    the proximity or similarity between the neighbors and the query point. This allows
    for more accurate and context-aware predictions.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们应用了加权k-NN算法，这是k-NN算法的一种变体，在预测或分类时为邻居分配不同的权重。在传统的k-NN中，每个邻居对最终决策的影响是相等的，但在加权k-NN中，每个邻居的影响会根据某些因素进行调整，通常是邻居与查询点之间的接近度或相似度。这允许进行更准确和上下文感知的预测。
- en: We start by choosing a distance metric to measure the similarity or dissimilarity
    between data points. We used the `cosine` metric, also known as cosine similarity,
    which is a similarity measure that’s used to determine the similarity between
    two non-zero vectors in a high-dimensional space. It is widely used in various
    fields, including information retrieval, natural language processing, and recommendation
    systems. The `cosine` metric measures the cosine of the angle between two vectors,
    and it provides a value between -1 and 1, where 1 indicates that the vectors are
    identical, 0 means that they are orthogonal (completely dissimilar), and -1 implies
    they are opposed.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先选择一个距离度量来衡量数据点之间的相似度或差异度。我们使用了`cosine`度量，也称为余弦相似度，这是一种用于确定高维空间中两个非零向量之间相似度的相似度度量。它在各个领域都得到广泛应用，包括信息检索、自然语言处理和推荐系统。`cosine`度量衡量两个向量之间的夹角的余弦值，它提供一个介于-1和1之间的值，其中1表示向量是相同的，0表示它们是正交的（完全不同），-1表示它们是相反的。
- en: The algorithm then determines the value of *k*, which represents the number
    of nearest neighbors to consider when making a prediction. The choice of k depends
    on your dataset and the specific problem you’re trying to solve. You must compute
    the distances between the query point (the point you want to classify or predict)
    and all other data points in your dataset, then calculate weights for each neighbor
    based on their proximity or similarity to the query point. Common methods for
    assigning weights include inverse distance, where closer neighbors have higher
    weights, or similarity-based weighting, where more similar neighbors are given
    higher weights. You can also choose the k neighbors with the highest weights.
    These neighbors will have a more significant impact on the final prediction. For
    classification tasks, assign class labels to the query point based on the majority
    class among the selected neighbors, with the weights influencing the voting process.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 算法随后确定*k*的值，这代表在做出预测时考虑的最近邻的数量。k的选择取决于你的数据集和你要尝试解决的问题的具体情况。你必须计算查询点（你想要分类或预测的点）与数据集中所有其他数据点之间的距离，然后根据它们与查询点的接近程度或相似性为每个邻居计算权重。常见的分配权重的方法包括逆距离，其中较近的邻居具有更高的权重，或者基于相似性的加权，其中更相似的邻居被赋予更高的权重。你也可以选择具有最高权重的k个邻居。这些邻居将对最终预测产生更大的影响。对于分类任务，根据所选邻居中的多数类别将类别标签分配给查询点，权重会影响投票过程。
- en: 'Here are the advantages of using weighted k-NN:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是使用加权k-NN的优点：
- en: Weighted k-NN can provide more accurate predictions because it considers the
    influence of each neighbor on the final decision
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权k-NN可以提供更准确的预测，因为它考虑了每个邻居对最终决策的影响。
- en: It allows for better handling of imbalanced datasets, where some neighbors may
    be more informative than others
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它允许更好地处理不平衡数据集，其中某些邻居可能比其他邻居更有信息量。
- en: Weighted k-NN is particularly useful when the neighbors are not equally informative
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权k-NN在邻居的信息量不均等时尤其有用。
- en: Weighted k-NN is a flexible and widely used machine learning technique that
    can be applied to a variety of problems, including classification, regression,
    and recommendation systems. It allows you to adapt the algorithm to the specific
    characteristics of your data and the problem you are trying to solve.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 加权k-NN是一种灵活且广泛使用的机器学习技术，可以应用于各种问题，包括分类、回归和推荐系统。它允许你根据数据的具体特征和你要尝试解决的问题调整算法。
- en: 'After training the model, we must evaluate its performance. We will start by
    using the trained model to predict data labels:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练模型后，我们必须评估其性能。我们将首先使用训练好的模型来预测数据标签：
- en: '[PRE7]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we employed the `predict()` function, which furnishes the anticipated
    response values produced by the generalized linear regression model.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`predict()`函数，它提供了广义线性回归模型产生的预期响应值。
- en: 'Now, we can assess the model’s accuracy, which gauges the extent to which a
    predictive model’s forecasts match the real or observed values. It serves as an
    indicator of the model’s performance in accurately predicting outcomes:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以评估模型的准确性，这衡量了预测模型的预测与实际或观察到的值匹配的程度。它作为模型在准确预测结果方面性能的指标：
- en: '[PRE8]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result is excellent, confirming that the choice of the algorithm and training
    parameters were correct.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果非常出色，证实了算法和训练参数的选择是正确的。
- en: In the ever-evolving landscape of cybersecurity, the development of effective
    tools for network intrusion detection is paramount. The next section will explore
    how to utilize MATLAB to create advanced recommender systems tailored for enhancing
    network intrusion detection capabilities.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络安全不断演变的领域中，开发有效的网络入侵检测工具至关重要。下一节将探讨如何利用MATLAB创建针对增强网络入侵检测能力的先进推荐系统。
- en: Creating recommender systems for network intrusion detection using MATLAB
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MATLAB创建网络入侵检测的推荐系统
- en: A NIDS serves as a security mechanism that’s employed to identify and prevent
    unauthorized access, malicious activities, and potential threats within a computer
    network. It involves monitoring network traffic and analyzing it to identify any
    suspicious or abnormal behaviors. The main objective of network intrusion detection
    is to protect the network from various types of attacks, such as **denial-of-service**
    (**DoS**) attacks, malware infections, data leakage, unauthorized access, and
    other cyber threats.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: NIDS 作为一种安全机制，用于识别和预防计算机网络中的未经授权的访问、恶意活动和潜在威胁。它涉及监控网络流量并分析它，以识别任何可疑或异常的行为。网络安全检测的主要目标是保护网络免受各种类型的攻击，例如**拒绝服务**（**DoS**）攻击、恶意软件感染、数据泄露、未经授权的访问和其他网络威胁。
- en: 'There are two primary methods of network intrusion detection:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 网络入侵检测主要有两种方法：
- en: '**Signature-based detection**: This method involves comparing network traffic
    patterns with a database of known signatures or patterns of known attacks. If
    a match is found, an alert is generated to notify the network administrator.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于签名的检测**：这种方法涉及将网络流量模式与已知签名或已知攻击模式的数据库进行比较。如果找到匹配项，将生成警报通知网络管理员。'
- en: '**Anomaly-based detection**: This method focuses on identifying abnormal or
    suspicious network behavior that deviates from the normal patterns. It uses machine
    learning algorithms to analyze network traffic and detect any anomalies that could
    potentially indicate an ongoing or imminent attack.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于异常的检测**：这种方法侧重于识别偏离正常模式的异常或可疑的网络行为。它使用机器学习算法分析网络流量，并检测可能表明正在进行或即将发生的攻击的任何异常。'
- en: A NIDS can be implemented at different levels within a network architecture,
    such as at the perimeter, on individual hosts, or within specific network segments.
    They collect and analyze network packets, logs, and other network data to identify
    and alert the system administrators about potential intrusions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: NIDS 可以在网络架构的不同级别实现，例如在边界、单个主机或特定网络段内。它们收集和分析网络数据包、日志和其他网络数据，以识别并向系统管理员发出潜在入侵的警报。
- en: 'The following are some common techniques that are used in network intrusion
    detection:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些在网络安全检测中常用的技术：
- en: '**Packet analysis**: For examining individual network packets to identify specific
    attack signatures or anomalies'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据包分析**：用于检查单个网络数据包，以识别特定的攻击签名或异常'
- en: '**Protocol analysis**: For analyzing network protocols to detect any abnormal
    or unauthorized activities'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协议分析**：用于分析网络协议，以检测任何异常或未经授权的活动'
- en: '**Traffic analysis**: For monitoring network traffic patterns to identify any
    sudden spikes or unusual patterns'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量分析**：用于监控网络流量模式，以识别任何突然的峰值或异常模式'
- en: '**Behavior analysis**: For analyzing user or host behavior to detect any unusual
    or malicious activities'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行为分析**：用于分析用户或主机的行为，以检测任何异常或恶意活动'
- en: NIDS play a crucial role in safeguarding computer networks against unauthorized
    access and potential threats. They help identify and respond to security incidents
    promptly, minimizing any potential damage or data breaches.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: NIDS 在保护计算机网络免受未经授权的访问和潜在威胁方面发挥着至关重要的作用。它们有助于及时识别和应对安全事件，最大限度地减少潜在的损害或数据泄露。
- en: Recommender system for NIDS
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NIDS 推荐系统
- en: 'In this example, we will adopt a new approach to identifying and preventing
    network attacks: network intrusion detection using a recommender system. Traditional
    NIDS rely on fixed rules and signatures to detect known attack patterns. However,
    attackers are continually evolving their techniques, making it challenging for
    these systems to keep up. By incorporating a recommender system into the network
    intrusion detection process, it becomes possible to leverage machine learning
    and data mining techniques to enhance detection capabilities. The primary objective
    is to utilize historical network traffic data to build a model that can predict
    whether a particular network event is normal or malicious.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将采用一种新的方法来识别和预防网络攻击：使用推荐系统进行网络入侵检测。传统的 NIDS 依赖于固定的规则和签名来检测已知的攻击模式。然而，攻击者不断进化他们的技术，这使得这些系统难以跟上。通过将推荐系统纳入网络入侵检测过程，可以利用机器学习和数据挖掘技术来增强检测能力。主要目标是利用历史网络流量数据构建一个模型，可以预测特定网络事件是正常还是恶意。
- en: 'Here is an overview of how network intrusion detection using a recommender
    system works:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用推荐系统进行网络入侵检测的工作概述：
- en: '**Data collection**: Network traffic data is collected and stored for analysis.
    This data consists of various network parameters, such as IP addresses, port numbers,
    protocols, packet sizes, and more.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集**：收集并存储网络流量数据以进行分析。这些数据包括各种网络参数，如IP地址、端口号、协议、数据包大小等。'
- en: '**Feature extraction**: Relevant features are extracted from the collected
    data. These features can include traffic volume, connection duration, packet headers,
    and other characteristics that provide insights into network behavior.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**：从收集的数据中提取相关特征。这些特征可以包括流量量、连接持续时间、数据包头部和其他有助于了解网络行为的特征。'
- en: '**Data preprocessing**: The gathered data undergoes preprocessing to eliminate
    noise, address missing values, and normalize the features. This step ensures that
    the data is in a suitable format for analysis.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据预处理**：收集到的数据经过预处理以消除噪声、处理缺失值并归一化特征。这一步骤确保数据适合分析。'
- en: '**Training the recommender system**: The preprocessed data is used to train
    a recommender system algorithm, such as CF, matrix factorization, or association
    rule mining. This algorithm learns the patterns and relationships within the data.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练推荐系统**：预处理后的数据用于训练推荐系统算法，例如协同过滤（CF）、矩阵分解或关联规则挖掘。此算法学习数据中的模式和关系。'
- en: '**Building a recommendation model**: The trained algorithm generates a recommendation
    model based on the network traffic data. This model can identify the normal network
    behavior and detect any deviations from it.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建推荐模型**：训练好的算法基于网络流量数据生成推荐模型。此模型可以识别正常网络行为并检测任何偏离。'
- en: '**Real-time monitoring**: The recommendation model is then used to monitor
    incoming network traffic in real time. It analyzes the network events and predicts
    whether they are normal or potentially malicious.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时监控**：然后使用推荐模型实时监控传入的网络流量。它分析网络事件并预测它们是否正常或可能恶意。'
- en: '**Alert generation**: When the recommendation model detects a potentially malicious
    network event, it triggers an alert to notify network administrators. The alert
    can include information about the detected attack type and recommended countermeasures.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报生成**：当推荐模型检测到潜在的恶意网络事件时，它会触发警报以通知网络管理员。警报可以包括有关检测到的攻击类型和推荐的对策的信息。'
- en: '**Continuous learning**: The recommendation model can continuously update itself
    over time by incorporating new data and adjusting its detection capabilities.
    This ensures that the system remains effective against emerging threats.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续学习**：推荐模型可以通过结合新数据和调整其检测能力来随着时间的推移不断更新自己。这确保了系统能够有效对抗新兴威胁。'
- en: Overall, network intrusion detection using a recommender system offers a more
    dynamic and adaptive approach to identifying network attacks. It leverages machine
    learning techniques to learn from historical data and make intelligent predictions
    about the network’s security status. This can enhance the accuracy and efficiency
    of network security operations by reducing false positives and detecting emerging
    attack patterns.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，使用推荐系统进行网络入侵检测提供了一种更动态和自适应的方法来识别网络攻击。它利用机器学习技术从历史数据中学习并智能预测网络的安全状态。这可以通过减少误报并检测新兴攻击模式来提高网络安全操作的正确性和效率。
- en: NIDS using a recommender system in MATLAB
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在MATLAB中使用推荐系统进行NIDS
- en: 'In this practical example, we will build a NIDS-adopting recommender system
    using **ensemble methods**. Ensemble methods are techniques that combine multiple
    individual models to form a more powerful and accurate predictor. These individual
    models, also known as base models or weak models, can be of any type, such as
    decision trees, support vector machines, or neural networks. By combining the
    predictions of these base models, ensemble methods aim to improve the overall
    performance and generalization ability of the model. There are several popular
    ensemble methods, including the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实际示例中，我们将使用**集成方法**构建采用推荐系统的NIDS。集成方法是结合多个单个模型以形成一个更强大、更准确的预测器的技术。这些单个模型，也称为基础模型或弱模型，可以是任何类型，例如决策树、支持向量机或神经网络。通过结合这些基础模型的预测，集成方法旨在提高模型的整体性能和泛化能力。以下是一些流行的集成方法：
- en: '**Bagging**: Bagging, short for **bootstrap aggregating**, involves training
    multiple base models on different subsets of the training data, with replacement.
    The final prediction is made by averaging or voting the predictions of the individual
    models.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bagging**：Bagging，即**自助聚合**，涉及在不同的训练数据子集上训练多个基础模型，并带有替换。通过平均或投票各个模型的预测来做出最终的预测。'
- en: '**Boosting**: Boosting algorithms train base models sequentially, with each
    subsequent model focusing more on the samples that were previously misclassified.
    The predictions of multiple models are combined using weighted voting or averaging
    to make the final prediction.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Boosting**：Boosting算法按顺序训练基础模型，每个后续模型更关注先前被错误分类的样本。通过加权投票或平均将多个模型的预测组合起来，以做出最终的预测。'
- en: '**Random forest**: Random forest is an ensemble method that amalgamates bagging
    and decision trees. Numerous decision trees, each trained on a random subset of
    the features, are integrated through majority voting to formulate the final prediction.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：随机森林是一种集成方法，它结合了袋装和决策树。通过多数投票将训练在特征随机子集上的多个决策树集成，以形成最终的预测。'
- en: '**Adaptive boosting** (**AdaBoost**): AdaBoost is a boosting algorithm that
    assigns weights to the training samples based on their classification errors.
    Weak models are trained iteratively, with each subsequent model focusing more
    on the misclassified samples. The final prediction is made by combining the predictions
    of multiple models using weighted voting.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自适应提升**（**AdaBoost**）：AdaBoost是一种提升算法，它根据训练样本的分类错误分配权重。弱模型迭代训练，每个后续模型更关注被错误分类的样本。通过加权投票将多个模型的预测组合起来，以做出最终的预测。'
- en: '**Gradient boosting**: Gradient boosting is another boosting algorithm that
    sequentially trains weak models, with each subsequent model minimizing the loss
    function using gradient descent. The predictions of multiple models are combined
    using weighted averaging to make the final prediction.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升**：梯度提升是另一种提升算法，它按顺序训练弱模型，每个后续模型使用梯度下降最小化损失函数。通过加权平均将多个模型的预测组合起来，以做出最终的预测。'
- en: Ensemble methods have proven to be effective in improving the performance and
    robustness of predictive models in various domains, including classification,
    regression, and anomaly detection. They are widely used in machine learning and
    data mining applications.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法已被证明在各种领域（包括分类、回归和异常检测）中提高预测模型的性能和鲁棒性是有效的。它们在机器学习和数据挖掘应用中得到了广泛的使用。
- en: 'As usual, we start by importing the dataset into the MATLAB environment. We
    will use the Network Intrusion Detection dataset, which is available in the Kaggle
    dataset repository ([https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection](https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection)).
    The dataset contains a diverse range of simulated intrusions in a military network
    setting. The objective was to create a realistic environment resembling a US Air
    Force LAN, which was then exposed to multiple attacks. Each connection in this
    environment represents a sequence of TCP packets, with data flowing between a
    source IP address and a target IP address under a predefined protocol. Every connection
    is classified as either normal or as an attack, with a specific attack type assigned
    to it. A connection record contains approximately 100 bytes of data. For each
    TCP/IP connection, a total of 41 features, both quantitative and qualitative,
    are collected from both normal and attack data. These features include three qualitative
    features and 38 quantitative features. The class variable in the dataset has two
    categories – normal and anomalous:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们首先将数据集导入MATLAB环境。我们将使用Kaggle数据集仓库中可用的网络入侵检测数据集（[https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection](https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection)）。该数据集包含在军事网络环境中的多种模拟入侵。目标是创建一个类似于美国空军局域网的现实环境，然后对其进行多次攻击。该环境中的每个连接代表一系列TCP数据包，数据在源IP地址和目标IP地址之间按照预定义的协议流动。每个连接都被分类为正常或攻击，并分配一个特定的攻击类型。连接记录包含大约100字节的数据。对于每个TCP/IP连接，从正常和攻击数据中收集了总共41个特征，包括定量和定性特征。数据集中的类别变量有两个类别——正常和异常：
- en: 'We start by importing the dataset into the MATLAB environment:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将数据集导入MATLAB环境：
- en: '[PRE9]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This function prints a summary of the table, displaying the properties description
    of the variables and some statistics such as min, median, and max for numeric
    features.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个函数会打印出表格的摘要，显示变量的属性描述和一些统计数据，如数值特征的min、median和max。
- en: 'As we did in the *Finding similar users in data* section, we have to split
    the data into two subsets: train and test. We will use the `cvpartition()` function
    for this, as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们在“在数据中找到相似用户”部分所做的那样，我们必须将数据分成两个子集：训练集和测试集。我们将使用`cvpartition()`函数来完成这项工作，如下所示：
- en: '[PRE10]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We began by using the `length()` function to determine the number of observations
    in our dataset. This function gives us the size of the largest dimension in the
    array, `X`, which in the case of vectors represents the total number of elements.
    Next, we utilized the `cvpartition()` function to randomly split the dataset into
    training and test subsets. This partition forms the basis for evaluating a statistical
    model. We extracted the indices for the training and test data using the training
    and test object functions and then used these indices to obtain the respective
    data subsets.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先使用`length()`函数来确定数据集中观察值的数量。这个函数给出了数组`X`中最大维度的尺寸，在向量的情况下，它代表元素的总数。接下来，我们利用`cvpartition()`函数将数据集随机分成训练集和测试集。这个分区是评估统计模型的基础。我们使用训练和测试对象函数提取了训练和测试数据的索引，然后使用这些索引获取相应的数据子集。
- en: 'Now, it’s time to train the algorithm for NDIS. To do this, we will use an
    algorithm based on ensemble methods:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候为NDIS训练算法了。为此，我们将使用基于集成方法的算法：
- en: '[PRE11]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We started by setting the data used for the training and divided the subset
    into predictors and response variables. These terms are used in statistical analysis
    to describe the relationship between independent variables (predictors) and dependent
    variables (response). Predictors are variables that are used to predict, explain,
    or account for the variation in the response variable. They can be continuous
    or categorical and may have various levels or values. The response variable, on
    the other hand, is the outcome or variable that is being predicted or explained
    by the predictors. It is also known as the dependent variable. In our case, it
    is the label of the network intrusion detection classification (anomaly, normal).
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首先设置了用于训练的数据，并将子集划分为预测变量和响应变量。这些术语在统计分析中用于描述自变量（预测变量）和因变量（响应变量）之间的关系。预测变量是用于预测、解释或说明响应变量变化的变量。它们可以是连续的或分类的，并且可能有各种级别或值。另一方面，响应变量是预测变量预测或解释的变量或结果。它也被称为因变量。在我们的案例中，它是网络入侵检测分类（异常、正常）的标签。
- en: 'Now, we can train the model:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以训练模型了：
- en: '[PRE12]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As a classification method, we used `AdaBoostM1`. `AdaBoostM1`, also known as
    adaptive boosting, is a machine learning algorithm that can be used for both classification
    and regression problems. It is particularly effective in handling complex datasets
    and improving weak learning algorithms. The fundamental concept behind `AdaBoostM1`
    is to amalgamate multiple weak classifiers to form a robust classifier. A weak
    classifier is a basic model that performs marginally better than random guessing.
    `AdaBoostM1` accomplishes this by iteratively training weak classifiers on varied
    weighted versions of the dataset. The main idea behind `AdaBoostM1` is to combine
    multiple weak classifiers to create a strong classifier. A weak classifier is
    a simple model that performs slightly better than random guessing. `AdaBoostM1`
    achieves this by iteratively training weak classifiers on different weighted versions
    of the dataset.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作为一种分类方法，我们使用了`AdaBoostM1`。`AdaBoostM1`，也称为自适应增强，是一种可以用于分类和回归问题的机器学习算法。它在处理复杂数据集和改进弱学习算法方面特别有效。`AdaBoostM1`背后的基本概念是将多个弱分类器合并成一个健壮的分类器。弱分类器是一个基本模型，其表现略好于随机猜测。`AdaBoostM1`通过在数据集的不同加权版本上迭代训练弱分类器来实现这一点。`AdaBoostM1`背后的主要思想是将多个弱分类器结合起来创建一个强分类器。弱分类器是一个简单的模型，其表现略好于随机猜测。`AdaBoostM1`通过在数据集的不同加权版本上迭代训练弱分类器来实现这一点。
- en: In each iteration, the algorithm assigns increased weights to instances misclassified
    in the previous iteration. This compels the weak classifiers to prioritize the
    most challenging instances, enhancing their focus on difficult cases. These weighted
    weak classifiers are then combined using a weighted majority voting scheme to
    make final predictions. In classification tasks, the final prediction is obtained
    by assigning a class label based on the weighted majority vote of the weak classifiers.
    In regression tasks, the final prediction is obtained by averaging the weighted
    predictions of the weak classifiers.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在每次迭代中，算法会给前一次迭代中错误分类的实例分配更高的权重。这迫使弱分类器优先考虑最具挑战性的实例，增强它们对困难案例的关注。然后，使用加权多数投票方案将这些加权弱分类器组合起来，以做出最终预测。在分类任务中，最终预测是通过根据弱分类器的加权多数投票分配类标签来获得的。在回归任务中，最终预测是通过平均弱分类器的加权预测来获得的。
- en: '`AdaBoostM1` has several advantages. It is robust to overfitting and can handle
    datasets with many features. It can also handle imbalanced datasets by adjusting
    the weights of the instances. Additionally, `AdaBoostM1` can be easily parallelized,
    making it suitable for distributed computing environments. However, `AdaBoostM1`
    may be sensitive to noisy data and outliers, as it assigns higher weights to misclassified
    instances. It also requires careful selection of weak classifiers, as too complex
    or too weak classifiers may not yield good results. Overall, `AdaBoostM1` is a
    powerful algorithm that has been widely used in many applications, including face
    detection, object recognition, and financial forecasting.'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`AdaBoostM1`具有几个优点。它对过拟合具有鲁棒性，可以处理具有许多特征的集合。它还可以通过调整实例的权重来处理不平衡的数据集。此外，`AdaBoostM1`可以轻松并行化，使其适合分布式计算环境。然而，`AdaBoostM1`可能对噪声数据和异常值敏感，因为它会给错误分类的实例分配更高的权重。它还需要仔细选择弱分类器，因为过于复杂或过于弱的分类器可能不会产生良好的结果。总的来说，`AdaBoostM1`是一个强大的算法，已在许多应用中得到广泛应用，包括人脸检测、物体识别和金融预测。'
- en: 'Let’s take a look at the model that was trained:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看看训练好的模型：
- en: '[PRE13]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Some information about the model is shown in the preceding code.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型的某些信息显示在上面的代码中。
- en: 'After training the algorithm, it is time to evaluate its performance:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练算法后，是时候评估其性能了：
- en: '[PRE14]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `predict()` function was utilized to obtain the expected response values
    generated by the generalized linear regression model. By evaluating the accuracy
    of the model, we can measure how well the predictive model’s predictions align
    with the actual observed values. This assessment serves as a performance indicator
    in accurately forecasting outcomes:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`predict()`函数获取由广义线性回归模型生成的预期响应值。通过评估模型的准确性，我们可以衡量预测模型的预测与实际观察值的一致性。这种评估作为准确预测结果的性能指标：
- en: '[PRE15]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These are amazing results that demonstrate that ensemble methods are very effective
    in classifying network intrusion.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是令人惊叹的结果，证明了集成方法在分类网络入侵方面非常有效。
- en: Embarking on the final frontier of the data science journey, the deployment
    of machine learning models marks the critical phase where theoretical prowess
    transforms into real-world impact. The next section delves into the intricacies
    and best practices of deploying machine learning models, ensuring their seamless
    integration into operational environments.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学之旅的最终前沿，部署机器学习模型标志着理论实力转化为现实影响的临界阶段。下一节将深入探讨部署机器学习模型的复杂性和最佳实践，确保它们无缝集成到运营环境中。
- en: Deploying machine learning models
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署机器学习模型
- en: Deploying machine learning models refers to the process of making a trained
    model available for making predictions on new, unseen data. It involves taking
    the trained model and integrating it into a production environment where it can
    receive input data, perform predictions, and return the results. The trained model
    needs to be organized and packaged into a format suitable for deployment. This
    may involve exporting the model into a file format that can be easily loaded and
    used by other systems. An **application programming interface** (**API**) is typically
    created to expose the machine learning model’s functionality. The API acts as
    the interface that other systems or applications can use to send data and receive
    predictions from the model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 部署机器学习模型是指将训练好的模型用于对新、未见数据做出预测的过程。这涉及到将训练好的模型集成到生产环境中，使其能够接收输入数据、执行预测并返回结果。训练好的模型需要组织并打包成适合部署的格式。这可能涉及到将模型导出为其他系统可以轻松加载和使用的文件格式。通常创建一个**应用程序编程接口**（**API**）来公开机器学习模型的功能。该API作为其他系统或应用程序可以用来向模型发送数据和从模型接收预测的接口。
- en: If the model is expected to handle many concurrent requests, the deployment
    environment may need to be scaled to accommodate the increased load. This may
    involve setting up clusters of servers or using cloud-based infrastructure. Once
    the model has been deployed, it is important to monitor its performance and behavior
    to ensure it continues to provide accurate predictions. Monitoring can involve
    tracking metrics such as response time, throughput, or error rates to identify
    any issues or performance degradation. Machine learning models often need updates
    or retraining as new data becomes available. Therefore, it is important to have
    processes in place for continuous integration and delivery to easily deploy new
    versions of the model and ensure it stays up to date.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型预计要处理许多并发请求，部署环境可能需要扩展以适应增加的负载。这可能涉及到设置服务器集群或使用基于云的基础设施。一旦模型被部署，重要的是要监控其性能和行为，以确保它继续提供准确的预测。监控可能包括跟踪响应时间、吞吐量或错误率等指标，以识别任何问题或性能下降。随着新数据的出现，机器学习模型通常需要更新或重新训练。因此，建立持续集成和交付流程对于轻松部署模型的新版本并确保其保持最新状态非常重要。
- en: Understanding model compression
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解模型压缩
- en: Model compression refers to the process of diminishing the size of a machine
    learning model without significantly compromising its performance. The need for
    model compression arises in scenarios where the size or computational requirements
    of a model become critical, such as when deploying models on resource-constrained
    devices such as smartphones or edge devices.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 模型压缩是指在不显著影响性能的情况下减小机器学习模型大小的过程。在模型的大小或计算需求变得关键的情况下，需要模型压缩，例如在部署到资源受限的设备如智能手机或边缘设备上时。
- en: 'There are several techniques for model compression:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 模型压缩有几种技术：
- en: '**Pruning**: Pruning involves removing unnecessary connections or parameters
    from the model. Typically, connections with small weights are pruned based on
    a certain threshold, resulting in a sparser model with fewer parameters.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剪枝**：剪枝涉及从模型中移除不必要的连接或参数。通常，基于某个阈值，剪除权重较小的连接，从而得到参数更少、更稀疏的模型。'
- en: '**Quantization**: Quantization is the process of reducing the precision of
    the weights and activations in a model. For example, instead of using 32-bit floating-point
    values, weights can be represented using 8-bit integers. This reduces memory requirements
    and improves computational efficiency.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化**：量化是减少模型中权重和激活精度的过程。例如，可以使用8位整数来表示权重，而不是使用32位浮点值。这减少了内存需求并提高了计算效率。'
- en: '**Knowledge distillation**: Knowledge distillation involves training a smaller,
    “student” model to mimic the predictions of a larger, “teacher” model. The teacher
    model’s knowledge is transferred to the student model, allowing for a compact
    representation of the original model while maintaining performance.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识蒸馏**：知识蒸馏涉及训练一个较小的“学生”模型来模仿较大的“教师”模型的预测。教师模型的知识被转移到学生模型，从而在保持性能的同时，以紧凑的形式表示原始模型。'
- en: '**Low-rank approximation**: Low-rank approximation techniques aim to approximate
    the weights of a model using low-rank matrices or tensors. This reduces the number
    of parameters required to represent the model, leading to a smaller memory footprint
    and faster computations.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低秩逼近**：低秩逼近技术旨在使用低秩矩阵或张量逼近模型的权重。这减少了表示模型所需的参数数量，从而减小了内存占用并加快了计算速度。'
- en: '**Compact architectures**: This involves designing or using compact architectures,
    such as MobileNet or SqueezeNet, that are specifically built to be lightweight
    and efficient.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**紧凑架构**：这涉及设计或使用紧凑架构，如 MobileNet 或 SqueezeNet，这些架构专门设计为轻量级和高效。'
- en: These compression techniques enable models to be deployed on devices with limited
    resources or used in scenarios with strict latency or memory constraints. However,
    it is important to consider trade-offs as model compression may lead to slight
    performance degradation in terms of accuracy or inference speed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些压缩技术使模型能够在资源有限的设备上部署或在具有严格延迟或内存约束的场景中使用。然而，考虑权衡是很重要的，因为模型压缩可能会导致准确性或推理速度的轻微性能下降。
- en: Discovering model pruning techniques
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现模型剪枝技术
- en: Model pruning is a machine learning technique that aims to decrease the size
    and complexity of a trained model by eliminating unnecessary or redundant parameters,
    connections, or nodes. The objective of model pruning is to enhance the efficiency
    and computational performance of the model without significantly compromising
    accuracy.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 模型剪枝是一种机器学习技术，旨在通过消除不必要的或冗余的参数、连接或节点来减小训练模型的尺寸和复杂性。模型剪枝的目的是在不显著降低准确性的情况下提高模型的效率和计算性能。
- en: 'There are several methods of model pruning, including the following:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 模型剪枝有几种方法，包括以下几种：
- en: '**Weight pruning**: In weight pruning, individual weights in the model are
    set to zero or removed entirely based on their magnitude. This reduces the number
    of parameters and can result in a sparser model.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**权重剪枝**：在权重剪枝中，根据其幅度将模型中的单个权重设置为零或完全移除。这减少了参数数量，可以导致模型更稀疏。'
- en: '**Neuron pruning**: Neuron pruning entails the removal of entire neurons from
    the model, guided by their contribution to the overall performance. Neurons with
    low activation or minimal impact on the output are pruned.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经元剪枝**：神经元剪枝涉及根据其对整体性能的贡献从模型中移除整个神经元。具有低激活或对输出影响最小的神经元被剪枝。'
- en: '**Filter pruning**: This technique is commonly used in **convolutional neural
    networks** (**CNNs**). Filters are groups of feature detectors that are applied
    across an image during the convolution operation. Filter pruning involves removing
    unnecessary filters that do not contribute significantly to the model’s accuracy.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滤波器剪枝**：这种技术在**卷积神经网络**（**CNNs**）中常用。滤波器是一组特征检测器，在卷积操作期间应用于图像。滤波器剪枝涉及移除对模型准确性贡献不大的不必要滤波器。'
- en: '**Structured pruning**: Structured pruning involves removing entire layers
    or blocks of the model, rather than individual weights or neurons. This method
    often results in more efficient implementations since removing entire layers reduces
    both computational complexity and memory requirements.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化剪枝**：结构化剪枝涉及移除整个层或模型块，而不是单个权重或神经元。这种方法通常会导致更高效的实现，因为移除整个层可以减少计算复杂性和内存需求。'
- en: Model pruning can be performed during training or as a post-training optimization
    step. It is often combined with other techniques such as regularization methods
    or quantization to further improve the efficiency of the pruned model. Pruning
    can provide significant benefits in terms of model size, speed, and memory usage,
    making it a useful technique for deploying models on resource-constrained devices
    or in real-time applications.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 模型剪枝可以在训练期间或作为训练后的优化步骤执行。它通常与其他技术（如正则化方法或量化）结合使用，以进一步提高剪枝模型的效率。剪枝可以在模型大小、速度和内存使用方面提供显著的好处，使其成为在资源受限设备或实时应用中部署模型的有用技术。
- en: 'In MATLAB, you can perform model pruning using various techniques and tools
    such as Neural Network Toolbox. The following steps outline a general approach
    to model pruning in MATLAB:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MATLAB 中，您可以使用各种技术和工具（如神经网络工具箱）执行模型剪枝。以下步骤概述了在 MATLAB 中进行模型剪枝的一般方法：
- en: Load or create your initial neural network model using Neural Network Toolbox
    in MATLAB.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 MATLAB 中的神经网络工具箱加载或创建您的初始神经网络模型。
- en: Train the neural network model to achieve a reasonably good performance on a
    given task or dataset.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练神经网络模型以在给定的任务或数据集上实现合理良好的性能。
- en: Use the pruning algorithm or technique of your choice to identify and remove
    unnecessary weights, connections, or nodes from the trained model. Some commonly
    used pruning techniques include magnitude-based pruning, sensitivity-based pruning,
    and weight-decay pruning.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您选择的剪枝算法或技术来识别和从训练模型中移除不必要的权重、连接或节点。常用的剪枝技术包括基于幅度的剪枝、基于敏感度的剪枝和权重衰减剪枝。
- en: Evaluate the pruned model’s performance by testing it on a validation or test
    dataset. Make sure that the pruning process does not significantly degrade the
    model’s performance.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在验证或测试数据集上测试来评估剪枝模型的表现。确保剪枝过程不会显著降低模型的表现。
- en: Fine-tune or retrain the pruned model, if necessary, to recover any performance
    degradation due to pruning. Adjust the learning rate or other training parameters
    to optimize the pruned model’s performance.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果由于剪枝导致性能下降，则对剪枝模型进行微调或重新训练以恢复任何性能下降。调整学习率或其他训练参数以优化剪枝模型的表现。
- en: Repeat *s**teps 3* to *5* until the desired level of model compression or performance
    trade-off is achieved.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤3到5，直到达到所需的模型压缩或性能权衡水平。
- en: Remember that model pruning is a dynamic and iterative process, and it requires
    careful consideration of the trade-off between model size, performance, and computational
    requirements.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，模型剪枝是一个动态和迭代的过程，需要仔细考虑模型大小、性能和计算需求之间的权衡。
- en: Introducing quantization for efficient inference on edge devices
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果需要，引入量化以在边缘设备上进行高效的推理
- en: Quantization is a technique that’s used in model compression to reduce the memory
    footprint and computational requirements of deep neural networks. It involves
    converting the weights and activations of a network from floating-point representation
    into lower precision representation, such as 8-bit or even lower.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 量化是一种用于模型压缩的技术，用于减少深度神经网络的内存占用和计算需求。它涉及将网络的权重和激活从浮点表示转换为较低精度的表示，如8位甚至更低。
- en: Quantization reduces the precision of the model, which can lead to a loss in
    model accuracy. However, it has been observed that many neural networks are robust
    to quantization and can still achieve similar performance with reduced precision
    representation. This is especially true for deep neural networks with large numbers
    of parameters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 量化会降低模型的精度，这可能导致模型精度的损失。然而，观察到许多神经网络对量化具有鲁棒性，并且仍然可以用降低精度的表示实现相似的性能。这对于具有大量参数的深度神经网络尤其如此。
- en: 'There are different approaches to quantization in model compression:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型压缩中，量化有不同的方法：
- en: '**Weight-only quantization**: In this approach, only the weights of the neural
    network are quantized, while the activations remain in the original precision.
    This reduces the memory requirements significantly as weights typically consume
    the majority of the memory in a neural network.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅权重量化**：在这种方法中，仅对神经网络的权重进行量化，而激活保持原始精度。这显著降低了内存需求，因为权重通常在神经网络中消耗大部分内存。'
- en: '**Full quantization**: In this approach, both the weights and activations are
    quantized to lower precision. This provides further reduction in memory requirements
    and computational complexity but can result in a larger loss in model accuracy
    compared to weight-only quantization.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全量化**：在这种方法中，权重和激活都量化为较低的精度。这进一步降低了内存需求和计算复杂性，但与仅权重量化相比，可能导致模型精度更大的损失。'
- en: '**Dynamic quantization**: Dynamic quantization techniques adaptively adjust
    the precision of weights and activations during inference based on the input data.
    This allows for more flexibility in the precision used, leading to potential accuracy
    improvements compared to static quantization.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态量化**：动态量化技术根据输入数据自适应地调整推理过程中的权重和激活的精度。这允许在精度使用上具有更大的灵活性，与静态量化相比，可能导致精度改进。'
- en: '**Quantization-aware training**: Instead of quantizing the model after training,
    quantization-aware training incorporates the quantization process during the training
    phase itself. This ensures that the model learns to be robust to quantization
    and results in better accuracy when quantized.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化感知训练**：不是在训练后量化模型，而是量化感知训练在训练阶段本身结合量化过程。这确保了模型学会对量化具有鲁棒性，并在量化时实现更好的精度。'
- en: Quantization is a widely used technique in model compression and is particularly
    useful when deploying deep neural networks on resource-constrained devices such
    as edge devices or mobile phones. It allows for efficient deployment of models
    with reduced memory requirements and improved computational efficiency, without
    sacrificing significant model accuracy.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 量化是一种在模型压缩中广泛使用的技巧，尤其在部署到资源受限的设备（如边缘设备或手机）上的深度神经网络时特别有用。它允许以减少内存需求和提高计算效率的方式高效部署模型，而不会牺牲模型精度。
- en: Getting started with knowledge distillation
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识蒸馏入门
- en: Knowledge distillation is a technique that’s used in model compression that
    refers to the process of reducing the size and complexity of a machine learning
    model without significant loss in performance. In knowledge distillation, a large
    “teacher” model is trained on a dataset and used as a reference to train a smaller
    “student” model. The goal is to transfer the knowledge, or the learned representations,
    from the teacher model to the student model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏是一种在模型压缩中使用的技巧，它指的是减少机器学习模型的大小和复杂度，同时不会在性能上造成重大损失的过程。在知识蒸馏中，一个大的“教师”模型在数据集上训练，并用作参考来训练一个较小的“学生”模型。目标是转移知识，或学习到的表示，从教师模型到学生模型。
- en: Knowledge transfer is achieved by training the student model to mimic the outputs
    of the teacher model. Typically, this involves using the teacher model’s soft
    targets or logits instead of the hard labels during training. Soft targets refer
    to the probabilities assigned to each class by the teacher model, which can provide
    more nuanced information compared to the one-hot encoded hard labels.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 知识迁移是通过训练学生模型来模仿教师模型的输出实现的。通常，这涉及到在训练过程中使用教师模型的软目标或logits，而不是使用硬标签。软目标是指教师模型为每个类别分配的概率，与one-hot编码的硬标签相比，可以提供更细致的信息。
- en: During the training process, the student model tries to minimize the difference
    between its predictions and the soft targets provided by the teacher model. This
    enables the student model to learn from the richer information provided by the
    teacher, improving its understanding of the data and increasing its performance.
    Knowledge distillation can lead to significant model compression as the smaller
    student model can capture the knowledge of the larger teacher model, often with
    fewer parameters. Additionally, the student model can be more efficient in terms
    of inference time and resource usage, making it suitable for deployment on resource-constrained
    platforms.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，学生模型试图最小化其预测与教师模型提供的软目标之间的差异。这使得学生模型能够从教师提供的更丰富信息中学习，提高其对数据的理解并提高其性能。知识蒸馏可以实现显著的模型压缩，因为较小的学生模型可以捕获较大教师模型的知识，通常参数更少。此外，学生模型在推理时间和资源使用方面可以更高效，使其适合在资源受限的平台部署。
- en: In summary, knowledge distillation is a technique that’s used in model compression
    to transfer knowledge from a larger teacher model to a smaller student model,
    thereby compressing the model size while maintaining performance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，知识蒸馏是一种在模型压缩中使用的技巧，用于将较大教师模型的知识转移到较小学生模型，从而在保持性能的同时压缩模型大小。
- en: Learning low-rank approximation
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习低秩近似
- en: Low-rank approximation is a technique that’s used in model compression to reduce
    the size of a given model. It involves approximating a high-dimensional weight
    matrix or tensor by a lower-rank approximation, which significantly reduces the
    number of parameters needed to represent the model. In low-rank approximation,
    a factorization of the weight matrix is performed to decompose it into two or
    more smaller matrices or tensors. The rank of the approximation determines the
    number of smaller matrices or tensors used. By choosing a lower rank, the resulting
    approximation will have fewer parameters, making it more compact and efficient.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩近似是一种在模型压缩中使用的技巧，用于减小给定模型的大小。它涉及到通过低秩近似来近似高维权重矩阵或张量，这显著减少了表示模型所需的参数数量。在低秩近似中，对权重矩阵进行分解，将其分解为两个或更多较小的矩阵或张量。近似的秩决定了使用的较小矩阵或张量的数量。通过选择较低的秩，得到的近似将具有更少的参数，使其更紧凑和高效。
- en: Low-rank approximation can be applied to various types of models, including
    neural networks, deep learning models, and other machine learning algorithms.
    It is especially useful for reducing the computational and memory requirements
    of large models. This enables their deployment on resource-constrained devices,
    such as mobile phones or embedded systems. One common approach for low-rank approximation
    is **singular value decomposition** (**SVD**), which decomposes a matrix into
    three matrices representing the left singular vectors, singular values, and right
    singular vectors. Selecting a subset of the singular values and their corresponding
    singular vectors allows for the creation of a low-rank approximation.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩近似可以应用于各种类型的模型，包括神经网络、深度学习模型和其他机器学习算法。它特别适用于减少大型模型的计算和内存需求。这使得它们可以在资源受限的设备上部署，例如移动电话或嵌入式系统。低秩近似的一种常见方法是**奇异值分解**（**SVD**），它将矩阵分解为三个矩阵，分别代表左奇异向量、奇异值和右奇异向量。选择奇异值及其对应的奇异向量子集，可以创建低秩近似。
- en: Other techniques for low-rank approximation include Tucker decomposition, which
    decomposes a tensor into smaller tensors, and tensor-train decomposition, which
    represents a tensor as a series of matrix products. These techniques can be applied
    to higher-order tensors typically found in deep learning models.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩近似的其他技术包括Tucker分解，它将张量分解为较小的张量，以及张量-训练分解，它将张量表示为一系列矩阵乘积。这些技术可以应用于深度学习模型中通常发现的更高阶张量。
- en: Overall, low-rank approximation is a powerful technique for model compression,
    enabling the reduction of model size without sacrificing too much performance.
    It allows for the efficient deployment of models on resource-constrained devices
    and faster inference times.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，低秩近似是模型压缩的一种强大技术，能够在不牺牲太多性能的情况下减少模型大小。它允许在资源受限的设备上高效部署模型，并加快推理时间。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we learned the basic concepts of recommender systems, starting
    with the definition of these systems and then understanding how the problem is
    approached. We analyzed the different types of recommender systems: CF, content-based
    filtering, and hybrid recommender systems.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了推荐系统的基本概念，从这些系统的定义开始，然后了解如何解决这个问题。我们分析了不同类型的推荐系统：协同过滤（CF）、基于内容的过滤和混合推荐系统。
- en: Next, we saw how to use similarities in the data to identify possible fraudulent
    uses of credit cards. To do this, we trained a model based on the nearest neighbor
    algorithm but using a modified version of the traditional k-NN algorithm, where
    neighbors are given varying weights during the prediction or classification process.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看到了如何利用数据中的相似性来识别可能的信用卡欺诈使用。为此，我们基于最近邻算法训练了一个模型，但使用了一种修改后的传统k-NN算法，在预测或分类过程中给邻居分配不同的权重。
- en: Then, we saw how to implement a NIDS based on ensemble methods in MATLAB. Specifically,
    we adopted an AdaBoost algorithm to identify intrusions in a LAN network.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们看到了如何在MATLAB中实现基于集成方法的NIDS。具体来说，我们采用AdaBoost算法来识别局域网网络中的入侵行为。
- en: Finally, we introduced the techniques of deploying machine learning models regarding
    model compression. We analyzed the most popular model compression techniques,
    including pruning, quantization, knowledge distillation, and low-rank approximation.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了关于模型压缩的机器学习模型部署技术。我们分析了最流行的模型压缩技术，包括剪枝、量化、知识蒸馏和低秩近似。
- en: In the next chapter, we will learn the basic concepts of anomaly detection and
    fault diagnosis systems. We will understand how to identify anomaly functioning
    using deep learning, as well as how to implement a fault diagnosis system in MATLAB.
    Finally, we will discover dropout, L1 and L2 regularization, and early stopping.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习异常检测和故障诊断系统的基本概念。我们将了解如何使用深度学习来识别异常行为，以及如何在MATLAB中实现故障诊断系统。最后，我们将探讨dropout、L1和L2正则化以及提前停止。
