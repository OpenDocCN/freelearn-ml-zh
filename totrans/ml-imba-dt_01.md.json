["```py\npip3 install imbalanced-learn==0.11.0\n```", "```py\nfrom sklearn.datasets import make_classification\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef make_data(sep):\n    X, y = make_classification(n_samples=50000,\n        n_features=2, n_redundant=0,\n        n_clusters_per_class=1, weights=[0.995],\n        class_sep=sep, random_state=1)\n    X = pd.DataFrame(X, columns=['feature_1', 'feature_2'])\n    y = pd.Series(y)\n    return X, y\n```", "```py\nfrom collections import Counter\nX, y = make_data(sep=2)\nprint(y.value_counts())\nsns.scatterplot(data=X, x=\"feature_1\", y=\"feature_2\", hue=y)\nplt.title('Separation: {}'.format(separation))\nplt.show()\n```", "```py\n0     49498\n1       502\n```", "```py\nFrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = \\\n    y, test_size=0.2, random_state=42)\nprint('train data: ', Counter(y_train))\nprint('test data: ', Counter(y_test))\n```", "```py\ntrain data:  Counter({0: 39598, 1: 402})\ntest data:  Counter({0: 9900, 1: 100})\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=0, max_iter=2000)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n```", "```py\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))\n```", "```py\n          precision     recall      f1-score    support\n0         0.99          1.00        1.00        9900\n1         0.94          0.17        0.29        100\naccuracy                                0.99      10000\nmacro avg       0.97        0.58        0.64      10000\nweighted avg    0.99        0.99        0.99      10000\n```", "```py\nfrom imblearn.metrics import classification_report_imbalanced\nprint(classification_report_imbalanced(y_test, y_pred))\n```"]