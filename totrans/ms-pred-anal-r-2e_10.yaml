- en: Chapter 10. Probabilistic Graphical Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probabilistic graphical models, or simply graphical models as we will refer
    to them in this chapter, are models that use the representation of a graph to
    describe the conditional independence relationships between a series of random
    variables. This topic has received an increasing amount of attention in recent
    years and probabilistic graphical models have been successfully applied to tasks
    ranging from medical diagnosis to image segmentation. In this chapter, we'll present
    some of the necessary background that will pave the way to understanding the most
    basic graphical model, the Naïve Bayes classifier. We will then look at a slightly
    more complicated graphical model, known as the **Hidden Markov Model** (**HMM**).
    To get started in this field, we must first learn about graphs and why they are
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: A little graph theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Graph theory is a branch of mathematics that deals with mathematical objects
    known as **graphs**. Here, a graph does not have the everyday meaning that we
    are more used to talking about, in the sense of a diagram or plot with an *x*
    and *y* axis. In graph theory, a graph consists of two sets. The first is a set
    of vertices, which are also referred to as **nodes**. We typically use integers
    to label and enumerate the vertices. The second set consists of **edges** between
    these vertices.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, a graph is nothing more than a description of some points and the connections
    between them. The connections can have a direction so that an edge goes from the
    **source** or **tail vertex** to the **target** or **head vertex**. In this case,
    we have a **directed graph**. Alternatively, the edges can have no direction,
    so that the graph is **undirected**.
  prefs: []
  type: TYPE_NORMAL
- en: A common way to describe a graph is via the **adjacency matrix**. If we have
    *V* vertices in the graph, an adjacency matrix is a *V×V* matrix whose entries
    are 0 if the vertex represented by the row number is not connected to the vertex
    represented by the column number. If there is a connection, the entry is 1 (however,
    when you are using weighted graphs, the entry value is not always 1).
  prefs: []
  type: TYPE_NORMAL
- en: 'With undirected graphs, both nodes at each edge are connected to each other
    so the adjacency matrix is symmetric. For directed graphs, a vertex *v[i]* is
    connected to a vertex *v[j]* via an edge (*v[i]*,*v[j]*); that is, an edge where
    *v[i]* is the tail and *v[j]* is the head. Here is an example adjacency matrix
    for a graph with seven nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This matrix is not symmetric, so we know that we are dealing with a directed
    graph. The first `1` value in the first row of the matrix denotes the fact that
    there is an edge starting from vertex 1 and ending on vertex 6\. When the number
    of nodes is small, it is easy to visualize a graph. We simply draw circles to
    represent the vertices and lines between them to represent the edges.
  prefs: []
  type: TYPE_NORMAL
- en: 'For directed graphs, we use arrows on the lines to denote the directions of
    the edges. It is important to note that we can draw the same graph in an infinite
    number of different ways on the page. This is because the graph tells us nothing
    about the positioning of the nodes in space; we only care about how they are connected
    to each other. Here are two different, but equally valid, ways to draw the graph
    described by the adjacency matrix we just saw:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A little graph theory](img/00167.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Two vertices are said to be connected with each other if there is an edge between
    them (taking note of the order when talking about directed graphs). If we can
    move from vertex *v[i]* to vertex *v[j]* by starting at the first vertex and finishing
    at the second vertex, by moving on the graph along the edges and passing through
    an arbitrary number of graph vertices, then these intermediate edges form a **path**
    between these two vertices. Note that this definition requires that all the vertices
    and edges along the path are distinct from each other (with the possible exception
    of the first and last vertex).
  prefs: []
  type: TYPE_NORMAL
- en: For example, in our graph, vertex 6 can be reached from vertex 2 by a path leading
    through vertex 1\. Sometimes, there can be many such possible paths through the
    graph, and we are often interested in the shortest path, which moves through the
    fewest number of intermediary vertices. We can define the distance between two
    nodes in the graph as the length of the shortest path between them. A path that
    begins and ends at the same vertex is known as a **cycle**. A graph that does
    not have any cycles in it is known as an **acyclic graph**. If an acyclic graph
    has directed edges, it is known as a **directed acyclic graph**, which is often
    abbreviated to **DAG**.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many excellent references on graph theory available. One such reference
    that is available online is *Graph Theory*, *Reinhard Diestel*, *Springer*. This
    landmark reference is now in its *4th* edition and can be found at [http://diestel-graph-theory.com/](http://diestel-graph-theory.com/).
  prefs: []
  type: TYPE_NORMAL
- en: It might not seem obvious at first, but it turns out that a large number of
    real-world situations can be conveniently described using graphs. For example,
    the network of friendships on social media sites, such as Facebook, or followers
    on Twitter, can be represented as graphs. On Facebook, the friendship relation
    is reciprocal, and so the graph is undirected. On Twitter, the follower relation
    is not, and so the graph is directed.
  prefs: []
  type: TYPE_NORMAL
- en: Another graph is the network of websites on the web, where links from one web
    page to the next form directed edges. Transport networks, communication networks,
    and electricity grids can be represented as graphs. For the predictive modeler,
    it turns out that a special class of models known as **probabilistic graphical
    models**, or **graphical models** for short, are models that involve a graph structure.
  prefs: []
  type: TYPE_NORMAL
- en: In a graphical model, the nodes represent random variables and the edges in
    between represent the dependencies between them. Before we can go into further
    detail, we'll need to take a short detour in order to visit Bayes' theorem, a
    classic theorem in statistics that, despite its simplicity, has implications both
    profound and practical when it comes to statistical inference and prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes' theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Suppose we are interested in two events, *A* and *B*. In this case, event *A*
    might represent the event that a patient has appendicitis and event *B* might
    represent a patient having a high white blood cell count. The **conditional probability**
    of event *A* given event *B* is essentially the probability that event *A* will
    occur when we know that event *B* has already happened.
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally, we define the conditional probability of event *A* given event *B*
    as the joint probability of both events occurring divided by the probability of
    event *B* occurring:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayes'' theorem](img/00168.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that this is consistent with the way in which we define statistical independence.
    Statistical independence occurs when the joint probability of two events occurring
    is just the product of the individual probabilities of the two events. If we substitute
    this in our previous equation, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayes'' theorem](img/00169.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This makes sense intuitively because if we know that two events are independent
    of each other, knowing that event *B* has occurred does not change the probability
    of event *A* occurring. Now, we can rearrange our equation for conditional probability
    as follows, and note that we can switch over events *A* and *B* to get an alternative
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayes'' theorem](img/00170.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This last step allows us to state Bayes'' theorem in its simplest form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayes'' theorem](img/00171.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous equation, *P(A)* is referred to as the **prior probability**
    of event *A*, as it represents the probability of event *A* occurring prior to
    any new information. *P(A|B)*, which is the conditional probability of event *A*
    given that event *B* has occurred, is often also referred to as the **posterior
    probability** of *A*. It is the probability of event *A* occurring after receiving
    some new information; in this case, the fact that event *B* has occurred.
  prefs: []
  type: TYPE_NORMAL
- en: All of this might seem like algebraic trickery, but if we revisit our example
    of event *A* representing a patient having appendicitis and event *B* representing
    a patient having a high white blood cell count, the usefulness of Bayes' theorem
    will be revealed. Knowing *P(A|B)*, the conditional probability of having appendicitis,
    given that we observe that a patient has a high white blood cell count (and similarly
    for other symptoms), is knowledge that would be very useful to doctors. This would
    allow them to make a diagnosis about something that isn't easily observable (appendicitis)
    using something that is (high white blood cell count).
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this is something that is very hard to estimate because a high
    white blood cell count might occur as a symptom of a host of other diseases or
    pathologies. The reverse probability, *P(B|A)*, however (namely, the conditional
    probability of having a high white blood cell count given that a patient already
    has appendicitis), is much easier to estimate. One simply needs to examine records
    of past cases with appendicitis and inspect the blood tests of those cases. Bayes'
    theorem is a fundamental boon to predictive modeling because it allows us to estimate
    cause by observing effect.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional independence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We know from statistics that the notion of statistical independence says that
    the joint probability of two random variables, *A* and *B*, is just the product
    of their (marginal) probabilities. Sometimes, two variables may not be statistically
    independent of each other to begin with, but observing a third variable, *C*,
    might result in them becoming independent of each other. In short, we say that
    events *A* and *B* are **conditionally independent** given *C*, and we can express
    this as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Conditional independence](img/00172.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'For example, suppose that *J* represents the probability of being given a job
    offer at a particular company and *G* represents the probability of being accepted
    into graduate school at a particular university. Both of these might depend on
    a variable *U*, a person''s performance on their undergraduate degree. This can
    be summarized in a graph as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Conditional independence](img/00173.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When we don't know *U*, a person's performance on their undergraduate degree,
    knowing that they were accepted into graduate school might increase our belief
    in their chances of getting a job and vice versa. This is because we are inclined
    to believe that they did well in their undergraduate degree, which influences
    that person's chances of getting a job. Thus, the two events *J* and *G* are not
    independent of each other.
  prefs: []
  type: TYPE_NORMAL
- en: If we are told the performance of a person on their undergraduate degree, however,
    we might assume that the person's chance of getting a job offer might be independent
    of their chance of getting into graduate school. This is because of other factors
    that might affect this, such as the person's job interview on a particular day
    or the quality of other potential candidates for the job, which are not influenced
    by the person's application to graduate school.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian networks** are a type of graphical model that involve a directed
    acyclic graph structure. We often refer to the tail node of a directed edge in
    a graphical model as the **parent** and the head node as the **child** or **descendant**.
    In fact, we generalize this latter notion so that, if there is a path from node
    *A* to node *B* in the model, node *B* is a descendant of node *A*. We can distinguish
    the special case of node *A* connected to node *B* by saying that the latter is
    a **direct descendant**.'
  prefs: []
  type: TYPE_NORMAL
- en: The parent relationship and the descendant relationship are mutually exclusive
    in a Bayesian network because it has no cycles. Bayesian networks have the distinguishing
    property that, given its parents, every node in the network is conditionally independent
    of all other nodes in the network that are not its descendants. This is sometimes
    referred to as the **local Markov property**. It is an important property because
    it means that we can easily factorize the joint probability function of all the
    random variables in the model by simply taking note of the edges in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how this works, we will begin with the product rule of probability
    for three variables that says the following (taking *G*, *J*, and *U* as example
    variables):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayesian networks](img/00174.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This rule is a general rule and always holds without any loss of generality.
    Let''s return to our student applicant example. This is actually a simple Bayesian
    network where *G* and *J* have *U* as a parent. Using the local Markov property
    of Bayesian networks, we can simplify the equation for the joint probability distribution
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayesian networks](img/00175.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The ability to factorize a probability distribution in this way is useful as
    it simplifies the computations we need to make. It can also allow us to represent
    the entire distribution in a more compact form. Suppose that the distribution
    of each random variable is discrete and takes on a finite set of values, for example,
    random variables *G* and *J* could each take on the two discrete values {yes,
    no}. To store a joint probability distribution without factorizing, and taking
    into account independence relations, we need to consider all possible combinations
    of every random variable.
  prefs: []
  type: TYPE_NORMAL
- en: By contrast, if the distribution factorizes into a product of simpler distributions
    as we saw earlier, the total number of random variable combinations we need to
    consider are far fewer. For networks with several random variables that take on
    many values, the savings are very substantial indeed.
  prefs: []
  type: TYPE_NORMAL
- en: Besides computation and storage, another significant benefit is that when we
    want to determine the joint probability distribution of our random variables given
    some data, it becomes much simpler to do so when we can factorize it because of
    known independence relations. We will see this in detail when, in the next section,
    we study an important example of a Bayesian network.
  prefs: []
  type: TYPE_NORMAL
- en: 'To wrap up this section, we''ll note the factorization of the joint probability
    function of the Bayesian network, represented by the graph we saw in the first
    diagram in this chapter, and leave it as an exercise for the reader to verify:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bayesian networks](img/00176.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The Naïve Bayes classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We now have the necessary tools to learn about our first and simplest graphical
    model, the **Naïve Bayes classifier**. This is a directed graphical model that
    contains a single parent node and a series of child nodes representing random
    variables that are dependent only on this node with no dependencies between them.
    Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Naïve Bayes classifier](img/00177.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We usually interpret our single parent node as the causal node, so in our particular
    example, the value of the *Sentiment* node will influence the value of the *sad*
    node, the *fun* node, and so on. As this is a Bayesian network, the local Markov
    property can be used to explain the core assumption of the model. Given the *Sentiment*
    node, all other nodes are independent of each other.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we use the Naïve Bayes classifier in a context where we can observe
    and measure the child nodes and attempt to estimate the parent node as our output.
    Thus, the child nodes will be the input features of our model, and the parent
    node will be the output variable. For example, the child nodes may represent various
    medical symptoms and the parent node might be whether a particular disease is
    present.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how the model works in practice, we make recourse to Bayes''
    theorem, where *C* is the parent node and *F[i]* are the children or feature nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Naïve Bayes classifier](img/00178.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can simplify this using the conditional independence assumptions of the
    network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Naïve Bayes classifier](img/00179.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To make a classifier out of this probability model, our objective is to choose
    the class *C[i]* which maximizes the posterior probability *P(Ci|F[1]* *…F[n]*
    *)*; that is, the posterior probability of that class given the observed features.
    The denominator is the joint probability of the observed features, which is not
    influenced by the class that is chosen. Consequently, maximizing the posterior
    class probability amounts to maximizing the numerator of the previous equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Naïve Bayes classifier](img/00180.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Given some data, we can estimate the probabilities, *P(F[i]* *|C[j]* *)*, for
    all the different values of the feature *F[i]* as the relative proportion of the
    observations of class *C[j]* that have each different value of feature *F[i]*.
    We can also estimate *P(C[j]* *)* as the relative proportion of the observations
    that are assigned to class *C[j]*. These are the maximum likelihood estimates.
    In the next section, we will see how the Naïve Bayes classifier works in a real
    example.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the sentiment of movie reviews
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a world of online reviews, forums, and social media, a task that has received,
    and continues to receive, a growing amount of interest is the task of **sentiment
    analysis**. Put simply, the task is to analyze a piece of text to determine the
    sentiment that is being expressed by the author. A typical scenario involves collecting
    online reviews, blog posts, or tweets and building a model that predicts whether
    the user is trying to express a positive or a negative feeling. Sometimes, the
    task can be framed to capture a wider variety of sentiments, such as a neutral
    sentiment or the degree of sentiment, such as mildly negative versus very negative.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will limit ourselves to the simpler task of discerning positive
    from negative sentiments. We will do this by modeling sentiment using a similar
    Bayesian network to the one that we saw in the previous section. The sentiment
    is our target output variable, which is either positive or negative. Our input
    features are all binary features that describe whether a particular word is present
    in a movie review. The key idea here is that users expressing a negative sentiment
    will tend to choose from a characteristic set of words in their review that is
    different from the characteristic set that users would pick from when writing
    a positive review.
  prefs: []
  type: TYPE_NORMAL
- en: By using the Naïve Bayes model, our assumption will be that if we know the sentiment
    being expressed, the presence of each word in the text is independent from all
    the other words. Of course, this is a very strict assumption to use and doesn't
    speak at all to the process of how real text is written. Nonetheless, we will
    show that even under these strict assumptions, we can build a model that performs
    reasonably well.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the *Large Movie Review Data Set*, first presented in the paper
    titled *Learning Word Vectors for Sentiment Analysis*, *Andrew L. Maas*, *Raymond
    E. Daly*, *Peter T. Pham*, *Dan Huang*, *Andrew Y. Ng*, and *Christopher Potts*,
    published in *The 49th Annual Meeting of the Association for Computational Linguistics*
    (*ACL 2011*). The data is hosted at [http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)
    and is comprised of a training set of 25,000 movie reviews and a test set of another
    25,000 movie reviews.
  prefs: []
  type: TYPE_NORMAL
- en: In order to demonstrate how the model works, we would like to keep the training
    time of our model low. For this reason, we are going to partition the original
    training set into a new training and test set, but the reader is very strongly
    encouraged to repeat the exercise with the larger test dataset that is part of
    the original data. When downloaded, the data is organized into a `train` folder
    and a `test` folder. The `train` folder contains a folder called `pos` that has
    12,500 positive movie reviews, each inside a separate text file, and similarly,
    a folder called `neg` with 12,500 negative movie reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Our first task is to load all this information into R and perform some necessary
    preprocessing. To do this, we are going to install and use the `tm` package, which
    is a specialized package for performing text-mining operations. This package is
    very useful when working with text data and we will use it again in a subsequent
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: When working with the `tm` package, the first task is to organize the various
    sources of text into a **corpus**. In linguistics, this commonly refers to a collection
    of documents. In the `tm` package, it is just a collection of strings representing
    individual sources of text, along with some metadata that describes some information
    about them, such as the names of the files from which they were retrieved.
  prefs: []
  type: TYPE_NORMAL
- en: With the `tm` package, we build a corpus using the `Corpus()` function, to which
    we must provide a source for the various documents we want to import. We could
    create a vector of strings and pass this as an argument to `Corpus()` using the
    `VectorSource()` function. Instead, as our data source is a series of text files
    in a directory, we will use the `DirSource()` function. First, we will create
    two string variables that will contain the absolute paths to the aforementioned
    `neg` and `pos` folders on our machine (this will depend on where the dataset
    is downloaded).
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we can use the `Corpus()` function twice to create two corpora for positive
    and negative reviews, which will then be merged into a single corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The second argument to the `Corpus()` function, `readerControl`, is a list of
    optional parameters. We used this to specify that the language of our text files
    is English. The `recursive` parameter in the `c()` function used to merge the
    two corpora is necessary to maintain the metadata information stored in the corpus
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we can merge the two corpora without actually losing the sentiment
    label. Each text file representing a movie review is named using the format `<counter>_<score>.txt`,
    and this information is stored in the metadata portion of the corpus object created
    by the `Corpus()` function. We can see the metadata for the first review in our
    corpus using the `meta()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `meta()` function thus retrieves a metadata object for each entry in our
    corpus. The `ID` attribute in this object contains the name of the file. The score
    part of the name is a number between 0 and 10, where higher numbers denote positive
    reviews, and low numbers denote negative reviews. In the training data, we only
    have polar reviews; that is, reviews that are in the ranges 0-4 and 7-10\. We
    can thus use this information to create a vector of document names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'From this list of document names, we''ll extract the score component using
    the `sub()` function with an appropriate regular expression. If the score of a
    movie review is less than or equal to 5, it is a negative review and if it is
    greater, it is a positive review:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `sub()` function is just one of R's functions that uses regular expressions.
    For readers unfamiliar with the concept, a regular expression is essentially a
    pattern language for describing strings. Online tutorials for regular expressions
    are easy to find. An excellent resource for learning about regular expressions'
    as well as text processing more generally, is *Speech and Language Processing
    Second Edition*, *Jurafsky and Martin*.
  prefs: []
  type: TYPE_NORMAL
- en: The features of our model will be binary features that describe the presence
    or absence of specific words in the dictionary. Intuitively, we should expect
    that a movie review containing words such as *boring*, *cliché*, and *horrible*
    is likely to be a negative review. A movie review with words such as *inspiring*,
    *enjoyable*, *moving*, and *excellent* is likely to be a good review.
  prefs: []
  type: TYPE_NORMAL
- en: When working with text data, we almost always need to perform a series of preprocessing
    steps. For example, we tend to convert all the words to a lowercase format because
    we don't want to have two separate features for the words *Excellent* and *excellent*.
    We also want to remove anything from our text that will likely be uninformative
    as features. For this reason, we tend to remove punctuation, numbers, and **stop
    words**. Stop words are words such as *the*, *and*, *in*, and *he*, which are
    very frequently used in the English language and are bound to appear in nearly
    all of the movie reviews. Finally, because we are removing words from sentences
    and creating repeated spaces, we will want to remove these in order to assist
    the process of tokenization (the process of splitting up the text into words).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `tm` package has two functions, `tm_map()` and `content_transformer()`,
    which together can be used to apply text transformations to the content of every
    entry in our corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have preprocessed our corpus, we are ready to compute our features.
    Essentially, what we need is a data structure known as a **document term matrix**.
    The rows of the matrix are the documents. The columns of the matrix are the words
    in our dictionary. Each entry in the matrix is a binary value, with `1` representing
    the fact that the word represented by the column number was found inside the review
    represented by the row number. For example, if the first column corresponds to
    the word `action`, the fourth row corresponds to the fourth movie review, and
    the value of the matrix at position (4,1) is `1`, this signifies that the fourth
    movie review contains the word `action`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `tm` package provides us with the `DocumentTermMatrix()` function that
    takes in a corpus object and builds a document term matrix. The particular matrix
    built has numerical entries that represent the total number of times a particular
    word is seen inside a particular text, so we will have to convert these into a
    binary factor afterward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Our document term matrix in this case has 117,473 columns, indicating that
    we have found this number of different words in the corpus. This matrix is very
    sparse, meaning that most of the entries are 0\. This is a very typical scenario
    when building document term matrices for text documents, especially text documents
    that are as short as movie reviews. Any particular movie review will only feature
    a tiny fraction of the words in the vocabulary. Let''s examine our matrix to see
    just how sparse it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: From the ratio of non-sparse to sparse entries, we can see that of the 2,936,825,000
    entries in the matrix (25000 × 117473), only 2,493,414 are nonzero. At this point,
    we should reduce the number of columns of this matrix for two reasons. On the
    one hand, because the words in our vocabulary will become the features in our
    model, we don't want to build a model that uses 117,473 features. This would take
    a very long time to train and, at the same time, is unlikely to provide us with
    a decent fit using only 25,000 data points.
  prefs: []
  type: TYPE_NORMAL
- en: Another significant reason for us to want to reduce the number of columns is
    that many words will appear only once or twice in the whole corpus, and will be
    as uninformative about the user's sentiment as words that occur in nearly all
    the documents. Given this, we have a natural way to reduce the dimensions of the
    document term matrix, namely by dropping the columns (that is, removing certain
    words from the feature set) that are the sparsest. We can remove all columns that
    have a certain percentage of sparse elements using the `removeSparseTerms()` function.
    The first argument that we must provide this with is a document term matrix, and
    the second is the maximum degree of column sparseness that we will allow. Choosing
    the degree of sparseness is tricky because we don't want to throw away too many
    of the columns that will become our features. We will proceed by running our experiments
    with 99 percent sparseness, but encourage the reader to repeat with different
    values to see the effect this has on the number of features and model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have 25,000 rows in the matrix corresponding to the total number of documents
    in our corpus. If we allow a maximum of 99 percent sparseness, we are effectively
    removing words that do not occur in at least 1 percent of those 25,000 documents;
    that is, in at least 250 documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now significantly reduced the number of columns down to 1,603\. This
    is a substantially more reasonable number of features for us to work with. Next,
    we convert all entries to binary, using another function of `tm`, `weightBin()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As the document term matrix is, in general, a very sparse matrix, R uses a
    compact data structure to store the information. To peek inside this matrix and
    examine the first few terms, we will use the `inspect()` function on a small slice
    of this matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'It looks like the word `ability` does not appear in the first six documents
    and the word `able` appears in the document `10004_8.txt`. We now have both our
    features and our output vector. The next step is to convert our document term
    matrix into a data frame. This is needed by the function that will train our Naïve
    Bayes model. Then, before we train the model, we will split our data into a training
    set with 80 percent of the documents and a test set with 20 percent of the documents,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To train a Naïve Bayes model, we will use the `naiveBayes()` function in the
    `e1071` package that we saw earlier. The first argument we will provide it with
    is our feature data frame, and the second argument is our vector of output labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `predict()` function to obtain predictions on our training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We have hit over 83 percent training accuracy with our simple Naïve Bayes model,
    which, admittedly, is not bad for such a simple model with an independence assumption
    that we know is not realistic for our data. Let''s repeat the same on our test
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The test accuracy of over 82 percent is comparable to what we saw on our training
    data. There are a number of potential avenues for improvement here. The first
    involves noticing that words such as *movie* and *movies* are treated differently,
    even though they are the same word but inflected. In linguistics, **inflection**
    is the process by which the base form or **lemma** of a word is modified to agree
    with another word on attributes such as tense, case, gender, and number. For example,
    in English, verbs must agree with their subject.
  prefs: []
  type: TYPE_NORMAL
- en: The `tm` package supports **stemming**, a process of removing the inflected
    part of a word in order to keep just a stem or root word. This is not always the
    same as retrieving what is known as the **morphological lemma** of a word, which
    is what we look up in a dictionary, but is a rough approximation. The `tm` package
    uses the well-known **Porter Stemmer**.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Martin Porter*, the author of the Porter Stemmer, maintains a website at [http://tartarus.org/martin/PorterStemmer/](http://tartarus.org/martin/PorterStemmer/),
    which is a great source of information on his famous algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply stemming to our corpus, we need to add a final transformation to our
    corpus using `tm_map()` and then recompute our document term matrix anew, as the
    columns (the word features) are now word stems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we have fewer columns that match our criterion of 99 percent maximum
    sparsity. We can use this new document term matrix to train another Naïve Bayes
    classifier and then measure the accuracy on our test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The result, 80 percent, is slightly lower than what we observed without stemming,
    although we are using slightly fewer features than before. Stemming is not always
    guaranteed to be a good idea, as in some problems it may improve performance,
    whereas in others it will make no difference or even make things worse. It is,
    however, a common transformation that is worth trying when working with text data.
  prefs: []
  type: TYPE_NORMAL
- en: A second possible improvement is to use **additive smoothing** (also known as
    **laplacian smoothing**) during the training of our Naïve Bayes model. This is
    actually a form of regularization and it works by adding a fixed number to all
    the counts of feature and class combinations during training. Using our original
    document term matrix, we can compute a Naïve Bayes model with additive smoothing
    by specifying the `laplace` parameter. For our particular dataset, however, we
    did not witness any improvements by doing this.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few more avenues of approach that we might try with a Naïve Bayes
    model, and we will propose them here for the reader to experiment with. The first
    of these is that it is often worth manually curating the list of words used as
    features for the model. When we study the terms selected by our document term
    matrix, we may find that some words are frequent in our training data, but we
    do not expect them to be frequent in general, or representative of the overall
    population. Furthermore, we may only want to experiment with words that we know
    are suggestive of emotion and sentiment. This can be done by specifying a specific
    dictionary of terms to use when constructing our document term matrix. Here is
    an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: It is relatively straightforward to find examples of such lists on the internet.
    Another common preprocessing step that is used with a Naïve Bayes model is to
    remove correlations between features. One way of doing this is to perform PCA,
    as we saw in [Chapter 1](part0015_split_000.html#E9OE2-c6198d576bbb4f42b630392bd61137d7
    "Chapter 1. Gearing Up for Predictive Modeling"), *Gearing Up for Predictive Modeling*.
    Furthermore, this method also allows us to begin with a slightly more sparse document
    term matrix with a larger number of terms, as we know we will be reducing the
    overall number of features with PCA.
  prefs: []
  type: TYPE_NORMAL
- en: Potential model improvements notwithstanding, it is important to be aware of
    the limitations that the Naïve Bayes model imposes that impede our ability to
    train a highly accurate sentiment analyzer. Assuming that all the words in a movie
    review are independent of each other, once we know the sentiment involved, is
    quite an unrealistic assumption. Our model completely disregards sentence structure
    and word order. For example, the phrase *not bad* in a review might indicate a
    positive sentiment, but because we look at words in isolation, we will tend to
    correlate the word *bad* with a negative sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Negation in general is one of the hardest problems to handle in text processing.
    Our model also cannot handle common patterns of language, such as sarcasm, irony,
    quoted passages that include other people's thoughts, and other such linguistic
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: The next section will introduce a more powerful graphical model.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Hidden Markov models**'
  prefs: []
  type: TYPE_NORMAL
- en: A good reference to study for the Naïve Bayes classifier is *An empirical study
    of the Naïve Bayes classifier*, *I. Rish*, presented in the 2001 IJCAI workshop
    on *Empirical Methods in AI*. For sentiment analysis, we recommend the slides
    from *Bing Liu*'s AAAI 2011 tutorial at (as of this writing) [https://www.researchgate.net/profile/Irina_Rish/publication/228845263_An_Empirical_Study_of_the_Naive_Bayes_Classifier/links/00b7d52dc3ccd8d692000000/An-Empirical-Study-of-the-Naive-Bayes-Classifier.pdf](https://www.researchgate.net/profile/Irina_Rish/publication/228845263_An_Empirical_Study_of_the_Naive_Bayes_Classifier/links/00b7d52dc3ccd8d692000000/An-Empirical-Study-of-the-Naive-Bayes-Classifier.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'A **Hidden Markov model**, often abbreviated to **HMM**, which we will use
    here, is a Bayesian network with a repeating structure that is commonly used to
    model and predict sequences. In this section, we''ll see two applications of this
    model: one to model DNA gene sequences, and another to model the sequences of
    letters that make up English text. The basic diagram for an HMM is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predicting the sentiment of movie reviews](img/00181.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see in the diagram, the sequence flows from left to right and we have
    a pair of nodes for every entry in the sequence that we are trying to model. Nodes
    labeled *Ci* are known as **latent states**, **hidden states**, or merely **states**,
    as they are typically nodes that are not observable. The nodes labeled *Oi* are
    **observed states** or **observations**. We will use the terms *states* and *observations*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, as this is a Bayesian network, we can immediately identify some key properties.
    All the observations are independent of each other given their corresponding state.
    Also, every state is independent of every other state earlier on in the sequence
    history, given the state that preceded it (which is its parent in the network).
    The key idea behind an HMM, therefore, is that the model moves in a linear fashion
    from one state to the next state.
  prefs: []
  type: TYPE_NORMAL
- en: In each latent state, it produces an observation, which is also known as an
    **emitted symbol**. These symbols are the observed part of the sequence. Hidden
    Markov models are very common in natural language processing, and a good example
    is their application to **part of speech tagging**. The task of a part of speech
    tagger is to read a sentence and return the sequence of corresponding part of
    speech labels for the words in that sentence. For example, given the previous
    sentence, a part of speech tagger might return *determiner* for the word *The*,
    *singular noun* for the word *task*, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: To model this using an HMM, we would have the words be the emitted symbols,
    and the part of speech tags be the latent states, as the former are observable
    and the latter are what we want to determine. There are many other sequence labeling
    tasks in natural language processing to which Hidden Markov models have been applied,
    such as **named entity recognition**, where the goal is to identify the words
    in a sentence that refer to names of individuals, locations, organizations, and
    other entities.
  prefs: []
  type: TYPE_NORMAL
- en: A Hidden Markov model is comprised of five core components. The first of these
    is the set of possible latent class labels. For the part of speech tagger example,
    this might be a list of all the part of speech tags that we will use. The second
    component is the set of all possible emitted symbols. For an English part of speech
    tagger, this is the dictionary of English words.
  prefs: []
  type: TYPE_NORMAL
- en: The next three components involve probabilities. The **starting probability
    vector** is a vector of probabilities that tells us the probability of starting
    in each latent state. For part of speech tagging, we may, for example, have a
    high probability of starting with a determiner such as *the*. The **transition
    probability matrix** is a matrix that tells us the probability of going to state
    *C[j]* when the current state is *C[i]*. Thus, this contains the probability of
    moving from a determiner to a noun for our part of speech example. Finally, the
    **emission probability matrix** tells us the probability of emitting every symbol
    in our dictionary for every state that we can be in. Note that some words (such
    as *bank*, which is both a noun and a verb) can be labeled with more than one
    part of speech tag, and so will have nonzero probabilities of being emitted from
    more than one state.
  prefs: []
  type: TYPE_NORMAL
- en: In circumstances such as part of speech tagging, we usually have a collection
    of labeled sequences so that our data contains both sequences of observations
    as well as their corresponding states. In this case, similar to the Naïve Bayes
    model, we use relative frequency counts to populate the probability components
    of our model.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to find a suitable starting probability vector, we could tabulate
    the starting state for every sequence in our dataset and use this to get the relative
    frequency of beginning in each state. When all we have are unlabeled sequences,
    the task is significantly harder because we might not even know how many states
    we need to include in our model. One method to assign states to unlabeled observation
    sequences in training data is known as the **Baum-Welch algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: Once we know the parameters of our model, the question becomes how to predict
    the most likely sequence of states behind a sequence of observations. Given an
    unlabeled sentence in English, a part of speech tagger based on an HMM must predict
    the sequence of part of speech labels. The most commonly used algorithm for this
    is based on a programming technique known as **dynamic programming** and is known
    as the **Viterbi algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithms we have discussed for the Hidden Markov model are beyond the
    scope of this book, but are quite intuitive and well worth studying. Given a basic
    understanding of the core components of the model and its assumptions, our next
    goal is to see how we can apply them to some real-world situations. We will first
    see an example with labeled sequences and later, an example with unlabeled sequences.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Perhaps the most definitive and thorough introduction to Hidden Markov models
    is the seminal paper titled *A Tutorial on Hidden Markov Models and Selected Applications
    in Speech Recognition*, *L. R. Rabiner*, published in the *Proceedings of the
    IEEE, 1989*. The *Jurafsky* and *Martin* textbook we mentioned earlier is also
    an ideal reference to learn more about HMMs, including details on the Baum-Welch
    and Viterbi algorithms, as well as applications such as part of speech tagging
    and named entity recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting promoter gene sequences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first application we will study in detail comes from the field of biology.
    There, we learn that the basic building blocks of DNA molecules are actually four
    fundamental molecules known as **nucleotides**. These are called *Thymine*, *Cytosine*,
    *Adenine*, and *Guanine*, and it is the order in which these molecules appear
    in a DNA strand that encodes the genetic information carried by the DNA.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting problem in molecular biology is finding **promoter sequences**
    within a larger DNA strand. These are special sequences of nucleotides that play
    an important role in regulating a genetic process known as **gene transcription**.
    This is the first step in the mechanism by which information in the DNA is read.
  prefs: []
  type: TYPE_NORMAL
- en: The *molecular biology (promoter gene sequences) dataset*, hosted by the UCI
    Machine Learning repository at [https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+(Promoter+Gene+Sequences)](https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+(Promoter+Gene+Sequences)),
    contains a number of gene sequences from DNA belonging to the bacterium *E. Coli*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The predictive task at hand is to build a model that will discern promoter
    gene sequences from non-promoter gene sequences. We will approach this problem
    using HMMs. Specifically, we will build an HMM for promoters and an HMM for non-promoters,
    and we will pick the model that gives us the highest probability for a test sequence
    in order to label that sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that it is important to strip whitespace using the `strip.white = TRUE`
    parameter setting in the call to `read.csv()`, as some fields have leading tab
    characters. The first column in the data frame contains a `+` or `-` to denote
    promoters or non-promoters respectively. The second column is just an identifier
    for the particular sequence and the third column is the sequence of nucleotides
    itself. We''ll begin by separating the data into positive and negative observations
    of promoter sequences using the first column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to train our HMMs, we want to concatenate all the observations from
    each class into a single observation. We do, however, want to store information
    about the start and end of each sequence. Consequently, we will prepend each sequence
    with the character `S` to denote the start of a sequence and append each sequence
    with the character `X` to denote the end of a sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will split each observation from a string into a vector of characters
    using the `strsplit()` function, which takes a string to split as the first argument
    and the character to use as the split points (delimiter). Here, we use an empty
    character on which to split, so that the whole string is broken up into single
    characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Now we have to specify the probability matrices for the HMMs that we want to
    train. In this particular situation, the states have a one-to-one correspondence
    with the emitted symbols, so in fact this type of problem can be simplified to
    a visible Markov model, which in this case is just a Markov chain. Nonetheless,
    the process we will follow for modeling this problem as an HMM is the same that
    we would follow in the more general case of having multiple symbols assigned to
    each state. We are going to assume that both positive and negative HMMs involve
    four states corresponding to the four nucleotides. Although both models will emit
    the same symbols in each state, they will differ in their transition probabilities
    from one state to the next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from the four states we mentioned earlier, we created a special terminating
    state at the end of each sequence using the symbol *X*. We also created a special
    starting state, which we called *S*, so that the starting probability of all the
    other states is 0\. In addition, the emission probabilities are trivial to compute
    as only one symbol is emitted per state. Due to the one-to-one correspondence
    between states and symbols, we will use the same alphabet to represent the states
    and the symbols they emit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Computing the transition probability matrix requires us to do a bit more work.
    Thus, we defined our own function for this: `calculateTransitionProbabilities()`.
    The input to this function is a single vector of training sequences concatenated
    with each other, along with a vector containing the names of the states.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The function first computes an empty transition probability matrix. By cycling
    over each consecutive pair of states, it tallies up counts of state transitions.
    After all the data has been traversed, we normalize the transition probability
    matrix by dividing each row of the matrix by the sum of the elements in that row.
    This is done because the rows of this matrix must sum to one. We use the `sweep()`
    function, which allows us to apply a function on every element of the matrix using
    a summary statistic. Here is `calculateTransitionProbabilities()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are ready to train our models. The key observation to make on this dataset
    is that we have very few observations, just 53 of each class in fact. This dataset
    is too small to set a portion aside for testing. Instead, we will implement leave-one-out
    cross validation to estimate the accuracy of our models. To do this, we will begin
    by leaving an observation out from the positive observations. This leaves all
    the negative observations available for computing the transition probability matrix
    for our negative HMM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: When in the start state (`S`), we can randomly move to a nucleotide state, but
    have zero probability of moving to the stop state (`X`) or staying in the start
    state. When in the nucleotide states, we can randomly transition to any state
    except back to the start state. Finally, the only valid transition from a stop
    state is to the start state for a new sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now introduce the `HMM` package in R, which is for working with Hidden Markov
    models, as the name implies. We can initialize an HMM with a specific set of parameters
    using the `initHMM()` function. As expected, this takes five inputs corresponding
    to the five components of a Hidden Markov model, which we discussed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to build the positive HMM, but we will have to do this multiple
    times, leaving out one observation for testing. This test observation will then
    be processed by the negative HMM we trained earlier and the positive HMM that
    was trained without that observation. If the positive HMM predicts a higher probability
    for the test observation than the negative HMM, our model will correctly classify
    the test observation. The following block of code performs a loop of these calculations
    for every positive observation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We'll now walk through the previous code block. Firstly, we keep track of any
    mistakes we make using the `incorrect` variable. For every observation in our
    positive observations list, we'll train a positive HMM without this observation.
    This observation then becomes our test observation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the probability of a particular sequence given a particular HMM, we
    used the `forward()` function, which computes a matrix containing the logarithm
    of all the forward probabilities for every step in the observation sequence. The
    final column in this matrix, whose numerical index is just the length of the sequence,
    contains the forward probability for the whole sequence. We compute the positive
    sequence probability using the positive HMM that we trained and use the `exp()`
    function to undo the logarithm operation (although not strictly necessary in this
    case, where we just need a comparison). We repeat this for the negative sequence
    probability using the negative HMM. As our test observation was one of the positive
    observations, we will misclassify only if the negative sequence probability is
    greater than the positive sequence probability. After our code block completes
    its execution, we can see how many mistakes we have made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that out of the 53 positive observations, we misclassified 13 and
    correctly classified 40\. We are not done yet, though, as we need to do a similar
    loop with the negative observations. This time, we will train a positive HMM once
    with all the positive observations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Next, we are going to iterate over all the negative observations. We will train
    a negative model by leaving one observation out as the test observation. We will
    then process this observation with both the positive HMM we just trained and the
    negative HMM trained without this observation in its training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will compare the predicted sequence probability for this test observation
    produced by the two HMMs and classify the test observation according to which
    model produced the higher probability. In essence, we are doing exactly the same
    process as we did earlier when we were iterating over the positive observations.
    The following code block will continue to update our `incorrect` variable and
    should be self-explanatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The overall number of misclassifications in the cross-validation is stored
    in the `incorrect` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Our overall cross-validation accuracy is roughly 76 percent. Given that we are
    using the leave-one-out approach, and that the overall size of the training data
    is so small, we expect this estimate to have a relatively high variance.
  prefs: []
  type: TYPE_NORMAL
- en: In our HMM, the Markov property essentially makes the assumption that only the
    previous nucleotide determines the choice of the next nucleotide in the sequence.
    We can reasonably expect that there are longer-range dependencies at work and,
    as a result, we are limited in accuracy by the assumptions of our model. For this
    reason, there are models, such as the **Trigram HMM**, that take into account
    additional states in the past other than the current state.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will study an example where we train a Hidden Markov
    model using unlabeled data. We will manually define the number of hidden states
    and use the Baum-Welch algorithm to train an HMM while estimating both state transitions
    and emissions.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting letter patterns in English words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will model the patterns of letters that form English words.
    Beyond having different words, and sometimes alphabets, languages differ from
    each other in the patterns of letters that are used to form words. English words
    have a characteristic distribution of letters and letter sequences and, in this
    section, we will try to model the process of word formation in a very simplistic
    way by using a Hidden Markov model.
  prefs: []
  type: TYPE_NORMAL
- en: The emitted symbols of our model will be the letters themselves but this time,
    we don't know what the states could be as we are using unlabeled data. For this
    reason, we are going to provide just the number of states that we want our model
    to have, and then use the Baum-Welch algorithm to train the parameters of our
    HMM.
  prefs: []
  type: TYPE_NORMAL
- en: 'All we need for this task is a corpus of text in English. Earlier in this chapter,
    we studied movie reviews with the Naïve Bayes classifier, so we will use these
    for convenience, although other sources of English text could be used as well.
    We shall begin by reloading our movie reviews and will use the `tm` package to
    transform them all to lowercase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will read the text from every review and collect these in a single
    vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'To simplify our task, aside from the individual letters, we will consider a
    category with all the whitespace characters (spaces, tabs, and so on) and represent
    these with the uppercase letter `W`. We will do the same for numerical digits
    with the uppercase character `N`, all punctuation marks with the uppercase character
    `P`, and use the uppercase character `O` for anything that is left. We use regular
    expressions for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have transformed all our text, we''ll pick out a sample and split each
    review into characters. The sequences of characters from each review will then
    be concatenated with each other to create one long character sequence. This works
    quite well in this context as the corpus of reviews contains complete sentences
    and concatenating them amounts to joining up complete sentences. We''ve chosen
    to use a sample of 100 movie reviews. We can use more, but the time taken to train
    the model would be longer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll want to initialize our HMM. In this example, we''ll consider a
    model with three states, which we''ll arbitrarily name `s1`, `s2`, and `s3`. For
    emitted symbols, we have the lowercase alphabet and the four uppercase characters
    that, as we saw earlier, are being used to represent four special character categories
    such as numbers. R holds a vector of lowercase letters in the variable `letters`,
    which is very convenient for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll create random starting, emission, and transmission probability
    matrices. We''ll generate random entries in the [0,1] interval using the `runif()`
    function. We will need to normalize every row in these matrices in order to ensure
    that the entries correspond to probabilities. To achieve this, we''ll use the
    `sweep()` function as we did earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We now initialize and train the HMM using the large character sequence we obtained
    earlier. This will take several minutes to run depending on the computational
    resources available, and this is the main reason we drew only a sample of the
    text earlier on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'We trained our model in a completely unsupervised way by simply providing it
    with character sequences. We don''t have a meaningful test dataset on which to
    assess the performance of our model; rather, this exercise is worthwhile in that
    it produces an HMM that has interesting properties. It is instructive to take
    a peek at the symbol emission probabilities for each state. These are accessible
    via the `hmm$emissionProbs` attribute on the `hmm_trained` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Predicting letter patterns in English words](img/00182.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Let's examine these states carefully. All states have a relatively high probability
    of emitting a whitespace character. State 3 is very interesting as, besides whitespace,
    it seems to have grouped together punctuation and vowels. The HMM has successfully
    managed to group together the letters *a*, *e*, *i*, *o*, and *u* in the same
    category without any prior information about the English language.
  prefs: []
  type: TYPE_NORMAL
- en: This state also emits two consonants with a noticeable probability. The consonant
    *y* is emitted, which we know occasionally does behave like a vowel in words such
    as *rhythm* and *phylum*, for example. The consonant *s* is also emitted, and
    because it is often used to form the plural of nouns, we find this at the end
    of words just like punctuation marks. So, we see that this state seems to have
    grouped two main themes.
  prefs: []
  type: TYPE_NORMAL
- en: 'By contrast, state 1 tends to emit consonants and not vowels. In fact, only
    the vowel *u* seems to have a small probability of being emitted from this state.
    State 2 has a mix of vowels and consonants, but it is the only state in which
    the consonant *h* has a high probability. This is very interesting, as *h* is
    another letter of the alphabet that has vowel-like properties in pronunciation
    (it is often silent or part of a diphthong). We can learn more by examining the
    transition probabilities between the states:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Again, we can discover a wealth of interesting properties. For example, when
    we are in state 3, the vowel state, we have a 95 percent chance of going to state
    1, the consonant state. This is quite intuitive, in that English rarely has consecutive
    vowels. When we are in state 1, we have a 36 percent chance of going to the vowel
    state and a 51 percent chance of going to state 2.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can begin to understand what state 2 represents. It primarily represents
    the state that emits the second consonant when we have two consecutive consonants.
    This is why the letter *h* has such a high probability in this state, as it participates
    in very common diphthongs, such as *ch*, *sh*, and *th*, the latter of course
    being found in very frequent words such as *the*. From this state, the most common
    successor state, with 72 percent probability, is the vowel state, as expected
    after two consecutive consonants.
  prefs: []
  type: TYPE_NORMAL
- en: This experiment is worth repeating with different conditions. If we use different
    seeds or sample a different number of movie reviews, we may see different results,
    as the Baum-Welch algorithm is sensitive to initial conditions and is unsupervised.
    Specifically, our Hidden Markov model might learn a completely different set of
    states.
  prefs: []
  type: TYPE_NORMAL
- en: For example, on some iterations, we noticed that all punctuation and numerical
    digits are grouped into one state, another state becomes the vowel state, and
    the third state is a pure consonant state. We can reproduce this behavior if,
    in the previous code, we sample 40 texts and use the numbers 1816, 1817, and 1818
    for the three seeds. There are many more possibilities—some of which are easier
    to interpret than others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another parameter that is worth varying here is the number of states. If we
    use two states, then the split tends to be between vowels and consonants. If we
    increase the number of states, we will often continue to find results that are
    interpretable for as many as 10 states. Hidden Markov models are often also referred
    to as **generative models** because we can use them to generate examples of states
    and observations once they have been trained. We can do this with the `simHMM()`
    function by providing our model and the length of the sequence we want to generate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'As a final point, we can download and use the `markovchain` package, take our
    learned transition probability matrix, and find out in the long run how much time
    our model spends in each state. This is done using a **steady state calculation**,
    the mathematics of which we will not explore in this book. Thankfully, the `markovchain`
    package has a simple way to initialize a Markov chain when we know the probabilities
    that are involved. It does this by using the `simpleMc()` function, and we can
    use the `steadyStates()` function on our Markov chain to find out the steady state
    distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: In the long term, we spend 38 percent of our time in state 1, the first consonant
    state; 27 percent in state 2, the second consonant state; and 35 percent of our
    time in state 3, the main vowel state.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced ourselves to one of the very active areas of
    research in machine learning, namely the field of probabilistic graphical models.
    These models involve using a graphical structure to encode conditional independence
    relations between random variables. We saw how Bayes' theorem, a very simple formula
    that essentially tells us how we can predicate cause by observing effect, can
    be used to build a simple classifier known as the Naïve Bayes classifier. This
    is a simple model where we are trying to predict an output class that best explains
    a set of observed features, all of which are assumed to be independent of each
    other given the output class.
  prefs: []
  type: TYPE_NORMAL
- en: We used this model to predict user sentiment on a set of movie reviews where
    the features were the words that were present in the reviews. Although we obtained
    reasonable accuracy, we found that the assumptions in our model are quite strict
    and prevent us from doing substantially better. Often, a Naïve Bayes model is
    built during the modeling process to provide us with a baseline performance that
    we know we should exceed with more sophisticated models.
  prefs: []
  type: TYPE_NORMAL
- en: We also studied Hidden Markov models, which are models typically used to label
    and predict sequences. Every position in the sequence is comprised of a hidden
    state and an observation emitted from that state. The key assumption of the model
    is that every state is independent of the entire sequence history, given the state
    that immediately preceded it. In addition, all observations are independent of
    each other as well as all other states in the sequence, given the state from which
    they were emitted.
  prefs: []
  type: TYPE_NORMAL
- en: When we have labeled sequences, we can train a Hidden Markov model by using
    state transition and symbol emission counts obtained from the data itself. It
    is also possible to train an unsupervised HMM using a very smart algorithm known
    as the Baum-Welch algorithm. Even though we did not dive into the algorithmic
    details, we saw an example of how this works in practice by training an HMM on
    sequences of characters in English words.
  prefs: []
  type: TYPE_NORMAL
- en: From this, we saw that the resulting model picked up on some interesting properties
    of language. Incidentally, even though we did not mention it, it is also possible
    to train a Naïve Bayes model with missing class labels, this time using the **EM
    algorithm**. Despite also having relatively strict independence assumptions, HMMs
    are quite powerful and have been successfully applied to a wide variety of applications
    from speech processing to molecular biology.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at analyzing and making predictions on time
    series. Many real-world applications involve taking measurements over a particular
    period of time and using them to make predictions about the future. For example,
    we might want to predict tomorrow's weather based on the weather today, or tomorrow's
    stock market index based on market fluctuations over the past few weeks.
  prefs: []
  type: TYPE_NORMAL
