["```py\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n```", "```py\n# Set your working directory according to your requirement\nos.chdir(\".../Chapter 6/Random Forest\")\nos.getcwd()\n```", "```py\ndf_creditcarddata = pd.read_csv(\"UCI_Credit_Card.csv\")\n```", "```py\ndf_creditcarddata.shape\n```", "```py\ndf_creditcarddata.dtypes\n```", "```py\ndf_creditcarddata = df_creditcarddata.drop(\"ID\", axis= 1) \n```", "```py\nselected_columns = df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']]\n\nselected_columns.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);\n```", "```py\ndf_creditcarddata['agegroup'] = pd.cut(df_creditcarddata['AGE'], range(0, 100, 10), right=False)\ndf_creditcarddata.head()\n```", "```py\n# Default vs Age\npd.crosstab(df_creditcarddata.age_group, \\\n           df_creditcarddata[\"default.payment.next.month\"]).plot(kind='bar',stacked=False, grid=True) \n\nplt.title('Count of Defaults by AGE')\nplt.xlabel('AGE')\nplt.ylabel('# of Default')\nplt.legend(loc='upper left')\n```", "```py\ndf_creditcarddata = df_creditcarddata.drop(columns = ['age_group'])\ndf_creditcarddata.head()\n```", "```py\nfig_facetgrid = sns.FacetGrid(df_creditcarddata, hue='default.payment.next.month', aspect=4)\nfig_facetgrid.map(sns.kdeplot, 'LIMIT_BAL', shade=True)\nmax_limit_bal = df_creditcarddata['LIMIT_BAL'].max()\nfig_facetgrid.set(xlim=(0,max_limit_bal));\nfig_facetgrid.set(ylim=(0.0,0.000007));\nfig_facetgrid.set(title='Distribution of limit balance by default.payment')\nfig_facetgrid.add_legend()\n```", "```py\nGenderMap = {2:'female', 1:'male'}\nMarriageMap = {1:'married', 2:'single', 3:'other', 0: 'other'}\nEducationMap = {1:'graduate school', 2:'university', 3:'high school', 4:'others', 5:'unknown', 6:'unknown', 0:'unknown'}\n\ndf_creditcarddata['SEX'] = df_creditcarddata.SEX.map(GenderMap)\ndf_creditcarddata['MARRIAGE'] = df_creditcarddata.MARRIAGE.map(MarriageMap) \ndf_creditcarddata['EDUCATION'] = df_creditcarddata.EDUCATION.map(EducationMap)\ndf_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].astype(str) \ndf_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].astype(str) \ndf_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].astype(str) \ndf_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].astype(str) \ndf_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].astype(str) \ndf_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].astype(str) \n```", "```py\npredictor= df_creditcarddata.iloc[:, df_creditcarddata.columns != 'default.payment.next.month']\ntarget= df_creditcarddata.iloc[:, df_creditcarddata.columns == 'default.payment.next.month']\n```", "```py\n# save all categorical columns in list\ncategorical_columns = [col for col in predictor.columns.values if predictor[col].dtype == 'object']\n\n# dataframe with categorical features\ndf_categorical = predictor[categorical_columns]\n\n# dataframe with numerical features\ndf_numeric = predictor.drop(categorical_columns, axis=1)\n```", "```py\ndummy_code_cat_vars = pd.get_dummies(df_categorical,drop_first=True)\n```", "```py\ndf_predictor = pd.concat([df_numeric, dummy_code_cat_vars], axis=1)\ndf_predictor.head()\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(df_predictor, target, test_size = 0.30, random_state=0)\nprint(\"x_train \",X_train.shape)\nprint(\"x_test \",X_test.shape)\nprint(\"y_train \",y_train.shape)\nprint(\"y_test \",y_test.shape)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n```", "```py\nX_train_scaled.columns = X_train.columns.values\nX_test_scaled.columns = X_test.columns.values\nX_train_scaled.index = X_train.index.values\nX_test_scaled.index = X_test.index.values\n\nX_train = X_train_scaled\nX_test = X_test_scaled\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\\\n criterion = 'entropy', max_leaf_nodes= 20,oob_score = True, n_jobs = -1 )\n\n# fit the model\nmodel_RF = classifier.fit(X_train, y_train)\n```", "```py\nacc_random_forest = round(classifier.score(X_train, y_train) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")\n```", "```py\nfrom sklearn import metrics\n\ny_pred_proba = model_RF.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\nplt.legend(loc=4)\nplt.show()\n```", "```py\n# predict the model\ny_pred_RF = model_RF.predict(X_test)\n\n# evaluate other scores\nevaluation_scores = pd.Series({'Model': \" Random Forest Classifier \",\n'ROC Score' : metrics.roc_auc_score(y_test, y_pred_RF),\n'Precision Score': metrics.precision_score(y_test, y_pred_RF),\n'Recall Score': metrics.recall_score(y_test, y_pred_RF),\n'Accuracy Score': metrics.accuracy_score(y_test, y_pred_RF),\n'Kappa Score':metrics.cohen_kappa_score(y_test, y_pred_RF)})\n\nprint(evaluation_scores)\n```", "```py\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_RF))\n```", "```py\nfeature_importances = pd.Series(classifier.feature_importances_, index=X_train.columns)\nfeature_importances.nlargest(10).plot(kind='barh') #top 10 features\n```", "```py\n! apt-get install default-jre\n! java -version\n```", "```py\n! pip install h2o\n```", "```py\nimport h2o\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport seaborn\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\nfrom sklearn import metrics\n```", "```py\nh2o.init()\n```", "```py\ndf_creditcarddata = pd.read_csv(\"UCI_Credit_Card.csv\")\n```", "```py\nhf_creditcarddata = h2o.H2OFrame(df_creditcarddata)\n```", "```py\nhf_creditcarddata.head()\n```", "```py\nhf_creditcarddata.describe()\n```", "```py\nhf_creditcarddata = hf_creditcarddata.drop([\"ID\"], axis = 1) \n```", "```py\ndf_creditcarddata.drop(['default.payment.next.month'], \\\n     axis = 1).corrwith(df_creditcarddata['default.payment.next.month']).\\\n     plot.bar(figsize=(20,10), \\\n     title = 'Correlation with Response variable', \\\n     fontsize = 15, rot = 45, grid = True)\n```", "```py\nhf_creditcarddata.types\n```", "```py\nhf_creditcarddata['SEX'] = hf_creditcarddata['SEX'].asfactor()\nhf_creditcarddata['EDUCATION'] = hf_creditcarddata['EDUCATION'].asfactor()\nhf_creditcarddata['MARRIAGE'] = hf_creditcarddata['MARRIAGE'].asfactor()\nhf_creditcarddata['PAY_0'] = hf_creditcarddata['PAY_0'].asfactor()\nhf_creditcarddata['PAY_2'] = hf_creditcarddata['PAY_2'].asfactor()\nhf_creditcarddata['PAY_3'] = hf_creditcarddata['PAY_3'].asfactor()\nhf_creditcarddata['PAY_4'] = hf_creditcarddata['PAY_4'].asfactor()\nhf_creditcarddata['PAY_5'] = hf_creditcarddata['PAY_5'].asfactor()\nhf_creditcarddata['PAY_6'] = hf_creditcarddata['PAY_6'].asfactor()\n```", "```py\nhf_creditcarddata['default.payment.next.month'] = \\\n             hf_creditcarddata['default.payment.next.month'].asfactor() \nhf_creditcarddata['default.payment.next.month'].levels() \n```", "```py\npredictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n\ntarget = 'default.payment.next.month'\n```", "```py\nsplits = hf_creditcarddata.split_frame(ratios=[0.7], seed=123) \ntrain = splits[0]\ntest = splits[1] \n```", "```py\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\n\nRF_D = H2ORandomForestEstimator(model_id = 'RF_D',seed = 123)\nRF_D.train(x = predictors, y = target, training_frame = train)\n\nprint(RF_D.model_performance(test))\n```", "```py\nRF_cv = H2ORandomForestEstimator(model_id = 'RF_cv', \n                                 seed = 12345, \n                                 ntrees = 500, \n                                 sample_rate = 0.9, \n                                 col_sample_rate_per_tree = 0.9, \n                                 nfolds = 10)\n\nRF_cv.train(x = predictors, y = target, training_frame = train)\nprint(RF_cv.model_performance(test))\n```", "```py\nsearch_criteria = {'strategy': \"RandomDiscrete\"}\n\nhyper_params = {'sample_rate': [0.5, 0.6, 0.7],\\\n                'col_sample_rate_per_tree': [0.7, 0.8, 0.9],\\\n                'max_depth': [3, 5, 7]}\n```", "```py\nfrom h2o.grid.grid_search import H2OGridSearch\n\nRF_Grid = H2OGridSearch(\n                    H2ORandomForestEstimator(\n                        model_id = 'RF_Grid', \n                        ntrees = 200, \n                        nfolds = 10,\n                        stopping_metric = 'AUC', \n                        stopping_rounds = 25), \n                    search_criteria = search_criteria, # full grid search\n                    hyper_params = hyper_params)\nRF_Grid.train(x = predictors, y = target, training_frame = train)\n```", "```py\nRF_Grid_sorted = RF_Grid.get_grid(sort_by='auc',decreasing=True)\nprint(RF_Grid_sorted)\n\nbest_RF_model = RF_Grid_sorted.model_ids[0]\nbest_RF_from_RF_Grid = h2o.get_model(best_RF_model)\n```", "```py\nbest_RF_from_RF_Grid.model_performance(test)\n```", "```py\nbest_RF_from_RF_G\nrid.varimp_plot()\n```"]