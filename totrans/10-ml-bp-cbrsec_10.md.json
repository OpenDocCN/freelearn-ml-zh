["```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms\n```", "```py\ndef Generate_FGSM_Image(model,\n                        x,\n                        epsilon):\n  # Check if epsilon is 0\n  # If so, that means no perturbation is added\n  # We can avoid gradient calculations\n  if epsilon == 0:\n    return x\n  # Convert x to a float and having gradients enabled\n  x = x.clone().detach()\n  x = x.to(torch.float)\n  x – x.requires_grad_(True)\n  # Get original label as predicted by model\n  _, y = torch.max(model(x), 1)\n  # Compute Loss\n  loss_function = nn.CrossEntropyLoss()\n  loss = loss_function(model(x), y)\n  # Backpropagate Loss\n  loss.backward()\n  # Calculate perturbation using the FGSM equation\n  perturbation = epsilon * torch.sign(x.grad)\n  # Calculate the adversarial image\n  x_adversarial = x + perturbation\n  return x_adversarial\n```", "```py\nclass BasicImageNetCNN(nn.Module):\n    def __init__(self, in_channels=1):\n        super(BasicImageNetCNN, self).__init__()\n        # Define the convolutional layers\n        self.conv1 = nn.Conv2d(in_channels, 64, 8, 1)\n        self.conv2 = nn.Conv2d(64, 128, 6, 2)\n        self.conv3 = nn.Conv2d(128, 128, 5, 2)\n        # Define the fully connected layer\n        self.fc = nn.Linear(128 * 3 * 3, 10)\n    def forward(self, x):\n        # Pass the image through convolutional layers one by one\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        # Flatten the output of the convolutional layer and pass to fully connected layer\n        x = x.view(-1, 128 * 3 * 3)\n        x = self.fc(x)\n        return x\n```", "```py\ndef load_cifar10_datasets(datapath):\n    # Load the transformations\n    train_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n    test_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n    # Obtain the datasets\n    # Download them if they are not present\n    train_dataset = torchvision.datasets.CIFAR10(root=datapath, train=True,\n    transform=train_transforms, download=True)\n    test_dataset = torchvision.datasets.CIFAR10(root=datapath, train=False,\n    transform=test_transforms, download=True)\n    # Create Data Loaders\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128,\n    shuffle=True, num_workers=2)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128,\n    shuffle=False, num_workers=2)\n    return train_loader, test_loader\n```", "```py\nNUM_EPOCHS = 10\ntrain_data, test_data = load_cifar10_datasets(datapath = \"./data\")\nmodel = BasicImageNetCNN(in_channels = 3)\nloss_function = torch.nn.CrossEntropyLoss(reduction=\"mean\")\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nif torch.cuda.is_available():\n  device = \"cuda\"\n  model = model.cuda()\nelse:\n  device = \"cpu\"\nmodel.train()\nfor epoch in range(NUM_EPOCHS):\n  train_loss = 0.0\n  for x, y in train_data:\n    # Move image and labels to device if applicable\n    x = x.to(device)\n    y = y.to(device)\n    # Zero out the gradients from previous epoch if any\n    optimizer.zero_grad()\n    # Calculate predicted value and loss\n    y_pred = model(x)\n    loss = loss_function(y_pred, y)\n    # Backpropagation\n    loss.backward()\n    optimizer.step()\n    # Keep track of the loss\n    train_loss = train_loss + loss.item()\n    # Print some information for logging\n    print(\"EPOCH: {} ---------- Loss: {}\".format(epoch, train_loss))\n```", "```py\nmodel.eval()\nclean_correct = 0\nfgsm_correct = 0\ntotal = 0\nfor x, y in test_data:\n    # Move image and labels to device if applicable\n    x = x.to(device)\n    y = y.to(device)\n    # Calculate the adversarial images\n    x_fgsm = Generate_FGSM_Image(model, x, epsilon = 0.005)\n    # Run inference for predicted values on clean and adversarial examples\n    _, y_pred_clean = torch.max(model(x), 1)\n    _, y_pred_fgsm = torch.max(model(x_fgsm), 1)\n    # Calculate accuracy of clean and adversarial predictions\n    clean_correct = clean_correct + y_pred_clean.eq(y).sum().item()\n    fgsm_correct = fgsm_correct + y_pred_fgsm.eq(y).sum().item()\n    total = total + y.size(0)\nclean_accuracy = clean_correct / total\nfgsm_accuracy = fgsm_correct / total\n```", "```py\ndef Generate_FGSM_Image_V2(model,x,y, // New Parameter.epsilon):\n  # Check if epsilon is 0\n  # If so, that means no perturbation is added\n  # We can avoid gradient calculations\n  if epsilon == 0:\n    return x\n  # Convert x to a float and having gradients enabled\n  x = x.clone().detach()\n  x = x.to(torch.float)\n  x - x.requires_grad_(True)\n  # Compute Loss\n  loss_function = nn.CrossEntropyLoss()\n  loss = loss_function(model(x), y)\n  # Backpropagate Loss\n  loss.backward()\n  # Calculate perturbation using the FGSM equation\n  perturbation = epsilon * torch.sign(x.grad)\n  # Calculate the adversarial image\n  x_adversarial = x + perturbation\n  return x_adversarial\n```", "```py\ndef Generate_PGDM_Image(model,x,epsilon,num_iterations):\n  # Obtain actual clean predictions from model\n  _, y = torch.max(model(x), 1)\n  # Calculate the initial adversarial value\n  eta = torch.zeros_like(x)\n  eta = torch.clamp(eta, -1*eps, 1*eps)\n  x_adv = x + eta\n  # For every iteration, do FGSM and clipping\n  for _ in range(num_iterations):\n    # Note that the FGSM function signature has changed\n    # We are passing it the predicted value y as a parameter\n    # Thus this will not be recomputed\n    x_adv = Generate_FGSM_Image_V2(model,x_adv,y,epsilon = 0.01)\n    eta = x_adv - x\n    eta = torch.clamp(eta, -1*eps, 1*eps)\n    x_adv= x + eta\n  # Return the final image\n  return x_adv\n```", "```py\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"FinalBalancedDataset.csv\", skiprows = 1, names= [\"TweetId\",\"Toxicity\",\"Tweet\"])\ndf.head()\n```", "```py\ndf.groupby(\"Toxicity\").count()[\"TweetId\"]\n```", "```py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef Extract_TF_IDF(train_data, test_data):\n    tf_idf = TfidfVectorizer()\n    X_train_TFIDF = tf_idf.fit_transform(train_data)\n    X_test_TFIDF = tf_idf.transform(test_data)\n    return X_train_TFIDF, X_test_TFIDF\n```", "```py\ndef double_last_letter(sentences, max_perturbations = 3):\n    # Output array\n    modified_sentences = []\n    for sentence in sentences:\n        # Split into words\n        words = sentence.split(' ')\n        # Randomly choose words to manipulate\n        rand_indices = np.random.randint(0, len(words), max_perturbations)\n        for idx in rand_indices:\n            # Check if the word is blank, if yes, skip\n            if len(words[idx]) == 0:\n              continue\n            # Double the last letter in the chosen word\n            words[idx]+=words[idx][-1]\n        # Join back to make sentence\n        modified_sentences.append(' '.join(word for word in words))\n    return modified_sentences\n```", "```py\ndef double_vowel(sentences, max_perturbations = 3):\n    total_perturbations = 0\n    # Output array\n    modified_sentences = []\n    for sentence in sentences:\n        # Split into words\n        words = sentence.split(' ')\n        for i in range(len(words)):\n            # Check if maximum perturbations done\n            # If so, break the loop and don't do any more!\n            if total_perturbations>max_perturbations:\n                break\n            for vowel in ['a','e','i','o','u']:\n                if vowel in words[i]:\n                    words[i] = words[i].replace(vowel,vowel+vowel,1)\n                    total_perturbations+=1\n                    # Here replace only for one vowel\n                    # So once replacement is done, break out\n                    # This will break only this loop\n                    break\n        modified_sentences.append(' '.join(word for word in words))\n    return modified_sentences\n```", "```py\nX = df[\"Tweet\"].tolist()\ny = df[\"Toxicity\"].tolist()\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,y,\ntest_size = 0.3,stratify = y)\nX_train_features, X_test_features = Extract_TF_IDF(X_train, X_test)\n```", "```py\nfrom sklearn.metrics import confusion_matrix\ndef evaluate_model(actual, predicted):\n  confusion = confusion_matrix(actual, predicted)\n  tn, fp, fn, tp = confusion.ravel()\n  total = tp + fp + tn + fn\n  accuracy = 1.0 * (tp + tn) / total\n  if tp + fp != 0:\n    precision = tp / (tp + fp)\n  else:\n    precision = 0\n  if tp + fn != 0:\n    recall = tp / (tp + fn)\n  else:\n    recall = 0\n  if precision == 0 or recall == 0:\n    f1 = 0\n  else:\n    f1 = 2 * precision * recall / (precision + recall)\n  evaluation = { 'accuracy': accuracy,\n                 'precision': precision,\n                 'recall': recall,\n                 'f1': f1}\n  return evaluation\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel.fit(X_train_features, Y_train)\nY_predicted = model.predict(X_test_features)\nevaluation = evaluate_model(Y_test, Y_predicted)\nprint(\"Accuracy: {}\".format(str(evaluation['accuracy'])))\nprint(\"Precision: {}\".format(str(evaluation['precision'])))\nprint(\"Recall: {}\".format(str(evaluation['recall'])))\nprint(\"F-1: {}\".format(str(evaluation['f1'])))\n```", "```py\n# Obtain adversarial samples\nX_test_adversarial = double_last_letter(X_test, max_perturbations=5)\n# Extract features\nX_train_features, X_test_features = Extract_TF_IDF(X_train, X_test_adversarial)\n# Train model\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel.fit(X_train_features, Y_train)\n# Predict on adversarial samples\nY_predicted = model.predict(X_test_features)\n# Evaluate\nevaluation = evaluate_model(Y_test, Y_predicted)\nprint(\"Accuracy: {}\".format(str(evaluation['accuracy'])))\nprint(\"Precision: {}\".format(str(evaluation['precision'])))\nprint(\"Recall: {}\".format(str(evaluation['recall'])))\nprint(\"F-1: {}\".format(str(evaluation['f1'])))\n```"]