# 7

# 模型聚合

在[第3章](B18369_03.xhtml#_idTextAnchor058)的“模型聚合基础”部分，我们介绍了联邦学习（**FL**）过程中聚合的概念。回想一下，聚合是联邦学习方法使用每个代理在本地训练的模型来产生具有强大全局性能的模型的方式。很明显，所采用的聚合方法的强度和鲁棒性与最终全局模型的性能直接相关。

因此，根据本地数据集、代理和联邦学习系统层次结构选择合适的聚合方法是实现联邦学习良好性能的关键。实际上，该领域许多出版物的研究焦点是提供这些方法在各种理论场景下的数学保证收敛性。

本章的目标是介绍一些关于聚合方法及其在理想和非理想情况下的收敛性的研究，将这些方法与它们在联邦学习实际应用中出现的不同场景中的优势联系起来。阅读完本章后，你应该能够理解不同的联邦学习场景特征如何要求不同的聚合方法，并且应该对如何实现这些算法有一个大致的了解。

本章将涵盖以下主题：

+   重新审视聚合

+   理解FedAvg

+   修改非理想情况下的聚合

# 技术要求

书中展示的Python算法实现都可以在`ch7`文件夹中找到，该文件夹位于[https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7](https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7)。

重要注意事项

你可以使用代码文件用于个人或教育目的。请注意，我们不会支持商业部署，并且不会对使用代码造成的任何错误、问题或损害负责。

对于纯聚合算法，包括辅助代码以显示从预设的本地参数中获取的示例输出。修改本地训练过程的聚合方法需要一个联邦学习系统来运行——对于这些，包括使用STADLE的完整实现。此外，纯聚合算法可以通过配置聚合方法直接使用STADLE进行测试。有关运行示例的信息可以在相关的`README`文件中找到。

通过`pip`安装`stadle-client`包是运行完整的联邦学习过程示例所必需的。以下命令可以用来执行此安装：

[PRE0]

建议使用虚拟环境来隔离`stadle-client`安装的特定包版本与其他系统上的安装。

# 重新审视聚合

为了在联邦学习中将聚合的上下文语境化，首先，我们描述了应用联邦学习所必需的系统组件：

+   一组执行联邦学习本地训练部分的计算代理。

+   每个代理都拥有一个本地数据集（静态或动态），在严格的联邦学习场景下，其任何部分都不能被发送给另一个代理。

+   每个代理都拥有一个参数化的模型，可以在本地数据集上进行训练，这个过程产生了模型的本地最优参数集。

+   参数服务器或聚合器，在每个迭代中从代理那里接收本地训练的模型，并返回由所选聚合方法产生的结果模型。

每一轮联邦学习通信都可以分解为以下两个阶段：

+   *本地训练阶段*，在这个阶段，代理在其本地数据集上对本地模型进行多次迭代训练

+   *聚合阶段*，在这个阶段，代理将上一阶段训练好的本地模型发送给聚合器，并接收聚合模型作为下一轮本地训练阶段的起始模型。

那么，在聚合阶段，一个代理发送一个本地训练的模型究竟意味着什么？一般的方法是使用定义本地模型的*参数集*，允许在所有可以以这种方式参数化的模型之间实现一定程度的泛化。然而，第二种方法侧重于在基于梯度的优化方法中，将本地训练期间累积的*本地梯度*发送给聚合器，代理在每一轮结束时使用接收到的聚合梯度更新他们的模型。虽然这种方法限制了只能使用基于梯度的本地训练方法的模型，但这种方法在训练深度学习模型时的普遍性导致了基于梯度聚合的聚合方法的一个子集。在本章中，我们选择通过FedAvg算法的视角来构建模型聚合的框架。

# 理解FedAvg

在[*第3章*](B18369_03.xhtml#_idTextAnchor058)“联邦学习系统的工作原理”中，介绍了名为FedAvg的聚合算法，以帮助阐明一般结构和用具体示例表示之前讨论的更抽象的概念。FedAvg被用于两个原因：底层算法的简单性和比基于梯度的方法更广泛模型类型的通用性。它还受益于研究者的广泛引用，在提出新的聚合方法时，使用FedAvg作为基准在不同理论场景中进行性能分析。这种研究界的关注很可能归因于原始FedAvg论文是由第一个将FL的概念和好处公之于众的谷歌团队发表的。关于进一步阅读，这篇论文可以在[https://arxiv.org/abs/1602.05629?context=cs](https://arxiv.org/abs/1602.05629?context=cs)找到。

FedAvg之前有一个称为**联邦随机梯度下降**（**FedSGD**）的聚合方法。FedSGD可以看作是FedAvg执行的模型参数平均的梯度聚合类似物。此外，在FL的背景下，在FedAvg之前还研究了平均模型参数的概念，用于并行化SGD方法。本质上，这些并行化SGD方法的分析反映了FedAvg的**独立同分布**（**IID**）情况——这一概念将在后面的章节中讨论。无论如何，FedAvg的简单性、通用性和流行性使其成为深入研究的好基础，为后面章节中讨论的众多聚合方法提供了背景，这些方法基于或改进了FedAvg。

以前，FedAvg仅被呈现为一个算法，它接受具有相应本地数据集大小的模型 *![](img/B18369_07_F05.png)*，其中总和等于 *N*，并返回：

![图片](img/B18369_07_F06.jpg)

如[*第4章*](B18369_04.xhtml#_idTextAnchor085)中“聚合本地模型”部分所示，*使用Python实现的联邦学习服务器实现*（simple-fl）使用以下函数根据每个模型本地训练所使用的数据量来计算缓冲模型（当前轮次中客户端发送的模型）的加权平均值：

[PRE1]

原始算法与这种描述差异不大。算法的高级步骤如下：

1.  服务器随机抽取 *K * C* 个客户端，其中 *K* 是客户端的总数，*C* 是介于0和1之间的一个参数。

1.  选定的 *K * C* 客户端接收最新的聚合模型，并开始在他们的本地数据上训练模型。

1.  每个客户端在完成一定量的训练后，将其本地训练的模型发送回服务器。

1.  服务器计算接收到的模型的参数算术平均值，以计算最新的聚合模型。

可以立即将这种形式表示与我们对联邦学习过程的介绍进行比较，其中 `ClientUpdate` 为代理执行本地训练，服务器使用相同的加权平均算法进行聚合。一个重要点是，在每一轮中采样一部分客户端进行本地训练和模型传输，允许通过 C 参数进行客户端子采样。这个参数包括实验性地确定各种客户端集大小的收敛速度——在理想情况下，这个值将被设置为 `1`。

如前所述，FedAvg 是一种理想的联邦学习场景，本质上反映了并行化随机梯度下降的方法。在 **并行化随机梯度下降（pSGD**）中，目标是利用硬件并行化（例如，在多个核心上并行运行）来加速特定机器学习任务上的 SGD 收敛。为此任务的一种方法是每个核心并行地在数据的一些子集上训练基础模型若干次迭代，然后聚合部分训练好的模型，并使用聚合模型作为下一次训练的基础。在这种情况下，如果将核心视为联邦学习场景中的代理，那么并行化 SGD 方法与理想情况下的 FedAvg 是相同的。这意味着为 pSGD 所做的所有收敛保证和相应的分析都可以直接应用于 FedAvg，假设是理想联邦学习场景。因此，从这项先前工作中可以看出，FedAvg 显示出强大的收敛速度。

在对 FedAvg 进行了所有这些赞誉之后，自然会质疑为什么更复杂的聚合方法甚至有必要。回想一下，在讨论 FedAvg 收敛时，多次使用了“理想联邦学习场景”这个短语。不幸的现实是，大多数实际的联邦学习应用将无法满足该短语所规定的条件之一或多个。

理想联邦学习场景可以分解为三个主要条件：

+   用于训练的本地数据集是 IID（数据集是从相同的数据分布中独立抽取的）。

+   计算代理在计算能力上相对同质。

+   可以假设所有代理都不是对抗性的。

从高层次来看，为什么这些特性在联邦学习场景中是可取的是显而易见的。为了更详细地了解为什么这三个条件是必要的，将在接下来的小节中检查在没有每个条件的情况下 FedAvg 的性能。

## 数据集分布

为了检验非IID情况下的FedAvg，首先，定义数据集的分布究竟指的是什么非常重要。在分类问题中，数据分布通常指的是与每个数据点相关的真实类别的分布。例如，考虑MNIST数据集，其中每个图像是从0到9的手写数字。如果从数据集中抽取1,000个图像的均匀随机样本，每个类别的预期图像数量将是相同的——这可以被认为是一种均匀数据分布。或者，一个包含910个数字0的图像和10个其他数字的图像的样本将是一个严重偏斜的数据分布。

为了将定义推广到分类任务之外，可以将它扩展到指代数据集中存在的*特征*的分布。这些特征可能是手动制作并提供给模型的（例如线性回归），或者它们可以作为模型管道的一部分从原始数据中提取（例如深度CNN模型）。对于分类问题，类分布通常包含在特征分布中，这是由于隐含的信念，即特征足以正确预测类别。查看特征分布的好处是，它关注于数据（相对于关注于任务的类别），允许在机器学习任务中进行泛化。

然而，在实验分析的情况下，从数据集中轻松构建非IID样本的能力使得分类任务非常适合测试FedAvg在FL环境中的鲁棒性以及不同的聚合方法。为了在本节中检验FedAvg，考虑一个玩具FL场景，其中每个代理在前面描述的MNIST数据集的数据样本上训练CNN。有两种主要情况，下面将详细说明。

### IID情况

模型的收敛可以通过使用模型参数空间来表示。具有*n*个参数的模型参数空间可以被视为一个*n*-维欧几里得空间，其中每个参数对应于空间中的一个维度。考虑一个初始化的模型；这个模型的初始参数可以表示为参数空间中的一个*点*。随着局部训练和聚合的发生，这个代表点将在参数空间中移动，最终目标是收敛到空间中的一个点，该点对应于损失或误差函数的最小化局部最优。

这些函数的一个关键点是它们依赖于在本地训练过程中使用的数据 – 当代理之间的数据集是 IID 时，相应的损失/误差函数的最优解在参数空间中相对接近。考虑一个简单的情况，即数据集是 IID，并且所有模型都使用相同的参数初始化。如[*第 3 章*](B18369_03.xhtml#_idTextAnchor058)中[*联邦学习系统的工作原理*](B18369_03.xhtml#_idTextAnchor058)的[*模型聚合基础*](B18369_03.xhtml#_idTextAnchor058)部分所示，参数空间的一个简化版本可以表示如下：

![图 7.1 – 具有相同初始化和 IID 数据集的模型

![img/B18369_07_01.jpg]

图 7.1 – 具有相同初始化和 IID 数据集的模型

观察两个模型如何从相同的起点（紫色 x）开始，并朝向相同的最优解（紫色点）移动，从而产生接近两个模型共享的最优解的聚合模型。

由于代理之间误差/损失函数的相似性，模型在训练过程中倾向于收敛到相同或相似的最优解。这意味着在每个聚合步骤之后，模型的变化相对较小，导致收敛速度与单本地模型情况相匹配。如果底层数据分布代表真实数据分布（例如，MNIST 中的 10 个不同数字是均匀的），则生成的聚合模型将表现出强大的性能。

接下来，考虑每个模型分别初始化的广义 IID 情况：

![图 7.2 – 具有不同初始化和 IID 数据集的模型

![img/B18369_07_02.jpg]

图 7.2 – 具有不同初始化和 IID 数据集的模型

在这种情况下，观察两个模型如何从不同的起点（粗体/虚线 *x*）开始，并最初朝向不同的最优解移动，从而产生一个较差的第一个模型。然而，在第一次聚合之后，两个模型从相同的起点开始，并朝向相同的最优解移动，导致与第一个案例相似的收敛。

应该很明显，在第一次聚合步骤之后，这会简化为之前的情况，因为每个模型都从聚合参数开始第二轮。因此，之前所述的收敛属性可以扩展到具有 IID 本地数据集的 FedAvg 的一般情况。

### 非IID情况

在 IID 本地数据集情况下，允许收敛速度与单模型情况相匹配的关键属性是由于它们从相似的数据分布中构建，损失/误差函数的局部最优相似性。在非 IID 情况下，最优相似性通常不再观察到。

以MNIST为例，让我们考虑一个有两个代理的FL场景，其中第一个代理只有0到4的数字图像，第二个代理只有5到9的数字图像；也就是说，数据集不是IID。这些数据集在局部训练级别本质上会导致两个完全不同的五类分类任务，而不是原始的10类分类问题——这将导致第一个代理和第二个代理之间的参数空间最优解完全不同。以下是对这个参数空间的简化表示，其中两个模型具有相同的初始化：

![图7.3 – 不同初始化和非IID数据集的模型

![img/B18369_07_03.jpg](img/B18369_07_03.jpg)

图7.3 – 不同初始化和非IID数据集的模型

现在由于最优解不再共享（分别用三角形/正方形表示粗体/点划线模型的最优解），即使重复聚合也无法创建一个接近任一模型最优解的聚合模型。由于每一轮中每个模型的目标最优解不同，模型在每次局部训练阶段都会发生分歧或漂移。

只有最优解的一小部分将在两个代理的损失/误差函数之间共享。因此，每个模型向局部训练期间未共享的最优解移动的概率很高，导致模型在参数空间中相互漂移。然后，每个聚合步骤都会将模型拉向错误的最优解，逆转局部训练期间取得的进展，并阻碍收敛。请注意，仅仅取不同代理的最优解的平均值，在参数空间中几乎不可能接近任何代理的最优解，因此在这种情况下，持续聚合的结果通常是一个在整个数据集上表现不佳的模型。由于在局部训练期间观察到的随机性，最终可能会收敛到一个共享的最优解，这会导致聚合模型在参数空间中的移动，但这没有理论保证，并且当它发生时，收敛速度将远慢于IID情况下的收敛速度。

重要提示

这个MNIST示例是非IID数据集的理论极端。在实践中，非IID数据集可能指的是代理之间数据分布的不同偏差（例如，0到4的数字图像是5到9的两倍，反之亦然）。差异的严重程度与FedAvg的性能相关，因此在较轻的情况下仍然可以达到足够的性能。然而，在这些情况下，FedAvg的性能通常始终劣于在所有本地数据集上一次性训练单个模型的类似集中式训练任务——FL能够实现的理想模型。

虽然本节重点介绍了非IID数据集引起的问题的统计基础，但下一节将探讨一个更为直接的问题，尤其是在更大规模部署时可能会出现的问题。

## 计算能力分布

参与联邦学习的代理的一个未声明的假设是，如果给予无限的时间，每个代理都能够执行本地训练。计算能力有限（内存和速度）的代理可能比其他代理花费更多的时间来完成本地训练，或者他们可能需要量化等技术来支持模型和训练过程。然而，在某些轮次中无法完成本地训练的代理将简单地通过阻碍联邦学习过程来阻止收敛。

通常，收敛界限和实验结果关注的是达到一定性能水平所需的通信轮数。在这个指标和上述假设下，收敛与分配给每个代理的计算能力完全无关，因为计算能力只影响完成一轮所需的实际时间。然而，在实际应用中，收敛速度是通过实际花费的时间来衡量的，而不是完成的通信轮数——这意味着完成每一轮的时间与轮数一样重要。这个总时间的指标是，当在参与联邦学习的代理中观察到异构计算能力时，简单的FedAvg表现不佳的地方。

具体来说，每轮完成的时间瓶颈在于参与该轮的最慢代理的本地训练时间；这是因为与大多数情况下的训练相比，聚合是极其快速的，并且必须等待所有代理完成本地训练。当所有代理都参与该轮时，这个瓶颈成为最慢的整体代理。在计算能力同质化的情况下，最快代理和最慢代理之间的本地训练时间差异将相对微不足道。在异质化的情况下，单个落后代理将大大减少FedAvg的收敛时间，并导致更快代理在等待接收聚合模型时产生显著的空闲时间。

两个针对完全参与代理的FedAvg的修改可能最初看起来可以解决这个问题；然而，两者都有缺点，导致性能次优：

+   一种方法是依靠每轮的代理子采样，导致每轮发生落后效应的概率取决于代理的数量和每轮采样的样本大小。在只有少数落后代理的情况下，这可能足够，但随着这个数量的增加，问题会成比例地恶化，并且并不能完全消除问题发生的可能性。此外，小样本大小会失去从更多代理的聚合中获得的鲁棒性优势。

+   第二种方法是允许所有代理在每个回合开始时开始本地训练，并在接收到一定数量的模型后提前开始聚合。这种方法的好处是能够在不大大限制每个回合参与聚合的代理数量的情况下，完全消除拖沓效应。然而，它会导致最慢的代理在整个回合中都不会参与聚合，这实际上减少了活跃代理的数量，并可能限制训练期间使用的数据的多样性。此外，那些太慢而无法参与聚合的代理将进行无益的计算工作。

很明显，无论在每个回合结束时应用于接收到的模型的最终聚合方法是什么，都需要基于可用的计算能力进行一些本地调整，以便有效地执行聚合。

非独立同分布案例和异构计算能力案例都关注FL系统的一般容易观察到的属性，并在一定程度上受到行政控制。我们接下来提出的案例与此不同，因为它挑战了在考虑实际FL系统时的一项关键假设。

## 防御对抗性代理

到目前为止，一直假设每个参与FL场景的代理总是以期望的方式行事；也就是说，积极且正确地在本地训练接收到的模型，并参与模型向聚合器或从聚合器传输。这在研究环境中很容易实现，其中联邦设置被模拟，代理被单独控制；然而，代理行为正确的这种假设在实践中并不总是成立。

一个不涉及针对性恶意意图的例子是代理向聚合器传输的模型权重中的错误。这可能发生在代理使用的数据集有缺陷或训练算法实现不正确（参数数据在传输过程中的损坏也是可能的）。在最坏的情况下，这可能导致一个或多个模型的参数在统计上等同于随机噪声。当随机噪声的L2范数（n维张量向量大小的扩展）不显著大于有效模型的范数时，FedAvg将遭受与故障代理与所有代理的比例成比例的性能损失——当这个比例较小时，这是相对可以接受的。然而，即使只有一个故障代理，如果代理噪声的范数显著较高，它也会导致几乎随机的聚合模型。这是由于FedAvg聚合过程中内部执行算术平均的性质。

当代理可以被恶意对手控制时，问题变得更加严重。一个拥有足够信息的恶意代理可以通过对其提交的模型参数进行大量修改，在聚合后产生任何期望的模型。即使没有直接了解其他代理的模型参数和相关权重，恶意代理也可以利用在后续回合中本地模型和聚合模型之间的相对较小变化，将之前的聚合模型作为对预期本地模型参数的估计。

因此，FedAvg在FL环境中对随机和受控的对抗性代理提供的鲁棒性很少或没有。虽然一种可能的缓解方法是对代理进行单独监控并防止对抗性代理传输模型，但在识别这些代理所需的时间内，最终模型的收敛可能已经受到了重大损害。

现在应该很清楚，FedAvg在这些非理想情况下牺牲了鲁棒性以换取计算的简单性。不幸的是，由于与研究环境相比缺乏控制，这种鲁棒性是FL实际应用中的一个关键考虑因素。下一节将重点介绍实现针对本节中提出的三个非理想情况鲁棒性的方法。

# 修改聚合以适应非理想情况

在实际的联邦学习（FL）应用中，上述构成理想FL场景的假设通常并不成立；因此，可能需要使用替代的聚合方法来最佳地执行FL。本节的目标是介绍针对异构计算能力、对抗性代理和非独立同分布（non-IID）数据集的聚合方法示例，按照难度顺序排列。

## 处理异构计算能力

如前所述，在这种情况下，理想的聚合方法始终避免出现落后效应（straggler effect），同时最大化参与FL的代理数量，并允许所有代理在一定程度上做出贡献，无论计算能力差异如何。当代理的本地训练时间显著长于大多数代理时，它们在某一回合中成为落后者。因此，有效地解决这个问题实际上需要在代理级别上在本地训练过程中具有一定的适应性，基于每个代理可用的计算能力。

### 手动调整

实现这一点的简单方法是根据每次迭代所需的时间来改变本地训练迭代的次数。换句话说，本地训练时间是固定的，每个代理尽可能在这个时间内完成尽可能多的迭代，而不是执行固定数量的迭代。这可以简单地消除落后者问题，但如果必须分配大量的本地训练时间给慢速代理以有意义地贡献，因为快速代理可能执行了过多的本地训练迭代而导致模型漂移，这可能会导致性能不佳。这可以通过设置最大本地训练迭代次数来缓解。然而，必须仔细平衡分配的本地训练时间，以便慢速代理有足够的时间产生足够的模型，同时防止快速代理在达到最大迭代次数后闲置。此外，如何预先确定这样的阈值以实现最佳性能，而不是依赖于实验结果来寻找最佳配置，目前还不清楚。

### 自动调整 – FedProx

一种称为 FedProx 的聚合方法遵循了基于计算能力动态调整每个代理的本地训练过程的相同方法，同时修改了本地训练的终止条件，以帮助进行收敛的理论分析。具体来说，固定的本地训练迭代次数被替换为训练循环的终止条件，该条件可以适应具有不同计算能力的代理。

这种终止条件的潜在概念是 γ-不精确解，当 γ-不精确最优点的梯度幅度小于本地训练开始时梯度幅度的 γ 倍时，该条件得到满足。直观地说，γ 是介于 0 和 1 之间的一个值，值越接近 0，由于更严格的终止条件，会导致更多的本地训练迭代。因此，γ 允许参数化代理的计算能力。

使用终止条件方法的一个潜在问题是，由于严格的条件，在多次本地训练迭代后，局部训练模型可能会从聚合模型中发散。为了解决这个问题，FedProx 在被最小化的目标函数中添加了一个近端项，等于以下内容：

![图片](img/B18369_07_F01.jpg)

在这里，![图片](img/B18369_07_F02.png) 表示接收到的聚合模型权重。

近端项惩罚当前权重与聚合模型权重之间的差异，通过 μ 参数参数化的强度限制上述本地模型发散。从这两个概念出发，FedProx 允许每个代理执行与每个代理的计算能力成比例的变量次数，而无需为每个代理手动调整迭代次数或分配一定量的训练时间。由于添加了近端项，FedProx 需要使用基于梯度的优化方法才能工作——有关底层理论和与 FedAvg 的比较的更多信息，可以在原始论文中找到（该论文位于 [https://arxiv.org/abs/1812.06127](https://arxiv.org/abs/1812.06127))。

### 实现FedProx

由于 FedProx 对 FedAvg 的修改都是在客户端进行的，因此 FedProx 的实际实现完全由对本地训练框架的修改组成。具体来说，FedProx 涉及本地训练的新终止条件，以及将约束项添加到本地损失函数中。因此，使用本地训练代码的示例可以帮助精确地说明如何集成 FedProx。

让我们考虑以下使用 PyTorch 的通用训练代码：

[PRE2]

让这段代码在每个回合使用接收到的聚合模型在本地数据集上执行 `num_epochs` 个训练周期。FedProx 的第一个必要修改是将固定的训练周期数替换为动态终止条件，检查是否已找到以聚合模型为初始模型的 γ-不精确解。为此，必须存储整个训练数据集上聚合模型和当前本地模型的总体梯度——这可以按以下方式执行：

[PRE3]

两个 FedProx 参数 `gamma` 和 `mu` 的值已设置，并定义了存储聚合模型和最新本地模型梯度的变量。

我们然后使用这些梯度变量定义本地训练的 γ-不精确新终止条件：

[PRE4]

在每次训练循环迭代之前检查此条件，以确定何时停止本地训练。创建 `total_grad` 变量以存储在反向传播期间从每个小批量中创建的累积梯度：

[PRE5]

为了计算近端项，计算聚合模型和最新本地模型的权重。从这些权重中，计算近端项并将其添加到损失项中：

[PRE6]

计算梯度并将其添加到存储在 `total_grad` 中的累积和中：

[PRE7]

最后，在完成当前本地训练迭代后，我们更新 `agg_grad`（如果梯度是用聚合权重计算的）和 `curr_grad`：

[PRE8]

这些修改使得FedProx可以在FedAvg之上实现。使用FedProx的完整FL示例可以在[https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7/agg_fl_examples/cifar_fedprox_example](https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7/agg_fl_examples/cifar_fedprox_example)找到。

处理异构计算能力场景的辅助方法，当观察到轻微异质性时有助于提高计算效率的想法是*聚合中的补偿*。考虑聚合发生时接收到的模型数量超过某个阈值的情况（通常，这小于参与代理的数量）。使用这个阈值可以减轻拖沓效应；然而，较慢代理所做的每轮工作最终都会被丢弃，导致训练效率低下。

补偿的核心思想是允许在某一轮次中由较慢的代理进行的本地训练被包含到下一轮次的模型聚合中。在下一轮次中，通过在聚合期间乘以用于加权平均的权重和惩罚项来补偿模型的年龄。通过这样做，较慢的代理可以获得的训练时间可以比快速代理多两到三倍，同时避免拖沓效应。为了防止较慢的代理需要过多的额外训练时间，需要轻微的异质性。这是由于在经过多轮之后给予模型的关联惩罚；它将足够严重，足以有效地导致没有贡献并减少补偿聚合 - 这是必要的，以防止过旧的模型阻碍聚合模型的收敛。

最后，我们检查帮助解决第三个非理想属性的方法，即某些代理子集被对手控制或以其他方式表现出不可取的行为。

## 对抗性代理

在上一节中，已经表明，在存在对抗性代理的情况下，FedAvg的核心问题是对聚合过程中使用的底层算术平均值的异常值缺乏鲁棒性。这自然引发了一个问题：这种均值是否可以以提供这种鲁棒性的方式估计。答案是鲁棒均值估计器类别。有许多这样的估计器，它们在鲁棒性、与真实算术平均值的距离和计算效率之间提供了不同的权衡。

作为以下聚合方法实现的基，考虑以下通用聚合函数：

[PRE9]

此函数接受一个参数向量的列表，并返回结果聚合参数向量。

现在我们将检查鲁棒均值估计器的三个示例实现。

### 使用几何中值进行聚合

样本的空间中位数是指使自身与样本之间的L1距离之和最小的点。从概念上讲，这与算术平均数相似，算术平均数是使自身与样本之间的L2距离之和最小的点。使用L1距离可以提供对异常值更大的鲁棒性；事实上，只有当至少一半的点来自对抗性代理时，才能在空间中位数中诱导出任意点。然而，空间中位数不能直接计算，而是依赖于数值近似或迭代算法来计算。

要迭代地计算几何平均数，可以使用Weiszfeld算法如下：

[PRE10]

该算法利用了这样一个事实：一组点的空间中位数是使该集合上欧几里得距离之和最小的点，在每个迭代中执行一种加权最小二乘法，权重与点与当前中位数估计的欧几里得距离成反比。

### 使用坐标中位数进行聚合

坐标中位数是通过取样本中每个坐标的中值来构建的，正如其名称所暗示的。这个中值可以直接计算，与空间中位数不同，并且由于单变量统计中中位数的性质，直观上提供了对异常值的类似鲁棒性。然而，不清楚所得到的模型在数据集性能和收敛性方面是否显示出与算术平均数有任何理论上的相似性。

NumPy使得实现这个函数变得非常简单，如下所示：

[PRE11]

很明显，坐标中位数比空间中位数更易于计算，这是以牺牲理论保证为代价来换取速度的。

### 使用Krum算法进行聚合

另一种方法是，在聚合之前从对抗性代理中隔离异常值点。这种方法的最著名例子是**Krum算法**，在该算法中，在聚合之前执行基于距离的评分，作为定位异常值点的一种手段。

具体来说，Krum算法首先计算每个点的成对L2距离——这些距离随后被用来计算每个点的分数，等于*n-f-2*个最小的L2距离之和（*f*是一个设置好的参数）。然后，Krum输出具有最低分数的点，实际上返回了与*f*个被忽略的异常值点具有最小总L2距离的点。或者，Krum使用的评分方法可以在计算算术平均值之前修剪异常值点。在两种情况下，对于足够大的*n*和*2f+2 < n*，收敛率与非对抗情况下的FedAvg相似。有关Krum算法的更多信息，可以在原始论文中找到，该论文位于[https://papers.nips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html](https://papers.nips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html)。

Krum算法可以按以下方式执行聚合：

[PRE12]

注意，已经包含了一个标志来决定应该使用两种Krum聚合方法中的哪一种（单选与修剪平均值）。向量化距离计算是可能的，但由于预期参数向量较大且代理数量较小，迭代方法被优先考虑。

## 非IID数据集

通过与独立同分布（IID）数据集合作，FL（联邦学习）所获得的理论基础在实现高性能聚合模型方面发挥着重要作用。从高层次来看，这可以通过不同数据集中模型学习到的差异来解释。当应用数据集无关的聚合方法时，无法对这些模型的收敛性做出理论保证——除非对数据集的非IID性质施加约束。关键阻碍因素是局部模型在参数空间中向非共享最优解移动的高概率，导致在每个局部训练阶段之后，局部模型与聚合模型之间的一致漂移。

有一些方法试图根据局部机器学习任务对聚合模型所做的修改进行限制，依赖于深度学习模型的过度参数化来找到相对分离的参数子集以优化每个任务的聚合模型。这种聚合方法之一是**FedCurv**，它使用先前聚合模型的Fisher信息矩阵作为局部训练期间辅助参数修改的调节器。然而，在实际应用中，对于极端非IID情况，这种方法鲁棒性的测试可能需要进一步进行，以确保可接受的性能。

### 实现FedCurv

FedCurv的实现涉及对标准FedAvg方法的两个关键修改。首先，本地损失函数必须修改以包含包含上一轮汇总Fisher信息的正则化项。其次，必须正确计算和汇总参数的Fisher信息矩阵，以便在下一轮中使用。

如*实现FedProx*部分所示，本地训练示例代码将被再次使用，以展示FedCurv的实现。在[*第4章*](B18369_04.xhtml#_idTextAnchor085) *使用Python实现联邦学习服务器*中，我们了解到一个模型转换层允许聚合器对框架无关的模型表示进行操作。以前，这些表示只包含原始模型的相关参数；然而，这种无关表示实际上允许聚合任何所需的参数，甚至那些与真实模型参数只有松散联系的那些参数。这意味着次要参数可以捆绑并随本地模型发送，汇总后，在下一轮中与汇总模型分离。

在FedCurv中，有两组参数必须在本地计算并汇总以用于下一轮；因此，可以假设这些参数在训练后与本地模型一起发送，并在训练前与汇总模型分离，以简化示例代码（此功能的实现很简单）。因此，如前所述，FedCurv的两个关键修改可以简化为在本地训练模型后计算Fisher信息参数，并使用接收到的汇总Fisher信息参数计算正则化项。

Fisher信息矩阵指的是模型对数似然函数的梯度相对于其参数的协方差，通常在现有数据上经验性地评估。FedCurv仅利用此矩阵的对角线元素，即梯度参数之间的方差及其零的期望值。

在高层次上，这个方差项可以被视为一个估计，即参数在改变模型在数据上的性能方面的影响程度。这个信息对于防止在本地训练其他代理时修改对某个数据集上良好性能至关重要的参数至关重要——这是FedCurv背后的基本思想。

将模型性能的度量从对数似然梯度放宽到任何目标函数的梯度，允许在计算使用基于梯度的优化方法（如深度学习模型）的模型的方差项时直接使用反向传播期间计算的梯度项。具体来说，参数的方差项等于其相应梯度项的平方，允许直接从本地训练期间计算的净梯度中计算这些项。

首先，我们创建两个变量来存储代理的最新Fisher信息参数和接收到的聚合Fisher信息参数，这些参数用于确定来自其他代理的Fisher信息。FedCurv的lambda参数值是固定的，`total_grad`被初始化为一个容器，用于存储每个训练循环的累积梯度：

[PRE13]

然后，我们从模型权重和聚合Fisher信息参数中计算FedCurv正则化项。这个项由lambda加权，并在计算梯度之前添加到损失项中：

[PRE14]

然后，在更新模型权重之前，我们计算并存储梯度到`total_grad`中：

[PRE15]

最后，我们计算并存储代理的最新Fisher信息参数，以便在下一轮中使用：

[PRE16]

因此，可以在FedAvg之上使用框架无关的聚合来实现FedCurv。使用FedCurv的完整FL示例可以在[https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7/agg_fl_examples/cifar_fedcurv_example](https://github.com/PacktPublishing/Federated-Learning-with-Python/tree/main/ch7/agg_fl_examples/cifar_fedcurv_example)找到。

### 数据共享方法

为了取得进一步进展，需要对FL场景的外部方面进行更改。例如，假设数据隐私限制被放宽，使得每个代理的本地数据集的小子集可以与其他代理共享。这种数据共享方法允许在本地数据分布中实现与共享数据量成比例的同质性，但以牺牲FL的关键平稳数据属性为代价，这使得它在许多以隐私为导向的应用中变得有吸引力。因此，数据共享方法通常不适合大多数应用。

### 通过微调实现个性化

当数据集是独立同分布（IID）时，产生一个在本地数据集上表现出强大性能的单个模型并不容易。然而，如果从FL过程中移除单个模型限制会发生什么？如果目标是产生在训练所进行的相同边缘设备上表现良好的本地模型，移除单个模型限制允许使用在精确数据分布上训练的不同本地模型，这些数据分布是推理应用的地方。

这个概念被称为**个性化**，其中代理使用针对本地数据分布调整过的聚合模型版本来实现强大的性能。这种方法的关键点是平衡本地训练模型的本地性能、全局性能以及每一轮接收到的聚合模型的鲁棒性。实现这一目标的一种方法是在每一轮中，每个代理都保持其本地模型，通过每一轮将前一个本地模型和接收到的聚合模型的加权平均值更新本地模型。

或者，考虑一种放松，允许在每一轮中产生多个聚合模型。在本地数据分布可以被聚类成几个分离组的情况下，分布感知聚合允许对属于同一分布聚类的模型组选择性地应用聚合方法。

这种方法的例子之一是**基于性能的邻近选择**（**PENS**）算法，其中代理在第一阶段从其他代理那里接收本地训练的模型，并在自己的本地数据集上对其进行测试。利用在相似数据集上训练的模型将比在差异数据集上训练的模型表现更好的假设，代理随后确定具有相似数据分布的其他代理的集合，允许在第二阶段只与相似代理进行聚合。

第二种方法是在本地模型和全局聚合模型之间添加一个中间聚合步骤，称为集群模型。通过利用关于代理数据分布的知识或通过动态分配方法，具有相似数据分布的代理可以被分配到一个集群聚合器，由于其代理拥有独立同分布的数据集，因此该聚合器产生的模型强度较大。

平衡集群模型的表现和全局聚合的鲁棒性导致了半全局模型的概念，在这种模型中，可以从集群模型中选择子样本（可能基于数据分布）来创建一个较小的部分全局聚合模型集，这些模型集可以保持性能和鲁棒性。因此，集群和半全局模型方法对聚合和实现完全分布式联邦学习系统都有益。

# 摘要

本章的目标是提供一个关于当前聚合知识的概念概述，这是联邦学习中的关键理论步骤，允许每个代理执行的非连接训练以最小的传输需求汇总在一起。FedAvg是一个简单但出奇强大的聚合算法，在理想的联邦学习场景中表现良好。当使用具有相似计算能力的机器在独立同分布数据集上进行训练，并且没有对抗性或其他表现不佳的代理时，这种场景得以实现。

不幸的是，在现实世界中部署联邦学习系统时，这些条件往往无法满足。为了解决这些问题，我们引入并实施了修改后的聚合方法：FedProx、FedCurv和三种不同的鲁棒均值估计器。阅读完这一章后，你应该对实际联邦学习应用中必须考虑的因素有了一个坚实的理解，并且应该能够将这些算法集成到这些应用中。

在下一章中，我们将通过几个玩具示例深入探讨一些现有的联邦学习框架，以展示每个框架提供的功能。

# 第3部分 联邦学习应用的生产化

在这部分，你将了解现有的**联邦学习**（**FL**）框架，例如**TensorFlow Federated**（**TFF**）、PySyft、Flower和STADLE，并学习它们的库以及如何实际运行这些框架。此外，通过了解全球范围内正在实施的当前和潜在用例，特别是全球企业公司中的用例，你将了解现实世界中的联邦学习情况。本书通过探讨联邦学习的未来趋势和发展，来理解人工智能技术本身的发展方向，以展望智慧驱动的未来。

本部分包括以下章节：

+   [*第8章*](B18369_08.xhtml#_idTextAnchor191), *介绍现有的联邦学习框架*

+   [*第9章*](B18369_09.xhtml#_idTextAnchor224), *联邦学习应用的关键用例案例研究*

+   [*第10章*](B18369_10.xhtml#_idTextAnchor256), *未来趋势与发展*
