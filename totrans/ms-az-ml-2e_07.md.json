["```py\n    from azureml.core import Datastore, Dataset\n    import pandas as pd\n    import seaborn as sns\n    import numpy as np\n    import plotly.express as px\n    import matplotlib.pyplot as plt\n    # retrieve an existing datastore in the workspace by name\n    datastore_name = 'mldemoblob'\n    datastore = Datastore.get(ws, datastore_name)\n    # create a TabularDataset from the file path in datastore\n    datastore_path = [(datastore, 'melb_data.csv')]\n    tabdf = Dataset.Tabular.from_delimited_files\n           (path=datastore_path)\n    ```", "```py\n    # increase display of all columns of rows for pandas datasets\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    # create pandas dataframe\n    raw_df = tabdf.to_pandas_dataframe()\n    raw_df.head()\n    ```", "```py\n    raw_df.shape\n    ```", "```py\n    stats = []\n    for cl in raw_df.columns:\n        stats.append((cl,\n                      raw_df[cl].nunique(), \n                      raw_df[cl].isnull().sum(),\n                      raw_df[cl].isnull().sum() * 100 / \n                                       raw_df.shape[0],\n                      raw_df[cl].value_counts(\n                           normalize=True, \n                            dropna=False).values[0] * 100,\n                      raw_df[cl].dtype))\n    # create new dataframe from stats   \n    stats_df = pd.DataFrame(stats, columns=[\n                  'Feature', \n                  'Unique Values',\n                  'Missing Values',\n                  'Missing Values [%]', \n                  'Values in the biggest category [%]', \n                  'Datatype'])\n    stats_df.sort_values('Missing Values [%]',\n                         ascending=False)\n    ```", "```py\n    df = raw_df.drop(['Address', 'SellerG'],axis=1)\n    ```", "```py\n    df = df.rename(columns={'Bedroom2': 'Bedrooms', \n                            'Bathroom': 'Bathrooms',\n                            'Regionname': 'Region',\n                            'Car': 'Parking',\n                            'Propertycount':  \n                            'SuburbPropCount'})\n    df.head()\n    ```", "```py\n    s = df.duplicated(keep = False)\n    s = s[s == True]\n    s\n    ```", "```py\ndf.loc[[7769,7770]]\n```", "```py\ndf.drop([7769], inplace=True)\n```", "```py\n    df['Method'].unique()\n    ```", "```py\ndf['Type'].unique()\n```", "```py\ndf = df.replace({'Type':  \n               {'h':'house','u':'unit','t':'townhouse'}})\ndf = df.replace({'Method': {'S':'Property Sold',\n                            'SP':'Property Sold Prior',\n                            'PI':'Property Passed In',\n                            'VB':'Vendor Bid', \n                            'SA':'Sold After Auction'}})\ndf.head()\n```", "```py\n    df['CouncilArea'].unique()\n    ```", "```py\narray(['Yarra', 'Moonee Valley', 'Port Phillip', 'Darebin', 'Hobsons Bay', 'Stonnington', 'Boroondara', 'Monash', 'Glen Eira', 'Whitehorse', 'Maribyrnong', 'Bayside', 'Moreland', 'Manningham', 'Banyule', 'Melbourne', 'Kingston', 'Brimbank', 'Hume', None, 'Knox', 'Maroondah', 'Casey', 'Melton', 'Greater Dandenong', 'Nillumbik', 'Whittlesea', 'Frankston', 'Macedon Ranges', 'Yarra Ranges', 'Wyndham', 'Cardinia', 'Unavailable', 'Moorabool'], dtype=object)\n```", "```py\n    postcodes_df = df.groupby(\n        'Postcode', as_index=False).Suburb.nunique()\n    postcodes_df.columns = ['Postcode', \n                            '#Assigned Suburbs']\n    postcodes_df.loc[postcodes_df['#Assigned Suburbs'] > 1]\n    ```", "```py\npostcodes_df.loc[postcodes_df['#Assigned Suburbs'] > 1].count()\n```", "```py\ndf = df.drop(['Postcode'],axis=1)\ndf.head()\n```", "```py\ndist_df = df.describe().T.apply(lambda s: s.apply(lambda x: format(x, 'g')))\ndist_df\n```", "```py\nfrom pandas.api.types import is_numeric_dtype\nmax_count=[]\nmin_count=[]\nmode_count=[]\nmode=[]\nskew=[]\nfor cl in df.columns:\n    if (is_numeric_dtype(df[cl])):\n        max_count.append(df[cl].value_counts(\n                         dropna=False).loc[df[cl].max()])\n        min_count.append(df[cl].value_counts(\n                         dropna=False).loc[df[cl].min()])\n        mode_count.append(df[cl].value_counts(\n                     dropna=False).loc[df[cl].mode()[0]])\n        skew.append(df[cl].skew())\n        mode.append(int(df[cl].mode()[0]))\ndist_df['mode'] = mode\ndist_df['skew'] = skew\ndist_df['#values(min)'] = min_count\ndist_df['#values(max)'] = max_count\ndist_df['#values(mode)'] = mode_count\ndist_df\n```", "```py\nfig = px.box(df, x=\"Price\",points=\"all\")\nfig.show()\n```", "```py\ndf[\"Price_log\"] = np.log(df['Price']) \nfig = px.box(df, x=\"Price_log\",points=\"all\")\nfig.show()\n```", "```py\nfig = px.box(df, y=\"BuildingArea\",points=\"all\")\nfig.show()\n```", "```py\ndf.loc[raw_df['BuildingArea'] > 295]['BuildingArea'].count()\n```", "```py\ndf.loc[raw_df['BuildingArea'] > 2000]\n```", "```py\ndf.drop([13245], inplace=True)\n```", "```py\nDataset.Tabular.register_pandas_dataframe(\n        dataframe = df, \n        target = datastore, \n        name ='Melbourne Housing Dataset', \n        description = 'Data Cleansing 1 - removed address,    \n                       postcode, duplicates and outliers')\n```", "```py\ndf.dropna(how='any').shape\n```", "```py\nimport missingno as msno\nmsno.matrix(df);\n```", "```py\ndf.loc[df.CouncilArea.isin(['Unavailable'])]\n```", "```py\ndf['CouncilArea'].fillna(value = \"Missing\", inplace = True)\ndf['CouncilArea'].replace(to_replace=\"Unavailable\", value=\"Missing\", inplace=True)\n```", "```py\ndf['CouncilArea'].unique()\n```", "```py\nBA_mean = df['BuildingArea'].mean()\ndf['BuildingArea'].replace(to_replace=np.nan, value=BA_mean, inplace=True)\ndf['BuildingArea'].isnull().sum()\n```", "```py\n# compute the correlation matrix\ncorr = df.corr()\n# define and create seaborn plot\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n            center=0, square=True, linewidths=.5, \n            cbar_kws={\"shrink\": .5})\nplt.show()\n```", "```py\nobj_df = df.select_dtypes(include=['object']).copy()\nobj_df.head()\n```", "```py\nfor cl in obj_df.columns:\n    obj_df[cl] = obj_df[cl].astype('category')\nobj_df.dtypes\n```", "```py\nfor cl in obj_df.columns:\n     obj_df[cl+\"_cat\"] = obj_df[cl].cat.codes\nobj_df.head()\n```", "```py\ncolumn_replacement = {'Type':'Type_cat','Suburb':'Suburb_cat','Method':'Method_cat','CouncilArea':'CouncilArea_cat','Region':'Region_cat'}\ncont_df = df.copy()\nfor key in column_replacement:\n     cont_df[key] = obj_df[column_replacement[key]]\ncont_df.dtypes\n```", "```py\ncont_df['Date_Epoch'] = cont_df['Date'].apply(lambda x: x.timestamp())\ncont_df.drop(['Date'], axis=1, inplace=True)\ncont_df.dtypes\n```", "```py\nfor cl in cont_df.columns:\n    if (cont_df[cl].dtype == np.float64 and cl not in    \n                                   ['Lattitude', 'Longtitude', \n                                    'Price_log', 'Distance']):\n       cont_df[cl] = cont_df[cl].astype('int')\ncont_df.dtypes\n```", "```py\nfig = px.box(df, y=\"Price_log\",x='Type', color = 'Type', \n                 category_orders={\"Type\": [\"house\",\n                                  \"townhouse\", \"unit\"]})\nfig.show()\n```", "```py\nimport seaborn as sns\nsns.set(style=\"ticks\")\ndf = sns.load_dataset(\"iris\")\nsns.pairplot(df, hue=\"species\")\n```", "```py\nwith exp.start_logging() as run:\n  fig = sns.pairplot(df, hue=\"species\")\n  run.log_image(\"pairplot\", plot=fig)\n```"]