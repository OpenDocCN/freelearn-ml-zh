["```py\nimport boto3\nclient = boto3.client('comprehend')\nresponse = client.detect_entities(Text='<input text>') \n```", "```py\nimport boto3\nclient = boto3.client('textract')\nresponse = client.detect_document_text(\n        Document={\n            'Bytes': b'bytes',\n            'S3Object': {\n                'Bucket': '<S3 bucket name>',\n                'Name': '<name of the file>'}\n}) \n```", "```py\nboto3 APIs for Rekognition can be found at https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html:\n```", "```py\nimport boto3\nclient = boto3.client('rekognition')\nresponse = client.detect_labels(\n    Image={\n        'Bytes': b'bytes',\n        'S3Object': {\n            'Bucket': '<S3 bucket name>',\n            'Name': '<file name>'\n        }\n    }) \n```", "```py\nimport boto3\ntranscribe_client = boto3.client('transcribe')\ntranscribe_job = transcribe_client.start_transcription_job(**job_args) \n```", "```py\nimport boto3\nclient = boto3.client('personalize')\nresponse = client.create_campaign(\n    name='<name of the campaign>',\n    solutionVersionArn='<AWS Arn to the solution>',\n    minProvisionedTPS=<provisioned TPS>,\n    campaignConfig={\n        'itemExplorationConfig': {\n            '<name of configuration>': '<value of configuration>'\n        }}) \n```", "```py\nkendra = boto3.client('kendra')\nquery = '${searchString}'\nindex_id = '${indexID}'\nresponse=kendra.query(\nQueryText = query, IndexId = index_id) \n```", "```py\n        from pprint import pprint\n        import boto3 items_to_show = 10\n        with open('data/comprehend_sample.txt') as sample_file:\n            sample_text = sample_file.read()\n        comprehend_client = boto3.client('comprehend') \n        ```", "```py\n        print(\"detecting dominant language\")\n        languages = comprehend_client.detect_dominant_language(\n                        Text=sample_text)\n        lang_code = languages['Languages'][0]['LanguageCode']\n        pprint(lang_code) \n        ```", "```py\n        print(\"Detecting entities using the pre-trained model.\")\n        entities = comprehend_client.detect_entities(\n                        Text=sample_text, LanguageCode=lang_code)\n        print(f\"The first {items_to_show} are:\")\n        pprint(entities['Entities'][:items_to_show]) \n        ```", "```py\n        print(\"Detecting sentiment in text\")\n        sentiment = comprehend_client.detect_sentiment(\n                        Text=sample_text, LanguageCode=lang_code)\n        pprint(sentiment['Sentiment'])\n        pprint(sentiment['SentimentScore']) \n        ```", "```py\n        print(\"Detecting pii entities in text\")\n        pii = comprehend_client.detect_pii_entities(\n                    Text=sample_text, LanguageCode=lang_code)\n        pprint(pii['Entities'][:items_to_show]) \n        ```", "```py\n        print('Dectecting key phrases')\n        key_phrases = comprehend_client.detect_key_phrases(\n                        Text=sample_text, LanguageCode=lang_code)\n        pprint(key_phrases['KeyPhrases'][:items_to_show]) \n        ```", "```py\n        print('Detecting syntax')\n        syntax = comprehend_client.detect_syntax(\n                        Text=sample_text, LanguageCode=lang_code)\n        pprint(syntax['SyntaxTokens'][:items_to_show]) \n        ```", "```py\n        from pprint import pprint\n        import boto3\n        import time\n        transcribe_client = boto3.client('transcribe')\n        s3_resource = boto3.resource('s3') \n        ```", "```py\n        bucket_name = f'transcribe-bucket-{time.time_ns()}'\n        bucket = s3_resource.create_bucket(\n                Bucket=bucket_name,\n                CreateBucketConfiguration={\n                    'LocationConstraint': transcribe_client.meta.region_name})\n        media_file_name = 'data/transcribe_sample.mp3'\n        media_object_key = 'transcribe_sample.mp3'\n        bucket.upload_file(media_file_name, media_object_key)\n        media_uri = f's3://{bucket.name}/{media_object_key}' \n        ```", "```py\n        job_name = f'transcribe_job_{time.time_ns()}'\n        media_format = 'mp3'\n        language_code = 'en-US'\n        job_args = {\n                    'TranscriptionJobName': job_name,\n                    'Media': {'MediaFileUri': media_uri},\n                    'MediaFormat': media_format,\n                    'LanguageCode': language_code}\n        transcribe_job = transcribe_client.start_transcription_job(**job_args) \n        ```", "```py\n        from pprint import pprint\n        import boto3\n        textract_client = boto3.client('textract') \n        ```", "```py\n        document_file_name = 'data/textract_sample.png'\n        with open(document_file_name, 'rb') as document_file:\n                        document_bytes = document_file.read() \n        ```", "```py\n        print('Detecting tables and forms')\n        feature_types = ['TABLES', 'FORMS']\n        tables_forms = textract_client.analyze_document(\n                Document={'Bytes': document_bytes},\n                FeatureTypes=feature_types)\n        blocks_to_show = 10\n        pprint(tables_forms['Blocks'][:blocks_to_show]) \n        ```", "```py\n        print('Detect text')\n        text = textract_client.detect_document_text(\n                Document={'Bytes': document_bytes})\n        blocks_to_show = 20\n        pprint(text['Blocks'][:blocks_to_show]) \n        ```"]