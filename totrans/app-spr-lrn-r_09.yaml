- en: '*Chapter 9:*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Capstone Project - Based on Research Papers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Apply end-to-end machine learning workflow on a problem using mlr and OpenML,
    which involves identifying research articles.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train machine learning model and, subsequently, predict and evaluate using the
    model on a test dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform resampling on the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design experiments for building various models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build benchmarks for choosing the best model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will take up the latest research paper based on a real-world
    problem and will reproduce the result.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this final chapter, we will focus on working on a research-based capstone
    project. The ideas from all the previous chapters such as designing the problem
    using the SCQ framework, identifying the source of data, preprocessing the dataset,
    training a machine learning model, evaluating a model, applying resampling techniques,
    and many other concepts will be used. Additionally, this chapter will also focus
    on benchmarking models, designing experiments in machine learning, collaborating
    in open source platforms, and making a research work reproducible for the benefits
    of the larger community.
  prefs: []
  type: TYPE_NORMAL
- en: The abundance of online resources, computation power, and out-of-the-box toolkit
    solutions has made the entry barrier in becoming a machine learning professional
    minimum. Today, we have plenty of quickstart algorithms provided as a function
    in a package in programming languages such as R and Python, or even as a drag
    and drop in platforms such as Google Cloud AutoML or Microsoft Azure Machine Learning
    Studio. However, what is often missing in many such quick start Hello World models
    is the keen focus on problem solving and the ability to go beyond the available
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the extravagant toolkits, there exists a world of research-oriented
    work produced by many leading practitioners from academia and industry. The importance
    of such research work is immense when it comes to producing breakthrough and high-quality
    outcomes. However, the accessibility of such research work is limited and hence
    prevents the widespread adoption among machine learning practitioners. Another
    reason why one does not pursue research-based work is because of the lack of reproducibility
    (mostly because of code not being available in public domain, unclear research
    finding, or poor quality of the research work) and jargon-filled theory (many
    written in mathematical language) found in research articles or papers.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is dedicated to such research work, which often goes unnoticed
    by many learners who endeavor into machine learning but limit themselves to using
    only specific tools and packages advocated in blogs or online books. We will focus
    on two significant research works, which, fortunately, also found a place in R
    packages. The next section will introduce the work and set the flow of the rest
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Research Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we will explore the two most significant research works that
    eventually also became an open source offering. The emphasis in this chapter is
    given onto a top-down approach, where we will start from the origin of excellent
    research work and see how it became a mainstream toolkit for everyone to use.
    While emphasizing on research work, we would like to highlight that a lot of research
    work does not find its place in the standard toolkit available in the market,
    but some gems could be found if one works slightly harder.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend following the fantastic effort put by the creators of https://paperswithcode.com.
    The **Papers With Code** team has created a free and open resource platform with
    machine learning papers, code, and evaluation tables with the help from the community
    and powered by automation. They have already automated the linking of code to
    papers, and they are now working on automating the extraction of evaluation metrics
    from papers. The work is commendable because it will bring the best research work
    to stand out amid the noise and abundance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table will highlight five cases of research work, which we found
    through the Papers With Code website. Throughout this book, you would have seen
    a lot of R code using various packages for each stage of the machine learning
    workflow. The work done by the researchers of mlr and OpenML is now packaged in
    R, and in particular, OpenML is a complete platform. We will learn how to leverage
    the mlr and OpenML platforms to produce the best machine learning model, beyond
    just the quickstart **Hello World** examples. For reference, review the following
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1: Research papers used in this lesson for demonstration (Part 1)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.1: Research papers used in this chapter for demonstration (Part 1)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.2: Research papers used in this lesson for demonstration (Part 2)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.2: Research papers used in this chapter for demonstration (Part 2)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The mlr Package
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we shall go into learning how the mlr package offers a complete framework
    to work with many machine learning models and problem. Often, in many ML projects,
    one has to manage an overwhelming amount of detailing around numerous experiments
    (also called **trial-and-error iterations**). Each experiment consists of many
    pieces of training using different machine learning algorithms, performance measures,
    hyperparameters, resampling techniques and predictions. Unless we do not systematically
    analyze the information obtained in each experiment, we will not be able to come
    out with the best combination of parameter values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another advantage of using the mlr package comes from its rich collection of
    machine learning algorithms from various packages. We do not have to install multiple
    packages for different implementation of the machine learning algorithm anymore.
    Instead, mlr offers everything in one place. To understand this better, refer
    to the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3: The mlr Package (Part 1)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.3: The mlr Package (Part 1)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Multilabel Classification Algorithms**'
  prefs: []
  type: TYPE_NORMAL
- en: The following models are available in the mlr package for multilabel classification,
    where one observation could be assigned to more than one class. These models are
    useful in solving many useful problems, such as, in Netflix, you will see that
    each movie could be tagged as Action, Adventure and Fantasy. Alternatively, in
    YouTube, where millions of videos are posted every day, an automatic algorithm
    could tag the videos into multiple class and hence help in content filtering and
    better search.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use these algorithms along with the classifiers defined in the previous
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4: Multilabel classification with the mlr package'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.4: Multilabel classification with the mlr package'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: OpenML Package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenML, a collaboration platform through which researchers from academia and
    industry can automatically share, organize, and deliberate machine learning experiments,
    data, algorithms, and flows. The platform brings efficient collaboration and results
    in reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenML package in R comes with various features that allow users to search,
    upload, and download the datasets and perform Machine Learning related operations.
    A user can upload the output of ML experiments, share them with other users, and
    download the output results. This enhances the reproducibility of work, speeds
    up the research work, and brings people from different domains together.
  prefs: []
  type: TYPE_NORMAL
- en: Problem Design from the Research Paper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this chapter, we will understand, analyze, and reproduce the results from
    the *Learning multi-label scene classification* paper. We will effectively use
    the mlr and OpenML packages to reproduce the result. Before that, let’s write
    the **Situation-Complication-Question** from the paper using the **SCQ framework**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5: SCQ from the paper Learning multi-label scene classification'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.5: SCQ from the paper Learning multi-label scene classification'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Features in Scene Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The paper uses the `scene` dataset for semantic scene classification task.
    The dataset is a collection of images of natural scenes, where a natural scene
    may contain multiple objects, such that multiple class labels can describe the
    scene. For example, a field scene with a mountain in the background. From the
    paper, we have taken the first figure, which shows two images that are multilabel
    images depicting two different scenes in a single image. *Figure 9.6* is a beach
    and urban scene, whereas *Figure 9.7* shows mountains:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6: A beach and urban scene.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.6: A beach and urban scene.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.7: A mountains scene.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.7: A mountains scene.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'From the given images, we could use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Color information**: This information is useful when differentiating between
    certain types of outdoor scenes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial information**: This information is useful in various cases. For example,
    light, warm colors at the top of the image may correspond to sunrise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The paper uses *CIE L*U*V**, such as space, denoted as Luv. Luv space proposes
    the anticipated perceptual uniformity. After adaptation (a mathematical transformation
    from the XYZ space to the *L*U*V* space) to Luv spaces, the image is divided into
    49 blocks using a 7 x 7 grid. Then, the authors calculate the first and second
    moment (mean and variance) of each band (RGB), which corresponds to a low-resolution
    image and to computationally low-cost quality features, respectively. In total,
    we obtain *49 x 2 x 3 = 294* features vector per image.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining six columns in the dataset correspond to the six labels represented
    in a true/false encoded value. If an image belongs to two classes, the respective
    column will have true value.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In colorimetry, the CIE 1976 L*, u*, v* color space, was adopted by the **International
    Commission on Illumination** (**CIE**) in 1976, as a simple-to-compute transformation
    of the 1931 CIE XYZ color space, but which attempted perceptual uniformity, which
    is the difference or distance between two colors.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Multilabel Classifier Using the mlr and OpenML Packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now see how to train a multilabel classifier using the mlr and OpenML
    packages. First, we will download the scene dataset from OpenML.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 102: Downloading the Scene Dataset from OpenML'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will download the scene dataset and set it up for further
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to download the scene dataset through OpenML API, first create an
    account in the OpenML website at [https://www.openml.org/register](https://www.openml.org/register).
    The registration process involves verifying your email address, post which you
    will get the access to the API keys.![Figure 9.8: The OpenML registration page.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/C12624_09_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 9.8: The OpenML registration page.'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: After logging in to your account, navigate to your account and select the API
    AUTHENTICATION option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the API Authentication page, select and copy-paste the API key from the API
    key section. The authors of the Multilabel Classification with R Package mlr paper
    uploaded a bunch of datasets with a 2016_multilabel_r_benchmark_paper tag, which
    we can now download from OpenML and start reproducing their results. We will specifically
    use the scene dataset (with ID 40595).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open RStudio and install all the required packages before proceeding.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the required packages and libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the API key from the OpenML and register the API key using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the following command to download the dataset from the source:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we will use the ID 40595 to get the scene dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Ensure that you install the farff package before proceeding with the previous
    two commands.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create the DataFrame using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.9: Environment setting of the scene.task variable.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.9: Environment setting of the scene.task variable.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this exercise, we registered an account in OpenML and obtained an API key.
    Using the API key, we were able to download the scene dataset, which has a 2016_multilabel_r_benchmark_paper
    tag in OpenML. Finally, we converted the dataset into data frame. OpenML provides
    many such features to collaborate. One can share their code, experiments, and
    flow with a larger community by assigning a tag.
  prefs: []
  type: TYPE_NORMAL
- en: Constructing a Learner
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **learner** is a machine learning algorithm implementation in the mlr package.
    As highlighted in the previous section on the mlr package, there is a rich collection
    of such learner functions in mlr.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our scene classification problem, the mlr package offers building a multilabel
    classification model in two possible ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adaptation method**: In this, we adapt an explicit algorithm on the entire
    problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformation method**: We transform the problem into a simple binary classification
    problem and then apply the available algorithm for the binary classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaptation Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The mlr package in R offers two algorithm adaption methods. First, the multivariate
    random forest algorithm that comes from the `randomForestSRC` package, and second,
    the random ferns multilabel algorithm built in the `rFerns` package.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `makeLearner()` function in mlr creates the model object for the `rFerns`
    and `randomForestSRC` algorithms, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows, which shows the information such as name and predict-type
    about the multilable.rFerns model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Ensure that you install the *rFerns* and *randomForestSRC* packages before proceeding
    with the previous two commands.
  prefs: []
  type: TYPE_NORMAL
- en: Transformation Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second method for constructing a learner is to use the `makeLearner()` function,
    and then any one of the five wrapper functions (described in the following section)
    could be utilized for problem transformation.
  prefs: []
  type: TYPE_NORMAL
- en: Binary Relevance Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In multilabel classification problems, each label could be transformed as a
    binary classification problem. In the process, any one observation could have
    multiple labels assigned to it. In the mlr package, the `makeMultilabelBinaryRelevanceWrapper()`
    method converts the binary learner method to a wrapped Binary Relevance multilabel
    learner.
  prefs: []
  type: TYPE_NORMAL
- en: Classifier Chains Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The classifier chain wrapper method implements a multilabel model, where the
    binary classifiers are arranged into a chain. Each model comes out with a prediction
    in the order specified by the chain. The model uses all the features in the given
    dataset, along with all the predictions of the model that are before in the chain.
    The `makeMultilabelClassifierChainsWrapper()` method in mlr is used to create
    the classifier chain wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: Nested Stacking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like classifier chain, however, the class (or label) of the observation are
    not the actual class but are based on estimations of the class obtained by the
    trained model (learner) from the previous model in the chain. The `makeMultilabelNestedStackingWrapper()`
    method in the mlr package is used to create the nested stacking wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: Dependent Binary Relevance Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `makeMultilabelDBRWrapper` method in the mlr package is used to create the
    dependent Binary Relevance wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: Stacking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like the dependent Binary Relevance method, however, in the training phase,
    the labels used as input for each label are obtained by the Binary Relevance method
    instead of using the actual labels. The `makeMultilabelStackingWrapper` method
    in the mlr package is used to create the stacking wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we will see how to generate decision tree model using
    the `classif.rpart` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 103: Generating Decision Tree Model Using the classif.rpart Method'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will generate the decision tree model using the `classif.rpart`
    method and then transform it using *Binary Relevance* and nested *Stacking* wrappers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, use the `makeLearner` method to create the object for `classif.rpart`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the stacking wrappers using the `makeMultilabelBinaryRelevanceWrapper`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, print the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the stacking wrappers, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the previous command is as follows, which shows the information
    such as the type of model, properties available as part of the model output, and
    the predict-type:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Train the Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can train a model as usual with a multilabel learner and a multilabel task
    as input; use the `multilabel.lrn1` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 104: Train the Model'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will first randomly split the data into train and test
    datasets and then train the model using the `tain()` function from mlr package
    and the `multilabel.lrn1` object defined in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to train, predict, and evaluate the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `test_index variable` using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `train` function, which takes model object `multilabel.lrn1` (`scene.task`
    with only randomly selected `train_index` to train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `scene_classi_mod` model using the `1684` randomly chosen observations from
    `scene` dataset is trained using the `rpart` package in R, which is an implementation
    of the **Classification and Regression Tree** (**CART**) algorithm in machine
    learning wrapped with the Binary Relevance method for multilabel classification.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the Output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Prediction can be done as usual in mlr with the `predict` function. The input
    arguments are trained models; the scene.task dataset is assigned to the `task`
    and `test_index` arguments, which correspond to the `test` dataset is assigned
    to the `subset` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Performance of the Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order assess the performance of the prediction, the mlr package offers the
    `performance()` function, which takes as an input the prediction of the model
    along with all the measures we would like to compute. All available measures for
    multilabel classification can be listed by `listMeasures()`. As per the paper,
    we use measures such as `hamloss`, `f1`, `subset01`, `acc`, `tpr`, and `ppv` on
    our predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the previous command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will list down all the measures available for multilabel
    classification problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Resampling the Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For evaluating the complete performance of the learning algorithm, we can do
    some resampling. To define a resampling strategy, either use `makeResampleDesc()`
    or `makeResampleInstance()`. After that, run the `resample()` function. Use the
    following default measure to calculate the hamming loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Binary Performance for Each Label
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can calculate a binary performance measure, for example, the accuracy, or
    the `auc` for each label, the `getMultilabelBinaryPerformances()` function is
    useful. We can apply this function to any multilabel prediction, for example,
    also on the resampled multilabel prediction. For calculating `auc`, we need predicted
    probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Benchmarking Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a benchmark experiment, different learning methods are applied to one or
    more than a few datasets with the purpose of comparing and ranking the algorithms
    concerning one or more performance measures. The `mlr()` method offers a very
    robust framework to conduct such experiments and helps in keeping track of all
    the results of the experiment to compare.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting Benchmark Experiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our first experiment, we use the multilabel `randomForestSRC` and `rFerns`
    learners of the `mlr()` package and various measures to get our first benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we will explore how to conduct a benchmarking on
    various learners.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 105: Exploring How to Conduct a Benchmarking on Various Learners'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will see how to conduct a benchmarking on various learners
    we created so far and compare the results to select the best learner (model) for
    the multilabel scene classification problem. This helps us organize all the results
    in a structured format to select the best performing model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, list all learners using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Conduct the benchmark experiment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, execute the `bmr` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Iterations of the model train will look something like the following for each
    learner:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following table demonstrates the mean of various measures on the test data:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.10: Mean of various measures on the test data.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.10: Mean of various measures on the test data.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This table shows that the `randomForestSRC` model does a slightly better job
    than `rFerns` on all the measures, primarily in the **hamloss mean measure**.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Benchmark Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `mlr()` method provides many `getBMR` functions to extract useful information
    such as performance, predictions, leaners, and many more from the benchmark experiment
    object.
  prefs: []
  type: TYPE_NORMAL
- en: Learner Performances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `getBMRPerformances` function gives all values of all the measures defined
    in the benchmark in each iteration of the training. The following table lists
    the values for each measure using the `randomForestSRC` and `rFerns` learners.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 9.11: Learner performances randomForestSRC'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.11: Learner performances randomForestSRC'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.12: Learner performances rFerns'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.12: Learner performances rFerns'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We could also get the predictions on the test dataset using the `getBMRPredictions`
    function. The two tables in this section show the actual and the predicted labels
    of a few images represented by the ID column. Observe that the predictions are
    not perfect, just as we would expect from the relatively low overall accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Predictions using randomForestSRC**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 9.13: The actual labels.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.13: The actual labels.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 9.14: The predicted labels.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.14: The predicted labels.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Learners and measures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `getBMRLearners` function gives details about the learners used in the
    benchmark. Information such as hyperparameter and predict-type could be obtained
    using this function. Similarly, the `getBMRMeasures` function provides details
    such as best about the performance measures. The following table shows the details
    about the measures we used in our benchmark experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the `getBMRMeasures(bmr)` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 9.15: Learners and measures (part 1).'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.15: Learners and measures (part 1).'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Figures 15 and 16 summarize the result of the `getBMRMeasures(bmr)` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.16: Learners and measures (part 2).'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.16: Learners and measures (part 2).'
  prefs: []
  type: TYPE_NORMAL
- en: Merging Benchmark Results
  prefs: []
  type: TYPE_NORMAL
- en: Often, we run multiple experiments and would like to see all the benchmarks
    coming from the experiments into one consolidated list of values to compare the
    results. The `mergeBenchmarkResults` function helps in combining the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the benchmark:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 9.17: Merging benchmark results.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_09_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9.17: Merging benchmark results.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Clearly, using `classif.randomForest` with the classifier chain wrapper produces
    the highest accuracy and performs well in all the other measures as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 14: Getting the Binary Performance Step with classif.C50 Learner Instead
    of classif.rpart'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, we will revisit the entire process flow of building a model,
    in which we will use the `makeLearner` function to specify the `rpart` model,
    replacing `C50`. Specifically, we will rerun the entire machine learning flow,
    starting from the problem transformation step to getting the binary performance
    step with the classif.C50 learner instead of `classif.rpart`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the algorithm adaptation methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the problem transformation method, and change the `classif.rpart` learner
    to `classif.C50`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: You need to install the `C50` package for this code to work.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Print the learner details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the multilabel learner details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the model using the same dataset with training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the model details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predict the output using the C50 model we created earlier on the test dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the performance measures.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the performance measures for the `listMeasures` variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the resampling with the cross validation method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the binary performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you complete the activity, you should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 466.
  prefs: []
  type: TYPE_NORMAL
- en: Working with OpenML Upload Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to improve collaboration and version control the experiments, we can
    upload the flows we create into OpenML using the `uploadOMLFlow` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: We encourage students to explore the OpenML platform to find many more such
    functionalities, as the platform helps researchers all around the world to collaborate
    and share their work, making good work spread fast and help build the best model
    with the collective wisdom of researchers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we used the mlr and OpenML packages from R to build an entire
    machine learning workflow for solving a multilabel semantic scene classification
    problem. The mlr package offered a rich collection of machine learning algorithms
    and evaluation measures that helped us in quick implementation and facilitated
    a faster experimentation process to get the best model for the problem. The package
    also offered many wrapper functions to handle the multilabel problem. Building
    real-world machine learning models using a robust framework such as the one in
    mlr helps in speeding the implementation and provides a structure to the complete
    project. Further, using OpenML, we could reproduce a research work using the already
    available dataset and code, and then modify it according to our need. Such a platform
    offers the ability to collaborate at scale with researchers all over the world.
    At the end, we could also upload our own machine learning flows with others for
    them to pick it up from where we left.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, our focus was to teach supervised learning in R programming language.
    Supervised learning is a class of algorithms where we are provided with labeled
    observation of data. Exploratory Data Analysis (EDA) methods help in understanding
    the dataset well, and the SCQ framework is used to design the problem precisely.
    The features are chosen on the basis of the problem design and an appropriate
    supervised learning model is selected after many rounds of experiments and evaluation.
    We then learned how to deploy machine learning models in production environment,
    which could be used by an application team in a business. Also, in cases where
    the dataset has hundreds of features, we used feature reduction and selection
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: We would like to emphasize that in any machine learning project, beyond a certain
    point (could be defined such as 3 months of effort from the start of project or
    100 trial runs with different combinations), we should stop and ask whether or
    not what we have done so far could be deployed in a production environment. If
    the answer is yes, deploy it and keep monitoring the response for any abnormality
    and improvements. If it’s a no, go back to the drawing boards and start over (obviously
    if such a luxury is given). Machine learning in stages such as hyperparameter
    fine-tuning and model selection is an art. A lot of trial-and-error experiments
    are required to come out with the best model.
  prefs: []
  type: TYPE_NORMAL
