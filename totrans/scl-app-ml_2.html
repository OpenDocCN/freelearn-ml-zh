<html><head></head><body><div class="part" title="Part&#xA0;II.&#xA0;Module 2" id="aid-4IRMK1"><div class="titlepage"><div><div><h1 class="title"><a id="part02"/>Part II. Module 2</h1></div></div></div><div class="partintro" title="Module 2"><div/><div class="blockquote"><blockquote class="blockquote"><p>
<span class="strong"><strong>Scala for Machine Learning</strong></span>
</p><p>
<span class="emphasis"><em>Leverage Scala and Machine Learning to construct and study systems that can learn from data</em></span>
</p></blockquote></div></div></div>
<div class="chapter" title="Chapter&#xA0;1.&#xA0;Getting Started" id="aid-4JQ761"><div class="titlepage"><div><div><h1 class="title"><a id="ch15"/>Chapter 1. Getting Started</h1></div></div></div><p>It is critical for any computer scientist to understand the different classes of machine learning algorithms and be able to select the ones that are relevant to the domain of their expertise and dataset. However, the application of these algorithms represents a small fraction of the overall effort needed to extract an accurate and performing model from input data. A common data mining workflow consists of the following sequential steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Defining the problem to solve.</li><li class="listitem">Loading the data.</li><li class="listitem">Preprocessing, analyzing, and filtering the input data.</li><li class="listitem">Discovering patterns, affinities, clusters, and classes, if needed.</li><li class="listitem">Selecting the model features and appropriate machine learning algorithm(s).</li><li class="listitem">Refining and validating the model.</li><li class="listitem">Improving the computational performance of the implementation.</li></ol><div style="height:10px; width: 1px"/></div><p>In this book, each stage of the process is critical to build the <span class="emphasis"><em>right</em></span> model.</p><div class="note" title="Note"><h3 class="title"><a id="tip0200"/>Tip</h3><p>It is impossible to describe the key machine learning algorithms and their implementations in detail in a single book. The sheer quantity of information and Scala code would overwhelm even the most dedicated readers. Each chapter focuses on the mathematics and code that are absolutely essential to the understanding of the topic. Developers are encouraged to browse through the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The Scala coding convention and standard used in the book in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span></li><li class="listitem">API Scala docs</li><li class="listitem">A fully documented source code that is available online</li></ul></div></div><p>This first chapter introduces you to the taxonomy of machine learning algorithms, the tools and frameworks used in the book, and a simple application of logistic regression to get your feet wet.</p><div class="section" title="Mathematical notation for the curious"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec0800"/>Mathematical notation for the curious</h1></div></div></div><p>Each <a id="id00000" class="indexterm"/>chapter contains a small section dedicated to the formulation of the algorithms for those interested in the mathematical concepts behind the science and art of machine learning. These sections are optional and defined within a tip box. For example, the mathematical expression of the mean and the variance of a variable <span class="emphasis"><em>X</em></span> mentioned in a tip box will be as follows:</p><div class="note" title="Note"><h3 class="title"><a id="tip0300"/>Tip</h3><p>
<span class="strong"><strong>Convention and notation</strong></span>
</p><p>This book uses zero-based indexing of datasets in the mathematical formulas.</p><p>M1: A set of <span class="emphasis"><em>N</em></span> observations is denoted as <span class="emphasis"><em>{xi} = x<sub>0</sub>, x<sub>1</sub>, … , x<sub>N-1</sub></em></span>, and the arithmetic mean value for the random value with <span class="emphasis"><em>xi</em></span> as values is defined as:</p><div class="mediaobject"><img src="../Images/image01236.jpeg" alt="Mathematical notation for the curious"/></div><p style="clear:both; height: 1em;"> </p></div></div></div>
<div class="section" title="Why machine learning?" id="aid-4KONO1"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec0900"/>Why machine learning?</h1></div></div></div><p>The<a id="id10000" class="indexterm"/> explosion in the number of digital devices generates an ever-increasing amount of data. The best analogy I can find to describe the need, desire, and urgency to extract knowledge from large datasets is the process of extracting a precious metal from a mine, and in some cases, extracting blood from a stone.</p><p>Knowledge is quite often defined as a model that can be constantly updated or tweaked as new data comes into play. Models are obviously domain-specific ranging from credit risk assessment, face recognition, maximization of quality of service, classification of pathological symptoms of disease, optimization of computer networks, and security intrusion detection, to customers' online behavior and purchase history.</p><p>Machine learning problems are categorized as classification, prediction, optimization, and regression.</p><div class="section" title="Classification"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec0700"/>Classification</h2></div></div></div><p>The<a id="id20000" class="indexterm"/> purpose of classification is to extract knowledge from historical data. For instance, a classifier can be built to identify a disease from a set of symptoms. The scientist collects information regarding the body temperature (continuous variable), congestion (discrete variables <span class="emphasis"><em>HIGH</em></span>, <span class="emphasis"><em>MEDIUM</em></span>, and <span class="emphasis"><em>LOW</em></span>), and <a id="id30000" class="indexterm"/>the actual diagnostic (flu). This dataset is used to create a model such as <span class="emphasis"><em>IF temperature &gt; 102 AND congestion = HIGH THEN patient has the flu (probability 0.72)</em></span>, which doctors can use in their diagnostic.</p></div><div class="section" title="Prediction"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec0800"/>Prediction</h2></div></div></div><p>Once<a id="id40000" class="indexterm"/> the model is trained using historical observations and validated against historical observations, it can be used to predict some outcome. A doctor collects symptoms from a patient, such as body temperature and nasal congestion, and anticipates the state of his/her health.</p></div><div class="section" title="Optimization"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec0900"/>Optimization</h2></div></div></div><p>Some<a id="id50000" class="indexterm"/> global optimization problems are intractable using traditional linear and non-linear optimization methods. Machine learning techniques improve the chances that the optimization method converges toward a solution (intelligent search). You can imagine that fighting the spread of a new virus requires optimizing a process that may evolve over time as more symptoms and cases are uncovered.</p></div><div class="section" title="Regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1000"/>Regression</h2></div></div></div><p>Regression<a id="id60000" class="indexterm"/> is a classification technique that is particularly suitable for a continuous model. Linear (least squares), polynomial, and logistic regressions are among the most commonly used techniques to fit a parametric model, or function, <span class="emphasis"><em>y= f (x), x={x<sub>i</sub>}</em></span>, to a dataset. Regression is sometimes regarded as a specialized case of classification for which the output variables are continuous instead of categorical.</p></div></div>
<div class="section" title="Why Scala?"><div class="titlepage" id="aid-4LN8A2"><div><div><h1 class="title"><a id="ch01lvl1sec1000"/>Why Scala?</h1></div></div></div><p>Like <a id="id70000" class="indexterm"/>most<a id="id80000" class="indexterm"/> functional languages, Scala provides developers and scientists with a toolbox to implement iterative computations that can be easily woven into a coherent dataflow. To some extent, Scala can be regarded as an extension of the popular MapReduce model for distributed computation of large amounts of data. Among the capabilities of the language, the following features are deemed essential in machine learning and statistical analysis.</p><div class="section" title="Abstraction"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1100"/>Abstraction</h2></div></div></div><p>
<span class="strong"><strong>Functors</strong></span> <a id="id90000" class="indexterm"/>and <span class="strong"><strong>monads</strong></span> <a id="id100000" class="indexterm"/>are important <a id="id110000" class="indexterm"/>concepts in functional programming. Monads are derived<a id="id120000" class="indexterm"/> from the category and group theory that allow developers to create a high-level abstraction as illustrated in <a id="id130000" class="indexterm"/><span class="strong"><strong>Scalaz</strong></span>, Twitter's <a id="id140000" class="indexterm"/><span class="strong"><strong>Algebird</strong></span>, or Google's <a id="id150000" class="indexterm"/><span class="strong"><strong>Breeze Scala</strong></span> libraries. More information about these libraries can be found at the following links:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><a class="ulink" href="https://github.com/scalaz">https://github.com/scalaz</a></li><li class="listitem"><a class="ulink" href="https://github.com/twitter/algebird">https://github.com/twitter/algebird</a></li><li class="listitem"><a class="ulink" href="https://github.com/dlwh/breeze">https://github.com/dlwh/breeze</a></li></ul></div><p>In mathematics, a category <span class="strong"><strong>M</strong></span> is a structure that is defined by:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Objects of some type: <span class="emphasis"><em>{x </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> X, y </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> Y, z </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> Z, …}</em></span></li><li class="listitem">Morphisms or maps applied to these objects: <span class="emphasis"><em>x </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> X, y </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> Y, f: x -› y</em></span></li><li class="listitem">Composition of morphisms: <span class="emphasis"><em>f: x -› y, g: y -› z =&gt; g o f: x -› z</em></span></li></ul></div><p>
<span class="strong"><strong>Covariant</strong></span>, <span class="strong"><strong>contravariant functors</strong></span>, and <span class="strong"><strong>bifunctors</strong></span> are well-understood concepts in algebraic topology that are related to manifold and vector bundles. They are commonly used in differential geometry and generation of non-linear models from data.</p><div class="section" title="Higher-kind projection"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0100"/>Higher-kind projection</h3></div></div></div><p>Scientists <a id="id160000" class="indexterm"/>define observations as sets or vectors of features. Classification problems rely on the estimation of the similarity between vectors of observations. One technique consists of comparing two vectors by computing the normalized inner product. A <span class="strong"><strong>co-vector</strong></span>
<a id="id170000" class="indexterm"/> is defined as a linear map α of a vector to the inner product (field).</p><div class="note" title="Note"><h3 class="title"><a id="tip0400"/>Tip</h3><p>
<span class="strong"><strong>Inner product</strong></span>
</p><p>M1: The definition of a &lt;.&gt; inner product and a α co-vector is as follows:</p><div class="mediaobject"><img src="../Images/image01237.jpeg" alt="Higher-kind projection"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's define a vector as a constructor from any <code class="literal">_ =&gt; Vector[_]</code> field (or <code class="literal">Function1[_, Vector]</code>). A co-vector is then defined as the mapping function of a vector to its <code class="literal">Vector[_] =&gt; _</code> field (or <code class="literal">Function1[Vector, _]</code>).</p><p>Let's define a two-dimensional (two types or fields) higher kind structure, <code class="literal">Hom</code>, that can be defined as either a vector or co-vector by fixing one of the two types:</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>Hom</strong></span>[T] = {
  type <span class="strong"><strong>Right</strong></span>[X] = Function1[X,T] // Co-vector
  type <span class="strong"><strong>Left</strong></span>[X] = Function1[T,X]   // Vector
 }</pre></div><div class="note" title="Note"><h3 class="title"><a id="note0400"/>Note</h3><p>
<span class="strong"><strong>Tensors and manifolds</strong></span>
</p><p>Vectors and co-vectors are classes of tensor (contravariant and covariant). Tensors (fields) are used in manifold learning of nonlinear models and in the generation of kernel functions. Manifolds are briefly introduced in the <span class="emphasis"><em>Manifolds</em></span> section under <span class="emphasis"><em>Dimension reduction</em></span> in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>. The topic of tensor fields and manifold learning is beyond the scope of this book.</p></div><p>The <a id="id180000" class="indexterm"/>projections of the higher kind, <code class="literal">Hom</code>, to the <code class="literal">Right</code> or <code class="literal">Left</code> single parameter types are known as functors, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A covariant functor for the <code class="literal">right</code> projection</li><li class="listitem">A contravariant functor for the <code class="literal">left</code> projection.</li></ul></div></div><div class="section" title="Covariant functors for vectors"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0200"/>Covariant functors for vectors</h3></div></div></div><p>A <a id="id190000" class="indexterm"/><span class="strong"><strong>covariant functor</strong></span> <a id="id200000" class="indexterm"/>of a variable is a map <span class="emphasis"><em>F: C =&gt; C</em></span> such that:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">If <span class="emphasis"><em>f: x -› y</em></span> is a morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(x) -› F(y)</em></span> is also a morphism on <span class="emphasis"><em>C</em></span></li><li class="listitem">If <span class="emphasis"><em>id: x -› x</em></span> is the identity morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(id)</em></span> is also an identity morphism on <span class="emphasis"><em>C</em></span></li><li class="listitem">If <span class="emphasis"><em>g: y -› z</em></span> is also a morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(g o f) = F(g) o F(f)</em></span></li></ul></div><p>The definition of the <code class="literal">F[U =&gt; V] := F[U] =&gt; F[V]</code>covariant functor in Scala is as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Functor</strong></span>[M[_]] {
  def <span class="strong"><strong>map</strong></span>[U,V](m: M[U])(f: U =&gt;V): M[V]
}</pre></div><p>For example, let's consider an observation defined as a <code class="literal">n</code> dimension vector of a <code class="literal">T</code> type, <code class="literal">Obs[T]</code>. The constructor for the observation can be represented as <code class="literal">Function1[T,Obs]</code>. Its <code class="literal">ObsFunctor</code> functor is implemented as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>ObsFunctor</strong></span>[T] extends Functor[(<span class="strong"><strong>Hom</strong></span>[T])#<span class="strong"><strong>Left</strong></span>] { self =&gt;
  override def <span class="strong"><strong>map</strong></span>[U,V](vu: Function1[T,U])(f: U =&gt;V): 
    Function1[T,V] = f.compose(vu)
}</pre></div><p>The functor is qualified as a <span class="strong"><strong>covariant functor</strong></span> because the morphism is applied to the return type of <a id="id210000" class="indexterm"/>the element of <code class="literal">Obs</code> as <code class="literal">Function1[T, Obs]</code>. The <code class="literal">Hom</code> projection of the two parameters types to a vector is implemented as <code class="literal">(Hom[T])#Left</code>.</p></div><div class="section" title="Contravariant functors for co-vectors"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0300"/>Contravariant functors for co-vectors</h3></div></div></div><p>A <a id="id220000" class="indexterm"/>contravariant functor of one variable is a map <span class="emphasis"><em>F: C =&gt; C</em></span> such that:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">If <span class="emphasis"><em>f: x -› y</em></span> is a morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(y) -&gt; F(x)</em></span> is also a morphism on <span class="emphasis"><em>C</em></span></li><li class="listitem">If <span class="emphasis"><em>id: x -› x</em></span> is the identity morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(id)</em></span> is also an identity morphism on <span class="emphasis"><em>C</em></span></li><li class="listitem">If <span class="emphasis"><em>g: y -› z</em></span> is also a morphism on <span class="emphasis"><em>C</em></span>, then <span class="emphasis"><em>F(g o f) = F(f) o F(g)</em></span></li></ul></div><p>The definition of the <code class="literal">F[U =&gt; V] := F[V] =&gt; F[U]</code> contravariant functor in Scala is as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>CoFunctor</strong></span>[M[_]] {
  def <span class="strong"><strong>map</strong></span>[U,V](m: M[U])(f: V =&gt;U): M[V]
}</pre></div><p>Note that the input and output types in the <code class="literal">f</code> morphism are reversed from the definition of a covariant functor. The constructor for the co-vector can be represented as <code class="literal">Function1[Obs,T]</code>. Its <code class="literal">CoObsFunctor</code> functor is implemented as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>CoObsFunctor</strong></span>[T] extends CoFunctor[(Hom[T])<span class="strong"><strong>#Right</strong></span>] {
  self =&gt;
    override def <span class="strong"><strong>map</strong></span>[U,V](vu: Function1[U,T])(f: V =&gt;U): 
       Function1[V,T] = f.andThen(vu)
}</pre></div></div><div class="section" title="Monads"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0400"/>Monads</h3></div></div></div><p>Monads<a id="id230000" class="indexterm"/> are structures in algebraic topology that are related to <a id="id240000" class="indexterm"/>the category theory. Monads extend the concept of a functor to allow a composition known as the <span class="strong"><strong>monadic composition</strong></span>
<a id="id250000" class="indexterm"/> of morphisms on a single type. They enable the chaining or weaving of computation into a sequence of steps or pipeline. The collections bundled with the Scala standard library (<code class="literal">List</code>, <code class="literal">Map</code>, and so on) are constructed as monads [1:1].</p><p>Monads provide the ability for those collections to perform the following functions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Create the collection</li><li class="listitem">Transform the elements of the collection</li><li class="listitem">Flatten nested collections</li></ul></div><p>An example is as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Monad</strong></span>[M[_]] {
  def unit[T](a: T): M[T]
  def map[U,V](m: M[U])(f U =&gt;V): M[V]
  def flatMap[U,V](m: M[U])(f: U =&gt;M[V]): M[V]
}</pre></div><p>Monads <a id="id260000" class="indexterm"/>are <a id="id270000" class="indexterm"/>therefore critical in machine learning as they enable you to compose multiple data transformation functions into a sequence or workflow. This property is applicable to any type of complex scientific computation [1:2].</p><div class="note" title="Note"><h3 class="title"><a id="note0500"/>Note</h3><p>
<span class="strong"><strong>The monadic composition of kernel functions</strong></span>
</p><p>Monads are used in the composition of kernel functions in the <span class="emphasis"><em>Kernel monadic composition section under Kernel functions</em></span> section in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>.</p></div></div></div><div class="section" title="Scalability"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1200"/>Scalability</h2></div></div></div><p>As<a id="id280000" class="indexterm"/> seen <a id="id290000" class="indexterm"/>previously, functors and monads enable parallelization and chaining of data processing functions by leveraging the Scala higher-order methods. In terms of implementation, <span class="strong"><strong>actors</strong></span> <a id="id300000" class="indexterm"/>are one of the core elements that make Scala scalable. Actors provide Scala developers with a high level of abstraction to build scalable, distributed, and concurrent applications. Actors hide the nitty-gritty implementation details of concurrency and the management of the underlying threads pool. Actors communicate through asynchronous immutable messages. A distributed computing Scala framework such as<a id="id310000" class="indexterm"/> <span class="strong"><strong>Akka</strong></span> or <span class="strong"><strong>Apache Spark</strong></span> extends the capabilities of the Scala standard library to support computation on very large datasets. Akka and Apache Spark are described in detail in the last chapter of this book [1:3].</p><p>In a nutshell, a workflow is implemented as a sequence of activities or computational tasks. These tasks consist of high-order Scala methods such as <code class="literal">flatMap</code>, <code class="literal">map</code>, <code class="literal">fold</code>, <code class="literal">reduce</code>, <code class="literal">collect</code>, <code class="literal">join</code>, or <code class="literal">filter</code> that are applied to a large collection of observations. Scala provides developers with the tools to partition datasets and execute the tasks through a cluster of actors. Scala also supports message dispatching and routing between local and remote actors. A developer can decide to deploy a workflow either locally or across multiple CPU cores and servers with very few code alterations.</p><div class="mediaobject"><img src="../Images/image01238.jpeg" alt="Scalability"/><div class="caption"><p>Deployment of a workflow for model training as a distributed computation</p></div></div><p style="clear:both; height: 1em;"> </p><p>In the <a id="id320000" class="indexterm"/>preceding diagram, a controller, that is, the master node, manages the sequence of tasks <span class="strong"><strong>1</strong></span> to <span class="strong"><strong>4</strong></span> similar to a scheduler. These tasks are actually executed over multiple <a id="id330000" class="indexterm"/>worker nodes, which are implemented by actors. The master node or actor exchanges messages with the workers to manage the state of the execution of the workflow as well as its reliability, as illustrated in the <span class="emphasis"><em>Scalability with Actors</em></span> section in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span>. High availability of these tasks is implemented through a hierarchy of supervising actors.</p></div><div class="section" title="Configurability"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1300"/>Configurability</h2></div></div></div><p>Scala<a id="id340000" class="indexterm"/> supports <a id="id350000" class="indexterm"/><span class="strong"><strong>dependency injection</strong></span> using a combination of abstract variables, self-referenced <a id="id360000" class="indexterm"/>composition, and stackable traits. One of the most commonly used dependency injection patterns, the <a id="id370000" class="indexterm"/><span class="strong"><strong>cake pattern</strong></span>, is described in the <span class="emphasis"><em>Composing mixins to build a workflow</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p></div><div class="section" title="Maintainability"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1400"/>Maintainability</h2></div></div></div><p>Scala <a id="id380000" class="indexterm"/>embeds <a id="id390000" class="indexterm"/><span class="strong"><strong>Domain Specific Languages</strong></span> (<span class="strong"><strong>DSL</strong></span>) natively. DSLs<a id="id400000" class="indexterm"/> are syntactic layers built on top of Scala native libraries. DSLs allow software developers to abstract computation in terms that are easily understood by scientists. The most notorious application of DSLs is the definition of the emulation of the syntax used in the MATLAB program, which data scientists are familiar with.</p></div><div class="section" title="Computation on demand"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1500"/>Computation on demand</h2></div></div></div><p>
<span class="strong"><strong>Lazy</strong></span> methods<a id="id410000" class="indexterm"/> and values allow developers to execute functions <a id="id420000" class="indexterm"/>and allocate computing resources on demand. The Spark framework relies on lazy variables and methods to chain <a id="id430000" class="indexterm"/><span class="strong"><strong>Resilient Distributed Datasets</strong></span> (<span class="strong"><strong>RDD</strong></span>).</p></div></div>
<div class="section" title="Model categorization" id="aid-4MLOS1"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec1100"/>Model categorization</h1></div></div></div><p>A model can be <a id="id440000" class="indexterm"/>predictive, descriptive, or adaptive.</p><p>
<span class="strong"><strong>Predictive</strong></span> models<a id="id450000" class="indexterm"/> discover patterns in historical data <a id="id460000" class="indexterm"/>and extract fundamental trends and relationships between factors (or features). They are used to predict and classify future events or observations. Predictive analytics is used in a variety of fields, including marketing, insurance, and pharmaceuticals. Predictive models are created through supervised learning using a preselected training set.</p><p>
<span class="strong"><strong>Descriptive</strong></span> models <a id="id470000" class="indexterm"/>attempt to find unusual <a id="id480000" class="indexterm"/>patterns or affinities in data by grouping observations into clusters with similar properties. These models define the first and important step in knowledge discovery. They are generated through unsupervised learning.</p><p>A third category of <a id="id490000" class="indexterm"/>models, known as <a id="id500000" class="indexterm"/><span class="strong"><strong>adaptive modeling</strong></span>, is created through <a id="id510000" class="indexterm"/><span class="strong"><strong>reinforcement learning</strong></span>. Reinforcement learning consists of one or several decision-making agents that recommend and possibly execute actions in the attempt of solving a problem, optimizing an objective function, or resolving constraints.</p></div>
<div class="section" title="Taxonomy of machine learning algorithms"><div class="titlepage" id="aid-4NK9E2"><div><div><h1 class="title"><a id="ch01lvl1sec1200"/>Taxonomy of machine learning algorithms</h1></div></div></div><p>The <a id="id520000" class="indexterm"/>purpose of machine learning is to teach <a id="id530000" class="indexterm"/>computers to execute tasks without human intervention. An increasing number of applications such as genomics, social networking, advertising, or risk analysis generate a very large amount of data that can be analyzed or mined to extract knowledge or insight into a process, customer, or organization. Ultimately, machine learning algorithms consist of identifying and validating models to optimize a performance criterion using historical, present, and future data [1:4].</p><p>Data mining is the process of extracting or identifying patterns in a dataset.</p><div class="section" title="Unsupervised learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1600"/>Unsupervised learning</h2></div></div></div><p>The goal <a id="id540000" class="indexterm"/>of <span class="strong"><strong>unsupervised learning</strong></span> is<a id="id550000" class="indexterm"/> to discover patterns of regularities and irregularities in a set of observations. The process is known as density estimation in statistics is broken down into two categories: discovery of data clusters and discovery of latent factors. The methodology consists of processing input data to understand patterns similar to the natural learning process in infants or animals. Unsupervised learning does not require labeled data (or expected values), and therefore, it is easy to implement and execute because no expertise is needed to validate an output. However, it is possible to label the output of a clustering algorithm and use it for future classification.</p><div class="section" title="Clustering"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0500"/>Clustering</h3></div></div></div><p>The purpose<a id="id560000" class="indexterm"/> of <span class="strong"><strong>data clustering</strong></span> <a id="id570000" class="indexterm"/>is to partition a collection of data into a number of clusters or data segments. Practically, a clustering algorithm is used to organize observations into clusters by minimizing the distance between observations within a cluster and maximizing the distance between observations across clusters. A clustering algorithm consists of the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Creating a model by making an assumption on the input data.</li><li class="listitem">Selecting the objective function or goal of the clustering.</li><li class="listitem">Evaluating one or more algorithms to optimize the objective function.</li></ol><div style="height:10px; width: 1px"/></div><p>Data clustering is also known as <a id="id580000" class="indexterm"/><span class="strong"><strong>data segmentation</strong></span> or <a id="id590000" class="indexterm"/><span class="strong"><strong>data partitioning</strong></span>.</p></div><div class="section" title="Dimension reduction"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0600"/>Dimension reduction</h3></div></div></div><p>
<span class="strong"><strong>Dimension reduction</strong></span>
<a id="id600000" class="indexterm"/> techniques aim at finding<a id="id610000" class="indexterm"/> the smallest but most relevant set of features needed to build a reliable model. There are many reasons for reducing the number of features or parameters in a model, from avoiding overfitting to reducing computation costs.</p><p>There are many ways to classify the different techniques used to extract knowledge from data using unsupervised learning. The following taxonomy breaks down these techniques according to their purpose, although the list is far from being exhaustive, as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01239.jpeg" alt="Dimension reduction"/><div class="caption"><p>Taxonomy of unsupervised learning algorithms</p></div></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="Supervised learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1700"/>Supervised learning</h2></div></div></div><p>The <a id="id620000" class="indexterm"/>best analogy for supervised learning is <a id="id630000" class="indexterm"/><span class="strong"><strong>function approximation</strong></span> or <span class="strong"><strong>curve fitting</strong></span>. In <a id="id640000" class="indexterm"/>its simplest form, supervised learning attempts to find a relation or function <span class="emphasis"><em>f: x → y</em></span> using a training set <span class="emphasis"><em>{x, y}</em></span>. Supervised learning is <a id="id650000" class="indexterm"/>far more accurate than any other learning strategy as long as the input (labeled data) is available and reliable. The downside is that a domain expert may be required to label (or tag) data as a training set.</p><p>Supervised machine learning algorithms<a id="id660000" class="indexterm"/> can be broken into two categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Generative models</li><li class="listitem">Discriminative models</li></ul></div><div class="section" title="Generative models"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0700"/>Generative models</h3></div></div></div><p>In order<a id="id670000" class="indexterm"/> to simplify the description of a statistics formula, we adopt the following simplification: the probability of an <span class="emphasis"><em>X</em></span> event is the same as the probability of the discrete <span class="emphasis"><em>X</em></span> random variable to have a value <span class="emphasis"><em>x</em></span>: <span class="emphasis"><em>p(X) = p(X=x)</em></span>.</p><p>The notation for the joint probability is <span class="emphasis"><em>p(X,Y) = p(X=x,Y=y)</em></span>.</p><p>The notation for the conditional probability is <span class="emphasis"><em>p(X|Y) = p(X=x|Y=y)</em></span>.</p><p>Generative models attempt to fit a joint probability distribution, <span class="emphasis"><em>p(X,Y)</em></span>, of two <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> events (or random variables), representing two sets of observed and hidden <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> variables. Discriminative models compute the conditional probability, <span class="emphasis"><em>p(Y|X)</em></span>, of an event or random variable <span class="emphasis"><em>Y</em></span> of hidden variables <span class="emphasis"><em>y</em></span>, given an event or random variable <span class="emphasis"><em>X</em></span> of observed variables <span class="emphasis"><em>x</em></span>. Generative models are commonly introduced through the Bayes' rule. The <a id="id680000" class="indexterm"/>conditional probability of a <span class="emphasis"><em>Y</em></span> event, given an <span class="emphasis"><em>X</em></span> event, is computed as the product of the conditional probability of the <span class="emphasis"><em>X</em></span> event, given the <span class="emphasis"><em>Y</em></span> event, and the probability of the <span class="emphasis"><em>X</em></span> event normalized by the probability of the <span class="emphasis"><em>Y</em></span> event [1:5].</p><div class="note" title="Note"><h3 class="title"><a id="note0600"/>Note</h3><p>
<span class="strong"><strong>Bayes' rule</strong></span>
</p><p>Joint probability for independent random variables, <span class="emphasis"><em>X=x</em></span> and <span class="emphasis"><em>Y=y</em></span>, is given by:</p><div class="mediaobject"><img src="../Images/image01240.jpeg" alt="Generative models"/></div><p style="clear:both; height: 1em;"> </p><p>Conditional probability of a random variable, <span class="emphasis"><em>Y = y</em></span>, given <span class="emphasis"><em>X = x</em></span>, is given by:</p><div class="mediaobject"><img src="../Images/image01241.jpeg" alt="Generative models"/></div><p style="clear:both; height: 1em;"> </p><p>Bayes' formula is given by:</p><div class="mediaobject"><img src="../Images/image01242.jpeg" alt="Generative models"/></div><p style="clear:both; height: 1em;"> </p></div><p>The Bayes' rule is the foundation of the Naïve Bayes classifier, as described in the <span class="emphasis"><em>Introducing the multinomial Naïve Bayes</em></span> section in <a class="link" title="Chapter 5. Naïve Bayes Classifiers" href="part0182.xhtml#aid-5DI6C1">Chapter 5</a>, <span class="emphasis"><em>Naïve Bayes Classifiers</em></span>.</p></div><div class="section" title="Discriminative models"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0800"/>Discriminative models</h3></div></div></div><p>Contrary <a id="id690000" class="indexterm"/>to generative models, discriminative models compute the conditional probability <span class="emphasis"><em>p(Y|X)</em></span> directly, using the same algorithm for training and classification.</p><p>Generative and discriminative models have their respective advantages and disadvantages. Novice data scientists learn to match the appropriate algorithm to each problem through experimentation. Here is a brief guideline describing which type of models make sense according to the objective or criteria of the project:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Objective</p>
</th><th valign="bottom">
<p>Generative models</p>
</th><th valign="bottom">
<p>Discriminative models</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>Accuracy</p>
</td><td valign="top">
<p>Highly dependent on the training set.</p>
</td><td valign="top">
<p>This depends on the training set and algorithm configuration (that is, kernel functions)</p>
</td></tr><tr><td valign="top">
<p>Modeling requirements</p>
</td><td valign="top">
<p>There is a need to model both observed and hidden variables, which requires a significant amount of training.</p>
</td><td valign="top">
<p>The quality of the training set does not have to be as rigorous as for generative models.</p>
</td></tr><tr><td valign="top">
<p>Computation cost</p>
</td><td valign="top">
<p>This is usually low. For example, any graphical method derived from the Bayes' rule has low overhead.</p>
</td><td valign="top">
<p>Most algorithms rely on optimization of a convex function with significant performance overhead.</p>
</td></tr><tr><td valign="top">
<p>Constraints</p>
</td><td valign="top">
<p>These models assume some degree of independence among the model features.</p>
</td><td valign="top">
<p>Most discriminative algorithms accommodate dependencies between features.</p>
</td></tr></tbody></table></div><p>We can <a id="id700000" class="indexterm"/>further refine the taxonomy of supervised learning algorithms by segregating arbitrarily between sequential and random variables for generative models and breaking down discriminative methods as applied to continuous processes (regression) and discrete processes (classification):</p><div class="mediaobject"><img src="../Images/image01243.jpeg" alt="Discriminative models"/><div class="caption"><p>Taxonomy of supervised learning algorithms</p></div></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="Semi-supervised learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1800"/>Semi-supervised learning</h2></div></div></div><p>Semi-supervised learning<a id="id710000" class="indexterm"/> is <a id="id720000" class="indexterm"/>used to build models from a dataset with incomplete labels. Manifold learning and information geometry algorithms are commonly applied to large datasets that are partially labeled. The description of semi-supervised learning techniques is beyond the scope of this book.</p></div><div class="section" title="Reinforcement learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec1900"/>Reinforcement learning</h2></div></div></div><p>Reinforcement learning<a id="id730000" class="indexterm"/> is<a id="id740000" class="indexterm"/> not as well understood as supervised and unsupervised learning outside the realms of robotics or game strategy. However, since the 90s, genetic-algorithms-based classifiers have become increasingly popular to solve problems that require collaboration with a domain expert. For some types of applications, reinforcement learning algorithms output a set of recommended actions for the adaptive system to execute. In its simplest form, these algorithms estimate the best course of action. Most complex systems based on reinforcement learning establish and update policies that can be vetoed by an expert, if necessary. The foremost challenge developers of reinforcement learning systems face is that the recommended action or policy may depend on partially observable states.</p><p>Genetic algorithms are not usually considered part of the reinforcement learning toolbox. However, advanced models, such as learning classifier systems, use genetic algorithms to classify and reward the most performing rules and policies.</p><p>As with the two previous learning strategies, reinforcement learning models can be categorized as Markovian or evolutionary:</p><div class="mediaobject"><img src="../Images/image01244.jpeg" alt="Reinforcement learning"/><div class="caption"><p>Taxonomy of reinforcement learning algorithms</p></div></div><p style="clear:both; height: 1em;"> </p><p>This is a brief overview of machine learning algorithms with a suggested, approximate taxonomy. There<a id="id750000" class="indexterm"/> are almost as many ways to introduce machine learning as there are data and computer scientists. We encourage you to browse through the list of references at the end of the book to find the documentation appropriate to your level of interest and understanding.</p></div></div>
<div class="section" title="Don't reinvent the wheel!" id="aid-4OIQ01"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec1300"/>Don't reinvent the wheel!</h1></div></div></div><p>There are <a id="id760000" class="indexterm"/>numerous robust, accurate, and efficient Java libraries for <a id="id770000" class="indexterm"/>mathematics, linear algebra, or optimization that have been widely used for many years:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">JBlas/Linpack (<a class="ulink" href="https://github.com/mikiobraun/jblas">https://github.com/mikiobraun/jblas</a>)</li><li class="listitem">Parallel Colt (<a class="ulink" href="https://github.com/rwl/ParallelColt">https://github.com/rwl/ParallelColt</a>)</li><li class="listitem">Apache Commons Math (<a class="ulink" href="http://commons.apache.org/proper/commons-math">http://commons.apache.org/proper/commons-math</a>)</li></ul></div><p>There is <a id="id780000" class="indexterm"/>absolutely no need to rewrite, debug, and test these components in Scala. Developers should consider creating a wrapper or interface to his/her favorite and reliable Java library. The book leverages the Apache Commons Math library for some specific linear algebra algorithms.</p></div>
<div class="section" title="Tools and frameworks"><div class="titlepage" id="aid-4PHAI2"><div><div><h1 class="title"><a id="ch01lvl1sec1400"/>Tools and frameworks</h1></div></div></div><p>Before getting<a id="id790000" class="indexterm"/> your hands dirty, you need to download and deploy a minimum set of tools and libraries; there is no need to reinvent the wheel after all. A few key<a id="id800000" class="indexterm"/> components have to be installed in order to compile and run the source code described throughout the book. We focus on open source and commonly available libraries, although you are invited to experiment with equivalent tools of your choice. The learning curve for the frameworks described here is minimal.</p><div class="section" title="Java"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2000"/>Java</h2></div></div></div><p>The code <a id="id810000" class="indexterm"/>described in this book has been tested with JDK 1.7.0_45 and JDK 1.8.0_25 on Windows x64 and Mac OS X x64. You need to install the Java Development Kit if you have not already done so. Finally, the <code class="literal">JAVA_HOME</code>, <code class="literal">PATH</code>, and <code class="literal">CLASSPATH</code> environment variables have to be updated accordingly.</p></div><div class="section" title="Scala"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2100"/>Scala</h2></div></div></div><p>The<a id="id820000" class="indexterm"/> code has been tested with Scala 2.10.4 and 2.11.4. We recommend that you use Scala Version 2.10.4 or higher with SBT 0.13 or higher. Let's assume that Scala runtime (REPL) and libraries have been properly installed and the <code class="literal">SCALA_HOME</code> and <code class="literal">PATH</code> environment variables have been updated.</p><p>The description and installation instructions of the <a id="id830000" class="indexterm"/>S<span class="strong"><strong>cala plugin for Eclipse</strong></span> (version 4.0 or higher) are available at <a class="ulink" href="http://scala-ide.org/docs/user/gettingstarted.html">http://scala-ide.org/docs/user/gettingstarted.html</a>. You can also download the <a id="id840000" class="indexterm"/><span class="strong"><strong>Scala plugin for IntelliJ IDEA</strong></span> (version 13 or higher) from the JetBrains website at <a class="ulink" href="http://confluence.jetbrains.com/display/SCA/">http://confluence.jetbrains.com/display/SCA/</a>.</p><p>The ubiquitous <span class="strong"><strong>Simple Build Tool</strong></span> (<span class="strong"><strong>SBT</strong></span>)<a id="id850000" class="indexterm"/> will be our primary building engine. The syntax of the build file, <code class="literal">sbt/build.sbt</code>, conforms to the Version 0.13 and is used to compile and assemble the source code presented throughout the book. Sbt can be downloaded as part of Typesafe activator or directly from <a class="ulink" href="http://www.scala-sbt.org/download.html">http://www.scala-sbt.org/download.html</a>.</p></div><div class="section" title="Apache Commons Math"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2200"/>Apache Commons Math</h2></div></div></div><p>Apache Commons Math<a id="id860000" class="indexterm"/> is a Java library used for numerical processing, algebra, statistics, and optimization [1:6].</p><div class="section" title="Description"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec0900"/>Description</h3></div></div></div><p>This <a id="id870000" class="indexterm"/>is a lightweight library that provides developers with a foundation of small, ready-to-use Java classes that can be easily weaved into a machine learning problem. The examples used throughout the book require Version 3.5 or higher.</p><p>The math library supports the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Functions, differentiation, and integral and ordinary differential equations</li><li class="listitem">Statistics distributions</li><li class="listitem">Linear and nonlinear optimization</li><li class="listitem">Dense and sparse vectors and matrices</li><li class="listitem">Curve fitting, correlation, and regression</li></ul></div><p>For more information, visit <a class="ulink" href="http://commons.apache.org/proper/commons-math">http://commons.apache.org/proper/commons-math</a>.</p></div><div class="section" title="Licensing"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1000"/>Licensing</h3></div></div></div><p>We need <a id="id880000" class="indexterm"/>Apache Public License 2.0; the terms are available at <a class="ulink" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>.</p></div><div class="section" title="Installation"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1100"/>Installation</h3></div></div></div><p>The installation<a id="id890000" class="indexterm"/> and deployment of the Apache Commons Math library are quite simple. The steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Go to the download page at <a class="ulink" href="http://commons.apache.org/proper/commons-math/download_math.cgi">http://commons.apache.org/proper/commons-math/download_math.cgi</a>.</li><li class="listitem">Download the latest <code class="literal">.jar</code> files to the binary section, <code class="literal">commons-math3-3.5-bin.zip</code> (for instance, for Version 3.5).</li><li class="listitem">Unzip and install the <code class="literal">.jar</code> file.</li><li class="listitem">Add <code class="literal">commons-math3-3.5.jar</code> to the <a id="id900000" class="indexterm"/>classpath as follows:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>For Mac OS X</strong></span>: <code class="literal">export CLASSPATH=$CLASSPATH:/Commons_Math_path/commons-math3-3.5.jar</code></li><li class="listitem"><span class="strong"><strong>For Windows</strong></span>: Go <a id="id910000" class="indexterm"/>to system <span class="strong"><strong>Properties</strong></span> | <span class="strong"><strong>Advanced system settings</strong></span> | <span class="strong"><strong>Advanced</strong></span> | <span class="strong"><strong>Environment Variables</strong></span>, then edit the <code class="literal">CLASSPATH</code> variable</li></ul></div></li><li class="listitem">Add the <code class="literal">commons-math3-3.5.jar</code> file to your IDE environment if needed (that is, for Eclipse, go to <span class="strong"><strong>Project</strong></span> | <span class="strong"><strong>Properties</strong></span> | <span class="strong"><strong>Java Build Path</strong></span> | <span class="strong"><strong>Libraries</strong></span> | <span class="strong"><strong>Add External JARs</strong></span> and for IntelliJ IDEA, go to <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Project Structure</strong></span> | <span class="strong"><strong>Project Settings</strong></span> | <span class="strong"><strong>Libraries</strong></span>).</li></ol><div style="height:10px; width: 1px"/></div><p>You can also<a id="id920000" class="indexterm"/> download <code class="literal">commons-math3-3.5-src.zip</code> from the <span class="strong"><strong>Source</strong></span> section.</p></div></div><div class="section" title="JFreeChart"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2300"/>JFreeChart</h2></div></div></div><p>JFreeChart<a id="id930000" class="indexterm"/> is an open source chart and plotting Java library, widely used in the Java programmer community. It was originally created by David Gilbert [1:7].</p><div class="section" title="Description"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1200"/>Description</h3></div></div></div><p>The<a id="id940000" class="indexterm"/> library supports a variety of configurable plots and charts (scatter, dial, pie, area, bar, box and whisker, stacked, and 3D). We use JFreeChart to display the output of data processing and algorithms throughout the book, but you are encouraged to explore this great library on your own, as time permits.</p></div><div class="section" title="Licensing"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1300"/>Licensing</h3></div></div></div><p>It is<a id="id950000" class="indexterm"/> distributed under the terms of the <a id="id960000" class="indexterm"/>GNU <span class="strong"><strong>Lesser General Public License</strong></span> (<span class="strong"><strong>LGPL</strong></span>), which permits its use in proprietary applications.</p></div><div class="section" title="Installation"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1400"/>Installation</h3></div></div></div><p>To install <a id="id970000" class="indexterm"/>and deploy JFreeChart, perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Visit <a class="ulink" href="http://www.jfree.org/jfreechart/">http://www.jfree.org/jfreechart/</a>.</li><li class="listitem">Download the latest version from Source Forge at <a class="ulink" href="http://sourceforge.net/projects/jfreechart/files">http://sourceforge.net/projects/jfreechart/files</a>.</li><li class="listitem">Unzip and <a id="id980000" class="indexterm"/>deploy the <code class="literal">.jar</code> file.</li><li class="listitem">Add <code class="literal">jfreechart-1.0.17.jar</code> (for Version 1.0.17) to the classpath as follows:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>For Mac OS X</strong></span>: <code class="literal">export CLASSPATH=$CLASSPATH:/JFreeChart_path/jfreechart-1.0.17.jar</code></li><li class="listitem"><span class="strong"><strong>For Windows</strong></span>: Go to <a id="id990000" class="indexterm"/>system<span class="strong"><strong> Properties</strong></span> | <span class="strong"><strong>Advanced system settings</strong></span> | <span class="strong"><strong>Advanced</strong></span> | <span class="strong"><strong>Environment Variables</strong></span>, then edit the <code class="literal">CLASSPATH</code> variable</li></ul></div></li><li class="listitem">Add the <code class="literal">jfreechart-1.0.17.jar</code> file to your IDE environment, if needed</li></ol><div style="height:10px; width: 1px"/></div></div></div><div class="section" title="Other libraries and frameworks"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2400"/>Other libraries and frameworks</h2></div></div></div><p>Libraries<a id="id1000000" class="indexterm"/> and tools that are specific to a single chapter are introduced along with the topic. Scalable frameworks are presented in the last chapter along with the instructions to download them. Libraries related to the conditional random fields and support vector machines are described in their respective chapters. </p><div class="note" title="Note"><h3 class="title"><a id="note0900"/>Note</h3><p>
<span class="strong"><strong>Why not use the Scala algebra and numerical libraries?</strong></span>
</p><p>Libraries such as Breeze, ScalaNLP, and Algebird are interesting Scala frameworks for linear algebra, numerical analysis, and machine learning. They provide even the most seasoned Scala programmer with a high-quality layer of abstraction. However, this book is designed as a tutorial that allows developers to write algorithms from the ground up using existing or legacy Java libraries [1:8].</p></div></div></div>
<div class="section" title="Source code"><div class="titlepage" id="aid-4QFR42"><div><div><h1 class="title"><a id="ch01lvl1sec1500"/>Source code</h1></div></div></div><p>The <a id="id1010000" class="indexterm"/>Scala programming language is used to implement and evaluate the machine learning techniques covered in <span class="emphasis"><em>Scala for Machine Learning</em></span>. However, the source code snippets are reduced to the strict minimum essential to the understanding of machine learning algorithms discussed throughout the book. The formal implementation of these algorithms is available on the website of Packt Publishing (<a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>).</p><div class="note" title="Note"><h3 class="title"><a id="tip0500"/>Tip</h3><p>
<span class="strong"><strong>Downloading the example code</strong></span>
</p><p>You can download the example code files for all Packt books you have purchased from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p></div><div class="section" title="Context versus view bounds"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2500"/>Context versus view bounds</h2></div></div></div><p>Most Scala <a id="id1020000" class="indexterm"/>classes discussed in the book are parameterized with the type associated with the discrete/categorical value (<code class="literal">Int</code>) or continuous value (<code class="literal">Double</code>). Context bounds would require that any type used by the client code has <code class="literal">Int</code> or <code class="literal">Double</code> as upper bounds:</p><div class="informalexample"><pre class="programlisting">class A[T &lt;: Int](param: Param)
class B[T &lt;: Double](param: Param)</pre></div><p>Such a design introduces constraints on the client to inherit from simple types and to deal with covariance and contravariance for container types [1:9].</p><p>For this book, <span class="strong"><strong>view bounds</strong></span> <a id="id1030000" class="indexterm"/>are used instead of context bounds because they only require an implicit conversion to the parameterized type to be defined:</p><div class="informalexample"><pre class="programlisting">class A[T &lt;: AnyVal](param: Param)(implicit f: T =&gt; Int)
class C[T &lt; : AnyVal](param: Param)(implicit f: T =&gt; Float)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note1000"/>Note</h3><p>
<span class="strong"><strong>View bound deprecation</strong></span>
</p><p>The notation for the view bound, <code class="literal">T &lt;% Double</code>, is being deprecated in Scala 2.11 and higher. The <code class="literal">class A[T &lt;% Float]</code> declaration is the short notation for <code class="literal">class A[T](implicit f: T =&gt; Float)</code>.</p></div></div><div class="section" title="Presentation"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2600"/>Presentation</h2></div></div></div><p>For the sake of <a id="id1040000" class="indexterm"/>readability of the implementation of algorithms, all nonessential code such as error checking, comments, exceptions, or imports are omitted. The following code elements are omitted in the code snippet presented in the book:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Code documentation:<div class="informalexample"><pre class="programlisting">// …..
/* … */</pre></div></li><li class="listitem">Validation of class parameters and method arguments:<div class="informalexample"><pre class="programlisting">require( Math.abs(x) &lt; EPS, " …")</pre></div></li><li class="listitem">Class qualifiers and scope declaration:<div class="informalexample"><pre class="programlisting">final protected class SVM { … }
private[this] val lsError = …</pre></div></li><li class="listitem">Method qualifiers:<div class="informalexample"><pre class="programlisting">final protected def dot: = …</pre></div></li><li class="listitem">Exceptions:<div class="informalexample"><pre class="programlisting">try {
   correlate …
} catch {
   case e: MathException =&gt; ….
}
Try {    .. } match {
  case Success(res) =&gt;
  case Failure(e =&gt; ..
}</pre></div></li><li class="listitem">Logging and debugging code:<div class="informalexample"><pre class="programlisting">private val logger = Logger.getLogger("..")
logger.info( … )</pre></div></li><li class="listitem">Nonessential annotation:<div class="informalexample"><pre class="programlisting">@inline def main = ….
@throw(classOf[IllegalStateException])</pre></div></li><li class="listitem">Nonessential methods</li></ul></div><p>The complete <a id="id1050000" class="indexterm"/>list of Scala code elements omitted in the code snippets in this book can be found in the <span class="emphasis"><em>Code snippets format</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p></div><div class="section" title="Primitives and implicits"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2700"/>Primitives and implicits</h2></div></div></div><p>The algorithms presented in this book share the same primitive types, generic operators, and implicit conversions.</p><div class="section" title="Primitive types"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1500"/>Primitive types</h3></div></div></div><p>For<a id="id1060000" class="indexterm"/> the sake of readability of the code, the following primitive types will be used:</p><div class="informalexample"><pre class="programlisting">type DblPair = (Double, Double)
type DblArray = Array[Double]
type DblMatrix = Array[DblArray]
type DblVector = Vector[Double]
type XSeries[T] = Vector[T]         // One dimensional vector
type XVSeries[T] = Vector[Array[T]] // multi-dimensional vector</pre></div><p>The times series introduced in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>, is implemented as <code class="literal">XSeries[T]</code> or <code class="literal">XVSeries[T]</code> of a parameterized <code class="literal">T</code> type.</p><div class="note" title="Note"><h3 class="title"><a id="note1100"/>Note</h3><p>Make a note of these six types; they are used throughout the book.</p></div></div><div class="section" title="Type conversions"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1600"/>Type conversions</h3></div></div></div><p>Implicit conversion <a id="id1070000" class="indexterm"/>is an important feature of the Scala programming<a id="id1080000" class="indexterm"/> language. It allows developers to specify a type conversion for an entire library in a single place. Here are a few of the implicit type conversions that are used throughout the book:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>Types</strong></span> {
  Object <span class="strong"><strong>ScalaMl</strong></span> {  
   implicit def double2Array(x: Double): DblArray = 
      Array[Double](x)
   implicit def dblPair2Vector(x: DblPair): Vector[DblPair] = 
      Vector[DblPair](x._1,x._2)
   ...
  }
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note1200"/>Note</h3><p>
<span class="strong"><strong>Library-specific conversion</strong></span>
</p><p>The conversion between the primitive type listed here and types introduced in a particular library (such as, the Apache Commons Math library) are described in the relevant chapters.</p></div></div></div><div class="section" title="Immutability"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2800"/>Immutability</h2></div></div></div><p>It is usually <a id="id1090000" class="indexterm"/>a good idea to reduce the number of states of an object. A method invocation transitions an object from one state to another. The larger the number of methods or states, the more cumbersome the testing process becomes. </p><p>There is no point in creating a model that is not defined (trained). Therefore, making the training of a model as part of the constructor of the class it implements makes a lot of sense. Therefore, the only public methods of a machine learning algorithm are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Classification or prediction</li><li class="listitem">Validation </li><li class="listitem">Retrieval of model parameters (weights, latent variables, hidden states, and so on), if needed</li></ul></div></div><div class="section" title="Performance of Scala iterators"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec2900"/>Performance of Scala iterators</h2></div></div></div><p>The evaluation of the <a id="id1100000" class="indexterm"/>performance of Scala high-order iterative methods is beyond the scope of this book. However, it is important to be aware of the trade-off of each method.</p><p>The <code class="literal">for</code> construct is to be avoided as a counting iterator. It is designed to implement the for-comprehensive monad (<code class="literal">map</code> and <code class="literal">flatMap</code>). The source code presented in this book uses the high-order <code class="literal">foreach</code> method instead.</p></div></div>
<div class="section" title="Let's kick the tires"><div class="titlepage" id="aid-4REBM2"><div><div><h1 class="title"><a id="ch01lvl1sec1600"/>Let's kick the tires</h1></div></div></div><p>This final section introduces the key elements of the training and classification workflow. A test case using a simple logistic regression is used to illustrate each step of the computational workflow.</p><div class="section" title="An overview of computational workflows"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec3000"/>An overview of computational workflows</h2></div></div></div><p>In its <a id="id1110000" class="indexterm"/>simplest form, a computational workflow to perform runtime processing of a dataset is composed of the following stages:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Loading the dataset from files, databases, or any streaming devices.</li><li class="listitem">Splitting the dataset for parallel data processing.</li><li class="listitem">Preprocessing data using filtering techniques, analysis of variance, and applying penalty and normalization functions whenever necessary.</li><li class="listitem">Applying the model—either a set of clusters or classes—to classify new data.</li><li class="listitem">Assessing the quality of the model.</li></ol><div style="height:10px; width: 1px"/></div><p>A similar sequence of tasks is used to extract a model from a training dataset:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Loading the dataset from files, databases, or any streaming devices.</li><li class="listitem">Splitting the dataset for parallel data processing.</li><li class="listitem">Applying filtering techniques, analysis of variance, and penalty and normalization functions to the raw dataset whenever necessary.</li><li class="listitem">Selecting the training, testing, and validation set from the cleansed input data.</li><li class="listitem">Extracting key features and establishing affinity between a similar group of observations using clustering techniques or supervised learning algorithms.</li><li class="listitem">Reducing the number of features to a manageable set of attributes to avoid overfitting the training set.</li><li class="listitem">Validating the model and tuning the model by iterating steps 5, 6, and 7 until the error meets a predefined convergence criteria.</li><li class="listitem">Storing the model in a file or database so that it can be applied to future observations.</li></ol><div style="height:10px; width: 1px"/></div><p>Data clustering and <a id="id1120000" class="indexterm"/>data classification can be performed independent of each other or as part of a workflow that uses clustering techniques at the preprocessing stage of the training phase of a supervised learning algorithm. Data clustering does not require a model to be extracted from a training set, while classification can be performed only if a model has been built from the training set. The following image gives an overview of training, classification, and validation:</p><div class="mediaobject"><img src="../Images/image01245.jpeg" alt="An overview of computational workflows"/><div class="caption"><p>A generic data flow for training and running a model</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding diagram is an overview of a typical data mining processing pipeline. The first phase consists of extracting the model through clustering or training of a supervised learning algorithm. The model is then validated against test data for which the source is the same as the training set but with different observations. Once the model is created and validated, it can be used to classify real-time data or predict future behavior. Real-world workflows are more complex and require dynamic configuration to allow experimentation of different models. Several alternative classifiers can be used to perform a regression and different filtering algorithms are applied against input data, depending on the latent noise in the raw data.</p></div><div class="section" title="Writing a simple workflow"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec3100"/>Writing a simple workflow</h2></div></div></div><p>This book<a id="id1130000" class="indexterm"/> relies on financial data to experiment with different learning strategies. The objective of the exercise is to build a model that can discriminate between volatile and nonvolatile trading sessions for stock or commodities. For the first example, we select a simplified version of the binomial logistic regression as our classifier as we treat stock-price-volume action as a continuous or pseudo-continuous process. </p><div class="note" title="Note"><h3 class="title"><a id="note1300"/>Note</h3><p>
<span class="strong"><strong>An introduction to the logistic regression</strong></span>
</p><p>Logistic regression is explained in depth in the <span class="emphasis"><em>Logistic regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>. The model treated in this example is the simple binomial logistic regression classifier for two-dimension observations.</p></div><p>The steps for classification of trading sessions according to their volatility and volume is as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Scoping the problem</li><li class="listitem">Loading data</li><li class="listitem">Preprocessing raw data</li><li class="listitem">Discovering patterns, whenever possible</li><li class="listitem">Implementing the classifier</li><li class="listitem">Evaluating the model</li></ol><div style="height:10px; width: 1px"/></div><div class="section" title="Step 1 – scoping the problem"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1700"/>Step 1 – scoping the problem</h3></div></div></div><p>The<a id="id1140000" class="indexterm"/> objective is to create a model for stock price using its daily trading volume and volatility. Throughout the book, we will rely on financial data to evaluate and discuss the merits of different data processing and machine learning methods. In this example, the data is extracted from <a id="id1150000" class="indexterm"/><span class="strong"><strong>Yahoo Finances</strong></span> using the CSV format with the following fields:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Date</li><li class="listitem">Price at open</li><li class="listitem">Highest price in the session</li><li class="listitem">Lowest price in the session</li><li class="listitem">Price at session close</li><li class="listitem">Volume </li><li class="listitem">Adjust price at session close</li></ul></div><p>The <code class="literal">YahooFinancials</code> enumerator extracts the historical daily trading information from the Yahoo finance site:</p><div class="informalexample"><pre class="programlisting">type Fields = Array[String]
object <span class="strong"><strong>YahooFinancials</strong></span> extends Enumeration {
   type YahooFinancials = Value
   val DATE, OPEN, HIGH, LOW, CLOSE, VOLUME, ADJ_CLOSE = Value

   def <span class="strong"><strong>toDouble</strong></span>(v: Value): Fields =&gt; Double =   //<span class="strong"><strong>1</strong></span>
   (s: Fields) =&gt; s(v.id).toDouble
   def <span class="strong"><strong>toDblArray</strong></span>(vs: Array[Value]): Fields =&gt; DblArray = //<span class="strong"><strong>2</strong></span>
       (s: Fields) =&gt; vs.map(v =&gt; s(v.id).toDouble)
  …
}</pre></div><p>The <code class="literal">toDouble</code> method converts an array of string into a single value (line <code class="literal">1</code>) and <code class="literal">toDblArray</code> converts an array of string into an array of values (line <code class="literal">2</code>). The <code class="literal">YahooFinancials</code> enumerator is described in the <span class="emphasis"><em>Data sources</em></span> section in <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span> in detail.</p><p>Let's create a<a id="id1160000" class="indexterm"/> simple program that loads the content of the file, executes some simple preprocessing functions, and creates a simple model. We selected the CSCO stock price between January 1, 2012 and December 1, 2013 as our data input.</p><p>Let's consider the two variables, <span class="emphasis"><em>price</em></span> and <span class="emphasis"><em>volume</em></span>, as shown in the following screenshot. The top graph displays the variation of the price of Cisco stock over time and the bottom bar chart represents the daily trading volume on Cisco stock over time:</p><div class="mediaobject"><img src="../Images/image01246.jpeg" alt="Step 1 – scoping the problem"/><div class="caption"><p>Price-Volume action for Cisco stock 2012-2013</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Step 2 – loading data"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1800"/>Step 2 – loading data</h3></div></div></div><p>The second step <a id="id1170000" class="indexterm"/>is loading the dataset from a local or remote data storage. Typically, large datasets are loaded from a database or distributed filesystems such as <a id="id1180000" class="indexterm"/><span class="strong"><strong>Hadoop Distributed File System</strong></span> (<span class="strong"><strong>HDFS</strong></span>). The <code class="literal">load</code> method takes an absolute pathname, <code class="literal">extract</code>, and transforms the input data from a file into a time series of a <code class="literal">Vector[DblPair]</code> type:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>load</strong></span>(fileName: String): Try[<span class="strong"><strong>Vector[DblPair]</strong></span>] = Try {
   val src =  Source.fromFile(fileName)  //<span class="strong"><strong>3</strong></span>
   val data = <span class="strong"><strong>extract</strong></span>(src.getLines.map(_.split(",")).drop(1)) //<span class="strong"><strong>4</strong></span>
   src.close //<span class="strong"><strong>5</strong></span>
   data
 }</pre></div><p>The data file is extracted through an invocation of the <code class="literal">Source.fromFile</code> static method (line <code class="literal">3</code>), and then the fields are extracted through a map before the header (first row in the file) is removed using <code class="literal">drop</code> (line <code class="literal">4</code>). The file has to be closed to avoid leaking of the file handle (line <code class="literal">5</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note1400"/>Note</h3><p>
<span class="strong"><strong>Data extraction</strong></span>
</p><p>The <code class="literal">Source.fromFile.getLines.map</code> invocation pipeline method returns an iterator that can be traversed only once.</p></div><p>The purpose of the <code class="literal">extract</code> method is to generate a time series of two variables (<span class="emphasis"><em>relative stock volatility</em></span> and <span class="emphasis"><em>relative stock daily trading volume</em></span>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>extract</strong></span>(cols: Iterator[Array[String]]): XVSeries[Double]= {
  val features = Array[YahooFinancials](<span class="strong"><strong>LOW</strong></span>, <span class="strong"><strong>HIGH</strong></span>, <span class="strong"><strong>VOLUME</strong></span>) //<span class="strong"><strong>6</strong></span>
  val conversion = YahooFinancials.toDblArray(features)  //<span class="strong"><strong>7</strong></span>
  cols.map(c =&gt; conversion(c)).toVector   
      .map(x =&gt; Array[Double](1.0 - x(0)/x(1), x(2)))  //<span class="strong"><strong>8</strong></span>
}</pre></div><p>The only purpose of the <code class="literal">extract</code> method is to convert the raw textual data into a two-dimensional time series. The first step consists of selecting the three features to extract <code class="literal">LOW</code> (the lowest stock price in the session), <code class="literal">HIGH</code> (the highest price in the session), and <code class="literal">VOLUME</code> (trading volume for the session) (line <code class="literal">6</code>). This feature set is used to convert each line of fields into a corresponding set of three values (line <code class="literal">7</code>). Finally, the feature set is reduced to the following two variables (line <code class="literal">8</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Relative volatility of the stock price in a session: <span class="emphasis"><em>1.0 – LOW/HIGH</em></span></li><li class="listitem">Trading volume for the stock in the session: <span class="emphasis"><em>VOLUME</em></span></li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note1500"/>Note</h3><p>
<span class="strong"><strong>Code readability</strong></span>
</p><p>A long pipeline of Scala high-order methods make the code and underlying code quite difficult to read. It is recommended that you break down long chains of method calls, such as the following:</p><div class="informalexample"><pre class="programlisting">val cols = Source.fromFile.getLines.map(_.split(",")).toArray.drop(1)</pre></div><p>We can break down method calls into several steps as follows:</p><div class="informalexample"><pre class="programlisting">val lines = Source.fromFile.getLines
val fields = lines.map(_.split(",")).toArray
val cols = fields.drop(1)</pre></div><p>We strongly encourage you to consult the excellent guide <span class="emphasis"><em>Effective Scala,</em></span> written by Marius Eriksen from Twitter. This is definitively a must read for any Scala developer [1:10].</p></div></div><div class="section" title="Step 3 – preprocessing the data"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec1900"/>Step 3 – preprocessing the data</h3></div></div></div><p>The next step <a id="id1190000" class="indexterm"/>is to normalize the data in the range <span class="emphasis"><em>[0.0, 1.0]</em></span> to be trained by the binomial logistic regression. It is time to introduce an immutable and flexible normalization class.</p><div class="section" title="Immutable normalization"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0100"/>Immutable normalization</h4></div></div></div><p>The <a id="id1200000" class="indexterm"/>logistic regression relies on the sigmoid curve or logistic function is described in the <span class="emphasis"><em>Logistic function</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>. The logistic functions are used to segregate training data into classes. The output value of the logistic function ranges from 0 for <span class="emphasis"><em>x = - INFINITY</em></span> to 1 for <span class="emphasis"><em>x = + INFINITY</em></span>. Therefore, it makes sense to normalize the input data or observation over [0, 1].</p><div class="note" title="Note"><h3 class="title"><a id="note1800"/>Note</h3><p>
<span class="strong"><strong>Normalize or not normalize?</strong></span>
</p><p>The purpose of normalizing data is to impose a single range of values for all the features, so the model does not favor any particular feature. Normalization techniques include linear normalization and Z-score. Normalization is an expensive operation that is not always needed.</p></div><p>The normalization is a linear transformation of the raw data that can be generalized to any range <span class="emphasis"><em>[l, h]</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note1900"/>Note</h3><p>
<span class="strong"><strong>Linear normalization</strong></span>
</p><p>M2: [0, 1] Normalization of features <span class="emphasis"><em>{x<sub>i</sub>}</em></span> with minimum <span class="emphasis"><em>x<sub>min</sub></em></span> and maximum <span class="emphasis"><em>x<sub>max</sub></em></span> values:</p><div class="mediaobject"><img src="../Images/image01247.jpeg" alt="Immutable normalization"/></div><p style="clear:both; height: 1em;"> </p><p>M3: [l, h] Normalization of features <span class="emphasis"><em>{xi}</em></span>:</p><div class="mediaobject"><img src="../Images/image01248.jpeg" alt="Immutable normalization"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id1210000" class="indexterm"/>normalization of input data in supervised learning has a specific requirement: the classification and prediction of new observations have to use the normalization parameters (<span class="emphasis"><em>min</em></span> and <span class="emphasis"><em>max</em></span>) extracted from the training set, so all the observations share the same scaling factor.</p><p>Let's define the <code class="literal">MinMax</code> normalization class. The class is immutable: the minimum, <code class="literal">min</code>, and maximum, <code class="literal">max</code>, values are computed within the constructor. The class takes a time series of a parameterized <code class="literal">T</code> type and values as arguments (line <code class="literal">8</code>). The steps of the normalization process are defined as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Initialize the minimum values for a given time series during instantiation (line <code class="literal">9</code>).</li><li class="listitem">Compute the normalization parameters (line <code class="literal">10</code>) and normalize the input data (line <code class="literal">11</code>).</li><li class="listitem">Normalize any new data points reusing the normalization parameters (line <code class="literal">14</code>):<div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MinMax</strong></span>[T &lt;: AnyVal](val <span class="strong"><strong>values</strong></span>: XSeries[T]) (f : T =&gt; Double) { //<span class="strong"><strong>8</strong></span>
  val zero = (Double.MaxValue, -Double.MaxValue)
  val <span class="strong"><strong>minMax</strong></span> = values./:(zero)((mM, x) =&gt; { //9
    val min = mM._1
    val max = mM._2
   (if(x &lt; min) x else min, if(x &gt; max) x else max)
  })
  case class ScaleFactors(low:Double ,high:Double, ratio: Double)
  var <span class="strong"><strong>scaleFactors</strong></span>: Option[ScaleFactors] = None //<span class="strong"><strong>10</strong></span>

  def min = minMax._1
  def max = minMax._2
  def <span class="strong"><strong>normalize</strong></span>(low: Double, high: Double): DblVector //<span class="strong"><strong>11</strong></span>
  def <span class="strong"><strong>normalize</strong></span>(value: Double): Double
}</pre></div></li></ol><div style="height:10px; width: 1px"/></div><p>The class<a id="id1220000" class="indexterm"/> constructor computes the tuple of minimum and maximum values, <code class="literal">minMax</code>, using a fold (line <code class="literal">9</code>). The <code class="literal">scaleFactors</code> scaling parameters are computed during the normalization of the time series (line <code class="literal">11</code>), which are described as follows. The <code class="literal">normalize</code> method initializes the scaling factor parameters (line <code class="literal">12</code>) before normalizing the input data (line <code class="literal">13</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>normalize</strong></span>(low: Double, high: Double): DblVector = 
  setScaleFactors(low, high).map( scale =&gt; { //<span class="strong"><strong>12</strong></span>
    values.map(x =&gt;(x - min)*scale.ratio + scale.low) //<span class="strong"><strong>13</strong></span>
  }).getOrElse(/* … */)

def <span class="strong"><strong>setScaleFactors</strong></span>(l: Double, h: Double): Option[ScaleFactors]={
    // .. error handling code
   Some(ScaleFactors(l, h, (h - l)/(max - min))
}</pre></div><p>Subsequent observations use the same scaling factors extracted from the input time series in <code class="literal">normalize</code> (line <code class="literal">14</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>normalize</strong></span>(value: Double):Double = setScaleFactors.map(scale =&gt; 
   if(value &lt; min) scale.low
   else if (value &gt; max) scale.high
   else (value - min)* scale.high + scale.low
).getOrElse( /* … */)</pre></div><p>The <code class="literal">MinMax</code> class normalizes single variable observations.</p><div class="note" title="Note"><h3 class="title"><a id="note2100"/>Note</h3><p>
<span class="strong"><strong>The statistics class</strong></span>
</p><p>The class that extracts the basic statistics from a <code class="literal">Stats</code> dataset, which is introduced in the <span class="emphasis"><em>Profiling data</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, inherits the <code class="literal">MinMax</code> class.</p></div><p>The test case with the binomial logistic regression uses a multiple variable normalization, implemented by the <code class="literal">MinMaxVector</code> class, which takes observations of the <code class="literal">XVSeries[Double]</code> type as inputs:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MinMaxVector</strong></span>(series: XVSeries[Double]) {
  val minMaxVector: Vector[MinMax[Double]] = //<span class="strong"><strong>15</strong></span>
      series.<span class="strong"><strong>transpose</strong></span>.map(new MinMax[Double](_))
  def normalize(low: Double, high: Double): XVSeries[Double]
}</pre></div><p>The constructor <a id="id1230000" class="indexterm"/>of the <code class="literal">MinMaxVector</code> class transposes the vector of array of observations in order to compute the minimum and maximum value for each dimension (line <code class="literal">15</code>).</p></div></div><div class="section" title="Step 4 – discovering patterns"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec2000"/>Step 4 – discovering patterns</h3></div></div></div><p>The price <a id="id1240000" class="indexterm"/>action chart has a very interesting characteristic.</p><div class="section" title="Analyzing data"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0200"/>Analyzing data</h4></div></div></div><p>At a <a id="id1250000" class="indexterm"/>closer look, a sudden change in price and increase in volume occurs about every three months or so. Experienced investors will undoubtedly recognize that these price-volume patterns are related to the release of quarterly earnings of Cisco. Such a regular but unpredictable pattern can be a source of concern or opportunity if risk can be properly managed. The strong reaction of the stock price to the release of corporate earnings may scare some long-term investors while enticing day traders.</p><p>The following graph visualizes the potential correlation between sudden price change (volatility) and heavy trading volume:</p><div class="mediaobject"><img src="../Images/image01249.jpeg" alt="Analyzing data"/><div class="caption"><p>Price-volume correlation for the Cisco stock 2012-2013</p></div></div><p style="clear:both; height: 1em;"> </p><p>The next section is not required for the understanding of the test case. It illustrates the capabilities of<a id="id1260000" class="indexterm"/> JFreeChart as a simple visualization and plotting library.</p></div><div class="section" title="Plotting data"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0300"/>Plotting data</h4></div></div></div><p>Although charting <a id="id1270000" class="indexterm"/>is not the primary goal of this book, we thought that you will benefit from a brief introduction to JFreeChart.</p><div class="note" title="Note"><h3 class="title"><a id="note2200"/>Note</h3><p>
<span class="strong"><strong>Plotting classes</strong></span>
</p><p>This section illustrates a simple Scala interface to JFreeChart Java classes. Reading this is not required for the understanding of machine learning. The visualization of the results of a computation is beyond the scope of this book.</p><p>Some of the classes used in visualization are described in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p></div><p>The dataset (volatility and volume) is converted into internal JFreeChart data structures. The <code class="literal">ScatterPlot</code> class implements a simple configurable scatter plot with the following arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This includes information, labels, fonts, and so on, of the plot</li><li class="listitem"><code class="literal">theme</code>: This is the predefined theme for the plot (black, white background, and so on)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>ScatterPlot</strong></span>(<span class="strong"><strong>config</strong></span>: PlotInfo, <span class="strong"><strong>theme</strong></span>: PlotTheme) { //<span class="strong"><strong>16</strong></span>
  def <span class="strong"><strong>display</strong></span>(xy: Vector[DblPair], width: Int, height) //<span class="strong"><strong>17</strong></span>
  def <span class="strong"><strong>display</strong></span>(xt: XVSeries[Double], width: Int, height)
  // ….
}</pre></div><p>The <code class="literal">PlotTheme</code> class defines a specific theme or preconfiguration of the chart (line <span class="strong"><strong>16</strong></span>). The class offers a set of <code class="literal">display</code> methods to accommodate a wide range of data structures and configuration (line <code class="literal">17</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note2300"/>Note</h3><p>
<span class="strong"><strong>Visualization</strong></span>
</p><p>The JFreeChart library is introduced as a robust charting tool. The code related to plots and charts is omitted from the book in order to keep the code snippets concise and dedicated to machine learning. On a few occasions, output data is formatted as a CSV file to be imported into a spreadsheet.</p></div><p>The <code class="literal">ScatterPlot.display</code> method is used to display the normalized input data used in the binomial logistic <a id="id1280000" class="indexterm"/>regression as follows:</p><div class="informalexample"><pre class="programlisting">val plot = new <span class="strong"><strong>ScatterPlot</strong></span>(("CSCO 2012-2013", 
   "Session High - Low", "Session Volume"), new BlackPlotTheme)
plot.display(volatility_vol, 250, 340)</pre></div><div class="mediaobject"><img src="../Images/image01250.jpeg" alt="Plotting data"/><div class="caption"><p>A scatter plot of volatility and volume for the Cisco stock 2012-2013</p></div></div><p style="clear:both; height: 1em;"> </p><p>The scatter plot shows a level of correlation between session volume and session volatility and confirms the initial finding in the stock price and volume chart. We can leverage this information to classify trading sessions by their volatility and volume. The next step is to create a two class model by loading a training set, observations, and expected values, into our logistic regression algorithm. The classes are delimited by a <a id="id1290000" class="indexterm"/><span class="strong"><strong>decision boundary</strong></span> (also known as a hyperplane) drawn on the scatter plot.</p><p>Visualizing labels—the normalized variation of the stock price between the opening and closing of the trading session is selected as the label for this classifier.</p></div></div><div class="section" title="Step 5 – implementing the classifier"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec2100"/>Step 5 – implementing the classifier </h3></div></div></div><p>The <a id="id1300000" class="indexterm"/>objective of this training is to build a model that can discriminate between volatile and nonvolatile trading sessions. For the sake of the exercise, session volatility is defined as the relative difference between the session highest price and lower price. The total trading volume within a session constitutes the second parameter of the model. The relative price movement within a trading session (that is, <span class="emphasis"><em>closing price/open price - 1</em></span>) is our expected values or labels.</p><p>Logistic regression is commonly used in statistics inference.</p><div class="note" title="Note"><h3 class="title"><a id="tip0600"/>Tip</h3><p>M4: <span class="strong"><strong>Logistic regression model</strong></span>
</p><div class="mediaobject"><img src="../Images/image01251.jpeg" alt="Step 5 – implementing the classifier"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id1310000" class="indexterm"/>first weight <span class="emphasis"><em>w<sub>0</sub></em></span> is known as the intercept. The binomial logistic regression is described in the <span class="emphasis"><em>Logistic regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>, in detail.</p><p>The following implementation of the binomial logistic regression classifier exposes a single <code class="literal">classify</code> method to comply with our desire to reduce the complexity and life cycle of objects. The model <code class="literal">weights</code> parameters are computed during training when the <code class="literal">LogBinRegression</code> class/model is instantiated. As mentioned earlier, the sections of the code nonessential to the understanding of the algorithm are omitted.</p><p>The <code class="literal">LogBinRegression</code> constructor has five arguments (line <code class="literal">18</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">obsSet</code>: These <a id="id1320000" class="indexterm"/>are vector observations that represent volume and volatility</li><li class="listitem"><code class="literal">expected</code>: This<a id="id1330000" class="indexterm"/> is a vector of expected values</li><li class="listitem"><code class="literal">maxIters</code>: This<a id="id1340000" class="indexterm"/> is the maximum number of iterations allowed for the optimizer to extract the regression weights during training</li><li class="listitem"><code class="literal">eta</code>: This <a id="id1350000" class="indexterm"/>is the learning or training rate</li><li class="listitem"><code class="literal">eps</code>: This<a id="id1360000" class="indexterm"/> is the maximum value of the error (<span class="emphasis"><em>predicted—expected</em></span>) for which the model is valid</li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>LogBinRegression</strong></span>(
     <span class="strong"><strong>obsSet</strong></span>: Vector[DblArray], 
     <span class="strong"><strong>expected</strong></span>: Vector[Int],
     <span class="strong"><strong>maxIters</strong></span>: Int, 
     <span class="strong"><strong>eta</strong></span>: Double, 
     <span class="strong"><strong>eps</strong></span>: Double) {  //<span class="strong"><strong>18</strong></span>

   val <span class="strong"><strong>model</strong></span>: <span class="strong"><strong>LogBinRegressionModel</strong></span> = train  //<span class="strong"><strong>19</strong></span>
   def <span class="strong"><strong>classify</strong></span>(obs: DblArray): Try[(Int, Double)]   //<span class="strong"><strong>20</strong></span>
   def <span class="strong"><strong>train</strong></span>: LogBinRegressionModel
   def intercept(weights: DblArray): Double
   …
}</pre></div><p>The <code class="literal">LogBinRegressionModel</code> model is generated through training during the instantiation of the <code class="literal">LogBinRegression</code> logistic regression class (line <code class="literal">19</code>):</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>LogBinRegressionModel</strong></span>(val weights: DblArray)</pre></div><p>The <a id="id1370000" class="indexterm"/>model is fully defined by its weights, as described in the mathematical formula <span class="strong"><strong>M3</strong></span>. The <code class="literal">weights(0)</code> intercept represents the mean value of the prediction for observations for which variables are zero. The intercept does not have any specific meaning for most of the cases and it is not always computable.</p><div class="note" title="Note"><h3 class="title"><a id="note2400"/>Note</h3><p>
<span class="strong"><strong>Intercept or not intercept?</strong></span>
</p><p>The intercept corresponds to the value of weights when the observations have null values. It is a common practice to estimate, whenever possible, the intercept for binomial linear or logistic regression independently from the slope of the model in the minimization of the error function. The multinomial regression models treat the intercept or weight <span class="emphasis"><em>w<sub>0</sub></em></span> as part of the regression model, as described in the <span class="emphasis"><em>Ordinary least squares regression</em></span> section of <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>.</p></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>intercept</strong></span>(weights: DblArray): Double = {
  val zeroObs = obsSet.filter(!_.exists( _ &gt; 0.01))
  if( zeroObs.size &gt; 0)
    zeroObs.aggregate(0.0)((s,z) =&gt; s + dot(z, weights), 
       _ + _ )/zeroObs.size
  else 0.0
}</pre></div><p>The <code class="literal">classify</code> methods takes new observations as inputs and compute the index of the classes (0 or 1) the observations belong to and the actual likelihood (line <code class="literal">20</code>).</p><div class="section" title="Selecting an optimizer"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0400"/>Selecting an optimizer</h4></div></div></div><p>The goal of the training<a id="id1380000" class="indexterm"/> of a model using expected values is to compute the optimal weights that minimizes the <span class="strong"><strong>error</strong></span> or <span class="strong"><strong>cost function</strong></span>. We select <a id="id1390000" class="indexterm"/>the <span class="strong"><strong>batch gradient descent</strong></span> algorithm to minimize the cumulative error between the predicted and expected values for all the observations. Although there are quite a few alternative optimizers, the gradient descent is quite robust and simple enough for this first chapter. The algorithm consists of updating the weights <span class="emphasis"><em>w<sub>i</sub></em></span> of the regression model by minimizing the cost.</p><div class="note" title="Note"><h3 class="title"><a id="note2500"/>Note</h3><p>
<span class="strong"><strong>Cost function</strong></span>
</p><p>M5: Cost (or <span class="emphasis"><em>compound error = predicted – expected</em></span>):</p><div class="mediaobject"><img src="../Images/image01252.jpeg" alt="Selecting an optimizer"/></div><p style="clear:both; height: 1em;"> </p><p>M6: The batch gradient descent method to update model weights <span class="emphasis"><em>w<sub>i</sub></em></span> is as follows:</p><div class="mediaobject"><img src="../Images/image01253.jpeg" alt="Selecting an optimizer"/></div><p style="clear:both; height: 1em;"> </p></div><p>For those interested in learning about of optimization techniques, the <span class="emphasis"><em>Summary of optimization techniques</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span> presents an overview of the most commonly used <a id="id1400000" class="indexterm"/>optimizers. The batch descent gradient method is also used for the training of the multilayer perceptron (refer to <span class="emphasis"><em>The training epoch</em></span> section under <span class="emphasis"><em>The multilayer perceptron</em></span> section in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span>).</p><p>The execution of the batch gradient descent algorithm follows these steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Initialize the weights of the regression model.</li><li class="listitem">Shuffle the order of observations and expected values.</li><li class="listitem">Aggregate the cost or error for the entire observation set.</li><li class="listitem">Update the model weights using the cost as the objective function.</li><li class="listitem">Repeat from step 2 until either the maximum number of iterations is reached or the incremental update of the cost is close to zero.</li></ol><div style="height:10px; width: 1px"/></div><p>The purpose<a id="id1410000" class="indexterm"/> of <span class="strong"><strong>shuffling</strong></span> the order of the observations between iterations is to avoid the minimization of the cost reaching a local minimum.</p><div class="note" title="Note"><h3 class="title"><a id="tip0700"/>Tip</h3><p>
<span class="strong"><strong>Batch and stochastic gradient descent</strong></span>
</p><p>The stochastic gradient descent is a variant of the gradient descent that updates the model weights after computing the error on each observation. Although the stochastic gradient descent requires a higher computation effort to process each observation, it converges toward the optimal value of weights fairly quickly after a small number of iterations. However, the stochastic gradient descent is sensitive to the initial value of the weights and the selection of the learning rate, which is usually defined by an adaptive formula.</p></div></div><div class="section" title="Training the model"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0500"/>Training the model</h4></div></div></div><p>The <code class="literal">train</code> method <a id="id1420000" class="indexterm"/>consists of iterating through the computation of the weight using a simple descent gradient method. The method computes <code class="literal">weights</code> and returns an instance of the <code class="literal">LogBinRegressionModel</code> model:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: LogBinRegressionModel = {
  val <span class="strong"><strong>nWeights</strong></span> = obsSet.head.length + 1  //<span class="strong"><strong>21</strong></span>
  val init = Array.fill(nWeights)(<span class="strong"><strong>Random</strong></span>.nextDouble )  //<span class="strong"><strong>22</strong></span>
  val <span class="strong"><strong>weights</strong></span> = <span class="strong"><strong>gradientDescent</strong></span>(obsSet.zip(expected),0.0,0,init)
  new LogBinRegressionModel(weights)   //<span class="strong"><strong>23</strong></span>
}</pre></div><p>The <code class="literal">train</code> method extracts the number of weights, <code class="literal">nWeights</code>, for the regression model as the <span class="emphasis"><em>number of variables in each observation + 1</em></span> (line <code class="literal">21</code>). The method initializes <code class="literal">weights</code> with random values over [0, 1] (line <code class="literal">22</code>). The weights are computed through the tail recursive <code class="literal">gradientDescent</code> method, and the method returns a new model for the binomial logistic regression (line <code class="literal">23</code>).</p><div class="note" title="Note"><h3 class="title"><a id="tip0800"/>Tip</h3><p>
<span class="strong"><strong>Unwrapping values from Try</strong></span>
</p><p>It is usually not recommended to invoke the <code class="literal">get</code> method to a <code class="literal">Try</code> value, unless it is enclosed in a <code class="literal">Try</code> statement. The best course of action is to do the following:</p><p>1. Catch the failure with <code class="literal">match{ case Success(m) =&gt; ..case Failure(e) =&gt;}</code>
</p><p>2. Extract the <code class="literal">getOrElse( /* … */ )</code> result safely</p><p>3. Propagate the results as a <code class="literal">Try</code> type <code class="literal">map( _.m)</code>
</p></div><p>Let's take a<a id="id1430000" class="indexterm"/> look at the computation for <code class="literal">weights</code> through the minimization of the cost function in the <code class="literal">gradientDescent</code> method:</p><div class="informalexample"><pre class="programlisting">type LabelObs = Vector[(DblArray, Int)]

<span class="strong"><strong>@tailrec</strong></span>
def <span class="strong"><strong>gradientDescent</strong></span>(
      <span class="strong"><strong>obsAndLbl</strong></span>: LabelObs, 
      cost: Double, 
      nIters: Int, 
      weights: DblArray): DblArray = {  //<span class="strong"><strong>24</strong></span>
  
  if(nIters &gt;= maxIters) 
       throw new IllegalStateException("..")//<span class="strong"><strong>25</strong></span>
  val shuffled = <span class="strong"><strong>shuffle</strong></span>(obsAndLbl)   //<span class="strong"><strong>26</strong></span>
  val <span class="strong"><strong>errorGrad</strong></span> = shuffled.map{ case(x, y) =&gt; {  //<span class="strong"><strong>27</strong></span>
      val error = <span class="strong"><strong>sigmoid</strong></span>(dot(x, weights)) - y
      (error, x.map( _ * error))  //<span class="strong"><strong>28</strong></span>
   }}.unzip

   val scale = 0.5/obsAndLbl.size
   val newCost = errorGrad._1   //<span class="strong"><strong>29</strong></span>
.aggregate(0.0)((s,c) =&gt;s + c*c, _ + _ )*scale
   val <span class="strong"><strong>relativeError</strong></span> = cost/newCost - 1.0
   
   if( Math.abs(relativeError) &lt; eps)  weights  //<span class="strong"><strong>30</strong></span>
   else {
     val derivatives = Vector[Double](1.0) ++ 
                 errorGrad._2.transpose.map(_.sum) //<span class="strong"><strong>31</strong></span>
     val newWeights = weights.zip(derivatives)
                       .map{ case (w, df) =&gt; w - eta*df)  //<span class="strong"><strong>32</strong></span>
     newWeights.copyToArray(weights)
     <span class="strong"><strong>gradientDescent</strong></span>(shuffled, newCost, nIters+1, newWeights)//<span class="strong"><strong>33</strong></span>
   }
}</pre></div><p>The <code class="literal">gradientDescent</code> method recurses on the vector of pairs (observations and expected values), <code class="literal">obsAndLbl</code>, <code class="literal">cost</code>, and the model <code class="literal">weights</code> (line <code class="literal">24</code>). It throws an exception if the maximum number of iterations allowed for the optimization is reached (line <code class="literal">25</code>). It shuffles the order of the observations (line <code class="literal">26</code>) before computing the  <code class="literal">errorGrad</code> derivatives of the cost over each weights (line <code class="literal">27</code>). The computation of the derivative of the cost (or <span class="emphasis"><em>error = predicted value – expected value</em></span>) in formula <span class="strong"><strong>M5</strong></span> returns a pair of cumulative cost and derivative values using the formula (line <code class="literal">28</code>).</p><p>Next, the <a id="id1440000" class="indexterm"/>method computes the overall compound cost using the formula <span class="strong"><strong>M4</strong></span> (line <code class="literal">29</code>), converts it to a relative incremental <code class="literal">relativeError</code> cost that is compared to the <code class="literal">eps</code> convergence criteria (line <code class="literal">30</code>). The method extracts <code class="literal">derivatives</code> of cost over weights by transposing the matrix of errors, and then prepends the bias <code class="literal">1.0</code> value to match the array of weights (line <code class="literal">31</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note2700"/>Note</h3><p>
<span class="strong"><strong>Bias value</strong></span>
</p><p>The purpose of the bias value is to prepend <code class="literal">1.0</code> to the vector of observation so it can be directly processed (for example, zip and dot) with the weights. For instance, a regression model for two-dimensional observations (x, y) has three weights (<span class="emphasis"><em>w<sub>0</sub>, w<sub>1</sub>, w<sub>2</sub></em></span>). The bias value +1 is prepended to the observations to compute the predicted value 1.0: <span class="emphasis"><em>w<sub>0</sub> + x.w<sub>1</sub>, +
 y.w<sub>2</sub></em></span>.</p><p>This technique is used in the computation of the activation function of the multilayer perceptron, as described in the <span class="emphasis"><em>The multilayer perceptron</em></span> section in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span>.</p></div><p>The formula <span class="strong"><strong>M6</strong></span> updates the weights for the next iteration (line <code class="literal">32</code>) before invoking the method with new weights, cost, and iteration count (line <code class="literal">33</code>).</p><p>Let's take a look at the shuffling of the order of observations using a random sequence generator. The following implementation is an alternative to the Scala standard library method <code class="literal">scala.util.Random.shuffle</code> for shuffling elements of collections. The purpose is to change the order of observations and labels between iterations in order to prevent the optimizer to reach a local minimum. The <code class="literal">shuffle</code> method permutes the order in the <code class="literal">labelObs</code> vector of observations by partitioning it into segments of random size and reversing the order of the other segment:</p><div class="informalexample"><pre class="programlisting">val SPAN = 5
def <span class="strong"><strong>shuffle</strong></span>(labelObs: LabelObs): LabelObs = { 
  shuffle(new ArrayBuffer[Int],0,0).map(labelObs( _ )) //<span class="strong"><strong>34</strong></span>
}</pre></div><p>Once the order of the observations is updated, the vector of pair (observations, labels) is easily built through a map (line <code class="literal">34</code>). The actual shuffling of the index is performed in the following <code class="literal">shuffle</code> recursive function:</p><div class="informalexample"><pre class="programlisting">val maxChunkSize = Random.nextInt(SPAN)+2  //<span class="strong"><strong>35</strong></span>

@tailrec
def <span class="strong"><strong>shuffle</strong></span>(<span class="strong"><strong>indices</strong></span>: ArrayBuffer[Int], count: Int, start: Int): 
      Array[Int] = {
  val end = start + Random.nextInt(maxChunkSize) //<span class="strong"><strong>36</strong></span>
  val isOdd = ((count &amp; 0x01) != 0x01)
  if(end &gt;= sz) 
    indices.toArray ++ slice(isOdd, start, sz) //<span class="strong"><strong>37</strong></span>
  else 
    <span class="strong"><strong>shuffle</strong></span>(indices ++ <span class="strong"><strong>slice</strong></span>(isOdd, start, end), count+1, end)
}</pre></div><p>The <a id="id1450000" class="indexterm"/>maximum size of partition of the <code class="literal">maxChunkSize</code> vector observations is randomly computed (line <code class="literal">35</code>). The method extracts the next slice (<code class="literal">start</code>, <code class="literal">end</code>) (line <code class="literal">36</code>). The slice is either added to the existing indices vector and returned once all the observations have been shuffled (line <code class="literal">37</code>) or passed to the next invocation.</p><p>The <code class="literal">slice</code> method returns an array of indices over the range (<code class="literal">start</code>, <code class="literal">end</code>) either in the right order if the number of segments processed is odd, or in reverse order if the number of segment processed is even:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>slice</strong></span>(<span class="strong"><strong>isOdd</strong></span>: Boolean, start: Int, end: Int): Array[Int] = {
  val r = Range(<span class="strong"><strong>start</strong></span>, <span class="strong"><strong>end</strong></span>).toArray
  (if(isOdd) r else r.<span class="strong"><strong>reverse</strong></span>)
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note2800"/>Note</h3><p>
<span class="strong"><strong>Iterative versus tail recursive computation</strong></span>
</p><p>The tail recursion in Scala is a very efficient alternative to the iterative algorithm. Tail recursion avoids the need to create a new stack frame for each invocation of the method. It is applied to the implementation of many machine learning algorithms presented throughout the book. </p></div><p>In order to train the model, we need to label the input data. The labeling process consists of associating the relative price movement during a session (price at <span class="emphasis"><em>close/price at open – 1</em></span>) with one of the following two configurations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Volatile trading sessions with high trading volume</li><li class="listitem">Trading sessions with low volatility and low trading volume</li></ul></div><p>The two classes of training observations are segregated by a decision boundary drawn on the scatter plot in the previous section. The labeling process is usually quite cumbersome and should be automated as much as possible.</p><div class="note" title="Note"><h3 class="title"><a id="note2900"/>Note</h3><p>
<span class="strong"><strong>Automated labeling</strong></span>
</p><p>Although quite convenient, automated creation of training labels is not without risk as it may mislabel singular observations. This technique is used in this test for convenience, but it is not recommended unless a domain expert reviews the labels manually.</p></div></div><div class="section" title="Classifying observations"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec0600"/>Classifying observations</h4></div></div></div><p>Once the model <a id="id1460000" class="indexterm"/>is successfully created through training, it is available to classify new observation. The runtime classification of observations using the binomial logistic regression is implemented by the <code class="literal">classify</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>classify</strong></span>(<span class="strong"><strong>obs</strong></span>: DblArray): Try[(Int, Double)] = 
  val linear = <span class="strong"><strong>dot</strong></span>(obs, model.weights)  //<span class="strong"><strong>37</strong></span>
  val prediction = sigmoid(linear)
  (if(linear &gt; 0.0) 1 else 0, prediction) //<span class="strong"><strong>38</strong></span>
})</pre></div><p>The method applies the logistic function to the linear inner product, <code class="literal">linear</code>, of the new <code class="literal">obs</code> and <code class="literal">weights</code> observations of the model (line <code class="literal">37</code>). The method returns the tuple (the predicted class of the observation {0, 1}, prediction value) where the class is defined by comparing the prediction to the boundary value <code class="literal">0.0</code> (line <code class="literal">38</code>).</p><p>The computation of the <code class="literal">dot</code> product of weights and observations uses the bias value as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>dot</strong></span>(obs: DblArray, weights: DblArray): Double =
   weights.zip(Array[Double](1.0) ++ obs)
          .aggregate(0.0){case (s, (w,x)) =&gt; s + w*x, _ + _ }</pre></div><p>The alternative implementation of the <code class="literal">dot</code> product of weights and observations consists of extracting the first <code class="literal">w.head</code> weight:</p><div class="informalexample"><pre class="programlisting">def <code class="literal">dot</code>(x: DblArray, w: DblArray): Double = 
  x.zip(w.drop(1)).map {case (_x,_w) =&gt; _x*_w}.sum + w.head</pre></div><p>The <code class="literal">dot</code> method is used in the <code class="literal">classify</code> method.</p></div></div><div class="section" title="Step 6 – evaluating the model"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec2200"/>Step 6 – evaluating the model</h3></div></div></div><p>The first step <a id="id1470000" class="indexterm"/>is to define the configuration parameters for the test: the maximum number of <code class="literal">NITERS</code> iterations, the <code class="literal">EPS</code> convergence criteria, the <code class="literal">ETA</code> learning rate, the decision boundary used to label the <code class="literal">BOUNDARY</code> training observations, and the path to the training and test sets:</p><div class="informalexample"><pre class="programlisting">val NITERS = 800; val EPS = 0.02; val ETA = 0.0001
val path_training = "resources/data/chap1/CSCO.csv"
val path_test = "resources/data/chap1/CSCO2.csv"</pre></div><p>The various activities of creating and testing the model, loading, normalizing data, training the<a id="id1480000" class="indexterm"/> model, loading, and classifying test data is organized as a workflow using the monadic composition of the <code class="literal">Try</code> class:</p><div class="informalexample"><pre class="programlisting">for {
  <span class="strong"><strong>volatilityVol</strong></span> &lt;- <span class="strong"><strong>load</strong></span>(path_training)    //39
  minMaxVec &lt;- Try(new MinMaxVector(volatilityVol))    //40
  normVolatilityVol &lt;- Try(minMaxVec.<span class="strong"><strong>normalize</strong></span>(0.0,1.0))//41
  <span class="strong"><strong>classifier</strong></span> &lt;- logRegr(normVolatilityVol)    //42
  <span class="strong"><strong>testValues</strong></span> &lt;- load(path_test)    //43
  normTestValue0 &lt;- minMaxVec.normalize(testValues(0))  //44
  class0 &lt;- classifier.<span class="strong"><strong>classify</strong></span>(normTestValue0)   //45
  normTestValue1 &lt;- minMaxVec.<span class="strong"><strong>normalize</strong></span>(testValues(1))    
  class1 &lt;- classifier.<span class="strong"><strong>classify</strong></span>(normTestValues1)
} yield {
   val modelStr = model.toString
   …
}</pre></div><p>First, the daily trading volatility and volume for the <code class="literal">volatilityVol</code> stock price is loaded from file (line <code class="literal">39</code>). The workflow initializes the multi-dimensional <code class="literal">MinMaxVec</code> normalizer (line <code class="literal">40</code>) and uses it to normalize the training set (line <code class="literal">41</code>). The <code class="literal">logRegr</code> method instantiates the binomial <code class="literal">classifier</code> logistic regression (line <code class="literal">42</code>). The <code class="literal">testValues</code> test data is loaded from file (line <code class="literal">43</code>), normalized using <code class="literal">MinMaxVec</code> already applied to the training data (line <code class="literal">44</code>), and classified (line <code class="literal">45</code>).</p><p>The <code class="literal">load</code> method extracts <code class="literal">data</code> (observations) of a <code class="literal">XVSeries[Double]</code> type from the file. The heavy lifting is done by the <code class="literal">extract</code> method (line <code class="literal">46</code>), and then the file handle is closed (line <code class="literal">47</code>) before returning the vector of raw observations:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>load</strong></span>(fileName: String): Try[XVSeries[Double], XSeries[Double]] =  {
  val src =  Source.fromFile(fileName)
  val <span class="strong"><strong>data</strong></span> = <span class="strong"><strong>extract</strong></span>(src.getLines.map( _.split(",")).drop(1)) //<span class="strong"><strong>46</strong></span>
  src.close; data //<span class="strong"><strong>47</strong></span>
}</pre></div><p>The private <code class="literal">logRegr</code> method has the following two purposes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Labeling automatically the <code class="literal">obs</code> observations to generate the <code class="literal">expected</code> values (line <code class="literal">48</code>)</li><li class="listitem">Initializing (instantiation and training of the model) the binomial logistic regression (line <code class="literal">49</code>)</li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>logRegr</strong></span>(<span class="strong"><strong>obs</strong></span>: XVSeries[Double]): Try[LogBinRegression] = Try {
    val <span class="strong"><strong>expected</strong></span> = normalize(labels._2).get  //<span class="strong"><strong>48</strong></span>
    new LogBinRegression(obs, expected, NITERS, ETA, EPS)  //<span class="strong"><strong>49</strong></span>
}</pre></div><p>The method <a id="id1490000" class="indexterm"/>labels observations by evaluating if they belong to any one of the two classes delimited by the <code class="literal">BOUNDARY</code> condition, as illustrated in the scatter plot in a previous section.</p><div class="note" title="Note"><h3 class="title"><a id="note3000"/>Note</h3><p>
<span class="strong"><strong>Validation</strong></span>
</p><p>The simple classification in this test case is provided for illustrating the runtime application of the model. It does not constitute a validation of the model by any stretch of imagination. The next chapter digs into validation methodologies (refer to the <span class="emphasis"><em>Assessing a model</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p></div><p>The training run is performed with three different values of the learning rate. The following chart illustrates the convergence of the batch gradient descent in the minimization of the cost, given different values of learning rates:</p><div class="mediaobject"><img src="../Images/image01254.jpeg" alt="Step 6 – evaluating the model"/><div class="caption"><p>Impact of the learning rate on the batch gradient descent on the convergence of the cost (error)</p></div></div><p style="clear:both; height: 1em;"> </p><p>As expected, the<a id="id1500000" class="indexterm"/> execution of the optimizer with a higher learning rate produces a steepest descent in the cost function.</p><p>The execution of the test produces the following model:</p><p>
<span class="strong"><strong>iters = 495</strong></span>
</p><p>
<span class="strong"><strong>weights: 0.859-3.6177923,-64.927832</strong></span>
</p><p>
<span class="strong"><strong>input (0.0088, 4.10E7) normalized (0.063,0.061) class 1 prediction 0.515</strong></span>
</p><p>
<span class="strong"><strong>input (0.0694, 3.68E8) normalized (0.517,0.641) class 0 prediction 0.001</strong></span>
</p><div class="note" title="Note"><h3 class="title"><a id="note3100"/>Note</h3><p>
<span class="strong"><strong>Learning more about regressive models</strong></span>
</p><p>The binomial logistic regression is merely used to illustrate the concept of training and prediction. It is described in the <span class="emphasis"><em>Logistic regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span> in detail.</p></div></div></div></div>
<div class="section" title="Summary" id="aid-4SCS81"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec1700"/>Summary</h1></div></div></div><p>I hope you enjoyed this introduction to machine learning. You learned how to leverage your skills in Scala programming to create a simple logistic regression program for predicting stock price/volume action. Here are the highlights of this introductory chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">From monadic composition and high order collection methods for parallelization to configurability and reusability patterns, Scala is the perfect fit to implement data mining and machine learning algorithms for large-scale projects.</li><li class="listitem">There are many logical steps to create and deploy a machine learning model.</li><li class="listitem">The implementation of the binomial logistic regression classifier presented as part of the test case is simple enough to encourage you to learn how to write and apply more advanced machine learning algorithms.</li></ul></div><p>To the delight of Scala programming aficionados, the next chapter will dig deeper into building a flexible workflow by leveraging monadic data transformation and stackable traits.</p></div>
<div class="chapter" title="Chapter&#xA0;2.&#xA0;Hello World!"><div class="titlepage" id="aid-4TBCQ2"><div><div><h1 class="title"><a id="ch16"/>Chapter 2. Hello World!</h1></div></div></div><p>In the first chapter, you were acquainted with some rudimentary concepts regarding data processing, clustering, and classification. This chapter is dedicated to the creation and maintenance of a flexible end-to-end workflow to train and classify data. The first section of the chapter introduces a data-centric (functional) approach to create number-crunching applications.</p><p>You will learn how to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Apply the concept of monadic design to create dynamic workflows</li><li class="listitem">Leverage some of Scala's advanced patterns, such as the cake pattern, to build portable computational workflows</li><li class="listitem">Take into account the bias-variance trade-off in selecting a model</li><li class="listitem">Overcome overfitting in modeling</li><li class="listitem">Break down data into training, test, and validation sets</li><li class="listitem">Implement model validation in Scala using precision, recall, and F score</li></ul></div><div class="section" title="Modeling"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec1800"/>Modeling</h1></div></div></div><p>Data is <a id="id1510000" class="indexterm"/>the lifeline of any scientist, and the selection of data providers is critical in developing or evaluating any statistical inference or machine learning algorithm.</p><div class="section" title="A model by any other name"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3200"/>A model by any other name</h2></div></div></div><p>We briefly <a id="id1520000" class="indexterm"/>introduced the concept of a <span class="strong"><strong>model</strong></span> in the <span class="emphasis"><em>Model categorization</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p><p>What constitutes a model? Wikipedia provides a reasonably good definition of a model as understood by scientists [2:1]:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>A scientific model seeks to represent empirical objects, phenomena, and physical processes in a logical and objective way.</em></span></p><p>…</p><p><span class="emphasis"><em>Models that are rendered in software allow scientists to leverage computational power to simulate, visualize, manipulate and gain intuition about the entity, phenomenon or process being represented.</em></span></p></blockquote></div><p>In statistics<a id="id1530000" class="indexterm"/> and the probabilistic theory, a model describes data that one might observe from a system to express any form of uncertainty and noise. A model allows us to infer rules, make predictions, and learn from data.</p><p>A model is composed of <a id="id1540000" class="indexterm"/><span class="strong"><strong>features</strong></span>, also known as <a id="id1550000" class="indexterm"/><span class="strong"><strong>attributes</strong></span> or <a id="id1560000" class="indexterm"/><span class="strong"><strong>variables</strong></span>, and a set of relation between those features. For instance, the model represented by the function <span class="emphasis"><em>f(x, y) = x.sin(2y)</em></span> has two features, <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y,</em></span> and a relation, <span class="emphasis"><em>f</em></span>. Those two features are assumed to be independent. If the model is subject to a constraint such as <span class="emphasis"><em>f(x, y) &lt; 20</em></span>, then the <span class="strong"><strong>conditional independence</strong></span>
<a id="id1570000" class="indexterm"/> is no longer valid.</p><p>An astute Scala programmer would associate a model to a monoid for which the set is a group of observations and the operator is the function implementing the model.</p><p>Models come in a variety of shapes and forms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Parametric</strong></span>: This <a id="id1580000" class="indexterm"/>consists of functions and equations (for example, <span class="emphasis"><em>y = sin(2t + w)</em></span>)</li><li class="listitem"><span class="strong"><strong>Differential</strong></span>: This <a id="id1590000" class="indexterm"/>consists of ordinary and partial differential equations (for example, <span class="emphasis"><em>dy = 2x.dx</em></span>)</li><li class="listitem"><span class="strong"><strong>Probabilistic</strong></span>: This<a id="id1600000" class="indexterm"/> consists of probability distributions (for example, <span class="emphasis"><em>p(x|c) = exp (k.logx – x)/x!</em></span>)</li><li class="listitem"><span class="strong"><strong>Graphical</strong></span>: This <a id="id1610000" class="indexterm"/>consists of graphs that abstract out the conditional independence between variables (for example, <span class="emphasis"><em>p(x,y|c) = p(x|c).p(y|c)</em></span>)</li><li class="listitem"><span class="strong"><strong>Directed graphs</strong></span>: This<a id="id1620000" class="indexterm"/> consists of temporal and spatial relationships (for example, a scheduler)</li><li class="listitem"><span class="strong"><strong>Numerical method</strong></span>: This<a id="id1630000" class="indexterm"/> consists of computational methods such as finite difference, finite elements, or Newton-Raphson</li><li class="listitem"><span class="strong"><strong>Chemistry</strong></span>: This <a id="id1640000" class="indexterm"/>consists of formula and components (for example, <span class="emphasis"><em>H<sub>2</sub>O, Fe + C<sub>12</sub> = FeC<sub>13</sub></em></span>, and so on)</li><li class="listitem"><span class="strong"><strong>Taxonomy</strong></span>: This<a id="id1650000" class="indexterm"/> consists of a semantic definition and relationship of concepts (for example, <span class="emphasis"><em>APG/Eudicots/Rosids/Huaceae/Malvales</em></span>)</li><li class="listitem"><span class="strong"><strong>Grammar and lexicon</strong></span>: This<a id="id1660000" class="indexterm"/> consists of a syntactic representation of documents (for example, the Scala programming language)</li><li class="listitem"><span class="strong"><strong>Inference logic</strong></span>: This <a id="id1670000" class="indexterm"/>consists of rules (for example, <span class="emphasis"><em>IF (stock vol &gt; 1.5 * average) AND rsi &gt; 80 THEN …</em></span>)</li></ul></div></div><div class="section" title="Model versus design"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3300"/>Model versus design</h2></div></div></div><p>The <a id="id1680000" class="indexterm"/>confusion between a model and design is quite common in computer science, the reason being that these terms have different meanings for different people depending on the subject. The following metaphors should help with your understanding of these two concepts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Modeling</strong></span>: This <a id="id1690000" class="indexterm"/>describes something you know. A model makes an assumption, which becomes an assertion if proven correct (for example, the US population, <span class="emphasis"><em>p</em></span>, increases by 1.2 percent a year, <span class="emphasis"><em>dp/dt = 1.012</em></span>).</li><li class="listitem"><span class="strong"><strong>Designing</strong></span>: This<a id="id1700000" class="indexterm"/> manipulates the representation of things you don't know. Designing can be regarded as the exploration phase of modeling (for example, what are the features that contribute to the growth of the US population? Birth rate? Immigration? Economic conditions? Social policies?).</li></ul></div></div><div class="section" title="Selecting features"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3400"/>Selecting features</h2></div></div></div><p>The <a id="id1710000" class="indexterm"/>selection<a id="id1720000" class="indexterm"/> of a model's features is the process of discovering and documenting the minimum set of variables required to build the model. Scientists assume that data contains many redundant or irrelevant features. Redundant features do not provide information already given by the selected features, and irrelevant features provide no useful information.</p><p>A <span class="strong"><strong>features selection</strong></span> consists of two consecutive steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Searching for new feature subsets.</li><li class="listitem">Evaluating these feature subsets using a scoring mechanism.</li></ol><div style="height:10px; width: 1px"/></div><p>The<a id="id1730000" class="indexterm"/> process <a id="id1740000" class="indexterm"/>of evaluating each possible subset of features to find the one that maximizes the objective function or minimizes the error rate is computationally intractable for large datasets. A model with <span class="emphasis"><em>n</em></span> features requires <span class="emphasis"><em>2<sup>n</sup>-1</em></span> evaluations.</p></div><div class="section" title="Extracting features"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3500"/>Extracting features</h2></div></div></div><p>An <a id="id1750000" class="indexterm"/><span class="strong"><strong>observation</strong></span> is<a id="id1760000" class="indexterm"/> a set of indirect measurements of hidden, also known as latent, variables, which may be noisy or contain a high degree of correlation and redundancies. Using raw observations in a classification task would very likely produce inaccurate results. Using all features in each observation also incurs a high computation cost.</p><p>The purpose of <a id="id1770000" class="indexterm"/><span class="strong"><strong>features extraction</strong></span> is to reduce the number of variables or dimensions of the model by eliminating redundant or irrelevant features. The features are extracted by transforming the original set of observations into a smaller set at the risk of losing some vital information embedded in the original set.</p></div></div></div>
<div class="section" title="Defining a methodology" id="aid-4U9TC1"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec1900"/>Defining a methodology</h1></div></div></div><p>A data<a id="id1780000" class="indexterm"/> scientist has many options in selecting and implementing a classification or clustering algorithm.</p><p>Firstly, a mathematical or statistical model is to be selected to extract knowledge from the raw input data or the output of a data upstream transformation. The selection of the model is constrained by the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Business requirements such as accuracy of results or computation time</li><li class="listitem">Availability of training data, algorithms, and libraries</li><li class="listitem">Access to a domain or subject matter expert, if needed</li></ul></div><p>Secondly, the engineer has to select a computational and deployment framework suitable for the amount of data to be processed. The computational context is to be defined by the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Available resources such as machines, CPU, memory, or I/O bandwidth</li><li class="listitem">An implementation strategy such as iterative versus recursive computation or caching</li><li class="listitem">Requirements for the responsiveness of the overall process such as duration of computation or display of intermediate results</li></ul></div><p>Thirdly, a <a id="id1790000" class="indexterm"/>domain expert has to tag or label the observations in order to generate an accurate classifier.</p><p>Finally, the model has to be validated against a reliable test dataset.</p><p>The following diagram illustrates the selection process to create a workflow:</p><div class="mediaobject"><img src="../Images/image01255.jpeg" alt="Defining a methodology"/><div class="caption"><p>Statistical and computation modeling for machine learning applications</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note3200"/>Note</h3><p>
<span class="strong"><strong>Domain expertise, data science, and software engineering</strong></span>
</p><p>A domain or subject matter expert is a person with authoritative or credited expertise in a particular area or topic. A chemist is an expert in the domain of chemistry and possibly related fields.</p><p>A data scientist solves problems related to data in a variety of fields, such as biological sciences, health care, marketing, or finances. Data and text mining, signal processing, statistical analysis, and modeling using machine learning algorithms are some of the activities performed by a data scientist.</p><p>A software developer performs all the tasks related to the creation of software applications, including analysis, design, coding, testing, and deployment.</p></div><p>The<a id="id1800000" class="indexterm"/> parameters of a data transformation may need to be reconfigured according to the output of the upstream data transformation. Scala's higher-order functions are particularly suitable for implementing configurable data transformations.</p></div>
<div class="section" title="Monadic data transformation"><div class="titlepage" id="aid-4V8DU2"><div><div><h1 class="title"><a id="ch02lvl1sec2000"/>Monadic data transformation</h1></div></div></div><p>The <a id="id1810000" class="indexterm"/>first step is to define a trait and method that describe the transformation of data by the computation units of a workflow. The data transformation is the foundation of any workflow for processing and classifying a dataset, training and validating a model, and displaying results.</p><p>There are two symbolic models used for defining a data processing or data transformation:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Explicit model</strong></span>: The <a id="id1820000" class="indexterm"/>developer creates a model explicitly from a set of configuration parameters. Most of deterministic algorithms and unsupervised learning techniques use an explicit model.</li><li class="listitem"><span class="strong"><strong>Implicit model</strong></span>: The<a id="id1830000" class="indexterm"/> developer provides a training set that is a set of labeled observations (observations with an expected outcome). A classifier extracts a model through the training set. Supervised learning techniques rely on models implicitly generated from labeled data.</li></ul></div><div class="section" title="Error handling"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3600"/>Error handling</h2></div></div></div><p>The <a id="id1840000" class="indexterm"/>simplest form of data transformation is <a id="id1850000" class="indexterm"/><span class="strong"><strong>morphism</strong></span> between <a id="id1860000" class="indexterm"/>the two <code class="literal">U</code> and <code class="literal">V</code> types. The data transformation enforces a <span class="emphasis"><em>contract</em></span> for validating an input and returning either a value or an error. From now on, we use the following convention:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Input value</strong></span>: The <a id="id1870000" class="indexterm"/>validation is implemented through a partial function of the <code class="literal">PartialFunction</code> type that is returned by the data transformation. A <code class="literal">MatchErr</code> error is thrown in case the input value does not meet the required condition (contract).</li><li class="listitem"><span class="strong"><strong>Output value</strong></span>: The <a id="id1880000" class="indexterm"/>type of a return value is <code class="literal">Try[V]</code> for which an exception is returned in case of an error.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note3300"/>Note</h3><p>
<span class="strong"><strong>Reusability of partial functions</strong></span>
</p><p>Reusability is another benefit of partial functions, which is illustrated in the following code snippet:</p><div class="informalexample"><pre class="programlisting">class F { 
  def f: PartialFunction[Int, Try[Double]] { case n: Int … 
  }
}
val pfn = (new F).f
pfn(4)
pfn(10)</pre></div></div><p>Partial<a id="id1890000" class="indexterm"/> functions enable developers to implement methods that address the most common (primary) use cases for which input values have been tested. All other nontrivial use cases (or input values) generate a <code class="literal">MatchErr</code> exception. At a later stage in the development cycle, the developer can implement the code to handle the less common use cases.</p><div class="note" title="Note"><h3 class="title"><a id="note3400"/>Note</h3><p>
<span class="strong"><strong>Runtime validation of a partial function</strong></span>
</p><p>It is a good practice to validate if a partial function is defined for a specific value of the argument:</p><div class="informalexample"><pre class="programlisting">for {
  pfn.isDefinedAt(input)
  value &lt;- pfn(input)
} yield { … }</pre></div><p>This preemptive approach allows the developer to select an alternative method or a full function. It is an efficient alternative to catch a <code class="literal">MathErr</code> exception. The validation of a partial function is omitted throughout the book for the sake of clarity.</p></div><p>Therefore, the<a id="id1900000" class="indexterm"/> signature of a data transformation is defined as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]]</pre></div><div class="note" title="Note"><h3 class="title"><a id="note3600"/>Note</h3><p>
<span class="strong"><strong>F# language references</strong></span>
</p><p>The <code class="literal">|&gt;</code> notation used as the signature of the transform is borrowed from the F# language [2:2].</p></div></div><div class="section" title="Explicit models"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3700"/>Explicit models</h2></div></div></div><p>The <a id="id1910000" class="indexterm"/>objective is to define a symbolic representation of the transformation of different types of data without exposing the internal state of the algorithm implementing the data transformation. The transformation on a dataset is performed using a model or configuration that is fully defined by the user, which is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01256.jpeg" alt="Explicit models"/><div class="caption"><p>Visualization of explicit models</p></div></div><p style="clear:both; height: 1em;"> </p><p>The transformation of an explicit configuration or model, <code class="literal">config</code>, is defined as an <code class="literal">ETransform</code> abstract class parameterized by the <code class="literal">T</code> type of the model:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>ETransform</strong></span>[<span class="strong"><strong>T</strong></span>](val <span class="strong"><strong>config</strong></span>: T) { //explicit model
  type U   // type of input
  type V   // type of output
  def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]]  // data transformation
}</pre></div><p>The input <code class="literal">U</code> type and output <code class="literal">V</code> type have to be defined in the subclasses of <code class="literal">ETransform</code>. The <code class="literal">|&gt;</code> transform operator returns a partial function that can be reused for different input values.</p><p>The <a id="id1920000" class="indexterm"/>creation of a class that implements a specific transformation using an explicit configuration is quite simple: all you need is the definition of an input/output <code class="literal">U</code>/<code class="literal">V</code> type and an implementation of the <code class="literal">|&gt;</code> transformation method.</p><p>Let's consider the extraction of data from a financial source, <code class="literal">DataSource</code>, that takes a list of functions that convert some text fields, <code class="literal">Fields</code>, into a <code class="literal">Double</code> value as the input and produce a list of observations of the <code class="literal">XSeries[Double]</code> type. The extraction parameters are defined in the <code class="literal">DataSourceConfig</code> class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DataSource</strong></span>(
  config: <span class="strong"><strong>DataSourceConfig</strong></span>,   //<span class="strong"><strong>1</strong></span>
  srcFilter: Option[Fields =&gt; Boolean]= None)
        extends <span class="strong"><strong>ETransform</strong></span>[DataSourceConfig](config) { //<span class="strong"><strong>2</strong></span>
  type U = <span class="strong"><strong>List[Fields =&gt; Double]</strong></span>   //<span class="strong"><strong>3</strong></span>
  type V = <span class="strong"><strong>List[XSeries[Double]]</strong></span>     //<span class="strong"><strong>4</strong></span>
  override <span class="strong"><strong>def |&gt; : PartialFunction[U, Try[V]]</strong></span> = { //<span class="strong"><strong>5</strong></span>
    case u: U if(!u.isEmpty) =&gt; … 
  }
}</pre></div><p>The <code class="literal">DataSourceConfig</code> configuration is explicitly provided as an argument of the constructor for <code class="literal">DataSource</code> (line <code class="literal">1</code>). The constructor implements the basic type and data transformation associated with an explicit model (line <code class="literal">2</code>). The class defines the <code class="literal">U</code> type of input values (line <code class="literal">3</code>), <code class="literal">V</code> type of output values (line <code class="literal">4</code>), and <code class="literal">|&gt;</code> transformation method that returns a partial function (line <code class="literal">5</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note3700"/>Note</h3><p>
<span class="strong"><strong>The DataSource class</strong></span>
</p><p>The <span class="emphasis"><em>Data extraction</em></span> section of the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span> describes the <code class="literal">DataSource</code> class functionality. The <code class="literal">DataSource</code> class is used throughout the book.</p></div><p>Data transformations using an explicit model or configuration constitute a category with monadic operations. The monad associated with the <code class="literal">ETransform</code> class subclasses the definition of the higher kind, <code class="literal">_Monad</code>:</p><div class="informalexample"><pre class="programlisting">private val <span class="strong"><strong>eTransformMonad</strong></span> = new <span class="strong"><strong>_Monad</strong></span>[ETransform] {
  override def <span class="strong"><strong>unit</strong></span>[T](t:T) = eTransform(t)   //<span class="strong"><strong>6</strong></span>
  override def <span class="strong"><strong>map</strong></span>[T,U](m: ETransform[T])     //<span class="strong"><strong>7</strong></span>
      (f: T =&gt; U): ETransform[U] = eTransform( f(m.config) )
  override def <span class="strong"><strong>flatMap</strong></span>[T,U](m: ETransform[T])  //<span class="strong"><strong>8</strong></span>
      (f: T =&gt;ETransform[U]): ETransform[U] = f(m.config)
}</pre></div><p>The<a id="id1930000" class="indexterm"/> singleton <code class="literal">eTransformMonad</code> implements the following basic monadic operators introduced in the <span class="emphasis"><em>Monads</em></span> section under <span class="emphasis"><em>Abstraction</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">unit</code> method is used to instantiate <code class="literal">ETransform</code> (line <code class="literal">6</code>)</li><li class="listitem">The <code class="literal">map</code> is used to transform an <code class="literal">ETransform</code> object by morphing its elements (line <code class="literal">7</code>)</li><li class="listitem">The <code class="literal">flatMap</code> is used to transform an <code class="literal">ETransform</code> object by instantiating its elements (line <code class="literal">8</code>)</li></ul></div><p>For practical purposes, an implicit class is created to convert an <code class="literal">ETransform</code> object to its associated monad, allowing transparent access to the <code class="literal">unit</code>, <code class="literal">map</code>, and <code class="literal">flatMap</code> methods:</p><div class="informalexample"><pre class="programlisting">implicit class eTransform2Monad[T](fct: ETransform[T]) {
  def <span class="strong"><strong>unit</strong></span>(t: T) = eTransformMonad.unit(t)
  final def <span class="strong"><strong>map</strong></span>[U](f: T =&gt; U): ETransform[U] = 
      eTransformMonad.map(fct)(f)
  final def <span class="strong"><strong>flatMap</strong></span>[U](f: T =&gt; ETransform[U]): ETransform[U] =
      eTransformMonad.flatMap(fct)(f)
}</pre></div></div><div class="section" title="Implicit models"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3800"/>Implicit models</h2></div></div></div><p>Supervised <a id="id1940000" class="indexterm"/>learning models are extracted from a training set. Transformations, such as classification or regression use the implicit models to process the input data, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01257.jpeg" alt="Implicit models"/><div class="caption"><p>Visualization of implicit models</p></div></div><p style="clear:both; height: 1em;"> </p><p>The<a id="id1950000" class="indexterm"/> transformation for a model implicitly extracted from the training data is defined as an abstract <code class="literal">ITransform</code> class parameterized by the <code class="literal">T</code> type of observations, <code class="literal">xt</code>:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>ITransform</strong></span>[T](val <span class="strong"><strong>xt</strong></span>: Vector[T]) { //Model input
   type V   // type of output
   def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[T, Try[V]]  // data transformation
}</pre></div><p>The type of the data collection is <code class="literal">Vector</code>, which is an immutable and effective container. An <code class="literal">ITransform</code> type is created by defining the <code class="literal">T</code> type of the observation, the <code class="literal">V</code> output of the data transformation, and the <code class="literal">|&gt;</code> method that implements the transformation, usually a classification or regression. Let' s consider the support vector machine algorithm, <code class="literal">SVM</code>, to illustrate the implementation of a data transformation using an implicit model:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SVM</strong></span>[T &lt;: AnyVal]( //9  
    config: SVMConfig, 
    xt: Vector[<span class="strong"><strong>Array[T]</strong></span>], 
    expected: Vector[Double])(implicit f: T =&gt; Double)
  extends <span class="strong"><strong>ITransform</strong></span>[<span class="strong"><strong>Array[T]</strong></span>](xt) {//10

 type V = <span class="strong"><strong>Double</strong></span>  //11
 override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[<span class="strong"><strong>Array[T], Try[V]]</strong></span> = { //12
     case x: <span class="strong"><strong>Array[T]</strong></span> if(x.length == data.size) =&gt; ...
  }</pre></div><p>The support vector machine is a discriminative supervised learning algorithm described in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>. A support vector machine, <code class="literal">SVM</code>, is instantiated with a configuration and training set: the <code class="literal">xt</code> observations and <code class="literal">expected</code> data (line <code class="literal">9</code>). Contrary to the explicit model, the <code class="literal">config</code> configuration does not define the model used in the data transformation; the model is implicitly generated from the training set of the <code class="literal">xt</code> input data and <code class="literal">expected</code> values. An <code class="literal">SVM</code> instance is created as an <code class="literal">ITransform</code> (line <code class="literal">10</code>) by specifying the <code class="literal">V</code> output type (line <code class="literal">11</code>) and overriding the <code class="literal">|&gt;</code> transformation method (line <code class="literal">12</code>).</p><p>The <code class="literal">|&gt;</code> classification method produces a partial function that takes an <code class="literal">x</code> observation as an input and returns the prediction value of a <code class="literal">Double</code> type.</p><p>Similar <a id="id1960000" class="indexterm"/>to the explicit transformation, we define the monadic operation for the <code class="literal">ITransform</code> by overriding the <code class="literal">unit</code> (line <code class="literal">13</code>), <code class="literal">map</code> (line <code class="literal">14</code>), and <code class="literal">flatMap</code> (line <code class="literal">15</code>) methods:</p><div class="informalexample"><pre class="programlisting">private val iTransformMonad = new _Monad[<span class="strong"><strong>ITransform</strong></span>] {
  override def <span class="strong"><strong>unit</strong></span>[T](t: T) = iTransform(Vector[T](t))  //<span class="strong"><strong>13</strong></span>
  
  override def <span class="strong"><strong>map</strong></span>[T,U](m: ITransform[T])(f: T =&gt; U): 
ITransform[U] = iTransform( m.xt.map(f) )   //<span class="strong"><strong>14</strong></span>
  
  override def <span class="strong"><strong>flatMap</strong></span>[T,U](m: ITransform[T])  
    (f: T=&gt;ITransform[U]): ITransform[U] = 
 iTransform(m.xt.flatMap(t =&gt; f(t).xt)) //<span class="strong"><strong>15</strong></span>
}</pre></div><p>Finally, let's create an implicit class to automatically convert an <code class="literal">ITransform</code> object into its associated monad so that it can access the <code class="literal">unit</code>, <code class="literal">map</code>, and <code class="literal">flatMap</code> monad methods transparently:</p><div class="informalexample"><pre class="programlisting">implicit class iTransform2Monad[T](fct: <span class="strong"><strong>ITransform</strong></span>[T]) {
   def <span class="strong"><strong>unit</strong></span>(t: T) = iTransformMonad.unit(t)
   
   final def <span class="strong"><strong>map</strong></span>[U](f: T =&gt; U): ITransform[U] = 
      iTransformMonad.map(fct)(f)
   final def <span class="strong"><strong>flatMap</strong></span>[U](f: T =&gt; ITransform[U]): ITransform[U] = 
      iTransformMonad.flatMap(fct)(f)
   def <span class="strong"><strong>filter</strong></span>(p: T =&gt;Boolean): ITransform[T] =  //<span class="strong"><strong>16</strong></span>
      iTransform(fct.xt.filter(p))
}</pre></div><p>The <code class="literal">filter</code> method is strictly not an operator of the monad (line <code class="literal">16</code>). However, it is commonly included to constrain (or guard) a sequence of transformation (for example, for comprehension closure). As stated in the <span class="emphasis"><em>Presentation</em></span> section under <span class="emphasis"><em>Source code</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, code related to exceptions, error checking, and validation of arguments is omitted.</p><div class="note" title="Note"><h3 class="title"><a id="note3800"/>Note</h3><p>
<span class="strong"><strong>Immutable transformations</strong></span>
</p><p>The model for a data transformation (or a processing unit or classifier) class should be immutable. Any modification will alter the integrity of the model or parameters used to process data. In order to ensure that the same model is used in processing the input data for the entire lifetime of a transformation, we do the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A model for an <code class="literal">ETransform</code> is defined as an argument of its constructor.</li><li class="listitem">The constructor of an <code class="literal">ITransform</code> generates the model from a given training set. The model has to be rebuilt from the training set (not altered), if it provides an incorrect outcome or prediction.</li></ul></div><p>Models are created by the constructor of classifiers or data transformation classes to ensure their immutability. The design of an immutable transformation is described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section under <span class="emphasis"><em>Scala programming</em></span> of the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p></div></div></div>
<div class="section" title="A workflow computational model"><div class="titlepage" id="aid-506UG2"><div><div><h1 class="title"><a id="ch02lvl1sec2100"/>A workflow computational model</h1></div></div></div><p>Monads<a id="id1970000" class="indexterm"/> are very useful for manipulating and chaining data transformations using implicit configurations or explicit models. However, they are restricted to a single morphism <code class="literal">T =&gt; U</code> type. More complex and flexible workflows require weaving transformations of different types using a generic factory pattern.</p><p>Traditional factory patterns rely on a combination of composition and inheritance and do not provide developers with the same level of flexibility as stackable traits.</p><p>In this section, we introduce you to the concept of modeling using mixins and a variant of the cake pattern to provide a workflow with three degrees of configurability.</p><div class="section" title="Supporting mathematical abstractions"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec3900"/>Supporting mathematical abstractions</h2></div></div></div><p>Stackable traits <a id="id1980000" class="indexterm"/>enable developers to follow a strict mathematical formalism while implementing <a id="id1990000" class="indexterm"/>a model in Scala. Scientists use a universally accepted template to solve a mathematical problem:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Declare the variables relevant to the problem.</li><li class="listitem">Define a model (equations, algorithms, formulas, and so on) as the solution to the problem.</li><li class="listitem">Instantiate the variables and execute the model to solve the problem.</li></ol><div style="height:10px; width: 1px"/></div><p>Let's <a id="id2000000" class="indexterm"/>consider<a id="id2010000" class="indexterm"/> the example of the concept of kernel functions (described in the <span class="emphasis"><em>Kernel functions</em></span> section in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>), a model that consists of a composition of two mathematical functions and its potential implementation in Scala.</p><div class="section" title="Step 1 – variable declaration"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2300"/>Step 1 – variable declaration</h3></div></div></div><p>The<a id="id2020000" class="indexterm"/> implementation consists of wrapping (scope) the two functions into traits and defining these functions as abstract values.</p><p>The mathematical formalism is as follows:</p><div class="mediaobject"><img src="../Images/image01258.jpeg" alt="Step 1 – variable declaration"/></div><p style="clear:both; height: 1em;"> </p><p>The Scala implementation is as follows:</p><div class="informalexample"><pre class="programlisting">type V = Vector[Double]
trait <span class="strong"><strong>F</strong></span> { val <span class="strong"><strong>f</strong></span>: V =&gt; V}
trait <span class="strong"><strong>G</strong></span> { val <span class="strong"><strong>g</strong></span>: V =&gt; Double }</pre></div></div><div class="section" title="Step 2 – model definition"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2400"/>Step 2 – model definition</h3></div></div></div><p>The <a id="id2030000" class="indexterm"/>model is defined as the composition of the two functions. The <code class="literal">G</code> and <code class="literal">F</code> stack of traits describe the type of compatible functions that can be composed using the self-referenced <code class="literal">self: G with F</code> constraint.</p><p>The formalism will be <span class="emphasis"><em>h = f o g</em></span>.</p><p>The Scala implementation is as follows:</p><div class="informalexample"><pre class="programlisting">class H {self: <span class="strong"><strong>G</strong></span> with <span class="strong"><strong>F</strong></span> =&gt; def apply(v:V): Double =<span class="strong"><strong>g</strong></span>(<span class="strong"><strong>f</strong></span>(v))}</pre></div></div><div class="section" title="Step 3 – instantiation"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2500"/>Step 3 – instantiation</h3></div></div></div><p>The<a id="id2040000" class="indexterm"/> model is executed once the <code class="literal">f</code> and <code class="literal">g</code> variables are instantiated.</p><p>The formalism will be as follows:</p><div class="mediaobject"><img src="../Images/image01259.jpeg" alt="Step 3 – instantiation"/></div><p style="clear:both; height: 1em;"> </p><p>The Scala implementation is as follows:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>h</strong></span> = new <span class="strong"><strong>H</strong></span> with <span class="strong"><strong>G</strong></span> with <span class="strong"><strong>F</strong></span> {
  val <span class="strong"><strong>f</strong></span>: V =&gt; V = (v: V) =&gt; v.map(Math.exp(_))
  val <span class="strong"><strong>g</strong></span>: V =&gt; Double = (v: V) =&gt; v.sum
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note4000"/>Note</h3><p>
<span class="strong"><strong>Lazy value triggers</strong></span>
</p><p>In the preceding example, the value of <span class="emphasis"><em>h(v) = g(f(v))</em></span> can be automatically computed as soon as <span class="emphasis"><em>g</em></span> and <span class="emphasis"><em>f</em></span> are initialized, by declaring <span class="emphasis"><em>h</em></span> a lazy value.</p></div><p>Clearly, Scala preserves the formalism of mathematical models, making it easier for scientists and developers to migrate their existing projects written in scientific-oriented languages, such as R.</p><div class="note" title="Note"><h3 class="title"><a id="note4100"/>Note</h3><p>
<span class="strong"><strong>Emulation of R</strong></span>
</p><p>Most data scientists use the R language to create models and apply learning strategies. They may consider Scala as an alternative to R in some cases, as Scala preserves the mathematical formalism used in models implemented in R.</p></div><p>Let's extend the concept preservation of mathematical formalism to the dynamic creation of workflows using traits. The design pattern described in the next section is sometimes referred to as the <a id="id2050000" class="indexterm"/><span class="strong"><strong>Cake pattern</strong></span>.</p></div></div><div class="section" title="Composing mixins to build a workflow"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4000"/>Composing mixins to build a workflow</h2></div></div></div><p>This section <a id="id2060000" class="indexterm"/>presents the key constructs behind the Cake pattern. A workflow composed of configurable data transformations requires a dynamic modularization (substitution) of the different stages of the workflow.</p><div class="note" title="Note"><h3 class="title"><a id="note4200"/>Note</h3><p>
<span class="strong"><strong>Traits and mixins</strong></span>
</p><p>Mixins <a id="id2070000" class="indexterm"/>are traits that are stacked against a class. The composition of mixins and the Cake pattern described in this section are important for defining the sequences of data transformations. However, the topic is not directly related to machine learning and so you can skip this section.</p></div><p>The Cake pattern<a id="id2080000" class="indexterm"/> is an advanced class composition pattern that uses mixin traits to meet the demands of a configurable computation workflow. It is also known as stackable modification traits [2:4].</p><p>This is not an in-depth analysis of the <span class="strong"><strong>stackable trait injection</strong></span>
<a id="id2090000" class="indexterm"/> and <span class="strong"><strong>self-reference</strong></span> in Scala. There are few interesting articles on dependencies injection that are worth a look [2:5].</p><p>Java relies on packages tightly coupled with the directory structure and prefixed to modularize the code base. Scala provides developers with a flexible and reusable approach to create and organize modules: traits. Traits can be nested, mixed with classes, stacked, and inherited.</p><div class="section" title="Understanding the problem"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2600"/>Understanding the problem</h3></div></div></div><p>Dependency<a id="id2100000" class="indexterm"/> injection is a fancy name for a reverse look-up and binding to dependencies. Let's consider a simple application that requires data preprocessing, classification, and validation. A simple implementation using traits looks like this:</p><div class="informalexample"><pre class="programlisting">val app = new Classification with Validation with PreProcessing { 
   val filter = .. 
}</pre></div><p>If, at a later stage, you need to use an unsupervised clustering algorithm instead of a classifier, then the application has to be rewired:</p><div class="informalexample"><pre class="programlisting">val app = new Clustering with Validation with PreProcessing { 
    val filter = ..  
}</pre></div><p>This approach results in code duplication and lack of flexibility. Moreover, the <code class="literal">filter</code> class member <a id="id2110000" class="indexterm"/>needs to be redefined for each new class in the composition of the application. The problem arises when there is a dependency between traits used in the composition. Let's consider the case for which the <span class="emphasis"><em>filter</em></span> depends on the <span class="emphasis"><em>validation</em></span> methodology.</p><div class="note" title="Note"><h3 class="title"><a id="note4300"/>Note</h3><p>
<span class="strong"><strong>Mixins linearization</strong></span> [2:6]</p><p>The linearization or invocation of methods between mixins follows a right-to-left and base-to-subtype pattern:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Trait <span class="emphasis"><em>B</em></span> extends <span class="emphasis"><em>A</em></span></li><li class="listitem">Trait <span class="emphasis"><em>C</em></span> extends <span class="emphasis"><em>A</em></span></li><li class="listitem">Class <span class="emphasis"><em>M</em></span> extends <span class="emphasis"><em>N</em></span> with <span class="emphasis"><em>C</em></span> with <span class="emphasis"><em>B</em></span></li></ul></div><p>The Scala compiler implements the linearization as <span class="emphasis"><em>A =&gt; B =&gt; C =&gt; N</em></span>.</p></div><p>Although you can define <code class="literal">filter</code> as an abstract value, it still has to be redefined each time a new validation type is introduced. The solution is to use the <code class="literal">self</code> type in the definition of the newly composed <code class="literal">PreProcessingWithValidation</code> trait:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>PreProcessiongWithValidation</strong></span> extends PreProcessing {
   <span class="strong"><strong>self</strong></span>: Validation =&gt; val filter = ..
}</pre></div><p>The application is built by stacking the <code class="literal">PreProcessingWithValidation</code> mixin against the <code class="literal">Classification</code> class:</p><div class="informalexample"><pre class="programlisting">val app = new <span class="strong"><strong>Classification</strong></span> with <span class="strong"><strong>PreProcessingWithValidation</strong></span> {
   val validation: Validation
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note4500"/>Note</h3><p>
<span class="strong"><strong>Overriding def with val</strong></span>
</p><p>It is advantageous to override the declaration of a method with a declaration of a value with the same signature. Contrary to a value that is assigned once for all during instantiation, a method may return a different value for each invocation. A <span class="strong"><strong>def</strong></span>
<a id="id2120000" class="indexterm"/> is a <span class="strong"><strong>proc</strong></span> that can be redefined as a <span class="strong"><strong>def</strong></span>, <span class="strong"><strong>val</strong></span>, or <span class="strong"><strong>lazy val</strong></span>. Therefore, you should not override a value declaration with a method with the same signature:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>trait Validator { val g = (n: Int) =&gt;  }trait MyValidator extends Validator { def g(n: Int) = …} //WRONG </strong></span>
</pre></div></div><p>Let's adapt <a id="id2130000" class="indexterm"/>and generalize this pattern to construct a boilerplate template in order to create dynamic computational workflows.</p></div><div class="section" title="Defining modules"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2700"/>Defining modules</h3></div></div></div><p>The first step is <a id="id2140000" class="indexterm"/>to generate different modules to encapsulate different types of data transformation.</p><div class="note" title="Note"><h3 class="title"><a id="note4600"/>Note</h3><p>
<span class="strong"><strong>Use case for describing the cake pattern</strong></span>
</p><p>It is difficult to build an example of a real-world workflow using classes and algorithms introduced later in the book. The following simple example is realistic enough to illustrate the different components of the Cake pattern.</p></div><p>Let's define a sequence of the three parameterized modules that each define a specific data transformation using the explicit configuration of the <code class="literal">Etransform</code> type:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Sampling</code>: This is used to extract a sample from raw data</li><li class="listitem"><code class="literal">Normalization</code>: This is used to normalize the sampled data over [0, 1]</li><li class="listitem"><code class="literal">Aggregation</code>: This is used to aggregate or reduce the data</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Sampling</strong></span>[T,A,B] { 
  val sampler: ETransform[T] { type U = A; type V = B }
}
trait <span class="strong"><strong>Normalization</strong></span>[T,A,B] { 
  val normalizer: ETransform[T] { type U = A; type V = B }
  }
trait <span class="strong"><strong>Aggregation</strong></span>[T,A,B] { 
  val aggregator: ETransform[T] { type U = A; type V = B }
}</pre></div><p>The modules contain a single abstract value. One characteristic of the Cake pattern is to enforce strict modularity by initializing the abstract values with the type encapsulated in the module. One<a id="id2150000" class="indexterm"/> of the objectives in building the framework is allowing developers to create data transformation (inherited from <code class="literal">ETransform</code>) independently from any workflow.</p><div class="note" title="Note"><h3 class="title"><a id="note4700"/>Note</h3><p>
<span class="strong"><strong>Scala traits and Java packages</strong></span>
</p><p>There is a major difference between Scala and Java in terms of modularity. Java packages constrain developers into following a strict syntax that requires, for instance, the source file to have the same name as the class it contains. Scala modules based on stackable traits are far more flexible.</p></div></div><div class="section" title="Instantiating the workflow"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2800"/>Instantiating the workflow</h3></div></div></div><p>The <a id="id2160000" class="indexterm"/>next step is to <span class="emphasis"><em>write</em></span> the different modules into a workflow. This is achieved by using the <code class="literal">self</code> reference to the stack of the three traits defined in the previous section:</p><div class="informalexample"><pre class="programlisting">class Workflow[T,U,V,W,Z] {
  self: <span class="strong"><strong>Sampling</strong></span>[T,U,V] with 
         <span class="strong"><strong>Normalization</strong></span>[T,V,W] with 
           <span class="strong"><strong>Aggregation</strong></span>[T,W,Z] =&gt;
    def |&gt; (u: U): Try[Z] = for {
      v &lt;- sampler |&gt; u
      w &lt;- normalizer |&gt; v
      z &lt;- aggregator |&gt; w
    } yield z
}</pre></div><p>A picture is worth a thousand words; the following UML class diagram illustrates the workflow factory (or Cake) design pattern:</p><div class="mediaobject"><img src="../Images/image01260.jpeg" alt="Instantiating the workflow"/><div class="caption"><p>The UML class diagram of the workflow factory</p></div></div><p style="clear:both; height: 1em;"> </p><p>Finally, the <a id="id2170000" class="indexterm"/>workflow is instantiated by dynamically initializing the <code class="literal">sampler</code>, <code class="literal">normalizer</code>, and <code class="literal">aggregator</code> abstract values of the transformation as long as the signature (input and output types) matches the parameterized types defined in each module (line <code class="literal">1</code>):</p><div class="informalexample"><pre class="programlisting">type Dbl_F = Function1[Double, Double]
val samples = 100; val normRatio = 10; val splits = 4

val workflow = new Workflow[Int, Dbl_F, DblVector, DblVector,Int] 
      with Sampling[Int, Dbl_F, DblVector] 
         with Normalization[Int, DblVector, DblVector] 
            with Aggregation[Int, DblVector, Int] {
    val <span class="strong"><strong>sampler</strong></span> = new ETransform[Int](samples) { /* .. */} //<span class="strong"><strong>1</strong></span>
    val <span class="strong"><strong>normalizer</strong></span> = new ETransform[Int](normRatio) { /*  .. */}
    val <span class="strong"><strong>aggregator</strong></span> = new ETransform[Int](splits) {/*  .. */}
}</pre></div><p>Let's implement the data transformation function for each of the three modules/traits by assigning a transformation to the abstract values.</p><p>The first transformation, <code class="literal">sampler</code>, samples a <code class="literal">f</code> function with frequency as <span class="emphasis"><em>1/samples</em></span> over the interval [0, 1]. The second transformation, <code class="literal">normalizer</code>, normalizes the data over the range [0, 1] using the <code class="literal">Stats</code> class introduced in the next chapter. The last transformation, <code class="literal">aggregator</code>, extracts the index of the large sample (value 1.0):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>sampler</strong></span> = new ETransform[Int](<span class="strong"><strong>samples</strong></span>) { //<span class="strong"><strong>2</strong></span>
  type U = Dbl_F  //<span class="strong"><strong>3</strong></span>
  type V = DblVector  //<span class="strong"><strong>4</strong></span>
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = { 
    case f: U =&gt; 
     Try(Vector.tabulate(samples)(n =&gt;f(1.0*n/samples))) //<span class="strong"><strong>5</strong></span>
  }
}</pre></div><p>The <code class="literal">sampler</code> transformation<a id="id2180000" class="indexterm"/> uses a single model or configuration parameter, <code class="literal">sample</code>, (line <code class="literal">2</code>). The <code class="literal">U</code> type of an input is defined as <code class="literal">Double =&gt; Double</code> (line <code class="literal">3</code>) and the <code class="literal">V</code> type of an output is defined as a vector of floating point values, <code class="literal">DblVector</code> (line <code class="literal">4</code>). In this particular case, the transformation consists of applying the input <code class="literal">f</code> function to a vector of increasing normalized values (line <code class="literal">5</code>).</p><p>The <code class="literal">normalizer</code> and <code class="literal">aggregator</code> transforms follow the same design pattern as <code class="literal">sampler</code>:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>normalizer</strong></span> = new ETransform[Int](normRatio) {
  type U = DblVector;  type V = DblVector
  override def |&gt; : PartialFunction[U, Try[V]] = { case x: U 
    if(x.size &gt;0) =&gt; Try((<span class="strong"><strong>Stats</strong></span>[Double](x)).normalize)
  }
}
val <span class="strong"><strong>aggregator</strong></span> = new ETransform[Int](splits) {
  type U = DblVector; type V = Int
  override def |&gt; : PartialFunction[U, Try[V]] = case x: U 
    if(x.size &gt; 0) =&gt; Try(Range(0,x.size).find(x(_)==1.0).get)
  }
}</pre></div><p>The instantiation of the transformation function follows the template described in the <span class="emphasis"><em>Explicit models</em></span> section in this chapter.</p><p>The workflow is now ready to process any function as an input:</p><div class="informalexample"><pre class="programlisting">val g = (x: Double) =&gt; Math.log(x+1.0) + Random.nextDouble
Try( workflow |&gt; g )  //<span class="strong"><strong>6</strong></span>
</pre></div><p>The workflow is executed by providing the input <code class="literal">g</code> function to the first <code class="literal">sampler</code> mixin (line <code class="literal">6</code>).</p><p>Scala's strong type checking catches any inconsistent data types at compilation time. It reduces the development cycle because runtime errors are more difficult to track down.</p><div class="note" title="Note"><h3 class="title"><a id="note4800"/>Note</h3><p>
<span class="strong"><strong>Mixins composition for ITransform</strong></span>
</p><p>We arbitrary selected a data transformation using an explicit <code class="literal">ETransform</code> configuration to illustrate the concept of mixins composition. The same pattern applies to the implicit <code class="literal">ITransform</code> data transformation.</p></div></div></div><div class="section" title="Modularization"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4100"/>Modularization</h2></div></div></div><p>The last step<a id="id2190000" class="indexterm"/> is the modularization of the workflow. For complex scientific computations, you need to be able to do the following:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select the appropriate <span class="emphasis"><em>workflow</em></span> as a sequence of modules or tasks according to the objective of the execution (regression, classification, clustering, and so on).</li><li class="listitem">Select the appropriate <span class="emphasis"><em>algorithm</em></span> to fulfill a task according to the data (noisy data, an incomplete training set, and so on).</li><li class="listitem">Select the appropriate <span class="emphasis"><em>implementation</em></span> of the algorithm according to the environment (distributed with a high-latency network, single host, and so on).<div class="mediaobject"><img src="../Images/image01261.jpeg" alt="Modularization"/><div class="caption"><p>An Illustration of the dynamic creation of a workflow from modules/traits</p></div></div><p style="clear:both; height: 1em;"> </p></li></ol><div style="height:10px; width: 1px"/></div><p>Let's consider a simple preprocessing task defined in the <code class="literal">PreprocessingModule</code> module. The <a id="id2200000" class="indexterm"/>module (or task) is declared as a trait to hide its internal workings from other modules. The preprocessing task is executed by a preprocessor of a <code class="literal">Preprocessor</code> type. We arbitrary list two algorithms: the exponential moving average of the <code class="literal">ExpMovingAverage</code> type and the discrete Fourier transform low pass filter of the <code class="literal">DFTFilter</code> type as a potential preprocessor:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>PreprocessingModule</strong></span>[T] {
  trait <span class="strong"><strong>Preprocessor</strong></span>[T] { //<span class="strong"><strong>7</strong></span>
    def <span class="strong"><strong>execute</strong></span>(x: Vector[T]): Try[DblVector] 
  } 
  val preprocessor: Preprocessor[T]//<span class="strong"><strong>8</strong></span>

  class <span class="strong"><strong>ExpMovingAverage</strong></span>[T &lt;: AnyVal]( //<span class="strong"><strong>9</strong></span>
      p: Int)
      (implicit num: Numeric[T], f: T =&gt;Double) 
    extends Preprocessor[T] {
  
    val expMovingAvg = <span class="strong"><strong>filtering.ExpMovingAverage</strong></span>[T](p) //<span class="strong"><strong>10</strong></span>
    val <span class="strong"><strong>pfn</strong></span> = expMovingAvg |&gt;  //<span class="strong"><strong>11</strong></span>
    override def <span class="strong"><strong>execute</strong></span>(x: Vector[T]): Try[DblVector] = 
      pfn(x).map(_.toVector)
  }

   class <span class="strong"><strong>DFTFilter</strong></span>[T &lt;: AnyVal]( 
      fc: Double)
    (g: (Double,Double) =&gt;Double) 
     (implicit f : T =&gt; Double)
   extends Preprocessor[T] { //<span class="strong"><strong>12</strong></span>

     val filter = <span class="strong"><strong>filtering.DFTFir</strong></span>[T](g, fc, 1e-5)
     val <span class="strong"><strong>pfn</strong></span> = filter |&gt;
     override def <span class="strong"><strong>execute</strong></span>(x: Vector[T]): Try[DblVector]=
        pfn(x).map(_.toVector)
   }
}</pre></div><p>The generic preprocessor trait, <code class="literal">Preprocessor</code>, declares a single <code class="literal">execute</code> method whose purpose is to filter an <code class="literal">x</code> input vector of an element of a <code class="literal">T</code> type for noise (line <code class="literal">7</code>). The instance of the preprocessor is declared as an abstract class to be instantiated as one of the filtering algorithms (line <code class="literal">8</code>).</p><p>The first <a id="id2210000" class="indexterm"/>filtering algorithm of an <code class="literal">ExpMovingAverage</code> type implements the <code class="literal">Preprocessor</code> trait and overrides the <code class="literal">execute</code> method (line <code class="literal">9</code>). The class declares the algorithm but delegates its implementation to a class with an identical <code class="literal">org.scalaml.filtering.ExpMovingAverage</code> signature (line <code class="literal">10</code>). The partial function returned from the <code class="literal">|&gt;</code> method is instantiated as a <code class="literal">pfn</code> value, so it can be applied multiple times (line <code class="literal">11</code>). The same design pattern is used for the discrete Fourier transform filter (line <code class="literal">12</code>).</p><p>The filtering algorithm (<code class="literal">ExpMovingAverage</code> or <code class="literal">DFTFir</code>) is selected according to the profile or characteristic of the input data. Its implementation in the <code class="literal">org.scalaml.filtering</code> package depends on the environment (a single host, cluster, Apache spark, and so on).</p><div class="note" title="Note"><h3 class="title"><a id="note4900"/>Note</h3><p>
<span class="strong"><strong>Filtering algorithms</strong></span>
</p><p>The filtering algorithms used to illustrate the concept of modularization in the context of the Cake pattern are described in detail in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</p></div></div></div>
<div class="section" title="Profiling data" id="aid-515F21"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec2200"/>Profiling data</h1></div></div></div><p>The<a id="id2220000" class="indexterm"/> selection of a preprocessing, clustering, or classification algorithm depends highly on the quality and profile of the input data (observations and expected values whenever available). The <span class="emphasis"><em>Step 3 – preprocessing the data</em></span> section under <span class="emphasis"><em>Let's kick the tires</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, introduced the <code class="literal">MinMax</code> class for normalizing a dataset using the minimum and maximum values.</p><div class="section" title="Immutable statistics"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4200"/>Immutable statistics</h2></div></div></div><p>The mean<a id="id2230000" class="indexterm"/> and standard deviation are the most commonly used statistics.</p><div class="note" title="Note"><h3 class="title"><a id="note5000"/>Note</h3><p>
<span class="strong"><strong>Mean and variance</strong></span>
</p><p>Arithmetic mean is defined as:</p><div class="mediaobject"><img src="../Images/image01262.jpeg" alt="Immutable statistics"/></div><p style="clear:both; height: 1em;"> </p><p>Variance is defined as:</p><div class="mediaobject"><img src="../Images/image01263.jpeg" alt="Immutable statistics"/></div><p style="clear:both; height: 1em;"> </p><p>Variance adjusted for a sampling bias is defined as:</p><div class="mediaobject"><img src="../Images/image01264.jpeg" alt="Immutable statistics"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's <a id="id2240000" class="indexterm"/>extend the <code class="literal">MinMax</code> class with some basic statistics capabilities using <code class="literal">Stats</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Stats</strong></span>[T &lt; : AnyVal](
     <span class="strong"><strong>values</strong></span>: Vector[T])(implicit f ; T =&gt; Double)
  extends <span class="strong"><strong>MinMax</strong></span>[T](values) {

  val zero = (0.0. 0.0)
  val sums = <span class="strong"><strong>values</strong></span>./:(zero)((s,x) =&gt;(s._1 +x, s._2 + x*x)) //<span class="strong"><strong>1</strong></span>
  
  lazy val <span class="strong"><strong>mean</strong></span> = sums._1/values.size  //<span class="strong"><strong>2</strong></span>
  lazy val <span class="strong"><strong>variance</strong></span> = 
         (sums._2 - mean*mean*values.size)/(values.size-1)
  lazy val stdDev = Math.sqrt(variance)
  …
}</pre></div><p>The <code class="literal">Stats</code> class <a id="id2250000" class="indexterm"/>implements <span class="strong"><strong>immutable statistics</strong></span>. Its constructor computes the sum of <code class="literal">values</code> and sum of square values, <code class="literal">sums</code> (line <code class="literal">1</code>). The statistics such as <code class="literal">mean</code> and <code class="literal">variance</code> are computed once when needed by declaring these values as lazy (line <code class="literal">2</code>). The <code class="literal">Stats</code> class inherits the normalization functions of <code class="literal">MinMax</code>.</p></div><div class="section" title="Z-Score and Gauss"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4300"/>Z-Score and Gauss</h2></div></div></div><p>The <a id="id2260000" class="indexterm"/>Gaussian distribution of the input data is implemented by the <code class="literal">gauss</code> method of the <code class="literal">Stats</code> class.</p><div class="note" title="Note"><h3 class="title"><a id="note5300"/>Note</h3><p>
<span class="strong"><strong>The Gaussian distribution</strong></span>
</p><p>M1: Gaussian for a mean μ and a standard deviation σ transformation is defined as:</p><div class="mediaobject"><img src="../Images/image01265.jpeg" alt="Z-Score and Gauss"/></div><p style="clear:both; height: 1em;"> </p></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>gauss</strong></span>(mu: Double, sigma: Double, x: Double): Double = {
   val y = (x - mu)/sigma
   INV_SQRT_2PI*Math.exp(-0.5*y*y)/sigma
}
val <span class="strong"><strong>normal</strong></span> = gauss(1.0, 0.0, _: Double)</pre></div><p>The computation of the normal distribution is computed as a partially applied function. The Z-score is computed as a normalization of the raw data taking into account the standard deviation.</p><div class="note" title="Note"><h3 class="title"><a id="note5400"/>Note</h3><p>
<span class="strong"><strong>Z-score normalization</strong></span>
</p><p>M2: Z-score for a mean μ and a standard deviation σ is defined as:</p><div class="mediaobject"><img src="../Images/image01266.jpeg" alt="Z-Score and Gauss"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id2270000" class="indexterm"/>computation of the Z-score is implemented by the <code class="literal">zScore</code> method of <code class="literal">Stats</code>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>zScore</strong></span>: DblVector = values.map(x =&gt; (x - mean)/stdDev )</pre></div><p>The following graph illustrates the relative behavior of the <code class="literal">zScore</code> normalization and normal transformation:</p><div class="mediaobject"><img src="../Images/image01267.jpeg" alt="Z-Score and Gauss"/><div class="caption"><p>A comparative analysis of linear, Gaussian, and Z-score normalization</p></div></div><p style="clear:both; height: 1em;"> </p></div></div>
<div class="section" title="Assessing a model"><div class="titlepage" id="aid-523VK2"><div><div><h1 class="title"><a id="ch02lvl1sec2300"/>Assessing a model</h1></div></div></div><p>Evaluating a<a id="id2280000" class="indexterm"/> model is an essential part of the workflow. There is no point in creating the most sophisticated model if you do not have the tools to assess its quality. The validation process consists of defining some quantitative reliability criteria, setting a strategy such as a <a id="id2290000" class="indexterm"/><span class="strong"><strong>K-fold cross-validation</strong></span> scheme, and selecting the appropriate labeled data.</p><div class="section" title="Validation"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4400"/>Validation</h2></div></div></div><p>The<a id="id2300000" class="indexterm"/> purpose<a id="id2310000" class="indexterm"/> of this section is to create a reusable Scala class to validate models. For starters, the validation process relies on a set of metrics to quantify the fitness of a model generated through training.</p><div class="section" title="Key quality metrics"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec2900"/>Key quality metrics</h3></div></div></div><p>Let's consider<a id="id2320000" class="indexterm"/> a simple classification model with<a id="id2330000" class="indexterm"/> two classes defined as positive (with respect to negative) represented with Black (with respect to White) color in the following diagram. Data scientists use the following terminologies:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>True positives</strong></span> (<span class="strong"><strong>TP</strong></span>): These <a id="id2340000" class="indexterm"/>are observations that are correctly labeled as those that belong to the positive class (white dots on a dark background)</li><li class="listitem"><span class="strong"><strong>True negatives</strong></span> (<span class="strong"><strong>TN</strong></span>): These<a id="id2350000" class="indexterm"/> are observations that are correctly labeled as those that belong to the negative class (black dots on a light background)</li><li class="listitem"><span class="strong"><strong>False positives</strong></span> (<span class="strong"><strong>FP</strong></span>): These <a id="id2360000" class="indexterm"/>are observations incorrectly labeled as those that belong to the positive class (white dots on a dark background)</li><li class="listitem"><span class="strong"><strong>False negatives</strong></span> (<span class="strong"><strong>FN</strong></span>): These <a id="id2370000" class="indexterm"/>are observations incorrectly labeled as those that belong to the negative class (dark dots on a light background)<div class="mediaobject"><img src="../Images/image01268.jpeg" alt="Key quality metrics"/><div class="caption"><p>Categorization of validation results</p></div></div><p style="clear:both; height: 1em;"> </p></li></ul></div><p>This<a id="id2380000" class="indexterm"/> simplistic representation can be extended to classification problems that involve more than two classes. For instance, false positives are defined as observations incorrectly labeled that belong to any class other than the correct one. These four factors are used for evaluating accuracy, precision, recall, and F and G measures, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Accuracy</strong></span>: This is <a id="id2390000" class="indexterm"/>the percentage of observations correctly classified and is represented as <span class="emphasis"><em>ac</em></span>.</li><li class="listitem"><span class="strong"><strong>Precision</strong></span>: This <a id="id2400000" class="indexterm"/>is the percentage of observations correctly classified as positive in the group that the classifier has declared positive. It is represented as <span class="emphasis"><em>p</em></span>.</li><li class="listitem"><span class="strong"><strong>Recall</strong></span>: This is <a id="id2410000" class="indexterm"/>the percentage of observations labeled as positive that are correctly classified and is represented as <span class="emphasis"><em>r</em></span>.</li><li class="listitem"><span class="strong"><strong>F<sub>1</sub>-measure or F<sub>1</sub></strong></span><span class="strong"><strong>-score</strong></span>: This measure strikes a balance between precision and recall. It <a id="id2420000" class="indexterm"/>is computed as the harmonic mean of the precision and recall with values ranging between 0 (worst score) and 1 (best score). It is represented as <span class="emphasis"><em>F<sub>1</sub></em></span>.</li><li class="listitem"><span class="strong"><strong>F<sub>n</sub> score</strong></span>: This is the generic F scoring method with an arbitrary <span class="emphasis"><em>n</em></span> degree. It is represented as <span class="emphasis"><em>F<sub>n</sub></em></span>.</li><li class="listitem"><span class="strong"><strong>G measure</strong></span>: This <a id="id2430000" class="indexterm"/>is similar to the F-measure but is computed as the geometric mean of precision <span class="emphasis"><em>p</em></span> and recall <span class="emphasis"><em>r</em></span>. It is represented as <span class="emphasis"><em>G</em></span>.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note5500"/>Note</h3><p>
<span class="strong"><strong>Validation metrics</strong></span>
</p><p>M3:Accuracy <span class="emphasis"><em>ac</em></span>, precision <span class="emphasis"><em>p</em></span>, recall <span class="emphasis"><em>r</em></span>, <span class="emphasis"><em>F<sub>1</sub></em></span>, <span class="emphasis"><em>F<sub>n</sub></em></span>, and <span class="emphasis"><em>G</em></span> scores are defined as follows:</p><div class="mediaobject"><img src="../Images/image01269.jpeg" alt="Key quality metrics"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id2440000" class="indexterm"/>computation of the precision, recall, and F<sub>1</sub> score depends on the number of classes used in the classifier. We will consider the following implementations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">F-score validation for binomial (two classes) classification (that is, a positive and negative outcome)</li><li class="listitem">F-score validation for multinomial (more than two classes) classification</li></ul></div></div><div class="section" title="F-score for binomial classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec3000"/>F-score for binomial classification</h3></div></div></div><p>The<a id="id2450000" class="indexterm"/> binomial F validation computes the precision, recall, and F scores for the positive class.</p><p>Let's implement the F-score or F-measure as a specialized validation of the following:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Validation</strong></span> { def <span class="strong"><strong>score</strong></span>: Double }</pre></div><p>The<a id="id2460000" class="indexterm"/> <code class="literal">BinFValidation</code> class encapsulates the computation of the <span class="emphasis"><em>F<sub>n</sub></em></span> score as well as precision and recall by counting the occurrences of <span class="emphasis"><em>TP</em></span>, <span class="emphasis"><em>TN</em></span>, <span class="emphasis"><em>FP</em></span>, and <span class="emphasis"><em>FN</em></span> values. It implements the <span class="strong"><strong>M3</strong></span> formula. In the tradition of Scala programming, the class is immutable; it computes the counters for <span class="emphasis"><em>TP</em></span>, <span class="emphasis"><em>TN</em></span>, <span class="emphasis"><em>FP</em></span>, and <span class="emphasis"><em>FN</em></span> when the class is instantiated. The class takes the following three parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">expected</code> values with the <code class="literal">0</code> value for a negative outcome and <code class="literal">1</code> for a positive outcome</li><li class="listitem">The set of observations, <code class="literal">xt</code>, is used for validating the model</li><li class="listitem">The predictive <code class="literal">predict</code> function classifies observations (line <code class="literal">1</code>)</li></ul></div><p>The code <a id="id2470000" class="indexterm"/>will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>BinFValidation</strong></span>[T &lt;: AnyVal](
     <span class="strong"><strong>expected</strong></span>: Vector[Int],
     <span class="strong"><strong>xt</strong></span>: XVSeries[T])
     (<span class="strong"><strong>predict</strong></span>: Array[T] =&gt; Int)(implicit f: T =&gt; Double) 
  extends Validation { //<span class="strong"><strong>1</strong></span>

  val counters = {
    val predicted = xt.map( predict(_))
    expected.zip(predicted)
      .aggregate(new Counter[Label])((cnt, ap) =&gt; 
         cnt + classify(ap._1, ap._2), _ ++ _) //<span class="strong"><strong>2</strong></span>
  }

  override def <span class="strong"><strong>score</strong></span>: Double = f1   //<span class="strong"><strong>3</strong></span>
  lazy val <span class="strong"><strong>f1</strong></span> = 2.0*precision*recall/(precision + recall)
  lazy val <span class="strong"><strong>precision</strong></span> = compute(FP)  //<span class="strong"><strong>4</strong></span>
  lazy val <span class="strong"><strong>recall</strong></span> = compute(FN) 

  def compute(n: Label): Double = {
    val denom = counters(TP) + counters(n)
    counters(TP).toDouble/denom
  }
  def classify(predicted: Int, expected: Int): Label = //<span class="strong"><strong>5</strong></span>
    if(expected == predicted) if(expected == POSITIVE) TP else TN
    else if(expected == POSITIVE) FN else FP 
}</pre></div><p>The <a id="id2480000" class="indexterm"/>constructor counts the number of occurrences for each of the four outcomes (<span class="emphasis"><em>TP</em></span>, <span class="emphasis"><em>TN</em></span>, <span class="emphasis"><em>FP</em></span>, and <span class="emphasis"><em>FN</em></span>) (line <code class="literal">2</code>). The <code class="literal">precision</code>, <code class="literal">recall</code>, and <code class="literal">f1</code> values are defined as lazy values so they are computed only once, when they are accessed directly or the <code class="literal">score</code> method is invoked (line <code class="literal">4</code>). The F<sub>1</sub> measure is the most commonly used scoring value for validating classifiers. Therefore, it is the default score (line <code class="literal">3</code>). The <code class="literal">classify</code> private method extracts the qualifier from the expected and predicted values (line <code class="literal">5</code>).</p><p>The <code class="literal">BinFValidation</code> class is independent of the type of classifier, training, labeling process, and type of observations.</p><p>Contrary <a id="id2490000" class="indexterm"/>to Java, which defines an enumerator as a class of types, Scala requires enumerators to be singletons. Enumerators extend the <code class="literal">scala.Enumeration</code> abstract class:</p><div class="informalexample"><pre class="programlisting">object Label extends <span class="strong"><strong>Enumeration</strong></span> {
  type Label = Value
  val TP, TN, FP, FN = Value
}</pre></div><p>The<a id="id2500000" class="indexterm"/> F-score formula with higher cardinality (F<sub>n</sub>) with <span class="emphasis"><em>n &gt; 1</em></span> favors precision over recall, which is shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01270.jpeg" alt="F-score for binomial classification"/><div class="caption"><p>A comparative analysis of the impact of precision on F1, F2, and F3 score for a given recall</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note5600"/>Note</h3><p>
<span class="strong"><strong>Multiclass scoring</strong></span>
</p><p>Our implementation of the binomial validation computes the precision, recall, and F<sub>1</sub> score for the positive class only. The generic multinomial validation class presented in the next section computes these quality metrics for both positive and negative classes.</p></div></div><div class="section" title="F-score for multinomial classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec3100"/>F-score for multinomial classification</h3></div></div></div><p>The <a id="id2510000" class="indexterm"/>validation metric is defined by the <span class="strong"><strong>M3 </strong></span>formula. The idea is quite simple: the precision and recall values are computed <a id="id2520000" class="indexterm"/>for all the classes and then they are averaged to produce a single precision and recall value for the entire model. The precision and recall for the entire model leverage the counts of <span class="emphasis"><em>TP</em></span>, <span class="emphasis"><em>FP</em></span>, <span class="emphasis"><em>FN</em></span>, and <span class="emphasis"><em>TN</em></span> introduced in the previous section.</p><p>There are two commonly used set of formulas to compute the precision and recall for a model:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Macro</strong></span>: This <a id="id2530000" class="indexterm"/>method computes the precision and recall for each class, sums and then averages them up.</li><li class="listitem"><span class="strong"><strong>Micro</strong></span>: This<a id="id2540000" class="indexterm"/> method sums the numerator and denominator of the precision and recall formulas for all the classes before computing the precision and recall.</li></ul></div><p>We will use the macro formulas from now on.</p><div class="note" title="Note"><h3 class="title"><a id="note5700"/>Note</h3><p>
<span class="strong"><strong>Macro formulas for multinomial precision and recall</strong></span>
</p><p>M4: The macro version of the precision <span class="emphasis"><em>p</em></span> and recall <span class="emphasis"><em>r</em></span> for a model of the <span class="emphasis"><em>c</em></span> classes is computed as follows:</p><div class="mediaobject"><img src="../Images/image01271.jpeg" alt="F-score for multinomial classification"/></div><p style="clear:both; height: 1em;"> </p></div><p>The computation of the precision and recall factor for a classifier with more than two classes requires the extraction and manipulation of the <a id="id2550000" class="indexterm"/><span class="strong"><strong>confusion matrix</strong></span>. We use the following convention: <span class="emphasis"><em>expected values are defined as columns and predicted values are defined as rows</em></span>.</p><div class="mediaobject"><img src="../Images/image01272.jpeg" alt="F-score for multinomial classification"/><div class="caption"><p>A confusion matrix for six class classification</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">MultiFValidation</code> multinomial<a id="id2560000" class="indexterm"/> validation <a id="id2570000" class="indexterm"/>class takes the following four parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">expected</code> class index with the <code class="literal">0</code> value for a negative outcome and <code class="literal">1</code> for a positive outcome</li><li class="listitem">The set of observations, <code class="literal">xt</code>, is used for validating the model</li><li class="listitem">The number of <code class="literal">classes</code> in the model</li><li class="listitem">The <code class="literal">predict</code> predictive function classifies observations (line <code class="literal">7</code>)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MultiFValidation</strong></span>[T &lt;: AnyVal](
    <span class="strong"><strong>expected</strong></span>: Vector[Int],
    <span class="strong"><strong>xv</strong></span>: XVSeries[T],
    <span class="strong"><strong>classes</strong></span>: Int)
    (<span class="strong"><strong>predict</strong></span>: Array[T] =&gt; Int)(implicit f : T =&gt; Double)
  extends Validation { //<span class="strong"><strong>7</strong></span>

  val <span class="strong"><strong>confusionMatrix</strong></span>: Matrix[Int] = //<span class="strong"><strong>8</strong></span>
  labeled./:(Matrix[Int](classes)){case (m, (x,n)) =&gt; 
    m + (n, predict(x), 1)}  //<span class="strong"><strong>9</strong></span>

 val macroStats: DblPair = { //<span class="strong"><strong>10</strong></span>
   val pr= Range(0, classes)./:(0.0,0.0)((s, n) =&gt; {
     val <span class="strong"><strong>tp</strong></span> = confusionMatrix(n, n)   //<span class="strong"><strong>11</strong></span>
     val <span class="strong"><strong>fn</strong></span> = confusionMatrix.col(n).sum – tp  //<span class="strong"><strong>12</strong></span>
     val <span class="strong"><strong>fp</strong></span> = confusionMatrix.row(n).sum – tp  //<span class="strong"><strong>13</strong></span>
     (s._1 + tp.toDouble/(tp + fp), s._2 +tp.toDouble/(tp + fn))
   })
   (pr._1/classes, pr._2/classes)
 }
 lazy val <span class="strong"><strong>precision</strong></span>: Double = macroStats._1
 lazy val <span class="strong"><strong>recall</strong></span>: Double = macroStats._1
 def <span class="strong"><strong>score</strong></span>: Double = 2.0*precision*recall/(precision+recall)
 }</pre></div><p>The core <a id="id2580000" class="indexterm"/>element of the multiclass validation is the confusion matrix, <code class="literal">confusionMatrix</code> (line <code class="literal">8</code>). Its elements at indices <span class="emphasis"><em>(i, j) = (index of expected class for an observation, index of the predicted class for the same observation)</em></span> are computed using the expected and predictive outcome for each class (line <code class="literal">9</code>).</p><p>As stated in <a id="id2590000" class="indexterm"/>the introduction of the section, we use the macro definition of the precision and recall (line <code class="literal">10</code>). The count of a true positive, <code class="literal">tp</code>, for each class corresponds to the diagonal element of the confusion matrix (line <code class="literal">11</code>). The count of the <code class="literal">fn</code> false negatives for a class is computed as the sum of the counts for all the predicted classes (column values), given an expected class except the true positive class (line <code class="literal">12</code>). The count of the <code class="literal">fp</code> false positives for a class is computed as the sum of the counts for all the expected classes (row values), given a predicted class except the true positive class (line <code class="literal">13</code>).</p><p>The formula for the computation of the F<sub>1</sub> score is the same as the formula used in the binomial validation.</p></div></div><div class="section" title="Cross-validation"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4500"/>Cross-validation</h2></div></div></div><p>It is<a id="id2600000" class="indexterm"/> quite common<a id="id2610000" class="indexterm"/> that the labeled dataset (observations plus the expected outcome) available to the scientists is not very large. The solution is to break the original labeled dataset into <span class="emphasis"><em>K</em></span> groups of data.</p><div class="section" title="One-fold cross validation"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec3200"/>One-fold cross validation</h3></div></div></div><p>The<a id="id2620000" class="indexterm"/> one-fold cross validation is the simplest scheme used for extracting a training set and validation set from a labeled dataset, as described in the following diagram:</p><div class="mediaobject"><img src="../Images/image01273.jpeg" alt="One-fold cross validation"/><div class="caption"><p>An illustration of the generation of a one-fold validation set</p></div></div><p style="clear:both; height: 1em;"> </p><p>The one-fold cross validation methodology consists of the following three steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select the ratio of the size of the training set over the size of the validation set.</li><li class="listitem">Randomly select the labeled observations for the validation phase.</li><li class="listitem">Create the training set as the remaining labeled observations.</li></ol><div style="height:10px; width: 1px"/></div><p>The one-fold cross validation is implemented by the <code class="literal">OneFoldXValidation</code> class. It takes the following three arguments: an <code class="literal">xt</code> vector of observations, the <code class="literal">expected</code> vector of expected classes, and <code class="literal">ratio</code> of the size of the training set over the size of the validation set (line <code class="literal">14</code>):</p><div class="informalexample"><pre class="programlisting">type ValidationType[T] = Vector[(Array[T], Int)]
class <span class="strong"><strong>OneFoldXValidation</strong></span>[T &lt;: AnyVal](
    <span class="strong"><strong>xt</strong></span>: XVSeries[T],
    <span class="strong"><strong>expected</strong></span>: Vector[Int], 
    <span class="strong"><strong>ratio</strong></span>: Double)(implicit f : T =&gt; Double) {  //<span class="strong"><strong>14</strong></span>
  val <span class="strong"><strong>datasSet</strong></span>: (ValidationType[T], ValidationType[T]) //<span class="strong"><strong>15</strong></span>
  def trainingSet: ValidationType[T] = datasSet._1
  def validationSet: ValidationType[T] = datasSet._1
}</pre></div><p>The <a id="id2630000" class="indexterm"/>constructor of the <code class="literal">OneFoldXValidation</code> class generates the segregated training and validation sets from the set of observations and expected classes (line <code class="literal">15</code>):</p><div class="informalexample"><pre class="programlisting">val datasSet: (Vector[LabeledData[T]],Vector[LabeledData[T]]) = { 
  val labeledData = xt.drop(1).zip(expected)  //<span class="strong"><strong>16</strong></span>
  val trainingSize = (ratio*expected.size).floor.toInt //<span class="strong"><strong>17</strong></span>
  
  val valSz = labeledData.size - trainingSize
  val adjSz = if(valSz &lt; 2) 1 
          else if(valSz &gt;= labeledData.size)  labeledData.size -1 
          else valSz  //<span class="strong"><strong>18</strong></span>
  val iter = labeledData.grouped(adjSz )  //<span class="strong"><strong>18</strong></span>
  val ordLabeledData = labeledData
      .map( (_, Random.nextDouble) )  //19
      .sortWith( _._2 &lt; _._2).unzip._1 //20
 
  (ordlabeledData.takeRight(adjValSz),   
   ordlabeledData.dropRight(adjValSz))  //21
}</pre></div><p>The initialization of the <code class="literal">OneFoldXValidation</code> class creates a <code class="literal">labeledData</code> vector of labeled observations by zipping the observations and the expected outcome (line <code class="literal">16</code>). The training <code class="literal">ratio</code> value is used to compute the respective size of the training set (line <code class="literal">17</code>) and validation set (line <code class="literal">18</code>).</p><p>In order to create training and validations sets randomly, we zip the labeled dataset with a random generator (line <code class="literal">19</code>), and then reorder <a id="id2640000" class="indexterm"/>the labeled dataset by sorting the random values (line <code class="literal">20</code>). Finally, the method returns the pair of training set and validation set (line <code class="literal">21</code>).</p></div><div class="section" title="K-fold cross validation"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec3300"/>K-fold cross validation</h3></div></div></div><p>The <a id="id2650000" class="indexterm"/>data scientist creates <span class="emphasis"><em>K</em></span> training-validation datasets by selecting one of the groups as a validation set and then combining all the remaining<a id="id2660000" class="indexterm"/> groups into a training set, as illustrated in the following diagram. The process is known as the <span class="strong"><strong>K-fold cross validation</strong></span> [2:7].</p><div class="mediaobject"><img src="../Images/image01274.jpeg" alt="K-fold cross validation"/><div class="caption"><p>An illustration of the generation of a K-fold cross validation set</p></div></div><p style="clear:both; height: 1em;"> </p><p>The third segment is used as validation data and all other dataset segments except S3 are combined into a single training set. This process is applied to each segment of the original labeled dataset.</p></div></div><div class="section" title="Bias-variance decomposition"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4600"/>Bias-variance decomposition</h2></div></div></div><p>The <a id="id2670000" class="indexterm"/>challenge is to create a model that fits both the training set and subsequent observations to be classified during the validation phase.</p><p>If the model <a id="id2680000" class="indexterm"/>tightly fits the observations selected for training, there is a high probability that new observations may not be correctly classified. This is usually the case when the model is complex. This model is characterized as having a low bias with a high variance. Such a scenario can be attributed to the fact that the scientist is overly confident that the observations she/he selected for training are representative of the real world.</p><p>The probability<a id="id2690000" class="indexterm"/> of a new observation being classified as belonging to a positive class increases as the selected model fits loosely the training set. In this case, the model is characterized as having a high bias with a low variance.</p><p>The mathematical definition for the <span class="strong"><strong>bias</strong></span>, <span class="strong"><strong>variance</strong></span>, and <span class="strong"><strong>mean square error</strong></span> (MSE) of the distribution are defined by the following formulas:</p><div class="note" title="Note"><h3 class="title"><a id="note5800"/>Note</h3><p>M5: Variance and bias for a true model, θ, is defined as:</p><div class="mediaobject"><img src="../Images/image01275.jpeg" alt="Bias-variance decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>M6: Mean square error is defined as:</p><div class="mediaobject"><img src="../Images/image01276.jpeg" alt="Bias-variance decomposition"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's illustrate the concept of bias, variance, and mean square error with an example. At this stage, you have not been introduced to most of the machines learning techniques. Therefore, we create a simulator to illustrate the relation between the bias and variance of a classifier. The components of the simulation are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A training set, <code class="literal">training</code></li><li class="listitem">A simulated <code class="literal">target</code> model of the <code class="literal">target: Double =&gt; Double</code> type extracted from the training set</li><li class="listitem">A set of possible <code class="literal">models</code> to evaluate</li></ul></div><p>A model that exactly matches the training data overfits the target model. Models that approximate the target model will most likely underfit. The models in this example are defined by single variable functions.</p><p>These <a id="id2700000" class="indexterm"/>models are evaluated against a validation dataset. The <code class="literal">BiasVariance</code> class takes the target model, <code class="literal">target</code>, and the size of the <code class="literal">nValues</code> validation test as parameters (line <code class="literal">22</code>). It merely implements the formula to compute the bias and variance for each model:</p><div class="informalexample"><pre class="programlisting">type Dbl_F = Double =&gt; Double 
class <span class="strong"><strong>BiasVariance</strong></span>[T](<span class="strong"><strong>target</strong></span>: Dbl_F,<span class="strong"><strong>nValues</strong></span>: Int)
     (implicit f: T =&gt; Double) {//<span class="strong"><strong>22</strong></span>
  def <span class="strong"><strong>fit</strong></span>(models: List[Dbl_F]): List[DblPair] = { //<span class="strong"><strong>23</strong></span>
    models.map(<span class="strong"><strong>accumulate</strong></span>(_, models.size)) //<span class="strong"><strong>24</strong></span>
  }
}</pre></div><p>The <code class="literal">fit</code> method computes the variance and bias for each of the <code class="literal">models</code> model compared to the <code class="literal">target</code> model (line <code class="literal">23</code>). It computes the mean, variance, and bias in the <code class="literal">accumulate</code> method (line <code class="literal">24</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>accumulate</strong></span>(f: Dbl_F, y:Double, numModels: Int): DblPair = 
  Range(0, nValues)./:(0.0, 0.0){ case((s,t) x) =&gt; { 
    val diff = (f(x) - y)/numModels
    (s + diff*diff, t + Math.abs(f(x)-target(x))) //<span class="strong"><strong>25</strong></span>
  }}</pre></div><p>The training data is generated by the single variable function with the <span class="emphasis"><em>r<sub>1</sub></em></span> and <span class="emphasis"><em>r<sub>2</sub></em></span> noise components:</p><div class="mediaobject"><img src="../Images/image01277.jpeg" alt="Bias-variance decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">accumulate</code> method returns a tuple (variance, bias) for each model, <span class="emphasis"><em>f</em></span> (line <code class="literal">25</code>). The model candidates are defined by the following family of single variable for values <span class="emphasis"><em>n = 1, 2, and 4</em></span>:</p><div class="mediaobject"><img src="../Images/image01278.jpeg" alt="Bias-variance decomposition"/></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">target</code> model (line <code class="literal">26</code>) and <code class="literal">models</code> (line <code class="literal">27</code>) belong to the same family of single variable <a id="id2710000" class="indexterm"/>functions:</p><div class="informalexample"><pre class="programlisting">val template = (x: Double, n : Int) =&gt; 
                        0.2*x*(1.0 + Math.sin(x*0.1)/n) 
val <span class="strong"><strong>training</strong></span> = (x: Double) =&gt; {
  val r1 = 0.45*(Random.nextDouble-0.5)
  val r2 = 38.0*(Random.nextDouble - 0.5) + Math.sin(x*0.3)
  0.2*x*(1.0 + Math.sin(x*0.1 + r1)) + r2
}
Val <span class="strong"><strong>target</strong></span> = (x: Double) =&gt; template(x, 1) //<span class="strong"><strong>26</strong></span>
val <span class="strong"><strong>models</strong></span> = List[(Dbl_F, String)] (  //27
  ((x: Double) =&gt; template(x, 4), "Underfit1"),  
  ((x: Double) =&gt; template(x, 2), "Underfit2"),
  ((x : Double) =&gt; training(x), "Overfit")
  (target, "target"),
)
val evaluator = new <span class="strong"><strong>BiasVariance</strong></span>[Double](target, 200)
evaluator.fit(models.map( _._1)) match { /* … */ }</pre></div><p>The <span class="strong"><strong>JFreeChart</strong></span> library<a id="id2720000" class="indexterm"/> is used to display the training dataset and the models:</p><div class="mediaobject"><img src="../Images/image01279.jpeg" alt="Bias-variance decomposition"/><div class="caption"><p>Fitting models to dataset</p></div></div><p style="clear:both; height: 1em;"> </p><p>The model <a id="id2730000" class="indexterm"/>that replicates the training data overfits. The models that smooth the model with lower amplitude for the sine component of the <code class="literal">template</code> function underfit. The <span class="strong"><strong>variance-bias trade-off</strong></span>
<a id="id2740000" class="indexterm"/> for the different models and training data is illustrated in the following scatter chart:</p><div class="mediaobject"><img src="../Images/image01280.jpeg" alt="Bias-variance decomposition"/><div class="caption"><p>Scatter plot for the bias-variance trade-off for four models, one duplicating the training set</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id2750000" class="indexterm"/>variance of each of the smoothing or approximating models is lower than the variance of the training set. As expected the target model, <span class="emphasis"><em>0.2.x.(1+sin(x/10))</em></span>, has no bias and no variance. The training set has a very high variance because it overfits any target model. The last chart compares the mean square error between each of the models, training set, and the target model:</p><div class="mediaobject"><img src="../Images/image01281.jpeg" alt="Bias-variance decomposition"/><div class="caption"><p>Comparative mean squares error for four models</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note6000"/>Note</h3><p>
<span class="strong"><strong>Evaluating bias and variance</strong></span>
</p><p>The section uses a fictitious target model and training set to illustrate the concept of the bias and variance of models. The bias and variance of machine learning models are actually estimated using validation data.</p></div></div><div class="section" title="Overfitting"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec4700"/>Overfitting</h2></div></div></div><p>You <a id="id2760000" class="indexterm"/>can<a id="id2770000" class="indexterm"/> apply the methodology presented in the example to any classification and regression model. The list of models with low variance includes constant functions and models independent of the training set. High degree polynomials, complex functions, and deep neural networks have high variance. Linear regression applied to linear data has a low bias, while linear regression applied to nonlinear data has a higher bias [2:8].</p><p>Overfitting affects all aspects of the modeling process negatively, for example:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It renders debugging difficult</li><li class="listitem">It makes the model too dependent of minor fluctuations (long tail) and noisy data</li><li class="listitem">It may discover irrelevant relationships between observed and latent features</li><li class="listitem">It leads to poor predictive performance</li></ul></div><p>However, there are well-proven solutions to reduce overfitting [2:9]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Increasing the size of the training set whenever possible</li><li class="listitem">Reducing noise in labeled observations using smoothing and filtering techniques</li><li class="listitem">Decreasing the number of features using techniques such as principal components analysis, as discussed in the <span class="emphasis"><em>Principal components analysis</em></span> section in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span></li><li class="listitem">Modeling observable and latent noisy data using Kalman or auto regressive models, as discussed in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span></li><li class="listitem">Reducing inductive bias in a training set by applying cross-validation</li><li class="listitem">Penalizing extreme values for some of the model's features using regularization techniques, as discussed in the <span class="emphasis"><em>Regularization</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span></li></ul></div></div></div>
<div class="section" title="Summary" id="aid-532G61"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec2400"/>Summary</h1></div></div></div><p>In this chapter, we established the framework for the different data processing units that will be introduced in this book. There is a very good reason why the topics of model validation and overfitting are explored early in this book. There is no point in building models and selecting algorithms if we do not have a methodology to evaluate their relative merits.</p><p>In this chapter, you were introduced to the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The concept of monadic transformation for implicit and explicit models</li><li class="listitem">The versatility and cleanness of the Cake pattern and mixins composition in Scala as an effective scaffolding tool for data processing</li><li class="listitem">A robust methodology to validate machine learning models</li><li class="listitem">The challenge in fitting models to both training and real-world data</li></ul></div><p>The next chapter will address the problem of overfitting by identifying outliers and reducing noise in data.</p></div>
<div class="chapter" title="Chapter&#xA0;3.&#xA0;Data Preprocessing"><div class="titlepage" id="aid-5410O2"><div><div><h1 class="title"><a id="ch17"/>Chapter 3. Data Preprocessing</h1></div></div></div><p>Real-world data is usually noisy and inconsistent with missing observations. No classification, regression, or clustering model can extract relevant information from raw data.</p><p>Data preprocessing <a id="id2780000" class="indexterm"/>consists of cleaning, filtering, transforming, and normalizing raw observations using statistics in order to correlate features or groups of features, identify trends and models, and filter out noise. The purpose of cleansing raw data is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">To extract some basic knowledge from raw datasets</li><li class="listitem">To evaluate the quality of data and generate clean datasets for unsupervised or supervised learning</li></ul></div><p>You should not underestimate the power of traditional statistical analysis methods to infer and classify information from textual or unstructured data.</p><p>In this chapter, you will learn how to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Apply commonly used moving average techniques to detect long-term trends in a time series</li><li class="listitem">Identify market and sector cycles using discrete Fourier series</li><li class="listitem">Leverage the discrete Kalman filter to extract the state of a linear dynamic system from incomplete and noisy observations</li></ul></div><div class="section" title="Time series in Scala"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec2500"/>Time series in Scala</h1></div></div></div><p>The<a id="id2790000" class="indexterm"/> overwhelming<a id="id2800000" class="indexterm"/> majority of examples used to illustrate the different machine algorithms in this book deal with time series or sequential, time-ordered set of observations.</p><div class="section" title="Types and operations"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec4800"/>Types and operations</h2></div></div></div><p>The <span class="emphasis"><em>Primitives types</em></span> section under <span class="emphasis"><em>Source code</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, introduced <a id="id2810000" class="indexterm"/>the types for a time series of a single <code class="literal">XSeries[T]</code> variable and multiple <code class="literal">XVSeries[T]</code> variables.</p><p>A time series of observations is a vector (a <code class="literal">Vector</code> type) of observation elements of the following types:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A <code class="literal">T</code> type in the case of a single variable/feature observation</li><li class="listitem">An <code class="literal">Array[T]</code> type for observations with more than one variable/feature</li></ul></div><p>A time series of labels or expected values is a single variable vector for which elements may have a primitive <code class="literal">Int</code> type for classification and <code class="literal">Double</code> for regression.</p><p>A time series of labeled observations is a pair of a vector of observations and a vector of labels:</p><div class="mediaobject"><img src="../Images/image01282.jpeg" alt="Types and operations"/><div class="caption"><p>Visualization of the single features and multi-feature observations</p></div></div><p style="clear:both; height: 1em;"> </p><p>The two generic <code class="literal">XSeries</code> and <code class="literal">XVSeries</code> types for the time series will be used as the two primary classes for the input data, from now on.</p><div class="note" title="Note"><h3 class="title"><a id="note6100"/>Note</h3><p>
<span class="strong"><strong>Structure of labeled observations</strong></span>
</p><p>Throughout the book, labeled observations are defined either as a pair of vector of observations and a vector of labels/expected values or as a vector of a pair of {observation, label/expected value}.</p></div><p>The <code class="literal">Stats</code> class <a id="id2820000" class="indexterm"/>introduced in the <span class="emphasis"><em>Profiling data</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, implements some basic statistics and normalization for single variable observations. Let's create an <code class="literal">XTSeries</code> singleton to compute the statistics and normalize multidimensional observations:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>XTSeries</strong></span> { 
  def zipWithShift[T](xv: XSeries[T], n: Int): Vector[(T, T)] = 
     xv.drop(n).zip(xv.view.dropRight(n))  //<span class="strong"><strong>1</strong></span>
  
  def zipWithShift1[T](xv: XSeries[T]): Vector[(T, T)] = 
     xv.zip(xv.view.drop(n))

  def <span class="strong"><strong>statistics</strong></span>[T &lt;: AnyVal](xt:XVSeries[T])
       (implicit f: T =&gt;: Double): Vector[Stats[T]] = 
    xt.transpose.map( Stats[T]( _ ))  //<span class="strong"><strong>2</strong></span>
  
  def <span class="strong"><strong>normalize</strong></span>[T &lt;: AnyVal](  //<span class="strong"><strong>3</strong></span>
      xt: XSeries[T], low: Double, high: Double) 
      (implicit ordering: Ordering[T], 
          f: T =&gt; Double): Try[DblVector] = 
    Try (Stats[T](xt).normalize(low, high) )
   ...
}</pre></div><p>The first method of the <code class="literal">XTSeries</code> singleton generates a vector of a pair of elements by zipping the last <span class="emphasis"><em>size – n</em></span> elements of a time series with its first <span class="emphasis"><em>size – n</em></span> elements (line <code class="literal">1</code>). The <code class="literal">statistics</code> (line <code class="literal">2</code>) and <code class="literal">normalize</code> (line <code class="literal">3</code>) methods operate on both the single and multivariable observations. These three methods are subsets of functionalities implemented in <code class="literal">XTSeries</code>.</p><p>Create a time series of the <code class="literal">XVSeries[T]</code> type by zipping the two <code class="literal">x</code> and <code class="literal">y</code> vectors and converting the pair into an array:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>zipToSeries</strong></span>[T: ClassTag](
x: Vector[T], y: Vector[T]): XVSeries[T]</pre></div><p>Split a single or multidimensional time series, <code class="literal">xv</code>, into a two-time series at index, <span class="emphasis"><em>n</em></span>:</p><div class="informalexample"><pre class="programlisting">def splitAt[T](xv: XSeries[T], n: Int): (XSeries[T], XSeries[T])</pre></div><p>Apply a <code class="literal">zScore</code> transform to a single dimension time series:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>zScore</strong></span>[T &lt;: AnyVal](xt: XSeries[T])
    (implicit f: T =&gt; Double): Try[DblVector]</pre></div><p>Apply a <code class="literal">zScore</code> transform to a multidimension time series:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>zScores</strong></span>[T &lt;: AnyVal](xt: XVSeries[T])
    (implicit f: T =&gt; Double): Try[XVSeries[Double]] </pre></div><p>Transform<a id="id2830000" class="indexterm"/> a single dimension time series <code class="literal">x</code> into a new time series whose elements are <span class="emphasis"><em>x(n) – x(n-1)</em></span>:</p><div class="informalexample"><pre class="programlisting">def delta(x: DblVector): DblVector</pre></div><p>Transform a single dimension time series <code class="literal">x</code> into a new time series which elements if <span class="emphasis"><em>(x(n) – x(n-1) &gt; 0.0) 1 else 0</em></span>:</p><div class="informalexample"><pre class="programlisting">def binaryDelta(x: DblVector): Vector[Int]</pre></div><p>Compute the sum of the squared error between the two <code class="literal">x</code> and <code class="literal">z</code> arrays:</p><div class="informalexample"><pre class="programlisting">def sse[T &lt;: AnyVal](x: Array[T], z: Array[T])
   (implicit f: T =&gt; Double): Double</pre></div><p>Compute the mean squared error between the two <code class="literal">x</code> and <code class="literal">z</code> arrays:</p><div class="informalexample"><pre class="programlisting">def mse[T &lt;: AnyVal](x: Array[T], z: Array[T])
    (implicit f: T =&gt; Double): Double</pre></div><p>Compute the mean squared error between the two <code class="literal">x</code> and <code class="literal">z</code> vectors:</p><div class="informalexample"><pre class="programlisting">def mse(x: DblVector, z: DblVector): Double</pre></div><p>Compute the statistics for each feature of a multidimensional time series:</p><div class="informalexample"><pre class="programlisting">def statistics[T &lt;: AnyVal](xt: XVSeries[T])
    (implicit f: T =&gt; Double): Vector[Stats[T]]</pre></div><p>Apply a <code class="literal">f</code> function to a zipped pair of multidimensional vectors of the <code class="literal">XVSeries</code> type:</p><div class="informalexample"><pre class="programlisting">def zipToVector[T](x: XVSeries[T], y: XVSeries[T])
  (f: (Array[T], Array[T]) =&gt;Double): XSeries[Double] = 
  x.zip(y.view).map{ case (x, y) =&gt; f(x,y)}</pre></div></div><div class="section" title="The magnet pattern"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec4900"/>The magnet pattern</h2></div></div></div><p>Some<a id="id2840000" class="indexterm"/> operations on the time series that are implemented as the <code class="literal">XTSeries</code> methods may have a large variety of input and output types. Scala and Java support method overloading that has the following limitations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It does not prevent the type collision caused by the erasure type in the JVM</li><li class="listitem">It does not allow lifting to a single, generic function</li><li class="listitem">It does not completely reduce code redundancy</li></ul></div><div class="section" title="The transpose operator"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3400"/>The transpose operator</h3></div></div></div><p>Let's <a id="id2850000" class="indexterm"/>consider the transpose operator for any kind of multidimensional time series. The transpose operator can be objectified as the <code class="literal">Transpose</code> trait:</p><div class="informalexample"><pre class="programlisting">sealed trait <span class="strong"><strong>Transpose</strong></span> {
  type Result   //<span class="strong"><strong>4</strong></span>
  def apply(): Result  //<span class="strong"><strong>5</strong></span>
}</pre></div><p>The trait has an abstract <code class="literal">Result</code> type (line <code class="literal">4</code>) and an abstract <code class="literal">apply()</code>constructor (line <code class="literal">5</code>) that allows us to create a generic <code class="literal">transpose</code> method with any kind of combination of input and output types. The conversion type for the input and output types of the <code class="literal">transpose</code> method is defined as <code class="literal">implicit</code>:</p><div class="informalexample"><pre class="programlisting">implicit def xvSeries2Matrix[T: ClassTag](from: XVSeries[T]) = 
  new <span class="strong"><strong>Transpose</strong></span> { type Result = Array[Array[T]]  //<span class="strong"><strong>6</strong></span>
    def apply(): Result =  from.toArray.transpose
}
implicit def list2Matrix[T: ClassTag](from: List[Array[T]]) = 
  new <span class="strong"><strong>Transpose</strong></span> { type Result = Array[Array[T]]  //<span class="strong"><strong>7</strong></span>
   def apply(): Result =  from.toArray.transpose
}
…</pre></div><p>The first <code class="literal">xvSeries2Matrix</code> implicit transposes a time series of the <code class="literal">XVSeries[T]</code> type into a matrix with elements of the <code class="literal">T</code> type (line <code class="literal">6</code>). The <code class="literal">list2Matrix</code> implicit transposes a time series of the <code class="literal">List[Array[T]]</code> type into a matrix with elements of the <code class="literal">T</code> type (line <code class="literal">7</code>).</p><p>The generic <code class="literal">transpose</code> method is written as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>transpose</strong></span>(tpose: Transpose): tpose.Result = tpose()</pre></div></div><div class="section" title="The differential operator"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3500"/>The differential operator</h3></div></div></div><p>The <a id="id2860000" class="indexterm"/>second candidate for the magnet pattern is the computation of the differential in a time series. The purpose is to generate the time series <span class="emphasis"><em>{x<sub>t+1</sub> – x<sub>t</sub>}</em></span> from a time series <span class="emphasis"><em>{x<sub>t</sub>}</em></span>:</p><div class="informalexample"><pre class="programlisting">sealed trait <span class="strong"><strong>Difference</strong></span>[T] {
  type Result
  def apply(f: (Double, Double) =&gt; T): Result
}</pre></div><p>The <code class="literal">Difference</code> trait allows us to compute the differential of a time series with arbitrary element types. For instance, the differential of a one-dimensional vector of the <code class="literal">Double</code> type is defined by the following implicit conversion:</p><div class="informalexample"><pre class="programlisting">implicit def vector2Double[T](x: DblVector) = new <span class="strong"><strong>Difference</strong></span>[T] {
  type Result = Vector[T]
  def apply(f: (Double, Double) =&gt; T): Result =  //<span class="strong"><strong>8</strong></span>
    zipWithShift(x, 1).collect{case(next,prev) =&gt;f(prev,next)}
}</pre></div><p>The <code class="literal">apply()</code>constructor takes one argument: the user-defined <code class="literal">f</code> function that computes the difference between two consecutive elements of the time series (line <code class="literal">8</code>). The generic difference method is as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>difference</strong></span>[T](
   diff: Difference[T], 
   f: (Double, Double) =&gt; T): diff.Result = diff(f)</pre></div><p>Here are some of the predefined differential operators of a time series for which the output of the operator has the <code class="literal">Double</code> (line <code class="literal">9</code>), <code class="literal">Int</code> (line <code class="literal">10</code>), and <code class="literal">Boolean</code> (line <code class="literal">11</code>) types:</p><div class="informalexample"><pre class="programlisting">val diffDouble = (x: Double,y: Double) =&gt; y –x //<span class="strong"><strong>9</strong></span>
val diffInt = (x: Double,y: Double) =&gt; if(y &gt; x) 1 else 0 //<span class="strong"><strong>10</strong></span>
val diffBoolean = (x: Double,y: Double) =&gt; (y &gt; x) //<span class="strong"><strong>11</strong></span>
</pre></div><p>The differential operator is used to implement the <code class="literal">labeledData</code> method to generate labeled data from observations with two features and a target (labels) dataset:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>differentialData</strong></span>[T](
   x: DblVector, 
   y: DblVector, 
   target: DblVector,
   f: (Double,Double) =&gt;T): Try[(XVSeries[Double],Vector[T])] = 
  Try((zipToSeries(x,y), difference(target, f)))</pre></div><p>The structure of the labeled data is the pair of observations and the differential of target values.</p></div></div><div class="section" title="Lazy views"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5000"/>Lazy views</h2></div></div></div><p>A view in<a id="id2870000" class="indexterm"/> Scala is a proxy collection that represents a collection but implements the data transformation or higher-order method lazily. The elements of a view are defined as lazy values, which are instantiated on demand.</p><p>One important advantage of views over a <span class="strong"><strong>strict</strong></span> (or fully allocated) collection is the reduced memory consumption.</p><p>Let's take a look at the <code class="literal">aggregator</code> data transformation introduced in the <span class="emphasis"><em>Instantiating the workflow</em></span> section under <span class="emphasis"><em>A workflow computational model</em></span> in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>. There is no need to allocate the entire set of <code class="literal">x.size</code> of elements: the higher-order <code class="literal">find</code> method may exit after only a few elements have been read (line <code class="literal">12</code>):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>aggregator</strong></span> = new ETransform[Int](splits) { 
  override def |&gt; : PartialFunction[U, Try[V]] = { 
    case x: U if(!x.isEmpty) =&gt; 
      Try( Range(0, x.size).<span class="strong"><strong>view</strong></span>.<span class="strong"><strong>find</strong></span>(x(_) == 1.0).get) //<span class="strong"><strong>12</strong></span>
   }
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note6200"/>Note</h3><p>
<span class="strong"><strong>Views, iterators, and streams</strong></span>
</p><p>Views, iterators, and streams share the same objective of constructing elements on demand. There are, however, some major differences:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Iterators do not persist elements of the collection (read once)</li><li class="listitem">Streams allow operations to be performed on the collection with an undefined size</li></ul></div></div></div></div></div>
<div class="section" title="Moving averages"><div class="titlepage" id="aid-54VHA2"><div><div><h1 class="title"><a id="ch03lvl1sec2600"/>Moving averages</h1></div></div></div><p>Moving averages<a id="id2880000" class="indexterm"/> provide data analysts and scientists with a basic predictive model. Despite its simplicity, the moving average method is widely used in a variety of fields, such as marketing survey, consumer behavior, or sport statistics. Traders use the moving average method to identify different levels of support and resistance <a id="id2890000" class="indexterm"/>for the price of a given security.</p><div class="note" title="Note"><h3 class="title"><a id="note6300"/>Note</h3><p>
<span class="strong"><strong>An average reducing function</strong></span>
</p><p>Let's consider the time series <span class="emphasis"><em>x<sub>t</sub> = x(t)</em></span> and function <span class="emphasis"><em>f(x<sub>t-p-1</sub>,…, x<sub>t</sub>)</em></span> that reduces the last <span class="emphasis"><em>p</em></span> observations into a value or average. The estimation of the observation at <span class="emphasis"><em>t</em></span> is defined by the following formula:</p><div class="mediaobject"><img src="../Images/image01283.jpeg" alt="Moving averages"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>f</em></span> is an average reducing function from the previous <span class="emphasis"><em>p</em></span> data points.</p></div><div class="section" title="The simple moving average"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5100"/>The simple moving average</h2></div></div></div><p>The <a id="id2900000" class="indexterm"/>simple moving average is the simplest form of the <a id="id2910000" class="indexterm"/>moving averages algorithms [3:1]. The simple moving average of period <span class="emphasis"><em>p</em></span> estimates the value at time <span class="emphasis"><em>t</em></span> by computing the average value of the previous <span class="emphasis"><em>p</em></span> observations using the following formula.</p><div class="note" title="Note"><h3 class="title"><a id="note6500"/>Note</h3><p>
<span class="strong"><strong>The simple moving average</strong></span>
</p><p>M1: The simple moving average of a time series <span class="emphasis"><em>{x<sub>t</sub>}</em></span> with a period <span class="emphasis"><em>p</em></span> is computed as the average of the last <span class="emphasis"><em>p</em></span> observations:</p><div class="mediaobject"><img src="../Images/image01284.jpeg" alt="The simple moving average"/></div><p style="clear:both; height: 1em;"> </p><p>M2: The computation is implemented iteratively using the following formula:</p><div class="mediaobject"><img src="../Images/image01285.jpeg" alt="The simple moving average"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="inlinemediaobject"><img src="../Images/image01286.jpeg" alt="The simple moving average"/></span> is the estimate or simple moving average value at time <span class="emphasis"><em>t</em></span>.</p></div><p>Let's <a id="id2920000" class="indexterm"/>build a class hierarchy of moving average algorithms, with <a id="id2930000" class="indexterm"/>the parameterized <code class="literal">MovingAverage</code> trait as its root:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>MovingAverage</strong></span>[T]</pre></div><p>We use the generic <code class="literal">XSeries[T]</code> type and the data transform with the <code class="literal">ETransform</code> explicit configuration, introduced in the <span class="emphasis"><em>Explicit models</em></span> section under <span class="emphasis"><em>Monadic data transformation</em></span> in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, to implement the simple moving average, <code class="literal">SimpleMovingAverage</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SimpleMovingAverage</strong></span>[T &lt;: AnyVal](period: Int)
     (implicit <span class="strong"><strong>num</strong></span>: <span class="strong"><strong>Numeric</strong></span>[T], f: T =&gt; Double) //<span class="strong"><strong>1</strong></span>
  extends <span class="strong"><strong>Etransform</strong></span>[Int](period) with <span class="strong"><strong>MovingAverage</strong></span>[T] {

  type <span class="strong"><strong>U</strong></span> = XSeries[T]  //<span class="strong"><strong>2</strong></span>
  type <span class="strong"><strong>V</strong></span> = DblVector   //<span class="strong"><strong>3</strong></span>
  
  val zeros = Vector.fill(0.0)(period-1) 
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
    case xt: U if( xt.size &gt;= period ) =&gt; {
      val splits = xt.splitAt(period)
      val <span class="strong"><strong>slider</strong></span> = xt.take(xt.size - period).zip(splits._2)  //<span class="strong"><strong>4</strong></span>

      val zero = splits._1.sum/period //<span class="strong"><strong>5</strong></span>
      Try( zeros ++ slider.<span class="strong"><strong>scanLeft</strong></span>(zero) {
         case (s, (x,y)) =&gt; s + (x - y)/period }) //7
  }
}</pre></div><p>The class is parameterized for the <code class="literal">T</code> type of elements of the input time series; <span class="emphasis"><em>we cannot make any assumption regarding the type of input data</em></span>. The type of the elements of the output time series is <code class="literal">Double</code>. The implicit instantiation of the <code class="literal">Numeric[T]</code> class is required by the <code class="literal">sum</code> and <code class="literal">/</code> arithmetic operators (line <code class="literal">1</code>). The simple moving average implements <code class="literal">ETransform</code> by defining the abstract <code class="literal">U</code> types for the input (line <code class="literal">2</code>) and <code class="literal">V</code> for the output ( line <code class="literal">3</code>) as a time series, <code class="literal">DblVector</code>.</p><p>The <a id="id2940000" class="indexterm"/>implementation has a few interesting<a id="id2950000" class="indexterm"/> elements. First, the set of observations is duplicated and the index in the resulting clone instance is shifted by <code class="literal">p</code> observations before being zipped with the original to the array of a pair of <code class="literal">slider</code> values (line <code class="literal">4</code>):</p><div class="mediaobject"><img src="../Images/image01287.jpeg" alt="The simple moving average"/><div class="caption"><p>The sliding algorithm to compute moving averages</p></div></div><p style="clear:both; height: 1em;"> </p><p>The average value is initialized with the mean value of the first <code class="literal">period</code> data points (line <code class="literal">5</code>). The first <code class="literal">period</code> values of the trends are initialized to zero (line <code class="literal">6</code>). The method concatenates the initial null values and the computed average values to implement the <span class="strong"><strong>M2</strong></span> formula (line <code class="literal">7</code>).</p></div><div class="section" title="The weighted moving average"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5200"/>The weighted moving average</h2></div></div></div><p>The<a id="id2960000" class="indexterm"/> weighted moving average method<a id="id2970000" class="indexterm"/> is an extension of the simple moving average by computing the weighted average of the last <span class="emphasis"><em>p</em></span> observations [3:2]. The weights <span class="emphasis"><em>α<sub>j</sub></em></span> are assigned to each of the last <span class="emphasis"><em>p</em></span> data points <span class="emphasis"><em>x<sub>j</sub></em></span> and are normalized by the sum of the weights.</p><div class="note" title="Note"><h3 class="title"><a id="note6800"/>Note</h3><p>
<span class="strong"><strong>The weighted moving average</strong></span>
</p><p>M3: The weighted moving average of a series <span class="emphasis"><em>{x<sub>t</sub>}</em></span> with a period <span class="emphasis"><em>p</em></span> and a normalized weights distribution <span class="emphasis"><em>{α<sub>j</sub>}</em></span> is given by the following formula:</p><div class="mediaobject"><img src="../Images/image01288.jpeg" alt="The weighted moving average"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>x<sub>t</sub></em></span> is the estimate or simple moving average value at time <span class="emphasis"><em>t</em></span>.</p></div><p>The<a id="id2980000" class="indexterm"/> implementation of the <code class="literal">WeightedMovingAverage</code> class requires the computation of the last <span class="emphasis"><em>p</em></span> (<code class="literal">weights.size</code>) data points. There is<a id="id2990000" class="indexterm"/> no simple iterative formula to compute the weighted moving average at time <span class="emphasis"><em>t + 1</em></span> using the moving average at time <span class="emphasis"><em>t</em></span>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>WeightedMovingAverage</strong></span>[@<span class="strong"><strong>specialized</strong></span>(Double) T &lt;: AnyVal]( 
    weights: DblArray)
    (implicit num: Numeric[T], f: T =&gt; Double) 
  extends <span class="strong"><strong>SimpleMovingAverage</strong></span>[T](weights.length) {  //<span class="strong"><strong>8</strong></span>

  override def |&gt; : PartialFunction[U, Try[V]] = {
    case xt: U if(xt.size &gt;= weights.length ) =&gt; {
      val smoothed =  (config to xt.size).map( i =&gt; 
       xt.slice(i- config, i).zip(weights) //<span class="strong"><strong>9</strong></span>
             .map { case(x, w) =&gt; x*w).sum  //<span class="strong"><strong>10</strong></span>
      )
      Try(zeros ++ smoothed) //<span class="strong"><strong>11</strong></span>
    }
  }
}</pre></div><p>The computation of the weighted moving average is a bit more involved than the simple moving average. Therefore, we specify the generation of the byte code that is dedicated to the <code class="literal">Double</code> type using the specialized annotation. The weighted moving average inherits the <code class="literal">SimpleMovingAverage</code> class, and therefore, implements the <code class="literal">ETransform</code> explicit transformation for a configuration of weights, with input observations of the <code class="literal">XSeries[T]</code> type <a id="id3000000" class="indexterm"/>and output observations of the <code class="literal">DblVector</code> type. The implementation of <span class="strong"><strong>M3</strong></span> formula generates a smoothed time series by slicing (line <code class="literal">9</code>) the input time series and then computing the inner product of weights and the slice of the time series (line <code class="literal">10</code>).</p><p>As with the simple<a id="id3010000" class="indexterm"/> moving average, the output is the concatenation of the initial <code class="literal">weights.size</code> null values, <code class="literal">zeros</code>, and the <code class="literal">smoothed</code> data (line <code class="literal">11</code>).</p></div><div class="section" title="The exponential moving average"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5300"/>The exponential moving average</h2></div></div></div><p>The <a id="id3020000" class="indexterm"/>exponential moving average is widely<a id="id3030000" class="indexterm"/> used in financial analysis and marketing surveys because it favors the latest values. The older the value, the less impact it has on the moving average value at time <span class="emphasis"><em>t</em></span> [3:3].</p><div class="note" title="Note"><h3 class="title"><a id="note7000"/>Note</h3><p>
<span class="strong"><strong>The exponential moving average</strong></span>
</p><p>M4: The exponential moving average of a series <span class="emphasis"><em>{x<sub>t</sub>}</em></span> and smoothing factor <span class="emphasis"><em>α</em></span> is computed by the following iterative formula:</p><div class="mediaobject"><img src="../Images/image01289.jpeg" alt="The exponential moving average"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="inlinemediaobject"><img src="../Images/image01290.jpeg" alt="The exponential moving average"/></span> is the value of the exponential average at <span class="emphasis"><em>t</em></span>.</p></div><p>The implementation of the <code class="literal">ExpMovingAverage</code> class is rather simple. The constructor has a single <code class="literal">α</code> argument (the decay rate) (line <code class="literal">12</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>ExpMovingAverage</strong></span>[@specialized(Double) T &lt;: AnyVal](  
    <span class="strong"><strong>alpha</strong></span>: Double)    //<span class="strong"><strong>12</strong></span>
    (implicit f: T =&gt; Double) 
  extends <span class="strong"><strong>ETransform</strong></span>[Double](alpha) with <span class="strong"><strong>MovingAverage</strong></span>[T]{ //<span class="strong"><strong>13</strong></span>
  
  type <span class="strong"><strong>U</strong></span> = XSeries[T]    //<span class="strong"><strong>14</strong></span>
  type <span class="strong"><strong>V</strong></span> = DblVector    //<span class="strong"><strong>15</strong></span>

  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
    case xt: U if( xt.size &gt; 0) =&gt; {
      val alpha_1 = 1-alpha
      var y: Double = data(0)
      Try( xt.view.<span class="strong"><strong>map</strong></span>(x =&gt; {
        val z = x*alpha + y*alpha_1; y = z; z})) //<span class="strong"><strong>16</strong></span>
    }
}
}</pre></div><p>The <a id="id3040000" class="indexterm"/>exponential moving average implements the <code class="literal">ETransform</code> (line <code class="literal">13</code>) by defining the abstract <code class="literal">U</code> types for the input (line <code class="literal">14</code>) as a time series named <code class="literal">XSeries[T]</code> and <code class="literal">V</code> for the output (line <code class="literal">15</code>) as a time series named <code class="literal">DblVector</code>. The <code class="literal">|&gt;</code> method<a id="id3050000" class="indexterm"/> applies the <span class="strong"><strong>M4</strong></span> formula to all the observations of the time series within a <code class="literal">map</code> (line <code class="literal">16</code>).</p><p>The version of the constructor that uses the <code class="literal">p</code> period to compute <span class="emphasis"><em>alpha = 1/(p+1)</em></span> as an argument is implemented using the Scala <code class="literal">apply</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>[T &lt;: AnyVal](p: Int)
     (implicit f: T =&gt; Double): ExpMovingAverage[T] = 
  new ExpMovingAverage[T](2/(p + 1))</pre></div><p>Let's compare the results generated from these three moving averages methods with the original price. We use a data source, <code class="literal">DataSource</code>, to load and extract values from the historical daily closing stock price of Bank of America (BAC), which is available at the Yahoo Financials pages. The <code class="literal">DataSink</code> class is responsible for formatting and saving the results into a CSV file for further analysis. The <code class="literal">DataSource</code> and <code class="literal">DataSink</code> classes are described in detail in the <span class="emphasis"><em>Data extraction</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">import YahooFinancials._
val hp = p &gt;&gt;1
val w = Array.tabulate(p)(n =&gt; 
       if(n == hp) 1.0 else 1.0/(Math.abs(n - hp)+1)) //<span class="strong"><strong>17</strong></span>
val sum = w.sum
val weights = w.map { _ / sum }                          //<span class="strong"><strong>18</strong></span>

val dataSrc = <span class="strong"><strong>DataSource</strong></span>(s"$RESOURCE_PATH$symbol.csv", false)//<span class="strong"><strong>19</strong></span>
val <span class="strong"><strong>pfnSMvAve</strong></span> = SimpleMovingAverage[Double](p) |&gt;         //<span class="strong"><strong>20</strong></span>   
val <span class="strong"><strong>pfnWMvAve</strong></span> = WeightedMovingAverage[Double](weights) |&gt;  
val <span class="strong"><strong>pfnEMvAve</strong></span> = ExpMovingAverage[Double](p) |&gt;

for {
   price &lt;- dataSrc.get(adjClose)   //<span class="strong"><strong>21</strong></span>
   if(pfnSMvSve.<span class="strong"><strong>isDefinedAt</strong></span>(price) )
   sMvOut &lt;- pfnSMvAve(price)         //<span class="strong"><strong>22</strong></span>
   if(pfnWMvSve.isDefinedAt(price)
   eMvOut &lt;- pfnWMvAve(price)
  if(pfnEMvSve.isDefinedAt(price)
   wMvOut &lt;- pfnEMvAve(price)
} yield {
  val dataSink = DataSink[Double](s"$OUTPUT_PATH$p.csv")
  val results = List[DblSeries](price, sMvOut, eMvOut, wMvOut)
  dataSink |&gt; results  //23
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note7200"/>Note</h3><p>
<span class="strong"><strong>isDefinedAt</strong></span>
</p><p>Each of the partial function is validated by a call to <code class="literal">isDefinedAt</code>. From now on, the validation of a partial function will be omitted throughout the book for the sake of clarity.</p></div><p>The <a id="id3060000" class="indexterm"/>coefficients for the weighted moving average are <a id="id3070000" class="indexterm"/>generated (line <code class="literal">17</code>) and normalized (line <code class="literal">18</code>). The trading data regarding the ticker symbol, BAC, is extracted from the Yahoo Finances CSV file (line <code class="literal">19</code>), <code class="literal">YahooFinancials</code>, using the <code class="literal">adjClose</code> extractor (line <code class="literal">20</code>). The next step is to initialize the <code class="literal">pfnSMvAve</code>, <code class="literal">pfnWMvAve</code>, and <code class="literal">pfnEMvAve</code> partial functions related to each of the moving average (line <code class="literal">21</code>). The invocation of the partial functions with <code class="literal">price</code> as an argument generates the three smoothed time series (line <code class="literal">22</code>).</p><p>Finally, a <code class="literal">DataSink</code> instance formats and dumps the results into a file (line <code class="literal">23</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note7300"/>Note</h3><p>Implicit postfixOps</p><p>The instantiation of the <code class="literal">filter |&gt;</code> partial function requires that the post fix operation, <code class="literal">postfixOps</code>, be made visible by importing <code class="literal">scala.language.postfixOps</code>.</p></div><p>The <a id="id3080000" class="indexterm"/>weighted moving average method relies on a symmetric distribution of normalized weights computed by a function passed as an argument of the generic <code class="literal">tabulate</code> method. Note that the original price time series is displayed if one of the specific moving averages cannot be computed. The following graph is an example of a symmetric filter for weighted moving averages:</p><div class="mediaobject"><img src="../Images/image01291.jpeg" alt="The exponential moving average"/><div class="caption"><p>An example of a symmetric filter for weighted moving averages</p></div></div><p style="clear:both; height: 1em;"> </p><p>The<a id="id3090000" class="indexterm"/> three moving average techniques are applied to the price of the stock of Bank of America stock (BAC) over 200 trading days. Both the simple and weighted moving averages use a period of 11 trading days. The exponential moving average method uses a scaling factor of <span class="emphasis"><em>2/(11+1) = 0.1667</em></span>:</p><div class="mediaobject"><img src="../Images/image01292.jpeg" alt="The exponential moving average"/><div class="caption"><p>11-day moving averages of the historical stock price of Bank of America</p></div></div><p style="clear:both; height: 1em;"> </p><p>The<a id="id3100000" class="indexterm"/> three techniques filter the noise out of the original historical price time series. The exponential moving average reacts to a <a id="id3110000" class="indexterm"/>sudden price fluctuation despite the fact that the smoothing factor is low. If you increase the period to 51 trading days (which is equivalent to two calendar months), the simple and weighted moving averages produce a time series smoother than the exponential moving average with <span class="emphasis"><em>alpha = 2/(p+1) = 0.038</em></span>:</p><div class="mediaobject"><img src="../Images/image01293.jpeg" alt="The exponential moving average"/><div class="caption"><p>51-day moving averages of the historical stock price of Bank of America</p></div></div><p style="clear:both; height: 1em;"> </p><p>You are<a id="id3120000" class="indexterm"/> invited to experiment further with different smooth factors and weight distributions. You will be able to confirm the following basic rule: as the period of the moving average increases, noise with decreasing frequencies is eliminated. In other words, the window of allowed frequencies is shrinking. The moving average acts as a <span class="strong"><strong>low-pass filter</strong></span>
<a id="id3130000" class="indexterm"/> that preserves only lower frequencies.</p><p>Fine-tuning the period of a smoothing factor is time consuming. Spectral analysis, or more specifically, Fourier analysis transforms a time series into a sequence of frequencies, which <a id="id3140000" class="indexterm"/>provide the statistician with a more powerful frequency analysis tool.</p><div class="note" title="Note"><h3 class="title"><a id="note7400"/>Note</h3><p>
<span class="strong"><strong>The moving average on a multidimensional time series</strong></span>
</p><p>The moving average techniques are presented for a single feature or variable time series, for the sake of simplicity. Moving averages on multidimensional time series are computed by executing a single variable moving average for each feature using the <code class="literal">transform</code> method of <code class="literal">XTSeries</code>, which is introduced in the first section. For example, the simple moving average applied to a multidimensional time series, <code class="literal">xt</code>. The smoothed values are computed as follows:</p><div class="informalexample"><pre class="programlisting">   val pfnMv = SimpleMovingAverage[Double](period) |&gt;
   val smoothed = transform(xt, pfnMv)</pre></div></div></div></div>
<div class="section" title="Fourier analysis"><div class="titlepage" id="aid-55U1S2"><div><div><h1 class="title"><a id="ch03lvl1sec2700"/>Fourier analysis</h1></div></div></div><p>The<a id="id3150000" class="indexterm"/> purpose<a id="id3160000" class="indexterm"/> of <span class="strong"><strong>spectral density estimation</strong></span> is to measure the amplitude of a signal or a time series according to its frequency [3:4]. The objective is to estimate the spectral density by detecting periodicities in the dataset. A scientist can better understand a signal or time series by analyzing its harmonics.</p><div class="note" title="Note"><h3 class="title"><a id="note7500"/>Note</h3><p>
<span class="strong"><strong>The spectral theory</strong></span>
</p><p>Spectral analysis for a time series should not be confused with the spectral theory, a subset of linear algebra that studies eigenfunctions on <span class="strong"><strong>Hilbert</strong></span> and <span class="strong"><strong>Banach</strong></span> spaces. In fact, harmonic analysis and Fourier analysis are regarded as subsets of the spectral theory.</p></div><p>Let's explore the concept behind the discrete Fourier series as well as its benefits as applied to financial markets. The <span class="strong"><strong>Fourier analysis</strong></span> approximates any generic function as the sum of trigonometric functions, sine and cosine.</p><div class="note" title="Note"><h3 class="title"><a id="note7600"/>Note</h3><p>
<span class="strong"><strong>Complex Fourier transform</strong></span>
</p><p>This section focuses on the discrete Fourier series for real values. The generic Fourier transform applies to complex values [3:5].</p></div><p>The decomposition in a basic trigonometric function process is known as the <a id="id3170000" class="indexterm"/><span class="strong"><strong>Fourier transform</strong></span> [3:6].</p><div class="section" title="Discrete Fourier transform"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5400"/>Discrete Fourier transform</h2></div></div></div><p>A <a id="id3180000" class="indexterm"/>time series <span class="emphasis"><em>{x<sub>k</sub>}</em></span> can be represented as a discrete real-time domain function <span class="emphasis"><em>f, x = f(t)</em></span>. In the 18<sup>th</sup> century, Jean Baptiste Joseph Fourier demonstrated that any continuous periodic function <span class="emphasis"><em>f</em></span> can be represented as a linear combination of sine and cosine functions. The <span class="strong"><strong>discrete Fourier transform</strong></span> (<span class="strong"><strong>DFT</strong></span>) is a <a id="id3190000" class="indexterm"/>linear transformation that converts a time series into a list of coefficients of a finite combination of complex or real trigonometric functions, ordered by their frequencies.</p><p>The<a id="id3200000" class="indexterm"/> frequency <span class="emphasis"><em>ω</em></span> of each trigonometric function defines one of the harmonics of the signal. The space that represents the signal amplitude versus frequency of the signal is known as the <a id="id3210000" class="indexterm"/><span class="strong"><strong>frequency domain</strong></span>. The generic DFT transforms a time series into a sequence of frequencies defined as complex numbers <span class="emphasis"><em>a + j.φ (j<sup>2</sup> = -1)</em></span>, where <span class="emphasis"><em>a</em></span> is the amplitude of the frequency and <span class="emphasis"><em>φ</em></span> is the phase.</p><p>This section is dedicated to the real DFT that converts a time series into an ordered sequence of frequencies with real values.</p><div class="note" title="Note"><h3 class="title"><a id="note7700"/>Note</h3><p>
<span class="strong"><strong>Real discrete Fourier transform</strong></span>
</p><p>M5: A periodic function <span class="emphasis"><em>f</em></span> can be represented as an infinite combination of sine and cosine functions:</p><div class="mediaobject"><img src="../Images/image01294.jpeg" alt="Discrete Fourier transform"/></div><p style="clear:both; height: 1em;"> </p><p>M6: The Fourier cosine transform of a function <span class="emphasis"><em>f</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01295.jpeg" alt="Discrete Fourier transform"/></div><p style="clear:both; height: 1em;"> </p><p>M7: The discrete real cosine series of a function <span class="emphasis"><em>f(-x) = f(x)</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01296.jpeg" alt="Discrete Fourier transform"/></div><p style="clear:both; height: 1em;"> </p><p>M8: The Fourier sine transform of a function is defined as:</p><div class="mediaobject"><img src="../Images/image01297.jpeg" alt="Discrete Fourier transform"/></div><p style="clear:both; height: 1em;"> </p><p>M9: The discrete real sine series of a function <span class="emphasis"><em>f(-x) = f(x)</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01298.jpeg" alt="Discrete Fourier transform"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id3220000" class="indexterm"/>computation of the Fourier trigonometric series is time consuming with an asymptotic time complexity of <span class="emphasis"><em>O(n<sup>2</sup>)</em></span>. Scientists and <a id="id3230000" class="indexterm"/>mathematicians have been working to make the computation as effective as possible. The most common numerical algorithm used to compute the Fourier series is the <a id="id3240000" class="indexterm"/><span class="strong"><strong>Fast Fourier Transform</strong></span> (<span class="strong"><strong>FFT</strong></span>) created by J.W. Cooley and J. Tukey [3:7].</p><p>The algorithm called Radix-2 version recursively breaks down the Fourier transform for a time series of <span class="emphasis"><em>N</em></span> data points into any combination of <span class="emphasis"><em>N<sub>1</sub></em></span> and <span class="emphasis"><em>N<sub>2</sub></em></span> sized segments such as <span class="emphasis"><em>N = N<sub>1</sub> N<sub>2</sub></em></span>. Ultimately, the discrete Fourier transform is applied to the deeper-nested segments.</p><div class="note" title="Note"><h3 class="title"><a id="tip0900"/>Tip</h3><p>
<span class="strong"><strong>The Cooley-Tukey algorithm</strong></span>
</p><p>I encourage you to implement the Radix-2 Cooley-Tukey algorithm in Scala using a tail recursion.</p></div><p>The <a id="id3250000" class="indexterm"/>Radix-2 implementation requires that the number of data points is <span class="emphasis"><em>N=2<sup>n</sup></em></span> for even functions (sine) and <span class="emphasis"><em>N=2<sup>n</sup>+1</em></span> for cosine. There are two approaches to meet this constraint:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Reduce the actual number of points to the next lower radix, <span class="emphasis"><em>2<sup>n</sup></em></span><span class="emphasis"><em> &lt; N</em></span></li><li class="listitem">Extend the original time series by padding it with 0 to the next higher radix, <span class="emphasis"><em>N &lt; 2<sup>n</sup></em></span><span class="emphasis"><em>+1</em></span></li></ul></div><p>Padding the <a id="id3260000" class="indexterm"/>time series is the preferred option because it does not affect the original set of observations.</p><p>Let's define a <code class="literal">DTransform</code> trait for any variant of the discrete Fourier transform. The first step is to wrap the default configuration parameters used in the Apache Commons Math library into a <code class="literal">Config</code> singleton:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>DTransform</strong></span> {
  object <span class="strong"><strong>Config</strong></span> {
     final val FORWARD = TransformType.FORWARD
     final val INVERSE = TransformType.INVERSE
     final val SINE = DstNormalization.STANDARD_DST_I
     final val COSINE = DctNormalization.STANDARD_DCT_I
   }
   …
}</pre></div><p>The main purpose of the <code class="literal">DTransform</code> trait is to pad the <code class="literal">vec</code> time series with zero values:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>pad</strong></span>(vec: DblVector, 
    even: Boolean = true)(implicit f: T =&gt;Double): DblArray = {
  val newSize = <span class="strong"><strong>padSize</strong></span>(vec.size, even)   //<span class="strong"><strong>1</strong></span>
  val arr: DblVector = vec.map(_.toDouble)
  if( newSize &gt; 0) arr ++ Array.fill(newSize)(0.0) else arr //<span class="strong"><strong>2</strong></span>
}

def <span class="strong"><strong>padSize</strong></span>(xtSz: Int, even: Boolean= true): Int = {
  val sz = if( even ) xtSz else xtSz-1  //<span class="strong"><strong>3</strong></span>
  if( (sz &amp; (sz-1)) == 0) 0
  else {
    var bitPos = 0
    do { bitPos += 1 } while( (sz &gt;&gt; bitPos) &gt; 0) //<span class="strong"><strong>4</strong></span>
    (if(even) (1&lt;&lt;bitPos) else (1&lt;&lt;bitPos)+1) - xtSz
  }
}</pre></div><p>The <code class="literal">pad</code> method<a id="id3270000" class="indexterm"/> computes the optimal size of the frequency vector as <span class="emphasis"><em>2<sup>N</sup></em></span> by invoking the <code class="literal">padSize</code> method (line <code class="literal">1</code>). It then concatenates the padding with the original time series or vector of observations (line <code class="literal">2</code>). The <code class="literal">padSize</code> method <a id="id3280000" class="indexterm"/>adjusts the size of the data depending on whether the time series has initially an even or odd number of observations (line <code class="literal">3</code>). It relies on bit operations to find the next radix, <span class="emphasis"><em>N</em></span> (line <code class="literal">4</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note8200"/>Note</h3><p>
<span class="strong"><strong>The while loop</strong></span>
</p><p>Scala developers prefer Scala higher-order methods for collections to implement the iterative computation. However, nothing prevents you from using the traditional <code class="literal">while</code> or <code class="literal">do {…} while</code> loop if either readability or performance is an issue.</p></div><p>The fast implementation of the padding method, <code class="literal">pad</code>, consists of detecting the number of <span class="emphasis"><em>N</em></span> observations as a power of 2 (the next highest radix). The method evaluates if <span class="emphasis"><em>N</em></span> and <span class="emphasis"><em>(N-1)</em></span> are zero after it shifts the number of bits in the value, <span class="emphasis"><em>N</em></span>. The code illustrates the effective use of implicit conversion to make the code readable in the <code class="literal">pad</code> method:</p><div class="informalexample"><pre class="programlisting"> val arr: DblVector = vec.map(_.toDouble)</pre></div><p>The next step is to write the <code class="literal">DFT</code> class for the real sine and cosine discrete transforms by subclassing <code class="literal">DTransform</code>. The class relies on the padding mechanism implemented in <code class="literal">DTransform</code> whenever necessary:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DFT</strong></span>[@specialized(Double) T &lt;: AnyVal](
    eps: Double)(implicit f: T =&gt; Double)
    extends <span class="strong"><strong>ETransform</strong></span>[Double](eps) with DTransform { //<span class="strong"><strong>5</strong></span>
  type <span class="strong"><strong>U</strong></span> = XSeries[T]   //<span class="strong"><strong>6</strong></span>
  type <span class="strong"><strong>V</strong></span> = DblVector
  
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = { //<span class="strong"><strong>7</strong></span>
    case xv: U if(xv.size &gt;= 2) =&gt; fwrd(xv).map(_._2.toVector) 
  }
}</pre></div><p>We treat the discrete Fourier transform as a transformation on the time series using an explicit <code class="literal">ETransform</code> configuration (line <code class="literal">5</code>). The <code class="literal">U</code> data type of the input and the <code class="literal">V</code> type of the output have to be defined (line <code class="literal">6</code>). The <code class="literal">|&gt;</code> transformation function delegates the computation to the <code class="literal">fwrd</code> method (line <code class="literal">7</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>fwrd</strong></span>(xv: U): Try[(RealTransformer, DblArray)] = {
  val rdt = if(Math.abs(xv.head) &lt; config)  //<span class="strong"><strong>8</strong></span>
      new FastSineTransformer(SINE)  //<span class="strong"><strong>9</strong></span>
  else  new FastCosineTransformer(COSINE)  //<span class="strong"><strong>10</strong></span>
  
  val padded = pad(xv.map(_.toDouble), xv.head == 0.0).toArray
  Try( (rdt, rdt.transform(padded, FORWARD)) )
}</pre></div><p>The <code class="literal">fwrd</code> method <a id="id3290000" class="indexterm"/>selects the discrete Fourier<a id="id3300000" class="indexterm"/> sine series if the first value of the time series is 0.0, otherwise it selects the discrete cosine series. This implementation automates the selection of the appropriate series by evaluating <code class="literal">xt.head</code> (line <code class="literal">8</code>). The transformation invokes the <code class="literal">FastSineTransformer</code> (line <code class="literal">9</code>) and <code class="literal">FastCosineTransformer</code> (line <code class="literal">10</code>) classes of the Apache Commons Math library [3:8] introduced in the first chapter.</p><p>This example uses the standard formulation of the cosine and sine transformations, defined by the <code class="literal">COSINE</code> argument. The orthogonal normalization that normalizes the frequency by a factor of <span class="emphasis"><em>1/sqrt(2(N-1))</em></span>, where <span class="emphasis"><em>N</em></span> is the size of the time series, generates a cleaner frequency spectrum for a higher computation cost.</p><div class="note" title="Note"><h3 class="title"><a id="note8300"/>Note</h3><p>
<span class="strong"><strong>The @specialized annotation</strong></span>
</p><p>The <code class="literal">@specialized(Double)</code> annotation is used to instruct the Scala compiler to generate a specialized and more efficient version of the class for the <code class="literal">Double</code> type. The drawback of the specialization is the duplication of byte code as the specialized version coexists with the parameterized classes [3:9].</p></div><p>In order to illustrate the different concepts behind DFTs, let's consider the case of a time series generated by a <code class="literal">h</code> sequence of sinusoidal functions:</p><div class="informalexample"><pre class="programlisting">val F = Array[Double](2.0, 5.0, 15.0)
val A = Array[Double](2.0, 1.0, 0.33)

def harmonic(x: Double, n: Int): Double =  
      A(n)*Math.cos(Math.PI*F(n)*x)
val <span class="strong"><strong>h</strong></span> = (x: Double) =&gt; 
    Range(0, A.size).aggregate(0.0)((s, i) =&gt; 
          s + harmonic(x, i), _ + _)</pre></div><p>As the signal <a id="id3310000" class="indexterm"/>is synthetically created, we can select the size of the time series to avoid padding. The first value in the time series is not null, so the number of observations is <span class="emphasis"><em>2<sup>n</sup>+1</em></span>. The data generated by the <span class="emphasis"><em>h</em></span> function is plotted as follows:</p><div class="mediaobject"><img src="../Images/image01299.jpeg" alt="Discrete Fourier transform"/><div class="caption"><p>An example of sinusoidal time series</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's <a id="id3320000" class="indexterm"/>extract the frequencies' spectrum for the time series generated by the <code class="literal">h</code> function. The data points are created by tabulating the <code class="literal">h</code> function. The frequencies spectrum is computed with a simple invocation of the explicit <code class="literal">|&gt; </code>data transformation of the <code class="literal">DFT</code> class:</p><div class="informalexample"><pre class="programlisting">val OUTPUT1 = "output/chap3/simulated.csv"
val OUTPUT2 = "output/chap3/smoothed.csv"
val FREQ_SIZE = 1025; val INV_FREQ = 1.0/FREQ_SIZE

val <span class="strong"><strong>pfnDFT</strong></span> = DFT[Double] <span class="strong"><strong>|&gt;</strong></span> //<span class="strong"><strong>11</strong></span>
for {
  values &lt;- Try(Vector.tabulate(FREQ_SIZE)
               (n =&gt; <span class="strong"><strong>h</strong></span>(n*INV_FREQ))) //<span class="strong"><strong>12</strong></span>
  output1 &lt;- DataSink[Double](OUTPUT1).write(values)
  spectrum &lt;- pfnDFT(values)
  output2 &lt;- DataSink[Double](OUTPUT2).write(spectrum) //<span class="strong"><strong>13</strong></span>
} yield {
  val results = format(spectrum.take(DISPLAY_SIZE), 
"x/1025", SHORT)
  show(s"$DISPLAY_SIZE frequencies: ${results}")
}</pre></div><p>The <a id="id3330000" class="indexterm"/>execution of the data simulator <a id="id3340000" class="indexterm"/>follows these steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Generate a raw data with the 3-harmonic <code class="literal">h</code> function (line <code class="literal">12</code>).</li><li class="listitem">Instantiate the partial function generated by the transformation (line <code class="literal">11</code>).</li><li class="listitem">Store the resulting frequencies in a data sink (filesystem) (line <code class="literal">13</code>).</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note8400"/>Note</h3><p>
<span class="strong"><strong>Data sinks and spreadsheets</strong></span>
</p><p>In this particular case, the results of the discrete Fourier transform are dumped into a CSV file so that it can be loaded into a spreadsheet. Some spreadsheets support a set of filtering techniques that can be used to validate the result of the example. A simpler alternative would be to use JFreeChart.</p></div><p>The spectrum of frequencies of the time series, plotted for the first 32 points, clearly shows three frequencies at <span class="emphasis"><em>k = 2</em></span>, <span class="emphasis"><em>5</em></span>, and <span class="emphasis"><em>15</em></span>. This result is expected because the original signal is composed of three sinusoidal functions. The amplitude of these frequencies are 1024/1, 1024/2, and 1024/6, respectively. The following plot represents the first 32 harmonics for the time series:</p><div class="mediaobject"><img src="../Images/image01300.jpeg" alt="Discrete Fourier transform"/><div class="caption"><p>The frequency spectrum for a three-frequency sinusoidal</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id3350000" class="indexterm"/>next step is to use the frequencies <a id="id3360000" class="indexterm"/>spectrum to create a low-pass filter using DFT. There are many algorithms available to implement a low or pass band filter in the time domain, from autoregressive models to the Butterworth algorithm. However, the discrete Fourier transform is still a very popular technique to smooth signals and identify trends.</p><div class="note" title="Note"><h3 class="title"><a id="note8500"/>Note</h3><p>
<span class="strong"><strong>Big Data</strong></span>
</p><p>A DFT for a large time series can be very computation intensive. One option is to treat the time series as a continuous signal and sample it using the <span class="strong"><strong>Nyquist</strong></span> frequency. The Nyquist frequency is half of the sampling rate of a continuous signal.</p></div></div><div class="section" title="DFT-based filtering"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5500"/>DFT-based filtering</h2></div></div></div><p>The <a id="id3370000" class="indexterm"/>purpose of this section is to introduce, describe, and<a id="id3380000" class="indexterm"/> implement a noise filtering mechanism that leverages the discrete Fourier transform. The idea is quite simple: the forward and inverse Fourier series are used sequentially to convert the raw data from the time domain to the frequency domain and back. The only input you need to supply is a function <span class="emphasis"><em>g</em></span> that modifies the sequence of frequencies. This operation is known as the convolution of the filter <span class="emphasis"><em>g</em></span> and the frequencies' spectrum.</p><p>A <a id="id3390000" class="indexterm"/>convolution is similar to an inner product of two time series<a id="id3400000" class="indexterm"/> in the frequencies domain. Mathematically, the convolution is defined as follows:</p><div class="note" title="Note"><h3 class="title"><a id="note8600"/>Note</h3><p>
<span class="strong"><strong>Convolution</strong></span>
</p><p>M10: The convolution of two functions <span class="emphasis"><em>f</em></span> and <span class="emphasis"><em>g</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01301.jpeg" alt="DFT-based filtering"/></div><p style="clear:both; height: 1em;"> </p><p>M11: The convolution <span class="emphasis"><em>F</em></span> of a time series <span class="emphasis"><em>x = (x<sub>i</sub>}</em></span> with a frequency spectrum <span class="emphasis"><em>ω<sup>x</sup></em></span> and a filter <span class="emphasis"><em>f</em></span> in frequency domain <span class="emphasis"><em>ω<sup>f</sup></em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01302.jpeg" alt="DFT-based filtering"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's apply the convolution to our filtering problem. The filtering algorithm using the discrete Fourier transform consists of five steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Pad the time series to enable the discrete sine or cosine transform.</li><li class="listitem">Generate the ordered sequence of frequencies using the forward transform <span class="emphasis"><em>F</em></span>.</li><li class="listitem">Select the filter function <span class="emphasis"><em>G</em></span> in the frequency domain and a cutoff frequency.</li><li class="listitem">Convolute the sequence of frequency with the filter function <span class="emphasis"><em>G</em></span>.</li><li class="listitem">Generate the filtered signal in the time domain by applying the inverse DFT transform to the convoluted frequencies.<div class="mediaobject"><img src="../Images/image01303.jpeg" alt="DFT-based filtering"/><div class="caption"><p>A diagram of the discrete Fourier filter</p></div></div><p style="clear:both; height: 1em;"> </p></li></ol><div style="height:10px; width: 1px"/></div><p>The most <a id="id3410000" class="indexterm"/>commonly used low-pass filter functions are known as the <code class="literal">sinc</code> and <code class="literal">sinc2</code> functions, which are defined as a rectangular function and <a id="id3420000" class="indexterm"/>triangular function, respectively. These functions are partially applied functions that are derived from a generic <code class="literal">convol</code> method. The simplest <code class="literal">sinc</code> function returns <code class="literal">1</code> for frequencies below a cutoff frequency, <code class="literal">fC</code>, and <code class="literal">0</code> if the frequency is higher:</p><div class="informalexample"><pre class="programlisting">val convol = (n: Int, f: Double, fC: Double) =&gt; 
     if( Math.pow(f, n) &lt; fC) 1.0 else 0.0
val <span class="strong"><strong>sinc</strong></span> = convol(1, _: Double, _:Double)
val <span class="strong"><strong>sinc2</strong></span> = convol(2, _: Double, _:Double)
val sinc4 = convol(4, _: Double, _:Double)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note8800"/>Note</h3><p>
<span class="strong"><strong>Partially applied functions versus partial functions</strong></span>
</p><p>Partial functions and partially applied functions are not actually related.</p><p>A partial function <span class="emphasis"><em>f'</em></span> is a function that is applied to a subset <span class="emphasis"><em>X'</em></span> of the input space <span class="emphasis"><em>X</em></span>. It does not execute all possible input values:</p><div class="mediaobject"><img src="../Images/image01304.jpeg" alt="DFT-based filtering"/></div><p style="clear:both; height: 1em;"> </p><p>A partially applied function <span class="emphasis"><em>f"</em></span> is a function value for which the user supplies the value for one or more arguments. The projection reduces the dimension of the input space <span class="emphasis"><em>(X, Z)</em></span>:</p><div class="mediaobject"><img src="../Images/image01305.jpeg" alt="DFT-based filtering"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <code class="literal">DFTFilter</code> class<a id="id3430000" class="indexterm"/> inherits from the <code class="literal">DFT</code> class in order to reuse the <code class="literal">fwrd</code> forward transform function. The <code class="literal">g</code> frequency domain function is an attribute of the filter. The <code class="literal">g</code> function takes the <code class="literal">fC</code> frequency<a id="id3440000" class="indexterm"/> cutoff value as the second argument (line <code class="literal">14</code>). The two <code class="literal">sinc</code> and <code class="literal">sinc2</code> filters defined in the previous section are examples of filtering functions:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DFTFilter</strong></span>[@specialized(Double) T &lt;: AnyVal]( 
    <span class="strong"><strong>fC</strong></span>: Double,
    eps: Double)
    (<span class="strong"><strong>g</strong></span>: (Double, Double) =&gt;Double)(implicit f: T =&gt; Double)
  extends <span class="strong"><strong>DFT</strong></span>[T](eps) { //<span class="strong"><strong>14</strong></span>

  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
    case xt: U if( xt.size &gt;= 2 ) =&gt; {
      <span class="strong"><strong>fwrd</strong></span>(xt).map{ case(trf, freq) =&gt; {  //<span class="strong"><strong>15</strong></span>
        val cutOff = fC*freq.size
        val filtered = freq.zipWithIndex
                     .map{ case(x, n) =&gt; x*g(n, cutOff) } //<span class="strong"><strong>16</strong></span>
        trf.transform(filtered, <span class="strong"><strong>INVERSE</strong></span>).toVector }) //<span class="strong"><strong>17</strong></span>
    }
  }
}</pre></div><p>The filtering process follows three steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Computation of the <code class="literal">fwrd</code> discrete Fourier forward transformation (sine or cosine) (line <code class="literal">15</code>).</li><li class="listitem">Apply the filter function (formula <span class="strong"><strong>M11</strong></span>) through a Scala <code class="literal">map</code> method (line <code class="literal">16</code>).</li><li class="listitem">Apply the inverse transform to the frequencies (line <code class="literal">17</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>Let's evaluate the impact of the cutoff values on the filtered data. The implementation of the test program consists of loading the data from the file (line <code class="literal">19</code>) and then invoking the <code class="literal">DFTFilter</code> of the <code class="literal">pfnDFTfilter</code> partial function (line <code class="literal">19</code>):</p><div class="informalexample"><pre class="programlisting">import YahooFinancials._

val inputFile = s"$RESOURCE_PATH$symbol.csv"
val src = DataSource(input, false, true, 1)
val CUTOFF = 0.005
val <span class="strong"><strong>pfnDFTfilter</strong></span> = DFTFilter[Double](CUTOFF)(sinc) |&gt;
for {
  price &lt;- src.<span class="strong"><strong>get</strong></span>(adjClose)  //<span class="strong"><strong>18</strong></span>
  filtered &lt;- pfnDFTfilter(price)  //<span class="strong"><strong>19</strong></span>
} 
yield { /* ... */ }</pre></div><p>Filtering out <a id="id3450000" class="indexterm"/>the noise is accomplished by selecting the cutoff <a id="id3460000" class="indexterm"/>value between any of the three harmonics with the respective frequencies of 2, 5, and 15. The original and the two filtered time series are plotted on the following graph:</p><div class="mediaobject"><img src="../Images/image01306.jpeg" alt="DFT-based filtering"/><div class="caption"><p>Plotting of the discrete Fourier filter-based smoothing</p></div></div><p style="clear:both; height: 1em;"> </p><p>As you would expect, the low-pass filter with a cutoff value of 12 eliminates the noise with the highest frequencies. The filter with the cutoff value 4 cancels out the second harmonic (low-frequency noise), leaving out only the main trend cycle.</p></div><div class="section" title="Detection of market cycles"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5600"/>Detection of market cycles</h2></div></div></div><p>Using the <a id="id3470000" class="indexterm"/>discrete Fourier transform to generate the frequencies spectrum of a periodical time series is easy. However, what about real-world signals such as the time series that represent the historical price of a stock?</p><p>The purpose of the next exercise is to detect, if any, the long term cycle(s) of the overall stock market by applying the discrete Fourier transform to the quote of the S&amp;P 500 index between January 1, 2009 and December 31, 2013, as illustrated in the following graph:</p><div class="mediaobject"><img src="../Images/image01307.jpeg" alt="Detection of market cycles"/><div class="caption"><p>Historical S&amp;P 500 index prices</p></div></div><p style="clear:both; height: 1em;"> </p><p>The first step is to apply the DFT to extract a frequencies spectrum for the S&amp;P 500 historical prices, as shown in the following graph, with the first 32 harmonics:</p><div class="mediaobject"><img src="../Images/image01308.jpeg" alt="Detection of market cycles"/><div class="caption"><p>Frequencies spectrum for the historical S&amp;P index</p></div></div><p style="clear:both; height: 1em;"> </p><p>The frequency<a id="id3480000" class="indexterm"/> domain chart highlights some interesting characteristics regarding the S&amp;P 500 historical prices:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Both positive and negative amplitudes are present, as you would expect in a time series with complex values. The cosine series contributes to the positive amplitudes while the sine series affects both positive and negative amplitudes, <span class="emphasis"><em>(cos(x+π) = sin(x))</em></span>.</li><li class="listitem">The decay of the amplitude along the frequencies is steep enough to warrant further analysis beyond the first harmonic, which represents the main trend of the historical stock price. The next step is to apply a band-pass filter technique to the S&amp;P 500 historical data in order to identify short-term trends with lower periodicity.</li></ul></div><p>A low-pass filter is limited to reduce or cancel out the noise in the raw data. In this case, a band-pass filter using a range or window of frequencies is appropriate to isolate the frequency or the group of frequencies that characterize a specific cycle. The <code class="literal">sinc</code> function, which was introduced in the previous section to implement a low-pass filter, is modified to enforce the band-pass filter within a window, <span class="emphasis"><em>[w<sub>1</sub>, w<sub>2</sub>]</em></span>, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>sinc</strong></span>(f: Double, w: (Double, Double)): Double = 
    if(f &gt; w._1 &amp;&amp; f &lt; w._2) 1.0 else 0.0</pre></div><p>Let's define a DFT-based band-pass filter with a window of width 4, <span class="emphasis"><em>w=(i, i+4)</em></span>, with <span class="emphasis"><em>i</em></span> ranging <a id="id3490000" class="indexterm"/>between 2 and 20. Applying the window <span class="emphasis"><em>[4, 8]</em></span> isolates the impact of the second harmonic on the price. As we eliminate the main upward trend with frequencies less than 4, all the filtered data varies within a short range relative to the main trend. The following graph shows the output of this filter:</p><div class="mediaobject"><img src="../Images/image01309.jpeg" alt="Detection of market cycles"/><div class="caption"><p>The output of a band-pass DFT filter range 4-8 on the historical S&amp;P index</p></div></div><p style="clear:both; height: 1em;"> </p><p>In this case, we filter the S&amp;P 500 index around the third group of harmonics with frequencies ranging from 18 to 22; the signal is converted into a familiar sinusoidal function, as shown here:</p><div class="mediaobject"><img src="../Images/image01310.jpeg" alt="Detection of market cycles"/><div class="caption"><p>The output of a band-pass DFT filter range 18-22 on the historical S&amp;P index</p></div></div><p style="clear:both; height: 1em;"> </p><p>There is<a id="id3500000" class="indexterm"/> a possible rational explanation for the shape of the S&amp;P 500 data filtered by a band-pass filter with a frequency of 20, as illustrated in the previous graph. The S&amp;P 500 historical data plot shows that the frequency of the fluctuation in the middle of the uptrend (trading sessions 620 to 770) increases significantly.</p><p>This phenomenon can be explained by the fact that the S&amp;P 500 index reaches a resistance level around the trading session 545 when the existing uptrend breaks. A tug of war starts between the bulls, betting the market nudges higher, and the bears, who are expecting a correction. The back and forth between the traders ends when the S&amp;P 500 index breaks through its resistance and resumes a strong uptrend characterized by a high amplitude low frequency, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01311.jpeg" alt="Detection of market cycles"/><div class="caption"><p>An illustration of support and resistance levels for the historical S&amp;P 500 index prices</p></div></div><p style="clear:both; height: 1em;"> </p><p>One of the <a id="id3510000" class="indexterm"/>limitations of using the discrete Fourier-based filters to clean up data is that it requires the data scientist to extract the frequencies spectrum and modify the filter on a regular basis, as he or she is never sure that the most recent batch of data does not introduce noise with a different frequency. The Kalman filter addresses this limitation.</p></div></div>
<div class="section" title="The discrete Kalman filter"><div class="titlepage" id="aid-56SIE2"><div><div><h1 class="title"><a id="ch03lvl1sec2800"/>The discrete Kalman filter</h1></div></div></div><p>The <a id="id3520000" class="indexterm"/>Kalman filter is a mathematical model that provides an accurate and recursive computation approach to estimate the previous states and predict the future states of a process for which some variables may be unknown. R.E. Kalman introduced it in the early 60s to model dynamics systems and predict a trajectory in aerospace [3:10]. Today, the Kalman filter is used to discover a relationship between two observed variables that may or may not be associated with other hidden variables. In this respect, the Kalman filter shares some similarities with the Hidden Markov models, as described in the <span class="emphasis"><em>The hidden Markov model</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span> [3:11].</p><p>The Kalman filter is used as:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A predictor of the next data point from the current observation</li><li class="listitem">A filter that weeds out noise by processing the last two observations</li><li class="listitem">A smoothing model that identifies trends from a history of observations</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note9000"/>Note</h3><p>
<span class="strong"><strong>Smoothing versus filtering</strong></span>
</p><p>Smoothing is an operation that removes high-frequency fluctuations from a time series or signal. Filtering consists of selecting a range of frequencies to process the data. In this regard, smoothing is somewhat similar to low-pass filtering. The only difference is that a low-pass filter is usually implemented through linear methods.</p></div><p>Conceptually, the <a id="id3530000" class="indexterm"/>Kalman filter estimates the state of a system from noisy observations. The Kalman filter has two characteristics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Recursive</strong></span>: A <a id="id3540000" class="indexterm"/>new state is predicted and corrected using the input of a previous state</li><li class="listitem"><span class="strong"><strong>Optimal</strong></span>: This is an optimal estimator<a id="id3550000" class="indexterm"/> because it minimizes the mean square error of the estimated parameters (against actual values)</li></ul></div><p>The Kalman filter is one of the stochastic models that are used in adaptive control [3:12].</p><div class="note" title="Note"><h3 class="title"><a id="note9100"/>Note</h3><p>
<span class="strong"><strong>Kalman and nonlinear systems</strong></span>
</p><p>The Kalman filter estimates the internal state of a linear dynamic system. However, it can be extended to a nonlinear state space model using linear or quadratic approximation functions. These filters are known as, you guessed it, <a id="id3560000" class="indexterm"/><span class="strong"><strong>Extended Kalman Filters</strong></span> (<span class="strong"><strong>EKF</strong></span>), the theory of which is beyond the scope of this book.</p></div><p>The following section is dedicated to discrete Kalman filters for linear systems, as applied to financial engineering. A continuous signal can be converted to a time series using the Nyquist frequency.</p><div class="section" title="The state space estimation"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5700"/>The state space estimation</h2></div></div></div><p>The<a id="id3570000" class="indexterm"/> Kalman filter model consists of two core elements of a dynamic system: a process that generates data and a measurement that collects data. These<a id="id3580000" class="indexterm"/> elements are referred to as the state space model. Mathematically speaking, the state space model consists of two equations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The transition equation</strong></span>: This describes the dynamics of the system, including the unobserved variables</li><li class="listitem"><span class="strong"><strong>The measurement equation</strong></span>: This describes the relationship between the observed and unobserved variables</li></ul></div><div class="section" title="The transition equation"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3600"/>The transition equation</h3></div></div></div><p>Let's <a id="id3590000" class="indexterm"/>consider a system with a linear state <span class="emphasis"><em>x<sub>t</sub></em></span> of <span class="emphasis"><em>n</em></span> variables and a control input vector <span class="emphasis"><em>u<sub>t</sub></em></span>. The prediction of the state at time <span class="emphasis"><em>t</em></span> is computed by a linear stochastic equation (<span class="strong"><strong>M12</strong></span>):</p><div class="mediaobject"><img src="../Images/image01312.jpeg" alt="The transition equation"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>A<sup>t</sup></em></span> is the square matrix of dimension <span class="emphasis"><em>n</em></span> that represents the transition from a state <span class="emphasis"><em>x<sub>t-1</sub></em></span> at <span class="emphasis"><em>t-1</em></span> to a state <span class="emphasis"><em>x<sub>t</sub></em></span> at <span class="emphasis"><em>t</em></span>. The matrix is intrinsic to the dynamic system under consideration.</li><li class="listitem"><span class="emphasis"><em>B<sub>t</sub></em></span> is a <span class="emphasis"><em>n by n</em></span> matrix that describes the control input model (an external action on the system or model). It is applied to the control vector, <span class="emphasis"><em>u<sub>t</sub></em></span>.</li><li class="listitem"><span class="emphasis"><em>w<sub>t</sub></em></span> represents the noise generated by the system, or from a probabilistic point of view, it represents the uncertainty on the model. It is known as the process white noise.</li></ul></div><p>The control input vector represents the external input (or control) to the state of the system. Most systems, including our financial example later in this chapter, have no external input to the state of the model.</p><div class="note" title="Note"><h3 class="title"><a id="note9200"/>Note</h3><p>
<span class="strong"><strong>A white and Gaussian noise</strong></span>
</p><p>A white noise is a Gaussian noise, following a normal distribution with zero mean.</p></div></div><div class="section" title="The measurement equation"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3700"/>The measurement equation</h3></div></div></div><p>The<a id="id3600000" class="indexterm"/> measurement of <span class="emphasis"><em>m</em></span> values <span class="emphasis"><em>z<sub>t</sub></em></span> of the state of the system is defined by the following equation (M13):</p><div class="mediaobject"><img src="../Images/image01313.jpeg" alt="The measurement equation"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>H<sub>t</sub></em></span> is a <span class="emphasis"><em>m by n</em></span> matrix that models the dependency of the measurement to the state of the system.</li><li class="listitem"><span class="emphasis"><em>v<sub>t</sub></em></span> is the white noise introduced by the measuring devices. Similarly to the process noise, <span class="emphasis"><em>v</em></span> follows a Gaussian distribution with zero mean and a variance <span class="emphasis"><em>R</em></span>, known as the <a id="id3610000" class="indexterm"/><span class="strong"><strong>measurement noise covariance</strong></span>.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note9300"/>Note</h3><p>
<span class="strong"><strong>The time dependency model</strong></span>
</p><p>We cannot assume that the parameters of the generalized discrete Kalman filter, such as the state transition <span class="emphasis"><em>A<sub>t</sub></em></span>, control input <span class="emphasis"><em>B<sub>t</sub></em></span>, and observation matrices (or measurement dependency) <span class="emphasis"><em>H<sub>t</sub></em></span> are independent of time. However, these parameters are constant in most practical applications.</p></div></div></div><div class="section" title="The recursive algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ch03lvl2sec5800"/>The recursive algorithm</h2></div></div></div><p>The<a id="id3620000" class="indexterm"/> set of equations for the discrete Kalman filter <a id="id3630000" class="indexterm"/>is implemented as a recursive computation with two distinct steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The algorithm uses the transition equations to estimate the next observation</li><li class="listitem">The estimation is created with the actual measurement for this observation</li></ul></div><p>The recursion is visualized in the following diagram:</p><div class="mediaobject"><img src="../Images/image01314.jpeg" alt="The recursive algorithm"/><div class="caption"><p>An overview diagram of the recursive Kalman algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's illustrate <a id="id3640000" class="indexterm"/>the prediction and correction phases in the context of filtering financial data, in a manner similar to the moving average and Fourier transform. The objective is to extract the trend and the<a id="id3650000" class="indexterm"/> transitory component of the yield of the 10-year Treasury bond. The Kalman filter is particularly suitable for the analysis of interest rates for two reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Yields are the results of multiple factors, some of which are not directly observable.</li><li class="listitem">Yields are influenced by the policy of the Federal Reserve that can be easily modeled by the control matrix.</li></ul></div><p>The 10-year Treasury bond has a higher trading volume than bonds with longer maturity, making trends in interest rates a bit more reliable [3:13].</p><p>Applying the Kalman filter to clean raw data requires you to define a model that encompasses both observed and non-observed states. In the case of the trend analysis, we can safely create our model with a two-variable state: the current yield <span class="emphasis"><em>x<sub>t</sub></em></span> and the previous yield <span class="emphasis"><em>x<sub>t-1</sub></em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note9400"/>Note</h3><p>
<span class="strong"><strong>The state of dynamic systems</strong></span>
</p><p>The term "state" refers to the state of the dynamic system under consideration and not the state of the execution of the algorithm.</p></div><p>This implementation of the Kalman filter uses the Apache Commons Math library. Therefore, we<a id="id3660000" class="indexterm"/> need to specify the implicit conversion from our primitives, introduced in the <span class="emphasis"><em>Primitives and implicits</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, to the <code class="literal">RealMatrix</code>, <code class="literal">RealVector</code>, <code class="literal">Array2DRowRealMatrix</code>, and <code class="literal">ArrayRealVector</code> Apache Commons Math types:</p><div class="informalexample"><pre class="programlisting">implicit def double2RealMatrix(x: DblMatrix): RealMatrix = 
    new Array2DRowRealMatrix(x)
implicit def double2RealRow(x: DblVector): RealMatrix = 
    new Array2DRowRealMatrix(x)
implicit def double2RealVector(x: DblVector): RealVector = 
    new ArrayRealVector(x)</pre></div><p>The client<a id="id3670000" class="indexterm"/> code has to import the implicit conversion functions within its scope.</p><p>The Kalman model assumes that the process and measurement noise follows a Gaussian distribution, also known as a white noise. For the sake of maintainability, the generation of the white noise is encapsulated in the <code class="literal">QRNoise</code> class with the following arguments (line <code class="literal">1</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">qr</code>: This is the tuple of scale factors for the process noise matrix <span class="emphasis"><em>Q</em></span> and the measurement noise <span class="emphasis"><em>R</em></span></li><li class="listitem"><code class="literal">profile</code>: This is the noise profile with the normal distribution as default</li></ul></div><p>The two <code class="literal">noiseQ</code> and <code class="literal">noiseR</code> methods generate an array of two independent white noise elements (line <code class="literal">2</code>):</p><div class="informalexample"><pre class="programlisting">val normal = Stats.normal(_)
class <span class="strong"><strong>QRNoise</strong></span>(<span class="strong"><strong>qr</strong></span>: DblPair,<span class="strong"><strong>profile</strong></span>: Double=&gt;Double = normal){ //1 
  def q = profile(qr._1)
  def r = profile(qr._2)
  lazy val <span class="strong"><strong>noiseQ</strong></span> = Array[Double](q, q)   //2
  lazy val <span class="strong"><strong>noiseR</strong></span> = Array[Double](r, r)
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note9500"/>Note</h3><p>
<span class="strong"><strong>Experimenting with a noise profile</strong></span>
</p><p>Although the discrete Kalman filter assumes that the noise profile follows a normal distribution, the <code class="literal">QRNoise</code> class allows the user to experiment with different noise profiles.</p></div><p>The easiest approach to manage the matrices and vectors used in the recursion is to define them as arguments of a <code class="literal">kalmanConfig</code> configuration class. The arguments of the configuration follow<a id="id3680000" class="indexterm"/> the naming convention defined in the mathematical formulas: <code class="literal">A</code> is the state transition matrix, <code class="literal">B</code> is the control matrix, <code class="literal">H</code> is the matrix of observations that define the dependencies between the measurement and system state, and <code class="literal">P</code> is the covariance error matrix:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>KalmanConfig</strong></span>(<span class="strong"><strong>A</strong></span>: DblMatrix, <span class="strong"><strong>B</strong></span>: DblMatrix, 
    <span class="strong"><strong>H</strong></span>: DblMatrix, <span class="strong"><strong>P</strong></span>: DblMatrix)</pre></div><p>Let's <a id="id3690000" class="indexterm"/>implement the Kalman filter as a <code class="literal">DKalman</code> transformation of the <code class="literal">ETransform</code> type on a time series with a predefined <code class="literal">KalmanConfig</code> configuration:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DKalman</strong></span>(config: KalmanConfig)(implicit qrNoise: QRNoise) 
            extends <span class="strong"><strong>ETransform</strong></span>[KalmanConfig](config) {
  type <span class="strong"><strong>U</strong></span> = Vector[DblPair]  //<span class="strong"><strong>3</strong></span>
  type <span class="strong"><strong>V</strong></span> = Vector[DblPair]  //<span class="strong"><strong>4</strong></span>
  type KRState = (KalmanFilter, RealVector)  //<span class="strong"><strong>5</strong></span>
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]]
   ...
}</pre></div><p>As with any explicit data transformation, we need to specify the <code class="literal">U</code> and <code class="literal">V</code> types (lines <code class="literal">3</code> and <code class="literal">4</code>), which are identical. The Kalman filter does not alter the structure of the data, it alters only the values. We define an internal state for the <code class="literal">KRState</code> Kalman computation by creating a tuple of two <code class="literal">KalmanFilter</code> and <code class="literal">RealVector</code> (line <code class="literal">5</code>) Apache Commons Math types.</p><p>The key elements of the filter are now in place and it's time to implement the prediction-correction cycle portion of the Kalman algorithm.</p><div class="section" title="Prediction"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3800"/>Prediction</h3></div></div></div><p>The <a id="id3700000" class="indexterm"/>prediction phase consists of estimating the <span class="emphasis"><em>x</em></span> state (yield of the Treasury bond) using the transition equation. We assume that the Federal Reserve has no material effect on the interest rates, making the <span class="emphasis"><em>B</em></span> control input matrix null. The transition equation can be easily resolved using simple operations on matrices:</p><div class="mediaobject"><img src="../Images/image01315.jpeg" alt="Prediction"/><div class="caption"><p>Visualization of the transition equation of the Kalman filter</p></div></div><p style="clear:both; height: 1em;"> </p><p>The purpose of this exercise is to evaluate the impact of the different parameters of the transition matrix <span class="emphasis"><em>A</em></span> in terms of smoothing.</p><div class="note" title="Note"><h3 class="title"><a id="note9600"/>Note</h3><p>
<span class="strong"><strong>The control input matrix B</strong></span>
</p><p>In this example, the control matrix <span class="emphasis"><em>B</em></span> is null because there is no known, deterministic external action on the yield of the 10-year Treasury bond. However, the yield can be affected by unknown parameters that we represent as hidden variables. For example, the matrix <span class="emphasis"><em>B</em></span> can be used to model the decision of the Federal Reserve regarding asset purchases and federal fund rates.</p></div><p>The <a id="id3710000" class="indexterm"/>mathematics behind the Kalman filter presented as a reference to the implementation in Scala, use the same notation for matrices and vectors. It is absolutely not a prerequisite to understand the Kalman filter and its implementation in the next section. If you have a natural inclination toward linear algebra, the following describe the two equations for the prediction step.</p><div class="note" title="Note"><h3 class="title"><a id="note9700"/>Note</h3><p>
<span class="strong"><strong>The prediction step</strong></span>
</p><p>M14: The prediction of the state at time <span class="emphasis"><em>t</em></span> is computed by extrapolating the state estimate:</p><div class="mediaobject"><img src="../Images/image01316.jpeg" alt="Prediction"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>A</em></span> is the square matrix of dimension <span class="emphasis"><em>n</em></span> that represents the transition from state <span class="emphasis"><em>x</em></span> at <span class="emphasis"><em>t-1</em></span> to state <span class="emphasis"><em>x</em></span> at time <span class="emphasis"><em>t</em></span></li><li class="listitem"><span class="emphasis"><em>x'<sub>t</sub></em></span> is the predicted state of the system based on the current state and the model <span class="emphasis"><em>A</em></span></li><li class="listitem"><span class="emphasis"><em>B</em></span> is the vector of <span class="emphasis"><em>n</em></span> dimension that describes the input to the state</li></ul></div><p>M15: The mean square error matrix, <span class="emphasis"><em>P</em></span>, which is to be minimized, is updated using the following formula:</p><div class="mediaobject"><img src="../Images/image01317.jpeg" alt="Prediction"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>A<sup>T</sup></em></span> is the transpose of the state transition matrix</li><li class="listitem"><span class="emphasis"><em>Q</em></span> is the process white noise described as a Gaussian distribution with a zero mean and a variance <span class="emphasis"><em>Q</em></span>, known as the noise covariance</li></ul></div></div><p>The <a id="id3720000" class="indexterm"/>state transition matrix is implemented using the matrix and vector classes included in the Apache Commons Math library. The types of matrices and vectors are automatically converted into the <code class="literal">RealMatrix</code> and <code class="literal">RealVector</code> classes.</p><p>The implementation of the equation <span class="strong"><strong>M14</strong></span> is as follows:</p><div class="informalexample"><pre class="programlisting">x = A.operate(x).add(qrNoise.create(0.03, 0.1))</pre></div><p>The new state is predicted (or estimated), and then used as an input to the correction step.</p></div><div class="section" title="Correction"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec3900"/>Correction</h3></div></div></div><p>The<a id="id3730000" class="indexterm"/> second step of the recursive Kalman algorithm is the correction of the estimated yield of the 10-year Treasury bond with the actual yield. In this example, the white noise of the measurement is negligible. The measurement equation is simple because the state is represented by the current and previous yield and their measurement, <span class="emphasis"><em>z</em></span>:</p><div class="mediaobject"><img src="../Images/image01318.jpeg" alt="Correction"/><div class="caption"><p>Visualization of the measurement equation of the Kalman filter</p></div></div><p style="clear:both; height: 1em;"> </p><p>The sequence of mathematical equations of the correction phase consists of updating the estimation of the state <span class="emphasis"><em>x</em></span> using the actual values <span class="emphasis"><em>z</em></span> and computing the Kalman gain, <span class="emphasis"><em>K</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note9900"/>Note</h3><p>
<span class="strong"><strong>The correction step</strong></span>
</p><p>M16: The state of the system <span class="emphasis"><em>x</em></span> is estimated from the actual measurement <span class="emphasis"><em>z</em></span> using the following formula:</p><div class="mediaobject"><img src="../Images/image01319.jpeg" alt="Correction"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>r<sub>t</sub></em></span> is the residual between the predicted measurement and the actual measured values</li><li class="listitem"><span class="emphasis"><em>K<sub>t</sub></em></span> is the Kalman gain for the correction factor</li></ul></div><p>M17: The Kalman gain is computed as:</p><div class="mediaobject"><img src="../Images/image01320.jpeg" alt="Correction"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>H<sup>T</sup></em></span> is the matrix transpose of <span class="emphasis"><em>H</em></span> and <span class="emphasis"><em>P<sub>t</sub>'</em></span> is the estimate of the error covariance.</p></div></div><div class="section" title="Kalman smoothing"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec4000"/>Kalman smoothing</h3></div></div></div><p>It is time <a id="id3740000" class="indexterm"/>to put our knowledge <a id="id3750000" class="indexterm"/>of the transition and measurement equations to test. The Apache Commons Math library defines the two <code class="literal">DefaultProcessModel</code> and <code class="literal">DefaultMeasurementModel</code> classes to encapsulate the components of the matrices and vectors. The historical values for the yield of the 10-year Treasury bond are loaded through the <code class="literal">DataSource</code> method and mapped to the smoothed series that is the output of the filter:</p><div class="informalexample"><pre class="programlisting">  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
    case xt: U if( !xt.isEmpty) =&gt; Try( 
      xt.map { case(current, prev) =&gt; {
        val <span class="strong"><strong>models</strong></span> = <span class="strong"><strong>initialize</strong></span>(current, prev) //<span class="strong"><strong>6</strong></span>
        val nState = <span class="strong"><strong>newState</strong></span>(models) //<span class="strong"><strong>7</strong></span>
        (nState(0), nState(1))  //<span class="strong"><strong>8</strong></span>
      }}
    ) 
   }</pre></div><p>The data transformation for the Kalman filter initializes the process and measurement model for <a id="id3760000" class="indexterm"/>each data point in the private <code class="literal">initialize</code> (line <code class="literal">6</code>) method, updates the state using the transition and correction equations iteratively in the <code class="literal">newState</code> method (line <code class="literal">7</code>), and returns the filtered series of pair values (line <code class="literal">8</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note10200"/>Note</h3><p>
<span class="strong"><strong>Exception handling</strong></span>
</p><p>The code to catch and process exceptions thrown by the Apache Commons Math library is omitted as the standard practice in the book. As far as the execution of the Kalman filter is concerned, the following exceptions have to be handled:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">NonSquareMatrixException</code></li><li class="listitem"><code class="literal">DimensionMismatchException</code></li><li class="listitem"><code class="literal">MatrixDimensionMismatchException</code></li></ul></div></div><p>The <code class="literal">initialize</code> method <a id="id3770000" class="indexterm"/>encapsulates the initialization of the <code class="literal">pModel</code> process model (line <code class="literal">9</code>) and the <code class="literal">mModel</code> measurement (observations dependencies) model (line <code class="literal">10</code>), as defined in the Apache Commons Math library:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>initialize</strong></span>(current: Double, prev: Double): KRState = {  
  val pModel = new <span class="strong"><strong>DefaultProcessModel</strong></span>(config.A, config.B, 
                Q, input, config.P) //<span class="strong"><strong>9</strong></span>
  val mModel = new <span class="strong"><strong>DefaultMeasurementModel</strong></span>(config.H, R) //<span class="strong"><strong>10</strong></span>
  val in = Array[Double](current, prev)
  (new KalmanFilter(pModel,mModel), new ArrayRealVector(in))
}</pre></div><p>The exceptions thrown by the Apache Commons Math API are caught and processed through the <code class="literal">Try</code> monad. The iterative prediction and correction of the smoothed yields of 10-year Treasury bond is implemented by the <code class="literal">newState</code> method. The method iterates through the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Estimate the new values of the state by invoking the Apache Commons Math <code class="literal">KalmanFilter.predict</code> method that implements the <span class="strong"><strong>M14</strong></span> formula (line <code class="literal">11</code>).</li><li class="listitem">Apply the <span class="strong"><strong>M12</strong></span> formula to the new state <span class="emphasis"><em>x</em></span> at time <span class="emphasis"><em>t</em></span> (line <code class="literal">12</code>).</li><li class="listitem">Compute the measured value <span class="emphasis"><em>z</em></span> at time <span class="emphasis"><em>t</em></span> using the <span class="strong"><strong>M13</strong></span> formula (line <code class="literal">13</code>).</li><li class="listitem">Invoke the Apache Commons Math <code class="literal">KalmanFilter.correct</code> method to implement the <span class="strong"><strong>M16 </strong></span>formula (line <code class="literal">14</code>).</li><li class="listitem">Return the estimated value of the state <span class="emphasis"><em>x</em></span> by invoking the Apache Commons Math <code class="literal">KalmanFilter.getStateEstimation</code> method (line <code class="literal">15</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The <a id="id3780000" class="indexterm"/>code <a id="id3790000" class="indexterm"/>will be as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>newState</strong></span>(state: KRState): DblArray = {
  state._1.predict  //<span class="strong"><strong>11</strong></span>
  val x = config.A.operate(state._2).add(qrNoise.noisyQ) //<span class="strong"><strong>12</strong></span>
  val z = config.H.operate(x).add(qrNoise.noisyR) //<span class="strong"><strong>13</strong></span>
  state._1.correct(z)  //<span class="strong"><strong>14</strong></span>
  state._1.getStateEstimation  //<span class="strong"><strong>15</strong></span>
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note10300"/>Note</h3><p>
<span class="strong"><strong>The exit condition</strong></span>
</p><p>In the code snippet for the <code class="literal">newState</code> method, the iteration for specific data points exits when the maximum number of iterations is reached. A more elaborate implementation consists of either evaluating the matrix <span class="emphasis"><em>P</em></span> at each iteration or estimation converged within a predefined range.</p></div></div><div class="section" title="Fixed lag smoothing"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec4100"/>Fixed lag smoothing</h3></div></div></div><p>So far, we <a id="id3800000" class="indexterm"/>have studied the Kalman filtering algorithm. We need to adapt it to the smoothing of a time series. The <span class="strong"><strong>fixed lag smoothing</strong></span>
<a id="id3810000" class="indexterm"/> technique consists of backward correcting previous data points, taking into account the latest actual value.</p><p>A N-lag smoother defines the input as a vector <span class="emphasis"><em>X = {x<sub>t-N-1</sub>, x<sub>t-N-2</sub>, …, x<sub>t</sub>}</em></span> for which the value <span class="emphasis"><em>x<sub>t-N-j</sub></em></span> is corrected taking into account the current value of <span class="emphasis"><em>x<sub>t</sub></em></span>.</p><p>The strategy is quite similar to the hidden Markov model forward and backward passes (refer to the <span class="emphasis"><em>Evaluation – CF-1</em></span> section under <span class="emphasis"><em>The hidden Markov model</em></span> in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>).</p><div class="note" title="Note"><h3 class="title"><a id="note10400"/>Note</h3><p>
<span class="strong"><strong>Complex strategies for lag smoothing</strong></span>
</p><p>There are numerous formulas or methodologies to implement an accurate fixed lag smoothing strategy and correct the predicted observations. Such strategies are beyond the scope of this book.</p></div></div><div class="section" title="Experimentation"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec4200"/>Experimentation</h3></div></div></div><p>The <a id="id3820000" class="indexterm"/>objective is to smoothen the yield of the 10-year Treasury bond using a <a id="id3830000" class="indexterm"/><span class="strong"><strong>two-step lag smoothing</strong></span> algorithm.</p><div class="note" title="Note"><h3 class="title"><a id="note10500"/>Note</h3><p>
<span class="strong"><strong>The two-step lag smoothing</strong></span>
</p><p>M18: The two-step lag smoothing algorithm for state <span class="emphasis"><em>St</em></span> using a single smoothing factor <span class="emphasis"><em>α</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01321.jpeg" alt="Experimentation"/></div><p style="clear:both; height: 1em;"> </p></div><p>The state equation updates the values of the state <span class="emphasis"><em>[x<sub>t</sub>, x<sub>t-1</sub>]</em></span> using the previous state <span class="emphasis"><em>[x<sub>t-1</sub>, x<sub>t-2</sub>]</em></span>, where <span class="emphasis"><em>x<sub>t</sub></em></span> represents the yield of the 10-year Treasury bond at time <span class="emphasis"><em>t</em></span>. This is accomplished by shifting the values of the original time series <span class="emphasis"><em>{x<sub>0</sub> … x<sub>n-1</sub>}</em></span> by 1 using the drop method, <span class="emphasis"><em>X<sub>1</sub></em></span>
<span class="emphasis"><em>={x<sub>1</sub>, …, x<sub>n-1</sub>}</em></span>, creating a copy of the original time series without the last element <span class="emphasis"><em>X<sub>2</sub>={x<sub>0</sub>, …, x<sub>n-2</sub>}</em></span>, and zipping <span class="emphasis"><em>X<sub>1</sub></em></span> and <span class="emphasis"><em>X<sub>2</sub></em></span>. This process is implemented by the <code class="literal">zipWithShift</code> method, which is introduced in the first section of the chapter.</p><p>The resulting sequence of a state vector <span class="emphasis"><em>S<sub>k</sub> = [x<sub>k</sub>, x<sub>k-1</sub>]<sup>T</sup></em></span> is processed by the Kalman algorithm, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">Import YahooFinancials._ 
val RESOURCE_DIR = "resources/data/chap3/"
implicit val <span class="strong"><strong>qrNoise</strong></span> = new QRNoise((0.7, 0.3)) //<span class="strong"><strong>16</strong></span>

val <span class="strong"><strong>H</strong></span>: DblMatrix = ((0.9, 0.0), (0.0, 0.1))    //<span class="strong"><strong>17</strong></span>
val <span class="strong"><strong>P0</strong></span>: DblMatrix = ((0.4, 0.3), (0.5, 0.4))   //<span class="strong"><strong>18</strong></span>
val <span class="strong"><strong>ALPHA1</strong></span> = 0.5; val <span class="strong"><strong>ALPHA2</strong></span> = 0.8
val src = DataSource(s"${RESOURCE_DIR}${symbol}.csv", false)

(src.get(adjClose)).map(zt =&gt; {  //<span class="strong"><strong>19</strong></span>
   twoStepLagSmoother(zt, ALPHA1)     //<span class="strong"><strong>20</strong></span>
   twoStepLagSmoother(zt, ALPHA2)
})</pre></div><div class="note" title="Note"><h3 class="title"><a id="note10600"/>Note</h3><p>
<span class="strong"><strong>An implicit noise instance</strong></span>
</p><p>The noise for the process and measurement is defined as an implicit argument to the <code class="literal">DKalman</code> Kalman filter for the following two reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The profile of the noise is specific to the process or system under evaluation and its measurement; it is independent of the <code class="literal">A</code>, <code class="literal">B</code>, and <code class="literal">H</code> Kalman configuration parameters. Therefore, it cannot be a member of the <code class="literal">KalmanConfig</code> class.</li><li class="listitem">The same noise characteristics should be shared with other alternative filtering techniques, if needed.</li></ul></div></div><p>The white <a id="id3840000" class="indexterm"/>noise for the process and measurement is initialized implicitly with the <code class="literal">qrNoise</code> value (line <code class="literal">16</code>). The code initializes the matrices <code class="literal">H</code> of the measurement dependencies on the state (line <code class="literal">17</code>) and <code class="literal">P0</code> that contains the initial covariance errors (line <code class="literal">18</code>). The input data is extracted from a CSV file that contains the daily Yahoo financial data (line <code class="literal">19</code>). Finally, the method executes the <code class="literal">twoStepLagSmoother</code> two-step lag smoothing algorithm with two different <code class="literal">ALPHA1</code> and <code class="literal">ALPHA2</code> alpha parameter values (line <code class="literal">20</code>).</p><p>Let's take a look at the <code class="literal">twoStepLagSmoother</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>twoStepLagSmoother</strong></span>(<span class="strong"><strong>zSeries</strong></span>: DblVector,<span class="strong"><strong>alpha</strong></span>: Double): Int = { 
  val <span class="strong"><strong>A</strong></span>: DblMatrix = ((alpha, 1.0-alpha), (1.0, 0.0))  //<span class="strong"><strong>21</strong></span>
  val xt = <span class="strong"><strong>zipWithShift</strong></span>(1)  //<span class="strong"><strong>22</strong></span>
  val <span class="strong"><strong>pfnKalman</strong></span> = DKalman(A, H, P0) |&gt;    //<span class="strong"><strong>23</strong></span>
  pfnKalman(xt).map(filtered =&gt;          //<span class="strong"><strong>24</strong></span>
    display(zSeries, filtered.map(_._1), alpha) )
}</pre></div><p>The <code class="literal">twoStepLagSmoother</code> method takes two arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A <code class="literal">zSeries</code> single variable time series </li><li class="listitem">A <code class="literal">alpha</code> state transition parameter </li></ul></div><p>It initializes the state transition matrix <code class="literal">A</code> using the <code class="literal">alpha</code> exponential moving average decay parameter (line <code class="literal">21</code>). It creates the two-step lag time series, <code class="literal">xt</code>, using the <code class="literal">zipWithShift</code> method (line <code class="literal">22</code>). It extracts the <code class="literal">pfnKalman</code> partial function (line <code class="literal">23</code>), processes, and finally, displays the two-step lag time series (line <code class="literal">24</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note10700"/>Note</h3><p>
<span class="strong"><strong>Modeling state transition and noise</strong></span>
</p><p>The state transition and the noise related to the process have to be selected carefully. The resolution of the state equations relies on the <span class="strong"><strong>Cholesky</strong></span> (QR) decomposition, which requires a nonnegative definite matrix. The implementation in the Apache Commons Math library throws a <code class="literal">NonPositiveDefiniteMatrixException</code> exception if the principle is violated.</p></div><p>The<a id="id3850000" class="indexterm"/> smoothed yield is plotted along the raw data as follows:</p><div class="mediaobject"><img src="../Images/image01322.jpeg" alt="Experimentation"/><div class="caption"><p>The output of the Kalman filter for the 10-year Treasury-Bond historical prices</p></div></div><p style="clear:both; height: 1em;"> </p><p>The Kalman filter is able to smooth the historical yield of the 10-year Treasury bond while preserving the spikes and lower frequency noise. Let's analyze the data for a shorter period during which the noise is the strongest, between the 190<sup>th</sup> and the 275<sup>th</sup> trading days:</p><div class="mediaobject"><img src="../Images/image01323.jpeg" alt="Experimentation"/><div class="caption"><p>The output of the Kalman filter for the 10-year Treasury bond prices 0.8-.02</p></div></div><p style="clear:both; height: 1em;"> </p><p>The high<a id="id3860000" class="indexterm"/> frequency noise has been significantly reduced without cancelling the actual spikes. The distribution (0.8, 0.2) takes into consideration the previous state and favors the predicted value. Contrarily, a run with a state transition matrix <span class="emphasis"><em>A</em></span> [0.2, 0.8, 0.0, 1.0] that favors the latest measurement will preserve the noise, as seen in the following graph:</p><div class="mediaobject"><img src="../Images/image01324.jpeg" alt="Experimentation"/><div class="caption"><p>The output of the Kalman filter for the 10-year Treasury bond price 0.2-0.8</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Benefits and drawbacks"><div class="titlepage"><div><div><h3 class="title"><a id="ch03lvl3sec4300"/>Benefits and drawbacks</h3></div></div></div><p>The Kalman filter <a id="id3870000" class="indexterm"/>is a very useful and powerful tool used to help you understand the distribution of the noise between the process and observation. Contrary to the low or band-pass filters based on the discrete Fourier transform, the Kalman filter does not require the computation of the frequencies spectrum or assume the range of frequencies of the noise.</p><p>However, the linear discrete Kalman filter <a id="id3880000" class="indexterm"/>has its limitations, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The noise generated by both the process and the measurement has to be Gaussian. Processes with non-Gaussian noise can be modeled with techniques such as a Gaussian sum filter or adaptive Gaussian mixture [3:14].</li><li class="listitem">It requires that the underlying process is linear. However, researchers have been able to formulate extensions to the Kalman filter, known as the <a id="id3890000" class="indexterm"/><span class="strong"><strong>extended Kalman filter</strong></span> (<span class="strong"><strong>EKF</strong></span>), to filter signals from nonlinear dynamic systems, at the cost of significant computational complexity.<div class="note" title="Note"><h3 class="title"><a id="note10800"/>Note</h3><p>
<span class="strong"><strong>The continuous-time Kalman filter</strong></span>
</p><p>The Kalman filter is not restricted to dynamic systems with discrete states <span class="emphasis"><em>x</em></span>. The case of continuous state-time is handled by modifying the state transition equation, so the estimated state is computed as the derivative <span class="emphasis"><em>dx/dt</em></span>.</p></div></li></ul></div></div></div></div>
<div class="section" title="Alternative preprocessing techniques" id="aid-57R301"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec2900"/>Alternative preprocessing techniques</h1></div></div></div><p>For<a id="id3900000" class="indexterm"/> the sake of space and your time, this chapter introduced and applied three filtering and smoothing classes of algorithms. Moving averages, Fourier series, and the Kalman filter are far from being the only techniques used in cleaning raw data. The alternative techniques can be classified into the following categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Autoregressive models<a id="id3910000" class="indexterm"/> that encompass <a id="id3920000" class="indexterm"/><span class="strong"><strong>Autoregressive Moving Average</strong></span> (<span class="strong"><strong>ARMA</strong></span>), <span class="strong"><strong>Autoregressive Integrated Moving Average</strong></span> (<span class="strong"><strong>ARIMA</strong></span>), <span class="strong"><strong>generalized autoregressive</strong></span><a id="id3930000" class="indexterm"/><span class="strong"><strong> conditional heteroskedasticity</strong></span> (<span class="strong"><strong>GARCH</strong></span>), and Box-Jenkins that relies <a id="id3940000" class="indexterm"/>on some form of autocorrelation function.</li><li class="listitem"><span class="strong"><strong>Curve-fitting</strong></span> algorithms<a id="id3950000" class="indexterm"/> that include the polynomial and geometric fit with the ordinary least squares method, nonlinear least squares using the <span class="strong"><strong>Levenberg-Marquardt</strong></span> optimizer, and probability distribution fitting.</li><li class="listitem">Nonlinear dynamic systems<a id="id3960000" class="indexterm"/> with a Gaussian noise such as a <span class="strong"><strong>particle filter</strong></span>.</li><li class="listitem">Hidden Markov models, as<a id="id3970000" class="indexterm"/> described in the <span class="emphasis"><em>The hidden Markov model</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>.</li></ul></div></div>
<div class="section" title="Summary" id="aid-58PJI1"><div class="titlepage"><div><div><h1 class="title"><a id="ch03lvl1sec3000"/>Summary</h1></div></div></div><p>This completes the overview of the most commonly used data filtering and smoothing techniques. There are other types of data preprocessing algorithms such as normalization, analysis, and reduction of variance; the identification of missing values is also essential to avoid the <span class="strong"><strong>garbage-in garbage-out</strong></span> conundrum that plagues so many projects that use machine learning for regression or classification.</p><p>Scala can be effectively used to make the code understandable and avoid cluttering methods with unnecessary arguments.</p><p>The three techniques presented in this chapter, from the simplest moving averages and Fourier transform to the more elaborate Kalman filter, go a long way in setting up data for the concepts introduced in the next chapter: unsupervised learning and more specifically, clustering.</p></div>
<div class="chapter" title="Chapter&#xA0;4.&#xA0;Unsupervised Learning"><div class="titlepage" id="aid-59O442"><div><div><h1 class="title"><a id="ch18"/>Chapter 4. Unsupervised Learning</h1></div></div></div><p>Labeling a set of observations for classification or regression can be a daunting task, especially in the case of a large feature set. In some cases, labeled observations are either unavailable or not possible to create. In an attempt to extract some hidden associations or structures from observations, the data scientist relies on unsupervised learning techniques to detect patterns or similarity in data.</p><p>The goal of unsupervised learning is to discover patterns of regularities and irregularities in a set of observations. These techniques are also applied in reducing the solution or feature space.</p><p>There are numerous unsupervised algorithms; some are more appropriate to handle dependent features while others generate affinity groups in the case of hidden features [4:1]. In this chapter, you will learn three of the most common unsupervised learning algorithms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>K-means</strong></span>: This used for clustering observed features</li><li class="listitem"><span class="strong"><strong>Expectation-maximization</strong></span> (<span class="strong"><strong>EM</strong></span>): This is used for clustering observed and latent features</li><li class="listitem"><span class="strong"><strong>Principal Components Analysis</strong></span> (<span class="strong"><strong>PCA</strong></span>): This is used to reduce the dimension of the model</li></ul></div><p>Any of these algorithms can be applied to technical analysis or fundamental analysis. Fundamental analysis of financial ratios and technical analysis of price movements is discussed in the <span class="emphasis"><em>Technical analysis</em></span> section under <span class="emphasis"><em>Finances 101</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>. The K-means algorithm is fully implemented in Scala while expectation-maximization and Principal Components Analysis leverage the Apache Commons Math library.</p><p>The chapter concludes with a brief overview of dimension reduction techniques for non-linear models.</p><div class="section" title="Clustering"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec3100"/>Clustering</h1></div></div></div><p>Problems<a id="id3980000" class="indexterm"/> involving a large number of features for large datasets become quickly intractable, and it is quite difficult to evaluate the independence between features. Any computation that requires some level of optimization and, at a minimum, the computation of first order derivatives requires a significant amount of computing power to manipulate high-dimension matrices. As with many engineering fields, a divide-and-conquer approach to classifying very large datasets is quite effective. The objective is to reduce very large sets of observations into a small group of observations that share some common attributes.</p><div class="mediaobject"><img src="../Images/image01325.jpeg" alt="Clustering"/><div class="caption"><p>Visualization of data clustering</p></div></div><p style="clear:both; height: 1em;"> </p><p>This approach is <a id="id3990000" class="indexterm"/>known as vector quantization. Vector quantization is a method that divides a set of observations into groups of similar size. The main benefit of vector quantization is that the analysis using a representative of each group is far simpler than an analysis of the entire dataset [4:2].</p><p>
<span class="strong"><strong>Clustering</strong></span>, also known as <span class="strong"><strong>cluster analysis</strong></span>, is a form of vector quantization that relies on a concept of distance or similarity to generate groups known as clusters.</p><div class="note" title="Note"><h3 class="title"><a id="note10900"/>Note</h3><p>
<span class="strong"><strong>Learning vector quantization (LVQ)</strong></span>
</p><p>Vector quantization should not be confused with <a id="id4000000" class="indexterm"/><span class="strong"><strong>learning vector quantization</strong></span>; learning vector quantization is a special case of artificial neural networks that relies on a winner-take-all learning strategy to compress signals, images, or videos.</p></div><p>This chapter <a id="id4010000" class="indexterm"/>introduces two of the most commonly applied clustering algorithms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>K-means</strong></span>: This is <a id="id4020000" class="indexterm"/>used for quantitative types and minimizes the total error (known as the reconstruction error) given the number of clusters and the distance formula.</li><li class="listitem"><span class="strong"><strong>Expectation-maximization</strong></span> (<span class="strong"><strong>EM</strong></span>): This<a id="id4030000" class="indexterm"/> is a two-step probabilistic approach that maximizes the likelihood estimates of a set of parameters. EM is particularly suitable for handling missing data.</li></ul></div><div class="section" title="K-means clustering"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec5900"/>K-means clustering</h2></div></div></div><p>K-means is <a id="id4040000" class="indexterm"/>a popular clustering algorithm<a id="id4050000" class="indexterm"/> that can be implemented either iteratively or recursively. The representative of each cluster is computed as the center of the cluster, known as the <a id="id4060000" class="indexterm"/><span class="strong"><strong>centroid</strong></span>. The similarity between observations within a single cluster relies on the concept of distance (or similarity) between observations.</p><div class="section" title="Measuring similarity"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4400"/>Measuring similarity</h3></div></div></div><p>There are<a id="id4070000" class="indexterm"/> many ways to measure the similarity between observations. The most appropriate measure has to be intuitive and avoid computational complexity. This section reviews three similarity measures:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The Manhattan distance</li><li class="listitem">The Euclidean distance</li><li class="listitem">The normalized inner or dot product</li></ul></div><p>The Manhattan distance is defined by the absolute distance between two variables or vectors, <span class="emphasis"><em>{x<sub>i</sub>}</em></span> and <span class="emphasis"><em>{y<sub>i</sub>}</em></span>, of the same size (M1):</p><div class="mediaobject"><img src="../Images/image01326.jpeg" alt="Measuring similarity"/></div><p style="clear:both; height: 1em;"> </p><p>The implementation<a id="id4080000" class="indexterm"/> is generic enough to compute the distance between two vectors of elements of different types as long as an implicit conversion between each of these types to the <code class="literal">Double</code> values is already defined, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>manhattan</strong></span>[T &lt;: AnyVal, U &lt;: AnyVal](
    x: Array[T], 
    y: Array[U])(implicit f: T =&gt; Double): Double = 
 (x,y).zipped.map{case (u,v) =&gt; Math.abs(u-v)}.sum</pre></div><p>The ubiquitous Euclidean distance between two vectors, <span class="emphasis"><em>{x<sub>i</sub>}</em></span> and <span class="emphasis"><em>{y<sub>i</sub>}</em></span>, of the same size is defined by the following formula (M2):</p><div class="mediaobject"><img src="../Images/image01327.jpeg" alt="Measuring similarity"/></div><p style="clear:both; height: 1em;"> </p><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>euclidean</strong></span>[T &lt;: AnyVal, U &lt;: AnyVal](
    x: Array[T], 
    y: Array[U])(implicit f: T =&gt; Double): Double = 
  Math.sqrt((x,y).zipped.map{case (u,v) =&gt;u-v}.map(sqr(_)).sum)</pre></div><p>The normalized inner product or cosine distance between two vectors, <span class="emphasis"><em>{x<sub>i</sub>}</em></span> and <span class="emphasis"><em>{y<sub>i</sub>}</em></span>, is defined by the following formula (M3):</p><div class="mediaobject"><img src="../Images/image01328.jpeg" alt="Measuring similarity"/></div><p style="clear:both; height: 1em;"> </p><p>In this implementation, the computation of the dot product and the norms for each dataset is done simultaneously using the tuple within the <code class="literal">fold</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>cosine</strong></span>[T &lt;: AnyVal, U &lt; : AnyVal] (
     x: Array[T], 
     y: Array[U])(implicit f : T =&gt; Double): Double = {
  val norms = (x,y).zipped
          .map{ case (u,v) =&gt; Array[Double](u*v, u*u, v*v)}
          ./:(Array.fill(3)(0.0))((s, t) =&gt; s ++ t) 
  norms(0)/Math.sqrt(norms(1)*norms(2))
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note11000"/>Note</h3><p>
<span class="strong"><strong>Performance of zip and zipped</strong></span>
</p><p>The scalar product of two vectors is one of the most common operations. It is tempting to implement the dot product using the generic <code class="literal">zip</code> method:</p><div class="informalexample"><pre class="programlisting"> def dot(x:Array[Double], y:Array[Double]): Array[Double] = x.zip(y).map{case(x, y) =&gt; f(x,y) )</pre></div><p>A functional alternative is to use the <code class="literal">Tuple2.zipped</code> method:</p><div class="informalexample"><pre class="programlisting"> def dot(x:Array[Double], y:Array[Double]): Array[Double] = (x, y).zipped map ( _ * _)</pre></div><p>If readability is not a primary issue, you can always implement the <code class="literal">dot</code> method with a <code class="literal">while</code> loop, which prevents you from using the ubiquitous <code class="literal">while</code> loop.</p></div></div><div class="section" title="Defining the algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4500"/>Defining the algorithm</h3></div></div></div><p>The<a id="id4090000" class="indexterm"/> main advantage of the K-means algorithm (and the reason for its popularity) is its simplicity [4:3].</p><div class="note" title="Note"><h3 class="title"><a id="note11300"/>Note</h3><p>
<span class="strong"><strong>K-means objective</strong></span>
</p><p>M4: Let's consider K clusters, <span class="emphasis"><em>{C<sub>k</sub>}</em></span>, with means or centroids, <span class="emphasis"><em>{m<sub>k</sub>}</em></span>. The K-means algorithm is indeed an optimization problem whose objective is to minimize the reconstruction or total error defined as the total sum of the distance:</p><div class="mediaobject"><img src="../Images/image01329.jpeg" alt="Defining the algorithm"/></div><p style="clear:both; height: 1em;"> </p></div><p>The four steps of the K-means algorithm are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Cluster configuration (initializing the centroids or means <span class="emphasis"><em>m<sub>k</sub></em></span> of the K clusters).</li><li class="listitem">Cluster assignment (assigning observations to the nearest cluster given the centroids <span class="emphasis"><em>m<sub>k</sub></em></span>).</li><li class="listitem">Error <a id="id4100000" class="indexterm"/>minimization (computing the total reconstruction error):<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute centroids <span class="emphasis"><em>m<sub>k</sub></em></span> that minimize the total reconstruction error for the current assignment.</li><li class="listitem">Reassign the observations given the new centroids <span class="emphasis"><em>m<sub>k</sub></em></span>.</li><li class="listitem">Repeat the computation of the total reconstruction error until no observations are reassigned.</li></ol><div style="height:10px; width: 1px"/></div></li><li class="listitem">Classification of a new observation by assigning the observation to the closest cluster.</li></ol><div style="height:10px; width: 1px"/></div><p>We need to define the components of the K-means in Scala before implementing the algorithm.</p></div><div class="section" title="Step 1 – cluster configuration"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4600"/>Step 1 – cluster configuration</h3></div></div></div><p>Let's <a id="id4110000" class="indexterm"/>create the two main components of the K-means <a id="id4120000" class="indexterm"/>algorithms: clusters of observations and the implementation of the K-means algorithm.</p><div class="section" title="Defining clusters"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec0700"/>Defining clusters</h4></div></div></div><p>The first <a id="id4130000" class="indexterm"/>step is to define a cluster. A cluster is defined by the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The centroid (<code class="literal">center</code>) (line <code class="literal">1</code>)</li><li class="listitem">The indices of the observations that belong to this cluster (<code class="literal">members</code>) (line <code class="literal">2</code>)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Cluster</strong></span>[T &lt;: AnyVal](val <span class="strong"><strong>center</strong></span>: DblArray)
     (implicit f: T =&gt; Double) {  //<span class="strong"><strong>1</strong></span>
  type DistanceFunc[T] = (DblArray, Array[T])=&gt; Double
  val <span class="strong"><strong>members</strong></span> = new ListBuffer[Int]    //<span class="strong"><strong>2</strong></span>
  def <span class="strong"><strong>moveCenter</strong></span>(xt: XVSeries[T]): Cluster[T] 
  ...
}</pre></div><p>The cluster is responsible for managing its members (data points) at any point of the iterative<a id="id4140000" class="indexterm"/> computation of the K-means algorithm. It is assumed that a cluster will never contain the same data points twice. The two key methods in the <code class="literal">Cluster</code> class are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">moveCenter</code>: This recomputes the centroid of a cluster</li><li class="listitem"><code class="literal">stdDev</code>: This computes the standard deviation of the distance between all the observation members and the centroid</li></ul></div><p>The constructor of the <code class="literal">Cluster</code> class is implemented by the <code class="literal">apply</code> method in the companion object. For convenience, refer to the <span class="emphasis"><em>Class constructor template</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>Cluster</strong></span> {
  def <span class="strong"><strong>apply</strong></span>[T &lt;: AnyVal](center: DblArray)
      (implicit f: T =&gt; Double): Cluster[T] = 
     new Cluster[T](center)
}</pre></div><p>Let's take a look at the <code class="literal">moveCenter</code> method. It creates a new cluster with the existing members and a new centroid. The computation of the values of the centroid requires the transposition of the matrix of observations by features into a matrix of feature by observations (line <code class="literal">3</code>). The new centroid is computed by normalizing the sum of each feature across all the observations by the number of data points (line <code class="literal">4</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>moveCenter</strong></span>(xt: XVSeries[T])
       (implicit m: Manifest[T], num: Numeric[T])
       : Cluster[T] = {  
  val sum = transpose(members.map( xt(_)).toList)
             .map(_.sum)  //<span class="strong"><strong>3</strong></span>
  Cluster[T](sum.map( _ / members.size).toArray) //<span class="strong"><strong>4</strong></span>
}</pre></div><p>The <code class="literal">stdDev</code> method computes the standard deviation of all the observations contained in the cluster relative to its center. The <code class="literal">distance</code> value between each member and the centroid is extracted through a map invocation (line <code class="literal">5</code>). It is then loaded into a statistics instance to compute the standard deviation (line <code class="literal">6</code>). The function to compute the distance between the center and an observation is an argument of the method. The default distance is <code class="literal">euclidean</code>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>stdDev</strong></span>(xt: XVSeries[T], <span class="strong"><strong>distance</strong></span>: DistanceFunc): Double = {
  val ts = members.map(xt( _)).map(distance(center,_)) //<span class="strong"><strong>5</strong></span>
  Stats[Double](ts).stdDev  //<span class="strong"><strong>6</strong></span>
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note11400"/>Note</h3><p>
<span class="strong"><strong>Cluster selection</strong></span>
</p><p>There are different ways to select the most appropriate cluster when reassigning an observation (updating its membership). In this implementation, we will select the cluster with the larger spread or lowest density. An alternative is to select the cluster with the largest membership.</p></div></div><div class="section" title="Initializing clusters"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec0800"/>Initializing clusters</h4></div></div></div><p>The<a id="id4150000" class="indexterm"/> initialization of the cluster centroids is important to ensure fast convergence of the K-means algorithm. Solutions range from the simple random generation of centroids to the application of genetic algorithms to evaluate the fitness of centroid candidates. We selected an efficient and fast initialization algorithm developed by M. Agha and W. Ashour [4:4].</p><p>The steps of the initialization are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute the standard deviation of the set of observations.</li><li class="listitem">Compute the index of the feature <span class="emphasis"><em>{x<sub>k,0</sub>, x<sub>k,1</sub> … x<sub>k,n</sub>}</em></span> with the maximum standard deviation.</li><li class="listitem">Rank the observations by their increasing value of standard deviation for the dimension <span class="emphasis"><em>k</em></span>.</li><li class="listitem">Divide the ranked observations set equally into <span class="emphasis"><em>K</em></span> sets <span class="emphasis"><em>{S<sub>m</sub>}</em></span>.</li><li class="listitem">Find the median value's <span class="emphasis"><em>size(S<sub>m</sub>)/2</em></span>.</li><li class="listitem">Use the resulting observations as initial centroids.</li></ol><div style="height:10px; width: 1px"/></div><p>Let's deconstruct the implementation of the Agha-Ashour algorithm in the <code class="literal">initialize</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>initialize</strong></span>(xt: U): V = {
  val stats = <span class="strong"><strong>statistics</strong></span>(xt)  //<span class="strong"><strong>7</strong></span>
  val <span class="strong"><strong>maxSDevVar</strong></span> = Range(0,stats.size)  //<span class="strong"><strong>8</strong></span>
                   .maxBy(stats( _ ).stdDev )

  val <span class="strong"><strong>rankedObs</strong></span> = xt.zipWithIndex
                .map{case (x, n) =&gt; (x(maxSDevVar), n)}
                .sortWith( _._1  &lt; _._1)  //<span class="strong"><strong>9</strong></span>

  val halfSegSize = ((rankedObs.size&gt;&gt;1)/_config.K)
                  .floor.toInt //<span class="strong"><strong>10</strong></span>
  val centroids = rankedObs
     .filter(isContained( _, halfSegSize, rankedObs.size))
     .map{ case(x, n) =&gt; xt(n)} //<span class="strong"><strong>11</strong></span>
  centroids.<span class="strong"><strong>aggregate</strong></span>(List[Cluster[T]]())((xs, c) =&gt; 
        Cluster[T](c) :: xs, _ ::: _)  //<span class="strong"><strong>12</strong></span>
}</pre></div><p>The <code class="literal">statistics</code> method <a id="id4160000" class="indexterm"/>on time series of the <code class="literal">XVSeries</code> type is defined in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span> (line <code class="literal">7</code>). The dimension (or feature) with the <code class="literal">maxSDevVar</code> maximum variance or standard deviation is computed using the <code class="literal">maxBy</code> method on a <code class="literal">Stats</code> instance (line <code class="literal">8</code>). Then, the observations are ranked by the increasing value of the <code class="literal">rankedObs</code> standard deviation (line <code class="literal">9</code>).</p><p>The ordered sequence of observations is then broken into the <code class="literal">xt.size/_config.K</code> segments (line <code class="literal">10</code>) and the indices of the centroids are selected as the midpoint (or median) observations of those segments using the <code class="literal">isContained</code> filtering condition (line <code class="literal">11</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>isContained</strong></span>(t: (T,Int), hSz: Int, dim: Int): Boolean = 
    (t._2 % hSz == 0) &amp;&amp; (t._2 %(hSz&lt;&lt;1) != 0)</pre></div><p>Finally, the list of clusters is generated using an <code class="literal">aggregate</code> call on the set of centroids (line <code class="literal">12</code>).</p></div></div><div class="section" title="Step 2 – cluster assignment"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4700"/>Step 2 – cluster assignment</h3></div></div></div><p>The <a id="id4170000" class="indexterm"/>second step in the K-means algorithm is the assignment <a id="id4180000" class="indexterm"/>of the observations to the clusters for which the centroids have been initialized in step 1. This feat is accomplished by the private <code class="literal">assignToClusters</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>assignToClusters</strong></span>(xt: U, clusters: V, 
     members: Array[Int]): Int =  {

  xt.zipWithIndex.<span class="strong"><strong>filter</strong></span>{ case(x, <span class="strong"><strong>n</strong></span>) =&gt; {  //<span class="strong"><strong>13</strong></span>
    val nearestCluster = <span class="strong"><strong>getNearestCluster</strong></span>(clusters, x) //<span class="strong"><strong>14</strong></span>
    val reassigned = nearestCluster != members(n) 

    <span class="strong"><strong>clusters(nearestCluster)</strong></span> += n //<span class="strong"><strong>15</strong></span>
    members(n) = nearestCluster //<span class="strong"><strong>16</strong></span>
    reassigned
  }}.size
}</pre></div><p>The core of the assignment of observations to each cluster is the filter on the time series (line <code class="literal">13</code>). The<a id="id4190000" class="indexterm"/> filter computes the index of the closest cluster and checks whether the observation is to be reassigned (line <code class="literal">14</code>). The observation at the <code class="literal">n</code> index is added to the nearest cluster, <code class="literal">clusters(nearestCluster)</code> (line <code class="literal">15</code>). The current membership of the observations is then updated (line <code class="literal">16</code>).</p><p>The cluster closest to an observation data is computed by the private <code class="literal">getNearestCluster</code> method as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>getNearestCluster</strong></span>(clusters: V, x: Array[T]): Int = 
  clusters.zipWithIndex./:((Double.MaxValue, 0)){
    case (p, (c, n) ) =&gt; { 
     val measure = distance(c.center, x) //<span class="strong"><strong>17</strong></span>
     if( measure &lt; p._1) (measure, n)  else p
  }}._2</pre></div><p>A fold is used to extract the cluster that is closest to the <code class="literal">x</code> observation from the list of clusters using the distance metric defined in the K-means constructor (line <code class="literal">17</code>).</p><p>As with other data processing units, the extraction of K-means clusters is encapsulated in a data transformation so that clustering can be integrated into a workflow using the composition of mixins described in the <span class="emphasis"><em>Composing mixins to build a workflow</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><div class="note" title="Note"><h3 class="title"><a id="note11500"/>Note</h3><p>
<span class="strong"><strong>K-means algorithm exit condition</strong></span>
</p><p>In some rare instances, the algorithm may reassign the same few observations between clusters, preventing its convergence toward a solution in a reasonable time. Therefore, it is recommended that you add a maximum number of iterations as an exit condition. If K-means does not converge with the maximum number of iterations, then the cluster centroids need to be reinitialized and the iterative (or recursive) execution needs to be restarted.</p></div><p>The <code class="literal">|&gt;</code> transformation requires that the computation of the standard deviation of the distance of the observations related to the centroid, <code class="literal">c</code>, is computed in the <code class="literal">stdDev</code> method:</p><div class="informalexample"><pre class="programlisting">type KMeansModel[T} = List[Cluster[T]] 
def <span class="strong"><strong>stdDev</strong></span>[T](
    clusters: KMeansModel[T], 
    xt: XVSeries[T], 
    distance: DistanceFunc[T]): DblVector = 
 clusters.map( _.stdDev(xt, distance)).toVector</pre></div><div class="note" title="Note"><h3 class="title"><a id="note11600"/>Note</h3><p>
<span class="strong"><strong>Centroid versus mean</strong></span>
</p><p>The terms centroid and mean refer to the same entity: the center of a cluster. This chapter uses these two terms interchangeably.</p></div></div><div class="section" title="Step 3 – reconstruction/error minimization"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4800"/>Step 3 – reconstruction/error minimization</h3></div></div></div><p>The <a id="id4200000" class="indexterm"/>clusters are initialized with <a id="id4210000" class="indexterm"/>predefined set of observations as their members. The algorithm updates the membership of each cluster by minimizing the total reconstruction error. There are two effective strategies to execute the K-means algorithm:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Tail recursive execution</li><li class="listitem">Iterative execution</li></ul></div><div class="section" title="Creating K-means components"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec0900"/>Creating K-means components</h4></div></div></div><p>Let's <a id="id4220000" class="indexterm"/>declare the K-means algorithm class, <code class="literal">KMeans</code>, with its public methods. <code class="literal">KMeans</code> implements an <code class="literal">ITransform</code> data transformation using an implicit model extracted from a training set and is described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">18</code>). The configuration of the <code class="literal">KMeansConfig</code> type consists of the tuple (<code class="literal">K</code>, <code class="literal">maxIters</code>) with <code class="literal">K</code> being the number of clusters and <code class="literal">maxIters</code> being the maximum number of iterations allowed for the convergence of the algorithm:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>KMeansConfig</strong></span>(val K: Int, maxIters: Int)</pre></div><p>The <code class="literal">KMeans</code> class takes the following three arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This is the configuration used for the execution of the algorithm</li><li class="listitem"><code class="literal">distance</code>: This is the function used to compute the distance between any observation and a cluster centroid</li><li class="listitem"><code class="literal">xt</code>: This is the training set</li></ul></div><p>The implicit conversion of the <code class="literal">T</code> type to a <code class="literal">Double</code> is implemented as a view bound. The instantiation of the <code class="literal">KMeans</code> class initializes a <code class="literal">V</code> type of output from K-means as <code class="literal">Cluster[T]</code> (line <code class="literal">20</code>). The <code class="literal">num</code> instance of the <code class="literal">Numeric</code> class has to be passed implicitly as a class parameter because it is required by the <code class="literal">sortWith</code> invocation in <code class="literal">initialize</code>, the <code class="literal">maxBy</code> method, and the <code class="literal">Cluster.moveCenter</code> method (line <code class="literal">19</code>). The <code class="literal">Manifest</code> is required to preserve the erasure type for <code class="literal">Array[T]</code> in the JVM:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>KMeans</strong></span>[T &lt;: AnyVal](<span class="strong"><strong>config</strong></span>: KMeansConfig,  //<span class="strong"><strong>18</strong></span>
    distance: DistanceFunc[T],
    xt: XVSeries[T])
    (implicit m: Manifest[T], <span class="strong"><strong>num</strong></span>: Numeric[T], f: T=&gt;Double) //<span class="strong"><strong>19</strong></span>
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Monitor[T] { 

  type <span class="strong"><strong>V</strong></span> = Cluster[T]     //<span class="strong"><strong>20</strong></span>
  val model: Option[KMeansModel[T]] = train
  def train: Option[KMeansModel[T]]
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]]
  ...
}</pre></div><p>The <code class="literal">KMeansModel</code> model<a id="id4230000" class="indexterm"/> is defined as the list of clusters extracted through training.</p></div><div class="section" title="Tail recursive implementation"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec1000"/>Tail recursive implementation</h4></div></div></div><p>The <a id="id4240000" class="indexterm"/>transformation or clustering function is implemented by the <code class="literal">train</code> training method that creates a partial function with <code class="literal">XVSeries[T]</code> as the input and <code class="literal">KMeansModel[T]</code> as the output:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[<span class="strong"><strong>KMeansModel</strong></span>[T]] = Try {
         // STEP 1
  val clusters =initialize(xt) //<span class="strong"><strong>21</strong></span>
  if( clusters.isEmpty)  /* ...  */
  else  {
         // STEP 2
    val members = Array.fill(xt.size)(0)
    <span class="strong"><strong>assignToClusters</strong></span>(xt, clusters, members) //<span class="strong"><strong>22</strong></span>
    var iters = 0

    // Declaration of the tail recursion def update      
    if( iters &gt;= _config.maxIters )
      throw new IllegalStateException( /* .. */)
         // STEP 3
    <span class="strong"><strong>update</strong></span>(clusters, xt, members)  //<span class="strong"><strong>23</strong></span>
  } 
} match {
   case Success(clusters) =&gt; Some(clusters)
   case Failure(e) =&gt; /* … */
}</pre></div><p>The K-means<a id="id4250000" class="indexterm"/> training algorithm is implemented through the following three steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Initialize the cluster's centroid using the <code class="literal">initialize</code> method (line <code class="literal">21</code>).</li><li class="listitem">Assign observations to each cluster using the <code class="literal">assignToClusters</code> method (line <code class="literal">22</code>).</li><li class="listitem">Recompute the total error reconstruction using the <code class="literal">update</code> recursive method (line <code class="literal">23</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The computation of the total error reconstruction is implemented as a tail recursive method, <code class="literal">update</code>, as follows:</p><div class="informalexample"><pre class="programlisting">@tailrec
def <span class="strong"><strong>update</strong></span>(clusters: KMeansModel[T], xt: U, 
       members: Array[Int]): KMeansModel[T] = {  //<span class="strong"><strong>24</strong></span>

  val <span class="strong"><strong>newClusters</strong></span> = clusters.map( c =&gt; {         
      if( c.size &gt; 0) c.moveCenter(xt) //<span class="strong"><strong>25</strong></span>
    else clusters.filter( _.size &gt;0)
          .maxBy(_.stdDev(xt, distance)) //<span class="strong"><strong>26</strong></span>
  }) 
  iters += 1
  if(iters &gt;= config.maxIters ||       //<span class="strong"><strong>27</strong></span>
      assignToClusters(xt, newClusters, members) ==0) 
    newClusters
  else 
    update(newClusters, xt, membership)   //<span class="strong"><strong>28</strong></span>
}</pre></div><p>The recursion takes the following three arguments (line <code class="literal">24</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The current list of <code class="literal">clusters</code> that is updated during the recursion</li><li class="listitem">The <code class="literal">xt</code> input time series</li><li class="listitem">The indices of membership to the clusters, <code class="literal">members</code></li></ul></div><p>A new list of clusters, <code class="literal">newClusters</code>, is computed by either recalculating each centroid if the cluster is not empty (line <code class="literal">25</code>) or evaluating the standard deviation of the distance of each observation relative to each centroid (line <code class="literal">26</code>). The execution exits when either the maximum number of the <code class="literal">maxIters</code> recursive calls is reached or when no more observations<a id="id4260000" class="indexterm"/> are reassigned to a different cluster (line <code class="literal">27</code>). Otherwise, the method invokes itself with an updated list of clusters (line <code class="literal">28</code>).</p></div><div class="section" title="Iterative implementation"><div class="titlepage"><div><div><h4 class="title"><a id="ch04lvl4sec1100"/>Iterative implementation</h4></div></div></div><p>The <a id="id4270000" class="indexterm"/>implementation of an iterative execution is presented for an informational purpose. It follows the same sequence of calls as with the recursive implementation. The new clusters are computed (line <code class="literal">29</code>) and the execution exits when either the maximum number of allowed iterations is reached (line <code class="literal">30</code>) or when no more observations are reassigned to a different cluster (line <code class="literal">31</code>):</p><div class="informalexample"><pre class="programlisting">val members = Array.fill(xt.size)(0)
assignToClusters(xt, clusters, members) 
var newClusters: KMeansModel[T] = List.empty[Cluster[T]]
Range(0,  maxIters).find( _ =&gt; {  //<span class="strong"><strong>29</strong></span>
  newClusters = clusters.map( c =&gt; {   //<span class="strong"><strong>30</strong></span>
    if( c.size &gt; 0)  c.moveCenter(xt) 
    else clusters.filter( _.size &gt; 0)
           .maxBy(_.stdDev(xt, distance))
  }) 
  assignToClusters(xt, newClusters, members) &gt; 0  //<span class="strong"><strong>31</strong></span>
}).map(_ =&gt; newClusters)</pre></div><p>The density of the clusters is computed in the <code class="literal">KMeans</code> class as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>density</strong></span>: Option[DblVector] = 
  model.map( _.map( c =&gt; 
    c.getMembers.map(xt(_)).map( distance(c.center, _)).sum)</pre></div></div></div><div class="section" title="Step 4 – classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec4900"/>Step 4 – classification</h3></div></div></div><p>The<a id="id4280000" class="indexterm"/> objective of the classification is to assign an observation to a cluster with the closest centroid:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] = {
  case x: Array[T] if( x.length == dimension(xt) 
                     &amp;&amp; model != None) =&gt; 
  Try (model.map( _.minBy(c =&gt; distance(c.center,x))).get )
}</pre></div><p>The most appropriate cluster is computed by selecting the <code class="literal">c</code> cluster whose <code class="literal">center</code> is the closest to the <code class="literal">x</code> observation using the <code class="literal">minBy</code> higher order method.</p></div><div class="section" title="The curse of dimensionality"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5000"/>The curse of dimensionality</h3></div></div></div><p>A <a id="id4290000" class="indexterm"/>model with a significant number of features (high dimensions) requires a larger number of observations in order to extract relevant and reliable clusters. K-means clustering with very small datasets (&lt; 50) produces models with high bias and a limited number of clusters, which are affected by the order of observations [4:5]. I have been using the following simple empirical rule of thumb for a training set of size <span class="emphasis"><em>n</em></span>, expected <span class="emphasis"><em>K</em></span> clusters, and <span class="emphasis"><em>N</em></span> features: <span class="emphasis"><em>n &lt; K.N</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note11700"/>Note</h3><p>Dimensionality and the size of the training set</p><p>The issue of sizing the training set given the dimensionality of a model is not specific to unsupervised learning algorithms. All supervised learning techniques face the same challenge to set up a viable training plan.</p></div><p>Whichever empirical rule you follow, such a restriction is particularly an issue for analyzing stocks using historical quotes. Let's consider our examples of using technical analysis to categorize stocks according to their price behavior over a period of 1 year (or approximately 250 trading days). The dimension of the problem is 250 (250 daily closing prices). The number of stocks (observations) would have exceeded several hundred!</p><div class="mediaobject"><img src="../Images/image01330.jpeg" alt="The curse of dimensionality"/><div class="caption"><p>Price model for K-means clustering</p></div></div><p style="clear:both; height: 1em;"> </p><p>There are options to get around this limitation and shrink the numbers of observations, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Sampling the trading data without losing a significant amount of information from the raw data, assuming that the distribution of observations follows a known probability density function.</li><li class="listitem">Smoothing the data to remove the noise as seen in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>, assuming that the noise is Gaussian. In our test, a smoothing technique will remove the price outliers for each stock and therefore reduce the number of features (trading session). This approach differs from the first (sampling) technique because it does not require an assumption that the dataset follows a known density function. On the other hand, the reduction of features will be less significant.</li></ul></div><p>These<a id="id4300000" class="indexterm"/> approaches are workaround solutions at best, used for the sake of this tutorial. You need to consider the quality of your data before applying these techniques to the actual commercial applications. The principal component analysis introduced in the last paragraph of this chapter is one of the most reliable dimension reduction techniques.</p></div><div class="section" title="Setting up the evaluation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5100"/>Setting up the evaluation</h3></div></div></div><p>The<a id="id4310000" class="indexterm"/> objective is to extract clusters from a set of stock price actions during a period of time between January 1 and Dec 31, 2013 as features. For this test, 127 stocks are randomly selected from the S&amp;P 500 list. The following chart visualizes the behavior of the normalized price of a subset of these 127 stocks:</p><div class="mediaobject"><img src="../Images/image01331.jpeg" alt="Setting up the evaluation"/><div class="caption"><p>Price action of a basket of stocks used in K-means clustering</p></div></div><p style="clear:both; height: 1em;"> </p><p>The key <a id="id4320000" class="indexterm"/>is to select the appropriate features prior to clustering and the time window to operate on. It would make sense to consider the entire historical price over the 252 trading days as a feature. However, the number of observations (stocks) is too limited to use the entire price range. The observations are the stock closing prices for each trading session between the 80<sup>th</sup> and 130<sup>th</sup> trading days. The adjusted daily closing prices are normalized using their respective minimum and maximum values.</p><p>First, let's create a simple method to compute the density of the clusters:</p><div class="informalexample"><pre class="programlisting">val MAX_ITERS = 150
def <span class="strong"><strong>density</strong></span>(K: Int, obs: XVSeries[Double]): DblVector = 
  KMeans[Double](KMeansConfig(K, MAX_ITERS)).density.get //<span class="strong"><strong>32</strong></span>
</pre></div><p>The <code class="literal">density</code> method invokes <code class="literal">KMeans.density</code> described in step 3. Let's load the data from CSV files using the <code class="literal">DataSource</code> class, as described in the <span class="emphasis"><em>Data extraction</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">import YahooFinancials.) 
val START_INDEX = 80; val NUM_SAMPLES = 50  //<span class="strong"><strong>33</strong></span>
val PATH = "resources/data/chap4/"

type INPUT = Array[String] =&gt; Double
val <span class="strong"><strong>extractor</strong></span> = adjClose :: List[INPUT]() //<span class="strong"><strong>34</strong></span>
val symbolFiles = <span class="strong"><strong>DataSource</strong></span>.listSymbolFiles(PATH) //<span class="strong"><strong>35</strong></span>

for {
  prices &lt;- <span class="strong"><strong>getPrices</strong></span>  //<span class="strong"><strong>36</strong></span>
  values &lt;- Try(<span class="strong"><strong>getPricesRange</strong></span>(prices))  //<span class="strong"><strong>37</strong></span>
  stdDev &lt;- Try(<span class="strong"><strong>ks</strong></span>.map( density(_, values.toVector))) //<span class="strong"><strong>38</strong></span>
  <span class="strong"><strong>pfnKmeans</strong></span> &lt;- Try { 
    KMeans[Double](KMeansConfig(5,MAX_ITERS),values.toVector) |&gt; 
  }   //<span class="strong"><strong>39</strong></span>
  predict &lt;- pfnKmeans(values.head)   //<span class="strong"><strong>40</strong></span>
} yield {
  val results = s"""Daily prices ${prices.size} stocks")
     | \nClusters density ${stdDev.mkString(", ")}"""
  .stripMargin
  show(results)
}</pre></div><p>As mentioned earlier, the cluster analysis applies to the closing price in the range between the 80<sup>th</sup> and 130<sup>th</sup> trading days (line <code class="literal">33</code>). The <code class="literal">extractor</code> function retrieves the adjusted closing price for a stock from <code class="literal">YahooFinancials</code> (line <code class="literal">34</code>). The list of stock tickers (or symbols) are extracted as a list of CSV filenames located in <code class="literal">path</code> (line <code class="literal">35</code>). For instance, the ticker symbol for General Electric Corp. is GE and the trading data is located in <code class="literal">GE.csv</code>.</p><p>The <a id="id4330000" class="indexterm"/>execution extracts 50 daily prices using <code class="literal">DataSource</code> and then filters out the incorrectly formatted data using <code class="literal">filter</code> (line <code class="literal">36</code>):</p><div class="informalexample"><pre class="programlisting">type XVSeriesSet = Array[XVSeries[Double]]
def <span class="strong"><strong>getPrices</strong></span>: Try[XVSeriesSet] = Try {
   symbolFiles.map( DataSource(_, path) |&gt; extractor )
   .<span class="strong"><strong>filter</strong></span>( _.isSuccess ).map( _.get)
}</pre></div><p>The historical stock prices for the trading session between the 80<sup>th</sup> and 130<sup>th</sup> days are generated by the <code class="literal">getPricesRange</code> closure (line <code class="literal">37</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>getPricesRange</strong></span>(prices: XVSeriesSet) = 
   prices.view.map(_.head.toArray)
    .map( _.drop(START_INDEX).take(NUM_SAMPLES))</pre></div><p>It computes the density of the clusters by invoking the <code class="literal">density</code> method for each <code class="literal">ks</code> value of the number of clusters (line <code class="literal">38</code>).</p><p>The <code class="literal">pfnKmeans</code> partial classification function is created for a 5-cluster, <code class="literal">KMeans</code> (line <code class="literal">39</code>), and then used to classify one of the observations (line <code class="literal">40</code>).</p></div><div class="section" title="Evaluating the results"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5200"/>Evaluating the results</h3></div></div></div><p>The first<a id="id4340000" class="indexterm"/> test run is executed with <span class="emphasis"><em>K=3</em></span> clusters. The mean (or centroid) vector for each cluster is plotted as follows:</p><div class="mediaobject"><img src="../Images/image01332.jpeg" alt="Evaluating the results"/><div class="caption"><p>A chart of means of clusters using K-means K=3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The means <a id="id4350000" class="indexterm"/>vectors of the three clusters are quite distinctive. The top and bottom means <span class="strong"><strong>1</strong></span> and <span class="strong"><strong>2</strong></span> in the chart have the respective standard deviation of 0.34 and 0.27 and share a very similar pattern. The difference between the elements of the <span class="strong"><strong>1</strong></span> and <span class="strong"><strong>2</strong></span> cluster mean vectors is almost constant: 0.37. The cluster with a mean vector <span class="strong"><strong>3</strong></span> represents the group of stocks that behave like the stocks in cluster <span class="strong"><strong>2</strong></span> at the beginning of the time period and behave like the stocks in cluster <span class="strong"><strong>1</strong></span> toward the end of the time period.</p><p>This behavior can be easily explained by the fact that the time window or trading period, the 80<sup>th</sup> to 130<sup>th</sup> trading day, correspond to the shift in the monetary policy of the federal reserve in regard to the quantitative easing program. Here is the partial list of stocks for each of the clusters whose centroid values are displayed on the chart:</p><div class="informaltable"><table border="1"><colgroup><col/><col/></colgroup><tbody><tr><td valign="top">
<p>
<span class="strong"><strong>Cluster 1</strong></span>
</p>
</td><td valign="top">
<p>AET, AHS, BBBY, BRCM, C, CB, CL, CLX, COH, CVX, CYH, DE, …</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>Cluster 2</strong></span>
</p>
</td><td valign="top">
<p>AA, AAPL, ADBE, ADSK, AFAM, AMZN, AU, BHI, BTU, CAT, CCL, … </p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>Cluster 3</strong></span>
</p>
</td><td valign="top">
<p>ADM, ADP, AXP, BA, BBT, BEN, BK, BSX, CA, CBS, CCE, CELG, CHK, …</p>
</td></tr></tbody></table></div><p>Let's evaluate the impact of the number of clusters <span class="emphasis"><em>K</em></span> on the characteristics of each cluster.</p></div><div class="section" title="Tuning the number of clusters"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5300"/>Tuning the number of clusters</h3></div></div></div><p>We <a id="id4360000" class="indexterm"/>repeat the previous test on the 127 stocks and the same time window with the number of clusters varying from 2 to 15.</p><p>The mean (or centroid) vector for each cluster for <span class="emphasis"><em>K = 2 </em></span>is plotted as follows:</p><div class="mediaobject"><img src="../Images/image01333.jpeg" alt="Tuning the number of clusters"/><div class="caption"><p>A chart of means of clusters using K-means K=2</p></div></div><p style="clear:both; height: 1em;"> </p><p>The chart of the results of the K-means algorithms with 2 clusters shows that the mean vector for the cluster labeled <span class="strong"><strong>2</strong></span> is similar to the mean vector labeled <span class="strong"><strong>3</strong></span> on the chart with <span class="emphasis"><em>K = 5</em></span> clusters. However, the cluster with the mean vector <span class="strong"><strong>1</strong></span> reflects somewhat the aggregation or summation of the mean vectors for the clusters <span class="strong"><strong>1</strong></span>and <span class="strong"><strong>3</strong></span> in the chart <span class="emphasis"><em>K = 5</em></span>. The aggregation effect explains why the standard deviation for the cluster <span class="strong"><strong>1</strong></span> (0.55) is twice as much as the standard deviation for the cluster <span class="strong"><strong>2</strong></span> (0.28).</p><p>The mean (or centroid) vector for each cluster for <span class="emphasis"><em>K = 5</em></span> is plotted as follows:</p><div class="mediaobject"><img src="../Images/image01334.jpeg" alt="Tuning the number of clusters"/><div class="caption"><p>A chart of means of clusters using K-means K=5</p></div></div><p style="clear:both; height: 1em;"> </p><p>In this chart, we <a id="id4370000" class="indexterm"/>can assess that the clusters <span class="strong"><strong>1</strong></span> (with the highest mean), <span class="strong"><strong>2</strong></span> (with the lowest mean), and <span class="strong"><strong>3</strong></span> are very similar to the clusters with the same labels in the chart for <span class="emphasis"><em>K = 3</em></span>. The cluster with the mean vector <span class="strong"><strong>4</strong></span> contains stocks whose behaviors are quite similar to those in cluster <span class="strong"><strong>3</strong></span>, but in the opposite direction. In other words, the stocks in cluster <span class="strong"><strong>3</strong></span> and <span class="strong"><strong>4</strong></span> reacted in opposite ways following the announcement of the change in the monetary policy.</p><p>In the tests with high values of <span class="emphasis"><em>K</em></span>, the distinction between the different clusters becomes murky, as shown in the following chart for <span class="emphasis"><em>K = 10</em></span>:</p><div class="mediaobject"><img src="../Images/image01335.jpeg" alt="Tuning the number of clusters"/><div class="caption"><p>A chart of means of clusters using K-means K=10</p></div></div><p style="clear:both; height: 1em;"> </p><p>The means for<a id="id4380000" class="indexterm"/> clusters <span class="strong"><strong>1</strong></span>, <span class="strong"><strong>2</strong></span>, and <span class="strong"><strong>3</strong></span> seen in the first chart for the case <span class="emphasis"><em>K = 2</em></span> are still visible. It is fair to assume that these are very likely the most reliable clusters. These clusters happened to have a low standard deviation or high density.</p><p>Let's define the density of a cluster, <span class="emphasis"><em>C<sub>j</sub></em></span>, with a centroid, <span class="emphasis"><em>c<sub>j</sub></em></span>, as the inverse of the Euclidean distance between all the members of each cluster and its mean (or centroid) (M6):</p><div class="mediaobject"><img src="../Images/image01336.jpeg" alt="Tuning the number of clusters"/></div><p style="clear:both; height: 1em;"> </p><p>The density of the cluster is plotted against the number of clusters with <span class="emphasis"><em>K = 1</em></span> to <span class="emphasis"><em>K = 13</em></span>:</p><div class="mediaobject"><img src="../Images/image01337.jpeg" alt="Tuning the number of clusters"/><div class="caption"><p>A bar chart of the average cluster density for K = 1 to 13</p></div></div><p style="clear:both; height: 1em;"> </p><p>As expected, the <a id="id4390000" class="indexterm"/>average density of each cluster increases as <span class="emphasis"><em>K</em></span> increases. From this experiment, we can draw the simple conclusion that the density of each cluster does not significantly increase in the test runs for <span class="emphasis"><em>K = 5</em></span> and beyond. You may observe that the density does not always increase as the number of clusters increases (<span class="emphasis"><em>K = 6</em></span> and <span class="emphasis"><em>K = 11</em></span>). The anomaly can be explained by the following three factors:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The original data is noisy</li><li class="listitem">The model is somewhat dependent on the initialization of the centroids</li><li class="listitem">The exit condition is too loose</li></ul></div></div><div class="section" title="Validation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5400"/>Validation</h3></div></div></div><p>There are <a id="id4400000" class="indexterm"/>several methodologies to validate the output of a K-means algorithm from purity to mutual information [4:6]. One effective way to validate the output of a clustering algorithm is to label each cluster and run those clusters through a new batch of labeled observations. For example, if during one of these tests, you find that one of the clusters, <span class="emphasis"><em>CC</em></span>, contains most of the commodity-related stocks, then you can select another commodity-related stock, <span class="emphasis"><em>SC</em></span>, which is not part of the first batch, and run the entire clustering algorithm again. If <span class="emphasis"><em>SC</em></span> is a subset of <span class="emphasis"><em>CC</em></span>, then K-means has performed as expected. If this is the case, you should run a new set of stocks, some of which are commodity-related, and measure the number of true positives, true negatives, false positives, and false negatives. The values for the precision, recall, and F<sub>1</sub> score introduced in the <span class="emphasis"><em>Assessing a model</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, confirms<a id="id4410000" class="indexterm"/> whether the tuning parameters and labels you selected for your cluster are indeed correct.</p><div class="note" title="Note"><h3 class="title"><a id="note11800"/>Note</h3><p>
<span class="strong"><strong>F1 validation for K-means</strong></span>
</p><p>The quality of the clusters, as measured by the F<sub>1</sub> score, depends on the rule, policy, or formula used to label observations (that is, label a cluster with the industry with the highest relative percentage of stocks in the cluster). This process is quite subjective. The only sure way to validate a methodology is to evaluate several labeling schemes and select the one that generate the highest F<sub>1</sub> score.</p></div><p>An alternative to measure the homogeneity of the distribution of observations across the clusters is to compute the statistical entropy. A low entropy value indicates that the clusters have a low level of impurity. Entropy can be used to find the optimal number of clusters <span class="emphasis"><em>K</em></span>.</p><p>We reviewed some of the tuning parameters that affect the quality of the results of the K-means clustering, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Initial selection of a centroid</li><li class="listitem">Number of <span class="emphasis"><em>K</em></span> clusters </li></ul></div><p>In some cases, the similarity criterion (that is, the Euclidean distance or cosine distance) can have an impact on the <span class="emphasis"><em>cleanness</em></span> or density of the clusters.</p><p>The final and important consideration is the computational complexity of the K-means algorithm. The previous sections of the chapter described some of the performance issues with K-means and possible remedies.</p><p>Despite its many benefits, the K-means algorithm does not handle missing data or unobserved features very well. Features that depend on each other indirectly may in fact depend on a common hidden (also known as latent) feature. The expectation-maximization algorithm described in the next section addresses some of these limitations.</p></div></div><div class="section" title="The expectation-maximization algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6000"/>The expectation-maximization algorithm</h2></div></div></div><p>The <a id="id4420000" class="indexterm"/>expectation-maximization algorithm was<a id="id4430000" class="indexterm"/> originally introduced to estimate the maximum likelihood in the case of incomplete data [4:7]. It is an iterative method to compute the model features that maximize the likely estimate for observed values, taking into account unobserved values.</p><p>The iterative algorithm consists of computing the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The expectation, <span class="emphasis"><em>E</em></span>, of the maximum likelihood for the observed data by inferring the latent values (E-step)</li><li class="listitem">The model features that maximize the expectation <span class="emphasis"><em>E</em></span> (M-step)</li></ul></div><p>The <a id="id4440000" class="indexterm"/>expectation-maximization algorithm is <a id="id4450000" class="indexterm"/>applied to solve clustering problems by assuming that each latent variable follows a normal or Gaussian distribution. This is similar to the K-means algorithm for which the distance of each data point to the center of each cluster follows a Gaussian distribution [4:8]. Therefore, a set of latent variables is a mixture of Gaussian distributions.</p><div class="section" title="Gaussian mixture models"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5500"/>Gaussian mixture models</h3></div></div></div><p>Latent <a id="id4460000" class="indexterm"/>variables, <span class="emphasis"><em>Z<sub>i</sub></em></span>, can be visualized as the behavior (or symptoms) of a model (observed) <span class="emphasis"><em>X</em></span> for which <span class="emphasis"><em>Z</em></span> are the root causes of the behavior:</p><div class="mediaobject"><img src="../Images/image01338.jpeg" alt="Gaussian mixture models"/><div class="caption"><p>Visualization of observed and latent features</p></div></div><p style="clear:both; height: 1em;"> </p><p>The latent values, <span class="emphasis"><em>Z</em></span>, follow a Gaussian distribution. For the statisticians among us, the mathematics of a mixture model is described here:</p><div class="note" title="Note"><h3 class="title"><a id="note11900"/>Note</h3><p>
<span class="strong"><strong>Maximization of the log likelihood</strong></span>
</p><p>M7: If <span class="emphasis"><em>x = {x<sub>i</sub>}</em></span> is a set of observed features associated with latent features <span class="emphasis"><em>z = {z<sub>i</sub>}</em></span>, the probability for the feature <span class="emphasis"><em>x<sub>i</sub></em></span>, of the observation <span class="emphasis"><em>x</em></span>, given a model parameter <span class="emphasis"><em>θ</em></span>, is defined as:</p><div class="mediaobject"><img src="../Images/image01339.jpeg" alt="Gaussian mixture models"/></div><p style="clear:both; height: 1em;"> </p><p>M8: The objective is to maximize the likelihood, <span class="emphasis"><em>L(θ)</em></span>, as shown here:</p><div class="mediaobject"><img src="../Images/image01340.jpeg" alt="Gaussian mixture models"/></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="Overview of EM"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5600"/>Overview of EM</h3></div></div></div><p>As far as<a id="id4470000" class="indexterm"/> the implementation is concerned, the expectation-maximization algorithm can be broken down into three stages:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The computation of the log likelihood for the model features given some latent variables (initial step).</li><li class="listitem">The computation of the expectation of the log likelihood at iteration <span class="emphasis"><em>t</em></span> (E step).</li><li class="listitem">The maximization of the expectation at iteration <span class="emphasis"><em>t</em></span> (M step).</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note12100"/>Note</h3><p>
<span class="strong"><strong>The E step</strong></span>
</p><p>M9: The expectation, <span class="emphasis"><em>Q</em></span>, of the complete data log likelihood for the model parameters, <span class="emphasis"><em>θ<sub>n</sub></em></span>, at iteration, <span class="emphasis"><em>n</em></span>, is computed using the posterior distribution of latent variable, <span class="emphasis"><em>z</em></span>, <span class="emphasis"><em>p(z|x, θ)</em></span>, and the joint probability of the observation and the latent variable:</p><div class="mediaobject"><img src="../Images/image01341.jpeg" alt="Overview of EM"/></div><p style="clear:both; height: 1em;"> </p><p>
<span class="strong"><strong>The M-step</strong></span>
</p><p>M10: The expectation function <span class="emphasis"><em>Q</em></span> is maximized for the model features <span class="emphasis"><em>θ</em></span> to compute the model parameters <span class="emphasis"><em>θ<sub>n+1</sub></em></span> for the next iteration:</p><div class="mediaobject"><img src="../Images/image01342.jpeg" alt="Overview of EM"/></div><p style="clear:both; height: 1em;"> </p></div><p>A formal, detailed, but <a id="id4480000" class="indexterm"/>short mathematical formulation of the EM algorithm can be found in S. Borman's tutorial [4:9].</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5700"/>Implementation</h3></div></div></div><p>Let's <a id="id4490000" class="indexterm"/>implement the three steps (initial step, E step, and M step) in Scala. The internal calculations of the EM algorithm are a bit complex and overwhelming. You may not benefit much from the details of a specific implementation such as computation of the eigenvalues of the covariance matrix of the expectation of the log likelihood. This implementation hides some complexities using the Apache Commons Math library package [4:10].</p><div class="note" title="Note"><h3 class="title"><a id="note12300"/>Note</h3><p>
<span class="strong"><strong>The inner workings of EM</strong></span>
</p><p>You may want to download the source code for the implementation of the EM algorithm in the Apache Commons Math library, if you need to understand the condition for which an exception is thrown.</p></div><p>The expectation-maximization algorithm of the <code class="literal">MultivariateEM</code> type is implemented as a data transformation of an <code class="literal">ITransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>. The two arguments of the constructors are the number of <code class="literal">K</code> clusters (or gauss distribution) and the <code class="literal">xt</code> training set (line <code class="literal">1</code>). The constructor initializes the <code class="literal">V</code> type of the output as <code class="literal">EMCluster</code> (line <code class="literal">2</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MultivariateEM</strong></span>[T &lt;: AnyVal](<span class="strong"><strong>K</strong></span>: Int, 
     <span class="strong"><strong>xt</strong></span>: XVSeries[T])(implicit f: T =&gt; Double)
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Monitor[T] {  //<span class="strong"><strong>1</strong></span>
  type <span class="strong"><strong>V</strong></span> = EMCluster  //<span class="strong"><strong>2</strong></span>
  val model: Option[EMModel ] = train //3
  override def |&gt; : PartialFunction[U, Try[V]]
}</pre></div><p>The multivariate <a id="id4500000" class="indexterm"/>expectation-maximization class has a model that consists of a list of EM clusters of the <code class="literal">EMCluster</code> type. The <code class="literal">Monitor</code> trait is used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The information about an EM cluster, <code class="literal">EMCluster</code>, is defined by <code class="literal">key</code>, the centroid or <code class="literal">means</code> value, and <code class="literal">density</code> of the cluster that is the standard deviation of the distance of all the data points to the mean (line <code class="literal">4</code>):</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>EMCluster</strong></span>(key: Double, val means: DblArray, 
      val density: DblArray)   //<span class="strong"><strong>4</strong></span>
type <span class="strong"><strong>EMModel</strong></span> = List[EMCluster]</pre></div><p>The implementation of the EM algorithm in the <code class="literal">train</code> method uses the Apache Commons Math <code class="literal">MultivariateNormalMixture</code> for the Gaussian mixture model and <code class="literal">MultivariateNormalMixtureExpectationMaximization</code> for the EM algorithm:</p><div class="informalexample"><pre class="programlisting">  def <span class="strong"><strong>train</strong></span>: Option[EMModel ] = Try {
  val data: DblMatrix = xt  //<span class="strong"><strong>5</strong></span>
  val <span class="strong"><strong>multivariateEM</strong></span> = new EM(data)
  multivariateEM.fit( estimate(data, K) ) //<span class="strong"><strong>6</strong></span>

  val newMixture = multivariateEM.<span class="strong"><strong>getFittedModel</strong></span>  //<span class="strong"><strong>7</strong></span>
  val components = newMixture.getComponents.toList  //<span class="strong"><strong>8</strong></span>
  components.map(p =&gt;EMCluster(p.getKey, p.getValue.getMeans, 
                      p.getValue.getStandardDeviations)) //<span class="strong"><strong>9</strong></span>
} match {/* … */}</pre></div><p>Let's take a look at the main <code class="literal">train</code> method of the <code class="literal">MultivariateEM</code> wrapper class. The first step is to convert the time series into a primitive matrix of <code class="literal">Double</code> with observations/historical quotes as rows and the stock symbols as columns.</p><p>The <code class="literal">xt</code> time series of the <code class="literal">XVSeries[T]</code> type is converted to a <code class="literal">DblMatrix</code> through an induced implicit conversion (line <code class="literal">5</code>).</p><p>The initial mixture of Gaussian distributions can be provided by the user or can be extracted from the <code class="literal">estimate</code> datasets (line <code class="literal">6</code>). The <code class="literal">getFittedModel</code> triggers the M-step (line <code class="literal">7</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note12400"/>Note</h3><p>
<span class="strong"><strong>Conversion from Java and Scala collections</strong></span>
</p><p>Java primitives need to be converted to Scala types using the <code class="literal">import scala.collection.JavaConversions</code> package. For example, <code class="literal">java.util.List</code> is converted to <code class="literal">scala.collection.immutable.List</code> by invoking the <code class="literal">asScalaIterator</code> method of the <code class="literal">WrapAsScala</code> class, one of the base traits of <code class="literal">JavaConversions</code>.</p></div><p>The Apache <a id="id4510000" class="indexterm"/>Commons Math <code class="literal">getComponents</code> method returns a <code class="literal">java.util.List</code> that is converted to <code class="literal">scala.collection.immutable.List</code> by invoking the <code class="literal">toList</code> method (line <code class="literal">8</code>). Finally, the data transform returns a list of cluster information of the <code class="literal">EMCluster</code> type (line <code class="literal">9</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note12500"/>Note</h3><p>
<span class="strong"><strong>Third-party library exceptions</strong></span>
</p><p>Scala does not enforce the declaration of exceptions as part of the signature of a method. Therefore, there is no guarantee that all types of exceptions will be caught locally. This problem occurs when exceptions are thrown from a third-party library in two scenarios:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The documentation of the API does not list all the types of exceptions</li><li class="listitem">The library is updated and a new type of exception is added to a method</li></ul></div><p>One easy workaround is to leverage the Scala exception-handling mechanism:</p><div class="informalexample"><pre class="programlisting">Try {
     ..
} match {
    case Success(results) =&gt; …
    case Failure(exception)  =&gt; ...
}</pre></div></div></div><div class="section" title="Classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5800"/>Classification</h3></div></div></div><p>The classification<a id="id4520000" class="indexterm"/> of a new observation or data points is implemented by the <code class="literal">|&gt;</code> method:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] = {
  case x: Array[T] 
    if(isModel &amp;&amp; x.length == dimension(xt)) =&gt; 
  Try( model.map(_.minBy(c =&gt; euclidean(c.means,x))).get)
}</pre></div><p>The <code class="literal">|&gt;</code> method <a id="id4530000" class="indexterm"/>is similar to the <code class="literal">KMeans.|&gt;</code> classifier.</p></div><div class="section" title="Testing"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec5900"/>Testing</h3></div></div></div><p>Let's <a id="id4540000" class="indexterm"/>apply the <code class="literal">MultivariateEM</code> class to the clustering of the same 127 stocks used in evaluating the K-means algorithm.</p><p>As discussed in the <span class="emphasis"><em>The curse of dimensionality</em></span> section, the number of stocks (127) to analyze restricts the number of observations to be used by the EM algorithm. A simple option is to filter out some of the noise of the stock's prices and apply a simple sampling method. The maximum sampling rate is restricted by the frequencies in the spectrum of noises of different types in the historical price of every stock.</p><div class="note" title="Note"><h3 class="title"><a id="note12700"/>Note</h3><p>
<span class="strong"><strong>Filtering and sampling</strong></span>
</p><p>The preprocessing of the data using a combination of a simple moving average and fixed interval sampling prior to clustering is very rudimentary in this example. For instance, we cannot assume that the historical price of all the stocks share the same noise characteristics. The noise pattern in the quotation of momentum and heavily traded stocks is certainly different from blue-chip securities with a strong ownership, and these stocks are held by large mutual funds.</p><p>The sampling rate should take into account the spectrum of frequency of the noise. It should be set as at least twice the frequency of the noise with the lowest frequency.</p></div><p>The object of the test is to evaluate the impact of the sampling rate, <code class="literal">samplingRate</code>, and the number of <code class="literal">K</code> clusters used in the EM algorithm:</p><div class="informalexample"><pre class="programlisting">val K = 4; val period = 8
val <span class="strong"><strong>smAve</strong></span> = SimpleMovingAverage[Double](period)  //<span class="strong"><strong>10</strong></span>
val <span class="strong"><strong>pfnSmAve</strong></span> = smAve |&gt;    //<span class="strong"><strong>11</strong></span>

val obs = symbolFiles.map(sym =&gt; (
  for {
    xs &lt;- DataSource(sym, path, true, 1) |&gt;extractor //<span class="strong"><strong>12</strong></span>
    <span class="strong"><strong>values</strong></span> &lt;- <span class="strong"><strong>pfnSmAve</strong></span>(xs.head)  //<span class="strong"><strong>13</strong></span>
    y &lt;- Try {   
        values.view.zipWithIndex.drop(period+1).toVector
          .filter( _._2 % samplingRate == 0)
          .map( _._1).toArray //<span class="strong"><strong>14</strong></span>
    }
  } yield y).get) 

em(K, obs)  //<span class="strong"><strong>15</strong></span>
</pre></div><p>The first <a id="id4550000" class="indexterm"/>step is to create a simple moving average with a predefined period (line <code class="literal">10</code>), as described in the <span class="emphasis"><em>The simple moving average</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>. The test code instantiates the <code class="literal">pfnSmAve</code> partial function that implements the moving average computation (line <code class="literal">11</code>). The symbols of the stocks under consideration are extracted from the name of the files in the path directory. The historical data is contained in the CSV file whose name is <code class="literal">path/STOCK_NAME.csv</code> (line <code class="literal">12</code>).</p><p>The execution of the moving average (line <code class="literal">13</code>) generates a set of smoothed values that is sampled given a sampling rate, <code class="literal">samplingRate</code> (line <code class="literal">14</code>). Finally, the expectation-maximization algorithm is instantiated to cluster the sampled data in the <code class="literal">em</code> method (line <code class="literal">15</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>em</strong></span>(K: Int, obs: DblMatrix): Int = {
  val em = MultivariateEM[Double](K, obs.toVector) //<span class="strong"><strong>16</strong></span>
  show(s"${em.toString}")  //<span class="strong"><strong>17</strong></span>
}</pre></div><p>The <code class="literal">em</code> method instantiates the EM algorithm for a specific number <code class="literal">K</code> of clusters (line <code class="literal">16</code>). The content of the model is displayed by invoking <code class="literal">MultivariateEM.toString</code>. The results are aggregated, then displayed in a textual format on the standard output (line <code class="literal">17</code>).</p><p>The first test is to execute the EM algorithm with <span class="emphasis"><em>K = 3</em></span> clusters and a sampling period of 10 on data smoothed by a simple moving average with period of 8. The sampling of historical prices of the 127 stocks between January 1, 2013 and December 31, 2013 with a frequency of 0.1 hertz produces 24 data points. The following chart displays the mean of each of the three clusters:</p><div class="mediaobject"><img src="../Images/image01343.jpeg" alt="Testing"/><div class="caption"><p>A chart of the normalized means per cluster using EM K=3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The mean <a id="id4560000" class="indexterm"/>vectors of clusters <span class="strong"><strong>2</strong></span> and <span class="strong"><strong>3</strong></span> have similar patterns, which may suggest that a set of three clusters is accurate enough to provide a first insight into the similarity within groups of stocks. The following is a chart of the normalized standard deviation per cluster using EM with <span class="emphasis"><em>K = 3</em></span>:</p><div class="mediaobject"><img src="../Images/image01344.jpeg" alt="Testing"/><div class="caption"><p>A chart of the normalized standard deviation per cluster using EM K=3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The distribution<a id="id4570000" class="indexterm"/> of the standard deviation along with the mean vector of each cluster can be explained by the fact that the price of stocks from a couple of industries went down in synergy, while others went up as a semi-homogenous group following the announcement from the Federal Reserve that the monthly quantity of bonds purchased as part of the quantitative easing program would be reduced in the near future.</p><div class="note" title="Note"><h3 class="title"><a id="note12800"/>Note</h3><p>
<span class="strong"><strong>Relation to K-means</strong></span>
</p><p>You may wonder what is the relation between EM and K-means, as both the techniques address the same problem. The K-means algorithm assigns each observation uniquely to one and only one cluster. The EM algorithm assigns an observation based on posterior probability. K-means is a special case of the EM for Gaussian mixtures [4:11].</p></div></div><div class="section" title="The online EM algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6000"/>The online EM algorithm</h3></div></div></div><p>Online learning<a id="id4580000" class="indexterm"/> is a powerful strategy for training a clustering model when dealing with very large datasets. This strategy has regained interest from scientists lately. The description of the online EM algorithm is beyond the scope of this tutorial. However, you may need to know that there are several algorithms for online EM available if you ever have to deal with large datasets, such as<a id="id4590000" class="indexterm"/> batch EM, stepwise EM, incremental EM, and Monte Carlo EM [4:12].</p></div></div></div></div>
<div class="section" title="Dimension reduction"><div class="titlepage" id="aid-5AMKM2"><div><div><h1 class="title"><a id="ch04lvl1sec3200"/>Dimension reduction</h1></div></div></div><p>Without<a id="id4600000" class="indexterm"/> prior knowledge of the problem domain, data scientists include all possible features in their first attempt to create a classification, prediction, or regression model. After all, making assumptions is a poor and dangerous approach to reduce the search space. It is not uncommon for a model to use hundreds of features, adding complexity and significant computation costs to build and validate the model.</p><p>Noise filtering techniques reduce the sensitivity of the model to features that are associated with sporadic behavior. However, these noise-related features are not known prior to the training phase, and therefore, cannot be completely discarded. As a consequence, training of the model becomes a very cumbersome and time-consuming task.</p><p>Overfitting is another hurdle that can arise from a large feature set. A training set of limited size does not allow you to create an accurate model with a large number of features.</p><p>Dimension reduction techniques alleviate these problems by detecting features that have little influence on the overall model behavior.</p><p>There are three approaches to reduce the number of features in a model:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Statistical analysis solutions such as ANOVA for smaller feature sets</li><li class="listitem">Regularization and shrinking techniques, which are introduced in the <span class="emphasis"><em>Regularization</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span></li><li class="listitem">Algorithms that maximize the variance of the dataset by transforming the covariance matrix</li></ul></div><p>The next section introduces one of the most commonly used algorithms of the third category: principal component analysis.</p><div class="section" title="Principal components analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6100"/>Principal components analysis</h2></div></div></div><p>The purpose <a id="id4610000" class="indexterm"/>of principal components analysis<a id="id4620000" class="indexterm"/> is to transform the original set of features into a new set of ordered features by decreasing the order of variance. The original observations are transformed into a set of variables with a lower degree of correlation. Let's consider a model with two features, <span class="emphasis"><em>{x, y}</em></span>, and a set of observations, <span class="emphasis"><em>{x<sub>i</sub>, y<sub>i</sub>}</em></span>, plotted on the following chart:</p><div class="mediaobject"><img src="../Images/image01345.jpeg" alt="Principal components analysis"/><div class="caption"><p>Visualization of principal components analysis for a two-dimensional model</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> features are converted into two <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> variables (that is rotation) to appropriately match the distribution of observations. The variable with the highest variance is known as the first principal component. The variable with the n<sup>th</sup> highest variance is known as the n<sup>th</sup> principal component.</p><div class="section" title="Algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6100"/>Algorithm</h3></div></div></div><p>I <a id="id4630000" class="indexterm"/>highly recommend that you read the tutorial from Lindsay Smith [4:13] that describes the PCA algorithm in a very concrete and simple way using a two-dimensional model.</p><div class="note" title="Note"><h3 class="title"><a id="note12900"/>Note</h3><p>
<span class="strong"><strong>PCA and covariance matrix</strong></span>
</p><p>M11: The covariance of two <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> features with the observations set <span class="emphasis"><em>{x<sub>i</sub>, y<sub>i</sub>}</em></span> and their respective mean values is defined as:</p><div class="mediaobject"><img src="../Images/image01346.jpeg" alt="Algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="inlinemediaobject"><img src="../Images/image01347.jpeg" alt="Algorithm"/></span> and <span class="inlinemediaobject"><img src="../Images/image01348.jpeg" alt="Algorithm"/></span> are the<a id="id4640000" class="indexterm"/> respective mean values for the observations, <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span>.</p><p>M12: The covariance is computed from the Z-score of each observation:</p><div class="mediaobject"><img src="../Images/image01349.jpeg" alt="Algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M13: For a model with <span class="emphasis"><em>n</em></span> features, <span class="emphasis"><em>x<sub>i</sub></em></span>, the covariance matrix is defined as:</p><div class="mediaobject"><img src="../Images/image01350.jpeg" alt="Algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M14: The transformation of <span class="emphasis"><em>x</em></span> to <span class="emphasis"><em>X</em></span> consists of computing the eigenvalues of the covariance matrix:</p><div class="mediaobject"><img src="../Images/image01351.jpeg" alt="Algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M15: The eigenvalues are ranked by their decreasing order of variance. Finally, the <span class="emphasis"><em>m</em></span> top eigenvalues for which the cumulative of variance exceeds a predefined threshold (percentage of the trace of the matrix) are the principal components:</p><div class="mediaobject"><img src="../Images/image01352.jpeg" alt="Algorithm"/></div><p style="clear:both; height: 1em;"> </p></div><p>The algorithm<a id="id4650000" class="indexterm"/> is implemented in five steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute the Z-score for the observations by standardizing the mean and standard deviation.</li><li class="listitem">Compute the covariance matrix <span class="emphasis"><em>Σ</em></span> for the original set of observations.</li><li class="listitem">Compute the new covariance matrix <span class="emphasis"><em>Σ'</em></span> for the observations with the transformed features by extracting the eigenvalues and eigenvectors.</li><li class="listitem">Convert the matrix to rank eigenvalues by decreasing the order of variance. The ordered eigenvalues are the principal components.</li><li class="listitem">Select the principal components for which the total sum of variance exceeds a threshold by a percentage of the trace of the new covariance matrix.</li></ol><div style="height:10px; width: 1px"/></div><p>The extraction of principal components by diagonalization of the covariance matrix <span class="emphasis"><em>Σ</em></span> is visualized in the following diagram. The shades of grey used to represent the covariance value varies from white (lowest value) to black (highest value):</p><div class="mediaobject"><img src="../Images/image01353.jpeg" alt="Algorithm"/><div class="caption"><p>Visualization of the extraction of eigenvalues in PCA</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id4660000" class="indexterm"/>eigenvalues (variance of <span class="emphasis"><em>X</em></span>) are ranked by the decreasing order of their values. The PCA algorithm succeeds when the cumulative value of the last eigenvalues (the right-bottom section of the diagonal matrix) becomes insignificant.</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6200"/>Implementation</h3></div></div></div><p>The <a id="id4670000" class="indexterm"/>principal components analysis can be easily implemented using the Apache Commons Math library methods that compute the eigenvalues and eigenvectors. The <code class="literal">PCA</code> class is defined as a data transformation of the <code class="literal">ITransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><p>The <code class="literal">PCA</code> class has a single argument: the <code class="literal">xt</code> training set (line <code class="literal">1</code>). The output type has a <code class="literal">Double</code> for the projection of an observation along with the eigenvectors (line <code class="literal">2</code>). The constructor defines the z-score <code class="literal">norm</code> function (line <code class="literal">3</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>PCA</strong></span>[@specialized(Double) T &lt;: AnyVal](
    xt: XVSeries[T])(implicit f: T =&gt; Double) 
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Monitor[T] { //<span class="strong"><strong>1</strong></span>
  type <span class="strong"><strong>V</strong></span> = Double    //<span class="strong"><strong>2</strong></span>
  
  val norm = (xv: XVSeries[T]) =&gt;  zScores(xv) //<span class="strong"><strong>3</strong></span>
  val model: Option[PCAModel] = train //<span class="strong"><strong>4</strong></span>
  override def |&gt; : PartialFunction[U, Try[V]]
}</pre></div><p>The model for the PCA algorithm is defined by the <code class="literal">PCAModel</code> case class (line <code class="literal">4</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note13400"/>Note</h3><p>
<span class="strong"><strong>Triggering an implicit conversion</strong></span>
</p><p>Implicit conversions can be invoked through an assignment to fully declared variables. For example, the conversion from <code class="literal">XVSeries[T]</code> to <code class="literal">XVseries[Double]</code> is invoked by the declaring the type of the target variable: <code class="literal">val z: XVSeries[Double] = xv</code> (line <code class="literal">4</code>).</p></div><p>The model <a id="id4680000" class="indexterm"/>for the PCA algorithm, <code class="literal">PCAModel</code>, consists of the covariance matrix, <code class="literal">covariance</code> defined in the formula <span class="strong"><strong>M11,</strong></span> and array of eigenvalues computed in the formula <span class="strong"><strong>M16</strong></span>:</p><div class="informalexample"><pre class="programlisting">case class PCAModel(val <span class="strong"><strong>covariance</strong></span>: DblMatrix, 
   val <span class="strong"><strong>eigenvalues</strong></span>: DblArray)</pre></div><p>The <code class="literal">|&gt;</code> transformative method implements the computation of the principal components (that is, the eigenvector and eigenvalues):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[PCAModel] = <span class="strong"><strong>zScores</strong></span>(xt).map(x =&gt; { //<span class="strong"><strong>5</strong></span>
  val obs: DblMatrix = x.toArray
  val cov = new Covariance(obs).getCovarianceMatrix //<span class="strong"><strong>6</strong></span>

  val transform = new <span class="strong"><strong>EigenDecomposition</strong></span>(cov) //<span class="strong"><strong>7</strong></span>
  val <span class="strong"><strong>eigenVectors</strong></span> = transform.getV  //<span class="strong"><strong>8</strong></span>
    val eigenValues = 
           new ArrayRealVector(transform.getRealEigenvalues)

  val <span class="strong"><strong>covariance</strong></span> = obs.multiply(eigenVectors).getData  //<span class="strong"><strong>9</strong></span>
  PCAModel(covariance, eigenValues.toArray)   //<span class="strong"><strong>10</strong></span>
}) match {/* … */}</pre></div><p>The normalization function <code class="literal">zScores</code> the Z-score transformation (formula <span class="strong"><strong>M12</strong></span>) (line <code class="literal">5</code>). Next, the method computes the <code class="literal">covariance</code> matrix from the normalized data (line <code class="literal">6</code>). The eigenvectors, <code class="literal">eigenVectors</code>, are computed (line <code class="literal">7</code>) and then retrieved using the <code class="literal">getV</code> method in the Apache Commons Math <code class="literal">EigenDecomposition</code> class (line <code class="literal">8</code>). The method computes the diagonal, transformed covariance matrix from the eigenvector (line <code class="literal">9</code>). Finally, the data transformation returns an instance of the PCA model (line <code class="literal">10</code>).</p><p>The <code class="literal">|&gt;</code> predictive method consists of projecting an observation onto the principal components:</p><div class="informalexample"><pre class="programlisting">override def <code class="literal">|&gt;</code> : PartialFunction[Array[T], Try[V]] = {
  case x: Array[T] 
     if(isModel &amp;&amp; x.length == dimension(xt)) =&gt; 
        Try( inner(x, model.get.eigenvalues) )
}</pre></div><p>The <code class="literal">inner</code> method of the <code class="literal">XTSeries</code> object computes the dot product of the values <code class="literal">x</code> and the <code class="literal">eigenvalues</code> model.</p></div><div class="section" title="Test case"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6300"/>Test case</h3></div></div></div><p>Let's apply<a id="id4690000" class="indexterm"/> the PCA algorithm to extract a subset of the features that represents some of the financial metrics ratios of 34 S&amp;P 500 companies. The metrics under consideration are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Trailing Price-to-Earnings ratio (PE)</li><li class="listitem">Price-to-Sale ratio (PS)</li><li class="listitem">Price-to-Book ratio (PB)</li><li class="listitem">Return on Equity (ROE)</li><li class="listitem">Operation Margin (OM)</li></ul></div><p>The financial metrics are described in the <span class="emphasis"><em>Terminology</em></span> section under <span class="emphasis"><em>Finances 101</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The input data is specified with the following format as a tuple (a ticker symbol and an array of five financial ratios, PE, PS, PB, ROE, and OM):</p><div class="informalexample"><pre class="programlisting">val data = Array[(String, DblVector)] (
  // Ticker              PE     PS     PB   ROE    OM
  ("QCOM", Array[Double](20.8, 5.32, 3.65, 17.65,29.2)),
  ("IBM",  Array[Double](13, 1.22, 12.2, 88.1,19.9)), 
   …
)</pre></div><p>The client code that executes the PCA algorithm is defined simply as follows:</p><div class="informalexample"><pre class="programlisting">val dim = data.head._2.size
val <span class="strong"><strong>input</strong></span> = data.map( _._2.take(dim)) 
val pca = new PCA[Double](input) //<span class="strong"><strong>11</strong></span>
show(s"PCA model: ${pca.toString}")  //<span class="strong"><strong>12</strong></span>
</pre></div><p>The PCA is instantiated with the <code class="literal">input</code> data (line <code class="literal">11</code>) and then displayed in a textual format (line <code class="literal">12</code>).</p></div><div class="section" title="Evaluation"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6400"/>Evaluation</h3></div></div></div><p>The first<a id="id4700000" class="indexterm"/> test on the 34 financial ratios uses a model that has five dimensions. As expected, the algorithm produces a list of five ordered eigenvalues:</p><p>
<span class="emphasis"><em>2.5321, 1.0350, 0.7438, 0.5218, 0.3284</em></span>
</p><p>Let's plot the relative value of the eigenvalues (that is, relative importance of each feature) on <a id="id4710000" class="indexterm"/>the following bar chart:</p><div class="mediaobject"><img src="../Images/image01354.jpeg" alt="Evaluation"/><div class="caption"><p>Distribution of eigenvalues in PCA for 5 dimensions</p></div></div><p style="clear:both; height: 1em;"> </p><p>The chart shows that three out of five features account for 85 percent of the total variance (trace of the transformed covariance matrix). I invite you to experiment with different combinations of these features. The selection of a subset of the existing features is as simple as applying Scala's <code class="literal">take</code> or <code class="literal">drop</code> methods:</p><div class="informalexample"><pre class="programlisting">data.map( _._2.<span class="strong"><strong>take</strong></span>(dim))</pre></div><p>Let's plot the cumulative eigenvalues for the three different model configurations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Five features</strong></span>: PE, PS, PB, ROE, and OM</li><li class="listitem"><span class="strong"><strong>Four features</strong></span>: PE, PS, PB, and ROE</li><li class="listitem"><span class="strong"><strong>Three features</strong></span>: PE, PS, and PB</li></ul></div><p>The graph will be as follows:</p><div class="mediaobject"><img src="../Images/image01355.jpeg" alt="Evaluation"/><div class="caption"><p>Distribution of eigenvalues in PCA for 3, 4, and 5 features</p></div></div><p style="clear:both; height: 1em;"> </p><p>The chart<a id="id4720000" class="indexterm"/> displays the cumulative value of eigenvalues that are the variance of the transformed features, <span class="emphasis"><em>X<sub>i</sub></em></span>. If we apply a threshold of 90 percent to the cumulative variance, then the number of principal components for each test model is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>{PE, PS, PB}</strong></span>: 2</li><li class="listitem"><span class="strong"><strong>{PE, PS, PB, ROE}</strong></span>:3</li><li class="listitem"><span class="strong"><strong>{PE, PS, PB, ROE, OM}</strong></span>: 3</li></ul></div><p>In conclusion, the PCA algorithm reduced the dimension of the model by 33 percent for the three-feature model, 25 percent for the four-feature model, and 40 percent for the five-feature model for a threshold of 90 percent.</p><div class="note" title="Note"><h3 class="title"><a id="note13500"/>Note</h3><p>
<span class="strong"><strong>Cross-validation of PCA</strong></span>
</p><p>Like any other unsupervised learning technique, the resulting principal components have to be validated through a one or K-fold cross-validation methodology using a regression estimator such as <a id="id4730000" class="indexterm"/><span class="strong"><strong>Partial Least Square Regression</strong></span> (PLSR) or the <a id="id4740000" class="indexterm"/><span class="strong"><strong>Predicted Residual Error Sum of Squares</strong></span> (<span class="strong"><strong>PRESS</strong></span>). For those who are not afraid of statistics, I recommend that you read <span class="emphasis"><em>Fast Cross-validation in Robust PCA</em></span> by <span class="emphasis"><em>S. Engelen and M. Hubert</em></span> [4:14]. You need to be aware of the fact that the implementation of these regression estimators is not simple. The validation of the PCA is beyond the scope of this book.</p></div><p>Principal components analysis<a id="id4750000" class="indexterm"/> is a special case of the more general factor analysis. The latter class of algorithm does not require the transformation of the covariance matrix to be orthogonal.</p></div></div><div class="section" title="Non-linear models"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6200"/>Non-linear models</h2></div></div></div><p>The <a id="id4760000" class="indexterm"/>principal components analysis technique requires<a id="id4770000" class="indexterm"/> the model to be linear. Although the study of such algorithms is beyond the scope of this book, it's worth mentioning two approaches that extend PCA for non-linear models:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Kernel PCA</li><li class="listitem">Manifold learning</li></ul></div><div class="section" title="Kernel PCA"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6500"/>Kernel PCA</h3></div></div></div><p>PCA extracts <a id="id4780000" class="indexterm"/>a set of orthogonal linear projections of an array of correlated values, <span class="emphasis"><em>X = {x<sub>i</sub>}</em></span>. The kernel PCA algorithm consists of extracting a similar set of orthogonal projection of the inner product matrix, <span class="emphasis"><em>X<sup>T</sup>X</em></span>. Nonlinearity is supported by applying a kernel function to the inner product. Kernel functions are described in the <span class="emphasis"><em>Kernel functions</em></span> section in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>. The kernel PCA is an attempt to extract a low dimension feature set (or manifold) from the original observation space. The linear PCA is the projection on the tangent space of the manifold.</p></div><div class="section" title="Manifolds"><div class="titlepage"><div><div><h3 class="title"><a id="ch04lvl3sec6600"/>Manifolds</h3></div></div></div><p>The <a id="id4790000" class="indexterm"/>concept of a manifold is borrowed from differential geometry. <span class="strong"><strong>Manifolds</strong></span> generalize the notions of curves in a two-dimension space or surfaces in a three dimension space to a higher dimension. Nonlinear models are associated with Riemann manifolds whose metric is the inner product, <span class="emphasis"><em>X<sup>T</sup>X</em></span>, on a tangent space. The manifold represents a low dimension feature space embedded into the original observation space. The idea is to project the principal components from the linear tangent space to a manifold using a exponential map. This feat is accomplished using a variety of techniques from Local Linear Embedding and density preserving maps to Laplacian Eigenmaps [4:15].</p><p>The<a id="id4800000" class="indexterm"/> vector of observations cannot be directly used on a manifold because metrics such as norms or inner products depend on the location of the manifold the vector is applied to. Computation on manifolds relies on tensors such as contravariant and covariant vectors. Tensors algebra is supported by covariant and contravariant functors, which is introduced in the <span class="emphasis"><em>Abstraction</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p><p>Techniques that use differentiable manifolds are known as spectral dimensionality reduction.</p><div class="note" title="Note"><h3 class="title"><a id="note13600"/>Note</h3><p>
<span class="strong"><strong>Alternative dimension reduction techniques</strong></span>
</p><p>Here are some more alternative techniques, listed as references: factor analysis, principal factor analysis, maximum likelihood factor analysis, independent component analysis, Random projection, nonlinear ICA, Kohonen's self-organizing maps, neural networks, and multidimensional scaling, just to name a few [4:16].</p></div><p>Manifold learning algorithms such as classifiers and dimension reduction techniques are associated with semi-supervised learning.</p></div></div></div>
<div class="section" title="Performance considerations" id="aid-5BL581"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec3300"/>Performance considerations</h1></div></div></div><p>The <a id="id4810000" class="indexterm"/>three unsupervised learning techniques share the same limitation—a high computational complexity.</p><div class="section" title="K-means"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6300"/>K-means</h2></div></div></div><p>The <a id="id4820000" class="indexterm"/>K-means has the computational complexity of <span class="emphasis"><em>O(iKnm)</em></span>, where <span class="emphasis"><em>i</em></span> is the number of iterations (or recursions), <span class="emphasis"><em>K</em></span> is the number of clusters, <span class="emphasis"><em>n</em></span> is the number of observations, and <span class="emphasis"><em>m</em></span> is the number of features. Here are some remedies to the poor performance of the K-means algorithm:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Reducing the average number of iterations by seeding the centroid using a technique such as initialization by ranking the variance of the initial cluster, as described in the beginning of this chapter</li><li class="listitem">Using <a id="id4830000" class="indexterm"/>a parallel implementation of K-means and leveraging a large-scale framework such as Hadoop or Spark</li><li class="listitem">Reducing the number of outliers and features by filtering out the noise with a smoothing algorithm such as a discrete Fourier transform or a Kalman filter</li><li class="listitem">Decreasing the dimensions of the model by following a two-step process:<div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Execute a first pass with a smaller number of clusters <span class="emphasis"><em>K</em></span> and/or a loose exit condition regarding the reassignment of data points. The data points close to each centroid are aggregated into a single observation.</li><li class="listitem">Execute a second pass on the aggregated observations.</li></ol><div style="height:10px; width: 1px"/></div></li></ul></div></div><div class="section" title="EM"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6400"/>EM</h2></div></div></div><p>The <a id="id4840000" class="indexterm"/>computational complexity of the expectation-maximization algorithm for each iteration (E + M steps) is <span class="emphasis"><em>O(m<sup>2</sup>n)</em></span>, where <span class="emphasis"><em>m</em></span> is the number of hidden or latent variables and <span class="emphasis"><em>n</em></span> is the number of observations.</p><p>A partial list of suggested performance improvement includes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Filtering of raw data to remove noise and outliers</li><li class="listitem">Using a sparse matrix on a large feature set to reduce the complexity of the covariance matrix, if possible</li><li class="listitem">Applying the Gaussian mixture model wherever possible—the assumption of Gaussian distribution simplifies the computation of the log likelihood</li><li class="listitem">Using a parallel data processing framework such as Apache Hadoop or Spark, as discussed in the <span class="emphasis"><em>Apache Spark</em></span> section in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span></li><li class="listitem">Using a kernel function to reduce the estimate of covariance in the E-step</li></ul></div></div><div class="section" title="PCA"><div class="titlepage"><div><div><h2 class="title"><a id="ch04lvl2sec6500"/>PCA</h2></div></div></div><p>The <a id="id4850000" class="indexterm"/>computational complexity of the extraction of the principal components is <span class="emphasis"><em>O(m<sup>2</sup>n + n<sup>3</sup>)</em></span>, where <span class="emphasis"><em>m</em></span> is the number of features and <span class="emphasis"><em>n</em></span> is the number of observations. The first term represents the computational complexity for computing the covariance matrix. The second term reflects the computational complexity of the eigenvalue decomposition.</p><p>The list <a id="id4860000" class="indexterm"/>of potential performance improvements or alternative solutions for PCA includes the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Assuming that the variance is Gaussian</li><li class="listitem">Using a sparse matrix to compute eigenvalues for problems with large feature sets and missing data</li><li class="listitem">Investigating alternatives to PCA to reduce the dimension of a model such as the <a id="id4870000" class="indexterm"/><span class="strong"><strong>discrete Fourier transform</strong></span> (<span class="strong"><strong>DFT</strong></span>) or <a id="id4880000" class="indexterm"/><span class="strong"><strong>singular value decomposition</strong></span> (<span class="strong"><strong>SVD</strong></span>) [4:17]</li><li class="listitem">Using PCA in conjunction with EM (at the research stage)</li><li class="listitem">Deploying a dataset on a parallel data processing framework such as Apache Hadoop or Spark, as described in the <span class="emphasis"><em>Apache Spark</em></span> section in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span></li></ul></div></div></div>
<div class="section" title="Summary" id="aid-5CJLQ1"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec3400"/>Summary</h1></div></div></div><p>This completes the overview of three of the most commonly used unsupervised learning techniques:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">K-means for clustering fully observed features of a model with reasonable dimensions</li><li class="listitem">Expectation-maximization for clustering a combination of observed and latent features</li><li class="listitem">Principal components analysis to transform and extract the most critical features in terms of variance for linear models</li></ul></div><p>Manifold learning for non-linear models is a technically challenging field with great potential in terms of dynamic object recognition [4:18].</p><p>The key point to remember is that unsupervised learning techniques are used:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">By themselves to extract structures and associations from unlabelled observations</li><li class="listitem">As a preprocessing stage to supervised learning in reducing the number of features prior to the training phase</li></ul></div><p>The distinction between unsupervised and supervised learning is not as strict as you may think. For instance, the K-means algorithm can be enhanced to support classification.</p><p>In the next chapter, we will address the second use case and cover supervised learning techniques starting with generative models.</p></div>
<div class="chapter" title="Chapter&#xA0;5.&#xA0;Na&#xEF;ve Bayes Classifiers" id="aid-5DI6C1"><div class="titlepage"><div><div><h1 class="title"><a id="ch19"/>Chapter 5. Naïve Bayes Classifiers</h1></div></div></div><p>This chapter introduces the most common and simple generative classifiers—Naïve Bayes. As mentioned earlier, generative classifiers are supervised learning algorithms that attempt to fit a <span class="emphasis"><em>joint probability distribution p(X,Y)</em></span> of two <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> events, representing two sets of observed and hidden (or latent) variables, <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span>.</p><p>In this chapter, you will learn, and hopefully appreciate, the simplicity of the Naïve Bayes technique through a concrete example. Then, you will learn how to build a Naïve Bayes classifier to predict the stock price movement, given some prior technical indicators in the analysis of financial markets.</p><p>Finally, you will learn how to apply Naïve Bayes to text mining by predicting stock prices using financial news feed and press releases.</p><div class="section" title="Probabilistic graphical models"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec3500"/>Probabilistic graphical models</h1></div></div></div><p>Let's start with a <a id="id4890000" class="indexterm"/>refresher course in basic statistics.</p><p>Given two events or observations <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span>, the joint probability of <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> is defined as <span class="emphasis"><em>p(X,Y) = p(X∩Y)</em></span>. If the <a id="id4900000" class="indexterm"/>observations <span class="emphasis"><em>X</em></span> and <span class="emphasis"><em>Y</em></span> are not related, an assumption known as conditional independence, then <span class="emphasis"><em>p(X,Y) = p(X).p(Y)</em></span>. The conditional probability of an event <span class="emphasis"><em>Y</em></span>, given <span class="emphasis"><em>X</em></span>, is defined as <span class="emphasis"><em>p(Y|X) = p(X,Y)/p(X)</em></span>.</p><p>These two definitions are quite simple. However, <span class="strong"><strong>probabilistic reasoning</strong></span> can be difficult to read <a id="id4910000" class="indexterm"/>in the case of large numbers of variables and sequences of conditional probabilities. As a picture is worth a thousand words, researchers introduced <a id="id4920000" class="indexterm"/><span class="strong"><strong>graphical models</strong></span> to describe a probabilistic relation between random variables using graphs [5:1].</p><p>There are two categories of graphs, and therefore, graphical models, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Directed graphs such as Bayesian networks</li><li class="listitem">Undirected graphs such as conditional random fields (refer to the <span class="emphasis"><em>Conditional random fields</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>)</li></ul></div><p>
<span class="strong"><strong>Directed graphical models</strong></span> <a id="id4930000" class="indexterm"/>are directed acyclic graphs that have been introduced to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Provide a simple way to visualize a probabilistic model</li><li class="listitem">Describe the conditional dependence between variables</li><li class="listitem">Represent a statistical inference in terms of connectivity between graphical objects</li></ul></div><p>A Bayesian network<a id="id4940000" class="indexterm"/> is a directed graphical model that defines a joint probability over a set of variables [5:2].</p><p>The two joint probabilities <span class="emphasis"><em>p(X,Y)</em></span> and <span class="emphasis"><em>p(X,Y,Z)</em></span> can be graphically modeled using Bayesian networks, as follows:</p><div class="mediaobject"><img src="../Images/image01356.jpeg" alt="Probabilistic graphical models"/><div class="caption"><p>Examples of probabilistic graphical models</p></div></div><p style="clear:both; height: 1em;"> </p><p>The conditional probability <span class="emphasis"><em>p(Y|X)</em></span> is represented by an arrow directed from the output (or symptoms) <span class="emphasis"><em>Y</em></span> to the input (or cause) <span class="emphasis"><em>X</em></span>. Elaborate models can be described as a large directed graph between variables.</p><div class="note" title="Note"><h3 class="title"><a id="note13700"/>Note</h3><p>
<span class="strong"><strong>A metaphor for graphical models</strong></span>
</p><p>From a software <a id="id4950000" class="indexterm"/>engineering perspective, graphical models visualize probabilistic equations in the same way the UML class diagram visualizes the object-oriented source code.</p></div><p>Here is an example of a <a id="id4960000" class="indexterm"/>real-world Bayesian network; the functioning of a smoke detector:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">A fire may generate smoke.</li><li class="listitem">Smoke may trigger an alarm.</li><li class="listitem">A depleted battery may trigger an alarm.</li><li class="listitem">The alarm may alert the homeowner.</li><li class="listitem">The alarm may alert the fire department.</li></ol><div style="height:10px; width: 1px"/></div><p>The flow diagram is as follows:</p><div class="mediaobject"><img src="../Images/image01357.jpeg" alt="Probabilistic graphical models"/><div class="caption"><p>A Bayesian network for smoke detectors</p></div></div><p style="clear:both; height: 1em;"> </p><p>This representation may be a bit counterintuitive, as the vertices are directed from the symptoms (or output) to the cause (or input). Directed graphical models are used in many different models, besides Bayesian networks [5:3].</p><div class="note" title="Note"><h3 class="title"><a id="note13800"/>Note</h3><p>
<span class="strong"><strong>Plate models</strong></span>
</p><p>There are several alternate representations of probabilistic models, besides the directed acyclic graph, such as the plate model commonly <a id="id4970000" class="indexterm"/>used for the <span class="strong"><strong>Latent Dirichlet Allocation</strong></span> (<span class="strong"><strong>LDA</strong></span>) [5:4].</p></div><p>The Naïve Bayes models <a id="id4980000" class="indexterm"/>are probabilistic models based on the Bayes's theorem under the assumption of features independence, as mentioned in the <span class="emphasis"><em>Generative models</em></span> section under <span class="emphasis"><em>Supervised learning</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p></div></div>
<div class="section" title="Na&#xEF;ve Bayes classifiers"><div class="titlepage" id="aid-5EGMU2"><div><div><h1 class="title"><a id="ch05lvl1sec3600"/>Naïve Bayes classifiers</h1></div></div></div><p>The conditional independence <a id="id4990000" class="indexterm"/>between <span class="emphasis"><em>X</em></span> features is an essential requirement for the Naïve Bayes classifier. It also restricts its applicability. The Naïve Bayes classification is better understood through simple and concrete examples [5:5].</p><div class="section" title="Introducing the multinomial Naïve Bayes"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec6600"/>Introducing the multinomial Naïve Bayes</h2></div></div></div><p>Let's <a id="id5000000" class="indexterm"/>consider the problem of how to <a id="id5010000" class="indexterm"/>predict a change in interest rates.</p><p>The first step is to list the factors that potentially may trigger or cause an increase or decrease in the interest rates. For the sake of illustrating Naïve Bayes, we <a id="id5020000" class="indexterm"/>will select the <span class="strong"><strong>consumer price index</strong></span> (<span class="strong"><strong>CPI</strong></span>) and change the <span class="strong"><strong>Federal fund rate</strong></span> (<span class="strong"><strong>FDF</strong></span>) <a id="id5030000" class="indexterm"/>and the <span class="strong"><strong>gross domestic product</strong></span> (<span class="strong"><strong>GDP</strong></span>), as <a id="id5040000" class="indexterm"/>the first set of features. The terminology is described in the <span class="emphasis"><em>Terminology</em></span> section under <span class="emphasis"><em>Finances 101</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The use case is used to predict the direction of the change in the yield <a id="id5050000" class="indexterm"/>of the <span class="strong"><strong>1-year Treasury bill</strong></span> (<span class="strong"><strong>1yTB</strong></span>), taking into account the change in the current CPI, FDF, and GDP. The objective is, therefore, to create a predictive model using a combination of these three features.</p><p>It is assumed that there is no available financial investment expert who can supply rules or policies to predict interest rates. Therefore, the model depends highly on the historical data. Intuitively, if one feature always increases when the yield of the 1-year Treasury bill increases, then we can conclude that there is a strong correlation of causal relationship between the features and the output variation in interest rates.</p><div class="mediaobject"><img src="../Images/image01358.jpeg" alt="Introducing the multinomial Naïve Bayes"/><div class="caption"><p>The Naive Bayes model for predicting the change in the yield of the 1-year T-bill</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id5060000" class="indexterm"/>correlation (or cause-effect relationship) is <a id="id5070000" class="indexterm"/>derived from the historical data. The methodology consists of counting the number of times each feature either increases (<span class="strong"><strong>UP</strong></span>) or decreases (<span class="strong"><strong>DOWN</strong></span>) and recording the corresponding expected outcome, as illustrated in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>ID</p>
</th><th valign="bottom">
<p>GDP</p>
</th><th valign="bottom">
<p>FDF</p>
</th><th valign="bottom">
<p>CPI</p>
</th><th valign="bottom">
<p>1y-TB</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="strong"><strong>1</strong></span>
</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>UP</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>2</strong></span>
</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>UP</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>3</strong></span>
</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>DOWN</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>4</strong></span>
</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>DOWN</p>
</td></tr><tr><td colspan="5" valign="top" style="text-align: center">
<p>…</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>256</strong></span>
</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>DOWN</p>
</td></tr></tbody></table></div><p>First, let's tabulate the number of occurrences of each change (<span class="strong"><strong>UP</strong></span> and <span class="strong"><strong>DOWN</strong></span>) for the three features and the output value (the direction of the change in the yield of the 1-year Treasury bill):</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Number</p>
</th><th valign="bottom">
<p>GDP</p>
</th><th valign="bottom">
<p>FDF</p>
</th><th valign="bottom">
<p>CPI</p>
</th><th valign="bottom">
<p>1yTB</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>169</p>
</td><td valign="top">
<p>184</p>
</td><td valign="top">
<p>175</p>
</td><td valign="top">
<p>159</p>
</td></tr><tr><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>97</p>
</td><td valign="top">
<p>72</p>
</td><td valign="top">
<p>81</p>
</td><td valign="top">
<p>97</p>
</td></tr><tr><td valign="top">
<p>Total</p>
</td><td valign="top">
<p>256</p>
</td><td valign="top">
<p>256</p>
</td><td valign="top">
<p>256</p>
</td><td valign="top">
<p>256</p>
</td></tr><tr><td valign="top">
<p>UP/Total</p>
</td><td valign="top">
<p>0.66</p>
</td><td valign="top">
<p>0.72</p>
</td><td valign="top">
<p>0.68</p>
</td><td valign="top">
<p>
<span class="strong"><strong>0.625</strong></span>
</p>
</td></tr></tbody></table></div><p>Next, let's compute the number of positive directions for each of the features when the yield of the<a id="id5080000" class="indexterm"/> 1-year Treasury bill increases (159 occurrences):</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Number</p>
</th><th valign="bottom">
<p>GDP</p>
</th><th valign="bottom">
<p>Fed Funds</p>
</th><th valign="bottom">
<p>CPI</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>UP</p>
</td><td valign="top">
<p>110</p>
</td><td valign="top">
<p>136</p>
</td><td valign="top">
<p>127</p>
</td></tr><tr><td valign="top">
<p>DOWN</p>
</td><td valign="top">
<p>49</p>
</td><td valign="top">
<p>23</p>
</td><td valign="top">
<p>32</p>
</td></tr><tr><td valign="top">
<p>Total</p>
</td><td valign="top">
<p>159</p>
</td><td valign="top">
<p>159</p>
</td><td valign="top">
<p>159</p>
</td></tr><tr><td valign="top">
<p>UP/Total</p>
</td><td valign="top">
<p>0.69</p>
</td><td valign="top">
<p>0.85</p>
</td><td valign="top">
<p>
<span class="strong"><strong>0.80</strong></span>
</p>
</td></tr></tbody></table></div><p>From the <a id="id5090000" class="indexterm"/>preceding table, we conclude that the yield of the 1-year Treasury bill increases when the GDP increases (69 percent of the time), the rate of the Federal funds increases (85 percent of the time), and the CPI increases (80 percent of the time).</p><p>Let's formalize the Naïve Bayes model before turning these findings into a probabilistic model.</p><div class="section" title="Formalism"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec6700"/>Formalism</h3></div></div></div><p>Let's start <a id="id5100000" class="indexterm"/>by clarifying the terminologies used in the Bayesian model:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Class prior probability or class prior</strong></span>: This <a id="id5110000" class="indexterm"/>is the <a id="id5120000" class="indexterm"/> probability of a class</li><li class="listitem"><span class="strong"><strong>Likelihood</strong></span>: This <a id="id5130000" class="indexterm"/>is the probability to observe a value or event, given a class, also known as the probability of the predictor, given a class</li><li class="listitem"><span class="strong"><strong>Evidence</strong></span>: This<a id="id5140000" class="indexterm"/> is the probability of observations that occur, also known as the prior probability of the predictor</li><li class="listitem"><span class="strong"><strong>Posterior probability</strong></span>: This <a id="id5150000" class="indexterm"/>is the probability of an observation <span class="emphasis"><em>x</em></span> being in a given class</li></ul></div><p>No model can be simpler! The log likelihood, <span class="emphasis"><em>log p(x<sub>i</sub>|C<sub>j</sub>)</em></span>, is commonly used instead of the likelihood in order to reduce the impact of the features <span class="emphasis"><em>x<sub>i</sub></em></span> that have a low likelihood.</p><p>The objective of the Naïve Bayes classification of a new observation is to compute the class that has the highest log likelihood. The mathematical notation <a id="id5160000" class="indexterm"/>for the Naïve Bayes model is also straightforward.</p><div class="note" title="Note"><h3 class="title"><a id="note13900"/>Note</h3><p>
<span class="strong"><strong>The Naïve Bayes classification</strong></span>
</p><p>M1: The posterior probability <span class="emphasis"><em>p(C<sub>j</sub>|x)</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01359.jpeg" alt="Formalism"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>x = {x<sub>i</sub>} (0, n-1)</em></span> is a set of <span class="emphasis"><em>n</em></span> features. <span class="emphasis"><em>{C<sub>j</sub>}</em></span> is a set of classes with their class prior <span class="emphasis"><em>p(C<sub>j</sub>)</em></span>. <span class="emphasis"><em>x = {x<sub>i</sub>} (0, n-1)</em></span> with a set of <span class="emphasis"><em>n</em></span> features. <span class="emphasis"><em>p(x|C<sub>j</sub>)</em></span> is the likelihood for each feature</p><p>M2: The computation of the posterior probability <span class="emphasis"><em>p(C<sub>j</sub>| x)</em></span> is simplified by the assumption of conditional independence of features:</p><div class="mediaobject"><img src="../Images/image01360.jpeg" alt="Formalism"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>x<sub>i</sub></em></span> are independent and the probabilities are normalized for evidence <span class="emphasis"><em>p(x) = 1</em></span>.</p><p>M3: The <span class="strong"><strong>maximum likelihood estimate</strong></span> (<span class="strong"><strong>MLE</strong></span>) is defined as:</p><div class="mediaobject"><img src="../Images/image01361.jpeg" alt="Formalism"/></div><p style="clear:both; height: 1em;"> </p><p>M4: The Naïve Bayes classification of an observation <span class="emphasis"><em>x</em></span> of a class <span class="emphasis"><em>C<sub>m</sub></em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01362.jpeg" alt="Formalism"/></div><p style="clear:both; height: 1em;"> </p></div><p>This particular use <a id="id5170000" class="indexterm"/>case has a major drawback—the GDP statistics are provided quarterly, while the CPI data is made available once a month and a change in FDF rate is rather infrequent.</p></div><div class="section" title="The frequentist perspective"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec6800"/>The frequentist perspective</h3></div></div></div><p>The ability <a id="id5180000" class="indexterm"/>to compute the posterior probability depends on the formulation of the likelihood using historical data. A simple solution is to count the occurrences of observations for each class and compute the frequency.</p><p>Let's consider the first example that predicts the direction of the change in the yield of the 1-year Treasury bill, given changes in the GDP, FDF, and CPI.</p><p>The results are expressed with simple probabilistic formulas and a directed graphical model:</p><div class="informalexample"><pre class="programlisting">P(GDP=UP|1yTB=UP) = 110/159
P(1yTB=UP) = num occurrences (1yTB=UP)/total num of occurrences=159/256
p(1yTB=UP|GDP=UP,FDF=UP,CPI=UP) = p(GDP=UP|1yTB=UP) x
                                  p(FDF=UP|1yTB=UP) x
                                  p(CPI=UP|1yTB=UP) x
                                  p(1yTB=UP) = 0.69 x 0.85 x 0.80 x 0.625</pre></div><div class="mediaobject"><img src="../Images/image01363.jpeg" alt="The frequentist perspective"/><div class="caption"><p>The Bayesian network for the prediction of the change of the yield of the 1-year Treasury bill</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note14400"/>Note</h3><p>
<span class="strong"><strong>Overfitting</strong></span>
</p><p>The <a id="id5190000" class="indexterm"/>Naïve Bayes model is not immune to overfitting if the number of observations is not large enough relative to the number of features. One approach to address this problem is to perform a feature selection using the mutual information exclusion [5:6].</p></div><p>This problem is not a good candidate for a Bayesian classification for the following two reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The training set is not large enough to compute accurate prior probabilities and generate a stable model. Decades of quarterly GDP data is needed to train and validate the model.</li><li class="listitem">The features have different rates of change, which predominately favor the features with the highest frequency; in this case, the CPI.</li></ul></div><p>Let's select <a id="id5200000" class="indexterm"/>another use case for which a large historical dataset is available and can be automatically labeled.</p></div><div class="section" title="The predictive model"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec6900"/>The predictive model</h3></div></div></div><p>The <a id="id5210000" class="indexterm"/>predictive model is the second use case <a id="id5220000" class="indexterm"/>that consists of predicting the direction of the change of the closing price of a stock, <span class="emphasis"><em>pr<sub>t+1</sub> = {UP, DOWN}</em></span>, at trading day <span class="emphasis"><em>t + 1</em></span>, given the history of its direction of the price, volume, and volatility for the previous <span class="emphasis"><em>t</em></span> days, <span class="emphasis"><em>pr<sub>i</sub></em></span> for <span class="emphasis"><em>i = 0</em></span> to <span class="emphasis"><em>i = t</em></span>. The volume and volatility features have already been used in the <span class="emphasis"><em>Writing a simple workflow</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p><p>Therefore, the three features under consideration are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The closing price <span class="emphasis"><em>pr<sub>t</sub></em></span> of the last trading session, <span class="emphasis"><em>t</em></span>, is above or below the average closing price over the <span class="emphasis"><em>n</em></span> previous trading days, <span class="emphasis"><em>[t-n, t]</em></span>.</li><li class="listitem">The volume of the last trading day <span class="emphasis"><em>vl<sub>t</sub></em></span> is above or below the average volume of the <span class="emphasis"><em>n</em></span> previous trading days</li><li class="listitem">The volatility on the last trading day <span class="emphasis"><em>vt<sub>t</sub></em></span> is above or below the average volatility of the previous <span class="emphasis"><em>n</em></span> trading days</li></ul></div><p>The directed <a id="id5230000" class="indexterm"/>graphic model can be expressed using one output variable (the price at session <span class="emphasis"><em>t + 1</em></span> is greater than the price at session <span class="emphasis"><em>t</em></span>) and three features: the price condition (1), volume condition (2), and volatility condition (3).</p><div class="mediaobject"><img src="../Images/image01364.jpeg" alt="The predictive model"/><div class="caption"><p>The Bayesian model for predicting the future direction of the stock price</p></div></div><p style="clear:both; height: 1em;"> </p><p>This model works under the assumption that there is at least one observation or ideally few observations for each feature and expected value.</p></div><div class="section" title="The zero-frequency problem"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7000"/>The zero-frequency problem</h3></div></div></div><p>It is possible <a id="id5240000" class="indexterm"/>that the training set does <a id="id5250000" class="indexterm"/>not contain any data actually observed for a feature for a specific label or class. In this case, the mean is <span class="emphasis"><em>0/N = 0</em></span>, and therefore, the likelihood is null, making classification unfeasible. The case for which there are only few observations for a feature in a given class is also an issue, as it skews the likelihood.</p><p>There are a <a id="id5260000" class="indexterm"/>couple of correcting or smoothing formulas for <a id="id5270000" class="indexterm"/>unobserved features or features with a low number of occurrences that address this issue, such as the <a id="id5280000" class="indexterm"/><span class="strong"><strong>Laplace</strong></span> and <a id="id5290000" class="indexterm"/><span class="strong"><strong>Lidstone</strong></span> smoothing formulas.</p><div class="note" title="Note"><h3 class="title"><a id="note14500"/>Note</h3><p>
<span class="strong"><strong>The smoothing factor for counters</strong></span>
</p><p>M5: The Laplace<a id="id5300000" class="indexterm"/> smoothing formula of the mean <span class="emphasis"><em>k/N</em></span> out of <span class="emphasis"><em>N</em></span> observations of features of dimension <span class="emphasis"><em>n</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01365.jpeg" alt="The zero-frequency problem"/></div><p style="clear:both; height: 1em;"> </p><p>M6: The Lidstone smoothing formula with a factor <span class="emphasis"><em>α </em></span>is defined as:</p><div class="mediaobject"><img src="../Images/image01366.jpeg" alt="The zero-frequency problem"/></div><p style="clear:both; height: 1em;"> </p></div><p>The two formulas are commonly used in natural language processing applications, for which the occurrence of a specific word or tag is a feature [5:7].</p></div></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec6700"/>Implementation</h2></div></div></div><p>I think it is <a id="id5310000" class="indexterm"/>time to write some Scala code and toy around with Naïve Bayes. Let's start with an overview of the software components.</p><div class="section" title="Design"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7100"/>Design</h3></div></div></div><p>Our<a id="id5320000" class="indexterm"/> implementation of the Naïve Bayes classifier uses the following components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A generic model, <code class="literal">NaiveBayesModel</code>, of the <code class="literal">Model</code> type that is initialized through training during the instantiation of the class.</li><li class="listitem">A model for the <code class="literal">BinNaiveBayesModel</code> binomial classification, which subclasses <code class="literal">NaiveBayesModel</code>. The model consists of a pair of positive and negative <code class="literal">Likelihood</code> class instances.</li><li class="listitem">A model for the <code class="literal">MultiNaiveBayesModel</code> multinomial classification.</li><li class="listitem">The <code class="literal">NaiveBayes</code> classifier class has four parameters: a smoothing function, such as Laplace and a set of observations of the <code class="literal">XVSeries</code> type, a set of labels of the <code class="literal">DblVector</code> type, a log density function of the <code class="literal">LogDensity</code> type, and the number of classes.</li></ul></div><p>The principle of software architecture applied to the implementation of classifiers is described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The key software components of the Naïve Bayes classifier are described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01367.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the Naive Bayes classifier</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram omits the helper traits or classes such as <code class="literal">Monitor</code> or Apache Commons <a id="id5330000" class="indexterm"/>Math components.</p></div><div class="section" title="Training"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7200"/>Training</h3></div></div></div><p>The objective of the<a id="id5340000" class="indexterm"/> training phase is to build <a id="id5350000" class="indexterm"/>a model consisting of the likelihood for each feature and the class prior. The likelihood for a feature is identified as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The number of occurrences <span class="emphasis"><em>k</em></span> of this feature for <span class="emphasis"><em>N &gt; k</em></span> observations in the case of binary features or counters</li><li class="listitem">The mean value for all the observations for this feature in the case of numeric or continuous features</li></ul></div><p>It is assumed, for the sake of this test case, that the features, that is, technical analysis indicators, such as price, volume, and volatility are conditionally independent. This assumption is not actually correct.</p><div class="note" title="Note"><h3 class="title"><a id="note14700"/>Note</h3><p>
<span class="strong"><strong>Conditional dependency</strong></span>
</p><p>Recent <a id="id5360000" class="indexterm"/>models, known as<a id="id5370000" class="indexterm"/> <span class="strong"><strong>Hidden Naïve Bayes</strong></span> (<span class="strong"><strong>HNB</strong></span>), relax the restrictions on the independence between features. The HNB algorithm uses conditional mutual information to describe the interdependency between some of the features [5:8].</p></div><p>Let's write the code to train the binomial and multinomial Naïve Bayes.</p><div class="section" title="Class likelihood"><div class="titlepage"><div><div><h4 class="title"><a id="ch05lvl4sec1200"/>Class likelihood</h4></div></div></div><p>The first step is to define <a id="id5380000" class="indexterm"/>the class likelihood for each feature using historical data. The <code class="literal">Likelihood</code> class has the following attributes (line <code class="literal">1</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The label for the <code class="literal">label</code> observation</li><li class="listitem">An array of tuple Laplace or Lidstone smoothed mean and standard deviation, <code class="literal">muSigma</code></li><li class="listitem">The prior probability of a <code class="literal">prior</code> class</li></ul></div><p>As with any code snippet presented in this book, the validation of class parameters and method arguments are omitted in order to keep the code readable:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Likelihood</strong></span>[T &lt;: AnyVal](
     val <span class="strong"><strong>label</strong></span>: Int, 
     val <span class="strong"><strong>muSigma</strong></span>: Vector[DblPair], 
     val <span class="strong"><strong>prior</strong></span>: Double)(implicit f: T =&gt; Double)  {  //<span class="strong"><strong>1</strong></span>
  
  def <span class="strong"><strong>score</strong></span>(obs: Array[T], logDensity: <span class="strong"><strong>LogDensity</strong></span>): Double = //<span class="strong"><strong>2</strong></span>
    (obs, muSigma).zipped
     .map{ case(x, (mu,sig)) =&gt; (x, mu, sig)}
     ./:(0.0)((prob, entry) =&gt; {
         val x = entry._1
         val mean = entry._2
         val stdDev = entry._3
         val logLikelihood = logDensity(mean, stdDev, x) //<span class="strong"><strong>3</strong></span>
         val adjLogLikelihood = if(logLikelihood &lt;MINLOGARG)
                     MINLOGVALUE else logLikelihood)
         prob + Math.log(adjLogLikelihood) //<span class="strong"><strong>4</strong></span>
   }) + Math.log(prior)
}</pre></div><p>The <a id="id5390000" class="indexterm"/>parameterized <code class="literal">Likelihood</code> class has the following two purposes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Define the statistics regarding a class <span class="emphasis"><em>C<sub>k</sub></em></span>: its label, its mean and standard deviation, and the prior probability <span class="emphasis"><em>p(C<sub>k</sub>)</em></span>.</li><li class="listitem">Compute the score of a new observation for its runtime classification (line <code class="literal">2</code>). The computation of the log of the likelihood uses a <code class="literal">logDensity</code> method of the <code class="literal">LogDensity</code> type (line <code class="literal">3</code>). As seen in the next section, the log density can be either a Gaussian or a Bernoulli distribution. The <code class="literal">score</code> method uses Scala's <code class="literal">zipped</code> method to merge the observation values with the labeled values and implements the <span class="strong"><strong>M3 </strong></span>formula (line <code class="literal">4</code>).</li></ul></div><p>The Gaussian mixture is particularly suited for modeling datasets, for which the features have large sets of discrete values or are continuous variables. The conditional probabilities for the feature <span class="emphasis"><em>x</em></span> is described by the normal probability density function [5:9].</p><div class="note" title="Note"><h3 class="title"><a id="note14800"/>Note</h3><p>
<span class="strong"><strong>The log likelihood using the Gaussian density</strong></span>
</p><p>M7: For a Lidstone or Laplace smoothed mean <span class="emphasis"><em>µ'</em></span> and a standard deviation <span class="emphasis"><em>σ</em></span>, the log likelihood of a posterior probability for a Gaussian distribution is defined as:</p><div class="mediaobject"><img src="../Images/image01368.jpeg" alt="Class likelihood"/></div><p style="clear:both; height: 1em;"> </p></div><p>The log of the <a id="id5400000" class="indexterm"/>Gauss, <code class="literal">logGauss</code>, and the log of the Normal distribution, <code class="literal">logNormal</code>, are defined in the <code class="literal">stats</code> class, which was introduced in the <span class="emphasis"><em>Profiling data</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>logGauss</strong></span>(mean: Double, stdDev: Double, x: Double): Double ={
  val y = (x - mean)/stdDev
  -LOG_2PI - Math.log(stdDev) - 0.5*y*y
}
val <span class="strong"><strong>logNormal</strong></span> = logGauss(0.0, 1.0, _: Double)</pre></div><p>The <code class="literal">logNormal</code> computation is implemented as a partial applied function.</p><p>The functions of the <code class="literal">LogDensity</code> type compute the probability density for each feature (line <code class="literal">5</code>):</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>LogDensity</strong></span> = (Double*) =&gt; Double</pre></div></div><div class="section" title="Binomial model"><div class="titlepage"><div><div><h4 class="title"><a id="ch05lvl4sec1300"/>Binomial model</h4></div></div></div><p>The <a id="id5410000" class="indexterm"/>next step is to define the <code class="literal">BinNaiveBayesModel</code> model for a two-class classification scheme. The two-class model consists of two <code class="literal">Likelihood</code> instances: <code class="literal">positives</code> for the label UP (value <code class="literal">1</code>) and <code class="literal">negatives</code> for the label DOWN (value <code class="literal">0</code>).</p><p>In order to make the model generic, we created a <code class="literal">NaiveBayesModel</code> trait that can be extended as needed to support both the binomial and multinomial Naïve Bayes models, as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>NaiveBayesModel[T]</strong></span>  {
  def <span class="strong"><strong>classify</strong></span>(<span class="strong"><strong>x</strong></span>: Array[T], <span class="strong"><strong>logDensity</strong></span>: <span class="strong"><strong>LogDensity</strong></span>): Int //<span class="strong"><strong>5</strong></span>
}</pre></div><p>The <code class="literal">classify</code> method uses the trained model to classify a multivariate observation <code class="literal">x</code> of the <code class="literal">Array[T]</code> type given a <code class="literal">logDensity</code> probability density function (line <code class="literal">5</code>). The method returns the class the observation belongs to.</p><p>Let's start with the definition of the <code class="literal">BinNaiveBayesModel</code> class that implements the binomial Naïve Bayes:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>BinNaiveBayesModel</strong></span>[T &lt;: AnyVal](
    pos: Likelihood[T], 
    neg: Likelihood[T])(implicit f: T =&gt; Double)
  extends NaiveBayesModel[T] { //<span class="strong"><strong>6</strong></span>

  override def classify(x: Array[T], logDensity: logDensity): Int = //<span class="strong"><strong>7</strong></span>
   if(pos.score(x,density) &gt; neg.score(x,density)) 1 else 0
  ...
}</pre></div><p>The constructor<a id="id5420000" class="indexterm"/> for the <code class="literal">BinNaiveBayesModel</code> class takes two arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">pos</code>: Class likelihood for observations with a positive outcome </li><li class="listitem"><code class="literal">neg</code>: Class likelihood for observations with a negative outcome (line <code class="literal">6</code>)</li></ul></div><p>The <code class="literal">classify</code> method is called by the <code class="literal">|&gt;</code> operator in the Naïve Bayes classifier. It returns <code class="literal">1</code> if the observation <code class="literal">x</code> matches the <code class="literal">Likelihood</code> class that contains the positive cases, and <code class="literal">0</code> otherwise (line <code class="literal">7</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note14900"/>Note</h3><p>
<span class="strong"><strong>Model validation</strong></span>
</p><p>The parameters of the Naïve Bayes model (likelihood) are computed through training and the <code class="literal">model</code> value is instantiated regardless of whether the model is actually validated in this example. A commercial application would require the model to be validated using a methodology such as the K-fold validation and F1 measure, as described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p></div></div><div class="section" title="The multinomial model"><div class="titlepage"><div><div><h4 class="title"><a id="ch05lvl4sec1400"/>The multinomial model</h4></div></div></div><p>The <a id="id5430000" class="indexterm"/>multinomial Naïve Bayes model defined by the <code class="literal">MultiNaiveBayesModel</code> class is very similar to the <code class="literal">BinNaiveBayesModel</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MultiNaiveBayesModel</strong></span>[T &lt;: AnyVal(   //<span class="strong"><strong>8</strong></span>
   likelihoodSet: Seq[Likelihood[T]])(implicit f: T =&gt; Double)
  extends NaiveBayesModel[T]{

  override def <span class="strong"><strong>classify</strong></span>(x: Array[T], logDensity: LogDensity): Int = {
    val &lt;&lt;&lt; = (p1: Likelihood[T], p2: Likelihood[T]) =&gt; 
              p1.score(x, density) &gt; p1.score(x, density) //<span class="strong"><strong>9</strong></span>
    likelihoodSet.sortWith(&lt;&lt;&lt;).head.label  //<span class="strong"><strong>10</strong></span>
  }
  ...
}</pre></div><p>The multinomial <a id="id5440000" class="indexterm"/>Naïve Bayes model differs from its binomial counterpart as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Its constructor requires a sequence of class likelihood <code class="literal">likelihoodSet</code> (line <code class="literal">8</code>).</li><li class="listitem">The <code class="literal">classify</code> runtime classification method sorts the class likelihoods by their score (posterior probability) using the <code class="literal">&lt;&lt;&lt;</code> function (line <code class="literal">9</code>). The method returns the ID of the class with the highest log likelihood (line <code class="literal">10</code>).</li></ul></div></div><div class="section" title="Classifier components"><div class="titlepage"><div><div><h4 class="title"><a id="ch05lvl4sec1500"/>Classifier components</h4></div></div></div><p>The <a id="id5450000" class="indexterm"/>Naïve Bayes algorithm is implemented as a data transformation using a model implicitly extracted from a training set of the <code class="literal">ITransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><p>The attributes of the multinomial Naïve Bayes are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The smoothing formula (Laplace, Lidstone, and so on), <code class="literal">smoothing</code></li><li class="listitem">The set of multivariable observations defined as <code class="literal">xt</code></li><li class="listitem">The expected values (or labels) associated with the set of observations, <code class="literal">expected</code></li><li class="listitem">The log of the probability density function, <code class="literal">logDensity</code></li><li class="listitem">The number of classes—two for the binomial Naïve Bayes with the <code class="literal">BinNaiveBayesModel</code> type or more for the multinomial Naïve Bayes with the <code class="literal">MultiNaiveBayesModel</code> type (line <code class="literal">11</code>)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>NaiveBayes</strong></span>[T &lt;: AnyVal](
    <span class="strong"><strong>smoothing</strong></span>: Double, 
    <span class="strong"><strong>xt</strong></span>: XVSeries[T],
    <span class="strong"><strong>expected</strong></span>: Vector[Int],
    <span class="strong"><strong>logDensity</strong></span>: LogDensity,
    <span class="strong"><strong>classes</strong></span>: Int)(implicit f: T =&gt; Double) 
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) 
    with Supervised[T, Array[T]] with Monitor[Double] { //<span class="strong"><strong>11</strong></span>
  type V = Int  //<span class="strong"><strong>12</strong></span>
  val <span class="strong"><strong>model</strong></span>: Option[NaiveBayesModel[T]]  //<span class="strong"><strong>13</strong></span>
  def <span class="strong"><strong>train</strong></span>(expected: Int): Likelihood[T]
  …
}</pre></div><p>The <code class="literal">Monitor</code> trait defines miscellaneous logging and display functions.</p><p>Data transformation <a id="id5460000" class="indexterm"/>of the <code class="literal">ITransform</code> type requires the output type <code class="literal">V</code> to be specified (line <code class="literal">12</code>). The output of the Naïve Bayes is the index of the class an observation belongs to. The <code class="literal">model</code> type of the model can be either <code class="literal">BinNaiveBayesModel</code> for two classes or <code class="literal">MultiNaiveBayesModel</code> for a multinomial model (line <code class="literal">13</code>):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>model</strong></span>: Option[NaiveBayesModel[T]] = Try {
  if(classes == 2) 
    BinNaiveBayesModel[T](train(1), train(0))
  else 
    MultiNaiveBayesModel[T](List.tabulate(classes)( train(_)))
} match {
  case Success(_model) =&gt; Some(_model)
  case Failure(e) =&gt; /* … */
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note15000"/>Note</h3><p>
<span class="strong"><strong>Training and class instantiation</strong></span>
</p><p>There are several benefits of allowing the instantiation of the Naïve Bayes mode only once when it is trained. It prevents the client code from invoking the algorithm on an untrained or partially trained model, and it reduces the number of states of the model (untrained, partially trained, trained, validated, and so on). It is an elegant way to hide the details of the training of the model from the user.</p></div><p>The <code class="literal">train</code> method is applied to each class. It takes the index or label of the class and generates its log likelihood data (line <code class="literal">14</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>(index: Int): Likelihood[T] = {   //<span class="strong"><strong>14</strong></span>
  val xv: XVSeries[Double] = xt
  val values = xv.zip(expected) //<span class="strong"><strong>15</strong></span>
               .filter( _._2 == index).map(_._1) //<span class="strong"><strong>16</strong></span>
  if( values.isEmpty )
     throw new IllegalStateException( /* ... */)

  val dim = dimension(xt)
  val <span class="strong"><strong>meanStd</strong></span> = statistics(values).map(stat =&gt; 
         (stat.lidstoneMean(smoothing, dim), stat.stdDev)) //<span class="strong"><strong>17</strong></span>
  Likelihood(index, meanStd, values.size.toDouble/xv.size) //<span class="strong"><strong>18</strong></span>
}</pre></div><p>The training <a id="id5470000" class="indexterm"/>set is generated by zipping the <code class="literal">xt</code> vector of observations with expected classes, <code class="literal">expected</code> (line <code class="literal">15</code>). The method filters out the observation for which the label does not correspond to this class (line <code class="literal">16</code>). The <code class="literal">meanStd</code> pair (mean and standard deviation) is computed using the Lidstone smoothing factor (line <code class="literal">17</code>). Finally, the training method returns the class likelihood corresponding to the index <code class="literal">label</code> (line <code class="literal">18</code>).</p><p>The <code class="literal">NaiveBayes</code> class also defines the <code class="literal">|&gt;</code> runtime classification method and the F<sub>1</sub> validation methods. Both methods are described in the next section.</p><div class="note" title="Note"><h3 class="title"><a id="note15100"/>Note</h3><p>
<span class="strong"><strong>Handling missing data</strong></span>
</p><p>Naïve Bayes has a no-nonsense approach to handling missing data. You just ignore the attribute in the observations for which the value is missing. In this case, the prior for this particular attribute for these observations is not computed. This workaround is obviously made possible because of the conditional independence between features.</p></div><p>The <code class="literal">apply</code> constructor for <code class="literal">NaiveBayes</code> returns the <code class="literal">NaiveBayes</code> type:</p><div class="informalexample"><pre class="programlisting">object NaiveBayes {
  def <span class="strong"><strong>apply</strong></span>[T &lt;: AnyVal](
        smoothing: Double, 
        xt: XVSeries[T],
        expected: Vector[Int],
        logDensity: LogDensity,
        classes: Int) (implicit f: T =&gt; Double): NaiveBayes[T] = 
    new NaiveBayes[T](smoothing, xt, y, logDensity, classes)
   …
}</pre></div></div></div><div class="section" title="Classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7300"/>Classification</h3></div></div></div><p>The <a id="id5480000" class="indexterm"/>likelihood and class prior that have been computed through training is used for validating the model and classifying new observations.</p><p>The score represents the log of likelihood estimate (or the posterior probability), which is computed as the summation of the log of the Gaussian distribution using the mean and standard deviation extracted from the training phase and the log of the class likelihood.</p><p>The Naïve Bayes classification using the Gaussian distribution is illustrated using the two <span class="emphasis"><em>C<sub>1</sub></em></span> and <span class="emphasis"><em>C<sub>2</sub></em></span>
<span class="emphasis"><em> </em></span>classes and a model with two features (<span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span>):</p><div class="mediaobject"><img src="../Images/image01369.jpeg" alt="Classification"/><div class="caption"><p>An illustration of the Gaussian Naive Bayes using 2-dimensional model</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">|&gt;</code> method<a id="id5490000" class="indexterm"/> returns the partial function that implements the runtime classification of a new <code class="literal">x</code> observation using one of the two Naïve Bayes models. The <code class="literal">model</code> and the <code class="literal">logDensity</code> functions are used to assign the <code class="literal">x</code> observation to the appropriate class (line <code class="literal">19</code>):</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] = {
  case <span class="strong"><strong>x</strong></span>: Array[T] if(x.length &gt;0 &amp;&amp; model != None) =&gt; 
    Try( <span class="strong"><strong>model</strong></span>.map(_.classify(x, <span class="strong"><strong>logDensity</strong></span>)).get)  //<span class="strong"><strong>19</strong></span>
}</pre></div></div><div class="section" title="F1 validation"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7400"/>F1 validation</h3></div></div></div><p>Finally, the Naïve Bayes classifier is implemented by the <code class="literal">NaiveBayes</code> class. It implements<a id="id5500000" class="indexterm"/> the training and runtime classification using the Naïve Bayes formula. In order to force the developer to define a validation for any new supervised learning technique, the class inherits from the <code class="literal">Supervised</code> trait that declares the <code class="literal">validate</code> validation method:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Supervised</strong></span>[T, V] {
  self: <span class="strong"><strong>ITransform</strong></span>[V] =&gt;  //<span class="strong"><strong>20</strong></span>
    def <span class="strong"><strong>validate</strong></span>(xt: XVSeries[T], 
      expected: Vector[V]): Try[Double]  //<span class="strong"><strong>21</strong></span>
}</pre></div><p>The validation of a model applies only to a data transformation of the <code class="literal">ITransform</code> type (line <code class="literal">20</code>).</p><p>The <code class="literal">validate</code> method takes the following arguments (line <code class="literal">21</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An <code class="literal">xt</code> time series of multidimensional observations</li><li class="listitem">An <code class="literal">expected</code> vector of expected class values</li></ul></div><p>By default, the <code class="literal">validate</code> method returns the F<sub>1</sub> score for the model, as described in the <span class="emphasis"><em>Assessing a model</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><p>Let's implement <a id="id5510000" class="indexterm"/>the key functionality of the <code class="literal">Supervised</code> trait for the Naïve Bayes classifier:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>validate</strong></span>(
    <span class="strong"><strong>xt</strong></span>: XVSeries[T], 
    <span class="strong"><strong>expected</strong></span>: Vector[V]): Try[Double] =  Try {   //<span class="strong"><strong>22</strong></span>
  val predict = model.get.classify(_:Array[Int],logDensity) //<span class="strong"><strong>23</strong></span>
  MultiFValidation(expected, xt, classes)(predict).score  //<span class="strong"><strong>24</strong></span>
}</pre></div><p>The predictive <code class="literal">predict</code> partially applied function is created by assigning a predicted class to a new <code class="literal">x</code> observation (line <code class="literal">23</code>), and then the prediction, the index of classes, is loaded into the <code class="literal">MultiFValidation</code> class to compute the F<sub>1</sub> score (line <code class="literal">24</code>).</p></div><div class="section" title="Feature extraction"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7500"/>Feature extraction</h3></div></div></div><p>The most <a id="id5520000" class="indexterm"/>critical element in the training of a supervised learning algorithm is the creation of labeled data. Fortunately, in this case, the labels (or expected classes) can be automatically generated. The objective is to predict the direction of the price of a stock for the next trading day, taking into account the moving average price, volume, and volatility over the last <span class="emphasis"><em>n</em></span> days.</p><p>The extraction of features follows these six steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Extract historical trading data of each feature (that is, price, volume, and volatility).</li><li class="listitem">Compute the simple moving average of each feature.</li><li class="listitem">Compute the difference between the value and moving average of each feature.</li><li class="listitem">Normalize the difference by assigning 1 for positive values and 0 for negative values.</li><li class="listitem">Generate a time series of the difference between the closing price of the stock and the closing price of the previous trading session.</li><li class="listitem">Normalize the difference by assigning 1 for positive values and 0 for negative values.</li></ol><div style="height:10px; width: 1px"/></div><p>The following <a id="id5530000" class="indexterm"/>diagram illustrates the feature extractions for steps 1 to 4:</p><div class="mediaobject"><img src="../Images/image01370.jpeg" alt="Feature extraction"/><div class="caption"><p>Binary quantization of the difference value—moving average</p></div></div><p style="clear:both; height: 1em;"> </p><p>The first step is to extract the average price, volume, and volatility (that is, <span class="emphasis"><em>1 – low/high</em></span>) for each stock during the period of Jan 1, 2000 and Dec 31, 2014 with daily and weekly closing prices. Let's use the simple moving average to compute these averages for the <span class="emphasis"><em>[t-n, t]</em></span>window.</p><p>The <code class="literal">extractor</code> variable defines the list of features to extract from the financial data source, as described in the <span class="emphasis"><em>Data extraction</em></span> and <span class="emphasis"><em>Data sources</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>extractor</strong></span> = toDouble(CLOSE)  // stock closing price
               :: ratio(HIGH, LOW) //volatility(HIGH-LOW)/HIGH
               :: toDouble(VOLUME)  // daily stock trading volume
               :: List[Array[String] =&gt;Double]()</pre></div><p>The naming convention for the trading data and metrics is described in the <span class="emphasis"><em>Trading data</em></span> section under <span class="emphasis"><em>Technical analysis</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The training and validation of the binomial Naïve Bayes is implemented using a monadic composition:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>trainRatio</strong></span> = 0.8  //25
val period = 4
val symbol ="IBM"
val path = "resources/chap5"
val <span class="strong"><strong>pfnMv</strong></span> = SimpleMovingAverage[Double](period, false) |&gt; //<span class="strong"><strong>26</strong></span>
val <span class="strong"><strong>pfnSrc</strong></span> = DataSource(symbol, path, true, 1) |&gt;  //<span class="strong"><strong>27</strong></span>

for {
  obs &lt;- pfnSrc(extractor)  //<span class="strong"><strong>28</strong></span>
  (x, delta) &lt;- computeDeltas(obs) //<span class="strong"><strong>29</strong></span>
  expected &lt;- Try{difference(x.head.toVector, diffInt)}//<span class="strong"><strong>30</strong></span>
  features &lt;- Try { transpose(delta) } //<span class="strong"><strong>31</strong></span>
  labeled &lt;- //<span class="strong"><strong>32</strong></span>
     OneFoldXValidation[Int](features, expected, trainRatio) 
  nb &lt;- NaiveBayes[Int](1.0, labeled.trainingSet) //<span class="strong"><strong>33</strong></span>
  f1Score &lt;- nb.validate(labeled.validationSet) //<span class="strong"><strong>34</strong></span>
}
yield {
  val labels = Array[String](
    "price/ave price", "volatility/ave. volatility",
    "volume/ave. volume"
  )
  show(s"\nModel: ${nb.toString(labels)}")
}</pre></div><p>The first step is to <a id="id5540000" class="indexterm"/>distribute the observations between the training set and validation set. The <code class="literal">trainRatio</code> value (line <code class="literal">25</code>) defines the ratio of the original observation set to be included in the training set. The simple moving average values are generated by the <code class="literal">pfnMv</code> partial function (line <code class="literal">26</code>). The extracting <code class="literal">pfnSrc</code> partial function (line <code class="literal">27</code>) is used to generate the three trading time series, price, volatility, and volume (line <code class="literal">28</code>).</p><p>The next step consists of applying the <code class="literal">pfnMv</code> simple moving average to the <code class="literal">obs</code> multidimensional time series (line <code class="literal">29</code>) using the <code class="literal">computeRatios</code> method:</p><div class="informalexample"><pre class="programlisting">type LabeledPairs = (XVSeries[Double], Vector[Array[Int]])

def <span class="strong"><strong>computeDeltas</strong></span>(obs: XVSeries[Double]): Try[LabeledPairs] =
Try{
  val sm = obs.map(_.toVector).map( pfnMv(_).get.toArray) //<span class="strong"><strong>35</strong></span>
  val x = obs.map(_.drop(period-1) )
  (x, x.zip(sm).map{ case(x,y) =&gt; x.zip(y).map(delta(_)) })//<span class="strong"><strong>36</strong></span>
}</pre></div><p>The <code class="literal">computeDeltas</code> method computes the time series of the <code class="literal">sm</code> observations smoothed with a simple moving average (line <code class="literal">35</code>). The method generates a time series of 0 and 1 for each of the three features in the <code class="literal">xs</code> observation set and <code class="literal">sm</code> smoothed dataset (line <code class="literal">36</code>).</p><p>Next, the call to <a id="id5550000" class="indexterm"/>the <code class="literal">difference</code> differential computation generates the labels (0 and 1) representing the change in the direction of the price of a security between two consecutive trading sessions: 0 if the price is decreased and 1 if the price is increased (line <code class="literal">30</code>) (refer to the <span class="emphasis"><em>The differential operator</em></span> section under <span class="emphasis"><em>Time series in Scala</em></span> in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>).</p><p>The features for the training of the Naïve Bayes model are extracted from these ratios by transposing the ratios-time series matrix in the <code class="literal">transpose</code> method of the <code class="literal">XTSeries</code> singleton (line <code class="literal">31</code>).</p><p>Next, the training set and validation set are extracted from the <code class="literal">features</code> set using the <code class="literal">OneFoldXValidation</code> class, which was introduced in the <span class="emphasis"><em>One-fold cross validation</em></span> section under <span class="emphasis"><em>Cross-validation</em></span> in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">32</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note15200"/>Note</h3><p>
<span class="strong"><strong>Selecting the training data</strong></span>
</p><p>In our example, the training set is simplistically the first <code class="literal">trainRatio</code> multiplied by the size of dataset observations. Practical applications use a K-fold cross-validation technique to validate models, as described in the <span class="emphasis"><em>K-fold cross validation</em></span> section under <span class="emphasis"><em>Assessing a model</em></span> in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>. A simpler alternative is to create the training set by picking observations randomly and using the remaining data for validation.</p></div><p>The last two stages in the workflow consists of training the Naïve Bayes model by instantiating the <code class="literal">NaiveBayes</code> class (line <code class="literal">33</code>) and computing the F<sub>1</sub> score for different values of the smoothing coefficient of the simple moving average applied to the stock price, volatility, and volume (line <code class="literal">34</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note15300"/>Note</h3><p>
<span class="strong"><strong>The implicit conversion</strong></span>
</p><p>The <code class="literal">NaiveBayes</code> class operates on elements of the <code class="literal">Int</code> and <code class="literal">Double</code> types, and therefore, assumes that there is conversion between <code class="literal">Int</code> and <code class="literal">Double</code> (view bounded). The Scala compiler may generate a warning because the conversion from <code class="literal">Int</code> to <code class="literal">Double</code> has not been defined. Although Scala relies on its own conversion functions, I would recommend that you explicitly define and control your conversion function:</p><div class="informalexample"><pre class="programlisting">implicit def intToDouble(n: Int): Double = n.toDouble</pre></div></div></div><div class="section" title="Testing"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7600"/>Testing</h3></div></div></div><p>The next<a id="id5560000" class="indexterm"/> chart plots the value of the F<sub>1</sub> measure of the predictor of the direction of the IBM stock using price, volume, and volatility over the previous <span class="emphasis"><em>n</em></span> trading days, with <span class="emphasis"><em>n</em></span> varying from 1 to 12 trading days:</p><div class="mediaobject"><img src="../Images/image01371.jpeg" alt="Testing"/><div class="caption"><p>A graph of the F1-measure for the validation of the Naive Bayes model</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding chart illustrates the impact of the value of the averaging period (number of trading days) on the quality of the multinomial Naïve Bayes prediction, using the value of the stock price, volatility, and volume relative to their average over the averaging period.</p><p>From this experiment, we conclude the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The prediction of the stock movement using the average price, volume, and volatility is not very good. The F<sub>1</sub> score for the models using weekly (with respect to daily) closing prices varies between 0.68 and 0.74 (with respect to 0.56 and 0.66).</li><li class="listitem">The prediction<a id="id5570000" class="indexterm"/> using weekly closing prices is more accurate than the prediction using the daily closing prices. In this particular example, the distribution of the weekly closing prices is more reflective of an intermediate term trend than the distribution of daily prices.</li><li class="listitem">The prediction is somewhat independent of the period used to average the features.</li></ul></div></div></div></div>
<div class="section" title="The Multivariate Bernoulli classification" id="aid-5FF7G1"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec3700"/>The Multivariate Bernoulli classification</h1></div></div></div><p>The <a id="id5580000" class="indexterm"/>previous example uses the Gaussian distribution for features that are essentially binary (<span class="emphasis"><em>UP = 1</em></span> and <span class="emphasis"><em>DOWN = 0</em></span>) to represent the change in value. The mean value is computed as the ratio of the number of observations for which <span class="emphasis"><em>x<sub>i</sub> = UP</em></span> over the total number of observations.</p><p>As stated in the first section, the Gaussian distribution is more appropriate for either continuous features or binary features for very large labeled datasets. The example is the perfect candidate for the <a id="id5590000" class="indexterm"/><span class="strong"><strong>Bernoulli</strong></span> model. </p><div class="section" title="Model"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec6800"/>Model</h2></div></div></div><p>The <a id="id5600000" class="indexterm"/>Bernoulli model differs from the Naïve Bayes classifier in such a way that it penalizes the feature <span class="emphasis"><em>x</em></span> that does not have any observation; the Naïve Bayes classifier ignores it [5:10].</p><div class="note" title="Note"><h3 class="title"><a id="note15400"/>Note</h3><p>
<span class="strong"><strong>The Bernoulli mixture model</strong></span>
</p><p>M8: For <a id="id5610000" class="indexterm"/>a feature function <span class="emphasis"><em>f<sub>k</sub></em></span> with <span class="emphasis"><em>f<sub>k</sub></em></span>
<span class="emphasis"><em> = 1</em></span>, if the feature is observed, and a value of 0 otherwise, and the probability <span class="emphasis"><em>p</em></span> of the observed feature <span class="emphasis"><em>x<sub>k</sub></em></span> belongs to the class <span class="emphasis"><em>C<sub>j</sub></em></span>, then the posterior probability is computed as follows:</p><div class="mediaobject"><img src="../Images/image01372.jpeg" alt="Model"/></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec6900"/>Implementation</h2></div></div></div><p>The implementation <a id="id5620000" class="indexterm"/>of the Bernoulli model consists of modifying the <code class="literal">score</code> function in the <code class="literal">Likelihood</code> class using the Bernoulli density method, <code class="literal">bernoulli</code>, defined in the <code class="literal">Stats</code> object:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>Stats</strong></span> {
  def <span class="strong"><strong>bernoulli</strong></span>(mean: Double, p: Int): Double = 
     mean*p + (1-mean)*(1-p)
def <span class="strong"><strong>bernoulli</strong></span>(x: Double*): Double = bernoulli(x(0), x(1).toInt)
…</pre></div><p>The first version of the Bernoulli algorithm is the direct implementation of the <span class="strong"><strong>M8 </strong></span>mathematical formula. The second version uses the signature of the <code class="literal">Density (Double*) =&gt; Double</code> type.</p><p>The mean <a id="id5630000" class="indexterm"/>value is the same as in the Gaussian density function. The binary feature is implemented as an <code class="literal">Int</code> type with the value <span class="emphasis"><em>UP = 1</em></span> (with respect to <span class="emphasis"><em>DOWN = 0</em></span>) for the upward (with respect to downward) direction of the financial technical indicator.</p></div></div>
<div class="section" title="Na&#xEF;ve Bayes and text mining"><div class="titlepage" id="aid-5GDO22"><div><div><h1 class="title"><a id="ch05lvl1sec3800"/>Naïve Bayes and text mining</h1></div></div></div><p>The multinomial Naïve Bayes <a id="id5640000" class="indexterm"/>classifier is particularly suited for <a id="id5650000" class="indexterm"/><span class="strong"><strong>text mining</strong></span>. The Naïve Bayes formula is quite effective to classify the following entities:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">E-mail spams</li><li class="listitem">Business news stories</li><li class="listitem">Movie reviews</li><li class="listitem">Technical papers as per field of expertise</li></ul></div><p>This third use case <a id="id5660000" class="indexterm"/>consists of predicting the direction of a stock given the financial news. There are two type of news that affect the stock of a particular company:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Macro trends</strong></span>: Economic or social news such as conflicts, economic trends, or labor market statistics</li><li class="listitem"><span class="strong"><strong>Micro updates</strong></span>: Financial or market news related to a specific company such as earnings, change in ownership, or press releases</li></ul></div><p>Macroeconomic news related to a specific company have the potential to affect the sentiments of investors toward the company and may lead to a sudden shift in the price of its stock. Another important feature is the average time it takes for investors to react to the news and affect the price of the stock.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Long-term investors may react within days or even weeks</li><li class="listitem">Short-term traders adjust their positions within hours, sometimes within the same trading session</li></ul></div><p>The average time the market takes to react to a significant financial news on a company is illustrated in the following chart:</p><div class="mediaobject"><img src="../Images/image01373.jpeg" alt="Naïve Bayes and text mining"/><div class="caption"><p>An illustration of the reaction of investors on the price of a stock following a news release</p></div></div><p style="clear:both; height: 1em;"> </p><p>The delay in the <a id="id5670000" class="indexterm"/>market response is a relevant feature only if the variance of the response time is significant. The distribution of the frequencies of the <a id="id5680000" class="indexterm"/>delay in the market response to any newsworthy articles regarding TSLA is fairly constant. It shows that the stock prices react within the same day in 82 percent of the cases, as seen in the following bar chart:</p><div class="mediaobject"><img src="../Images/image01374.jpeg" alt="Naïve Bayes and text mining"/><div class="caption"><p>The distribution of the frequencies of the reaction of investors on the price of a stock following a news release</p></div></div><p style="clear:both; height: 1em;"> </p><p>The frequency peak <a id="id5690000" class="indexterm"/>for a market response delay of 1.75 days can be explained by the fact that some news are released over the weekend and investors <a id="id5700000" class="indexterm"/>have to wait until the following Monday to drive the stock price higher or lower. Another challenge is to assign any shift of a stock price to a specific news release, taking into account that some news can be redundant, confusing, or simultaneous.</p><p>Therefore, the model features for predicting the stock price <span class="emphasis"><em>pr<sub>t+1</sub></em></span> are the relative frequency <span class="emphasis"><em>f<sub>i</sub></em></span> of an occurrence of a term <span class="emphasis"><em>T<sub>i</sub></em></span> within a time window <span class="emphasis"><em>[t-n, t]</em></span>, where <span class="emphasis"><em>t</em></span> and <span class="emphasis"><em>n</em></span> are trading days.</p><p>The following graphical model formally describes the causal relation or conditional dependency of the relative change of the stock price between two consecutive trading sessions <span class="emphasis"><em>t</em></span> and <span class="emphasis"><em>t + 1</em></span>, given the relative frequency of appearance of some key terms in the media:</p><div class="mediaobject"><img src="../Images/image01375.jpeg" alt="Naïve Bayes and text mining"/><div class="caption"><p>The Bayesian model for the prediction of the stock movement given financial news</p></div></div><p style="clear:both; height: 1em;"> </p><p>For this exercise, the <a id="id5710000" class="indexterm"/>observation sets are the corpus of news <a id="id5720000" class="indexterm"/>feeds and articles released by the most prominent financial news organizations, such as Bloomberg or CNBC. The first step is to devise a methodology to extract and select the most relevant terms associated with a specific stock.</p><div class="section" title="Basics of information retrieval"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec7000"/>Basics of information retrieval</h2></div></div></div><p>A full discussion of <a id="id5730000" class="indexterm"/>information retrieval and text mining is beyond the scope of this book [5:11]. For the sake of simplicity, the model will rely on a very simple scheme for extracting relevant terms and computing their relative frequency. The following 10-step sequence of actions describe one of the numerous methodologies used to extract the most relevant terms from a corpus:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create or extract the timestamp for each news article.</li><li class="listitem">Extract the title, paragraph, and sentences of each article using a Markovian classifier.</li><li class="listitem">Extract the terms from each sentence using regular expressions.</li><li class="listitem">Correct terms for typos using a dictionary and metric such as the <a id="id5740000" class="indexterm"/><span class="strong"><strong>Levenstein</strong></span> distance.</li><li class="listitem">Remove the nonstop words.</li><li class="listitem">Perform <a id="id5750000" class="indexterm"/><span class="strong"><strong>stemming</strong></span> and<a id="id5760000" class="indexterm"/> <span class="strong"><strong>lemmatization</strong></span>.</li><li class="listitem">Extract bags of words and generate a list of <a id="id5770000" class="indexterm"/><span class="strong"><strong>n-grams</strong></span> (as a sequence of <span class="emphasis"><em>n</em></span> terms).</li><li class="listitem">Apply a <span class="strong"><strong>tagging model</strong></span> build <a id="id5780000" class="indexterm"/>using a maximum entropy or conditional random field to extract nouns and adjectives (for example, <span class="emphasis"><em>NN</em></span>, <span class="emphasis"><em>NNP</em></span>, and so on).</li><li class="listitem">Match the terms against a dictionary <a id="id5790000" class="indexterm"/>that supports senses, hyponyms, and synonyms, such as <span class="strong"><strong>WordNet</strong></span>.</li><li class="listitem">Disambiguate word sense using Wikipedia's repository <a id="id5800000" class="indexterm"/><span class="strong"><strong>DBpedia</strong></span> [5:12].</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note15500"/>Note</h3><p>
<span class="strong"><strong>Text extraction from the Web</strong></span>
</p><p>The methodology discussed in this section does not include the process of searching and extracting news and articles from the Web that requires additional steps such as search, crawling, and scraping [5:13].</p></div></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec7100"/>Implementation</h2></div></div></div><p>Let's apply the <a id="id5810000" class="indexterm"/>text mining methodology template to predict the direction of a stock, given the financial news. The algorithm relies on a sequence of seven simple steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Searching and loading the news articles related to a given company and its stock as a <span class="emphasis"><em>Ɗ<sub>t</sub></em></span> document of the <code class="literal">Document</code> type.</li><li class="listitem">Extracting the <code class="literal">date: T</code> timestamp of the article using a regular expression.</li><li class="listitem">Ordering the <span class="emphasis"><em>Ɗ<sub>t</sub></em></span> documents as per the timestamp.</li><li class="listitem">Extracting the <span class="emphasis"><em>{T<sub>i,D</sub>} </em></span>terms from the content of each <span class="emphasis"><em>Ɗ</em></span><span class="emphasis"><em>t</em></span> document.</li><li class="listitem">Aggregating the <span class="emphasis"><em>{T<sub>t,D</sub>} </em></span>terms for all the <span class="emphasis"><em>Ɗ<sub>t</sub></em></span> documents that share the same publication date <span class="emphasis"><em>t</em></span>.</li><li class="listitem">Computing the <span class="emphasis"><em>rtf</em></span> relative frequency of each <span class="emphasis"><em>{T<sub>i,D</sub>} </em></span>term for the date <span class="emphasis"><em>t</em></span>, as the ratio of number of its occurrences in all the articles released at <span class="emphasis"><em>t</em></span> to the total number of its occurrences of the term in the entire corpus.</li><li class="listitem">Normalizing the relative frequency for the average number of articles per date, <span class="emphasis"><em>nrtf</em></span>.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note15600"/>Note</h3><p>
<span class="strong"><strong>Text analysis metrics</strong></span>
</p><p>M9: The relative frequency of occurrences for term (or keyword) <span class="emphasis"><em>t<sub>i</sub></em></span> with <span class="emphasis"><em>n<sub>i</sub><sup>a</sup></em></span> occurrences in the article <span class="emphasis"><em>a</em></span> is defined as follows:</p><div class="mediaobject"><img src="../Images/image01376.jpeg" alt="Implementation"/></div><p style="clear:both; height: 1em;"> </p><p>M10: The relative frequency of occurrences of a term <span class="emphasis"><em>t<sub>i</sub></em></span> normalized by the daily average number of articles for which <span class="emphasis"><em>N<sub>a</sub></em></span> is the total number of articles and <span class="emphasis"><em>N<sub>d</sub></em></span> is the number of days in the survey is defined as follows:</p><div class="mediaobject"><img src="../Images/image01377.jpeg" alt="Implementation"/></div><p style="clear:both; height: 1em;"> </p></div><p>The news <a id="id5820000" class="indexterm"/>articles are <span class="emphasis"><em>minimalist</em></span> documents with a timestamp, title, and content, as implemented by the <code class="literal">Document</code> class:</p><div class="informalexample"><pre class="programlisting">case class Document[T &lt;: AnyVal]( //<span class="strong"><strong>1</strong></span>
date: T, title: String, content: String)
(implicit f: T =&gt; Double)   </pre></div><p>The <code class="literal">date</code> timestamp has a type bounded to the <code class="literal">Long</code> type, so <code class="literal">T</code> can be converted to the current time in milliseconds of the JVM (line <code class="literal">1</code>).</p><div class="section" title="Analyzing documents"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7700"/>Analyzing documents</h3></div></div></div><p>This section is <a id="id5830000" class="indexterm"/>dedicated to the implementation of the simple text analyzer. Its purpose is to convert a set of documents of the <code class="literal">Document</code> type; in our case, news articles, into a distribution of relative frequencies of keywords.</p><p>The <code class="literal">TextAnalyzer</code> class implements a data transformation of the <code class="literal">ETransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>. It transforms a sequence of documents into a sequence of relative frequency distribution.</p><p>The <code class="literal">TextAnalyzer</code> class has the following two arguments (line <code class="literal">4</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A simple text parser, <code class="literal">parser</code>, that extracts an array of keywords from the title and content of each news articles (line <code class="literal">2</code>).</li><li class="listitem">A <code class="literal">lexicon</code> type that lists keywords used in monitoring news related to a company and their synonyms. The synonyms or terms that are semantically similar to each keywords are defined in an immutable map.</li></ul></div><p>The code <a id="id5840000" class="indexterm"/>will be as follows:</p><div class="informalexample"><pre class="programlisting">type TermsRF = Map[String, Double]  
type TextParser = String =&gt; Array[String] //<span class="strong"><strong>2</strong></span>
type Lexicon = immutable.Map[String, String]  //<span class="strong"><strong>3</strong></span>
type Corpus[T] = Seq[Document[T]]

class <span class="strong"><strong>TextAnalyzer</strong></span>[T &lt;: AnyVal](  //<span class="strong"><strong>4</strong></span>
     <span class="strong"><strong>parser</strong></span>: TextParser, 
     <span class="strong"><strong>lexicon</strong></span>: Lexicon)(implicit f: T =&gt; Double)
  extends ETransform[Lexicon](lexicon) {

  type <span class="strong"><strong>U</strong></span> = Corpus[T]    //<span class="strong"><strong>5</strong></span>
  type <span class="strong"><strong>V</strong></span> = Seq[TermsRF] //<span class="strong"><strong>6</strong></span>
  
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
     case docs: U =&gt; Try( score(docs) )
  }
  
  def <span class="strong"><strong>score</strong></span>(corpus: Corpus[T]): Seq[TermsRF]  //<span class="strong"><strong>7</strong></span>
  def <span class="strong"><strong>quantize</strong></span>(termsRFSeq: Seq[TermsRF]): //<span class="strong"><strong>8</strong></span>
          Try[(Array[String], XVSeries[Double])]
  def count(term: String): Counter[String] //<span class="strong"><strong>9</strong></span>
}</pre></div><p>The <code class="literal">U</code> type of an input into the data transformation <code class="literal">|&gt;</code> is the corpus or sequence of news articles (line <code class="literal">5</code>). The <code class="literal">V</code> type of the output from the data transformation is the sequence of relative frequency distribution of the <code class="literal">TermsRF</code> type (line <code class="literal">6</code>).</p><p>The <code class="literal">score</code> private method does the heavy lifting for the class (line <code class="literal">7</code>). The <code class="literal">quantize</code> method creates a homogenous set of observed features (line <code class="literal">8</code>) and the <code class="literal">count</code> method counts the number of occurrences of terms or keywords across the documents or news articles that share the same publication date (line <code class="literal">9</code>).</p><p>The following diagram describes the different components of the text mining process:</p><div class="mediaobject"><img src="../Images/image01378.jpeg" alt="Analyzing documents"/><div class="caption"><p>An illustration of the components of the text mining procedure</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Extracting the frequency of relative terms"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7800"/>Extracting the frequency of relative terms</h3></div></div></div><p>Let's dive into <a id="id5850000" class="indexterm"/>the <code class="literal">score</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>score</strong></span>(corpus: Corpus[T]): Seq[TermsRF] = {
  val termsCount = corpus.map(doc =&gt;  //<span class="strong"><strong>10</strong></span>
      (doc.date, count(doc.content))) //Seq[(T, Counter[String])]

  val <span class="strong"><strong>termsCountMap</strong></span> = termsCount.<span class="strong"><strong>groupBy</strong></span>( _._1).map{ 
     case (t, seq) =&gt; (t, seq.aggregate(new Counter[String])
                         ((s, cnt) =&gt; s ++ cnt._2, _ ++ _)) //<span class="strong"><strong>11</strong></span>
  }
  val <span class="strong"><strong>termsCountPerDate</strong></span> = termsCountMap.toSeq
         .sortWith( _._1 &lt; _._1).unzip._2  //<span class="strong"><strong>12</strong></span>
  val <span class="strong"><strong>allTermsCounts</strong></span> = termsCountPerDate
          .aggregate(new Counter[String])((s, cnt) =&gt; 
                               s ++ cnt, _ ++ _) //<span class="strong"><strong>13</strong></span>

  termsCountPerDate.map( _ /allTermsCounts).map(_.toMap) //<span class="strong"><strong>14</strong></span>
}</pre></div><p>The first step in the execution of the <code class="literal">score</code> method is the computation of the number of occurrences of keywords of the <code class="literal">lexicon</code> type on each of the document/news article (line <code class="literal">10</code>). The computation of the number of occurrences is implemented by the <code class="literal">count</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>count</strong></span>(term: String): Counter[String] = 
   parser(term)./:(new Counter[String])((cnt, w) =&gt;   //<span class="strong"><strong>16</strong></span>
   if(lexicon.contains(w)) cnt + lexicon(w) else cnt)</pre></div><p>The method <a id="id5860000" class="indexterm"/>relies on the term <code class="literal">Counter</code> counting class that subclasses <code class="literal">mutable.Map[String, Int]</code>, as described in the <span class="emphasis"><em>Counter</em></span> section under <span class="emphasis"><em>Scala programming</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>. It uses a fold to update the count for each of the terms associated with a keyword (line <code class="literal">16</code>). The <code class="literal">count</code> term for the entire corpus is computed by aggregating the terms count for all the documents (line <code class="literal">11</code>).</p><p>The next step consists of aggregating the count of the keywords across the document for each timestamp. A <code class="literal">termsCountMap</code> map with the date as the key and keywords counter, as values are generated by invoking the <code class="literal">groupBy</code> higher-order method (line <code class="literal">11</code>). Next, the <code class="literal">score</code> method extracts a sorted sequence of keywords counts, <code class="literal">termsCountPerDate</code> (line <code class="literal">12</code>). The total counts for each keyword over the <code class="literal">allTermsCounts</code> entire corpus (line <code class="literal">13</code>) is used to compute the relative or normalized keywords frequencies (formulas <span class="strong"><strong>M9</strong></span> and <span class="strong"><strong>M10</strong></span>) (line <code class="literal">14</code>).</p></div><div class="section" title="Generating the features"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec7900"/>Generating the features</h3></div></div></div><p>There is no <a id="id5870000" class="indexterm"/>guarantee that all the news articles associated with a specific publication date are used in the model. The <code class="literal">quantize</code> method assigns a relative frequency of <span class="strong"><strong>0.0</strong></span> for keywords that are missing from the news articles, as illustrated in the following table:</p><div class="mediaobject"><img src="../Images/image01379.jpeg" alt="Generating the features"/><div class="caption"><p>A table on relative frequencies of keywords as per the publishing date</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">quantize</code> method transforms a sequence of term-relative frequencies into a pair keywords and observations:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>quantize</strong></span>(termsRFSeq: Seq[TermsRF]): 
             Try[(Array[String], XVSeries[Double])] = Try {
  val keywords = lexicon.values.toArray.distinct //<span class="strong"><strong>15</strong></span>
  val <span class="strong"><strong>relFrequencies</strong></span> = 
      termsRFSeq.map( tf =&gt;  //<span class="strong"><strong>16</strong></span>
          keywords.map(key =&gt; 
              if(tf.contains(key)) tf.get(key).get else 0.0))
  (keywords, <span class="strong"><strong>relFrequencies</strong></span>.toVector) //<span class="strong"><strong>17</strong></span>
}</pre></div><p>The <code class="literal">quantize</code> method <a id="id5880000" class="indexterm"/>extracts an array of keywords from the lexicon (line <code class="literal">15</code>). The <code class="literal">relFrequencies</code> vector of features is generated by assigning the relative <code class="literal">0.0 </code>keyword frequency for keywords that are not detected across the news articles published at a specific date (line <code class="literal">16</code>). Finally, the key-value pair (keywords and relative keyword frequency) (line 17).</p><div class="note" title="Note"><h3 class="title"><a id="note15800"/>Note</h3><p>
<span class="strong"><strong>Sparse relative frequencies vector</strong></span>
</p><p>Text analysis and natural language processing deals with very large feature sets, with potentially hundreds of thousands of features or keywords. Such computations would be almost intractable if it was not for the fact that the vast majority of keywords are not present in each document. It is a common practice to use sparse vectors and sparse matrices to reduce the memory consumption during training.</p></div></div></div><div class="section" title="Testing"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec7200"/>Testing</h2></div></div></div><p>For testing<a id="id5890000" class="indexterm"/> purpose, let's select the news articles that mention Tesla Motors and its ticker symbol TSLA over a period of 2 months.</p><div class="section" title="Retrieving the textual information"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec8000"/>Retrieving the textual information</h3></div></div></div><p>Let's start <a id="id5900000" class="indexterm"/>implementing and defining the two components of <code class="literal">TextAnalyzer</code>: the <code class="literal">parsing</code> function and the <code class="literal">lexicon</code> variable:</p><div class="informalexample"><pre class="programlisting">val pathLexicon = "resources/text/lexicon.txt"
val <span class="strong"><strong>LEXICON</strong></span> = loadLexicon  //<span class="strong"><strong>18</strong></span>

def <span class="strong"><strong>parse</strong></span>(content: String): Array[String] = {
  val <span class="strong"><strong>regExpr</strong></span> = "['|,|.|?|!|:|\"]"
  content.trim.toLowerCase.replace(regExpr," ") //<span class="strong"><strong>19</strong></span>
  .split(" ") //<span class="strong"><strong>20</strong></span>
  .filter( _.length &gt; 2) //<span class="strong"><strong>21</strong></span>
}</pre></div><p>The lexicon<a id="id5910000" class="indexterm"/> is loaded from a file (line <code class="literal">18</code>). The <code class="literal">parse</code> method uses a simple <code class="literal">regExpr</code> regular expression to replace any punctuation into a space character (line <code class="literal">19</code>), which is used as a word delimiter (line <code class="literal">20</code>). All the words shorter than three characters are discounted (line 21).</p><p>Let's describe the workflow to load, parse, and analyze news articles related to the company, Tesla Inc. and its stock, ticker symbol TSLA.</p><p>The first step is to load and clean all the articles (corpus) defined in the <code class="literal">pathCorpus</code> directory (line <code class="literal">22</code>). This task is performed by the <code class="literal">DocumentsSource</code> class, as described in the <span class="emphasis"><em>Data extraction</em></span> section under <span class="emphasis"><em>Scala programming</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">val pathCorpus = "resources/text/chap5/"   //<span class="strong"><strong>22</strong></span>
val dateFormat = new SimpleDateFormat("MM.dd.yyyy")
val <span class="strong"><strong>pfnDocs</strong></span> = DocumentsSource(dateFormat, pathCorpus) |&gt;  //<span class="strong"><strong>23</strong></span>

val textAnalyzer = <span class="strong"><strong>TextAnalyzer</strong></span>[Long](parse, LEXICON)
val <span class="strong"><strong>pfnText</strong></span> = textAnalyzer |&gt;   //<span class="strong"><strong>24</strong></span>

for {
  corpus &lt;- pfnDocs(None)  //<span class="strong"><strong>25</strong></span>
  termsFreq &lt;- pfnText(corpus)  //<span class="strong"><strong>26</strong></span>
  <span class="strong"><strong>featuresSet</strong></span> &lt;- textAnalyzer.<span class="strong"><strong>quantize</strong></span>(termsFreq) //<span class="strong"><strong>27</strong></span>
  expected &lt;- Try(difference(TSLA_QUOTES, diffInt)) //<span class="strong"><strong>28</strong></span>
  nb &lt;- <span class="strong"><strong>NaiveBayes</strong></span>[Double](1.0, 
             featuresSet._2.zip(expected))//<span class="strong"><strong>29</strong></span>
} yield {
  show(s"Naive Bayes model${nb.toString(quantized._1)}")
   …
}</pre></div><p>A document source is fully defined by the path of the data input files and the format used in the timestamp (line <code class="literal">23</code>). The text analyzer and its explicit <code class="literal">pfnText</code> data transformation is instantiated (line <code class="literal">24</code>). The text processing pipeline is defined by the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The transformation of an input source file into a corpus (a sequence of news articles) using the <code class="literal">pfnDoc</code> partial function (line <code class="literal">25</code>).</li><li class="listitem">The transformation of a corpus into a sequence of a <code class="literal">termsFreq</code> relative keyword frequency vector using the <code class="literal">pfnText</code> partial function (line <code class="literal">26</code>).</li><li class="listitem">The transformation of a sequence of relative keywords frequency vector into a <code class="literal">featuresSet</code> using <code class="literal">quantize</code> (line <code class="literal">27</code>) (refer to the <span class="emphasis"><em>The differential operator</em></span> section under <span class="emphasis"><em>Time series in Scala</em></span> in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>).</li><li class="listitem">The creation of the binomial <code class="literal">NaiveBayes</code> model using the pair (<code class="literal">featuresSet._2</code> and <code class="literal">expected</code>) as training data (line <code class="literal">29</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The expected <a id="id5920000" class="indexterm"/>class values (0,1) are extracted from the daily stock price for Tesla Motors, <code class="literal">TSLA_QUOTES</code>:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>TSLA_QUOTES</strong></span> = Array[Double](250.56, 254.84, … )</pre></div><div class="note" title="Note"><h3 class="title"><a id="note15900"/>Note</h3><p>
<span class="strong"><strong>The semantic analysis</strong></span>
</p><p>This example uses a very primitive semantic map (lexicon) for the sake of illustrating the benefits and inner workings of the multinomial Naïve Bayes algorithm. Commercial applications involving sentiment analysis or topic analysis require a deeper understanding of semantic associations and extraction of topics using advanced generative models, such as the Latent Dirichlet allocation.</p></div></div><div class="section" title="Evaluating the text mining classifier"><div class="titlepage"><div><div><h3 class="title"><a id="ch05lvl3sec8100"/>Evaluating the text mining classifier</h3></div></div></div><p>The following <a id="id5930000" class="indexterm"/>chart describes the frequency of occurrences of some of the keywords related to either Tesla Motors or its stock ticker TSLA:</p><div class="mediaobject"><img src="../Images/image01380.jpeg" alt="Evaluating the text mining classifier"/><div class="caption"><p>A graph of the relative frequency of a partial list of stock-related terms</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following <a id="id5940000" class="indexterm"/>chart plots the expected change in the direction of the stock price for the trading day following the press release(s) or news article(s):</p><div class="mediaobject"><img src="../Images/image01381.jpeg" alt="Evaluating the text mining classifier"/><div class="caption"><p>A graph of the stock price and movement for the Tesla Motors stock</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding <a id="id5950000" class="indexterm"/>chart displays the historical price of the stock TSLA with the direction (UP and DOWN). The classification of 15 percent of the labeled data selected for the validation of the classifier has an F<sub>1</sub> score of 0.71. You need to keep in mind that no preprocessing or clustering was performed to isolate the most relevant features/keywords. We initially selected the keywords according to the frequency of their occurrences in the financial news.</p><p>It is fair to assume that some of the keywords have a more significant impact on the direction of the stock price than others. One simple but interesting exercise is to record the value of the F<sub>1</sub> score for a validation for which only the observations that have a high number of occurrences of a specific keyword are used, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01382.jpeg" alt="Evaluating the text mining classifier"/><div class="caption"><p>A bar chart representing predominant keywords in predicting the TSLA stock movement</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding <a id="id5960000" class="indexterm"/>bar chart shows that the terms <span class="strong"><strong>China</strong></span>, representing all the mentions of the activities of Tesla Motors in China, and <span class="strong"><strong>Charger</strong></span>, which covers all the references to the charging stations, have a significant positive impact on the direction of the stock with a probability averaging to 75 percent. The terms under the <span class="strong"><strong>Risk</strong></span> category have a negative impact on the direction of the stock with a probability of 68 percent, or a positive impact of the direction of the stock with a probability of 32 percent. Within the remaining eight categories, 72 percent of them were unusable as a predictor of the direction of the stock price.</p><p>This approach can be used for selecting features as an alternative to mutual information for using classifiers that are more elaborate. However, it should not regarded as the primary methodology for selecting features, but instead as a by-product of the Naïve Bayes formula applied to models with a very small number of relevant features. Techniques such as the principal components analysis, as described in the <span class="emphasis"><em>Principal components analysis</em></span> section under <span class="emphasis"><em>Dimension reduction</em></span> in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>, are available to reduce the dimension of the problem and make Naïve Bayes a viable classifier.</p></div></div></div>
<div class="section" title="Pros and cons" id="aid-5HC8K1"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec3900"/>Pros and cons</h1></div></div></div><p>The examples <a id="id5970000" class="indexterm"/>selected in this chapter do not do justice to the versatility and accuracy of the Naïve Bayes family of classifiers.</p><p>The Naïve Bayes algorithm is a simple and robust generative classifier that relies on prior conditional probabilities to extract a model from a training dataset. The Naïve Bayes model has its benefits, as mentioned here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It is easy to implement and parallelize</li><li class="listitem">It has a very low computational complexity: <span class="emphasis"><em>O((n+c)*m)</em></span>, where <span class="emphasis"><em>m</em></span> is the number of features, <span class="emphasis"><em>C</em></span> is the number of classes, and <span class="emphasis"><em>n</em></span> is the number of observations</li><li class="listitem">It handles missing data</li><li class="listitem">It supports incremental updates, insertions, and deletions</li></ul></div><p>However, Naïve Bayes is <a id="id5980000" class="indexterm"/>not a silver bullet. It has the following disadvantages:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It requires a large training set to achieve reasonable accuracy</li><li class="listitem">The assumption of the independence of features is not practical in the real world</li><li class="listitem">It requires dealing with the zero-frequency problem for counters</li></ul></div></div>
<div class="section" title="Summary" id="aid-5IAP61"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec4000"/>Summary</h1></div></div></div><p>There is a reason why the Naïve Bayes model is one of the first supervised learning techniques taught in a machine learning course: it is simple and robust. As a matter of fact, this is the first technique that should come to mind when you are considering creating a model from a labeled dataset, as long as the features are conditionally independent.</p><p>This chapter also introduced you to the basics of text mining as an application of Naïve Bayes.</p><p>Despite all its benefits, the Naïve Bayes classifier assumes that the features are conditionally independent, a limitation that cannot be always overcome. In the case of the classification of documents or news releases, Naïve Bayes incorrectly assumes that terms are semantically independent: the two entities' age and date of birth are highly correlated. The discriminative classifiers described in the next few chapters address some of Naïve Bayes' limitations [5:14].</p><p>This chapter does not treat temporal dependencies, sequence of events, or conditional dependencies between observed and hidden features. These types of dependencies necessitate a different approach to modeling that is the subject of <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>.</p></div>
<div class="chapter" title="Chapter&#xA0;6.&#xA0;Regression and Regularization"><div class="titlepage" id="aid-5J99O2"><div><div><h1 class="title"><a id="ch20"/>Chapter 6. Regression and Regularization</h1></div></div></div><p>In the first chapter, we briefly introduced the binary logistic regression (the binomial logistic regression for a single variable) as our first test case. The purpose was to illustrate the concept of discriminative classification. There are many more regression models, starting with the ubiquitous ordinary least square linear regression and the logistic regression [6:1].</p><p>The purpose of regression is to minimize a loss function, with the <a id="id5990000" class="indexterm"/><span class="strong"><strong>residual sum of squares</strong></span> (<span class="strong"><strong>RSS</strong></span>) being one that is commonly used. The problem of overfitting described in the <span class="emphasis"><em>Overfitting</em></span> section under <span class="emphasis"><em>Assessing a model</em></span> in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, can be addressed by adding a <span class="strong"><strong>penalty term</strong></span>
<a id="id6000000" class="indexterm"/> to the loss function. The penalty term is an element of the larger concept of <a id="id6010000" class="indexterm"/><span class="strong"><strong>regularization</strong></span>.</p><p>The first section of this chapter will describe and implement the <a id="id6020000" class="indexterm"/>linear <span class="strong"><strong>least-squares regression</strong></span>. The second section will introduce the concept of regularization with an implementation of the <a id="id6030000" class="indexterm"/><span class="strong"><strong>ridge regression</strong></span>. Finally, the logistic regression will be revisited in detail from the perspective of a classification model.</p><div class="section" title="Linear regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec4100"/>Linear regression</h1></div></div></div><p>Linear regression<a id="id6040000" class="indexterm"/> is by far the most widely used, or at least the most commonly known, regression method. The terminology is usually associated with the concept of fitting a model to data and minimizing the errors between the expected and predicted values by computing the sum of square errors, residual sum of square errors, or least-square errors.</p><p>The least squares problems fall into the following two categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Ordinary least squares</li><li class="listitem">Nonlinear least squares</li></ul></div><div class="section" title="One-variate linear regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7300"/>One-variate linear regression</h2></div></div></div><p>Let's start <a id="id6050000" class="indexterm"/>with the simplest form of linear <a id="id6060000" class="indexterm"/>regression, which is the single variable regression, in order to introduce the terms and concepts behind linear regression. In its simplest interpretation, the one-variate linear regression consists of fitting a line to a set of data points <span class="emphasis"><em>{x, y}</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note16000"/>Note</h3><p>M1: A single variable linear regression for a model <span class="emphasis"><em>f</em></span> with weights <span class="emphasis"><em>w<sub>j</sub></em></span> for features <span class="emphasis"><em>x<sub>j</sub></em></span> and labels (or expected values) <span class="emphasis"><em>y<sub>j</sub></em></span> is given by the following formula:</p><div class="mediaobject"><img src="../Images/image01383.jpeg" alt="One-variate linear regression"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>w<sub>1</sub></em></span> is the slope, <span class="emphasis"><em>w<sub>0</sub></em></span> is the intercept, <span class="emphasis"><em>f</em></span> is the linear function that minimizes the RSS, and (<span class="emphasis"><em>x<sub>j</sub>, y<sub>j</sub></em></span>) is a set of <span class="emphasis"><em>n</em></span> observations.</p></div><p>The RSS<a id="id6070000" class="indexterm"/> is also known as the <span class="strong"><strong>sum of squared errors</strong></span> (<span class="strong"><strong>SSE</strong></span>). The <span class="strong"><strong>mean squared error</strong></span> (<span class="strong"><strong>MSE</strong></span>) for<a id="id6080000" class="indexterm"/> <span class="emphasis"><em>n</em></span> observations is defined as the ratio <span class="emphasis"><em>RSS/n</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note16200"/>Note</h3><p>
<span class="strong"><strong>Terminology</strong></span>
</p><p>The <a id="id6090000" class="indexterm"/>terminology used in the scientific literature regarding regression is a bit confusing at times. Regression weights are also known as regression coefficients or regression parameters. The weights are referred to as <span class="emphasis"><em>w</em></span> in formulas and the source code throughout the chapter, although <span class="emphasis"><em>β</em></span> is also used in reference books.</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8200"/>Implementation</h3></div></div></div><p>Let's <a id="id6100000" class="indexterm"/>create a <code class="literal">SingleLinearRegression</code> parameterized class to implement the <span class="strong"><strong>M1 </strong></span>formula. The linear regression is a data transformation that uses a model implicitly derived or built from data. Therefore, the simple linear regression implements the <code class="literal">ITransform</code> trait, as described in <a id="id6110000" class="indexterm"/>the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><p>The <code class="literal">SingleLinearRegression</code> class takes the following two arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An <code class="literal">xt</code> vector of single variable observations</li><li class="listitem">A vector of <code class="literal">expected</code> values or labels (line <code class="literal">1</code>)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SingleLinearRegression</strong></span>[T &lt;: AnyVal](
    <span class="strong"><strong>xt</strong></span>: XSeries[T], 
    <span class="strong"><strong>expected</strong></span>: Vector[T])(implicit f: T =&gt; Double)
  extends ITransform[T](xt) with Monitor[Double] {   //<span class="strong"><strong>1</strong></span>
  type <span class="strong"><strong>V</strong></span> = Double  //<span class="strong"><strong>2</strong></span>

  val model: Option[DblPair] = train //<span class="strong"><strong>3</strong></span>
  def train: Option[DblPair]
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[T, Try[V]]
  def slope: Option[Double] = model.map(_._1)
  def intercept: Option[Double] = model.map(_._2)
}</pre></div><p>The <code class="literal">Monitor</code> trait is used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The class has to define the type of the output of the <code class="literal">|&gt;</code> prediction method, which is a <code class="literal">Double</code> (line <code class="literal">2</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note16300"/>Note</h3><p>
<span class="strong"><strong>Model instantiation</strong></span>
</p><p>The model parameters are computed through training and the model is instantiated regardless of whether the model is actually validated. A commercial application requires the model to be validated using a methodology such as the K-fold validation, as described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p></div><p>The training generates the model defined as the regression weights (slope and intercept) (line <code class="literal">3</code>). The model is set as <code class="literal">None</code> if an exception is thrown during training:</p><div class="informalexample"><pre class="programlisting">def train: Option[DblPair] = {
   val regr = new SimpleRegression(true) //<span class="strong"><strong>4</strong></span>
   regr.addData(<span class="strong"><strong>zipToSeries</strong></span>(xt, expected).toArray)  //<span class="strong"><strong>5</strong></span>
   Some((regr.getSlope, regr.getIntercept))  //<span class="strong"><strong>6</strong></span>
}</pre></div><p>The regression <a id="id6120000" class="indexterm"/>weights or coefficients, that is the <code class="literal">model</code> tuple, are computed using the <code class="literal">SimpleRegression</code> class from the <code class="literal">stats.regression</code> package of the Apache Commons Math library with the <code class="literal">true</code> argument to trigger the computation of the intercept (line <code class="literal">4</code>). The input time series and the labels (or expected values) are zipped to generate an array of two values (input and expected) (line <code class="literal">5</code>). The <code class="literal">model</code> is initialized with the slope and intercept computed during the training (line <code class="literal">6</code>).</p><p>The <code class="literal">zipToSeries</code> method of the <code class="literal">XTSeries</code> object is described in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note16400"/>Note</h3><p>
<span class="strong"><strong>private versus private[this]</strong></span>
</p><p>A <code class="literal">private</code> value or variable can be accessed only by all the instances of a class. A value declared <code class="literal">private[this]</code> can be manipulated only by the <code class="literal">this</code> instance. For example, the value model can be accessed only by the <code class="literal">this</code> instance of <code class="literal">SingleLinearRegression</code>.</p></div></div><div class="section" title="Test case"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8300"/>Test case</h3></div></div></div><p>For our <a id="id6130000" class="indexterm"/>first test case, we compute the single variate linear regression of the price of the Copper ETF (ticker symbol: CU) over a period of 6 months (January 1, 2013 to June 30, 2013):</p><div class="informalexample"><pre class="programlisting">val path = "resources/data/chap6/CU.csv"
for {
  price &lt;- DataSource(path, false, true, 1) get adjClose //<span class="strong"><strong>7</strong></span>
  days &lt;- Try(Vector.tabulate(price.size)(_.toDouble)) //<span class="strong"><strong>8</strong></span>
  linRegr &lt;- SingleLinearRegression[Double](days, price) //<span class="strong"><strong>9</strong></span>
} yield {
  if( linRegr.isModel ) {
    val slope = linRegr.slope.get
    val intercept = linRegr.intercept.get
    val error = mse(days, price, slope, intercept)//<span class="strong"><strong>10</strong></span>
  }
  …
}</pre></div><p>The daily closing <code class="literal">price</code> of the ETF CU is extracted from a CSV file (line <code class="literal">7</code>) as the expected values using a <code class="literal">DataSource</code> instance, as described in the <span class="emphasis"><em>Data extraction and Data sources</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>. The x values <code class="literal">days</code> are automatically generated as a linear function (line <code class="literal">8</code>). The expected values (<code class="literal">price</code>) and sessions (<code class="literal">days</code>) are the inputs to the instantiation of the simple linear regression (line <code class="literal">9</code>).</p><p>Once the <a id="id6140000" class="indexterm"/>model is created successfully, the test code computes the <code class="literal">mse</code> mean squared error of the predicted and expected values (line <code class="literal">10</code>):</p><div class="informalexample"><pre class="programlisting">def mse(
    predicted: DblVector, 
    expected: DblVector, 
    slope: Double, 
    intercept: Double): Double = {
  val predicted = xt.map( slope*_ + intercept)
  XTSeries.mse(predicted, expected)  //<span class="strong"><strong>11</strong></span>
}</pre></div><p>The mean least squared error is computed using the <code class="literal">mse</code> method of <code class="literal">XTSeries</code> (line <code class="literal">11</code>). The original stock price and linear regression equation are plotted on the following chart:</p><div class="mediaobject"><img src="../Images/image01384.jpeg" alt="Test case"/></div><p style="clear:both; height: 1em;"> </p><p>The total least square error is 0.926.</p><p>Although the single variable linear regression is convenient, it is limited to a scalar time series. Let's consider <a id="id6150000" class="indexterm"/>the case of multiple variables.</p></div></div><div class="section" title="Ordinary least squares regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7400"/>Ordinary least squares regression</h2></div></div></div><p>The <a id="id6160000" class="indexterm"/><span class="strong"><strong>ordinary least squares regression</strong></span> computes<a id="id6170000" class="indexterm"/> the parameters <span class="emphasis"><em>w</em></span> of a linear function <span class="emphasis"><em>y = f(x<sub>0</sub>, x<sub>2</sub> … x<sub>d</sub>)</em></span> by minimizing the residual sum of squares. The optimization problem is solved by performing vector and matrix operations (transposition, inversion, and substitution).</p><div class="note" title="Note"><h3 class="title"><a id="note16500"/>Note</h3><p>M2: The minimization of the loss function is given by the following formula:</p><div class="mediaobject"><img src="../Images/image01385.jpeg" alt="Ordinary least squares regression"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>wj</em></span> is the weights or parameters of the regression, <span class="emphasis"><em>(x<sub>i</sub>, y<sub>i</sub>)<sub>i:0, n-1</sub></em></span> is the <span class="emphasis"><em>n</em></span> observations of a vector <span class="emphasis"><em>x</em></span> and an expected output value <span class="emphasis"><em>y</em></span>, and <span class="emphasis"><em>f</em></span> is the linear multivariate function, <span class="emphasis"><em>y = f (x0, x1, …,xd)</em></span>.</p></div><p>There are several methodologies to minimize the residual sum of squares for a linear regression:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Resolution of the set of <span class="emphasis"><em>n</em></span> equations with <span class="emphasis"><em>d</em></span> variables (weights) using the <span class="strong"><strong>QR decomposition</strong></span> <a id="id6180000" class="indexterm"/>of the <span class="emphasis"><em>n</em></span> by <span class="emphasis"><em>d</em></span> matrix, representing the time series of <span class="emphasis"><em>n</em></span> observations of a vector of <span class="emphasis"><em>d</em></span> dimensions with <span class="emphasis"><em>n &gt;= d</em></span> [6:2]</li><li class="listitem"><span class="strong"><strong>Singular value decomposition</strong></span> on the <a id="id6190000" class="indexterm"/>observations-features matrix, in the case where the dimension <span class="emphasis"><em>d</em></span> exceeds the number <a id="id6200000" class="indexterm"/>of observations <span class="emphasis"><em>n</em></span> [6:3]</li><li class="listitem"><span class="strong"><strong>Gradient descent</strong></span> [6:4]</li><li class="listitem"><span class="strong"><strong>Stochastic </strong></span><a id="id6210000" class="indexterm"/><span class="strong"><strong>gradient descent</strong></span> [6:5]</li></ul></div><p>An overview of these matrix decompositions and optimization techniques can be found in the <span class="emphasis"><em>Linear algebra</em></span> and <span class="emphasis"><em>Summary of optimization techniques</em></span> sections in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The QR <a id="id6220000" class="indexterm"/>decomposition generates the smallest <a id="id6230000" class="indexterm"/>relative error MSE for the most common least squares problem. The technique is used in our implementation of the least squares regression.</p><div class="section" title="Design"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8400"/>Design</h3></div></div></div><p>The <a id="id6240000" class="indexterm"/>implementation of the least squares regression leverages the Apache Commons Math library implementation of the ordinary least squares regression [6:6].</p><p>This chapter describes several types of regression algorithms. It makes sense to define a generic <code class="literal">Regression</code> trait that defines the key element component of a regression algorithm.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A model of the <code class="literal">RegressionModel</code> type (line <code class="literal">1</code>)</li><li class="listitem">Two methods to access the components of the regression model: <code class="literal">weights</code> and <code class="literal">rss</code> (line <code class="literal">2</code> and <code class="literal">3</code>)</li><li class="listitem">A <code class="literal">train</code> polymorphic method that implements the training of this specific regression algorithm (line <code class="literal">4</code>)</li><li class="listitem">A <code class="literal">training</code> protected method that wraps <code class="literal">train</code> into a <code class="literal">Try</code> monad</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Regression</strong></span> {
  val <span class="strong"><strong>model</strong></span>: Option[<span class="strong"><strong>RegressionModel</strong></span>] = training //<span class="strong"><strong>1</strong></span>
   
  def <span class="strong"><strong>weights</strong></span>: Option[DblArray] = model.map( _.weights)//<span class="strong"><strong>2</strong></span>
  def <span class="strong"><strong>rss</strong></span>: Option[Double] = model.map(_.rss) //<span class="strong"><strong>3</strong></span>
  def isModel: Boolean = model != None
     
  protected def <span class="strong"><strong>train</strong></span>: RegressionModel  //<span class="strong"><strong>4</strong></span>
  def training: Option[RegressionModel] = Try(train) match {
    case Success(_model) =&gt; Some(_model)
    case Failure(e) =&gt; e match {
      case err: MatchError =&gt; { … }        case _ =&gt; { … }
    }
  }
}</pre></div><p>The model is simply defined by its <code class="literal">weights</code> and its residual sum of squares (line <code class="literal">5</code>):</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>RegressionModel</strong></span>(  //<span class="strong"><strong>5</strong></span>
   val weights: DblArray, val rss: Double) extends Model

object <span class="strong"><strong>RegressionModel</strong></span> {
  def <span class="strong"><strong>dot[T &lt;: AnyVal]</strong></span>(x: Array[T], 
     w: DblArray)(implicit f: T =&gt; Double): Double = 
     x.zip(weights.drop(1))  
      .map{ case(_x, w) =&gt; _x*w}.sum + weights.head //<span class="strong"><strong>6</strong></span>
}</pre></div><p>The <code class="literal">RegressionModel</code> companion<a id="id6250000" class="indexterm"/> object implements the computation of the <code class="literal">dot</code> inner product of the <code class="literal">weights</code> regression and an observation, <code class="literal">x</code> (line <code class="literal">6</code>). The <code class="literal">dot</code> method is used throughout the chapter.</p><p>Let's create a <code class="literal">MultiLinearRegression</code> class as a data transformation whose model is implicitly derived from the input data (training set), as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MultiLinearRegression</strong></span>[T &lt;: AnyVal](
     xt: XVSeries[T], 
     expected: DblVector)(implicit f: T =&gt; Double)
  extends ITransform[Array[T]](xt) with Regression 
       with Monitor[Double] { //<span class="strong"><strong>7</strong></span>
  type <span class="strong"><strong>V</strong></span> = Double  //<span class="strong"><strong>8</strong></span>

  override def <span class="strong"><strong>train</strong></span>: Option[RegressionModel] //<span class="strong"><strong>9</strong></span>
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] //<span class="strong"><strong>10</strong></span>
}</pre></div><p>The <code class="literal">MultiLinearRegression</code> class takes two arguments: the multidimensional time series of the <code class="literal">xt</code> observations and the vector of <code class="literal">expected</code> values (line <code class="literal">7</code>). The class implements the <code class="literal">ITransform</code> trait and needs to define the type of the output value for the prediction or regression, <code class="literal">V</code> as a <code class="literal">Double</code> (line <code class="literal">8</code>). The constructor for <code class="literal">MultiLinearRegression</code> creates the <code class="literal">model</code> through training (line <code class="literal">9</code>). The <code class="literal">ITransform</code> trait's <code class="literal">|&gt;</code> method implements the runtime prediction for the multilinear regression (line <code class="literal">10</code>).</p><p>The <code class="literal">Monitor</code> trait is used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><div class="note" title="Note"><h3 class="title"><a id="note16700"/>Note</h3><p>
<span class="strong"><strong>The regression model</strong></span>
</p><p>The RSS <a id="id6260000" class="indexterm"/>is included in the model because it provides the client code with the important information regarding the accuracy of the underlying technique used to minimize the loss function.</p></div><p>The relationship<a id="id6270000" class="indexterm"/> between the different components of the multilinear regression is described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01386.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the multilinear (OLS) regression</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram omits the helper traits and classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8500"/>Implementation</h3></div></div></div><p>The<a id="id6280000" class="indexterm"/> training is performed during the instantiation of the <code class="literal">MultiLinearRegression</code> class (refer to the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: RegressionModel = {
  val <span class="strong"><strong>olsMlr</strong></span> = new MultiLinearRAdapter   //<span class="strong"><strong>11</strong></span>
  olsMlr.createModel(expected, data)  //<span class="strong"><strong>12</strong></span>
  RegressionModel(olsMlr.weights, olsMlr.rss) //<span class="strong"><strong>13</strong></span>
}</pre></div><p>The functionality of the ordinary least squares regression in the Apache Commons Math library is accessed through an <code class="literal">olsMlr</code> reference to the <code class="literal">MultiLinearRAdapter</code> adapter class (line <code class="literal">11</code>).</p><p>The <code class="literal">train</code> method <a id="id6290000" class="indexterm"/>creates the model by invoking the <code class="literal">OLSMultipleLinearRegression</code> Apache Commons Math class (line <code class="literal">12</code>) and returns the regression model (line <code class="literal">13</code>). The various methods of the class are accessed through the <code class="literal">MultiLinearRAdapter</code> adapter class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MultiLinearRAdapter</strong></span> extends OLSMultipleLinearRegression {
  def createModel(y: DblVector, x: Vector[DblArray]): Unit = 
     super.newSampleData(y.toArray, x.toArray)
  
  def weights: DblArray = estimateRegressionParameters
  def rss: Double = calculateResidualSumOfSquares
}</pre></div><p>The <code class="literal">createModel</code>, <code class="literal">weights</code>, and <code class="literal">rss</code> methods route the request to the corresponding methods in <code class="literal">OLSMultipleLinearRegression</code>.</p><p>The <code class="literal">Try{}</code> Scala exception handling monad is used as the return type for the <code class="literal">train</code> method in order to catch the different types of exceptions thrown by the Apache Commons Math library such as <code class="literal">MathIllegalArgumentException</code>, <code class="literal">MathRuntimeException</code>, or <code class="literal">OutOfRangeException</code>.</p><div class="note" title="Note"><h3 class="title"><a id="note16800"/>Note</h3><p>
<span class="strong"><strong>Exception handling</strong></span>
</p><p>Wrapping up invocation of methods in a third party with a <code class="literal">Try {}</code> Scala exception handler matters for a couple of reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It makes debugging easier by segregating your code from the third party</li><li class="listitem">It allows your code to recover from the exception by reexecuting the same function with an alternative third-party library method, whenever possible</li></ul></div></div><p>The predictive algorithm for the ordinary least squares regression is implemented by the <code class="literal">|&gt;</code> data transformation. The method predicts the output value, given a model and an input value, <code class="literal">x</code>:</p><div class="informalexample"><pre class="programlisting">def |&gt; : PartialFunction[Array[T], Try[V]] = {
  case x: Array[T] if isModel &amp;&amp; 
       x.length == model.get.size-1  
         =&gt; Try( dot(x, model.get) ) //<span class="strong"><strong>14</strong></span>
}</pre></div><p>The predictive value is computed using the <code class="literal">dot</code> method defined in the <code class="literal">RegressionModel</code> singleton, which<a id="id6300000" class="indexterm"/> was introduced earlier in this section (line <code class="literal">14</code>).</p></div><div class="section" title="Test case 1 – trending"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8600"/>Test case 1 – trending</h3></div></div></div><p>
<span class="strong"><strong>Trending</strong></span> <a id="id6310000" class="indexterm"/>consists <a id="id6320000" class="indexterm"/>of extracting the long-term movement in a time series. Trend lines are detected using a multivariate least squares regression. The objective of this first test is to evaluate the filtering capability of the ordinary least squares regression. </p><p>The regression is performed on the relative price variation of the Copper ETF (ticker symbol: CU). The selected features are <code class="literal">volatility</code> and <code class="literal">volume</code>, and the label or target variable is the price change between two consecutive <code class="literal">y</code> trading sessions.</p><p>The naming convention for the trading data and metrics is described in the <span class="emphasis"><em>Trading data</em></span> section under <span class="emphasis"><em>Technical analysis</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The volume, volatility, and price variation for CU between January 1, 2013 and June 30, 2013 are plotted on the following chart:</p><div class="mediaobject"><img src="../Images/image01387.jpeg" alt="Test case 1 – trending"/><div class="caption"><p>The chart for price variation, volatility, and trading volume for Copper ETF</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's write the <a id="id6330000" class="indexterm"/>client code to compute the multivariate linear regression, <span class="emphasis"><em>price change = w<sub>0</sub> + volatility.w<sub>1</sub> + volume.w<sub>2</sub></em></span>:</p><div class="informalexample"><pre class="programlisting">import  YahooFinancials._
val path = "resources/data/chap6/CU.csv"  //<span class="strong"><strong>15</strong></span>
val src = DataSource(path, true, true, 1)  //<span class="strong"><strong>16</strong></span>

for {
  price &lt;- src.get(adjClose)  //<span class="strong"><strong>17</strong></span>
  volatility &lt;- src.get(volatility)  //<span class="strong"><strong>18</strong></span>
  volume &lt;- src.get(volume)  //<span class="strong"><strong>19</strong></span>
  (features, expected) &lt;- differentialData(volatility, 
                     volume, price, diffDouble)  //<span class="strong"><strong>20</strong></span>
  <span class="strong"><strong>regression</strong></span> &lt;- MultiLinearRegression[Double]( 
                  features, expected)  //<span class="strong"><strong>21</strong></span>
} yield {
  if( regression.isModel ) {
    val trend = features.map(dot(_,regression.weights.get))
    <span class="strong"><strong>display</strong></span>(expected, trend)  //<span class="strong"><strong>22</strong></span>
  }
}</pre></div><p>Let's take a look at the steps required for the execution of the test: it consists of collecting data, extracting the features and expected values, and training the multilinear regression model:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Locate the CSV formatted data source file (line <code class="literal">15</code>).</li><li class="listitem">Create a data source extractor, <code class="literal">DataSource</code>, for the trading session closing <code class="literal">price</code>, the <code class="literal">volatility</code> session, and the <code class="literal">volume</code> session for the ETF CU (line <code class="literal">16</code>).</li><li class="listitem">Extract the price of the ETF (line <code class="literal">17</code>), its volatility within a trading session (line <code class="literal">18</code>), and the trading volume during the session (line <code class="literal">19</code>) using the <code class="literal">DataSource</code> transform.</li><li class="listitem">Generate the labeled data as a pair of features (relative volatility and relative volume for the ETF) and expected outcome (0, 1) for training the model for which <code class="literal">1</code> represents the increase in the price and <code class="literal">0</code> represents the decrease in the price (line <code class="literal">20</code>). The <code class="literal">differentialData</code> generic method of the <code class="literal">XTSeries</code> singleton is described in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</li><li class="listitem">The multilinear regression is instantiated using the <code class="literal">features</code> set and the <code class="literal">expected</code> change in the daily ETF price (line <code class="literal">21</code>).</li><li class="listitem">Display the expected and trending values using JFreeChart (line <code class="literal">22</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The time series of <a id="id6340000" class="indexterm"/>expected values and the data predicted by the regression are plotted on the following chart:</p><div class="mediaobject"><img src="../Images/image01388.jpeg" alt="Test case 1 – trending"/><div class="caption"><p>The price variation and the least squares regression for the Copper ETF according to volatility and volume</p></div></div><p style="clear:both; height: 1em;"> </p><p>The least squares regression model is defined by the linear function for the estimation of price variation as follows:</p><p>
<span class="emphasis"><em>price(t+1)-price(t) = -0.01 + 0.014 volatility – 0.0042.volume</em></span>
</p><p>The estimated price change (the dotted line in the preceding chart) represents the long-term trend from which the noise is filtered out. In other words, the least squares regression operates as a simple low-pass filter as an alternative to some of the filtering techniques such as the discrete Fourier transform or the Kalman filter, as described in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span> [6:7].</p><p>Although trend detection is an interesting application of the least squares regression, the method has limited filtering<a id="id6350000" class="indexterm"/> capabilities for time series [6:8]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It is sensitive to outliers</li><li class="listitem">The first and last few observations need to be discarded</li><li class="listitem">As a deterministic method, it does not support noise analysis (distribution, frequencies, and so on)</li></ul></div></div><div class="section" title="Test case 2 – feature selection"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8700"/>Test case 2 – feature selection</h3></div></div></div><p>The second test<a id="id6360000" class="indexterm"/> case is related to feature selection. The objective is to discover which subset of initial features generates the most accurate regression model, that is, the model with the smallest residual sum of squares on the training set.</p><p>Let's consider an initial set of <span class="emphasis"><em>D</em></span> features <span class="emphasis"><em>{x<sub>i</sub>}</em></span>. The objective is to estimate the subset of features <span class="emphasis"><em>{x<sub>id</sub>}</em></span> that are most relevant to the set of observations using a least squares regression. Each subset of features is associated with a <span class="emphasis"><em>f<sub>j</sub>(x|w<sub>j</sub>)</em></span> model:</p><div class="mediaobject"><img src="../Images/image01389.jpeg" alt="Test case 2 – feature selection"/><div class="caption"><p>A diagram for the features set selection</p></div></div><p style="clear:both; height: 1em;"> </p><p>The ordinary least square regression is used to select the model parameters <span class="emphasis"><em>w</em></span> in the case the feature set is small. Performing the regression of each subset of a large original feature set is not practical.</p><div class="note" title="Note"><h3 class="title"><a id="note16900"/>Note</h3><p>M3: The features selection can be expressed mathematically as follows:</p><div class="mediaobject"><img src="../Images/image01390.jpeg" alt="Test case 2 – feature selection"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>w<sub>jk</sub></em></span> is the weights of the regression for the function/model <span class="emphasis"><em>f<sub>j</sub>, (x<sub>i</sub>, y<sub>i</sub>)<sub>i:0,n-1</sub></em></span> is the <span class="emphasis"><em>n</em></span> observations of a vector <span class="emphasis"><em>x</em></span> and expected output value <span class="emphasis"><em>y</em></span>, and <span class="emphasis"><em>f</em></span> is the linear multivariate function, <span class="emphasis"><em>y = f (x<sub>0</sub>, x<sub>1</sub>, …,x<sub>d</sub>)</em></span>.</p></div><p>Let's consider <a id="id6370000" class="indexterm"/>the following four financial time series over the period from January 1, 2009 to December 31, 2013:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The exchange rate of Chinese Yuan to US Dollar</li><li class="listitem">The S&amp;P 500 index</li><li class="listitem">The spot price of gold</li><li class="listitem">The 10-year Treasury bond price</li></ul></div><p>The problem is to estimate which combination of the S&amp;P 500 index, gold price, and 10-year Treasury bond price variables is the most correlated to the exchange rate of the Yuan. For practical reasons, we use the Exchange Trade Funds CYN as the proxy for the Yuan/US dollar exchange rate (similarly, SPY, GLD, and TLT for the S&amp;P 500 index, spot price of gold, and 10-year Treasury bond price, respectively).</p><div class="note" title="Note"><h3 class="title"><a id="note17100"/>Note</h3><p>
<span class="strong"><strong>Automation of features extraction</strong></span>
</p><p>The code in this section implements an ad hoc extraction of features with an arbitrary fixed set of models. The process can be easily automated with an optimizer (the gradient descent, genetic algorithm, and so on) using <span class="emphasis"><em>1/RSS</em></span> as the objective function.</p></div><p>The number of models to evaluate is relatively small, so an ad hoc approach to compute the RSS for each combination is acceptable. Let's take a look at the following graph:</p><div class="mediaobject"><img src="../Images/image01391.jpeg" alt="Test case 2 – feature selection"/><div class="caption"><p>The graph of the Chinese Yuan exchange rate, gold price, 10-year Treasury bond price, and S&amp;P 500 index</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">getRss</code> method<a id="id6380000" class="indexterm"/> implements the computation of the RSS value given a set of <code class="literal">xt</code> observations, <code class="literal">y</code> expected (smoothed) values, and <code class="literal">featureLabels</code> labels for features and then returns a textual result:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>getRss</strong></span>(
     xt: Vector[DblArray], 
     expected: DblVector, 
     featureLabels: Array[String]): String = {

  val <span class="strong"><strong>regression</strong></span> = 
         new MultiLinearRAdapter[Double](xt,expected) //<span class="strong"><strong>23</strong></span>
  val modelStr = regression.weights.get.view
        .zipWithIndex.map{ case( w, n) =&gt; {
    val weights_str = format(w, emptyString, SHORT)
    if(n == 0 ) s"${featureLabels(n)} = $weights_str"
    else s"${weights_str}.${featureLabels(n)}"
  }}.mkString(" + ")
  s"model: $modelStr\nRSS =${regression.get.rss}" //<span class="strong"><strong>24</strong></span>
}</pre></div><p>The <code class="literal">getRss</code> method <a id="id6390000" class="indexterm"/>merely trains the model by instantiating the multilinear regression class (line <code class="literal">23</code>). Once the regression model is trained during the instantiation of the <code class="literal">MultiLinearRegression</code> class, the coefficients of the regression weights and the RSS values are stringized (line <code class="literal">24</code>). The <code class="literal">getRss</code> method is invoked for any combination of the ETF, GLD, SPY, and TLT variables against the CNY label.</p><p>Let's take a look at the following test code:</p><div class="informalexample"><pre class="programlisting">val SMOOTHING_PERIOD: Int = 16  //<span class="strong"><strong>25</strong></span>
val path = "resources/data/chap6/"
val symbols = Array[String]("CNY", "GLD", "SPY", "TLT") //<span class="strong"><strong>26</strong></span>
val movAvg = SimpleMovingAverage[Double](SMOOTHING_PERIOD) //<span class="strong"><strong>27</strong></span>

for {
  <span class="strong"><strong>pfnMovAve</strong></span> &lt;- Try(movAvg |&gt;)  //<span class="strong"><strong>28</strong></span>
  smoothed &lt;- <span class="strong"><strong>filter</strong></span>(pfnMovAve)  //<span class="strong"><strong>29</strong></span>
  models &lt;- <span class="strong"><strong>createModels</strong></span>(smoothed)  //<span class="strong"><strong>30</strong></span>
  rsses &lt;- Try(<span class="strong"><strong>getModelsRss</strong></span>(models, smoothed)) //<span class="strong"><strong>31</strong></span>
  (mses, tss) &lt;- <span class="strong"><strong>totalSquaresError</strong></span>(models,smoothed.head) //<span class="strong"><strong>32</strong></span>
} yield {
   s"""${rsses.mkString("\n")}\n${mses.mkString("\n")}
      | \nResidual error= $tss".stripMargin
}</pre></div><p>The dataset is large (1,260 trading sessions) and noisy enough to warrant filtering using a simple moving average with a period of 16 trading sessions (line <code class="literal">25</code>). The purpose of the test is to evaluate the possible correlation between the four ETFs: CNY, GLD, SPY, and TLT (line <code class="literal">26</code>). The execution test instantiates the simple moving average (line <code class="literal">27</code>), as described in the <span class="emphasis"><em>The simple moving average</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</p><p>The workflow executes the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Instantiate a simple moving average <code class="literal">pfnMovAve</code> partial function (line <code class="literal">28</code>).</li><li class="listitem">Generate smoothed historical prices for the CNY, GLD, SPY, and TLT ETFs using the <code class="literal">filter</code> function (line <code class="literal">29</code>):<div class="informalexample"><pre class="programlisting">Type PFNMOVAVE = PartialFunction[DblVector, Try[DblVector]]

def filter(pfnMovAve: PFNMOVEAVE): Try[Array[DblVector]] = Try {
   symbols.map(s =&gt; DataSource(s"$path$s.csv", true, true, 1))
      .map( _.get(adjClose) )
      .map( pfnMovAve(_)).map(_.get)</pre></div></li><li class="listitem">Generate <a id="id6400000" class="indexterm"/>the list of features for each model using the <code class="literal">createModels</code> method (line <code class="literal">30</code>):<div class="informalexample"><pre class="programlisting">type Models = List[(Array[String], DblMatrix)]

def <span class="strong"><strong>createModels</strong></span>(smoothed: Array[DblVector]): Try[Models] = 
Try {
  val features = smoothed.drop(1).map(_.toArray)  //<span class="strong"><strong>33</strong></span>
  List[(Array[String], DblMatrix)](   //<span class="strong"><strong>34</strong></span>
   (Array[String]("CNY","SPY","GLD","TLT"), features.transpose),
   (Array[String]("CNY","GLD","TLT"),features.drop(1).transpose),
   (Array[String]("CNY","SPY","GLD"),features.take(2).transpose),
   (Array[String]("CNY","SPY","TLT"), features.zipWithIndex
                      .filter( _._2 != 1).map( _._1).transpose),
   (Array[String]("CNY","GLD"), features.slice(1,2).transpose)
   )
}</pre></div><p>The smoothed values for CNY are used as the expected values. Therefore, they are removed from the features list (line <code class="literal">33</code>). The five models are evaluated by adding or removing elements from the features list (line <code class="literal">34</code>).</p></li><li class="listitem">Next, the workflow computes the residual sum of squares for all the models using <code class="literal">getModelsRss</code> (line <code class="literal">31</code>). The method invokes <code class="literal">getRss</code>, which was introduced earlier in this section, for each model (line <code class="literal">35</code>):<div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>getModelsRss</strong></span>(
    <span class="strong"><strong>models</strong></span>: Models, 
    y: Array[DblVector]): List[String] = 
  models.map{ case (labels, m) =&gt; 
         s"${<span class="strong"><strong>getRss</strong></span>(m.toVector, y.head, labels)}" }  //<span class="strong"><strong>35</strong></span>
</pre></div></li><li class="listitem">Finally, the<a id="id6410000" class="indexterm"/> last step of the workflow consists of computing the <code class="literal">mses</code> mean squared errors for each model and the total squared errors (line <code class="literal">33</code>):<div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>totalSquaresError</strong></span>(
    models: Models, 
    expected: DblVector): Try[(List[String], Double)] = Try {
 
  val errors = models.map{case (labels,m) =&gt; 
<span class="strong"><strong>rssSum</strong></span>(m, expected)._1}//<span class="strong"><strong>36</strong></span>
  val mses = models.zip(errors)
           .map{case(f,e) =&gt; s"MSE: ${f._1.mkString(" ")} = $e"}
  (mses, Math.sqrt(errors.sum)/models.size)  //<span class="strong"><strong>37</strong></span>
}</pre></div></li></ol><div style="height:10px; width: 1px"/></div><p>The <code class="literal">totalSquaresError</code> method computes the error for each model by summing the RSS value, <code class="literal">rssSum</code>, for each model (line <code class="literal">36</code>). The method returns a pair of an array of the mean squared error for each model and the total squared error (line <code class="literal">37</code>).</p><p>The RSS does not always provide an accurate visualization of the fitness of the regression model. The fitness of the regression model is commonly assessed using the <span class="strong"><strong>r<sup>2</sup> statistics</strong></span>. The r<sup>2</sup> value is a number that indicates how well data fits into a statistical model.</p><div class="note" title="Note"><h3 class="title"><a id="note17200"/>Note</h3><p>M4: The RSS and r<sup>2</sup> statistics are defined by the following formulae:</p><div class="mediaobject"><img src="../Images/image01392.jpeg" alt="Test case 2 – feature selection"/></div><p style="clear:both; height: 1em;"> </p></div><p>The implementation of the computation of the r<sup>2</sup> statistics is simple. For each model <span class="emphasis"><em>f<sub>j</sub></em></span>, the <code class="literal">rssSum</code> method computes the tuple (rss and least squares errors), as defined in the <span class="strong"><strong>M4 </strong></span>formula:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>rssSum</strong></span>(xt: DblMatrix, expected: DblVector): DblPair = {
  val regression = 
         MultiLinearRegression[Double](xt, expected) //<span class="strong"><strong>38</strong></span>
  val pfnRegr = regression |&gt;  //<span class="strong"><strong>39</strong></span>
  val results = sse(expected.toArray, xt.map(pfnRegr(_).get))
  (regression.rss, results) //<span class="strong"><strong>40</strong></span>
}</pre></div><p>The <code class="literal">rssSum</code> method <a id="id6420000" class="indexterm"/>instantiates the <code class="literal">MultiLinearRegression</code> class (line <code class="literal">38</code>), retrieves the RSS value, and then validates the <code class="literal">pfnRegr</code> regressive model (line <code class="literal">39</code>) against the expected values (line <code class="literal">40</code>). The output of the test is presented in the following screenshot:</p><div class="mediaobject"><img src="../Images/image01393.jpeg" alt="Test case 2 – feature selection"/></div><p style="clear:both; height: 1em;"> </p><p>The output results clearly show that the three variable regression, <span class="emphasis"><em>CNY = f (SPY, GLD, TLT)</em></span>, is the most accurate or fittest model for the CNY time series, followed by <span class="emphasis"><em>CNY = f (SPY, TLT)</em></span>. Therefore, the feature selection process generates the features set, <span class="emphasis"><em>{SPY, GLD, TLT}</em></span>.</p><p>Let's plot the <a id="id6430000" class="indexterm"/>model against the raw data:</p><div class="mediaobject"><img src="../Images/image01394.jpeg" alt="Test case 2 – feature selection"/><div class="caption"><p>Ordinary least regression on the Chinese Yuan ETF (CNY)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The regression model smoothed the original CNY time series. It weeded out all but the most significant price variation. The graph plotting the r<sup>2</sup> value for each of the model confirms that the three features model <span class="emphasis"><em>CNY=f (SPY, GLD, TLT)</em></span> is the most accurate:</p><div class="mediaobject"><img src="../Images/image01395.jpeg" alt="Test case 2 – feature selection"/></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note17300"/>Note</h3><p>
<span class="strong"><strong>The general linear regression</strong></span>
</p><p>The concept of a linear regression is not restricted to polynomial fitting models such as <span class="emphasis"><em>y = w<sub>0</sub> + w<sub>1</sub>.x + w<sub>2</sub>.x<sup>2</sup> + …+ w<sub>n</sub>x<sup>n</sup></em></span>. Regression models can be also defined as a linear combination of basis functions such as <span class="emphasis"><em>ϕ<sub>j</sub>: y = w<sub>0</sub> + w<sub>1</sub>.ϕ<sub>1</sub>(x) + w<sub>2</sub>ϕ<sub>2</sub>(x) + … + w<sub>n</sub>.ϕ<sub>n</sub>(x)</em></span> [6:9].</p></div></div></div></div></div>
<div class="section" title="Regularization"><div class="titlepage" id="aid-5K7QA2"><div><div><h1 class="title"><a id="ch06lvl1sec4200"/>Regularization</h1></div></div></div><p>The ordinary<a id="id6440000" class="indexterm"/> least squares method for finding the regression parameters is a specific case of the maximum likelihood. Therefore, regression models are subject to the same challenge in terms of overfitting as any other discriminative models. You are already aware of the fact that regularization is used to reduce model complexity and avoid overfitting, as stated in the <span class="emphasis"><em>Overfitting</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><div class="section" title="Ln roughness penalty"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7500"/>L<sub>n</sub> roughness penalty</h2></div></div></div><p>
<span class="strong"><strong>Regularization</strong></span> <a id="id6450000" class="indexterm"/>consists <a id="id6460000" class="indexterm"/>of adding a <span class="emphasis"><em>J(w) </em></span>penalty function to the loss function (or RSS in the case of a regressive classifier) in order to prevent the model parameters (also known as weights) from reaching high values. A model that fits a training set very well tends to have many features variables with relatively large weights. This process is known as <a id="id6470000" class="indexterm"/><span class="strong"><strong>shrinkage</strong></span>. Practically, shrinkage involves adding a function with model parameters as an argument to the loss function (<span class="strong"><strong>M5</strong></span>):</p><div class="mediaobject"><img src="../Images/image01396.jpeg" alt="Ln roughness penalty"/></div><p style="clear:both; height: 1em;"> </p><p>The penalty function is completely independent of the training set <span class="emphasis"><em>{x,y}</em></span>. The penalty term is usually expressed as a power to the function of the norm of the model parameters (or weights) <span class="emphasis"><em>w<sub>d</sub></em></span>. For a model of <span class="emphasis"><em>D</em></span> dimension, the <a id="id6480000" class="indexterm"/>generic <span class="strong"><strong>L<sub>p</sub>
-norm</strong></span> is defined as follows (<span class="strong"><strong>M6</strong></span>):</p><div class="mediaobject"><img src="../Images/image01397.jpeg" alt="Ln roughness penalty"/></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note17400"/>Note</h3><p>
<span class="strong"><strong>Notation</strong></span>
</p><p>Regularization applies to parameters or weights associated with observations. In order to be consistent with our notation, <span class="emphasis"><em>w<sub>0</sub></em></span> being the intercept value, the regularization applies to the parameters <span class="emphasis"><em>w<sub>1</sub>…w<sub>d</sub></em></span>.</p></div><p>The two most commonly used penalty functions for regularization are L<sub>1</sub> and L<sub>2</sub>.</p><div class="note" title="Note"><h3 class="title"><a id="note17500"/>Note</h3><p>
<span class="strong"><strong>Regularization in machine learning</strong></span>
</p><p>The regularization technique is not specific to the linear or logistic regression. Any algorithm that minimizes the residual sum of squares, such as a support vector machine or feed-forward neural network, can be regularized by adding a roughness penalty function to the RSS.</p></div><p>The<a id="id6490000" class="indexterm"/> L<sub>1</sub> regularization <a id="id6500000" class="indexterm"/>applied to the linear regression is known as the <a id="id6510000" class="indexterm"/><span class="strong"><strong>lasso regularization</strong></span>. The <span class="strong"><strong>ridge regression</strong></span>
<a id="id6520000" class="indexterm"/> is a linear regression that uses the<a id="id6530000" class="indexterm"/> L<sub>2</sub> regularization penalty.</p><p>You may wonder which regularization makes sense for a given training set. In a nutshell, L<sub>2</sub> and L<sub>1</sub> regularizations differ in terms of computation efficiency, estimation, and features selection [6:10] [6:11]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Model estimation</strong></span>: L<sub>1</sub> generates a sparser estimation of the regression parameters than L<sub>2</sub>. For a large nonsparse dataset, L<sub>2</sub> has a smaller estimation error than L<sub>1</sub>.</li><li class="listitem"><span class="strong"><strong>Feature selection</strong></span>: L<sub>1</sub> is more effective in reducing the regression weights for features with a higher value than L<sub>2</sub>. Therefore, L1 is a reliable features selection tool.</li><li class="listitem"><span class="strong"><strong>Overfitting</strong></span>: Both L<sub>1</sub> and L<sub>2</sub> reduce the impact of overfitting. However, L<sub>1</sub> has a significant advantage in overcoming overfitting (or excessive complexity of a model); for the same reason, L<sub>1</sub> is more appropriate for selecting features.</li><li class="listitem"><span class="strong"><strong>Computation</strong></span>: L<sub>2</sub> is conducive to a more efficient computation model. The summation of the loss function and L<sub>2</sub> penalty, <span class="emphasis"><em>w<sup>2</sup></em></span>, is a continuous and differentiable function for which the first and second derivatives can be computed (<span class="strong"><strong>convex minimization</strong></span>). The L1 term is the summation of <span class="emphasis"><em>|w<sub>i</sub>|</em></span> and therefore not differentiable.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note17600"/>Note</h3><p>
<span class="strong"><strong>Terminology</strong></span>
</p><p>The ridge regression is sometimes called the <a id="id6540000" class="indexterm"/><span class="strong"><strong>penalized least squares regression</strong></span>. The L<sub>2</sub> regularization is also known as the <span class="strong"><strong>weight decay</strong></span>.</p></div><p>Let's implement the ridge regression, and then evaluate the impact of the L<sub>2</sub>-norm penalty factor.</p></div><div class="section" title="Ridge regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7600"/>Ridge regression</h2></div></div></div><p>The <a id="id6550000" class="indexterm"/>ridge regression is a multivariate linear regression<a id="id6560000" class="indexterm"/> with an L<sub>2</sub>-norm penalty term (<span class="strong"><strong>M7</strong></span>):</p><div class="mediaobject"><img src="../Images/image01398.jpeg" alt="Ridge regression"/></div><p style="clear:both; height: 1em;"> </p><p>The computation of the ridge regression parameters requires the resolution of a system of linear equations that are similar to the linear regression.</p><div class="note" title="Note"><h3 class="title"><a id="note17700"/>Note</h3><p>M8: The matrix representation of ridge regression closed form for an input dataset <span class="emphasis"><em>X</em></span>, a regularization factor <span class="emphasis"><em>λ</em></span>, and expected values vector <span class="emphasis"><em>y</em></span> is defined as follows (<span class="emphasis"><em>I</em></span> is the identity matrix):</p><div class="mediaobject"><img src="../Images/image01399.jpeg" alt="Ridge regression"/></div><p style="clear:both; height: 1em;"> </p><p>M9: The matrices equation is resolved using the QR decomposition as follows:</p><div class="mediaobject"><img src="../Images/image01400.jpeg" alt="Ridge regression"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Design"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8800"/>Design</h3></div></div></div><p>The<a id="id6570000" class="indexterm"/> implementation of the ridge regression adds the L<sub>2</sub> regularization term to the multiple linear regression computation of the Apache Commons Math Library. The methods of <code class="literal">RidgeRegression</code> have the same signature as their ordinary least squares counterparts except for the <code class="literal">lambda</code> L<sub>2</sub> penalty term (line <code class="literal">1</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>RidgeRegression</strong></span>[T &lt;: AnyVal](  //<span class="strong"><strong>1</strong></span>
     xt: XVSeries[T], 
     expected: DblVector, 
     <span class="strong"><strong>lambda</strong></span>: Double)(implicit f: T =&gt; Double)
   extends ITransform[Array[T]](xt) with Regression 
       with Monitor[Double] { //<span class="strong"><strong>2</strong></span>

  type <span class="strong"><strong>V</strong></span> = Double //<span class="strong"><strong>3</strong></span>
  override def train: Option[RegressionModel]  //<span class="strong"><strong>4</strong></span>
  override def |&gt; : PartialFunction[Array[T], Try[V]]
}</pre></div><p>The<a id="id6580000" class="indexterm"/> <code class="literal">RidgeRegression</code> class is implemented as an <code class="literal">ITransform</code> data transformation whose model is implicitly derived from the input data (training set), as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">2</code>). The <code class="literal">V</code> type of the output of the <code class="literal">|&gt;</code> predictive function is a <code class="literal">Double</code> (line <code class="literal">3</code>). The model is created through training during the instantiation of the class (line <code class="literal">4</code>).</p><p>The relationship between the different components of the ridge regression is described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01401.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the ridge regression</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram omits the helper traits or classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec8900"/>Implementation</h3></div></div></div><p>Let's <a id="id6590000" class="indexterm"/>take a look at the training method, <code class="literal">train</code>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: RegressionModel = {
  val mlr = new <span class="strong"><strong>RidgeRAdapter</strong></span>(lambda, xt.head.size) //<span class="strong"><strong>5</strong></span>
  mlr.createModel(data, expected) //<span class="strong"><strong>6</strong></span>
  RegressionModel(mlr.getWeights, mlr.getRss)  //<span class="strong"><strong>7</strong></span>
}</pre></div><p>It is rather simple; it initialized and executed the regression algorithm implemented in the <code class="literal">RidgeRAdapter</code> class (line <code class="literal">5</code>), which acts as an adapter to the internal Apache Commons Math library <code class="literal">AbstractMultipleLinearRegression</code> class in the <code class="literal">org.apache.commons.math3.stat.regression</code> package (line <code class="literal">6</code>). The method returns a fully initialized regression model that is similar to the ordinary least squared regression (line <code class="literal">7</code>).</p><p>Let's take a look at the <code class="literal">RidgeRAdapter</code> adapter class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>RidgeRAdapter</strong></span>(
    lambda: Double, 
    dim: Int) extends AbstractMultipleLinearRegression {
  var qr: QRDecomposition = _  //<span class="strong"><strong>8</strong></span>
  
  def <span class="strong"><strong>createModel</strong></span>(x: DblMatrix, y: DblVector): Unit ={ //<span class="strong"><strong>9</strong></span>
    this.newXSampleData(x) //<span class="strong"><strong>10</strong></span>
    super.newYSampleData(y.toArray)
  }
  def getWeights: DblArray = calculateBeta.toArray //<span class="strong"><strong>11</strong></span>
  def getRss: Double = rss
}</pre></div><p>The constructor for the <code class="literal">RidgeRAdapter</code> class takes two parameters: the <code class="literal">lambda</code> L<sub>2</sub> penalty parameter and the number of features, <code class="literal">dim</code>, in an observation. The QR decomposition in the <code class="literal">AbstractMultipleLinearRegression</code> base class does not process the penalty term (line <code class="literal">8</code>). Therefore, the creation of the model has to be redefined in the <code class="literal">createModel</code> method (line <code class="literal">9</code>), which requires to override the <code class="literal">newXSampleData</code> method (line <code class="literal">10</code>):</p><div class="informalexample"><pre class="programlisting">override protected def <span class="strong"><strong>newXSampleData</strong></span>(x: DblMatrix): Unit =  {
  super.newXSampleData(x)    //<span class="strong"><strong>12</strong></span>
  val r: RealMatrix = getX
  Range(0, dim).foreach(i =&gt; 
        r.setEntry(i, i, r.getEntry(i,i) + lambda) ) //<span class="strong"><strong>13</strong></span>
  qr = new QRDecomposition(r) //<span class="strong"><strong>14</strong></span>
}</pre></div><p>The <code class="literal">newXSampleData</code> method overrides the default observations-features <code class="literal">r</code> matrix (line <code class="literal">12</code>) by adding the <code class="literal">lambda</code> coefficient to its diagonal elements (line <code class="literal">13</code>), and then updating the QR decomposition components (line <code class="literal">14</code>).</p><p>The weights for the <a id="id6600000" class="indexterm"/>ridge regression models is computed by implementing the <span class="strong"><strong>M6 </strong></span>formula (line <code class="literal">11</code>) in the <code class="literal">calculateBeta</code> overridden method (line <code class="literal">15</code>):</p><div class="informalexample"><pre class="programlisting">override protected def <span class="strong"><strong>calculateBeta</strong></span>: RealVector =
   qr.getSolver().solve(getY()) //<span class="strong"><strong>15</strong></span>
</pre></div><p>The predictive algorithm for the ordinary least squares regression is implemented by the <code class="literal">|&gt;</code> data transformation. The method predicts the output value, given a model and an input <code class="literal">x</code> value (line <code class="literal">16</code>):</p><div class="informalexample"><pre class="programlisting">def |&gt; : PartialFunction[Array[T], Try[V]] = {
  case x: Array[T] if(isModel &amp;&amp; 
      x.length == model.get.size-1) =&gt; 
        Try( dot(x, model.get) ) //<span class="strong"><strong>16</strong></span>
}</pre></div></div><div class="section" title="Test case"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9000"/>Test case</h3></div></div></div><p>The objective of the <a id="id6610000" class="indexterm"/>test case is to identify the impact of the L<sub>2</sub> penalization on the RSS value and then compare the predicted values with the original values.</p><p>Let's consider the first test case related to the regression on the daily price variation of the Copper ETF (symbol: CU) using the stock daily volatility and volume as features. The implementation of the extraction of observations is identical to that for the least squares regression, as described in the previous section:</p><div class="informalexample"><pre class="programlisting">val LAMBDA: Double = 0.5
val src = <span class="strong"><strong>DataSource</strong></span>(path, true, true, 1)  //<span class="strong"><strong>17</strong></span>

for {
  <span class="strong"><strong>price</strong></span> &lt;- src.get(adjClose)   //<span class="strong"><strong>18</strong></span>
  <span class="strong"><strong>volatility</strong></span> &lt;- src.get(volatility) //<span class="strong"><strong>19</strong></span>
  volume &lt;- src.get(volume)  //<span class="strong"><strong>20</strong></span>
  (features, expected) &lt;- differentialData(volatility, 
              volume, price, diffDouble) //<span class="strong"><strong>21</strong></span>
  regression &lt;- <span class="strong"><strong>RidgeRegression</strong></span>[Double](features, 
expected, LAMBDA)  //<span class="strong"><strong>22</strong></span>
} yield {
  if( regression.isModel ) {
    val <span class="strong"><strong>trend</strong></span> = features
               .map( dot(_, regression.weights.get) )  //<span class="strong"><strong>23</strong></span>

    val y1 = <span class="strong"><strong>predict</strong></span>(0.2, expected, volatility, volume) //<span class="strong"><strong>24</strong></span>
    val y2 = <span class="strong"><strong>predict</strong></span>(5.0, expected, volatility, volume)
    val output = (2 until 10 by 2).map( n =&gt; 
          <span class="strong"><strong>predict</strong></span>(n*0.1, expected, volatility, volume) )
  }
}</pre></div><p>Let's take a <a id="id6620000" class="indexterm"/>look at the steps required for the execution of the test. The steps consist of collecting data, extracting the features and expected values, and training the ridge regression model:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a data source extractor for the <code class="literal">price</code> trading session closing, the <code class="literal">volatility</code> session, and the <code class="literal">volume</code> session for the ETF CU using the <code class="literal">DataSource</code> transformation (line <code class="literal">17</code>).</li><li class="listitem">Extract the closing <code class="literal">price</code> of the ETF (line <code class="literal">18</code>), its <code class="literal">volatility</code> within a trading session (line <code class="literal">19</code>), and the <code class="literal">volume</code> trading during the same session (line <code class="literal">20</code>).</li><li class="listitem">Generate the labeled data as a pair of features (the relative volatility and relative volume for the ETF) and the <code class="literal">expected</code> outcome <span class="emphasis"><em>{0, 1}</em></span> for training the model, where <code class="literal">1</code> represents the increase in the price and <code class="literal">0</code> represents the decrease in the price (line 21). The <code class="literal">differentialData</code> generic method of the <code class="literal">XTSeries</code> singleton is described in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</li><li class="listitem">Instantiate the ridge regression using the <code class="literal">features</code> set and the <code class="literal">expected</code> change in the daily stock price (line <code class="literal">22</code>).</li><li class="listitem">Compute the <code class="literal">trend</code> values using the <code class="literal">dot</code> function of the <code class="literal">RegressionModel</code> singleton (line <code class="literal">23</code>).</li><li class="listitem">Execute a using the ridge regression is implemented by the <code class="literal">predict</code> method (line <code class="literal">24</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>predict</strong></span>(
    lambda: Double, 
    deltaPrice: DblVector, 
    volatility: DblVector, 
    volume: DblVector): DblVector = {

  val observations = zipToSeries(volatility, volume)//<span class="strong"><strong>25</strong></span>
  val regression = new RidgeRegression[Double](observations, 
          deltaPrice, lambda)
  val fnRegr = regression |&gt; //<span class="strong"><strong>26</strong></span>
  observations.map( fnRegr(_).get)  //<span class="strong"><strong>27</strong></span>
}</pre></div><p>The observations <a id="id6630000" class="indexterm"/>are extracted from the <code class="literal">volatility</code> and <code class="literal">volume</code> time series (line <code class="literal">25</code>). The predictive method for the <code class="literal">fnRegr</code> ridge regression (line <code class="literal">26</code>) is applied to each observation (line <code class="literal">27</code>). The RSS value, <code class="literal">rss</code>, is plotted for different values of <span class="emphasis"><em>λ</em></span>, as shown in the following chart:</p><div class="mediaobject"><img src="../Images/image01402.jpeg" alt="Test case"/><div class="caption"><p>The graph of RSS versus lambda for the Copper ETF</p></div></div><p style="clear:both; height: 1em;"> </p><p>The residual sum of squares decreases as <span class="emphasis"><em>λ</em></span> increases. The curve seems to be reaching for a minimum around <span class="emphasis"><em>λ = 1</em></span>. The case of <span class="emphasis"><em>λ = 0</em></span> corresponds to the least squares regression.</p><p>Next, let's plot the RSS value for <span class="emphasis"><em>λ</em></span> varying between 1 and 100:</p><div class="mediaobject"><img src="../Images/image01403.jpeg" alt="Test case"/><div class="caption"><p>The graph of RSS versus a large value Lambda for the Copper ETF</p></div></div><p style="clear:both; height: 1em;"> </p><p>This time <a id="id6640000" class="indexterm"/>around, the value of RSS increases with <span class="emphasis"><em>λ</em></span> before reaching a maximum for <span class="emphasis"><em>λ &gt; 60</em></span>. This behavior is consistent with other findings [6:12]. As <span class="emphasis"><em>λ</em></span> increases, the overfitting gets more expensive, and therefore, the RSS value increases.</p><p>Let's plot the predicted price variation of the Copper ETF using the ridge regression with different values of lambda (<span class="emphasis"><em>λ</em></span>):</p><div class="mediaobject"><img src="../Images/image01404.jpeg" alt="Test case"/><div class="caption"><p>The graph of ridge regression on the Copper ETF price variation with a variable, lambda</p></div></div><p style="clear:both; height: 1em;"> </p><p>The original <a id="id6650000" class="indexterm"/>price variation of the Copper ETF, <span class="emphasis"><em>Δ = price(t + 1) - price(t)</em></span>, is plotted as <span class="emphasis"><em>λ = 0</em></span>. Let's analyze the behavior of the predictive model for different values of <span class="emphasis"><em>λ</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The predicted values for <span class="emphasis"><em>λ = 0.8</em></span> is very similar to the original data.</li><li class="listitem">The predicted values for <span class="emphasis"><em>λ = 2</em></span> follow the pattern of the original data with a reduction of large variations (peaks and troves).</li><li class="listitem">The predicted values for <span class="emphasis"><em>λ = 5</em></span> corresponds to a smoothed dataset. The pattern of the original data is preserved but the magnitude of the price variation is significantly reduced.</li></ul></div><p>The logistic regression, which was briefly introduced in the <span class="emphasis"><em>Let's kick the tires</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, is the next logical regression model to be discussed. The logistic regression relies on optimization methods. Let's go through a short refresher course in optimization before diving into the logistic regression.</p></div></div></div>
<div class="section" title="Numerical optimization" id="aid-5L6AS1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec4300"/>Numerical optimization</h1></div></div></div><p>This <a id="id6660000" class="indexterm"/>section briefly introduces the different optimization algorithms that can be applied to minimize the loss function, with or without a penalty term. These algorithms are described in more detail in the <span class="emphasis"><em>Summary of optimization techniques</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>First, let's define the <a id="id6670000" class="indexterm"/><span class="strong"><strong>least squares problem</strong></span>. The minimization of the loss function consists of nullifying the first order derivatives, which in turn generates a system of <span class="emphasis"><em>D</em></span> equations (also known as the gradient equations), <span class="emphasis"><em>D</em></span> being the number of regression weights (parameters). The weights are iteratively computed by solving the system of equations using a numerical optimization algorithm.</p><div class="note" title="Note"><h3 class="title"><a id="note17900"/>Note</h3><p>M10: The definition of the least squares-based loss function for residual <span class="emphasis"><em>r<sub>i</sub></em></span>, weights <span class="emphasis"><em>w</em></span>, a model <span class="emphasis"><em>f</em></span>, input data <span class="emphasis"><em>x<sub>i</sub></em></span>, and expected values <span class="emphasis"><em>y<sub>i</sub></em></span> is as follows:</p><div class="mediaobject"><img src="../Images/image01405.jpeg" alt="Numerical optimization"/></div><p style="clear:both; height: 1em;"> </p><p>M10: The generation of gradient equations with a Jacobian <span class="emphasis"><em>J</em></span> matrix (refer to the <span class="emphasis"><em>Mathematics</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>) after minimization of the loss function <span class="emphasis"><em>L</em></span> is defined as follows:</p><div class="mediaobject"><img src="../Images/image01406.jpeg" alt="Numerical optimization"/></div><p style="clear:both; height: 1em;"> </p><p>M11: The iterative approximation using the Taylor series on the model <span class="emphasis"><em>f</em></span> for <span class="emphasis"><em>k</em></span> iterations on the computation of weights <span class="emphasis"><em>w</em></span> is defined as follows:</p><div class="mediaobject"><img src="../Images/image01407.jpeg" alt="Numerical optimization"/></div><p style="clear:both; height: 1em;"> </p></div><p>The logistic regression<a id="id6680000" class="indexterm"/> is a nonlinear function. Therefore, it requires the nonlinear minimization of the sum of least squares. The optimization algorithms for the nonlinear least squares problems can be divided into two categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Newton</strong></span> (or 2nd order techniques): These <a id="id6690000" class="indexterm"/>algorithms calculate the second order derivatives (the Hessian matrix) to compute the regression weights that nullify the gradient. The two most common algorithms in this category are the Gauss-Newton and Levenberg-Marquardt methods (refer to the <span class="emphasis"><em>Nonlinear least squares minimization</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>). Both algorithms are included in the Apache Commons Math library.</li><li class="listitem"><span class="strong"><strong>Quasi-Newton</strong></span> (or 1<sup>st</sup> order techniques): First <a id="id6700000" class="indexterm"/>order algorithms do not compute but estimate the second order derivatives of the least squares residuals from the Jacobian matrix. These methods can minimize any real-valued functions, not just the least squares summation. This category of algorithms includes the Davidon-Fletcher-Powell and the Broyden-Fletcher-Goldfarb-Shannon methods (refer to the <span class="emphasis"><em>Quasi-Newton algorithms</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</li></ul></div></div>
<div class="section" title="Logistic regression"><div class="titlepage" id="aid-5M4RE2"><div><div><h1 class="title"><a id="ch06lvl1sec4400"/>Logistic regression</h1></div></div></div><p>Despite its<a id="id6710000" class="indexterm"/> name, the <span class="emphasis"><em>logistic regression is a classifier</em></span>. As a matter of fact, the logistic regression is one of the most commonly used discriminative learning techniques because of its simplicity and its ability to leverage a large variety of optimization algorithms. The technique is used to quantify the relationship between an observed target (or expected) variable <span class="emphasis"><em>y</em></span> and a set of variables <span class="emphasis"><em>x</em></span> that it depends on. Once the model is created (trained), it is available to classify real-time data.</p><p>A logistic regression can be either binomial (two classes) or multinomial (three or more classes). In a <a id="id6720000" class="indexterm"/>binomial classification, the observed outcome is defined as <span class="emphasis"><em>{true, false}</em></span>, <span class="emphasis"><em>{0, 1}</em></span>, or <span class="emphasis"><em>{-1, +1}</em></span>.</p><div class="section" title="Logistic function"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7700"/>Logistic function</h2></div></div></div><p>The conditional<a id="id6730000" class="indexterm"/> probability in a linear regression model is a linear function of its weights [6:13]. The logistic regression model addresses the nonlinear regression problem by defining the logarithm of the conditional probability as a linear function of its parameters.</p><p>First, let's introduce the logistic function and its derivative, which are defined as follows (M12):</p><div class="mediaobject"><img src="../Images/image01408.jpeg" alt="Logistic function"/></div><p style="clear:both; height: 1em;"> </p><p>The logistic function and its derivative are illustrated in the following graph:</p><div class="mediaobject"><img src="../Images/image01409.jpeg" alt="Logistic function"/><div class="caption"><p>The graph of the logistic function and its derivative</p></div></div><p style="clear:both; height: 1em;"> </p><p>The remainder of this section is dedicated to the application of the multivariate logistic regression to the binomial classification.</p></div><div class="section" title="Binomial classification"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7800"/>Binomial classification</h2></div></div></div><p>The<a id="id6740000" class="indexterm"/> logistic regression is popular for several reasons; some are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It is available with most statistical software packages and open source libraries</li><li class="listitem">Its S-shape describes the combined effect of several explanatory variables</li><li class="listitem">Its range of values [0, 1] is intuitive from a probabilistic perspective</li></ul></div><p>Let's consider the classification problem using two classes. As discussed in the <span class="emphasis"><em>Validation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, even the best classifier produces false positives and false negatives. The training procedure for a binomial classification is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01410.jpeg" alt="Binomial classification"/><div class="caption"><p>An illustration of the binomial classification for a two-dimension dataset</p></div></div><p style="clear:both; height: 1em;"> </p><p>The purpose of the training is to compute the <a id="id6750000" class="indexterm"/><span class="strong"><strong>hyperplane</strong></span> that separates the observations into two categories or classes. Mathematically speaking, a hyperplane in an n-dimensional space (number of features) is a subspace of <span class="emphasis"><em>n - 1</em></span> dimensions, as described in the <span class="emphasis"><em>Manifolds</em></span> section in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>. The separating hyperplane of a three-dimension space is a curved surface. The separating hyperplane of a two-dimension problem (plane) is a line. In our preceding example, the hyperplane segregates/separates a training set into two very distinct classes (or groups), <span class="strong"><strong>Class 1</strong></span> and <span class="strong"><strong>Class 2</strong></span>, in an attempt to reduce the overlap (false positive and false negative).</p><p>The equation of <a id="id6760000" class="indexterm"/>the hyperplane is defined as the logistic function of the dot product of the regression parameters (or weights) and features.</p><p>The logistic function accentuates the difference between the two groups of training observations, separated by the hyperplane. It <span class="emphasis"><em>pushes the observations away</em></span> from the separating hyperplane toward either classes.</p><p>In the case of two classes, <span class="emphasis"><em>c1</em></span> and <span class="emphasis"><em>c2</em></span> with their respective probabilities, <span class="emphasis"><em>p(C=c1| X=x<sub>i</sub>|w) = p(x<sub>i</sub>|w)</em></span> and <span class="emphasis"><em>p(C=c2 |X= x<sub>i</sub>|w) = 1- p(x<sub>i</sub>|w)</em></span>, where <span class="emphasis"><em>w</em></span> is the model parameters set or weights in the case of the logistic regression.</p><div class="note" title="Note"><h3 class="title"><a id="note18200"/>Note</h3><p>
<span class="strong"><strong>The logistic regression</strong></span>
</p><p>M13: The log likelihood for <span class="emphasis"><em>N</em></span> observations <span class="emphasis"><em>x<sub>i</sub></em></span> given regression weights <span class="emphasis"><em>w </em></span>is defined as:</p><div class="mediaobject"><img src="../Images/image01411.jpeg" alt="Binomial classification"/></div><p style="clear:both; height: 1em;"> </p><p>M14: Conditional probabilities <span class="emphasis"><em>p(x|w)</em></span> with regression weights <span class="emphasis"><em>w</em></span>, using the logistic function for <span class="emphasis"><em>N</em></span> observations with <span class="emphasis"><em>d</em></span> features <span class="emphasis"><em>{x<sub>ij</sub>}
<sub>j=0;d-1</sub></em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01412.jpeg" alt="Binomial classification"/></div><p style="clear:both; height: 1em;"> </p><p>M15: The sum of square errors, <span class="emphasis"><em>sse</em></span>, for the binomial logistic regression with weights <span class="emphasis"><em>w</em></span>, input values <span class="emphasis"><em>x<sub>
i</sub></em></span>, and expected binary outcome <span class="emphasis"><em>y</em></span> is as follows:</p><div class="mediaobject"><img src="../Images/image01413.jpeg" alt="Binomial classification"/></div><p style="clear:both; height: 1em;"> </p><p>M16: The computation of the weights <span class="emphasis"><em>w</em></span> of the logistic regression by maximizing the log likelihood, given the input data <span class="emphasis"><em>x<sub>i</sub></em></span> and expected outcome (labels) <span class="emphasis"><em>y<sub>i</sub></em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01414.jpeg" alt="Binomial classification"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's implement<a id="id6770000" class="indexterm"/> the logistic regression without regularization using the Apache Commons Math library. The library contains several least squares optimizers that allow you to specify the <code class="literal">optimizer</code> minimizing algorithm for the loss function in the logistic regression class, <code class="literal">LogisticRegression</code>.</p><p>The constructor for the <code class="literal">LogisticRegression</code> class follows a very familiar pattern: it defines an <code class="literal">ITransform</code> data transformation, whose model is implicitly derived from the input data (training set), as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">2</code>). The output of the <code class="literal">|&gt;</code> predictor is a class ID, and therefore, the <code class="literal">V</code> type of the output is an <code class="literal">Int</code> (line <code class="literal">3</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>LogisticRegression</strong></span>[T &lt;: AnyVal](
    xt: XVSeries[T], 
    expected: Vector[Int], 
    <span class="strong"><strong>optimizer</strong></span>: LogisticRegressionOptimizer)  //<span class="strong"><strong>1</strong></span>
    (implicit f: T =&gt; Double)
   extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Regression 
       with Monitor[Double] { //<span class="strong"><strong>2</strong></span>

  type V = Int //<span class="strong"><strong>3</strong></span>
    override def train: RegressionModel  //<span class="strong"><strong>4</strong></span>
  def |&gt; : PartialFunction[Array[T], Try[V]]
}</pre></div><p>The parameters of the logistic regression class are the multivariate <code class="literal">xt</code> time series (features), the target or expected classes, <code class="literal">expected</code>, and the <code class="literal">optimizer</code> used to minimize the loss function or residual sum of squares (line <code class="literal">1</code>). In the case of the binomial logistic regression, <code class="literal">expected</code> are assigned the value of <code class="literal">1</code> for one class and <code class="literal">0</code> for the other.</p><p>The <code class="literal">Monitor</code> trait is<a id="id6780000" class="indexterm"/> used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The purpose of the training is to determine the regression weights that minimize the loss function, as defined in the <span class="strong"><strong>M14</strong></span> formula as well as the residual sum of squares (line <code class="literal">4</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note18600"/>Note</h3><p>
<span class="strong"><strong>Target values</strong></span>
</p><p>There is no specific rule to assign the two values to the observed data for the binomial logistic regression: <span class="emphasis"><em>{-1, +1}</em></span>, <span class="emphasis"><em>{0, 1}</em></span>, or <span class="emphasis"><em>{false, true}</em></span>. The values pair <span class="emphasis"><em>{0, 1}</em></span> is convenient because it allows the developer to reuse the code for multinomial logistic regression using normalized class values.</p></div><p>For convenience, the definition and configuration of the optimizer are encapsulated in the <code class="literal">LogisticRegressionOptimizer</code> class.</p></div><div class="section" title="Design"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec7900"/>Design</h2></div></div></div><p>The <a id="id6790000" class="indexterm"/>implementation of the logistic regression uses the following components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A <code class="literal">RegressionModel</code> model of the <code class="literal">Model</code> type that is initialized through training during the instantiation of the classifier. We reuse the <code class="literal">RegressionModel</code> type, which was introduced in the <span class="emphasis"><em>Linear regression</em></span> section.</li><li class="listitem">The logistic regression class, <code class="literal">LogisticRegression</code>, that implements an <code class="literal">ITransform</code> for the prediction of future observations</li><li class="listitem">An adapter class named <code class="literal">RegressionJacobian</code> for the computation of the Jacobian </li><li class="listitem">An adapter class named <code class="literal">RegressionConvergence</code> to manage the convergence criteria and exit condition of the minimization of the sum of square errors</li></ul></div><p>The key software<a id="id6800000" class="indexterm"/> components of the logistic regression are described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01415.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the logistic regression</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram omits the helper traits or classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="The training workflow"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec8000"/>The training workflow</h2></div></div></div><p>Our<a id="id6810000" class="indexterm"/> implementation of the training of the logistic regression model<a id="id6820000" class="indexterm"/> leverages either the Gauss-Newton or the Levenberg-Marquardt nonlinear least squares optimizers, (refer to the <span class="emphasis"><em>Nonlinear least squares minimization</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>) packaged with the Apache Commons Math library.</p><p>The training of the logistic regression is performed by the <code class="literal">train</code> method.</p><div class="note" title="Note"><h3 class="title"><a id="note18700"/>Note</h3><p>
<span class="strong"><strong>Handling exceptions from the Apache Commons Math library</strong></span>
</p><p>The training of the logistic regression using the Apache Commons Math library requires handling the <code class="literal">ConvergenceException</code>, <code class="literal">DimensionMismatchException</code>, <code class="literal">TooManyEvaluationsException</code>, <code class="literal">TooManyIterationsException</code>, and <code class="literal">MathRuntimeException</code> exceptions. Debugging is greatly facilitated by understanding the context of these exceptions in the Apache library source code.</p></div><p>The<a id="id6830000" class="indexterm"/> implementation of the training method, <code class="literal">train</code>, relies on the following five steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select and configure the least squares optimizer.</li><li class="listitem">Define the logistic function and its Jacobian.</li><li class="listitem">Specify the convergence and exit criteria.</li><li class="listitem">Compute the residuals using the least squares problem builder.</li><li class="listitem">Run the optimizer.</li></ol><div style="height:10px; width: 1px"/></div><p>The workflow and the Apache Commons Math classes used in the training of the logistic regression are visualized by the following flow diagram:</p><div class="mediaobject"><img src="../Images/image01416.jpeg" alt="The training workflow"/><div class="caption"><p>The workflow for training the logistic regression using the Apache Commons Math library</p></div></div><p style="clear:both; height: 1em;"> </p><p>The first four steps are required by the Apache Commons Math library to initialize the configuration of the logistic regression prior to the minimization of the loss function. Let's start with the configuration of the least squares optimizer:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: RegressionModel = {
  val weights0 = Array.fill(data.head.length +1)(INITIAL_WEIGHT)
  val lrJacobian = new RegressionJacobian(data, weights0) //<span class="strong"><strong>5</strong></span>
  val exitCheck = new RegressionConvergence(optimizer) //<span class="strong"><strong>6</strong></span>

  def createBuilder: LeastSquaresProblem  //<span class="strong"><strong>7</strong></span>
  val optimum = optimizer.optimize(createBuilder) //<span class="strong"><strong>8</strong></span>
  RegressionModel(optimum.getPoint.toArray, optimum.getRMS)
}</pre></div><p>The <code class="literal">train</code> method <a id="id6840000" class="indexterm"/>implements the last four steps of the computation of the regression model:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Computation of logistic values and the Jacobian matrix (line <code class="literal">5</code>).</li><li class="listitem">Initialization of the convergence criteria (line <code class="literal">6</code>).</li><li class="listitem">Definition of the least square problem (line <code class="literal">7</code>).</li><li class="listitem">Minimization of the sum of square errors (line <code class="literal">8</code>). It is performed by the optimizer as part of the constructor of <code class="literal">LogisticRegression</code>.</li></ul></div><div class="section" title="Step 1 – configuring the optimizer"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9100"/>Step 1 – configuring the optimizer</h3></div></div></div><p>In <a id="id6850000" class="indexterm"/>this step, you have to specify the algorithm to minimize the residual of the sum of the squares. The <code class="literal">LogisticRegressionOptimizer</code> class is responsible for configuring the optimizer. The class has the following two purposes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Encapsulating the configuration parameters for the optimizer</li><li class="listitem">Invoking the <code class="literal">LeastSquaresOptimizer</code> interface defined in the Apache Commons Math library</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>LogisticRegressionOptimizer</strong></span>(
     <span class="strong"><strong>maxIters</strong></span>: Int, 
     <span class="strong"><strong>maxEvals</strong></span>: Int,
     <span class="strong"><strong>eps</strong></span>: Double, 
     <span class="strong"><strong>lsOptimizer</strong></span>: LeastSquaresOptimizer) {  //<span class="strong"><strong>9</strong></span>
  def optimize(lsProblem: LeastSquaresProblem): Optimum = 
       lsOptimizer.optimize(lsProblem)
}</pre></div><p>The configuration of the logistic regression optimizer is defined as the maximum number of iterations,<code class="literal"> maxIters</code>, the maximum number of evaluations, <code class="literal">maxEval</code>, for the logistic function and its derivatives, the <code class="literal">eps</code> convergence criteria of the residual sum of squares, and the instance of the least squares problem (line <code class="literal">9</code>).</p></div><div class="section" title="Step 2 – computing the Jacobian matrix"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9200"/>Step 2 – computing the Jacobian matrix</h3></div></div></div><p>The next <a id="id6860000" class="indexterm"/>step consists of computing the value of the logistic function and its first order partial derivatives with respect to the weights by overriding the <code class="literal">value</code> method of the <code class="literal">fitting.leastsquares.MultivariateJacobianFunction</code> Apache Commons Math interface:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>RegressionJacobian</strong></span>[T &lt;: AnyVal](  //<span class="strong"><strong>10</strong></span>
    xv: XVSeries[T], 
    weights0: DblArray)(implicit f: T =&gt; Double) 
  extends MultivariateJacobianFunction {

  type GradientJacobian = Pair[RealVector, RealMatrix]
  override def <span class="strong"><strong>value</strong></span>(w: RealVector): GradientJacobian = { //<span class="strong"><strong>11</strong></span>
    val gradient = xv.map( g =&gt; { //<span class="strong"><strong>12</strong></span>
      val f = logistic(dot(g, w))//<span class="strong"><strong>13</strong></span>
     (f, f*(1.0-f))  //<span class="strong"><strong>14</strong></span>
   })
   xv.zipWithIndex   //<span class="strong"><strong>15</strong></span>
    ./:(Array.ofDim[Double](xv.size, weights0.size)) {
     case (j, (x,i)) =&gt; {   
       val df = gradient(i)._2
       Range(0, x.size).foreach(n =&gt; j(i)(n+1) = x(n)*df)
       j(i)(0) = 1.0; j //<span class="strong"><strong>16</strong></span>
     }
   }
   (new ArrayRealVector(gradient.map(_._1).toArray), 
      new Array2DRowRealMatrix(jacobian))  //<span class="strong"><strong>17</strong></span>
  }
}</pre></div><p>The constructor for the <code class="literal">RegressionJacobian</code> class requires the following two arguments (line <code class="literal">10</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">xv</code> time series of observations </li><li class="listitem">The <code class="literal">weights0 </code>initial regression weights </li></ul></div><p>The <code class="literal">value</code> method uses the <code class="literal">RealVector</code>, <code class="literal">RealMatrix</code>, <code class="literal">ArrayRealVector</code>, and <code class="literal">Array2DRowRealMatrix</code> primitive types defined in the <code class="literal">org.apache.commons.math3.linear</code> Apache Commons Math package (line <code class="literal">11</code>). It takes the <code class="literal">w</code> regression weight as an argument, computes the <code class="literal">gradient</code> (line <code class="literal">12</code>) of the logistic function (line <code class="literal">13</code>) for each data point, and returns the value and its derivative (line <code class="literal">14</code>).</p><p>The Jacobian matrix<a id="id6870000" class="indexterm"/> is populated with the values of the derivative of the logistic function (line <code class="literal">15</code>). The first element of each column of the Jacobian matrix is set to <code class="literal">1.0</code> to take into account the intercept (line <code class="literal">16</code>). Finally, the <code class="literal">value</code> function returns the pair of gradient values and the Jacobian matrix using types that comply with the signature of the <code class="literal">value</code> method in the Apache Commons Math library (line <code class="literal">17</code>).</p></div><div class="section" title="Step 3 – managing the convergence of the optimizer"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9300"/>Step 3 – managing the convergence of the optimizer</h3></div></div></div><p>The<a id="id6880000" class="indexterm"/> third step defines the exit condition for the optimizer. It is accomplished by overriding the <code class="literal">converged</code> method of the parameterized <code class="literal">ConvergenceChecker</code> interface in the <code class="literal">org.apache.commons.math3.optim</code> Java package:</p><div class="informalexample"><pre class="programlisting">val exitCheck = new <span class="strong"><strong>ConvergenceChecker</strong></span>[PointVectorValuePair] {
  override def <span class="strong"><strong>converged</strong></span>(
      iters: Int, 
      prev: PointVectorValuePair, 
      current:PointVectorValuePair): Boolean =  
   <span class="strong"><strong>sse</strong></span>(prev.getValue, current.geValue) &lt; optimizer.<span class="strong"><strong>eps</strong></span> 
           &amp;&amp; <span class="strong"><strong>iters</strong></span> &gt;= optimizer.<span class="strong"><strong>maxIters</strong></span> //<span class="strong"><strong>18</strong></span>
}</pre></div><p>This implementation computes the convergence or exit condition as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">sse</code> sum of square errors between weights of two consecutive iterations is smaller than the <code class="literal">eps</code> convergence criteria</li><li class="listitem">The <code class="literal">iters</code> value exceeds the maximum number of iterations, <code class="literal">maxIters</code>, allowed (line <code class="literal">18</code>)</li></ul></div></div><div class="section" title="Step 4 – defining the least squares problem"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9400"/>Step 4 – defining the least squares problem</h3></div></div></div><p>The Apache Commons Math<a id="id6890000" class="indexterm"/> least squares optimizer package requires all the input to the nonlinear least squares minimizer to be defined as an instance of the <code class="literal">LeastSquareProblem</code> generated by the factory <code class="literal">LeastSquareBuilder</code> class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>createBuilder</strong></span>: LeastSquaresProblem = 
   (new <span class="strong"><strong>LeastSquaresBuilder</strong></span>).model(lrJacobian)    //<span class="strong"><strong>19</strong></span>
   .weight(MatrixUtils.createRealDiagonalMatrix(
             Array.fill(xt.size)(1.0)))  //<span class="strong"><strong>20</strong></span>
   .target(expected.toArray) //<span class="strong"><strong>21</strong></span>
   .checkerPair(exitCheck)  //<span class="strong"><strong>22</strong></span>
   .maxEvaluations(optimizer.maxEvals)  //<span class="strong"><strong>23</strong></span>
   .start(weights0)  //<span class="strong"><strong>24</strong></span>
   .maxIterations(optimizer.maxIters) //<span class="strong"><strong>25</strong></span>
   .build</pre></div><p>The <a id="id6900000" class="indexterm"/>diagonal elements of the weights matrix are initialized to <code class="literal">1.0</code> (line <code class="literal">20</code>). Besides the initialization of the model with the <code class="literal">lrJacobian</code> Jacobian matrix (line <code class="literal">19</code>), the sequence of method invocations sets the maximum number of evaluations (line <code class="literal">23</code>), maximum number of iterations (line <code class="literal">25</code>), and the exit condition (line <code class="literal">22</code>).</p><p>The regression weights are initialized with the <code class="literal">weights0</code> weights as arguments of the constructor for <code class="literal">LogisticRegression</code> (line <code class="literal">24</code>). Finally, the expected or target values are initialized (line <code class="literal">21</code>).</p></div><div class="section" title="Step 5 – minimizing the sum of square errors"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9500"/>Step 5 – minimizing the sum of square errors</h3></div></div></div><p>The<a id="id6910000" class="indexterm"/> training is executed with a simple call to the <code class="literal">lsp</code> least squares minimizer:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>optimum</strong></span> = optimizer.optimize(<span class="strong"><strong>lsp</strong></span>)
(optimum.<span class="strong"><strong>getPoint</strong></span>.toArray, optimum.<span class="strong"><strong>getRMS</strong></span>)</pre></div><p>The regression coefficients (or weights) and the<a id="id6920000" class="indexterm"/> <span class="strong"><strong>residuals mean square</strong></span> (<span class="strong"><strong>RMS</strong></span>) are returned by invoking the <code class="literal">getPoint</code> method on the <code class="literal">Optimum</code> class of the Apache Commons Math library.</p></div><div class="section" title="Test"><div class="titlepage"><div><div><h3 class="title"><a id="ch06lvl3sec9600"/>Test</h3></div></div></div><p>Let's test our <a id="id6930000" class="indexterm"/>implementation of the binomial multivariate logistic regression using the example of the price variation versus volatility and volume of the Copper ETF, which is used in the previous two sections. The only difference is that we need to define the target values as 0 if the ETF price decreases between two consecutive trading sessions, and 1 otherwise:</p><div class="informalexample"><pre class="programlisting">import YahooFinancials._ 
val maxIters = 250
val maxEvals = 4500
val eps = 1e-7

val <span class="strong"><strong>src</strong></span> = DataSource(path, true, true, 1)  //<span class="strong"><strong>26</strong></span>
val <span class="strong"><strong>optimizer</strong></span> = new <span class="strong"><strong>LevenbergMarquardtOptimizer</strong></span>  //<span class="strong"><strong>27</strong></span>

for {
  <span class="strong"><strong>price</strong></span> &lt;- src.get(adjClose) //<span class="strong"><strong>28</strong></span>
  <span class="strong"><strong>volatility</strong></span> &lt;- src.get(volatility)  //<span class="strong"><strong>29</strong></span>
  <span class="strong"><strong>volume</strong></span> &lt;- src.get(volume)  //<span class="strong"><strong>30</strong></span>
  (features, expected) &lt;- differentialData(volatility, 
volume, price, diffInt) //<span class="strong"><strong>31</strong></span>
  <span class="strong"><strong>lsOpt</strong></span> &lt;- LogisticRegressionOptimizer(maxIters, maxEvals, 
                        eps, optimizer) //<span class="strong"><strong>32</strong></span>
  <span class="strong"><strong>regr</strong></span> &lt;- LogisticRegression[Double](features, expected, lsOpt)      
  pfnRegr &lt;- Try(regr |&gt;) //<span class="strong"><strong>33</strong></span>
} 
yield {
   show(s"${LogisticRegressionEval.toString(regr)}")
   val predicted = features.map(pfnRegr(_))
   val delta = predicted.view.zip(expected.view)
            .map{case(p, e) =&gt; if(p.get == e) 1 else 0}.sum
   show(s"Accuracy: ${delta.toDouble/expected.size}")
}</pre></div><p>Let's take a <a id="id6940000" class="indexterm"/>look at the steps required for the execution of the test that consists of collecting data, initializing the parameters for the minimization of the sum of square errors, training a logistic regression model, and running the prediction:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a <code class="literal">src</code> data source to extract the market and trading data (line <code class="literal">26</code>).</li><li class="listitem">Select the <code class="literal">LevenbergMarquardtOptimizer</code> Levenberg-Marquardt algorithm as <code class="literal">optimizer</code> (line <code class="literal">27</code>).</li><li class="listitem">Load the daily closing <code class="literal">price</code> (line <code class="literal">28</code>), <code class="literal">volatility</code> within a trading session (line <code class="literal">29</code>), and the <code class="literal">volume</code> daily trading (line <code class="literal">30</code>) for the ETF CU.</li><li class="listitem">Generate the labeled data as a pair of features (the relative volatility and relative volume for the ETF) and the <code class="literal">expected</code> outcome <span class="emphasis"><em>{0, 1}</em></span> for training the model for which <code class="literal">1</code> represents the increase in the price and <code class="literal">0</code> represents the decrease in the price (line <code class="literal">31</code>). The <code class="literal">differentialData</code> generic method of the <code class="literal">XTSeries</code> singleton is described in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</li><li class="listitem">Instantiate the <code class="literal">lsOpt</code> optimizer to minimize the sum of square errors during training (line <code class="literal">32</code>).</li><li class="listitem">Train the <code class="literal">regr</code> model and return the <code class="literal">pfnRegr</code> predictor partial function (line <code class="literal">33</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>There are <a id="id6950000" class="indexterm"/>many alternative optimizers available to minimize the sum of square errors optimizers (refer to the <span class="emphasis"><em>Nonlinear least squares minimization</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><div class="note" title="Note"><h3 class="title"><a id="note18800"/>Note</h3><p>
<span class="strong"><strong>Levenberg-Marquardt parameters</strong></span>
</p><p>The driver code uses the <code class="literal">LevenbergMarquardtOptimizer</code> with the default tuning parameters' configuration to keep the implementation simple. However, the algorithm has a few important parameters, such as the relative tolerance for cost and matrix inversion, that are worth tuning for commercial applications (refer to the <span class="emphasis"><em>Levenberg-Marquardt</em></span> section under <span class="emphasis"><em>Nonlinear least squares minimization</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p></div><p>The execution of the test produces the following results:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The residual mean square</strong></span> is 0.497</li><li class="listitem"><span class="strong"><strong>Weights</strong></span> are -0.124 for intercept, 0.453 for ETF volatility, and -0.121 for ETF volume</li></ul></div><p>The last step is the classification of the real-time data.</p></div></div><div class="section" title="Classification"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec8100"/>Classification</h2></div></div></div><p>As mentioned <a id="id6960000" class="indexterm"/>earlier and despite its name, the binomial logistic regression is actually a binary classifier. The classification method is implemented as an implicit data transformation <code class="literal">|&gt;</code>:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>HYPERPLANE</strong></span> = - Math.log(1.0/INITIAL_WEIGHT -1)
def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] = {
  case <span class="strong"><strong>x</strong></span>: Array[T] if(isModel &amp;&amp; 
      model.size-1 == x.length &amp;&amp; isModel)  =&gt; 
       Try (if(dot(x, model) &gt; HYPERPLANE) 1 else 0 ) //<span class="strong"><strong>34</strong></span>
}</pre></div><p>The <code class="literal">dot</code> (or inner) product of the observation <code class="literal">x</code> with the <code class="literal">weights</code> model is evaluated against the hyperplane. The predicted class is <code class="literal">1</code> if the produce exceeds <code class="literal">HYPERPLANE</code>, and <code class="literal">0</code> otherwise (line <code class="literal">34</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note18900"/>Note</h3><p>
<span class="strong"><strong>Class identification</strong></span>
</p><p>The class that the new data <span class="emphasis"><em>x</em></span> belongs to is determined by the <span class="emphasis"><em>dot(x, weights) &gt; 0.5</em></span> test, where <span class="emphasis"><em>dot</em></span> is the product of the features and the regression weights (<span class="emphasis"><em>w<sub>0</sub>+w<sub>1</sub>.volatility + w<sub>2</sub>.volume</em></span>). You may find different classification schemes in the scientific literature.</p></div><p>The <a id="id6970000" class="indexterm"/>direction of the price variation of the Copper ETF, <span class="emphasis"><em>CU price(t+1) – price(t)</em></span>, is compared to the direction predicted by the logistic regression. The result is plotted with the <span class="strong"><strong>success</strong></span> value if the positive or negative direction is correctly predicted; otherwise, it is plotted with the <span class="strong"><strong>failure</strong></span> value:</p><div class="mediaobject"><img src="../Images/image01417.jpeg" alt="Classification"/><div class="caption"><p>The prediction of the direction of the variation of price of the Copper ETF using the logistic regression</p></div></div><p style="clear:both; height: 1em;"> </p><p>The logistic regression was able to classify 78 out of 121 trading sessions (65 percent accuracy).</p><p>Now, let's use the logistic regression to predict the positive price variation for the Copper ETF, given its volatility and trading volume. This trading or investment strategy is known as being <span class="emphasis"><em>long on the market</em></span>. This particular use case ignores the trading sessions for which the price was either flat or declined:</p><div class="mediaobject"><img src="../Images/image01418.jpeg" alt="Classification"/><div class="caption"><p>The prediction of the direction of the variation of price of the Copper ETF using the logistic regression</p></div></div><p style="clear:both; height: 1em;"> </p><p>The logistic regression <a id="id6980000" class="indexterm"/>was able to correctly predict the positive price variation for 58 out of 64 trading sessions (90.6 percent accuracy). What is the difference between the first and second test cases?</p><p>In the first case, the <span class="emphasis"><em>w<sub>0</sub> + w<sub>1</sub>.volatility + w<sub>2</sub>.volume</em></span> separating hyperplane equation is used to segregate the features generating either the positive or negative price variation. Therefore, the overall accuracy of the classification is negatively impacted by the overlap of the features from the two classes.</p><p>In the second case, the classifier has to consider only the <span class="emphasis"><em>observations located on the positive side</em></span> of the hyperplane equation, without taking into account the false negatives.</p><div class="note" title="Note"><h3 class="title"><a id="note19000"/>Note</h3><p>
<span class="strong"><strong>Impact of rounding errors</strong></span>
</p><p>Under some circumstances, the generation of the rounding errors during the computation of the Jacobian matrix has an impact on the accuracy of the <span class="emphasis"><em>w<sub>0</sub> + w<sub>1</sub>.volatility + w<sub>2</sub>.volume</em></span> separating hyperplane equation. It reduces the accuracy of the prediction of both the positive and negative price variation.</p></div><p>The accuracy of the binary classifier can be further improved by considering the positive variation of the <a id="id6990000" class="indexterm"/>price using a margin error EPS as <span class="emphasis"><em>price(t+1) – price(t) &gt; EPS</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note19100"/>Note</h3><p>
<span class="strong"><strong>The validation methodology</strong></span>
</p><p>The validation set is generated by randomly selecting observations from the original labeled dataset. A formal validation requires you to use a K-fold validation methodology to compute the recall, precision, and F1 measure for the logistic regression model.</p></div></div></div>
<div class="section" title="Summary" id="aid-5N3C01"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec4500"/>Summary</h1></div></div></div><p>This concludes the description and implementation of the linear and logistic regression and the concept of regularization to reduce overfitting. Your first analytical projects using machine learning will (or did) likely involve a regression model of some type. Regression models, along with the Naïve Bayes classification, are the most understood techniques for those without a deep knowledge of statistics or machine learning.</p><p>After the completion of this chapter, you will hopefully have a grasp on the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The concept of linear and nonlinear least squares-based optimization</li><li class="listitem">The implementation of ordinary least square regression as well as logistic regression</li><li class="listitem">The impact of regularization with an implementation of the ridge regression</li></ul></div><p>The logistic regression is also the foundation of the conditional random fields, as described in the <span class="emphasis"><em>Conditional random fields</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>, and multilayer perceptrons, which was introduced in the <span class="emphasis"><em>The multilayer perceptron</em></span> section in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span>.</p><p>Contrary to the Naïve Bayes models (refer to <a class="link" title="Chapter 5. Naïve Bayes Classifiers" href="part0182.xhtml#aid-5DI6C1">Chapter 5</a>, <span class="emphasis"><em>Naïve Bayes Classifiers</em></span>), the least squares or logistic regression does not impose the condition that the features have to be independent. However, the regression models do not take into account the sequential nature of a time series such as asset pricing. The next chapter, which is dedicated to models for sequential data, introduces two classifiers that take into account the time dependency in a time series: the hidden Markov model and conditional random fields.</p></div>
<div class="chapter" title="Chapter&#xA0;7.&#xA0;Sequential Data Models" id="aid-5O1SI1"><div class="titlepage"><div><div><h1 class="title"><a id="ch21"/>Chapter 7. Sequential Data Models</h1></div></div></div><p>The universe of Markov models is vast and encompasses computational concepts such as the Markov decision process, discrete Markov, Markov chain Monte Carlo for Bayesian networks, and hidden Markov models.</p><p>Markov processes, and more specifically, the <a id="id7000000" class="indexterm"/><span class="strong"><strong>hidden Markov model</strong></span> (<span class="strong"><strong>HMM</strong></span>), are commonly used in speech recognition, language translation, text classification, document tagging, and data compression and decoding.</p><p>The first section of this chapter introduces and describes the hidden Markov model with the full implementation of the three canonical forms of the hidden Markov model using Scala. This section covers the different dynamic programming techniques used in the evaluation, decoding, and training of the hidden Markov model. The design of the classifier follows the same pattern as the logistic and linear regression, as described in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>.</p><p>The second and last section of this chapter is dedicated to a discriminative (labels conditional to observations) alternative to the hidden Markov model: conditional random fields. The open source CRF Java library authored by Sunita Sarawagi from the Indian Institute of Technology, Bombay, is used to create a predictive model using conditional random fields [7:1].</p><div class="section" title="Markov decision processes"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec4600"/>Markov decision processes</h1></div></div></div><p>This<a id="id7010000" class="indexterm"/> first section also describes the basic concepts you need to know in order to understand, develop, and apply the hidden Markov model. The<a id="id7020000" class="indexterm"/> foundation of the Markovian universe is the concept known as the <span class="strong"><strong>Markov property</strong></span>.</p><div class="section" title="The Markov property"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8200"/>The Markov property</h2></div></div></div><p>The Markov property<a id="id7030000" class="indexterm"/> is a characteristic of a stochastic process where the conditional probability distribution of a future state depends on the current state and not on its past states. In this case, the transition between the states occurs at a discrete time, and the Markov property is known as the <span class="strong"><strong>discrete Markov chain</strong></span>.</p></div><div class="section" title="The first order discrete Markov chain"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8300"/>The first order discrete Markov chain</h2></div></div></div><p>The <a id="id7040000" class="indexterm"/>following example is taken from <span class="emphasis"><em>Introduction to Machine Learning</em></span>, <span class="emphasis"><em>E. Alpaydin</em></span> [7:2].</p><p>Let's consider the following use case. <span class="emphasis"><em>N</em></span> balls of different colors are hidden in <span class="emphasis"><em>N</em></span> boxes (one each). The balls can have only three colors (Blue, Red, and Green). The experimenter draws the balls one by one. The state of the discovery process is defined by the color of the latest ball drawn from one of the boxes: <span class="emphasis"><em>S<sub>0</sub> = Blue, S<sub>1</sub> = Red, and S<sub>2</sub> = Green</em></span>.</p><p>Let <span class="emphasis"><em>{π<sub>0</sub>, π<sub>1</sub>, π<sub>2</sub>}</em></span> be the initial probabilities for having an initial set of color in each of the boxes.</p><p>Let <span class="emphasis"><em>q<sub>t</sub></em></span> denote the color of the ball drawn at the time <span class="emphasis"><em>t</em></span>. The probability of drawing a ball of color <span class="emphasis"><em>S<sub>k</sub></em></span> at the time <span class="emphasis"><em>k</em></span> after drawing a ball of the color <span class="emphasis"><em>S</em></span>
<span class="emphasis"><em>j</em></span> at the time <span class="emphasis"><em>j</em></span> is defined as <span class="emphasis"><em>p(q<sub>t</sub> = S<sub>k</sub> q<sub>t-1</sub> = S<sub>j</sub>) = a<sub>jk</sub></em></span>. The probability of drawing a red ball in the first attempt is <span class="emphasis"><em>p(q<sub>t0</sub> = S<sub>1</sub>) = π<sub>1</sub></em></span>. The probability of drawing a blue ball in the second attempt is <span class="emphasis"><em>p(q<sub>0</sub> = S<sub>1</sub>) p(q<sub>1</sub> = S<sub>0</sub>|q<sub>0</sub> = S<sub>1</sub>) = π<sub>1</sub> a<sub>10</sub></em></span>. The process is repeated to create a sequence of the state <span class="emphasis"><em>{S<sub>t</sub>} = {Red, Blue, Blue, Green, …}</em></span> with the following probability: <span class="emphasis"><em>p(q<sub><sub>0</sub></sub> = S<sub>1</sub>).p(q<sub>1</sub> = S<sub>0</sub>|q<sub>0</sub> = S<sub>1</sub>).p(q<sub>2</sub> = S<sub>0</sub>|q<sub>1</sub> = S<sub>0</sub>).p(q<sub>3</sub> = S<sub>2</sub>|q<sub>2</sub> = S<sub>0</sub>)… = π<sub>1</sub>.a<sub>10</sub>.a<sub>00</sub>.a2…</em></span>. The sequence of states/colors can be represented as follows:</p><div class="mediaobject"><img src="../Images/image01419.jpeg" alt="The first order discrete Markov chain"/><div class="caption"><p>An illustration of the ball and boxes example</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's estimate the probabilities <span class="emphasis"><em>p</em></span> using historical data (learning phase):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The estimation of the probability of drawing a red ball (<span class="emphasis"><em>S<sub>1</sub></em></span>) in the first attempt is <span class="emphasis"><em>π<sub>1</sub></em></span>, which is computed as the number of sequences starting with <span class="emphasis"><em>S<sub>1</sub></em></span><span class="emphasis"><em> (red) / total number of balls</em></span>.</li><li class="listitem">The<a id="id7050000" class="indexterm"/> estimation of the probability of retrieving a blue ball in the second attempt is <span class="emphasis"><em>a<sub>10</sub></em></span>, the number of sequences for which a blue ball is drawn after a red ball / total number of sequences, and so on.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note19200"/>Note</h3><p>
<span class="strong"><strong>Nth-order Markov</strong></span>
</p><p>The Markov property is popular mainly because of its simplicity. As you will discover while studying the hidden Markov model, having a state solely dependent on the previous state allows us to apply efficient dynamic programming techniques. However, some problems require dependencies between more than two states. These models are known as Markov random fields.</p></div><p>Although the discrete Markov process can be applied to trial and error types of applications, its applicability is limited to solving problems for which the observations do not depend on hidden states. Hidden Markov models are a commonly applied technique to meet such a challenge.</p></div></div></div>
<div class="section" title="The hidden Markov model"><div class="titlepage" id="aid-5P0D42"><div><div><h1 class="title"><a id="ch07lvl1sec4700"/>The hidden Markov model</h1></div></div></div><p>The<a id="id7060000" class="indexterm"/> hidden Markov model has numerous applications related to speech recognition, face identification (biometrics), and pattern recognition in pictures and videos [7:3].</p><p>A hidden Markov model consists of a Markov process (also known as a Markov chain) for observations with a discrete time. The main difference with the Markov processes is that the states are not observable. A new observation is emitted with a probability known as the emission probability each time the state of the system or model changes.</p><p>There are two sources of randomness, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Transition between states</li><li class="listitem">Emission of an observation when a state is given</li></ul></div><p>Let's reuse the boxes and balls example. If the boxes are hidden states (nonobservable), then the user draws the balls whose color is not visible. The emission probability is the probability <span class="emphasis"><em>b<sub>ik</sub> =p(o<sub>t</sub> = colork|q<sub>t</sub> =S<sub>i</sub>)</em></span> to retrieve a ball of the color <span class="emphasis"><em>k</em></span> from a hidden box <span class="emphasis"><em>I</em></span>, as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01420.jpeg" alt="The hidden Markov model"/><div class="caption"><p>The hidden Markov model for the balls and boxes example</p></div></div><p style="clear:both; height: 1em;"> </p><p>In this example, we <a id="id7070000" class="indexterm"/>do not assume that all the boxes contain balls of different colors. We cannot make any assumptions on the order as defined by the transition <span class="emphasis"><em>a<sub>ij</sub></em></span>. The HMM does not assume that the number of colors (observations) is identical to the number of boxes (states).</p><div class="note" title="Note"><h3 class="title"><a id="note19300"/>Note</h3><p>
<span class="strong"><strong>Time invariance</strong></span>
</p><p>Contrary to the Kalman filter, for example, the hidden Markov model requires that the transition elements, <span class="emphasis"><em>a<sub>ji</sub></em></span>, are independent of time. This property is known as stationary or homogeneous restriction.</p></div><p>Keep in mind that the observations, in this case the color of the balls, are the only tangible data available to the experimenter. From this example, we can conclude that a formal HMM has three <a id="id7080000" class="indexterm"/>components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A set of observations</li><li class="listitem">A sequence of hidden states</li><li class="listitem">A model that maximizes the joint probability of the observations and hidden states, known as the Lambda model</li></ul></div><p>A Lambda model, <span class="emphasis"><em>λ</em></span>, is composed of initial probabilities <span class="emphasis"><em>π</em></span>, the probabilities of state transitions as defined by the matrix <span class="emphasis"><em>A</em></span>, and the probabilities of states emitting one or more observations, as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01421.jpeg" alt="The hidden Markov model"/><div class="caption"><p>The visualization of the HMM key components</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding <a id="id7090000" class="indexterm"/>diagram illustrates that, given a sequence of observations, the HMM tackles the following three problems known as <a id="id7100000" class="indexterm"/>canonical forms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>CF1 (evaluation)</strong></span>: This evaluates the probability of a given sequence of observations <span class="emphasis"><em>O</em></span><span class="emphasis"><em>t</em></span>, given a model <span class="emphasis"><em>λ = (π, A, B)</em></span></li><li class="listitem"><span class="strong"><strong>CF2 (training)</strong></span>: This identifies (or learns) a model <span class="emphasis"><em>λ = (π, A, B)</em></span>, given a set of observations <span class="emphasis"><em>O</em></span></li><li class="listitem"><span class="strong"><strong>CF3 (decoding)</strong></span>: This estimates the state sequence <span class="emphasis"><em>Q</em></span> with the highest probability to generate a given set of observations <span class="emphasis"><em>O</em></span> and a model <span class="emphasis"><em>λ</em></span></li></ul></div><p>The solution to these three problems uses dynamic programming techniques. However, we need to clarify the notations prior to diving into the mathematical foundation of the hidden Markov model.</p><div class="section" title="Notations"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8400"/>Notations</h2></div></div></div><p>One of the challenges <a id="id7110000" class="indexterm"/>of describing the hidden Markov model is the mathematical notation that sometimes differs from author to author. From now on, we will use the following notation:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><thead><tr><th valign="bottom"> </th><th valign="bottom">
<p>Description</p>
</th><th valign="bottom">
<p>Formulation</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="emphasis"><em>N</em></span>
</p>
</td><td valign="top">
<p>The number of hidden states</p>
</td><td valign="top"> </td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>S</em></span>
</p>
</td><td valign="top">
<p>A finite set of <span class="emphasis"><em>N</em></span> hidden states</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>S = {S<sub>0</sub>, S<sub>1</sub>, … S<sub>N-1</sub>}</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>M</em></span>
</p>
</td><td valign="top">
<p>The number of observation symbols </p>
</td><td valign="top"> </td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>qt</em></span>
</p>
</td><td valign="top">
<p>The state at time or step <span class="emphasis"><em>t</em></span>
</p>
</td><td valign="top"> </td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>Q</em></span>
</p>
</td><td valign="top">
<p>A time sequence of states</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>Q = {q<sub>0</sub>, q<sub>1</sub>, … q<sub>n-1</sub>} = Q<sub>0:n-1</sub></em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>T</em></span>
</p>
</td><td valign="top">
<p>The number of observations</p>
</td><td valign="top"> </td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>ot</em></span>
</p>
</td><td valign="top">
<p>The observation at time <span class="emphasis"><em>t</em></span>
</p>
</td><td valign="top"> </td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>O</em></span>
</p>
</td><td valign="top">
<p>A finite sequence of <span class="emphasis"><em>T</em></span> observations</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>O = {o<sub>0</sub>, o<sub>1</sub>, … o<sub>T-1</sub>} = O<sub>0:T-1</sub></em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>A</em></span>
</p>
</td><td valign="top">
<p>The state transition probability matrix</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>a<sub>ji</sub> = p(q<sub>t+1</sub>=S<sub>i</sub>| q<sub>t</sub>=S<sub>j</sub>)</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>B</em></span>
</p>
</td><td valign="top">
<p>The emission probability matrix</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>b<sub>jk</sub> = p(o<sub>t</sub>=O<sub>k</sub>| q<sub>t</sub>=S<sub>j</sub>)</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>π</em></span>
</p>
</td><td valign="top">
<p>The initial state probability vector</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>π<sub>i</sub> = p(q<sub>0</sub>=S<sub>j</sub>)</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>λ</em></span>
</p>
</td><td valign="top">
<p>The hidden Markov model</p>
</td><td valign="top">
<p>
<span class="emphasis"><em>λ = (π, A, B)</em></span>
</p>
</td></tr></tbody></table></div><div class="note" title="Note"><h3 class="title"><a id="note19400"/>Note</h3><p>
<span class="strong"><strong>Variance in the notation</strong></span>
</p><p>Some authors use the symbol <span class="emphasis"><em>z</em></span> to represent the hidden states instead of <span class="emphasis"><em>q</em></span> and <span class="emphasis"><em>x</em></span> to represent the observations <span class="emphasis"><em>O</em></span>.</p></div><p>For convenience, let's<a id="id7120000" class="indexterm"/> simplify the notation of the sequence of observations and states using the condensed form: <span class="emphasis"><em>p(O<sub>0:T</sub>, q<sub>t</sub>| λ) = p(O<sub>0</sub>, O<sub>1</sub>, … O<sub>T</sub>, q<sub>t</sub>| λ)</em></span>. It is quite common to visualize a hidden Markov model with a lattice of states and observations, which is similar to our description of the boxes and balls examples, as shown here:</p><div class="mediaobject"><img src="../Images/image01422.jpeg" alt="Notations"/><div class="caption"><p>The formal HMM-directed graph</p></div></div><p style="clear:both; height: 1em;"> </p><p>The state <span class="emphasis"><em>Si</em></span> is observed as <span class="emphasis"><em>O<sub>k</sub></em></span> at time <span class="emphasis"><em>t</em></span>, before being transitioned to the state <span class="emphasis"><em>S<sub>j</sub></em></span> observed as <span class="emphasis"><em>O<sub>m</sub></em></span> at the time <span class="emphasis"><em>t+1</em></span>. The first step in the creation of our HMM is the definition of the class that implements the lambda model <span class="emphasis"><em>λ = (π, A, B)</em></span> [7:4].</p></div><div class="section" title="The lambda model"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8500"/>The lambda model</h2></div></div></div><p>The <a id="id7130000" class="indexterm"/>three canonical forms of the hidden Markov model rely heavily on manipulation and operations on matrices and vectors. For convenience, let's define an <code class="literal">HMMConfig</code> class that contains the dimensions used in the HMM:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>HMMConfig</strong></span>(val <span class="strong"><strong>numObs</strong></span>: Int, val <span class="strong"><strong>numStates</strong></span>: Int, 
    val <span class="strong"><strong>numSymbols</strong></span>: Int, val <span class="strong"><strong>maxIters</strong></span>: Int, val eps: Double) 
    extends Config</pre></div><p>The input parameters for the class are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">numObs</code>: This is the number of observations</li><li class="listitem"><code class="literal">numStates</code>: This is the number of hidden states</li><li class="listitem"><code class="literal">numSymbols</code>: This is the number of observation symbols or features</li><li class="listitem"><code class="literal">maxIters</code>: This is the maximum number of iterations required for the HMM training</li><li class="listitem"><code class="literal">eps</code>: This is the convergence criteria for the HMM training</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note19500"/>Note</h3><p>
<span class="strong"><strong>Consistency with a mathematical notation</strong></span>
</p><p>The implementation uses <code class="literal">numObs</code> (with respect to <code class="literal">numStates</code> and <code class="literal">numSymbols</code>) to represent programmatically the number of observations <code class="literal">T</code> (with respect to the <code class="literal">N</code> hidden states and <code class="literal">M</code> features). As a general rule, the implementation reuses the mathematical symbols as much as possible.</p></div><p>The <code class="literal">HMMConfig</code> companion object defines the operations on ranges of index of matrix rows and columns. The <code class="literal">foreach</code> (line <code class="literal">1</code>), <code class="literal">foldLeft</code> (<code class="literal">/:</code>) (line <code class="literal">2</code>), and <code class="literal">maxBy</code> (line <code class="literal">3</code>) methods are regularly used in each of the three canonical forms:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>HMMConfig</strong></span> {
  def <span class="strong"><strong>foreach</strong></span>(i: Int, f: Int =&gt; Unit): Unit =
      Range(0, i).foreach(f)  //<span class="strong"><strong>1</strong></span>
  def <span class="strong"><strong>/:</strong></span>(i: Int, f: (Double, Int) =&gt; Double, zero: Double) = 
        Range(0, i)./:(zero)(f) //<span class="strong"><strong>2</strong></span>
  def <span class="strong"><strong>maxBy</strong></span>(i: Int, f: Int =&gt; Double): Int = 
      Range(0,i).maxBy(f)   //<span class="strong"><strong>3</strong></span>
   … 
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note19600"/>Note</h3><p>
<span class="strong"><strong>The λ notation</strong></span>
</p><p>The <span class="emphasis"><em>λ</em></span> model in the HMM should not be confused with the regularization factor discussed in the <span class="emphasis"><em>L<sub>n</sub></em></span>
<span class="emphasis"><em> roughness penalty</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>.</p></div><p>As mentioned <a id="id7140000" class="indexterm"/>earlier, the lambda model is defined as a tuple of the transition probability matrix <span class="emphasis"><em>A</em></span>, emission probability matrix <span class="emphasis"><em>B</em></span>, and the initial probability <span class="emphasis"><em>π</em></span>. It is easily implemented as an <code class="literal">HMMModel</code> class using the <code class="literal">DMatrix</code> class, as defined in the <span class="emphasis"><em>Utility classes</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>. The simplest constructor for the <code class="literal">HMMModel</code> class is invoked in the case where the state-transition probability matrix, the emission probability matrix, and the initial states are known, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>HMMModel</strong></span>( val <span class="strong"><strong>A</strong></span>: DMatrix, val <span class="strong"><strong>B</strong></span>: DMatrix, var <span class="strong"><strong>pi</strong></span>: DblArray, 
    val <span class="strong"><strong>numObs</strong></span>: Int) {   //<span class="strong"><strong>4</strong></span>
  val numStates = A.nRows
  val numSymbols = B.nCols

  def setAlpha(obsSeqNum: Vector[Int]): DMatrix
  def getAlphaVal(a: Double, i: Int, obsId: Int): Double
  def getBetaVal(b: Double, i: Int, obsId: Int): Double
  def update(gamma: Gamma, diGamma: DiGamma, 
      obsSeq: Vector[Int])
  def normalize: Unit
}</pre></div><p>The constructor of the <code class="literal">HMMModel</code> class has the following four arguments (line <code class="literal">4</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">A</code>: This is the state transition probabilities matrix</li><li class="listitem"><code class="literal">B</code>: This is the omission probabilities matrix</li><li class="listitem"><code class="literal">pi</code>: This is the initial probability for the states</li><li class="listitem"><code class="literal">numObs</code>: This is the number of observations</li></ul></div><p>The number of states and symbols are extracted from the dimension of the <code class="literal">A</code> and <code class="literal">B</code> matrices.</p><p>The <code class="literal">HMMModel</code> class has several methods that will be described in detail whenever they are required for the execution of the model. The probabilities for the <code class="literal">pi</code> initial states are unknown, and therefore, they are initialized with a random generator of values [0, 1].</p><div class="note" title="Note"><h3 class="title"><a id="note19700"/>Note</h3><p>
<span class="strong"><strong>Normalization</strong></span>
</p><p>Input states and observation data may have to be normalized and converted to probabilities before we initialize the <code class="literal">A</code> and <code class="literal">B</code> matrices.</p></div><p>The other two <a id="id7150000" class="indexterm"/>components of the HMM are the sequence of observations and the sequence of hidden states.</p></div><div class="section" title="Design"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8600"/>Design</h2></div></div></div><p>The <a id="id7160000" class="indexterm"/>canonical forms of the HMM are implemented through dynamic programming techniques. These techniques rely on variables that define the state of the execution of the HMM for any of the canonical forms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Alpha</code> (the forward pass): The probability of observing the first <span class="emphasis"><em>t &lt; T</em></span> observations for a specific state at <span class="emphasis"><em>S<sub>i</sub></em></span> for the observation <span class="emphasis"><em>t</em></span> is <span class="emphasis"><em>α<sub>t</sub>(i) = p(O<sub>0:t</sub>, q<sub>t</sub>=S<sub>i</sub>|λ)</em></span></li><li class="listitem"><code class="literal">Beta</code> (the backward pass): The probability of observing the remainder of the sequence <span class="emphasis"><em>q</em></span><span class="emphasis"><em>t</em></span> for a specific state is <span class="emphasis"><em>β<sub>t</sub>(i) =p(O<sub>t+1:T-1</sub>|q<sub>t</sub>=S<sub>i</sub>,λ)</em></span></li><li class="listitem"><code class="literal">Gamma</code>: The probability of being in a specific state given a sequence of observations and a model is <span class="emphasis"><em>γ<sub>t</sub>(i) =p(q<sub>t</sub>=S<sub>i</sub>|O<sub>0:T-1</sub>, λ)</em></span></li><li class="listitem"><code class="literal">Delta</code>: This is the sequence that has the highest probability path for the first <span class="emphasis"><em>i</em></span> observations defined for a specific test <span class="emphasis"><em>δ<sub>t</sub>(i)</em></span></li><li class="listitem"><code class="literal">Qstar</code>: This is the optimum sequence <span class="emphasis"><em>q*</em></span> of states <span class="emphasis"><em>Q<sub>0:T-1</sub></em></span></li><li class="listitem"><code class="literal">DiGamma</code>: The probability of being in a specific state at <span class="emphasis"><em>t</em></span> and another defined state at <span class="emphasis"><em>t + 1</em></span> given the sequence of observations and the model is <span class="emphasis"><em>γ</em></span><sub>t</sub>(i,j) = p(q<sub>t</sub>=S<sub>i</sub>,q<sub>t+1</sub>=S<sub>j</sub>|O<sub>0:T-1</sub>, λ)</li></ul></div><p>Each of the parameters is described mathematically and programmatically in the section related to each specific canonical form. The <code class="literal">Gamma</code> and <code class="literal">DiGamma</code> classes are used and described in the evaluation canonical form. The <code class="literal">DiGamma</code> singleton is described as part of the Viterbi algorithm to extract the sequence of states with the highest probability given a <span class="emphasis"><em>λ</em></span> model and a set of observations.</p><p>The list of dynamic programming-related algorithms used in any of the three canonical forms is visualized through the class hierarchy of our implementation of the HMM:</p><div class="mediaobject"><img src="../Images/image01423.jpeg" alt="Design"/><div class="caption"><p>Scala classes' hierarchy for HMM (the UML class diagram)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram<a id="id7170000" class="indexterm"/> omits the utility traits and classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p><p>The <span class="emphasis"><em>λ</em></span> model, the HMM state, and the sequence of observations are all the elements needed to implement the three canonical cases. Each class is described as needed in the description of the three canonical forms of HMM. It is time to dive into the implementation details of each of the canonical forms, starting with the evaluation.</p><p>The execution of any of the three canonical forms relies on dynamic programming techniques (refer to the <span class="emphasis"><em>Overview of dynamic programming</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>) [7:5]. The simplest of the dynamic programming techniques is a single traversal of the observations/state chain.</p></div><div class="section" title="Evaluation – CF-1"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8700"/>Evaluation – CF-1</h2></div></div></div><p>The <a id="id7180000" class="indexterm"/>objective is to compute the probability (or likelihood) of the observed sequence <span class="emphasis"><em>O<sub>t</sub></em></span> given a <span class="emphasis"><em>λ</em></span> model. A dynamic programming technique<a id="id7190000" class="indexterm"/> is used to break down the probability of the sequence of observations into two probabilities (<span class="strong"><strong>M1</strong></span>):</p><div class="mediaobject"><img src="../Images/image01424.jpeg" alt="Evaluation – CF-1"/></div><p style="clear:both; height: 1em;"> </p><p>The likelihood is computed by marginalizing over all the hidden states <span class="emphasis"><em>{S<sub>i</sub>}</em></span> [7:6] (<span class="strong"><strong>M2</strong></span>):</p><div class="mediaobject"><img src="../Images/image01425.jpeg" alt="Evaluation – CF-1"/></div><p style="clear:both; height: 1em;"> </p><p>If we use <a id="id7200000" class="indexterm"/>the <a id="id7210000" class="indexterm"/>notation introduced in the previous chapter for alpha and beta variables, the probability for the observed sequence <span class="emphasis"><em>O<sub>t</sub></em></span> given a <span class="emphasis"><em>λ</em></span> model can be expressed as follows (<span class="strong"><strong>M3</strong></span>):</p><div class="mediaobject"><img src="../Images/image01426.jpeg" alt="Evaluation – CF-1"/></div><p style="clear:both; height: 1em;"> </p><p>The product of the <span class="emphasis"><em>α</em></span> and <span class="emphasis"><em>β</em></span> probabilities can potentially underflow. Therefore, it is recommended that you use the log of the probabilities instead of the probabilities.</p><div class="section" title="Alpha – the forward pass"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec9700"/>Alpha – the forward pass</h3></div></div></div><p>The computation of the <a id="id7220000" class="indexterm"/>probability of observing a specific sequence given a sequence of hidden states and a <span class="emphasis"><em>λ</em></span> model relies on a two-pass algorithm. The alpha algorithm consists of the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute the initial alpha value [<span class="strong"><strong>M4</strong></span>]. The value is then normalized by the sum of alpha values across all the hidden states [<span class="strong"><strong>M5</strong></span>].</li><li class="listitem">Compute the alpha value iteratively for the time 0 to time <span class="emphasis"><em>t</em></span>, and then normalize it by the sum of alpha values for all states [<span class="strong"><strong>M6</strong></span>].</li><li class="listitem">The final step is to compute of the log of the probability of observing the sequence [<span class="strong"><strong>M7</strong></span>].</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note19800"/>Note</h3><p>
<span class="strong"><strong>Performance consideration</strong></span>
</p><p>A direct computation of the probability of observing a specific sequence requires <span class="emphasis"><em>2TN<sub>2</sub></em></span> multiplications. The iterative alpha and beta classes reduce the number of multiplications to <span class="emphasis"><em>N<sub>2</sub>T</em></span>.</p></div><p>For those with some inclination toward mathematics, the computation of the alpha matrix is defined in the <a id="id7230000" class="indexterm"/>following information box.</p><div class="note" title="Note"><h3 class="title"><a id="note19900"/>Note</h3><p>
<span class="strong"><strong>Alpha (the forward pass)</strong></span>
</p><p>M4: Initialization is defined as:</p><div class="mediaobject"><img src="../Images/image01427.jpeg" alt="Alpha – the forward pass"/></div><p style="clear:both; height: 1em;"> </p><p>M5: Normalization of initial values <span class="emphasis"><em>N – 1</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01428.jpeg" alt="Alpha – the forward pass"/></div><p style="clear:both; height: 1em;"> </p><p>M6: Normalized summation is defined as:</p><div class="mediaobject"><img src="../Images/image01429.jpeg" alt="Alpha – the forward pass"/></div><p style="clear:both; height: 1em;"> </p><p>M7: The probability of observing a sequence given a lambda model and states is defined as:</p><div class="mediaobject"><img src="../Images/image01430.jpeg" alt="Alpha – the forward pass"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's take a <a id="id7240000" class="indexterm"/>look at the implementation of the alpha class in Scala, using the referenced number of the mathematical expressions of the alpha class. The alpha and beta values have to be normalized [M3], and therefore, we define an <code class="literal">HMMTreillis</code> base class for the alpha and beta algorithms that implements the normalization:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>HMMTreillis</strong></span>(<span class="strong"><strong>numObs</strong></span>: Int, numStates: Int){ //<span class="strong"><strong>5</strong></span>
  var <span class="strong"><strong>treillis</strong></span>: DMatrix = _   //<span class="strong"><strong>6</strong></span>
  val ct = Array.fill(numObs)(0.0) 

   def <span class="strong"><strong>normalize</strong></span>(t: Int): Unit = { //<span class="strong"><strong>7</strong></span>
     ct.update(t, /:(numStates, (s, n) =&gt; s + treillis(t, n)))
     treillis /= (t, ct(t))
   }
   def getTreillis: DMatrix = treillis
}</pre></div><p>The <code class="literal">HMMTreillis</code> class has two configuration parameters: the number of observations, <code class="literal">numObs</code>, and the number of states, <code class="literal">numStates</code> (line <code class="literal">5</code>). The <code class="literal">treillis</code> variable represents the scaling matrix used in the alpha (or forward) and beta (or backward) passes (line <code class="literal">6</code>).</p><p>The normalization method, <code class="literal">normalize</code>, implements the <span class="strong"><strong>M6 </strong></span>formula by recomputing the <code class="literal">ct</code> scaling factor (line <code class="literal">7</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note20400"/>Note</h3><p>
<span class="strong"><strong>Computation efficiency</strong></span>
</p><p>Scala's <code class="literal">reduce</code>, <code class="literal">fold</code>, and <code class="literal">foreach</code> methods are far more efficient iterators than the <code class="literal">for</code> loop. You need to keep in mind that the main purpose of the <code class="literal">for</code> loop in Scala is the monadic composition of the <code class="literal">map</code> and <code class="literal">flatMap</code> operations.</p></div><p>The computation of the <code class="literal">alpha</code> variable in the <code class="literal">Alpha</code> class follows the same computation flow as defined in the <span class="strong"><strong>M4</strong></span>, <span class="strong"><strong>M5</strong></span>, and <span class="strong"><strong>M6</strong></span> mathematical expressions:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Alpha</strong></span>(<span class="strong"><strong>lambda</strong></span>: HMMModel, <span class="strong"><strong>obsSeq</strong></span>: Vector[Int]) //<span class="strong"><strong>8</strong></span>
    extends HMMTreillis(lambda.numObs, lambda.numStates) {

  val <span class="strong"><strong>alpha</strong></span>: Double = Try { 
    treillis = lambda.<span class="strong"><strong>setAlpha</strong></span>(obsSeq) //<span class="strong"><strong>9</strong></span>
    <span class="strong"><strong>normalize</strong></span>(0)  //<span class="strong"><strong>10</strong></span>
    <span class="strong"><strong>sumUp</strong></span>  //<span class="strong"><strong>11</strong></span>
  }.getOrElse(Double.NaN)
  
  override def isInitialized: Boolean = alpha != Double.NaN

  val last = lambda.numObs-1
  def <span class="strong"><strong>sumUp</strong></span>: Double = {
    foreach(1, lambda.numObs, t =&gt; {
      updateAlpha(t) //<span class="strong"><strong>12</strong></span>
      normalize(t)  //<span class="strong"><strong>13</strong></span>
    })
    /:(lambda.numStates, (s,k) =&gt; s + treillis(last, k))
  }

  def updateAlpha(t: Int): Unit = 
    foreach(lambda.numStates, i =&gt; { //<span class="strong"><strong>14</strong></span>
      val newAlpha = lambda.getAlphaVal(treillis(t-1, i)
      treillis += (t, i, newAlpha, i, obsSeq(t))) 
    })
  
  def <span class="strong"><strong>logProb</strong></span>: Double = /:(lambda.numObs, (s,t) =&gt; //<span class="strong"><strong>15</strong></span>
    s + Math.log(ct(t)), Math.log(alpha))
}</pre></div><p>The <code class="literal">Alpha</code> class <a id="id7250000" class="indexterm"/>has two arguments: the <code class="literal">lambda</code> model and the <code class="literal">obsSeq</code> sequence of observations (line <code class="literal">8</code>). The definition of the scaling factor <code class="literal">alpha</code> initializes the <code class="literal">treillis</code> scaling matrix using the <code class="literal">HMMModel.setAlpha</code> method (line <code class="literal">9</code>), normalizes the initial value of the matrix by invoking the <code class="literal">HMMTreillis.normalize</code> method for the first observation (line <code class="literal">10</code>), and sums the matrix element to return the scaling factor by invoking <code class="literal">sumUp</code> (line <code class="literal">11</code>).</p><p>The <code class="literal">setAlpha</code> method implements the mathematical expression <span class="strong"><strong>M4</strong></span> as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>setAlpha</strong></span>(obsSeq: Array[Int]): DMatrix = 
  Range(0,numStates)./:(DMatrix(numObs, numStates))((m,j) =&gt; 
      m += (0, j, pi(j)*B(j, obsSeq.head)))
}</pre></div><p>The fold generates an instance of the <code class="literal">DMatrix</code> class, as described in the <span class="emphasis"><em>Utility classes</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The <code class="literal">sumUp</code> method implements the mathematical expression <span class="strong"><strong>M6</strong></span> as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Update the <code class="literal">treillis</code> matrix of the scaling factor in the <code class="literal">updateAlpha</code> method (line <code class="literal">12</code>)</li><li class="listitem">Normalize all the scaling factors for all the remaining observations (line <code class="literal">13</code>)</li></ul></div><p>The <code class="literal">updateAlpha</code> method updates the <code class="literal">treillis</code> scaling matrix by computing all the <code class="literal">alpha</code> factors for all states (line <code class="literal">14</code>). The <code class="literal">logProb</code> method implements the mathematical expression <span class="strong"><strong>M7</strong></span>. It computes the logarithm of the probability of observing a specific sequence, given the <a id="id7260000" class="indexterm"/>sequence of states and a predefined <span class="emphasis"><em>λ</em></span> model (line <code class="literal">15</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note20500"/>Note</h3><p>
<span class="strong"><strong>The log probability</strong></span>
</p><p>The <code class="literal">logProb</code> method computes the logarithm of the probability instead of the probability itself. The summation of the logarithm of probabilities is less likely to cause an underflow than the product of probabilities.</p></div></div><div class="section" title="Beta – the backward pass"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec9800"/>Beta – the backward pass</h3></div></div></div><p>The computation <a id="id7270000" class="indexterm"/>of beta values is similar to the <code class="literal">Alpha</code> class except that the iteration executes backward on the sequence of states.</p><p>The implementation of <code class="literal">Beta</code> is similar to the alpha class:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute (<span class="strong"><strong>M5</strong></span>) and normalize (<span class="strong"><strong>M6</strong></span>) the value of beta at <span class="emphasis"><em>t = 0</em></span> across states.</li><li class="listitem">Compute and normalize iteratively the beta value at time <span class="emphasis"><em>T - 1</em></span> to <span class="emphasis"><em>t</em></span>, which is updated from its value at <span class="emphasis"><em>t + 1</em></span> (<span class="strong"><strong>M7</strong></span>).</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note20600"/>Note</h3><p>
<span class="strong"><strong>Beta (the backward pass)</strong></span>
</p><p>M8: Initialization of beta <span class="emphasis"><em>β<sub>T-1</sub>(t) = 1</em></span>.</p><p>M9: Normalization of initial beta values is defined as:</p><div class="mediaobject"><img src="../Images/image01431.jpeg" alt="Beta – the backward pass"/></div><p style="clear:both; height: 1em;"> </p><p>M10: Normalized summation of beta is defined as:</p><div class="mediaobject"><img src="../Images/image01432.jpeg" alt="Beta – the backward pass"/></div><p style="clear:both; height: 1em;"> </p></div><p>The definition of the <code class="literal">Beta</code> class is very similar to the <code class="literal">Alpha</code> class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Beta</strong></span>(lambda: HMMModel, obsSeq: Vector[Int]) 
     extends HMMTreillis(lambda.numObs, lambda.numStates) {

  val <span class="strong"><strong>initialized</strong></span>: Boolean  //<span class="strong"><strong>16</strong></span>

  override def isInitialized: Boolean = <span class="strong"><strong>initialized</strong></span>
  def <span class="strong"><strong>sumUp</strong></span>: Unit =   //<span class="strong"><strong>17</strong></span>
    (lambda.numObs-2 to 0 by -1).foreach(t =&gt; { //<span class="strong"><strong>18</strong></span>
      updateBeta(t)  //<span class="strong"><strong>19</strong></span>
      normalize(t) 
    })
   
   def <span class="strong"><strong>updateBeta</strong></span>(t: Int): Unit =
     foreach(lambda.numStates, i =&gt; { 
       val newBeta = lambda.getBetaVal(treillis(t+1, i)
       treillis += (t, i, newBeta, i, obsSeq(t+1))) //<span class="strong"><strong>20</strong></span>
     })
}</pre></div><p>Contrary to <a id="id7280000" class="indexterm"/>the <code class="literal">Alpha</code> class, the <code class="literal">Beta</code> class does not generate an output value. The <code class="literal">Beta</code> class has an <code class="literal">initialized</code> Boolean attribute to indicate whether the constructor has executed successfully (line <code class="literal">16</code>). The constructor updates and normalizes the beta matrix by traversing the sequence of observations backward from before the last observation to the first:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>initialized</strong></span>: Boolean = Try {
  treillis = DMatrix(lambda.numObs, lambda.numStates)
  treillis += (lambda.numObs-1, 1.0) //<span class="strong"><strong>21</strong></span>
  normalize(lambda.numObs-1)  //<span class="strong"><strong>22</strong></span>
  sumUp  //<span class="strong"><strong>23</strong></span>
}._toBoolean("Beta initialization failed")</pre></div><p>The initialization of the <code class="literal">treillis</code> beta scaling matrix of the <code class="literal">DMatrix</code> type assigns the value <code class="literal">1.0</code> to the last observation (line <code class="literal">21</code>) and normalizes the beta values for the last observation, as defined in <span class="strong"><strong>M8</strong></span> (line <code class="literal">22</code>). It implements the mathematical expressions <span class="strong"><strong>M9</strong></span> and <span class="strong"><strong>M10</strong></span> by invoking the <code class="literal">sumUp</code> method (line <code class="literal">23</code>).</p><p>The <code class="literal">sumUp</code> method is similar to <code class="literal">Alpha.sumUp</code> (line <code class="literal">17</code>). It traverses the sequence of observations backward (line <code class="literal">18</code>) and updates the beta scaling matrix, as defined in the mathematical expression <span class="strong"><strong>M9</strong></span> (line <code class="literal">19</code>). The implementation of the mathematical expression <span class="strong"><strong>M10</strong></span> in the <code class="literal">updateBeta</code> method is similar to the alpha pass: it updates the <code class="literal">treillis</code> scaling matrix with the <code class="literal">newBeta</code> values computed in the <code class="literal">lambda</code> model (line <code class="literal">20</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note20800"/>Note</h3><p>
<span class="strong"><strong>Constructors and initialization</strong></span>
</p><p>The alpha and beta values are computed within the constructors of their respective classes. The client code has to validate these instances by invoking <code class="literal">isInitialized</code>.</p></div><p>What is the <a id="id7290000" class="indexterm"/>value of a model if it cannot be created? The next canonical form CF2 leverages dynamic programming and recursive functions to extract the <span class="emphasis"><em>λ</em></span> model.</p></div></div><div class="section" title="Training – CF-2"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8800"/>Training – CF-2</h2></div></div></div><p>The <a id="id7300000" class="indexterm"/>objective of this canonical form is to extract the <span class="emphasis"><em>λ</em></span> model <a id="id7310000" class="indexterm"/>given a set of observations and a sequence of states. It is similar to the training of a classifier. The simple dependency of a current state on the previous state enables an implementation using an iterative procedure, known as the <span class="strong"><strong>Baum-Welch estimator</strong></span> or <a id="id7320000" class="indexterm"/><span class="strong"><strong>expectation-maximization</strong></span> (<span class="strong"><strong>EM</strong></span>).</p><div class="section" title="The Baum-Welch estimator (EM)"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec9900"/>The Baum-Welch estimator (EM)</h3></div></div></div><p>At its core, the <a id="id7330000" class="indexterm"/>algorithm consists of<a id="id7340000" class="indexterm"/> three steps and an iterative method, which is similar to the evaluation canonical form:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Compute the probability <span class="emphasis"><em>π</em></span> (the gamma value at <span class="emphasis"><em>t = 0</em></span>) (<span class="strong"><strong>M11</strong></span>).</li><li class="listitem">Compute and normalize the state's transition probabilities matrix <span class="emphasis"><em>A</em></span> (<span class="strong"><strong>M12</strong></span>).</li><li class="listitem">Compute and normalize the matrix of emission probabilities <span class="emphasis"><em>B</em></span> (<span class="strong"><strong>M13</strong></span>).</li><li class="listitem">Repeat steps 2 and 3 until the change of likelihood is insignificant.</li></ol><div style="height:10px; width: 1px"/></div><p>The algorithm uses the digamma and summation gamma classes.</p><div class="note" title="Note"><h3 class="title"><a id="note20900"/>Note</h3><p>
<span class="strong"><strong>The Baum-Welch algorithm</strong></span>
</p><p>M11: The joint probability of the state <span class="emphasis"><em>q<sub>i</sub></em></span> at <span class="emphasis"><em>t</em></span> and <span class="emphasis"><em>q<sub>j</sub></em></span> at <span class="emphasis"><em>t+1</em></span> (digamma) is defined as:</p><div class="mediaobject"><img src="../Images/image01433.jpeg" alt="The Baum-Welch estimator (EM)"/></div><p style="clear:both; height: 1em;"> </p><div class="mediaobject"><img src="../Images/image01434.jpeg" alt="The Baum-Welch estimator (EM)"/></div><p style="clear:both; height: 1em;"> </p><p>M12: The initial probabilities vector <span class="emphasis"><em>N−1</em></span> and sum of joint probabilities for all the states (gamma)are defined as:</p><div class="mediaobject"><img src="../Images/image01435.jpeg" alt="The Baum-Welch estimator (EM)"/></div><p style="clear:both; height: 1em;"> </p><p>M13: The update of the transition probabilities matrix is defined as:</p><div class="mediaobject"><img src="../Images/image01436.jpeg" alt="The Baum-Welch estimator (EM)"/></div><p style="clear:both; height: 1em;"> </p><p>M14: The update of the emission probabilities matrix is defined as:</p><div class="mediaobject"><img src="../Images/image01437.jpeg" alt="The Baum-Welch estimator (EM)"/></div><p style="clear:both; height: 1em;"> </p></div><p>The Baum-Welch algorithm <a id="id7350000" class="indexterm"/>is <a id="id7360000" class="indexterm"/>implemented in the <code class="literal">BaumWelchEM</code> class and requires the following two inputs (line <code class="literal">24</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <span class="emphasis"><em>λ</em></span> model, <code class="literal">lambda</code>, computed from the <code class="literal">config</code> configuration</li><li class="listitem">The <code class="literal">obsSeq</code> sequence (vector) of observations</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>BaumWelchEM</strong></span>(<span class="strong"><strong>config</strong></span>: HMMConfig, <span class="strong"><strong>obsSeq</strong></span>: Vector[Int]) { //<span class="strong"><strong>24</strong></span>
  val <span class="strong"><strong>lambda</strong></span> = HMMModel(config)
  val <span class="strong"><strong>diGamma</strong></span> = new DiGamma(lambda.numObs,lambda.numStates)//<span class="strong"><strong>25</strong></span>
  val <span class="strong"><strong>gamma</strong></span> = new Gamma(lambda.numObs, lambda.numStates) //<span class="strong"><strong>26</strong></span>
  val maxLikelihood: Option[Double] //<span class="strong"><strong>27</strong></span>
}</pre></div><p>The <code class="literal">DiGamma</code> class <a id="id7370000" class="indexterm"/>defines <a id="id7380000" class="indexterm"/>the joint probabilities for any consecutive states (line <code class="literal">25</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DiGamma</strong></span>(numObs: Int, numStates: Int) {
  val <span class="strong"><strong>diGamma</strong></span> = Array.fill(numObs-1)(DMatrix(numStates))
  def <span class="strong"><strong>update</strong></span>(alpha: DMatrix, beta: DMatrix, A: DMatrix, 
  B: DMatrix, obsSeq: Array[Int]): Try[Int]
}</pre></div><p>The <code class="literal">diGamma</code> variable is an array of matrices that represents the joint probabilities of two consecutive states. It is initialized through an invocation of the <code class="literal">update</code> method, which implements the mathematical expression <span class="strong"><strong>M11</strong></span>.</p><p>The <code class="literal">Gamma</code> class computes the sum of the joint probabilities across all the states (line <code class="literal">26</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Gamma</strong></span>(numObs: Int, numStates: Int) {
  val gamma = DMatrix(numObs, numStates)
  def <span class="strong"><strong>update</strong></span>(alpha: DMatrix, beta: DMatrix): Unit
}</pre></div><p>The <code class="literal">update</code> method of the <code class="literal">Gamma</code> class implements the mathematical expression <span class="strong"><strong>M12</strong></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note21300"/>Note</h3><p>
<span class="strong"><strong>Source code for Gamma and DiGamma</strong></span>
</p><p>The <code class="literal">Gamma</code> and <code class="literal">DiGamma</code> classes implement the mathematical expressions for the Baum-Welch algorithm. The <code class="literal">update</code> method uses simple linear algebra and is not described; refer to the documented source code for details.</p></div><p>The maximum likelihood, <code class="literal">maxLikelihood</code>, for the sequence of states given an existing lambda model and a sequence of observations (line <code class="literal">27</code>) is computed using the <code class="literal">getLikelihood</code> tail recursive method, as follows:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>maxLikelihood</strong></span>: Option[Double] = Try {

  @<span class="strong"><strong>tailrec</strong></span>
  def <span class="strong"><strong>getLikelihood</strong></span>(likelihood: Double, index: Int): Double ={
    lambda.update(gamma, diGamma, obsSeq) //<span class="strong"><strong>28</strong></span>
    val _likelihood = <span class="strong"><strong>frwrdBckwrdLattice</strong></span>   //<span class="strong"><strong>29</strong></span>
    val diff = likelihood - _likelihood
      
    if( diff &lt; config.eps ) _likelihood    //<span class="strong"><strong>30</strong></span>
    else if (index &gt;= config.maxIters)  //<span class="strong"><strong>31</strong></span>
      throw new IllegalStateException(" … ")
    else <span class="strong"><strong>getLikelihood</strong></span>(_likelihood, index+1) 
  }

  val max = <span class="strong"><strong>getLikelihood</strong></span>(frwrdBckwrdLattice, 0)
  lambda.normalize   //<span class="strong"><strong>32</strong></span>
  max
}._toOption("BaumWelchEM not initialized", logger)</pre></div><p>The <code class="literal">maxLikelihood</code> value <a id="id7390000" class="indexterm"/>implements <a id="id7400000" class="indexterm"/>the mathematical expressions <span class="strong"><strong>M13</strong></span> and <span class="strong"><strong>M14</strong></span>. The <code class="literal">getLikelihood</code> recursive method updates the lambda model matrices <span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span> and initial state probabilities <span class="emphasis"><em>pi</em></span> (line <code class="literal">28</code>). The likelihood for the sequence of states is recomputed using the forward-backward lattice algorithm implemented in the <code class="literal">frwrBckwrdLattice</code> method (line <code class="literal">29</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note21400"/>Note</h3><p>
<span class="strong"><strong>Update of lambda model</strong></span>
</p><p>The <code class="literal">update</code> method of the <code class="literal">HMMModel</code> object uses simple linear algebra and is not described; refer to the documented source code for details.</p></div><p>The core of the Baum-Welch expectation maximization is the iterative forward and backward update of the lattice of states and observations between time <span class="emphasis"><em>t</em></span> and <span class="emphasis"><em>t + 1</em></span>. The lattice-based iterative computation is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01438.jpeg" alt="The Baum-Welch estimator (EM)"/><div class="caption"><p>The visualization of the HMM graph lattice for the Baum-Welch algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>frwrdBckwrdLattice</strong></span>: Double  = {
  val _alpha = <span class="strong"><strong>Alpha</strong></span>(lambda, obsSeq) //<span class="strong"><strong>33</strong></span>
  val beta = <span class="strong"><strong>Beta</strong></span>(lambda, obsSeq).getTreillis //<span class="strong"><strong>34</strong></span>
  val alphas = _alpha.getTreillis
  gamma.update(alphas, beta) //<span class="strong"><strong>35</strong></span>
  diGamma.update(alphas, beta, lambda.A, lambda.B, obsSeq)
  _alpha.alpha
}</pre></div><p>The forward-backward <a id="id7410000" class="indexterm"/>algorithm <a id="id7420000" class="indexterm"/>uses the <code class="literal">Alpha</code> class for the computation/update of the <code class="literal">lambda</code> model in the forward pass(line <code class="literal">33</code>) and the <code class="literal">Beta</code> class for the update of <code class="literal">lambda</code> in the backward pass (line <code class="literal">34</code>). The joint probabilities-related <code class="literal">gamma</code> and <code class="literal">diGamma</code> matrices are updated at each recursion (line <code class="literal">35</code>), reflecting the iteration of the mathematical expressions <span class="strong"><strong>M11</strong></span> to <span class="strong"><strong>M14</strong></span>.</p><p>The recursive computation of <code class="literal">maxLikelihood</code> exists if the algorithm converges (line <code class="literal">30</code>). It throws an exception if the maximum number of recursions is exceeded (line <code class="literal">31</code>).</p></div></div><div class="section" title="Decoding – CF-3"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec8900"/>Decoding – CF-3</h2></div></div></div><p>This last<a id="id7430000" class="indexterm"/> canonical form consists of extracting the most <a id="id7440000" class="indexterm"/>likely sequence of states <span class="emphasis"><em>{q<sub>t</sub>}</em></span> given a set of observations <span class="emphasis"><em>O<sub>t</sub></em></span> and a <span class="emphasis"><em>λ</em></span> model. Solving this problem requires, once again, a recursive algorithm.</p><div class="section" title="The Viterbi algorithm"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10000"/>The Viterbi algorithm</h3></div></div></div><p>The extraction of the <a id="id7450000" class="indexterm"/>best state sequence (the sequence of a state that has the highest probability) is very time consuming. An alternative<a id="id7460000" class="indexterm"/> consists of applying a dynamic programming technique to find the best sequence <span class="emphasis"><em>{q<sub>t</sub>}</em></span> through iteration. This algorithm is known as the <span class="strong"><strong>Viterbi algorithm</strong></span>. Given a sequence of states <span class="emphasis"><em>{q<sub>t</sub>}</em></span> and sequence of observations <span class="emphasis"><em>{o<sub>j</sub>}</em></span>, the probability <span class="emphasis"><em>δ<sub>t</sub>(i)</em></span> for any sequence to have the highest probability path for the first <span class="emphasis"><em>T</em></span> observations is defined for the state <span class="emphasis"><em>S<sub>i</sub></em></span> [7:7].</p><div class="note" title="Note"><h3 class="title"><a id="note21500"/>Note</h3><p>
<span class="strong"><strong>The Viterbi algorithm</strong></span>
</p><p>M12: The definition of the delta function is as follows:</p><div class="mediaobject"><img src="../Images/image01439.jpeg" alt="The Viterbi algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M13: Initialization of delta is defined as:</p><div class="mediaobject"><img src="../Images/image01440.jpeg" alt="The Viterbi algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M14: Recursive computation of delta is defined as:</p><div class="mediaobject"><img src="../Images/image01441.jpeg" alt="The Viterbi algorithm"/></div><p style="clear:both; height: 1em;"> </p><p>M15: The computation of the optimum state sequence {q} is defined as:</p><div class="mediaobject"><img src="../Images/image01442.jpeg" alt="The Viterbi algorithm"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <code class="literal">ViterbiPath</code> class implements the Viterbi algorithm whose purpose is to compute the optimum sequence (or path) of states given a set of observations and a <span class="emphasis"><em>λ</em></span> model. The optimum sequence or path of states is computed by maximizing the delta function.</p><p>The constructors<a id="id7470000" class="indexterm"/> for the <code class="literal">ViterbiPath</code> class <a id="id7480000" class="indexterm"/>have the same arguments as the forward, backward, and Baum-Welch algorithm: the <code class="literal">lambda</code> model and the set of observations <code class="literal">obsSeq</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>ViterbiPath</strong></span>(<span class="strong"><strong>lambda</strong></span>: <code class="literal">HMMModel</code>, <span class="strong"><strong>obsSeq</strong></span>: Vector[Int]) {
  val nObs = lambda.numObs
  val nStates = lambda.numStates
  val <span class="strong"><strong>psi</strong></span> = Array.fill(nObs)(Array.fill(nStates)(0)) //<span class="strong"><strong>35</strong></span>
  val <span class="strong"><strong>qStar</strong></span> = new QStar(nObs, nStates) //<span class="strong"><strong>36</strong></span>
  
  val <span class="strong"><strong>delta</strong></span> = { //<span class="strong"><strong>37</strong></span>
    Range(0, nStates)./:(DMatrix(nObs, nStates))((m,n) =&gt; {
     psi(0)(n) = 0
     m += (0, n, lambda.pi(n) * lambda.B(n,obsSeq.head))
    })
  val <span class="strong"><strong>path</strong></span> = HMMPrediction(viterbi(1), qStar()) //<span class="strong"><strong>38</strong></span>
}</pre></div><p>As seen in the preceding information box containing the mathematical expressions for the Viterbi algorithm, the following matrices have to be defined:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">psi</code>: This <a id="id7490000" class="indexterm"/>is the matrix of indices of <code class="literal">nObs</code> observations by indices of <code class="literal">nStates</code> states (line <code class="literal">35</code>).</li><li class="listitem"><code class="literal">qStar</code>: This<a id="id7500000" class="indexterm"/> is the optimum sequence of states at each recursion of the Viterbi algorithm (line <code class="literal">36</code>).</li><li class="listitem"><code class="literal">delta</code>: This<a id="id7510000" class="indexterm"/> is the sequence that has the highest probability path for the first <span class="emphasis"><em>n</em></span> observations. It also sets the <code class="literal">psi</code> values for the first observation to 0 (line <code class="literal">37</code>).</li></ul></div><p>All members of the <code class="literal">ViterbiPath</code> class are private except <code class="literal">path</code> that defines the optimum sequence or path of states given the <code class="literal">obsSeq</code> observations (line <code class="literal">38</code>).</p><p>The matrix that defines the maximum probability <code class="literal">delta</code> of any sequence of states given the <code class="literal">lambda</code> model and the <code class="literal">obsSeq</code> observation is initialized using the mathematical expression <span class="strong"><strong>M13</strong></span> (line <code class="literal">37</code>). The predictive model returns the path or optimum sequence of states as an instance of <code class="literal">HMMPrediction</code>:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>HMMPrediction</strong></span>(likelihood: Double, states: Array[Int])</pre></div><p>The first argument of <code class="literal">likelihood</code> is computed by the <code class="literal">viterbi</code> recursive method. The indices of the states in the <code class="literal">states</code> optimum sequence is computed by the <code class="literal">QStar</code> class (line <code class="literal">38</code>).</p><p>Let's take a look under the hood of the Viterbi recursive method:</p><div class="informalexample"><pre class="programlisting">@<span class="strong"><strong>tailrec</strong></span>
def <span class="strong"><strong>viterbi</strong></span>(t: Int): Double = {
  Range(0, numStates).foreach( <span class="strong"><strong>updateMaxDelta</strong></span>(t, _)) //<span class="strong"><strong>39</strong></span>

  if( t == obsSeq.size-1) {  //<span class="strong"><strong>40</strong></span>
    val idxMaxDelta = Range(0, numStates)
                .map(i =&gt; (i, delta(t, i))).maxBy(_._2) //<span class="strong"><strong>41</strong></span>
    qStar.update(t+1, idxMaxDelta._1)  //<span class="strong"><strong>42</strong></span>
    idxMaxDelta._2
  }
  else <span class="strong"><strong>viterbi</strong></span>(t+1)  //<span class="strong"><strong>43</strong></span>
}</pre></div><p>The recursion <a id="id7520000" class="indexterm"/>started on the second observation as the <code class="literal">qStar</code>, <code class="literal">psi</code>, and <code class="literal">delta</code> parameters have already been initialized in the constructor. The <a id="id7530000" class="indexterm"/>recursive implementation invokes the <code class="literal">updateMaxDelta</code> method to update the <code class="literal">psi</code> indexing matrix and the highest probability for any state, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>updateMaxDelta</strong></span>(t: Int, j: Int): Unit = {.
   val idxDelta = Range(0, nStates)
        .map(i =&gt; (i, delta(t-1, i)*lambda.A(i, j)))
        .maxBy(_._2)   //<span class="strong"><strong>44</strong></span>
   psi(t)(j) = idxDelta._1
   delta += (t, j, idxDelta._2)  //<span class="strong"><strong>45</strong></span>
}</pre></div><p>The <code class="literal">updateMaxDelta</code> method implements the mathematical expression <span class="strong"><strong>M14</strong></span> that extracts the index of the state that maximizes <code class="literal">psi</code> (line <code class="literal">44</code>). The <code class="literal">delta</code> probability matrix and the <code class="literal">psi</code> indexing matrix are updated accordingly (line <code class="literal">45</code>).</p><p>The <code class="literal">viterbi</code> method is called recursively for the remaining observations except the last one (line <code class="literal">43</code>). At the last observation of the <code class="literal">obsSeq.size-1</code> index, the algorithm executes the mathematical expression <span class="strong"><strong>M15,</strong></span> which is implemented in the <code class="literal">QStar</code> class (line <code class="literal">42</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note21900"/>Note</h3><p>
<span class="strong"><strong>The QStar class</strong></span>
</p><p>The <code class="literal">QStar</code> class <a id="id7540000" class="indexterm"/>and its <code class="literal">update</code> method use linear algebra and are not described here; refer to the documented source code and Scaladocs files for details.</p></div><p>This implementation of the decoding form of the hidden Markov model completes the description of the <a id="id7550000" class="indexterm"/>hidden Markov model <a id="id7560000" class="indexterm"/>and its implementation in Scala. Now, let's put this knowledge into practice.</p></div></div><div class="section" title="Putting it all together"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9000"/>Putting it all together</h2></div></div></div><p>The main <code class="literal">HMM</code> class implements the <a id="id7570000" class="indexterm"/>three canonical forms. A view bound to an array of integers is used to parameterize the <code class="literal">HMM</code> class. We assume that a time series of continuous or pseudo-continuous values is quantized into discrete symbol values.</p><p>The <code class="literal">@specialized</code> annotation ensures that the byte code is generated for the <code class="literal">Array[Int]</code> primitive without executing the conversion implicitly declared by the bound view.</p><p>There are two modes that execute any of the three canonical forms of the hidden Markov model:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">ViterbiPath</code> class: The <a id="id7580000" class="indexterm"/>constructor initializes/trains a model similar to any other learning algorithm, as described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section of the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>. The constructor generates the model by executing the Baum-Welch algorithm. Once the model is successfully created, it can be used for decoding or evaluation.</li><li class="listitem">The <code class="literal">ViterbiPath</code> object: The<a id="id7590000" class="indexterm"/> companion provides the <code class="literal">decode</code> and <code class="literal">evaluate</code> methods for the decoding and evaluation of the sequence of observations using HMM.</li></ul></div><p>The two modes of operations are described in the following diagram:</p><div class="mediaobject"><img src="../Images/image01443.jpeg" alt="Putting it all together"/><div class="caption"><p>The computational flow for the hidden Markov model</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's complete our implementation of the HMM with the definition of its class. The <code class="literal">HMM</code> class is defined as a data transformation using a model implicitly generated from an <code class="literal">xt</code> training set, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">46</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>HMM</strong></span>[@specialized(Double) T &lt;: AnyVal](
    config: HMMConfig,
    <span class="strong"><strong>xt</strong></span>: XVSeries[T], 
    form: HMMForm)
    (implicit quantize: Array[T] =&gt; Int, f: T =&gt; Double) 
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with <span class="strong"><strong>Monitor</strong></span>[Double] {//<span class="strong"><strong>46</strong></span>

  type <span class="strong"><strong>V</strong></span> = HMMPrediction  //<span class="strong"><strong>47</strong></span>
  val obsSeq: Vector[Int] = xt.map(<span class="strong"><strong>quantize</strong></span>(_)) //<span class="strong"><strong>48</strong></span>

  val <span class="strong"><strong>model</strong></span>: Option[HMMModel] = train  //<span class="strong"><strong>49</strong></span>
  override def |&gt; : PartialFunction[U, Try[V]] //<span class="strong"><strong>50</strong></span>
}</pre></div><p>The <code class="literal">HMM</code> constructor takes<a id="id7600000" class="indexterm"/> the following four arguments (line <code class="literal">46</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This is<a id="id7610000" class="indexterm"/> the configuration of the HMM that is the dimension of <code class="literal">lambda</code> model and execution parameters</li><li class="listitem"><code class="literal">xt</code>: This is<a id="id7620000" class="indexterm"/> the multidimensional time series of observations whose features have the <code class="literal">T</code> type</li><li class="listitem"><code class="literal">form</code>: This is<a id="id7630000" class="indexterm"/> the canonical form to be used once the model is generated (evaluation or decoding)</li><li class="listitem"><code class="literal">quantize</code>: This is<a id="id7640000" class="indexterm"/> the quantization function that converts an observation of the <code class="literal">Array[T]</code> type to an <code class="literal">Int </code>type</li><li class="listitem"><code class="literal">f</code>: This is <a id="id7650000" class="indexterm"/>the implicit conversion from the <code class="literal">T</code> type to <code class="literal">Double</code></li></ul></div><p>The constructor has to override the <code class="literal">V</code> type (<code class="literal">HMMPrediction</code>) of the output data (line <code class="literal">47</code>) declared in the <code class="literal">ITransform</code> abstract class. The structure of the <code class="literal">HMMPrediction</code> class has been defined in the previous section.</p><p>The <code class="literal">Monitor</code> trait is used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The time series of <code class="literal">xt</code> observations is converted into a vector of <code class="literal">obsSeq</code> observed states by applying the <code class="literal">quantize</code> quantization function to each observation (line <code class="literal">48</code>).</p><p>As with any supervised learning technique, the model is created through training (line <code class="literal">49</code>). Finally, the <code class="literal">|&gt;</code> polymorphic predictor invokes either the <code class="literal">decode</code> method or the <code class="literal">evaluate</code> method (line <code class="literal">50</code>).</p><p>The <code class="literal">train</code> method consists of the execution of the Baum-Welch algorithm and returns the <code class="literal">lambda</code> model:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[HMMModel] = Try {
  BaumWelchEM(config, obsSeq).lambda }.toOption</pre></div><p>Finally. the <code class="literal">|&gt;</code>predictor is a simple wrapper to the evaluation form (<code class="literal">evaluate</code>) and the decoding form (<code class="literal">decode</code>):</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
  case x: Array[T] if(isModel &amp;&amp; x.length &gt; 1) =&gt; 
  form match {
    case _: EVALUATION =&gt; 
      <span class="strong"><strong>evaluation</strong></span>(model.get, Vector[Int](quantize(x))
    case _: DECODING =&gt; 
       <span class="strong"><strong>decoding</strong></span>(model.get, Vector[Int](quantize(x))
   }
}</pre></div><p>The <a id="id7660000" class="indexterm"/>protected <code class="literal">evaluation</code> method of the <code class="literal">HMM</code> companion object is a wrapper around the <code class="literal">Alpha</code> computation:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>evaluation</strong></span>(model: HMMModel, 
    obsSeq: Vector[Int]): Try[HMMPrediction] = Try {
  HMMPrediction(-<span class="strong"><strong>Alpha</strong></span>(model,obsSeq).logProb, obsSeq.toArray) 
}</pre></div><p>The <code class="literal">evaluate</code> method of the <code class="literal">HMM</code> object exposes the evaluation canonical form:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>evaluate</strong></span>[T &lt;: AnyVal]( model: HMMModel, 
    xt: XVSeries[T])(implicit quantize: Array[T] =&gt; Int, 
      f: T =&gt; Double): Option[HMMPrediction] =  
  <span class="strong"><strong>evaluation</strong></span>(model, xt.map(quantize(_))).toOption</pre></div><p>The <code class="literal">decoding</code> method wraps the Viterbi algorithm to extract the optimum sequence of states:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>decoding</strong></span>( model: HMMModel, obsSeq: Vector[Int]): 
     Try[HMMPrediction] = Try { 
  <span class="strong"><strong>ViterbiPath</strong></span>(model, obsSeq).path
}</pre></div><p>The <code class="literal">decode</code> method of the <code class="literal">HMM</code> object exposes the decoding canonical form:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>decode</strong></span>[T &lt;: AnyVal](model: HMMModel, 
    xt: XVSeries[T])(implicit quantize: Array[T] =&gt; Int,
    f: T =&gt; Double): Option[HMMPrediction] =
  <span class="strong"><strong>decoding</strong></span>(model, xt.map(quantize(_))).toOption</pre></div><div class="note" title="Note"><h3 class="title"><a id="note22000"/>Note</h3><p>
<span class="strong"><strong>Normalized probabilities input</strong></span>
</p><p>You need to make sure that the input probabilities for the <span class="emphasis"><em>λ</em></span> model for evaluating and decoding canonical forms are normalized—the sum of the probabilities of all the states for the <span class="emphasis"><em>π</em></span> vector and <span class="emphasis"><em>A</em></span> and <span class="emphasis"><em>B</em></span> matrices are equal to 1. This validation code is omitted in the example code.</p></div></div><div class="section" title="Test case 1 – training"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9100"/>Test case 1 – training</h2></div></div></div><p>Our first test case <a id="id7670000" class="indexterm"/>is to train an HMM to predict the sentiment of investors as measured by the weekly sentiment survey of the members of the <span class="strong"><strong>American Association of Individual Investors</strong></span> (<span class="strong"><strong>AAII</strong></span>) [7:8]. The goal is to compute the transition probabilities matrix <span class="emphasis"><em>A</em></span>, the emission probabilities matrix <span class="emphasis"><em>B</em></span>, and the steady state probability distribution <span class="emphasis"><em>π</em></span>, given the observations and hidden states (training canonical forms).</p><p>We assume that the change in investor sentiments is independent of time, as required by the hidden Markov model.</p><p>The AAII sentiment survey grades the bullishness on the market in terms of percentage:</p><div class="mediaobject"><img src="../Images/image01444.jpeg" alt="Test case 1 – training"/><div class="caption"><p>The weekly AAII market sentiment (reproduced by courtesy from AAII)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The sentiment of investors is known as a contrarian indicator of the future direction of the stock market. Refer to the <span class="emphasis"><em>Terminology</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>Let's select the ratio of the percentage of investors that are bullish over the percentage of investors that are bearish. The ratio is then normalized. The following table lists this:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Time</p>
</th><th valign="bottom">
<p>Bullish</p>
</th><th valign="bottom">
<p>Bearish</p>
</th><th valign="bottom">
<p>Neutral</p>
</th><th valign="bottom">
<p>Ratio</p>
</th><th valign="bottom">
<p>Normalized Ratio</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="strong"><strong>t0</strong></span>
</p>
</td><td valign="top">
<p>0.38</p>
</td><td valign="top">
<p>0.15</p>
</td><td valign="top">
<p>0.47</p>
</td><td valign="top">
<p>2.53</p>
</td><td valign="top">
<p>1.0</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>t1</strong></span>
</p>
</td><td valign="top">
<p>0.41</p>
</td><td valign="top">
<p>0.25</p>
</td><td valign="top">
<p>0.34</p>
</td><td valign="top">
<p>1.68</p>
</td><td valign="top">
<p>0.53</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>t2</strong></span>
</p>
</td><td valign="top">
<p>0.25</p>
</td><td valign="top">
<p>0.35</p>
</td><td valign="top">
<p>0.40</p>
</td><td valign="top">
<p>0.71</p>
</td><td valign="top">
<p>0.0</p>
</td></tr><tr><td valign="top">
<p>…</p>
</td><td valign="top">
<p>…</p>
</td><td valign="top">
<p>…</p>
</td><td valign="top">
<p>…</p>
</td><td valign="top">
<p>…</p>
</td><td valign="top">
<p>….</p>
</td></tr></tbody></table></div><p>The sequence <a id="id7680000" class="indexterm"/>of nonnormalized observations (the ratio of bullish sentiments over bearish sentiments) is defined in a CSV file as follows:</p><div class="informalexample"><pre class="programlisting">val OBS_PATH = "resources/data/chap7/obsprob.csv"
val NUM_SYMBOLS = 6
val NUM_STATES = 5
val EPS = 1e-4
val MAX_ITERS = 150
val <span class="strong"><strong>observations</strong></span> = Vector[Double](
   0.01, 0.72, 0.78, 0.56, 0.61, 0.56, 0.45, …  )

val <span class="strong"><strong>quantize</strong></span> = (x: DblArray) =&gt; 
      (x.head* (NUM_STATES+1)).floor.toInt  //<span class="strong"><strong>51</strong></span>
val xt = observations.map(Array[Double](_))

val <span class="strong"><strong>config</strong></span> = HMMConfig(xt.size, NUM_STATES, NUM_SYMBOLS, 
    MAX_ITERS, EPS)
val <span class="strong"><strong>hmm</strong></span> = HMM[Array[Int]](config,  <span class="strong"><strong>xt</strong></span>) //<span class="strong"><strong>52</strong></span>
show(s"Training):\n${hmm.model.toString}")</pre></div><p>The constructor for the <code class="literal">HMM</code> class requires a <code class="literal">T =&gt; Array[Int]</code> implicit conversion, which is implemented by the <code class="literal">quantize</code> function (line <code class="literal">51</code>). The <code class="literal">hmm.model</code> model is created by instantiating an <code class="literal">HMM</code> class with a predefined configuration and an <code class="literal">obsSeq</code> sequence of observed states (line <code class="literal">52</code>).</p><p>The training of the HMM generates the following state transition probabilities matrix:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>A</p>
</th><th valign="bottom">
<p>1</p>
</th><th valign="bottom">
<p>2</p>
</th><th valign="bottom">
<p>3</p>
</th><th valign="bottom">
<p>4</p>
</th><th valign="bottom">
<p>5</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="strong"><strong>1</strong></span>
</p>
</td><td valign="top">
<p>0.090</p>
</td><td valign="top">
<p>0.026</p>
</td><td valign="top">
<p>0.056</p>
</td><td valign="top">
<p>0.046</p>
</td><td valign="top">
<p>0.150</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>2</strong></span>
</p>
</td><td valign="top">
<p>0.094</p>
</td><td valign="top">
<p>0.123</p>
</td><td valign="top">
<p>0.074</p>
</td><td valign="top">
<p>0.058</p>
</td><td valign="top">
<p>0.0</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>3</strong></span>
</p>
</td><td valign="top">
<p>0.093</p>
</td><td valign="top">
<p>0.169</p>
</td><td valign="top">
<p>0.087</p>
</td><td valign="top">
<p>0.061</p>
</td><td valign="top">
<p>0.056</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>4</strong></span>
</p>
</td><td valign="top">
<p>0.033</p>
</td><td valign="top">
<p>0.342</p>
</td><td valign="top">
<p>0.017</p>
</td><td valign="top">
<p>0.031</p>
</td><td valign="top">
<p>0.147</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>5</strong></span>
</p>
</td><td valign="top">
<p>0.386</p>
</td><td valign="top">
<p>0.47</p>
</td><td valign="top">
<p>0.314</p>
</td><td valign="top">
<p>0.541</p>
</td><td valign="top">
<p>0.271</p>
</td></tr></tbody></table></div><p>The emission matrix is as follows:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>B</p>
</th><th valign="bottom">
<p>1</p>
</th><th valign="bottom">
<p>2</p>
</th><th valign="bottom">
<p>3</p>
</th><th valign="bottom">
<p>4</p>
</th><th valign="bottom">
<p>5</p>
</th><th valign="bottom">
<p>6</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="strong"><strong>1</strong></span>
</p>
</td><td valign="top">
<p>0.203</p>
</td><td valign="top">
<p>0.313</p>
</td><td valign="top">
<p>0.511</p>
</td><td valign="top">
<p>0.722</p>
</td><td valign="top">
<p>0.264</p>
</td><td valign="top">
<p>0.307</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>2</strong></span>
</p>
</td><td valign="top">
<p>0.149</p>
</td><td valign="top">
<p>0.729</p>
</td><td valign="top">
<p>0.258</p>
</td><td valign="top">
<p>0.389</p>
</td><td valign="top">
<p>0.324</p>
</td><td valign="top">
<p>0.471</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>3</strong></span>
</p>
</td><td valign="top">
<p>0.305</p>
</td><td valign="top">
<p>0.617</p>
</td><td valign="top">
<p>0.427</p>
</td><td valign="top">
<p>0.596</p>
</td><td valign="top">
<p>0.189</p>
</td><td valign="top">
<p>0.186</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>4</strong></span>
</p>
</td><td valign="top">
<p>0.207</p>
</td><td valign="top">
<p>0.312</p>
</td><td valign="top">
<p>0.351</p>
</td><td valign="top">
<p>0.653</p>
</td><td valign="top">
<p>0.358</p>
</td><td valign="top">
<p>0.442</p>
</td></tr><tr><td valign="top">
<p>
<span class="strong"><strong>5</strong></span>
</p>
</td><td valign="top">
<p>0.674</p>
</td><td valign="top">
<p>0.520</p>
</td><td valign="top">
<p>0.248</p>
</td><td valign="top">
<p>0.294</p>
</td><td valign="top">
<p>0.259</p>
</td><td valign="top">
<p>0.03</p>
</td></tr></tbody></table></div></div><div class="section" title="Test case 2 – evaluation"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9200"/>Test case 2 – evaluation</h2></div></div></div><p>The objective <a id="id7690000" class="indexterm"/>of the evaluation is to compute the probability of the <code class="literal">xt</code> observed data given a <span class="emphasis"><em>λ</em></span> model (<code class="literal">A0</code>, <code class="literal">B0</code>, and <code class="literal">PI0</code>):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>A0</strong></span> = Array[Array[Double]](
  Array[Double](0.21, 0.13, 0.25, 0.06, 0.11, 0.24),
  Array[Double](0.31, 0.17, 0.18, 0.04, 0.19, 0.11),
  …. 
) 
val <span class="strong"><strong>B0</strong></span> =  Array[Array[Double]](
  Array[Double](0.61, 0.39),
  Array[Double](0.54, 0.46),
  …  
)
val <span class="strong"><strong>PI0</strong></span> = Array[Double](
  0.26, 0.04, 0.11, 0.26, 0.19, 0.14)

val <span class="strong"><strong>xt</strong></span> = Vector[Double](
  0.0, 1.0, 21.0, 1.0, 30.0, 0.0, 1.0, 0.0, …
).map(Array[Double](_))
val max = data.max
val min = data.min
implicit val <span class="strong"><strong>quantize</strong></span> = (x: DblArray) =&gt; 
  ((x.head/(max - min) + min)*(B0.head.length-1)).toInt   //<span class="strong"><strong>55</strong></span>
val lambda = HMMModel(
  DMatrix(A0), DMatrix(B0), PI0, xt.length) //<span class="strong"><strong>53</strong></span>
evaluation(lambda, xt).map( _.toString).map(show(_)) //<span class="strong"><strong>54</strong></span>
</pre></div><p>The model is created directly by converting the <code class="literal">A0</code> state-transition probabilities and <code class="literal">B0</code> emission probabilities as matrices of the <code class="literal">DMatrix</code> type (line <code class="literal">53</code>). The evaluation method generates an <code class="literal">HMMPrediction</code> object, which is stringized, and then displays it in the standard output (line <code class="literal">54</code>).</p><p>The <code class="literal">quantization</code> method consists of normalizing the input data over the number (or range) of symbols associated with the <code class="literal">lambda</code> model. The number of symbols is the size of the rows of the emission probabilities matrix <span class="emphasis"><em>B</em></span>. In this case, the range of the input data is [0.0, 3.0]. The range is normalized using the linear transform <span class="emphasis"><em>f(x) = x/(max – min) + min</em></span>, then adjusted for the number of symbols (or values for states) (line <code class="literal">55</code>).</p><p>The <code class="literal">quantize</code> quantization function has to be explicitly defined before invoking the evaluation method.</p><div class="note" title="Note"><h3 class="title"><a id="note22100"/>Note</h3><p>
<span class="strong"><strong>Test case for decoding</strong></span>
</p><p>Refer to the source code and the API documents for the test case related to the decoding form.</p></div></div><div class="section" title="HMM as a filtering technique"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9300"/>HMM as a filtering technique</h2></div></div></div><p>The evaluation form <a id="id7700000" class="indexterm"/>of the hidden Markov model is very suitable for filtering data for discrete states. Contrary to time series filters such as the Kalman filter introduced in the <span class="emphasis"><em>The discrete Kalman filter</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>, the HMM requires data to be stationary in order to create a reliable model. However, the hidden Markov model overcomes some of the limitations of analytical time series analysis. Filters and smoothing techniques assume that the noise (frequency mean, variance, and covariance) is known and usually follows a Gaussian distribution.</p><p>The hidden Markov model does not have such a restriction. Filtering techniques, such as moving averaging techniques, discrete Fourier transforms, and Kalman filters apply to both discrete and continuous states while the HMM does not. Moreover, the extended Kalman filter can estimate nonlinear states.</p></div></div>
<div class="section" title="Conditional random fields"><div class="titlepage" id="aid-5PUTM2"><div><div><h1 class="title"><a id="ch07lvl1sec4800"/>Conditional random fields</h1></div></div></div><p>The<a id="id7710000" class="indexterm"/> <span class="strong"><strong>conditional random field</strong></span> (<span class="strong"><strong>CRF</strong></span>) is a discriminative machine learning algorithm introduced by John Lafferty, Andrew McCallum, and Fernando Pereira [7:9] at the turn of the century as an alternative to the HMM. The algorithm was originally developed to assign labels to a set of observation sequences.</p><p>Let's consider a concrete example to understand the conditional relation between the observations and the label data.</p><div class="section" title="Introduction to CRF"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9400"/>Introduction to CRF</h2></div></div></div><p>Let's consider <a id="id7720000" class="indexterm"/>the problem of detecting a foul during a soccer game using a combination of video and audio. The objective is to assist the referee and analyze the behavior of the players to determine whether an action on the field is dangerous (red card), inappropriate (yellow card), in doubt to be replayed, or legitimate. The following image is an example of the segmentation of a video frame for image processing:</p><div class="mediaobject"><img src="../Images/image01445.jpeg" alt="Introduction to CRF"/><div class="caption"><p>An example of an image processing problem requiring machine learning</p></div></div><p style="clear:both; height: 1em;"> </p><p>The analysis of <a id="id7730000" class="indexterm"/>the video consists of segmenting each video frame and extracting image features such as colors or edges [7:10]. A simple segmentation scheme consists of breaking down each video frame into tiles or groups of pixels indexed by their coordinates on the screen. A time sequence is then created for each tile <span class="emphasis"><em>S<sub>ij</sub></em></span>, as represented in the following image:</p><div class="mediaobject"><img src="../Images/image01446.jpeg" alt="Introduction to CRF"/><div class="caption"><p>The learning strategy for pixels in a sequence of video frames</p></div></div><p style="clear:both; height: 1em;"> </p><p>The image segment <span class="emphasis"><em>S<sub>ij</sub></em></span> is one of the labels that is associated with multiple observations. The same features extraction process applies to the audio associated with the video. The relation between the video/image segment and the hidden state of the altercation between the soccer players is illustrated in the following model graph:</p><div class="mediaobject"><img src="../Images/image01447.jpeg" alt="Introduction to CRF"/><div class="caption"><p>The undirected graph representation of CRF for the soccer infraction detection</p></div></div><p style="clear:both; height: 1em;"> </p><p>CRFs are <a id="id7740000" class="indexterm"/>discriminative models that can be regarded as a structured output extension of the logistic regression. CRFs address the problem of labeling a sequence of data, such as assigning a tag to each word in a sentence. The objective is to estimate the correlation among the output (observed) values <span class="emphasis"><em>Y</em></span> that are conditional on the input values (features) <span class="emphasis"><em>X</em></span>.</p><p>The correlation between the output and input values is described as a <a id="id7750000" class="indexterm"/>graph (also known as a <span class="strong"><strong>graph-structured CRF</strong></span>). A good example of graph-structured CRFs are cliques. Cliques are sets of connected nodes in a graph for which each vertex has an edge connecting it to every other vertex in the clique.</p><p>Such models are complex and their implementation is challenging. Most real-world problems related to time series or ordered sequences of data can be solved as a correlation between a linear sequence of observations and a linear sequence of input data, which is similar to the HMM. Such a model is known as the<a id="id7760000" class="indexterm"/> <span class="strong"><strong>linear chain structured graph CRF</strong></span> or <a id="id7770000" class="indexterm"/><span class="strong"><strong>linear chain CRF</strong></span> for short:</p><div class="mediaobject"><img src="../Images/image01448.jpeg" alt="Introduction to CRF"/><div class="caption"><p>An illustration of a nonlinear and linear chain CRF</p></div></div><p style="clear:both; height: 1em;"> </p><p>One main advantage of the linear chain CRF is that the maximum likelihood <span class="emphasis"><em>p(Y|X, w)</em></span> can be estimated using dynamic programming techniques such as the Viterbi algorithm used in the HMM. From now on, the section focuses exclusively on the linear chain CRF in order to stay <a id="id7780000" class="indexterm"/>consistent with the HMM, as described in the previous section.</p></div><div class="section" title="Linear chain CRF"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9500"/>Linear chain CRF</h2></div></div></div><p>Let's consider a <a id="id7790000" class="indexterm"/>random variable <span class="emphasis"><em>X={x<sub>i</sub>}<sub>0:n-1</sub></em></span> representing <span class="emphasis"><em>n</em></span> observations and a random variable <span class="emphasis"><em>Y</em></span> representing a corresponding sequence of labels <span class="emphasis"><em>Y={y<sub>j</sub>}<sub>0:n-1</sub></em></span>. The hidden Markov model estimates the joint probability <span class="emphasis"><em>p(X,Y)</em></span>, as any generative model requires the enumeration of all the sequences of observations.</p><p>If each element of <span class="emphasis"><em>Y</em></span>, <span class="emphasis"><em>y<sub>j</sub></em></span>, obeys the first order of the Markov property, then <span class="emphasis"><em>(Y, X)</em></span> is a CRF. The likelihood is defined as a conditional probability <span class="emphasis"><em>p(Y|X, w)</em></span>, where <span class="emphasis"><em>w</em></span> is the model parameters vector.</p><div class="note" title="Note"><h3 class="title"><a id="note22200"/>Note</h3><p>
<span class="strong"><strong>Observation dependencies</strong></span>
</p><p>The purpose of CRF models is to estimate the maximum likelihood of <span class="emphasis"><em>p(Y|X, w)</em></span>. Therefore, independence between <span class="emphasis"><em>X</em></span> observations is not required.</p></div><p>A graphical model is a probabilistic model for which a graph denotes the conditional independence between random variables (vertices). The conditional and joint probabilities of random variables are represented as edges. The graph for generic conditional random fields can indeed be complex. The most common and simplistic graph is the linear chain CRF.</p><p>A first order linear chain conditional random field can be visualized as an undirected graphical model, which illustrates the conditional probability of a label <span class="emphasis"><em>Y<sub>j</sub></em></span> given a set of observations <span class="emphasis"><em>X</em></span>:</p><div class="mediaobject"><img src="../Images/image01449.jpeg" alt="Linear chain CRF"/><div class="caption"><p>A linear, conditional, random field undirected graph</p></div></div><p style="clear:both; height: 1em;"> </p><p>The Markov property simplifies the conditional probabilities of <span class="emphasis"><em>Y</em></span>, given <span class="emphasis"><em>X</em></span>, by considering only the neighbor labels <span class="emphasis"><em>p(Y<sub>1</sub>|X, Y<sub>j</sub> j ≠1) = p(Y<sub>1</sub>|X, Y<sub>0</sub>, Y<sub>2</sub>) and p(Y<sub>i</sub>|X, Y<sub>j</sub> j ≠i) = p(Y<sub>i</sub>|X, Y<sub>i-1</sub>, Y<sub>i+1</sub>)</em></span>.</p><p>The conditional random fields<a id="id7800000" class="indexterm"/> introduce a new set of entities and a new terminology:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Potential functions</strong></span> (<span class="emphasis"><em>f</em></span><span class="emphasis"><em><sub>i</sub></em></span>): These <a id="id7810000" class="indexterm"/>strictly positive and real value functions represent a set of constraints on the configurations of random variables. They do not have any obvious probabilistic interpretation.</li><li class="listitem"><span class="strong"><strong>Identity potential functions</strong></span>: These <a id="id7820000" class="indexterm"/>are potential functions <span class="emphasis"><em>I(x, t)</em></span> that take 1 if the condition on the feature <span class="emphasis"><em>x</em></span> at time <span class="emphasis"><em>t</em></span> is true, and 0 otherwise.</li><li class="listitem"><span class="strong"><strong>Transition feature functions</strong></span>: Simply <a id="id7830000" class="indexterm"/>known as feature functions, <span class="emphasis"><em>t<sub>i</sub></em></span>, are potential functions that take a sequence of features <span class="emphasis"><em>{X<sub>i</sub>}</em></span>, the previous label <span class="emphasis"><em>Y<sub>t-1</sub></em></span>, the current label <span class="emphasis"><em>Y<sub>t</sub></em></span>, and an index <span class="emphasis"><em>i</em></span>. The transition feature function outputs a real value function. In a text analysis, a transition feature function would be defined by a sentence as a sequence of observed features, the previous word, the current word, and a position of a word in a sentence. Each transition feature function is assigned a weight that is similar to the weights or parameters in the logistic regression. Transition feature functions play a similar role to the state transition factors <span class="emphasis"><em>a<sub>ij</sub></em></span> in the HMM but without a direct probabilistic interpretation.</li><li class="listitem"><span class="strong"><strong>State feature functions</strong></span> (<span class="emphasis"><em>s<sub>j</sub></em></span>): These <a id="id7840000" class="indexterm"/>are potential functions that take the sequence of features <span class="emphasis"><em>{X<sub>i</sub>}</em></span>, the current label <span class="emphasis"><em>Y<sub>i</sub></em></span>, and the index <span class="emphasis"><em>i</em></span>. They play a similar role to the emission factors in the HMM.</li></ul></div><p>A CRF defines the log probability of a particular label sequence <span class="emphasis"><em>Y</em></span>, given a sequence of observations <span class="emphasis"><em>X</em></span> as the normalized product of the transition feature and state feature functions. In other words, the likelihood of a particular sequence <span class="emphasis"><em>Y</em></span>, given the observed features <span class="emphasis"><em>X</em></span>, is a logistic regression.</p><p>The mathematical notation to compute the conditional probabilities in the case of a first order linear chain CRF is described in the following information box:</p><div class="note" title="Note"><h3 class="title"><a id="note22300"/>Note</h3><p>
<span class="strong"><strong>The CRF conditional distribution</strong></span>
</p><p>M1: The log probability of a label's sequence <span class="emphasis"><em>y</em></span>, given an observation <span class="emphasis"><em>x</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01450.jpeg" alt="Linear chain CRF"/></div><p style="clear:both; height: 1em;"> </p><p>M2: Transition feature functions are defined as:</p><div class="mediaobject"><img src="../Images/image01451.jpeg" alt="Linear chain CRF"/></div><p style="clear:both; height: 1em;"> </p><p>M3: Using the notation:</p><div class="mediaobject"><img src="../Images/image01452.jpeg" alt="Linear chain CRF"/></div><p style="clear:both; height: 1em;"> </p><p>M4: The conditional distribution of labels <span class="emphasis"><em>y</em></span>, given <span class="emphasis"><em>x</em></span>, using the Markov property is defined as:</p><div class="mediaobject"><img src="../Images/image01453.jpeg" alt="Linear chain CRF"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <a id="id7850000" class="indexterm"/>weights <span class="emphasis"><em>w<sub>j</sub></em></span> are sometimes referred as <span class="emphasis"><em>λ</em></span> in scientific papers, which may confuse the reader; <span class="emphasis"><em>w</em></span> is used to avoid any confusion with the <span class="emphasis"><em>λ</em></span> regularization factor.</p><p>Now, let's get acquainted with the conditional random fields algorithm and its implementation by Sunita Sarawagi.</p></div></div>
<div class="section" title="Regularized CRFs and text analytics"><div class="titlepage" id="aid-5QTE82"><div><div><h1 class="title"><a id="ch07lvl1sec4900"/>Regularized CRFs and text analytics</h1></div></div></div><p>Most of the<a id="id7860000" class="indexterm"/> examples used to demonstrate the capabilities of conditional random fields are related to text mining, intrusion detection, or <a id="id7870000" class="indexterm"/>bioinformatics. Although these applications have a great commercial merit, they are not suitable for introductory test cases because they usually require a lengthy description of the model and the training process.</p><div class="section" title="The feature functions model"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9600"/>The feature functions model</h2></div></div></div><p>For our example, we<a id="id7880000" class="indexterm"/> will select a simple problem: how to collect and aggregate an analyst's recommendation on any given stock from different sources with different formats.</p><p>Analysts at brokerage firms and investment funds routinely publish the list of recommendations or ratings for any stock. These analysts use different rating schemes from buy/hold/sell, A/B/C rating, and stars rating, to market perform/neutral/market underperform rating. For this example, the rating is normalized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">0 for a strong sell (F or 1 star rating)</li><li class="listitem">1 for sell (D, 2 stars, or marker underperform)</li><li class="listitem">2 for neutral (C, hold, 3 stars, market perform, and so on)</li><li class="listitem">3 for buy (B, 4 stars, market overperform, and so on)</li><li class="listitem">4 for strong buy (A, 5 stars, highly recommended, and so on)</li></ul></div><p>Here are examples of recommendations by stock analysts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>Macquarie upgraded AUY from Neutral to Outperform rating</em></span></li><li class="listitem"><span class="emphasis"><em>Raymond James initiates Ainsworth Lumber as Outperform</em></span></li><li class="listitem"><span class="emphasis"><em>BMO Capital Markets upgrades Bear Creek Mining to Outperform</em></span></li><li class="listitem"><span class="emphasis"><em>Goldman Sachs adds IBM to its conviction list</em></span></li></ul></div><p>The objective is to extract the name of the financial institution that publishes the recommendation or rating, the stock rated, the previous rating, if available, and the new rating. The output can be inserted into a database for further trend analysis, prediction, or simply the creation of reports.</p><div class="note" title="Note"><h3 class="title"><a id="note22800"/>Note</h3><p>
<span class="strong"><strong>The scope of the application</strong></span>
</p><p>Ratings from analysts are updated every day through different protocols (feed, e-mails, blogs, web pages, and so on). The data has to be extracted from HTML, JSON, plain text, or XML format before being processed. In this exercise, we assume that the input has already been converted into plain text (ASCII) using a regular expression or another classifier.</p></div><p>The first step<a id="id7890000" class="indexterm"/> is to define the labels <span class="emphasis"><em>Y</em></span> representing the categories or semantics of the rating. A segment or sequence is defined as a recommendation sentence. After reviewing the different recommendations, we are able to specify the following seven labels:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Source of the recommendation (Goldman Sachs and so on)</li><li class="listitem">Action (upgrades, initiates, and so on)</li><li class="listitem">Stock (either the company name or the stock ticker symbol)</li><li class="listitem">From (an optional keyword)</li><li class="listitem">Rating (an optional previous rating)</li><li class="listitem">To</li><li class="listitem">Rating (the new rating for the stock)</li></ul></div><p>The training set is generated from the raw data by <span class="emphasis"><em>tagging</em></span> the different components of the recommendation. The first (or initial) rating for a stock does not have the labels 4 and 5 from the preceding list defined.</p><p>Consider the following example:</p><div class="informalexample"><pre class="programlisting">Citigroup // Y(0) = 1 
upgraded // Y(1) 
Macys // Y(2) 
from // Y(3) 
Buy // Y(4) 
to // Y(5)
Strong Buy //Y(6) = 7</pre></div><div class="note" title="Note"><h3 class="title"><a id="note22900"/>Note</h3><p>
<span class="strong"><strong>Tagging</strong></span>
</p><p>Tagging as a word may have a different meaning depending on the context. In <a id="id7900000" class="indexterm"/><span class="strong"><strong>natural language processing</strong></span> (<span class="strong"><strong>NLP</strong></span>), tagging refers to the process of assigning an attribute (an adjective, pronoun, verb, proper name, and so on) to a word in a sentence [7:11].</p></div><p>A training sequence can be visualized in the following undirected graph:</p><div class="mediaobject"><img src="../Images/image01454.jpeg" alt="The feature functions model"/><div class="caption"><p>An example of a recommendation as a CRF training sequence</p></div></div><p style="clear:both; height: 1em;"> </p><p>You may <a id="id7910000" class="indexterm"/>wonder why we need to tag the <span class="emphasis"><em>From</em></span> and <span class="emphasis"><em>To</em></span> labels in the creation of the training set. The reason is that these keywords may not always be stated and/or their positions in the recommendation differ from one source to another.</p></div><div class="section" title="Design"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9700"/>Design</h2></div></div></div><p>The implementation <a id="id7920000" class="indexterm"/>of the conditional random fields follows the design template for classifiers, which is described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section under <span class="emphasis"><em>Source code considerations</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>Its key components are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A <code class="literal">CrfModel</code> model of the <code class="literal">Model</code> type is initialized through training during the instantiation of the classifier. A model is an array of <code class="literal">weights</code>.</li><li class="listitem">The predictive or classification routine is implemented as an implicit data transformation of the <code class="literal">ITransform</code> type.</li><li class="listitem">The <code class="literal">Crf</code> conditional random field classifier has four parameters: the number of labels (or number of features), <code class="literal">nLabels</code>, configuration of the <code class="literal">CrfConfig</code> type, the sequence of delimiters of the <code class="literal">CrfSeqDelimiter</code> type, and a vector of name of files <code class="literal">xt</code> that contains the tagged observations.</li><li class="listitem">The <code class="literal">CrfAdapter</code> class interfaces with the IITB CRF library.</li><li class="listitem">The <code class="literal">CrfTagger</code> class extracts features from the tagged files.</li></ul></div><p>The key software components of the conditional random fields are described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01455.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the conditional random fields</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram<a id="id7930000" class="indexterm"/> omits the utility traits and classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9800"/>Implementation</h2></div></div></div><p>The test case uses <a id="id7940000" class="indexterm"/>the IIT-B's CRF Java implementation from the Indian Institute of Technology Bombay by Sunita Sarawagi. The JAR files can be downloaded from SourceForge (<a class="ulink" href="http://sourceforge.net/projects/crf/">http://sourceforge.net/projects/crf/</a>).</p><p>The library is available as JAR files and source code. Some of the functionalities, such as the selection of a training algorithm, is not available through the API. The components (JAR files) of the library are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A CRF for the implementation of the CRF algorithm</li><li class="listitem">LBFGS for limited-memory Broyden-Fletcher-Goldfarb-Shanno nonlinear optimization of convex functions (used in training)</li><li class="listitem">The CERN Colt library for the manipulation of a matrix</li><li class="listitem">The GNU generic hash container for indexing</li></ul></div><div class="section" title="Configuring the CRF classifier"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10100"/>Configuring the CRF classifier</h3></div></div></div><p>Let's take a look at the<a id="id7950000" class="indexterm"/> <code class="literal">Crf</code> class that implements the conditional random fields classifier. The <code class="literal">Crf</code> class is defined as a data transformation of the <code class="literal">ITransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">2</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Crf</strong></span>(<span class="strong"><strong>nLabels</strong></span>: Int, <span class="strong"><strong>config</strong></span>: CrfConfig, 
    <span class="strong"><strong>delims</strong></span>: CrfSeqDelimiter, <span class="strong"><strong>xt</strong></span>: Vector[String])//<span class="strong"><strong>1</strong></span>
  extends <span class="strong"><strong>ITransform</strong></span>[String](xt) with <span class="strong"><strong>Monitor</strong></span>[Double]{//<span class="strong"><strong>2</strong></span>

  type V = Double  //<span class="strong"><strong>3</strong></span>
  val tagsGen = new CrfTagger(nLabels) //<span class="strong"><strong>4</strong></span>
  val crf = CrfAdapter(nLabels, tagsGen, config.params) //<span class="strong"><strong>5</strong></span>
  val <span class="strong"><strong>model</strong></span>: Option[CrfModel] = train //<span class="strong"><strong>6</strong></span>
  weights: Option[DblArray] = model.map( _.weights)

  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[String, Try[V]] //<span class="strong"><strong>7</strong></span>
}</pre></div><p>The constructor <a id="id7960000" class="indexterm"/>for <code class="literal">Crf</code> has the following four arguments (line <code class="literal">1</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">nLabels</code>: These are the number of labels used for the classification</li><li class="listitem"><code class="literal">config</code>: This is the configuration parameter used to train <code class="literal">Crf</code></li><li class="listitem"><code class="literal">delims</code>: These are the delimiters used in raw and tagged files</li><li class="listitem"><code class="literal">xt</code>: This is a vector of name of files that contains raw and tagged data</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note23000"/>Note</h3><p>
<span class="strong"><strong>Filenames for raw and tagged data</strong></span>
</p><p>For the sake of simplicity, the files for the raw observations and the tagged observations have the same name with different extensions: <code class="literal">filename.raw</code> and <code class="literal">filename.tagged</code>.</p></div><p>The <code class="literal">Monitor</code> trait is used to collect the profiling information during training (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The <code class="literal">V</code> type of the output of the <code class="literal">|&gt;</code> predictor is defined as <code class="literal">Double</code> (line <code class="literal">3</code>).</p><p>The execution of the CRF algorithm is controlled by a wide variety of configuration parameters encapsulated in the <code class="literal">CrfConfig</code> configuration class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>CrfConfig</strong></span>(<span class="strong"><strong>w0</strong></span>: Double, maxIters: Int, <span class="strong"><strong>lambda</strong></span>: Double, 
     <span class="strong"><strong>eps</strong></span>: Double) extends Config { //<span class="strong"><strong>8</strong></span>
  val params = s"""initValue $w0 maxIters $maxIters
     | lambda $lambda scale true eps $eps""".stripMargin
}</pre></div><p>For the sake of simplicity, we use the default <code class="literal">CrfConfig</code> configuration parameters to control the execution of the learning algorithm, with the exception of the following four variables (line <code class="literal">8</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Initialization of the <code class="literal">w0</code> weight that uses either a predefined or random value between 0 and 1 (default 0)</li><li class="listitem">The maximum number of iterations,<code class="literal"> maxIters</code>, that is used in the computation of the weights during the learning phase (default 50)</li><li class="listitem">The <code class="literal">lamdba</code> scaling factor for the L2 penalty function that is used to reduce observations with a high value (default 1.0)</li><li class="listitem">The <code class="literal">eps</code> convergence criteria that is used to compute the optimum values for the <code class="literal">wj</code> weights (default 1e-4)</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note23100"/>Note</h3><p>
<span class="strong"><strong>The L<sub>2</sub></strong></span>
<span class="strong"><strong> regularization</strong></span>
</p><p>This implementation of the conditional random fields support the L<sub>2</sub> regularization, as described in the <span class="emphasis"><em>Regularization</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>. The regularization is turned off by setting <span class="emphasis"><em>λ = 0</em></span>.</p></div><p>The <code class="literal">CrfSeqDelimiter</code> case<a id="id7970000" class="indexterm"/> class specifies the following regular expressions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">obsDelim</code> to parse each observation in the raw files</li><li class="listitem"><code class="literal">labelsDelim</code> to parse each labeled record in the tagged files</li><li class="listitem"><code class="literal">seqDelim</code> to extract records from raw and tagged files</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>CrfSeqDelimiter</strong></span>(obsDelim: String, 
    labelsDelim: String, seqDelim: String)</pre></div><p>The <code class="literal">DEFAULT_SEQ_DELIMITER</code> instance is the default sequence delimiter used in this implementation:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>DEFAULT_SEQ_DELIMITER</strong></span> = 
   new CrfSeqDelimiter(",\t/ -():.;'?#`&amp;_", "//", "\n") </pre></div><p>The <code class="literal">CrfTagger</code> tag or label generator iterates through the tagged file and applies the relevant regular expressions of <code class="literal">CrfSeqDelimiter</code> to extract the symbols used in training (line <code class="literal">4</code>).</p><p>The <code class="literal">CrfAdapter</code> object defines the different interfaces to the IITB CRF library (line <code class="literal">5</code>). The factory for CRF instances is implemented by the <code class="literal">apply</code> constructor as follows:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>CrfAdapter</strong></span> {
  import iitb.CRF.CRF
    def <span class="strong"><strong>apply</strong></span>(nLabels: Int, tagger: CrfTagger, 
     config: String): CRF = new <span class="strong"><strong>CRF</strong></span>(nLabels, tagger, config)
  …
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note23200"/>Note</h3><p>
<span class="strong"><strong>Adapter classes to the IITB CRF library</strong></span>
</p><p>The training of the conditional random field for sequences requires to define a few key interfaces:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">DataSequence</code> to specify the mechanism to access observations and labels for training and testing data</li><li class="listitem"><code class="literal">DataIter</code> to iterate through the sequence of data created using the <code class="literal">DataSequence</code> interface</li><li class="listitem"><code class="literal">FeatureGenerator</code> to aggregate all the feature types</li></ul></div><p>These interfaces have default implementations bundled in the CRF Java library [7:12]. Each of these interfaces have to be implemented as adapter classes:</p><div class="informalexample"><pre class="programlisting">class CrfTagger(nLabels: Int) extends FeatureGenerator
class CrfDataSeq(nLabels: Int, tags: Vector[String], delim: String) extends DataSequence
class CrfSeqIter(nLabels: Int, input: String, delim: CrfSeqDelimiter) extends DataIter</pre></div><p>Refer to the documented source code and Scaladocs files for the description and implementation of these adapter classes.</p></div></div><div class="section" title="Training the CRF model"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10200"/>Training the CRF model</h3></div></div></div><p>The objective <a id="id7980000" class="indexterm"/>of the training is to compute the weights <span class="emphasis"><em>w<sub>j</sub></em></span> that maximize the conditional log-likelihood function without the L<sub>2</sub> penalty function. Maximizing the log-likelihood function is equivalent to minimizing the loss with the L<sub>2</sub> penalty. The function is convex, and therefore, any variant gradient descent (greedy) algorithm can be applied iteratively.</p><div class="note" title="Note"><h3 class="title"><a id="note23500"/>Note</h3><p>M5: The conditional log-likelihood for a linear chain CRF training set <span class="emphasis"><em>D = {xi, yi}</em></span> is given as follows:</p><div class="mediaobject"><img src="../Images/image01456.jpeg" alt="Training the CRF model"/></div><p style="clear:both; height: 1em;"> </p><p>M6: Maximization of the loss function and L2 penalty is given as follows:</p><div class="mediaobject"><img src="../Images/image01457.jpeg" alt="Training the CRF model"/></div><p style="clear:both; height: 1em;"> </p></div><p>The training<a id="id7990000" class="indexterm"/> file consists of a pair of files:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Raw datasets</strong></span>: Recommendations (such as <span class="emphasis"><em>Raymond James upgrades Gentiva Health Services from Underperform to Market perform</em></span>)</li><li class="listitem"><span class="strong"><strong>Tagged datasets</strong></span>: Tagged recommendations (such as <span class="emphasis"><em>Raymond James [1] upgrades [2] Gentiva Health Services [3], from [4] Underperform [5] to [6] Market perform [7]</em></span>)</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note23800"/>Note</h3><p>
<span class="strong"><strong>Tags type</strong></span>
</p><p>In this implementation, the tags have the <code class="literal">Int</code> type. However, alternative types, such as enumerators or even continuous values (that is, <code class="literal">Double</code>) can be used.</p></div><p>The training or computation of weights can be quite expensive. It is highly recommended that you distribute the observations and tagged observations dataset across multiple files, so they can be processed concurrently:</p><div class="mediaobject"><img src="../Images/image01458.jpeg" alt="Training the CRF model"/><div class="caption"><p>The distribution of the computation of the weights of the CRF</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">train</code> method creates the model by computing the <code class="literal">weights</code> of the CRF. It is invoked by the constructor of <code class="literal">Crf</code>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[<span class="strong"><strong>CrfModel</strong></span>] = Try {
  val weights = if(xt.size == 1)  //<span class="strong"><strong>9</strong></span>
    <span class="strong"><strong>computeWeights</strong></span>(xt.head) 
  else {
    val weightsSeries = xt.map( <span class="strong"><strong>computeWeights</strong></span>(_) )
    <span class="strong"><strong>statistics</strong></span>(weightsSeries).map(_.mean).toArray //<span class="strong"><strong>10</strong></span>
  }
  new <span class="strong"><strong>CrfModel</strong></span>(weights) //<span class="strong"><strong>11</strong></span>
}._toOption("Crf training failed", logger)</pre></div><p>We cannot<a id="id8000000" class="indexterm"/> assume that there is only one tagged dataset (that is, a single pair of <code class="literal">*.raw</code> and <code class="literal">*.tagged</code> files) (line <code class="literal">9</code>). The <code class="literal">computeWeights</code> method used for computation of weights for the CRF is applied to the first dataset if there is only one pair of raw and tagged file. In the case of multiple datasets, the <code class="literal">train</code> method computes the mean of all the weights extracted from each tagged dataset (line <code class="literal">10</code>). The mean of the weights are computed using the <code class="literal">statistics</code> method of the <code class="literal">XTSeries</code> object, which was introduced in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>. The <code class="literal">train</code> method returns <code class="literal">CrfModel</code> if successful, and <code class="literal">None</code> otherwise (line <code class="literal">11</code>).</p><p>For efficiency purpose, the map should be parallelized using the <code class="literal">ParVector</code> class as follows:</p><div class="informalexample"><pre class="programlisting">val parXt = xt.<span class="strong"><strong>par</strong></span>
val pool = new ForkJoinPool(nTasks)
v.tasksupport = new ForkJoinTaskSupport(pool)
parXt.map(<span class="strong"><strong>computeWeights</strong></span>(_) )</pre></div><p>The parallel collections are described in detail in the <span class="emphasis"><em>Parallel collections</em></span> section under <span class="emphasis"><em>Scala</em></span> in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note23900"/>Note</h3><p>
<span class="strong"><strong>CRF weights computation</strong></span>
</p><p>It is assumed that input tagged files share the same list of tags or symbols, so each dataset produces the same array of weights.</p></div><p>The <code class="literal">computeWeights</code> method extracts the weights from each pair of observations and tagged observation files. It invokes the <code class="literal">train</code> method of the <code class="literal">CrfTagger</code> tag generator (line <code class="literal">12</code>) to prepare, normalize, and set up the training set, and then invokes the training procedure on the IITB <code class="literal">CRF</code> class (line <code class="literal">13</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>computeWeights</strong></span>(tagsFile: String): DblArray = {
  val seqIter = <span class="strong"><strong>CrfSeqIter</strong></span>(nLabels, tagsFile, delims)
  tagsGen.<span class="strong"><strong>train</strong></span>(seqIter)  //<span class="strong"><strong>12</strong></span>
  crf.<span class="strong"><strong>train</strong></span>(seqIter)  //<span class="strong"><strong>13</strong></span>
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note24000"/>Note</h3><p>
<span class="strong"><strong>The scope of the IITB CRF Java library evaluation</strong></span>
</p><p>The CRF library has been evaluated with three simple text analytics test cases. Although the library is certainly robust enough to illustrate the internal workings of the CRF, I cannot vouch for its scalability or applicability in other fields of interests, such as bioinformatics or process control.</p></div></div><div class="section" title="Applying the CRF model"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10300"/>Applying the CRF model</h3></div></div></div><p>The predictive method<a id="id8010000" class="indexterm"/> implements the <code class="literal">|&gt; </code>data transformation operator. It takes a new observation (the analyst's recommendation on a stock) and returns the maximum likelihood, as shown here:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[String, Try[V]] = {
   case <span class="strong"><strong>obs</strong></span>: String if( !obs.isEmpty &amp;&amp; isModel) =&gt; {
     val <span class="strong"><strong>dataSeq</strong></span> = new CrfDataSeq(nLabels,obs,delims.obsDelim)
     Try (crf.apply(dataSeq)) //<span class="strong"><strong>14</strong></span>
   }
}</pre></div><p>The <code class="literal">|&gt;</code> method merely creates a <code class="literal">dataSeq</code> data sequence and invokes the constructor of the IITB <code class="literal">CRF</code> class (line <code class="literal">14</code>). The condition on the <code class="literal">obs</code> input argument to the partial function is rather rudimentary. A more elaborate condition of the observation should be implemented using a regular expression. The code to validate the arguments/parameters of the class and methods are omitted along with the exception handler for the sake of readability.</p><div class="note" title="Note"><h3 class="title"><a id="note24100"/>Note</h3><p>
<span class="strong"><strong>An advanced CRF configuration</strong></span>
</p><p>The CRF model of the <span class="strong"><strong>IITB</strong></span> library is highly configurable. It allows developers to specify a state-label undirected graph with any combination of flat and nested dependencies between states. The source code includes several training algorithms such as the exponential gradient.</p></div></div></div><div class="section" title="Tests"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec9900"/>Tests</h2></div></div></div><p>The client code to<a id="id8020000" class="indexterm"/> execute the test consists of defining the number of labels, <code class="literal">NLABELS</code> (that is, the number of tags for recommendation), the <code class="literal">LAMBDA</code> L2 penalty factor, the maximum of iterations, <code class="literal">MAX_ITERS</code>, allowed in the minimization of the loss function, and the <code class="literal">EPS</code> convergence criteria:</p><div class="informalexample"><pre class="programlisting">val LAMBDA = 0.5
val NLABELS = 9
val MAX_ITERS = 100
val W0 = 0.7
val EPS = 1e-3
val PATH = "resources/data/chap7/rating"
val OBS_DELIM = ",\t/ -():.;'?#`&amp;_"

val <span class="strong"><strong>config</strong></span> = CrfConfig(W0 , MAX_ITERS, LAMBDA, EPS) //<span class="strong"><strong>15</strong></span>
val <span class="strong"><strong>delims</strong></span> = CrfSeqDelimiter(DELIM,"//","\n") //<span class="strong"><strong>16</strong></span>
val <span class="strong"><strong>crf</strong></span> = Crf(NLABELS, config, delims, PATH) //<span class="strong"><strong>17</strong></span>
crf.weights.map( display(_) )</pre></div><p>The three simple steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Instantiate the <code class="literal">config</code> configuration for the CRF (line <code class="literal">15</code>)</li><li class="listitem">Define the three <code class="literal">delims</code> delimiters to extract the tagged data (line <code class="literal">16</code>)</li><li class="listitem">Instantiate and train the CRF classifier, <code class="literal">crf</code> (line <code class="literal">17</code>)</li></ol><div style="height:10px; width: 1px"/></div><p>For these tests, the<a id="id8030000" class="indexterm"/> initial value of the weights (with respect to the maximum number of iterations for the maximization of the log likelihood and the convergence criteria) are set to 0.7 (with respect to 100 and 1e-3). The delimiters for labels sequence, observed features sequence, and the training set are customized for the format of <code class="literal">rating.raw</code> and <code class="literal">rating.tagged</code> input data files.</p><div class="section" title="The training convergence profile"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10400"/>The training convergence profile</h3></div></div></div><p>The first training<a id="id8040000" class="indexterm"/> run discovered 136 features from 34 analysts' stock recommendations. The algorithm converged after 21 iterations. The value of the log of the likelihood for each of those iterations is plotted to illustrate the convergence toward a solution of optimum <span class="emphasis"><em>w</em></span>:</p><div class="mediaobject"><img src="../Images/image01459.jpeg" alt="The training convergence profile"/><div class="caption"><p>The visualization of the log conditional probability of a CRF during training</p></div></div><p style="clear:both; height: 1em;"> </p><p>The training<a id="id8050000" class="indexterm"/> phase converges quickly toward a solution. It can be explained by the fact that there is little variation in the six-field format of the analyst's recommendations. A loose or free-style format would require a larger number of iterations during training to converge.</p></div><div class="section" title="Impact of the size of the training set"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10500"/>Impact of the size of the training set</h3></div></div></div><p>The second test <a id="id8060000" class="indexterm"/>evaluates the impact of the size of the training set on the convergence of the training algorithm. It consists of computing the difference <span class="emphasis"><em>Δw</em></span> of the model parameters (weights) between two consecutive iterations <span class="emphasis"><em>{w<sub>i</sub>}<sub>t+1</sub></em></span> and <span class="emphasis"><em>{w<sub>i</sub>}<sub>t</sub></em></span>:</p><div class="mediaobject"><img src="../Images/image01460.jpeg" alt="Impact of the size of the training set"/></div><p style="clear:both; height: 1em;"> </p><p>The test is run on 163 randomly chosen recommendations using the same model but with two different training sets:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">34 analysts' stock recommendations</li><li class="listitem">55 stock recommendations</li></ul></div><p>The larger training set is a superset of the 34 recommendations' set. The following graph illustrates the comparison of features generated with 34 and 55 CRF training sequences:</p><div class="mediaobject"><img src="../Images/image01461.jpeg" alt="Impact of the size of the training set"/><div class="caption"><p>The convergence of the CRF weight using training sets of different sizes</p></div></div><p style="clear:both; height: 1em;"> </p><p>The disparity between<a id="id8070000" class="indexterm"/> the test runs using two different sizes of training sets is very small. This can be easily explained by the fact that there is a small variation in the format between the analyst's recommendations.</p></div><div class="section" title="Impact of the L2 regularization factor"><div class="titlepage"><div><div><h3 class="title"><a id="ch07lvl3sec10600"/>Impact of the L<sub>2</sub> regularization factor</h3></div></div></div><p>The third test <a id="id8080000" class="indexterm"/>evaluates the impact of the L<sub>2</sub> regularization penalty on the convergence toward the optimum weights/features. The test is similar to the first test with a different value of <span class="emphasis"><em>λ</em></span>. The following chart plots <span class="emphasis"><em>log [p(Y|X, w)]</em></span> for different values of <span class="emphasis"><em>λ = 1/σ2</em></span> (0.2, 0.5, and 0.8):</p><div class="mediaobject"><img src="../Images/image01462.jpeg" alt="Impact of the L2 regularization factor"/><div class="caption"><p>The impact of the L2 penalty on the convergence of the CRF training algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>The log of the<a id="id8090000" class="indexterm"/> conditional probability decreases or the conditional probability increases with the number of iterations. The lower the L<sub>2</sub> regularization factor, the higher the conditional probability.</p><p>The variation of the analysts' recommendations within the training set is small, which limits the risk of overfitting. A free-style recommendation format would have been more sensitive to overfitting.</p></div></div></div>
<div class="section" title="Comparing CRF and HMM" id="aid-5RRUQ1"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec5000"/>Comparing CRF and HMM</h1></div></div></div><p>The cost/benefit analysis <a id="id8100000" class="indexterm"/>of discriminative models relative to generative models applies to the comparison of the conditional random field with the hidden Markov model.</p><p>Contrary to the hidden Markov model, the conditional random field does not require the observations to be independent (conditional probability). The conditional random field can be regarded as a generalization of the HMM by extending the transition probabilities to arbitrary feature functions that can depend on the input sequence. The HMM assumes the transition probabilities matrix to be constant.</p><p>The HMM learns the transition probabilities <span class="emphasis"><em>a<sub>ij</sub></em></span> on its own by processing more training data. The HMM<a id="id8110000" class="indexterm"/> can be regarded as a special case of CRF where the probabilities used in the state transition are constant.</p></div>
<div class="section" title="Performance consideration" id="aid-5SQFC1"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec5100"/>Performance consideration</h1></div></div></div><p>The time complexity for <a id="id8120000" class="indexterm"/>decoding and evaluating canonical forms of the hidden Markov model for <span class="emphasis"><em>N</em></span> states and <span class="emphasis"><em>T</em></span> observations is <span class="emphasis"><em>O(N<sub>2</sub>T)</em></span>. The training of the HMM using the Baum-Welch algorithm is <span class="emphasis"><em>O(N<sub>2</sub>TM)</em></span>, where <span class="emphasis"><em>M</em></span> is the number of iterations.</p><p>There are several options to improve the performance of the HMM:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Avoid unnecessary multiplication by 0 in the emission probabilities matrix by either using sparse matrices or tracking the null entries.</li><li class="listitem">Train the HMM on the most <span class="emphasis"><em>relevant</em></span> subset of the training data. This technique can be particularly effective in the case of tagging of words or a bag of words in natural language processing.</li></ul></div><p>The training of the linear chain conditional random fields is implemented using the same dynamic programming techniques as the HMM implementation (Viterbi, forward-backward passes, and so on). Its time complexity for training <span class="emphasis"><em>T</em></span> data sequences, <span class="emphasis"><em>N</em></span> labels (or expected outcomes), and <span class="emphasis"><em>M</em></span> weights/features <span class="emphasis"><em>λ</em></span> is <span class="emphasis"><em>O(MTN<sub>2</sub>)</em></span>.</p><p>The time complexity of the training of a CRF can be reduced by distributing the computation of the log likelihood and gradient over multiple nodes using a framework such as Akka or Apache Spark, as described in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span> [7:13].</p></div>
<div class="section" title="Summary" id="aid-5TOVU1"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec5200"/>Summary</h1></div></div></div><p>In this chapter, we had a closer look at modeling sequences of observations with hidden (or latent) states with the two commonly used algorithms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The generative hidden Markov model to maximize <span class="emphasis"><em>p(X,Y)</em></span></li><li class="listitem">The discriminative conditional random field to maximize <span class="emphasis"><em>log p(Y|X)</em></span></li></ul></div><p>The HMM is a special form of Bayes network. It requires the observations to be independent. Although restrictive, the conditional independence prerequisites make the HMM fairly easy to understand and validate, which is not the case for a CRF.</p><p>You learned how to implement three dynamic programming techniques: Viterbi, Baum-Welch, and alpha/beta algorithms in Scala. These algorithms are used to solve diverse type of optimization problems. They should be an essential component of your algorithmic tool box.</p><p>The conditional random field relies on the logistic regression to estimate the optimal weights of the model. Such a technique is also used in the multiple layer perceptron, which was introduced in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Network</em></span>. The next chapter introduces two important alternatives to the logistic regression for discriminating between observations: the Kernel function for nonlinear models and the maximization of the margin between classes of observations.</p></div>
<div class="chapter" title="Chapter&#xA0;8.&#xA0;Kernel Models and Support Vector Machines"><div class="titlepage" id="aid-5UNGG2"><div><div><h1 class="title"><a id="ch22"/>Chapter 8. Kernel Models and Support Vector Machines</h1></div></div></div><p>This chapter introduces kernel functions, binary support vectors classifiers, one-class support vector machines for anomaly detection, and support vector regression.</p><p>In the <span class="emphasis"><em>Binomial classification</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>, you learned the concept of hyperplanes to segregate observations from the training set and estimate the linear decision boundary. The logistic regression has at least one limitation: it requires that the datasets be linearly separated using a defined function (sigmoid). This limitation is especially an issue for high-dimension problems (large number of features that are highly nonlinearly dependent). <span class="strong"><strong>Support vector machines</strong></span> (<span class="strong"><strong>SVMs</strong></span>) overcome this limitation by<a id="id8130000" class="indexterm"/> estimating the optimal separating hyperplane using kernel functions.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The impact of some of the SVM configuration parameters and the kernel method on the accuracy of the classification</li><li class="listitem">How to apply the binary support vector classifier to estimate the risk for a public company to curtail or eliminate its dividend</li><li class="listitem">How to detect outliers with a one-class support vector classifier</li><li class="listitem">How the support vector regression is compared to the linear regression</li></ul></div><p>Support vector machines are formulated as a convex optimization problem. The mathematical foundation of the related algorithms is described in this chapter, for reference.</p><div class="section" title="Kernel functions"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec5300"/>Kernel functions</h1></div></div></div><p>Every<a id="id8140000" class="indexterm"/> machine learning model introduced in this book so far assumes that observations are represented by a feature vector of a fixed size. However, some real-world applications such as text mining or genomics do not lend themselves to this restriction. The critical element of the process of classification is to define a similarity<a id="id8150000" class="indexterm"/> or distance between two observations. Kernel functions allow developers to compute the similarity between observations without the need to encode them in feature vectors [8:1].</p><div class="section" title="An overview"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10000"/>An overview</h2></div></div></div><p>The concept of kernel methods may be a bit odd at first to a novice. Let's consider the example of the classification of proteins. Proteins have different lengths and compositions, but they do not prevent scientists from classifying them [8:2].</p><div class="note" title="Note"><h3 class="title"><a id="note24200"/>Note</h3><p>
<span class="strong"><strong>Proteins</strong></span>
</p><p>Proteins are polymers of amino acids joined together by peptide bonds. They are composed of a carbon atom bonded to a hydrogen atom, another amino acid, or a carboxyl group.</p></div><p>A protein is represented using a traditional molecular notation to which biochemists are familiar. Geneticists describe proteins in terms of a sequence of characters known as the <a id="id8160000" class="indexterm"/><span class="strong"><strong>protein sequence annotation</strong></span>. The sequence annotation encodes the structure and composition of the protein. The following image illustrates the molecular (left) and encoded (right) representation of a protein:</p><div class="mediaobject"><img src="../Images/image01463.jpeg" alt="An overview"/><div class="caption"><p>The sequence annotation of a protein</p></div></div><p style="clear:both; height: 1em;"> </p><p>The classification and the clustering of a set of proteins require the definition of a similarity factor or distance used to evaluate and compare the proteins. For example, the similarity between three proteins can be defined as a normalized dot product of their sequence annotation:</p><div class="mediaobject"><img src="../Images/image01464.jpeg" alt="An overview"/><div class="caption"><p>The similarity between the sequence annotations of three proteins</p></div></div><p style="clear:both; height: 1em;"> </p><p>You do not have to<a id="id8170000" class="indexterm"/> represent the entire sequence annotation of the proteins as a feature vector in order to establish that they belong to the same class. You only need to compare each element of each sequence, one by one, and compute the similarity. For the same reason, the estimation of the similarity does not require the two proteins to have the same length.</p><p>In this example, we do not have to assign a numerical value to each element of the annotation. Let's consider an element of the protein annotation as its character <span class="emphasis"><em>c</em></span> and position <span class="emphasis"><em>p</em></span> (for example, K, 4). The dot product of the two protein annotations <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>x'</em></span> of the respective lengths <span class="emphasis"><em>n</em></span> and <span class="emphasis"><em>n'</em></span> are defined as the number of identical elements (character and position) between the two annotations divided by the maximum length between the two annotations (<span class="strong"><strong>M1</strong></span>):</p><div class="mediaobject"><img src="../Images/image01465.jpeg" alt="An overview"/></div><p style="clear:both; height: 1em;"> </p><p>The computation of the similarity for the three proteins produces the result as <span class="emphasis"><em>sim(x,x')=6/12 = 0.50</em></span>, <span class="emphasis"><em>sim(x,x'')=3/13 =0.23</em></span>, and <span class="emphasis"><em>sim(x',x'')= 4/13= 0.31</em></span>.</p><p>Another similar aspect is that the similarity of two identical annotations is 1.0 and the similarity of two completely different annotations is 0.0.</p><div class="note" title="Note"><h3 class="title"><a id="note24300"/>Note</h3><p>
<span class="strong"><strong>The visualization of similarity</strong></span>
</p><p>It is usually more convenient to use a radial representation to visualize the similarity between features, as in the example of proteins' annotations. The distance <span class="emphasis"><em>d(x,x') = 1/sim(x,x')</em></span> is visualized as the angle or cosine between two features. The cosine metric is commonly used in text mining.</p></div><p>In this example, the<a id="id8180000" class="indexterm"/> similarity is known as a kernel function in the space of the sequence annotation of proteins.</p></div><div class="section" title="Common discriminative kernels"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10100"/>Common discriminative kernels</h2></div></div></div><p>Although <a id="id8190000" class="indexterm"/>the measure of similarity is very useful to understand the concept of a kernel function, kernels have a broader definition. A<a id="id8200000" class="indexterm"/> kernel <span class="emphasis"><em>K(x, x')</em></span> is a symmetric, nonnegative real function that takes two real arguments (values of two features). There are many different types of kernel functions, among which the most common are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The linear kernel</strong></span> (<span class="strong"><strong>dot product</strong></span>): This <a id="id8210000" class="indexterm"/>is useful in the case of very high-dimensional data where problems can be expressed as a linear combination of the original features.</li><li class="listitem"><span class="strong"><strong>The polynomial kernel</strong></span>: This<a id="id8220000" class="indexterm"/> extends the linear kernel for a combination of features that are not completely linear.</li><li class="listitem"><span class="strong"><strong>The radial basis function</strong></span> (<span class="strong"><strong>RBF</strong></span>): This<a id="id8230000" class="indexterm"/> is the most commonly applied kernel. It is used where the labeled or target data is noisy and requires some level of regularization.</li><li class="listitem"><span class="strong"><strong>The sigmoid kernel</strong></span>: This is <a id="id8240000" class="indexterm"/>used in conjunction with neural networks.</li><li class="listitem"><span class="strong"><strong>The Laplacian kernel</strong></span>: This <a id="id8250000" class="indexterm"/>is a variant of RBF with a higher regularization impact on training data.</li><li class="listitem"><span class="strong"><strong>The log kernel</strong></span>: This is <a id="id8260000" class="indexterm"/>used in image processing.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note24400"/>Note</h3><p>
<span class="strong"><strong>The RBF terminology</strong></span>
</p><p>In this presentation and the library used in its implementation, the radial basis function is a synonym to the Gaussian kernel function. However, RBF also refers to the family of exponential kernel functions that encompasses Gaussian, Laplacian, and exponential functions.</p></div><p>The simple linear model for regression consists of the dot product of the regression parameters (weights) and the input data (refer to the <span class="emphasis"><em>Ordinary least squares regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</p><p>The model <a id="id8270000" class="indexterm"/>is, in fact, the linear combination of weights and linear combination of inputs. The concept can be extended by defining a general regression model as the linear combination of nonlinear functions, known as basis functions (<span class="strong"><strong>M2</strong></span>):</p><div class="mediaobject"><img src="../Images/image01466.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>The most <a id="id8280000" class="indexterm"/>commonly used basis functions are the power and Gaussian functions. The kernel function is described as the dot product of the two vectors of the basis function <span class="emphasis"><em>φ(x).φ(x')</em></span> of two features vectors <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>x'</em></span>. A partial list of kernel methods is as follows:</p><div class="note" title="Note"><h3 class="title"><a id="note24500"/>Note</h3><p>M3: The generic kernel function is defined as:</p><div class="mediaobject"><img src="../Images/image01467.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M4: The linear kernel is defined as:</p><div class="mediaobject"><img src="../Images/image01468.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M5: The polynomial kernel with the slope <span class="emphasis"><em>γ</em></span>, degree <span class="emphasis"><em>n</em></span>, and constant <span class="emphasis"><em>c</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01469.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M6: The sigmoid kernel with the slope <span class="emphasis"><em>γ</em></span> and constant <span class="emphasis"><em>c</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01470.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M7: The radial basis function kernel with the slope <span class="emphasis"><em>γ</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01471.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M8: The Laplacian kernel with the slope <span class="emphasis"><em>γ</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01472.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p><p>M9: The log kernel with the degree <span class="emphasis"><em>n</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01473.jpeg" alt="Common discriminative kernels"/></div><p style="clear:both; height: 1em;"> </p></div><p>The list<a id="id8290000" class="indexterm"/> of <a id="id8300000" class="indexterm"/>discriminative kernel functions described earlier is just a subset of the kernel methods' universe. The other types of kernels include the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Probabilistic kernels</strong></span>: These <a id="id8310000" class="indexterm"/>are kernels derived from generative models. Probabilistic models such as Gaussian processes can be used as a kernel function [8:3].</li><li class="listitem"><span class="strong"><strong>Smoothing kernels</strong></span>: This<a id="id8320000" class="indexterm"/> is the nonparametric formulation, averaging density with the nearest neighbor observations [8:4].</li><li class="listitem"><span class="strong"><strong>Reproducible kernel Hilbert spaces</strong></span>: This <a id="id8330000" class="indexterm"/>is the dot product of finite or infinite basis functions [8:5].</li></ul></div><p>The kernel functions play a very important role in support vector machines for nonlinear problems.</p></div><div class="section" title="Kernel monadic composition"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10200"/>Kernel monadic composition</h2></div></div></div><p>The <a id="id8340000" class="indexterm"/>concept of a kernel function is actually derived from differential geometry and more specifically from manifold, which was introduced in the <span class="emphasis"><em>Non-linear models</em></span> section under <span class="emphasis"><em>Dimension reduction</em></span> in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>.</p><p>A manifold is a low dimension features space embedded in the observation space of higher dimension. The dot (or inner) product of two observations, known as the <a id="id8350000" class="indexterm"/><span class="strong"><strong>Riemann metric,</strong></span> is computed on a Euclidean tangent space.</p><div class="note" title="Note"><h3 class="title"><a id="note25200"/>Note</h3><p>
<span class="strong"><strong>The heat kernel function</strong></span>
</p><p>The kernel function on a manifold is actually computed by solving the heat equation that uses the Laplace-Beltrami operator. The heat kernel is the solution of the heat differential equation. It associates the dot product with an exponential map.</p></div><p>The kernel function is the composition of the dot product on the tangent space projected on the manifold using an exponential map, as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01474.jpeg" alt="Kernel monadic composition"/><div class="caption"><p>The visualization of a manifold, Riemann metric, and projection of an inner product</p></div></div><p style="clear:both; height: 1em;"> </p><p>A kernel function is the composition <span class="emphasis"><em>g o f</em></span> of two functions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A function <span class="emphasis"><em>h</em></span> that implements the Riemann metric or similarity between two vectors <span class="emphasis"><em>v</em></span> and <span class="emphasis"><em>w</em></span></li><li class="listitem">A function <span class="emphasis"><em>g</em></span> that implements the projection of the similarity <span class="emphasis"><em>h(v, w)</em></span> to the manifold (exponential map)</li></ul></div><p>The <code class="literal">KF</code> class implements the kernel function as a composition of the functions <span class="emphasis"><em>g</em></span> and <span class="emphasis"><em>h</em></span>:</p><div class="informalexample"><pre class="programlisting">type F1 = Double =&gt; Double
type F2 = (Double, Double) =&gt; Double

case class <span class="strong"><strong>KF</strong></span>[G](val g: G, h: F2) {
  def <span class="strong"><strong>metric</strong></span>(v: DblVector, w: DblVector)
      (implicit gf: G =&gt; F1): Double =  //<span class="strong"><strong>1</strong></span>
    g(v.zip(w).map{ case(_v, _w) =&gt; h(_v, _w)}.sum) //<span class="strong"><strong>2</strong></span>
}</pre></div><p>The <code class="literal">KF</code> class <a id="id8360000" class="indexterm"/>is parameterized with a <code class="literal">G</code> type that can be converted to <code class="literal">Function1[Double, Double]</code>. Therefore, the computation of <code class="literal">metric</code> (dot product) requires an implicit conversion from <code class="literal">G</code> to <code class="literal">Function1</code> (line <code class="literal">1</code>). The <code class="literal">metric</code> is computed by zipping the two vectors, mapping the <code class="literal">h</code> similarity function, and summing up the resulting vector (line <code class="literal">2</code>).</p><p>Let's define the monadic composition for the <code class="literal">KF</code> class:</p><div class="informalexample"><pre class="programlisting">val kfMonad = new _<span class="strong"><strong>Monad</strong></span>[KF] {
  override def <span class="strong"><strong>map</strong></span>[G,H](kf: KF[G])(f: G =&gt;H): KF[H] = 
     KF[H](f(kf.g), kf.h) //<span class="strong"><strong>3</strong></span>
  override def <span class="strong"><strong>flatMap</strong></span>[G,H](kf: KF[G])(f: G =&gt;KF[H]): KF[H] =
     KF[H](f(kf.g).g, kf.h)
}</pre></div><p>The creation of the <code class="literal">kfMonad</code> instance overrides the <code class="literal">map</code> and <code class="literal">flatMap</code> methods defined in the generic <code class="literal">_Monad</code> trait, as described in the <span class="emphasis"><em>Monads</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>. The implementation of the <code class="literal">unit</code> method is not essential to the monadic composition and it is, therefore, omitted.</p><p>The function argument of the <code class="literal">map</code> and <code class="literal">flatMap</code> methods applies only to the exponential map function <span class="emphasis"><em>g</em></span> (line <code class="literal">3</code>). The composition of two kernel functions <span class="emphasis"><em>kf1 = g1 o h</em></span> and <span class="emphasis"><em>kf2 = g2 o h</em></span> produces a kernel function <span class="emphasis"><em>kf3 = g2 o (g1 o h) = (g2 o g1) o h = g3 o h</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note25300"/>Note</h3><p>
<span class="strong"><strong>Interpretation of kernel functions' monadic composition</strong></span>
</p><p>The visualization of the monadic composition of kernel functions on the manifold is quite intuitive. The composition of two kernel functions consists of composing their respective projections or exponential map functions <span class="emphasis"><em>g</em></span>. The function <span class="emphasis"><em>g</em></span> is directly related to the curvature of the manifold around the data point for which the metric is computed. The monadic composition of the kernel functions attempts to adjust the exponential map to fit the curvature of the manifold.</p></div><p>The next step is to define an implicit class to convert a kernel function of the <code class="literal">KF</code> type to its monadic representation so that it can access the <code class="literal">map</code> and <code class="literal">flatMap</code> methods (line <code class="literal">4</code>):</p><div class="informalexample"><pre class="programlisting">implicit class kF2Monad[G](kf: <span class="strong"><strong>KF</strong></span>[G]) {  //<span class="strong"><strong>4</strong></span>
  def <span class="strong"><strong>map</strong></span>[H](f: G =&gt;H): KF[H] = kfMonad.map(kf)(f)
  def <span class="strong"><strong>flatMap</strong></span>[H](f: G =&gt;KF[H]): KF[H] =kfMonad.flatMap(kf)(f)
}</pre></div><p>Let's implement <a id="id8370000" class="indexterm"/>the <code class="literal">RBF</code> radial basis function and the polynomial kernel function, <code class="literal">Polynomial</code>, by defining their respective <span class="emphasis"><em>g</em></span> and <span class="emphasis"><em>h</em></span> functions. The parameterized type for the kernel function is simply <code class="literal">Function1[Double, Double]</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>RBF</strong></span>(s2: Double) extends KF[F1](
    (x: Double) =&gt; Math.exp(-0.5*x*x/s2), 
    (x: Double, y: Double) =&gt; x -y)
class <span class="strong"><strong>Polynomial</strong></span>(d: Int) extends KF[F1](
    (x: Double) =&gt; Math.pow(1.0+x, d), 
    (x: Double, y: Double) =&gt; x*y)</pre></div><p>Here is an example of the composition of two kernel functions: a <code class="literal">kf1</code> kernel RBF with a standard deviation of <code class="literal">0.6</code> (line <code class="literal">5</code>) and a <code class="literal">kf2</code> polynomial kernel with a degree <code class="literal">3</code> (line <code class="literal">6</code>):</p><div class="informalexample"><pre class="programlisting">val v = Vector[Double](0.5, 0.2, 0.3)
val w = Vector[Double](0.1, 0.7, 0.2)
val <span class="strong"><strong>composed</strong></span> = for {
  kf1 &lt;- new RBF(0.6)  //<span class="strong"><strong>5</strong></span>
  kf2 &lt;- new Polynomial(3)  //<span class="strong"><strong>6</strong></span>
} yield kf2
composed.<span class="strong"><strong>metric</strong></span>(v, w) //<span class="strong"><strong>7</strong></span>
</pre></div><p>Finally, the <code class="literal">metric</code> is computed on the <code class="literal">composed</code> kernel functions (line <code class="literal">7</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note25400"/>Note</h3><p>
<span class="strong"><strong>Kernel functions in SVM</strong></span>
</p><p>Our implementation of the support vector machine uses the kernel function included in the LIBSVM library.</p></div></div></div></div>
<div class="section" title="Support vector machines"><div class="titlepage" id="aid-5VM122"><div><div><h1 class="title"><a id="ch08lvl1sec5400"/>Support vector machines</h1></div></div></div><p>A <a id="id8380000" class="indexterm"/>support vector machine is a linear discriminative classifier that attempts to maximize the margin between classes during training. This approach is similar to the definition of a hyperplane through the training of the logistic regression (refer to the <span class="emphasis"><em>Binomial classification</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>). The main difference is that the support vector machine computes the optimum separating hyperplane between groups or classes of observations. The hyperplane is indeed the equation that represents the model generated through training.</p><p>The quality of the SVM depends on the distance, known as margin, between the different classes of observations. The accuracy of the classifier increases as the margin increases.</p><div class="section" title="The linear SVM"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10300"/>The linear SVM</h2></div></div></div><p>First, let's <a id="id8390000" class="indexterm"/>apply the support vector machine to <a id="id8400000" class="indexterm"/>extract a linear model (classifier or regression) for a labeled set of observations. There are two scenarios for defining a linear model. The labeled observations are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">They are naturally segregated in the features space (the <span class="strong"><strong>separable</strong></span> case)</li><li class="listitem">They are intermingled with overlap (the <span class="strong"><strong>nonseparable</strong></span> case)</li></ul></div><p>It is easy to understand the concept of an optimal separating hyperplane in cases where the observations are naturally segregated.</p><div class="section" title="The separable case – the hard margin"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec10700"/>The separable case – the hard margin</h3></div></div></div><p>The concept <a id="id8410000" class="indexterm"/>of separating a training set of observations with a hyperplane is explained in a better way with a two-dimensional <span class="emphasis"><em>(x, y)</em></span> set of observations with two classes <span class="emphasis"><em>C<sub>1</sub></em></span> and <span class="emphasis"><em>C<sub>2</sub></em></span>. The label <span class="emphasis"><em>y</em></span> has the value -1 or +1.</p><p>The equation for the separating hyperplane is defined by the linear equation <span class="emphasis"><em>y=w.x<sub>T</sub></em></span>
<span class="emphasis"><em>+w<sub>0</sub></em></span>, which sits in the midpoint between the boundary data points for the class <span class="emphasis"><em>C<sub>1</sub> (H<sub>1</sub>: w.x
<sup>T</sup> + w<sub>0</sub> + 1=0</em></span>) and class <span class="emphasis"><em>C<sub>2</sub> (H<sub>2</sub>: w.x<sup>T</sup> + w<sub>0</sub> - 1</em></span>). The planes <span class="emphasis"><em>H<sub>1</sub></em></span> and <span class="emphasis"><em>H<sub>2</sub></em></span> are the support vectors:</p><div class="mediaobject"><img src="../Images/image01475.jpeg" alt="The separable case – the hard margin"/><div class="caption"><p>The visualization of the hard margin in the support vector machine</p></div></div><p style="clear:both; height: 1em;"> </p><p>In the separable case, the <a id="id8420000" class="indexterm"/>support vectors fully segregate the observations into two distinct classes. The margin between the two support vectors is the same for all the observations and is known as the <a id="id8430000" class="indexterm"/><span class="strong"><strong>hard margin</strong></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note25500"/>Note</h3><p>
<span class="strong"><strong>The separable case</strong></span>
</p><p>M1: The support vectors equation <span class="emphasis"><em>w</em></span> is represented as:</p><div class="mediaobject"><img src="../Images/image01476.jpeg" alt="The separable case – the hard margin"/></div><p style="clear:both; height: 1em;"> </p><p>M2: The hard margin optimization problem is given by:</p><div class="mediaobject"><img src="../Images/image01477.jpeg" alt="The separable case – the hard margin"/></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="The nonseparable case – the soft margin"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec10800"/>The nonseparable case – the soft margin</h3></div></div></div><p>In the <a id="id8440000" class="indexterm"/>nonseparable case, the support vectors cannot completely segregate observations through training. They merely become linear functions that penalize the few observations or outliers that are located outside (or beyond) their respective support vector <span class="emphasis"><em>H<sub>1</sub></em></span> or <span class="emphasis"><em>H<sub>2</sub></em></span>. The penalty variable <span class="emphasis"><em>ξ</em></span>, also known as the slack variable, increases if the outlier is further away from the support vector:</p><div class="mediaobject"><img src="../Images/image01478.jpeg" alt="The nonseparable case – the soft margin"/><div class="caption"><p>The visualization of the hard margin in the support vector machine</p></div></div><p style="clear:both; height: 1em;"> </p><p>The observations that belong to the appropriate (or own) class do not have to be penalized. The condition is similar to the hard margin, which means that the slack <span class="emphasis"><em>ξ</em></span> is null. This technique penalizes the observations that belong to the class but are located beyond their support vectors; the slack <span class="emphasis"><em>ξ</em></span> increases as the observations get closer to the support vector of the other class and beyond. The margin is then known as a <a id="id8450000" class="indexterm"/>soft margin because the separating hyperplane is enforced through a slack variable.</p><div class="note" title="Note"><h3 class="title"><a id="note25700"/>Note</h3><p>
<span class="strong"><strong>The nonseparable case</strong></span>
</p><p>M3: The optimization of the soft margin for a linear SVM with <span class="emphasis"><em>C</em></span> formulation is defined as:</p><div class="mediaobject"><img src="../Images/image01479.jpeg" alt="The nonseparable case – the soft margin"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>C</em></span> is the penalty (or inversed regularization) factor.</p></div><p>You may wonder<a id="id8460000" class="indexterm"/> how the minimization of the margin error is related to the loss function and the penalization factor, introduced for the ridge regression (refer to the <span class="emphasis"><em>Numerical optimization</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>). The second factor in the formula corresponds to the ubiquitous loss function. You will certainly be able to recognize the first term as the L2 regularization penalty with <span class="emphasis"><em>λ = 1/2C</em></span>.</p><p>The problem can be reformulated as the minimization of a function known as the <a id="id8470000" class="indexterm"/><span class="strong"><strong>primal problem</strong></span> [8:6].</p><div class="note" title="Note"><h3 class="title"><a id="note25900"/>Note</h3><p>M4: The primal problem formulation of the support vector classifier using the L<sub>2</sub> regularization is as follows:</p><div class="mediaobject"><img src="../Images/image01480.jpeg" alt="The nonseparable case – the soft margin"/></div><p style="clear:both; height: 1em;"> </p></div><p>The <span class="emphasis"><em>C</em></span> penalty factor is the inverse of the L2 regularization factor. The loss function <span class="emphasis"><em>L</em></span> is known as the <a id="id8480000" class="indexterm"/><span class="strong"><strong>hinge loss</strong></span>. The formulation of the margin using the <span class="emphasis"><em>C</em></span> penalty (or cost) parameter is known as the <span class="strong"><strong>C-SVM</strong></span> formulation. C-SVM is sometimes called the <a id="id8490000" class="indexterm"/><span class="strong"><strong>C-Epsilon SVM</strong></span> formulation for the nonseparable case.</p><p>The <span class="strong"><strong>υ-SVM</strong></span> (or Nu-SVM) is <a id="id8500000" class="indexterm"/>an alternative formulation to C-SVM. The formulation is more descriptive than C-SVM; <span class="emphasis"><em>υ</em></span> represents the upper bound of the training observations that are poorly classified and the lower bound of the observations on the support vectors [8:7].</p><div class="note" title="Note"><h3 class="title"><a id="note26000"/>Note</h3><p>M5: The <span class="strong"><strong>ν-SVM</strong></span> formulation of a linear SVM using the L2 regularization is defined as:</p><div class="mediaobject"><img src="../Images/image01481.jpeg" alt="The nonseparable case – the soft margin"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>ρ</em></span> is a margin factor used as an optimization variable.</p></div><p>The C-SVM <a id="id8510000" class="indexterm"/>formulation is used throughout the chapters for the binary, one class support vector classifier as well as the support vector regression.</p><div class="note" title="Note"><h3 class="title"><a id="note26200"/>Note</h3><p>
<span class="strong"><strong>Sequential Minimal Optimization</strong></span>
</p><p>The optimization problem consists of the minimization of a quadratic objective function (<span class="emphasis"><em>w<sup>2</sup></em></span>) subject to <span class="emphasis"><em>N</em></span> linear constraints, <span class="emphasis"><em>N</em></span> being the number of observations. The time complexity of the algorithm is <span class="emphasis"><em>O(N<sup>3</sup></em></span>
<span class="emphasis"><em>)</em></span>. A more efficient algorithm known as <a id="id8520000" class="indexterm"/><span class="strong"><strong>Sequential Minimal Optimization</strong></span> (<span class="strong"><strong>SMO</strong></span>) has been introduced to reduce the time complexity to <span class="emphasis"><em>O(N<sup>2</sup>)</em></span>.</p></div></div></div><div class="section" title="The nonlinear SVM"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10400"/>The nonlinear SVM</h2></div></div></div><p>So far, we <a id="id8530000" class="indexterm"/>assumed that the separating <a id="id8540000" class="indexterm"/>hyperplane and therefore the support vectors are linear functions. Unfortunately, such assumptions are not always correct in the real world.</p><div class="section" title="Max-margin classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec10900"/>Max-margin classification</h3></div></div></div><p>Support vector <a id="id8550000" class="indexterm"/>machines are known as large or <a id="id8560000" class="indexterm"/><span class="strong"><strong>maximum margin classifiers</strong></span>. The objective is to maximize the margin between the support vectors with hard constraints for separable (similarly, soft constraints with slack variables for nonseparable) cases.</p><p>The model parameters <span class="emphasis"><em>{w<sub>i</sub>}</em></span> are rescaled during optimization to guarantee that the margin is at least 1. Such algorithms are known as maximum (or large) margin classifiers.</p><p>The problem <a id="id8570000" class="indexterm"/>of fitting a nonlinear model into the labeled observations using support vectors is not an easy task. A better alternative consists of mapping the problem to a new and higher dimensional space using a nonlinear transformation. The nonlinear separating hyperplane becomes a linear plane in the new space, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01482.jpeg" alt="Max-margin classification"/><div class="caption"><p>An illustration of the kernel trick in the SVM</p></div></div><p style="clear:both; height: 1em;"> </p><p>The nonlinear SVM is implemented using a basis function <span class="emphasis"><em>ϕ</em></span>
<span class="emphasis"><em>(x)</em></span>. The formulation of the nonlinear C-SVM is very similar to the linear case. The only difference is the constraint along with the support vector, using the basis function <span class="emphasis"><em>φ</em></span> (<span class="strong"><strong>M6</strong></span>):</p><div class="mediaobject"><img src="../Images/image01483.jpeg" alt="Max-margin classification"/></div><p style="clear:both; height: 1em;"> </p><p>The minimization of <span class="emphasis"><em>w<sup>T</sup>.ϕ(x)</em></span> in the preceding equation requires the computation of the inner product <span class="emphasis"><em>ϕ(x)<sup>T</sup>.ϕ(x)</em></span>. The inner product of the basis functions is implemented using one of the kernel functions introduced in the first section. The optimization of the preceding convex problem computes the optimal hyperplane <span class="emphasis"><em>w*</em></span> as the kernelized linear combination of the training samples <span class="emphasis"><em>y.</em></span>
<span class="emphasis"><em>ϕ</em></span>
<span class="emphasis"><em>(x)</em></span> and <span class="strong"><strong>Lagrange</strong></span> multipliers. This formulation of the optimization problem is known as the <a id="id8580000" class="indexterm"/><span class="strong"><strong>SVM dual problem</strong></span>. The description of the dual problem is mentioned as a reference and is well beyond the scope of this book [8:8].</p><div class="note" title="Note"><h3 class="title"><a id="note26300"/>Note</h3><p>M7: The optimal hyperplane for the SVM dual problem is defined as:</p><div class="mediaobject"><img src="../Images/image01484.jpeg" alt="Max-margin classification"/></div><p style="clear:both; height: 1em;"> </p><p>M8: The hard margin formulation for the SVM dual problem is defined as:</p><div class="mediaobject"><img src="../Images/image01485.jpeg" alt="Max-margin classification"/></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="The kernel trick"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11000"/>The kernel trick</h3></div></div></div><p>The<a id="id8590000" class="indexterm"/> transformation <span class="emphasis"><em>(x,x') =&gt; K(x,x')</em></span> maps a nonlinear problem into a linear problem in a higher dimensional space. It is known as the <span class="strong"><strong>kernel trick</strong></span>.</p><p>Let's consider, for <a id="id8600000" class="indexterm"/>example, the polynomial kernel defined in the first section with a degree <span class="emphasis"><em>d = 2</em></span> and coefficient of <span class="emphasis"><em>C0 = 1</em></span> in a two-dimension space. The polynomial kernel function of two vectors, <span class="emphasis"><em>x = [x<sub>1</sub>, x<sub>2</sub>]</em></span> and <span class="emphasis"><em>z = [x'<sub>1</sub>, x'<sub>2</sub>]</em></span>, is decomposed into a linear function in a 6 dimension space:</p><div class="mediaobject"><img src="../Images/image01486.jpeg" alt="The kernel trick"/></div><p style="clear:both; height: 1em;"> </p></div></div></div>
<div class="section" title="Support vector classifiers &#x2013; SVC"><div class="titlepage" id="aid-60KHK2"><div><div><h1 class="title"><a id="ch08lvl1sec5500"/>Support vector classifiers – SVC</h1></div></div></div><p>Support vector machines<a id="id8610000" class="indexterm"/> can be applied to classification, anomalies detection, and regression problems. Let's first dive into the support vector classifiers.</p><div class="section" title="The binary SVC"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10500"/>The binary SVC</h2></div></div></div><p>The<a id="id8620000" class="indexterm"/> first classifier <a id="id8630000" class="indexterm"/>to be evaluated is the binary (2-class) support vector classifier. The implementation uses the LIBSVM library created by Chih-Chung Chang and Chih-Jen Lin from the National Taiwan University [8:9].</p><div class="section" title="LIBSVM"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11100"/>LIBSVM</h3></div></div></div><p>The <a id="id8640000" class="indexterm"/>library <a id="id8650000" class="indexterm"/>was originally written in C before being ported to Java. It <a id="id8660000" class="indexterm"/>can be downloaded from <a class="ulink" href="http://www.csie.ntu.edu.tw/~cjlin/libsvm">http://www.csie.ntu.edu.tw/~cjlin/libsvm</a> as a <code class="literal">.zip</code> or <code class="literal">tar.gzip</code> file. The library includes the following classifier modes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Support vector classifiers (C-SVC, υ-SVC, and one-class SVC)</li><li class="listitem">Support vector regression (υ-SVR and ε-SVR)</li><li class="listitem">RBF, linear, sigmoid, polynomial, and precomputed kernels</li></ul></div><p>LIBSVM has the <a id="id8670000" class="indexterm"/>distinct advantage of using <span class="strong"><strong>Sequential Minimal Optimization</strong></span> (<span class="strong"><strong>SMO</strong></span>), which reduces the time complexity of a training of <span class="emphasis"><em>n</em></span> observations to <span class="emphasis"><em>O(n
<sup>2</sup>)</em></span>. The LIBSVM documentation covers both the theory and <a id="id8680000" class="indexterm"/>implementation of hard and soft margins and is available at <a class="ulink" href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf</a>.</p><div class="note" title="Note"><h3 class="title"><a id="note26500"/>Note</h3><p>
<span class="strong"><strong>Why LIBSVM?</strong></span>
</p><p>There are <a id="id8690000" class="indexterm"/>alternatives to the LIBSVM library for learning and experimenting with SVM. David Soergel from the University of Berkeley<a id="id8700000" class="indexterm"/> refactored and optimized the Java version [8:10]. Thorsten Joachims' <span class="strong"><strong>SVMLight</strong></span> [8:11] Spark/MLlib 1.0 includes two Scala implementations of the SVM using resilient distributed datasets (refer to the <span class="emphasis"><em>Apache Spark</em></span> section in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span>). However, LIBSVM is the most commonly used SVM library.</p></div><p>The implementation of the different support vector classifiers and the support vector regression in LIBSVM is broken down into the following five Java classes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">svm_model</code>: This <a id="id8710000" class="indexterm"/>defines the parameters of the model created during training</li><li class="listitem"><code class="literal">svm_node</code>: This <a id="id8720000" class="indexterm"/>models the element of the sparse matrix <span class="emphasis"><em>Q</em></span>, which is used in the maximization of the margins</li><li class="listitem"><code class="literal">svm_parameters</code>: This <a id="id8730000" class="indexterm"/>contains the different models for support vector classifiers and regressions, the five kernels supported in LIBSVM with their parameters, and the <code class="literal">weights</code> vectors used in cross-validation</li><li class="listitem"><code class="literal">svm_problem</code>: This <a id="id8740000" class="indexterm"/>configures the input to any of the SVM algorithm (the number of observations, input vector data <span class="emphasis"><em>x</em></span> as a matrix, and the vector of labels <span class="emphasis"><em>y</em></span>)</li><li class="listitem"><code class="literal">svm</code>: This <a id="id8750000" class="indexterm"/>implements algorithms used in training, classification, and regression</li></ul></div><p>The <a id="id8760000" class="indexterm"/>library also includes template programs for training, prediction, and normalization of datasets.</p><div class="note" title="Note"><h3 class="title"><a id="note26600"/>Note</h3><p>
<span class="strong"><strong>The LIBSVM Java code</strong></span>
</p><p>The Java version of LIBSVM is a direct port of the original C code. It does not support generic types and is not easily configurable (the code uses switch statements instead of polymorphism). For all its limitations, LIBSVM is a fairly well-tested and robust Java library for SVMs.</p></div><p>Let's create a Scala wrapper to the LIBSVM library to improve its flexibility and ease of use.</p></div><div class="section" title="Design"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11200"/>Design</h3></div></div></div><p>The implementation<a id="id8770000" class="indexterm"/> of the support vector machine algorithm uses the design template for classifiers (refer to the <span class="emphasis"><em>Design template for classifier</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The key components of the<a id="id8780000" class="indexterm"/> implementation of a SVM are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A model, <code class="literal">SVMModel</code>, of the <code class="literal">Model</code> type is initialized through training during the instantiation of the classifier. The model class is an adapter to the <code class="literal">svm_model</code> structure defined in LIBSVM.</li><li class="listitem">An <code class="literal">SVMAdapter</code> object interfaces with the internal LIBSVM data structures and methods.</li><li class="listitem">The <code class="literal">SVM</code> support vector machine class is implemented as an implicit data transformation of the <code class="literal">ITransform</code> type. It has three parameters: the configuration wrapper of the <code class="literal">SVMConfig</code> type, the features/time series of the <code class="literal">XVSeries</code> type, and the target or labeled values, <code class="literal">DblVector</code>.</li><li class="listitem">The <a id="id8790000" class="indexterm"/>configuration (the <code class="literal">SVMConfig</code> type) consists of three distinct elements: <code class="literal">SVMExecution</code> that defines the execution parameters such as the maximum number of iterations or convergence criteria, <code class="literal">SVMKernel</code> that specifies the kernel function used during training, and <code class="literal">SVMFormulation</code> that defines the formula (<span class="emphasis"><em>C</em></span>, <span class="emphasis"><em>epsilon</em></span>, or <span class="emphasis"><em>nu</em></span>) used to compute a nonseparable case for the support vector classifier and regression.</li></ul></div><p>The key<a id="id8800000" class="indexterm"/> software components of the support vector machine are described in the following UML class diagram:</p><div class="mediaobject"><img src="../Images/image01487.jpeg" alt="Design"/><div class="caption"><p>The UML class diagram for the support vector machine</p></div></div><p style="clear:both; height: 1em;"> </p><p>The UML diagram omits the helper traits and classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="Configuration parameters"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11300"/>Configuration parameters</h3></div></div></div><p>LIBSVM exposes<a id="id8810000" class="indexterm"/> a large number of parameters for the configuration and execution of any of the SVM algorithms. Any SVM algorithm is configured with three categories of parameters, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Formulation (or type) of the SVM algorithms (the multiclass classifier, one-class classifier, regression, and so on) using the <code class="literal">SVMFormulation</code> class</li><li class="listitem">The kernel function used in the algorithm (the RBF kernel, Sigmoid kernel, and so on) using the <code class="literal">SVMKernel</code> class</li><li class="listitem">Training and executing parameters (the convergence criteria, number of folds for cross-validation, and so on) using<a id="id8820000" class="indexterm"/> the <code class="literal">SVMExecution</code> class</li></ul></div><div class="section" title="The SVM formulation"><div class="titlepage"><div><div><h4 class="title"><a id="ch08lvl4sec1600"/>The SVM formulation</h4></div></div></div><p>The <a id="id8830000" class="indexterm"/>instantiation of the configuration consists of initializing the <code class="literal">param</code> LIBSVM parameter by the SVM type, kernel, and the execution context selected by the user.</p><p>Each of the SVM parameters' case class extends the generic <code class="literal">SVMConfigItem</code> trait:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>SVMConfigItem</strong></span> { def update(param: svm_parameter): Unit }</pre></div><p>The classes inherited from <code class="literal">SVMConfigItem</code> are responsible for updating the list of the SVM parameters, <code class="literal">svm_parameter</code>, defined in LIBSVM. The <code class="literal">update</code> method encapsulates the configuration of LIBSVM.</p><p>The formulation of the SVM algorithm by a class hierarchy with <code class="literal">SVMFormulation</code> as the base trait is as follows:</p><div class="informalexample"><pre class="programlisting">sealed trait <span class="strong"><strong>SVMFormulation</strong></span> extends SVMConfigItem {   
  def update(param: svm_parameter): Unit 
}</pre></div><p>The list of the <a id="id8840000" class="indexterm"/>formulation for the SVM (<code class="literal">C</code>, <code class="literal">nu</code>, and <code class="literal">eps</code> for regression) is completely defined and known. Therefore, the hierarchy should not be altered and the <code class="literal">SVMFormulation</code> trait has to be declared sealed. Here is an example of the SVM <code class="literal">CSVCFormulation</code> formulation class, which defines the C-SVM model:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>CSVCFormulation</strong></span> (c: Double) extends SVMFormulation {   
   override def update(param: svm_parameter): Unit = {      
     param.svm_type = svm_parameter.C_SVC
     param.C = c
  }
}</pre></div><p>The other SVM <code class="literal">NuSVCFormulation</code>, <code class="literal">OneSVCFormulation</code>, and <code class="literal">SVRFormulation</code> formulation classes implement the υ-SVM, 1-SVM, and ε-SVM, respectively for regression models.</p></div><div class="section" title="The SVM kernel function"><div class="titlepage"><div><div><h4 class="title"><a id="ch08lvl4sec1700"/>The SVM kernel function</h4></div></div></div><p>Next, you need <a id="id8850000" class="indexterm"/>to specify the kernel functions by defining and implementing the <code class="literal">SVMKernel</code> trait:</p><div class="informalexample"><pre class="programlisting">sealed trait <span class="strong"><strong>SVMKernel</strong></span> extends SVMConfigItem {
  override def update(param: svm_parameter): Unit 
}</pre></div><p>Once again, there are a limited number of kernel functions supported in LIBSVM. Therefore, the hierarchy of kernel functions is sealed. The following code snippet configures the <a id="id8860000" class="indexterm"/>radius basis function kernel, <code class="literal">RbfKernel</code>, as an example of the definition of the kernel definition class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>RbfKernel</strong></span>(gamma: Double) extends SVMKernel {
  override def update(param: svm_parameter): Unit = {
    param.kernel_type = svm_parameter.RBF
    param.gamma = gamma
}</pre></div><p>The fact that the LIBSVM Java byte code library is not very extensible does not prevent you from defining a new kernel function in the LIBSVM source code. For example, the Laplacian kernel can be added by performing the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a new kernel type in <code class="literal">svm_parameter</code>, such as <code class="literal">svm_parameter. LAPLACE = 5</code>.</li><li class="listitem">Add the kernel function name to <code class="literal">kernel_type_table</code> in the <code class="literal">svm</code> class.</li><li class="listitem">Add <code class="literal">kernel_type != svm_parameter.LAPLACE</code> to the <code class="literal">svm_check_</code> parameter method.</li><li class="listitem">Add the implementation of the kernel function to two values in <code class="literal">svm</code>: <code class="literal">kernel_function</code> (Java code):<div class="informalexample"><pre class="programlisting">case svm_parameter.<span class="strong"><strong>LAPLACE</strong></span>:
   double sum = 0.0;
   for(int k = 0; k &lt; x[i].length; k++) { 
     final double diff = x[i][k].value - x[j][k].value; 
     sum += diff*diff;
    }    
    return Math.exp(-gamma*Math.sqrt(sum));</pre></div></li><li class="listitem">Add the implementation of the Laplace kernel function in the <code class="literal">svm.k_function</code> method by modifying the existing implementation of RBF (<code class="literal">distanceSqr</code>).</li><li class="listitem">Rebuild the <code class="literal">libsvm.jar</code> file</li></ol><div style="height:10px; width: 1px"/></div></div><div class="section" title="The SVM execution"><div class="titlepage"><div><div><h4 class="title"><a id="ch08lvl4sec1800"/>The SVM execution</h4></div></div></div><p>The <code class="literal">SVMExecution</code> class <a id="id8870000" class="indexterm"/>defines the configuration parameters for the execution of the training of the model, namely the <code class="literal">eps</code> convergence factor for the optimizer (line <code class="literal">2</code>), the size of the cache, <code class="literal">cacheSize</code> (line <code class="literal">1</code>), and the number of folds, <code class="literal">nFolds</code>, used during cross-validation:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SVMExecution</strong></span>(cacheSize: Int, eps: Double, <span class="strong"><strong>nFolds</strong></span>: Int) 
     extends <span class="strong"><strong>SVMConfigItem</strong></span> {
  override def update(param: svm_parameter): Unit = { 
    param.cache_size = cacheSize //<span class="strong"><strong>1</strong></span>
    param.eps = eps //<span class="strong"><strong>2</strong></span>
  }
}</pre></div><p>The cross-validation<a id="id8880000" class="indexterm"/> is performed only if the <code class="literal">nFolds</code> value is greater than 1.</p><p>We are finally ready to create the <code class="literal">SVMConfig</code> configuration class, which hides and manages all of the different configuration parameters:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SVMConfig</strong></span>(formula: SVMFormulation, kernel: SVMKernel,
     exec: SVMExecution) {
  val param = new svm_parameter
  formula.update(param) //<span class="strong"><strong>3</strong></span>
  kernel.update(param)  //<span class="strong"><strong>4</strong></span>
  exec.update(param)  //<span class="strong"><strong>5</strong></span>
}</pre></div><p>The <code class="literal">SVMConfig</code> class delegates the selection of the formula to the <code class="literal">SVMFormulation</code> class (line <code class="literal">3</code>), selection of the kernel function to the <code class="literal">SVMKernel</code> class (line <code class="literal">4</code>), and the execution of parameters to the <code class="literal">SVMExecution</code> class (line <code class="literal">5</code>). The sequence of update calls initializes the LIBSVM list of configuration parameters.</p></div></div><div class="section" title="Interface to LIBSVM"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11400"/>Interface to LIBSVM</h3></div></div></div><p>We need to create an <a id="id8890000" class="indexterm"/>adapter object to encapsulate the invocation to LIBSVM. The <code class="literal">SVMAdapter</code> object hides the LIBSVM internal data structures: <code class="literal">svm_model</code> and <code class="literal">svm_node</code>:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>SVMAdapter</strong></span> {
  type SVMNodes = Array[Array[svm_node]]
  class <span class="strong"><strong>SVMProblem</strong></span>(numObs: Int, expected: DblArray) //<span class="strong"><strong>6</strong></span>
   
  def <span class="strong"><strong>createSVMNode</strong></span>(dim: Int, x: DblArray): Array[svm_node] //<span class="strong"><strong>7</strong></span>
  def <span class="strong"><strong>predictSVM</strong></span>(model: SVMModel, x: DblArray): Double //<span class="strong"><strong>8</strong></span>
  def <span class="strong"><strong>crossValidateSVM</strong></span>(problem: SVMProblem, //<span class="strong"><strong>9</strong></span>
     param: svm_parameter, nFolds: Int, expected: DblArray) 
  def <span class="strong"><strong>trainSVM</strong></span>(problem: SVMProblem,  //<span class="strong"><strong>10</strong></span>
     param: svm_parameter): svm_model 
}</pre></div><p>The <code class="literal">SVMAdapter</code> object is a single entry point to LIBSVM for training, validating a SVM model, and executing predictions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">SVMProblem</code> wraps the definition of the training objective or problem in LIBSVM, using the labels or <code class="literal">expected</code> values (line <code class="literal">6</code>)</li><li class="listitem"><code class="literal">createSVMNode</code> creates a new computation node for each observation <code class="literal">x</code> (line <code class="literal">7</code>)</li><li class="listitem"><code class="literal">predictSVM</code> predicts the outcome of a new observation <code class="literal">x</code> given a model, <code class="literal">svm_model</code>, generated through training (line <code class="literal">8</code>)</li><li class="listitem"><code class="literal">crossValidateSVM</code> validates the model, <code class="literal">svm_model</code>, with the <code class="literal">nFold</code> training—validation sets (line <code class="literal">9</code>)</li><li class="listitem"><code class="literal">trainSVM</code> executes the <code class="literal">problem</code> training configuration (line <code class="literal">10</code>)</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note26700"/>Note</h3><p>
<span class="strong"><strong>svm_node</strong></span>
</p><p>The LIBSVM <code class="literal">svm_node</code> Java class is defined as a pair of indices of the feature in the observation array and its value:</p><div class="informalexample"><pre class="programlisting">public class svm_node implements java.io.Serializable {   
  public int index;    
  public double value;
}</pre></div></div><p>The <code class="literal">SVMAdapter</code> methods<a id="id8900000" class="indexterm"/> are described in the next section.</p></div><div class="section" title="Training"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11500"/>Training</h3></div></div></div><p>The model for the <a id="id8910000" class="indexterm"/>SVM is defined by the following two components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">svm_model</code>: This is the SVM model parameters defined in LIBSVM</li><li class="listitem"><code class="literal">accuracy</code>: This is the accuracy of the model computed during cross-validation</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>SVMModel</strong></span>(val svmmodel: <span class="strong"><strong>svm_model</strong></span>, 
     val <span class="strong"><strong>accuracy</strong></span>: Double) extends Model {
  lazy val <span class="strong"><strong>residuals</strong></span>: DblArray = svmmodel.sv_coef(0)
}</pre></div><p>The <code class="literal">residuals</code>, that is, <span class="emphasis"><em>r = y – f(x)</em></span> are computed in the LIBSVM library.</p><div class="note" title="Note"><h3 class="title"><a id="note26800"/>Note</h3><p>
<span class="strong"><strong>Accuracy in the SVM model</strong></span>
</p><p>You may wonder why the value of the accuracy is a component of the model. The accuracy component of the model provides the client code with a quality metric associated with the model. Integrating the accuracy into the model, allows the user to make informed decisions in accepting or rejecting the model. The accuracy is stored in the model file for subsequent analysis.</p></div><p>Next, let's <a id="id8920000" class="indexterm"/>create the first support vector classifier for the two-class problems. The SVM class implements the <code class="literal">ITransform</code> monadic data transformation that implicitly generates a model from a training set, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">11</code>).</p><p>The constructor for the SVM follows the template described in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SVM</strong></span>[T &lt;% Double](config: SVMConfig, xt: XVSeries[T], 
   expected: DblVector) extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) {//<span class="strong"><strong>11</strong></span>

  type <span class="strong"><strong>V</strong></span> = Double   //<span class="strong"><strong>12</strong></span>
  val <span class="strong"><strong>normEPS</strong></span> = config.eps*1e-7  //<span class="strong"><strong>13</strong></span>
  val model: Option[<span class="strong"><strong>SVMModel</strong></span>] = train  //<span class="strong"><strong>14</strong></span>

  def <span class="strong"><strong>accuracy</strong></span>: Option[Double] = model.map( _.accuracy) //<span class="strong"><strong>15</strong></span>
  def <span class="strong"><strong>mse</strong></span>: Option[Double]  //<span class="strong"><strong>16</strong></span>
  def <span class="strong"><strong>margin</strong></span>: Option[Double]  //<span class="strong"><strong>17</strong></span>
}</pre></div><p>The implementation of the <code class="literal">ITransform</code> abstract class requires the definition of the output value of the predictor as a <code class="literal">Double</code> (line <code class="literal">12</code>). The <code class="literal">normEPS</code> is used for rounding errors in the computation of the margin (line <code class="literal">13</code>). The model of the <code class="literal">SVMModel</code> type is generated through training by the <code class="literal">SVM</code> constructor (line <code class="literal">14</code>). The last four methods are used to compute the parameters of the <code class="literal">accuracy</code> model (line <code class="literal">15</code>), the mean square of errors, <code class="literal">mse</code>, (line <code class="literal">16</code>), and the <code class="literal">margin</code> (line <code class="literal">17</code>).</p><p>Let's take a look at the training method, <code class="literal">train</code>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[SVMModel] = Try {
  val problem = new <span class="strong"><strong>SVMProblem</strong></span>(xt.size, expected.toArray) //<span class="strong"><strong>18</strong></span>
  val dim = dimension(xt)

  xt.zipWithIndex.foreach{ case (_x, n) =&gt;  //<span class="strong"><strong>19</strong></span>
      problem.update(n, <span class="strong"><strong>createSVMNode</strong></span>(dim, _x))
  }
  new SVMModel(<span class="strong"><strong>trainSVM</strong></span>(problem, config.param), accuracy(problem))   //<span class="strong"><strong>20</strong></span>
}._toOption("SVM training failed", logger)</pre></div><p>The <code class="literal">train</code> method creates <code class="literal">SVMProblem</code> that provides LIBSVM with the training components (line <code class="literal">18</code>). The purpose of the <code class="literal">SVMProblem</code> class is to manage the definition of training parameters<a id="id8930000" class="indexterm"/> implemented in LIBSVM, as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SVMProblem</strong></span>(numObs: Int, expected: DblArray) {
  val problem = new <span class="strong"><strong>svm_problem</strong></span>  //21
  problem.l = numObs
  problem.y = expected 
  problem.x = new SVMNodes(numObs)

  def <span class="strong"><strong>update</strong></span>(n: Int, node: Array[<span class="strong"><strong>svm_node</strong></span>]): Unit = 
    problem.x(n) = node  //22
}</pre></div><p>The arguments of the <code class="literal">SVMProblem</code> constructor, the number of observations, and the labels or expected values are used to initialize the corresponding <code class="literal">svm_problem</code> data structure in LIBSVM (line <code class="literal">21</code>). The <code class="literal">update</code> method maps each observation, which is defined as an array of <code class="literal">svm_node</code> to the problem (line <code class="literal">22</code>).</p><p>The <code class="literal">createSVMNode</code> method creates an array of <code class="literal">svm_node</code> from an observation. A <code class="literal">svm_node</code> in LIBSVM is the pair of the <code class="literal">j</code> index of a feature in an observation (line <code class="literal">23</code>) and its value, <code class="literal">y</code> (line <code class="literal">24</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>createSVMNode</strong></span>(dim: Int, x: DblArray): Array[svm_node] = {
   val newNode = new Array[svm_node](dim)
   x.zipWithIndex.foreach{ case (y, j) =&gt;  {
      val node = new svm_node
      node.index= j  //<span class="strong"><strong>23</strong></span>
      node.value = y  //<span class="strong"><strong>24</strong></span>
      newNode(j) = node 
   }}
   newNode</pre></div><p>The mapping between an observation and a LIBSVM node is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01488.jpeg" alt="Training"/><div class="caption"><p>Indexing of observations using LIBSVM</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">trainSVM</code> method pushes the training request with a well-defined problem and configuration parameters to LIBSVM by invoking the <code class="literal">svm_train</code> method (line <code class="literal">26</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>trainSVM</strong></span>(problem: SVMProblem, 
     param: svm_parameter): svm_model =
   svm.svm_train(problem.problem, param) //<span class="strong"><strong>26</strong></span>
</pre></div><p>The accuracy<a id="id8940000" class="indexterm"/> is the ratio of the true positive plus the true negative over the size of the test sample (refer to the <span class="emphasis"><em>Key quality metrics</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>). It is computed through cross-validation only if the number of folds initialized in the <code class="literal">SVMExecution</code> configuration class is greater than 1. Practically, the accuracy is computed by invoking the cross-validation method, <code class="literal">svm_cross_validation</code>, in the LIBSVM package, and then computing the ratio of the number of predicted values that match the labels over the total number of observations:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>accuracy</strong></span>(problem: SVMProblem): Double = { 
  if( config.isCrossValidation ) {
    val target = new Array[Double](expected.size)
    <span class="strong"><strong>crossValidateSVM</strong></span>(problem, config.param,  //<span class="strong"><strong>27</strong></span>
        config.nFolds, target)

    target.zip(expected)
       .filter{case(x, y) =&gt;Math.abs(x- y) &lt; config.eps}  //<span class="strong"><strong>28</strong></span>
       .size.toDouble/expected.size
  }
  else 0.0
}</pre></div><p>The call to the <code class="literal">crossValidateSVM</code> method of <code class="literal">SVMAdapter</code> forwards the configuration and execution of the cross validation with <code class="literal">config.nFolds</code> (line <code class="literal">27</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>crossValidateSVM</strong></span>(problem: SVMProblem, param: svm_parameter, 
    nFolds: Int, expected: DblArray) {
  svm.svm_cross_validation(problem.problem, param, 
    nFolds, expected)
}</pre></div><p>The Scala <code class="literal">filter</code> weeds out the observations that were poorly predicted (line <code class="literal">28</code>). This minimalist implementation is good enough to start exploring the support vector classifier.</p></div><div class="section" title="Classification"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11600"/>Classification</h3></div></div></div><p>The<a id="id8950000" class="indexterm"/> implementation of the <code class="literal">|&gt;</code> classification method for the <code class="literal">SVM</code> class follows the same pattern as the other classifiers. It invokes the <code class="literal">predictSVM</code> method in <code class="literal">SVMAdapter</code> that forwards the request to LIBSVM (line <code class="literal">29</code>):</p><div class="informalexample"><pre class="programlisting">override def |&gt; : PartialFunction[Array[T], Try[V]] =  {
   case x: Array[T] if(x.size == dimension(xt) &amp;&amp; isModel) =&gt;
      Try( predictSVM(model.get.svmmodel, x) )  //<span class="strong"><strong>29</strong></span>
}</pre></div></div><div class="section" title="C-penalty and margin"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11700"/>C-penalty and margin</h3></div></div></div><p>The first<a id="id8960000" class="indexterm"/> evaluation consists of understanding the impact of the penalty factor <span class="emphasis"><em>C</em></span> on the margin in the generation of the classes. Let's implement the computation of the margin. The margin is defined as <span class="emphasis"><em>2/|w|</em></span> and implemented as a method of the <code class="literal">SVM</code> class, as follows:-</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>margin</strong></span>: Option[Double] = 
  if(isModel) {
    val <span class="strong"><strong>wNorm</strong></span> = model.get.residuals./:(0.0)((s,r) =&gt; s + r*r)
    if(wNorm &lt; normEPS) None else Some(2.0/Math.sqrt(wNorm))
  }
  else None</pre></div><p>The first instruction computes the sum of the squares, <code class="literal">wNorm</code>, of the residuals <span class="emphasis"><em>r = y – f(x|w)</em></span>. The margin is ultimately computed if the sum of squares is significant enough to avoid rounding errors.</p><p>The margin is evaluated using an artificially generated time series and labeled data. First, we define the method to evaluate the margin for a specific value of the penalty (inversed regularization coefficient) factor <span class="emphasis"><em>C</em></span>:</p><div class="informalexample"><pre class="programlisting">val GAMMA = 0.8
val CACHE_SIZE = 1&lt;&lt;8
val NFOLDS = 1
val EPS = 1e-5

def <span class="strong"><strong>evalMargin</strong></span>(features: Vector[DblArray], 
    expected: DblVector, c: Double): Int = {
  val execEnv = SVMExecution(CACHE_SIZE, EPS, NFOLDS)
  val config = SVMConfig(new CSVCFormulation(c), 
     new RbfKernel(GAMMA), execEnv)
  val svc = SVM[Double](config, features, expected)
  svc.margin.map(_.toString)     //<span class="strong"><strong>30</strong></span>
}</pre></div><p>The <code class="literal">evalMargin</code> method uses the <code class="literal">CACHE_SIZE</code>, <code class="literal">EPS</code>, and <code class="literal">NFOLDS</code> execution parameters. The execution displays the value of the margin for different values of <span class="emphasis"><em>C</em></span> (line <code class="literal">30</code>). The method is invoked iteratively to evaluate the impact of the penalty factor on the margin extracted from the training of the model. The test uses a synthetic time series to highlight the relation between <span class="emphasis"><em>C</em></span> and the margin. The synthetic time series created by the <code class="literal">generate</code> method consists of two training sets of an equal size, <span class="emphasis"><em>N</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Data points generated as <span class="emphasis"><em>y = x(1 + r/5)</em></span> for the label 1, <span class="emphasis"><em>r</em></span> being a randomly generated number over the range [0,1] (line <code class="literal">31</code>)</li><li class="listitem">A randomly generated data point <span class="emphasis"><em>y = r</em></span> for the label -1 (line <code class="literal">32</code>)</li></ul></div><p>Consider the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>generate</strong></span>: (Vector[DblArray], DblArray) = {
  val z  = Vector.tabulate(N)(i =&gt; {
    val ri = i*(1.0 + 0.2*Random.nextDouble)
    Array[Double](i, ri)  //<span class="strong"><strong>31</strong></span>
  }) ++
  Vector.tabulate(N)(i =&gt;Array[Double](i,i*Random.nextDouble))
  (z, Array.fill(N)(1) ++ Array.fill(N)(-1))  //<span class="strong"><strong>32</strong></span>
}</pre></div><p>The <code class="literal">evalMargin</code> method <a id="id8970000" class="indexterm"/>is executed for different values of <span class="emphasis"><em>C</em></span> ranging from 0 to 5:</p><div class="informalexample"><pre class="programlisting">generate.map(y =&gt; 
  (0.1 until 5.0 by 0.1)
    .flatMap(evalMargin(y._1, y._2, _)).mkString("\n") 
)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note26900"/>Note</h3><p>
<span class="strong"><strong>val versus final val</strong></span>
</p><p>There is a difference between a val and a final val. A nonfinal value can be overridden in a subclass. Overriding a final value produces a compiler error, as follows:</p><div class="informalexample"><pre class="programlisting">class A { val x = 5;  final val y = 8 } 
class B extends A { 
  override val x = 9 // OK    
  override val y = 10 // Error 
}</pre></div></div><p>The following chart illustrates the relation between the penalty or cost factor <span class="emphasis"><em>C</em></span> and the margin:</p><div class="mediaobject"><img src="../Images/image01489.jpeg" alt="C-penalty and margin"/><div class="caption"><p>The margin value versus the C-penalty factor for a support vector classifier</p></div></div><p style="clear:both; height: 1em;"> </p><p>As expected, the value <a id="id8980000" class="indexterm"/>of the margin decreases as the penalty term <span class="emphasis"><em>C</em></span> increases. The <span class="emphasis"><em>C</em></span> penalty factor is related to the L
<sub>2</sub> regularization factor <span class="emphasis"><em>λ</em></span> as <span class="emphasis"><em>C ~ 1/λ</em></span>. A model with a large value of <span class="emphasis"><em>C</em></span> has a high variance and a low bias, while a small value of <span class="emphasis"><em>C</em></span> will produce lower variance and a higher bias.</p><div class="note" title="Note"><h3 class="title"><a id="note27000"/>Note</h3><p>
<span class="strong"><strong>Optimizing C penalty</strong></span>
</p><p>The optimal value for <span class="emphasis"><em>C</em></span> is usually evaluated through cross-validation, by varying <span class="emphasis"><em>C</em></span> in incremental powers of 2: 2n, 2n+1, … [8:12].</p></div></div><div class="section" title="Kernel evaluation"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11800"/>Kernel evaluation</h3></div></div></div><p>The next test consists of <a id="id8990000" class="indexterm"/>comparing the impact of the kernel function on the accuracy of the prediction. Once again, a synthetic time series is generated to highlight the contribution of each kernel. The test code uses the runtime prediction or classification method, <code class="literal">|&gt;</code>, to evaluate the different kernel functions. Let's create a method to evaluate and compare these kernel functions. All we need is the following (line <code class="literal">33</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An <code class="literal">xt</code> training set of the <code class="literal">Vector[DblArray]</code> type</li><li class="listitem">A test set, <code class="literal">test</code>, of the <code class="literal">Vector[DblArray]</code> type</li><li class="listitem">A set of <code class="literal">labels</code> for the training set that takes the value 0 or 1</li><li class="listitem">A <code class="literal">kF</code> kernel function </li></ul></div><p>Consider the following code:</p><div class="informalexample"><pre class="programlisting">val C = 1.0
def <span class="strong"><strong>evalKernel</strong></span>(xt: Vector[DblArray],  test: Vector[DblArray], 
     labels: DblVector, kF: SVMKernel): Double = { //<span class="strong"><strong>33</strong></span>
  
  val config = SVMConfig(new CSVCFormulation(C), kF) //<span class="strong"><strong>34</strong></span>
  val svc = <span class="strong"><strong>SVM</strong></span>[Double](config, xt, labels)
  val pfnSvc = svc |&gt;  //<span class="strong"><strong>35</strong></span>
  test.zip(labels).count{case(x, y) =&gt;pfnSvc(x).get == y}
    .toDouble/test.size  //<span class="strong"><strong>36</strong></span>
}</pre></div><p>The <code class="literal">config</code> configuration <a id="id9000000" class="indexterm"/>of the SVM uses the <span class="emphasis"><em>C</em></span> penalty factor 1, the C-formulation, and the default execution environment (line <code class="literal">34</code>). The predictive <code class="literal">pfnSvc</code> partial function (line <code class="literal">35</code>) is used to compute the predictive values for the test set. Finally, the <code class="literal">evalKernel</code> method counts the number of successes for which the predictive values match the labeled or expected values. The accuracy is computed as the ratio of the successful prediction over the size of the test sample (line <code class="literal">36</code>).</p><p>In order to compare the different kernels, let's generate three datasets of the size 2N for a binomial classification using the pseudo-random <code class="literal">genData</code> data generation method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>genData</strong></span>(variance: Double, mean: Double): Vector[DblArray] = {
  val rGen = new Random(System.currentTimeMillis)
  Vector.tabulate(N)( _ =&gt; { 
    rGen.setSeed(rGen.nextLong)
    Array[Double](rGen.nextDouble, rGen.nextDouble)
      .map(variance*_ - mean)  //<span class="strong"><strong>37</strong></span>
  })
}</pre></div><p>The random value is computed through a transformation <span class="emphasis"><em>f(x) = variance*x = mean</em></span> (line <code class="literal">37</code>). The training and test sets consist of the aggregate of two classes of data points:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Random data points with the variance <code class="literal">a</code> and mean <code class="literal">b</code> associated with the label 0.0</li><li class="listitem">Random data points with the variance <code class="literal">a</code> and mean <code class="literal">1-b</code> associated with the label 1.0</li></ul></div><p>Consider the following code for the training set:</p><div class="informalexample"><pre class="programlisting">val trainSet = genData(a, b) ++ genData(a, 1-b)
val testSet = genData(a, b) ++ genData(a, 1-b)</pre></div><p>The <code class="literal">a</code> and <code class="literal">b</code> parameters are selected from two groups of training data points with various degrees of separation to illustrate the separating hyperplane.</p><p>The following chart describes the high margin; the first training set generated with the parameters <span class="emphasis"><em>a = 0.6</em></span> and <span class="emphasis"><em>b = 0.3</em></span> illustrates the highly separable classes with a clean and distinct hyperplane:</p><div class="mediaobject"><img src="../Images/image01490.jpeg" alt="Kernel evaluation"/><div class="caption"><p>The scatter plot for training and testing sets with a = 0.6 and b = 0.3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following <a id="id9010000" class="indexterm"/>chart describes the medium margin; the parameters <span class="emphasis"><em>a = 0.8</em></span> and <span class="emphasis"><em>b = 0.3</em></span> generate two groups of observations with some overlap:</p><div class="mediaobject"><img src="../Images/image01491.jpeg" alt="Kernel evaluation"/><div class="caption"><p>The scatter plot for training and testing sets with a = 0.8 and b = 0.3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following<a id="id9020000" class="indexterm"/> chart describes the low margin; the two groups of observations in this last training set are generated with <span class="emphasis"><em>a = 1.4</em></span> and <span class="emphasis"><em>b = 0.3</em></span> and show a significant overlap:</p><div class="mediaobject"><img src="../Images/image01492.jpeg" alt="Kernel evaluation"/><div class="caption"><p>The scatter plot for training and testing sets with a = 1.4 and b = 0.3</p></div></div><p style="clear:both; height: 1em;"> </p><p>The test set is <a id="id9030000" class="indexterm"/>generated in a similar fashion as the training set, as they are extracted from the same data source:</p><div class="informalexample"><pre class="programlisting">val GAMMA = 0.8; val COEF0 = 0.5; val DEGREE = 2 //38
val N = 100

def <span class="strong"><strong>compareKernel</strong></span>(a: Double, b: Double) {
  val labels = Vector.fill(N)(0.0) ++ Vector.fill(N)(1.0)
  <span class="strong"><strong>evalKernel</strong></span>(trainSet, testSet,labels,new RbfKernel(GAMMA)) 
  <span class="strong"><strong>evalKernel</strong></span>(trainSet, testSet, labels, 
      new SigmoidKernel(GAMMA)) 
  <span class="strong"><strong>evalKernel</strong></span>(trainSet, testSet, labels, LinearKernel) 
  <span class="strong"><strong>evalKernel</strong></span>(trainSet, testSet, labels, 
      new PolynomialKernel(GAMMA, COEF0, DEGREE))
}</pre></div><p>The parameters for each of the four kernel functions are arbitrary selected from textbooks (line <code class="literal">38</code>). The <code class="literal">evalKernel</code> method defined earlier is applied to the three training sets: the high margin (<span class="emphasis"><em>a = 1.4</em></span>), medium margin (<span class="emphasis"><em>a = 0.8</em></span>), and low margin (<span class="emphasis"><em>a = 0.6</em></span>) with each of the four kernels (RBF, sigmoid, linear, and polynomial). The accuracy is assessed by counting the number of observations correctly classified for all of the classes for each invocation of the predictor, <code class="literal">|&gt;</code>:</p><div class="mediaobject"><img src="../Images/image01493.jpeg" alt="Kernel evaluation"/><div class="caption"><p>A comparative chart of kernel functions using synthetic data</p></div></div><p style="clear:both; height: 1em;"> </p><p>Although the<a id="id9040000" class="indexterm"/> different kernel functions do not differ in terms of the impact on the accuracy of the classifier, you can observe that the RBF and polynomial kernels produce results that are slightly more accurate. As expected, the accuracy decreases as the margin decreases. A decreasing margin indicates that the cases are not easily separable, affecting the accuracy of the classifier:</p><div class="mediaobject"><img src="../Images/image01494.jpeg" alt="Kernel evaluation"/><div class="caption"><p>The impact of the margin value on the accuracy of RBF and Sigmoid kernel functions</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note27100"/>Note</h3><p>
<span class="strong"><strong>A test case design</strong></span>
</p><p>The test to compare the different kernel methods is highly dependent on the distribution or mixture of data in the training and test sets. The synthetic generation of data in this test case is used for illustrating the margin between classes of observations. Real-world datasets may produce different results.</p></div><p>In summary, there<a id="id9050000" class="indexterm"/> are four steps required to create a SVC-based model:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select a features set.</li><li class="listitem">Select the C-penalty (inverse regularization).</li><li class="listitem">Select the kernel function.</li><li class="listitem">Tune the kernel parameters.</li></ol><div style="height:10px; width: 1px"/></div><p>As mentioned earlier, this test case relies on synthetic data to illustrate the concept of the margin and compare kernel methods. Let's use the support vector classifier for a real-world financial application.</p></div><div class="section" title="Applications in risk analysis"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec11900"/>Applications in risk analysis</h3></div></div></div><p>The purpose <a id="id9060000" class="indexterm"/>of the test case is to evaluate the risk for a company to curtail or eliminate its quarterly or yearly dividend. The features selected are financial metrics relevant to a company's ability to generate a cash flow and pay out its dividends over the long term.</p><p>We need to select any subset of the following financial technical analysis metrics (refer to <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Relative change in stock prices over the last 12 months</li><li class="listitem">Long-term debt-equity ratio</li><li class="listitem">Dividend coverage ratio </li><li class="listitem">Annual dividend yield</li><li class="listitem">Operating profit margin</li><li class="listitem">Short interest (ratio of shares shorted over the float)</li><li class="listitem">Cash per share-share price ratio</li><li class="listitem">Earnings per share trend</li></ul></div><p>The earnings trend has the following values:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">-2 if earnings per share decline by more than 15 percent over the last 12 months.</li><li class="listitem">-1 if earnings per share decline between 5 percent and 15 percent.</li><li class="listitem">0 if earnings per share is maintained within 5 percent.</li><li class="listitem">+1 if earnings per share increase between 5 percent and 15 percent.</li><li class="listitem">+2 if earnings per share increase by more than 15 percent. The values are normalized with values 0 and 1.</li></ul></div><p>The labels <a id="id9070000" class="indexterm"/>or expected output (dividend changes) is categorized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">-1 if the dividend is cut by more than 5 percent</li><li class="listitem">0 if the dividend is maintained within 5 percent</li><li class="listitem">+1 if the dividend is increased by more than 5 percent</li></ul></div><p>Let's combine two of these three labels <span class="emphasis"><em>{-1, 0, 1}</em></span> to generate two classes for the binary SVC:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Class C1 = stable or decreasing dividends and class C2 = increasing dividends—training set A</li><li class="listitem">Class C1 = decreasing dividends and class C2 = stable or increasing dividends—training set B</li></ul></div><p>The different tests are performed with a fixed set of <code class="literal">C</code> and <code class="literal">GAMMA</code> configuration parameters and a 2-fold validation configuration:</p><div class="informalexample"><pre class="programlisting">val path = "resources/data/chap8/<span class="strong"><strong>dividends2</strong></span>.csv"
val <span class="strong"><strong>C</strong></span> = 1.0
val <span class="strong"><strong>GAMMA</strong></span> = 0.5
val EPS = 1e-2
val NFOLDS = 2

val <span class="strong"><strong>extractor</strong></span> = relPriceChange :: debtToEquity :: 
    dividendCoverage :: cashPerShareToPrice :: epsTrend :: 
    shortInterest :: dividendTrend :: 
    List[Array[String] =&gt;Double]()  //<span class="strong"><strong>39</strong></span>

val <span class="strong"><strong>pfnSrc</strong></span> = DataSource(path, true, false,1) |&gt; //<span class="strong"><strong>40</strong></span>
val config = SVMConfig(new CSVCFormulation(C), 
     new RbfKernel(GAMMA), SVMExecution(EPS, NFOLDS))

for {
  input &lt;- pfnSrc(extractor) //<span class="strong"><strong>41</strong></span>
  <span class="strong"><strong>obs</strong></span> &lt;- <span class="strong"><strong>getObservations</strong></span>(input)  //<span class="strong"><strong>42</strong></span>
  svc &lt;- SVM[Double](config, obs, input.last.toVector)
} yield {
  show(s"${svc.toString}\naccuracy ${svc.accuracy.get}")
}</pre></div><p>The first step <a id="id9080000" class="indexterm"/>is to define the <code class="literal">extractor</code> (which is the list of fields to be retrieved from the <code class="literal">dividends2.csv</code> file) (line <code class="literal">39</code>). The <code class="literal">pfnSrc</code> partial function generated by the <code class="literal">DataSource</code> transformation class (line <code class="literal">40</code>) converts the input file into a set of typed fields (line <code class="literal">41</code>). An observation is an array of fields. The <code class="literal">obs</code> sequence of observations is generated from the input fields by transposing the matrix observations <code class="literal">x</code> features (line <code class="literal">42</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>getObservations</strong></span>(input: Vector[DblArray]):
     Try[Vector[DblArray]] = Try {
  <span class="strong"><strong>transpose</strong></span>( input.dropRight(1).map(_.toArray) ).toVector
}</pre></div><p>The test computes the model parameters and the accuracy from the cross-validation during the instantiation of the SVM.</p><div class="note" title="Note"><h3 class="title"><a id="note27200"/>Note</h3><p>
<span class="strong"><strong>LIBSVM scaling</strong></span>
</p><p>LIBSVM supports feature normalization known as scaling, prior to training. The main advantage of scaling is to avoid attributes in greater numeric ranges, dominating those in smaller numeric ranges. Another advantage is to avoid numerical difficulties during the calculation. In our examples, we use the normalization method of the <code class="literal">normalize</code> time series. Therefore, the scaling flag in LIBSVM is disabled.</p></div><p>The test is repeated with a different set of features and consists of comparing the accuracy of the support vector classifier for different features sets. The features sets are selected from the content of the <code class="literal">.csv</code> file by assembling the extractor with different configurations, as follows:</p><div class="informalexample"><pre class="programlisting">val extractor =  … :: dividendTrend :: …</pre></div><p>Let's take a look at the following graph:</p><div class="mediaobject"><img src="../Images/image01495.jpeg" alt="Applications in risk analysis"/><div class="caption"><p>A comparative study of trading strategies using the binary SVC</p></div></div><p style="clear:both; height: 1em;"> </p><p>The test <a id="id9090000" class="indexterm"/>demonstrates that the selection of the proper features set is the most critical step in applying the support vector machine, and any other model for that matter, to classification problems. In this particular case, the accuracy is also affected by the small size of the training set. The increase in the number of features also reduces the contribution of each specific feature to the loss function.</p><div class="note" title="Note"><h3 class="title"><a id="note27300"/>Note</h3><p>
<span class="strong"><strong>The N-fold cross-validation</strong></span>
</p><p>The cross-validation in this test example uses only two folds because the number of observations is small, and you want to make sure that any class contains at least a few observations.</p></div><p>The same process is repeated for the test B whose purpose is to classify companies with decreasing dividends and companies with stable or increasing dividends, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01496.jpeg" alt="Applications in risk analysis"/><div class="caption"><p>A comparative study of trading strategies using the binary SVC</p></div></div><p style="clear:both; height: 1em;"> </p><p>The difference<a id="id9100000" class="indexterm"/> in terms of accuracy of prediction between the first three features set and the last two features set in the preceding graph is more pronounced in test A than test B. In both the tests, the <code class="literal">eps</code> feature (earning per share) trend improves the accuracy of the classification. It is a particularly good predictor for companies with increasing dividends.</p><p>The problem of predicting the distribution (or not) dividends can be restated as evaluating the risk of a company to dramatically reduce its dividends.</p><p>What is the risk if a company eliminates its dividend altogether? Such a scenario is rare, and these cases are actually outliers. A one-class support vector classifier can be used to detect outliers or anomalies [8:13].</p></div></div></div>
<div class="section" title="Anomaly detection with one-class SVC" id="aid-61J261"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec5600"/>Anomaly detection with one-class SVC</h1></div></div></div><p>The <a id="id9110000" class="indexterm"/>design <a id="id9120000" class="indexterm"/>of the one-class SVC is an extension of the binary SVC. The main difference is that a single class contains most of the baseline (or normal) observations. A reference point, known as the SVC origin, replaces the second class. The outliers (or abnormal) observations reside beyond (or outside) the support vector of the single class:</p><div class="mediaobject"><img src="../Images/image01497.jpeg" alt="Anomaly detection with one-class SVC"/><div class="caption"><p>The visualization of the one-class SVC</p></div></div><p style="clear:both; height: 1em;"> </p><p>The outlier <a id="id9130000" class="indexterm"/>observations have a labeled value of -1, while the remaining training sets are labeled +1. In order to create a relevant test, we add four more companies that have drastically cut their dividends (ticker symbols WLT, RGS, MDC, NOK, and GM). The dataset includes the stock prices and financial metrics recorded prior to the cut in dividends.</p><p>The implementation of this test case is very similar to the binary SVC driver code, except for the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The classifier uses the Nu-SVM formulation, <code class="literal">OneSVFormulation</code></li><li class="listitem">The labeled data is generated by assigning -1 to companies that have eliminated their dividends and +1 for all other companies</li></ul></div><p>The test is executed against the <code class="literal">resources/data/chap8/dividends2.csv</code> dataset. First, we need to define the formulation for the one-class SVM:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>OneSVCFormulation</strong></span>(nu: Double) extends SVMFormulation {
  override def update(param: svm_parameter): Unit = {
    param.svm_type = svm_parameter.ONE_CLASS
    param.nu = nu
  }
}</pre></div><p>The test code is similar to the execution code for the binomial SVC. The only difference is the definition of the output labels; -1 for companies eliminating dividends and +1 for all other companies:</p><div class="informalexample"><pre class="programlisting">val NU = 0.2
val GAMMA = 0.5
val EPS = 1e-3
val NFOLDS = 2

val <span class="strong"><strong>extractor</strong></span> = relPriceChange :: debtToEquity ::
   dividendCoverage :: cashPerShareToPrice :: epsTrend ::
   <span class="strong"><strong>dividendTrend</strong></span> :: List[Array[String] =&gt;Double]()

val <span class="strong"><strong>filter</strong></span> = (x: Double) =&gt; if(x == 0) -1.0 else 1.0  //<span class="strong"><strong>43</strong></span>
val pfnSrc = DataSource(path, true, false, 1) |&gt;
val config = SVMConfig(new <span class="strong"><strong>OneSVCFormulation</strong></span>(NU),  //<span class="strong"><strong>44</strong></span>
    new RbfKernel(GAMMA), SVMExecution(EPS, NFOLDS))

for {
  input &lt;- pfnSrc(extractor)
  obs &lt;- getObservations(input)
  svc &lt;- SVM[Double](config, obs, 
             input.last.map(filter(_)).toVector)
} yield {
  show(s"${svc.toString}\naccuracy ${svc.accuracy.get}")'
}</pre></div><p>The labels <a id="id9140000" class="indexterm"/>or expected data is generated by applying a binary filter to the last <code class="literal">dividendTrend</code> field (line <code class="literal">43</code>). The formulation in the configuration has the <code class="literal">OneSVCFormulation</code> type (line <code class="literal">44</code>).</p><p>The model is generated with the accuracy of 0.821. This level of accuracy should not be a surprise; the outliers (companies that eliminated their dividends) are added to the original dividend <code class="literal">.csv</code> file. These outliers differ significantly from the baseline observations (companies who have reduced, maintained, or increased their dividends) in the original input file.</p><p>In cases where the labeled observations are available, the one-class support vector machine is an excellent alternative to clustering techniques.</p><div class="note" title="Note"><h3 class="title"><a id="note27400"/>Note</h3><p>
<span class="strong"><strong>The definition of an anomaly</strong></span>
</p><p>The results generated by a one-class support vector classifier depend heavily on the subjective definition of an outlier. The test case assumes that the companies that eliminate their dividends have unique characteristics that set them apart and are different even from companies who have cut, maintained, or increased their dividends. There is no guarantee that this assumption is indeed always valid.</p></div></div>
<div class="section" title="Support vector regression"><div class="titlepage" id="aid-62HIO2"><div><div><h1 class="title"><a id="ch08lvl1sec5700"/>Support vector regression</h1></div></div></div><p>Most of the <a id="id9150000" class="indexterm"/>applications using support vector machines are related to classification. However, the same technique can be applied to regression problems. Luckily, as with classification, LIBSVM supports two formulations for support vector regression:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">∈-VR (sometimes called C-SVR)</li><li class="listitem">υ-SVR</li></ul></div><p>For the sake of consistency with the two previous cases, the following test uses the ∈ (or <span class="emphasis"><em>C</em></span>) formulation of the support vector regression.</p><div class="section" title="An overview"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10600"/>An overview</h2></div></div></div><p>The SVR <a id="id9160000" class="indexterm"/>introduces the concept of <a id="id9170000" class="indexterm"/><span class="strong"><strong>error insensitive zone</strong></span> and <a id="id9180000" class="indexterm"/>insensitive error, <span class="emphasis"><em>ε</em></span>. The insensitive zone defines a range of values around the predictive values, <span class="emphasis"><em>y(x)</em></span>. The penalization component <span class="emphasis"><em>C</em></span> does not affect the data point <span class="emphasis"><em>{x<sub>i</sub>,y<sub>i</sub>}</em></span> that belongs to the insensitive zone [8:14].</p><p>The following diagram illustrates the concept of an error insensitive zone using a single variable feature <span class="emphasis"><em>x</em></span> and an output <span class="emphasis"><em>y</em></span>. In the case of a single variable feature, the error insensitive zone is a band of width <span class="emphasis"><em>2ε</em></span> (<span class="emphasis"><em>ε</em></span> is known as the insensitive error). The insensitive error plays a similar role to the margin in the SVC.</p><div class="mediaobject"><img src="../Images/image01498.jpeg" alt="An overview"/><div class="caption"><p>The visualization of the support vector regression and insensitive error</p></div></div><p style="clear:both; height: 1em;"> </p><p>For the mathematically inclined, the maximization of the margin for nonlinear models introduces a pair of slack variables. As you may remember, the C-support vector classifiers use a <a id="id9190000" class="indexterm"/>single slack variable. The preceding diagram illustrates the minimization formula.</p><div class="note" title="Note"><h3 class="title"><a id="note27500"/>Note</h3><p>M9: The ε-SVR formulation is defined as:</p><div class="mediaobject"><img src="../Images/image01499.jpeg" alt="An overview"/></div><p style="clear:both; height: 1em;"> </p><p>Here, <span class="emphasis"><em>ε</em></span> is the insensitive error function.</p><p>M10: The ε-SVR regression equation is given by:</p><div class="mediaobject"><img src="../Images/image01500.jpeg" alt="An overview"/></div><p style="clear:both; height: 1em;"> </p></div><p>Let's reuse the <code class="literal">SVM</code> class to evaluate the capability of the SVR, compared to the linear regression (refer to the <span class="emphasis"><em>Ordinary least squares regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</p></div><div class="section" title="SVR versus linear regression"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec10700"/>SVR versus linear regression</h2></div></div></div><p>This test <a id="id9200000" class="indexterm"/>consists of reusing the example on single-variate <a id="id9210000" class="indexterm"/>linear regression (refer to the <span class="emphasis"><em>One-variate linear regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>). The purpose is to compare the output of the linear regression with the output of the SVR for predicting the value of a stock price or an index. We select the S&amp;P 500 exchange traded fund, SPY, which is a proxy for the S&amp;P 500 index.</p><p>The model consists of the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">One labeled output: SPY-adjusted daily closing price</li><li class="listitem">One single variable feature set: the index of the trading session (or index of the values SPY)</li></ul></div><p>The implementation <a id="id9220000" class="indexterm"/>follows a familiar pattern:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define the <a id="id9230000" class="indexterm"/>configuration parameters for the SVR (the <code class="literal">C</code> cost/penalty function, <code class="literal">GAMMA</code> coefficient for the RBF kernel, <code class="literal">EPS</code> for the convergence criteria, and <code class="literal">EPSILON</code> for the regression insensitive error).</li><li class="listitem">Extract the labeled data (the SPY <code class="literal">price</code>) from the data source (<code class="literal">DataSource</code>), which is the Yahoo financials CSV-formatted data file.</li><li class="listitem">Create the linear regression, <code class="literal">SingleLinearRegression</code>, with the index of the trading session as the single variable feature and the SPY-adjusted closing price as the labeled output.</li><li class="listitem">Create the observations as a time series of indices, <code class="literal">xt</code>.</li><li class="listitem">Instantiate the SVR with the index of trading session as features and the SPY-adjusted closing price as the labeled output.</li><li class="listitem">Run the prediction methods for both SVR and the linear regression and compare the results of the linear regression and SVR, <code class="literal">collect</code>.</li></ol><div style="height:10px; width: 1px"/></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">val path = "resources/data/chap8/SPY.csv"
val C = 12
val GAMMA = 0.3
val EPSILON = 2.5

val config = SVMConfig(new SVRFormulation(C, EPSILON), 
    new RbfKernel(GAMMA)) //<span class="strong"><strong>45</strong></span>
for {
  price &lt;-  DataSource(path, false, true, 1) get close
  (xt, y) &lt;- <span class="strong"><strong>getLabeledData</strong></span>(price.size)  //<span class="strong"><strong>46</strong></span>
  linRg &lt;- <span class="strong"><strong>SingleLinearRegression</strong></span>[Double](price, y) //<span class="strong"><strong>47</strong></span>
  svr &lt;- SVM[Double](config, xt, price)
} yield {
  collect(svr, linRg, price)
}</pre></div><p>The formulation in the configuration has the <code class="literal">SVRFormulation</code> type (line <code class="literal">45</code>). The <code class="literal">DataSource</code> class extracts the price of the SPY ETF. The <code class="literal">getLabeledData</code> method generates the <code class="literal">xt</code> input features and the <code class="literal">y</code> labels (or expected values) (line <code class="literal">46</code>):</p><div class="informalexample"><pre class="programlisting">type LabeledData = (Vector[DblArray], DblVector)
def <span class="strong"><strong>getLabeledData</strong></span>(numObs: Int): Try[LabeledData ] = Try {
    val y = Vector.tabulate(numObs)(_.toDouble)
    val xt = Vector.tabulate(numObs)(Array[Double](_))
    (xt, y)
}</pre></div><p>The single <a id="id9240000" class="indexterm"/>variate linear regression, <code class="literal">SingleLinearRegression</code>, is instantiated using the <code class="literal">price</code> input and <code class="literal">y</code> labels as inputs (line <code class="literal">47</code>).</p><p>Finally, the <code class="literal">collect</code> method <a id="id9250000" class="indexterm"/>executes the two <code class="literal">pfSvr</code> and <code class="literal">pfLinr</code> regression partial functions:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>collect</strong></span>(svr: SVM[Double], 
   linr: SingleLinearRegression[Double], price: DblVector){
  
  val <span class="strong"><strong>pfSvr</strong></span> = svr |&gt;
  val <span class="strong"><strong>pfLinr</strong></span> = linr |&gt;
  for {
    if( pfSvr.<span class="strong"><strong>isDefinedAt</strong></span>(n.toDouble))
    x &lt;- pfSvr(n.toDouble) 
    if( pfLin.<span class="strong"><strong>isDefinedAt</strong></span>(n))
    y &lt;- pfLinr(n)
  } yield  {  ... }
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note27700"/>Note</h3><p>
<span class="strong"><strong>isDefinedAt</strong></span>
</p><p>It is a good practice to validate whether a partial function is defined for a specific value of the argument or not. This preemptive approach allows the developer to select an alternative method or a full function. It is an efficient alternative to catch a <code class="literal">MathErr</code> exception.</p></div><p>The results are displayed in the following graph, which are generated using the JFreeChart library. The code to plot the data is omitted because it is not essential to the understanding of the application.</p><div class="mediaobject"><img src="../Images/image01501.jpeg" alt="SVR versus linear regression"/><div class="caption"><p>A comparative plot of linear regression and SVR</p></div></div><p style="clear:both; height: 1em;"> </p><p>The support <a id="id9260000" class="indexterm"/>vector regression <a id="id9270000" class="indexterm"/>provides a more accurate prediction than the linear regression model. You can also observe that the L<sub>2</sub> regularization term of the SVR penalizes the data points (the SPY price) with a high deviation from the mean of the price. A lower value of <span class="emphasis"><em>C</em></span> will increase the L<sub>2</sub>-norm penalty factor as <span class="emphasis"><em>λ =1/C</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note27800"/>Note</h3><p>
<span class="strong"><strong>SVR and L<sub>2</sub></strong></span>
<span class="strong"><strong> regularization</strong></span>
</p><p>You are invited to run the use case with a different value of <span class="emphasis"><em>C</em></span> to quantify the impact of the L<sub>2</sub> regularization on the predictive values of the SVR.</p></div><p>There is no need to compare SVR with the logistic regression, as the logistic regression is a classifier. However, the SVM is related to the logistic regression; the hinge loss in the SVM is similar to the loss in the logistic regression [8:15].</p></div></div>
<div class="section" title="Performance considerations" id="aid-63G3A1"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec5800"/>Performance considerations</h1></div></div></div><p>You may <a id="id9280000" class="indexterm"/>have already observed that the training of a model for the support vector regression on a large dataset is time consuming. The performance of the support vector machine depends on the type of optimizer (for example, a sequential <a id="id9290000" class="indexterm"/>minimal optimization) selected to maximize the margin during training:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A linear model (a SVM without kernel) has an asymptotic time complexity <span class="emphasis"><em>O(N)</em></span> for training <span class="emphasis"><em>N</em></span> labeled observations.</li><li class="listitem">Nonlinear models rely on kernel methods formulated as a quadratic programming problem with an asymptotic time complexity of <span class="emphasis"><em>O(N<sup>3</sup>)</em></span></li><li class="listitem">An algorithm that uses sequential minimal optimization techniques, such as index caching or elimination of null values (as in LIBSVM), has an asymptotic time complexity of <span class="emphasis"><em>O(N<sup>2</sup>)</em></span> with the worst case scenario (quadratic optimization) of <span class="emphasis"><em>O(N<sup>3</sup>)</em></span></li><li class="listitem">Sparse problems for very large training sets (<span class="emphasis"><em>N &gt; 10,000</em></span>) also have an asymptotic time of <span class="emphasis"><em>O(N<sup>2</sup>)</em></span></li></ul></div><p>The time and space complexity of the kernelized support vector machine has been receiving a great deal of attention [8:16] [8:17].</p></div>
<div class="section" title="Summary" id="aid-64EJS1"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec5900"/>Summary</h1></div></div></div><p>This concludes our investigation of kernel and support vector machines. Support vector machines have become a robust alternative to logistic regression and neural networks for extracting discriminative models from large training sets.</p><p>Apart from the unavoidable references to the mathematical foundation of maximum margin classifiers, such as SVMs, you should have developed a basic understanding of the power and complexity of the tuning and configuration parameters of the different variants of SVMs.</p><p>As with other discriminative models, the selection of the optimization method for SVMs has a critical impact not only on the quality of the model, but also on the performance (time complexity) of the training and cross-validation process.</p><p>The next chapter will describe the third most commonly used discriminative supervised model—artificial neural networks.</p></div>
<div class="chapter" title="Chapter&#xA0;9.&#xA0;Artificial Neural Networks" id="aid-65D4E1"><div class="titlepage"><div><div><h1 class="title"><a id="ch23"/>Chapter 9. Artificial Neural Networks</h1></div></div></div><p>The popularity of neural networks surged in the 90s. They were seen as the silver bullet to a vast <a id="id9300000" class="indexterm"/>number of problems. At its core, a neural network is a nonlinear statistical model that leverages the logistic regression to create a nonlinear distributed model. The concept of artificial neural networks is rooted in biology, with the desire to simulate key functions of the brain and replicate its structure in terms of neurons, activation, and synapses.</p><p>In this chapter, you will move beyond the hype and learn the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The concepts and elements of the <span class="strong"><strong>multilayer perceptron</strong></span> (<span class="strong"><strong>MLP</strong></span>)</li><li class="listitem">How to train a neural network using error backpropagation</li><li class="listitem">The evaluation and tuning of MLP configuration parameters</li><li class="listitem">A full Scala implementation of the MLP classifier</li><li class="listitem">How to apply MLP to extract correlation models for currency exchange rates</li><li class="listitem">A brief introduction to <span class="strong"><strong>convolutional neural network</strong></span> (<span class="strong"><strong>CNN</strong></span>)</li></ul></div><div class="section" title="Feed-forward neural networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec6000"/>Feed-forward neural networks</h1></div></div></div><p>The idea <a id="id9310000" class="indexterm"/>behind <a id="id9320000" class="indexterm"/>artificial neural networks was to build mathematical and computational models of the natural neural network in the brain. After all, the brain is a very powerful information processing engine that surpasses computers in domains, such as learning, inductive reasoning, prediction and vision, and speech recognition.</p><div class="section" title="The biological background"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec10800"/>The biological background</h2></div></div></div><p>In biology, a <a id="id9330000" class="indexterm"/>neural network is composed of groups of neurons interconnected through synapses [9:1], as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01502.jpeg" alt="The biological background"/><div class="caption"><p>The visualization of biological neurons and synapses</p></div></div><p style="clear:both; height: 1em;"> </p><p>Neuroscientists have been especially interested in understanding how billions of neurons in the brain can interact to provide human beings with parallel processing capabilities. The 60s saw a new field of study emerging, known as <a id="id9340000" class="indexterm"/><span class="strong"><strong>connectionism</strong></span>. Connectionism marries cognitive psychology, artificial intelligence, and neuroscience. The goal was to create a model for mental phenomena. Although there are many forms of connectionism, the neural network models have become the most popular and the most taught of all connectionism models [9:2].</p><p>Biological neurons communicate with electrical charges known as <a id="id9350000" class="indexterm"/><span class="strong"><strong>stimuli</strong></span>. This network of neurons can be represented as a simple schematic, as follows:</p><div class="mediaobject"><img src="../Images/image01503.jpeg" alt="The biological background"/><div class="caption"><p>The representation of neuron layers, connections, and synapses</p></div></div><p style="clear:both; height: 1em;"> </p><p>This representation categorizes groups of neurons as layers. The terminology used to describe the natural neural networks has a corresponding nomenclature for the artificial neural network.</p><div class="informaltable"><table border="1"><colgroup><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>The biological neural network</p>
</th><th valign="bottom">
<p>The artificial neuron network</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>Axon</p>
</td><td valign="top">
<p>Connection</p>
</td></tr><tr><td valign="top">
<p>Dendrite</p>
</td><td valign="top">
<p>Connection</p>
</td></tr><tr><td valign="top">
<p>Synapse</p>
</td><td valign="top">
<p>Weight</p>
</td></tr><tr><td valign="top">
<p>Potential</p>
</td><td valign="top">
<p>Weighted sum</p>
</td></tr><tr><td valign="top">
<p>Threshold</p>
</td><td valign="top">
<p>Bias weight</p>
</td></tr><tr><td valign="top">
<p>Signal, Stimulus</p>
</td><td valign="top">
<p>Activation</p>
</td></tr><tr><td valign="top">
<p>Group of neurons</p>
</td><td valign="top">
<p>Layer of neurons</p>
</td></tr></tbody></table></div><p>In the <a id="id9360000" class="indexterm"/>biological world, stimuli do not propagate in any specific direction between neurons. An artificial neural network can have the same degree of freedom. The most commonly used artificial neural networks by data scientists have a predefined direction: from <a id="id9370000" class="indexterm"/>the input layer to output layers. These neural networks are known as a <span class="strong"><strong>feed-forward neural network</strong></span> (<span class="strong"><strong>FFNN</strong></span>).</p></div><div class="section" title="Mathematical background"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec10900"/>Mathematical background</h2></div></div></div><p>In the <a id="id9380000" class="indexterm"/>previous chapter, you learned that support vector machines have the ability to formulate the training of a model as a nonlinear optimization for which the objective function is convex. A convex objective function is fairly straightforward to implement. The drawback is that the kernelization of the SVM may result in a large number of basis functions (or model dimensions). Refer to the <span class="emphasis"><em>The kernel trick</em></span> section under <span class="emphasis"><em>Support vector machines</em></span> in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>. One solution is to reduce the number of basis functions through parameterization, so these functions can adapt to different training sets. Such an approach can be modeled as a FFNN, known as the multilayer perceptron [9:3].</p><p>The linear regression can be visualized as a simple connectivity model using neurons and synapses, as follows:</p><div class="mediaobject"><img src="../Images/image01504.jpeg" alt="Mathematical background"/><div class="caption"><p>A two-layer neural network</p></div></div><p style="clear:both; height: 1em;"> </p><p>The feature <span class="emphasis"><em>x<sub>0</sub>=+1</em></span> is known as the <a id="id9390000" class="indexterm"/><span class="strong"><strong>bias input</strong></span> (or the bias element), which corresponds to the intercept in the classic linear regression.</p><p>As with <a id="id9400000" class="indexterm"/>support vector machines, linear regression is appropriate for observations that can be linearly separable. The real world is usually driven by a nonlinear phenomenon. Therefore, the logistic regression is naturally used to compute the output of the perceptron. For a set of input variable <span class="emphasis"><em>x = {x<sub>i</sub>}<sub>0,n</sub></em></span> and the weights <span class="emphasis"><em>w={w<sub>i</sub>}<sub>1,n</sub></em></span>, the output <span class="emphasis"><em>y</em></span> is computed as follows (<span class="strong"><strong>M1</strong></span>):</p><div class="mediaobject"><img src="../Images/image01505.jpeg" alt="Mathematical background"/></div><p style="clear:both; height: 1em;"> </p><p>A FFNN can be regarded as a stack of layers of logistic regression with the output layer as a linear regression.</p><p>The value of the variables in each hidden layer is computed as the sigmoid of the dot product of the connection weights and the output of the previous layer. Although interesting, the theory behind artificial neural networks is beyond the scope of this book [9:4].</p></div></div></div>
<div class="section" title="The multilayer perceptron"><div class="titlepage" id="aid-66BL02"><div><div><h1 class="title"><a id="ch09lvl1sec6100"/>The multilayer perceptron</h1></div></div></div><p>The <a id="id9410000" class="indexterm"/>perceptron is a basic processing element that performs a binary classification by mapping a scalar or vector to a binary (or <span class="strong"><strong>XOR</strong></span>) value <span class="emphasis"><em>{true, false}</em></span> or <span class="emphasis"><em>{-1, +1}</em></span>. The original perceptron algorithm was defined as a single layer of neurons for which each value <span class="emphasis"><em>x<sub>i</sub></em></span> of the feature vector is processed in parallel and generates a single output <span class="emphasis"><em>y</em></span>. The perceptron was later extended to encompass the concept of an activation function.</p><p>The single layer perceptrons are limited to process a single linear combination of weights and input values. Scientists found out that adding intermediate layers between the input and output layers enable them to solve more complex classification problems. These intermediate layers are known as <a id="id9420000" class="indexterm"/><span class="strong"><strong>hidden layers</strong></span> because they interface only with other perceptrons. Hidden nodes can be accessed only through the input layer.</p><p>From now on, we will use a three-layered perceptron to investigate and illustrate the properties of neural networks, as shown here:</p><div class="mediaobject"><img src="../Images/image01506.jpeg" alt="The multilayer perceptron"/><div class="caption"><p>A three-layered perceptron</p></div></div><p style="clear:both; height: 1em;"> </p><p>The three-layered perceptron requires two sets of weights: <span class="emphasis"><em>w<sub>ij</sub></em></span> to process the output of the input layer to the hidden layer and <span class="emphasis"><em>v<sub>ij</sub></em></span> between the hidden layer and the output layer. The intercept value <span class="emphasis"><em>w<sub>0</sub></em></span>, in both linear and logistic regression, is represented with <span class="emphasis"><em>+1</em></span> in the visualization of the neural network (<span class="emphasis"><em>w<sub>0</sub>.1+ w<sub>1</sub>.x<sub>1</sub>+w<sub>2</sub>.x<sub>2</sub>+ …</em></span>).</p><div class="note" title="Note"><h3 class="title"><a id="note27900"/>Note</h3><p>
<span class="strong"><strong>A FFNN without a hidden layer</strong></span>
</p><p>A <a id="id9430000" class="indexterm"/>FFNN without a hidden layer is similar to a linear statistical model. The only transformation or connection between the input and output layer is actually a linear regression. A linear regression is a more efficient alternative to the FFNN without a hidden layer.</p></div><p>The <a id="id9440000" class="indexterm"/>description of the MLP components and their implementations rely on the following stages:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">An overview of the software design.</li><li class="listitem">A description of the MLP model components.</li><li class="listitem">The implementation of the four-step training cycle.</li><li class="listitem">The definition and implementation of the training strategy and the resulting classifier.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note28000"/>Note</h3><p>
<span class="strong"><strong>Terminology</strong></span>
</p><p>Artificial neural networks encompass a large variety of learning algorithms, the multilayer perceptron being one of them. Perceptrons are indeed components of a neural network organized as the input, output, and hidden layers. This chapter is dedicated to the multilayer perceptron with hidden layers. The terms "neural network" and "multilayer perceptron" are used interchangeably.</p></div><div class="section" title="The activation function"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11000"/>The activation function</h2></div></div></div><p>The <a id="id9450000" class="indexterm"/>perceptron is represented as a linear combination of weights <span class="emphasis"><em>w<sub>i</sub></em></span> and input values <span class="emphasis"><em>x<sub>i</sub></em></span> processed by the output unit activation function <span class="emphasis"><em>h</em></span>, as shown here (<span class="strong"><strong>M2</strong></span>):</p><div class="mediaobject"><img src="../Images/image01507.jpeg" alt="The activation function"/></div><p style="clear:both; height: 1em;"> </p><p>The output activation function <span class="emphasis"><em>h</em></span> has to be continuous and differentiable for a range of value of the weights. It takes different forms depending on the problems to be solved, as mentioned here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An identity for the output layer (linear formula) of the regression mode</li><li class="listitem">The sigmoid <span class="emphasis"><em>σ</em></span> for hidden layers and output layers of the binomial classifier</li><li class="listitem">Softmax for the multinomial classification</li><li class="listitem">The hyperbolic tangent, <span class="emphasis"><em>tanh</em></span>, for the classification using zero mean</li></ul></div><p>The <a id="id9460000" class="indexterm"/>softmax formula is described in <span class="emphasis"><em>Step 1 – input forward propagation</em></span> under <span class="emphasis"><em>Training epoch</em></span>.</p></div><div class="section" title="The network topology"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11100"/>The network topology</h2></div></div></div><p>The <a id="id9470000" class="indexterm"/>output layers and hidden layers have a computational capability (dot product of weights, inputs, and activation functions). The input layer does not transform data. An n-layer neural network is a network with <span class="emphasis"><em>n</em></span> computational layers. Its architecture consists of the following components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">one input layer</li><li class="listitem"><span class="emphasis"><em>n-1</em></span> hidden layer</li><li class="listitem">one output layer</li></ul></div><p>A <span class="strong"><strong>fully connected neural network</strong></span> <a id="id9480000" class="indexterm"/>has all its input nodes connected to hidden layer neurons. Networks are characterized as <a id="id9490000" class="indexterm"/><span class="strong"><strong>partially connected neural networks</strong></span> if one or more of their input variables are not processed. This chapter deals with a fully connected neural network.</p><div class="note" title="Note"><h3 class="title"><a id="note28100"/>Note</h3><p>
<span class="strong"><strong>Partially connected networks</strong></span>
</p><p>Partially connected networks are not as complex as they seem. They can be generated from fully connected networks by setting some of the weights to zero.</p></div><p>The structure of the output layer is highly dependent on the type of problems (regression or classification) you need to solve, also known as the operating mode of the multilayer perceptron. The type of problem at hand defines the number of output nodes [9:5]. Consider the following examples:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A one-variate regression has one output node whose value is a real number [0, 1]</li><li class="listitem">A multivariate regression with <span class="emphasis"><em>n</em></span> variables has <span class="emphasis"><em>n</em></span> real output nodes</li><li class="listitem">A binary classification has one binary output node <span class="emphasis"><em>{0, 1}</em></span> or <span class="emphasis"><em>{-1, +1}</em></span></li><li class="listitem">A multinomial or K-class classification has <span class="emphasis"><em>K</em></span> binary output nodes</li></ul></div></div><div class="section" title="Design"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11200"/>Design</h2></div></div></div><p>The implementation of the <a id="id9500000" class="indexterm"/>MLP classifier follows the same pattern as previous classifiers (refer to the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An <code class="literal">MLPNetwork</code> connectionist network is composed of a layer of neurons of the <code class="literal">MLPLayer</code> type, connected by synapses of the <code class="literal">MLPSynapse</code> type contained by a connector of the <code class="literal">MLPConnection</code> type.</li><li class="listitem">All of the configuration parameters are encapsulated into a single <code class="literal">MLPConfig</code> configuration class.</li><li class="listitem">A model, <code class="literal">MLPModel</code>, consists of a sequence of connection synapses.</li><li class="listitem">The <code class="literal">MLP</code> multilayer perceptron class is implemented as a data transformation, <code class="literal">ITransform</code>, for which the model is automatically extracted from a training set with labels.</li><li class="listitem">The <code class="literal">MLP</code> multilayer perceptron class takes four parameters: a configuration, a features set or time series of the <code class="literal">XVSeries</code> type, a labeled dataset of the <code class="literal">XVSeries</code> type, and an activation function of the <code class="literal">Function1[Double, Double]</code> type.</li></ul></div><p>The software components of the <a id="id9510000" class="indexterm"/>multilayer perceptron are described in the following UML class diagram:</p><p>.</p><div class="mediaobject"><img src="../Images/image01508.jpeg" alt="Design"/><div class="caption"><p>A UML class diagram for the multilayer perceptron</p></div></div><p style="clear:both; height: 1em;"> </p><p>
</p><p>The class diagram is a convenient navigation map used to understand the role and relation of the Scala classes used to build an MLP. Let's start with the implementation of the MLP network and its components. The UML diagram omits the helper traits or classes such as <code class="literal">Monitor</code> or the Apache Commons Math components.</p></div><div class="section" title="Configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11300"/>Configuration</h2></div></div></div><p>The <code class="literal">MLPConfig</code> configuration <a id="id9520000" class="indexterm"/>of the multilayer perceptron consists of the definition of the network configuration with its hidden layers, the learning and training parameters, and the activation function:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>MLPConfig</strong></span>(
    val <span class="strong"><strong>alpha</strong></span>: Double,  //<span class="strong"><strong>1</strong></span>
    val <span class="strong"><strong>eta</strong></span>: Double, 
    val <span class="strong"><strong>numEpochs</strong></span>: Int, 
    val <span class="strong"><strong>eps</strong></span>: Double, 
    val <span class="strong"><strong>activation</strong></span>: Double =&gt; Double) extends <span class="strong"><strong>Config</strong></span> {  //<span class="strong"><strong>1</strong></span>
}</pre></div><p>For the sake of readability, the name of the configuration parameters matches the symbols defined in the mathematical formulation (line <code class="literal">1</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">alpha</code>: This is the momentum factor <span class="emphasis"><em>α</em></span> that smoothes the computation of the gradient of the weights for online training. The momentum factor is used in the mathematical expression <span class="strong"><strong>M10</strong></span> in <span class="emphasis"><em>Step 2 – error backpropagation</em></span> under <span class="emphasis"><em>Training epoch</em></span>.</li><li class="listitem"><code class="literal">eta</code>: This is the learning rate <span class="emphasis"><em>η</em></span> used in the gradient descent. The gradient descent updates the weights or parameters of a model by the quantity, <span class="emphasis"><em>eta.(predicted – expected).input,</em></span> as described in the mathematical formulation <span class="strong"><strong>M9</strong></span> in <span class="emphasis"><em>Step 2 – error backpropagation</em></span> section under <span class="emphasis"><em>The training epoch</em></span>. The gradient descent was introduced in <span class="emphasis"><em>Let's kick the tires</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</li><li class="listitem"><code class="literal">numEpochs</code>: This is the maximum number of epochs (or cycles or episodes) allowed for training the neural network. An epoch is the execution of the error backpropagation across the entire observation set.</li><li class="listitem"><code class="literal">eps</code>: This is the convergence criteria used as an exit condition for the training of the neural network when <span class="emphasis"><em>error &lt; eps</em></span>.</li><li class="listitem"><code class="literal">activation</code>: This is the activation function used for nonlinear regression applied to hidden layers. The default function is the sigmoid (or the hyperbolic tangent) introduced for the logistic regression (refer to the <span class="emphasis"><em>Logistic function</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</li></ul></div></div><div class="section" title="Network components"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11400"/>Network components</h2></div></div></div><p>The training <a id="id9530000" class="indexterm"/>and classification<a id="id9540000" class="indexterm"/> of an MLP model relies on the network architecture. The <code class="literal">MLPNetwork</code> class is responsible for creating and managing the different components and the topology of the network, that is layers, synapses, and connections.</p><div class="section" title="The network topology"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12000"/>The network topology</h3></div></div></div><p>The <a id="id9550000" class="indexterm"/>instantiation of the <code class="literal">MLPNetwork</code> class requires a minimum set of two parameters with an instance of the model as an optional third argument (line <code class="literal">2</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An MLP execution configuration, <code class="literal">config</code>, introduced in the previous section</li><li class="listitem">A <code class="literal">topology</code> defined as an array of the number of nodes for each layer: input, hidden, and output layers.</li><li class="listitem">A <code class="literal">model</code> with the <code class="literal">Option[MLPModel]</code> type if it has already been generated through training, or <code class="literal">None</code> otherwise</li><li class="listitem">An implicit reference to the operating <code class="literal">mode</code> of the MLP</li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPNetwork</strong></span>(<span class="strong"><strong>config</strong></span>: MLPConfig, 
     <span class="strong"><strong>topology</strong></span>: Array[Int], 
     <span class="strong"><strong>model</strong></span>: Option[<span class="strong"><strong>MLPModel</strong></span>] = None)
     (implicit <span class="strong"><strong>mode</strong></span>: MLPMode){ //<span class="strong"><strong>2</strong></span>

  val <span class="strong"><strong>layers</strong></span> = topology.zipWithIndex.map { case(t, n) =&gt; 
    if(topology.size != n+1) 
       MLPLayer(n, t+1, config.activation) 
   else MLPOutLayer(n, t) 
  }  //<span class="strong"><strong>3</strong></span>
  val <span class="strong"><strong>connections</strong></span> = <span class="strong"><strong>zipWithShift1</strong></span>(layers,1).map{case(src,dst) =&gt; 
     new MLPConnection(config, src, dst,  model)} //<span class="strong"><strong>4</strong></span>

  def <span class="strong"><strong>trainEpoch</strong></span>(x: DblArray, y: DblArray): Double //<span class="strong"><strong>5</strong></span>
  def getModel: MLPModel  //<span class="strong"><strong>6</strong></span>
  def <span class="strong"><strong>predict</strong></span>(x: DblArray): DblArray  //<span class="strong"><strong>7</strong></span>
}</pre></div><p>A MLP network has the following components, which are derived from the topology array:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Multiple <code class="literal">layers</code> of the <code class="literal">MLPLayers</code> class (line <code class="literal">3</code>)</li><li class="listitem">Multiple <code class="literal">connections</code> of the <code class="literal">MLPConnection</code> class (line <code class="literal">4</code>)</li></ul></div><p>The topology is defined as an array of number of nodes per layer, starting with the input nodes. The array indices follow the forward path within the network. The size of the input layer is automatically generated from the observations as the size of the features vector. The size of the output layer is automatically extracted from the size of the output vector (line <code class="literal">3</code>).</p><p>The constructor for <code class="literal">MLPNetwork</code> creates a sequence of layers by assigning and ordering an <code class="literal">MLPLayer</code> instance to each entry in the topology (line <code class="literal">3</code>). The constructor creates <span class="emphasis"><em>number of layers – 1</em></span> interlayer connections of the <code class="literal">MLPConnection</code> type (line <code class="literal">4</code>). The <code class="literal">zipWithShift1</code> method of the <code class="literal">XTSeries</code> object zips a time series with its duplicated shift by one element.</p><p>The <code class="literal">trainEpoch</code> method (line <code class="literal">5</code>) implements the training of this network for a single pass of the entire set of <a id="id9560000" class="indexterm"/>observations (refer to the <span class="emphasis"><em>Putting it all together</em></span> section under <span class="emphasis"><em>The training epoch</em></span>). The <code class="literal">getModel</code> method retrieves the model (synapses) generated through training of the MLP (line <code class="literal">6</code>). The <code class="literal">predict</code> method computes the output value generated from the network using the forward propagation algorithm (line <code class="literal">7</code>).</p><p>The following diagram visualizes the interaction between the different components of a model: <code class="literal">MLPLayer</code>, <code class="literal">MLPConnection</code>, and <code class="literal">MLPSynapse</code>:</p><div class="mediaobject"><img src="../Images/image01509.jpeg" alt="The network topology"/><div class="caption"><p>Core components of the MLP Network</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Input and hidden layers"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12100"/>Input and hidden layers</h3></div></div></div><p>First, let's start with <a id="id9570000" class="indexterm"/>the definition of the <code class="literal">MLPLayer</code> layer class, which is completely specified by its position (or rank) <code class="literal">id</code> in the network and the number of nodes, <code class="literal">numNodes</code>, it contains:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPLayer</strong></span>(val <span class="strong"><strong>id</strong></span>: Int, val <span class="strong"><strong>numNodes</strong></span>: Int, 
    val activation: Double =&gt; Double)  //<span class="strong"><strong>8</strong></span>
    (implicit mode: MLPMode){  //<span class="strong"><strong>9</strong></span>
  
  val output = Array.fill(numNodes)(1.0)  //<span class="strong"><strong>10</strong></span>

  def <span class="strong"><strong>setOutput</strong></span>(xt: DblArray): Unit =
      xt.copyToArray(output, 1) //<span class="strong"><strong>11</strong></span>
  def <span class="strong"><strong>activate</strong></span>(x: Double): Double = activation(x) .//<span class="strong"><strong>12</strong></span>
  def <span class="strong"><strong>delta</strong></span>(loss: DblArray, srcOut: DblArray, 
      synapses: MLPConnSynapses): Delta //<span class="strong"><strong>13</strong></span>
  def <span class="strong"><strong>setInput</strong></span>(_x: DblArray): Unit  //<span class="strong"><strong>14</strong></span>
}</pre></div><p>The <code class="literal">id</code> parameter is the order of the layer (0 for input, 1 for the first hidden layer, and <span class="emphasis"><em>n – 1</em></span> for the output layer) in the network. The <code class="literal">numNodes</code> value is the number of elements or nodes, including the bias element, in this layer. The <code class="literal">activation</code> function is the last argument of the layer given a user-defined mode or objective (line <code class="literal">8</code>). The operating <code class="literal">mode</code> has to be provided implicitly prior to the instantiation of a layer (line <code class="literal">9</code>).</p><p>The <code class="literal">output</code> vector <a id="id9580000" class="indexterm"/>for the layer is an uninitialized array of values updated during the forward propagation. It initializes the bias value with the value 1.0 (line <code class="literal">9</code>). The matrix of difference of weights, <code class="literal">deltaMatrix</code>, associated with the output vector (line <code class="literal">10</code>) is updated using the error backpropagation algorithm, as described in the <span class="emphasis"><em>Step 2 – error back propagation</em></span> section under <span class="emphasis"><em>The training epoch</em></span>. The <code class="literal">setOutput</code> method initializes the output values for the output and hidden layers during the backpropagation of the error on the output of the network (<span class="emphasis"><em>expected – predicted</em></span>) values (line <code class="literal">11</code>).</p><p>The <code class="literal">activate</code> method invokes the activation method (<span class="emphasis"><em>tanh</em></span>, <span class="emphasis"><em>sigmoid</em></span>, …) defined in the configuration (line <code class="literal">12</code>).</p><p>The <code class="literal">delta</code> method computes the correction to be applied to each weight or synapses, as described in the <span class="emphasis"><em>Step 2 – error back propagation</em></span> section under <span class="emphasis"><em>The training epoch</em></span> (line <code class="literal">13</code>).</p><p>The <code class="literal">setInput</code> method initializes the <code class="literal">output</code> values for the nodes of the input and hidden layers, except the bias element, with the value <code class="literal">x</code> (line <code class="literal">14</code>). The method is invoked during the forward propagation of input values:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>setInput</strong></span>(x: DblVector): Unit = 
  x.copyToArray(output, output.length -x.length)</pre></div><p>The methods of the <code class="literal">MLPLayer</code> class for the input and hidden layers are overridden for the output layer of the <code class="literal">MLPOutLayer</code> type.</p></div><div class="section" title="The output layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12200"/>The output layer</h3></div></div></div><p>Contrary <a id="id9590000" class="indexterm"/>to the hidden layers, the output layer does not have either an activation function or a bias element. The <code class="literal">MLPOutLayer</code> class has the following arguments: the order <code class="literal">id</code> in the network (as the last layer of the network) and the number, <code class="literal">numNodes</code>, of the output or nodes (line <code class="literal">15</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPOutLayer</strong></span>(<span class="strong"><strong>id</strong></span>: Int, <span class="strong"><strong>numNodes</strong></span>: Int) 
    (implicit <span class="strong"><strong>mode: MLP.MLPMode</strong></span>)  //<span class="strong"><strong>15</strong></span>
  extends MLPLayer(id, numNodes, (x: Double) =&gt; x) {

  override def <span class="strong"><strong>numNonBias</strong></span>: Int = numNodes
  override def <span class="strong"><strong>setOutput</strong></span>(xt: DblArray): Unit = 
    obj(xt).copyToArray(output)
  override def <span class="strong"><strong>delta</strong></span>(loss: DblArray, srcOut: DblArray, 
     synapses: MLPConnSynapses): Delta 
 …
}</pre></div><p>The <code class="literal">numNonBias</code> method <a id="id9600000" class="indexterm"/>returns the actual number of output values from the network. The implementation of the <code class="literal">delta</code> method is described in the <span class="emphasis"><em>Step 2 – error back propagation</em></span> section under <span class="emphasis"><em>The training epoch</em></span>.</p></div><div class="section" title="Synapses"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12300"/>Synapses</h3></div></div></div><p>A synapse is <a id="id9610000" class="indexterm"/>defined as a pair of real (a floating point) values:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The weight <span class="emphasis"><em>w<sub>ij</sub></em></span> of the connection from the neuron <span class="emphasis"><em>i</em></span> of the previous layer to the neuron <span class="emphasis"><em>j</em></span></li><li class="listitem">The weights' adjustment (or gradient of weights) <span class="emphasis"><em>∆w<sub>ij</sub></em></span></li></ul></div><p>Its type is defined as <code class="literal">MLPSynapse</code>, as shown here:</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>MLPSynapse</strong></span> = (Double, Double)</pre></div></div><div class="section" title="Connections"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12400"/>Connections</h3></div></div></div><p>The connections are <a id="id9620000" class="indexterm"/>instantiated by selecting two consecutive layers of an index <span class="emphasis"><em>n</em></span> (with respect to <span class="emphasis"><em>n + 1</em></span>) as a source (with respect to destination). A connection between two consecutive layers implements the matrix of synapses as the <span class="emphasis"><em>(w<sub>ij</sub></em></span>
<span class="emphasis"><em>, ∆w<sub>ij</sub>)</em></span> pairs. The <code class="literal">MLPConnection</code> instance is created with the following parameters (line <code class="literal">16</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Configuration parameters, <code class="literal">config</code></li><li class="listitem">The source layer, sometimes known as the ingress layer, <code class="literal">src</code></li><li class="listitem">The <code class="literal">dst</code> destination (or egress) layer</li><li class="listitem">A reference to the <code class="literal">model</code> if it has already been generated through training or <code class="literal">None</code> if the model has not been trained</li><li class="listitem">An implicitly defined operating <code class="literal">mode</code> or objective <code class="literal">mode</code></li></ul></div><p>The <code class="literal">MLPConnection</code> class is defined as follows:</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>MLPConnSynapses</strong></span> = Array[Array[MLPSynapse]]

class <span class="strong"><strong>MLPConnection</strong></span>(<span class="strong"><strong>config</strong></span>: MLPConfig, 
    <span class="strong"><strong>src</strong></span>: MLPLayer, 
    <span class="strong"><strong>dst</strong></span>: MLPLayer,
    <span class="strong"><strong>model</strong></span>: Option[MLPModel]) //<span class="strong"><strong>16</strong></span>
    (implicit <span class="strong"><strong>mode</strong></span>: MLP.MLPMode) {

  var <span class="strong"><strong>synapses</strong></span>: MLPConnSynapses  //<span class="strong"><strong>17</strong></span>
  def <span class="strong"><strong>connectionForwardPropagation</strong></span>: Unit //<span class="strong"><strong>18</strong></span>
  def <span class="strong"><strong>connectionBackpropagation</strong></span>(delta: Delta): Delta  //<span class="strong"><strong>19</strong></span>
    …
}</pre></div><p>The last step in the <a id="id9630000" class="indexterm"/>initialization of the MLP algorithm is the selection of the initial (usually random) values of the weights (synapse) (line <code class="literal">17</code>).</p><p>The <code class="literal">MLPConnection</code> methods implement the forward propagation of weights' computation for this <code class="literal">connectionForwardPropagation</code> connection (line <code class="literal">18</code>) and the backward propagation of the delta error during training <code class="literal">connectionBackpropagation</code> (line <code class="literal">19</code>). These methods are described in the next section related to the training of the MLP model.</p></div><div class="section" title="The initialization weights"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12500"/>The initialization weights</h3></div></div></div><p>The <a id="id9640000" class="indexterm"/>initialization values for the weights depends is domain specific. Some problems require a very small range, less than <span class="emphasis"><em>1e-3</em></span>, while others use the probability space <span class="emphasis"><em>[0, 1]</em></span>. The initial values have an impact on the number of epochs required to converge toward an optimal set of weights [9:6].</p><p>Our implementation relies on the sigmoid activation function and uses the range <span class="emphasis"><em>[0, BETA/sqrt(numOutputs + 1)]</em></span> (line <code class="literal">20</code>). However, the user can select a different range for random values, such as <span class="emphasis"><em>[-r, +r]</em></span> for the <span class="emphasis"><em>tanh</em></span> activation function. The weight of the bias is obviously defined as <span class="emphasis"><em>w<sub>0</sub></em></span>
<span class="emphasis"><em>=+1</em></span>, and its weight adjustment is initialized as <span class="emphasis"><em>∆w<sub>0</sub> = 0</em></span>, as shown here (line <code class="literal">20</code>):</p><div class="informalexample"><pre class="programlisting">var <span class="strong"><strong>synapses</strong></span>: MLPConnSynapses = if(model == None) {
  val max = BETA/Math.sqrt(src.output.length+1.0) //<span class="strong"><strong>20</strong></span>
  Array.fill(dst.numNonBias)(
    Array.fill(src.numNodes)((Random.nextDouble*max,0.00))
  )
} else model.get.synapses(src.id)  //<span class="strong"><strong>21</strong></span>
</pre></div><p>The connection derives its weights or synapses from a model (line <code class="literal">21</code>) if it has already been created through training.</p></div></div><div class="section" title="The model"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11500"/>The model</h2></div></div></div><p>The <code class="literal">MLPNetwork</code> class <a id="id9650000" class="indexterm"/>defines the topological model of the multilayer perceptron. The weights or synapses are the attributes of the model of the <code class="literal">MLPModel</code> type generated through training:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>MLPModel</strong></span>(
   val <span class="strong"><strong>synapses</strong></span>: Vector[MLPConnSynapses]) extends Model</pre></div><p>The model can be stored in a simple key-value pair JSON, CVS, or sequence file.</p><div class="note" title="Note"><h3 class="title"><a id="note28200"/>Note</h3><p>
<span class="strong"><strong>Encapsulation and the model factory</strong></span>
</p><p>The network components: connections, layers, and synapses are implemented as top-level classes for the sake of clarity. However, there is no need for the model to expose its inner workings to the client code. These components should be declared as an inner class to the model. A factory design pattern would be perfectly appropriate to instantiate an <code class="literal">MLPNetwork</code> instance dynamically [9:7].</p></div><p>Once initialized, the MLP model is ready to be trained using a combination of forward propagation, output error back propagation, and iterative adjustment of weights and gradients of weights.</p></div><div class="section" title="Problem types (modes)"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11600"/>Problem types (modes)</h2></div></div></div><p>There <a id="id9660000" class="indexterm"/>are three distinct types of problems or operating modes associated with the multilayer perceptron:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The binomial classification</strong></span> (binary) with two classes and one output</li><li class="listitem"><span class="strong"><strong>The multinomial classification</strong></span> (multiclass) with <span class="emphasis"><em>n</em></span> classes and output</li><li class="listitem"><span class="strong"><strong>Regression</strong></span></li></ul></div><p>Each operating mode has distinctive error, hidden layer, and output layer activation functions, as illustrated in the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Operating modes</p>
</th><th valign="bottom">
<p>Error function</p>
</th><th valign="bottom">
<p>Hidden layer activation function</p>
</th><th valign="bottom">
<p>Output layer activation function</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>Binomial classification</p>
</td><td valign="top">
<p>Cross-entropy</p>
</td><td valign="top">
<p>Sigmoid</p>
</td><td valign="top">
<p>Sigmoid</p>
</td></tr><tr><td valign="top">
<p>Multinomial classification</p>
</td><td valign="top">
<p>Sum of squares error or mean squared error</p>
</td><td valign="top">
<p>Sigmoid</p>
</td><td valign="top">
<p>Softmax</p>
</td></tr><tr><td valign="top">
<p>Regression</p>
</td><td valign="top">
<p>Sum of squares error or mean squared error</p>
</td><td valign="top">
<p>Sigmoid</p>
</td><td valign="top">
<p>Linear</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p>
<span class="emphasis"><em>A table for operating modes of the multilayer perceptron</em></span>
</p></blockquote></div><p>The cross-entropy <a id="id9670000" class="indexterm"/>is described by the mathematical expressions <span class="strong"><strong>M6</strong></span> and <span class="strong"><strong>M7</strong></span> and the softmax uses the formula <span class="strong"><strong>M8</strong></span> in the <span class="emphasis"><em>Step 1 – input forward propagation</em></span> section under <span class="emphasis"><em>The training epoch</em></span>.</p></div><div class="section" title="Online training versus batch training"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11700"/>Online training versus batch training</h2></div></div></div><p>One <a id="id9680000" class="indexterm"/>important issue is to find a strategy to conduct the training of a time series as an ordered sequence of data. There are two strategies to create an MLP model for a time series:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Batch training</strong></span>: The <a id="id9690000" class="indexterm"/>entire time series is processed at once as a single input to the neural network. The weights (synapses) are updated at each epoch using the sum of the squared errors on the output of the time series. The training exits once the sum of the squared errors meets the convergence criteria.</li><li class="listitem"><span class="strong"><strong>Online training</strong></span>: The <a id="id9700000" class="indexterm"/>observations are fed to the neural network one at a time. Once the time series has been processed, the total of the sum of the squared errors (<code class="literal">sse</code>) for the time series for all the observations are computed. If the exit condition is not met, the observations are reprocessed by the network.<div class="mediaobject"><img src="../Images/image01510.jpeg" alt="Online training versus batch training"/><div class="caption"><p>An illustration on online and batch training</p></div></div><p style="clear:both; height: 1em;"> </p></li></ul></div><p>An <a id="id9710000" class="indexterm"/>online training<a id="id9720000" class="indexterm"/> is faster than batch training because the convergence criterion has to be met for each data point, possibly resulting in a smaller number of epochs [9:12]. Techniques such as the momentum factor, which is described earlier, or any adaptive learning scheme improves the performance and accuracy of the online training methodology.</p><p>The online training strategy is applied to all the test cases of this chapter.</p></div><div class="section" title="The training epoch"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11800"/>The training epoch</h2></div></div></div><p>The <a id="id9730000" class="indexterm"/>training of the <a id="id9740000" class="indexterm"/>model processes the training observations iteratively multiple times. A training cycle or iteration is known as an <a id="id9750000" class="indexterm"/><span class="strong"><strong>epoch</strong></span>. The order of observations is shuffled for each epoch. The three steps of the training cycle are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Forward the propagation of the input value for a specific epoch.</li><li class="listitem">Computation and backpropagation of the output error.</li><li class="listitem">Evaluate the convergence criteria and exit if the criteria is met.</li></ol><div style="height:10px; width: 1px"/></div><p>The computation of the network weights during training can use the difference between labeled data and actual output for each layer. But this solution is not feasible because the output of the hidden layers is actually unknown. The solution is to propagate the error on the output values (predicted values) backward to the input layer through the hidden layers, if an error is defined.</p><p>The three steps of the training cycle or training epoch are summarized in the following diagram:</p><div class="mediaobject"><img src="../Images/image01511.jpeg" alt="The training epoch"/><div class="caption"><p>An iterative implementation of the training for MLP</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's apply <a id="id9760000" class="indexterm"/>the <a id="id9770000" class="indexterm"/>three steps of a training epoch in the <code class="literal">trainEpoch</code> method of the <code class="literal">MLPNetwork</code> class using a simple <code class="literal">foreach</code> Scala higher order function, as shown here:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>trainEpoch</strong></span>(x: DblArray, y: DblArray): Double = {
  layers.head.setInput(x)  //22
  connections.foreach( _.<span class="strong"><strong>connectionForwardPropagation</strong></span>) //<span class="strong"><strong>23</strong></span>

  val err = mode.error(y, layers.last.output) 
  val bckIterator = connections.reverseIterator 

  var delta = Delta(zipToArray(y, layers.last.output)(diff)) //<span class="strong"><strong>24</strong></span>
  bckIterator.foreach( iter =&gt; 
     delta = iter.<span class="strong"><strong>connectionBackpropagation</strong></span>(delta))  //<span class="strong"><strong>25</strong></span>
  err  //<span class="strong"><strong>26</strong></span>
}</pre></div><p>You can certainly recognize the first two stages of the training cycle: the forward propagation of the input and the backpropagation of the error of the online training of a single epoch.</p><p>The execution of the training of the network for one epoch, <code class="literal">trainEpoch</code>, initializes the input layer with observations, <code class="literal">x</code> (line <code class="literal">22</code>). The input values are propagated through the network by invoking <code class="literal">connectionForwardPropagation</code> for each connection (line <code class="literal">23</code>). The <code class="literal">delta</code> error is initialized from the values in the output layer and the expected values, <code class="literal">y</code> (line <code class="literal">24</code>).</p><p>The training method iterates through the connections backward to propagate the error through each connection by invoking the <code class="literal">connectionBackpropagation</code> method on the backward iterator, <code class="literal">bckIterator</code> (line <code class="literal">25</code>). Finally, the training method returns the cumulative error, mean square error, or cross entropy, according to the operating mode (line <code class="literal">26</code>).</p><p>This approach <a id="id9780000" class="indexterm"/>is not that different than the beta (or backward) pass in the hidden Markov model, which was covered in the <span class="emphasis"><em>Beta – the backward pass</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>.</p><p>Let's take a look <a id="id9790000" class="indexterm"/>at the implementation of the forward and backward propagation algorithm for each type of connection:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An input or hidden layer to a hidden layer</li><li class="listitem">A hidden layer to an output layer</li></ul></div><div class="section" title="Step 1 – input forward propagation"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12600"/>Step 1 – input forward propagation</h3></div></div></div><p>As mentioned <a id="id9800000" class="indexterm"/>earlier, the <a id="id9810000" class="indexterm"/>output values of a hidden layer are computed as the sigmoid or hyperbolic tangent of the dot product of the weights <span class="emphasis"><em>w<sub>ij</sub></em></span> and the input values <span class="emphasis"><em>x<sub>i</sub></em></span>.</p><p>In the following diagram, the MLP algorithm computes the linear product of the weights <span class="emphasis"><em>w<sub>ij</sub></em></span> and input <span class="emphasis"><em>x<sub>i</sub></em></span> for the hidden layer. The product is then processed by the activation function <span class="emphasis"><em>σ</em></span> (the sigmoid or hyperbolic tangent). The output values <span class="emphasis"><em>z<sub>j</sub></em></span> are then combined with the weights <span class="emphasis"><em>v<sub>ij</sub></em></span> of the output layer that doesn't have an activation function:</p><div class="mediaobject"><img src="../Images/image01512.jpeg" alt="Step 1 – input forward propagation"/><div class="caption"><p>The distribution of weights in MLP hidden and output layers</p></div></div><p style="clear:both; height: 1em;"> </p><p>The mathematical formulation of the output of a neuron <span class="emphasis"><em>j</em></span> is defined as a composition of the activation function and the dot product of the weights <span class="emphasis"><em>w<sub>ij</sub></em></span> and input values <span class="emphasis"><em>x<sub>i</sub></em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note28300"/>Note</h3><p>M3: The computation (or prediction) of the output layer from the output values <span class="emphasis"><em>z<sub>j</sub></em></span> of the preceding hidden layer and the weights <span class="emphasis"><em>vkj</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01513.jpeg" alt="Step 1 – input forward propagation"/></div><p style="clear:both; height: 1em;"> </p><p>M4: The estimation of the output values for a binary classification with an activation function <span class="emphasis"><em>σ</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01514.jpeg" alt="Step 1 – input forward propagation"/></div><p style="clear:both; height: 1em;"> </p></div><p>As seen in<a id="id9820000" class="indexterm"/> the <a id="id9830000" class="indexterm"/>network architecture section, the output values for the multinomial (or multiclass) classification with more than two classes are normalized using an exponential function, as described in the following <span class="emphasis"><em>Softmax</em></span> section.</p><div class="section" title="The computational flow"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec1900"/>The computational flow</h4></div></div></div><p>The <a id="id9840000" class="indexterm"/>computation of the output values <span class="emphasis"><em>y</em></span> from the input <span class="emphasis"><em>x</em></span> is known as the input forward propagation. For the sake of simplicity, we represent the forward propagation between layers with the following block diagram:</p><div class="mediaobject"><img src="../Images/image01515.jpeg" alt="The computational flow"/><div class="caption"><p>A computation model of the input forward propagation</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding diagram conveniently illustrates a computational model for the input forward propagation, as the programmatic relation between the source and destination layers and their connectivity. The input <span class="emphasis"><em>x</em></span> is propagated forward through each connection.</p><p>The <code class="literal">connectionForwardPropagation</code> method computes the dot product of the weights and the input values and applies the activation function, in the case of hidden layers, for each connection. Therefore, it is a member of the <code class="literal">MLPConnection</code> class.</p><p>The forward <a id="id9850000" class="indexterm"/>propagation of input values across the entire network is managed by the MLP algorithm itself. The forward propagation of the input value is used in the classification or prediction <span class="emphasis"><em>y = f(x)</em></span>. It depends on the value weights <span class="emphasis"><em>w<sub>ij</sub></em></span> and <span class="emphasis"><em>v<sub>ij</sub></em></span> that need to be estimated through training. As you may have guessed, the weights define the model of a neural network similar to the regression models. Let's take a look at the <code class="literal">connectionForwardPropagation</code> method of the <code class="literal">MLPConnection</code> class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>connectionForwardPropagation</strong></span>: Unit = {
  val _output = <span class="strong"><strong>synapses</strong></span>.map(x =&gt; {
    val dot = <span class="strong"><strong>inner</strong></span>(src.output, x.map(_._1) ) //<span class="strong"><strong>27</strong></span>
    dst.<span class="strong"><strong>activate</strong></span>(dot)  //<span class="strong"><strong>28</strong></span>
  })
  dst.setOutput(_output) //<span class="strong"><strong>29</strong></span>
}</pre></div><p>The first step is to compute the linear inner (or dot) product (refer to the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>) of the output, <code class="literal">_output</code>, of the current source layer for this connection and the synapses (weights) (line <code class="literal">27</code>). The activation function is computed by applying the <code class="literal">activate</code> method of the destination layer to the dot product (line <code class="literal">28</code>). Finally, the computed value, <code class="literal">_output</code>, is used to initialize the output for the destination layer (line <code class="literal">29</code>).</p></div><div class="section" title="Error functions"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2000"/>Error functions</h4></div></div></div><p>As <a id="id9860000" class="indexterm"/>mentioned in the <span class="emphasis"><em>Problem types (modes)</em></span> section, there are two approaches to compute the error or loss on the output values:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The sum of the squared errors between expected and predicted output values, as defined in the <span class="strong"><strong>M5</strong></span> mathematical expression</li><li class="listitem">Cross-entropy of expected and predicted values described in the <span class="strong"><strong>M6</strong></span> and <span class="strong"><strong>M7</strong></span> mathematical formulas</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note28500"/>Note</h3><p>M5: The sum of the squared errors <span class="emphasis"><em>ε</em></span> and mean square error for predicted values <span class="emphasis"><em>~y</em></span> and expected values <span class="emphasis"><em>y</em></span> are defined as:</p><div class="mediaobject"><img src="../Images/image01516.jpeg" alt="Error functions"/></div><p style="clear:both; height: 1em;"> </p><p>M6: Cross entropy for a single output value <span class="emphasis"><em>y </em></span>is defined as:</p><div class="mediaobject"><img src="../Images/image01517.jpeg" alt="Error functions"/></div><p style="clear:both; height: 1em;"> </p><p>M7: Cross entropy for a multivariable output vector <span class="emphasis"><em>y</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01518.jpeg" alt="Error functions"/></div><p style="clear:both; height: 1em;"> </p></div><p>The sum of <a id="id9870000" class="indexterm"/>squared errors and mean squared error functions have been described in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>.</p><p>The <code class="literal">crossEntropy</code> method of the <code class="literal">XTSeries</code> object for a single variable is implemented as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>crossEntropy</strong></span>(x: Double, y: Double): Double = 
  -(x*Math.log(y) + (1.0 - x)*Math.log(1.0 - y))</pre></div><p>The computation of the cross entropy for multiple variable features as a signature is similar to the single variable case:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>crossEntropy</strong></span>(xt: DblArray, yt: DblArray): Double = 
  yt.zip(xt).aggregate(0.0)({ case (s, (y, x)) =&gt; 
    s - y*Math.log(x)}, _ + _)</pre></div></div><div class="section" title="Operating modes"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2100"/>Operating modes</h4></div></div></div><p>In the <span class="emphasis"><em>network architecture</em></span> section, you <a id="id9880000" class="indexterm"/>learned that the structure of the output layer depends on the type of problems that need to be resolved, also known as operating modes. Let's encapsulate the different operating modes (binomial, multinomial classification, and regression) into a class hierarchy, implementing the <code class="literal">MLPMode</code> trait. The <code class="literal">MLPMode</code> trait has two methods that is specific to the type of the problem:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">apply</code>: This is the transformation applied to the output values</li><li class="listitem"><code class="literal">error</code>: This is the computation of the cumulative error for the entire observation set</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>MLPMode</strong></span> { 
  def <span class="strong"><strong>apply</strong></span>(output: DblArray): DblArray   //<span class="strong"><strong>30</strong></span>
  def <span class="strong"><strong>error</strong></span>(labels: DblArray, output: DblArray): Double = 
    mse(labels, output)  //<span class="strong"><strong>31</strong></span>
}</pre></div><p>The <code class="literal">apply</code> method applies a transformation to the output layer, as described in the last column of the operating modes table (line <code class="literal">30</code>). The <code class="literal">error</code> function computes the cumulative error or loss in the output layer for all the observations, as described in the first column of the operating modes table (line <code class="literal">31</code>).</p><p>The <a id="id9890000" class="indexterm"/>transformation in the output layer of the <code class="literal">MLPBinClassifier</code> binomial (two-class) classifier consists of applying the <code class="literal">sigmoid</code> function to each <code class="literal">output</code> value (line <code class="literal">32</code>). The cumulative error is computed as the cross entropy of the expected output, labels, and the predicted output (line <code class="literal">33</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPBinClassifier</strong></span> extends MLPMode {   
  override def <span class="strong"><strong>apply</strong></span>(output: DblArray): DblArray = 
    output.map(sigmoid(_))  //<span class="strong"><strong>32</strong></span>
  override def <span class="strong"><strong>error</strong></span>(labels: DblArray,  
      output: DblArray): Double = 
    <span class="strong"><strong>crossEntropy</strong></span>(labels.head, output.head)  //<span class="strong"><strong>33</strong></span>
}</pre></div><p>The regression mode for the multilayer perceptron is defined according to the operating modes table in the <span class="emphasis"><em>Problem types (modes)</em></span> section:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPRegression</strong></span> extends MLPMode  {
  override def apply(output: DblArray): DblArray = output
}</pre></div><p>The multinomial classifier mode is defined by the <code class="literal">MLPMultiClassifier</code> class. It uses the <code class="literal">softmax</code> method to boost the <code class="literal">output</code> with the highest value, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLPMultiClassifier</strong></span> extends MLPMode {
  override def <span class="strong"><strong>apply</strong></span>(output: DblArray):DblArray = <span class="strong"><strong>softmax</strong></span>(<span class="strong"><strong>output</strong></span>)
}</pre></div><p>The <code class="literal">softmax</code> method is applied to the actual <code class="literal">output</code> value, not the bias. Therefore, the first node <span class="emphasis"><em>y(0) = +1</em></span> has to be dropped before applying the <code class="literal">softmax</code> normalization.</p></div><div class="section" title="Softmax"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2200"/>Softmax</h4></div></div></div><p>In the <a id="id9900000" class="indexterm"/>case of a classification problem with <span class="emphasis"><em>K</em></span> classes (<span class="emphasis"><em>K &gt; 2</em></span>), the output has to be converted into a probability <span class="emphasis"><em>[0, 1]</em></span>. For problems that require a large number of classes, there is a need to boost the output <span class="emphasis"><em>y<sub>k</sub></em></span> with the highest value (or probability). This process is known as <a id="id9910000" class="indexterm"/><span class="strong"><strong>exponential normalization</strong></span> or softmax [9:8].</p><div class="note" title="Note"><h3 class="title"><a id="note28800"/>Note</h3><p>M8: The softmax formula for the multinomial (<span class="emphasis"><em>K &gt; 2</em></span>) classification is as follows:</p><div class="mediaobject"><img src="../Images/image01519.jpeg" alt="Softmax"/></div><p style="clear:both; height: 1em;"> </p></div><p>Here is the simple implementation of the <code class="literal">softmax</code> method of the <code class="literal">MLPMultiClassifier</code> class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>softmax</strong></span>(y: DblArray): DblArray = {
  val softmaxValues = new DblArray(y.size)
  val <span class="strong"><strong>expY</strong></span> = y.map( Math.exp(_))  //<span class="strong"><strong>34</strong></span>
  val <span class="strong"><strong>expYSum</strong></span> = expY.sum  //<span class="strong"><strong>35</strong></span>
  
  expY.map( _ /expYSum).copyToArray(softmaxValues, 1) //<span class="strong"><strong>36</strong></span>
  softmaxValues
}</pre></div><p>The <code class="literal">softmax</code> method implements the <span class="strong"><strong>M8</strong></span> mathematical expression. First, the method computes the <code class="literal">expY</code> exponential values of the output values (line <code class="literal">34</code>). The exponentially transformed outputs are then normalized by their sum, <code class="literal">expYSum</code>, (line <code class="literal">35</code>) to generate the array of the <code class="literal">softmaxValues</code> output (line <code class="literal">36</code>). Once again, there is no need to update the bias element <span class="emphasis"><em>y(0)</em></span>.</p><p>The second step in the training phase is to define and initialize the matrix of delta error values to be back propagated between layers from the output layer back to the input layer.</p></div></div><div class="section" title="Step 2 – error backpropagation"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12700"/>Step 2 – error backpropagation</h3></div></div></div><p>The <a id="id9920000" class="indexterm"/>error backpropagation<a id="id9930000" class="indexterm"/> is an algorithm that estimates the error for the hidden layer in order to compute the change in weights of the network. It takes the sum of squared errors of the output as the input.</p><div class="note" title="Note"><h3 class="title"><a id="note28900"/>Note</h3><p>
<span class="strong"><strong>The convention for computing the cumulative error</strong></span>
</p><p>Some authors refer to the backpropagation as a training methodology for an MLP, which applies the gradient descent to the output error defined as either the sum of squared errors, or the mean squared error for multinomial classification or regression. In this chapter, we keep the narrower definition of the backpropagation as the backward computation of the sum of squared errors.</p></div><div class="section" title="Weights' adjustment"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2300"/>Weights' adjustment</h4></div></div></div><p>The <a id="id9940000" class="indexterm"/>connection weights <span class="emphasis"><em>∆v</em></span> and <span class="emphasis"><em>∆w</em></span> are adjusted by computing the sum of the derivatives of the error, over the weights scaled with a learning factor. The gradient of weights are then used to compute the error of the output of the source layer [9:9].</p><p>The simplest algorithm to update the weights is the gradient descent [9:10]. The batch gradient descent was introduced in <span class="emphasis"><em>Let's kick the tires</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p><p>The gradient descent is a very simple and robust algorithm. However, it can be slower in converging toward a global minimum than the conjugate gradient or the quasi-Newton method (refer to the <span class="emphasis"><em>Summary of optimization techniques</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>There are several methods available to speed up the convergence of the gradient descent toward a minimum, such as the momentum factor and adaptive learning coefficient [9:11].</p><p>Large variations of the weights during training increase the number of epochs required for the model (connection weights) to converge. This is particularly true for a training strategy known as online training. The training strategies are discussed in the next section. The momentum factor α is used for the remaining section of the chapter.</p><div class="note" title="Note"><h3 class="title"><a id="note29000"/>Note</h3><p>M9: The learning rate</p><p>The computation of neural network weights using the gradient descent is as follows:</p><div class="mediaobject"><img src="../Images/image01520.jpeg" alt="Weights' adjustment"/></div><p style="clear:both; height: 1em;"> </p><p>M10: The learning rate and momentum factor</p><p>The computation of neural network weights using the gradient descent method with the momentum coefficient <span class="emphasis"><em>α</em></span> is as follows:</p><div class="mediaobject"><img src="../Images/image01521.jpeg" alt="Weights' adjustment"/></div><p style="clear:both; height: 1em;"> </p></div><p>The simplest <a id="id9950000" class="indexterm"/>version of the gradient descent algorithm (<span class="strong"><strong>M9</strong></span>) is selected by simply setting the momentum factor <span class="emphasis"><em>α</em></span> to zero in the generic (<span class="strong"><strong>M10</strong></span>) mathematical expression.</p></div><div class="section" title="The error propagation"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2400"/>The error propagation</h4></div></div></div><p>The <a id="id9960000" class="indexterm"/>objective of the training of a perceptron is to minimize the loss or cumulative error for all the input observations as either the sum of squared errors or the cross entropy as computed at the output layer. The error <span class="emphasis"><em>ε<sub>k</sub></em></span> for each output neuron <span class="emphasis"><em>y<sub>k</sub></em></span> is computed as the difference between a predicted output value and label output value. The error cannot be computed on output values of the hidden layers <span class="emphasis"><em>z<sub>j</sub></em></span> because the label values for those layers are unknown:</p><div class="mediaobject"><img src="../Images/image01522.jpeg" alt="The error propagation"/><div class="caption"><p>An illustration of the back-propagation algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>In the case of the sum of squared errors, the partial derivative of the cumulative error over each weight of the output layer is computed as the composition of the derivative of the square function and the derivative of the dot product of weights and the input <span class="emphasis"><em>z</em></span>.</p><p>As mentioned earlier, the computation of the partial derivative of the error over the weights of the hidden layer is a bit tricky. Fortunately, the mathematical expression for the partial derivative can be written as the product of three partial derivatives:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The derivative of the cumulative error <span class="emphasis"><em>ε</em></span> over the output value <span class="emphasis"><em>y<sub>k</sub></em></span></li><li class="listitem">The derivative of the output value <span class="emphasis"><em>yk</em></span> over the hidden value <span class="emphasis"><em>z<sub>j</sub></em></span>, knowing that the derivative of a sigmoid <span class="emphasis"><em>σ</em></span> is <span class="emphasis"><em>σ(1 - σ)</em></span></li><li class="listitem">The derivative of the output of the hidden layer <span class="emphasis"><em>z<sub>j</sub></em></span> over the weights <span class="emphasis"><em>w<sub>ij</sub></em></span></li></ul></div><p>The <a id="id9970000" class="indexterm"/>decomposition of the partial derivative produces the following formulas for updating the synapses' weights for the output and hidden neurons by propagating the error (or loss) <span class="emphasis"><em>ε</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note29200"/>Note</h3><p>
<span class="strong"><strong>Output weights' adjustment</strong></span>
</p><p>M11: The computation of delta <span class="emphasis"><em>δ</em></span> and weight adjustment <span class="emphasis"><em>∆v</em></span> for the output layer with the predicted value <span class="emphasis"><em>~y</em></span> and expected value <span class="emphasis"><em>y</em></span>, and output <span class="emphasis"><em>z</em></span> of the hidden layer is as follows:</p><div class="mediaobject"><img src="../Images/image01523.jpeg" alt="The error propagation"/></div><p style="clear:both; height: 1em;"> </p><p>
<span class="strong"><strong>Hidden weights' adjustment</strong></span>
</p><p>M12: The computation of delta <span class="emphasis"><em>δ</em></span> and weight adjustment <span class="emphasis"><em>∆w</em></span> for the hidden layer with the predicted value <span class="emphasis"><em>~y</em></span> and expected value <span class="emphasis"><em>y</em></span>, output <span class="emphasis"><em>z</em></span> of the hidden layer, and the input value <span class="emphasis"><em>x</em></span> is as follows:</p><div class="mediaobject"><img src="../Images/image01524.jpeg" alt="The error propagation"/></div><p style="clear:both; height: 1em;"> </p></div><p>The matrix <span class="emphasis"><em>δ<sub>ij</sub></em></span> is defined by the <code class="literal">delta</code> matrix in the <code class="literal">Delta</code> class. It contains the basic parameters to be passed between layers, traversing the network from the output layer back to the input layer. The parameters are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Initial <code class="literal">loss</code> or error computed at the output layer</li><li class="listitem">Matrix of the <code class="literal">delta</code> values from the current connection</li><li class="listitem">Weights or <code class="literal">synapses</code> of the downstream connection (or connection between the destination layer and the following layer)</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>Delta</strong></span>(val <span class="strong"><strong>loss</strong></span>: DblArray, 
  val <span class="strong"><strong>delta</strong></span>: DblMatrix = Array.empty[DblArray],
  val <span class="strong"><strong>synapses</strong></span>: MLPConnSynapses = Array.empty[Array[MLPSynapse]] )</pre></div><p>The first instance of the <code class="literal">Delta</code> class is generated for the output layer using the expected values <span class="emphasis"><em>y</em></span>, then propagated to the preceding hidden layer in the <code class="literal">MLPNetwork.trainEpoch</code> method (line <code class="literal">24</code>):</p><div class="informalexample"><pre class="programlisting">val diff = (x: Double, y: Double) =&gt; x - y
<span class="strong"><strong>Delta</strong></span>(zipToArray(y, layers.last.output)(diff))</pre></div><p>The <span class="strong"><strong>M11</strong></span> mathematical <a id="id9980000" class="indexterm"/>expression is implemented by the <code class="literal">delta</code> method of the <code class="literal">MLPOutLayer</code> class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>delta</strong></span>(error: DblArray, srcOut: DblArray, 
     synapses: MLPConnSynapses): Delta = {

  val deltaMatrix = new ArrayBuffer[DblArray] //<span class="strong"><strong>34</strong></span>
  val <span class="strong"><strong>deltaValues</strong></span> = error./:(deltaMatrix)( (m, l) =&gt; {
    m.append( srcOut.map( _*l) )
    m
  })   //<span class="strong"><strong>35</strong></span>
  new Delta(error, deltaValues.toArray, synapses)  //<span class="strong"><strong>36</strong></span>
}</pre></div><p>The method generates the matrix of delta values associated with the output layer (line <code class="literal">34</code>). The <span class="strong"><strong>M11</strong></span> formula is actually implemented by the fold over the <code class="literal">srcOut</code> output value (line <code class="literal">35</code>). The new delta instances are returned to the <code class="literal">trainEpoch</code> method of <code class="literal">MLPNetwork</code> and backpropagated to the preceding hidden layer (line <code class="literal">36</code>).</p><p>The <code class="literal">delta</code> method of the <code class="literal">MLPLayer</code> class implements the <span class="strong"><strong>M12</strong></span> mathematical expression:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>delta</strong></span>(oldDelta: DblArray, srcOut: DblArray, 
     synapses: MLPConnSynapses): Delta = {
  
  val deltaMatrix = new ArrayBuffer[(Double, DblArray)]
  val <span class="strong"><strong>weights</strong></span> = <span class="strong"><strong>synapses</strong></span>.map(_.map(_._1))
       .transpose.drop(1) //<span class="strong"><strong>37</strong></span>

  val deltaValues = output.drop(1)
   .zipWithIndex./:(deltaMatrix){  // <span class="strong"><strong>38</strong></span>
     case (m, (zh, n)) =&gt; {
       val newDelta = inner(oldDelta, weights(n))*zh*(1.0 - zh)
       m.append((newDelta, srcOut.map( _ * newdelta) )
       m
     } 
  }.unzip
  new Delta(deltaValues._1.toArray, deltaValues._2.toArray)//<span class="strong"><strong>39</strong></span>
}</pre></div><p>The <a id="id9990000" class="indexterm"/>implementation of the <code class="literal">delta</code> method is similar to the <code class="literal">MLPOutLayer.delta</code> method. It extracts the weights <code class="literal">v</code> from the output layer through transposition (line <code class="literal">37</code>). The values of the delta matrix in the hidden connection is computed by applying the <span class="strong"><strong>M12</strong></span> formula (line <code class="literal">38</code>). The new delta instance is returned to the <code class="literal">trainEpoch</code> method (line <code class="literal">39</code>) to be propagated to the preceding hidden layer if one exists.</p></div><div class="section" title="The computational model"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec2500"/>The computational model</h4></div></div></div><p>The <a id="id10000000" class="indexterm"/>computational model for the error backpropagation algorithm is very similar to the forward propagation of the input. The main difference is that the propagation of <span class="emphasis"><em>δ</em></span> (delta) is performed from the output layer to the input layer. The following diagram illustrates the computational model of the backpropagation in the case of two hidden layers <span class="emphasis"><em>z<sub>s</sub></em></span> and <span class="emphasis"><em>z<sub>t</sub></em></span>:</p><div class="mediaobject"><img src="../Images/image01525.jpeg" alt="The computational model"/><div class="caption"><p>An illustration of the backpropagation of the delta error</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">connectionBackPropagation</code> method propagates the error back from the output layer or one of the hidden layers to the preceding layer. It is a member of the <code class="literal">MLPConnection</code> class. The backpropagation of the output error across the entire network is managed by the <code class="literal">MLP</code> class.</p><p>It implements the two set of equations where <code class="literal">synapses(j)(i)._1</code> are the weights <span class="emphasis"><em>w<sub>ji</sub></em></span>, <code class="literal">dst.delta</code> is the vector of the error derivative in the destination layer, and <code class="literal">src.delta</code> is the error derivative of the output in the source layer, as shown here:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>connectionBackpropagation</strong></span>(<span class="strong"><strong>delta</strong></span>: Delta): Delta = {  //<span class="strong"><strong>40</strong></span>
  val inSynapses =  //<span class="strong"><strong>41</strong></span>
    if( delta.synapses.length &gt; 0) delta.synapses 
    else synapses 
  
  val delta = <span class="strong"><strong>dst.delta</strong></span>(<span class="strong"><strong>delta.loss</strong></span>, <span class="strong"><strong>src.output</strong></span>,inSynapses) //<span class="strong"><strong>42</strong></span>
  synapse = synapses.zipWithIndex.map{ //43
    case (synapsesj, j) =&gt; synapsesj.zipWithIndex.map{
      case ((w, dw), i) =&gt; { 
        val ndw = config.eta*connectionDelta.delta(j)(i)
        (w + ndw - config.alpha*dw, ndw)
      } 
    }
  }
  new Delta(connectionDelta.loss, 
       connectionDelta.delta, synapses)
}</pre></div><p>The <code class="literal">connectionBackPropagation</code> method takes <code class="literal">delta</code> associated with the destination (output) layer as an argument (line <code class="literal">40</code>). The output layer is the last layer of the <a id="id10010000" class="indexterm"/>network, and therefore, the synapses for the following connection is defined as an empty matrix of length zero (line <code class="literal">41</code>). The method computes the new <code class="literal">delta</code> matrix for the hidden layer using the <code class="literal">delta.loss</code> error and output from the source layer, <code class="literal">src.output</code> (line <code class="literal">42</code>). The weights (synapses) are updated using the gradient descent with the momentum factor as in the <span class="strong"><strong>M10</strong></span> mathematical expression (line <code class="literal">43</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note29400"/>Note</h3><p>
<span class="strong"><strong>The adjustable learning rate</strong></span>
</p><p>The computation of the new weights of a connection for each new epoch can be further improved by making the learning adjustable.</p></div></div></div><div class="section" title="Step 3 – exit condition"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12800"/>Step 3 – exit condition</h3></div></div></div><p>The <a id="id10020000" class="indexterm"/>convergence criterion consists of evaluating the cumulative error (or loss) relevant to the operating mode (or problem) against a predefined <code class="literal">eps</code> convergence. The cumulative error is computed using either the sum of squares error formula (<span class="strong"><strong>M5</strong></span>) or the cross-entropy formula (<span class="strong"><strong>M6</strong></span> and <span class="strong"><strong>M7</strong></span>). An alternative approach is to compute the difference of the cumulative error between two consecutive epochs and apply the <code class="literal">eps</code> convergence criteria as the exit condition.</p></div><div class="section" title="Putting it all together"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec12900"/>Putting it all together</h3></div></div></div><p>The <code class="literal">MLP</code> class<a id="id10030000" class="indexterm"/> is defined as a data transformation of the <code class="literal">ITransform</code> type using a model implicitly generated from a training set, <code class="literal">xt</code>, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">44</code>).</p><p>The MLP algorithm takes the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This is the configuration of the algorithm</li><li class="listitem"><code class="literal">hidden</code>: This is an array of the size of the hidden layers if any</li><li class="listitem"><code class="literal">xt</code>: This is the time series of features used to train the model</li><li class="listitem"><code class="literal">expected</code>: This is the labeled output values for training purpose</li><li class="listitem"><code class="literal">mode</code>: This is the implicit operating mode or objective of the algorithm</li><li class="listitem"><code class="literal">f</code>: This is the implicit conversion from feature from type <code class="literal">T</code> to <code class="literal">Double</code></li></ul></div><p>The <code class="literal">V</code> type of the output of the prediction or classification method <code class="literal">|&gt;</code> of this implicit transform is <code class="literal">DblArray</code> (line <code class="literal">45</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MLP</strong></span>[T &lt;: AnyVal](<span class="strong"><strong>config</strong></span>: MLPConfig, 
    <span class="strong"><strong>hidden</strong></span>: Array[Int] = Array.empty[Int],
    <span class="strong"><strong>xt</strong></span>: XVSeries[T], 
    <span class="strong"><strong>expected</strong></span>: XVSeries[T])
    (implicit <span class="strong"><strong>mode</strong></span>: MLPMode, f: T =&gt; Double) 
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Monitor[Double] {  //<span class="strong"><strong>44</strong></span>

  type <span class="strong"><strong>V</strong></span> = DblArray  //<span class="strong"><strong>45</strong></span>

  lazy val <span class="strong"><strong>topology</strong></span> = if(hidden.length ==0) 
    Array[Int](<span class="strong"><strong>xt</strong></span>.head.size, <span class="strong"><strong>expected</strong></span>.head.size) 
  else  Array[Int](<span class="strong"><strong>xt</strong></span>.head.size) ++ <span class="strong"><strong>hidden</strong></span> ++ 
         Array[Int](<span class="strong"><strong>expected</strong></span>.head.size)  //<span class="strong"><strong>46</strong></span>

  val <span class="strong"><strong>model</strong></span>: Option[MLPModel] = train
  def <span class="strong"><strong>train</strong></span>: Option[MLPModel]   //<span class="strong"><strong>47</strong></span>
  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T], Try[V]] 
}</pre></div><p>The topology is created from the <code class="literal">xt</code> input variables, the <code class="literal">expected</code> values, and the configuration <a id="id10040000" class="indexterm"/>of <code class="literal">hidden</code> layers, if any (line <code class="literal">46</code>). The generation of the topology from parameters of the <code class="literal">MLPNetwork</code> class is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01526.jpeg" alt="Putting it all together"/><div class="caption"><p>Topology encoding for multi-layer perceptrons</p></div></div><p style="clear:both; height: 1em;"> </p><p>For instance, the <code class="literal">topology</code> of a neural network with three input variables: one output variable and two hidden layers of three neurons each is specified as <code class="literal">Array[Int](4, 3, 3, 1)</code>. The model is generated through training by invoking the <code class="literal">train</code> method (line <code class="literal">47</code>). Finally, the <code class="literal">|&gt; </code>operator of the <code class="literal">ITransform</code> trait is used for classification, prediction, or regression, depending on the selected operating mode (line <code class="literal">48</code>).</p></div></div><div class="section" title="Training and classification"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec11900"/>Training and classification</h2></div></div></div><p>Once <a id="id10050000" class="indexterm"/>the training <a id="id10060000" class="indexterm"/>cycle or epoch is defined, it is merely a matter of defining and implementing a strategy to create a model using a sequence of data or time series.</p><div class="section" title="Regularization"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13000"/>Regularization</h3></div></div></div><p>There <a id="id10070000" class="indexterm"/>are two approaches to find the most appropriate network architecture for a given classification or regression problem, which are follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Destructive tuning</strong></span>: Starting with a large network, and then removing nodes, synapses, and hidden layers that have no impact on the sum of squared errors</li><li class="listitem"><span class="strong"><strong>Constructive tuning</strong></span>: Starting <a id="id10080000" class="indexterm"/>with a small network, and then incrementally adding the nodes, synapses, and hidden layers that reduce the output error</li></ul></div><p>The <a id="id10090000" class="indexterm"/>destructive tuning strategy removes the synapses by zeroing out their weights. This is commonly accomplished using regularization.</p><p>You have seen that regularization is a powerful technique to address overfitting in the case of the linear and logistic regression in the <span class="emphasis"><em>Ridge regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>. Neural networks can benefit from adding a regularization term <a id="id10100000" class="indexterm"/>to the sum of squared errors. The larger the regularization factor is, the more likely some weights will be reduced to zero, thus reducing the scale of the network [9:13].</p></div><div class="section" title="The model generation"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13100"/>The model generation</h3></div></div></div><p>The <code class="literal">MLPModel</code> instance <a id="id10110000" class="indexterm"/>is created (trained) during the instantiation of the multilayer perceptron. The constructor iterates through the training cycles (or epochs) over all the data points of the <code class="literal">xt</code> time series, until the cumulative is smaller than the <code class="literal">eps</code> convergence criteria, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[MLPModel] = {
  val <span class="strong"><strong>network</strong></span> = new MLPNetwork(config, topology) //<span class="strong"><strong>48</strong></span>
  val <span class="strong"><strong>zi</strong></span> =  xt.toVector.zip(expected.view)   // <span class="strong"><strong>49</strong></span>

  Range(0, config.numEpochs).find( n =&gt; {  //<span class="strong"><strong>50</strong></span>
    val cumulErr = <span class="strong"><strong>fisherYates</strong></span>(xt.size)
       .map(zi(_))
       .map{ case(x, e) =&gt; network.<span class="strong"><strong>trainEpoch</strong></span>(x, e)}
       .sum/st.size   //<span class="strong"><strong>51</strong></span>
     cumulErr  &lt; config.<span class="strong"><strong>eps</strong></span>  //<span class="strong"><strong>52</strong></span>
  }).map(_ =&gt; network.getModel)
}</pre></div><p>The <code class="literal">train</code> method instantiates an MLP network using the configuration and <code class="literal">topology</code> as the input (line <code class="literal">48</code>). The method executes multiple epochs until either the gradient descent with a momentum converges or the maximum number of allowed iterations is reached (line <code class="literal">50</code>). At each epoch, the method shuffles the input values and labels using the Fisher-Yates algorithm, invokes the <code class="literal">MLPNetwork.trainEpoch</code> method, and computes the <code class="literal">cumulErr</code> cumulative error (line <code class="literal">51</code>). This particular implementation compares the value of the cumulative error against the <code class="literal">eps</code> convergence criteria as the exit condition (line <code class="literal">52</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note29500"/>Note</h3><p>
<span class="strong"><strong>Tail recursive training of MLP</strong></span>
</p><p>The training of the multilayer is implemented as an iterative process. It can be easily substituted with a tail recursion using weights and the cumulative error as the argument of the recursion.</p></div><p>Lazy views are used to reduce the unnecessary creation of objects (line <code class="literal">49</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note29600"/>Note</h3><p>
<span class="strong"><strong>The exit condition</strong></span>
</p><p>In this implementation, the training initializes the model as <code class="literal">None</code> if it does not converge before the maximum number of epochs are reached. An alternative would be to generate a model even in the case of nonconvergence and add an accuracy metric to the model, as in our implementation of the support vector machine (refer to the <span class="emphasis"><em>Training</em></span> section under <span class="emphasis"><em>Support vector classifiers – SVC</em></span> in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>).</p></div><p>Once the <a id="id10120000" class="indexterm"/>model is created during the instantiation of the multilayer perceptron, it is available to predict or classify the class of a new observation.</p></div><div class="section" title="The Fast Fisher-Yates shuffle"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13200"/>The Fast Fisher-Yates shuffle</h3></div></div></div><p>The <span class="emphasis"><em>Step 5 – implementing the classifier</em></span> section under <span class="emphasis"><em>Let's kick the tires</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, describes <a id="id10130000" class="indexterm"/>a home grown shuffling algorithm as an alternative to the <code class="literal">scala.util.Random.shuffle</code> method of the Scala standard library. This section describes an alternative shuffling mechanism known as the Fisher-Yates shuffling algorithm:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>fisherYates</strong></span>(n: Int): IndexedSeq[Int] = {

   def <span class="strong"><strong>fisherYates</strong></span>(seq: Seq[Int]): IndexedSeq[Int] = {
     Random.setSeed(System.currentTimeMillis)
    (0 until seq.size).map(i =&gt; {
       var randomIdx: Int = i + Random.nextInt(seq.size-i) //<span class="strong"><strong>53</strong></span>
       seq(randomIdx) ^= seq(i)    //<span class="strong"><strong>54</strong></span>
       seq(i) = seq(randomIdx) ^ seq(i) 
       seq(randomIdx) ^= (seq(i))
       seq(i)
    })
  }

  if( n &lt;= 0)  Array.empty[Int]
  else 
    <span class="strong"><strong>fisherYates</strong></span>(ArrayBuffer.tabulate(n)(n =&gt; n)) //<span class="strong"><strong>55</strong></span>
}</pre></div><p>The Fisher-Yates algorithm creates an ordered sequence of integers (line <code class="literal">55</code>), and swaps each integer with another integer, randomly selected from the remaining of the initial sequences (line <code class="literal">52</code>). This implementation is particularly fast because the integers are <a id="id10140000" class="indexterm"/>swapped in place using the bit operator, also known as <span class="strong"><strong>bitwise swap</strong></span> (line <code class="literal">54</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note29700"/>Note</h3><p>
<span class="strong"><strong>Tail recursive implementation of Fisher-Yates</strong></span>
</p><p>The Fisher-Yates shuffling algorithm can be implemented using a tail recursion instead of an iteration.</p></div></div><div class="section" title="Prediction"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13300"/>Prediction</h3></div></div></div><p>The <code class="literal">|&gt; </code>data transformation<a id="id10150000" class="indexterm"/> implements the runtime classification/prediction. It returns the predicted value that is normalized as a probability if the model was successfully trained and <code class="literal">None</code> otherwise. The methods invoke the forward prediction function of <code class="literal">MLPNetwork</code> (line <code class="literal">53</code>):</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[Array[T],Try[V]] ={
  case x: Array[T] if(isModel &amp;&amp; x.size == dimension(xt)) =&gt; 
   Try(MLPNetwork(config, topology, model).<span class="strong"><strong>predict</strong></span>(x)) //<span class="strong"><strong>56</strong></span>
}</pre></div><p>The <code class="literal">predict</code> method of <code class="literal">MLPNetwork</code> computes the output values from an input <code class="literal">x</code> using the forward propagation as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>predict</strong></span>(x: DblArray): DblArray = {
   layers.head.set(x)
   connections.foreach( _.connectionForwardPropagation)
   layers.last.<span class="strong"><strong>output</strong></span>
}</pre></div></div><div class="section" title="Model fitness"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13400"/>Model fitness</h3></div></div></div><p>The fitness of a <a id="id10160000" class="indexterm"/>model measures how well the model fits the training set. A model with a high-degree of fitness will likely overfit. The <code class="literal">fit</code> fitness method computes the mean squared errors of the predicted values against the labels (or expected values) of the training set. The method returns the percentage of observations for which the prediction value is correct, using the higher order <code class="literal">count</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>fit</strong></span>(threshold: Double): Option[Double] = model.map(m =&gt; 
  xt.map( MLPNetwork(config, topology, Some(m)).predict(_) )
    .zip(expected)
    .<span class="strong"><strong>count</strong></span>{case (y, e) =&gt;mse(y, e.map(_.toDouble))&lt; threshold }
    /xt.size.toDouble
)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note29800"/>Note</h3><p>
<span class="strong"><strong>Model fitness versus accuracy</strong></span>
</p><p>The fitness of a model against the training set reflects the degree the model fit the training set. The computation of the fitness does not involve a validation set. Quality parameters such as accuracy, precision, or recall measures the reliability or quality of the model against a validation set.</p></div><p>Our <code class="literal">MLP</code> class is <a id="id10170000" class="indexterm"/>now ready to tackle some classification challenges.</p></div></div></div>
<div class="section" title="Evaluation"><div class="titlepage" id="aid-67A5I2"><div><div><h1 class="title"><a id="ch09lvl1sec6300"/>Evaluation</h1></div></div></div><p>Before <a id="id10180000" class="indexterm"/>applying our multilayer perceptron to understand fluctuations in the currency market exchanges, let's get acquainted with some of the key learning parameters introduced in the first section.</p><div class="section" title="The execution profile"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12000"/>The execution profile</h2></div></div></div><p>Let's take <a id="id10190000" class="indexterm"/>a look at the convergence of the training of the multiple layer perceptron. The monitor trait (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>) collects and displays some execution parameters. We select to extract the profile for the convergence of the multiple layer perceptron using the difference of the backpropagation errors between two consecutive episodes (or epochs).</p><p>The test profiles the convergence of the MLP using a learning rate of <span class="emphasis"><em>η = 0.03</em></span> and a momentum factor of <span class="emphasis"><em>α = 0.3</em></span> for a multilayer perceptron with two input values: one hidden layer with three nodes and one output value. The test relies on synthetically generated random values:</p><div class="mediaobject"><img src="../Images/image01527.jpeg" alt="The execution profile"/><div class="caption"><p>The execution profile for the cumulative error for MLP</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Impact of the learning rate"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12100"/>Impact of the learning rate</h2></div></div></div><p>The purpose <a id="id10200000" class="indexterm"/>of the first exercise is to evaluate the impact of the learning rate <span class="emphasis"><em>η</em></span> on the convergence of the training epoch, as measured by the cumulative error of all output variables. The observations <code class="literal">xt</code> (with respect to the labeled output <code class="literal">yt</code>) are synthetically generated using several noisy patterns such as <code class="literal">f1</code> (line <code class="literal">57</code>) and <code class="literal">f2</code> functions (line <code class="literal">58</code>), as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>f1</strong></span>(x: Double): DblArray = Array[Double](  //<span class="strong"><strong>57</strong></span>
  0.1+ 0.5*Random.nextDouble, 0.6*Random.nextDouble) 
def <span class="strong"><strong>f2</strong></span>(x: Double): DblArray =  Array[Double](  //<span class="strong"><strong>58</strong></span>
  0.6 + 0.4*Random.nextDouble, 1.0 - 0.5*Random.nextDouble)

val HALF_TEST_SIZE = (TEST_SIZE&gt;&gt;1)
val <span class="strong"><strong>xt</strong></span> = Vector.tabulate(TEST_SIZE)(n =&gt;   //<span class="strong"><strong>59</strong></span>
  if( n &lt;HALF_TEST_SIZE) f1(n) else f2(n -HALF_TEST_SIZE))
val <span class="strong"><strong>yt</strong></span> = Vector.tabulate(TEST_SIZE)(n =&gt; 
  if( n &lt; HALF_TEST_SIZE) Array[Double](0.0) 
  else Array[Double](1.0) )  //<span class="strong"><strong>60</strong></span>
</pre></div><p>The input values, <code class="literal">xt</code>, are synthetically generated by the <code class="literal">f1</code> function for half of the dataset and by the <code class="literal">f2</code> function for the other half (line <code class="literal">59</code>). The data generator for the expected values <code class="literal">yt</code> assigns the label 0.0 for the input values generated with the <code class="literal">f1</code> function and 1.0 for the input values created with <code class="literal">f2</code> (line <code class="literal">60</code>).</p><p>The test is run <a id="id10210000" class="indexterm"/>with a sample of size <code class="literal">TEST_SIZE</code> data points over a maximum of <code class="literal">NUM_EPOCHS</code> epochs, a single hidden layer of <code class="literal">HIDDENS.head</code> neurons with no <code class="literal">softmax</code> transformation, and the following MLP parameters:</p><div class="informalexample"><pre class="programlisting">val ALPHA = 0.3
val ETA = 0.03
val <span class="strong"><strong>HIDDEN</strong></span> = Array[Int](3)
val <span class="strong"><strong>NUM_EPOCHS</strong></span> = 200
val <span class="strong"><strong>TEST_SIZE</strong></span> = 12000
val <span class="strong"><strong>EPS</strong></span> = 1e-7

def <span class="strong"><strong>testEta</strong></span>(eta: Double, 
    xt: XVSeries[Double], 
    yt: XVSeries[Double]): 
    Option[(ArrayBuffer[Double], String)] = {
  
  implicit val <span class="strong"><strong>mode</strong></span> = new MLPBinClassifier //<span class="strong"><strong>61</strong></span>
  val config = MLPConfig(ALPHA, eta, NUM_EPOCHS, EPS)
  MLP[Double](config, HIDDEN, xt, yt)  
    .<span class="strong"><strong>counters</strong></span>("err").map( (_, s"eta=$eta")) //<span class="strong"><strong>62</strong></span>
}</pre></div><p>The <code class="literal">testEta</code> method generates the profile or errors given different values of <code class="literal">eta</code>.</p><p>The operating <code class="literal">mode</code> has to be implicitly defined prior to the instantiation of the <code class="literal">MLP</code> class (line <code class="literal">61</code>). It is set as a binomial classifier of the <code class="literal">MLPBinClassifier</code> type. The execution profile data is collected by the <code class="literal">counters</code> method of the <code class="literal">Monitor</code> trait (line <code class="literal">62</code>) (refer to the <span class="emphasis"><em>Monitor</em></span> section under <span class="emphasis"><em>Utility classes</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The driver code for evaluating the impact of the learning rate on the convergence of the multilayer perceptron is quite simple:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>etaValues</strong></span> = List[Double](0.01, 0.02, 0.03, 0.1)
val data = etaValues.flatMap( testEta(_, xt, yt))
    .map{ case(x, s) =&gt; (x.toVector, s) }

val legend = new Legend("Err", 
   "MLP [2-3-1] training - learning rate", "Epochs", "Error")
LinePlot.display(data, legend, new LightPlotTheme)</pre></div><p>The profile is created with the JFreeChart library and displayed in the following chart:</p><div class="mediaobject"><img src="../Images/image01528.jpeg" alt="Impact of the learning rate"/><div class="caption"><p>The impact of the learning rate on the MLP training</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id10220000" class="indexterm"/>chart illustrates that the MLP model training converges a lot faster with a larger value of learning rate. You need to keep in mind, however, that a very steep learning rate may lock the training process into a local minimum for the cumulative error, generating weights with lesser accuracy. The same configuration parameters are used to evaluate the impact of the momentum factor on the convergence of the gradient descent algorithm.</p></div><div class="section" title="The impact of the momentum factor"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12200"/>The impact of the momentum factor</h2></div></div></div><p>Let's <a id="id10230000" class="indexterm"/>quantify the impact of the momentum factor <span class="emphasis"><em>α</em></span> on the convergence of the training process toward an optimal model (synapse weights). The testing code is very similar to the evaluation of the impact of the learning rate.</p><p>The cumulative error for the entire time series is plotted in the following graph:</p><div class="mediaobject"><img src="../Images/image01529.jpeg" alt="The impact of the momentum factor"/><div class="caption"><p>The impact of the momentum factor on the MLP training</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id10240000" class="indexterm"/>preceding graph shows that the rate of the mean square error decreases as the momentum factor increases. In other words, the momentum factor has a positive although limited impact on the convergence of the gradient descent.</p></div><div class="section" title="The impact of the number of hidden layers"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12300"/>The impact of the number of hidden layers</h2></div></div></div><p>Let's <a id="id10250000" class="indexterm"/>consider a multilayer perceptron with two hidden layers (7 and 3 neurons). The execution profile for the training shows that the cumulative error of the output converges abruptly after several epochs for which the descent gradient failed to find a direction:</p><div class="mediaobject"><img src="../Images/image01530.jpeg" alt="The impact of the number of hidden layers"/><div class="caption"><p>The execution profile of training of an MLP with two hidden layers</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's apply <a id="id10260000" class="indexterm"/>our newfound knowledge regarding neural networks and the classification of variables that impact the exchange rate of a certain currency.</p></div><div class="section" title="Test case"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12400"/>Test case</h2></div></div></div><p>Neural networks <a id="id10270000" class="indexterm"/>have <a id="id10280000" class="indexterm"/>been used in financial applications from risk management in mortgage applications and hedging strategies for commodities pricing, to predictive modeling of the financial markets [9:14].</p><p>The objective of the test case is to understand the correlation factors between the exchange rate of some currencies, the spot price of gold, and the S&amp;P 500 index. For this exercise, we will use the following <a id="id10290000" class="indexterm"/><span class="strong"><strong>exchange-traded funds</strong></span> (<span class="strong"><strong>ETFs</strong></span>) as proxies for the exchange rate of currencies:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>FXA</strong></span>: This is the rate of an Australian dollar in US dollar</li><li class="listitem"><span class="strong"><strong>FXB</strong></span>: This is the rate of a British pound in US dollar</li><li class="listitem"><span class="strong"><strong>FXE</strong></span>: This is the rate of an Euro in US dollar</li><li class="listitem"><span class="strong"><strong>FXC</strong></span>: This is the rate of a Canadian dollar in US dollar</li><li class="listitem"><span class="strong"><strong>FXF</strong></span>: This is the rate of a Swiss franc in US dollar</li><li class="listitem"><span class="strong"><strong>FXY</strong></span>: This is the rate of a Japanese yen in US dollar</li><li class="listitem"><span class="strong"><strong>CYB</strong></span>: This is the rate of a Chinese yuan in US dollar</li><li class="listitem"><span class="strong"><strong>SPY</strong></span>: This is the S&amp;P 500 index</li><li class="listitem"><span class="strong"><strong>GLD</strong></span>: This is the price of gold in US dollar</li></ul></div><p>Practically, the problem to solve is to extract one or more regressive models that link one ETFs <span class="emphasis"><em>y</em></span> with a basket of other ETFs <span class="emphasis"><em>{x<sub>i</sub>} y=f(x<sub>i</sub>)</em></span>. For example, is there a relation between the exchange rate of the Japanese yen (FXY) and a combination of the spot price for gold (GLD), exchange rate of the Euro in US dollar (FXE), the exchange rate of the Australian dollar in US dollar (FXA), and so on? If so, the regression <span class="emphasis"><em>f</em></span> will be defined as <span class="emphasis"><em>FXY = f (GLD, FXE, FXA)</em></span>.</p><p>The following <a id="id10300000" class="indexterm"/>two charts visualize the fluctuation between currencies over a period of two and a half years. The first chart displays an initial group of potentially correlated ETFs:</p><div class="mediaobject"><img src="../Images/image01531.jpeg" alt="Test case"/><div class="caption"><p>An example of correlated currency-based ETFs</p></div></div><p style="clear:both; height: 1em;"> </p><p>The second chart displays another group of currency-related ETFs that shares a similar price action behavior. Neural networks do not provide any analytical representation of their internal reasoning; therefore, a <span class="emphasis"><em>visual</em></span> correlation can be extremely useful to novice engineers to validate their models:</p><div class="mediaobject"><img src="../Images/image01532.jpeg" alt="Test case"/><div class="caption"><p>An example of correlated currency-based ETFs</p></div></div><p style="clear:both; height: 1em;"> </p><p>A very simple approach for finding any correlation between the movement of the currency exchange rates and the gold spot price is to select one ticker symbol as the target and a subset of other currency-based ETFs as features.</p><p>Let's consider the <a id="id10310000" class="indexterm"/>following problem: finding the correlation between the price of FXE and a range of currencies FXB, CYB, FXA, and FXC, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01533.jpeg" alt="Test case"/><div class="caption"><p>The mechanism to generate features from ticker symbols</p></div></div><p style="clear:both; height: 1em;"> </p><div class="section" title="Implementation"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13500"/>Implementation</h3></div></div></div><p>The first step <a id="id10320000" class="indexterm"/>is to define the configuration parameter for the MLP classifier, as follows:</p><div class="informalexample"><pre class="programlisting">val path = "resources/data/chap9/"
val ALPHA = 0.8; 
val ETA = 0.01
val NUM_EPOCHS = 250
val EPS = 1e-3
val THRESHOLD = 0.12
val <span class="strong"><strong>hiddens</strong></span> = Array[Int](7, 7) //<span class="strong"><strong>59</strong></span>
</pre></div><p>Besides the learning parameters, the network is initialized with multiple topology configurations (line <code class="literal">59</code>).</p><p>Next, let's create the search space of the prices of all the ETFs used in the analysis:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>symbols</strong></span> = Array[String](
 "FXE","FXA","SPY","GLD","FXB","FXF","FXC","FXY","CYB"
)
val <span class="strong"><strong>STUDIES</strong></span> = List[Array[String]](   //<span class="strong"><strong>60</strong></span>
  Array[String]("FXY","FXC","GLD","FXA"),
  Array[String]("FXE","FXF","FXB","CYB"),
  Array[String]("FXE","FXC","GLD","FXA","FXY","FXB"),
  Array[String]("FXC","FXY","FXA"),
  Array[String]("CYB","GLD","FXY"),
  symbols
)</pre></div><p>The purpose of the test is to evaluate and compare seven different portfolios or studies (line <code class="literal">60</code>). The closing prices of all the ETFs over a period of 3 years are extracted from the Google Financial tables, using the <code class="literal">GoogleFinancials</code> extractor for a basket of ETFs (line <code class="literal">61</code>):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>prices</strong></span> = symbols.map(s =&gt; DataSource(s"$path$s.csv"))
      .flatMap(_.get(close).toOption) //<span class="strong"><strong>61</strong></span>
</pre></div><p>The next <a id="id10330000" class="indexterm"/>step consists of implementing the mechanism to extract the target and the features from a basket of ETFs or studies introduced in the previous paragraph. Let's consider the following study as the list of ETF ticker symbols:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>study</strong></span> = Array[String]("FXE","FXF","FXB","CYB")</pre></div><p>The first element of the study, <code class="literal">FXE</code>, is the labeled output; the remaining three elements are observed features. For this study, the network architecture has three input variables (<code class="literal">FXF</code>, <code class="literal">FXB</code>, and <code class="literal">CYB</code>) and one output variable, <code class="literal">FXE</code>:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>obs</strong></span> = symbols.flatMap(index.get(_))
              .map( prices(_).toArray )  //<span class="strong"><strong>62</strong></span>
val <span class="strong"><strong>xv</strong></span> = obs.drop(1).transpose  //<span class="strong"><strong>63</strong></span>
val <span class="strong"><strong>expected</strong></span> = Array[DblArray](obs.head).<span class="strong"><strong>transpose</strong></span> //<span class="strong"><strong>64</strong></span>
</pre></div><p>The set of observations, <code class="literal">obs</code>, is built using an index (line <code class="literal">62</code>). By convention, the first observation is selected as the label data and the remaining studies as the features for training. As the observations are loaded as an array of time series, the time features of the series is computed using <code class="literal">transpose</code> (line <code class="literal">63</code>). The single <code class="literal">target</code> output variable has to be converted into a matrix before transposition (line <code class="literal">64</code>).</p><p>Ultimately, the model is built through instantiation of the <code class="literal">MLP</code> class:</p><div class="informalexample"><pre class="programlisting">implicit val <span class="strong"><strong>mode</strong></span> = new MLPBinClassifier  //<span class="strong"><strong>65</strong></span>
val <span class="strong"><strong>classifier</strong></span> = MLP[Double](config, hiddenLayers, xv, expected)
classifier.<span class="strong"><strong>fit</strong></span>(THRESHOLD)</pre></div><p>The objective or operating <code class="literal">mode</code> is implicitly defined as an MLP binary classifier, <code class="literal">MLPBinClassifier</code> (line <code class="literal">65</code>). The <code class="literal">MLP.fit</code> method is defined in the <span class="emphasis"><em>Training and classification</em></span> section.</p></div><div class="section" title="Evaluation of models"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13600"/>Evaluation of models</h3></div></div></div><p>The test consists <a id="id10340000" class="indexterm"/>of evaluating six different models to determine which ones provide the most reliable correlation. It is critical to ensure that the result is somewhat independent of the architecture of the neural network. Different architectures are evaluated as part of the test.</p><p>The following charts compare the models for two architectures:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Two hidden layers with four nodes each</li><li class="listitem">Three hidden layers with eight (with respect to five and six) nodes</li></ul></div><p>This first chart <a id="id10350000" class="indexterm"/>visualizes the fitness of the six regression models with an architecture consisting of a variable number of inputs (2, 7): one output variable and two hidden layers of four nodes each. The features (ETF symbols) are listed on the left-hand side of the arrow <span class="strong"><strong>=&gt;</strong></span> along the <span class="emphasis"><em>y</em></span> axis. The symbol on the right-hand side of the arrow is the expected output value:</p><div class="mediaobject"><img src="../Images/image01534.jpeg" alt="Evaluation of models"/><div class="caption"><p>The accuracy of MLP with two hidden layers of four nodes each</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following chart displays the fitness of the six regression models for an architecture with three hidden layers of eight, five, and six nodes, respectively:</p><div class="mediaobject"><img src="../Images/image01535.jpeg" alt="Evaluation of models"/><div class="caption"><p>The accuracy of MLP with three hidden layers with 8, 5, and 6 nodes, respectively</p></div></div><p style="clear:both; height: 1em;"> </p><p>The two network architectures shared a lot of similarity; in both cases, the fittest regression models are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>FXE = f (FXA, SPY, GLD, FXB, FXF, FXD, FXY, CYB)</em></span></li><li class="listitem"><span class="emphasis"><em>FXE = g (FXC, GLD, FXA, FXY, FXB)</em></span></li><li class="listitem"><span class="emphasis"><em>FXE = h (FXF, FXB, CYB)</em></span></li></ul></div><p>On the other <a id="id10360000" class="indexterm"/>hand, the prediction of the Canadian dollar to US dollar's exchange rate (FXC) using the exchange rate for the Japanese yen (FXY) and the Australian dollar (FXA) is poor with both the configurations.</p><div class="note" title="Note"><h3 class="title"><a id="note29900"/>Note</h3><p>
<span class="strong"><strong>The empirical evaluation</strong></span>
</p><p>These empirical tests use a simple accuracy metric. A formal comparison of the regression models will systematically analyze every combination of input and output variables. The evaluation will also compute the precision, the recall, and the F1 score for each of those models (refer to the <span class="emphasis"><em>Key quality metrics</em></span> section under <span class="emphasis"><em>Validation</em></span> in the <span class="emphasis"><em>Assessing a model</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>).</p></div></div><div class="section" title="Impact of the hidden layers' architecture"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec13700"/>Impact of the hidden layers' architecture</h3></div></div></div><p>The next test <a id="id10370000" class="indexterm"/>consists of evaluating the impact of the hidden layer(s) of configuration on the accuracy of three models: <span class="emphasis"><em>FXF, FXB, CYB =&gt; FXE</em></span>, <span class="emphasis"><em>FCX, GLD, FXA =&gt;FXY</em></span>, and <span class="emphasis"><em>FXC, GLD, FXA, FXY, FXB =&gt; FXE</em></span>. For this test, the accuracy is computed by selecting a subset of the training data as a test sample, for the sake of convenience. The objective of the test is to compare different network architectures using some metrics, and not to estimate the absolute accuracy of each model.</p><p>The four network configurations are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A single hidden layer with four nodes</li><li class="listitem">Two hidden layers with four nodes each</li><li class="listitem">Two hidden layers with seven nodes each</li><li class="listitem">Three hidden layers with eight, five, and six nodes</li></ul></div><p>Let's take a look at the following graph:</p><div class="mediaobject"><img src="../Images/image01536.jpeg" alt="Impact of the hidden layers' architecture"/><div class="caption"><p>The impact of the hidden layers' architecture on the MLP accuracy</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id10380000" class="indexterm"/>complex neural network architecture with two or more hidden layers generates weights with similar accuracy. The four-node single hidden layer architecture generates the highest accuracy. The computation of the accuracy using a formal cross-validation technique would generate a lower accuracy number.</p><p>Finally, we take a look at the impact of the complexity of the network on the duration of the training, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01537.jpeg" alt="Impact of the hidden layers' architecture"/><div class="caption"><p>The impact of the hidden layers' architecture on the duration of training</p></div></div><p style="clear:both; height: 1em;"> </p><p>Not surprisingly, the time complexity increases significantly with the number of hidden layers and number of nodes.</p></div></div></div>
<div class="section" title="Convolution neural networks"><div class="titlepage" id="aid-688M42"><div><div><h1 class="title"><a id="ch09lvl1sec6400"/>Convolution neural networks</h1></div></div></div><p>This section is provided as a brief introduction to convolution neural networks without the Scala implementation.</p><p>So far, the layers of perceptrons were organized as a fully connected network. It is clear that the number of synapses or weights increases significantly as the number and size of hidden layers increases. For instance, a network for a features set of dimension 6, 3 hidden layers of 64 nodes each, and one output value requires <span class="emphasis"><em>7*64 + 2*65*64 + 65*1 = 8833</em></span> weights!</p><p>Applications such as image or character recognition require very large features set, making training a fully connected layered perceptron very computational intensive. Moreover, these applications need to convey spatial information such as the proximity of pixels as part of the features vector.</p><p>A recent approach, known as <a id="id10390000" class="indexterm"/><span class="strong"><strong>convolution neural networks</strong></span>, consists of limiting the number of nodes in the hidden layers a input node is connected to. In other words, the methodology leverages spatial localization to reduce the complexity of connectivity between the input and the hidden layer [9:15]. The subset of input nodes connected to a single neuron in the hidden layer is known as the <span class="strong"><strong>local receptive fields</strong></span>.</p><div class="section" title="Local receptive fields"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12500"/>Local receptive fields</h2></div></div></div><p>The neuron <a id="id10400000" class="indexterm"/>of the hidden layer learns from the local receptive fields or subimage of <span class="emphasis"><em>n by n</em></span> pixels, each of those pixels being an input value. The next local receptive field, which is shifted by one pixel in any direction, is connected to the next neuron in the first hidden layer. The first hidden layer is known as the <span class="strong"><strong>convolution layer</strong></span>. An illustration of the mapping between the input (image) and the first hidden layer (convolution layer) is as follows:</p><div class="mediaobject"><img src="../Images/image01538.jpeg" alt="Local receptive fields"/><div class="caption"><p>The generation of a convolution layer from an image</p></div></div><p style="clear:both; height: 1em;"> </p><p>It would make <a id="id10410000" class="indexterm"/>sense that each <span class="emphasis"><em>n by n</em></span> local receptive field has a bias element (+1) that connects to the hidden neuron. However, the extra complexity does not lead to a more accurate model, and therefore, the bias is shared across the neurons of the convolution layer.</p></div><div class="section" title="Sharing of weights"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12600"/>Sharing of weights</h2></div></div></div><p>The local <a id="id10420000" class="indexterm"/>receptive fields representing a small section of the image are generated by shifting the fields by one pixel (up, down, left, or right). Therefore, the weights associated with the local receptive fields are also shared across the neurons in the hidden layer. As a matter of fact, the same feature such as an image color or edge can be detected in many pixels across the image. The maps between the input features and neurons in the hidden layer, known as <a id="id10430000" class="indexterm"/><span class="strong"><strong>features maps</strong></span>, share weights across the convolution layer. The output is computed using the activation function.</p><div class="note" title="Note"><h3 class="title"><a id="note30000"/>Note</h3><p>
<span class="strong"><strong>Tanh versus the sigmoid activation</strong></span>
</p><p>The sigmoid is predominately used in the examples related to the multilayer perceptron as the activation function for the hidden layer. The hyperbolic tangent function is commonly used for convolution networks.</p></div></div><div class="section" title="Convolution layers"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12700"/>Convolution layers</h2></div></div></div><p>The output <a id="id10440000" class="indexterm"/>computed from the features maps is expressed as a convolution that is similar to the convolution used in a discrete Fourier transformed-based filter (refer to <span class="strong"><strong>M11</strong></span> mathematical expression in the <span class="emphasis"><em>DFT-based filtering</em></span> section under <span class="emphasis"><em>Fourier analysis</em></span> in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>). The activation function that computes the output in the hidden layer has to be modified to take into account the local receptive fields.</p><div class="note" title="Note"><h3 class="title"><a id="note30100"/>Note</h3><p>
<span class="strong"><strong>The activation of a convolution neural network</strong></span>
</p><p>M13: The output value <span class="emphasis"><em>z<sub>j</sub></em></span> for a shared bias <span class="emphasis"><em>w<sub>0</sub></em></span>, an activation function <span class="emphasis"><em>σ</em></span>, a local receptive field of <span class="emphasis"><em>n by n</em></span> pixels, input values <span class="emphasis"><em>x<sub>ij</sub></em></span>
<span class="emphasis"><em>,</em></span> and weights <span class="emphasis"><em>wuv</em></span> associated with a features map is given by:</p><div class="mediaobject"><img src="../Images/image01539.jpeg" alt="Convolution layers"/></div><p style="clear:both; height: 1em;"> </p></div><p>The next step in building the neural network would be to use the output of the convolution layer to a full connected hidden layer. However, the features maps in the convolution layer are usually similar so that they can be reduced to a smaller set of outputs using an intermediate layer known as subsampling layer [9:16].</p></div><div class="section" title="Subsampling layers"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12800"/>Subsampling layers</h2></div></div></div><p>Each features <a id="id10450000" class="indexterm"/>map in the convolution layer is reduced or condensed into a smaller features map. The layer composed of these smaller features map is known as the subsampling layer. The purpose of the sampling is to reduce the sensitivity of the weights to any minute changes in the image between adjacent pixels. The sharing of weights reduces the sensitivity to any nonsignificant changes in the image:</p><div class="mediaobject"><img src="../Images/image01540.jpeg" alt="Subsampling layers"/><div class="caption"><p>The connectivity between features map from a convolution to a subsampling layer</p></div></div><p style="clear:both; height: 1em;"> </p><p>The subsampling layer is sometimes referred to as the <span class="strong"><strong>pooling layer</strong></span>.</p></div><div class="section" title="Putting it all together"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec12900"/>Putting it all together</h2></div></div></div><p>The last layer of the <a id="id10460000" class="indexterm"/>convolution neural network is the fully connected hidden layer and output layer, subjected to the same transformative formulas as the traditional multilayer perceptron. The output values can be computed using a linear product or a <code class="literal">softmax</code> function:</p><div class="mediaobject"><img src="../Images/image01541.jpeg" alt="Putting it all together"/><div class="caption"><p>An overview of a convolution neural network</p></div></div><p style="clear:both; height: 1em;"> </p><p>The error backpropagation algorithm described in the <span class="emphasis"><em>Step 2 – error back propagation</em></span> section has to be modified to support the features map [9:17].</p><div class="note" title="Note"><h3 class="title"><a id="note30200"/>Note</h3><p>
<span class="strong"><strong>The architecture of convolution networks</strong></span>
</p><p>Deep convolution neural networks have multiple sequences of convolution layers and subsampling layers and may have more than one fully connection hidden layer.</p></div></div></div>
<div class="section" title="Benefits and limitations" id="aid-6976M1"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec6500"/>Benefits and limitations</h1></div></div></div><p>The advantages and <a id="id10470000" class="indexterm"/>disadvantages of neural networks depend on which other machine learning methods they are compared to. However, neural-network-based classifiers, particularly the multilayer perceptron using the error backpropagation, have some obvious advantages, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The mathematical foundation of a neural network does not require expertise in dynamic programming or linear algebra, beyond the basic gradient descent algorithm.</li><li class="listitem">A neural network can perform tasks that a linear algorithm cannot.</li><li class="listitem">An MLP is usually reliable for highly dynamic and nonlinear processes. Contrary to the support vector machines, they do not require us to increase the problem dimension through kernelization.</li><li class="listitem">An MLP does not make any assumption on linearity, variable independence, or normality.</li><li class="listitem">The execution of <a id="id10480000" class="indexterm"/>training of an MLP lends itself to concurrent processing quite well for online training. In most architecture, the algorithm can continue even if a node in the network fails (refer to the <span class="emphasis"><em>Apache Spark</em></span> section in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span>).</li></ul></div><p>However, as with any machine <a id="id10490000" class="indexterm"/>learning algorithm, neural networks have their detractors. The most documented limitations are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">MLP models are black boxes for which the association between features and classes may not be easily described and understood.</li><li class="listitem">An MLP requires a lengthy training process, especially using the batch training strategy. For example, a two-layer network has a time complexity (number of multiplications) of <span class="emphasis"><em>O(n.m.p.N.e)</em></span> for <span class="emphasis"><em>n</em></span> input variables, <span class="emphasis"><em>m</em></span> hidden neurons, <span class="emphasis"><em>p</em></span> output values, <span class="emphasis"><em>N</em></span> observations, and <span class="emphasis"><em>e</em></span> epochs. It is not uncommon that a solution emerges after thousands of epochs. The online training strategy using a momentum factor tends to converge faster and requires a smaller number of epochs than the batch process.</li><li class="listitem">Tuning the configuration parameters, such as optimization of the learning rate and momentum factors, selection of the most appropriate activation method, and the cumulative error formula can turn into a lengthy process.</li><li class="listitem">Estimating the minimum size of the training set required to generate an accurate model and limiting the computation time is not obvious.</li><li class="listitem">A neural network cannot be incrementally retrained. Any new labeled data requires the execution of several training epochs.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note30300"/>Note</h3><p>
<span class="strong"><strong>Other types of neural networks</strong></span>
</p><p>This chapter covers the multilayer perceptron and introduces the concept of a convolution neural network. There are many more types of neural networks, such as recurrent networks and mixture density networks.</p></div></div>
<div class="section" title="Summary" id="aid-6A5N81"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec6600"/>Summary</h1></div></div></div><p>This concludes not only the journey inside the multilayer perceptron, but also the introduction of the supervised learning algorithms. In this chapter, you learned:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The components and architecture of artificial neural networks</li><li class="listitem">The stages of the training cycle (or epoch) for the backpropagation multilayer perceptron</li><li class="listitem">How to implement an MLP from the ground up in Scala</li><li class="listitem">The numerous configuration parameters and options available to create the MLP classification or regression model.</li><li class="listitem">To evaluate the impact of the learning rate and the gradient descent momentum factor on the convergence of the training process.</li><li class="listitem">How to apply a multilayer perceptron to the financial analysis of the fluctuation of currencies</li><li class="listitem">An overview of the convolution neural network</li></ul></div><p>The next chapter will introduce the concept of genetic algorithms with a complete implementation in Scala. Although, strictly speaking, genetic algorithms do not belong to the family of machine learning algorithms, they play a crucial role in the optimization of nonlinear, nondifferentiable problems, and the selection of strong classifiers within ensembles.</p></div>
<div class="chapter" title="Chapter&#xA0;10.&#xA0;Genetic Algorithms" id="aid-6B47Q1"><div class="titlepage"><div><div><h1 class="title"><a id="ch24"/>Chapter 10. Genetic Algorithms</h1></div></div></div><p>This chapter introduces the concept of evolutionary computing. Algorithms derived from the theory of evolution are particularly efficient in solving large combinatorial or <span class="strong"><strong>NP problems</strong></span>. Evolutionary computing has been pioneered by John Holland [10:1] and David Goldberg [10:2]. Their findings should be of interest to anyone eager to learn about the foundation of <span class="strong"><strong>genetic algorithms</strong></span> (<span class="strong"><strong>GA</strong></span>) and <span class="strong"><strong>artificial life</strong></span>.</p><p>This chapter covers the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The origin of evolutionary computing</li><li class="listitem">The theoretical foundation of genetic algorithms</li><li class="listitem">Advantages and limitations of genetic algorithms</li></ul></div><p>From a practical perspective, you will learn how to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Apply genetic algorithms to leverage technical analysis of market price and volume movement to predict future returns</li><li class="listitem">Evaluate or estimate the search space</li><li class="listitem">Encode solutions in the binary format using either hierarchical or flat addressing</li><li class="listitem">Tune some of the genetic operators</li><li class="listitem">Create and evaluate fitness functions</li></ul></div><div class="section" title="Evolution"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec6700"/>Evolution</h1></div></div></div><p>The <a id="id10500000" class="indexterm"/><span class="strong"><strong>theory of evolution</strong></span>, enunciated by Charles Darwin, describes the morphological adaptation of living organisms [10:3].</p><div class="section" title="The origin"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13000"/>The origin</h2></div></div></div><p>The <a id="id10510000" class="indexterm"/><span class="strong"><strong>Darwinian</strong></span> process <a id="id10520000" class="indexterm"/>consists of optimizing the morphology of organisms to adapt to the harshest environments—hydrodynamic optimization for fishes, aerodynamic for birds, or stealth skills for predators. The following diagram shows a gene:</p><div class="mediaobject"><img src="../Images/image01542.jpeg" alt="The origin"/></div><p style="clear:both; height: 1em;"> </p><p>The <span class="strong"><strong>population</strong></span> of organisms varies over time. The number of individuals within a population changes, sometimes dramatically. These variations are usually associated with the abundance or lack of predators and prey as well as the changing environment. Only the fittest organisms within the population can survive over time by adapting quickly to sudden changes in living environments and new constraints.</p></div><div class="section" title="NP problems"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13100"/>NP problems</h2></div></div></div><p>NP stands for <a id="id10530000" class="indexterm"/>nondeterministic polynomial <a id="id10540000" class="indexterm"/>time. The NP problems' concept relates to the theory of computation <a id="id10550000" class="indexterm"/>and more precisely, time and space complexity. The categories of NP problems <a id="id10560000" class="indexterm"/>are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>P-problems</strong></span> (or P decision problems): For <a id="id10570000" class="indexterm"/>these problems, the resolution on a deterministic Turing machine (computer) takes a deterministic polynomial time.</li><li class="listitem"><span class="strong"><strong>NP problems</strong></span>: These <a id="id10580000" class="indexterm"/>problems can be resolved in a polynomial time on nondeterministic machines.</li><li class="listitem"><span class="strong"><strong>NP-complete problems</strong></span>: These <a id="id10590000" class="indexterm"/>are NP-hard problems that are reduced to NP problems for which the solution takes a deterministic polynomial time. These types of problems may be difficult to solve but their solutions can be validated.</li><li class="listitem"><span class="strong"><strong>NP-hard problems</strong></span>: These <a id="id10600000" class="indexterm"/>problems have solutions that may not be found in polynomial time.<div class="mediaobject"><img src="../Images/image01543.jpeg" alt="NP problems"/><div class="caption"><p>The categorization of NP problems using computational complexity</p></div></div><p style="clear:both; height: 1em;"> </p></li></ul></div><p>Problems <a id="id10610000" class="indexterm"/>such as the traveling salesman, floor shop scheduling, the computation of a graph K-minimum spanning tree, map coloring, or cyclic ordering have a search execution time that is a nondeterministic polynomial, ranging from <span class="emphasis"><em>n!</em></span> to <span class="emphasis"><em>2<sub>n</sub></em></span> for a population of <span class="emphasis"><em>n</em></span> elements [10:4].</p><p>NP problems cannot always be solved using analytical methods because of the computation overhead—even in the case of a model, it relies on differentiable functions. Genetic algorithms were invented by John Holland in the 1970s, and they derived their properties from the theory of evolution of Darwin to tackle NP and NP-complete problems.</p></div><div class="section" title="Evolutionary computing"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13200"/>Evolutionary computing</h2></div></div></div><p>A living organism <a id="id10620000" class="indexterm"/>consists of cells that contain identical chromosomes. <span class="strong"><strong>Chromosomes</strong></span> <a id="id10630000" class="indexterm"/>are strands of <span class="strong"><strong>DNA</strong></span> <a id="id10640000" class="indexterm"/>and serve as a model for the whole organism. A chromosome consists of <a id="id10650000" class="indexterm"/><span class="strong"><strong>genes</strong></span> that are blocks of DNA and encode a specific protein.</p><p>
<span class="strong"><strong>Recombination</strong></span> (or crossover) is <a id="id10660000" class="indexterm"/>the first stage of reproduction. Genes from parents generate the whole new chromosome (<span class="strong"><strong>offspring</strong></span>) that can be mutated. During mutation, one or more elements, also known as individual bases of the DNA strand or chromosomes, are changed. These changes are mainly caused by errors that occur when the genes from parents are being passed on to their offspring. The success of an organism in its life measures its fitness [10:5].</p><p>Genetic algorithms use reproduction to evolve a population of possible solutions to a problem.</p></div></div></div>
<div class="section" title="Genetic algorithms and machine learning" id="aid-6C2OC1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec6800"/>Genetic algorithms and machine learning</h1></div></div></div><p>The practical purpose of a genetic algorithm as an optimization technique is to solve problems by finding the most relevant or fittest solution among a set or group of solutions. Genetic algorithms <a id="id10670000" class="indexterm"/>have many applications in machine learning, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Discrete model parameters</strong></span>: Genetic <a id="id10680000" class="indexterm"/>algorithms are particularly effective in finding the set of discrete parameters that maximizes the log likelihood. For example, the colorization of a black and white movie relies on a large but finite set of transformations from shades of grey to the RGB color scheme. The search space is composed of the different transformations and the objective function is the quality of the colorized version of the movie.</li><li class="listitem"><span class="strong"><strong>Reinforcement learning</strong></span>: Systems<a id="id10690000" class="indexterm"/> that select the most appropriate rules or policies to match a given dataset rely on genetic algorithms to evolve the set of rules over time. The search space or population is the set of candidate rules, and the objective function is the credit or reward for an action triggered by these rules (refer to <a class="link" title="Chapter 11. Reinforcement Learning" href="part0220.xhtml#aid-6HPRO2">Chapter 11</a>, <span class="emphasis"><em>Reinforcement Learning</em></span>).</li><li class="listitem"><span class="strong"><strong>The neural network architecture</strong></span>: A <a id="id10700000" class="indexterm"/>genetic algorithm drives the evaluation of different configurations of networks. The search space consists of different combinations of hidden layers and the size of those layers. The fitness or objective function is the sum of the squared errors.</li><li class="listitem"><span class="strong"><strong>Ensemble learning</strong></span> [10:6]: A genetic algorithm <a id="id10710000" class="indexterm"/>can weed out the weak learners among a set of classifiers in order to improve the quality of the prediction.</li></ul></div></div>
<div class="section" title="Genetic algorithm components"><div class="titlepage" id="aid-6D18U2"><div><div><h1 class="title"><a id="ch10lvl1sec6900"/>Genetic algorithm components</h1></div></div></div><p>Genetic algorithms <a id="id10720000" class="indexterm"/>have the following three components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Genetic encoding</strong></span> (<span class="strong"><strong>and decoding</strong></span>): This is <a id="id10730000" class="indexterm"/>the conversion of a solution candidate and its components into the binary format (an array of bits or a string of <code class="literal">0</code> and <code class="literal">1</code> characters)</li><li class="listitem"><span class="strong"><strong>Genetic operations</strong></span>: This is <a id="id10740000" class="indexterm"/>the application of a set of operators to extract the best (most genetically fit) candidates (chromosomes)</li><li class="listitem"><span class="strong"><strong>Genetic fitness functions</strong></span>: This <a id="id10750000" class="indexterm"/>is the evaluation of the fittest candidate using an objective function</li></ul></div><p>Encodings and the fitness function are problem dependent. Genetic operators are not.</p><div class="section" title="Encoding"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13300"/>Encoding</h2></div></div></div><p>Let's consider the <a id="id10760000" class="indexterm"/>optimization problem in machine learning that consists of maximizing the log likelihood or minimizing the loss function. The goal is to compute the parameters or weights, <span class="emphasis"><em>w={w<sub>i</sub>}</em></span>, that minimize or maximize a function <span class="emphasis"><em>f(w)</em></span>. In the case of a nonlinear model, variables may depend on other variables, which make the optimization problem particularly challenging.</p><div class="section" title="Value encoding"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec13800"/>Value encoding</h3></div></div></div><p>The genetic algorithm <a id="id10770000" class="indexterm"/>manipulates variables as bits or bit strings. The conversion of a variable into a bit string is known as encoding. In the case where the variable is continuous, the conversion is known as <a id="id10780000" class="indexterm"/><span class="strong"><strong>quantization</strong></span> or <a id="id10790000" class="indexterm"/><span class="strong"><strong>discretization</strong></span>. Each type of variable has a unique encoding scheme, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Boolean values are easily encoded with 1 bit: 0 for false and 1 for true.</li><li class="listitem">Continuous variables are quantized or discretized in a fashion similar to the conversion of an analog to a digital signal. Let's consider the function with a maximum <span class="strong"><strong>max</strong></span> (similarly <span class="strong"><strong>min</strong></span> for minimum) over a range of values, encoded with <span class="emphasis"><em>n = 16</em></span> bits:<div class="mediaobject"><img src="../Images/image01544.jpeg" alt="Value encoding"/><div class="caption"><p>An illustration of quantization of a continuous variable y = f(x)</p></div></div><p style="clear:both; height: 1em;"> </p></li></ul></div><p>The step size of the discretization is computed as (M1):</p><div class="mediaobject"><img src="../Images/image01545.jpeg" alt="Value encoding"/></div><p style="clear:both; height: 1em;"> </p><p>The step size of the quantization of the <span class="emphasis"><em>sine y = sin(x)</em></span> in 16 bits is 1.524e-5.</p><p>Discrete or categorical variables are a bit more challenging to encode to bits. At a minimum, all the discrete values have to be accounted for. However, there is no guarantee that the number of variables will coincide with the bits boundary:</p><div class="mediaobject"><img src="../Images/image01546.jpeg" alt="Value encoding"/><div class="caption"><p>Padding for base 2 representation of values</p></div></div><p style="clear:both; height: 1em;"> </p><p>In this case, the <a id="id10800000" class="indexterm"/>next exponent, <span class="emphasis"><em>n+1</em></span>, defines the minimum number of bits required to represent the set of values: <span class="emphasis"><em>n = log2(m).toInt + 1</em></span>. A discrete variable with 19 values requires 5 bits. The remaining bits are set to an arbitrary value (0, NaN, and so on) depending on the problem. This procedure is known as <a id="id10810000" class="indexterm"/><span class="strong"><strong>padding</strong></span>.</p><p>Encoding is as much art as it is science. For each encoding function, you need a decoding function to convert the bits representation back to actual values.</p></div><div class="section" title="Predicate encoding"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec13900"/>Predicate encoding</h3></div></div></div><p>A predicate for <a id="id10820000" class="indexterm"/>a variable <span class="emphasis"><em>x</em></span> is a relation defined as a <span class="emphasis"><em>x operator [target]</em></span>; for instance, <span class="emphasis"><em>unit cost &lt; [9$]</em></span>, <span class="emphasis"><em>temperature = [82F]</em></span>, or <span class="emphasis"><em>Movie rating is [3 stars]</em></span>.</p><p>The simplest encoding scheme for predicates is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Variables</strong></span> are encoded as a category or type (for example, temperature, barometric pressure, and so on) because there are a finite number of variables in any model</li><li class="listitem"><span class="strong"><strong>Operators</strong></span> are encoded as discrete types</li><li class="listitem"><span class="strong"><strong>Values</strong></span> are encoded as either discrete or continuous values</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note30400"/>Note</h3><p>
<span class="strong"><strong>Encoding format for predicates</strong></span>
</p><p>There are many approaches for encoding a predicate in a bits string. For instance, the format <span class="emphasis"><em>{operator, left-operand, </em></span>and<span class="emphasis"><em> right-operand}</em></span> is useful because it allows you to encode a binary tree. The entire rule, <span class="emphasis"><em>IF predicate THEN action</em></span>, can be encoded with the action being represented as a discrete or categorical value.</p></div></div><div class="section" title="Solution encoding"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14000"/>Solution encoding</h3></div></div></div><p>The solution encoding <a id="id10830000" class="indexterm"/>approach describes the solution to a problem as an unordered sequence of predicates. Let's consider the following rule:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>IF</strong></span> {Gold price rises to [1316$/ounce]} <span class="strong"><strong>AND</strong></span> 
   {US$/Yen rate is [104]}).
<span class="strong"><strong>THEN</strong></span> {S&amp;P 500 index is [UP]}</pre></div><p>In this example, the search space is defined by two levels:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Boolean operators (for example, AND) and predicates</li><li class="listitem">Each predicate is defined as a tuple (a variable, operator, target value)</li></ul></div><p>The tree representation for the search space is shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01547.jpeg" alt="Solution encoding"/><div class="caption"><p>A graph representation of encoded rules</p></div></div><p style="clear:both; height: 1em;"> </p><p>The bits string representation is decoded back to its original format for further computation:</p><div class="mediaobject"><img src="../Images/image01548.jpeg" alt="Solution encoding"/><div class="caption"><p>Encoding, alteration, and decoding of predicates</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="The encoding scheme"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14100"/>The encoding scheme</h3></div></div></div><p>There are <a id="id10840000" class="indexterm"/>two <a id="id10850000" class="indexterm"/>approaches to encode such a candidate solution or chain of predicates:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Flat coding of a chromosome</li><li class="listitem">Hierarchical coding of a chromosome as a composition of genes</li></ul></div><div class="section" title="Flat encoding"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec2600"/>Flat encoding</h4></div></div></div><p>The flat encoding <a id="id10860000" class="indexterm"/>approach consists of encoding the set of predicates into a single chromosome (bits string), representing a specific solution candidate to the optimization problem. The identity of the predicates is not preserved:</p><div class="mediaobject"><img src="../Images/image01549.jpeg" alt="Flat encoding"/><div class="caption"><p>Flat addressing schema for chromosomes</p></div></div><p style="clear:both; height: 1em;"> </p><p>A genetic operator manipulates the bits of the chromosome regardless of whether the bits refer to a particular predicate:</p><div class="mediaobject"><img src="../Images/image01550.jpeg" alt="Flat encoding"/><div class="caption"><p>Chromosome encoding with flat addressing</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Hierarchical encoding"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec2700"/>Hierarchical encoding</h4></div></div></div><p>In this configuration, the <a id="id10870000" class="indexterm"/>characteristic of each predicate is preserved during the encoding process. Each predicate is converted into a gene represented by a bit string. The genes are aggregated to form the chromosome. An extra field is added to the bits string or chromosome for the selection of the gene. This extra field consists of the index or the address of the gene:</p><div class="mediaobject"><img src="../Images/image01551.jpeg" alt="Hierarchical encoding"/><div class="caption"><p>Hierarchical addressing schema for chromosomes</p></div></div><p style="clear:both; height: 1em;"> </p><p>A generic operator <a id="id10880000" class="indexterm"/>selects the predicate it needs to first manipulate. Once the target gene is selected, the operator updates the bits string associated with the gene, as follows:</p><div class="mediaobject"><img src="../Images/image01552.jpeg" alt="Hierarchical encoding"/><div class="caption"><p>Chromosome encoding with flat addressing</p></div></div><p style="clear:both; height: 1em;"> </p><p>The next step is to define the genetic operators that manipulate or update the bits string representing either a chromosome or individual genes.</p></div></div></div><div class="section" title="Genetic operators"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13400"/>Genetic operators</h2></div></div></div><p>The <a id="id10890000" class="indexterm"/>implementation of the reproduction cycle attempts to replicate the natural reproduction process [10:7]. The reproduction cycle that controls the population of chromosomes consists of three genetic operators:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Selection</strong></span>: This <a id="id10900000" class="indexterm"/>operator ranks chromosomes according to a fitness function or criteria. It eliminates the weakest or less-fit chromosomes and controls the population growth.</li><li class="listitem"><span class="strong"><strong>Crossover</strong></span>: This <a id="id10910000" class="indexterm"/>operator pairs chromosomes to generate offspring chromosomes. These offspring chromosomes are added to the population along with their parent chromosomes.</li><li class="listitem"><span class="strong"><strong>Mutation</strong></span>: This <a id="id10920000" class="indexterm"/>operator introduces a minor alteration in the genetic code (bits string representation) to prevent the successive reproduction cycles from electing the same fittest chromosome. In optimization terms, this operator reduces the risk of the genetic algorithm converging quickly toward a local maximum or minimum.</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note30500"/>Note</h3><p>
<span class="strong"><strong>The transposition operator</strong></span>
</p><p>Some <a id="id10930000" class="indexterm"/>implementations of genetic algorithms use a fourth operator, genetic transposition, in case the fitness function cannot be very well defined and the initial population is very large. Although additional genetic operators could potentially reduce the odds of finding a local maximum or minimum, the inability to describe the fitness criteria or the search space is a sure sign that a genetic algorithm may not be the most suitable tool.</p></div><p>The following diagram gives an overview of the genetic algorithm workflow:</p><div class="mediaobject"><img src="../Images/image01553.jpeg" alt="Genetic operators"/><div class="caption"><p>A basic workflow for the execution of genetic algorithms</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note30600"/>Note</h3><p>
<span class="strong"><strong>Initialization</strong></span>
</p><p>The initialization of the search space (a set of potential solutions to a problem) in any optimization procedure is challenging and genetic algorithms are no exception. In the absence of biases or heuristics, the reproduction initializes the population with randomly generated chromosomes. However, it is worth the effort to extract the characteristics of a population. Any well-founded bias introduced during initialization facilitates the convergence of the reproduction process.</p></div><p>Each of these genetic operators has at least one configurable parameter that has to be estimated and/or tuned. Moreover, you will likely need to experiment with different fitness functions and encoding schemes in order to increase your odds of finding a fittest solution (or chromosome).</p><div class="section" title="Selection"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14200"/>Selection</h3></div></div></div><p>The purpose of <a id="id10940000" class="indexterm"/>the genetic selection phase is to evaluate, rank, and weed out the chromosomes (that is, the solution candidates) that are not a good fit for the problem. The selection procedure relies on a fitness function to score and rank candidate solutions through their chromosomal representation. It is a common practice to constrain the growth of the population of chromosomes by setting a limit to the size of the population.</p><p>There are several methodologies to implement the selection process from scaled relative fitness, Holland roulette wheel, and tournament selection to rank-based selection [10:8].</p><div class="note" title="Note"><h3 class="title"><a id="note30700"/>Note</h3><p>
<span class="strong"><strong>Relative fitness degradation</strong></span>
</p><p>As the initial population of chromosomes evolves, the chromosomes tend to get more and more similar to each other. This phenomenon is a healthy sign that the population is actually converging. However, for some problems, you may need to scale or magnify the relative fitness to preserve a meaningful difference in the fitness score between the chromosomes [10:9].</p></div><p>The following implementation relies on rank-based selection.</p><p>The selection process consists of the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Apply the fitness function to each chromosome <span class="emphasis"><em>j</em></span> in the population <span class="emphasis"><em>f<sub>j</sub></em></span>.</li><li class="listitem">Compute the total fitness score for the entire population <span class="emphasis"><em>∑f<sub>j</sub></em></span>.</li><li class="listitem">Normalize the fitness score of each chromosome by the sum of the fitness scores of all the chromosomes <span class="emphasis"><em>f<sub>j</sub> = f<sub>i</sub>/Σf<sub>j</sub></em></span>.</li><li class="listitem">Sort the chromosomes by their descending fitness score <span class="emphasis"><em>f<sub>j</sub> &lt; f<sub>j-1</sub></em></span>.</li><li class="listitem">Compute the cumulative fitness score for each chromosome <span class="emphasis"><em>j f<sub>j</sub> = f<sub>j</sub> + ∑f<sub>k</sub></em></span>.</li><li class="listitem">Generate the selection probability (for the rank-based formula) as a random value <span class="emphasis"><em>p ε [0,1]</em></span>.</li><li class="listitem">Eliminate the chromosome <span class="emphasis"><em>k</em></span> that has a low unfitness score <span class="emphasis"><em>f<sub>k</sub> &lt; p</em></span> or high fitness cost <span class="emphasis"><em>f<sub>k</sub></em></span><span class="emphasis"><em> &gt; p</em></span>.</li><li class="listitem">Reduce the size of the population if it exceeds the maximum allowed number of chromosomes.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note30800"/>Note</h3><p>
<span class="strong"><strong>Natural selection</strong></span>
</p><p>You should not be surprised by the need to control the size of the population of chromosomes. After all, nature does not allow any species to grow beyond a certain point in order to avoid depleting natural resources. The predator-prey process modeled by the <span class="strong"><strong>Lotka-Volterra</strong></span> equation [10:10] keeps the population of each species in check.</p></div></div><div class="section" title="Crossover"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14300"/>Crossover</h3></div></div></div><p>The purpose of the <a id="id10950000" class="indexterm"/>genetic crossover is to expand the current population of chromosomes in order to intensify the competition among the solution candidates. The crossover phase consists of reprogramming chromosomes from one generation to the next. There are many different variations of crossover techniques. The algorithm for the evolution of the population of chromosomes is independent of the crossover technique. Therefore, the case study uses the simpler one-point crossover. The crossover swaps sections of the two-parent chromosomes to produce two offspring chromosomes, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01554.jpeg" alt="Crossover"/><div class="caption"><p>A chromosome's crossover operation</p></div></div><p style="clear:both; height: 1em;"> </p><p>An important element in the crossover phase is selecting and pairing of parent chromosomes. There are different approaches for selecting and pairing the parent chromosomes that are the most suitable for reproduction:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Selecting only the <span class="emphasis"><em>n</em></span> fittest chromosomes for reproduction</li><li class="listitem">Pairing chromosomes ordered by their fitness (or unfitness) value</li><li class="listitem">Pairing the fittest chromosome with the least-fit chromosome, the second fittest chromosome with the second least-fit chromosome, and so on</li></ul></div><p>It is a common practice to rely on a specific optimization problem to select the most appropriate selection method as it is highly domain dependent.</p><p>The crossover phase that uses hierarchical addressing as the encoding scheme consists of the <a id="id10960000" class="indexterm"/>following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Extract pairs of chromosomes from the population.</li><li class="listitem">Generate a random probability <span class="emphasis"><em>p </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em> [0,1]</em></span>.</li><li class="listitem">Compute the index <span class="emphasis"><em>r<sub>i</sub></em></span> of the gene for which the crossover is applied as <span class="emphasis"><em>r<sub>i</sub></em></span><span class="emphasis"><em> = p.num_genes</em></span>, where <span class="emphasis"><em>num_genes</em></span> are the number of genes in a chromosome.</li><li class="listitem">Compute the index of the bit in the selected gene for which the crossover is applied as <span class="emphasis"><em>x<sub>i</sub></em></span><span class="emphasis"><em> = p.gene_length</em></span>, where <span class="emphasis"><em>gene_length</em></span> is the number of bits in the gene.</li><li class="listitem">Generate two offspring chromosomes by interchanging strands between parents.</li><li class="listitem">Add the two offspring chromosomes to the population.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note30900"/>Note</h3><p>
<span class="strong"><strong>Preserving parent chromosomes</strong></span>
</p><p>You may wonder why the parents are not removed from the population once the offspring chromosomes are created. This is because there is no guarantee that any of the offspring chromosomes are a better fit.</p></div></div><div class="section" title="Mutation"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14400"/>Mutation</h3></div></div></div><p>The <a id="id10970000" class="indexterm"/>objective of genetic mutation is to prevent the reproduction cycle from converging toward a local optimum by introducing a pseudo-random alteration to the genetic material. The mutation procedure inserts a small variation in a chromosome to maintain some level of diversity between generations. The methodology consists of flipping one bit in the bits string representation of the chromosome, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01555.jpeg" alt="Mutation"/><div class="caption"><p>A chromosome's mutation operation</p></div></div><p style="clear:both; height: 1em;"> </p><p>The mutation is the simplest of the three phases in the reproduction process. In the case of hierarchical <a id="id10980000" class="indexterm"/>addressing, the steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select the chromosome to be mutated.</li><li class="listitem">Generate a random probability <span class="emphasis"><em>p </em></span><span class="emphasis"><em>ϵ</em></span><span class="emphasis"><em>[0,1]</em></span>.</li><li class="listitem">Compute the index <span class="emphasis"><em>m<sub>i</sub></em></span> of the gene to be mutated using the formula <span class="emphasis"><em>m<sub>i</sub></em></span><span class="emphasis"><em> = p.num_genes</em></span>.</li><li class="listitem">Compute the index of the bit in the gene to be mutated <span class="emphasis"><em>x<sub>i</sub></em></span><span class="emphasis"><em> = p.genes_length</em></span>.</li><li class="listitem">Perform a flip XOR operation on the selected bit.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note31000"/>Note</h3><p>
<span class="strong"><strong>The tuning issue</strong></span>
</p><p>The tuning of a genetic algorithm can be a daunting task. A plan including a systematic design experiment for measuring the impact of the encoding, fitness function, crossover, and mutation ratio is necessary to avoid lengthy evaluation and self-doubt.</p></div></div></div><div class="section" title="The fitness score"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13500"/>The fitness score</h2></div></div></div><p>The <a id="id10990000" class="indexterm"/>fitness function is the centerpiece of the selection process. There are three categories of <a id="id11000000" class="indexterm"/>fitness functions, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>The fixed fitness function</strong></span>: In <a id="id11010000" class="indexterm"/>this function, the computation of the fitness value does not vary during the reproduction process</li><li class="listitem"><span class="strong"><strong>The evolutionary fitness function</strong></span>: In <a id="id11020000" class="indexterm"/>this function, the computation of the fitness value morphs between each selection according to predefined criteria</li><li class="listitem"><span class="strong"><strong>An approximate fitness function</strong></span>: In <a id="id11030000" class="indexterm"/>this function, the fitness value cannot be computed directly using an analytical formula [10:11]</li></ul></div><p>Our implementation of the genetic algorithm uses a fixed fitness function.</p></div></div>
<div class="section" title="Implementation"><div class="titlepage" id="aid-6DVPG2"><div><div><h1 class="title"><a id="ch10lvl1sec7000"/>Implementation</h1></div></div></div><p>As mentioned <a id="id11040000" class="indexterm"/>earlier, the genetic <a id="id11050000" class="indexterm"/>operators are independent of the problem to be solved. Let's implement all the components of the reproduction cycle. The fitness function and the encoding scheme are highly domain specific.</p><p>In accordance with the principles of object-oriented programming, the software architecture defines the genetic operators using a top-down approach: starting with the population, then each chromosome, and down to each gene.</p><div class="section" title="Software design"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13600"/>Software design</h2></div></div></div><p>The <a id="id11060000" class="indexterm"/>implementation of the genetic algorithm uses a design that is similar to the template for classifiers (refer to the <span class="emphasis"><em>Design template for classifier</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The key components of the implementation of the genetic algorithm are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">Population</code> class defines the current set of solution candidates or chromosomes.</li><li class="listitem">The <code class="literal">GASolver</code> class implements the GA solver and has two components: a configuration object of the <code class="literal">GAConfig</code> type and the initial population. This class implements an explicit monadic data transformation of the <code class="literal">ETransform</code> type.</li><li class="listitem">The <code class="literal">GAConfig</code> configuration class consists of the GA execution and reproduction configuration parameters.</li><li class="listitem">The reproduction (of the <code class="literal">Reproduction</code> type) controls the reproduction cycle between consecutive generations of chromosomes through the <code class="literal">mate</code> method.</li><li class="listitem">The <code class="literal">GAMonitor</code> monitoring trait tracks the progress of the optimization and evaluates the exit condition for each reproduction cycle.</li></ul></div><p>The following UML class diagram describes the relation between the different components of the genetic algorithm:</p><div class="mediaobject"><img src="../Images/image01556.jpeg" alt="Software design"/><div class="caption"><p>The UML class diagram of genetic algorithm components</p></div></div><p style="clear:both; height: 1em;"> </p><p>Let's start with defining the key classes that control the genetic algorithm.</p></div><div class="section" title="Key components"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13700"/>Key components</h2></div></div></div><p>The <code class="literal">Population</code> <a id="id11070000" class="indexterm"/>parameterized class (with the <code class="literal">Gene</code> subtype) contains the set or pool of chromosomes. A population contains chromosomes that are a sequence or list of elements of the type inherited from <code class="literal">Gene</code>. A <code class="literal">Pool</code>
<a id="id11080000" class="indexterm"/> is a mutable array used in order to avoid excessive duplication of the <code class="literal">Chromosome</code> instances associated with immutable collections.</p><div class="note" title="Note"><h3 class="title"><a id="note31100"/>Note</h3><p>
<span class="strong"><strong>The case for mutability</strong></span>
</p><p>It is a good Scala programming practice to stay away from mutable collections. However, in this case, the number of chromosomes can be very large. Most implementations of genetic algorithms update the population potentially three times per reproduction cycle, generating a large number of objects and taxing the Java garbage collector.</p></div><div class="section" title="Population"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14500"/>Population</h3></div></div></div><p>The <code class="literal">Population</code> class <a id="id11090000" class="indexterm"/>takes two arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">limit</code>: This is the maximum size of the population</li><li class="listitem"><code class="literal">chromosomes</code>: This is the pool of chromosomes that define the current population</li></ul></div><p>A reproduction cycle executes the following sequence of three genetic operators on a population: <code class="literal">select</code> for the selection across all the chromosomes of the population (line <code class="literal">1</code>), <code class="literal">+-</code> for crossover of all the chromosomes (line <code class="literal">2</code>), and <code class="literal">^</code> for the mutation of each chromosome (line <code class="literal">3</code>). Consider the following code:</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>Pool</strong></span>[T &lt;: Gene] = mutable.ArrayBuffer[Chromosome[T]]

class <span class="strong"><strong>Population</strong></span>[T &lt;: Gene](
    <span class="strong"><strong>limit</strong></span>: Int, val <span class="strong"><strong>chromosomes</strong></span>: Pool[T]) {    
  def <span class="strong"><strong>select</strong></span>(score: Chromosome[T]=&gt;Unit, cutOff: Double) //<span class="strong"><strong>1</strong></span>
  def <span class="strong"><strong>+-</strong></span> (xOver: Double) //<span class="strong"><strong>2</strong></span>
  def <span class="strong"><strong>^</strong></span> (mu: Double) //<span class="strong"><strong>3</strong></span>
  …
}</pre></div><p>The <code class="literal">limit</code> value specifies the maximum size of the population during optimization. It defines the hard limit or constraints on the population growth.</p></div><div class="section" title="Chromosomes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14600"/>Chromosomes</h3></div></div></div><p>The <a id="id11100000" class="indexterm"/>chromosome is the second level of containment in the genotype hierarchy. The <code class="literal">Chromosome</code> class takes a list of genes as parameter (code). The signature of the crossover and mutation methods, <code class="literal">+-</code> and <code class="literal">^</code>, are similar to their implementation in the <code class="literal">Population</code> class except for the fact that the crossover and mutable parameters are passed as indices relative to the list of genes and each gene. The section dedicated to the genetic crossover describes the <code class="literal">GeneticIndices</code> class:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Chromosome</strong></span>[T &lt;: Gene](val code: List[T]) {   
  var <span class="strong"><strong>cost</strong></span>: Double = Random.nextDouble //<span class="strong"><strong>4</strong></span>
  def <span class="strong"><strong>+-</strong></span> (that: Chromosome[T], idx: <span class="strong"><strong>GeneticIndices</strong></span>): 
        (Chromosome[T], Chromosome[T]) 
  def <span class="strong"><strong>^</strong></span> (idx: GeneticIndices): Chromosome[T]
   …
}</pre></div><p>The algorithm assigns the (un)fitting score or a <code class="literal">cost</code> value to each chromosome to enable the ranking of chromosomes in the population, and ultimately, the selection of the fittest chromosomes (line <code class="literal">4</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note31200"/>Note</h3><p>
<span class="strong"><strong>Fitness versus cost</strong></span>
</p><p>The machine learning algorithms use the loss function or its variant as an objective function to be minimized. This implementation of the GA uses <code class="literal">cost</code> scores in order to be consistent with the concept of the minimization of the cost, loss, or penalty function.</p></div></div><div class="section" title="Genes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14700"/>Genes</h3></div></div></div><p>Finally, the <a id="id11110000" class="indexterm"/>reproduction process executes the genetic operators on each gene:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Gene</strong></span>(val <span class="strong"><strong>id</strong></span>: String, 
    val <span class="strong"><strong>target</strong></span>: Double, 
    <span class="strong"><strong>op</strong></span>: Operator)
    (implicit <span class="strong"><strong>quantize</strong></span>: Quantization, <span class="strong"><strong>encoding</strong></span>: Encoding){//<span class="strong"><strong>5</strong></span>
  lazy val <span class="strong"><strong>bits</strong></span>: BitSet = apply(target, op)

  def <span class="strong"><strong>apply</strong></span>(value: Double, op: Operator): BitSet //<span class="strong"><strong>6</strong></span>
  def <span class="strong"><strong>unapply</strong></span>(bitSet: BitSet): (Double, Operator) //<span class="strong"><strong>7</strong></span>
   …
  def <span class="strong"><strong>+-</strong></span> (index: Int, that: Gene): Gene //<span class="strong"><strong>8</strong></span>
  def <span class="strong"><strong>^</strong></span> (index: Int): Unit //<span class="strong"><strong>9</strong></span>
  …
}</pre></div><p>The <code class="literal">Gene</code> class takes three arguments and two implicit parameters, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">id</code>: This is the identifier of the gene. It is usually the name of the variable represented by the gene.</li><li class="listitem"><code class="literal">target</code>: This is the target value or threshold to be converted or discretized into a bit string.</li><li class="listitem"><code class="literal">op</code>: This is the operator that is applied to the target value.</li><li class="listitem"><code class="literal">quantize</code>: This is the <code class="literal">quantization</code> or <code class="literal">discretization</code> class that converts a double value to an integer to be converted into bits and vice versa (line <code class="literal">5</code>).</li><li class="listitem"><code class="literal">encoding</code>: This is the encoding or bits layout of the gene as a pair of values and operators.</li></ul></div><p>The <code class="literal">apply</code> method <a id="id11120000" class="indexterm"/>encodes a pair of value and operator into a bit set (line <code class="literal">6</code>). An <code class="literal">unapply</code> method is the reverse operation of <code class="literal">apply</code>. In this case, it decodes a bit set into a pair of value and operator (line <code class="literal">7</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note31300"/>Note</h3><p>
<span class="strong"><strong>unapply()</strong></span>
</p><p>The <code class="literal">unapply</code> method reverses the state transition performed by the <code class="literal">apply</code> method. For example, if the <code class="literal">apply</code> method populates a collection, the <code class="literal">unapply</code> method clears the collection from its elements.</p></div><p>The implementation of the crossover (line <code class="literal">8</code>) and mutation (line <code class="literal">9</code>) operators on a gene is similar to the operations on the container chromosome.</p><p>The quantization is implemented as a case class:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>Quantization</strong></span>(<span class="strong"><strong>toInt</strong></span>: Double =&gt; Int,
     <span class="strong"><strong>toDouble</strong></span>: Int =&gt; Double) {
   def this(R: Int) =  this((x: Double) =&gt; 
         (x*R).floor.toInt, (n: Int) =&gt; n/R) 
}</pre></div><p>The first <code class="literal">toInt</code> function converts a real value to an integer and <code class="literal">toDouble</code> converts the integer back to a real value. The <code class="literal">discretization</code> and <code class="literal">inverse</code> functions are encapsulated into a class to reduce the risk of inconsistency between the two opposite conversion functions.</p><p>The instantiation of a gene converts the predicate representation into a bit string (bits of the <code class="literal">java.util.BitSet</code> type) using the quantization function, <code class="literal">Quantization.toInt</code>.</p><p>The layout of a gene is defined by the <code class="literal">Encoding</code> class as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Encoding</strong></span>(nValueBits: Int, nOpBits: Int) {
  val rValue = Range(0, nValueBits)  
  val length = nValueBits + nOpBits
  val rOp = Range(nValueBits, length)
}</pre></div><p>The <code class="literal">Encoding</code> class <a id="id11130000" class="indexterm"/>specifies the bits layout of the gene as a number of bits, <code class="literal">nValueBits</code>, to encode the value and the number of bits, <code class="literal">nOpBits</code>, to encode the operator. The class defines the <code class="literal">rValue</code> range for the value and the <code class="literal">rOp</code> range for the operator. The client code has to be supplied to the implicit instance of the <code class="literal">Encoding</code> class.</p><p>The bit set, <code class="literal">bitset</code>, of the gene (encoding) is implemented by using the <code class="literal">apply</code> method:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>(<span class="strong"><strong>value</strong></span>: Double, <span class="strong"><strong>op</strong></span>: Operator): BitSet = {
  val bitset = new <span class="strong"><strong>BitSet</strong></span>(encoding.length)  
  encoding.rOp foreach(i =&gt;  //<span class="strong"><strong>10</strong></span>
    if(((op.<span class="strong"><strong>id</strong></span>&gt;&gt;i) &amp; 0x01)==0x01) bitset.set(i))
  encoding.rValue foreach(i =&gt; //<span class="strong"><strong>11</strong></span>
    if( ((quant.<span class="strong"><strong>toInt</strong></span>(<span class="strong"><strong>value</strong></span>)&gt;&gt;i) &amp; 0x01)==0x01) bitset.set(i))
  bitset
}</pre></div><p>The bits layout of the gene is created using <code class="literal">java.util.BitSet</code>. The <code class="literal">op</code> operator is encoded first through its identifier, <code class="literal">id</code> (line <code class="literal">10</code>). The <code class="literal">value</code> is quantized by invoking the <code class="literal">toInt</code> method and then encoded (line <code class="literal">11</code>).</p><p>The <code class="literal">unapply</code> method decodes the gene from a bit set or bit string to a pair of values and operators. The method uses the quantization instance to cover bits into values and a <code class="literal">convert</code> auxiliary function that is described along with its implementation in the source code, accompanying the book (line <code class="literal">12</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>unapply</strong></span>(<span class="strong"><strong>bits</strong></span>: BitSet): (Double, Operator) = 
  (quant.toDouble(convert(encoding.rValue, bits)), 
   op(convert(encoding.rOp, bits))) //<span class="strong"><strong>12</strong></span>
</pre></div><p>The <code class="literal">Operator</code> trait defines the signature of any operator. Each domain-specific problem requires a unique set of operations: Boolean, numeric, or string manipulation:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Operator</strong></span> {
   def id: Int
   def apply(id: Int): Operator
}</pre></div><p>The preceding operator has two methods: an identifier <code class="literal">id</code> and an <code class="literal">apply</code> method that converts an index to an operator.</p></div></div><div class="section" title="Selection"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13800"/>Selection</h2></div></div></div><p>The first <a id="id11140000" class="indexterm"/>genetic operator of the reproduction cycle is the selection process. The <code class="literal">select</code> method of the <code class="literal">Population</code> class implements the steps of the selection phase to the population of chromosomes in the most efficient manner, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>select</strong></span>(score: Chromosome[T]=&gt; Unit, cutOff: Double): Unit = {
  val cumul = chromosomes.map( _.<span class="strong"><strong>cost</strong></span>).sum/SCALING_FACTOR //<span class="strong"><strong>13</strong></span>
  chromosomes foreach( _ /= cumul) //<span class="strong"><strong>14</strong></span>

  val _chromosomes = chromosomes.sortWith(_.cost &lt; _.cost)//<span class="strong"><strong>15</strong></span>
  val <span class="strong"><strong>cutOffSize</strong></span> = (<span class="strong"><strong>cutOff</strong></span>*_chromosomes.size).floor.toInt //<span class="strong"><strong>16</strong></span>
  val popSize = if(<span class="strong"><strong>limit</strong></span> &lt; cutOffSize) limit else cutOffSize

  chromosomes.clear //<span class="strong"><strong>17</strong></span>
  chromosomes ++= _chromosomes.take(popSize) //<span class="strong"><strong>18</strong></span>
}</pre></div><p>The <code class="literal">select</code> method computes the <code class="literal">cumul</code> cumulative sum of the <code class="literal">cost</code> (line <code class="literal">13</code>) for the entire population. It normalizes the cost of each chromosome (line <code class="literal">14</code>), orders the population by decreasing the value (line <code class="literal">15</code>), and applies a <code class="literal">cutOff</code> soft limit function on the population growth (line <code class="literal">16</code>). The next step reduces the size of the population to the lowest of the two limits: the hard limit, <code class="literal">limit</code>, or the soft limit, <code class="literal">cutOffSize</code>. Finally, the existing chromosomes are cleared (line <code class="literal">17</code>) and updated with the next generation (line <code class="literal">18</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note31400"/>Note</h3><p>
<span class="strong"><strong>Even population size</strong></span>
</p><p>The next phase in the reproduction cycle is the crossover, which requires the pairing of parent chromosomes. It makes sense to pad the population so that its size is an even integer.</p></div><p>The <code class="literal">score</code> scoring function takes a chromosome as a parameter and returns the <code class="literal">cost</code> value for this chromosome.</p></div><div class="section" title="Controlling the population growth"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec13900"/>Controlling the population growth</h2></div></div></div><p>The natural <a id="id11150000" class="indexterm"/>selection process controls or manages the growth of the population of species. The genetic algorithm uses the following two mechanisms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The absolute maximum size of the population (the hard limit).</li><li class="listitem">The incentive to reduce the population as the optimization progresses (the soft limit). This incentive (or penalty) on the population growth is defined by the <code class="literal">cutOff</code> value used during selection (the <code class="literal">select</code> method).</li></ul></div><p>The <code class="literal">cutoff</code> value is computed using a <code class="literal">softLimit</code> user-defined function of the <code class="literal">Int =&gt; Double</code> type, which is provided as a configuration parameter (<code class="literal">softLimit(cycle: Int) =&gt; a.cycle +b</code>).</p></div><div class="section" title="The GA configuration"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14000"/>The GA configuration</h2></div></div></div><p>The four <a id="id11160000" class="indexterm"/>configurations and tuning parameters required by the genetic algorithm are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">xOver</code>: This is the crossover ratio (or probability) and has a value in the interval [0, 1]</li><li class="listitem"><code class="literal">mu</code>: This is the mutation ratio</li><li class="listitem"><code class="literal">maxCycles</code>: This is the maximum number of reproduction cycles</li><li class="listitem"><code class="literal">softLimit</code>: This is the soft constraint on the population growth</li></ul></div><p>Consider the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>GAConfig</strong></span>(val <span class="strong"><strong>xover</strong></span>: Double, 
     val <span class="strong"><strong>mu</strong></span>: Double, 
     val <span class="strong"><strong>maxCycles</strong></span>: Int, 
     val <span class="strong"><strong>softLimit</strong></span>: Int =&gt; Double) extends Config {
   val mutation = (cycle : Int) =&gt; softLimit(cycle)
}</pre></div></div><div class="section" title="Crossover"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14100"/>Crossover</h2></div></div></div><p>As mentioned <a id="id11170000" class="indexterm"/>earlier, the <a id="id11180000" class="indexterm"/>genetic crossover operator couples two chromosomes to generate two offspring chromosomes that compete with all the other chromosomes in the population, including their own parents, in the selection phase of the next reproduction cycle.</p><div class="section" title="Population"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14800"/>Population</h3></div></div></div><p>We use the <code class="literal">+-</code> notation <a id="id11190000" class="indexterm"/>as the implementation of the crossover operator in Scala. There are several options to select pairs of chromosomes for crossover. This implementation ranks the chromosomes by their <span class="emphasis"><em>fitness</em></span> (or inverse <code class="literal">cost</code>) value and then divides the population into two halves. Finally, it pairs the chromosomes of identical rank from each half, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01557.jpeg" alt="Population"/><div class="caption"><p>Pairing of chromosomes within a population prior to crossover</p></div></div><p style="clear:both; height: 1em;"> </p><p>The crossover implementation, <code class="literal">+-</code>, selects the parent chromosome candidates for crossover using the pairing scheme described earlier. Consider the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>+-</strong></span> (<span class="strong"><strong>xOver</strong></span>: Double): Unit = 
  if( size &gt; 1) {
    val mid = size&gt;&gt;1
    val bottom = chromosomes.slice(mid, size) //<span class="strong"><strong>19</strong></span>
    val gIdx = geneticIndices(xOver)  //<span class="strong"><strong>20</strong></span>

    val <span class="strong"><strong>offSprings</strong></span> = chromosomes.take(mid).zip(bottom)
          .map{ case (t, b) =&gt; t +- (b, gIdx) }.<span class="strong"><strong>unzip</strong></span> //<span class="strong"><strong>21</strong></span>
    chromosomes ++= offSprings._1 ++ offSprings._2 //<span class="strong"><strong>22</strong></span>
  }</pre></div><p>This method splits the population into two subpopulations of equal size (line <code class="literal">19</code>) and applies the Scala <code class="literal">zip</code> and <code class="literal">unzip</code> methods to generate the set of pairs of offspring chromosomes (line <code class="literal">20</code>). The  <code class="literal">+-</code> crossover operator is applied to each chromosome pair to produce an array of pairs of <code class="literal">offSprings</code> (line <code class="literal">21</code>). Finally, the <code class="literal">crossover</code> method adds offspring chromosomes to the existing population (line <code class="literal">22</code>). The <code class="literal">xOver</code> crossover value is a probability randomly generated over the interval [<code class="literal">config.xOver</code>, 1].</p><p>The <code class="literal">GeneticIndices</code> case class defines two indices of the bit whenever a crossover or a mutation occurs. The first <code class="literal">chOpIdx</code> index is the absolute index of the bit affected by the genetic operation in the chromosome (line <code class="literal">23</code>). The second <code class="literal">geneOpIdx</code> index is the index of the bit within the gene subjected to crossover or mutation (line <code class="literal">24</code>):</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>GeneticIndices</strong></span>(val chOpIdx: Int, //<span class="strong"><strong>23</strong></span>
     val geneOpIdx: Int)  //<span class="strong"><strong>24</strong></span>
</pre></div><p>The <code class="literal">geneticIndices</code> method computes the relative indices of the crossover bit in the chromosomes and genes:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>geneticIndices</strong></span>(prob: Double): GeneticIndices = {
  var idx = (prob*chromosomeSize).floor.toInt //<span class="strong"><strong>25</strong></span>
  val <span class="strong"><strong>chIdx</strong></span> = if(idx == chromosomeSize) chromosomeSize-1 
       else idx //25

  <span class="strong"><strong>idx</strong></span> = (prob*geneSize).floor.toInt  
  val <span class="strong"><strong>gIdx</strong></span> = if(idx == geneSize) geneSize-1 else idx //<span class="strong"><strong>26</strong></span>
  GeneticIndices(chIdx, gIdx)
}</pre></div><p>The <a id="id11200000" class="indexterm"/>first <code class="literal">chIdx</code> indexer is the index or rank of the gene within the chromosome to be affected by the genetic operator (line <code class="literal">25</code>). The second <code class="literal">gIdx</code> indexer is the relative index of the bit within the gene (line <code class="literal">26</code>).</p><p>Let's consider a chromosome composed of 2 genes with 63 bits/elements each, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01558.jpeg" alt="Population"/></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">geneticIndices</code> method computes the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">chIdx</code> index of the gene within the chromosome and the <code class="literal">gIdx</code> index of the bit within the gene</li><li class="listitem">The genetic operator selects the gene of the <code class="literal">chIdx</code> index (that is the second gene) to be altered</li><li class="listitem">The genetic operator alters the chromosome at the bit of the <code class="literal">gIdx</code> index (that is <span class="emphasis"><em>chIdx*64 + gIdx</em></span>)</li></ul></div></div><div class="section" title="Chromosomes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec14900"/>Chromosomes</h3></div></div></div><p>First, we need to <a id="id11210000" class="indexterm"/>define the <code class="literal">Chromosome</code> class, which takes a list of genes, <code class="literal">code</code>, (for genetic code) as the parameter:</p><div class="informalexample"><pre class="programlisting">val QUANT = 500
class <span class="strong"><strong>Chromosome</strong></span>[T &lt;: Gene](val <span class="strong"><strong>code</strong></span>: List[T]) {  
  var <span class="strong"><strong>cost</strong></span>: Double = QUANT*(1.0 + Random.nextDouble) //<span class="strong"><strong>27</strong></span>

  def <span class="strong"><strong>+-</strong></span> (that: Chromosome[T], indices: GeneticIndices): //<span class="strong"><strong>28</strong></span>
     (Chromosome[T], Chromosome[T]) 
  def <span class="strong"><strong>^</strong></span> (indices: GeneticIndices): Chromosome[T] //<span class="strong"><strong>29</strong></span>
  def <span class="strong"><strong>/</strong></span>= (normalizeFactor: Double): Unit =   //<span class="strong"><strong>30</strong></span>
      cost /= normalizeFactor
  def <span class="strong"><strong>decode</strong></span>(implicit d: Gene=&gt;T): List[T] =  //<span class="strong"><strong>31</strong></span>
      code.map( d(_)) 
  …
}</pre></div><p>The cost (or unfitness) of a chromosome is initialized as a random value between <code class="literal">QUANT</code> and <code class="literal">2*QUANT</code> (line <code class="literal">27</code>). The genetic <code class="literal">+-</code> crossover operator generates a pair of two offspring chromosomes (line <code class="literal">28</code>). The genetic <code class="literal">^ </code>mutation operator creates a slightly modified (1 or 2 bits) clone of this chromosome (line <code class="literal">29</code>). The <code class="literal">/=</code> method normalizes the cost of the chromosome (line <code class="literal">30</code>). The <code class="literal">decode</code> method converts the gene to a logic predicate or rule using an implicit conversion, <code class="literal">d</code>, between a gene and its subclass (line <code class="literal">31</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note31500"/>Note</h3><p>
<span class="strong"><strong>Cost initialization</strong></span>
</p><p>There is no absolute rule to initialize the cost of the chromosomes from an initial population. However, it is recommended that you differentiate a chromosome using nonzero random values with a large range as their cost.</p></div><p>The implementation of the crossover for a pair of chromosomes using hierarchical encoding follows two steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Find the gene on each chromosome that corresponds to the <code class="literal">indices.chOpIdx</code> crossover index and then swap the remaining genes.</li><li class="listitem">Split and splice the gene crossover at <code class="literal">xoverIdx</code>.</li></ol><div style="height:10px; width: 1px"/></div><p>Consider the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>+-</strong></span> (that: Chromosome[T], indices: GeneticIndices): 
    (Chromosome[T], Chromosome[T]) = {
  val <span class="strong"><strong>xoverIdx</strong></span> = indices.chOpIdx //<span class="strong"><strong>32</strong></span>
  val xGenes =  <span class="strong"><strong>spliceGene</strong></span>(indices, that.code(xoverIdx)) //<span class="strong"><strong>33</strong></span>

  val offSprng1 = code.slice(0, xoverIdx) ::: 
       xGenes._1 :: that.code.drop(xoverIdx+1) //<span class="strong"><strong>34</strong></span>
  val offSprng2 = that.code.slice(0, xoverIdx) ::: 
      xGenes._2 :: code.drop(xoverIdx+1)
  (Chromosome[T](offSprng1), Chromosome[T](offSprng2)) //<span class="strong"><strong>35</strong></span>
}</pre></div><p>The <a id="id11220000" class="indexterm"/>crossover method computes the index <code class="literal">xoverIdx</code> of the bit that defines the crossover in each parent chromosome (line <code class="literal">32</code>). The <code class="literal">this.code(xoverIdx)</code> and <code class="literal">that.code(xoverIdx)</code> genes are swapped and spliced by the <code class="literal">spliceGene</code> method to generate a spliced gene (line <code class="literal">33</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>spliceGene</strong></span>(indices: GeneticIndices, thatCode: T): (T,T) ={
  ((this.code(indices.chOpIdx) +- (thatCode,indices)), 
   (thatCode +- (code(indices.chOpIdx),indices)) )
}</pre></div><p>The offspring chromosomes are gathered by collating the first <code class="literal">xOverIdx</code> genes of the parent chromosome, the crossover gene, and the remaining genes of the other parent (line <code class="literal">34</code>). The method returns the pair of offspring chromosomes (line <code class="literal">35</code>).</p></div><div class="section" title="Genes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15000"/>Genes</h3></div></div></div><p>The <a id="id11230000" class="indexterm"/>crossover is applied to a gene using the <code class="literal">+-</code> method of the <code class="literal">Gene</code> class. The exchange of bits between the <code class="literal">this</code> and <code class="literal">that</code> genes uses the <code class="literal">BitSet</code> Java class to rearrange the bits after the permutation:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>+-</strong></span> (that: Gene, <span class="strong"><strong>indices</strong></span>: GeneticIndices): Gene = {
  val clonedBits = cloneBits(bits) //<span class="strong"><strong>36</strong></span>

  Range(<span class="strong"><strong>indices.geneOpIdx</strong></span>, bits.size).foreach(n =&gt; 
    if( that.bits.get(n) ) clonedBits.set(n) 
    else clonedBits.clear(n) //<span class="strong"><strong>37</strong></span>
   )
   val valOp = decode(clonedBits) //<span class="strong"><strong>38</strong></span>
   new Gene(id, valOp._1, valOp._2)
}</pre></div><p>The bits of the gene are cloned (line <code class="literal">36</code>) and then spliced by exchanging their bits along with the <code class="literal">indices.geneOpIdx</code> crossover point (line <code class="literal">37</code>). The <code class="literal">cloneBits</code> function duplicates <a id="id11240000" class="indexterm"/>a bit string, which is then converted into a (target value, operator) tuple using the <code class="literal">decode</code> method (line <code class="literal">38</code>). We omit these two methods because they are not critical to the understanding of the algorithm.</p></div></div><div class="section" title="Mutation"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14200"/>Mutation</h2></div></div></div><p>The mutation<a id="id11250000" class="indexterm"/> of the <a id="id11260000" class="indexterm"/>population uses the same algorithmic approach as the crossover operation.</p><div class="section" title="Population"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15100"/>Population</h3></div></div></div><p>The <code class="literal">^ </code>mutation <a id="id11270000" class="indexterm"/>operator invokes the same operator for all the chromosomes in the population and then adds the mutated chromosomes to the existing population, so that they can compete with the original chromosomes. We use the <code class="literal">^</code> notation to define the mutation operator to remind you that the mutation is implemented by flipping one bit:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>^</strong></span> (prob: Double): Unit = 
  chromosomes ++= chromosomes.map(_ ^ geneticIndices(prob))</pre></div><p>The <code class="literal">prob</code> mutation parameter is used to compute the absolute index of the mutating gene, <code class="literal">geneticIndices(prob)</code>.</p></div><div class="section" title="Chromosomes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15200"/>Chromosomes</h3></div></div></div><p>The <a id="id11280000" class="indexterm"/>implementation of the <code class="literal">^</code> mutation operator on a chromosome consists of mutating the gene of the <code class="literal">indices.chOpIdx</code> index (line <code class="literal">39</code>) and then updating the list of genes in the chromosome (line <code class="literal">40</code>). The method returns a new chromosome (line <code class="literal">41</code>) that will compete with the original chromosome:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>^</strong></span> (indices: GeneticIndices): Chromosome[T] = { //<span class="strong"><strong>39</strong></span> 
  val mutated = code(<span class="strong"><strong>indices.chOpIdx</strong></span>) ^ indices 
  val xs = Range(0, code.size).map(i =&gt;
    if(i== indices.chOpIdx) mutated 
    else code(i)).toList //<span class="strong"><strong>40</strong></span>
  Chromosome[T](xs) //<span class="strong"><strong>41</strong></span>
}</pre></div></div><div class="section" title="Genes"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15300"/>Genes</h3></div></div></div><p>Finally, the mutation <a id="id11290000" class="indexterm"/>operator flips (XOR) the bit at the <code class="literal">indices.geneOpIdx</code> index:</p><div class="informalexample"><pre class="programlisting">def ^ (indices: GeneticIndices): Gene = { 
  val idx = <span class="strong"><strong>indices.geneOpIdx</strong></span>
  val clonedBits = cloneBits(bits) //<span class="strong"><strong>42</strong></span>
  
  clonedBits.flip(idx)  //43
  val valOp = decode(clonedBits)  //<span class="strong"><strong>44</strong></span>
  new Gene(id, valOp._1, valOp._2) //<span class="strong"><strong>45</strong></span>
}</pre></div><p>The <code class="literal">^</code> method mutates the cloned bit string, <code class="literal">clonedBits</code>, (line <code class="literal">42</code>) by flipping the bit at the <code class="literal">indices.geneOpIdx</code> index (line <code class="literal">43</code>). It decodes and converts the mutated bit string by converting it into a (target value, operator) tuple (line <code class="literal">44</code>). The last step creates a new gene from the target-operator tuple (line <code class="literal">45</code>).</p></div></div><div class="section" title="Reproduction"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14300"/>Reproduction</h2></div></div></div><p>Let's wrap <a id="id11300000" class="indexterm"/>the reproduction cycle into a <code class="literal">Reproduction</code> class that uses the scoring function, <code class="literal">score</code>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Reproduction</strong></span>[T &lt;: Gene](score: Chromosome[T] =&gt; Unit)</pre></div><p>The <code class="literal">mate</code> reproduction function implements the sequence or workflow of the three genetic operators: <code class="literal">select</code> for the selection, <code class="literal">+-</code> (xover) for the crossover, and <code class="literal">^</code> (mu) for the mutation:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>mate</strong></span>(population: Population[T], config: GAConfig, 
    cycle: Int): Boolean = (population.size: @switch) match {
  case 0 | 1 | 2 =&gt; false   //<span class="strong"><strong>46</strong></span>
  case _ =&gt; {
    rand.setSeed(rand.nextInt + System.currentTimeMillis)
    population.<span class="strong"><strong>select</strong></span>(score, config.<span class="strong"><strong>softLimit</strong></span>(cycle)) //<span class="strong"><strong>47</strong></span>
    population +- rand.nextDouble*config.<span class="strong"><strong>xover</strong></span> //<span class="strong"><strong>48</strong></span>
    population ^ rand.nextDouble*config.<span class="strong"><strong>mu</strong></span>  //<span class="strong"><strong>49</strong></span>
    true
  }
}</pre></div><p>The <code class="literal">mate</code> method returns false (that is, the reproduction cycle aborts) if the population size is less than 3 (line <code class="literal">46</code>). The chromosomes in the current population are ranked by the increasing cost. The chromosomes with the high cost or low fitness are discarded to comply with the soft limit, <code class="literal">softLimit</code>, on the population growth (line <code class="literal">47</code>). The <a id="id11310000" class="indexterm"/>randomly generated probability is used as an input to the crossover operation on the entire remaining population (line <code class="literal">48</code>) and as an input to the mutation of the remaining population (line <code class="literal">49</code>):</p><div class="mediaobject"><img src="../Images/image01559.jpeg" alt="Reproduction"/><div class="caption"><p>An illustration of the linear and quadratic soft limit for the population growth</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Solver"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14400"/>Solver</h2></div></div></div><p>The <code class="literal">GASolver</code> class <a id="id11320000" class="indexterm"/>manages the reproduction cycles and the population of chromosomes. The solver is defined as a data transformation of the <code class="literal">ETransform</code> type using an explicit configuration of the <code class="literal">GAConfig</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> (line <code class="literal">50</code>).</p><p>The <code class="literal">GASolver</code> class implements the <code class="literal">GAMonitor</code> trait to monitor the population diversity, manage the reproduction cycle, and control the convergence of the optimizer (line <code class="literal">51</code>).</p><p>The genetic algorithm-based solver has the following three arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This is the configuration of the execution of the genetic algorithm</li><li class="listitem"><code class="literal">score</code>: This is the scoring function of a chromosome</li><li class="listitem"><code class="literal">tracker</code>: This is the optional tracking function to initialize the monitoring function of <code class="literal">GAMonitor</code></li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>GASolver</strong></span>[T &lt;: Gene](<span class="strong"><strong>config</strong></span>: GAConfig, 
    <span class="strong"><strong>score</strong></span>: Chromosome[T] =&gt; Unit,
    <span class="strong"><strong>tracker</strong></span>: Option[Population[T] =&gt; Unit] = None) 
     extends <span class="strong"><strong>ETransform</strong></span>[GAConfig](config) //<span class="strong"><strong>50</strong></span>
        with <span class="strong"><strong>GAMonitor</strong></span>[T] { //<span class="strong"><strong>51</strong></span>

  type <span class="strong"><strong>U</strong></span> = Population[T]  //<span class="strong"><strong>52</strong></span>
  type <span class="strong"><strong>V</strong></span> = Population[T]  //<span class="strong"><strong>53</strong></span>

  val <span class="strong"><strong>monitor</strong></span>: Option[Population[T] =&gt; Unit] = tracker
  def <span class="strong"><strong>|&gt;</strong></span>(initialize: =&gt; Population[T]): Try[Population[T]] = 
      this.|&gt; (initialize()) //<span class="strong"><strong>54</strong></span>
  override def |&gt; : PartialFunction[U, Try[V]] //<span class="strong"><strong>55</strong></span>
}</pre></div><p>This explicit data <a id="id11330000" class="indexterm"/>transformation has to initialize the <code class="literal">U</code> type of an input element (line <code class="literal">52</code>) and the <code class="literal">V</code> type of an output element (line <code class="literal">53</code>) for the prediction or optimization method, <code class="literal">|&gt;</code>. The optimizer takes an initial population as the input and generates a very small population of the fittest chromosomes from which the best solution is extracted (line <code class="literal">55</code>).</p><p>The population is generated by the <code class="literal">|&gt; </code>method <code class="literal">( =&gt; Population[T])</code> that takes the constructor of the <code class="literal">Population</code> class as an argument (line <code class="literal">54</code>).</p><p>Let's briefly take a look at the <code class="literal">GAMonitor</code> monitoring trait assigned to the genetic algorithm. The trait has the following two attributes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">monitor</code>: This is an abstract value to be initialized by classes that implement this trait (line <code class="literal">55</code>).</li><li class="listitem"><code class="literal">state</code>: This is the current state of the execution of the genetic algorithm. The initial state of the genetic algorithm is <code class="literal">GA_NOT_RUNNING</code> (line <code class="literal">56</code>).</li></ul></div><p>The code will be as follows:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>GAMonitor</strong></span>[T &lt;: Gene] extends Monitor {
  <span class="strong"><strong>self</strong></span>: { 
    def |&gt; :PartialFunction[Population[T],Try[Population[T]]] 
  } =&gt; //<span class="strong"><strong>55</strong></span>
    val <span class="strong"><strong>monitor</strong></span>: Option[Population[T] =&gt; Unit] //<span class="strong"><strong>56</strong></span>
    var <span class="strong"><strong>state</strong></span>: GAState = GA_NOT_RUNNING //<span class="strong"><strong>57</strong></span>

    def isReady: Boolean = state == GA_NOT_RUNNING
    def start: Unit = state = GA_RUNNING
    def <span class="strong"><strong>isComplete</strong></span>(population: Population[T], 
        remainingCycles: Int): Boolean  = { … } //<span class="strong"><strong>58</strong></span>
}</pre></div><p>The <code class="literal">state</code> of <a id="id11340000" class="indexterm"/>the genetic algorithm can only be updated in the <code class="literal">|&gt;</code> method through an instance of the <code class="literal">GAMonitor</code> class. (line <code class="literal">55</code>).</p><p>Here is a subset of the possible state of the execution of the genetic algorithm:</p><div class="informalexample"><pre class="programlisting">sealed abstract class <span class="strong"><strong>GAState</strong></span>(description: String)
case class <span class="strong"><strong>GA_FAILED</strong></span>(description: String) 
   extends GAState(description)
object <span class="strong"><strong>GA_RUNNING</strong></span> extends GAState("Running")</pre></div><p>The solver invokes the <code class="literal">isComplete</code> method to test the convergence of the optimizer at each reproduction cycle (line <code class="literal">58</code>).</p><p>There are two options for estimating that the reproducing cycle is converging:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Greedy</strong></span>: In this approach, the objective is to check whether the <span class="emphasis"><em>n</em></span> fittest chromosomes have not changed in the last <span class="emphasis"><em>m</em></span> reproduction cycles</li><li class="listitem"><span class="strong"><strong>Loss function</strong></span>: This approach is similar to the convergence criteria for the training of supervised learning</li></ul></div><p>Let's consider the following implementation of the genetic algorithm solver:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
  case population: U if(population.size &gt; 1 &amp;&amp; isReady) =&gt; {
    start //<span class="strong"><strong>59</strong></span>
    val reproduction = Reproduction[T](score)  //<span class="strong"><strong>60</strong></span>

    @<span class="strong"><strong>tailrec</strong></span>
    def <span class="strong"><strong>reproduce</strong></span>(population: Population[T], 
          n:Int): Population[T] = { //<span class="strong"><strong>61</strong></span>
      if( !reproduction.mate(population, config, n) || 
         isComplete(population, config.maxCycles -n) )
       population
      else
       <span class="strong"><strong>reproduce</strong></span>(population, n+1)
    }
    <span class="strong"><strong>reproduce</strong></span>(population, 0)
    population.<span class="strong"><strong>select</strong></span>(score, 1.0) //<span class="strong"><strong>62</strong></span>
    Try(population)
  }
}</pre></div><p>The optimizing method initializes the state of execution (line <code class="literal">59</code>) and the components of the <code class="literal">reproduction</code> cycle (line <code class="literal">60</code>). The reproduction cycle (or an epoch) is implemented as a tail recursion that tests whether the last reproduction cycle has failed or whether the <a id="id11350000" class="indexterm"/>optimization has converged toward a solution (line <code class="literal">61</code>). Finally, the remaining fittest chromosomes are reordered by invoking the <code class="literal">select</code> method of the <code class="literal">Population</code> class (line <code class="literal">62</code>).</p></div></div>
<div class="section" title="GA for trading strategies"><div class="titlepage" id="aid-6EUA22"><div><div><h1 class="title"><a id="ch10lvl1sec7100"/>GA for trading strategies</h1></div></div></div><p>Let's apply <a id="id11360000" class="indexterm"/>our expertise in genetic algorithms to evaluate different strategies to trade securities using trading signals. Knowledge in trading strategies is not required to understand the implementation of a GA. However, you may want to get familiar with the foundation and terminology of technical analysis of securities and financial markets, as described briefly in the <span class="emphasis"><em>Technical analysis</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The problem is to find the best trading strategy to predict the increase or decrease of the price of a security given a set of trading signals. A trading strategy is defined as a set of trading signals <span class="emphasis"><em>ts<sub>j</sub></em></span> that are triggered or fired when a variable <span class="emphasis"><em>x = {x<sub>j</sub>}</em></span>, derived from financial metrics such as the price of the security or the daily or weekly trading volume, either exceeds or equals or is below a predefined target value <span class="emphasis"><em>α<sub>j</sub></em></span> (refer to the <span class="emphasis"><em>Trading signals and strategy</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>).</p><p>The number of variables that can be derived from price and volume can be very large. Even the most seasoned financial professionals face two challenges, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Selecting a minimal set of trading signals that are relevant to a given dataset (minimize a cost or unfitness function)</li><li class="listitem">Turning those trading signals with heuristics derived from personal experience and expertise</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note31600"/>Note</h3><p>
<span class="strong"><strong>Alternative to GA</strong></span>
</p><p>The problem described earlier can certainly be solved using one of the machine learning algorithms introduced in the previous chapters. It is just a matter of defining a training set and formulating the problem as minimizing the loss function between the predictor and the training score.</p></div><p>The following table lists the <a id="id11370000" class="indexterm"/>trading classes with their counterpart in the genetic world:</p><div class="informaltable"><table border="1"><colgroup><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Generic classes</p>
</th><th valign="bottom">
<p>Corresponding securities trading classes</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>Operator</p>
</td><td valign="top">
<p>
<code class="literal">SOperator</code>
</p>
</td></tr><tr><td valign="top">
<p>Gene</p>
</td><td valign="top">
<p>
<code class="literal">Signal</code>
</p>
</td></tr><tr><td valign="top">
<p>Chromosome</p>
</td><td valign="top">
<p>
<code class="literal">Strategy</code>
</p>
</td></tr><tr><td valign="top">
<p>Population</p>
</td><td valign="top">
<p>
<code class="literal">StrategiesFactory</code>
</p>
</td></tr></tbody></table></div><div class="section" title="Definition of trading strategies"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14500"/>Definition of trading strategies</h2></div></div></div><p>A chromosome is <a id="id11380000" class="indexterm"/>the genetic <a id="id11390000" class="indexterm"/>encoding of a trading strategy. A factory class, <code class="literal">StrategyFactory</code>, assembles the components of a trading strategy: operators, unfitness function, and signals</p><div class="section" title="Trading operators"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15400"/>Trading operators</h3></div></div></div><p>Let's extend the <code class="literal">Operator</code> trait <a id="id11400000" class="indexterm"/>with the <code class="literal">SOperator</code> class to define the operations that we need to trigger the signals. The <code class="literal">SOperator</code> instance has a single parameter: its identifier, <code class="literal">_id</code>. The class overrides the <code class="literal">id()</code> method to retrieve the ID (similarly, the class overrides the <code class="literal">apply</code> method to convert an ID into an <code class="literal">SOperator</code> instance):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SOperator</strong></span>(_id: Int) extends Operator {
  override def <span class="strong"><strong>id</strong></span>: Int = _id
  override def <span class="strong"><strong>apply</strong></span>(idx: Int): SOperator = new SOperator(idx) 
}</pre></div><p>The operators used by trading signals are the logical operators: &lt; (<code class="literal">LESS_THAN</code>), &gt; (<code class="literal">GREATER_THAN</code>), and = (<code class="literal">EQUAL</code>), as follows:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>LESS_THAN</strong></span> extends SOperator(1) 
object <span class="strong"><strong>GREATER_THAN</strong></span> extends SOperator(2)
object <span class="strong"><strong>EQUAL</strong></span> extends SOperator(3)</pre></div><p>Each operator of the <code class="literal">SOperator</code> type is associated with a scoring function by the <code class="literal">operatorFuncMap</code> map. The scoring function computes the cost (or unfitness) of the signal against a real value or a time series:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>operatorFuncMap</strong></span> = Map[Operator, (Double,Double) =&gt;Double](
  LESS_THAN -&gt; ((x: Double, target: Double) =&gt; target - x),
  … )</pre></div><p>The <code class="literal">select</code> method of <code class="literal">Population</code> computes the <code class="literal">cost</code> value of a signal by quantifying the truthfulness of the predicate. For instance, the unfitness value for a trading signal, <span class="emphasis"><em>x &gt; 10</em></span>, is penalized as <span class="emphasis"><em>5 – 10 = -5</em></span> for <span class="emphasis"><em>x = 5</em></span> and credited as <span class="emphasis"><em>14 – 10 = 4</em></span> if <span class="emphasis"><em>x = 14</em></span>. In this case, the unfitness <a id="id11410000" class="indexterm"/>value is similar to the cost or loss in a discriminative machine learning algorithm.</p></div><div class="section" title="The cost function"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15500"/>The cost function</h3></div></div></div><p>Let's consider the <a id="id11420000" class="indexterm"/>following trading strategy defined as a set of two signals to predict the sudden relative decrease <span class="emphasis"><em>Δp</em></span> of the price of a security:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Relative volume <span class="emphasis"><em>v<sub>m</sub></em></span> with a condition <span class="emphasis"><em>v<sub>m</sub> &lt; α</em></span></li><li class="listitem">Relative volatility <span class="emphasis"><em>v<sub>l</sub></em></span> with the condition <span class="emphasis"><em>v<sub>l</sub> &gt; β</em></span></li></ul></div><p>Let's take a look at the following graphs:</p><div class="mediaobject"><img src="../Images/image01560.jpeg" alt="The cost function"/><div class="caption"><p>A chart of the price, relative volume, and relative volatility of a security</p></div></div><p style="clear:both; height: 1em;"> </p><p>As the goal is to model a sudden crash in the stock price, we should reward the trading strategies that predict the steep decrease in the stock price and penalize the strategies that work well only with a small decrease or increase in the stock price. In the case of the trading strategy with two signals, relative volume <span class="emphasis"><em>v<sub>m</sub></em></span> and relative volatility <span class="emphasis"><em>v<sub>l</sub></em></span>, <span class="emphasis"><em>n</em></span> trading sessions, the cost or unfitness function <span class="emphasis"><em>C</em></span>, and given a relative variation of the stock price and a penalization <span class="emphasis"><em>w = -Δp (M2)</em></span>:</p><div class="mediaobject"><img src="../Images/image01561.jpeg" alt="The cost function"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Trading signals"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15600"/>Trading signals</h3></div></div></div><p>Let's subclass the <a id="id11430000" class="indexterm"/><code class="literal">Gene</code> class to define the trading signal of the <code class="literal">Signal</code> type as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Signal</strong></span>(<span class="strong"><strong>id</strong></span>: String, <span class="strong"><strong>target</strong></span>: Double, <span class="strong"><strong>op</strong></span>: Operator,
   <span class="strong"><strong>xt</strong></span>: DblVector, <span class="strong"><strong>weights</strong></span>: Option[DblVector] = None)
   (implicit <span class="strong"><strong>quantize</strong></span>: Quantization, <span class="strong"><strong>encoding</strong></span>: Encoding) 
  extends Gene(id, target, op) </pre></div><p>The <code class="literal">Signal</code> class requires the following arguments:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An identifier <code class="literal">id</code> for the feature</li><li class="listitem">A <code class="literal">target</code> value</li><li class="listitem">An <code class="literal">op</code> operator</li><li class="listitem">An <code class="literal">xt</code> time series of the <code class="literal">DblVector</code> type</li><li class="listitem">The optional <code class="literal">weights</code> associated with each data point of the time series, <code class="literal">xt</code></li><li class="listitem">An implicit quantization instance, <code class="literal">quantize</code></li><li class="listitem">An implicit <code class="literal">encoding</code> scheme</li></ul></div><p>The main purpose of the <code class="literal">Signal</code> class is to compute its <code class="literal">score</code> as a chromosome. The chromosome updates its <code class="literal">cost</code> by summing the score or weighted score of the signals it contains. The score of the trading signal is simply the summation of the penalty or truthfulness of the signal for each entry of the time series, <code class="literal">ts</code>:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>score</strong></span>: Double = 
  if(!operatorFuncMap.contains(op)) Double.MaxValue
  else {
    val f = operatorFuncMap.get(op).get
    if( weights != None ) xt.zip(weights.get)
        .map{case(x, w) =&gt; w*f(x,target)}.sum
    else xt.map( f(_, target)).sum   
  }</pre></div></div><div class="section" title="Trading strategies"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15700"/>Trading strategies</h3></div></div></div><p>A trading strategy is <a id="id11440000" class="indexterm"/>an unordered list of trading signals. It makes sense to create a factory class to generate the trading strategies. The <code class="literal">StrategyFactory</code> class creates strategies of the <code class="literal">List[Signal]</code> type from an existing pool of signals of the subtype, <code class="literal">Gene</code>:</p><div class="mediaobject"><img src="../Images/image01562.jpeg" alt="Trading strategies"/><div class="caption"><p>A factory pattern for trading signals</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">StrategyFactory</code> class has two arguments: the number of signals, <code class="literal">nSignals</code>, in a trading strategy and the implicit <code class="literal">Quantization</code> and <code class="literal">Encoding</code> instances (line <code class="literal">63</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>StrategyFactory</strong></span>(<span class="strong"><strong>nSignals</strong></span>: Int)  //<span class="strong"><strong>63</strong></span>
    (implicit quantize: <span class="strong"><strong>Quantization</strong></span>, encoding: <span class="strong"><strong>Encoding</strong></span>){
  val signals = new ListBuffer[Signal]   
  <span class="strong"><strong>lazy</strong></span> val <span class="strong"><strong>strategies</strong></span>: Pool[Signal] //<span class="strong"><strong>64</strong></span>
  def <span class="strong"><strong>+=</strong></span> (id: String, target: Double, op: SOperator, 
       xt: DblVector, weights: DblVector)
  …
 }</pre></div><p>The <code class="literal">+=</code> method takes <a id="id11450000" class="indexterm"/>five arguments: the identifier <code class="literal">id</code>, the <code class="literal">target</code> value, the <code class="literal">op</code> operation to qualify the class as <code class="literal">Gene</code>, the <code class="literal">xt</code> times series for scoring the signals, and the <code class="literal">weights</code> associated with the overall cost function. The <code class="literal">StrategyFactory</code> class generates all possible sequences of signals as trading strategies as lazy values to avoid unnecessary regeneration of the pool on demand (line <code class="literal">64</code>), as follows:</p><div class="informalexample"><pre class="programlisting">lazy val <span class="strong"><strong>strategies</strong></span>: Pool[Signal] = {
  implicit val ordered = Signal.orderedSignals //<span class="strong"><strong>70</strong></span>
  
  val xss = new Pool[Signal] //65
  val <span class="strong"><strong>treeSet</strong></span> = new TreeSet[Signal] ++= signals.toList //<span class="strong"><strong>66</strong></span>
  val <span class="strong"><strong>subsetsIterator</strong></span> = treeSet.subsets(nSignals) //<span class="strong"><strong>67</strong></span>

  while( subsetsIterator.hasNext) {
    val signalList = subsetsIterator.next.toList  //<span class="strong"><strong>68</strong></span>
    xss.append(Chromosome[Signal](signalList)) //<span class="strong"><strong>69</strong></span>
  } 
  xss
}</pre></div><p>The implementation of the <code class="literal">strategies</code> value creates a pool of signals <code class="literal">Pool</code> (line <code class="literal">65</code>) by converting the list of signals to <code class="literal">treeset</code> (line <code class="literal">66</code>). It breaks down the tree set into unique subtrees of <code class="literal">nSignals</code> nodes each. It instantiates a <code class="literal">subsetsIterator</code> iterator to traverse the sequence of subtrees (line <code class="literal">67</code>) and converts them into a list (line <code class="literal">68</code>) as arguments of the new chromosome (trading strategy) (line <code class="literal">69</code>). The procedure to order the signals, <code class="literal">orderedSignals,</code> in the tree set has to be implicitly defined (line <code class="literal">70</code>) as <code class="literal">val orderedSignals = Ordering.by((signal: Signal) =&gt; signal.id)</code>.</p></div><div class="section" title="Trading signal encoding"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15800"/>Trading signal encoding</h3></div></div></div><p>The encoding <a id="id11460000" class="indexterm"/>of trading predicates is the most critical element of the genetic algorithm. In our example, we encode a predicate as a tuple (target value, operator). Let's consider the simple predicate <span class="emphasis"><em>volatility &gt; 0.62</em></span>. The discretization converts the value 0.62 into 32 bits for the instance and a 2-bit representation for the operator:</p><div class="mediaobject"><img src="../Images/image01563.jpeg" alt="Trading signal encoding"/><div class="caption"><p>Encoding of the trading signal:  volatility &gt; 0.62</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note31700"/>Note</h3><p>
<span class="strong"><strong>IEEE-732 encoding</strong></span>
</p><p>The threshold value for predicates is converted into an integer (the <code class="literal">Int</code> type or <code class="literal">Long</code>). The IEEE-732 binary representation of floating point values makes the bit addressing required to apply genetic operators quite challenging. A simple conversion consists of the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">encoding e: (x: Double) =&gt; (x*100000).toInt</code></li><li class="listitem"><code class="literal">decoding d: (x: Int) =&gt; x*1e-5</code></li></ul></div><p>All values are normalized, so there is no risk of overflowing the 32-bit representation.</p></div></div></div><div class="section" title="A test case"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec14600"/>A test case</h2></div></div></div><p>The goal is <a id="id11470000" class="indexterm"/>to evaluate <a id="id11480000" class="indexterm"/>which trading strategy was the most relevant (fittest) during the crash of the stock market in fall 2008. Let's consider the stock price of one of the financial institutions, Goldman Sachs, as a proxy of the sudden market decline:</p><div class="mediaobject"><img src="../Images/image01564.jpeg" alt="A test case"/><div class="caption"><p>A sudden decrease in Goldman-Sachs stock price in Sept – Nov 2008</p></div></div><p style="clear:both; height: 1em;"> </p><p>Besides the <a id="id11490000" class="indexterm"/>variation of the price of the stock between two consecutive trading sessions (<code class="literal">dPrice</code>), the model uses the following parameters (or trading signals):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">dVolume</code>: This is the relative variation of the volume between two consecutive trading sessions</li><li class="listitem"><code class="literal">dVolatility</code>: This is the relative variation of volatility between two consecutive trading sessions</li><li class="listitem"><code class="literal">volatility</code>: This is the relative volatility within a trading session</li><li class="listitem"><code class="literal">vPrice</code>: This is the relative difference of the stock opening and closing price</li></ul></div><p>The naming convention for the trading data and metrics is described in the <span class="emphasis"><em>Trading data</em></span> section under <span class="emphasis"><em>Technical analysis</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.</p><p>The execution of the <a id="id11500000" class="indexterm"/>genetic algorithm requires the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Extraction of model parameters or variables.</li><li class="listitem">Generation of the initial population of trading strategies.</li><li class="listitem">Setting up the GA configuration parameters with the maximum number of reproduction cycles allowed, the crossover and mutation ratio, and the soft limit function for the population growth.</li><li class="listitem">Instantiating the GA algorithm with the scoring/unfitness function.</li><li class="listitem">Extracting the fittest trading strategy that can best explain the sharp decline in the price of Goldman Sachs stocks.</li></ol><div style="height:10px; width: 1px"/></div><div class="section" title="Creating trading strategies"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec15900"/>Creating trading strategies</h3></div></div></div><p>The input to the <a id="id11510000" class="indexterm"/>genetic algorithm is the population of trading strategies. Each strategy consists of the combination of three trading signals and each trading signal is a tuple (signal ID, operator, and target value).</p><p>The first step is to extract the model parameters as illustrated for the variation of the stock price volume, volatility, and relative volatility between two consecutive trading sessions (line <code class="literal">71</code>):</p><div class="informalexample"><pre class="programlisting">Import YahooFinancials._
val NUM_SIGNALS = 3

def <span class="strong"><strong>createStrategies</strong></span>: Try[Pool[Signal]] = {
  val src = DataSource(path, false, true, 1) //<span class="strong"><strong>71</strong></span>
  for {  //<span class="strong"><strong>72</strong></span>
    <span class="strong"><strong>price</strong></span> &lt;- src.get(adjClose)
    <span class="strong"><strong>dPrice</strong></span> &lt;- delta(price, -1.0) 
    <span class="strong"><strong>volume</strong></span> &lt;- src.get(volume)
    <span class="strong"><strong>dVolume</strong></span> &lt;- delta(volume, 1.0)
    <span class="strong"><strong>volatility</strong></span> &lt;- src.get(volatility)
    <span class="strong"><strong>dVolatility</strong></span> &lt;- delta(volatility, 1.0)
    vPrice = src.get(vPrice)
  } yield { //<span class="strong"><strong>72</strong></span>
    val <span class="strong"><strong>factory</strong></span> = new StrategyFactory(NUM_SIGNALS) //<span class="strong"><strong>73</strong></span>

    val weights = dPrice  //<span class="strong"><strong>74</strong></span>
    factory += ("dvolume", 1.1, GREATER_THAN, dVolume, weights)
    factory += ("volatility", 1.3, GREATER_THAN, 
       volatility.drop(1), weights)
    factory += ("vPrice", 0.8, LESS_THAN, 
       vPrice.drop(1), weights)
    factory += ("dVolatility", 0.9, GREATER_THAN, 
       dVolatility, weights)
    factory.strategies
   }
}</pre></div><p>The purpose is <a id="id11520000" class="indexterm"/>to generate the initial population of strategies that compete to become relevant to the decline of the price of stocks of Goldman Sachs. The initial population of trading strategies is generated by creating a combination from four trading signals weighted by the variation in the stock price: <span class="emphasis"><em>∆(volume) &gt; 1.1</em></span>, <span class="emphasis"><em>∆(volatility) &gt; 1.3</em></span>, <span class="emphasis"><em>∆(close-open) &lt; 0.8</em></span>, and <span class="emphasis"><em>volatility &gt; 0.9</em></span>.</p><p>The <code class="literal">delta</code> method computes the variation of a trading variable between consecutive trading sessions. It invokes the <code class="literal">XTSeries.zipWithShift</code> method, which was introduced in the <span class="emphasis"><em>Time series in Scala</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>delta</strong></span>(xt: DblVector, a: Double): Try[DblVector] = Try {
  <span class="strong"><strong>zipWithShift</strong></span>(xt, 1).map{case(x, y) =&gt; a*(y/x - 1.0)}
}</pre></div><p>The trading strategies are generated by the <code class="literal">StrategyFactory</code> class introduced in the previous section (line <code class="literal">73</code>). The <code class="literal">weights</code> for the trading strategies are computed as the <code class="literal">dPrice</code> difference of the price of the stock between two consecutive trading sessions (line <code class="literal">74</code>). The option of unweighted trading strategies is selected by replacing the <code class="literal">weights</code> by the average price variation as follows:</p><div class="informalexample"><pre class="programlisting">val avWeights = dPrice.sum/dPrice.size
val <span class="strong"><strong>weights</strong></span> = Vector.fill(dPrice.size)(avWeights)</pre></div><p>The generation of the initial population of trading strategies is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01565.jpeg" alt="Creating trading strategies"/><div class="caption"><p>A design for the generation of the initial population of trading strategies</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Configuring the optimizer"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec16000"/>Configuring the optimizer</h3></div></div></div><p>The configuration parameters <a id="id11530000" class="indexterm"/>for the execution of the genetic algorithm is categorized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Tuning parameters such as crossover, mutation ratio, or soft limit on the population growth</li><li class="listitem">Data representation parameters such as quantization and encoding</li><li class="listitem">A scoring scheme</li></ul></div><p>The four configuration parameters for the GA are the maximum number of reproduction cycles (<code class="literal">MAX_CYCLES</code>) allowed in the execution, the crossover (<code class="literal">XOVER</code>), the mutation ratio (<code class="literal">MU</code>), and the soft limit function (<code class="literal">softLimit</code>) to control the population growth. The soft limit is implemented as a linearly decreasing function of the number of cycles (<code class="literal">n</code>) to retrain the growth of the population as the execution of the genetic algorithm progresses:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>XOVER</strong></span> = 0.8  //Probability(ratio) for cross-over
val <span class="strong"><strong>MU</strong></span> = 0.4  //Probability(ratio) for mutation
val <span class="strong"><strong>MAX_CYCLES</strong></span> = 400  //Max. number of optimization cycles 

val CUTOFF_SLOPE = -0.003  //Slope linear soft limit
val CUTOFF_INTERCEPT = 1.003  //Intercept linear soft limit
val <span class="strong"><strong>softLimit</strong></span> = (n: Int) =&gt; CUTOFF_SLOPE*n +CUTOFF_INTERCEPT</pre></div><p>The trading strategies are converted into chromosomes through <code class="literal">encoding</code> (line <code class="literal">75</code>). A <code class="literal">digitize</code> quantization scheme has to be implicitly defined in order to encode the target value in each trading signal (line <code class="literal">76</code>):</p><div class="informalexample"><pre class="programlisting">implicit val <span class="strong"><strong>encoding</strong></span> = defaultEncoding //<span class="strong"><strong>75</strong></span>
val R = 1024  //Quantization ratio
implicit val <span class="strong"><strong>digitize</strong></span> = new Quantization(R) //<span class="strong"><strong>76</strong></span>
</pre></div><p>The <code class="literal">scoring</code> function computes the <code class="literal">cost</code> or unfitness of a trading strategy (chromosome) by applying the <code class="literal">score</code> function to each of the three trading signals (genes) it contains (line <code class="literal">77</code>):</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>scoring</strong></span> = (chr: Chromosome[Signal]) =&gt; {
  val signals: List[Gene] = chr.code
  chr.<span class="strong"><strong>cost</strong></span> = signals.map(_.<span class="strong"><strong>score</strong></span>).sum //<span class="strong"><strong>77</strong></span>
}</pre></div></div><div class="section" title="Finding the best trading strategy"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec16100"/>Finding the best trading strategy</h3></div></div></div><p>The trading <code class="literal">strategies</code> generated <a id="id11540000" class="indexterm"/>by the factory in the <code class="literal">createStrategies</code> method are fed to the genetic algorithm as the <code class="literal">initial</code> population (line <code class="literal">79</code>). The upper <code class="literal">limit</code> to the population growth is set at eight times the size of the initial population (line <code class="literal">78</code>):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>createStrategies</strong></span>.map(strategies =&gt; {
  val limit = strategies.size &lt;&lt;3 //78
  val <span class="strong"><strong>initial</strong></span> = Population[Signal](limit, <span class="strong"><strong>strategies</strong></span>) //<span class="strong"><strong>79</strong></span>

  val <span class="strong"><strong>config</strong></span> = GAConfig(XOVER, MU, MAX_CYCLES,softLimit) //<span class="strong"><strong>80</strong></span>
  val <span class="strong"><strong>solver</strong></span> = GASolver[Signal](config,scoring,Some(tracker)) 
                                                //<span class="strong"><strong>81</strong></span>
  (solver |&gt; initial)
    .map(_.fittest.map(_.symbolic).getOrElse("NA")) match {
      case Success(results) =&gt; show(results)
      case Failure(e) =&gt; error("GAEval: ", e)
    } //<span class="strong"><strong>82</strong></span>
})</pre></div><p>The configuration, <code class="literal">config</code> (line <code class="literal">80</code>), the scoring function, and optionally a tracker function are all that you need to create and execute the <code class="literal">solver</code> genetic algorithm (line <code class="literal">81</code>). The partial function generated by the <code class="literal">|&gt;</code> operator transforms the <code class="literal">initial</code> population of trading strategies into the two <code class="literal">fittest</code> strategies (line <code class="literal">82</code>).</p><p>The documented source code for the monitoring function, tracker, and miscellaneous methods is available online.</p></div><div class="section" title="Tests"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec16200"/>Tests</h3></div></div></div><p>The cost <a id="id11550000" class="indexterm"/>function <span class="emphasis"><em>C</em></span> (or unfitness) score <a id="id11560000" class="indexterm"/>of each trading strategy are weighted for the rate of decline of the price of the Goldman Sachs stock. Let's run the following two tests:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Evaluation of the configuration of the genetic algorithm with the score weighted by the price variation</li><li class="listitem">Evaluation of the genetic algorithm with an unweighted scoring function</li></ul></div><div class="section" title="The weighted score"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec2800"/>The weighted score</h4></div></div></div><p>The score is weighted <a id="id11570000" class="indexterm"/>by the variation of the price of the stock GS. The test uses three different sets of crossover and mutation ratios: (0.6, 0.2), (0.3, 0.1), and (0.2, 0.6). The best trading strategy for each scenario is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>0.6-0.2</strong></span>: <span class="emphasis"><em>change &lt; 0.82 dVolume &gt; 1.17 volatility &gt; 1.35 cost= 0.0 fitness: 1.0E10</em></span></li><li class="listitem"><span class="strong"><strong>0.3-0.1</strong></span>: <span class="emphasis"><em>change &lt; 0.42 dVolume &gt; 1.61 volatility &gt; 1.08 cost= 59.18 fitness: 0.016</em></span></li><li class="listitem"><span class="strong"><strong>0.2-0.6</strong></span>: <span class="emphasis"><em>change &lt; 0.87 dVolume &lt; 8.17 volatility &gt; 3.91 cost= 301.3 fitness: 0.003</em></span></li></ul></div><p>The fittest trading strategy for each case does not differ much from the initial population for one or several of the following reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The initial guess for the trading signals was good</li><li class="listitem">The size of the initial population is too small to generate genetic diversity</li><li class="listitem">The test does not take into account the rate of decline of the stock price</li></ul></div><p>The execution of the genetic algorithm with <span class="emphasis"><em>cross-over = 0.2</em></span> and <span class="emphasis"><em>mutation = 0.6</em></span> produces a trading strategy that is inconsistent with the first two cases. One possible explanation is the fact that the crossover is applied always to the first of the three genes, forcing the optimizer to converge toward a local minimum.</p><p>Let's examine the behavior of the genetic algorithm during execution. We are particularly interested in the convergence of the average chromosome unfitness score. The average chromosome unfitness is the ratio of the total unfitness score for the population over the size of the population. Let's take a look at the following graph:</p><div class="mediaobject"><img src="../Images/image01566.jpeg" alt="The weighted score"/><div class="caption"><p>The convergence of a genetic algorithm for the crossover ratio 0.2 and mutation 0.6 with a weighted score</p></div></div><p style="clear:both; height: 1em;"> </p><p>The GA converges quite quickly and then stabilizes. The size of the population increases through crossover and mutation operations until it reaches the maximum of 256 trading <a id="id11580000" class="indexterm"/>strategies. The soft limit or constraint on the population size kicks in after 23 trading cycles. The test is run again with different values of crossover and mutation ratios, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01567.jpeg" alt="The weighted score"/><div class="caption"><p>The impact of the crossover and mutation ratio on the convergence of a genetic algorithm with a weighted score</p></div></div><p style="clear:both; height: 1em;"> </p><p>The profile of the execution of the genetic algorithm is not overly affected by the different values of crossover and mutation ratios. The chromosome unfitness score for the high crossover ratio (0.6) oscillates as the execution progresses. In some cases, the unfitness score between chromosomes is so small that the GA recycles the same few trading strategies.</p><p>The quick decline in the unfitness of the chromosomes is consistent with the fact that some of the fittest strategies were part of the initial population. It should, however, raise some concerns that the GA locked on a local minimum early on.</p></div><div class="section" title="The unweighted score"><div class="titlepage"><div><div><h4 class="title"><a id="ch10lvl4sec2900"/>The unweighted score</h4></div></div></div><p>The <a id="id11590000" class="indexterm"/>execution of a test that is similar to the previous one with the unweighted trading strategies (trading strategies that use the average price variation) scoring formula produces some interesting results, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01568.jpeg" alt="The unweighted score"/><div class="caption"><p>The convergence of a genetic algorithm for the crossover ratio 0.4 and mutation 0.4 with an unweighted score</p></div></div><p style="clear:both; height: 1em;"> </p><p>The profile for the size of the population is similar to the test using weighted scoring. However, the chromosome average cost pattern is somewhat linear. The unweighted (or averaging) adds the rate of decline of the stock price to the score (cost).</p><div class="note" title="Note"><h3 class="title"><a id="note31900"/>Note</h3><p>
<span class="strong"><strong>The complexity of a scoring function</strong></span>
</p><p>The complexity of the scoring (or computation of the cost) formula increases the odds of the genetic algorithm not converging properly. The possible solutions to the convergence problem are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Make the weighting function additive (less complex)</li><li class="listitem">Increase the size and diversity of the initial population</li></ul></div></div></div></div></div></div>
<div class="section" title="Advantages and risks of genetic algorithms" id="aid-6FSQK1"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec7200"/>Advantages and risks of genetic algorithms</h1></div></div></div><p>Now, it should be clear that <a id="id11600000" class="indexterm"/>genetic algorithms provide scientists with a powerful toolbox with which to optimize problems that:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Are poorly understood.</li><li class="listitem">May have more than one good enough solution.</li><li class="listitem">Have discrete, discontinuous, and nondifferentiable functions.</li><li class="listitem">Can be <a id="id11610000" class="indexterm"/>easily integrated with the rules engine and knowledge bases (for example, learning classifiers systems).</li><li class="listitem">Do not require deep domain knowledge. The genetic algorithm generates new solution candidates through genetic operators. The initial population does not have to contain the fittest solution.</li><li class="listitem">Do not require knowledge of numerical methods such as the <span class="strong"><strong>Newton-Raphson</strong></span>, <span class="strong"><strong>conjugate gradient</strong></span>, or <span class="strong"><strong>BFGS</strong></span> as optimization techniques, which frighten those with little inclination for mathematics.</li></ul></div><p>However, evolutionary <a id="id11620000" class="indexterm"/>computation is not suitable for problems for which:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A fitness function cannot be clearly defined</li><li class="listitem">Finding the global (absolute) minimum or maximum is essential to the problem</li><li class="listitem">The execution time has to be predictable</li><li class="listitem">The solution has to be provided in real time or pseudo-real time (streaming data)</li></ul></div></div>
<div class="section" title="Summary" id="aid-6GRB61"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec7300"/>Summary</h1></div></div></div><p>Are you hooked on evolutionary computation, genetic algorithms in particular, and their benefits, limitations as well as some of the common pitfalls? If the answer is yes, then you may find learning classifier systems, introduced in the next chapter, fascinating. This chapter dealt with the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Key concepts in evolutionary computing</li><li class="listitem">The key components and operators of genetic operators</li><li class="listitem">The pitfalls in defining a fitness or unfitness score using a financial trading strategy as a backdrop</li><li class="listitem">The challenge of encoding predicates in the case of trading strategies</li><li class="listitem">Advantages and risks of genetic algorithms</li><li class="listitem">The process for building a genetic algorithm forecasting tool from the bottom up</li></ul></div><p>The genetic algorithm is an important element of a special class of reinforcement learning, which is introduced in the <span class="emphasis"><em>Learning classifier systems</em></span> section in the next chapter.</p></div>
<div class="chapter" title="Chapter&#xA0;11.&#xA0;Reinforcement Learning"><div class="titlepage" id="aid-6HPRO2"><div><div><h1 class="title"><a id="ch25"/>Chapter 11. Reinforcement Learning</h1></div></div></div><p>This chapter presents the <a id="id11630000" class="indexterm"/>concept of <span class="strong"><strong>reinforcement learning</strong></span>, which is widely used in gaming and robotics. The second part of this chapter is dedicated to <span class="strong"><strong>learning classifier systems</strong></span>, which combine reinforcement learning techniques with evolutionary computing introduced in the previous chapter. Learning classifiers are an interesting breed of algorithms that are not commonly included in literature dedicated to machine learning. I highly recommend that you to read the seminal book on reinforcement learning by R. Sutton and A. Barto [11:1] if you are interested to know about the origin, purpose, and scientific foundation of reinforcement learning.</p><p>In this chapter, you will learn the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Basic concepts behind reinforcement learning</li><li class="listitem">A detailed implementation of the Q-learning algorithm</li><li class="listitem">A simple approach to manage and balance an investment portfolio using reinforcement learning</li><li class="listitem">An introduction to learning classifier systems</li><li class="listitem">A simple implementation of extended learning classifiers</li></ul></div><p>The section on <span class="strong"><strong>learning classifier systems</strong></span> (<span class="strong"><strong>LCS</strong></span>) is mainly informative and does not include a test case.</p><div class="section" title="Reinforcement learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec7400"/>Reinforcement learning</h1></div></div></div><p>The need of an alternative to traditional learning techniques arose with the design of the first autonomous systems.</p><div class="section" title="The problem"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec14700"/>The problem</h2></div></div></div><p>
<span class="strong"><strong>Autonomous systems</strong></span> <a id="id11640000" class="indexterm"/>are semi-independent <a id="id11650000" class="indexterm"/>systems that perform tasks with a high degree of autonomy. Autonomous systems touch every facet of our life, from robots and self-driving cars to drones. Autonomous devices react to the environment in which they operate. The reaction or action requires the knowledge of not only the current state of the environment but also the previous state(s).</p><p>Autonomous systems have specific characteristics that challenge traditional methodologies of machine learning, as listed here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Autonomous systems have poorly defined domain knowledge because of the sheer number of possible combinations of states.</li><li class="listitem">Traditional nonsequential supervised learning is not a practical option because of the following:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Training consumes significant computational resources, which are not always available on small autonomous devices</li><li class="listitem">Some learning algorithms are not suitable for real-time prediction</li><li class="listitem">The models do not capture the sequential nature of the data feed</li></ul></div></li><li class="listitem">Sequential data models such as hidden Markov models require training sets to compute the emission and state transition matrices (as explained in <span class="emphasis"><em>The hidden Markov model</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>), which are not always available. However, a reinforcement learning algorithm benefits from a hidden Markov model if some of the states are unknown. These algorithms are known as behavioral hidden Markov models [11:2].</li><li class="listitem">Genetic algorithms are an option if the search space can be constrained heuristically. However, genetic algorithms have unpredictable response time, which makes them impractical for real-time processing.</li></ul></div></div><div class="section" title="A solution – Q-learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec14800"/>A solution – Q-learning</h2></div></div></div><p>Reinforcement learning <a id="id11660000" class="indexterm"/>is an algorithmic approach to understanding and ultimately <a id="id11670000" class="indexterm"/>automating goal-based decision making. Reinforcement learning is also known as <a id="id11680000" class="indexterm"/>control learning. It differs from both supervised and unsupervised learning techniques from the knowledge acquisition standpoint: <span class="strong"><strong>autonomous</strong></span>, automated systems, or devices learn from direct and real-time interaction with their environment. There are numerous practical applications of reinforcement learning from robotics, navigation agents, drones, adaptive process control, game playing, and online learning, to scheduling and routing problems.</p><div class="section" title="Terminology"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16300"/>Terminology</h3></div></div></div><p>Reinforcement learning introduces <a id="id11690000" class="indexterm"/>new terminologies as listed here, which are quite different from that of older <a id="id11700000" class="indexterm"/>machine learning techniques:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Environment</strong></span>: This is any system that has states and mechanisms to transition between states. For example, the environment for a robot is the landscape or facility it operates.</li><li class="listitem"><span class="strong"><strong>Agent</strong></span>: This is <a id="id11710000" class="indexterm"/>an automated system that interacts with the environment.</li><li class="listitem"><span class="strong"><strong>State</strong></span>: The state <a id="id11720000" class="indexterm"/>of the environment or system is the set of variables or features that fully describe the environment.</li><li class="listitem"><span class="strong"><strong>Goal or absorbing state or terminal state</strong></span>: This <a id="id11730000" class="indexterm"/>is the state that provides a higher discounted <a id="id11740000" class="indexterm"/>cumulative <a id="id11750000" class="indexterm"/>reward than any other state. A high cumulative reward prevents the best policy from being dependent on the initial state during training.</li><li class="listitem"><span class="strong"><strong>Action</strong></span>: This <a id="id11760000" class="indexterm"/>defines the transition between states. The agent is responsible for performing or at least recommending an action. Upon execution of the action, the agent collects a reward (or punishment) from the environment.</li><li class="listitem"><span class="strong"><strong>Policy</strong></span>: This <a id="id11770000" class="indexterm"/>defines the action to be selected and executed for any state of the environment.</li><li class="listitem"><span class="strong"><strong>Best policy</strong></span>: This <a id="id11780000" class="indexterm"/>is the policy generated through training. It defines the model in Q-learning and is constantly updated with any new episode.</li><li class="listitem"><span class="strong"><strong>Reward</strong></span>: This <a id="id11790000" class="indexterm"/>quantifies the positive or negative interaction of the agent with the environment. Rewards are essentially the training set for the learning engine.</li><li class="listitem"><span class="strong"><strong>Episode</strong></span>: This <a id="id11800000" class="indexterm"/>defines the number of steps necessary to reach the goal state from an initial state. Episodes are also known as trials.</li><li class="listitem"><span class="strong"><strong>Horizon</strong></span>: This <a id="id11810000" class="indexterm"/>is the number of future steps or actions used in the maximization of the reward. The horizon can be infinite, in which case the future rewards are discounted in order for the value of the policy to converge.</li></ul></div></div><div class="section" title="Concepts"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16400"/>Concepts</h3></div></div></div><p>The key component <a id="id11820000" class="indexterm"/>in reinforcement learning is a <a id="id11830000" class="indexterm"/><span class="strong"><strong>decision-making agent</strong></span> that reacts to its environment by selecting and executing the best course of actions and being rewarded or penalized for it [11:3]. You can visualize these agents as robots navigating through an unfamiliar terrain or a maze. Robots use reinforcement learning as part of their reasoning process after all. The following diagram gives the overview architecture of the reinforcement learning agent:</p><div class="mediaobject"><img src="../Images/image01569.jpeg" alt="Concepts"/><div class="caption"><p>The four state transitions of reinforcement learning</p></div></div><p style="clear:both; height: 1em;"> </p><p>The agent collects the state of the environment, selects, and then executes the most appropriate action. The environment responds to the action by changing its state and rewarding or punishing the agent for the action.</p><p>The four steps of an episode or learning cycle are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The learning agent retrieves or is notified of a new state of the environment.</li><li class="listitem">The agent evaluates and selects the action that may provide the highest reward.</li><li class="listitem">The agent executes the action.</li><li class="listitem">The agent collects the reward or penalty and applies it to calibrate the learning algorithm.</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note32000"/>Note</h3><p>
<span class="strong"><strong>Reinforcement versus supervision</strong></span>
</p><p>The training process in reinforcement learning rewards features that maximize a value or return. Supervised learning rewards features that meet a predefined labeled value. Supervised learning can be regarded as forced learning.</p></div><p>The action of the agent modifies the state of the system, which in turn notifies the agent of the new operational condition. Although not every action will trigger a change in the state of the environment, the agent collects the reward or penalty nevertheless. At its core, the agent has to design and execute a sequence of actions to reach its goal. This sequence of actions is modeled using the ubiquitous Markov decision process (refer to the <span class="emphasis"><em>Markov decision processes</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>).</p><div class="note" title="Note"><h3 class="title"><a id="note32100"/>Note</h3><p>
<span class="strong"><strong>Dummy actions</strong></span>
</p><p>It is important to design the agent so that actions may not automatically trigger a new state of the environment. It is easy to think about a scenario in which the agent triggers an action just to evaluate its reward without affecting the environment significantly.</p></div><p>A good metaphor for such a scenario is the <span class="emphasis"><em>rollback</em></span> of the action. However, not all environments support such a <span class="emphasis"><em>dummy</em></span> action, and the agent may have to run Monte-Carlo simulations to try out an action.</p></div><div class="section" title="Value of a policy"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16500"/>Value of a policy</h3></div></div></div><p>Reinforcement learning is <a id="id11840000" class="indexterm"/>particularly suited to problems for which long-term rewards can be balanced against short-term rewards. A policy enforces the trade-off between short-term and long-term rewards. It guides the behavior of the agent by mapping the state of the environment to its actions. Each policy is evaluated through a variable known as the <span class="strong"><strong>value of a policy</strong></span>.</p><p>Intuitively, the value of a policy is the sum of all the rewards collected as a result of the sequence of actions taken by the agent. In practice, an action over the policy farther in the future obviously has a lesser impact than the next action from a state <span class="emphasis"><em>S<sub>t</sub></em></span> to a state <span class="emphasis"><em>S<sub>t+1</sub></em></span>. In other words, the impact of future actions on the current state has to be discounted by a factor, known as the <span class="emphasis"><em>discount coefficient for future rewards</em></span> &lt; 1.</p><div class="note" title="Note"><h3 class="title"><a id="note32200"/>Note</h3><p>
<span class="strong"><strong>Transition and rewards matrices</strong></span>
</p><p>The transition and emission matrices have been introduced in the <span class="emphasis"><em>The hidden Markov model</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>.</p></div><p>The optimum policy <span class="emphasis"><em>π*</em></span> is the agent's sequence of actions that maximizes the future reward discounted to the current time.</p><p>The following table introduces the mathematical notation of each component of reinforcement learning:</p><div class="informaltable"><table border="1"><colgroup><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Notation</p>
</th><th valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<span class="emphasis"><em>S = {s<sub>i</sub>}</em></span>
</p>
</td><td valign="top">
<p>These are the states of the environment</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>A = {a<sub>i</sub>}</em></span>
</p>
</td><td valign="top">
<p>These are the actions on the environment</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>Π<sub>t</sub> = p(a<sub>t</sub> | s<sub>t</sub>)</em></span>
</p>
</td><td valign="top">
<p>This is the policy (or strategy) of the agent</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>V<sup>π</sup>(s<sub>t</sub>)</em></span>
</p>
</td><td valign="top">
<p>This is the value of the policy at a state</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>pt =p(s<sub>t+1</sub> | s<sub>t</sub>,a<sub>t</sub>)</em></span>
</p>
</td><td valign="top">
<p>These are the state transition probabilities from the state <span class="emphasis"><em>st</em></span> to the state <span class="emphasis"><em>s<sub>t+1</sub></em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>r<sub>t</sub>= p(r<sub>t+1</sub> | s<sub>t</sub>,s<sub>t+1</sub>,a<sub>t</sub>)</em></span>
</p>
</td><td valign="top">
<p>This is the reward of an action <span class="emphasis"><em>a<sub>t</sub></em></span> for a state <span class="emphasis"><em>s<sub>t</sub></em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>R<sub>t</sub></em></span>
</p>
</td><td valign="top">
<p>This is the expected discounted long-term return</p>
</td></tr><tr><td valign="top">
<p>
<span class="emphasis"><em>γ</em></span>
</p>
</td><td valign="top">
<p>This is the coefficient to discount the future rewards</p>
</td></tr></tbody></table></div><p>The purpose is to <a id="id11850000" class="indexterm"/>compute the maximum expected reward <span class="emphasis"><em>R<sub>t</sub></em></span> from any starting state <span class="emphasis"><em>s<sub>k</sub></em></span> as the sum of all discounted rewards to reach the current state <span class="emphasis"><em>s<sub>t</sub></em></span>. The value <span class="emphasis"><em>V<sup>π</sup></em></span> of a policy <span class="emphasis"><em>π</em></span> at the state <span class="emphasis"><em>s<sub>t</sub></em></span> is the maximum expected reward <span class="emphasis"><em>R<sub>t</sub></em></span> given the state <span class="emphasis"><em>s<sub>t</sub></em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note32300"/>Note</h3><p>M1: The cumulative reward <span class="emphasis"><em>R<sub>t</sub></em></span> and value function <span class="emphasis"><em>V<sup>π</sup>(st)</em></span> for the state <span class="emphasis"><em>st</em></span> given a policy <span class="emphasis"><em>π</em></span> and a discount rate <span class="emphasis"><em>γ </em></span>is defined as:</p><div class="mediaobject"><img src="../Images/image01570.jpeg" alt="Value of a policy"/></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="The Bellman optimality equations"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16600"/>The Bellman optimality equations</h3></div></div></div><p>The problem <a id="id11860000" class="indexterm"/>of finding the optimal policies is indeed a nonlinear optimization problem whose solution is iterative (dynamic programming). The expression of the value function <span class="emphasis"><em>V<sup>π</sup></em></span> of a policy <span class="emphasis"><em>π</em></span> can be formulated using the Markovian state transition probabilities <span class="emphasis"><em>p<sub>t</sub></em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note32400"/>Note</h3><p>M2: The value function <span class="emphasis"><em>V<sup>π</sup>(s<sub>t</sub>)</em></span> for a state <span class="emphasis"><em>st</em></span> and future state <span class="emphasis"><em>s<sub>k</sub></em></span> with a reward <span class="emphasis"><em>r<sub>k</sub></em></span> using the transition probability <span class="emphasis"><em>p<sub>k</sub></em></span>, given a policy <span class="emphasis"><em>π</em></span> and a discount rate <span class="emphasis"><em>γ</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01571.jpeg" alt="The Bellman optimality equations"/></div><p style="clear:both; height: 1em;"> </p></div><p>
<span class="emphasis"><em>V*(s<sub>t</sub>)</em></span> is the <a id="id11870000" class="indexterm"/>optimal value of the state <span class="emphasis"><em>st</em></span> across all the policies. The equations are known as the Bellman optimality equations.</p><div class="note" title="Note"><h3 class="title"><a id="note32500"/>Note</h3><p>
<span class="strong"><strong>The curse of dimensionality</strong></span>
</p><p>The number of states for a high-dimension problem (large-feature vector) becomes quickly unsolvable. A workaround is to approximate the value function and reduce the number of states by sampling. The application test case introduces a very simple approximation function.</p></div><p>If the environment model, state, action, and rewards, as well as transition between states, are completely defined, the reinforcement learning technique is known as model-based learning. In this case, there is no need to explore a new sequence of actions or state transitions. Model-based learning is similar to playing a board game in which all combinations of steps that are necessary to win are completely known.</p><p>However, most practical applications using sequential data do not have a complete, definitive model. Learning techniques that do not depend on a fully defined and available model are known as model-free techniques. These techniques require exploration to find the best policy for any given state. The remaining sections in this chapter deal with model-free learning techniques, and more specifically, the temporal difference algorithm.</p></div><div class="section" title="Temporal difference for model-free learning"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16700"/>Temporal difference for model-free learning</h3></div></div></div><p>
<span class="strong"><strong>Temporal difference</strong></span> <a id="id11880000" class="indexterm"/>is a <a id="id11890000" class="indexterm"/>model-free learning technique that samples the environment. It is a commonly used approach to solve the Bellman equations iteratively. The absence of a model requires a discovery or <span class="strong"><strong>exploration</strong></span> of the environment. The simplest form of exploration is to use the value of the next state and the reward defined from the action to update the value of the current state, as described in the following diagram:</p><div class="mediaobject"><img src="../Images/image01572.jpeg" alt="Temporal difference for model-free learning"/><div class="caption"><p>An illustration of the temporal difference algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>The iterative feedback loop used to adjust the value action on the state plays a role similar to the backpropagation of errors in artificial neural networks or minimization of the loss function in supervised learning. The adjustment algorithm has to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Discount the estimate value of the next state using the discount rate <span class="emphasis"><em>γ</em></span></li><li class="listitem">Strike a balance between the impact of the current state and the next state on updating the value at time <span class="emphasis"><em>t</em></span> using the learning rate <span class="emphasis"><em>α</em></span></li></ul></div><p>The iterative formulation of the first Bellman equation predicts <span class="emphasis"><em>V<sup>π</sup>(st)</em></span>, the value function of state <span class="emphasis"><em>st</em></span> from the value function of the next state <span class="emphasis"><em>s<sub>t+1</sub></em></span>. The difference between the predicted value and the actual value is known as the temporal difference error abbreviated as <span class="emphasis"><em>δt</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note32600"/>Note</h3><p>M3: The formula for tabular temporal difference <span class="emphasis"><em>δ<sub>t</sub></em></span> for a value function <span class="emphasis"><em>V(s<sub>t</sub>)</em></span> at state <span class="emphasis"><em>s<sub>t</sub></em></span>, a learning rate <span class="emphasis"><em>α</em></span>, a reward <span class="emphasis"><em>r<sub>t</sub></em></span>, and a discount rate <span class="emphasis"><em>γ</em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01573.jpeg" alt="Temporal difference for model-free learning"/></div><p style="clear:both; height: 1em;"> </p></div><p>An alternative to evaluating a policy using the value of the state <span class="emphasis"><em>V<sup>π</sup>(s<sub>t</sub>)</em></span> is to use the value of taking an action on a state <span class="emphasis"><em>s<sub>t</sub></em></span> known as the value of action (or action-value) <span class="emphasis"><em>Q<sup>π</sup>(s<sub>t</sub>, a<sub>t</sub>)</em></span>.</p><div class="note" title="Note"><h3 class="title"><a id="note32700"/>Note</h3><p>M4: The definition of the value <span class="emphasis"><em>Q</em></span> of action at a state <span class="emphasis"><em>st</em></span> as the expectation of a reward <span class="emphasis"><em>R<sub>t</sub></em></span> for an action <span class="emphasis"><em>a<sub>t</sub></em></span> on a state <span class="emphasis"><em>s<sub>t</sub></em></span> is defined as:</p><div class="mediaobject"><img src="../Images/image01574.jpeg" alt="Temporal difference for model-free learning"/></div><p style="clear:both; height: 1em;"> </p></div><p>There are two methods to implement the temporal difference algorithm:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>On-policy</strong></span>: This is the value for the next best action that uses the policy</li><li class="listitem"><span class="strong"><strong>Off-policy</strong></span>: This is the value for the next best action that does not use the policy</li></ul></div><p>Let's consider <a id="id11900000" class="indexterm"/>the temporal difference algorithm using an off-policy method and its most commonly used implementation: Q-learning.</p></div><div class="section" title="Action-value iterative update"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16800"/>Action-value iterative update</h3></div></div></div><p>Q-learning is <a id="id11910000" class="indexterm"/>a model-free learning technique using an off-policy method. It optimizes the action-selection policy by learning an action-value function. Like any machine learning technique that relies on convex optimization, the Q-learning algorithm iterates through actions and states using the quality function, as described in the following mathematical formulation.</p><p>The algorithm predicts and discounts the optimum value of action <span class="emphasis"><em>max{Q<sub>t</sub>}</em></span> for the current state <span class="emphasis"><em>st</em></span> and action <span class="emphasis"><em>at</em></span> on the environment to transition to the state <span class="emphasis"><em>s<sub>t+1</sub></em></span>.</p><p>Similar to genetic algorithms that reuse the population of chromosomes in the previous reproduction cycle to produce offspring, the Q-learning technique strikes a balance between the new value of the quality function <span class="emphasis"><em>Q<sub>t+1</sub></em></span> and the old value <span class="emphasis"><em>Q<sub>t</sub></em></span> using the learning rate <span class="emphasis"><em>α</em></span>. Q-learning applies temporal difference techniques to the Bellman equation for an off-policy methodology.</p><div class="note" title="Note"><h3 class="title"><a id="note32800"/>Note</h3><p>M5: The Q-learning action-value updating formula for a given policy <span class="emphasis"><em>π</em></span>, set of states <span class="emphasis"><em>{s<sub>t</sub>}</em></span>, a set of actions <span class="emphasis"><em>{a<sub>t</sub>}</em></span> associated with each state <span class="emphasis"><em>s<sub>t</sub></em></span>, a learning rate <span class="emphasis"><em>α</em></span>, and a discount rate <span class="emphasis"><em>γ</em></span> is given by:</p><div class="mediaobject"><img src="../Images/image01575.jpeg" alt="Action-value iterative update"/></div><p style="clear:both; height: 1em;"> </p></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A value 1 for the learning rate <span class="emphasis"><em>α</em></span> discards the previous state, while a value 0 discards learning</li><li class="listitem">A value 1 for the discount rate <span class="emphasis"><em>γ</em></span> uses long-term rewards only, while a value 0 uses the short-term reward only</li></ul></div><p>Q-learning <a id="id11920000" class="indexterm"/>estimates the cumulative reward discounted for future actions.</p><div class="note" title="Note"><h3 class="title"><a id="note32900"/>Note</h3><p>
<span class="strong"><strong>Q-learning as reinforcement learning</strong></span>
</p><p>Q-learning qualifies as a reinforcement learning technique because it does not strictly require labeled data and training. Moreover, the Q-value does not have to be a continuous, differentiable function.</p></div><p>Let's apply our hard-earned knowledge of reinforcement learning to management and optimization of a portfolio of exchange-traded funds.</p></div></div><div class="section" title="Implementation"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec14900"/>Implementation</h2></div></div></div><p>Let's implement <a id="id11930000" class="indexterm"/>the <a id="id11940000" class="indexterm"/>Q-learning algorithm in Scala.</p><div class="section" title="Software design"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec16900"/>Software design</h3></div></div></div><p>The key components of <a id="id11950000" class="indexterm"/>the implementation of the Q-learning algorithm are defined as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The <code class="literal">QLearning</code> class implements training and prediction methods. It defines a data transformation of the <code class="literal">ETransform</code> type using an explicit configuration of the <code class="literal">QLConfig</code> type.</li><li class="listitem">The <code class="literal">QLSpace</code> class has two components: a sequence of states of the <code class="literal">QLState</code> type and the identifier <code class="literal">id</code> of one or more goal states within the sequence.</li><li class="listitem">A state, <code class="literal">QLState</code>, contains a sequence of <code class="literal">QLAction</code> instances used in its transition to another state and a reference to the object or <code class="literal">instance</code> for which the state is to be evaluated and predicted.</li><li class="listitem">An indexed state, <code class="literal">QLIndexedState</code>, indexes a state in the search toward the goal state.</li><li class="listitem">An optional <code class="literal">constraint</code> function that limits the scope of the search for the next most rewarding action from the current state.</li><li class="listitem">The model of the <code class="literal">QLModel</code> type is generated through training. It contains the best policy and the accuracy for a model.</li></ul></div><p>The following diagram shows the key components of the Q-learning algorithm:</p><div class="mediaobject"><img src="../Images/image01576.jpeg" alt="Software design"/><div class="caption"><p>The UML components diagram of the Q-learning algorithm</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="The states and actions"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17000"/>The states and actions</h3></div></div></div><p>The <code class="literal">QLAction</code> class <a id="id11960000" class="indexterm"/>specifies the transition of one state with a <code class="literal">from</code> identifier to another state with the <code class="literal">to</code> identifier, as shown here:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLAction</strong></span>(val <span class="strong"><strong>from</strong></span>: Int, val <span class="strong"><strong>to</strong></span>: Int)</pre></div><p>Actions have a <span class="emphasis"><em>Q</em></span> value (or action-value), a reward, and a probability. The implementation defines these three values in three separate matrices: <span class="emphasis"><em>Q</em></span> for the action values, <span class="emphasis"><em>R</em></span> for rewards, and <span class="emphasis"><em>P</em></span> for probabilities, in order to stay consistent with the mathematical formulation.</p><p>A state of the <code class="literal">QLState</code> type is fully defined by its identifier, <code class="literal">id</code>, the list of <code class="literal">actions</code> to transition to some other states, and a <code class="literal">prop</code> property of the parameterized type, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLState</strong></span>[T](val <span class="strong"><strong>id</strong></span>: Int, 
  val <span class="strong"><strong>actions</strong></span>: List[QLAction] = List.empty, 
  val <span class="strong"><strong>instance</strong></span>: T])</pre></div><p>The state might not have any actions. This is usually the case of the goal or absorbing state. In this case, the list is empty. The parameterized <code class="literal">instance</code> is a reference to the object for which the state is computed.</p><p>The next step consists of creating the graph or search space.</p></div><div class="section" title="The search space"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17100"/>The search space</h3></div></div></div><p>The search space <a id="id11970000" class="indexterm"/>is the container responsible for any sequence of states. The <code class="literal">QLSpace</code> class takes the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The sequence of all the possible <code class="literal">states</code></li><li class="listitem">The ID of one or several states that have been selected as <code class="literal">goals</code></li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note33000"/>Note</h3><p>
<span class="strong"><strong>Why multiple goals?</strong></span>
</p><p>There is absolutely no requirement that a state space must have a single goal. You can describe a solution to a problem as reaching a threshold or meeting one of the several conditions. Each condition can be defined as a state goal.</p></div><p>The <code class="literal">QLSpace</code> class is implemented as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLSpace</strong></span>[T](states: Seq[QLState[T]], goals: Array[Int]) {
  val <span class="strong"><strong>statesMap</strong></span> = states.map(st =&gt;(st.id, st)) //<span class="strong"><strong>1</strong></span>
  val <span class="strong"><strong>goalStates</strong></span> = new HashSet[Int]() ++ goals //<span class="strong"><strong>2</strong></span>
  
  def <span class="strong"><strong>maxQ</strong></span>(state: QLState[T], 
      policy: QLPolicy): Double   //<span class="strong"><strong>3</strong></span>
  def init(state0: Int)  //<span class="strong"><strong>4</strong></span>
  def <span class="strong"><strong>nextStates</strong></span>(st: QLState[T]): Seq[QLState[T]]  //<span class="strong"><strong>5</strong></span>
   …
}</pre></div><p>The constructor of the <code class="literal">QLSpace</code> class generates a map, <code class="literal">statesMap</code>. It retrieves the state using its <code class="literal">id</code> value (line <code class="literal">1</code>) and the array of goals, <code class="literal">goalStates</code> (line <code class="literal">2</code>). Furthermore, the <code class="literal">maxQ</code> method computes the maximum action-value, <code class="literal">maxQ</code>, for a state given a policy (line <code class="literal">3</code>). The implementation of the <code class="literal">maxQ</code> method is described in the next section.</p><p>The <code class="literal">init</code> method selects an initial state for training episodes (line <code class="literal">4</code>). The state is randomly selected if the <code class="literal">state0</code> argument is invalid:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>init</strong></span>(state0: Int): QLState[T] = 
  if(state0 &lt; 0) {
    val seed = System.currentTimeMillis+Random.nextLong
      states((new Random(seed)).nextInt(states.size-1))
  }
  else states(state0)</pre></div><p>Finally, the <code class="literal">nextStates</code> method retrieves the list of states resulting from the execution of all the actions associated with the <code class="literal">st</code> state (line <code class="literal">5</code>).</p><p>The <code class="literal">QLSpace</code> search space is actually created by the <code class="literal">apply</code> factory method defined in the <code class="literal">QLSpace</code> companion object, as shown here:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>[T](<span class="strong"><strong>goals</strong></span>: Array[Int], <span class="strong"><strong>instances</strong></span>: Seq[T],
    <span class="strong"><strong>constraints</strong></span>: Option[Int =&gt;List[Int]): QLSpace[T] ={ //<span class="strong"><strong>6</strong></span>

  val r = Range(n, instances.size)  

  val <span class="strong"><strong>states</strong></span> = instances.zipWithIndex.map{ case(x, n) =&gt; {
    val validStates = constraints.map( _(n)).getOrElse(r)
    val actions = validStates.view
          .map(new QLAction(n, _)).filter(n != _.to) //<span class="strong"><strong>7</strong></span>
    QLState[T](n, actions, x)
  }}
  new QLSpace[T](states, goals) 
}</pre></div><p>The <code class="literal">apply</code> method <a id="id11980000" class="indexterm"/>creates a list of states using the <code class="literal">instances</code> set, the <code class="literal">goals</code>, and the <code class="literal">constraints</code> constraining function as inputs (line <code class="literal">6</code>). Each state creates its list of <code class="literal">actions</code>. The actions are generated from this state to any other states (line <code class="literal">7</code>).</p><p>The search space of states is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01577.jpeg" alt="The search space"/><div class="caption"><p>The state transition matrix with QLData (Q-value, reward, and probability)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <code class="literal">constraints</code> function limits the scope of the actions that can be triggered from any given state, as illustrated in the preceding diagram.</p></div><div class="section" title="The policy and action-value"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17200"/>The policy and action-value</h3></div></div></div><p>Each action has an action-value, a reward, and a potentially probability. The probability variable is introduced to simply model the hindrance or adverse condition for an action to be executed. If the action does not have any external constraint, the probability is 1. If the action is not allowed, the probability is 0.</p><div class="note" title="Note"><h3 class="title"><a id="note33100"/>Note</h3><p>
<span class="strong"><strong>Dissociating a policy from states</strong></span>
</p><p>The action and states are the edges and vertices of the search space or search graph. The policy defined by the action-values, rewards, and probabilities is completely dissociated from the graph. The Q-learning algorithm initializes the reward matrix and updates the action-value matrix independently of the structure of the graph.</p></div><p>The <code class="literal">QLData</code> class is a container for three values: <code class="literal">reward</code>, <code class="literal">probability</code>, and a <code class="literal">value</code> variable for the Q-value, as shown here:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLData</strong></span>(val reward: Double, val probability: Double) {
  var value: Double = 0.0
  def <span class="strong"><strong>estimate</strong></span>: Double = value*probability
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note33200"/>Note</h3><p>
<span class="strong"><strong>Reward and punishment</strong></span>
</p><p>The probability in the <code class="literal">QLData</code> class represents the hindrance or difficulty to reach one state from another state. Nothing prevents you from using the probability as a negative reward or punishment. However, its proper definition is to create a soft constraint of a state transition for a small subset of a state. For most applications, the overwhelming majority of state transitions have a probability of 1.0, and therefore, rely on the reward to guide the search toward the goal.</p></div><p>The <code class="literal">estimate</code> method adjusts the Q-value, <code class="literal">value</code>, with the probability to reflect any external condition that can impede the action.</p><div class="note" title="Note"><h3 class="title"><a id="note33300"/>Note</h3><p>
<span class="strong"><strong>Mutable data</strong></span>
</p><p>You might wonder why the <code class="literal">QLData</code> class defines a value as a variable instead of a value as recommended by the best Scala coding practices [11:4]. The reason being that an instance of an immutable class can be created for each action or state transition that requires you to update the <code class="literal">value</code> variable.</p><p>The training of the Q-learning model entails iterating across several episodes, each episode being defined as a multiple iteration. For instance, the training of a model with 400 states for 10 episodes of 100 iterations can potentially create 160 million instances of <code class="literal">QLData</code>. Although not quite elegant, mutability reduces the load on the JVM garbage collector.</p></div><p>Next, let's create <a id="id11990000" class="indexterm"/>a simple schema or class, <code class="literal">QLInput</code>, to initialize the reward and probability associated with each action as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLInput</strong></span>(val <span class="strong"><strong>from</strong></span>: Int, val <span class="strong"><strong>to</strong></span>: Int, 
    val <span class="strong"><strong>reward</strong></span>: Double, val <span class="strong"><strong>probability</strong></span>: Double = 1.0)</pre></div><p>The first two arguments are the identifiers for the <code class="literal">from</code> source state and the <code class="literal">to</code> target state for this specific action. The last two arguments are the <code class="literal">reward</code>, collected at the completion of the action, and its <code class="literal">probability</code>. There is no need to provide an entire matrix. Actions have a reward of 1 and a probability of 1 by default. You only need to create an input for actions that have either a higher reward or a lower probability.</p><p>The number of states and a sequence of input define the policy of the <code class="literal">QLPolicy</code> type. It is merely a data container, as shown here:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLPolicy</strong></span>(input: Seq[QLInput]) { 
  val <span class="strong"><strong>numStates</strong></span> = Math.sqrt(input.size).toInt  //<span class="strong"><strong>8</strong></span>
  
  val <span class="strong"><strong>qlData</strong></span> = input.map(qlIn =&gt; 
new QLData(qlIn.reward, qlIn.prob))  //<span class="strong"><strong>9</strong></span>
  
  def setQ(from: Int, to: Int, value: Double): Unit =
     qlData(from*numStates + to).value = value //<span class="strong"><strong>10</strong></span>

  def <span class="strong"><strong>Q</strong></span>(from: Int, to: Int): Double = 
    qlData(from*numStates + to).value  //<span class="strong"><strong>11</strong></span>
  def <span class="strong"><strong>EQ</strong></span>(from: Int, to: Int): Double = 
    qlData(from*numStates + to).estimate //<span class="strong"><strong>12</strong></span>
  def <span class="strong"><strong>R</strong></span>(from: Int, to: Int): Double = 
    qlData(from*numStates + to).reward //<span class="strong"><strong>13</strong></span>
  def <span class="strong"><strong>P</strong></span>(from: Int, to: Int): Double = 
    qlData(from*numStates + to).probability //<span class="strong"><strong>14</strong></span>
}</pre></div><p>The number of states, <code class="literal">numStates</code>, is the square root of the number of elements of the initial input matrix, <code class="literal">input</code> (line <code class="literal">8</code>). The constructor initializes the <code class="literal">qlData</code> matrix of the <code class="literal">QLData</code> type with the input data, <code class="literal">reward</code>, and <code class="literal">probability</code> (line <code class="literal">9</code>). The <code class="literal">QLPolicy</code> class <a id="id12000000" class="indexterm"/>defines the shortcut methods to update (line <code class="literal">10</code>) and retrieve (line <code class="literal">11</code>) the <code class="literal">value</code>, the <code class="literal">estimate</code> (line <code class="literal">12</code>), the <code class="literal">reward</code> (line <code class="literal">13</code>), and the <code class="literal">probability</code> (line <code class="literal">14</code>).</p></div><div class="section" title="The Q-learning components"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17300"/>The Q-learning components</h3></div></div></div><p>The <code class="literal">QLearning</code> class <a id="id12010000" class="indexterm"/>encapsulates the Q-learning algorithm, and more specifically, the action-value updating equation. It is a data transformation of the <code class="literal">ETransform</code> type with an explicit configuration of the <code class="literal">QLConfig</code> type (line <code class="literal">16</code>) (refer to the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLearning</strong></span>[T](<span class="strong"><strong>conf</strong></span>: QLConfig, 
    <span class="strong"><strong>qlSpace</strong></span>: QLSpace[T], <span class="strong"><strong>qlPolicy</strong></span>: QLPolicy) //<span class="strong"><strong>15</strong></span>
    extends <span class="strong"><strong>ETransform</strong></span>[QLConfig](conf) { //<span class="strong"><strong>16</strong></span>

  type <span class="strong"><strong>U</strong></span> = QLState[T] //<span class="strong"><strong>17</strong></span>
  type <span class="strong"><strong>V</strong></span> = QLState[T] //<span class="strong"><strong>18</strong></span>

  val <span class="strong"><strong>model</strong></span>: Option[QLModel] = train //<span class="strong"><strong>19</strong></span>
  def train: Option[QLModel]
  def nextState(iSt: QLIndexedState[T]): QLIndexedState[T]

  override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]]
  …
}</pre></div><p>The constructor takes the following parameters (line <code class="literal">15</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">config</code>: This is the configuration of the algorithm</li><li class="listitem"><code class="literal">qlSpace</code>: This is the search space</li><li class="listitem"><code class="literal">qlPolicy</code>: This is the policy</li></ul></div><p>The <code class="literal">model</code> is generated or trained during the instantiation of the class (refer to the <span class="emphasis"><em>Design template for classifier</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>) (line <code class="literal">19</code>). The Q-learning algorithm is implemented as an explicit data transformation; therefore, the <code class="literal">U</code> type of the input element and the <code class="literal">V</code> type of the output element to the <code class="literal">|&gt; </code>predictor are initialized as <code class="literal">QLState</code> (lines <code class="literal">17</code> and <code class="literal">18</code>).</p><p>The configuration of the Q-learning algorithm, <code class="literal">QLConfig</code>, specifies the learning rate, <code class="literal">alpha</code>, the discount rate, <code class="literal">gamma</code>, the maximum number of states (or length) of an episode, <code class="literal">episodeLength</code>, the number of episodes (or epochs) used in training, <code class="literal">numEpisodes</code>, and the <a id="id12020000" class="indexterm"/>minimum coverage, <code class="literal">minCoverage</code>, required to select the best policy as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>QLConfig</strong></span>(val <span class="strong"><strong>alpha</strong></span>: Double, 
  val <span class="strong"><strong>gamma</strong></span>: Double, 
  val <span class="strong"><strong>episodeLength</strong></span>: Int, 
  val <span class="strong"><strong>numEpisodes</strong></span>: Int, 
  val <span class="strong"><strong>minCoverage</strong></span>: Double) extends Config</pre></div><p>The <code class="literal">QLearning</code> class has two constructors defined in its companion object that initializes the policy either from an input matrix of states or from a function that compute the reward and probabilities:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The client code specifies the <code class="literal">input</code> function to initialize the state of the Q-learning algorithm from the input data</li><li class="listitem">The client code specifies the functions to generate the <code class="literal">reward</code> and <code class="literal">probability</code> for each action or state transition</li></ul></div><p>The first constructor for the <code class="literal">QLearning</code> class passes the initialization of states <code class="literal">=&gt; Seq[QLInput]</code>, the sequence of references of <code class="literal">instances</code> associated with the states, and the <code class="literal">constraints</code> scope constraining function as an argument, besides the configuration and the goals (line <code class="literal">20</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>[T](config: QLConfig,  //<span class="strong"><strong>20</strong></span>
   goals: Array[Int], 
   <span class="strong"><strong>input</strong></span>: =&gt; Seq[QLInput], 
   <span class="strong"><strong>instances</strong></span>: Seq[T],
   <span class="strong"><strong>constraints</strong></span>: Option[Int =&gt;List[Int]] =None): QLearning[T]={
     
   new QLearning[T](config, 
     QLSpace[T](goals, instances, constraints),
     new QLPolicy(input))
}</pre></div><p>The second constructor passes the input data, <code class="literal">xt</code> (line <code class="literal">21</code>), the <code class="literal">reward</code> function (line <code class="literal">22</code>), and the <code class="literal">probability</code> function (line <code class="literal">23</code>) as well as the sequence of references of <code class="literal">instances</code> associated with the states and the <code class="literal">constraints</code> scope constraining function as arguments:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>[T](config: QLConfig, 
   goals: Array[Int],
   <span class="strong"><strong>xt</strong></span>: DblVector,  //<span class="strong"><strong>21</strong></span>
   <span class="strong"><strong>reward</strong></span>: (Double, Double) =&gt; Double, //<span class="strong"><strong>22</strong></span>
   <span class="strong"><strong>probability</strong></span>: (Double, Double) =&gt; Double, //<span class="strong"><strong>23</strong></span>
   <span class="strong"><strong>instances</strong></span>: Seq[T].
   <span class="strong"><strong>constraints</strong></span>: Option[Int =&gt;List[Int]] =None): QLearning[T] ={

  val r = Range(0, xt.size)
  val input = new ArrayBuffer[QLInput] //<span class="strong"><strong>24</strong></span>
  r.foreach(i =&gt; 
    r.foreach(j =&gt; 
     input.append(QLInput(i, j, reward(xt(i), xt(j)), 
          probability(xt(i), xt(j))))
    )
  )
  new QLearning[T](config, 
    QLSpace[T](goals, instances, constraints), 
    new QLPolicy(input))
}</pre></div><p>The reward and <a id="id12030000" class="indexterm"/>probability matrices are used to initialize the <code class="literal">input</code> state (line <code class="literal">24</code>).</p></div><div class="section" title="The Q-learning training"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17400"/>The Q-learning training</h3></div></div></div><p>Let's take a look <a id="id12040000" class="indexterm"/>at the computation of the best policy during training. First, we need to define a <code class="literal">QLModel</code> model class with the <code class="literal">bestPolicy</code> optimum policy (or path) and its <code class="literal">coverage</code> as parameters:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>QLModel</strong></span>(val <span class="strong"><strong>bestPolicy</strong></span>: <span class="strong"><strong>QLPolicy</strong></span>, 
    val <span class="strong"><strong>coverage</strong></span>: Double) extends Model</pre></div><p>The creation of <code class="literal">model</code> consists of executing multiple episodes to extract the best policy. The training is executed in the <code class="literal">train</code> method: Each episode starts with a randomly selected state, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>: Option[QLModel] = Try {
  val completions = Range(0, <span class="strong"><strong>config.numEpisodes</strong></span>)
     .map(epoch =&gt; if(train(-1)) 1 else 0).sum  //<span class="strong"><strong>25</strong></span>
  completions.toDouble/config.numEpisodes //<span class="strong"><strong>26</strong></span>
}
.map( coverage =&gt; {
  if(coverage &gt; <span class="strong"><strong>config.minCoverage</strong></span>) 
    Some(new QLModel(qlPolicy, coverage))  //<span class="strong"><strong>27</strong></span>
  else None
}).get</pre></div><p>The <code class="literal">train</code> method iterates through the generation of the best policy starting from a randomly selected state <code class="literal">config.numEpisodes</code> times (line <code class="literal">25</code>). The state <code class="literal">coverage</code> is calculated as the percentage of times the search ends with the goal state (line <code class="literal">26</code>). The training <a id="id12050000" class="indexterm"/>succeeds only if the coverage exceeds a threshold value, <code class="literal">config.minAccuracy</code>, specified in the configuration.</p><div class="note" title="Note"><h3 class="title"><a id="note33400"/>Note</h3><p>
<span class="strong"><strong>The quality of the model</strong></span>
</p><p>The implementation uses the accuracy to measure the quality of the model or best policy. The F1 measure (refer to the <span class="emphasis"><em>Assessing a model</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>), is not appropriate because there are no false positives.</p></div><p>The <code class="literal">train(state0: Int)</code> method does the heavy lifting at each episode (or epoch). It triggers the search by selecting either the <code class="literal">state0 </code>initial state or a <code class="literal">r</code> random generator with a new seed, if <code class="literal">state0</code> is &lt; 0, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>QLIndexedState</strong></span>[T](val state: QLState[T], 
  val iter: Int)</pre></div><p>The <code class="literal">QLIndexedState</code> utility class keeps track of the <code class="literal">state</code> at a specific iteration, <code class="literal">iter</code>, within an episode or epoch:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>train</strong></span>(<span class="strong"><strong>state0</strong></span>: Int): Boolean = {
  @<span class="strong"><strong>tailrec</strong></span>
  def <span class="strong"><strong>search</strong></span>(iSt: QLIndexedState[T]): QLIndexedState[T]

    val finalState = <span class="strong"><strong>search</strong></span>(
       QLIndexedState(qlSpace.init(state0), 0)
    )
  if( finalState.index == -1) false //<span class="strong"><strong>28</strong></span>
  else qlSpace.isGoal(finalState.state) //<span class="strong"><strong>29</strong></span>
}</pre></div><p>The implementation of <code class="literal">search</code> for the goal state(s) from a <code class="literal">state0 </code>predefined or random is a textbook implementation of the Scala tail recursion. Either the recursive search ends if there are no more states to consider (line <code class="literal">28</code>) or the goal state is reached (line <code class="literal">29</code>).</p></div><div class="section" title="Tail recursion to the rescue"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17500"/>Tail recursion to the rescue</h3></div></div></div><p>Tail recursion is a <a id="id12060000" class="indexterm"/>very effective construct to apply an operation to every item of a collection [11:5]. It optimizes the management of the function stack frame during the recursion. The annotation triggers a validation of the condition necessary for the compiler to optimize the function calls, as shown here:</p><div class="informalexample"><pre class="programlisting">@<span class="strong"><strong>tailrec</strong></span>
def <span class="strong"><strong>search</strong></span>(iSt: QLIndexedState[T]): QLIndexedState[T] = {
  val states = qlSpace.nextStates(iSt.state) //<span class="strong"><strong>30</strong></span> 

  if( states.isEmpty || iSt.iter &gt;= config.episodeLength) //<span class="strong"><strong>31</strong></span> 
    QLIndexedState(iSt.state, -1)

  else {
    val state = states.<span class="strong"><strong>maxBy</strong></span>(s =&gt; 
       qlPolicy.R(iSt.state.id, s.id)) //<span class="strong"><strong>32</strong></span>
    if( qlSpace.<span class="strong"><strong>isGoal</strong></span>(state) ) 
       QLIndexedState(state, iSt.iter)  //<span class="strong"><strong>33</strong></span>
    
    else {
      val fromId = iSt.state.id
      val r = qlPolicy.R(fromId, state.id)   
      val q = qlPolicy.Q(fromId, state.id) //<span class="strong"><strong>34</strong></span>

      val nq = q + config.alpha*(r + 
         config.gamma * qlSpace.maxQ(state, qlPolicy)-q) //<span class="strong"><strong>35</strong></span>
      qlPolicy.setQ(fromId, state.id,  nq) //<span class="strong"><strong>36</strong></span>
      <span class="strong"><strong>search</strong></span>(<span class="strong"><strong>QLIndexedState</strong></span>(state, iSt.iter+1))
    }
  }
}</pre></div><p>Let's dive into the implementation for the <span class="emphasis"><em>Q</em></span> action-value updating equation. The <code class="literal">search</code> method implements the <span class="strong"><strong>M5</strong></span> mathematical expression for each recursion.</p><p>The recursion uses the <code class="literal">QLIndexedState</code> utility class (state, iteration number in the episode) as an argument. First, the recursion invokes the <code class="literal">nextStates</code> method of <code class="literal">QLSpace</code> (line <code class="literal">30</code>) to retrieve all the states associated with the <code class="literal">st</code> current state through its actions, as shown here:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>nextStates</strong></span>(st: QLState[T]): Seq[QLState[T]] = 
  if( st.actions.isEmpty )
    Seq.empty[QLState[T]]
  else
    st.actions.map(ac =&gt; statesMap.get(ac.to) )</pre></div><p>The search completes and returns the current <code class="literal">state</code> if the length of the episode (maximum number of states visited) is reached or the <code class="literal">goal</code> is reached or there is no further state to transition to (line <code class="literal">31</code>). Otherwise, the recursion computes the state to which the transition generates the higher reward <code class="literal">R</code> from the current policy (line <code class="literal">32</code>). The recursion returns the state with the highest reward if it is one of the goal states (line <code class="literal">33</code>). The method retrieves the current <code class="literal">q</code> action-value (line <code class="literal">34</code>) and <code class="literal">r</code> reward matrices from the policy, and then applies the equation to update the action-value (line <code class="literal">35</code>). The method updates the action-value <code class="literal">Q</code> with the new value <code class="literal">nq</code> (line <code class="literal">36</code>).</p><p>The action-value <a id="id12070000" class="indexterm"/>updating equation requires the computation of the maximum action-value associated with the current state, which is performed by the <code class="literal">maxQ</code> method of the <code class="literal">QLSpace</code> class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>maxQ</strong></span>(state: QLState[T], policy: QLPolicy): Double = {
   val best = states.filter( _ != state)  //<span class="strong"><strong>37</strong></span>
      .maxBy(st =&gt; policy.EQ(state.id, st.id))  //<span class="strong"><strong>38</strong></span>
   policy.EQ(state.id, best.id)
}</pre></div><p>The <code class="literal">maxQ</code> method filters out the current state (line <code class="literal">37</code>) and then extracts the best state, which maximizes the policy (line <code class="literal">38</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note33500"/>Note</h3><p>
<span class="strong"><strong>Reachable goal</strong></span>
</p><p>The algorithm does not require the goal state to be reached for every episode. After all, there is no guarantee that the goal will be reached from any randomly selected state. It is a constraint on the algorithm to follow a positive gradient of the rewards when transitioning between states within an episode. The goal of the training is to compute the best possible policy or sequence of states from any given initial state. You are responsible for validating the model or best policy extracted from the training set, independent from the fact that the goal state is reached for every episode.</p></div></div><div class="section" title="The validation"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17600"/>The validation</h3></div></div></div><p>A commercial <a id="id12080000" class="indexterm"/>application may require multiple types of validation mechanisms regarding the states transition, reward, probability, and Q-value matrices.</p><p>One critical validation is to verify that the user-defined <code class="literal">constraints</code> function does not create a dead end in the search or training of Q-learning. The <code class="literal">constraints</code> function establishes the list of states that can be accessed from a given state through actions. If the <a id="id12090000" class="indexterm"/>constraints are too tight, some of the possible search paths may not reach the goal state. Here is a simple validation of the <code class="literal">constraints</code> function:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>validateConstraints</strong></span>(numStates: Int, 
    <span class="strong"><strong>constraints</strong></span>: Int =&gt; List[Int]): Boolean = 
  Range(0, numStates).exists( constraints(_).isEmpty )</pre></div></div><div class="section" title="The prediction"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17700"/>The prediction</h3></div></div></div><p>The last <a id="id12100000" class="indexterm"/>functionality of the <code class="literal">QLearning</code> class is the prediction using the model created during training. The <code class="literal">|&gt;</code> method predicts the optimum state transition (or action) from a given state, <code class="literal">state0</code>:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = {
  case <span class="strong"><strong>state0</strong></span>: U if(isModel) =&gt;  Try {
    if(state0.<span class="strong"><strong>isGoal</strong></span>) state0  //<span class="strong"><strong>39</strong></span>
    else <span class="strong"><strong>nextState</strong></span>(QLIndexedState[T](state0, 0)).state) //<span class="strong"><strong>40</strong></span>
  }
}</pre></div><p>The <code class="literal">|&gt;</code> data transformation returns itself if the <code class="literal">state0 </code>input state is the goal (line <code class="literal">39</code>) or computes the best outcome, <code class="literal">nextState</code>, (line <code class="literal">40</code>) using another tail recursion, as follows:</p><div class="informalexample"><pre class="programlisting">@<span class="strong"><strong>tailrec</strong></span>
def <span class="strong"><strong>nextState</strong></span>(iSt: QLIndexedState[T]): QLIndexedState[T] =  {
  val states = qlSpace.nextStates(<span class="strong"><strong>iSt.state</strong></span>) //<span class="strong"><strong>41</strong></span>

  if( states.isEmpty || iSt.iter &gt;=config.episodeLength) 
     iSt  //<span class="strong"><strong>42</strong></span>
  else {
    val fromId = iSt.state.id
    val qState = states.maxBy(s =&gt;  //<span class="strong"><strong>43</strong></span>
       model.map(_.bestPolicy.R(fromId, s.id)).getOrElse(-1.0))
    <span class="strong"><strong>nextState</strong></span>(QLIndexedState[T](qState, iSt.iter+1)) //<span class="strong"><strong>44</strong></span>
  }
}</pre></div><p>The <code class="literal">nextState</code> method executes the following sequence of invocations:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Retrieve the eligible states that can be transitioned to from the current state, <code class="literal">iSt.state</code> (line <code class="literal">41</code>).</li><li class="listitem">Return the states if there are no more states or if the method does not converge within the maximum number of allowed iterations, <code class="literal">config.episodeLength</code> (line <code class="literal">42</code>).</li><li class="listitem">Extracts <a id="id12110000" class="indexterm"/>the state, <code class="literal">qState</code>, with the most rewarding policy (line <code class="literal">43</code>).</li><li class="listitem">Increment the <code class="literal">iSt.iter</code> iteration counter (line <code class="literal">44</code>).</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note33600"/>Note</h3><p>
<span class="strong"><strong>The exit condition</strong></span>
</p><p>The prediction ends when no more states are available or the maximum number of iterations within the episode is exceeded. You can define a more sophisticated exit condition. The challenge is that there is no explicit error or loss variable/function that can be used except the temporal difference error.</p></div><p>The <code class="literal">|&gt;</code> prediction method returns either the best possible state or <code class="literal">None</code> if the model cannot be created during training.</p></div></div><div class="section" title="Option trading using Q-learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15000"/>Option trading using Q-learning</h2></div></div></div><p>The Q-learning <a id="id12120000" class="indexterm"/>algorithm is used <a id="id12130000" class="indexterm"/>in many financial and market trading applications [11:6]. Let's consider the problem of computing the best strategy to trade certain types of options given some market conditions and trading data.</p><p>The <span class="strong"><strong>Chicago Board Options Exchange</strong></span> (<span class="strong"><strong>CBOE</strong></span>) offers an excellent online tutorial on options [11:7]. An option is a contract that gives the buyer the right but not the obligation to buy or sell an underlying asset at a specific price on or before a certain date (refer to the <span class="emphasis"><em>Options trading</em></span> section under <span class="emphasis"><em>Finances 101</em></span> in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>.) There are several option pricing models, the Black-Scholes stochastic partial differential equations being the most recognized [11:8].</p><p>The purpose of the exercise is to predict the price of an option on a security for <span class="emphasis"><em>N</em></span> days in the future according to the current set of observed features derived from the time to expiration, price of the security, and volatility. Let's focus on the call options of a given security, IBM. The following chart plots the daily price of the IBM stock and its derivative <a id="id12140000" class="indexterm"/>call option for May 2014 with a strike price of $190:</p><div class="mediaobject"><img src="../Images/image01578.jpeg" alt="Option trading using Q-learning"/><div class="caption"><p>The IBM stock and Call $190 May 2014 pricing in May-Oct 2013</p></div></div><p style="clear:both; height: 1em;"> </p><p>The price of an option depends on the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Time to expiration of the option (time decay)</li><li class="listitem">The price of the underlying security</li><li class="listitem">The volatility of returns of the underlying asset</li></ul></div><p>The pricing <a id="id12150000" class="indexterm"/>model usually does not take into account the variation in trading volume of the underlying security. Therefore, it would be quite interesting to include it in our model. Let's define the state of an option using the following four normalized features:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Time decay</strong></span> (<code class="literal">timeToExp</code>): This is the time to expiration once normalized over [0, 1].</li><li class="listitem"><span class="strong"><strong>Relative volatility</strong></span> (<code class="literal">volatility</code>): This is the relative variation of the price of the underlying security within a trading session. It is different from the more complex volatility of returns defined in the Black-Scholes model, for example.</li><li class="listitem"><span class="strong"><strong>Volatility relative to volume</strong></span> (<code class="literal">vltyByVol</code>): This is the relative volatility of the price of the security adjusted for its trading volume.</li><li class="listitem"><span class="strong"><strong>Relative difference between the current price and strike price</strong></span> (<code class="literal">priceToStrike</code>): This measures the ratio of the difference between price and strike price to the strike price.</li></ul></div><p>The following graph shows the four normalized features for the IBM option strategy:</p><div class="mediaobject"><img src="../Images/image01579.jpeg" alt="Option trading using Q-learning"/><div class="caption"><p>Normalized relative stock price volatility, volatility relative to trading volume, and price relative to strike price for the IBM stock</p></div></div><p style="clear:both; height: 1em;"> </p><p>The implementation <a id="id12160000" class="indexterm"/>of the <a id="id12170000" class="indexterm"/>option trading strategy using Q-learning consists of the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Describing the property of an option</li><li class="listitem">Defining the function approximation</li><li class="listitem">Specifying the constraints on the state transition</li></ol><div style="height:10px; width: 1px"/></div><div class="section" title="The OptionProperty class"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17800"/>The OptionProperty class</h3></div></div></div><p>Let's <a id="id12180000" class="indexterm"/>select <span class="emphasis"><em>N = 2</em></span> as the number <a id="id12190000" class="indexterm"/>of days in the future for our prediction. Any longer-term prediction is quite unreliable because it falls outside the constraint of the discrete Markov model. Therefore, the price of the option two days in the future is the value of the reward—profit or loss.</p><p>The <code class="literal">OptionProperty</code> class encapsulates the four attributes of an option (line <code class="literal">45</code>) as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>OptionProperty</strong></span>(timeToExp: Double, volatility: Double, 
     vltyByVol: Double, priceToStrike: Double) { //<span class="strong"><strong>45</strong></span>

  val toArray = Array[Double](
     timeToExp, volatility, vltyByVol, priceToStrike
  )
}</pre></div><div class="note" title="Note"><h3 class="title"><a id="note33700"/>Note</h3><p>
<span class="strong"><strong>A modular design</strong></span>
</p><p>The implementation avoids subclassing the <code class="literal">QLState</code> class to define the features of our option pricing model. The state of the option is a parameterized <code class="literal">prop</code> parameter for the state class.</p></div></div><div class="section" title="The OptionModel class"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec17900"/>The OptionModel class</h3></div></div></div><p>The <code class="literal">OptionModel</code> class <a id="id12200000" class="indexterm"/>is a container <a id="id12210000" class="indexterm"/>and a factory for the properties of the option. It creates the list of <code class="literal">propsList</code> option properties by accessing the data source of the four features introduced earlier. It takes the following parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The symbol of the security.</li><li class="listitem">The strike price for the <code class="literal">strikePrice</code> option.</li><li class="listitem">The source of data, <code class="literal">src</code>.</li><li class="listitem">The minimum time decay or time to expiration, <code class="literal">minTDecay</code>. Out-of-the-money options expire worthless and in-the-money options have very different price behavior as they get closer to the expiration date (refer to the <span class="emphasis"><em>Options trading</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>). Therefore, the last <code class="literal">minTDecay</code> trading sessions prior to the expiration date are not used in the training of the model.</li><li class="listitem">The number of steps (or buckets), <code class="literal">nSteps</code>. It is used in approximating the values of each feature. For instance, an approximation of four steps creates four buckets [0, 25], [25, 50], [50, 75], and [75, 100].</li></ul></div><p>The implementation of the <code class="literal">OptionModel</code> class is as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>OptionModel</strong></span>(<span class="strong"><strong>symbol</strong></span>: String,  <span class="strong"><strong>strikePrice</strong></span>: Double, 
   <span class="strong"><strong>src</strong></span>: DataSource, <span class="strong"><strong>minExpT</strong></span>: Int, <span class="strong"><strong>nSteps</strong></span>: Int) {

  val propsList = (for {
    price &lt;- src.get(adjClose)
    volatility &lt;- src.get(volatility)
    nVolatility &lt;- normalize(volatility)
    vltyByVol &lt;- src.get(volatilityByVol)
    nVltyByVol &lt;- normalize(vltyByVol)
    priceToStrike &lt;- normalize(price.map(p =&gt; 
       (1.0 - strikePrice/p)))
  } yield {
    nVolatility.<span class="strong"><strong>zipWithIndex</strong></span>./:(List[OptionProperty]()){ //<span class="strong"><strong>46</strong></span>
      case(xs, (v,n)) =&gt; {
         val <span class="strong"><strong>normDecay</strong></span> = (n + minExpT).toDouble/
            (price.size + minExpT) //<span class="strong"><strong>47</strong></span>
         new OptionProperty(normDecay, v, nVltyByVol(n), 
           priceToStrike(n)) :: xs
      }
    }.drop(2).reverse  //<span class="strong"><strong>48</strong></span>
   })
  .getOrElse(List.empty[OptionProperty].)

  def <span class="strong"><strong>quantize</strong></span>(o: DblArray): Map[Array[Int], Double] 
}</pre></div><p>The factory <a id="id12220000" class="indexterm"/>uses the <code class="literal">zipWithIndex</code> Scala method to represent the index of the trading sessions (line <code class="literal">46</code>). All feature values are normalized over the interval [0, 1], including the time decay (or time to expiration) of the <code class="literal">normDecay</code> option (line <code class="literal">47</code>). The instantiation of the <code class="literal">OptionModel</code> class generates a list of <code class="literal">OptionProperty</code> elements if the constructor succeeds (line <code class="literal">48</code>), an empty list otherwise.</p></div><div class="section" title="Quantization"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18000"/>Quantization</h3></div></div></div><p>The four <a id="id12230000" class="indexterm"/>properties of the option are continuous values, normalized as a probability [0, 1]. The states in the Q-learning algorithm are discrete and require a quantization or categorization known as a <a id="id12240000" class="indexterm"/><span class="strong"><strong>function approximation</strong></span>; although a function approximation scheme can be quite elaborate [11:9]. Let's settle for a simple linear categorization, as illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01580.jpeg" alt="Quantization"/><div class="caption"><p>Quantization of the state of a traded option</p></div></div><p style="clear:both; height: 1em;"> </p><p>The function approximation defines the number of states. In this example, a function approximation that converts a normalized value into three intervals or buckets generates <span class="emphasis"><em>3<sup>4</sup> = 81</em></span> states or potentially <span class="emphasis"><em>3<sup>8</sup>-3<sup>4</sup></em></span>
<span class="emphasis"><em> = 6480</em></span> actions! The maximum number of states for <span class="emphasis"><em>l</em></span> buckets function approximation and <span class="emphasis"><em>n</em></span> features is <span class="emphasis"><em>l<sup>n</sup></em></span> with a maximum number of <span class="emphasis"><em>l<sup>2n</sup>-l<sup>n</sup></em></span> actions.</p><div class="note" title="Note"><h3 class="title"><a id="note33800"/>Note</h3><p>
<span class="strong"><strong>Quantization or function approximation guidelines</strong></span>
</p><p>The design of the function to approximate the state of options has to address the following two conflicting requirements:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Accuracy demands a fine-grained approximation</li><li class="listitem">Limited computation resources restrict the number of states, and therefore, level of approximation</li></ul></div></div><p>The <code class="literal">quantize</code> method <a id="id12250000" class="indexterm"/>of the <code class="literal">OptionModel</code> class converts the normalized value of each option property of features into an array of bucket indices. It returns a map of profit and loss for each bucket keyed on the array of bucket indices, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>quantize</strong></span>(o: DblArray): Map[Array[Int], Double] = {
  val <span class="strong"><strong>mapper</strong></span> = new mutable.HashMap[Int, Array[Int]] //<span class="strong"><strong>49</strong></span>
  val _acc = new <span class="strong"><strong>NumericAccumulator</strong></span>[Int] //<span class="strong"><strong>50</strong></span>
   
  val acc = propsList.view.map( _.toArray)
       .map( <span class="strong"><strong>toArrayInt</strong></span>( _ )) //<span class="strong"><strong>51</strong></span>
       .map(ar =&gt; { 
          val enc = <span class="strong"><strong>encode</strong></span>(ar)  //<span class="strong"><strong>52</strong></span>
          mapper.put(enc, ar)
          enc
       }).zip(o)
       ./:(_acc){ 
          case (acc, (t,y)) =&gt; { //<span class="strong"><strong>53</strong></span>
          acc += (t, y)
          acc 
       }}
   acc.map {case (k, (v,w)) =&gt; (k, v/w) }  //<span class="strong"><strong>54</strong></span>
     .map {case( k,v) =&gt; (mapper(k), v) }.toMap
}</pre></div><p>The method creates a <code class="literal">mapper</code> instance to index the array of buckets (line <code class="literal">49</code>). An <code class="literal">acc</code> accumulator of the <code class="literal">NumericAccumulator</code> type extends <code class="literal">Map[Int, (Int, Double)]</code> and computes the tuple (number of occurrences of features on each buckets and the sum of increase or decrease of the option price) (line <code class="literal">50</code>). The <code class="literal">toArrayInt</code> method converts the value of each option property (<code class="literal">timeToExp</code>, <code class="literal">volatility</code>, and so on) into the index of the appropriate bucket (line <code class="literal">51</code>). The array of indices is then encoded (line <code class="literal">52</code>) to generate the <code class="literal">id</code> or index of a state. The method updates the accumulator with the number of occurrences and the total profit and loss for a trading session for the option (line <code class="literal">53</code>). It finally computes the reward on each action by averaging the profit and loss on each bucket (line <code class="literal">54</code>).</p><p>A view is used in the generation of the list of <code class="literal">OptionProperty</code> to avoid unnecessary object creation.</p><p>The source code for the <code class="literal">toArrayInt</code> and <code class="literal">encode</code> methods and <code class="literal">NumericAccumulator</code> is documented and available online.</p></div></div><div class="section" title="Putting it all together"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15100"/>Putting it all together</h2></div></div></div><p>The final piece <a id="id12260000" class="indexterm"/>of the puzzle is the code that configures and executes the Q-learning algorithm on one or several options on a security, IBM:</p><div class="informalexample"><pre class="programlisting">val STOCK_PRICES = "resources/data/chap11/IBM.csv"
val OPTION_PRICES = "resources/data/chap11/IBM_O.csv"
val QUANTIZER = 4
val src = DataSource(STOCK_PRICES, false, false, 1) //<span class="strong"><strong>55</strong></span>

val <span class="strong"><strong>model</strong></span> = for {
  option &lt;- Try(createOptionModel(src)) //<span class="strong"><strong>56</strong></span>
  oPrices &lt;- DataSource(OPTION_PRICES, false).extract //<span class="strong"><strong>57</strong></span>
   _model &lt;- createModel(<span class="strong"><strong>option</strong></span>, <span class="strong"><strong>oPrices</strong></span>) //<span class="strong"><strong>58</strong></span>
} yield <span class="strong"><strong>_model</strong></span>
</pre></div><p>The preceding implementation creates the Q-learning model with the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Extract the historical prices for the IBM stock by instantiating a data source, <code class="literal">src</code> (line <code class="literal">55</code>).</li><li class="listitem">Create an <code class="literal">option</code> model (line <code class="literal">56</code>).</li><li class="listitem">Extract the historical prices <code class="literal">oPrices</code> for option call $190 May 2014 (line <code class="literal">57</code>).</li><li class="listitem">Create the model, <code class="literal">_model</code>, with a <code class="literal">goalStr</code> predefined goal (line <code class="literal">58</code>).</li></ol><div style="height:10px; width: 1px"/></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">val STRIKE_PRICE = 190.0
val MIN_TIME_EXPIRATION = 6

def <span class="strong"><strong>createOptionModel</strong></span>(src: DataSource): OptionModel = 
   new OptionModel("IBM", STRIKE_PRICE, src, 
       MIN_TIME_EXPIRATION, QUANTIZER)</pre></div><p>Let's take a look at the <code class="literal">createModel</code> method that takes the option pricing model, <code class="literal">option,</code> and the historical prices for <code class="literal">oPrice</code> options as arguments:</p><div class="informalexample"><pre class="programlisting">val LEARNING_RATE = 0.2
val DISCOUNT_RATE = 0.7
val MAX_EPISODE_LEN = 128
val NUM_EPISODES = 80

def <span class="strong"><strong>createModel</strong></span>(option: OptionModel, <span class="strong"><strong>oPrices</strong></span>: DblArray,
     alpha: Double, gamma: Double): Try[QLModel] = Try {

  val qPriceMap = option.quantize(oPrices) //<span class="strong"><strong>59</strong></span>
  val numStates = qPriceMap.size

  val <span class="strong"><strong>qPrice</strong></span> = qPriceMap.values.toVector //<span class="strong"><strong>60</strong></span>
  val profit= zipWithShift(qPrice,1).map{case(x,y) =&gt; y -x}//<span class="strong"><strong>61</strong></span>
  val <span class="strong"><strong>maxProfitIndex</strong></span> = profit.zipWithIndex.maxBy(_._1)._2 //<span class="strong"><strong>62</strong></span>

  val <span class="strong"><strong>reward</strong></span> = (x: Double, y: Double) 
            =&gt; Math.exp(30.0*(y – x)) //<span class="strong"><strong>63</strong></span>
  val <span class="strong"><strong>probability</strong></span> = (x: Double, y: Double) =&gt; 
         if(y &lt; 0.3*x) 0.0 else 1.0  //<span class="strong"><strong>64</strong></span>

  if( !validateConstraints(profit.size, neighbors)) //<span class="strong"><strong>65</strong></span> 
      throw new IllegalStateException(" ... ")

  val config = QLConfig(alpha, gamma, 
     MAX_EPISODE_LEN, NUM_EPISODES) //<span class="strong"><strong>66</strong></span>
  val instances = qPriceMap.keySet.toSeq.drop(1)
  QLearning[Array[Int]](config, Array[Int](maxProfitIndex), 
     profit, reward, probability, 
     instances, Some(neighbors)).getModel //<span class="strong"><strong>67</strong></span>
}</pre></div><p>The method <a id="id12270000" class="indexterm"/>quantizes the option prices map, <code class="literal">oPrices</code> (line <code class="literal">59</code>), extracts the historical option prices, <code class="literal">qPrice</code> (line <code class="literal">60</code>), computes the profit as the difference in the price of the option between two consecutive trading sessions (line <code class="literal">61</code>), and computes the index, <code class="literal">maxProfitIndex,</code> of the trading session with the highest profile (line <code class="literal">62</code>). The state with the <code class="literal">maxProfitIndex</code> index is selected as the goal.</p><p>The input matrix is automatically generated using the <code class="literal">reward</code> and <code class="literal">probability</code> functions. The <code class="literal">reward</code> function rewards the state transition proportionally to the profit (line <code class="literal">63</code>). The <code class="literal">probability</code> function punishes the state transition for which the loss <span class="emphasis"><em>y – x</em></span> is greater than <span class="emphasis"><em>0.3*x</em></span> by setting the probability value to <code class="literal">0</code> (line <code class="literal">64</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note33900"/>Note</h3><p>
<span class="strong"><strong>Initialization of rewards and probabilities</strong></span>
</p><p>In our example, the reward and probability matrices are automatically generated through two functions. An alternative approach consists of initializing these two matrices using either historical data or educated guesses.</p></div><p>The <code class="literal">validateConstraints</code> method of the <code class="literal">QLearning</code> companion object validates the <code class="literal">neighbors</code> constraints function, as described in the <span class="emphasis"><em>The validation</em></span> section (line <code class="literal">65</code>).</p><p>The last two steps consists <a id="id12280000" class="indexterm"/>of creating a configuration, <code class="literal">config,</code> for the Q-learning algorithm (line <code class="literal">66</code>) and training the model by instantiating the <code class="literal">QLearning</code> class with the appropriate parameters, including the <code class="literal">neighbors</code> method that defines the neighboring states for any given state (line <code class="literal">67</code>). The <code class="literal">neighbors</code> method is described in the documented source code available online.</p><div class="note" title="Note"><h3 class="title"><a id="note34000"/>Note</h3><p>
<span class="strong"><strong>The anti-goal state</strong></span>
</p><p>The goal state is the state with the highest assigned reward. It is a heuristic to reward a strategy for a good performance. However, it is conceivable and possible to define an anti-goal state with the highest assigned penalty or the lowest assigned reward to guide the search away from some condition.</p></div></div><div class="section" title="Evaluation"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15200"/>Evaluation</h2></div></div></div><p>Besides the <a id="id12290000" class="indexterm"/>function approximation, the size of the training set has an impact on the number of states. A well-distributed or large training set provides at least one value for each bucket created by the approximation. In this case, the training set is quite small and only 34 out of 81 buckets have actual values. As result, the number of states is 34. The initialization of the Q-learning model generates the following reward matrix:</p><div class="mediaobject"><img src="../Images/image01581.jpeg" alt="Evaluation"/><div class="caption"><p>The reward matrix for the option-pricing Q-learning strategy</p></div></div><p style="clear:both; height: 1em;"> </p><p>The graph visualizes the distribution of the rewards computed from the profit and loss of the option. The <span class="emphasis"><em>xy</em></span> plane represents the actions between states. The states' IDs are listed on <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> axes. The <span class="emphasis"><em>z</em></span> axis measures the actual value of the reward associated with each action.</p><p>The reward reflects the fluctuation in the price of the option. The price of an option has a higher volatility than the price of the underlying security.</p><p>The <span class="emphasis"><em>xy</em></span> reward matrix <span class="emphasis"><em>R</em></span> is rather highly distributed. Therefore, we select a small value for the learning rate <span class="emphasis"><em>0.2</em></span> to reduce the impact of the previous state on the new state. The value for the discount rate <span class="emphasis"><em>0.7</em></span> accommodates the fact that the number of states is limited. There is no reason to compute the future discounted reward using a long sequence of states. The training of the policies generates the following action-value matrix <span class="emphasis"><em>Q</em></span> of 34 states by 34 states after the first episode:</p><div class="mediaobject"><img src="../Images/image01582.jpeg" alt="Evaluation"/><div class="caption"><p>The Q action-value matrix for the first episode (epoch)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The distribution <a id="id12300000" class="indexterm"/>of the action-values between states at the end of the first episode reflects the distribution of the reward across state-to-state action. The first episode consists of a sequence of nine states from an initial randomly selected state to the goal state. The action-value map is compared to the map generated after 20 episodes in the following graph:</p><div class="mediaobject"><img src="../Images/image01583.jpeg" alt="Evaluation"/><div class="caption"><p>The Q Action-Value matrix for the last episode (epoch)</p></div></div><p style="clear:both; height: 1em;"> </p><p>The action-value map at the end of the last episode shows some clear patterns. Most of the rewarding actions transition from a large number of states (<span class="emphasis"><em>X</em></span> axis) to a smaller number of states (<span class="emphasis"><em>Y</em></span> axis). The chart illustrates the following issues with the small training sample:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The small size of the training set forces us to use an approximate representation of each feature. The purpose is to increase the odds that most buckets have, that is, at least one data point.</li><li class="listitem">However, a loose function approximation or quantization tends to group quite different states into the same bucket.</li><li class="listitem">The bucket with a very low number can potentially mischaracterize one property or feature of a state.</li></ul></div><p>The next test is to display the profile of the log of the Q-value (<code class="literal">QLData.value</code>) as the recursive search (or training) progress for different episodes or epochs. The test uses a learning rate <span class="emphasis"><em>α = 0.1</em></span> and a discount rate <span class="emphasis"><em>γ = 0.9</em></span>.</p><div class="mediaobject"><img src="../Images/image01584.jpeg" alt="Evaluation"/><div class="caption"><p>The profile of the log (Q-Value) for different epochs during Q-learning training</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding <a id="id12310000" class="indexterm"/>chart illustrates the fact that the Q-value for each profile is independent of the order of the epochs during training. However, the length of the profile (or number of iterations to reach the goal state) depends on the initial state, which is selected randomly, in this example.</p><p>The last test consists of evaluating the impact of the learning rate and discount rate on the coverage of the training:</p><div class="mediaobject"><img src="../Images/image01585.jpeg" alt="Evaluation"/><div class="caption"><p>Training coverage versus learning rate and discount rate</p></div></div><p style="clear:both; height: 1em;"> </p><p>The coverage (percentage of an episode or epoch for which the goal state is reached) decreases as the learning rate increases. The result confirms the general rule of using learning rate &lt; 0.2. The similar test to evaluate the impact of the discount rate on the coverage is inconclusive.</p></div><div class="section" title="Pros and cons of reinforcement learning"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15300"/>Pros and cons of reinforcement learning</h2></div></div></div><p>Reinforcement learning <a id="id12320000" class="indexterm"/>algorithms are ideal for the following problems:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Online learning</li><li class="listitem">The training data is small or nonexistent</li><li class="listitem">A model is nonexistent or poorly defined</li><li class="listitem">Computation resources are limited</li></ul></div><p>However, these <a id="id12330000" class="indexterm"/>techniques perform poorly in the following cases:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The search space (number of possible actions) is large because the maintenance of the states, action graph, and rewards matrix becomes challenging</li><li class="listitem">The execution is not always predictable in terms of scalability and performance</li></ul></div></div></div></div>
<div class="section" title="Learning classifier systems"><div class="titlepage" id="aid-6IOCA2"><div><div><h1 class="title"><a id="ch11lvl1sec7500"/>Learning classifier systems</h1></div></div></div><p>J. Holland <a id="id12340000" class="indexterm"/>introduced the concept of <span class="strong"><strong>learning classifier systems</strong></span> (<span class="strong"><strong>LCS</strong></span>) more than 30 years ago as an extension to evolutionary computing [11:10].</p><p>Learning classifier systems are a kind of rule-based system with general mechanisms for processing rules in parallel, for adaptive generation of new rules, and for testing the effectiveness of new rules.</p><p>However, the concept started to get the attention of computer scientists only a few years ago, with the introduction of several variants of the original concept, including <span class="strong"><strong>extended learning classifiers</strong></span> (<span class="strong"><strong>XCS</strong></span>). Learning classifier systems are interesting because they combine rules, reinforcement learning, and genetic algorithms.</p><div class="note" title="Note"><h3 class="title"><a id="note34100"/>Note</h3><p>
<span class="strong"><strong>Disclaimer</strong></span>
</p><p>The implementation of the extended learning classifier is presented for informational purposes only. Validating XCS against a known and labeled population of rules is a very significant endeavor. The source code snippet is presented only to illustrate the different components of the XCS algorithm.</p></div><div class="section" title="Introduction to LCS"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15400"/>Introduction to LCS</h2></div></div></div><p>Learning classifier systems <a id="id12350000" class="indexterm"/>merge the concepts of reinforcement learning, rule-based policies, and evolutionary computing. This unique class of learning algorithms represents the merger of the following research fields [11:11]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Reinforcement learning</li><li class="listitem">Genetic algorithms and evolutionary computing</li><li class="listitem">Supervised learning</li><li class="listitem">Rule-based knowledge encoding</li></ul></div><p>Let's take a look at the following diagram:</p><div class="mediaobject"><img src="../Images/image01586.jpeg" alt="Introduction to LCS"/><div class="caption"><p>A diagram of the scientific disciplines required for learning classifier systems</p></div></div><p style="clear:both; height: 1em;"> </p><p>Learning classifier systems are an example of <a id="id12360000" class="indexterm"/><span class="strong"><strong>complex adaptive systems</strong></span>. A learning classifier system has the following four <a id="id12370000" class="indexterm"/>components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>A population of classifiers or rules</strong></span>: This evolves over time. In some cases, a domain expert creates a primitive set of rules (core knowledge). In other cases, the rules are randomly generated prior to the execution of the learning classifier system.</li><li class="listitem"><span class="strong"><strong>A genetic algorithm-based discovery engine</strong></span>: This generates new classifiers or rules from the existing population. This component is also known as the <span class="strong"><strong>rules discovery module</strong></span>. The rules rely on the same pattern of evolution of organisms introduced in the previous chapter. The rules are encoded as strings or bit strings to represent a condition (predicate) and action.</li><li class="listitem"><span class="strong"><strong>A performance or evaluation function</strong></span>: This measures the positive or negative impact of the actions from the fittest classifiers or policies.</li><li class="listitem"><span class="strong"><strong>A reinforcement learning component</strong></span>: This rewards or punishes the classifiers that contribute to the action, as seen in the previous section. The rules that contribute to an action that improves the performance of the system are <a id="id12380000" class="indexterm"/>rewarded, while those that degrade the performance of the system are punished. This component is also known as the credit assignment module.</li></ul></div></div><div class="section" title="Why LCS?"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15500"/>Why LCS?</h2></div></div></div><p>Learning classifier systems <a id="id12390000" class="indexterm"/>are particularly appropriate to problems in which the environment is constantly changing and are the combinations of a learning strategy and an evolutionary approach to build and maintain a knowledge base [11:12].</p><p>Supervised learning methods alone can be effective on large datasets, but they require either a significant amount of labeled data or a reduced set of features to avoid overfitting. Such constraints may not be practical in the case of ever-changing environments.</p><p>The last 20 years have seen the introduction of many variants of learning classifier systems that belong to the following two categories:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Systems for which accuracy is computed from the correct predictions and that apply the discovery to a subset of those correct classes. They incorporate elements of supervised learning to constrain the population of classifiers. These systems are known to follow the <a id="id12400000" class="indexterm"/><span class="strong"><strong>Pittsburgh approach</strong></span>.</li><li class="listitem">Systems that explore all the classifiers and apply rule accuracy to the genetic selection of the rules. Each individual classifier is a rule. These systems are known to follow the <a id="id12410000" class="indexterm"/><span class="strong"><strong>Michigan approach</strong></span>.</li></ul></div><p>The rest of this section is dedicated to the second type of learning classifiers—more specifically, extended learning classifier systems. In a context of LCS, the term <span class="emphasis"><em>classifier</em></span> refers to the predicate or rule generated by the system. From this point on, the term <span class="emphasis"><em>rule</em></span> replaces the term <span class="emphasis"><em>classifier</em></span> to avoid confusion with the more common definition of classification.</p></div><div class="section" title="Terminology"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15600"/>Terminology</h2></div></div></div><p>Each domain of <a id="id12420000" class="indexterm"/>research <a id="id12430000" class="indexterm"/>has its own terminology and LCS is no exception. The terminology of LCS consists of the following terms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Environment</strong></span>: These are the environment variables in the context of reinforcement learning.</li><li class="listitem"><span class="strong"><strong>Agent</strong></span>: An <a id="id12440000" class="indexterm"/>agent used in reinforcement learning.</li><li class="listitem"><span class="strong"><strong>Predicate</strong></span>: A <a id="id12450000" class="indexterm"/>clause or fact using the format, <span class="emphasis"><em>variable-operator-value</em></span>, and usually implemented as (operator, variable value); for example, <span class="emphasis"><em>Temperature-exceeds-87F</em></span> or <span class="emphasis"><em>('Temperature', 87F)</em></span>, <span class="emphasis"><em>Hard drive–failed</em></span> or <span class="emphasis"><em>('Status hard drive', FAILED)</em></span>, and so on. It is encoded as a gene in order to be processed by the genetic algorithm.</li><li class="listitem"><span class="strong"><strong>Compound predicate</strong></span>: This <a id="id12460000" class="indexterm"/>is the composition of several predicates and Boolean logic operators, which is usually implemented as a logical tree (for example, <span class="emphasis"><em>((predicate1 AND predicate2) OR predicate3</em></span> is implemented as <span class="emphasis"><em>OR (AND (predicated 1, predicate 2), predicate3)</em></span>. It uses a chromosome representation.</li><li class="listitem"><span class="strong"><strong>Action</strong></span>: This is a <a id="id12470000" class="indexterm"/>mechanism that alters the environment by modifying the value of one or several of its parameters using a format <span class="emphasis"><em>(type of action, target)</em></span>; for example, <span class="emphasis"><em>change thermostat settings</em></span>, <span class="emphasis"><em>replace hard drive</em></span>, and so on.</li><li class="listitem"><span class="strong"><strong>Rule</strong></span>: This is a <a id="id12480000" class="indexterm"/>formal first-order logic formula using the format <span class="emphasis"><em>IF compound predicate THEN sequence of action</em></span>; for example, <span class="emphasis"><em>IF gold price &lt; $1140 THEN sell stock of oil and gas producing companies</em></span>.</li><li class="listitem"><span class="strong"><strong>Classifier</strong></span>: This <a id="id12490000" class="indexterm"/>is a rule in the context of an LCS.</li><li class="listitem"><span class="strong"><strong>Rule fitness or score</strong></span>: This <a id="id12500000" class="indexterm"/>is identical to the definition of the fitness or score in the genetic algorithm. In the context of an LCS, it is the probability of a rule to be invoked and fired in response to the change in environment.</li><li class="listitem"><span class="strong"><strong>Sensors</strong></span>: These <a id="id12510000" class="indexterm"/>are environment variables monitored by an agent; for example, the temperature and hard drive status.</li><li class="listitem"><span class="strong"><strong>Input data stream</strong></span>: This <a id="id12520000" class="indexterm"/>is the flow of data generated by sensors. It is usually associated with online training.</li><li class="listitem"><span class="strong"><strong>Rule matching</strong></span>: This <a id="id12530000" class="indexterm"/>is a mechanism to match a predicate or compound predicate with a sensor.</li><li class="listitem"><span class="strong"><strong>Covering</strong></span>: This is <a id="id12540000" class="indexterm"/>the process of creating new rules to match a new condition (sensor) in the environment. It generates the rules by either using a random generator or mutating existing rules.</li><li class="listitem"><span class="strong"><strong>Predictor</strong></span>: This is <a id="id12550000" class="indexterm"/>an algorithm to find the action with the maximum number of occurrences within a set of matching rules.</li></ul></div></div><div class="section" title="Extended learning classifier systems"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15700"/>Extended learning classifier systems</h2></div></div></div><p>Similar to <a id="id12560000" class="indexterm"/>reinforcement learning, the XCS algorithm has an <a id="id12570000" class="indexterm"/><span class="strong"><strong>exploration</strong></span> phase and an <a id="id12580000" class="indexterm"/><span class="strong"><strong>exploitation</strong></span> phase. The exploitation process consists of leveraging the existing rules to influence the target environment in a profitable or rewarding manner:</p><div class="mediaobject"><img src="../Images/image01587.jpeg" alt="Extended learning classifier systems"/><div class="caption"><p>The exploitation component of the XCS algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following list <a id="id12590000" class="indexterm"/>describes each numbered block:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Sensors acquire new data or events from the system.</li><li class="listitem">Rules for which the condition matches the input event are extracted from the current population.</li><li class="listitem">A new rule is created if no match is found in the existing population. This process is known as covering.</li><li class="listitem">The chosen rules are ranked by their fitness values, and the rules with the highest predicted outcome are used to trigger the action.</li></ol><div style="height:10px; width: 1px"/></div><p>The purpose of exploration components is to increase the rule base as a population of the chromosomes that encode these rules.</p><div class="mediaobject"><img src="../Images/image01588.jpeg" alt="Extended learning classifier systems"/><div class="caption"><p>Exploration components of the XCS algorithm</p></div></div><p style="clear:both; height: 1em;"> </p><p>The following list <a id="id12600000" class="indexterm"/>describes each numbered block of the block diagram:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Once the action is performed, the system rewards the rules for which the action has been executed. The reinforcement learning module assigns credit to these rules.</li><li class="listitem">Rewards are used to update the rule fitness, applying evolutionary constraints to the existing population.</li><li class="listitem">The genetic algorithm updates the existing population of classifiers/rules using operators such as crossover and mutation.</li></ol><div style="height:10px; width: 1px"/></div></div><div class="section" title="XCS components"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15800"/>XCS components</h2></div></div></div><p>This section <a id="id12610000" class="indexterm"/>describes the <a id="id12620000" class="indexterm"/>key classes of the XCS. The implementation leverages the existing design of the genetic algorithm and the reinforcement learning. It is easier to understand the inner workings of the XCS algorithm with a concrete application.</p><div class="section" title="Application to portfolio management"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18100"/>Application to portfolio management</h3></div></div></div><p>Portfolio management <a id="id12630000" class="indexterm"/>and trading have benefited from the application of extended learning classifiers [11:13]. The use case is the management of a portfolio of exchange-traded funds in an ever-changing financial environment. Contrary to stocks, exchange-traded funds are representative of an industry-specific group of stocks or the financial market at large. Therefore, the price of these ETFs is affected by the following macroeconomic changes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Gross domestic product</li><li class="listitem">Inflation</li><li class="listitem">Geopolitical events</li><li class="listitem">Interest rates</li></ul></div><p>Let's select the value of the 10-year Treasury yield as a proxy for the macroeconomic conditions, for the sake of simplicity.</p><p>The portfolio has to be constantly adjusted in response to any specific change in the environment or market condition that affects the total value of the portfolio, and this can be done by referring to the following table:</p><div class="informaltable"><table border="1"><colgroup><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>XCS component</p>
</th><th valign="bottom">
<p>Portfolio management</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>Environment</p>
</td><td valign="top">
<p>This is the portfolio of securities defined by its composition, total value, and the yield of the 10-year Treasury bond</p>
</td></tr><tr><td valign="top">
<p>Action</p>
</td><td valign="top">
<p>This is the change in the composition of the portfolio</p>
</td></tr><tr><td valign="top">
<p>Reward</p>
</td><td valign="top">
<p>This is the profit and loss of the total value of the portfolio</p>
</td></tr><tr><td valign="top">
<p>Input data stream</p>
</td><td valign="top">
<p>This is the feed of the stock and bond price quotation</p>
</td></tr><tr><td valign="top">
<p>Sensor</p>
</td><td valign="top">
<p>This is the trading information regarding securities in the portfolio such as price, volume, volatility, yield, and the yield of the-10 year Treasury bond</p>
</td></tr><tr><td valign="top">
<p>Predicate</p>
</td><td valign="top">
<p>This is the change in the composition of the portfolio</p>
</td></tr><tr><td valign="top">
<p>Action</p>
</td><td valign="top">
<p>This rebalances a portfolio by buying and selling securities</p>
</td></tr><tr><td valign="top">
<p>Rule</p>
</td><td valign="top">
<p>This is the association of trading data with the rebalancing of a portfolio</p>
</td></tr></tbody></table></div><p>The first step <a id="id12640000" class="indexterm"/>is to create an initial set of rules regarding the portfolio. This initial set can be created randomly, like the initial population of a genetic algorithm or defined by a domain expert.</p><div class="note" title="Note"><h3 class="title"><a id="note34200"/>Note</h3><p>
<span class="strong"><strong>The XCS initial population</strong></span>
</p><p>Rules or classifiers are defined and/or refined through evolution. Therefore, there is no absolute requirement for the domain expert to set up a comprehensive knowledge base. In fact, rules can be randomly generated at the start of the training phase. However, seeding the XCS initial population with a few relevant rules improves the odds of having the algorithm converge quickly.</p></div><p>You are invited to initialize the population of rules with as many relevant and financially sound trading rules as possible. Over time, the execution of the XCS algorithm will confirm whether or not the initial rules are indeed appropriate. The following diagram describes the application of the XCS algorithm to the composition of a portfolio of ETFs, such as VWO, TLT, IWC, and so on, with the following components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The population of trading rules</li><li class="listitem">An algorithm to match rules and compute the prediction</li><li class="listitem">An algorithm to extract the actions sets</li><li class="listitem">The Q-learning module to assign a credit or reward to the selected rules</li><li class="listitem">The genetic algorithm to evolve the population of rules</li></ul></div><p>Let's take a look at the following diagram:</p><div class="mediaobject"><img src="../Images/image01589.jpeg" alt="Application to portfolio management"/><div class="caption"><p>An overview of the XCS algorithm to optimize the portfolio allocation</p></div></div><p style="clear:both; height: 1em;"> </p><p>The agent responds to the change in the allocation of ETFs in the portfolio by matching one of the existing rules.</p><p>Let's build the XCS agent from the ground.</p></div><div class="section" title="The XCS core data"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18200"/>The XCS core data</h3></div></div></div><p>There are three types of data that are manipulated by the XCS agent:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Signal</code>: This is the trading signal.</li><li class="listitem"><code class="literal">XcsAction</code>: This is the action on the environment. It subclasses a <code class="literal">Gene</code> defined in the genetic algorithm.</li><li class="listitem"><code class="literal">XcsSensor</code>: This is the sensor or data from the environment.</li></ul></div><p>The <code class="literal">Gene</code> class was introduced for the evaluation of the genetic algorithm in the <span class="emphasis"><em>Trading signals</em></span> section in <a class="link" title="Chapter 10. Genetic Algorithms" href="part0213.xhtml#aid-6B47Q1">Chapter 10</a>, <span class="emphasis"><em>Genetic Algorithms</em></span>. The agent creates, modifies, and deletes actions. It makes sense to define these actions as mutable genes, as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>XcsAction</strong></span>(sensorId: String, target: Double)
    (implicit quantize: Quantization, encoding: Encoding) //<span class="strong"><strong>1</strong></span>
    extends <span class="strong"><strong>Gene</strong></span>(sensorId, target, EQUAL)</pre></div><p>The quantization and encoding of the <code class="literal">XCSAction</code> into a <code class="literal">Gene</code> has to be explicitly declared (line <code class="literal">1</code>). The <code class="literal">XcsAction</code> class has the identifier of the <code class="literal">sensorId</code> sensor and the target value as parameters. For example, the action to increase the number of shares of ETF, VWO in the portfolio to 80 is defined as follows:</p><div class="informalexample"><pre class="programlisting">val vwoTo80 = new XcsAction("VWO", 80.0)</pre></div><p>The only type <a id="id12650000" class="indexterm"/>of action allowed in this scheme is setting a value using the <code class="literal">EQUAL</code> operator. You can create actions that support other operators such as <code class="literal">+=</code> used to increase an existing value. These operators need to implement the operator trait, as explained in the <span class="emphasis"><em>Trading operators</em></span> section in <a class="link" title="Chapter 10. Genetic Algorithms" href="part0213.xhtml#aid-6B47Q1">Chapter 10</a>, <span class="emphasis"><em>Genetic Algorithms</em></span>.</p><p>Finally, the <code class="literal">XcsSensor</code> class encapsulates the <code class="literal">sensorId</code> identifier for the variable and <code class="literal">value</code> of the sensor, as shown here:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>XcsSensor</strong></span>(val <span class="strong"><strong>sensorId</strong></span>: String, val <span class="strong"><strong>value</strong></span>: Double) 
val new10ytb = XcsSensor("10yTBYield", 2.76)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note34300"/>Note</h3><p>
<span class="strong"><strong>Setters and getters</strong></span>
</p><p>In this simplistic scenario, the sensors retrieve a new value from an environment variable. The action sets a new value to an environment variable. You can think of a sensor as a get method of an environment class and an action as a set method with variable/sensor ID and value as arguments.</p></div></div><div class="section" title="XCS rules"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18300"/>XCS rules</h3></div></div></div><p>The next step <a id="id12660000" class="indexterm"/>consists of defining a rule of the <code class="literal">XcsRule</code> type as a pair of two genes: a <code class="literal">signal</code> and an <code class="literal">action</code>, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>XcsRule</strong></span>(val <span class="strong"><strong>signal</strong></span>: Signal, val <span class="strong"><strong>action</strong></span>: XcsAction)</pre></div><p>The rule: <span class="emphasis"><em>r1: IF(yield 10-year TB &gt; 2.84%) THEN reduce VWO shares to 240</em></span> is implemented as follows:</p><div class="informalexample"><pre class="programlisting">val signal = new <span class="strong"><strong>Signal</strong></span>("10ytb", 2.84, GREATER_THAN) 
val action = new <span class="strong"><strong>XcsAction</strong></span>("vwo", 240) 
val r1 = new <span class="strong"><strong>XcsRule</strong></span>(signal, action)</pre></div><p>The agent encodes the rule as a chromosome using 2 bits to represent the operator and 32 bits for values, as shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01590.jpeg" alt="XCS rules"/></div><p style="clear:both; height: 1em;"> </p><p>In this <a id="id12670000" class="indexterm"/>implementation, there is no need to encode the type of action as the agent uses only one type of action—set. A complex action requires encoding of its type.</p><div class="note" title="Note"><h3 class="title"><a id="note34400"/>Note</h3><p>
<span class="strong"><strong>Knowledge encoding</strong></span>
</p><p>This example uses very simple rules with a single predicate as the condition. Real-world domain knowledge is usually encoded using complex rules with multiple clauses. It is highly recommended that you break down complex rules into multiple basic rules of classifiers.</p></div><p>Matching a rule to a new sensor consists of matching the sensor to the signal. The algorithm matches the new <code class="literal">new10ytb</code> sensor (line <code class="literal">2</code>) against the signal in the current population of <code class="literal">s10ytb1</code> (line <code class="literal">3</code>) and <code class="literal">s10ytb2</code> (line <code class="literal">4</code>) rules that use the same sensor or the <code class="literal">10ytb</code> variable as follows:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>new10ytb</strong></span> = new XcsSensor("10ytb", 2.76) //<span class="strong"><strong>2</strong></span>
val <span class="strong"><strong>s10ytb1</strong></span> = Signal("10ytb", 2.5, GREATER_THAN)  //<span class="strong"><strong>3</strong></span>
val <span class="strong"><strong>s10ytb2</strong></span> = Signal("10ytb", 2.2, LESS_THAN) //<span class="strong"><strong>4</strong></span>
</pre></div><p>In this case, the agent selects the <code class="literal">r23</code> rule but not <code class="literal">r34</code> in the existing population. The agent then adds the <code class="literal">act12</code> action to the list of possible actions. The agent lists all the rules that match the <code class="literal">r23</code>, <code class="literal">r11</code>, and <code class="literal">r46</code> sensors, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">val <span class="strong"><strong>r23</strong></span>: XcsRule(s10yTB1, act12) //<span class="strong"><strong>5</strong></span>
val <span class="strong"><strong>r11</strong></span>: XcsRule(s10yTB6, act6) 
val <span class="strong"><strong>r46</strong></span>: XcsRule(s10yTB7, act12) //<span class="strong"><strong>6</strong></span>
</pre></div><p>The action with the most references, <code class="literal">act12</code>, (lines <code class="literal">5</code> and <code class="literal">6</code>) is executed. The Q-learning algorithm computes the reward from the profit or loss incurred by the portfolio following the execution of the selected <code class="literal">r23</code> and <code class="literal">r46</code> rules. The agent uses the reward to adjust the fitness of <code class="literal">r23</code> and <code class="literal">r46</code>, before the genetic selection in the next reproduction cycle. These two rules will reach and stay in the top tier of the rules in the population, until either a new genetic rule modified through crossover and mutation or a rule created through covering, triggers a more rewarding action on the environment.</p></div><div class="section" title="Covering"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18400"/>Covering</h3></div></div></div><p>The purpose of the <a id="id12680000" class="indexterm"/>covering phase is to generate new rules if no rule matches the input or sensor. The <code class="literal">cover</code> method of an <code class="literal">XcsCover</code> singleton generates a new <code class="literal">XcsRule</code> instance given a sensor and an existing set of actions, as shown here:</p><div class="informalexample"><pre class="programlisting">val MAX_NUM_ACTIONS = 2048

def <span class="strong"><strong>cover</strong></span>(sensor: XcsSensor, actions: List[XcsAction])
   (implicit quant: Quantization, encoding: Encoding): 
   List[XcsRule] = 

  actions./:(List[XcsRule]()) ((xs, act) =&gt; {
    val signal = Signal(sensor.id, sensor.value, 
       new SOperator(Random.nextInt(Signal.numOperators)))
    new XcsRule(signal, XcsAction(act, Random)) :: xs
  })
}</pre></div><p>You might wonder why the <code class="literal">cover</code> method uses a set of actions as arguments knowing that covering consists of creating new actions. The method mutates (<code class="literal">^</code> operator) an existing action to create a new one instead of using a random generator. This is one of the advantages of defining an action as a gene. One of the constructors of <code class="literal">XcsAction</code> executes the mutation, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>(action: XcsAction, r: Random): XcsAction = 
   (action <span class="strong"><strong>^</strong></span> r.nextInt(XCSACTION_SIZE))</pre></div><p>The index of the operator <code class="literal">r</code> type is a random value in the interval [0, 3] because a signal uses four types of operators: <code class="literal">None</code>, <code class="literal">&gt;</code>, <code class="literal">&lt;</code>, and <code class="literal">=</code>.</p></div><div class="section" title="An implementation example"><div class="titlepage"><div><div><h3 class="title"><a id="ch11lvl3sec18500"/>An implementation example</h3></div></div></div><p>The <code class="literal">Xcs</code> class <a id="id12690000" class="indexterm"/>has the following purposes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">gaSolver</code>: This is the selection and generation of genetically modified rules</li><li class="listitem"><code class="literal">qlLearner</code>: This is the rewarding and scoring the rules</li><li class="listitem"><code class="literal">Xcs</code>: These are the rules for matching, covering, and generation of actions</li></ul></div><p>The extended learning classifier is a data transformation of the <code class="literal">ETransform</code> type with an explicit configuration of the <code class="literal">XcsConfig</code> type (line <code class="literal">8</code>) (refer to the <span class="emphasis"><em>Monadic data transformation</em></span> section in C<a class="link" title="Chapter 2. Manipulating Data with Breeze" href="part0018.xhtml#aid-H5A41">hapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Xcs</strong></span>(config: XcsConfig, 
    <span class="strong"><strong>population</strong></span>: Population[Signal], 
    <span class="strong"><strong>score</strong></span>: Chromosome[Signal]=&gt; Unit, 
    <span class="strong"><strong>input</strong></span>: Array[QLInput])  //7
      extends <span class="strong"><strong>ETransform</strong></span>[XcsConfig](config) { //<span class="strong"><strong>8</strong></span>
  
  type <span class="strong"><strong>U</strong></span> = XcsSensor   //<span class="strong"><strong>9</strong></span>
  type <span class="strong"><strong>V</strong></span> = List[XcsAction]   //<span class="strong"><strong>10</strong></span>

   val solver = GASolver[Signal](config.gaConfig,score) 
   val features = population.chromosomes.toSeq
   val qLearner = QLearning[Chromosome[Signal]]( //<span class="strong"><strong>11</strong></span>
      config.qlConfig, extractGoals(input), input, features)
   override def |&gt; : PartialFunction[U, Try[V]]
   ...
}</pre></div><p>The XCS algorithm is initialized with a configuration <code class="literal">config</code>, an initial set of rules <code class="literal">population</code>, a fitness function <code class="literal">score</code>, and an <code class="literal">input</code> to the Q-learning policy generate reward matrix for <code class="literal">qlLearner</code> (line <code class="literal">7</code>). Being an explicit data transformation, the <code class="literal">U</code> type of an input element and the <code class="literal">V</code> type of the output element to the <code class="literal">|&gt;</code> predictor are initialized as <code class="literal">XcsSensor</code> (line <code class="literal">9</code>) and <code class="literal">List[XcsAction]</code> (line <code class="literal">10</code>).</p><p>The goals and <a id="id12700000" class="indexterm"/>number of states are extracted from the input to the policy of the Q-learning algorithm.</p><p>In this implementation, the <code class="literal">solver</code> generic algorithm is mutable. It is instantiated along with the <code class="literal">Xcs</code> container class. The Q-learning algorithm uses the same design, as any classifier, as immutable. The model of Q-learning is the best possible policy to reward rules. Any changes in the number of states or the rewarding scheme require a new instance of the learner.</p></div></div><div class="section" title="Benefits and limitations of learning classifier systems"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lvl2sec15900"/>Benefits and limitations of learning classifier systems</h2></div></div></div><p>Learning classifier systems <a id="id12710000" class="indexterm"/>and XCS in particular, hold many promises, which are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">They allow nonscientists and domain experts to describe the knowledge using familiar Boolean constructs and inferences such as predicates and rules</li><li class="listitem">They provide analysts with an overview of the knowledge base and its coverage <a id="id12720000" class="indexterm"/>by distinguishing between the need for exploration and exploitation of the knowledge base</li></ul></div><p>However, the <a id="id12730000" class="indexterm"/>scientific community has been slow to recognize the merits of these techniques. The wider adoption of learning classifier systems is hindered by the following factors:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The large number of parameters used in both exploration and exploitation phases adds to the sheer complexity of the algorithm.</li><li class="listitem">There are too many competitive variants of learning classifier systems</li><li class="listitem">There is no clear unified theory to validate the concept of evolutionary policies or rules. After all, these algorithms are the merger of standalone techniques. The accuracy and performance of the execution of many variants of the learning classifier systems depend on each component as well as the interaction between components.</li><li class="listitem">An execution that is not always predictable in terms of scalability and performance.</li></ul></div></div></div>
<div class="section" title="Summary" id="aid-6JMSS1"><div class="titlepage"><div><div><h1 class="title"><a id="ch11lvl1sec7600"/>Summary</h1></div></div></div><p>The software engineering community sometimes overlooks reinforcement learning algorithms. Let's hope that this chapter provides adequate answers to the following questions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">What is reinforcement learning?</li><li class="listitem">What are the different types of algorithms that qualify as reinforcement learning?</li><li class="listitem">How can we implement the Q-learning algorithm in Scala?</li><li class="listitem">How can we apply Q-learning to the optimization of option trading?</li><li class="listitem">What are the pros and cons of using reinforcement learning?</li><li class="listitem">What are learning classifier systems?</li><li class="listitem">What are the key components of the XCS algorithm?</li><li class="listitem">What are the potentials and limitations of learning classifier systems?</li></ul></div><p>This concludes the introduction of the last category of learning techniques. The ever-increasing amount of data that surrounds us requires data processing and machine learning algorithms to be highly scalable. This is the subject of the next and the final chapter.</p></div>
<div class="chapter" title="Chapter&#xA0;12.&#xA0;Scalable Frameworks" id="aid-6KLDE1"><div class="titlepage"><div><div><h1 class="title"><a id="ch26"/>Chapter 12. Scalable Frameworks</h1></div></div></div><p>The advent of social networking, interactive media, and deep analysis has caused the amount of data processed daily to skyrocket. For data scientists, it's no longer just a matter of finding the most appropriate and accurate algorithm to mine data; it is also about leveraging multi-core CPU architectures and distributed computing frameworks to solve problems in a timely fashion. After all, how valuable is a data mining application if the model does not scale?</p><p>There are many options available to Scala developers to build classification and regression applications for very large datasets. This chapter covers the Scala parallel collections, Actor model, Akka framework, and Apache Spark in-memory clusters. The following topics are covered in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">An introduction to Scala parallel collections</li><li class="listitem">Evaluation of performance of a parallel collection on multi-core CPUs</li><li class="listitem">The actor model and reactive systems</li><li class="listitem">Clustered and reliable distributed computing using Akka</li><li class="listitem">A design of the computational workflow using Akka routers</li><li class="listitem">An introduction to Apache Spark clustering and its design principles</li><li class="listitem">Using Spark MLlib for clustering</li><li class="listitem">Relative performance tuning and evaluation of Spark</li><li class="listitem">Benefits and limitations of the Apache Spark framework</li></ul></div><div class="section" title="An overview"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec7700"/>An overview</h1></div></div></div><p>The support<a id="id12740000" class="indexterm"/> for distributing and concurrent processing is provided by different stacked frameworks and libraries. Scala concurrent and parallel collections' classes leverage the threading capabilities of the Java virtual machine. <span class="strong"><strong>Akka.io</strong></span> <a id="id12750000" class="indexterm"/>implements a reliable action model originally introduced as part of the Scala standard library. The Akka framework<a id="id12760000" class="indexterm"/> supports remote actors, routing, load balancing protocols, dispatchers, clusters, events, and configurable mailbox management. This framework also provides support for different transport modes, supervisory strategies, and typed actors. Apache Spark's resilient distributed datasets with advanced serialization, caching, and partitioning capabilities leverage Scala and Akka libraries.</p><p>The following stack <a id="id12770000" class="indexterm"/>representation illustrates the interdependencies between frameworks:</p><div class="mediaobject"><img src="../Images/image01591.jpeg" alt="An overview"/><div class="caption"><p>The Stack representation of scalable frameworks using Scala</p></div></div><p style="clear:both; height: 1em;"> </p><p>Each layer adds a new functionality to the previous one to increase scalability. The Java virtual machine runs as a process within a single host. Scala concurrent classes support effective deployment of an application by leveraging multicore CPU capabilities without the need to write multithreaded applications. Akka extends the Actor paradigm to clusters with advanced messaging and routing options. Finally, Apache Spark leverages Scala higher-order collection methods and the Akka implementation of the Actor model to provide large-scale data processing systems with better performance and reliability, through its resilient distributed datasets and in-memory persistency.</p></div></div>
<div class="section" title="Scala"><div class="titlepage" id="aid-6LJU02"><div><div><h1 class="title"><a id="ch12lvl1sec7800"/>Scala</h1></div></div></div><p>The <a id="id12780000" class="indexterm"/>Scala standard library offers a rich set of tools, such as parallel collections and concurrent classes to scale number-crunching applications. Although these tools are very effective in processing medium-sized datasets, they are unfortunately quite often discarded by developers in favor of more elaborate frameworks.</p><div class="section" title="Object creation"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16000"/>Object creation</h2></div></div></div><p>Although <a id="id12790000" class="indexterm"/>code optimization and memory management is beyond the scope of this chapter, it is worthwhile to remember that a few simple steps can be taken to improve the scalability of an application. One of the most frustrating challenges in using Scala to process large datasets is the creation of a large number of objects and the load on the garbage collector.</p><p>A partial list of remedial actions is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Limiting unnecessary duplication of objects in an iterated function using a mutable instance</li><li class="listitem">Using lazy values and <span class="strong"><strong>Stream</strong></span> classes to create objects as needed</li><li class="listitem">Leveraging efficient collections such as <span class="strong"><strong>bloom filters</strong></span> or <span class="strong"><strong>skip lists</strong></span></li><li class="listitem">Running <code class="literal">javap</code> to decipher the generation of byte code by the JVM</li></ul></div></div><div class="section" title="Streams"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16100"/>Streams</h2></div></div></div><p>Some problems<a id="id12800000" class="indexterm"/> require the preprocessing and training of very large datasets, resulting on significant memory consumption by the JVM. Streams are list-like collections in which elements are instantiated or computed lazily. Streams share the same goal of postponing computation and memory allocation as views.</p><p>Let's consider the computation of the loss function in machine learning. An observation of the <code class="literal">DataPoint</code> type is defined as a features vector, <code class="literal">x</code>, and a labeled or expected value, <code class="literal">y</code>:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>DataPoint</strong></span>(x: DblVector, y: Double)</pre></div><p>We can create a loss function, <code class="literal">LossFunction</code>, that processes a very large dataset on a platform with limited memory. The optimizer responsible for the minimization of the loss or error invokes the loss function at each iteration or recursion, as described in the following diagram:</p><div class="mediaobject"><img src="../Images/image01592.jpeg" alt="Streams"/><div class="caption"><p>An illustration of Scala streams allocation and release</p></div></div><p style="clear:both; height: 1em;"> </p><p>The constructor <a id="id12810000" class="indexterm"/>of the <code class="literal">LossFunction</code> class has the following three arguments (line <code class="literal">2</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The computation <code class="literal">f</code> of the loss for each data point</li><li class="listitem">The <code class="literal">weights</code> of the model</li><li class="listitem">The size of the entire stream <code class="literal">dataSize</code></li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting">type StreamLike = <span class="strong"><strong>WeakReference</strong></span>[Stream[DataPoint]] //<span class="strong"><strong>1</strong></span>
class <span class="strong"><strong>LossFunction</strong></span>(
    <span class="strong"><strong>f</strong></span>: (DblVector, DblVector) =&gt; Double,
    <span class="strong"><strong>weights</strong></span>: DblVector, 
    <span class="strong"><strong>dataSize</strong></span>: Int) {  //<span class="strong"><strong>2</strong></span>

  var nElements = 0
  def compute(stream: () =&gt; StreamLike): Double = 
      compute(stream().get, 0.0)  //<span class="strong"><strong>3</strong></span>

  def _loss(xs: List[DataPoint]): Double = xs.map(
    dp =&gt; dp.y - f(weights, dp.x)).map( sqr(_)).sum //<span class="strong"><strong>4</strong></span>
}</pre></div><p>The loss function for the stream is implemented as the <code class="literal">compute</code> tail recursion (line <code class="literal">3</code>). The recursive method updates the reference of the stream. The type of reference of the stream is <code class="literal">WeakReference</code> (line <code class="literal">1</code>), so the garbage collection can reclaim the memory associated with the slice for which the loss has been computed. In this example, the loss function is computed as a sum of squared errors (line <code class="literal">4</code>).</p><p>The <code class="literal">compute</code> method manages the allocation and release of slices of stream:</p><div class="informalexample"><pre class="programlisting">@<span class="strong"><strong>tailrec</strong></span>
def <span class="strong"><strong>compute</strong></span>(stream: Stream[DataPoint], loss: Double): Double = {
  if( nElements &gt;= dataSize)  loss
  else {
    val step = if(nElements + STEP &gt; dataSize) 
             dataSize - nElements else STEP
    nElements += step
    val newLoss = _loss(stream.<span class="strong"><strong>take</strong></span>(step).toList) //<span class="strong"><strong>5</strong></span>
    <span class="strong"><strong>compute</strong></span>( stream.<span class="strong"><strong>drop</strong></span>(STEP), loss + newLoss ) //<span class="strong"><strong>6</strong></span>
  }
 }</pre></div><p>The dataset is <a id="id12820000" class="indexterm"/>processed in two steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The driver allocates (that is, <code class="literal">take</code>) a slice of the stream of observations and then computes the cumulative loss for all the observations in the slice (line <code class="literal">5</code>)</li><li class="listitem">Once the computation of the loss for the slice is completed, the memory allocated to the weak reference is released (that is, <code class="literal">drop</code>) (line <code class="literal">6</code>)</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note34500"/>Note</h3><p>
<span class="strong"><strong>An alternative to weak references</strong></span>
</p><p>There are alternatives to weak references in order for the stream to force the garbage collector to reclaim the memory blocks associated with each slice of observations, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Define the stream reference as <code class="literal">def</code></li><li class="listitem">Wrap the reference into a method; the reference is then accessible to the garbage collector when the wrapping method returns</li><li class="listitem">Use a <code class="literal">List</code> iterator</li></ul></div></div><p>The average memory allocated during the execution of the loss function for the entire stream is the memory needed to allocate a single slice.</p></div><div class="section" title="Parallel collections"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16200"/>Parallel collections</h2></div></div></div><p>The <a id="id12830000" class="indexterm"/>Scala standard library includes parallelized collections, whose purpose is to shield developers from the intricacies of concurrent thread execution and race condition. Parallel collections are a very convenient approach to encapsulate concurrency constructs to a higher level of abstraction [12:1].</p><p>There are two ways to create parallel collections in Scala, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Converting an existing collection into a parallel collection of the same semantic using the <code class="literal">par</code> method; for example, <code class="literal">List[T].par: ParSeq[T]</code>, <code class="literal">Array[T].par: ParArray[T]</code>, <code class="literal">Map[K,V].par: ParMap[K,V]</code>, and so on</li><li class="listitem">Using the collection classes from the <code class="literal">collection.parallel</code>, <code class="literal">parallel</code>. <code class="literal">immutable</code>, or <code class="literal">parallel.mutable</code> packages; for example, <code class="literal">ParArray</code>, <code class="literal">ParMap</code>, <code class="literal">ParSeq</code>, <code class="literal">ParVector</code>, and so on</li></ul></div><div class="section" title="Processing a parallel collection"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec18600"/>Processing a parallel collection</h3></div></div></div><p>A parallel collection<a id="id12840000" class="indexterm"/> does lend itself to concurrent processing until a pool of threads and a task scheduler are assigned to it. Fortunately, Scala parallel and concurrent packages provide developers with a powerful toolbox to map partitions or segments of collection to tasks running on different CPU cores. The components are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">TaskSupport</code>: This<a id="id12850000" class="indexterm"/> trait inherits the generic <code class="literal">Tasks</code> trait. It is responsible for scheduling the operation on the parallel collection. There are three concrete implementations of <code class="literal">TaskSupport</code>.</li><li class="listitem"><code class="literal">ThreadPoolTaskSupport</code>: This <a id="id12860000" class="indexterm"/>uses the threads pool in an older version of the JVM.</li><li class="listitem"><code class="literal">ExecutionContextTaskSupport</code>: This <a id="id12870000" class="indexterm"/>uses <code class="literal">ExecutorService</code> that delegates the management of tasks to either a thread pool or the <code class="literal">ForkJoinTasks</code> pool.</li><li class="listitem"><code class="literal">ForkJoinTaskSupport</code>: This <a id="id12880000" class="indexterm"/>uses the fork-join pools of the <code class="literal">java.util. concurrent.FortJoinPool</code> type introduced in the Java SDK 1.6. In Java, a <span class="strong"><strong>fork-join pool</strong></span> <a id="id12890000" class="indexterm"/>is an instance of <code class="literal">ExecutorService</code> that attempts to run not only the current task but also any of its subtasks. It executes the <code class="literal">ForkJoinTask</code> instances that are lightweight threads.</li></ul></div><p>The following example implements the generation of a random exponential value using a parallel vector and <code class="literal">ForkJoinTaskSupport</code>:</p><div class="informalexample"><pre class="programlisting">val rand = new ParVector[Float]
Range(0,MAX).foreach(n =&gt; rand.updated(n, n*Random.nextFloat))//<span class="strong"><strong>1</strong></span>
rand.tasksupport = new ForkJoinTaskSupport(new ForkJoinPool(16)) 
val randExp = vec.map( Math.exp(_) ) //<span class="strong"><strong>2</strong></span>
</pre></div><p>The <code class="literal">rand</code> parallel vector of random probabilities is created and initialized by the main task (line <code class="literal">1</code>), but the conversion to a vector of a <code class="literal">randExp</code> exponential value is executed by a pool of 16 concurrent tasks (line <code class="literal">2</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note34600"/>Note</h3><p>
<span class="strong"><strong>Preserving the order of elements</strong></span>
</p><p>Operations that traverse a parallel collection using an iterator preserve the original order of the element of the collection. Iterator-less methods such as <code class="literal">foreach</code> or <code class="literal">map</code> do not guarantee that the order of the elements that are processed will be preserved.</p></div></div><div class="section" title="The benchmark framework"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec18700"/>The benchmark framework</h3></div></div></div><p>The <a id="id12900000" class="indexterm"/>main purpose of parallel collections is to improve the performance of execution through concurrency. The first step is to either select an existing benchmark or create our own benchmark.</p><div class="note" title="Note"><h3 class="title"><a id="note34700"/>Note</h3><p>
<span class="strong"><strong>Scala library benchmark</strong></span>
</p><p>The Scala standard library has a <code class="literal">testing.Benchmark</code> trait used to test using the command line [12:2]. All you need to do is insert your function or code in the <code class="literal">run</code> method:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>object test with Benchmark { def run { /* … /* }</strong></span>
</pre></div></div><p>Let's create a <code class="literal">ParBenchmark</code> parameterized class to evaluate the performance of operations on parallel collections:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>ParBenchmark</strong></span>[U](times: Int) { 
  def map(f: U =&gt; U)(nTasks: Int): Double  //<span class="strong"><strong>1</strong></span>
  def filter(f: U =&gt; Boolean)(nTasks: Int): Double //<span class="strong"><strong>2</strong></span>
  def timing(g: Int =&gt; Unit ): Long
}</pre></div><p>The user has to supply the data transformation <code class="literal">f</code> for the <code class="literal">map</code> (line <code class="literal">1</code>) and <code class="literal">filter</code> (line <code class="literal">2</code>) operations of parallel collections as well as the number of concurrent tasks <code class="literal">nTasks</code>. The <code class="literal">timing</code> method collects the duration of the <code class="literal">times</code> execution of a given operation <code class="literal">g</code> on a parallel collection:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>timing</strong></span>(g: Int =&gt; Unit ): Long = {   
  var startTime = System.currentTimeMillis
  Range(0, times).foreach(<span class="strong"><strong>g</strong></span>)
  System.currentTimeMillis - startTime
}</pre></div><p>Let's define the mapping and reducing operation for the parallel arrays for which the benchmark is defined as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>ParArrayBenchmark</strong></span>[U](u: Array[U], //<span class="strong"><strong>3</strong></span>
  v: ParArray[U], //<span class="strong"><strong>4</strong></span>
  times:Int) extends ParBenchmark[T](times)</pre></div><p>The first argument of the benchmark constructor is the default array of the Scala standard library (line <code class="literal">3</code>). The second argument is the parallel data structure (or class) associated with the array (line <code class="literal">4</code>).</p><p>Let's compare the parallelized and default array on the <code class="literal">map</code> and <code class="literal">reduce</code> methods of <code class="literal">ParArrayBenchmark</code> as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>map</strong></span>(f: U =&gt; U)(nTasks: Int): Unit = {
  val pool = new ForkJoinPool(nTasks)
  v.tasksupport = new ForkJoinTaskSupport(pool)
  val duration = timing(_ =&gt; u.map(f)).toDouble  //<span class="strong"><strong>5</strong></span>
  val ratio = timing( _ =&gt; v.map(f))/duration  //<span class="strong"><strong>6</strong></span>
  show(s"$numTasks, $ratio")
}</pre></div><p>The user has<a id="id12910000" class="indexterm"/> to define the mapping function <code class="literal">f</code> and the number of concurrent tasks <code class="literal">nTasks</code> available to execute a map transformation on the array <code class="literal">u</code> (line <code class="literal">5</code>) and its parallelized counterpart <code class="literal">v</code> (line <code class="literal">6</code>). The <code class="literal">reduce</code> method follows the same design, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>reduce</strong></span>(f: (U,U) =&gt; U)(nTasks: Int): Unit = { 
  val pool = new ForkJoinPool(nTasks)
  v.tasksupport = new ForkJoinTaskSuppor(pool)   
  val duration = timing(_ =&gt; u.<span class="strong"><strong>reduceLeft</strong></span>(f)).toDouble //<span class="strong"><strong>7</strong></span>
  val ratio = timing( _ =&gt; v.<span class="strong"><strong>reduceLeft</strong></span>(f) )/duration  //<span class="strong"><strong>8</strong></span>
  show(s"$numTasks, $ratio")
}</pre></div><p>The user-defined function <code class="literal">f</code> is used to execute the reduce action on the array <code class="literal">u</code> (line <code class="literal">7</code>) and its parallelized counterpart <code class="literal">v</code> (line <code class="literal">8</code>).</p><p>The same template can be used for other higher Scala methods, such as <code class="literal">filter</code>.</p><p>The absolute timing of each operation is completely dependent on the environment. It is far more useful to record the ratio of the duration of execution of the operation on the parallelized array, over the single thread array.</p><p>The benchmark class <code class="literal">ParMapBenchmark</code> used to evaluate <code class="literal">ParHashMap</code> is similar to the benchmark for <code class="literal">ParArray</code>, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>ParMapBenchmark</strong></span>[U](val u: Map[Int, U], 
  val v: ParMap[Int, U], 
  times: Int) extends ParBenchmark[T](times)</pre></div><p>For example, the <code class="literal">filter</code> method of <code class="literal">ParMapBenchmark</code> evaluates the performance of the parallel map <code class="literal">v</code> relative to a single-threaded map <code class="literal">u</code>. It applies the filtering condition to the values of each map, as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>filter</strong></span>(f: U =&gt; Boolean)(nTasks: Int): Unit = {
  val pool = new ForkJoinPool(nTasks)
  v.tasksupport = new ForkJoinTaskSupport(pool)   
  val duration = timing(_ =&gt; u.<span class="strong"><strong>filter</strong></span>(e =&gt; f(e._2))).toDouble 
  val ratio = timing( _ =&gt; v.<span class="strong"><strong>filter</strong></span>(e =&gt; f(e._2)))/duration
  show(s"$nTasks, $ratio")
}</pre></div></div><div class="section" title="Performance evaluation"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec18800"/>Performance evaluation</h3></div></div></div><p>The <a id="id12920000" class="indexterm"/>first performance test consists of creating a single-threaded and a parallel array of random values and executing the <code class="literal">map</code> and <code class="literal">reduce</code> evaluation methods, on using an increasing number of tasks, as follows:</p><div class="informalexample"><pre class="programlisting">val sz = 1000000; val NTASKS = 16
val data = Array.fill(sz)(Random.nextDouble) 
val pData = <span class="strong"><strong>ParArray</strong></span>.fill(sz)(Random.nextDouble) 
val times: Int = 50

val bench = new <span class="strong"><strong>ParArrayBenchmark</strong></span>[Double](data, pData, times) 
val mapper = (x: Double) =&gt; Math.sin(x*0.01) + Math.exp(-x)
Range(1, NTASKS).foreach(bench.map(mapper)(_)) 
val reducer = (x: Double, y: Double) =&gt; x+y 
Range(1, NTASKS).foreach(bench.reduce(reducer)(_)) </pre></div><div class="note" title="Note"><h3 class="title"><a id="note34800"/>Note</h3><p>
<span class="strong"><strong>Measuring performance</strong></span>
</p><p>The code has to be executed within a loop and the duration has to be averaged over a large number of executions to avoid transient actions such as initialization of the JVM process or collection of unused memory (GC).</p></div><p>The following graph shows the output of the performance test:</p><div class="mediaobject"><img src="../Images/image01593.jpeg" alt="Performance evaluation"/><div class="caption"><p>The impact of concurrent tasks on the performance on Scala parallelized map and reduce</p></div></div><p style="clear:both; height: 1em;"> </p><p>The test executes the mapper and reducer functions 1 million times on an 8-core CPU with 8 GB <a id="id12930000" class="indexterm"/>of available memory on the JVM.</p><p>The results are not surprising in the following respects:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The reducer doesn't take advantage of the parallelism of the array. The reduction of <code class="literal">ParArray</code> has a small overhead in the single-task scenario and then matches the performance of <code class="literal">Array</code>.</li><li class="listitem">The performance of the <code class="literal">map</code> function benefits from the parallelization of the array. The performance levels off when the number of tasks allocated equals or exceeds the number of CPU core.</li></ul></div><p>The second test consists of comparing the behavior of the <code class="literal">ParArray</code> and <code class="literal">ParHashMap</code> parallel collections, on the <code class="literal">map</code> and <code class="literal">filter</code> methods, using a configuration identical to the first test as follows:</p><div class="informalexample"><pre class="programlisting">val sz = 10000000
val mData = new HashMap[Int, Double]
Range(0, sz).foreach( mData.put(_, Random.nextDouble)) //<span class="strong"><strong>9</strong></span>
val mParData = new <span class="strong"><strong>ParHashMap</strong></span>[Int, Double]
Range(0, sz).foreach( mParData.put(_, Random.nextDouble))

val bench = new <span class="strong"><strong>ParMapBenchmark</strong></span>[Double](mData, mParData, times)
Range(1, NTASKS).foreach(bench.map(mapper)(_)) //<span class="strong"><strong>10</strong></span>
val filterer = (x: Double) =&gt; (x &gt; 0.8) 
Range(1, NTASKS).foreach( bench.filter(filterer)(_)) //<span class="strong"><strong>11</strong></span>
</pre></div><p>The test initializes a <code class="literal">HashMap</code> instance and its <code class="literal">ParHashMap</code> parallel counter with 1 million random values (line <code class="literal">9</code>). The benchmark <code class="literal">bench</code> processes all the elements of these hash maps with the <code class="literal">mapper</code> instance introduced in the first test (line <code class="literal">10</code>) and a filtering function <code class="literal">filterer</code> (line <code class="literal">11</code>) with <code class="literal">NTASKS</code> equal to 6. The output is shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01594.jpeg" alt="Performance evaluation"/><div class="caption"><p>The impact of concurrent tasks on the performance on Scala parallelized array and hash map</p></div></div><p style="clear:both; height: 1em;"> </p><p>The impact of<a id="id12940000" class="indexterm"/> the parallelization of collections is very similar across methods and collections. It's important to notice that the performance of the parallel collections levels off at around four times the single thread collections for five concurrent tasks and above. <span class="strong"><strong>Core parking</strong></span> is partially responsible<a id="id12950000" class="indexterm"/> for this behavior. Core parking disables a few CPU cores in an effort to conserve power, and in the case of a single application, it consumes almost all CPU cycles.</p><div class="note" title="Note"><h3 class="title"><a id="note34900"/>Note</h3><p>
<span class="strong"><strong>Further performance evaluation</strong></span>
</p><p>The purpose of the performance test was to highlight the benefits of using Scala parallel collections. You should experiment further with collections other than <code class="literal">ParArray</code> and <code class="literal">ParHashMap</code> and other higher-order methods to confirm the pattern.</p></div><p>Clearly, a four times increase in performance is nothing to complain about. Having said that, parallel collections are limited to single-host deployments. If you cannot live with such a restriction and still need a scalable solution, the Actor model provides a blueprint for highly distributed applications.</p></div></div></div>
<div class="section" title="Scalability with Actors"><div class="titlepage" id="aid-6MIEI2"><div><div><h1 class="title"><a id="ch12lvl1sec7900"/>Scalability with Actors</h1></div></div></div><p>Traditional multithreaded<a id="id12960000" class="indexterm"/> applications rely on accessing data located in shared memory. The mechanism relies on synchronization monitors such as locks, mutexes, or semaphores to avoid deadlocks and inconsistent mutable states. Even for the most experienced software engineer, debugging multithreaded applications is not a simple endeavor.</p><p>The second <a id="id12970000" class="indexterm"/>problem with shared memory threads in Java is the high computation overhead caused by continuous context switches. Context switching consists of saving the current stack frame delimited by the base and stack pointers into the heap memory and loading another stack frame.</p><p>These restrictions and complexities can be avoided using a concurrency model that relies on the following key principles:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Immutable data structures</li><li class="listitem">Asynchronous communication</li></ul></div><div class="section" title="The Actor model"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16300"/>The Actor model</h2></div></div></div><p>The<a id="id12980000" class="indexterm"/> Actor model, originally introduced in the <a id="id12990000" class="indexterm"/><span class="strong"><strong>Erlang</strong></span> programming language, addresses these issues [12:3]. The<a id="id13000000" class="indexterm"/> purpose of using the Actor model is twofold as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It distributes the computation over as many cores and servers as possible</li><li class="listitem">It reduces or eliminates race conditions and deadlocks, which are very prevalent in the Java development</li></ul></div><p>The model consists of the following <a id="id13010000" class="indexterm"/>components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Independent processing units known as Actors. They communicate by exchanging messages asynchronously instead of sharing states.</li><li class="listitem">Immutable messages are sent to queues, known as mailboxes, before being processed by each actor one at a time.</li></ul></div><p>Let's take a look at the following diagram:</p><div class="mediaobject"><img src="../Images/image01595.jpeg" alt="The Actor model"/><div class="caption"><p>The representation of messaging between actors</p></div></div><p style="clear:both; height: 1em;"> </p><p>There are two message-passing mechanisms, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Fire-and-forget or tell</strong></span>: This <a id="id13020000" class="indexterm"/>sends the immutable message asynchronously to the target or receiving Actor and immediately returns without blocking. The syntax is <code class="literal">targetActorRef ! message</code>.</li><li class="listitem"><span class="strong"><strong>Send-and-receive or ask</strong></span>: This <a id="id13030000" class="indexterm"/>sends a message asynchronously, but returns a <code class="literal">Future</code> instance that defines the expected reply from the <code class="literal">val future = targetActorRef ? message</code> target actor.</li></ul></div><p>The generic <a id="id13040000" class="indexterm"/>construct for the Actor message handler is somewhat similar to the <code class="literal">Runnable.run()</code> method in Java, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">while( true ){
  <span class="strong"><strong>receive</strong></span> { case msg1: MsgType =&gt; handler } 
}</pre></div><p>The <code class="literal">receive</code> keyword is, in fact, a partial function of the <code class="literal">PartialFunction[Any, Unit]</code> type [12:4]. The purpose is to avoid forcing developers to handle all possible message types. The Actor consuming messages may very well run on a separate component or even application, from the Actor producing these messages. It not always easy to anticipate the type of messages an Actor has to process in a future version of an application.</p><p>A message whose type is not matched is merely ignored. There is no need to throw an exception from within the Actor's routine. Implementations of the Actor model strive to avoid the overhead of context switching and creation of threads [12:5].</p><div class="note" title="Note"><h3 class="title"><a id="note35000"/>Note</h3><p>
<span class="strong"><strong>I/O blocking operations</strong></span>
</p><p>Although it is highly recommended that you do not use Actors to block operations, such as I/O, there are circumstances that require the sender to wait for a response. You need to be keep in mind that blocking the underlying threads might starve other Actors from CPU cycles. It is recommended that you either configure the runtime system to use a large thread pool or allow the thread pool to be resized by setting the <code class="literal">actors.enableForkJoin</code> property as <code class="literal">false</code>.</p></div></div><div class="section" title="Partitioning"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16400"/>Partitioning</h2></div></div></div><p>A dataset <a id="id13050000" class="indexterm"/>is defined as a Scala collection, for example, <code class="literal">List</code>, <code class="literal">Map</code>, and so on. Concurrent processing requires the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Breaking down a dataset into multiple subdatasets.</li><li class="listitem">Processing each dataset independently and concurrently.</li><li class="listitem">Aggregating all the resulting datasets.</li></ol><div style="height:10px; width: 1px"/></div><p>These steps are defined through a monad associated with a collection in the <span class="emphasis"><em>Abstraction</em></span> section under <span class="emphasis"><em>Why Scala?</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The <code class="literal">apply</code> method creates the sub-collection or partitions for the first step, for example, <code class="literal">def apply[T](a: T): List[T]</code>.</li><li class="listitem">A map-like operation defines the second stage. The last step relies on the monoidal associativity of the Scala collection, for example, <code class="literal">def ++ (a: List[T]. b: List[T): List[T} = a ++ b</code>.</li><li class="listitem">The aggregation, such as <code class="literal">reduce</code>, <code class="literal">fold</code>, <code class="literal">sum</code>, and so on, consists of flattening all the subresults into a single output, for example, <code class="literal">val xs: List(…) = List(List(..), List(..)).flatten</code>.</li></ol><div style="height:10px; width: 1px"/></div><p>The methods <a id="id13060000" class="indexterm"/>that can be parallelized are <code class="literal">map</code>, <code class="literal">flatMap</code>, <code class="literal">filter</code>, <code class="literal">find</code>, and <code class="literal">filterNot</code>. The methods that cannot be completely parallelized are <code class="literal">reduce</code>, <code class="literal">fold</code>, <code class="literal">sum</code>, <code class="literal">combine</code>, <code class="literal">aggregate</code>, <code class="literal">groupBy</code>, and <code class="literal">sortWith</code>.</p></div><div class="section" title="Beyond actors – reactive programming"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16500"/>Beyond actors – reactive programming</h2></div></div></div><p>The <a id="id13070000" class="indexterm"/>Actor model is an example of the reactive programming paradigm. The concept is that functions and methods are executed in response to events or exceptions. Reactive programming combines concurrency with event-based systems [12:6].</p><p>Advanced functional reactive programming constructs rely on composable futures and <a id="id13080000" class="indexterm"/><span class="strong"><strong>continuation-passing style</strong></span> (<span class="strong"><strong>CPS</strong></span>). An example of a Scala reactive library can be found at <a class="ulink" href="https://github.com/ingoem/scala-react">https://github.com/ingoem/scala-react</a>.</p></div></div>
<div class="section" title="Akka"><div class="titlepage" id="aid-6NGV42"><div><div><h1 class="title"><a id="ch12lvl1sec8000"/>Akka</h1></div></div></div><p>The <a id="id13090000" class="indexterm"/>Akka framework extends the original Actor model in Scala by adding extraction capabilities such as support for typed Actor, message dispatching, routing, load balancing, and partitioning, as well as supervision and configurability [12:7].</p><p>The Akka framework can be downloaded from<a id="id13100000" class="indexterm"/> the <a class="ulink" href="http://akka.io/">http://akka.io/</a> website or through the <a id="id13110000" class="indexterm"/>Typesafe Activator at <a class="ulink" href="http://www.typesafe.com/platform">http://www.typesafe.com/platform</a>.</p><p>Akka simplifies the implementation of the Actor model by encapsulating some of the details of Scala Actor in the <code class="literal">akka.actor.Actor</code> and <code class="literal">akka.actor.ActorSystem</code> classes.</p><p>The three <a id="id13120000" class="indexterm"/>methods you want to override are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">prestart</code>: This is an optional method that is invoked to initialize all the necessary resources such as file or database connection before the Actor is executed</li><li class="listitem"><code class="literal">receive</code>: This method defines the Actor's behavior and returns a partial function of the <code class="literal">PartialFunction[Any, Unit]</code> type</li><li class="listitem"><code class="literal">postStop</code>: This is an optional method to clean up resources such as releasing memory, closing database connections, and socket or file handles</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note35100"/>Note</h3><p>
<span class="strong"><strong>Typed and untyped actors</strong></span>
</p><p>Untyped actors can process messages of any type. If the type of the message is not matched by the receiving actor, it is discarded. Untyped actors can be regarded as contract-less actors. They are the default actors in Scala.</p><p>Typed actors are similar to Java remote interfaces. They respond to a method invocation. The invocation is declared publicly, but the execution is delegated asynchronously to the private instance of the target actor [12:8].</p></div><p>Akka offers a variety of functionalities to deploy concurrent applications. Let's create a generic template for a master Actor and worker Actors to transform a dataset using any preprocessing or classification algorithm inherited from an explicit or implicit monadic data transformation, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>
</p><p>The master Actor manages the worker actors in one of the following ways:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Individual actors</li><li class="listitem">Clusters through a <span class="strong"><strong>router</strong></span> or a <span class="strong"><strong>dispatcher</strong></span></li></ul></div><p>The router is a very simple example of Actor supervision. Supervision strategies in Akka are an essential component to make the application fault-tolerant [12:9]. A supervisor Actor manages the operations, availability, and life cycle of its children, known as <span class="strong"><strong>subordinates</strong></span>. The supervision among actors is organized as a hierarchy. Supervision strategies are categorized as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>One-for-one strategy</strong></span>: This is the default strategy. In case of a failure of one of the subordinates, the supervisor executes a recovery, restart, or resume action for that subordinate only.</li><li class="listitem"><span class="strong"><strong>All-for-one strategy</strong></span>: The supervisor executes a recovery or remedial action on all its subordinates in case one of the Actors fails.</li></ul></div><div class="section" title="Master-workers"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16600"/>Master-workers</h2></div></div></div><p>The <a id="id13130000" class="indexterm"/>first <a id="id13140000" class="indexterm"/>model to evaluate is the traditional <span class="strong"><strong>master-slaves</strong></span> or <span class="strong"><strong>master-workers</strong></span> design for the computation workflow. In this design, the worker Actors are initialized and managed by the master Actor, which is responsible for controlling the iterative process, state, and termination condition of the algorithm. The orchestration of the distributed tasks is performed through message passing.</p><div class="note" title="Note"><h3 class="title"><a id="note35200"/>Note</h3><p>
<span class="strong"><strong>The design principle</strong></span>
</p><p>It is highly recommended that you segregate the implementation of the computation or domain-specific logic from the actual implementation of the worker and master actors.</p></div><div class="section" title="Exchange of messages"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec18900"/>Exchange of messages</h3></div></div></div><p>The first step in <a id="id13150000" class="indexterm"/>implementing the master-worker design is to define the different classes of messages exchanged between the master and each worker in order to control the execution of the iterative procedure. The implementation of the master-worker design is as follows:</p><div class="informalexample"><pre class="programlisting">sealed abstract class Message(val i: Int)
case class Terminate(i: Int) extends Message(i)
case class <span class="strong"><strong>Start</strong></span>(i: Int =0) extends Message(i)  //<span class="strong"><strong>1</strong></span>
case class <span class="strong"><strong>Activate</strong></span>(i: Int, x: DblVector) extends Message(i) //<span class="strong"><strong>2</strong></span>
case class <span class="strong"><strong>Completed</strong></span>(i: Int, x: DblVector) extends Message(i)//<span class="strong"><strong>3</strong></span>
</pre></div><p>Let's define the messages that control the execution of the algorithm. We need at least the following message types or case classes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Start</code>: This is sent by the client code to the master to start the computation (line <code class="literal">1</code>).</li><li class="listitem"><code class="literal">Activate</code>: This is sent by the master to the workers to activate the computation. This message contains the time series <code class="literal">x</code> to be processed by the worker Actors. It also contains the reference to <code class="literal">sender</code> (master actor). (line <code class="literal">2</code>).</li><li class="listitem"><code class="literal">Completed</code>: This is sent by each worker back to <code class="literal">sender</code>. It contains the variance of the data in the group (line <code class="literal">3</code>).</li></ul></div><p>The master stops a worker using a <code class="literal">PoisonPill</code> message. The different approaches to terminate an actor are described in the <span class="emphasis"><em>The master actor</em></span> section.</p><p>The hierarchy<a id="id13160000" class="indexterm"/> of the <code class="literal">Message</code> class is sealed to prevent third-party developers from adding another message type. The worker responds to the activate message by executing a data transformation of the <code class="literal">ITransform</code> type. The messages exchanged between master and worker actors are shown in the following diagram:</p><div class="mediaobject"><img src="../Images/image01596.jpeg" alt="Exchange of messages"/><div class="caption"><p>A sketch design of the master-slave communication in an actor framework</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note35300"/>Note</h3><p>
<span class="strong"><strong>Messages as case classes</strong></span>
</p><p>The actor retrieves the messages queued in its mailbox by managing each message instance (copying, matching, and so on). Therefore, the message type has to be defined as a case class. Otherwise, the developer will have to override the <code class="literal">equals</code> and <code class="literal">hashCode</code> methods.</p></div></div><div class="section" title="Worker actors"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19000"/>Worker actors</h3></div></div></div><p>The worker actors<a id="id13170000" class="indexterm"/> are responsible for transforming each partitioned datasets created by the master Actor, as follows:</p><div class="informalexample"><pre class="programlisting">type PfnTransform =  PartialFunction[DblVector, Try[DblVector]]

class <span class="strong"><strong>Worker</strong></span>(id: Int, 
     <span class="strong"><strong>fct</strong></span>: PfnTransform) extends Actor  {  //<span class="strong"><strong>1</strong></span>
  override def receive = {
    case msg: <span class="strong"><strong>Activate</strong></span> =&gt;  //<span class="strong"><strong>2</strong></span>
      sender ! <span class="strong"><strong>Completed</strong></span>(msg.id+id,  fct(msg.xt).get)
   }
}</pre></div><p>The <code class="literal">Worker</code> class constructor takes the <code class="literal">fct</code> (the partial function as an argument) (line <code class="literal">1</code>). The worker launches the processing or transformation of the <code class="literal">msg.xt</code> data on arrival of the <code class="literal">Activate</code> message (line <code class="literal">2</code>). It returns the <code class="literal">Completed</code> message to the master once the <code class="literal">fct</code> data transformation is completed.</p></div><div class="section" title="The workflow controller"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19100"/>The workflow controller</h3></div></div></div><p>In<a id="id13180000" class="indexterm"/> the <span class="emphasis"><em>Scalability</em></span> section in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, we introduced the concepts of workflow and controller to manage the training and classification process as a sequence of transformation on a time series. Let's define an abstract class for all controller actors, <code class="literal">Controller</code>, with the following three key parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A time series <code class="literal">xt</code> to be processed</li><li class="listitem">A <code class="literal">fct</code> data transformation implemented as a partial function</li><li class="listitem">The number of partitions <code class="literal">nPartitions</code> to break down a time series for concurrent processing</li></ul></div><p>The <code class="literal">Controller</code> class can be defined as follows:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>Controller</strong></span> (
  val <span class="strong"><strong>xt</strong></span>: DblVector, 
   val <span class="strong"><strong>fct</strong></span>: PfnTransform, 
   val <span class="strong"><strong>nPartitions</strong></span>: Int) extends Actor with Monitor { //<span class="strong"><strong>3</strong></span>

   def <span class="strong"><strong>partition</strong></span>: Iterator[DblVector] = { //<span class="strong"><strong>4</strong></span>
      val sz = (xt.size.toDouble/nPartitions).ceil.toInt
      xt.grouped(sz)
   }
}</pre></div><p>The controller is responsible for splitting the time series into several partitions and assigning each partition to a dedicated worker (line <code class="literal">4</code>).</p></div><div class="section" title="The master actor"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19200"/>The master actor</h3></div></div></div><p>Let's <a id="id13190000" class="indexterm"/>define a master actor class <code class="literal">Master</code>. The three methods to override are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">prestart</code>: This is a method invoked to initialize all the necessary resources such as a file or database connection before the actor executes (line <code class="literal">9</code>)</li><li class="listitem"><code class="literal">receive</code>: This is a partial function that dequeues and processes the messages from the mail box</li><li class="listitem"><code class="literal">postStop</code>: This cleans up resources such as releasing memory and closing database connections, sockets, or file handles (line <code class="literal">10</code>)</li></ul></div><p>The <code class="literal">Master</code> class can be defined as follows:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>Master</strong></span>(  //<span class="strong"><strong>5</strong></span>
    <span class="strong"><strong>xt</strong></span>: DblVector, 
    <span class="strong"><strong>fct</strong></span>: PfnTransform, 
    <span class="strong"><strong>nPartitions</strong></span>: Int) extends Controller(xt, fct, nPartitions) {

  val aggregator = new Aggregator(nPartitions)  //<span class="strong"><strong>6</strong></span>
  val workers = List.tabulate(nPartitions)(n =&gt; 
        context.actorOf(Props(new Worker(n, fct)), 
               name = s"worker_$n"))  //<span class="strong"><strong>7</strong></span>
  workers.foreach( context.watch ( _ ) )  //<span class="strong"><strong>8</strong></span>

  override def <span class="strong"><strong>preStart</strong></span>: Unit = /* ... */  //<span class="strong"><strong>9</strong></span>
  override def <span class="strong"><strong>postStop</strong></span>: Unit = /* ... */  //<span class="strong"><strong>10</strong></span>
  override def <span class="strong"><strong>receive</strong></span> 
}</pre></div><p>The <code class="literal">Master</code> class <a id="id13200000" class="indexterm"/>has the following parameters (line <code class="literal">5</code>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">xt</code>: This is the time series to transform</li><li class="listitem"><code class="literal">fct</code>: This is the transformation function </li><li class="listitem"><code class="literal">nPartitions</code>: This is the number of partitions</li></ul></div><p>An aggregating class <code class="literal">aggregator</code> collects and reduces the results from each worker (line <code class="literal">6</code>):</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Aggregator</strong></span>(partitions: Int) {
  val state = new ListBuffer[DblVector]

  def += (x: DblVector): Boolean = {
    state.append(x)
    state.size == partitions
  }

  def clear: Unit = state.clear
  def completed: Boolean = state.size == partitions
}</pre></div><p>The worker actors are created through the <code class="literal">actorOf</code> factory method of the <code class="literal">ActorSystem</code> context (line <code class="literal">7</code>). The worker actors are attached to the context of the master actor, so it can be notified when the workers terminate (line <code class="literal">8</code>).</p><p>The <code class="literal">receive</code> message handler processes only two types of messages: <code class="literal">Start</code> from the client code and <code class="literal">Completed</code> from the workers, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>receive</strong></span> = {
  case s: <span class="strong"><strong>Start</strong></span> =&gt; start  //<span class="strong"><strong>11</strong></span>

  case msg: <span class="strong"><strong>Completed</strong></span> =&gt;   //<span class="strong"><strong>12</strong></span>
    if( aggregator +=  msg.xt) //<span class="strong"><strong>13</strong></span>
      workers.foreach( context.stop(_) )   //<span class="strong"><strong>14</strong></span>

  case Terminated(sender) =&gt; //<span class="strong"><strong>15</strong></span>
    if( aggregator.completed ) {  
      context.stop(self)   //<span class="strong"><strong>16</strong></span>
      context.system.shutdown
    }
}</pre></div><p>The <code class="literal">Start</code> message <a id="id13210000" class="indexterm"/>triggers the partitioning of the input time series into partitions (line <code class="literal">11</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>start</strong></span>: Unit = workers.zip(partition.toVector)
             .foreach {case (w, s) =&gt; w ! <span class="strong"><strong>Activate</strong></span>(0,s)} //<span class="strong"><strong>16</strong></span>
</pre></div><p>The partitions are then dispatched to each worker with the <code class="literal">Activate</code> message (line <code class="literal">16</code>).</p><p>Each worker sends a <code class="literal">Completed</code> message back to master on the completion of their task (line <code class="literal">12</code>). The master aggregates the results from each worker (line <code class="literal">13</code>). Once all the workers have completed their task, they are removed from the master's context (line <code class="literal">14</code>). The master terminates all the workers through a <code class="literal">Terminated</code> message (line <code class="literal">15</code>), and finally, terminates itself through a request to its <code class="literal">context</code> to stop it (line <code class="literal">16</code>).</p><p>The previous code snippet uses two different approaches to terminate an actor. There are four different methods of shutting down an actor, as mentioned here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">actorSystem.shutdown</code>: This method is used by the client to shut down the parent actor system</li><li class="listitem"><code class="literal">actor ! PoisonPill</code>: This method is used by the client to send a poison pill message to the actor</li><li class="listitem"><code class="literal">context.stop(self)</code>: This method is used by the Actor to shut itself down within its context</li><li class="listitem"><code class="literal">context.stop(childActorRef)</code>: This method is used by the Actor to shut itself down through its reference</li></ul></div></div><div class="section" title="Master with routing"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19300"/>Master with routing</h3></div></div></div><p>The <a id="id13220000" class="indexterm"/>previous design makes sense only if each worker has a unique characteristic that requires direct communication with the master. This is not the case in most applications. The communication and internal management of the worker can be delegated to a router. The implementation of the master routing capabilities is very similar to the previous design, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>MasterWithRouter</strong></span>(
    xt: DblVector, 
    fct: PfnTransform, 
    nPartitions: Int) extends Controller(xt, fct, nPartitions)  {

  val aggregator = new Aggregator(nPartitions)
  val <span class="strong"><strong>router</strong></span> = {   //<span class="strong"><strong>17</strong></span>
    val routerConfig = <span class="strong"><strong>RoundRobinRouter</strong></span>(nPartitions, //<span class="strong"><strong>18</strong></span>
           supervisorStrategy = this.supervisorStrategy)
    <span class="strong"><strong>context.actorOf</strong></span>(
       Props(new Worker(0,fct)).withRouter(routerConfig) )
   }
   context.watch(router)

   override def receive
}</pre></div><p>The only <a id="id13230000" class="indexterm"/>difference is that the <code class="literal">context.actorOf</code> factory creates an extra actor, router, along with the workers (line <code class="literal">17</code>). This particular implementation relies on round-robin assignment of the message by the router to each worker (line <code class="literal">18</code>). Akka supports several routing mechanisms that select a random actor, or the actor with the smallest mailbox, or the first to respond to a broadcast, and so on.</p><div class="note" title="Note"><h3 class="title"><a id="note35400"/>Note</h3><p>
<span class="strong"><strong>Router supervision</strong></span>
</p><p>The router actor is a parent of the worker actors. It is by design a supervisor of the worker actors, which are its children actors. Therefore, the router is responsible for the life cycle of the worker actors, which includes their creation, restarting, and termination.</p></div><p>The implementation of the <code class="literal">receive</code> message handler is almost identical to the message handler in the master without routing capabilities, with the exception of the termination of the workers through the router (line <code class="literal">19</code>):</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>receive</strong></span> = {
  case <span class="strong"><strong>Start</strong></span> =&gt; start
  case msg: Completed =&gt; 
    if( aggregator += msg.xt) context.stop(<span class="strong"><strong>router</strong></span>)  //<span class="strong"><strong>19</strong></span>
   ...
}</pre></div><p>The <code class="literal">start</code> message handler has to be modified to broadcast the <code class="literal">Activate</code> message to all the workers through<a id="id13240000" class="indexterm"/> the router:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>start</strong></span>: Unit = 
  partition.toVector.foreach {<span class="strong"><strong>router</strong></span> ! Activate(0, _)}</pre></div></div><div class="section" title="Distributed discrete Fourier transform"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19400"/>Distributed discrete Fourier transform</h3></div></div></div><p>Let's select the<a id="id13250000" class="indexterm"/> <span class="strong"><strong>discrete Fourier transform</strong></span> (<span class="strong"><strong>DFT</strong></span>) on a time series <code class="literal">xt</code> as our data transformation. We discussed this in the <span class="emphasis"><em>Discrete Fourier transform</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>. The testing code is exactly the same, whether the master has routing capabilities or not.</p><p>First, let's define a master controller <code class="literal">DFTMaster</code> dedicated to the execution of the distributed discrete Fourier transform, as follows:</p><div class="informalexample"><pre class="programlisting">type <span class="strong"><strong>Reducer</strong></span> = List[DblVector] =&gt; immutable.Seq[Double]
class <span class="strong"><strong>DFTMaster</strong></span>(
    xt: DblVector, 
    nPartitions: Int, 
    <span class="strong"><strong>reducer</strong></span>: Reducer)   //<span class="strong"><strong>20</strong></span>
      extends Master(xt, DFT[Double].|&gt;, nPartitions)</pre></div><p>The <code class="literal">reducer</code> method aggregates or reduces the results of the discrete Fourier transform (frequencies distribution) from each worker (line <code class="literal">20</code>). In the case of the discrete Fourier transform, the <code class="literal">fReduce</code> reducer method transposes the list of frequencies distribution and then sums up the amplitude for each frequency (line <code class="literal">21</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>fReduce</strong></span>(buf: List[DblVector]): immutable.Seq[Double] = 
   buf.transpose.map( _.sum).toSeq  //<span class="strong"><strong>21</strong></span>
</pre></div><p>Let's take a look at the test code:</p><div class="informalexample"><pre class="programlisting">val NUM_WORKERS = 4 
val NUM_DATAPOINTS = 1000000
val h = (x: Double) =&gt;2.0*Math.cos(Math.PI*0.005*x) + 
    Math.cos(Math.PI*0.05*x) + 0.5*Math.cos(Math.PI*0.2*x) +
    0.3* Random.nextDouble   //<span class="strong"><strong>22</strong></span>

val actorSystem = <span class="strong"><strong>ActorSystem</strong></span>("System")  //<span class="strong"><strong>23</strong></span>
val xt = Vector.tabulate(NUM_DATA_POINTS)(h(_))
val controller = <span class="strong"><strong>actorSystem.actorOf</strong></span>(
         Props(new DFTMasterWithRouter(xt, NUM_WORKERS, 
                    fReduce)), "MasterWithRouter")  //<span class="strong"><strong>24</strong></span>
controller ! Start(1) //<span class="strong"><strong>25</strong></span>
</pre></div><p>The input time series is synthetically generated by the noisy sinusoidal function <code class="literal">h</code> (line <code class="literal">22</code>). The function <code class="literal">h</code> has three distinct harmonics: <code class="literal">0.005</code>, <code class="literal">0.05</code>, and <code class="literal">0.2</code>, so the results of the transformation can be easily validated. The Actor system, <code class="literal">ActorSystem</code>, is instantiated (line <code class="literal">23</code>) and the master Actor is generated through the Akka <code class="literal">ActorSytem.actorOf</code> factory (line <code class="literal">24</code>). The main program sends a <code class="literal">Start</code> message to the master to trigger the <a id="id13260000" class="indexterm"/>distributed computation of the discrete Fourier transform (line <code class="literal">25</code>).</p><div class="note" title="Note"><h3 class="title"><a id="note35500"/>Note</h3><p>
<span class="strong"><strong>The action instantiation</strong></span>
</p><p>Although the <code class="literal">scala.actor.Actor</code> class can be instantiated using the constructor, <code class="literal">akka.actor.Actor</code> is instantiated using an <code class="literal">ActorSystem</code> context, an <code class="literal">actorOf</code> factory, and a <code class="literal">Props</code> configuration object. This second approach has several benefits, including decoupling the deployment of the actor from its functionality and enforcing a default supervisor or parent for the Actor; in this case, <code class="literal">ActorSystem</code>.</p></div><p>The following sequential diagram illustrates the message exchange between the main program, master, and worker Actors:</p><div class="mediaobject"><img src="../Images/image01597.jpeg" alt="Distributed discrete Fourier transform"/><div class="caption"><p>A sequential diagram for the normalization of cross-validation groups</p></div></div><p style="clear:both; height: 1em;"> </p><p>The purpose of the test is to evaluate the performance of the computation of the discrete Fourier transform using the Akka framework relative to the original implementation, without actors. As with Scala parallel collections, the absolute timing for the transformation depends on the host and the configuration, as shown in the following graph:</p><div class="mediaobject"><img src="../Images/image01598.jpeg" alt="Distributed discrete Fourier transform"/><div class="caption"><p>The impact of the number of worker (slave) actors on the performance of the discrete Fourier transform</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id13270000" class="indexterm"/>single-threaded version of the discrete Fourier transform is significantly faster than the implementation using the Akka master-worker model with a single worker actor. The cost of partitioning and aggregating (or reducing) the results adds a significant overhead to the execution of the Fourier transform. However, the master worker model is far more efficient with three or more worker actors.</p></div><div class="section" title="Limitations"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19500"/>Limitations</h3></div></div></div><p>The master-worker <a id="id13280000" class="indexterm"/>implementation has a few problems, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">In the message handler of the master Actor, there is no guarantee that the poison pill will be consumed by all the workers before the master stops.</li><li class="listitem">The main program has to sleep for a period of time long enough to allow the master and workers to complete their tasks. There is no guarantee that the computation will be completed when the main program awakes.</li><li class="listitem">There is no mechanism to handle failure in delivering or processing messages.</li></ul></div><p>The culprit is the exclusive use of the fire-and-forget mechanism to exchange data between master and workers. The send-and-receive protocol and futures are remedies to these problems.</p></div></div><div class="section" title="Futures"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16700"/>Futures</h2></div></div></div><p>A future is <a id="id13290000" class="indexterm"/>an object, more specifically a monad, used to retrieve the results of concurrent operations, in a nonblocking fashion. The concept is very similar to a callback supplied to a worker, which invokes it when the task is completed. Futures<a id="id13300000" class="indexterm"/> hold a value that might or might not become available in the future when a task is completed, whether successful or not [12:10].</p><p>There are two options to retrieve results from futures:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Blocking the execution using <code class="literal">scala.concurrent.Await</code></li><li class="listitem">The <code class="literal">onComplete</code>, <code class="literal">onSuccess</code>, and <code class="literal">onFailure</code> callback functions</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note35600"/>Note</h3><p>
<span class="strong"><strong>Which future?</strong></span>
</p><p>A Scala environment provides developers with two different <code class="literal">Future</code> classes: <code class="literal">scala.actor.Future</code> and <code class="literal">scala.concurrent.Future</code>.</p><p>The <code class="literal">actor.Future</code> class is used to write continuation-passing style workflows in which the current actor is blocked until the value of the future is available. Instances of the <code class="literal">scala.concurrent.Future</code> type used in this chapter are the equivalent of <code class="literal">java.concurrent.Future</code> in Scala.</p></div><div class="section" title="The Actor life cycle"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19600"/>The Actor life cycle</h3></div></div></div><p>Let's <a id="id13310000" class="indexterm"/>reimplement the normalization of cross-validation groups by their variance, which we introduced in the previous section, using futures to support concurrency. The first step is to import the appropriate classes for execution of the main actor and futures, as follows:</p><div class="informalexample"><pre class="programlisting">import akka.actor.{Actor, ActorSystem, ActorRef, Props} //<span class="strong"><strong>26</strong></span>
import akka.util.Timeout   //<span class="strong"><strong>27</strong></span>
import scala.concurrent.{Await, Future}  //<span class="strong"><strong>28</strong></span>
</pre></div><p>The Actor classes are provided by the <code class="literal">akka.actor</code> package, instead of the <code class="literal">scala.actor._</code> package because of Akka's extended actor model (line <code class="literal">26</code>). The future-related classes, <code class="literal">Future</code> and <code class="literal">Await</code>, are imported from the <code class="literal">scala.concurrent</code> package, which is similar to the <code class="literal">java.concurrent</code> package (line <code class="literal">28</code>). The <code class="literal">akka.util.Timeout</code> class is used to specify the maximum duration the actor has to wait for the completion of the futures (line <code class="literal">27</code>).</p><p>There are two options for a parent actor or the main program to manage the futures it creates, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Blocking</strong></span>: The parent actor or main program stops the execution until all futures have completed their tasks.</li><li class="listitem"><span class="strong"><strong>Callback</strong></span>: The <a id="id13320000" class="indexterm"/>parent actor or the main program initiates the futures during the execution. The future tasks are performed concurrently with the parent actor, and it is then notified when each future task is completed.</li></ul></div></div><div class="section" title="Blocking on futures"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19700"/>Blocking on futures</h3></div></div></div><p>The following<a id="id13330000" class="indexterm"/> design consists of blocking the actor that launches the futures until all the futures have been completed, either returning with a result or throwing an exception. Let's modify the master actor into a <code class="literal">TransformFutures</code> class that manages futures instead of workers or routing actors, as follows:</p><div class="informalexample"><pre class="programlisting">abstract class <span class="strong"><strong>TransformFutures</strong></span>(
    <span class="strong"><strong>xt</strong></span>: DblVector, 
    <span class="strong"><strong>fct</strong></span>: PfnTransform, 
    <span class="strong"><strong>nPartitions</strong></span>: Int)
    (implicit timeout: Timeout) //<span class="strong"><strong>29</strong></span>
         extends Controller(xt, fct, nPartitions) {
  override def receive = {
    case s: <span class="strong"><strong>Start</strong></span> =&gt; compute(transform) //<span class="strong"><strong>30</strong></span>
  }
}</pre></div><p>The <code class="literal">TransformFutures</code> class requires the same parameters as the <code class="literal">Master</code> actor: a time series, <code class="literal">xt</code>, a data transformation, <code class="literal">fct</code>, and the number of partitions, <code class="literal">nPartitions</code>. The <code class="literal">timeout</code> parameter is an implicit argument of the <code class="literal">Await.result</code> method, and therefore, needs to be declared as an argument (line <code class="literal">29</code>). The only message, <code class="literal">Start</code>, triggers the computation of the data transformation of each future, and then the aggregation of the results (line <code class="literal">30</code>). The <code class="literal">transform</code> and <code class="literal">compute</code> methods have the same semantics as those in the master-workers design.</p><div class="note" title="Note"><h3 class="title"><a id="note35700"/>Note</h3><p>
<span class="strong"><strong>The generic message handler</strong></span>
</p><p>You may have read or even written examples of actors that have generic case <code class="literal">_ =&gt;</code> handlers in the message loop for debugging purposes. The message loop takes a partial function as an argument. Therefore, no error or exception is thrown if the message type is not recognized. There is no need for such a handler apart from the one for debugging purposes. Message types should inherit from a sealed abstract class or a sealed trait in order to prevent a new message type from being added by mistake.</p></div><p>Let's take a look at the <code class="literal">transform</code> method. Its main purpose is to instantiate, launch, and return an <a id="id13340000" class="indexterm"/>array of futures responsible for the transformation of the partitions, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>transform</strong></span>: Array[Future[DblVector]] = {
  val futures = new Array[Future[DblVector]](nPartitions) //<span class="strong"><strong>31</strong></span>

  <span class="strong"><strong>partition</strong></span>.zipWithIndex.foreach { case (x, n) =&gt; { //<span class="strong"><strong>32</strong></span>
    futures(n) = Future[DblVector] { <span class="strong"><strong>fct</strong></span>(x).get } //<span class="strong"><strong>33</strong></span>
  }}
  futures
}</pre></div><p>An array of <code class="literal">futures</code> (one future per partition) is created (line <code class="literal">31</code>). The <code class="literal">transform</code> method invokes the partitioning method <code class="literal">partition</code> (line <code class="literal">32</code>) and then initializes the future with the <code class="literal">fct</code> partial function (line <code class="literal">33</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>compute</strong></span>(futures: Array[Future[DblVector]]): Seq[Double] = 
  <span class="strong"><strong>reduce</strong></span>(futures.map(<span class="strong"><strong>Await</strong></span>.result(_, timeout.duration))) //<span class="strong"><strong>34</strong></span>
</pre></div><p>The <code class="literal">compute</code> method invokes a user-defined <code class="literal">reduce</code> function on the futures. The execution of the Actor is blocked until the <code class="literal">Await</code> class' <code class="literal">scala.concurrent.Await.result</code> method (line <code class="literal">34</code>) returns the result of each future computation. In the case of the discrete Fourier transform, the list of frequencies is transposed before the amplitude of each frequency is summed (line <code class="literal">35</code>), as follows:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>reduce</strong></span>(data: Array[DblVector]): Seq[Double] = 
    data.view.map(_.toArray)
        .transpose.map(_.sum)   //<span class="strong"><strong>35</strong></span>
            .take(SPECTRUM_WIDTH).toSeq</pre></div><p>The following sequential diagram illustrates the blocking design and the activities performed by the Actor and the futures:</p><div class="mediaobject"><img src="../Images/image01599.jpeg" alt="Blocking on futures"/><div class="caption"><p>The sequential diagram for actor blocking on future results</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Handling future callbacks"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19800"/>Handling future callbacks</h3></div></div></div><p>Callbacks<a id="id13350000" class="indexterm"/> are an excellent alternative to having the actor blocks on futures, as they can simultaneously execute other functions concurrently with the future execution.</p><p>There are two simple ways to implement the callback function, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Future.onComplete</code></li><li class="listitem"><code class="literal">Future.onSuccess</code> and <code class="literal">Future.onFailure</code></li></ul></div><p>The <code class="literal">onComplete</code> callback function takes a function of the <code class="literal">Try[T] =&gt; U</code> type as an argument with an implicit reference to the execution context, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">val f: Future[T] = future { execute task } f <span class="strong"><strong>onComplete</strong></span> {   
  case Success(s) =&gt; { … }   
  case Failure(e) =&gt; { … }
}</pre></div><p>You can surely recognize the <code class="literal">{Try, Success, Failure}</code> monad.</p><p>An alternative implementation is to invoke the <code class="literal">onSuccess</code> and <code class="literal">onFailure</code> methods that use partial functions as arguments to implement the callbacks, as follows:</p><div class="informalexample"><pre class="programlisting">f <span class="strong"><strong>onFailure</strong></span> { case e: Exception =&gt; { … } } 
f <span class="strong"><strong>onSuccess</strong></span> { case t =&gt; { … } }</pre></div><p>The only difference between blocking one future data transformation and handling callbacks is the implementation of the <code class="literal">compute</code> method or reducer. The class definition, message handler, and initialization of futures are identical, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>compute</strong></span>(futures: Array[Future[DblVector]]): Seq[Double] = {
  val buffer = new ArrayBuffer[DblVector]
  
  futures.foreach( f =&gt; {
    f <span class="strong"><strong>onSuccess</strong></span> {   //<span class="strong"><strong>36</strong></span>
      case data: DblVector =&gt; buffer.append(data)
    }
    f <span class="strong"><strong>onFailure</strong></span> { case e: Exception =&gt;  /* .. */ } //<span class="strong"><strong>37</strong></span>
  })
   buffer.find( _.isEmpty).map( _ =&gt; reduce(buffer)) //<span class="strong"><strong>38</strong></span>
}</pre></div><p>Each future calls the master actor back with either the result of the data transformation, the <code class="literal">onSuccess</code> message (line <code class="literal">36</code>), or an exception, the <code class="literal">OnFailure</code> message (line <code class="literal">37</code>). If every future succeeds, the<a id="id13360000" class="indexterm"/> values of all frequencies for all the partitions are summed (line <code class="literal">38</code>). The following sequential diagram illustrates the handling of the callback in the master actor:</p><div class="mediaobject"><img src="../Images/image01600.jpeg" alt="Handling future callbacks"/><div class="caption"><p>A sequential diagram for actor handling future result with callbacks</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note35800"/>Note</h3><p>
<span class="strong"><strong>The execution context</strong></span>
</p><p>The application of futures requires that the execution context is implicitly provided by the developer. There are three different ways to define the execution context:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Import the context: <code class="literal">import ExecutionContext.Implicits.global</code></li><li class="listitem">Create an instance of the context within the actor (or actor context): <code class="literal">implicit val ec = ExecutionContext.fromExecutorService( … )</code></li><li class="listitem">Define the context when instantiating the future: <code class="literal">val f= Future[T] ={  } (ec)</code></li></ul></div></div></div><div class="section" title="Putting it all together"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec19900"/>Putting it all together</h3></div></div></div><p>Let's reuse the discrete Fourier transform. The client code uses the same synthetically created time series as in the master-worker test model. The first step is to create a transform future for the discrete Fourier transform, <code class="literal">DFTTransformFuture</code>, as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DFTTransformFutures</strong></span>(
    xt: DblVector, 
    partitions: Int)(implicit timeout: Timeout) 
    extends <span class="strong"><strong>TransformFutures</strong></span>(xt, <span class="strong"><strong>DFT</strong></span>[Double].|&gt; , partitions)  {

  override def <span class="strong"><strong>reduce</strong></span>(data: Array[DblVector]): Seq[Double] = 
    data.map(_.toArray).transpose
        .map(_.sum).take(SPECTRUM_WIDTH).toSeq
}</pre></div><p>The only purpose of the <code class="literal">DFTTransformFuture</code> class is to define the <code class="literal">reduce</code> aggregation method for the discrete Fourier transform. Let's reuse the same test case as in the <span class="emphasis"><em>Distributed discrete Fourier transform</em></span> section under <span class="emphasis"><em>Master-workers</em></span>:</p><div class="informalexample"><pre class="programlisting">import akka.pattern.ask

val duration = Duration(8000, "millis")
implicit val timeout = new Timeout(duration)
val master = actorSystem.actorOf(   //<span class="strong"><strong>39</strong></span>
       Props(new <span class="strong"><strong>DFTTransformFutures</strong></span>(<span class="strong"><strong>xt</strong></span>, NUM_WORKERS)), 
                        "DFTTransform")
val future = master ? Start(0)  //<span class="strong"><strong>40</strong></span>
Await.result(future, timeout.duration)   //<span class="strong"><strong>41</strong></span>
actorSystem.<span class="strong"><strong>shutdown</strong></span>  //<span class="strong"><strong>42</strong></span>
</pre></div><p>The master actor is initialized as of the <code class="literal">TransformFutures</code> type with the input time series <code class="literal">xt</code>, the discrete Fourier transform <code class="literal">DFT</code>, and the number of workers or partitions <code class="literal">nPartitions</code> as arguments (line <code class="literal">39</code>). The program creates a future instance by sending (<code class="literal">ask</code>) the <code class="literal">Start</code> message to the master (line <code class="literal">40</code>). The program blocks until the completion of the future (line <code class="literal">41</code>), and then shuts down the Akka actor system (line <code class="literal">42</code>).</p></div></div></div>
<div class="section" title="Apache Spark"><div class="titlepage" id="aid-6OFFM2"><div><div><h1 class="title"><a id="ch12lvl1sec8100"/>Apache Spark</h1></div></div></div><p>Apache Spark is <a id="id13370000" class="indexterm"/>a fast and general-purpose cluster computing system, initially developed as AMPLab/UC Berkeley as part of the <a id="id13380000" class="indexterm"/><span class="strong"><strong>Berkeley Data Analytics Stack</strong></span> (<span class="strong"><strong>BDAS</strong></span>) (<a class="ulink" href="http://en.wikipedia.org/wiki/UC_Berkeley">http://en.wikipedia.org/wiki/UC_Berkeley</a>). It provides high-level APIs for the following programming languages that make large and concurrent parallel jobs easy to write and deploy [12:11]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Scala</strong></span>: <a class="ulink" href="http://spark.apache.org/docs/latest/api/scala/index.html">http://spark.apache.org/docs/latest/api/scala/index.html</a></li><li class="listitem"><span class="strong"><strong>Java</strong></span>: <a class="ulink" href="http://spark.apache.org/docs/latest/api/java/index.html">http://spark.apache.org/docs/latest/api/java/index.html</a></li><li class="listitem"><span class="strong"><strong>Python</strong></span>: <a class="ulink" href="http://spark.apache.org/docs/latest/api/python/index.html">http://spark.apache.org/docs/latest/api/python/index.html</a></li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note35900"/>Note</h3><p>
<span class="strong"><strong>The link to the latest information</strong></span>
</p><p>The URLs as any reference to Apache Spark may change in future versions.</p></div><p>The core element of Spark is a <a id="id13390000" class="indexterm"/><span class="strong"><strong>resilient distributed dataset</strong></span> (<span class="strong"><strong>RDD</strong></span>), which is a collection of elements partitioned across the nodes of a cluster and/or CPU cores of servers. An RDD can be created from a local data structure such as a list, array, or hash table, from the local filesystem or the <a id="id13400000" class="indexterm"/><span class="strong"><strong>Hadoop distributed file system</strong></span> (<span class="strong"><strong>HDFS</strong></span>).</p><p>The operations on an RDD in Spark are very similar to the Scala higher-order methods. These operations are performed concurrently over each partition. Operations on RDDs can be classified as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Transformation</strong></span>: This <a id="id13410000" class="indexterm"/>operation converts, manipulates, and filters the elements of an RDD on each partition</li><li class="listitem"><span class="strong"><strong>Action</strong></span>: This <a id="id13420000" class="indexterm"/>operation aggregates, collects, or reduces the elements of the RDD from all partitions</li></ul></div><p>An RDD can be persisted, serialized, and cached for future computation.</p><p>Spark is written in Scala and built on top of Akka libraries. Spark relies on the following mechanisms to distribute and partition RDDs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Hadoop/HDFS for the distributed and replicated filesystem</li><li class="listitem">Mesos or Yarn for the management of a cluster and shared pool of data nodes</li></ul></div><p>The Spark ecosystem can be represented as stacks of technology and framework, as seen in the following diagram:</p><div class="mediaobject"><img src="../Images/image01601.jpeg" alt="Apache Spark"/><div class="caption"><p>The Apache Spark framework ecosystem</p></div></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id13430000" class="indexterm"/>Spark ecosystem has grown to support some machine learning algorithms out of the box, such as <span class="strong"><strong>MLlib</strong></span>, a SQL-like interface to manipulate datasets with relational operators, <span class="strong"><strong>SparkSQL</strong></span>, a library for distributed graphs, <span class="strong"><strong>GraphX</strong></span>, and a streaming library [12:12].</p><div class="section" title="Why Spark?"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16800"/>Why Spark?</h2></div></div></div><p>The <a id="id13440000" class="indexterm"/>authors of Spark attempt to address the limitations of Hadoop in terms of performance and real-time processing by implementing in-memory iterative computing, which is critical to most discriminative machine learning algorithms. Numerous benchmark tests have been performed and published to evaluate the performance improvement of Spark relative to Hadoop. In the case of iterative algorithms, the time per iteration can be reduced by a ratio of 1:10 or more.</p><p>Spark provides a large array of prebuilt transforms and actions that go well beyond the basic map-reduce paradigm. These methods on RDDs are a natural extension of the Scala collections, making code migration seamless for Scala developers.</p><p>Finally, Apache Spark supports fault-tolerant operations by allowing RDDs to persist both in memory and in the filesystem. Persistency enables automatic recovery from node failures. The <a id="id13450000" class="indexterm"/>resiliency of Spark relies on the supervisory strategy of the underlying Akka actors, the persistency of their mailboxes, and the replication schemes of the HDFS.</p></div><div class="section" title="Design principles"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec16900"/>Design principles</h2></div></div></div><p>The <a id="id13460000" class="indexterm"/>performance <a id="id13470000" class="indexterm"/>of Spark relies on the following five core design principles [12:13]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">In-memory persistency</li><li class="listitem">Laziness in scheduling tasks</li><li class="listitem">Transform and actions applied to RDDs</li><li class="listitem">Implementation of shared variables</li><li class="listitem">Support for data frames (SQL-aware RDDS)</li></ul></div><div class="section" title="In-memory persistency"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20000"/>In-memory persistency</h3></div></div></div><p>The <a id="id13480000" class="indexterm"/>developer can decide to persist and/or cache an RDD for future usage. An RDD may persist in memory only or on disk only—in memory if available, or on disk otherwise as deserialized or serialized Java objects. For instance, an RDD, <code class="literal">rdd</code>, can be cached through serialization through a simple statement, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">rdd.persist(StorageLevel.MEMORY_ONLY_SER).cache</pre></div><div class="note" title="Note"><h3 class="title"><a id="note36000"/>Note</h3><p>
<span class="strong"><strong>Kryo serialization</strong></span>
</p><p>Java serialization through the <code class="literal">Serializable</code> interface is notoriously slow. Fortunately, the Spark framework allows the developer to specify a more efficient serialization mechanism such as the Kryo library.</p></div></div><div class="section" title="Laziness"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20100"/>Laziness</h3></div></div></div><p>Scala supports <a id="id13490000" class="indexterm"/>lazy values natively. The left-hand side of the assignment, which can either be a value, object reference, or method, is performed once, that is, the first time it is invoked, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">class Pipeline {
  lazy val x = { println("x"); 1.5}   
  lazy val m = { println("m"); 3}   
  val n = { println("n"); 6}   
  def f = (m &lt;&lt;1)
  def g(j: Int) = Math.pow(x, j)
}
val pipeline = new Pipeline  //<span class="strong"><strong>1</strong></span>
pipeline.g(pipeline.f)  //<span class="strong"><strong>2</strong></span>
</pre></div><p>The order of the variables printed is <code class="literal">n</code>, <code class="literal">m</code>, and then <code class="literal">x</code>. The instantiation of the <code class="literal">Pipeline</code> class initializes <code class="literal">n</code> but not <code class="literal">m</code> or <code class="literal">x</code> (line <code class="literal">1</code>). At a later stage, the <code class="literal">g</code> method is called, which in turn invokes the <code class="literal">f</code> method. The <code class="literal">f</code> method initializes the <code class="literal">m</code> value it needs, and then <code class="literal">g</code> initializes <code class="literal">x</code> to compute its power to <code class="literal">m &lt;&lt;1</code> (line <code class="literal">2</code>).</p><p>Spark <a id="id13500000" class="indexterm"/>applies the same principle to RDDs by executing the transformation only when an action is performed. In other words, Spark postpones memory allocation, parallelization, and computation until the driver code gets the result through the execution of an action. The cascading effect of invoking all these transformations backward is performed by the direct acyclic graph scheduler.</p></div><div class="section" title="Transforms and actions"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20200"/>Transforms and actions</h3></div></div></div><p>Spark is <a id="id13510000" class="indexterm"/>implemented in <a id="id13520000" class="indexterm"/>Scala, so you should not be too surprised to know that the most relevant Scala higher methods on collections are supported in Spark. The first table describes the transformation methods using Spark, as well as their counterparts in the Scala standard library. We use the (K, V) notation for (key, value) pairs:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Spark</p>
</th><th valign="bottom">
<p>Scala</p>
</th><th valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<code class="literal">map(f)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">map(f)</code>
</p>
</td><td valign="top">
<p>This transforms an RDD by executing the <code class="literal">f</code> function on each element of the collection</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">filter(f)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">filter(f)</code>
</p>
</td><td valign="top">
<p>This transforms an RDD by selecting the element for which the <code class="literal">f</code> function returns <code class="literal">true</code>
</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">flatMap(f)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">flatMap(f)</code>
</p>
</td><td valign="top">
<p>This transforms an RDD by mapping each element to a sequence of output items</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">mapPartitions(f)</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This executes the <code class="literal">map</code> method separately on each partition</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">sample</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This samples a fraction of the data with or without a replacement using a random generator</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">groupByKey</code>
</p>
</td><td valign="top">
<p>
<code class="literal">groupBy</code>
</p>
</td><td valign="top">
<p>This is called on <span class="emphasis"><em>(K,V)</em></span> to generate a new <span class="emphasis"><em>(K, Seq(V))</em></span> RDD</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">union</code>
</p>
</td><td valign="top">
<p>
<code class="literal">union</code>
</p>
</td><td valign="top">
<p>This creates a new RDD as an union of this RDD and the argument</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">distinct</code>
</p>
</td><td valign="top">
<p>
<code class="literal">distinct</code>
</p>
</td><td valign="top">
<p>This eliminates duplicate elements from this RDD</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">reduceByKey(f)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">reduce</code>
</p>
</td><td valign="top">
<p>This aggregates or reduces the value corresponding to each key using the <code class="literal">f</code> function</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">sortByKey</code>
</p>
</td><td valign="top">
<p>
<code class="literal">sortWith</code>
</p>
</td><td valign="top">
<p>This reorganizes <span class="emphasis"><em>(K,V)</em></span> in an RDD by ascending, descending, or otherwise specified order of the keys, <span class="emphasis"><em>K</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">join</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This joins an RDD <span class="emphasis"><em>(K,V)</em></span> with an RDD <span class="emphasis"><em>(K,W)</em></span> to generate a new RDD <span class="emphasis"><em>(K, (V,W))</em></span>
</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">coGroup</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This implements a join operation but generates an RDD <span class="emphasis"><em>(K, Seq(V), Seq(W))</em></span>
</p>
</td></tr></tbody></table></div><p>Action methods <a id="id13530000" class="indexterm"/>trigger the <a id="id13540000" class="indexterm"/>collection or the reduction of the datasets from all partitions back to the driver, as listed here:</p><div class="informaltable"><table border="1"><colgroup><col/><col/><col/></colgroup><thead><tr><th valign="bottom">
<p>Spark</p>
</th><th valign="bottom">
<p>Scala</p>
</th><th valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>
<code class="literal">reduce(f)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">reduce(f)</code>
</p>
</td><td valign="top">
<p>This aggregates all the elements of the RDD across all the partitions and returns a Scala object to the driver</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">collect</code>
</p>
</td><td valign="top">
<p>
<code class="literal">collect</code>
</p>
</td><td valign="top">
<p>This collects and returns all the elements of the RDD across all the partitions as a list in the driver</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">count</code>
</p>
</td><td valign="top">
<p>
<code class="literal">count</code>
</p>
</td><td valign="top">
<p>This returns the number of elements in the RDD to the driver</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">first</code>
</p>
</td><td valign="top">
<p>
<code class="literal">head</code>
</p>
</td><td valign="top">
<p>This returns the first element of the RDD to the driver</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">take(n)</code>
</p>
</td><td valign="top">
<p>
<code class="literal">take(n)</code>
</p>
</td><td valign="top">
<p>This returns the first <code class="literal">n</code> elements of the RDD to the driver </p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">takeSample</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This returns an array of random elements from the RDD back to the driver</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">saveAsTextFile</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This writes the elements of the RDD as a text file in either the local filesystem or HDFS</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">countByKey</code>
</p>
</td><td valign="top"> </td><td valign="top">
<p>This generates an <span class="emphasis"><em>(K, Int)</em></span> RDD with the original keys, <span class="emphasis"><em>K</em></span>, and the count of values for each key </p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">foreach</code>
</p>
</td><td valign="top">
<p>
<code class="literal">foreach</code>
</p>
</td><td valign="top">
<p>This executes a <code class="literal">T=&gt; Unit</code> function on each elements of the RDD</p>
</td></tr></tbody></table></div><p>Scala methods such as <code class="literal">fold</code>, <code class="literal">find</code>, <code class="literal">drop</code>, <code class="literal">flatten</code>, <code class="literal">min</code>, <code class="literal">max</code>, and <code class="literal">sum</code> are not currently implemented in Spark. Other Scala methods such as <code class="literal">zip</code> have to be used carefully, as there is no guarantee that the order of the two collections in <code class="literal">zip</code> is maintained between partitions.</p></div><div class="section" title="Shared variables"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20300"/>Shared variables</h3></div></div></div><p>In a <a id="id13550000" class="indexterm"/>perfect world, variables are immutable and local to each partition to avoid race conditions. However, there are circumstances where variables have to be shared without breaking the immutability provided by Spark. To this extent, Spark duplicates shared variables and copies them to each partition of the dataset. Spark supports the following types of shared variables:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Broadcast values</strong></span>: These values encapsulate and forward data to all the partitions</li><li class="listitem"><span class="strong"><strong>Accumulator variables</strong></span>: These variables act as summations or reference counters</li></ul></div><p>The four design principles can be summarized in the following diagram:</p><div class="mediaobject"><img src="../Images/image01602.jpeg" alt="Shared variables"/><div class="caption"><p>An interaction between the Spark driver and RDDs</p></div></div><p style="clear:both; height: 1em;"> </p><p>The preceding <a id="id13560000" class="indexterm"/>diagram illustrates the most common interaction between the Spark driver and its workers, as listed in the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The input data, residing in either the memory as a Scala collection or HDFS as a text file, is parallelized and partitioned into an RDD.</li><li class="listitem">A transformation function is applied to each element of the dataset across all the partitions.</li><li class="listitem">An action is performed to reduce and collect the data back to the driver.</li><li class="listitem">The data is processed locally within the driver.</li><li class="listitem">A second parallelization is performed to distribute computation through the RDDs.</li><li class="listitem">A variable is broadcast to all the partitions as an external parameter of the last RDD transformation.</li><li class="listitem">Finally, the last action aggregates and collects the final result back in the driver.</li></ol><div style="height:10px; width: 1px"/></div><p>If you take a look at it closely, the management of datasets and RDDs by the Spark driver is not very different from that by the Akka master and worker actors of futures.</p></div></div><div class="section" title="Experimenting with Spark"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17000"/>Experimenting with Spark</h2></div></div></div><p>Spark's in-memory <a id="id13570000" class="indexterm"/>computation for iterative computing makes it an excellent candidate to distribute the training of machine learning models, implemented with dynamic programming or optimization algorithms. Spark runs on Windows, Linux, and Mac OS operating systems. It can be deployed either in local mode for a single host or master mode for a distributed environment. The version of the Spark framework used is 1.3.</p><div class="note" title="Note"><h3 class="title"><a id="note36100"/>Note</h3><p>
<span class="strong"><strong>JVM and Scala compatible versions</strong></span>
</p><p>At the time of writing, the version of Spark 1.3.0 required Java 1.7 or higher and Scala 2.10.2 or higher. Spark 1.5.0 supports Scala 2.11 but requires the framework to be reassembled with the flag D-scala2.11.</p></div><div class="section" title="Deploying Spark"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20400"/>Deploying Spark</h3></div></div></div><p>The easiest way to <a id="id13580000" class="indexterm"/>learn Spark is to deploy a localhost in standalone mode. You can either deploy a precompiled version of Spark from the website, or build the JAR files using the <span class="strong"><strong>simple build tool</strong></span> (<span class="strong"><strong>sbt</strong></span>) <a id="id13590000" class="indexterm"/>or Maven [12:14] as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Go to the download page at <a class="ulink" href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a>.</li><li class="listitem">Choose a package type (Hadoop distribution). The Spark framework relies on the HDFS to run in cluster mode; therefore, you need to select a distribution of Hadoop or an open source distribution such as MapR or Cloudera.</li><li class="listitem">Download and decompress the package.</li><li class="listitem">If you are interested in the latest functionality added to the framework, check out the newest source code at <a class="ulink" href="http://github.com/apache/spark.git">http://github.com/apache/spark.git</a>.</li><li class="listitem">Next, you need to build, or assemble, the Apache Spark libraries from the top-level directory using either Maven or sbt:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Maven</strong></span>: Set the following Maven options to support build, deployment, and execution:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>MAVEN_OPTS="-Xmx4g -XX:MaxPermSize=512M</strong></span> 
          <span class="strong"><strong>-XX:ReservedCodeCacheSize=512m"</strong></span>
<span class="strong"><strong>mvn [args] –DskipTests clean package</strong></span>
</pre></div><p>The following are some examples:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Building on Hadoop 2.4 using Yarn clusters manager and Scala 2.10 (default):<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mvn -Pyarn –Phadoop-2.4 –Dhadoop.version-2.4.0 –DskipTests </strong></span>
<span class="strong"><strong>    clean package</strong></span>
</pre></div></li><li class="listitem">Building on Hadoop 2.6 using Yarn clusters manager and Scala 2.11:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mvn -Pyarn –Phadoop-2.6 –Dhadoop.version-2.6.0 –Dscala-2.11 </strong></span>
<span class="strong"><strong>    –DskipTests clean package</strong></span>
</pre></div></li><li class="listitem"><span class="strong"><strong>A simple build tool</strong></span>: Use the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sbt/sbt [args] assembly</strong></span>
</pre></div></li></ul></div><p>The following are some examples:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Building on Hadoop 2.4 using Yarn clusters manager and Scala 2.10 (default):<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>    sbt -Pyarn –pHadoop 2.4 assembly</strong></span>
</pre></div></li><li class="listitem">Building on Hadoop 2.6 using Yarn clusters manager and Scala 2.11:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>    sbt -Pyarn –pHadoop 2.6 –Dscala-2.11 assembly</strong></span>
</pre></div></li></ul></div></li></ul></div></li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note36200"/>Note</h3><p>
<span class="strong"><strong>Installation instructions</strong></span>
</p><p>The directory and name of artifacts used in Spark will undoubtedly change over time. You can refer to the documentation and installation guide for the latest version of Spark.</p></div><p>Apache supports <a id="id13600000" class="indexterm"/>multiple <a id="id13610000" class="indexterm"/>deployment modes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Standalone mode</strong></span>: The <a id="id13620000" class="indexterm"/>drivers and executors run as master and slave Akka actors, bundled with the default spark distribution JAR file.</li><li class="listitem"><span class="strong"><strong>Local mode</strong></span>: This is a <a id="id13630000" class="indexterm"/>standalone mode running on a single host. The slave actors are deployed across multiple cores within the same host.</li><li class="listitem"><span class="strong"><strong>Yarn clusters manager</strong></span>: Spark <a id="id13640000" class="indexterm"/>relies on the Yarn resource manager running on Hadoop version 2 and higher. The Spark driver can run either on the same JVM as the client application (client mode) or on the same JVM as the master (cluster mode).</li><li class="listitem"><span class="strong"><strong>Apache Mesos resource manager</strong></span>: This <a id="id13650000" class="indexterm"/>deployment allows dynamic and scalable partitioning. Apache Mesos is an open source and general-purpose cluster manager that has to be installed separately (refer to <a class="ulink" href="http://mesos.apache.org/">http://mesos.apache.org/</a>). Mesos manages abstracted the hardware artifacts such as memory or storage.</li></ul></div><p>The communication <a id="id13660000" class="indexterm"/>between a master node (or driver), cluster manager, and set of slave (or worker) nodes is illustrated in the following diagram:</p><div class="mediaobject"><img src="../Images/image01603.jpeg" alt="Deploying Spark"/><div class="caption"><p>The communication between a master, slave nodes, and a cluster manager</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note36300"/>Note</h3><p>
<span class="strong"><strong>Installation under Windows</strong></span>
</p><p>Hadoop relies on some UNIX/Linux utilities that need to be added to the development environment when running on Windows. The <code class="literal">winutils.exe</code> file has to be installed and added to the <code class="literal">HADOOP_PATH</code> environment variable.</p></div></div><div class="section" title="Using Spark shell"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20500"/>Using Spark shell</h3></div></div></div><p>Use any of the <a id="id13670000" class="indexterm"/>following methods to use the Spark shell:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The shell is an easy way to get your feet wet with Spark-resilient distributed datasets. To launch the shell locally, execute <code class="literal">./bin/spark-shell –master local[8]</code> to execute the shell on an 8-core localhost.</li><li class="listitem">To launch a Spark application locally, connect to the shell and execute the following command line:<div class="informalexample"><pre class="programlisting">./bin/spark-submit --class application_class --master local[4] 
   --executor-memory 12G  --jars myApplication.jar 
   –class myApp.class</pre></div><p>The command launches the application, <code class="literal">myApplication</code>, with the <code class="literal">myApp.main</code> main method  on a 4-core CPU localhost and 12 GB of memory.</p></li><li class="listitem">To launch the same Spark application remotely, connect to the shell execute the following command line:<div class="informalexample"><pre class="programlisting">./bin/spark-submit --class application_class 
   --master spark://162.198.11.201:7077 
   –-total-executor-cores 80  
   --executor-memory 12G  
   --jars myApplication.jar –class myApp.class</pre></div></li></ul></div><p>The output <a id="id13680000" class="indexterm"/>will be as follows:</p><div class="mediaobject"><img src="../Images/image01604.jpeg" alt="Using Spark shell"/><div class="caption"><p>A partial screenshot of the Spark shell command line output</p></div></div><p style="clear:both; height: 1em;"> </p><div class="note" title="Note"><h3 class="title"><a id="note36400"/>Note</h3><p>
<span class="strong"><strong>Potential pitfalls with the Spark shell</strong></span>
</p><p>Depending on your environment, you might need to disable logging information into the console by reconfiguring <code class="literal">conf/ log4j.properties</code>. The Spark shell might also conflict with the declaration of classpath in the profile or the environment variables' list. In this case, it has to be replaced by <code class="literal">ADD_JARS</code> as an environment variable such as <code class="literal">ADD_JARS = path1/jar1, path2/jar2</code>.</p></div></div><div class="section" title="MLlib"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20600"/>MLlib</h3></div></div></div><p>MLlib is a <a id="id13690000" class="indexterm"/>scalable machine learning library built on top of Spark. As of version 1.0, the library is a work in progress.</p><p>The main components of the library are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Classification algorithms, including logistic regression, Naïve Bayes, and support vector machines</li><li class="listitem">Clustering limited to K-means in version 1.0</li><li class="listitem">L1 and L1 regularization</li><li class="listitem">Optimization techniques such as gradient descent, logistic gradient and stochastic gradient descent, and L-BFGS</li><li class="listitem">Linear algebra such as the singular value decomposition</li><li class="listitem">Data generator for K-means, logistic regression, and support vector machines</li></ul></div><p>The machine <a id="id13700000" class="indexterm"/>learning bytecode is conveniently included in the Spark assembly JAR file built with the simple build tool.</p></div><div class="section" title="RDD generation"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20700"/>RDD generation</h3></div></div></div><p>The <a id="id13710000" class="indexterm"/>transformation and actions are performed on RDDs. Therefore, the first step is to create a mechanism to facilitate the generation of RDDs from a time series. Let's create an <code class="literal">RDDSource</code> singleton with a <code class="literal">convert</code> method that transforms a time series <code class="literal">xt</code> into an RDD, as shown here:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>convert</strong></span>(
    xt: immutable.Vector[DblArray], 
    <span class="strong"><strong>rddConfig</strong></span>: RDDConfig) 
    (implicit sc: <span class="strong"><strong>SparkContext</strong></span>): RDD[Vector] = {

  val rdd: RDD[Vector] = 
     sc.parallelize(xt.toVector.map(new DenseVector(_))) //3
  rdd.persist(rddConfig.persist) //4
  if( rddConfig.cache) rdd.cache  //5
  rdd
}</pre></div><p>The last <code class="literal">rddConfig</code> argument of the <code class="literal">convert</code> method specifies the configuration for the RDD. In this example, the configuration of the RDD consists of enabling/disabling cache and selecting the persistency model, as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>RDDConfig</strong></span>(val cache: Boolean, 
    val persist: StorageLevel)</pre></div><p>It is fair to assume that <code class="literal">SparkContext</code> has already been implicitly defined in a manner quite similar to <code class="literal">ActorSystem</code> in the Akka framework.</p><p>The generation of the RDD is performed in the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create an RDD using the <code class="literal">parallelize</code> method of the context and convert it into a vector (<code class="literal">SparseVector</code> or <code class="literal">DenseVector</code>) (line <code class="literal">3</code>).</li><li class="listitem">Specify the persistency model or the storage level if the default level needs to be overridden for the RDD (line <code class="literal">3</code>).</li><li class="listitem">Specify whether the RDD has to persist in memory (line <code class="literal">5</code>).</li></ol><div style="height:10px; width: 1px"/></div><div class="note" title="Note"><h3 class="title"><a id="note36500"/>Note</h3><p>
<span class="strong"><strong>An alternative for the creation of an RDD</strong></span>
</p><p>An RDD can be generated from data loaded from either the local filesystem or HDFS using the <code class="literal">SparkContext.textFile</code> method that returns an RDD of a string.</p></div><p>Once the <a id="id13720000" class="indexterm"/>RDD is created, it can be used as an input for any algorithm defined as a sequence of transformation and actions. Let's experiment with the implementation of the K-means algorithm in Spark/MLlib.</p></div><div class="section" title="K-means using Spark"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20800"/>K-means using Spark</h3></div></div></div><p>The <a id="id13730000" class="indexterm"/>first step is to create a <code class="literal">SparkKMeansConfig</code> class to define the configuration of the Apache Spark K-means algorithm, as follows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SparkKMeansConfig</strong></span>(<span class="strong"><strong>K</strong></span>: Int, <span class="strong"><strong>maxIters</strong></span>: Int, 
     <span class="strong"><strong>numRuns</strong></span>: Int = 1) {   
  val kmeans: KMeans = {      
    (new KMeans).setK(K) //<span class="strong"><strong>6</strong></span>
      .setMaxIterations(maxIters)  //<span class="strong"><strong>7</strong></span>
      .setRuns(numRuns) //<span class="strong"><strong>8</strong></span>
  }
}</pre></div><p>The minimum set of initialization parameters for MLlib K-means algorithm is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The number of clusters, <code class="literal">K</code> (line <code class="literal">6</code>)</li><li class="listitem">The maximum number of iterations for the reconstruction of the total errors, <code class="literal">maxIters</code> (line <code class="literal">7</code>)</li><li class="listitem">The number of training runs, <code class="literal">numRuns</code> (line <code class="literal">8</code>)</li></ul></div><p>The <code class="literal">SparkKMeans</code> class wraps the Spark <code class="literal">KMeans</code> into a data transformation of the <code class="literal">ITransform</code> type, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span> The class follows the design template for a classifier, as explained in the <span class="emphasis"><em>Design template for immutable classifiers</em></span> section in the <a class="link" title="Appendix A. Basic Concepts" href="part0229.xhtml#aid-6QCGQ2">Appendix A</a>, <span class="emphasis"><em>Basic Concepts</em></span>:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>SparkKMeans</strong></span>(    //<span class="strong"><strong>9</strong></span>
    <span class="strong"><strong>kMeansConfig</strong></span>: SparkKMeansConfig, 
    <span class="strong"><strong>rddConfig</strong></span>: RDDConfig, 
    <span class="strong"><strong>xt</strong></span>: Vector[DblArray])
   (implicit sc: SparkContext) extends ITransform[DblArray](xt){

  type <span class="strong"><strong>V</strong></span> = Int   //<span class="strong"><strong>10</strong></span>
  val model: Option[KMeansModel] = train  //<span class="strong"><strong>11</strong></span>

  override def |&gt; : PartialFunction[DblArray, Try[V]] //<span class="strong"><strong>12</strong></span>
  def train: Option[KMeansModel] 
}</pre></div><p>The constructor <a id="id13740000" class="indexterm"/>takes three arguments: the Apache Spark <code class="literal">KMeans</code> configuration <code class="literal">kMeansConfig</code>, the RDD configuration <code class="literal">rddConfig</code>, and the <code class="literal">xt</code> input time series for clustering (line <code class="literal">9</code>). The return type of the <code class="literal">ITransform</code> trait's partial function <code class="literal">|&gt;</code> is defined as an <code class="literal">Int</code> (line <code class="literal">10</code>).</p><p>The generation of <code class="literal">model</code> merely consists of converting the time series <code class="literal">xt</code> into an RDD using <code class="literal">rddConfig</code> and invoking MLlib <code class="literal">KMeans.run</code> (line <code class="literal">11</code>). Once it is created, the model of clusters (<code class="literal">KMeansModel</code>) is available for predicting a new observation, <code class="literal">x</code>, (line <code class="literal">12</code>), as follows:</p><div class="informalexample"><pre class="programlisting">override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[DblArray, Try[V]] = {
  case x: DblArray if(x.length &gt; 0 &amp;&amp; model != None) =&gt; 
     Try[V](model.get.predict(new DenseVector(x)))
}</pre></div><p>The <code class="literal">|&gt;</code> prediction method returns the index of the cluster of observations.</p><p>Finally, let's write a simple client program to exercise the <code class="literal">SparkKMeans</code> model using the volatility of the price of a stock and its daily trading volume. The objective is to extract clusters with features (volatility and volume), each cluster representing a specific behavior of the stock:</p><div class="informalexample"><pre class="programlisting">val K = 8
val RUNS = 16
val MAXITERS = 200
val PATH = "resources/data/chap12/CSCO.csv"
val CACHE = true

val <span class="strong"><strong>sparkConf</strong></span> = new SparkConf().setMaster("local[8]")
   .setAppName("SparkKMeans")
   .set("spark.executor.memory", "2048m") //<span class="strong"><strong>13</strong></span>
implicit val sc = new SparkContext(sparkConf) //<span class="strong"><strong>14</strong></span>

<span class="strong"><strong>extract</strong></span>.map { case (<span class="strong"><strong>vty</strong></span>,<span class="strong"><strong>vol</strong></span>)  =&gt; {  //<span class="strong"><strong>15</strong></span>
  val vtyVol = zipToSeries(vty, vol)  
  val conf = SparkKMeansConfig(K,MAXITERS,RUNS) //<span class="strong"><strong>16</strong></span>
  val rddConf = RDDConfig(CACHE, 
                    StorageLevel.MEMORY_ONLY) //<span class="strong"><strong>17</strong></span>

  val pfnSparkKMeans = SparkKMeans(conf,rddConf,vtyVol) |&gt; //<span class="strong"><strong>18</strong></span>
  val obs = Array[Double](0.23, 0.67)
  val clusterId = pfnSparkKMeans(obs)
}</pre></div><p>The first step is to define <a id="id13750000" class="indexterm"/>the minimum configuration for the <code class="literal">sc</code> context (line <code class="literal">13</code>) and initialize it (line <code class="literal">14</code>). The <code class="literal">vty</code> and <code class="literal">vol</code> volatility variables are used as features for K-means and extracted from a CSV file (line <code class="literal">15</code>):</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>extract</strong></span>: Option[(DblVector, DblVector)] = {
  val extractors = List[Array[String] =&gt; Double](
    YahooFinancials.volatility, YahooFinancials.volume 
  )
  val pfnSrc = DataSource(PATH, true) |&gt;
  pfnSrc( extractors ) match {
    case Success(x) =&gt; Some((x(0).toVector, x(1).toVector))
    case Failure(e) =&gt; { error(e.toString); None }
  }
}</pre></div><p>The execution creates a configuration <code class="literal">config</code> for the K-means (line <code class="literal">16</code>) and another configuration for the Spark RDD, <code class="literal">rddConfig</code>, (line <code class="literal">17</code>). The <code class="literal">pfnSparkKMeans</code> partial function, which implements the K-means algorithm, is created with the K-means, RDD configurations, and the input data <code class="literal">vtyVol</code> (line <code class="literal">18</code>).</p></div></div><div class="section" title="Performance evaluation"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17100"/>Performance evaluation</h2></div></div></div><p>Let's execute <a id="id13760000" class="indexterm"/>the normalization <a id="id13770000" class="indexterm"/>of the cross-validation groups on an 8-core CPU machine with 32 GB of RAM. The data is partitioned with a ratio of two partitions per CPU core.</p><div class="note" title="Note"><h3 class="title"><a id="note36600"/>Note</h3><p>
<span class="strong"><strong>A meaningful performance test</strong></span>
</p><p>The scalability test should be performed with a large number of data points (normalized volatility, normalized volume), in excess of 1 million, in order to estimate the asymptotic time complexity.</p></div><div class="section" title="Tuning parameters"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec20900"/>Tuning parameters</h3></div></div></div><p>The performance <a id="id13780000" class="indexterm"/>of a Spark application depends greatly on the configuration parameters. Selecting the appropriate value for those configuration parameters in Spark can be overwhelming—there are 54 configuration parameters as of the last count. Fortunately, the majority of those parameters have relevant default values. However, there are few parameters that deserve your attention, including the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The number of cores available to execute transformation and actions on RDDs (<code class="literal">config.cores.max</code>).</li><li class="listitem">Memory available for the execution of the transformation and actions (<code class="literal">spark.executor.memory</code>). Setting the value to 60 percent of the maximum JVM heap is a generally a good compromise.</li><li class="listitem">The number of concurrent tasks to use across all the partitions for shuffle-related operations; they use a key such as <code class="literal">reduceByKey</code> (<code class="literal">spark.default.parallelism</code>). The recommended formula is <span class="emphasis"><em>parallelism = total number of cores x 2</em></span>. The value of the parameter can be overridden with the <code class="literal">spark.reduceby.partitions</code> parameter for specific RDD reducers.</li><li class="listitem">A flag to compress a serialized RDD partition for <code class="literal">MEMORY_ONLY_SER</code> (<code class="literal">spark.rdd.compress</code>). The purpose is to reduce memory footprints at the cost of extra CPU cycles.</li><li class="listitem">The maximum size of messages containing the results of an action is sent to the <code class="literal">spark.akka.frameSize</code> driver. This value needs to be increased if a collection may potentially generate a large size array.</li><li class="listitem">A flag to compress large size broadcasted <code class="literal">spark.broadcast.compress</code> variables. It is usually recommended.</li></ul></div></div><div class="section" title="Tests"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21000"/>Tests</h3></div></div></div><p>The purpose <a id="id13790000" class="indexterm"/>of the test is to evaluate how the execution time is related to the size of the training set. The test executes K-means from the MLlib library on the volatility and trading session volume on the <span class="strong"><strong>Bank of America</strong></span> (<span class="strong"><strong>BAC</strong></span>) stock over the following periods: 3 months, 6 months, 12 months, 24 months, 48 months, 60 months, 72 months, 96 months, and 120 months.</p><p>The following configuration is used to perform the training of K-means: 10 clusters, 30 maximum iterations, and 3 runs. The test is run on a single host with 8-CPU cores and 32 GB of RAM. The test was conducted with the following values of parameters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">StorageLevel = MEMORY_ONLY</code></li><li class="listitem"><code class="literal">spark.executor.memory = 12G</code></li><li class="listitem"><code class="literal">spark.default.parallelism = 48</code></li><li class="listitem"><code class="literal">spark.akka.frameSize = 20</code></li><li class="listitem"><code class="literal">spark.broadcast.compress = true</code></li><li class="listitem">No serialization</li></ul></div><p>The first step <a id="id13800000" class="indexterm"/>after executing a test for a specific dataset is to log in to the Spark monitoring console at <code class="literal">http://host_name:4040/stages</code>:</p><div class="mediaobject"><img src="../Images/image01605.jpeg" alt="Tests"/><div class="caption"><p>The average duration of the K-means clustering versus size of trading data in months</p></div></div><p style="clear:both; height: 1em;"> </p><p>Obviously, each environment produces somewhat different performance results but confirms that the time complexity of the Spark K-means is a linear function of the training set.</p><div class="note" title="Note"><h3 class="title"><a id="note36700"/>Note</h3><p>
<span class="strong"><strong>Performance evaluation in a distributed environment</strong></span>
</p><p>A Spark deployment on multiple hosts will add latency to the overall execution time of the TCP communication. The latency is related to the collection of the results of the clustering back to the Spark driver, which is negligible and independent of the size of the training set.</p></div></div><div class="section" title="Performance considerations"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21100"/>Performance considerations</h3></div></div></div><p>This test barely <a id="id13810000" class="indexterm"/>scratches the surface of the capabilities of Apache Spark. The following are the lessons learned from personal experience in order to avoid the most common performance pitfalls when deploying Spark 1.3+:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Get acquainted with the most common Spark configuration parameters regarding partitioning, storage level, and serialization.</li><li class="listitem">Avoid serializing complex or nested objects unless you use an effective Java serialization library such as Kryo.</li><li class="listitem">Look into defining your own partitioning function to reduce large key-value pair datasets. The convenience of <code class="literal">reduceByKey</code> has its price. The ratio of number of partitions to number of cores has an impact on the performance of a reducer using keys.</li><li class="listitem">Avoid unnecessary actions such as <code class="literal">collect</code>, <code class="literal">count</code>, or <code class="literal">lookup</code>. An action reduces the data residing in the RDD partitions, and then forwards it to the Spark driver. The Spark driver (or master) program runs on a single JVM with limited resources.</li><li class="listitem">Rely on shared or broadcast variables whenever necessary. Broadcast variables, for instance, improve the performance of operations on multiple datasets with very different sizes. Let's consider the common case of joining two datasets of very different sizes. Broadcasting the smaller dataset to each partition of the RDD of the larger dataset is far more efficient than converting the smaller dataset into an RDD and executing a join operation between the two datasets.</li><li class="listitem">Use an accumulator variable for summation as it is faster than using a reduce action on an RDD.</li></ul></div></div></div><div class="section" title="Pros and cons"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17200"/>Pros and cons</h2></div></div></div><p>An increasing <a id="id13820000" class="indexterm"/>number of organizations are adopting Spark as their distributed data processing platform for real-time or pseudo real-time operations. There are several reasons for the fast adoption of Spark:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It is supported by a large and dedicated community of developers [12:15]</li><li class="listitem">In-memory persistency is ideal for iterative computation found in machine learning and statistical inference algorithms</li><li class="listitem">Excellent performance and scalability that can be extended with the Streaming module</li><li class="listitem">Apache Spark leverages Scala functional capabilities and a large number of open source Java libraries</li><li class="listitem">Spark can leverage the Mesos or Yarn cluster manager, which reduces the complexity of defining fault-tolerance and load balancing between worker nodes</li><li class="listitem">Spark needs to be integrated with commercial Hadoop vendors such as Cloudera</li></ul></div><p>However, no platform <a id="id13830000" class="indexterm"/>is perfect and Spark is no exception. The most common complaints or concerns regarding Spark are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Creating a Spark application can be intimidating for a developer with no prior knowledge of functional programming.</li><li class="listitem">The integration with the database has been somewhat lagging, relying heavily on Hive. The Spark development team has started to address these limitations with the introduction of SparkSQL and data frame RDDs.</li></ul></div></div><div class="section" title="0xdata Sparkling Water"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17300"/>0xdata Sparkling Water</h2></div></div></div><p>
<span class="strong"><strong>Sparkling Water</strong></span> is an <a id="id13840000" class="indexterm"/>initiative <a id="id13850000" class="indexterm"/>to integrate <a id="id13860000" class="indexterm"/><span class="strong"><strong>0xdata H2O</strong></span> with Spark and complement MLlib [12:16]. H2O from 0xdata is a very fast, open source, in-memory platform for machine learning for very large datasets (<a class="ulink" href="http://0xdata.com/product/">http://0xdata.com/product/</a>). The framework is worth mentioning for the following reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It has a Scala API</li><li class="listitem">It is fully dedicated to machine learning and predictive analytics</li><li class="listitem">It leverages both the frame data representation of H2O and in-memory clustering of Spark</li></ul></div><p>H2O has an extensive implementation of the generalized linear model and gradient boosted classification, among other goodies. Its data representation consists of hierarchical <a id="id13870000" class="indexterm"/><span class="strong"><strong>data frames</strong></span>. A data frame is a container of vectors potentially shared with other frames. Each vector is composed of <a id="id13880000" class="indexterm"/><span class="strong"><strong>data chunks</strong></span>, which themselves are containers of <a id="id13890000" class="indexterm"/><span class="strong"><strong>data elements</strong></span> [12:17]. At the time of writing, Sparkling Water is in beta version.</p></div></div>
<div class="section" title="Summary" id="aid-6PE081"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec8200"/>Summary</h1></div></div></div><p>This completes the introduction of the most common scalable frameworks built using Scala. It is quite challenging to describe frameworks, such as Akka and Spark, as well as new computing models such as Actors, futures, and RDDs, in a few pages. This chapter should be regarded as an invitation to further explore the capabilities of those frameworks in both a single host and a large deployment environment.</p><p>In this last chapter, we learned:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The benefits of asynchronous concurrency</li><li class="listitem">The essentials of the actor model and composing futures with blocking or callback modes</li><li class="listitem">How to implement a simple Akka cluster to squeeze performance of distributed applications</li><li class="listitem">The ease and blazing performance of Spark's resilient distributed datasets and the in-memory persistency approach</li></ul></div></div>
<div class="appendix" title="Appendix&#xA0;A.&#xA0;Basic Concepts"><div class="titlepage" id="aid-6QCGQ2"><div><div><h1 class="title"><a id="appB"/>Appendix A. Basic Concepts</h1></div></div></div><p>Machine learning algorithms make significant use of linear algebra and optimization techniques. Describing the concept and the implementation of linear algebra, calculus, and optimization algorithms in detail would have added significant complexity to the book and distracted the reader from the essence of machine learning.</p><p>The appendix lists a basic set of elements of linear algebra and optimization mentioned throughout the book. It also summarizes the coding practices and acquaints the reader with basic knowledge of financial analysis.</p><div class="section" title="Scala programming"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec8300"/>Scala programming</h1></div></div></div><p>Here is a <a id="id13900000" class="indexterm"/>partial list of coding practices and design techniques used throughout the book.</p><div class="section" title="List of libraries and tools"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17400"/>List of libraries and tools</h2></div></div></div><p>The precompiled <span class="emphasis"><em>Scala for Machine Learning</em></span> code is <code class="literal">ScalaMl-2.11-0.99.jar</code> located in the <code class="literal">$ROOT/project/target/scala-2.11</code> directory. Not all the libraries are needed for every chapter. The list is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Java JDK 1.7 or 1.8 is required for all chapters</li><li class="listitem">Scala 2.10.4 or higher is required for all chapters</li><li class="listitem">Scala IDE for Eclipse 4.0 or higher</li><li class="listitem">IntelliJ IDEA Scala plugin 13.0 or higher</li><li class="listitem">sbt 0.13 or higher</li><li class="listitem">Apache Commons Math 3.5+ is required for <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>, <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>, and <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span></li><li class="listitem">JFChart 1.0.7 is required for <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>, <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>, <a class="link" title="Chapter 5. Naïve Bayes Classifiers" href="part0182.xhtml#aid-5DI6C1">Chapter 5</a>, <span class="emphasis"><em>Naïve Bayes Classifiers</em></span>, and <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span></li><li class="listitem">Iitb CRF 0.2 (including the LBGFS and Colt libraries) is required for <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span></li><li class="listitem">LIBSVM 0.1.6 is required for <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span></li><li class="listitem">Akka framework 2.2 or higher is required for <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span></li><li class="listitem">Apache Spark/MLlib 1.3 or higher is required for <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span></li><li class="listitem">Apache Maven 3.3 or higher (required for Apache Spark 1.4 or higher)</li></ul></div><div class="note" title="Note"><h3 class="title"><a id="note36800"/>Note</h3><p>
<span class="strong"><strong>A note for Spark developers</strong></span>
</p><p>The <a id="id13910000" class="indexterm"/>Scala library <a id="id13920000" class="indexterm"/>and compiler JAR files bundled with the assembly JAR file for Apache Spark contain a version of the Scala standard library and compiler JAR file that may conflict with an existing Scala library (that is, Eclipse default ScalaIDE library).</p></div><p>The <code class="literal">lib</code> directory contains the following JAR files related to the third-party libraries or frameworks used in the book: colt, CRF, LBFGS and LIBSVM.</p></div><div class="section" title="Code snippets format"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17500"/>Code snippets format</h2></div></div></div><p>For the <a id="id13930000" class="indexterm"/>sake of readability of the implementation of algorithms, all <a id="id13940000" class="indexterm"/>nonessential code such as error checking, comments, exception, or import have been omitted. The following code elements are discarded in the code snippets presented in the book:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Comments:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/**</strong></span>
This class is defined as …
<span class="strong"><strong>*/</strong></span>
// The MathRuntime exception has to be caught here!</pre></div></li><li class="listitem">Validation of class parameters and method arguments:<div class="informalexample"><pre class="programlisting">class BaumWelchEM(val lambda: HMMLambda ...) {
<span class="strong"><strong>require</strong></span>( lambda != null, "Lambda model is undefined")</pre></div></li><li class="listitem">Class qualifiers such as <code class="literal">final</code> and <code class="literal">private</code>:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>final protected</strong></span> class MLP[T &lt;% Double] …</pre></div></li><li class="listitem">Method qualifiers and access control (<code class="literal">final</code>, <code class="literal">private</code>, and so on):<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>final</strong></span> def inputLayer: MLPLayer
<span class="strong"><strong>private</strong></span> def recurse: Unit =</pre></div></li><li class="listitem">Serialization:<div class="informalexample"><pre class="programlisting">class Config extends Serializable { … }</pre></div></li><li class="listitem">Validation<a id="id13950000" class="indexterm"/> of partial functions:<div class="informalexample"><pre class="programlisting">val pfn: PartialFunction[U, V]
pfn.<span class="strong"><strong>isDefinedAt</strong></span>(u)</pre></div></li><li class="listitem">Validation <a id="id13960000" class="indexterm"/>of intermediate states:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>assert</strong></span>( p != None, " … ")</pre></div></li><li class="listitem">Java style exceptions:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>try</strong></span> { … }
<span class="strong"><strong>catch</strong></span> { case e: ArrayIndexOutOfBoundsException  =&gt; … }
<span class="strong"><strong>if</strong></span> (y &lt; EPS)
   <span class="strong"><strong>throw</strong></span> new IllegalStateException( … )</pre></div></li><li class="listitem">Scala style exceptions:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Try</strong></span>(process(args)) match {
   case <span class="strong"><strong>Success</strong></span>(results) =&gt; …
   case <span class="strong"><strong>Failure</strong></span>(e) =&gt; …
}</pre></div></li><li class="listitem">Nonessential annotations:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>@inline</strong></span> def mean = { … }
<span class="strong"><strong>@implicitNotFound</strong></span>("Conversion $T to Array[Int] undefined")
<span class="strong"><strong>@throws</strong></span>(classOf[IllegalStateException)</pre></div></li><li class="listitem">Logging and debugging code:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>m_logger.debug</strong></span>( …)
<span class="strong"><strong>Console.println</strong></span>( … )</pre></div></li><li class="listitem">Auxiliary and nonessential methods</li></ul></div></div><div class="section" title="Best practices"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17600"/>Best practices</h2></div></div></div><div class="section" title="Encapsulation"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21200"/>Encapsulation</h3></div></div></div><p>One <a id="id13970000" class="indexterm"/>important objective while creating an API is to reduce the access to <a id="id13980000" class="indexterm"/>support a helper class. There are two options to encapsulate helper classes, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>A package scope</strong></span>: The <a id="id13990000" class="indexterm"/>supporting classes are first-level classes with protected access</li><li class="listitem"><span class="strong"><strong>A class or object scope</strong></span>: The <a id="id14000000" class="indexterm"/>supported classes are nested in the main class</li></ul></div><p>The algorithms presented in this book follow the first encapsulation pattern.</p></div><div class="section" title="Class constructor template"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21300"/>Class constructor template</h3></div></div></div><p>The <a id="id14010000" class="indexterm"/>constructors of a class are defined in the <a id="id14020000" class="indexterm"/>companion object using <code class="literal">apply</code> and the class has a package scope (<code class="literal">protected</code>):</p><div class="informalexample"><pre class="programlisting">protected class A[T](val x: X, val y: Y,…) { … } 
object A {
  def <span class="strong"><strong>apply</strong></span>[T](x: X, y: Y, ...): A[T] = new A(x, y,…)
  def <span class="strong"><strong>apply</strong></span>[T](x: , ..): A[T] = new A(x, y0, …)
}</pre></div><p>For example, the <code class="literal">SVM</code> class that implements the support vector machine is defined as follows:</p><div class="informalexample"><pre class="programlisting">final protected class <span class="strong"><strong>SVM</strong></span>[T &lt;: AnyVal](
    config: SVMConfig, 
    xt: XVSeries[T], 
    expected: DblVector)(implicit f: T =&gt; Double) 
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) {</pre></div><p>The <code class="literal">SVM</code> companion object is responsible for defining all the constructors (instance factories) relevant to the <code class="literal">SVM</code> protected class:</p><div class="informalexample"><pre class="programlisting">def <span class="strong"><strong>apply</strong></span>[T &lt;: AnyVal](
    config: SVMConfig, 
    xt: XVSeries[T], 
    expected: DblVector)(implicit f: T =&gt; Double): SVM[T] = 
  new <span class="strong"><strong>SVM</strong></span>[T](config, xt, expected)</pre></div></div><div class="section" title="Companion objects versus case classes"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21400"/>Companion objects versus case classes</h3></div></div></div><p>In the <a id="id14030000" class="indexterm"/>preceding example, the constructors are explicitly defined in the companion object. Although the invocation of <a id="id14040000" class="indexterm"/>the constructor is very similar to the instantiation of case classes, there is a major difference; the Scala compiler generates several <a id="id14050000" class="indexterm"/>methods to manipulate an instance as regular data (equals, copy, hash, and so on).</p><p>Case classes should be reserved for single state data objects (no methods).</p></div><div class="section" title="Enumerations versus case classes"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21500"/>Enumerations versus case classes</h3></div></div></div><p>It is quite <a id="id14060000" class="indexterm"/>common to read or hear discussions regarding the relative merit of enumerations and pattern matching with case <a id="id14070000" class="indexterm"/>classes in Scala [A:1]. As a very general guideline, enumeration values can be regarded as lightweight case classes or case classes can be <a id="id14080000" class="indexterm"/>considered as heavy weight enumeration values.</p><p>Let's take an example of a Scala enumeration that consists of evaluating the uniform distribution of the <code class="literal">scala.util.Random</code> library:</p><div class="informalexample"><pre class="programlisting">object A extends Enumeration {
  type TA = Value
  val A, B, C = Value
}

import A._
val counters = Array.fill(A.maxId+1)(0)
Range(0, 1000).foreach( _ =&gt; Random.nextInt(10) match {
  case 3 =&gt; counters(A.id) += 1
  …
  case _ =&gt; { }
})</pre></div><p>The pattern matching is very similar to the Java's <code class="literal">switch</code> statement.</p><p>Let's consider the following example of pattern matching using case classes that selects a mathematical formula according to the input:</p><div class="informalexample"><pre class="programlisting">package AA {
  sealed abstract class A(val level: Int)
  case class AA extends A(3) { def f =(x:Double) =&gt; 23*x}
  …
}

import AA._
def compute(a: A, x: Double): Double = a match {
   case a: A =&gt; a.f(x)
   …
}</pre></div><p>The pattern <a id="id14090000" class="indexterm"/>matching is performed <a id="id14100000" class="indexterm"/>using the default equals method, whose byte code is <a id="id14110000" class="indexterm"/>automatically set for each case class. This approach is far more flexible than the simple enumeration at the cost of extra computation cycles.</p><p>The advantages of <a id="id14120000" class="indexterm"/>using enumerations over case classes are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Enumerations involve less code for a single attribute comparison</li><li class="listitem">Enumerations are more readable, especially for Java developers.</li></ul></div><p>The advantages <a id="id14130000" class="indexterm"/>of using case classes are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Case classes are data objects and support more attributes than enumeration IDs</li><li class="listitem">Pattern matching is optimized for sealed classes as the Scala compiler is aware of the number of cases</li></ul></div><p>In short, you should use enumeration for single value constants and case classes to match data objects.</p></div><div class="section" title="Overloading"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21600"/>Overloading</h3></div></div></div><p>Contrary<a id="id14140000" class="indexterm"/> to C++, Scala does not actually overload operators. Here is the definition of <a id="id14150000" class="indexterm"/>the very few operators used in code snippets:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">+=</code>: This <a id="id14160000" class="indexterm"/>adds an element to a collection or container</li><li class="listitem"><code class="literal">+</code>: This <a id="id14170000" class="indexterm"/>sums two elements of the same type</li></ul></div></div><div class="section" title="Design template for immutable classifiers"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21700"/>Design template for immutable classifiers</h3></div></div></div><p>The <a id="id14180000" class="indexterm"/>machine learning algorithms described<a id="id14190000" class="indexterm"/> in this book uses the following design pattern and components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The set of configuration and tuning parameters for the classifier is defined in a class inheriting from <code class="literal">Config</code> (that is, <code class="literal">SVMConfig</code>).</li><li class="listitem">The classifier implements a monadic data transformation of the <code class="literal">ITransform</code> type for which the model is implicitly generated from a training set (that is, <code class="literal">SVM[T]</code>). The classifier requires at least three parameters, which are as follows:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A configuration for the execution of the training and classification tasks</li><li class="listitem">An input dataset, <code class="literal">xt</code>, of the <code class="literal">Vector[T]</code> type</li><li class="listitem">A vector of labels or <code class="literal">expected</code> values</li></ul></div></li><li class="listitem">A model of type inherited from <code class="literal">Model</code>. The constructor is responsible for creating the model through training (that is, <code class="literal">SVMModel</code>).</li></ul></div><p>Let's take a look at the following diagram:</p><div class="mediaobject"><img src="../Images/image01606.jpeg" alt="Design template for immutable classifiers"/><div class="caption"><p>A generic UML class diagram for classifiers</p></div></div><p style="clear:both; height: 1em;"> </p><p>For example, the key components of the support vector machine package are the classifier SVMs:</p><div class="informalexample"><pre class="programlisting">final protected class SVM[T &lt;: AnyVal](
    val <span class="strong"><strong>config</strong></span>: SVM<span class="strong"><strong>Config</strong></span>, 
    val xt: XTSeries[Array[T]], 
    val labels: DblVector)(implicit f: T =&gt; Double)
  extends <span class="strong"><strong>ITransform</strong></span>[Array[T]](xt) with Monitor[Double] {

  type V = 
  val <span class="strong"><strong>model</strong></span>: Option[SVM<span class="strong"><strong>Model</strong></span>] = { … }
  override def |&gt; PartialFunction[Array[T], V]
  …
}</pre></div><p>The <a id="id14200000" class="indexterm"/>training set is created by combining or <a id="id14210000" class="indexterm"/>zipping the input dataset <code class="literal">xt</code> with the labels or expected values <code class="literal">expected</code>. Once trained and validated, the model is available for prediction or classification.</p><p>This design has the main advantage of reducing the life cycle of a classifier: a model is either defined, available for classification, or is not created.</p><p>The configuration and model classes are implemented as follows:</p><div class="informalexample"><pre class="programlisting">final class SVM<span class="strong"><strong>Config</strong></span>(val formulation: SVMFormulation, 
    val kernel: SVMKernel, 
    val svmExec: SVMExecution) extends <span class="strong"><strong>Config</strong></span>

class SVM<span class="strong"><strong>Model</strong></span>(val svmmodel: svm_model) extends <span class="strong"><strong>Model</strong></span>
</pre></div><div class="note" title="Note"><h3 class="title"><a id="note36900"/>Note</h3><p>
<span class="strong"><strong>Implementation considerations</strong></span>
</p><p>The validation phase is omitted in most of the practical examples throughout the book for the sake of readability.</p></div></div></div><div class="section" title="Utility classes"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17700"/>Utility classes</h2></div></div></div><div class="section" title="Data extraction"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21800"/>Data extraction</h3></div></div></div><p>A CSV file <a id="id14220000" class="indexterm"/>is the most common format used to store historical financial data. It is the default format used to import data throughout the book. The <a id="id14230000" class="indexterm"/>data source relies on a <code class="literal">DataSourceConfig</code> configuration class, as follows:</p><div class="informalexample"><pre class="programlisting">case class <span class="strong"><strong>DataSourceConfig</strong></span>(pathName: String, normalize: Boolean, 
     reverseOrder: Boolean, headerLines: Int = 1)</pre></div><p>The parameters of the <code class="literal">DataSourceConfig</code> class are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">pathName</code>: This<a id="id14240000" class="indexterm"/> is the relative pathname of a data file to be loaded if the argument is a file or the directory containing multiple input data files. Most of files are CSV files.</li><li class="listitem"><code class="literal">normalize</code>: This<a id="id14250000" class="indexterm"/> is the flag that is used to specify whether the data has to be normalized over [0, 1].</li><li class="listitem"><code class="literal">reverseOrder</code>: This<a id="id14260000" class="indexterm"/> is the flag that is used to specify whether the order of the data in the file has to be reversed (for example, a time series) if its value is <code class="literal">true</code>.</li><li class="listitem"><code class="literal">headerLines</code>: This<a id="id14270000" class="indexterm"/> specifies the number of lines for the column headers and comments.</li></ul></div><p>The <a id="id14280000" class="indexterm"/>data <a id="id14290000" class="indexterm"/>source <code class="literal">DataSource</code> implements data transformation of the <code class="literal">ETransform</code> type using an explicit configuration <code class="literal">DataSourceConfig</code>, as described in the <span class="emphasis"><em>Monadic data transformation</em></span> section in <a class="link" title="Chapter 2. Hello World!" href="part0165.xhtml#aid-4TBCQ2">Chapter 2</a>, <span class="emphasis"><em>Hello World!</em></span>:</p><div class="informalexample"><pre class="programlisting">final class <span class="strong"><strong>DataSource</strong></span>(config: DataSourceConfig,
    <span class="strong"><strong>srcFilter</strong></span>: Option[Fields =&gt; Boolean]= None)
  extends ETransform[DataSourceConfig](config) {

  type Fields = Array[String]
  type <span class="strong"><strong>U</strong></span> = List[Fields =&gt; Double]
  type <span class="strong"><strong>V</strong></span> = XVSeries[Double]
  override def |&gt; : PartialFunction[U, Try[V]] 
  ...
}</pre></div><p>The <code class="literal">srcFilter</code> argument specifies the filter or condition of some of the row fields to skip the dataset (that is, missing data or incorrect format). Being an explicit data transformation, the <a id="id14300000" class="indexterm"/>constructor for the <code class="literal">DataSource</code> class has to initialize the <code class="literal">U</code> input type and the <code class="literal">V</code> output type of the <code class="literal">|&gt;</code> extracting method. The method takes the extractor from a row of literal values to double floating point values:</p><div class="informalexample"><pre class="programlisting">override def |&gt; : PartialFunction[U, Try[V]] = {
  case fields: U if(!fields.isEmpty) =&gt;load.map(data =&gt;{ //<span class="strong"><strong>1</strong></span>
    val convert = (f: Fields =&gt;Double) =&gt; data._2.map(f(_))
    if( config.normalize)  //<span class="strong"><strong>2</strong></span>
      fields.map(t =&gt; new MinMax[Double](convert(t)) //<span class="strong"><strong>3</strong></span>
           .normalize(0.0, 1.0).toArray ).toVector //<span class="strong"><strong>4</strong></span>
    else fields.map(convert(_)).toVector
  })
}</pre></div><p>The data is <a id="id14310000" class="indexterm"/>loaded from the file using the <code class="literal">load</code> helper method (line <code class="literal">1</code>). The data is normalized if required (line <code class="literal">2</code>) by converting each literal to a floating point value using an instance of the <code class="literal">MinMax</code> class (line <code class="literal">3</code>). Finally, the <code class="literal">MinMax</code> instance normalizes the sequence of floating point values (line <code class="literal">4</code>).</p><p>The <code class="literal">DataSource</code> class implements a significant set of methods that are documented in the source code available online.</p></div><div class="section" title="Data sources"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec21900"/>Data sources</h3></div></div></div><p>The examples <a id="id14320000" class="indexterm"/>in the book rely on three different sources of financial data using the CSV format:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">YahooFinancials</code>: This is for <a id="id14330000" class="indexterm"/>Yahoo schema for the historical stock and ETF price</li><li class="listitem"><code class="literal">GoogleFinancials</code>: This <a id="id14340000" class="indexterm"/>is for Google schema for the historical stock and ETF price</li><li class="listitem"><code class="literal">Fundamentals</code>: This is for fundamental financial analysis ration (a CSV file)</li></ul></div><p>Let's illustrate the extraction from a data source using <code class="literal">YahooFinancials</code> as an example:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>YahooFinancials</strong></span> extends Enumeration {
   type YahooFinancials = Value
   val DATE, OPEN, HIGH, LOW, CLOSE, VOLUME, ADJ_CLOSE = Value
   val <span class="strong"><strong>adjClose</strong></span> = ((s:Array[String]) =&gt;
        s(ADJ_CLOSE.id).toDouble)  //<span class="strong"><strong>5</strong></span>
   val volume =  (s: Fields) =&gt; s(VOLUME.id).toDouble
   …
   def <span class="strong"><strong>toDouble</strong></span>(value: Value): Array[String] =&gt; Double = 
       (s: Array[String]) =&gt; s(value.id).toDouble
}</pre></div><p>Let's take a<a id="id14350000" class="indexterm"/> look at an example of an application of a <code class="literal">DataSource</code> transformation: loading the historical stock data from the Yahoo finance site. The data is downloaded as a CSV formatted file. Each column is associated with an extractor function (line <code class="literal">5</code>):</p><div class="informalexample"><pre class="programlisting">val symbols = Array[String]("CSCO", ...)  //<span class="strong"><strong>6</strong></span>
val prices = symbols
       .map(s =&gt; DataSource(s"$path$s.csv",true,true,1))//<span class="strong"><strong>7</strong></span>
       .map( _ |&gt; <span class="strong"><strong>adjClose</strong></span> ) //<span class="strong"><strong>8</strong></span>
</pre></div><p>The list of stocks for which the historical data has to be downloaded is defined as an array of symbols (line <code class="literal">6</code>). Each symbol is associated with a CSV file (that is, <code class="literal">CSCO =&gt; resources/CSCO.csv</code>) (line <code class="literal">7</code>). Finally, the <code class="literal">YahooFinancials</code> extractor for the <code class="literal">adjClose</code> price is invoked (line <code class="literal">8</code>).</p><p>The format for the financial data extracted from the Google financial pages are similar to the format used in the Yahoo finances pages:</p><div class="informalexample"><pre class="programlisting">object <span class="strong"><strong>GoogleFinancials</strong></span> extends Enumeration {
   type <span class="strong"><strong>GoogleFinancials</strong></span> = Value
   val DATE, OPEN, HIGH, LOW, CLOSE, VOLUME = Value
   val close = ((s:Array[String]) =&gt;s(CLOSE.id).toDouble)//<span class="strong"><strong>5</strong></span>
   …
}</pre></div><p>The <code class="literal">YahooFinancials</code>, <code class="literal">YahooFinancials</code>, and <code class="literal">Fundamentals</code> classes implement a significant number of methods that are documented in the source code available online.</p></div><div class="section" title="Extraction of documents"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22000"/>Extraction of documents</h3></div></div></div><p>The <a id="id14360000" class="indexterm"/><code class="literal">DocumentsSource</code> class is responsible for extracting the date, title, and content of a list of text documents or text files. The class does not support HTML documents. The <code class="literal">DocumentsSource</code> class implements a monadic data transformation of the <code class="literal">ETransform</code> type with an explicit configuration of the <code class="literal">SimpleDataFormat</code> type:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DocumentsSource</strong></span>(<span class="strong"><strong>dateFormat</strong></span>: SimpleDateFormat,
    val pathName: String) 
  extends <span class="strong"><strong>ETransform</strong></span>[SimpleDateFormat](dateFormat) {

 type U = Option[Long] //2
 type V = Corpus[Long]  //3

 override def <span class="strong"><strong>|&gt;</strong></span> : PartialFunction[U, Try[V]] = { //<span class="strong"><strong>4</strong></span>
    case date: U if (filesList != None) =&gt; 
      Try( if(date == None ) getAll else get(date) )
 }
 def get(t: U): V = getAll.filter( _.date == t.get)
 def getAll: V  //<span class="strong"><strong>5</strong></span>
 ...
}</pre></div><p>The <code class="literal">DocumentsSource</code> class <a id="id14370000" class="indexterm"/>takes two arguments: the format of the date associated with the document and the name of the path in which the documents are located (line <code class="literal">1</code>). Being an explicit data transformation, the constructor of the <code class="literal">DocumentsSource</code> class has to initialize the <code class="literal">U</code> input type (line <code class="literal">2</code>) as a date and convert it into a <code class="literal">Long</code> and <code class="literal">V</code> output type (line <code class="literal">3</code>) as a <code class="literal">Corpus</code> to extract the <code class="literal">|&gt;</code> method.</p><p>The <code class="literal">|&gt;</code> extractor generates a corpus associated with a specific date and converts it into a <code class="literal">Long</code> type (line <code class="literal">4</code>). The <code class="literal">getAll</code> method does the heavy lifting to extract or sort documents (line <code class="literal">5</code>).</p><p>The implementation of the <code class="literal">getAll</code> method as well as other methods of the <code class="literal">DocumentsSource</code> class are described in the documented source code available online.</p></div><div class="section" title="DMatrix class"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22100"/>DMatrix class</h3></div></div></div><p>Some<a id="id14380000" class="indexterm"/> discriminative learning models require operations to <a id="id14390000" class="indexterm"/>be performed on rows and columns of a matrix. The <code class="literal">DMatrix</code> class facilitates the read and write operations on columns and rows:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>DMatrix</strong></span>(val nRows: Int, val nCols: Int, 
     val data: DblArray) {
 def <span class="strong"><strong>apply</strong></span>(i: Int, j: Int): Double = data(i*nCols+j)
 def <span class="strong"><strong>row</strong></span>(iRow: Int): DblArray = { 
   val idx = iRow*nCols
   data.slice(idx, idx + nCols)
 }
 def <span class="strong"><strong>col</strong></span>(iCol: Int): IndexedSeq[Double] =
   (iCol until data.size by nCols).map( data(_) )
 def <span class="strong"><strong>diagonal</strong></span>: IndexedSeq[Double] = 
    (0 until data.size by nCols+1).map( data(_))
 def <span class="strong"><strong>trace</strong></span>: Double = diagonal.sum
  …
}</pre></div><p>The<a id="id14400000" class="indexterm"/> <code class="literal">apply</code> method <a id="id14410000" class="indexterm"/>returns an element of the matrix. The <code class="literal">row</code> method returns a row array, and the <code class="literal">col</code> method returns the indexed sequence of column elements. The <code class="literal">diagonal</code> method returns the indexed sequence of diagonal elements, and the <code class="literal">trace</code> method sums the diagonal elements.</p><p>The <code class="literal">DMatrix</code> class supports normalization of elements, rows, and columns; transposition; and updation of elements, columns and rows. The <code class="literal">DMatrix</code> class implements a significant number of methods that are documented in the source code available online.</p></div><div class="section" title="Counter"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22200"/>Counter</h3></div></div></div><p>The<a id="id14420000" class="indexterm"/> <code class="literal">Counter</code> class<a id="id14430000" class="indexterm"/> implements a generic mutable counter for which the key is a parameterized type. The number of occurrences of a key is managed by a mutable hash map:</p><div class="informalexample"><pre class="programlisting">class <span class="strong"><strong>Counter</strong></span>[T] extends mutable.HashMap[T, Int] {
  def <span class="strong"><strong>+=</strong></span> (t: T): type.Counter = super.put(t, getOrElse(t, 0)+1) 
  def <span class="strong"><strong>+</strong></span> (t: T): Counter[T] = { 
   super.put(t, getOrElse(t, 0)+1); this 
  }
  def <span class="strong"><strong>++</strong></span> (cnt: Counter[T]): type.Counter = { 
    cnt./:(this)((c, t) =&gt; c + t._1); this
  }
  def <span class="strong"><strong>/</strong></span> (cnt: Counter[T]): mutable.HashMap[T, Double] = map { 
    case(str, n) =&gt; (str, if( !cnt.contains(str) ) 
      throw new IllegalStateException(" ... ")
        else n.toDouble/cnt.get(str).get )
  }
  …
}</pre></div><p>The <code class="literal">+=</code> operator updates the counter of the <code class="literal">t</code> key and returns itself. The <code class="literal">+</code> operator updates and then duplicates the updated counters. The <code class="literal">++</code> operator updates this counter with another counter. The <code class="literal">/</code> operator divides the count for each key by the counts of another counter.</p><p>The <code class="literal">Counter</code> class implements a significant set of methods that are documented in the source<a id="id14440000" class="indexterm"/> code <a id="id14450000" class="indexterm"/>available online.</p></div><div class="section" title="Monitor"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22300"/>Monitor</h3></div></div></div><p>The <a id="id14460000" class="indexterm"/><code class="literal">Monitor</code> class<a id="id14470000" class="indexterm"/> has two purposes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It stores log information and error messages using the <code class="literal">show</code> and <code class="literal">error</code> methods</li><li class="listitem">It collects and displays variables related to the recursive or iterative execution of an algorithm</li></ul></div><p>The data is collected at each iteration or recursion and then displayed as a time series with iterations as <span class="emphasis"><em>x</em></span> axis values:</p><div class="informalexample"><pre class="programlisting">trait <span class="strong"><strong>Monitor</strong></span>[T] {
  protected val logger: Logger
  lazy val _counters = 
      new mutable.HashMap[String, mutable.ArrayBuffer[T]]()

  def <span class="strong"><strong>counters</strong></span>(key: String): Option[mutable.ArrayBuffer[T]]
  def <span class="strong"><strong>count</strong></span>(key: String, value: T): Unit 
  def <span class="strong"><strong>display</strong></span>(key: String, legend: Legend)
      (implicit f: T =&gt; Double): Boolean
  def <span class="strong"><strong>show</strong></span>(msg: String): Int = DisplayUtils.show(msg, logger)
  def <span class="strong"><strong>error</strong></span>(msg: String): Int = DisplayUtils.error(msg, logger)
  ...
}</pre></div><p>The <code class="literal">counters</code> method returns an array associated with a specific key. The <code class="literal">count</code> method updates the data associated with a key. The <code class="literal">display</code> method plots the time series. Finally, the <code class="literal">show</code> and <code class="literal">error</code> methods send information and error messages to the standard output.</p><p>The documented source code for the implementation of the <code class="literal">Monitor</code> class is available online.</p></div></div></div></div>
<div class="section" title="Mathematics"><div class="titlepage" id="aid-6RB1C2"><div><div><h1 class="title"><a id="ch12lvl1sec8400"/>Mathematics</h1></div></div></div><p>This section very <a id="id14480000" class="indexterm"/>briefly describes some of the mathematical concepts used in this book.</p><div class="section" title="Linear algebra"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17800"/>Linear algebra</h2></div></div></div><p>Many<a id="id14490000" class="indexterm"/> algorithms <a id="id14500000" class="indexterm"/>used in machine learning such as minimization of a convex loss function, principal component analysis, or least squares regression invariably involves manipulation and transformation of matrices. There are many good books on the subject, from the inexpensive [A:2] to the sophisticated [A:3].</p><div class="section" title="QR decomposition"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22400"/>QR decomposition</h3></div></div></div><p>The<a id="id14510000" class="indexterm"/> QR decomposition (or the QR factorization) is the decomposition of a matrix <span class="emphasis"><em>A</em></span> into a product of an orthogonal matrix <span class="emphasis"><em>Q</em></span> and upper triangular matrix <span class="emphasis"><em>R</em></span>. So, <span class="emphasis"><em>A=QR</em></span> and <span class="emphasis"><em>Q<sup>T</sup></em></span>
<span class="emphasis"><em>Q=I</em></span> [A:4].</p><p>The decomposition is unique if <span class="emphasis"><em>A</em></span> is a real, square, and invertible matrix. In the case of a rectangle matrix <span class="emphasis"><em>A</em></span>, <span class="emphasis"><em>m by n</em></span> with <span class="emphasis"><em>m &gt; n</em></span>, the decomposition is implemented as the dot product of two vector of matrices: <span class="emphasis"><em>A = [Q<sub>1</sub>, Q<sub>2</sub>].[R<sub>1</sub>, R<sub>2</sub>]<sup>T</sup></em></span>, where <span class="emphasis"><em>Q<sub>1</sub></em></span> is an <span class="emphasis"><em>m by n</em></span> matrix, <span class="emphasis"><em>Q<sub>2</sub></em></span> is an <span class="emphasis"><em>m by n</em></span> matrix, <span class="emphasis"><em>R<sub>1</sub></em></span> is an <span class="emphasis"><em>n by n</em></span> upper triangle matrix, and <span class="emphasis"><em>R<sub>2</sub></em></span> is an <span class="emphasis"><em>m by n</em></span> null matrix.</p><p>The QR decomposition is a reliable method used to solve a large system of linear equations for which the number of equations (rows) exceeds the number of variables (columns). Its asymptotic computational time complexity for a training set of <span class="emphasis"><em>m</em></span> dimensions and <span class="emphasis"><em>n</em></span> observations is <span class="emphasis"><em>O(mn<sup>2</sup>-n<sup>3</sup>/3)</em></span>.</p><p>It is used to minimize the loss function for ordinary least squares regression (refer to the <span class="emphasis"><em>Ordinary least squares regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</p></div><div class="section" title="LU factorization"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22500"/>LU factorization</h3></div></div></div><p>
<span class="strong"><strong>LU factorization</strong></span>
<a id="id14520000" class="indexterm"/> is a <a id="id14530000" class="indexterm"/>technique used to solve a matrix equation <span class="emphasis"><em>A.x = b</em></span>, where <span class="emphasis"><em>A</em></span> is a nonsingular matrix and <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>b</em></span> are two vectors. The technique consists of decomposing the original matrix <span class="emphasis"><em>A</em></span> as the product of a simple matrix <span class="emphasis"><em>A= A<sub>1</sub>A<sub>2</sub>…A<sub>n</sub></em></span>.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Basic LU factorization</strong></span>: This<a id="id14540000" class="indexterm"/> defines <span class="emphasis"><em>A</em></span> as the product of a lower unit triangular matrix <span class="emphasis"><em>L</em></span> and an upper triangular matrix <span class="emphasis"><em>U</em></span>. So, <span class="emphasis"><em>A=LU</em></span>.</li><li class="listitem"><span class="strong"><strong>LU factorization with a pivot</strong></span>: This defines <span class="emphasis"><em>A</em></span> as the product of a permutation <a id="id14550000" class="indexterm"/>matrix <span class="emphasis"><em>P</em></span>, a lower unit triangular matrix <span class="emphasis"><em>L</em></span>, and an upper triangular matrix <span class="emphasis"><em>U</em></span>. So, <span class="emphasis"><em>A=PLU</em></span>.</li></ul></div></div><div class="section" title="LDL decomposition"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22600"/>LDL decomposition</h3></div></div></div><p>
<span class="strong"><strong>The </strong></span>
<a id="id14560000" class="indexterm"/><span class="strong"><strong>LDL decomposition</strong></span>
<a id="id14570000" class="indexterm"/> for real matrices defines a real positive matrix <span class="emphasis"><em>A</em></span> as the product of a lower unit triangular matrix <span class="emphasis"><em>L</em></span>, a diagonal matrix <span class="emphasis"><em>D</em></span>, and the transposed matrix of <span class="emphasis"><em>L</em></span>, that is, <span class="emphasis"><em>L<sup>T</sup></em></span>. So, <span class="emphasis"><em>A=LDL<sup>T</sup></em></span>.</p></div><div class="section" title="Cholesky factorization"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22700"/>Cholesky factorization</h3></div></div></div><p>The <a id="id14580000" class="indexterm"/><span class="strong"><strong>Cholesky</strong></span>
<a id="id14590000" class="indexterm"/><span class="strong"><strong> factorization</strong></span> (or the<a id="id14600000" class="indexterm"/> <span class="strong"><strong>Cholesky decomposition</strong></span>) of real matrices is a special case of the LU factorization [A:4]. It decomposes a positive definite matrix <span class="emphasis"><em>A</em></span> into a product of a lower triangular matrix <span class="emphasis"><em>L</em></span> and its conjugate transpose <span class="emphasis"><em>L<sup>T</sup></em></span>. So, <span class="emphasis"><em>A=LL<sup>T</sup></em></span>.</p><p>The asymptotic computational time complexity for the Cholesky factorization is <span class="emphasis"><em>O(mn<sup>2</sup>)</em></span>, where <span class="emphasis"><em>m</em></span> is the number of features (model parameters) and <span class="emphasis"><em>n</em></span> is the number of observations. The Cholesky factorization is used in linear least squares Kalman filter (refer to the <span class="emphasis"><em>The recursive algorithm</em></span> section in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>) and nonlinear Quasi-Newton optimizer.</p></div><div class="section" title="Singular Value Decomposition"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22800"/>Singular Value Decomposition</h3></div></div></div><p>The <a id="id14610000" class="indexterm"/><span class="strong"><strong>singular value decomposition</strong></span> (<span class="strong"><strong>SVD</strong></span>) <a id="id14620000" class="indexterm"/>of real matrices defines an <span class="emphasis"><em>m by n</em></span> real matrix <span class="emphasis"><em>A</em></span> as the product of an <span class="emphasis"><em>m</em></span> real square unitary matrix <span class="emphasis"><em>U</em></span>, an <span class="emphasis"><em>m by n</em></span> rectangular diagonal matrix <span class="emphasis"><em>Σ</em></span>, and the transpose matrix <span class="emphasis"><em>V<sup>T</sup></em></span> of a real matrix. So, <span class="emphasis"><em>A=UΣV<sup>T</sup></em></span>.</p><p>The columns of the <span class="emphasis"><em>U</em></span> and <span class="emphasis"><em>V</em></span> matrices are the orthogonal bases and the value of the diagonal matrix <span class="emphasis"><em>Σ</em></span> is a singular value [A:4]. The asymptotic computational time complexity for the singular value decomposition for <span class="emphasis"><em>n</em></span> observations and <span class="emphasis"><em>m</em></span> features is <span class="emphasis"><em>O(mn<sup>2</sup>-n<sup>3</sup>)</em></span>. The singular value decomposition is used to minimize the total least squares and solve homogeneous linear equations.</p></div><div class="section" title="Eigenvalue decomposition"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec22900"/>Eigenvalue decomposition</h3></div></div></div><p>The <a id="id14630000" class="indexterm"/>Eigen decomposition of a real square matrix <span class="emphasis"><em>A</em></span> is the canonical factorization, <span class="emphasis"><em>A</em></span>
<span class="emphasis"><em>x = λx</em></span>.</p><p>
<span class="emphasis"><em>λ</em></span> is the <a id="id14640000" class="indexterm"/><span class="strong"><strong>eigenvalue</strong></span> (scalar) corresponding to the vector <span class="emphasis"><em>x</em></span>. The <span class="emphasis"><em>n by n</em></span> matrix <span class="emphasis"><em>A</em></span> is then defined as <span class="emphasis"><em>A = QDQ<sup>T</sup></em></span>. <span class="emphasis"><em>Q</em></span> is the square matrix that contains the eigenvectors and <span class="emphasis"><em>D</em></span> is the diagonal matrix whose elements are the eigenvalues associated with the eigenvectors [A:5] and [A:6]. The Eigen decomposition is used in Principal Components Analysis (refer to the <span class="emphasis"><em>Principal components analysis</em></span> section in <a class="link" title="Chapter 4. Unsupervised Learning" href="part0178.xhtml#aid-59O442">Chapter 4</a>, <span class="emphasis"><em>Unsupervised Learning</em></span>).</p></div><div class="section" title="Algebraic and numerical libraries"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23000"/>Algebraic and numerical libraries</h3></div></div></div><p>There are many more <a id="id14650000" class="indexterm"/>open source <a id="id14660000" class="indexterm"/>algebraic libraries available to<a id="id14670000" class="indexterm"/> developers as APIs besides Apache Commons Math, which is used in <a class="link" title="Chapter 3. Data Preprocessing" href="part0172.xhtml#aid-5410O2">Chapter 3</a>, <span class="emphasis"><em>Data Preprocessing</em></span>, <a class="link" title="Chapter 5. Naïve Bayes Classifiers" href="part0182.xhtml#aid-5DI6C1">Chapter 5</a>, <span class="emphasis"><em>Naïve Bayes Classifiers</em></span>, <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>, and Apache Spark/MLlib in <a class="link" title="Chapter 12. Scalable Frameworks" href="part0223.xhtml#aid-6KLDE1">Chapter 12</a>, <span class="emphasis"><em>Scalable Frameworks</em></span>. They are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>jBlas 1.2.3</strong></span> (Java) created<a id="id14680000" class="indexterm"/> by Mikio Braun under the BSD revised license. This library provides Java and Scala developers a high-level Java interface to <span class="strong"><strong>BLAS</strong></span> and <span class="strong"><strong>LAPACK</strong></span> (<a class="ulink" href="https://github.com/mikiobraun/jblas">https://github.com/mikiobraun/jblas</a>).</li><li class="listitem"><span class="strong"><strong>Colt 1.2.0</strong></span> (Java) is a<a id="id14690000" class="indexterm"/> high-performance scientific library developed at CERN under the European Organization for Nuclear Research license (<a class="ulink" href="http://acs.lbl.gov/ACSSoftware/colt/">http://acs.lbl.gov/ACSSoftware/colt/</a>).</li><li class="listitem"><span class="strong"><strong>AlgeBird 2.10</strong></span> (Scala) developed <a id="id14700000" class="indexterm"/>at Twitter under Apache Public License 2.0. It defines concepts of abstract linear algebra using monoid and monads. This library is an excellent example of high-level functional programming using Scala (<a class="ulink" href="https://github.com/twitter/algebird">https://github.com/twitter/algebird</a>).</li><li class="listitem"><span class="strong"><strong>Breeze 0.8</strong></span> (Scala) is a <a id="id14710000" class="indexterm"/>numerical processing library using Apache Public License 2.0 originally created by David Hall. It is a component of the ScalaNLP suite of machine learning and numerical computing libraries (<a class="ulink" href="http://www.scalanlp.org/">http://www.scalanlp.org/</a>).</li></ul></div><p>The Apache Spark/MLlib framework bundles jBlas, Colt, and Breeze. The Iitb framework for conditional random fields uses Colt linear algebra components.</p><div class="note" title="Note"><h3 class="title"><a id="note37000"/>Note</h3><p>
<span class="strong"><strong>An alternative to Java/Scala libraries</strong></span>
</p><p>If your application or project needs a high-performance numerical processing tool under limited resources (CPU and RAM memory), then using a C/C++ compiled library is an excellent alternative if portability is not a constraint. The binary functions are accessed through the Java Native Interface (JNI).</p></div></div></div><div class="section" title="First order predicate logic"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec17900"/>First order predicate logic</h2></div></div></div><p>
<span class="strong"><strong>Propositional logic</strong></span> <a id="id14720000" class="indexterm"/>is<a id="id14730000" class="indexterm"/> the formulation of <span class="strong"><strong>axioms</strong></span> or propositions. There are several formal representations of propositions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Noun-VERB-Adjective</strong></span>: For example, <span class="emphasis"><em>Variance of the stock price EXCEEDS 0.76</em></span> or <span class="emphasis"><em>Minimization of the loss function DOES NOT converge</em></span></li><li class="listitem"><span class="strong"><strong>Entity-value = Boolean</strong></span>: For example, <span class="emphasis"><em>Variance of the stock price GREATER+THAN 0.76 = true</em></span> or <span class="emphasis"><em>Minimization of the loss function converge = false</em></span></li><li class="listitem"><span class="strong"><strong>Variable op value</strong></span>: For example, <span class="emphasis"><em>Variance_stock_price &gt; 0.76</em></span> or <span class="emphasis"><em>Minimization_loss_function != converge</em></span></li></ul></div><p>Propositional logic is subject to the rules of Boolean calculus. Let's consider three propositions: <span class="emphasis"><em>P</em></span>, <span class="emphasis"><em>Q</em></span>, and <span class="emphasis"><em>R</em></span> and the three Boolean operators <span class="emphasis"><em>NOT</em></span>, <span class="emphasis"><em>AND</em></span>, and <span class="emphasis"><em>OR</em></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>NOT (NOT P) = P</em></span></li><li class="listitem"><span class="emphasis"><em>P AND false = false</em></span>, <span class="emphasis"><em>P AND true = P</em></span>, <span class="emphasis"><em>P or false = P</em></span>, and <span class="emphasis"><em>P or true = P</em></span></li><li class="listitem"><span class="emphasis"><em>P AND Q = Q AND P</em></span> and <span class="emphasis"><em>P OR Q = Q OR P</em></span></li><li class="listitem"><span class="emphasis"><em>P AND (Q AND R) = (P AND Q) AND R</em></span></li></ul></div><p>
<span class="strong"><strong>First order predicate logic,</strong></span> also <a id="id14740000" class="indexterm"/>known as <span class="strong"><strong>first order predicate calculus,</strong></span> is the quantification of a propositional logic [A:7]. The most common formulations of the first order logic are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Rules (for example, <span class="emphasis"><em>IF P THEN action</em></span>)</li><li class="listitem">Existential operators</li></ul></div><p>First order logic is used to describe the classifiers in the learning classifier systems (refer to the <span class="emphasis"><em>XCS rules</em></span> section in <a class="link" title="Chapter 11. Reinforcement Learning" href="part0220.xhtml#aid-6HPRO2">Chapter 11</a>, <span class="emphasis"><em>Reinforcement Learning</em></span>).</p></div><div class="section" title="Jacobian and Hessian matrices"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18000"/>Jacobian and Hessian matrices</h2></div></div></div><p>Let's consider a function with <span class="emphasis"><em>n</em></span> variables <span class="emphasis"><em>x<sub>i</sub></em></span> and <span class="emphasis"><em>m</em></span> outputs <span class="emphasis"><em>y<sub>j</sub></em></span> such that <span class="emphasis"><em>f: {x<sub>i</sub>} -&gt; {y<sub>j</sub> =f<sub>j</sub>(x)}</em></span>.</p><p>The <a id="id14750000" class="indexterm"/><span class="strong"><strong>Jacobian matrix</strong></span> [A:8] is the matrix of the first order partial<a id="id14760000" class="indexterm"/> derivatives of the output values of a continuous, differential function:</p><div class="mediaobject"><img src="../Images/image01607.jpeg" alt="Jacobian and Hessian matrices"/></div><p style="clear:both; height: 1em;"> </p><p>The<a id="id14770000" class="indexterm"/> <span class="strong"><strong>Hessian matrix</strong></span> is<a id="id14780000" class="indexterm"/> the square matrix of the second order partial derivatives of a continuously, twice differentiable function:</p><div class="mediaobject"><img src="../Images/image01608.jpeg" alt="Jacobian and Hessian matrices"/></div><p style="clear:both; height: 1em;"> </p><p>An example is as follows:</p><div class="mediaobject"><img src="../Images/image01609.jpeg" alt="Jacobian and Hessian matrices"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Summary of optimization techniques"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18100"/>Summary of optimization techniques</h2></div></div></div><p>The same <a id="id14790000" class="indexterm"/>comments regarding linear algebra algorithms apply to optimization. Treating such techniques in depth would have rendered the book<a id="id14800000" class="indexterm"/> impractical. However, optimization is critical to the efficiency and, to a lesser extent, the accuracy of the machine learning algorithms. Some basic knowledge in this field goes a long way to build practical solutions for large datasets.</p><div class="section" title="Gradient descent methods"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23100"/>Gradient descent methods</h3></div></div></div><div class="section" title="Steepest descent"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3000"/>Steepest descent</h4></div></div></div><p>The <a id="id14810000" class="indexterm"/><span class="strong"><strong>steepest descent</strong></span> (or gradient descent) method <a id="id14820000" class="indexterm"/>is one of the simplest techniques <a id="id14830000" class="indexterm"/>used to find a local minimum of <a id="id14840000" class="indexterm"/>any continuous, differentiable function <span class="emphasis"><em>F</em></span> or the global minimum for any defined, differentiable, and convex function [A:9]. The value of a vector or data point <span class="emphasis"><em>x<sub>t+1</sub></em></span> at iteration <span class="emphasis"><em>t+1</em></span> is computed from the previous value <span class="emphasis"><em>x<sub>t</sub></em></span> using the <span class="emphasis"><em>gradient </em></span>
<span class="emphasis"><em>∇</em></span>
<span class="emphasis"><em>F</em></span> of function <span class="emphasis"><em>F</em></span> and the slope <span class="emphasis"><em>γ</em></span>:</p><div class="mediaobject"><img src="../Images/image01610.jpeg" alt="Steepest descent"/></div><p style="clear:both; height: 1em;"> </p><p>The steepest gradient algorithm is used to solve systems of nonlinear equations and minimization of the loss function in the logistic regression (refer to the <span class="emphasis"><em>Numerical optimization</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>), in support vector classifiers (refer to the <span class="emphasis"><em>The nonseparable case – the soft margin</em></span> section in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>), and in multilayer perceptrons (refer to the <span class="emphasis"><em>Training and classification</em></span> section in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span>).</p></div><div class="section" title="Conjugate gradient"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3100"/>Conjugate gradient</h4></div></div></div><p>The<a id="id14850000" class="indexterm"/> <span class="strong"><strong>conjugate gradient</strong></span> solves unconstrained<a id="id14860000" class="indexterm"/> optimization problems and systems of linear equations. It is an alternative to the LU factorization for positive, definite, and symmetric square matrices. The solution <span class="emphasis"><em>x*</em></span> of the equation <span class="emphasis"><em>Ax = b</em></span> is expanded as the weighted summation of <span class="emphasis"><em>n</em></span> basis orthogonal<a id="id14870000" class="indexterm"/> directions <span class="emphasis"><em>p<sub>i</sub></em></span> (or <span class="strong"><strong>conjugate directions</strong></span>):</p><div class="mediaobject"><img src="../Images/image01611.jpeg" alt="Conjugate gradient"/></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id14880000" class="indexterm"/>solution <span class="emphasis"><em>x*</em></span> is extracted by computing the <span class="emphasis"><em>i<sup>th</sup></em></span> conjugate vector <span class="emphasis"><em>p<sub>i</sub></em></span> and then computing the coefficients <span class="emphasis"><em>α<sub>i</sub></em></span>.</p></div><div class="section" title="Stochastic gradient descent"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3200"/>Stochastic gradient descent</h4></div></div></div><p>The<a id="id14890000" class="indexterm"/> <span class="strong"><strong>stochastic gradient</strong></span> method is a<a id="id14900000" class="indexterm"/> variant of the steepest descent that minimizes the convex function by defining the objective function <span class="emphasis"><em>F</em></span> as the sum of differentiable, basis function <span class="emphasis"><em>f<sub>i</sub></em></span>:</p><div class="mediaobject"><img src="../Images/image01612.jpeg" alt="Stochastic gradient descent"/></div><p style="clear:both; height: 1em;"> </p><p>The solution <span class="emphasis"><em>x<sub>t+1</sub></em></span> at iteration <span class="emphasis"><em>t+1</em></span> is computed from the value <span class="emphasis"><em>x<sub>t</sub></em></span> at iteration <span class="emphasis"><em>t</em></span>, the step size (or the learning rate) <span class="emphasis"><em>α</em></span>, and the sum of the gradient of the basis functions [A:10]. The stochastic gradient descent is usually faster than other gradient descents or quasi-Newton methods in converging toward a solution for convex functions. The stochastic gradient descent is used in logistic regression, support vector machines, and backpropagation neural networks.</p><p>Stochastic gradient is particularly suitable for discriminative models with large datasets [A:11]. Spark/MLlib makes extensive use of the stochastic gradient method.</p><div class="note" title="Note"><h3 class="title"><a id="note37100"/>Note</h3><p>
<span class="strong"><strong>The batch gradient descent</strong></span>
</p><p>The batch gradient descent is introduced and implemented in the <span class="emphasis"><em>Step 5 – implementing the classifier</em></span> section under <span class="emphasis"><em>Let's kick the tires</em></span> in <a class="link" title="Chapter 1. Getting Started" href="part0155.xhtml#aid-4JQ761">Chapter 1</a>, <span class="emphasis"><em>Getting Started</em></span>.</p></div></div></div><div class="section" title="Quasi-Newton algorithms"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23200"/>Quasi-Newton algorithms</h3></div></div></div><p>
<span class="strong"><strong>Quasi-Newton</strong></span> algorithms <a id="id14910000" class="indexterm"/>are variations <a id="id14920000" class="indexterm"/>of Newton's method of finding the value of a vector or data point that maximizes or minimizes a function <span class="emphasis"><em>F</em></span> (first order derivative is null) [A:12].</p><p>The Newton's method is a well-known and simple optimization method used to find the solution of equations <span class="emphasis"><em>F(x) = 0</em></span> for which <span class="emphasis"><em>F</em></span> is continuous and second order differentiable. It relies on the Taylor series expansion to approximate the function <span class="emphasis"><em>F</em></span> with a quadratic approximation of variable <span class="emphasis"><em>∆x = x<sub>t+1</sub>-x<sub>t</sub></em></span> to compute the value at the next iteration using the first order <span class="emphasis"><em>F'</em></span> and second order <span class="emphasis"><em>F"</em></span> derivatives:</p><div class="mediaobject"><img src="../Images/image01613.jpeg" alt="Quasi-Newton algorithms"/></div><p style="clear:both; height: 1em;"> </p><p>Contrary to Newton's method, quasi-Newton methods do not require that the second order derivative, Hessian matrix, of the objective function be computed; it just has to be approximated [A:13]. There are several approaches to approximate the computation of the Hessian matrix.</p><div class="section" title="BFGS"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3300"/>BFGS</h4></div></div></div><p>The <a id="id14930000" class="indexterm"/><span class="strong"><strong>Broyden-Fletcher-Goldfarb-Shanno</strong></span> (<span class="strong"><strong>BGFS</strong></span>) is a<a id="id14940000" class="indexterm"/> quasi-Newton iterative numerical method used to solve unconstrained nonlinear problems. The hessian matrix <span class="emphasis"><em>H<sub>t+1</sub></em></span> at iteration <span class="emphasis"><em>t</em></span> is approximated using the value of the previous iteration <span class="emphasis"><em>t</em></span> as <span class="emphasis"><em>H<sub>t+1</sub>=H<sub>t</sub> + U<sub>t</sub> + V<sub>t</sub></em></span> applied to the Newton equation for the direction <span class="emphasis"><em>p<sub>t</sub></em></span>:</p><div class="mediaobject"><img src="../Images/image01614.jpeg" alt="BFGS"/></div><p style="clear:both; height: 1em;"> </p><p>The BFGS is used in the minimization of the cost function for the conditional random field and L<sub>1</sub> and L<sub>2</sub> regressions.</p></div><div class="section" title="L-BFGS"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3400"/>L-BFGS</h4></div></div></div><p>The performance of the BFGS algorithm is related to the caching of the approximation of the Hessian matrix in the memory (<span class="emphasis"><em>U</em></span>, <span class="emphasis"><em>V</em></span>) at the cost of high-memory consumption.</p><p>The <a id="id14950000" class="indexterm"/><span class="strong"><strong>Limited memory Broyden-Fletcher-Goldfarb-Shanno</strong></span> (<span class="strong"><strong>L-BFGS</strong></span>) algorithm is a variant <a id="id14960000" class="indexterm"/>of BFGS that uses a minimum amount of computer RAM. The algorithm maintains the last <span class="emphasis"><em>m</em></span> incremental updates of the values <span class="emphasis"><em>∆x<sub>t</sub></em></span> and gradient <span class="emphasis"><em>∆G<sub>t</sub></em></span> at iteration <span class="emphasis"><em>t</em></span>, and then computes these values for the next step <span class="emphasis"><em>t+1</em></span>:</p><div class="mediaobject"><img src="../Images/image01615.jpeg" alt="L-BFGS"/></div><p style="clear:both; height: 1em;"> </p><p>It is supported by the Apache Commons Math 3.3+, Apache Spark/MLlib 1.0+, Colt 1.0+, and Iiitb CRF libraries. L-BFGS is used in the minimization of the loss function in conditional random fields (refer to the <span class="emphasis"><em>Conditional random fields</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>).</p></div></div><div class="section" title="Nonlinear least squares minimization"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23300"/>Nonlinear least squares minimization</h3></div></div></div><p>Let's <a id="id14970000" class="indexterm"/>consider the classic minimization<a id="id14980000" class="indexterm"/> of the least squares of a nonlinear function <span class="emphasis"><em>y = F(x, w)</em></span> with <span class="emphasis"><em>w<sub>i</sub></em></span> parameters for observations <span class="emphasis"><em>{y, x<sub>i</sub>}</em></span>. The objective is to minimize the sum of the squares of residuals <span class="emphasis"><em>r<sub>i</sub></em></span>, which is as follows:</p><div class="mediaobject"><img src="../Images/image01616.jpeg" alt="Nonlinear least squares minimization"/></div><p style="clear:both; height: 1em;"> </p><div class="section" title="Gauss-Newton"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3500"/>Gauss-Newton</h4></div></div></div><p>The <a id="id14990000" class="indexterm"/>Gauss-Newton technique <a id="id15000000" class="indexterm"/>is a generalization of Newton's method. The technique solves nonlinear least squares by updating the parameters <span class="emphasis"><em>w<sub>t+1</sub></em></span> at iteration <span class="emphasis"><em>t+1</em></span> using the first order derivative (or Jacobian):</p><div class="mediaobject"><img src="../Images/image01617.jpeg" alt="Gauss-Newton"/></div><p style="clear:both; height: 1em;"> </p><p>The <a id="id15010000" class="indexterm"/>Gauss-Newton algorithm <a id="id15020000" class="indexterm"/>is used in logistic regression (refer to the <span class="emphasis"><em>Logistic regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</p></div><div class="section" title="Levenberg-Marquardt"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec3600"/>Levenberg-Marquardt</h4></div></div></div><p>The <a id="id15030000" class="indexterm"/>Levenberg-Marquardt <a id="id15040000" class="indexterm"/>algorithm is an alternative to the Gauss-Newton technique used to solve nonlinear least squares and curve fitting problems. The method consists of adding the gradient (Jacobian) terms to the residuals <span class="emphasis"><em>r<sub>i</sub></em></span> to approximate the least squares error:</p><div class="mediaobject"><img src="../Images/image01618.jpeg" alt="Levenberg-Marquardt"/></div><p style="clear:both; height: 1em;"> </p><p>The Levenberg-Marquardt algorithm is used in the training of logistic regression (refer to the <span class="emphasis"><em>Logistic regression</em></span> section in <a class="link" title="Chapter 6. Regression and Regularization" href="part0188.xhtml#aid-5J99O2">Chapter 6</a>, <span class="emphasis"><em>Regression and Regularization</em></span>).</p></div></div><div class="section" title="Lagrange multipliers"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23400"/>Lagrange multipliers</h3></div></div></div><p>The <a id="id15050000" class="indexterm"/><span class="strong"><strong>Lagrange multipliers</strong></span> <a id="id15060000" class="indexterm"/>methodology is an optimization technique used to find the local optima of a multivariate function, subject to equality constraints [A:14]. The problem is stated as <span class="emphasis"><em>maximize f(x) subject to g(x) = c, where c is a constant and x is a variable or features vector</em></span>.</p><p>This methodology introduces a new variable <span class="emphasis"><em>λ</em></span> to integrate the constraint <span class="emphasis"><em>g</em></span> into a function, known as the Lagrange function <span class="emphasis"><em>ℒ</em></span>
<span class="emphasis"><em>(x, λ)</em></span>. Let's note <span class="emphasis"><em>∇ℒ</em></span>, which is the gradient of <span class="emphasis"><em>ℒ</em></span> over the variables <span class="emphasis"><em>x<sub>i</sub></em></span> and <span class="emphasis"><em>λ</em></span>. The Lagrange multipliers are computed by maximizing <span class="emphasis"><em>ℒ</em></span>:</p><div class="mediaobject"><img src="../Images/image01619.jpeg" alt="Lagrange multipliers"/></div><p style="clear:both; height: 1em;"> </p><p>An example is as follows:</p><div class="mediaobject"><img src="../Images/image01620.jpeg" alt="Lagrange multipliers"/></div><p style="clear:both; height: 1em;"> </p><p>Lagrange<a id="id15070000" class="indexterm"/> multipliers <a id="id15080000" class="indexterm"/>are used to minimize the loss function in the nonseparable case of linear support vector machines (refer to the <span class="emphasis"><em>The nonseparable case – the soft margin case</em></span> section in <a class="link" title="Chapter 8. Kernel Models and Support Vector Machines" href="part0200.xhtml#aid-5UNGG2">Chapter 8</a>, <span class="emphasis"><em>Kernel Models and Support Vector Machines</em></span>).</p></div></div><div class="section" title="Overview of dynamic programming"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18200"/>Overview of dynamic programming</h2></div></div></div><p>The purpose <a id="id15090000" class="indexterm"/>of <span class="strong"><strong>dynamic programming</strong></span> is to break<a id="id15100000" class="indexterm"/> down an optimization problem into a sequence of steps known as <a id="id15110000" class="indexterm"/><span class="strong"><strong>substructures</strong></span> [A:15]. There are two types of problems for which dynamic programming is suitable.</p><p>The solution of a global optimization problem can be broken down into optimal solutions for its subproblems. The solution of the subproblems is known as <a id="id15120000" class="indexterm"/><span class="strong"><strong>optimal substructures</strong></span>. Greedy algorithms or the computation of the minimum span of a graph are examples of the decomposition into optimal substructures. Such algorithms can be implemented either recursively or iteratively.</p><p>The solution of the global problem is applied recursively to the subproblems if the number of subproblems is small. This<a id="id15130000" class="indexterm"/> approach is known as dynamic programming using <span class="strong"><strong>overlapping substructures</strong></span>. Forward-backward passes on hidden Markov models, the Viterbi algorithm (refer to <span class="emphasis"><em>The Viterbi algorithm</em></span> section in <a class="link" title="Chapter 7. Sequential Data Models" href="part0193.xhtml#aid-5O1SI1">Chapter 7</a>, <span class="emphasis"><em>Sequential Data Models</em></span>), or the backpropagation of error in a multilayer perceptron (refer to the <span class="emphasis"><em>Step 2 – error backpropagation</em></span> section in <a class="link" title="Chapter 9. Artificial Neural Networks" href="part0207.xhtml#aid-65D4E1">Chapter 9</a>, <span class="emphasis"><em>Artificial Neural Networks</em></span>) are good examples of overlapping substructures.</p><p>The <a id="id15140000" class="indexterm"/>mathematical <a id="id15150000" class="indexterm"/>formulation of a dynamic programming solution is specific to the problem it attempts to resolve. Dynamic programming techniques are also commonly used in mathematical puzzles such as <span class="emphasis"><em>The Tower of Hanoi</em></span>.</p></div></div>
<div class="section" title="Finances 101"><div class="titlepage" id="aid-6S9HU2"><div><div><h1 class="title"><a id="ch12lvl1sec8500"/>Finances 101</h1></div></div></div><p>The <a id="id15160000" class="indexterm"/>exercises presented throughout this book are related to historical financial data and require the reader to have some basic understanding of financial markets and reports.</p><div class="section" title="Fundamental analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18300"/>Fundamental analysis</h2></div></div></div><p>Fundamental analysis <a id="id15170000" class="indexterm"/>is a set of techniques used to evaluate a security (stock, bond, currency, or commodity) that entails attempting to measure its intrinsic <a id="id15180000" class="indexterm"/>value by examining both macro and micro financial and economy reports. Fundamental analysis is usually applied to estimate the optimal price of a stock using a variety of financial ratios.</p><p>Numerous financial metrics are used throughout this book. Here are the definitions of the most commonly used metrics [A:16]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Earnings per share (EPS)</strong></span>: This is <a id="id15190000" class="indexterm"/>the ratio of net earnings to the number of outstanding shares.</li><li class="listitem"><span class="strong"><strong>Price/earnings ratio (PE)</strong></span>: This <a id="id15200000" class="indexterm"/>is the ratio of the market price per share to earnings per share.</li><li class="listitem"><span class="strong"><strong>Price/sales ratio (PS)</strong></span>: This <a id="id15210000" class="indexterm"/>is the ratio of the market price per share to gross sales (or revenue).</li><li class="listitem"><span class="strong"><strong>Price/book value ratio (PB)</strong></span>: This<a id="id15220000" class="indexterm"/> is the ratio of the market price per share to the total balance sheet value per share.</li><li class="listitem"><span class="strong"><strong>Price to earnings/growth (PEG)</strong></span>: This <a id="id15230000" class="indexterm"/>is the ratio of price/earnings per share (PE) to the annual growth of earnings per share.</li><li class="listitem"><span class="strong"><strong>Operating income</strong></span>: This is <a id="id15240000" class="indexterm"/>the difference between the operating revenue and operating expenses.</li><li class="listitem"><span class="strong"><strong>Net sales</strong></span>: This is <a id="id15250000" class="indexterm"/>the difference between the revenue or gross sales and cost of goods or cost of sales.</li><li class="listitem"><span class="strong"><strong>Operating profit margin</strong></span>: This<a id="id15260000" class="indexterm"/> is the ratio of the operating income to the net sales.</li><li class="listitem"><span class="strong"><strong>Net profit margin</strong></span>: This <a id="id15270000" class="indexterm"/>is the ratio of the net profit to the net sales (or the net revenue).</li><li class="listitem"><span class="strong"><strong>Short interest</strong></span>: This<a id="id15280000" class="indexterm"/> is the quantity of shares sold short and not yet covered.</li><li class="listitem"><span class="strong"><strong>Short interest ratio</strong></span>: This<a id="id15290000" class="indexterm"/> is the ratio of the short interest to the total number of shares floated.</li><li class="listitem"><span class="strong"><strong>Cash per share</strong></span>: This <a id="id15300000" class="indexterm"/>is the ratio of the value of cash per share to the market price per share.</li><li class="listitem"><span class="strong"><strong>Pay-out ratio</strong></span>: This<a id="id15310000" class="indexterm"/> is the percentage of the primary/basic earnings per share, excluding extraordinary items paid to common stockholders in the form of cash dividends.</li><li class="listitem"><span class="strong"><strong>Annual dividend yield</strong></span>: This<a id="id15320000" class="indexterm"/> is the ratio of the sum of dividends paid during the previous 12-month rolling period over the current stock price. Regular and extra dividends are included.</li><li class="listitem"><span class="strong"><strong>Dividend coverage ratio</strong></span>: This<a id="id15330000" class="indexterm"/> is the ratio of the income available to common stockholders, excluding extraordinary items, for the most recent trailing 12 months to gross dividends paid to common shareholders, expressed as percent.</li><li class="listitem"><span class="strong"><strong>Gross Domestic Product</strong></span> (<span class="strong"><strong>GDP</strong></span>): This<a id="id15340000" class="indexterm"/> is the aggregate measure of the economic output of a country. It actually measures the sum of values added by the production of goods and delivery of services.</li><li class="listitem"><span class="strong"><strong>Consumer Price Index</strong></span> (<span class="strong"><strong>CPI</strong></span>): This<a id="id15350000" class="indexterm"/> is an indicator that measures the change in the price of an arbitrary basket of goods and services used by the Bureau of Labor Statistics to evaluate the inflationary trend.</li><li class="listitem"><span class="strong"><strong>Federal Fund rate</strong></span>: This is <a id="id15360000" class="indexterm"/>the interest rate at which banks trade balances held at the Federal Reserve. The balances are called Federal Funds.</li></ul></div></div><div class="section" title="Technical analysis"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18400"/>Technical analysis</h2></div></div></div><p>
<span class="emphasis"><em>Technical analysis is a methodology used to forecast the direction of the price of any given security through the study of the past market information derived from price and volume</em></span>. In simpler <a id="id15370000" class="indexterm"/>terms, it is the study of price activity and price patterns in order to identify trade opportunities [A:17]. The price of a stock, commodity, bond, or financial future reflects all the information publicly known about that asset <a id="id15380000" class="indexterm"/>as processed by the market participants.</p><div class="section" title="Terminology"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23500"/>Terminology</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Bearish or bearish position</strong></span>: This<a id="id15390000" class="indexterm"/> attempts to profit by betting that the prices of the security will fall.</li><li class="listitem"><span class="strong"><strong>Bullish or bullish position</strong></span>: This<a id="id15400000" class="indexterm"/> attempts to profit by betting that the price of the security will rise.</li><li class="listitem"><span class="strong"><strong>Long position</strong></span>: This<a id="id15410000" class="indexterm"/> is the same as Bullish.</li><li class="listitem"><span class="strong"><strong>Neutral position</strong></span>: This <a id="id15420000" class="indexterm"/>attempts to profit by betting that the price of the security will not change significantly.</li><li class="listitem"><span class="strong"><strong>Oscillator</strong></span>: This <a id="id15430000" class="indexterm"/>is a technical indicator that measures the price momentum of a security using some statistical formula.</li><li class="listitem"><span class="strong"><strong>Overbought</strong></span>: This<a id="id15440000" class="indexterm"/> is a security that is overbought when its price rises too fast as measured by one or several trading signals or indicators.</li><li class="listitem"><span class="strong"><strong>Oversold</strong></span>: This<a id="id15450000" class="indexterm"/> is a security that is oversold when its price drops too fast as measured by one or several trading signals or indicators.</li><li class="listitem"><span class="strong"><strong>Relative strength index</strong></span> (<span class="strong"><strong>RSI</strong></span>): This <a id="id15460000" class="indexterm"/>is an oscillator that computes the average of number of trading sessions for which the closing price is higher than the opening price over the average of number of trading sessions for which the closing price is lower than the opening price. The value is normalized over [0, 1] or [0, 100%].</li><li class="listitem"><span class="strong"><strong>Resistance</strong></span>: This<a id="id15470000" class="indexterm"/> is the upper limit of the price range of a security. The price falls back as soon as it reaches the resistance level.</li><li class="listitem"><span class="strong"><strong>Short position</strong></span>: This<a id="id15480000" class="indexterm"/> is the same as Bearish.</li><li class="listitem"><span class="strong"><strong>Support</strong></span>: This is <a id="id15490000" class="indexterm"/>the lower limit of the price range of a security over a period of time. The price bounces back as soon as it reaches the support level.</li><li class="listitem"><span class="strong"><strong>Technical indicator:</strong></span> This<a id="id15500000" class="indexterm"/> is a variable derived from the price of a security and possibly its trading volume.</li><li class="listitem"><span class="strong"><strong>Trading range</strong></span>: The <a id="id15510000" class="indexterm"/>trading range for a security over a period of time is the difference between the highest and lowest price for this period of time.</li><li class="listitem"><span class="strong"><strong>Trading signal</strong></span>: This<a id="id15520000" class="indexterm"/> is a signal that is triggered when a technical indicator reaches a predefined value, upward or downward.</li><li class="listitem"><span class="strong"><strong>Volatility</strong></span>: This is<a id="id15530000" class="indexterm"/> the variance or standard deviation of the price of a security over a period of time.</li></ul></div></div><div class="section" title="Trading data"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23600"/>Trading data</h3></div></div></div><p>The raw <a id="id15540000" class="indexterm"/>trading data extracted from Google or Yahoo financials pages consists of the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>adjClose</strong></span> (or <span class="strong"><strong>close</strong></span>): This is the adjusted or nonadjusted price of a security at closing of the trading session</li><li class="listitem"><span class="strong"><strong>open</strong></span>: This is the price of the security at the opening of the trading session</li><li class="listitem"><span class="strong"><strong>high</strong></span>: This is the highest price of the security during the trading session</li><li class="listitem"><span class="strong"><strong>low</strong></span>: This is the lowest price of the security during the trading session</li></ul></div><p>Let's take a look at the following graph:</p><div class="mediaobject"><img src="../Images/image01621.jpeg" alt="Trading data"/></div><p style="clear:both; height: 1em;"> </p><p>We can derive<a id="id15550000" class="indexterm"/> the following metrics from the raw trading data:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Price volatility: <span class="emphasis"><em>volatility = 1.0 – high/low</em></span></li><li class="listitem">Price variation: <span class="emphasis"><em>vPrice = adjClose – open</em></span></li><li class="listitem">Price difference (or change) between two consecutive sessions: <span class="emphasis"><em>dPrice = adjClose – prevClose = adjClose(t) – adjClose(t-1)</em></span></li><li class="listitem">Volume difference between two consecutive sessions: <span class="emphasis"><em>dVolume = volume(t)/volume(t-1) – 1.0</em></span></li><li class="listitem">Volatility difference between two consecutive sessions: <span class="emphasis"><em>dVolatility = volatility(t)/volatility(t-1) – 1.0</em></span></li><li class="listitem">Relative price variation over the last <span class="emphasis"><em>T</em></span> trading days: <span class="emphasis"><em>rPrice = price(t)/average(price over T) – 1.0</em></span></li><li class="listitem">Relative volume variation over the last <span class="emphasis"><em>T</em></span> trading days: <span class="emphasis"><em>rVolume = volume(t)/average(volume over T) – 1.0</em></span></li><li class="listitem">Relative volatility variation over the last <span class="emphasis"><em>T</em></span> trading days: <span class="emphasis"><em>rVolatility = volatility(t)/average(volatility over T) – 1.0</em></span></li></ul></div></div><div class="section" title="Trading signals and strategy"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23700"/>Trading signals and strategy</h3></div></div></div><p>The purpose <a id="id15560000" class="indexterm"/>is to create a set variable <span class="emphasis"><em>x</em></span>, derived from price and volume <span class="emphasis"><em>x= f (price, volume)</em></span>, and then generate predicates <span class="emphasis"><em>x op c</em></span> for which <span class="emphasis"><em>op</em></span> is a Boolean operator, such as <span class="emphasis"><em>&gt;</em></span> or <span class="emphasis"><em>=</em></span> that compares the value of <span class="emphasis"><em>x</em></span> to a predetermined threshold <span class="emphasis"><em>c</em></span>.</p><p>Let's consider one of the most common technical indicators derived from price: the relative strength index <span class="emphasis"><em>RSI</em></span> or the normalized RSI <span class="emphasis"><em>nRSI</em></span>, whose formulation is provided here as a reference:</p><div class="note" title="Note"><h3 class="title"><a id="note37200"/>Note</h3><p>
<span class="strong"><strong>The relative strength index</strong></span>
</p><p>The RSI for a period of <span class="emphasis"><em>T</em></span> sessions with <span class="emphasis"><em>p<sub>o</sub></em></span> opening price and <span class="emphasis"><em>p<sub>c</sub></em></span> closing price is defined as:</p><div class="mediaobject"><img src="../Images/image01622.jpeg" alt="Trading signals and strategy"/></div><p style="clear:both; height: 1em;"> </p></div><p>A <span class="strong"><strong>trading signal</strong></span> is a<a id="id15570000" class="indexterm"/> predicate using a technical indicator <span class="emphasis"><em>nRSI<sub>T</sub>(t) &lt; 0.2</em></span>. In trading terminology, a signal is emitted for any time period <span class="emphasis"><em>t</em></span> for which the predicate is true:</p><div class="mediaobject"><img src="../Images/image01623.jpeg" alt="Trading signals and strategy"/><div class="caption"><p>The visualization of oversold and overbought positions using the relative strength index</p></div></div><p style="clear:both; height: 1em;"> </p><p>Traders do <a id="id15580000" class="indexterm"/>not usually rely on a single trading signal to make a rational decision.</p><p>For example, if <span class="emphasis"><em>G</em></span> is the price of gold, <span class="emphasis"><em>I<sub>10</sub></em></span> is the current rate of the 10-year Treasury bond, and <span class="emphasis"><em>RSI<sub>sp500</sub></em></span> is the relative strength index of the S&amp;P 500 index, then we can conclude that the increase in the exchange rate of US$ to the Japanese Yen is maximized for the following trading strategy: <span class="emphasis"><em>{G &lt; $1170 and I<sub>10</sub></em></span>
<span class="emphasis"><em> &gt; 3.9% and RSI<sub>sp500</sub></em></span>
<span class="emphasis"><em> &gt; 0.6 and RSI<sub>sp500</sub></em></span>
<span class="emphasis"><em> &lt; 0.8}</em></span>.</p></div><div class="section" title="Price patterns"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec23800"/>Price patterns</h3></div></div></div><p>Technical analysis <a id="id15590000" class="indexterm"/>assumes that historical prices contains some <a id="id15600000" class="indexterm"/>recurring albeit noisy, patterns that can be discovered using statistical methods. The most common patterns used in this book are the trend, support, and resistance levels [A:18], as illustrated in the following chart:</p><div class="mediaobject"><img src="../Images/image01624.jpeg" alt="Price patterns"/><div class="caption"><p>An illustration of trend, support, and resistance levels in technical analysis</p></div></div><p style="clear:both; height: 1em;"> </p></div></div><div class="section" title="Options trading"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18500"/>Options trading</h2></div></div></div><p>An <a id="id15610000" class="indexterm"/>option is a <a id="id15620000" class="indexterm"/>contract that gives the buyer the right, but not the obligation, to buy or sell a security at a specific price on or before a certain date [A:19].</p><p>The two types of options are calls and puts, as described here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">A call gives the holder the right to buy a security at a certain price within a specific period of time. Buyers of calls expect that the price of the security will increase substantially over the strike price before the option expires.</li><li class="listitem">A put option gives the holder the right to sell a security at a certain price within a specific period of time. Buyers of puts expect that the price of the stock will fall below the strike price before the option expires.</li></ul></div><p>Let's consider a call option contract of 100 shares at a strike price of $23 for a total cost of $270 ($2.7 per option). The maximum loss the holder of the call can incur is the loss of premium or $270 when the option expires. However, the profit can be potentially almost unlimited. If the price of the security reaches $36 when the call option expires, the owner will have a profit of ($36 - $23)*100 - $270 = $1030. The return on the investment is 1030/270 = 380%. Buying and then selling the stock would have generated a return on the investment of 36/24 -1= 50%. This example is simple and does not take into account a transaction <a id="id15630000" class="indexterm"/>fee or margin cost [A:20]:</p><p>Let's take a <a id="id15640000" class="indexterm"/>look at the following chart:</p><div class="mediaobject"><img src="../Images/image01625.jpeg" alt="Options trading"/><div class="caption"><p>An illustration of the pricing of a call option</p></div></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Financial data sources"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec18600"/>Financial data sources</h2></div></div></div><p>There are numerous<a id="id15650000" class="indexterm"/> sources of financial data available to experiment with machine learning and validation models [A:21]:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Yahoo finances (stocks, ETFs, and indices): <a class="ulink" href="http://finance.yahoo.com">http://finance.yahoo.com</a></li><li class="listitem">Google finances (stocks, ETFs, and indices): <a class="ulink" href="https://www.google.com/finance">https://www.google.com/finance</a></li><li class="listitem">NASDAQ (stocks, ETFs, and indices): <a class="ulink" href="http://www.nasdaq.com">http://www.nasdaq.com</a></li><li class="listitem">European Central Bank (European bonds and notes): <a class="ulink" href="http://www.ecb.int">http://www.ecb.int</a></li><li class="listitem">TrueFx (Forex): <a class="ulink" href="http://www.truefx.com">http://www.truefx.com</a></li><li class="listitem">Quandl (Economics and financials statistics): <a class="ulink" href="http://www.quantl.com">http://www.quantl.com</a></li><li class="listitem">Dartmouth University (portfolio and simulation): <a class="ulink" href="http://mba.tuck.dartmouth.edu">http://mba.tuck.dartmouth.edu</a></li></ul></div></div></div>
<div class="section" title="Suggested online courses" id="aid-6T82G1"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec8600"/>Suggested online courses</h1></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="emphasis"><em>Practical Machine Learning</em></span>, J. Leek, R. Peng, B. Caffo, Johns Hopkins University (<a class="ulink" href="https://www.coursera.org/jhu">https://www.coursera.org/jhu</a>)</li><li class="listitem"><span class="emphasis"><em>Probabilistic Graphical Models</em></span>, D. Koller, Stanford University (<a class="ulink" href="https://www.coursera.org/course/pgm">https://www.coursera.org/course/pgm</a>)</li><li class="listitem"><span class="emphasis"><em>Machine Learning</em></span>, A. Ng, Stanford University (<a class="ulink" href="https://www.coursera.org/course/ml">https://www.coursera.org/course/ml</a>)</li></ul></div></div>
<div class="section" title="References" id="aid-6U6J21"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec8700"/>References</h1></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">[A:1] <span class="emphasis"><em>Daily Scala: Enumeration</em></span>. J. Eichar. 2009 (<a class="ulink" href="http://daily-scala.blogspot.com/2009/08/enumerations.html">http://daily-scala.blogspot.com/2009/08/enumerations.html</a>)</li><li class="listitem">[A:2] <span class="emphasis"><em>Matrices and Linear Transformations 2nd Edition</em></span>. C. Cullen. Dover Books on Mathematics. 1990</li><li class="listitem">[A:3] <span class="emphasis"><em>Linear Algebra: A Modern Introduction</em></span>. D Poole. BROOKS/COLE CENGAGE Learning. 2010</li><li class="listitem">[A:4] <span class="emphasis"><em>Matrix decomposition for regression analysis</em></span>. D. Bates. 2007 (<a class="ulink" href="http://www.stat.wisc.edu/courses/st849-bates/lectures/Orthogonal.pdf">http://www.stat.wisc.edu/courses/st849-bates/lectures/Orthogonal.pdf</a>)</li><li class="listitem">[A:5] <span class="emphasis"><em>Eigenvalues and Eigenvectors of Symmetric Matrices</em></span>. I. Mateev. 2013 (<a class="ulink" href="http://www.slideshare.net/vanchizzle/eigenvalues-and-eigenvectors-of-symmetric-matrices">http://www.slideshare.net/vanchizzle/eigenvalues-and-eigenvectors-of-symmetric-matrices</a>)</li><li class="listitem">[A:6] <span class="emphasis"><em>Linear Algebra Done Right 2nd Edition</em></span> (§5 Eigenvalues and Eigenvectors) S Axler. Springer. 2000</li><li class="listitem">[A:7] <span class="emphasis"><em>First Order Predicate Logic</em></span>. S. Kaushik. CSE India Institute of Technology, Delhi (<a class="ulink" href="http://www.cse.iitd.ac.in/~saroj/LFP/LFP_2013/L4.pdf">http://www.cse.iitd.ac.in/~saroj/LFP/LFP_2013/L4.pdf</a>)</li><li class="listitem">[A:8] <span class="emphasis"><em>Matrix Recipes</em></span>. J. Movellan. 2005 (<a class="ulink" href="http://www.math.vt.edu/people/dlr/m2k_svb11_hesian.pdf">http://www.math.vt.edu/people/dlr/m2k_svb11_hesian.pdf</a>)</li><li class="listitem">[A:9] <span class="emphasis"><em>Gradient descent</em></span>. Wikipedia (<a class="ulink" href="http://en.wikipedia.org/wiki/Gradient_descent">http://en.wikipedia.org/wiki/Gradient_descent</a>)</li><li class="listitem">[A:10] <span class="emphasis"><em>Large Scale Machine Learning: Stochastic Gradient Descent Convergence</em></span>. A. Ng. Stanford University (<a class="ulink" href="https://class.coursera.org/ml-003/lecture/107">https://class.coursera.org/ml-003/lecture/107</a>)</li><li class="listitem">[A:11] <span class="emphasis"><em>Large-Scala Machine Learning with Stochastic Gradient Descent</em></span>. L Bottou. 2010 (<a class="ulink" href="http://leon.bottou.org/publications/pdf/compstat-2010.pdf">http://leon.bottou.org/publications/pdf/compstat-2010.pdf</a>)</li><li class="listitem">[A:12] <span class="emphasis"><em>Overview of Quasi-Newton optimization methods</em></span>. Dept. Computer Science, University of Washington (<a class="ulink" href="https://homes.cs.washington.edu/~galen/files/quasi-newton-notes.pdf">https://homes.cs.washington.edu/~galen/files/quasi-newton-notes.pdf</a>)</li><li class="listitem">[A:13] <span class="emphasis"><em>Lecture 2-3: Gradient and Hessian of Multivariate Function</em></span>. M. Zibulevsky. 2013 (<a class="ulink" href="http://www.youtube.com">http://www.youtube.com</a>)</li><li class="listitem">[A:14] <span class="emphasis"><em>Introduction to the Lagrange Multiplier</em></span>. ediwm.com video (<a class="ulink" href="http://www.noodle.com/learn/details/334954/introduction-to-the-lagrange-multiplier">http://www.noodle.com/learn/details/334954/introduction-to-the-lagrange-multiplier</a>)</li><li class="listitem">[A:15] <span class="emphasis"><em>A brief introduction to Dynamic Programming (DP)</em></span>. A. Kasibhatla. Nanocad Lab (<a class="ulink" href="http://nanocad.ee.ucla.edu/pub/Main/SnippetTutorial/Amar_DP_Intro.pdf">http://nanocad.ee.ucla.edu/pub/Main/SnippetTutorial/Amar_DP_Intro.pdf</a>)</li><li class="listitem">[A:16] <span class="emphasis"><em>Financial ratios</em></span>. Wikipedia (<a class="ulink" href="http://en.wikipedia.org/wiki/Financial_ratio">http://en.wikipedia.org/wiki/Financial_ratio</a>)</li><li class="listitem">[A:17] <span class="emphasis"><em>Getting started in Technical Analysis</em></span> (§1 Charts: Forecasting Tool or Folklore?) J Schwager. John Wiley &amp; Sons. 1999</li><li class="listitem">[A:18] <span class="emphasis"><em>Getting started in Technical Analysis</em></span> (§4 Trading Ranges, Support &amp; Resistance) J Schwager. John Wiley &amp; Sons. 1999</li><li class="listitem">[A:19] <span class="emphasis"><em>Options: a personal seminar</em></span> (§1 Options: An Introduction, What is an Option) S. Fullman, New York Institute of Finance. Simon Schuster. 1992</li><li class="listitem">[A:20] <span class="emphasis"><em>Options: a personal seminar</em></span> (§2 Purchasing Options) S. Fullman New York Institute of Finance. Simon Schuster. 1992</li><li class="listitem">[A:21] <span class="emphasis"><em>List of financial data feeds</em></span>. Wikipedia (<a class="ulink" href="http://en.wikipedia.org/wiki/List_of_financial_data_feeds">http://en.wikipedia.org/wiki/List_of_financial_data_feeds</a>)</li></ul></div></div></body></html>