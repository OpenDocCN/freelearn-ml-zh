- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Working with Data in AMLS
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AMLS 中处理数据
- en: In **Machine Learning** (**ML**), regardless of the use case or the algorithm
    we use, an important component that will always be used is data. Without data,
    you cannot build machine learning models. The quality of the data is very critical
    for building performant models. Complex models such as deep neural networks require
    a lot more data than simpler models. Data in an ML workflow will often come from
    a variety of data sources and require different methods to be leveraged for data
    processing, cleansing, and feature selection. During this process of feature engineering,
    your Azure Machine Learning workspace will be leveraged to empower you to collaboratively
    work with your data. This will ensure secure connectivity to a variety of data
    sources, as well as enable you to register your datasets for use in training,
    testing, and validation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **机器学习**（**ML**）中，无论使用案例或使用的算法如何，始终会使用的一个重要组件是数据。没有数据，您无法构建机器学习模型。数据的质量对于构建性能良好的模型至关重要。复杂的模型，如深度神经网络，需要比简单模型更多的数据。在
    ML 工作流程中的数据通常来自各种数据源，并需要不同的方法来利用数据处理、清理和特征选择。在这个过程中进行特征工程时，您的 Azure 机器学习工作区将得到利用，使您能够与数据协作工作。这将确保安全地连接到各种数据源，并使您能够注册数据集以用于训练、测试和验证。
- en: As an example of steps within this workflow, we may be required to take raw
    data, join with an additional dataset, cleanse data to remove duplicates, fill
    in missing values, and perform an initial analysis to identify outliers and skew
    in our data. This can be done even before an algorithm is selected to begin building
    a model to train leveraging our features and labels within our dataset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作为此工作流程中步骤的示例，我们可能需要获取原始数据，与额外的数据集合并，清理数据以删除重复项，填补缺失值，并对数据进行初步分析以识别异常值和偏斜。这甚至可以在选择算法开始构建用于训练的模型之前完成，利用数据集中的特征和标签。
- en: Azure Machine Learning provides methods for connecting to a variety of data
    sources and registering datasets to be used to build a model, so you can use your
    data in a business context.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习提供了连接到各种数据源并将数据集注册为用于构建模型的方法，因此您可以在业务环境中使用您的数据。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Azure Machine Learning datastore overview
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 机器学习数据存储概述
- en: Creating a Blob Storage account datastore
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Blob 存储帐户数据存储
- en: Creating Azure Machine Learning data assets
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Azure 机器学习数据资产
- en: Using Azure Machine Learning data assets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Azure 机器学习数据资产
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Read [*Chapter 1*](B18003_01.xhtml#_idTextAnchor020), *Introducing the Azure
    Machine Learning Service*, to get the environment workspace created to use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读第 *1 章*[*介绍 Azure 机器学习服务*](B18003_01.xhtml#_idTextAnchor020)，以获取创建用于使用的环境工作区。
- en: 'These are the prerequisites for the chapter:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的先决条件如下：
- en: Access to the internet.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问互联网。
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络浏览器，最好是 Google Chrome 或 Microsoft Edge Chromium。
- en: A supported storage service.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持的存储服务。
- en: Access to supported storage.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问支持的存储。
- en: To access the Azure machine learning service workspace, please go to [https://ml.azure.com](https://ml.azure.com).
    Select the workspace from the drop-down list on the left in your web browser.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要访问 Azure 机器学习服务工作区，请访问 [https://ml.azure.com](https://ml.azure.com)。在您的网页浏览器左侧的下拉列表中选择工作区。
- en: Azure Machine Learning datastore overview
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 机器学习数据存储概述
- en: Within an Azure Machine Learning workspace, a storage service that is the source
    of data is registered as a datastore for reusability. A datastore securely holds
    connectivity information for accessing data within the key vault that was created
    with your Azure Machine Learning workspace. The credentials supplied to the datastore
    are used to access the data within a given data service. These datastores can
    be created via the Azure Machine Learning Studio through the Azure Machine Learning
    SDK for Python, or the Azure Machine Learning **command-line interface** (**CLI**).
    Datastores enable data scientists to connect to data by name rather than passing
    connection information within scripts. This allows the portability of code through
    different environments (in different environments, a datastore may point to different
    services) and prevents the leaking of sensitive credentials.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure 机器学习工作区中，作为数据源的服务存储被注册为数据存储以实现可重用性。数据存储安全地保存了访问与您使用 Azure 机器学习工作区创建的密钥库中数据的连接信息。提供给数据存储的凭据用于访问给定数据服务中的数据。这些数据存储可以通过
    Azure 机器学习工作室通过 Azure 机器学习 Python SDK 或 Azure 机器学习 **命令行界面**（**CLI**）创建。数据存储使数据科学家能够通过名称连接到数据，而不是在脚本中传递连接信息。这允许代码在不同环境之间（在不同的环境中，数据存储可能指向不同的服务）的可移植性，并防止敏感凭据泄露。
- en: 'Supported datastores include the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 支持的数据存储包括以下内容：
- en: Azure Blob Storage
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Blob Storage
- en: Azure SQL Database
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure SQL Database
- en: Azure Data Lake Gen 1 (deprecated)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Data Lake Gen 1 (已弃用)
- en: Azure Data Lake Gen 2
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Data Lake Gen 2
- en: Azure file share
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 文件共享
- en: Azure Database for PostgreSQL
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Database for PostgreSQL
- en: Azure Database for MySQL
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure Database for MySQL
- en: Databricks File System
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Databricks 文件系统
- en: Each of the supported datastores will have an authentication type associated
    with the data service. When creating a datastore, the authentication type will
    be selected and leveraged within the Azure Machine Learning workspace. Note that
    Azure Database for MySQL is currently only supported for the `DataTransferStep`
    pipeline and thus cannot be created with Azure Machine Learning Studio. The Databricks
    File System is only supported for the `DatabricksStep` pipeline, and thus cannot
    be created leveraging Azure Machine Learning Studio.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 每个支持的数据存储都将与数据服务关联一个认证类型。在创建数据存储时，认证类型将在 Azure 机器学习工作区中选中并使用。请注意，目前 Azure Database
    for MySQL 仅支持 `DataTransferStep` 管道，因此无法使用 Azure 机器学习工作室创建。Databricks 文件系统仅支持
    `DatabricksStep` 管道，因此无法利用 Azure 机器学习工作室创建。
- en: 'The following table provides the authentication options for the Azure Storage
    types available for use with your Azure Machine Learning workspace:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下表提供了可用于与您的 Azure 机器学习工作区一起使用的 Azure 存储类型的认证选项：
- en: '| **Storage Type** | **Authentication** **Options Available** |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| **存储类型** | **认证** **选项** |'
- en: '| Azure Blob Container | SAS token, account key |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Azure Blob Container | SAS 令牌，账户密钥 |'
- en: '| Azure SQL Database | Service principal, SQL authentication |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Azure SQL Database | 服务主体, SQL 认证 |'
- en: '| Azure Data Lake Gen 1 | Service principal |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| Azure Data Lake Gen 1 | 服务主体 |'
- en: '| Azure Data Lake Gen 2 | Service principal |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| Azure Data Lake Gen 2 | 服务主体 |'
- en: '| Azure File Share | SAS token, account key |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Azure File Share | SAS 令牌，账户密钥 |'
- en: '| Azure Database for PostgreSQL | SQL authentication |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Azure Database for PostgreSQL | SQL 认证 |'
- en: '| Azure Database for MySQL | SQL authentication |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Azure Database for MySQL | SQL 认证 |'
- en: '| Databricks File System | No authentication |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Databricks 文件系统 | 无认证 |'
- en: Figure 2.1 – Supported authentication for Azure Storage types
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – Azure 存储类型的支持认证
- en: Now that you have an understanding of the types of supported datastores, in
    the next section, you will learn how to connect your Azure Machine Learning workspace
    to datastores that you can use within your ML workflow. The most common and recommended
    datastore is an Azure blob container. In fact, one was created for you in [*Chapter
    1*](B18003_01.xhtml#_idTextAnchor020), *Introducing the Azure Machine Learning
    Service*, as part of the workspace deployment process.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '现在您已经了解了支持的数据存储类型，在下一节中，您将学习如何将您的 Azure 机器学习工作区连接到您可以在您的 ML 工作流程中使用的数据存储。最常见且推荐的数据存储是一个
    Azure Blob 容器。事实上，在 [*第 1 章*](B18003_01.xhtml#_idTextAnchor020)，*介绍 Azure 机器学习服务*，作为工作区部署过程的一部分，为您创建了一个。 '
- en: Before continuing to the next section to create datastores using Azure Machine
    Learning Studio, the Python SDK, and the Azure Machine Learning CLI, we will briefly
    review the default datastore that was created for you.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续到下一节，使用 Azure Machine Learning Studio、Python SDK 和 Azure Machine Learning
    CLI 创建数据存储之前，我们将简要回顾为您创建的默认数据存储。
- en: Default datastore review
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 默认数据存储回顾
- en: As noted in [*Chapter 1*](B18003_01.xhtml#_idTextAnchor020), *Introducing the
    Azure Machine Learning Service*, the left navigation includes a **Data** section,
    which you can use to access the datastores, as shown in *Figure 2**.2*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第 1 章*](B18003_01.xhtml#_idTextAnchor020)中所述，*介绍 Azure Machine Learning 服务*，左侧导航包括一个**数据**部分，您可以使用它来访问数据存储，如图
    *图 2**.2* 所示。
- en: Tip
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Clicking on the hamburger icon on the top of the left navigation within your
    workspace will include words with the icons in your navigation bar.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在您工作区的左侧导航顶部点击汉堡图标，将在您的导航栏中包含带有图标的文字。
- en: 'If you click on the **Datastore** tab, you can see the storage accounts that
    have already been created for your workspace:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您点击**数据存储**选项卡，您可以看到为您的工作区已创建的存储账户：
- en: '![Figure 2.2 – Datastores](img/B18003_02_002.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – 数据存储](img/B18003_02_002.jpg)'
- en: Figure 2.2 – Datastores
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – 数据存储
- en: '**workspaceblobstore** is the default Azure Machine Learning workspace datastore
    and holds experiment logs as well as workspace artifacts. Data can be uploaded
    to this default datastore, which will be covered in an upcoming section. **workspacefilestore**
    is used to store your notebooks that are created within your Azure Machine Learning
    workspace.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**workspaceblobstore** 是默认的 Azure Machine Learning 工作区数据存储，包含实验日志以及工作区工件。数据可以上传到这个默认数据存储，将在下一节中介绍。**workspacefilestore**
    用于存储您在 Azure Machine Learning 工作区中创建的笔记本。'
- en: In the next section, we will see how to connect to a new datastore through Azure
    Machine Learning Studio, through the Azure Machine Learning Python SDK, as well
    as through the Azure Machine Learning CLI. This will enable you to use data where
    the data lives instead of bringing it into the default datastore associated with
    your Azure Machine Learning workspace.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何通过 Azure Machine Learning Studio、Azure Machine Learning Python
    SDK 以及 Azure Machine Learning CLI 连接到新的数据存储。这将使您能够使用数据所在的位置的数据，而不是将其带入与您的 Azure
    Machine Learning 工作区关联的默认数据存储。
- en: Creating a blob storage account datastore
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 blob 存储账户数据存储
- en: As mentioned in the previous section, *Default datastore review*, we can create
    a datastore through Azure Machine Learning Studio, through the Azure Machine Learning
    Python SDK, and through the Azure Machine Learning CLI. In the next section, we
    will walk through creating a datastore for a blob storage account with each of
    these methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，*默认数据存储回顾*，我们可以通过 Azure Machine Learning Studio、Azure Machine Learning
    Python SDK 和 Azure Machine Learning CLI 创建数据存储。在下一节中，我们将通过这些方法中的每一个创建 blob 存储账户的数据存储进行操作。
- en: Creating a blob storage account datastore through Azure Machine Learning Studio
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 Azure Machine Learning Studio 创建 blob 存储账户数据存储
- en: 'In order to create a blob storage account datastore, first you need to create
    a storage account that contains a blob. Follow these steps to create an Azure
    storage account and create blob storage within that storage account:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个包含 blob 的存储账户数据存储，首先您需要创建一个包含 blob 的存储账户。按照以下步骤创建 Azure 存储账户并在该存储账户中创建
    blob 存储：
- en: Go to the Azure portal at [https://ms.portal.azure.com/#home](https://ms.portal.azure.com/#home).
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 Azure 门户，请点击[https://ms.portal.azure.com/#home](https://ms.portal.azure.com/#home)。
- en: Find **Storage accounts** under **Azure Services**.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Azure 服务**下找到**存储账户**。
- en: Click `amlv2sa`.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `amlv2sa`。
- en: Once the storage account is created, you can see it under **Storage accounts**.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储账户创建完成后，您可以在**存储账户**下看到它。
- en: Go ahead and click on the newly created storage account.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击新创建的存储账户。
- en: Then from the left side navigation click on `datacontainer`.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后从左侧导航点击 `datacontainer`。
- en: 'Now, go back to Azure Machine Learning Studio, click on the **Data** icon on
    the left navigation, go to the **Datastores** tab as shown in *Figure 2**.2*,
    and click on **+Create**. A new **Create datastore** pane will open, as shown
    in *Figure 2**.3*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，返回 Azure Machine Learning Studio，点击左侧导航中的**数据**图标，转到**数据存储**选项卡，如图 *图 2**.2*
    所示，然后点击**+创建**。将打开一个新的**创建数据存储**面板，如图 *图 2**.3* 所示：
- en: '![Figure 2.3 – Create datastore](img/B18003_02_003.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – 创建数据存储](img/B18003_02_003.jpg)'
- en: Figure 2.3 – Create datastore
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 创建数据存储
- en: 'On the **Create datastore** pane, configure the required settings:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在**创建数据存储**面板上，配置所需的设置：
- en: Set `azureblobdatastore`.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `azureblobdatastore`。
- en: Given that this is an Azure blob storage account, leave `Azure` `Blob Storage`.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这是一个 Azure blob 存储帐户，请保留 `Azure Blob Storage`。
- en: Select your **Subscription ID** – note it should default to the Azure subscription
    of your workspace.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您的 **订阅 ID** – 注意它应该默认为您的 workspace 的 Azure 订阅。
- en: Find the storage account that you just created (`amlv2sa`) by clicking on the
    dropdown under **Storage account**.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击 **存储帐户** 下拉菜单找到您刚刚创建的存储帐户 (`amlv2sa`)。
- en: Find the blob container that you just created (`datacontainer`) by clicking
    on the dropdown under **Blob container**.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击 **Blob 容器** 下拉菜单找到您刚刚创建的 blob 容器 (`datacontainer`)。
- en: Set **Save credentials with the datastore for data access** to **Yes**.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 **使用数据存储保存凭据以进行数据访问** 设置为 **是**。
- en: Set **Authentication type** to **Account key**.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 **身份验证类型** 设置为 **帐户密钥**。
- en: Set the **Account key** by entering the value found in the **Access Keys** section
    of your storage account.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入存储帐户 **访问密钥** 部分找到的值来设置 **帐户密钥**。
- en: Set **Use workspace managed identity for data preview and profiling in Azure
    Machine Learning studio** to **Yes**.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 **在 Azure Machine Learning Studio 中使用工作区托管身份进行数据预览和配置文件** 设置为 **是**。
- en: This will grant your Azure Machine Learning service workspace’s managed **identity
    Reader** and **Storage Blob Data** **Reader** access.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这将授予您的 Azure Machine Learning 服务工作区的托管 **身份读取器** 和 **存储 Blob 数据读取器** 访问权限。
- en: Click on **Create**.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **创建**。
- en: You can verify that a datastore called `azureblobdatastore` has been created
    for you by viewing the **Datastores** tab shown in *Figure 2**.2*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过查看 *图 2**.2* 中显示的 **数据存储** 选项卡来验证是否为您创建了一个名为 `azureblobdatastore` 的数据存储。
- en: Now that we have seen how to easily configure a datastore through the UI, we
    will continue with creating a datastore through the Python SDK.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到如何通过 UI 轻松配置数据存储，我们将继续通过 Python SDK 创建数据存储。
- en: Creating a blob storage account datastore through the Python SDK
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 Python SDK 创建 blob 存储帐户数据存储
- en: 'In order to use the Python SDK, you need to run Python scripts in a Jupyter
    notebook. To start a Jupyter notebook, please click on the **Compute** tab on
    the left navigation, as shown in *Figure 2**.4*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Python SDK，您需要在 Jupyter 笔记本中运行 Python 脚本。要启动 Jupyter 笔记本，请点击左侧导航中的 **计算**
    选项卡，如图 *图 2**.4* 所示：
- en: '![Figure 2.4 – Opening Jupyter Server from a compute instance](img/B18003_02_004.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – 从计算实例打开 Jupyter 服务器](img/B18003_02_004.jpg)'
- en: Figure 2.4 – Opening Jupyter Server from a compute instance
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 从计算实例打开 Jupyter 服务器
- en: 'Next, from an existing compute instance click on **Jupyter** to open Jupyter
    Server. Under **New**, click on **Python 3.10 – SDKV2** in order to create a new
    Jupyter notebook, as shown in *Figure 2**.5*:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，从现有的计算实例点击 **Jupyter** 以打开 Jupyter 服务器。在 **新建** 中，点击 **Python 3.10 – SDKV2**
    以创建一个新的 Jupyter 笔记本，如图 *图 2**.5* 所示：
- en: '![Figure 2.5 – Creating a new Jupyter notebook](img/B18003_02_005.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 创建新的 Jupyter 笔记本](img/B18003_02_005.jpg)'
- en: Figure 2.5 – Creating a new Jupyter notebook
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 创建新的 Jupyter 笔记本
- en: 'Using the Azure Machine Learning Python SDK, an Azure blob container can be
    registered to your Azure Machine Learning workspace leveraging the following code
    in *Figure 2**.6*. Recall from when we created a new datastore through the UI
    that the value of the account key can be found in the **Access Keys** section
    of your storage account:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure Machine Learning Python SDK，可以通过 *图 2**.6* 中的以下代码将 Azure blob 容器注册到您的
    Azure Machine Learning 工作区。回想一下，当我们通过 UI 创建新的数据存储时，帐户密钥的值可以在存储帐户的 **访问密钥** 部分找到：
- en: '![Figure 2.6 – Using the Python SDK to create a blob storage account datastore](img/B18003_02_006.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – 使用 Python SDK 创建 blob 存储帐户数据存储](img/B18003_02_006.jpg)'
- en: Figure 2.6 – Using the Python SDK to create a blob storage account datastore
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 使用 Python SDK 创建 blob 存储帐户数据存储
- en: 'You can verify that a new blob storage datastore called **blob_storage** has
    been created if you click on **Data** in the left navigation and then the **Datastores**
    option, as shown in *Figure 2**.7*:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您点击左侧导航中的 **数据**，然后选择 **数据存储** 选项，如图 *图 2**.7* 所示，您可以验证是否已创建了一个名为 **blob_storage**
    的新 blob 存储数据存储：
- en: '![Figure 2.7 – List of datastores created in the workspace](img/B18003_02_007.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 – 工作区中创建的数据存储列表](img/B18003_02_007.jpg)'
- en: Figure 2.7 – List of datastores created in the workspace
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 工作区中创建的数据存储列表
- en: Next, let’s created a blob storage account datastore with the Azure Machine
    Learning CLI.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用 Azure Machine Learning CLI 创建一个 blob 存储帐户数据存储。
- en: Creating a blob storage account datastore through the Azure Machine Learning
    CLI
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 Azure Machine Learning CLI 创建 blob 存储帐户数据存储
- en: 'Assuming you have followed the instructions in [*Chapter 1*](B18003_01.xhtml#_idTextAnchor020),
    *Introducing the Azure Machine Learning Service*, to install the Azure CLI and
    the machine learning extension in your local environment, you can run the following
    command to create a blob storage account datastore:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已按照[*第1章*](B18003_01.xhtml#_idTextAnchor020)中“介绍Azure Machine Learning服务”的说明，在本地环境中安装了Azure
    CLI和机器学习扩展，您可以使用以下命令创建一个blob存储数据存储库：
- en: '![Figure 2.8 – CLI command to create a blob storage account datastore](img/B18003_02_008.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – CLI命令创建blob存储账户数据存储](img/B18003_02_008.jpg)'
- en: Figure 2.8 – CLI command to create a blob storage account datastore
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – CLI命令创建blob存储账户数据存储
- en: 'In the preceding command, `blobstore.yml` is a YAML file schema specifying
    the datastore type, name, description, storage account name, and credentials for
    the storage account, as shown in *Figure 2**.9*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的命令中，`blobstore.yml`是一个YAML文件模式，指定数据存储类型、名称、描述、存储账户名称和存储账户凭据，如图*图2**.9*所示：
- en: '![Figure 2.9 – Blob datastore YAML schema file](img/B18003_02_009.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – Blob数据存储YAML模式文件](img/B18003_02_009.jpg)'
- en: Figure 2.9 – Blob datastore YAML schema file
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – Blob数据存储YAML模式文件
- en: You can verify that a new blob storage datastore called `blob_storage_cli` has
    been created if you click on the **Datastores** tab, as shown earlier in *Figure
    2**.7*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您点击**数据存储**选项卡，如图*图2**.7*中所示，您可以验证是否已创建一个名为`blob_storage_cli`的新blob存储数据存储库。
- en: Now that you have successfully created a blob storage datastore, within your
    Azure Machine Learning workspace, you will be able to use this datastore for multiple
    data assets. The connection information to this datastore is securely held within
    your Azure key vault, and you have a location to store data as it is generated.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已成功创建blob存储数据存储库，在您的Azure Machine Learning工作区中，您将能够使用此数据存储库为多个数据资产提供服务。此数据存储库的连接信息安全地存储在您的Azure密钥保管库中，并且您有一个存储生成数据的存储位置。
- en: Creating Azure Machine Learning data assets
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Azure Machine Learning数据资产
- en: Once the previous datastore is created, the next step is to create a data asset.
    Please note that we will be using the terms “data asset” and “dataset” interchangeably
    throughout the chapter. A dataset is a logical connection to the datastore with
    versioning and schema management, such as choosing which columns of the data to
    use, the types of the columns in the dataset, and some statistics about the data.
    Data assets abstract the code from configuring data to be read. Also, data assets
    are very useful when we run multiple models as each model can be configured to
    read the dataset name instead of configuring or programming how to connect to
    the dataset and read it. This makes it easier to scale the model training.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建完上一个数据存储库后，下一步是创建数据资产。请注意，在本章中，我们将交替使用“数据资产”和“数据集”这两个术语。数据集是对数据存储的逻辑连接，具有版本控制和模式管理，例如选择要使用的数据列、数据集中列的类型以及一些数据统计信息。数据资产抽象了从配置数据读取的代码。此外，当运行多个模型时，数据资产非常有用，因为每个模型都可以配置为读取数据集名称，而不是配置或编程如何连接到数据集并读取它。这使得模型训练的扩展变得更加容易。
- en: In the following sections, you will learn how to create datasets using the Azure
    Machine Learning Python SDK, CLI, and UI. Datasets allow us to create versions
    based on schema changes without changing the underlying datastore that holds the
    data. Specific versions can be used within code. We can also create profiles on
    the data for each dataset created and stored for further data analysis.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下部分，您将学习如何使用Azure Machine Learning Python SDK、CLI和UI创建数据集。数据集允许我们根据模式更改创建版本，而无需更改存储数据的底层数据存储。可以在代码中使用特定版本。我们还可以为每个创建并存储的数据集创建数据配置文件，以进行进一步的数据分析。
- en: Creating a data asset using the UI
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用UI创建数据资产
- en: 'Azure Machine Learning Studio provides a great interface for creating a dataset
    through a guided UI. In order to create a dataset using Azure Machine Learning
    Studio, follow these steps:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning Studio提供了一个通过引导式UI创建数据集的出色界面。为了使用Azure Machine Learning
    Studio创建数据集，请按照以下步骤操作：
- en: Go to [https://ml.azure.com](https://ml.azure.com).
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问[https://ml.azure.com](https://ml.azure.com)。
- en: Select your workspace name.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您的工作区名称。
- en: In the workspace UI, click **Data** and make sure that the **Data assets** option
    is selected.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在工作区UI中，点击**数据**并确保已选择**数据资产**选项。
- en: 'Next, click **+ Create** and fill out the **Create data asset** form, as shown
    in *Figure 2**.10*, and make sure to select **Tabular** in the **Type** field:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，点击 **+ 创建** 并填写如图 *图 2.10* 所示的 **创建数据资产** 表单，并确保在 **类型** 字段中选择 **表格**：
- en: '![Figure 2.10 – Create data asset](img/B18003_02_010.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10 – 创建数据资产](img/B18003_02_010.jpg)'
- en: Figure 2.10 – Create data asset
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 创建数据资产
- en: On the next screen, select **From local files** and click **Next** to see the
    **Select a datastore** screen, as shown in *Figure 2**.11.* Go ahead and select
    the **blob_storage** datastore that you created in the last section.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一屏幕上，选择 **从本地文件** 并点击 **下一步** 以查看如图 *图 2.11* 所示的 **选择数据存储** 屏幕。继续选择您在上一个部分中创建的
    **blob_storage** 数据存储。
- en: '![Figure 2.11 – Select a datastore](img/B18003_02_011.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11 – 选择数据存储](img/B18003_02_011.jpg)'
- en: Figure 2.11 – Select a datastore
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 选择数据存储
- en: 'Once the datastore is selected, you are provided with the option to choose
    the path where the file is located, as shown in *Figure 2**.12*. For this example,
    we will use the `titanic.csv` file, which can be downloaded from our GitHub repository.
    Enter the path where you downloaded and saved the file and then click **Next**:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 选择数据存储后，您可以选择文件所在的路径，如图 *图 2.12* 所示。在本例中，我们将使用 `titanic.csv` 文件，该文件可以从我们的 GitHub
    仓库下载。输入您下载并保存文件的路径，然后点击 **下一步**：
- en: '![Figure 2.12 – Upload your data file](img/B18003_02_012.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12 – 上传您的数据文件](img/B18003_02_012.jpg)'
- en: Figure 2.12 – Upload your data file
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 上传您的数据文件
- en: 'Next is the **Settings and preview** screen. On this screen, the file is automatically
    parsed, and options are displayed for the format detected. In our case, it’s a
    CSV file, and settings for CSV file format are shown. Check the preview section
    to validate whether the dataset shows the data in the right format like identifying
    columns, header, and values. If the format is not detected, then you can change
    the settings for **File Format**, **Delimiter**, **Encoding**, **Column headers**,
    and **Skip rows**, as shown in *Figure 2**.13*. If the dataset contains multi-line
    data, then check the option for **Dataset contains multi-line data**. Once the
    settings are configured properly for your dataset, click the **Next** button to
    go to the next section regarding schema:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是 **设置和预览** 屏幕。在此屏幕上，文件将自动解析，并显示检测到的格式的选项。在我们的案例中，它是一个 CSV 文件，并显示了 CSV 文件格式的设置。检查预览部分以验证数据集是否以正确的格式显示数据，例如识别列、标题和值。如果未检测到格式，则可以更改
    **文件格式**、**分隔符**、**编码**、**列标题** 和 **跳过行** 的设置，如图 *图 2.13* 所示。如果数据集包含多行数据，则检查 **数据集包含多行数据**
    选项。一旦为您的数据集正确配置了设置，请点击 **下一步** 按钮进入有关架构的下一部分：
- en: '![Figure 2.13 – Settings and preview screen](img/B18003_02_013.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13 – 设置和预览屏幕](img/B18003_02_013.jpg)'
- en: Figure 2.13 – Settings and preview screen
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – 设置和预览屏幕
- en: On this screen, the system will identify the schema of the data and display
    it for review, allowing changes as needed. Typically, a CSV or text file may require
    schema changes. As an example, a column may have an incorrect data type, so be
    sure to select the correct data type.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在此屏幕上，系统将识别数据的架构并将其显示以供审查，允许根据需要做出更改。通常，CSV 或文本文件可能需要架构更改。例如，一个列可能具有错误的数据类型，因此请确保选择正确的数据类型。
- en: Important note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The first 200 rows are used to detect the column type. If the dataset has a
    column type mismatch, consider cleaning your dataset before registering using
    a Jupyter notebook.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行用于检测列类型。如果数据集存在列类型不匹配，请在使用 Jupyter notebook 注册之前考虑清理您的数据集。
- en: 'Here are the available data type formats:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是可用的数据类型格式：
- en: '**String**'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字符串**'
- en: '**Integer**'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**整数**'
- en: '**Boolean**'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**布尔值**'
- en: '**Decimal (****dot ‘.’)**'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**十进制（****点‘.’）**'
- en: '**Decimal (****comma ‘,’)**'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**十进制（****逗号‘,’）**'
- en: '**Date**'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日期**'
- en: '*Figure 2**.14* shows the schema information for your dataset. Check the **Type**
    header dropdown to see the available data types:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.14* 展示了数据集的架构信息。检查 **类型** 标题下拉菜单以查看可用的数据类型：'
- en: '![Figure 2.14 – Schema screen](img/B18003_02_014.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.14 – 架构屏幕](img/B18003_02_014.jpg)'
- en: Figure 2.14 – Schema screen
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – 架构屏幕
- en: Scroll down and review all the columns. For your registered data asset, you
    can choose to include or exclude a given column. The option to **Include** is
    available per column, as shown in *Figure 2**.14*. This screen also includes the
    option to **Search** a column. Once the screen is properly configured for your
    data asset, click **Next**.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动并审查所有列。对于您的已注册数据资产，您可以选择包含或排除特定的列。每个列都有**包含**的选项，如图2.14所示。此屏幕还包括**搜索**列的选项。一旦数据资产屏幕配置正确，点击**下一步**。
- en: 'Next is the **Review** screen. Confirm all the settings that were selected
    previously are correct and then click **Create**:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来是**审查**屏幕。确认之前选择的设置是否正确，然后点击**创建**：
- en: '![Figure 2.15 – Confirm review screen](img/B18003_02_015.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图2.15 – 确认审查屏幕](img/B18003_02_015.jpg)'
- en: Figure 2.15 – Confirm review screen
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 – 确认审查屏幕
- en: During the review, if any changes are required, click the **Back** button and
    change the settings.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查过程中，如果需要任何更改，请点击**返回**按钮并更改设置。
- en: Once the data asset creation is complete, you will see the `titanicdataset`
    data asset page, which includes different options, such as **Explore**, **Consume**,
    and **Generate Profile**.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据资产创建完成，您将看到`titanicdataset`数据资产页面，其中包括不同的选项，例如**探索**、**消费**和**生成配置文件**。
- en: 'Click on the **Consume** option, as shown in *Figure 2**.16*, to review the
    code for retrieving your registered dataset by name and displaying a pandas dataframe
    from your dataset:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击如图2.16所示的**消费**选项，以查看通过名称检索您的已注册数据集的代码，并显示数据集的pandas数据框：
- en: '![Figure 2.16 – Consuming the data asset using Python](img/B18003_02_016.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图2.16 – 使用Python消费数据资产](img/B18003_02_016.jpg)'
- en: Figure 2.16 – Consuming the data asset using Python
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16 – 使用Python消费数据资产
- en: The code shown in *Figure 2**.16* can be copied and pasted directly into an
    Azure Machine Learning notebook and run on your Azure Machine Learning compute
    instance, as discussed later in the chapter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章后面所述，图2.16中显示的代码可以直接复制粘贴到Azure Machine Learning笔记本中，并在您的Azure Machine Learning计算实例上运行。
- en: 'Within the **Consume** option for the registered dataset, you can select the
    **Generate profile** option to begin a guided tour through profiling your dataset,
    as shown in *Figure 2**.17*:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在已注册数据集的**消费**选项中，您可以选择**生成配置文件**选项，开始对数据集进行配置的引导浏览，如图2.17所示：
- en: '![Figure 2.17 – Generate profile screen](img/B18003_02_017.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图2.17 – 生成配置文件屏幕](img/B18003_02_017.jpg)'
- en: Figure 2.17 – Generate profile screen
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17 – 生成配置文件屏幕
- en: If you want to create a new version of the dataset, click **New Version**.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您想创建数据集的新版本，请点击**新版本**。
- en: 'There is also the **Explore** option to view a sample of the data set. Only
    the first 50 rows are shown:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，还有**探索**选项来查看数据集的样本。仅显示前50行：
- en: '![Figure 2.18 – Explore screen](img/B18003_02_018.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图2.18 – 探索屏幕](img/B18003_02_018.jpg)'
- en: Figure 2.18 – Explore screen
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18 – 探索屏幕
- en: In this section, we showed you how to create data assets using the UI. In the
    next section, we will show you how to create data assets using the Python SDK.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了如何使用UI创建数据资产。在下一节中，我们将向您展示如何使用Python SDK创建数据资产。
- en: Creating a data asset using the Python SDK
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python SDK创建数据资产
- en: In this section, we will show you how to create a data asset using the Python
    SDK. As mentioned in the previous section, you can create data from datastores,
    local files, and public URLs. The Python script to create a data asset from a
    local file (for example, `titanic.csv`) is shown in *Figure 2**.19*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何使用Python SDK创建数据资产。如前所述，您可以从数据存储、本地文件和公共URL创建数据。从本地文件（例如，`titanic.csv`）创建数据资产的Python脚本如图2.19所示。
- en: 'Please note that in the following code snippet, `type = AssetTypes.mltable`
    abstracts the schema definition for the tabular data, making it easier to share
    datasets:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在下面的代码片段中，`type = AssetTypes.mltable`抽象了表格数据的模式定义，使其更容易共享数据集：
- en: '![Figure 2.19 – Creating a data asset via the Python SDK](img/B18003_02_019.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图2.19 – 通过Python SDK创建数据资产](img/B18003_02_019.jpg)'
- en: Figure 2.19 – Creating a data asset via the Python SDK
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19 – 通过Python SDK创建数据资产
- en: 'Inside the `my_data` folder, there are two files:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在`my_data`文件夹内，有两个文件：
- en: The actual data file, which in this case is `titanic.csv`
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际的数据文件，在本例中是`titanic.csv`
- en: The `mltable` file, which is a YAML file specifying the data’s schema so that
    the `mltable` engine can use it in order to materialize the data into an in-memory
    object such as pandas or DASK
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mltable`文件，这是一个YAML文件，指定了数据的模式，以便`mltable`引擎可以使用它来将数据转换为内存中的对象，如pandas或DASK'
- en: '*Figure 2**.20* shows the `mltable` YAML file for this example:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2**.20*显示了此示例的`mltable` YAML文件：'
- en: '![Figure 2.20 – The mltable YAML file for creating an mltable data asset](img/B18003_02_020.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图2.20 – 创建mltable数据资产的mltable YAML文件](img/B18003_02_020.jpg)'
- en: Figure 2.20 – The mltable YAML file for creating an mltable data asset
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20 – 创建mltable数据资产的mltable YAML文件
- en: If you head back to the **Data** tab under **Data assets**, you will see that
    a new dataset called **titanic-mltable-sdk** has been created with its type set
    to **Table(mltable)** and its version to **1**.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回到**数据资产**下的**数据**标签页，您将看到已创建了一个名为**titanic-mltable-sdk**的新数据集，其类型设置为**Table(mltable**)，版本为**1**。
- en: In this section, we showed you how to create a data asset using the Python SDK.
    In the next section, you will learn how to consume a data asset.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了如何使用Python SDK创建数据资产。在下一节中，您将学习如何消费数据资产。
- en: Using Azure Machine Learning datasets
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Azure Machine Learning数据集
- en: During this chapter, we have covered what an Azure Machine Learning datastore
    is and how to connect to a variety of supported data sources. We created connections
    to Azure Machine Learning datastores using Azure Machine Learning Studio, the
    Python SDK, and the Azure CLI. We have just covered Azure Machine Learning datasets,
    a valuable asset for your ML projects. We went through how to generate Azure Machine
    Learning datasets using Azure Machine Learning Studio and the Python SDK. Once
    an Azure Machine Learning dataset is created, it can be used throughout your Azure
    Machine Learning experiments, which are called **jobs**.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了Azure Machine Learning数据存储是什么以及如何连接到各种支持的数据源。我们使用Azure Machine Learning
    Studio、Python SDK和Azure CLI创建了到Azure Machine Learning数据存储的连接。我们刚刚介绍了Azure Machine
    Learning数据集，这是您ML项目中的一个宝贵资产。我们介绍了如何使用Azure Machine Learning Studio和Python SDK生成Azure
    Machine Learning数据集。一旦创建了Azure Machine Learning数据集，它就可以在您的Azure Machine Learning实验中整个使用，这些实验被称为**作业**。
- en: '*Figure 2**.21* shows a code snippet for materializing the `mltable` artifact
    into a pandas dataframe. Please note that you need the `mltable` library installed
    in your environment (using the `pip install` `mltable` command).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.21*显示了将`mltable`工件转换为pandas数据框的代码片段。请注意，您需要在您的环境中安装`mltable`库（使用`pip install
    mltable`命令）。'
- en: '![Figure 2.21 – Materializing the mltable artifact into a pandas dataframe](img/B18003_02_021.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图2.21 – 将mltable工件转换为pandas数据框](img/B18003_02_021.jpg)'
- en: Figure 2.21 – Materializing the mltable artifact into a pandas dataframe
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21 – 将mltable工件转换为pandas数据框
- en: Now let’s see how to use a data asset inside an ML job, which will be covered
    in the next section.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在ML作业中使用数据资产，这将在下一节中介绍。
- en: Read data in a job
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在作业中读取数据
- en: An Azure Machine Learning job consists of a Python script, which could be simple
    data processing or a complex code for model development, a Bash command to specify
    tasks to be performed, the inputs and outputs of the job, the Docker environment
    specifying the runtime libraries required to run the job and a compute where the
    Docker container would run on. The code that is executed inside a job will probably
    need to use a dataset. The primary way to pass data to an Azure Machine Learning
    job is by using datasets.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Machine Learning作业由一个Python脚本组成，这可能是一个简单的数据处理或用于模型开发的复杂代码，一个Bash命令用于指定要执行的任务，作业的输入和输出，指定运行作业所需的运行时库的Docker环境，以及Docker容器将运行的计算环境。在作业内部执行的代码可能需要使用数据集。将数据传递给Azure
    Machine Learning作业的主要方式是使用数据集。
- en: 'Let’s walk you through the steps needed to run a job that takes a dataset as
    input:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们带您了解运行一个以数据集为输入的作业所需的步骤：
- en: 'Create an Azure Machine Learning environment, which is where your process to
    train a model or process your data takes place. *Figure 2**.22* shows the code
    snippet to create an environment called `env_docker_conda`, which will be used
    in *step 4*:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Azure Machine Learning环境，这是您训练模型或处理数据的过程所在的地方。*图2**.22*显示了创建一个名为`env_docker_conda`的环境的代码片段，它将在*步骤4*中使用：
- en: '![Figure 2.22 – Creating the Azure Machine Learning environment](img/B18003_02_022.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图2.22 – 创建Azure Machine Learning环境](img/B18003_02_022.jpg)'
- en: Figure 2.22 – Creating the Azure Machine Learning environment
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22 – 创建Azure Machine Learning环境
- en: 'In the preceding code, `env-mltable.yml`, which is shown in *Figure 2**.22*,
    is a YAML file defining the Python libraries that need to be installed in the
    environment:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`env-mltable.yml`，如 *图 2.22* 所示，是一个 YAML 文件，定义了需要在环境中安装的 Python 库：
- en: '![Figure 2.23 – Environment specification YAML file](img/B18003_02_023.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.23 – 环境规范 YAML 文件](img/B18003_02_023.jpg)'
- en: Figure 2.23 – Environment specification YAML file
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23 – 环境规范 YAML 文件
- en: 'Write a Python script to process your data and build a model. For this chapter,
    we will show you a simple Python script that takes an input dataset, converts
    it to a pandas dataframe, and then prints it. *Figure 2**.24* shows the script
    saved in a file called `read_data.py`, which will be used in *step 4*:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个 Python 脚本来处理你的数据并构建模型。对于本章，我们将向你展示一个简单的 Python 脚本，该脚本接受一个输入数据集，将其转换为 pandas
    数据框，然后打印它。*图 2.24* 展示了保存为 `read_data.py` 文件的脚本，该脚本将在 *步骤 4* 中使用：
- en: '![Figure 2.24 – Python script processing the input dataset](img/B18003_02_024.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.24 – 处理输入数据集的 Python 脚本](img/B18003_02_024.jpg)'
- en: Figure 2.24 – Python script processing the input dataset
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.24 – 处理输入数据集的 Python 脚本
- en: 'Create an Azure Machine Learning compute cluster where the Azure Machine Learning
    containerized job will be submitted. *Figure 2**.25* shows the Python script to
    create a compute cluster called `cpu-cluster` by specifying its type and the minimum
    and maximum number of nodes:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Azure Machine Learning 计算集群，其中将提交 Azure Machine Learning 容器化作业。*图 2.25*
    展示了创建一个名为 `cpu-cluster` 的计算集群的 Python 脚本，通过指定其类型和最小和最大节点数：
- en: '![ Figure 2.25 – Create Azure Machine Learning compute cluster](img/B18003_02_025.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.25 – 创建 Azure Machine Learning 计算集群](img/B18003_02_025.jpg)'
- en: Figure 2.25 – Create Azure Machine Learning compute cluster
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.25 – 创建 Azure Machine Learning 计算集群
- en: 'Now you have all the necessary pieces to construct an Azure Machine Learning
    job and submit it for execution. *Figure 2**.26* shows the Python script for creating
    an Azure Machine Learning job called `job`. This job is essentially a Docker container
    containing your Python code in `read_data.py`, which is taking your previously
    created input dataset and is submitted to the compute cluster you created:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经拥有了构建 Azure Machine Learning 作业并提交执行的所有必要组件。*图 2.26* 展示了创建一个名为 `job` 的
    Azure Machine Learning 作业的 Python 脚本。这个作业本质上是一个包含你的 Python 代码（`read_data.py`）的
    Docker 容器，该代码正在处理你之前创建的输入数据集，并将其提交到你创建的计算集群：
- en: '![Figure 2.26 – Creating an Azure Machine Learning job](img/B18003_02_026.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.26 – 创建 Azure Machine Learning 作业](img/B18003_02_026.jpg)'
- en: Figure 2.26 – Creating an Azure Machine Learning job
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.26 – 创建 Azure Machine Learning 作业
- en: 'The output of the Jupyter notebook cell is a link to the job in Azure Machine
    Learning Studio, which displays the job’s overview, its status, the Python code,
    and the output of the job. If you navigate to this link and click on **Outputs
    + logs**, then **std_log.txt** under **user_logs**, you will see the output generated
    by the Python code, which is printing the input dataset to the standard log, as
    shown in *Figure 2**.27*:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 笔记本单元格的输出是一个指向 Azure Machine Learning Studio 中作业的链接，该链接显示作业概述、状态、Python
    代码和作业输出。如果你导航到这个链接并点击 **输出 + 日志**，然后点击 **user_logs** 下的 **std_log.txt**，你将看到由
    Python 代码生成的输出，该代码将输入数据集打印到标准日志中，如 *图 2.27* 所示：
- en: '![Figure 2.27 – Output of the Azure Machine Learning job after successful execution](img/B18003_02_027.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.27 – Azure Machine Learning 作业执行成功后的输出](img/B18003_02_027.jpg)'
- en: Figure 2.27 – Output of the Azure Machine Learning job after successful execution
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.27 – Azure Machine Learning 作业执行成功后的输出
- en: Let’s summarize the chapter now.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们总结本章内容。
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have explored Azure Machine Learning datastores, which
    enable you to connect to datastore services. You have also learned about Azure
    Machine Learning datasets, empowering you to create a reference to a location
    within a datastore. These assets within Azure Machine Learning can be created
    through the UI for a low code experience, as well as through the Azure Machine
    Learning Python SDK or the Azure Machine Learning CLI. Once these references are
    created, datasets can be retrieved and used through the Azure Machine Learning
    Python SDK. Once the dataset has been retrieved, it can easily be converted into
    a pandas dataframe for use within your code. You have also seen how to use datasets
    within an Azure Machine Learning job by passing them as input to the job.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经探索了Azure机器学习数据存储，这些数据存储使您能够连接到数据存储服务。您还了解了Azure机器学习数据集，这使您能够创建对数据存储中位置的引用。在Azure机器学习中，这些资产可以通过UI创建以实现低代码体验，也可以通过Azure机器学习Python
    SDK或Azure机器学习CLI创建。一旦创建了这些引用，就可以通过Azure机器学习Python SDK检索和使用数据集。一旦检索到数据集，就可以轻松将其转换为pandas
    dataframe以在您的代码中使用。您还看到了如何在Azure机器学习作业中使用数据集，通过将它们作为作业的输入传递。
- en: In [*Chapter 3*](B18003_03.xhtml#_idTextAnchor053), *Training Machine Learning
    Models in AMLS*, you will explore training models; experiments will become a key
    asset in your toolbelt, enabling traceability as you build your model in AMLS.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第3章*](B18003_03.xhtml#_idTextAnchor053) *在AMLS中训练机器学习模型* 中，您将探索模型训练；实验将成为您工具箱中的关键资产，在您在AMLS中构建模型时提供可追溯性。
