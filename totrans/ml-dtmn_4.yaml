- en: Improving Individual Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will see how we can improve different models, and we will
    see how to modify model options. We will also learn how to use different models
    and see how we can remove noise by removing predictors that are not really needed
    for predictions. You will also understand how to prepare additional data for the
    models, and we will see how we can add additional fields. Finally, you see how
    how oversampling and undersampling different categories of an outcome variable
    can make it more likely that the model that you end up using actually better understands
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the topics that will be covered in this chapter, and these
    are the ways in which models can be improved:'
  prefs: []
  type: TYPE_NORMAL
- en: Modifying model options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using different models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doing additional data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balancing data (oversampling/undersampling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modifying model options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Modifying model options to improve the model is one of the straightforward
    ways to improve a model. We will see how we can do this with the help of an example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create an SVM model just as we did in the second chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5df9f40a-f416-4358-a497-5ded25fa0549.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on Status, go to the Expert tab, and select Expert under Mode. As we have
    seen in [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml), *Getting Started
    with Machine Learning*, whenever we are using SVM models, we need to modify their
    settings. Change the Regularization parameter to 5\. And, in the Kernel type,
    select Polynomial. Then, click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see a model created. Now, let''s do our next step of analyzing the
    model. Connect your generated model to an Analysis node from the Output palette.
    Open the Analysis node, and select the Coincidence matrices (for the symbolic
    targets option) and click on Run. This will be the result that will be acquired:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ca69616e-309c-453d-b08a-0ba3c5710a08.png)'
  prefs: []
  type: TYPE_IMG
- en: The results clearly show that the model isn't consistent as there is a huge
    difference between the accuracy percentage of the training and the testing dataset.
    But, what we can see is the testing percentage is better than the testing percentage
    that we acquired for the linear model in [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml),
    *Getting Started with Machine Learning*, around 73%. Hence, maybe the polynomial
    model can do a better job but not with the current model as it is capitalizing
    on chance.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a potentially better model, we can go ahead and modify the
    settings of this model. You can go to the SVM model status, and in the Expert
    tab, you can see that the Degree is set to 3\. There is a chance that this cubic
    function may be proving a bit complex for the data that we have. Let's use a quadratic
    function instead. Change the Degree to 2 and click Run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, run the analysis just like we have always done, and you will find these
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8554ba26-20aa-4c56-b168-1b0242cb7c29.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the accuracy percentages of both the datasets are within a difference
    of 5%. Hence, we can say that the model is consistent. Moreover, we can also see
    that the overall accuracy for the testing dataset has improved.
  prefs: []
  type: TYPE_NORMAL
- en: This is how we improved an existing model by modifying its options to provide
    better results with higher overall accuracy and consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Using a different model to improve results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we saw how we can improve a result acquired from the
    model by modifying its options. Now, we will see how to improve the results by
    changing the model itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every model looks at the data differently. They have their own algorithms.
    These algorithms provide us with different perspectives to look at the data. Sometimes,
    just changing the perception of looking at the data can give us improved results.
    The different algorithms capitalize on unique aspects of data. Let''s see how
    we can do this with the help of an example:'
  prefs: []
  type: TYPE_NORMAL
- en: Bring your data, and partition it into training and testing datasets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the Partition node to a Neural Net node from the Modeling palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/75253761-59fd-422c-aea4-a4e03a8f3af5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Neural Net node and go to the Build Options tab. In this, go the
    Advanced option and just change the Random seed to `5000`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4fd2e68f-7287-4803-b3a1-63fb082eb2b6.png)'
  prefs: []
  type: TYPE_IMG
- en: The reason that we are keeping the seed as `5000` is because we have acquired
    a better result using `5000` as the seed, as you may can recall from [Chapter
    2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml), *Getting Started with Machine
    Learning*, where we have demonstrated a neural network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once again, you will have to analyze the model that is built. For this, recall
    the steps that we have followed until now. Go to the Output palette, and connect
    the generated model node to the Analysis node. Run the Analysis node with the
    checked Coincidence matrices. The following will be the results acquired:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/df18ccd7-5fd4-43f7-aa7b-38a7f0f902a2.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that we are at an overall accuracy of around 80%, and how each of
    the predictions have performed. The overall accuracy is similar to what we have
    achieved when we used the SVM model. Hence, we can say that the SVM and Neural
    Net models are doing equally well for this dataset. Let's see how we can improve
    these results a little more.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will use a decision tree in this example. For adding a decision tree node,
    select the Partition node, and connect it to the C5.0 node from the Modeling palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bbfe92f1-947f-4b21-b98e-186e5cd9d482.png)'
  prefs: []
  type: TYPE_IMG
- en: The C5.0 model is a decision tree model that looks at the data from a very different
    perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the C5.0 model node to build a **C5.0** model and run it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a23483f3-5ab3-4967-8189-0ba7a4c1e610.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, connect the C5.0 model node to the Neural Net generated model node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the C5.0 generated model to the Analysis node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e1bebf80-9c06-4a40-8a34-4cca560fee36.png)'
  prefs: []
  type: TYPE_IMG
- en: This will enable us to compare the results very easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the Analysis node. The following will be the results acquired:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0156d7c3-821b-41a3-b8bb-33478e428957.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the overall accuracy for the testing dataset with the C5.0 model
    is 85%. This is much better than what we had acquired with just the Neural Net
    model. We can certainly improve on this by making some modifications to the C5.0
    model, which I'll leave up to you as a homework exercise.
  prefs: []
  type: TYPE_NORMAL
- en: So, we saw how the C5.0 model slightly improved the results, and has done a
    good job in overall accuracy and with each of the predictions both for the training
    and testing dataset. This was just an example on another approach to improve the
    performance of a model. We will now see how removing noise from the data can give
    us much better results.
  prefs: []
  type: TYPE_NORMAL
- en: Removing noise to improve models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's focus on how noise can affect the results. Noise is nothing but missing
    data, outliers, or too many predictors that try to confuse the model with unnecessary
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree models don't have noise because of too many predictors, as by
    default, they eliminate the predictors that they don't use for predictions as
    opposed to other statistical and machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having too many predictors in a model causes the following problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional noise in the data that affects the overall accuracy of the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model becomes much more complex than it should be
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If new data is to be added for new predictions, we need to collect data even
    for the variables that are not important and are not really required for the predictions,
    because our model uses them up to a certain extent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If these kinds of predictors are cleared and eliminated from the model, this
    could simplify the understanding of the model and, potentially, it will give better
    results as well.
  prefs: []
  type: TYPE_NORMAL
- en: How to remove noise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s understand with the help of an example. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Partition your data into a training and testing dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your Partition node to a Neural Net model from the Modeling palette.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the model and, just like we have always done, go to the Build Options
    tab, then to the Advanced options, and change the Random seed to `5000` (because
    that has given us the best results so far). Click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We have seen the accuracy of this model before. Refer to the list of top 10
    predictors for different random seeds that we acquired and stored in a table while
    demonstrating Neural Net in [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml),
    *Getting Started with Machine Learning*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6e878a7d-ac7e-449f-9a20-3c5b75b0fbf4.png)'
  prefs: []
  type: TYPE_IMG
- en: We will now remove the variables, which haven't appeared in any of the models
    or have appeared in just a few.
  prefs: []
  type: TYPE_NORMAL
- en: 'For removing variables, we will create another version of this Neural Net model.
    Connect the Partition node to another Neural Net model from the Modeling palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4251f35a-c0c2-40f3-b57d-f1ae18201be8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Edit the new Neural Net model: Here, in the Fields tab, we will remove the
    Predictors that didn''t appear in the top 10 list of any model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3b731e5b-ff81-4d04-b837-297657a1df6a.png)'
  prefs: []
  type: TYPE_IMG
- en: You just have to click the predictor from the Inputs list and click on the arrow
    pointing towards the left-side box. You can also restore them if needed using
    the same method. These are the variables that didn't appear in the top 10 list
    of any model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also remove the variables that appeared just once or twice in the lists:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f8917ea-9fa6-4c73-9d7a-83d1088e724e.png)'
  prefs: []
  type: TYPE_IMG
- en: Go to the Advanced options in the Build Options tab and change the Random seed
    to `5000.` Then click on Run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the first Neural Net model to the second Neural Net model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e168247f-90d3-4dc4-83c0-ef782b8cd18b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Connect the second Neural Net model to the Analysis node from the Output palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bb652aff-a9e8-46bb-9409-b42ebf681a07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the Analysis node, just like we have always done. The following will be
    the comparative analysis of the two models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ddd7e56b-0830-4cf5-b040-e33ca0dc02f4.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the overall accuracy for the testing and training dataset of
    the second model is slightly better than the first model. Hence, we got a 2% improvement
    in predictability just by removing some unnecessary predictors. If we see the
    job of the model in predicting for each of the individual categories, the model
    with noise removed has done well in that too.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, we have explored another way to improve the results acquired from a model.
    We saw how removing noise, and reducing the number of variables or predictors
    by eliminating the unnecessary ones, can give us better results. Let's move on
    to see another method to improve accuracy. We will see how preparing the data
    to some extent can give us better results.
  prefs: []
  type: TYPE_NORMAL
- en: Doing additional data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see how additional preparation done on the data can
    allow us to extract an extra piece of information.
  prefs: []
  type: TYPE_NORMAL
- en: Until now, we have improved our model by modifying its options, using a different
    model, changing the perspective of looking at data, and removing noise. Sometimes
    though, these techniques will just slightly improve the model; but if you could
    go back to the data preparation phase and look for extra bits that can be pulled
    from the data that can give better results, this can really go a long way in improving
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to prepare the data in the data preparation stage:'
  prefs: []
  type: TYPE_NORMAL
- en: Get your data and partition it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run a Neural Net model again, with a Random seed of `5000`. We will get an accuracy
    of around 80%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now create a new model and add one additional predictor. If you go back
    to the list of top ten predictors list, we will find predictors such as the number
    of speakers and TVs that customers purchased. Hence, it makes sense to have a
    predictor that shows the total number of items purchased.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go to the Field Ops palette and connect the Partition node to a Derive node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e4bbdd4e-1820-4afb-91b6-036ef9b63b36.png)'
  prefs: []
  type: TYPE_IMG
- en: A Derive node allows us to create additional variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the Derive node. Set the Derive field as `Total Items` and click on the
    expression builder button, which is on the right of the Formula field, and we
    will create an expression by selecting the predictors of interest and clicking
    on the plus button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/98a8ca4d-86d7-41b9-b4d7-6bc7a20ae433.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This means that `Total Items` includes Stereos, TVs, and Speakers. You will
    get an expression in the Formula field, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15f8b8bf-8e7a-4d06-a0ff-5a47982557d8.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the expression that will be used for `Total Items`. Click on OK.
  prefs: []
  type: TYPE_NORMAL
- en: 'The variable that we just created needs to be instantiated so that the model
    is able to use it; for this, connect the Total Items node to the Type node from
    the Field Ops palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2d96befb-9d04-40ec-8d39-b527c5e644c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Edit the Type node. Click on the Read Values button to read the new variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/411fecf1-2216-4a4a-9834-c3690eb8255f.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the Total Items predictor is now read, and that it will be counted
    as an Input predictor in this model. Click on OK.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect the Type node to a Neural Net model from the Modeling palette:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8b81bf1a-ad4f-444d-a4ff-04029669859c.png)'
  prefs: []
  type: TYPE_IMG
- en: Run the Neural Net model with Random seed set to `5000`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take a look at the model results by clicking on the newly generated model.
    You can see that the Total Items has acquired its place in the top ten predictors
    in Predictor Importance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3817cc99-fd3a-4d12-a4e3-0b5e7f86cdbb.png)'
  prefs: []
  type: TYPE_IMG
- en: Close the window.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now connect the first generated model to the second model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e5599821-c246-4666-ae5e-48dc8a0e9ca3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Add an Analysis node to the first Neural Net model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/485ecf60-b958-48f0-b325-f7d0139299a5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the Analysis node, as always. You should get the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/39ca2cea-7c35-4900-bba7-4fa8123c2a97.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that the accuracy that we have has slightly improved. We just added a
    variable to an existing model. Hence, we get an idea of how our results can be
    affected when we do additional preparation on the data before running the model.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of how Total Items has helped the model, you can see the job it has
    done for predicting current customers. We have actually done a better job in predicting
    the current customer field. Hence, this shows that the new variables that we chose
    to add may not necessarily improve the accuracy of the overall model, but can
    certainly improve the accuracy of one or more predicted categories. You can decide
    which category is more important for your requirements and select a new variable
    accordingly. We will now move on to see how sampling can help us provide better
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Balancing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see how we can oversample or undersample different
    aspects of the outcome variable to improve our accuracy. We will change our dataset
    to see this. Refer to the `Loan` dataset provided with the GitHub link of this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: The need for balancing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate this, we will use a different dataset. Select the Var. File
    node on the canvas. Navigate to where the file is located by clicking the triple
    dots beside the file field. Then select the `Loan` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7cf695c-f156-44e5-b18d-0be27afcdc9c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Go to the Types tab and change the Loan predictor''s Role to Target. This is
    the variable that we will predict:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/997d3766-6a5c-4628-a83c-e348b8d32a48.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on Read Values. Then, click on OK. In this example, we are predicting
    whether or not people have a loan.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the distribution of our loan variable; go to the Graphs palette
    and connect our source node, Loan, to a Distribution node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12c1e1d3-6e9b-4bd8-851e-d1d49887c575.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Distribution node. Then click on the arrow next to the field box
    to select our predictor, for which we need to see the distribution, in our case,
    loan:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2deb58f3-850b-4b01-921d-a1110f5ad231.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, click on Run. You will see the following distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffadf281-bcfb-44ee-9f38-18992d4b1072.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that 86% of the people in this dataset have a loan, and 13% don't have
    a loan. In such a case, predicting the group of people having no loan can be a
    little difficult because the distribution is very uneven. Hence, in such a situation,
    we need to balance the data. This means making it a little more similar similar
    in terms of the category size of each group. This balancing of data is also known
    as oversampling or undersampling.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a little more of an extreme example. Let's say that we're trying
    to predict fraud, and that the distribution of the dataset is that 99% of the
    cases are perfectly legitimate and only 1% of the cases are fraudulent. Now, if
    we build a model with that type of distribution, what will often happen is that
    the model is going to predict that all cases aren't fraudulent. The overall accuracy
    of such a model will be 99%, because 99% of the time it's right, but what we really
    care about is predicting those few fraudulent cases. If we're always predicting
    that we have a good case, then you know the model itself is not really that useful,
    even though its overall accuracy is 99%. Hence, sometimes the overall accuracy
    of the model is not that useful. What we really care more about is the accuracy
    of predicting each individual category.
  prefs: []
  type: TYPE_NORMAL
- en: What happens with situations like the fraud detection example is, because one
    group is so over-represented, or technically the other group, or the smaller group,
    is under-represented, the model doesn't really learn the patterns or the characteristics
    that are going on for the smaller group, and that's why we sometimes need to oversample
    or undersample.
  prefs: []
  type: TYPE_NORMAL
- en: Let's come back to our example and try and see what we can do with it.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing balance in data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s first build a model to predict the loan and see what we find:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the Field Ops palette and connect the Loan node to a Partition node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the Neural Net model to the Partition node from the Modeling palette,
    and run the Neural Net model with defaults:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aa6246f9-abcb-475b-851f-1944ce0b9ce5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Go to the Output palette and connect the newly generated node to the Analysis
    node. Run the Analysis node with the Coincidence matrices checked, and you will
    get the following results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ba16f041-ca0f-4a0b-9f32-ebc41e04ee97.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the overall accuracy of the model is around 93%, and the model
    is quite consistent. Let's see how well the model has predicted each one of the
    categories. We are certainly predicting the Yes group pretty well. However, we
    are not doing so well with the No group. We can try to improve the way we predict
    our No group.
  prefs: []
  type: TYPE_NORMAL
- en: The results acquired bring us to a stage where we will have to oversample the
    **No** group. Or undersample the **Yes** group.
  prefs: []
  type: TYPE_NORMAL
- en: 'For oversampling, we will first need to partition the dataset into a training
    and testing dataset. One thing to remember here is when we are oversampling a
    dataset, we do not need to have equal oversampling on the training as well as
    the testing dataset. In fact, what we need is to assess the testing dataset on
    the original distribution, because with oversampling we run the risk of performing
    well on the training dataset but not on the testing dataset. To avoid this, we
    will first have to separate our data. Hence, we will first oversample the training
    dataset data, then build a model on it, and then apply it to the testing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the Record Ops palette, and connect the Partition node to the Select
    node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c540cd83-60ab-4ecd-8f78-b3cdbe1f437b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the Select node. Here we will select only the people that are in the
    training dataset. We will perform our data manipulations, then oversample or undersample
    our data and get the results. For doing this, click on the expression builder.
    Then, select the Partition variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/660c1692-3a94-4f46-a63b-4bc525ef556f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **=** sign, and then click on the field values button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e3bb5a8-6db6-4091-b19f-67a29ec3a660.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, select the Training dataset and click on OK:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28c04fbc-d9e0-4e18-8304-fa59eb964160.png)'
  prefs: []
  type: TYPE_IMG
- en: A dialogue box will open. Click OK on that too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect another Select node to the existing Select node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e46787d5-ec29-4070-913d-ec07251891e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this Select node, we will keep people with a value of No; for this, go to
    the expression builder and select the loan variable, click on the = sign, and
    then click on the field values button and select No:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/32af08b7-2893-47e4-acf7-e5c412441b45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will add another Select node connected to the first Select node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/93b6c218-d985-4a99-9e89-32b917349cca.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on the expression builder. Select the loan variable, and click on the
    = sign. Click on the field values button and select the Yes value. Click on OK.
    So, now we have selected all people with a loan. This is a larger group of people,
    which is over-represented. This brings us to the stage where we select only one-third
    of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the Record Ops palette and connect the Sample node to the Select node
    of the Yes group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b0380f14-be87-418d-9334-dcdcf9742366.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Edit the Sample node. Select Random% to randomly select the values, and set
    the value to 33%. Also, check the Repeatable partition assignment. This will allow
    us to select the same people every time we create a model for this selection.
    Click on OK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7a0be76c-898a-455e-8913-a0cbae412d99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will have to combine this separate data and bring it back together. For
    this, connect the Select node that has all people with the value set as No to
    the Append node. Then right-click on the Sample node and select connect to connect
    it to the Append node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/37bcd7c9-5889-451a-b764-e49cce86c5c9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Append node and select All datasets, then click on OK:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0fcd1a05-80c1-4005-99cc-9ccead12a53a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s check how the distribution of the Loan field looks now after sampling.
    For this, go to the Graphs palette and connect the Append node to the Distribution
    node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/499396cf-81a2-409e-8233-fd29ec77aee0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Distribution node, go to the Field box, and select loan just as
    we did before. Then click on Run. Here is the distribution that we have acquired
    after sampling:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b6f718b4-972c-4b13-8261-875316efd736.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the No group constitutes about one-third of the sample.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, by undersampling the Yes node, we were able to see the difference from
    13%.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see oversampling:'
  prefs: []
  type: TYPE_NORMAL
- en: Let's now connect the Append node to the Type node from the Field Ops palette.
    Here, we won't be using the partition field. Hence, go to the Types node and change
    the Partition's role to None.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will again build our model by going to the modeling palette. And connect
    the Type node to a neural net model. And run this setup on the defaults.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, connect your first generated model to the newly generated model, and connect
    both of them to the Analysis node. Let''s see our results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4b578ba2-2d91-42ba-b105-0637a652776e.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see how well we are predicting the No group now! Our model has performed
    pretty well in predicting the accuracies of the individual models. Hence, we ended
    up balancing the data, obviously it is at expense of errors in the yes group.
    But the No group was our matter of concern as it was under-represented.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter taught us how to modify the various options that are available
    for enhancing the model. We also learned how to add additional fields and remove
    noise from these models. Lastly, we sampled the data available, which helped us
    to understand the model better.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to learn how to combine models and improve
    them even further.
  prefs: []
  type: TYPE_NORMAL
