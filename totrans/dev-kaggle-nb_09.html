<html><head></head><body>
<div class="Basic-Text-Frame" id="_idContainer217">
<h1 class="chapterNumber"><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 class="chapterTitle" id="_idParaDest-126"><span class="koboSpan" id="kobo.2.1">Can You Find Out Which Movie Is a Deepfake?</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.3.1">In the previous chapters, we explored various data formats: tabular, geospatial, text, image, and acoustic, while working with Kaggle datasets, learning about shapefile visualization, building models for image or text classification, and acoustic signal analysis.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.4.1">In this chapter, we will introduce video data analysis. </span><span class="koboSpan" id="kobo.4.2">We will start by describing a Kaggle competition, </span><em class="italic"><span class="koboSpan" id="kobo.5.1">Deepfake Detection Challenge</span></em><span class="koboSpan" id="kobo.6.1">.</span><em class="italic"> </em><span class="koboSpan" id="kobo.7.1">This competition challenged the participants to classify which videos were generated artificially to create realistic fake content convincingly. </span><span class="koboSpan" id="kobo.7.2">We will continue by quickly exploring the most used video formats, followed by introducing two utility scripts used for our data analysis. </span><span class="koboSpan" id="kobo.7.3">First, a utility script with functions for manipulating video content, i.e., reading, visualizing images from videos, and playing video files. </span><span class="koboSpan" id="kobo.7.4">Second, a utility script with functions for body, face, and face element detection. </span><span class="koboSpan" id="kobo.7.5">We will continue with metadata exploration from the competition dataset and then apply the utility scripts introduced to analyze the video data from the competition dataset.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.8.1">In a nutshell, the following topics will be covered in this chapter:</span></p>
<ul>
<li class="bulletList"><span class="koboSpan" id="kobo.9.1">An introduction to the </span><em class="italic"><span class="koboSpan" id="kobo.10.1">Deepfake Detection Challenge</span></em><span class="koboSpan" id="kobo.11.1"> competition</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.12.1">Utility scripts for video data manipulation and object detection in video data</span></li>
<li class="bulletList"><span class="koboSpan" id="kobo.13.1">Metadata analysis and video data analysis from the competition dataset</span></li>
</ul>
<h1 class="heading-1" id="_idParaDest-127"><span class="koboSpan" id="kobo.14.1">Introducing the competition</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.15.1">In </span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.16.1">this chapter, we examine data from the well-known Kaggle competition the </span><strong class="keyWord"><span class="koboSpan" id="kobo.17.1">Deepfake</span></strong><em class="italic"> </em><strong class="keyWord"><span class="koboSpan" id="kobo.18.1">Detection</span></strong><em class="italic"> </em><strong class="keyWord"><span class="koboSpan" id="kobo.19.1">Challenge</span></strong><span class="koboSpan" id="kobo.20.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.21.1">DFDC</span></strong><span class="koboSpan" id="kobo.22.1">). </span><span class="koboSpan" id="kobo.22.2">The competition, detailed in </span><em class="italic"><span class="koboSpan" id="kobo.23.1">Reference 1</span></em><span class="koboSpan" id="kobo.24.1">, commenced on December 11, 2019, and concluded on March 31, 2020. </span><span class="koboSpan" id="kobo.24.2">It attracted 2,265 teams comprising 2,904 participants, who collectively made 8,951 submissions. </span><span class="koboSpan" id="kobo.24.3">Competitors vied for a total prize pool of $1,000,000, with the first prize being $500,000.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.25.1">The event was a collaborative effort involving AWS, Facebook, Microsoft, the Partnership on AI’s Media Integrity Steering Committee, and various academic entities. </span><span class="koboSpan" id="kobo.25.2">At the time, there was a widespread agreement among tech industry leaders and academics on the technical complexity and rapidly changing nature of media content manipulation. </span><span class="koboSpan" id="kobo.25.3">The competition’s aim was to encourage global researchers to devise innovative and effective technologies to detect deepfakes and media manipulation. </span><span class="koboSpan" id="kobo.25.4">Unlike later competitions that focused on code, this one required prize-eligible participants to test their code in a “black box” environment. </span><span class="koboSpan" id="kobo.25.5">The testing data, not available on Kaggle and necessitating a longer process, resulted in the private leaderboard being revealed later than usual, officially on June 12, 2020, although the competition ended on April 24, 2020.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.26.1">The DFDC drew numerous high-ranking Kaggle Grandmasters who engaged in data analysis and developed models for submission. </span><span class="koboSpan" id="kobo.26.2">Notably, the initial first-prize winner was later disqualified by the organizers. </span><span class="koboSpan" id="kobo.26.3">This team, along with other top-ranked participants, had expanded their training sets using publicly available data. </span><span class="koboSpan" id="kobo.26.4">While they adhered to the competition’s rules regarding the use of external data, they failed to meet the documentation requirements for winning submissions. </span><span class="koboSpan" id="kobo.26.5">These rules included obtaining written consent from all individuals featured in the images used in the additional training data.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.27.1">The competition data was given in two separate sets. </span><span class="koboSpan" id="kobo.27.2">In the first set, 400 video samples for training and 400 videos for testing were provided in two folders, one for training data and one for testing data. </span><span class="koboSpan" id="kobo.27.3">These files are in the MP4 format, one of the most commonly used video formats.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.28.1">A much larger dataset, of over 470 GB, for training, was made available as a download link. </span><span class="koboSpan" id="kobo.28.2">Alternatively, the same data was also made available as 50 smaller files of around 10 GB each. </span><span class="koboSpan" id="kobo.28.3">For the current analysis, we will only use the data from the first set (containing the 400 training and 400 testing files, in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.29.1">.mp4</span></code><span class="koboSpan" id="kobo.30.1"> format).</span></p>
<div class="note">
<p class="normal"><strong class="keyWord"><span class="koboSpan" id="kobo.31.1">Formats for video data</span></strong></p>
<p class="normal"><span class="koboSpan" id="kobo.32.1">Video formats refer to standards used to encode, compress, and store video data. </span><span class="koboSpan" id="kobo.32.2">Currently, there are multiple formats that are used in parallel. </span><span class="koboSpan" id="kobo.32.3">Some of these video formats were created and promoted by technology companies like Microsoft, Apple, and Adobe. </span><span class="koboSpan" id="kobo.32.4">Their decision to develop proprietary formats might have been related to the need to control the quality of rendering on their own devices or devices running their operating systems.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.33.1">Additionally, proprietary formats can give you a competitive advantage and larger control over licensing and the royalties associated with the format. </span><span class="koboSpan" id="kobo.33.2">Some of these formats incorporate innovations and useful features not existent in previously used formats. </span><span class="koboSpan" id="kobo.33.3">In parallel with the development by technology leaders, other formats were developed in response to a combination of technology advancements, market demand, and the need to align industry standards.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.34.1">To give just a few examples of frequently </span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.35.1">used formats, we can mention </span><strong class="keyWord"><span class="koboSpan" id="kobo.36.1">Windows Media Video</span></strong><span class="koboSpan" id="kobo.37.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.38.1">WMV</span></strong><span class="koboSpan" id="kobo.39.1">) and </span><strong class="keyWord"><span class="koboSpan" id="kobo.40.1">Audio Video Interleave</span></strong><span class="koboSpan" id="kobo.41.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.42.1">AVI</span></strong><span class="koboSpan" id="kobo.43.1">), both </span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.44.1">developed by Microsoft. </span><span class="koboSpan" id="kobo.44.2">The MOV (QuickTime Movie) format was developed by Apple to run on their macOS and iOS platforms. </span><span class="koboSpan" id="kobo.44.3">All these formats support multiple audio and video codecs. </span><span class="koboSpan" id="kobo.44.4">Then, we also</span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.45.1"> have </span><strong class="keyWord"><span class="koboSpan" id="kobo.46.1">Flash Video</span></strong><span class="koboSpan" id="kobo.47.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.48.1">FLV</span></strong><span class="koboSpan" id="kobo.49.1">), which was developed by Adobe. </span><span class="koboSpan" id="kobo.49.2">Additionally, one widely adopted format is </span><strong class="keyWord"><span class="koboSpan" id="kobo.50.1">MPEG-4 Part 14</span></strong><span class="koboSpan" id="kobo.51.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.52.1">MP4</span></strong><span class="koboSpan" id="kobo.53.1">), which</span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.54.1"> is open-source and can also hold many video and audio codecs. </span><strong class="keyWord"><span class="koboSpan" id="kobo.55.1">Moving Picture Experts Group</span></strong><span class="koboSpan" id="kobo.56.1"> (</span><strong class="keyWord"><span class="koboSpan" id="kobo.57.1">MPEG</span></strong><span class="koboSpan" id="kobo.58.1">) refers</span><a id="_idIndexMarker441"/><span class="koboSpan" id="kobo.59.1"> to a group of industry experts that developed the standards for audio and video compressing and encoding/decoding. </span><span class="koboSpan" id="kobo.59.2">The successive standards, from MPEG-1 to MPEG-4, have had a massive impact on the development of the media industry.</span></p>
</div>
<h1 class="heading-1" id="_idParaDest-128"><span class="koboSpan" id="kobo.60.1">Introducing competition utility scripts</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.61.1">Let’s begin </span><a id="_idIndexMarker442"/><span class="koboSpan" id="kobo.62.1">by grouping the Python modules with reusable functions for video manipulation in two Kaggle utility scripts. </span><span class="koboSpan" id="kobo.62.2">The first utility script groups </span><a id="_idIndexMarker443"/><span class="koboSpan" id="kobo.63.1">functions to load and display images from videos or play video files. </span><span class="koboSpan" id="kobo.63.2">The second one is geared toward object detection in videos – more specifically, to detect human faces and bodies – using a few alternative methods.</span></p>
<h2 class="heading-2" id="_idParaDest-129"><span class="koboSpan" id="kobo.64.1">Video data utils</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.65.1">We developed a </span><a id="_idIndexMarker444"/><span class="koboSpan" id="kobo.66.1">utility script to assist us in the manipulation of video data. </span><span class="koboSpan" id="kobo.66.2">Let’s introduce one utility script that we will use in the notebook associated with the current chapter to read video data, as well as visualize frames from a video file.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.67.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.68.1">video_utils</span></code><span class="koboSpan" id="kobo.69.1"> utility script </span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.70.1">includes functions to load, transform, and display images from videos. </span><span class="koboSpan" id="kobo.70.2">Additionally, it also contains a function to play video content. </span><span class="koboSpan" id="kobo.70.3">For video manipulation, we will use the OpenCV library. </span><span class="koboSpan" id="kobo.70.4">OpenCV is an open-source computer vision library widely used for image and video processing. </span><span class="koboSpan" id="kobo.70.5">Developed in C and C++, OpenCV has also a Python interface.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.71.1">The following code block shows the included libraries and the function to display one image from a video file:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.72.1">import</span></span><span class="koboSpan" id="kobo.73.1"> os
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.74.1">import</span></span><span class="koboSpan" id="kobo.75.1"> cv2 </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.76.1">as</span></span><span class="koboSpan" id="kobo.77.1"> cv
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.78.1">import</span></span><span class="koboSpan" id="kobo.79.1"> matplotlib.pyplot </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.80.1">as</span></span><span class="koboSpan" id="kobo.81.1"> plt
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.82.1">from</span></span><span class="koboSpan" id="kobo.83.1"> IPython.display </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.84.1">import</span></span><span class="koboSpan" id="kobo.85.1"> HTML
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.86.1">from</span></span><span class="koboSpan" id="kobo.87.1"> base64 </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.88.1">import</span></span><span class="koboSpan" id="kobo.89.1"> b64encode
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.90.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.91.1">display_image_from_video</span></span><span class="koboSpan" id="kobo.92.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.93.1">video_path</span></span><span class="koboSpan" id="kobo.94.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.95.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.96.1">    Display image from video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.97.1">    Process</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.98.1">        1. </span><span class="koboSpan" id="kobo.98.2">perform a video capture from the video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.99.1">        2. </span><span class="koboSpan" id="kobo.99.2">read the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.100.1">        3. </span><span class="koboSpan" id="kobo.100.2">display the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.101.1">    Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.102.1">        video_path - path for video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.103.1">    Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.104.1">        None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.105.1">    '''</span></span><span class="koboSpan" id="kobo.106.1">
    capture_image = cv.VideoCapture(video_path)
    ret, frame = capture_image.read()
    fig = plt.figure(figsize=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.107.1">10</span></span><span class="koboSpan" id="kobo.108.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.109.1">10</span></span><span class="koboSpan" id="kobo.110.1">))
    ax = fig.add_subplot(</span><span class="hljs-number"><span class="koboSpan" id="kobo.111.1">111</span></span><span class="koboSpan" id="kobo.112.1">)
    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
    ax.imshow(frame)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.113.1">In the preceding code, the function </span><code class="inlineCode"><span class="koboSpan" id="kobo.114.1">display_image_from_video</span></code><span class="koboSpan" id="kobo.115.1"> receives as a parameter the path to a video file, performs an image capture from the video, reads the image, creates a Matplotlib Pyplot image, converts it from BGR (Blue Green Red) to RGB (Red Green Blue), and displays it. </span><span class="koboSpan" id="kobo.115.2">RGB is a color model used to represent color in a digital image. </span><span class="koboSpan" id="kobo.115.3">The difference between RGB and BGR is in the order in which the color information is stored. </span><span class="koboSpan" id="kobo.115.4">In </span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.116.1">the case of RGB, blue is stored as the least significant area, followed by green, and then red. </span><span class="koboSpan" id="kobo.116.2">In the case of BGR, the </span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.117.1">order is reversed.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.118.1">Next, we define a function to represent a group of image captures, from a list of video files:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.119.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.120.1">display_images_from_video_list</span></span><span class="koboSpan" id="kobo.121.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.122.1">video_path_list, data_folder, video_folder</span></span><span class="koboSpan" id="kobo.123.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.124.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.125.1">    Display images from video list</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.126.1">    Process:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.127.1">        0. </span><span class="koboSpan" id="kobo.127.2">for each video in the video path list</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.128.1">            1. </span><span class="koboSpan" id="kobo.128.2">perform a video capture from the video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.129.1">            2. </span><span class="koboSpan" id="kobo.129.2">read the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.130.1">            3. </span><span class="koboSpan" id="kobo.130.2">display the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.131.1">    Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.132.1">        video_path_list: path for video list</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.133.1">        data_folder: path for data</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.134.1">        video_folder: path for video folder</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.135.1">    Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.136.1">        None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.137.1">    '''</span></span><span class="koboSpan" id="kobo.138.1">
    plt.figure()
    fig, ax = plt.subplots(</span><span class="hljs-number"><span class="koboSpan" id="kobo.139.1">2</span></span><span class="koboSpan" id="kobo.140.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.141.1">3</span></span><span class="koboSpan" id="kobo.142.1">,figsize=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.143.1">16</span></span><span class="koboSpan" id="kobo.144.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.145.1">8</span></span><span class="koboSpan" id="kobo.146.1">))
    </span><span class="hljs-comment"><span class="koboSpan" id="kobo.147.1"># we only show images extracted from the first 6 videos</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.148.1">for</span></span><span class="koboSpan" id="kobo.149.1"> i, video_file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.150.1">in</span></span> <span class="hljs-built_in"><span class="koboSpan" id="kobo.151.1">enumerate</span></span><span class="koboSpan" id="kobo.152.1">(video_path_list[</span><span class="hljs-number"><span class="koboSpan" id="kobo.153.1">0</span></span><span class="koboSpan" id="kobo.154.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.155.1">6</span></span><span class="koboSpan" id="kobo.156.1">]):
        video_path = os.path.join(data_folder, video_folder,video_file)
        capture_image = cv.VideoCapture(video_path)
        ret, frame = capture_image.read()
        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
        ax[i//</span><span class="hljs-number"><span class="koboSpan" id="kobo.157.1">3</span></span><span class="koboSpan" id="kobo.158.1">, i%</span><span class="hljs-number"><span class="koboSpan" id="kobo.159.1">3</span></span><span class="koboSpan" id="kobo.160.1">].imshow(frame)
        ax[i//</span><span class="hljs-number"><span class="koboSpan" id="kobo.161.1">3</span></span><span class="koboSpan" id="kobo.162.1">, i%</span><span class="hljs-number"><span class="koboSpan" id="kobo.163.1">3</span></span><span class="koboSpan" id="kobo.164.1">].set_title(</span><span class="hljs-string"><span class="koboSpan" id="kobo.165.1">f"Video: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.166.1">{video_file}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.167.1">"</span></span><span class="koboSpan" id="kobo.168.1">)
        ax[i//</span><span class="hljs-number"><span class="koboSpan" id="kobo.169.1">3</span></span><span class="koboSpan" id="kobo.170.1">, i%</span><span class="hljs-number"><span class="koboSpan" id="kobo.171.1">3</span></span><span class="koboSpan" id="kobo.172.1">].axis(</span><span class="hljs-string"><span class="koboSpan" id="kobo.173.1">'on'</span></span><span class="koboSpan" id="kobo.174.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.175.1">The function </span><code class="inlineCode"><span class="koboSpan" id="kobo.176.1">display_images_from_video_list</span></code><span class="koboSpan" id="kobo.177.1"> receives as a parameter the path to a list of video filenames, relative to the path to its folder, and the path to the dataset. </span><span class="koboSpan" id="kobo.177.2">The function will perform the same processing as </span><code class="inlineCode"><span class="koboSpan" id="kobo.178.1">display_image_from_video</span></code><span class="koboSpan" id="kobo.179.1"> does, for the first six video files in the list. </span><span class="koboSpan" id="kobo.179.2">We limit the number of images captured from video files for convenience.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.180.1">The </span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.181.1">utility script also includes a function to play videos. </span><span class="koboSpan" id="kobo.181.2">The function uses the </span><code class="inlineCode"><span class="koboSpan" id="kobo.182.1">HTML</span></code><span class="koboSpan" id="kobo.183.1"> function from the IPython </span><code class="inlineCode"><span class="koboSpan" id="kobo.184.1">display</span></code><span class="koboSpan" id="kobo.185.1"> module. </span><span class="koboSpan" id="kobo.185.2">The code will be:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.186.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.187.1">play_video</span></span><span class="koboSpan" id="kobo.188.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.189.1">video_file, data_folder, subset</span></span><span class="koboSpan" id="kobo.190.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.191.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.192.1">    Display video given by composed path</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.193.1">    Args</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.194.1">        video_file: the name of the video file to display</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.195.1">        data_folder: data folder</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.196.1">        subset: the folder where the video file is located</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.197.1">    Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.198.1">        a HTML objects running the video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.199.1">    '''</span></span><span class="koboSpan" id="kobo.200.1">
    video_url = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.201.1">open</span></span><span class="koboSpan" id="kobo.202.1">(os.path.join(data_folder, subset,video_file),</span><span class="hljs-string"><span class="koboSpan" id="kobo.203.1">'rb'</span></span><span class="koboSpan" id="kobo.204.1">).read()
    data_url = </span><span class="hljs-string"><span class="koboSpan" id="kobo.205.1">"data:video/mp4;base64,"</span></span><span class="koboSpan" id="kobo.206.1"> + b64encode(video_url).decode()
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.207.1">return</span></span><span class="koboSpan" id="kobo.208.1"> HTML(</span><span class="hljs-string"><span class="koboSpan" id="kobo.209.1">"""&lt;video width=500 controls&gt;&lt;source src="%s" type="video/mp4"&gt;&lt;/video&gt;"""</span></span><span class="koboSpan" id="kobo.210.1"> % data_url)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.211.1">The</span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.212.1"> function </span><code class="inlineCode"><span class="koboSpan" id="kobo.213.1">play_video</span></code><span class="koboSpan" id="kobo.214.1"> receives as parameters the name of the video file to play, the data folder, the folder contained in the data folder, and where the video file is located. </span><span class="koboSpan" id="kobo.214.2">The function uses the </span><code class="inlineCode"><span class="koboSpan" id="kobo.215.1">b64encode</span></code><span class="koboSpan" id="kobo.216.1"> function from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.217.1">base64</span></code><span class="koboSpan" id="kobo.218.1"> library to decode the MP4 video format, and the decoded content is displayed in a video frame with a controlled width of 500 pixels, using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.219.1">HTML</span></code><span class="koboSpan" id="kobo.220.1"> control.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.221.1">We have introduced the utility script for video image manipulation, loads the video, visualize images from videos, and play video files. </span><span class="koboSpan" id="kobo.221.2">In the next section, we introduce more utility scripts for object detection in images. </span><span class="koboSpan" id="kobo.221.3">These Python modules contain specialized classes for object detection. </span><span class="koboSpan" id="kobo.221.4">The modules implement two alternatives for face object detection, both based on computer vision algorithms.</span></p>
<h2 class="heading-2" id="_idParaDest-130"><span class="koboSpan" id="kobo.222.1">Face and body detection utils</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.223.1">In the </span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.224.1">detection of deepfake videos, the analysis of video features such as desynchronization between sound and lip </span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.225.1">movement or unnatural motions of parts of the faces of people appearing in the video were, at the time of this competition, valuable elements to train models to recognize deepfake videos. </span><span class="koboSpan" id="kobo.225.2">Therefore, we include here the utility script specialized to detect bodies and faces.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.226.1">The first module for face detection </span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.227.1">used the </span><strong class="keyWord"><span class="koboSpan" id="kobo.228.1">Haar cascade</span></strong><span class="koboSpan" id="kobo.229.1"> algorithm. </span><span class="koboSpan" id="kobo.229.2">Haar cascade is a lightweight machine learning algorithm for object detection. </span><span class="koboSpan" id="kobo.229.3">It is usually trained to identify specific objects. </span><span class="koboSpan" id="kobo.229.4">The algorithm uses Haar-like features and the Adaboost classifier to create a strong classifier. </span><span class="koboSpan" id="kobo.229.5">The algorithm operates on a sliding window, applying a cascade of weak classifiers that rejects regions of the image less likely to contain the object of interest. </span><span class="koboSpan" id="kobo.229.6">In our case, we want to use the algorithm to identify details in video images that are usually altered in the case of a deepfake, such as the facial expression, the gaze, and the mouth shape. </span><span class="koboSpan" id="kobo.229.7">This module includes two classes. </span><span class="koboSpan" id="kobo.229.8">We start with one of these classes. </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.230.1">CascadeObjectDetector</span></strong><span class="koboSpan" id="kobo.231.1"> is a</span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.232.1"> generic class for the detection of objects using the </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.233.1">Haar</span></strong> <strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.234.1">cascade</span></strong><span class="koboSpan" id="kobo.235.1"> algorithm. </span><span class="koboSpan" id="kobo.235.2">The </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.236.1">CascadeObjectDetector</span></strong><strong class="keyWord"> </strong><span class="koboSpan" id="kobo.237.1">class, which is modified from the code in </span><em class="italic"><span class="koboSpan" id="kobo.238.1">Reference 3</span></em><span class="koboSpan" id="kobo.239.1">, has an </span><code class="inlineCode"><span class="koboSpan" id="kobo.240.1">init</span></code><span class="koboSpan" id="kobo.241.1"> function where we initialize the object with the specific </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.242.1">Haar cascade</span></strong><span class="koboSpan" id="kobo.243.1"> object</span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.244.1"> that stores the trained model. </span><span class="koboSpan" id="kobo.244.2">The class also has a </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.245.1">detect</span></strong><span class="koboSpan" id="kobo.246.1"> function. </span><span class="koboSpan" id="kobo.246.2">The following is the code for </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.247.1">CascadeObjectDetector</span></strong><span class="koboSpan" id="kobo.248.1">. </span><span class="koboSpan" id="kobo.248.2">In the </span><code class="inlineCode"><span class="koboSpan" id="kobo.249.1">init</span></code><span class="koboSpan" id="kobo.250.1"> function, we initialize the </span><code class="inlineCode"><span class="koboSpan" id="kobo.251.1">cascade</span></code><span class="koboSpan" id="kobo.252.1"> object:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.253.1">import</span></span><span class="koboSpan" id="kobo.254.1"> os
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.255.1">import</span></span><span class="koboSpan" id="kobo.256.1"> cv2 </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.257.1">as</span></span><span class="koboSpan" id="kobo.258.1"> cv
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.259.1">import</span></span><span class="koboSpan" id="kobo.260.1"> matplotlib.pyplot </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.261.1">as</span></span><span class="koboSpan" id="kobo.262.1"> plt
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.263.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.264.1">CascadeObjectDetector</span></span><span class="koboSpan" id="kobo.265.1">():
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.266.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.267.1">    Class for Cascade Object Detection</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.268.1">    '''</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.269.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.270.1">__init__</span></span><span class="koboSpan" id="kobo.271.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.272.1">self,object_cascade_path</span></span><span class="koboSpan" id="kobo.273.1">):
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.274.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.275.1">        Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.276.1">        object_cascade_path: path for the *.xml defining the parameters</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.277.1">                for {face, eye, smile, profile} detection algorithm</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.278.1">                source of the haarcascade resource is:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.279.1">                https://github.com/opencv/opencv/tree/master/data/haarcascades</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.280.1">        Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.281.1">            None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.282.1">        '''</span></span><span class="koboSpan" id="kobo.283.1">
        self.object_cascade=cv.CascadeClassifier(object_cascade_path)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.284.1">The </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.285.1">next code snippet contains the </span><code class="inlineCode"><span class="koboSpan" id="kobo.286.1">detect</span></code><span class="koboSpan" id="kobo.287.1"> function of the </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.288.1">CascadeObjectDetector</span></strong><span class="koboSpan" id="kobo.289.1"> class. </span><span class="koboSpan" id="kobo.289.2">This function returns the rectangle coordinates of the object detected in the image:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.290.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.291.1">detect</span></span><span class="koboSpan" id="kobo.292.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.293.1">self, image, scale_factor=</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.294.1">1.3</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.295.1">,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.296.1">           min_neighbors=</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.297.1">5</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.298.1">,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.299.1">           min_size=(</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.300.1">20</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.301.1">,</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.302.1">20</span></span><span class="hljs-params"><span class="koboSpan" id="kobo.303.1">)</span></span><span class="koboSpan" id="kobo.304.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.305.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.306.1">    Function return rectangle coordinates of object for given image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.307.1">    Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.308.1">        image: image to process</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.309.1">        scale_factor: scale factor used for object detection</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.310.1">        min_neighbors: minimum number of parameters considered during object detection</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.311.1">        min_size: minimum size of bounding box for object detected</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.312.1">    Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.313.1">        rectangle with detected object</span></span>
<span class="hljs-string"> </span>
<span class="hljs-string"><span class="koboSpan" id="kobo.314.1">    '''</span></span><span class="koboSpan" id="kobo.315.1">
    rects=self.object_cascade.detectMultiScale(image,
                                            scaleFactor=scale_factor,
                                            minNeighbors=min_neighbors,
                                            minSize=min_size)
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.316.1">return</span></span><span class="koboSpan" id="kobo.317.1"> rects
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.318.1">For this competition, I created a dedicated Kaggle dataset, from the Haar cascade algorithms defined at </span><a href="https://github.com/opencv/opencv/tree/master/data/haarcascades"><span class="url"><span class="koboSpan" id="kobo.319.1">https://github.com/opencv/opencv/tree/master/data/haarcascades</span></span></a><span class="koboSpan" id="kobo.320.1">, as part of the OpenCV library distribution. </span><span class="koboSpan" id="kobo.320.2">The link to this database, called </span><em class="italic"><span class="koboSpan" id="kobo.321.1">Haar Cascades for Face Detection</span></em><span class="koboSpan" id="kobo.322.1">, is given in </span><em class="italic"><span class="koboSpan" id="kobo.323.1">Reference 2</span></em><span class="koboSpan" id="kobo.324.1">. </span><span class="koboSpan" id="kobo.324.2">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.325.1">init</span></code><span class="koboSpan" id="kobo.326.1"> function receives a path to one of the object detection</span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.327.1"> models included in the database. </span><span class="koboSpan" id="kobo.327.2">The function </span><code class="inlineCode"><span class="koboSpan" id="kobo.328.1">detect</span></code><span class="koboSpan" id="kobo.329.1"> receives, as parameters, the image to process for object extraction and a few parameters that can be used to adjust the detection. </span><span class="koboSpan" id="kobo.329.2">These parameters are the scale factor, the minimum number of neighbors used in detection, and the minimum size of the bounding box used for object detection. </span><span class="koboSpan" id="kobo.329.3">Inside the </span><code class="inlineCode"><span class="koboSpan" id="kobo.330.1">detect</span></code><span class="koboSpan" id="kobo.331.1"> function we call the function </span><code class="inlineCode"><span class="koboSpan" id="kobo.332.1">detectMultiscale</span></code><span class="koboSpan" id="kobo.333.1"> from the Haar cascade model.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.334.1">The </span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.335.1">next class defined in the utility script is </span><code class="inlineCode"><span class="koboSpan" id="kobo.336.1">FaceObjectDetector</span></code><span class="koboSpan" id="kobo.337.1">. </span><span class="koboSpan" id="kobo.337.2">This </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.338.1">class initializes four </span><code class="inlineCode"><span class="koboSpan" id="kobo.339.1">CascadeObjectDetector</span></code><strong class="keyWord"> </strong><span class="koboSpan" id="kobo.340.1">objects, for the face, face profile, eyes, and smile detection. </span><span class="koboSpan" id="kobo.340.2">The following code block shows the class definition with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.341.1">init</span></code><span class="koboSpan" id="kobo.342.1"> function, where these objects are defined. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.343.1">For each face element, i.e., the frontal view of a person, profile view of a person, eye view, and smile view, we first initialize a dedicated variable with the value of the path to the Haar cascade resource. </span><span class="koboSpan" id="kobo.343.2">Then, for each of the resources, we initialize a </span><code class="inlineCode"><span class="koboSpan" id="kobo.344.1">CascadeObjectDetector</span></code><span class="koboSpan" id="kobo.345.1"> object (see the code explanation for the </span><code class="inlineCode"><span class="koboSpan" id="kobo.346.1">CascadeObjectDetector</span></code><span class="koboSpan" id="kobo.347.1"> class above):</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.348.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.349.1">FaceObjectDetector</span></span><span class="koboSpan" id="kobo.350.1">():
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.351.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.352.1">    Class for Face Object Detection</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.353.1">    '''</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.354.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.355.1">__init__</span></span><span class="koboSpan" id="kobo.356.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.357.1">self, face_detection_folder</span></span><span class="koboSpan" id="kobo.358.1">):
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.359.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.360.1">        Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.361.1">        face_detection_folder: path for folder where the *.xmls</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.362.1">                for {face, eye, smile, profile} detection algorithm</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.363.1">        Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.364.1">            None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.365.1">        '''</span></span><span class="koboSpan" id="kobo.366.1">
        self.path_cascade=face_detection_folder
        self.frontal_cascade_path= os.path.join(self.path_cascade,</span><span class="hljs-string"><span class="koboSpan" id="kobo.367.1">'haarcascade_frontalface_default.xml'</span></span><span class="koboSpan" id="kobo.368.1">)
        self.eye_cascade_path= os.path.join(self.path_cascade,</span><span class="hljs-string"><span class="koboSpan" id="kobo.369.1">'haarcascade_eye.xml'</span></span><span class="koboSpan" id="kobo.370.1">)
        self.profile_cascade_path= os.path.join(self.path_cascade,</span><span class="hljs-string"><span class="koboSpan" id="kobo.371.1">'haarcascade_profileface.xml'</span></span><span class="koboSpan" id="kobo.372.1">)
        self.smile_cascade_path= os.path.join(self.path_cascade,</span><span class="hljs-string"><span class="koboSpan" id="kobo.373.1">'haarcascade_smile.xml'</span></span><span class="koboSpan" id="kobo.374.1">)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.375.1">#Detector object created</span></span>
<span class="hljs-comment"><span class="koboSpan" id="kobo.376.1"># frontal face</span></span><span class="koboSpan" id="kobo.377.1">
        self.face_detector=CascadeObjectDetector(self.frontal_cascade_path)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.378.1"># eye</span></span><span class="koboSpan" id="kobo.379.1">
        self.eyes_detector=CascadeObjectDetector(self.eye_cascade_path)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.380.1"># profile face</span></span><span class="koboSpan" id="kobo.381.1">
        self.profile_detector=CascadeObjectDetector(self.profile_cascade_path)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.382.1"># smile</span></span><span class="koboSpan" id="kobo.383.1">
        self.smile_detector=CascadeObjectDetector(self.smile_cascade_path)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.384.1">The objects are stored as the member variables </span><code class="inlineCode"><span class="koboSpan" id="kobo.385.1">face_detector</span></code><span class="koboSpan" id="kobo.386.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.387.1">eyes_detector</span></code><span class="koboSpan" id="kobo.388.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.389.1">profile_detector</span></code><span class="koboSpan" id="kobo.390.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.391.1">smile_detector</span></code><span class="koboSpan" id="kobo.392.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.393.1">In the </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.394.1">next code block, we show the </span><code class="inlineCode"><span class="koboSpan" id="kobo.395.1">detect_objects</span></code><span class="koboSpan" id="kobo.396.1"> function, where we call, for each of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.397.1">CascadeObjectDetector</span></code><strong class="keyWord"> </strong><span class="koboSpan" id="kobo.398.1">objects defined in the </span><code class="inlineCode"><span class="koboSpan" id="kobo.399.1">init</span></code><span class="koboSpan" id="kobo.400.1"> function, the </span><code class="inlineCode"><span class="koboSpan" id="kobo.401.1">detect</span></code><span class="koboSpan" id="kobo.402.1"> function. </span><span class="koboSpan" id="kobo.402.2">To make it easier to follow, we will split the code snippet into three parts. </span><span class="koboSpan" id="kobo.402.3">The first part shows the call, from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.403.1">detect_object</span></code><span class="koboSpan" id="kobo.404.1"> function of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.405.1">FaceObjectDetector</span></code><span class="koboSpan" id="kobo.406.1"> class, and the detect</span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.407.1"> function of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.408.1">CascadeObjectDetector</span></code><span class="koboSpan" id="kobo.409.1"> object initialized with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.410.1">eyes</span></code><span class="koboSpan" id="kobo.411.1"> Haar cascade object. </span><span class="koboSpan" id="kobo.411.2">Then, we use the OpenCV </span><code class="inlineCode"><span class="koboSpan" id="kobo.412.1">Circle</span></code><span class="koboSpan" id="kobo.413.1"> function to mark on the initial image, with a circle, the position of the eyes detected in the image:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.414.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.415.1">detect_objects</span></span><span class="koboSpan" id="kobo.416.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.417.1">self,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.418.1">                   image,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.419.1">                   scale_factor,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.420.1">                   min_neighbors,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.421.1">                   min_size,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.422.1">                   show_smile=</span></span><span class="hljs-literal"><span class="koboSpan" id="kobo.423.1">False</span></span><span class="koboSpan" id="kobo.424.1">):
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.425.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.426.1">    Objects detection function</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.427.1">    Identify frontal face, eyes, smile and profile face and display the detected objects over the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.428.1">    Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.429.1">        image: the image extracted from the video</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.430.1">        scale_factor: scale factor parameter for `detect` function of CascadeObjectDetector object</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.431.1">        min_neighbors: min neighbors parameter for `detect` function of CascadeObjectDetector object</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.432.1">        min_size: minimum size parameter for f`detect` function of CascadeObjectDetector object</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.433.1">        show_smile: flag to activate/deactivate smile detection; set to False due to many false positives</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.434.1">    Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.435.1">        None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.436.1">    '''</span></span><span class="koboSpan" id="kobo.437.1">
    image_gray=cv.cvtColor(image, cv.COLOR_BGR2GRAY)
    eyes=self.eyes_detector.detect(image_gray,
                   scale_factor=scale_factor,
                   min_neighbors=min_neighbors,
                   min_size=(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.438.1">int</span></span><span class="koboSpan" id="kobo.439.1">(min_size[</span><span class="hljs-number"><span class="koboSpan" id="kobo.440.1">0</span></span><span class="koboSpan" id="kobo.441.1">]/</span><span class="hljs-number"><span class="koboSpan" id="kobo.442.1">2</span></span><span class="koboSpan" id="kobo.443.1">), </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.444.1">int</span></span><span class="koboSpan" id="kobo.445.1">(min_size[</span><span class="hljs-number"><span class="koboSpan" id="kobo.446.1">1</span></span><span class="koboSpan" id="kobo.447.1">]/</span><span class="hljs-number"><span class="koboSpan" id="kobo.448.1">2</span></span><span class="koboSpan" id="kobo.449.1">)))
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.450.1">for</span></span><span class="koboSpan" id="kobo.451.1"> x, y, w, h </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.452.1">in</span></span><span class="koboSpan" id="kobo.453.1"> eyes:
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.454.1">#detected eyes shown in color image</span></span><span class="koboSpan" id="kobo.455.1">
        cv.circle(image,(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.456.1">int</span></span><span class="koboSpan" id="kobo.457.1">(x+w/</span><span class="hljs-number"><span class="koboSpan" id="kobo.458.1">2</span></span><span class="koboSpan" id="kobo.459.1">),</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.460.1">int</span></span><span class="koboSpan" id="kobo.461.1">(y+h/</span><span class="hljs-number"><span class="koboSpan" id="kobo.462.1">2</span></span><span class="koboSpan" id="kobo.463.1">)),(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.464.1">int</span></span><span class="koboSpan" id="kobo.465.1">((w + h)/</span><span class="hljs-number"><span class="koboSpan" id="kobo.466.1">4</span></span><span class="koboSpan" id="kobo.467.1">)),(</span><span class="hljs-number"><span class="koboSpan" id="kobo.468.1">0</span></span><span class="koboSpan" id="kobo.469.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.470.1">0</span></span><span class="koboSpan" id="kobo.471.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.472.1">255</span></span><span class="koboSpan" id="kobo.473.1">),</span><span class="hljs-number"><span class="koboSpan" id="kobo.474.1">3</span></span><span class="koboSpan" id="kobo.475.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.476.1">Next, we </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.477.1">apply the same approach to the </span><code class="inlineCode"><span class="koboSpan" id="kobo.478.1">smile</span></code><span class="koboSpan" id="kobo.479.1"> objects in the image. </span><span class="koboSpan" id="kobo.479.2">We first detect the smile, and if detected, we display it using a rectangle, drawn with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.480.1">opencv</span></code><span class="koboSpan" id="kobo.481.1"> function over the </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.482.1">bounding box of the detected object. </span><span class="koboSpan" id="kobo.482.2">Because this function tends to give a lot of false positives, by default, this functionality is deactivated, using a flag set to </span><code class="inlineCode"><span class="koboSpan" id="kobo.483.1">False</span></code><span class="koboSpan" id="kobo.484.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"> <span class="hljs-comment"><span class="koboSpan" id="kobo.485.1"># deactivated by default due to many false positive</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.486.1">if</span></span><span class="koboSpan" id="kobo.487.1"> show_smile:
            smiles=self.smile_detector.detect(image_gray,
                          scale_factor=scale_factor,
                          min_neighbors=min_neighbors,
                          min_size=(</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.488.1">int</span></span><span class="koboSpan" id="kobo.489.1">(min_size[</span><span class="hljs-number"><span class="koboSpan" id="kobo.490.1">0</span></span><span class="koboSpan" id="kobo.491.1">]/</span><span class="hljs-number"><span class="koboSpan" id="kobo.492.1">2</span></span><span class="koboSpan" id="kobo.493.1">), </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.494.1">int</span></span><span class="koboSpan" id="kobo.495.1">(min_size[</span><span class="hljs-number"><span class="koboSpan" id="kobo.496.1">1</span></span><span class="koboSpan" id="kobo.497.1">]/</span><span class="hljs-number"><span class="koboSpan" id="kobo.498.1">2</span></span><span class="koboSpan" id="kobo.499.1">)))
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.500.1">for</span></span><span class="koboSpan" id="kobo.501.1"> x, y, w, h </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.502.1">in</span></span><span class="koboSpan" id="kobo.503.1"> smiles:
               </span><span class="hljs-comment"><span class="koboSpan" id="kobo.504.1">#detected smiles shown in color image</span></span><span class="koboSpan" id="kobo.505.1">
               cv.rectangle(image,(x,y),(x+w, y+h),(</span><span class="hljs-number"><span class="koboSpan" id="kobo.506.1">0</span></span><span class="koboSpan" id="kobo.507.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.508.1">0</span></span><span class="koboSpan" id="kobo.509.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.510.1">255</span></span><span class="koboSpan" id="kobo.511.1">),</span><span class="hljs-number"><span class="koboSpan" id="kobo.512.1">3</span></span><span class="koboSpan" id="kobo.513.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.514.1">Finally, we extract the </span><code class="inlineCode"><span class="koboSpan" id="kobo.515.1">profile</span></code><span class="koboSpan" id="kobo.516.1"> and </span><code class="inlineCode"><span class="koboSpan" id="kobo.517.1">face</span></code><span class="koboSpan" id="kobo.518.1"> objects using the specialized Haar cascade algorithms. </span><span class="koboSpan" id="kobo.518.2">If detected, we draw rectangles to mark the bounding boxes of the detected objects:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.519.1">        profiles=self.profile_detector.detect(image_gray,
                       scale_factor=scale_factor,
                       min_neighbors=min_neighbors,
                       min_size=min_size)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.520.1">for</span></span><span class="koboSpan" id="kobo.521.1"> x, y, w, h </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.522.1">in</span></span><span class="koboSpan" id="kobo.523.1"> profiles:
            </span><span class="hljs-comment"><span class="koboSpan" id="kobo.524.1">#detected profiles shown in color image</span></span><span class="koboSpan" id="kobo.525.1">
            cv.rectangle(image,(x,y),(x+w, y+h),(</span><span class="hljs-number"><span class="koboSpan" id="kobo.526.1">255</span></span><span class="koboSpan" id="kobo.527.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.528.1">0</span></span><span class="koboSpan" id="kobo.529.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.530.1">0</span></span><span class="koboSpan" id="kobo.531.1">),</span><span class="hljs-number"><span class="koboSpan" id="kobo.532.1">3</span></span><span class="koboSpan" id="kobo.533.1">)
        faces=self.face_detector.detect(image_gray,
                       scale_factor=scale_factor,
                       min_neighbors=min_neighbors,
                       min_size=min_size)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.534.1">for</span></span><span class="koboSpan" id="kobo.535.1"> x, y, w, h </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.536.1">in</span></span><span class="koboSpan" id="kobo.537.1"> faces:
            </span><span class="hljs-comment"><span class="koboSpan" id="kobo.538.1">#detected faces shown in color image</span></span><span class="koboSpan" id="kobo.539.1">
            cv.rectangle(image,(x,y),(x+w, y+h),(</span><span class="hljs-number"><span class="koboSpan" id="kobo.540.1">0</span></span><span class="koboSpan" id="kobo.541.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.542.1">255</span></span><span class="koboSpan" id="kobo.543.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.544.1">0</span></span><span class="koboSpan" id="kobo.545.1">),</span><span class="hljs-number"><span class="koboSpan" id="kobo.546.1">3</span></span><span class="koboSpan" id="kobo.547.1">)
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.548.1"># image</span></span><span class="koboSpan" id="kobo.549.1">
        fig = plt.figure(figsize=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.550.1">10</span></span><span class="koboSpan" id="kobo.551.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.552.1">10</span></span><span class="koboSpan" id="kobo.553.1">))
        ax = fig.add_subplot(</span><span class="hljs-number"><span class="koboSpan" id="kobo.554.1">111</span></span><span class="koboSpan" id="kobo.555.1">)
        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)
        ax.imshow(image)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.556.1">For each</span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.557.1"> of the four specialized object detectors (the face, face profile, eyes, and smile) we call the detect function and the results (a list of rectangles with the bounding box of the detected object), and then we draw in the context of the initial image either circles (for eyes) or rectangles (for the smile, face, and face profile) around the detected object. </span><span class="koboSpan" id="kobo.557.2">Finally, the function displays the image, with the superposed layers marking the bounding boxes of detected objects. </span><span class="koboSpan" id="kobo.557.3">Because the model for </span><code class="inlineCode"><span class="koboSpan" id="kobo.558.1">smile</span></code><span class="koboSpan" id="kobo.559.1"> gives many false positives, we set an additional parameter, a flag to decide whether we show the extracted bounding boxes with smiles.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.560.1">Next, the class has a function to extract image objects. </span><span class="koboSpan" id="kobo.560.2">The function receives a video path, captures an image from the video, and applies the </span><code class="inlineCode"><span class="koboSpan" id="kobo.561.1">detect_objects</span></code><span class="koboSpan" id="kobo.562.1"> function on the image capture for detection of the face and face details (the eyes, smile, and so on) from that image. </span><span class="koboSpan" id="kobo.562.2">The following code block shows the function for extraction:</span></p>
<pre class="programlisting code"><code class="hljs-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.563.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.564.1">extract_image_objects</span></span><span class="koboSpan" id="kobo.565.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.566.1">self,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.567.1">                              video_file,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.568.1">                              data_folder,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.569.1">                              video_set_folder,</span></span>
<span class="hljs-params"><span class="koboSpan" id="kobo.570.1">                              show_smile=</span></span><span class="hljs-literal"><span class="koboSpan" id="kobo.571.1">False</span></span>
<span class="hljs-params"> </span><span class="koboSpan" id="kobo.572.1">):
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.573.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.574.1">        Extract one image from the video and then perform face/eyes/smile/profile detection on the image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.575.1">        Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.576.1">            video_file: the video from which to extract the image from which we extract the face</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.577.1">            data_folder: folder with the data</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.578.1">            video_set_folder: folder with the video set</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.579.1">            show_smile: show smile (False by default)</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.580.1">        Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.581.1">            None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.582.1">        '''</span></span><span class="koboSpan" id="kobo.583.1">
        video_path = os.path.join(data_folder, video_set_folder,video_file)
        capture_image = cv.VideoCapture(video_path)
        ret, frame = capture_image.read()
        </span><span class="hljs-comment"><span class="koboSpan" id="kobo.584.1">#frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)</span></span><span class="koboSpan" id="kobo.585.1">
        self.detect_objects(image=frame,
                scale_factor=</span><span class="hljs-number"><span class="koboSpan" id="kobo.586.1">1.3</span></span><span class="koboSpan" id="kobo.587.1">,
                min_neighbors=</span><span class="hljs-number"><span class="koboSpan" id="kobo.588.1">5</span></span><span class="koboSpan" id="kobo.589.1">,
                min_size=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.590.1">50</span></span><span class="koboSpan" id="kobo.591.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.592.1">50</span></span><span class="koboSpan" id="kobo.593.1">),
                show_smile=show_smile) 
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.594.1">We</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.595.1"> introduced a module for </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.596.1">face detection using Haar cascade algorithms. </span><span class="koboSpan" id="kobo.596.2">Next, we will review an alternative approach, where we use the </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.597.1">MTCNN</span></strong><span class="koboSpan" id="kobo.598.1"> model for face detection. </span><span class="koboSpan" id="kobo.598.2">We want to test multiple approaches to decide which one works better for </span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.599.1">face detection. </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.600.1">MTCNN</span></strong><span class="koboSpan" id="kobo.601.1"> stands for </span><strong class="keyWord"><span class="koboSpan" id="kobo.602.1">Multi-Task Cascaded Convolution Networks</span></strong><span class="koboSpan" id="kobo.603.1"> and is based on a concept developed first in the paper </span><em class="italic"><span class="koboSpan" id="kobo.604.1">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</span></em><span class="koboSpan" id="kobo.605.1"> (see </span><em class="italic"><span class="koboSpan" id="kobo.606.1">Reference 4</span></em><span class="koboSpan" id="kobo.607.1">). </span><span class="koboSpan" id="kobo.607.2">In another article titled </span><em class="italic"><span class="koboSpan" id="kobo.608.1">Face Detection using MTCNN</span></em><span class="koboSpan" id="kobo.609.1">, the authors propose a “cascaded multi-task framework using different features of sub-models” (see </span><em class="italic"><span class="koboSpan" id="kobo.610.1">Reference 5</span></em><span class="koboSpan" id="kobo.611.1">). </span><span class="koboSpan" id="kobo.611.2">The implementation of face element extraction using the MTCNN approach is done in the utility script </span><code class="inlineCode"><span class="koboSpan" id="kobo.612.1">face_detection_mtcnn</span></code><span class="koboSpan" id="kobo.613.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.614.1">In this module, we define the class </span><code class="inlineCode"><span class="koboSpan" id="kobo.615.1">MTCNNFaceDetector</span></code><span class="koboSpan" id="kobo.616.1">. </span><span class="koboSpan" id="kobo.616.2">In the next code block, we show the class definition with the </span><code class="inlineCode"><span class="koboSpan" id="kobo.617.1">init</span></code><span class="koboSpan" id="kobo.618.1"> function:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.619.1">class</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.620.1">MTCNNFaceDetector</span></span><span class="koboSpan" id="kobo.621.1">():
    </span><span class="hljs-string"><span class="koboSpan" id="kobo.622.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.623.1">    Class for MTCNN Face Detection</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.624.1">    Detects the face and the face keypoints: right &amp; left eye,</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.625.1">    nose, right and left lips limits</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.626.1">    Visualize a image capture from a video and marks the</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.627.1">    face boundingbox and the features</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.628.1">    On top of the face boundingbox shows the confidence score</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.629.1">    '''</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.630.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.631.1">__init__</span></span><span class="koboSpan" id="kobo.632.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.633.1">self, mtcnn_model</span></span><span class="koboSpan" id="kobo.634.1">):
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.635.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.636.1">        Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.637.1">            mtcnn_model: mtcnn model instantiated already</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.638.1">        Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.639.1">            None</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.640.1">        '''</span></span><span class="koboSpan" id="kobo.641.1">
        self.detector = mtcnn_model
        self.color_face = (</span><span class="hljs-number"><span class="koboSpan" id="kobo.642.1">255</span></span><span class="koboSpan" id="kobo.643.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.644.1">0</span></span><span class="koboSpan" id="kobo.645.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.646.1">0</span></span><span class="koboSpan" id="kobo.647.1">)
        self.color_keypoints = (</span><span class="hljs-number"><span class="koboSpan" id="kobo.648.1">0</span></span><span class="koboSpan" id="kobo.649.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.650.1">255</span></span><span class="koboSpan" id="kobo.651.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.652.1">0</span></span><span class="koboSpan" id="kobo.653.1">)
        self.font = cv.FONT_HERSHEY_SIMPLEX
        self.color_font = (</span><span class="hljs-number"><span class="koboSpan" id="kobo.654.1">255</span></span><span class="koboSpan" id="kobo.655.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.656.1">0</span></span><span class="koboSpan" id="kobo.657.1">,</span><span class="hljs-number"><span class="koboSpan" id="kobo.658.1">255</span></span><span class="koboSpan" id="kobo.659.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.660.1">The </span><code class="inlineCode"><span class="koboSpan" id="kobo.661.1">init</span></code><span class="koboSpan" id="kobo.662.1"> function </span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.663.1">receives, as a parameter, an instance of the MTCNN model, imported and instantiated in the calling application from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.664.1">mtcnn</span></code><span class="koboSpan" id="kobo.665.1"> library. </span><span class="koboSpan" id="kobo.665.2">The class member variable detector is initialized with this object. </span><span class="koboSpan" id="kobo.665.3">The rest of the class variables are used for visualization of the detected objects.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.666.1">The</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.667.1"> class also has a </span><code class="inlineCode"><span class="koboSpan" id="kobo.668.1">detect</span></code><span class="koboSpan" id="kobo.669.1"> function. </span><span class="koboSpan" id="kobo.669.2">The next code block shows the </span><code class="inlineCode"><span class="koboSpan" id="kobo.670.1">detect</span></code><span class="koboSpan" id="kobo.671.1"> function implementation:</span></p>
<pre class="programlisting code"><code class="hljs-code"> <span class="hljs-keyword"><span class="koboSpan" id="kobo.672.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.673.1">detect</span></span><span class="koboSpan" id="kobo.674.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.675.1">self, video_path</span></span><span class="koboSpan" id="kobo.676.1">):
        </span><span class="hljs-string"><span class="koboSpan" id="kobo.677.1">'''</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.678.1">        Function plot image</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.679.1">        Args:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.680.1">            video_path: path to the video from which to capture</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.681.1">            image and then apply detector</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.682.1">        Returns:</span></span>
<span class="hljs-string"><span class="koboSpan" id="kobo.683.1">            rectangle with detected object</span></span>
<span class="hljs-string"> </span>
<span class="hljs-string"><span class="koboSpan" id="kobo.684.1">        '''</span></span><span class="koboSpan" id="kobo.685.1">
        capture_image = cv.VideoCapture(video_path)
        ret, frame = capture_image.read()
        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)
   
        results = self.detector.detect_faces(image)
        </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.686.1">if</span></span><span class="koboSpan" id="kobo.687.1"> results:
            </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.688.1">for</span></span><span class="koboSpan" id="kobo.689.1"> result </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.690.1">in</span></span><span class="koboSpan" id="kobo.691.1"> results:
                </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.692.1">print</span></span><span class="koboSpan" id="kobo.693.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.694.1">f"Extracted features: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.695.1">{result}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.696.1">"</span></span><span class="koboSpan" id="kobo.697.1">)
                x, y, w, h = bounding_box = result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.698.1">'box'</span></span><span class="koboSpan" id="kobo.699.1">]
                keypoints = result[</span><span class="hljs-string"><span class="koboSpan" id="kobo.700.1">'keypoints'</span></span><span class="koboSpan" id="kobo.701.1">]
                confidence = </span><span class="hljs-string"><span class="koboSpan" id="kobo.702.1">f"</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.703.1">{</span></span><span class="hljs-built_in"><span class="koboSpan" id="kobo.704.1">round</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.705.1">(result[</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.706.1">'confidence'</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.707.1">], </span></span><span class="hljs-number"><span class="koboSpan" id="kobo.708.1">4</span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.709.1">)}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.710.1">"</span></span><span class="koboSpan" id="kobo.711.1">
                cv.rectangle(image, (x, y),(x+w,y+h), self.color_face, </span><span class="hljs-number"><span class="koboSpan" id="kobo.712.1">3</span></span><span class="koboSpan" id="kobo.713.1">)
                </span><span class="hljs-comment"><span class="koboSpan" id="kobo.714.1"># add all the internal features</span></span>
<span class="hljs-keyword"><span class="koboSpan" id="kobo.715.1">for</span></span><span class="koboSpan" id="kobo.716.1"> key </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.717.1">in</span></span><span class="koboSpan" id="kobo.718.1"> keypoints:
                    xk, yk = keypoints[key]
                    cv.rectangle(image, (xk-</span><span class="hljs-number"><span class="koboSpan" id="kobo.719.1">2</span></span><span class="koboSpan" id="kobo.720.1">, yk-</span><span class="hljs-number"><span class="koboSpan" id="kobo.721.1">2</span></span><span class="koboSpan" id="kobo.722.1">), (xk+</span><span class="hljs-number"><span class="koboSpan" id="kobo.723.1">2</span></span><span class="koboSpan" id="kobo.724.1">, yk+</span><span class="hljs-number"><span class="koboSpan" id="kobo.725.1">2</span></span><span class="koboSpan" id="kobo.726.1">), self.color_keypoints, </span><span class="hljs-number"><span class="koboSpan" id="kobo.727.1">3</span></span><span class="koboSpan" id="kobo.728.1">)
                image = cv.putText(image, confidence, (x, y-</span><span class="hljs-number"><span class="koboSpan" id="kobo.729.1">2</span></span><span class="koboSpan" id="kobo.730.1">),
                                   self.font, </span><span class="hljs-number"><span class="koboSpan" id="kobo.731.1">1</span></span><span class="koboSpan" id="kobo.732.1">,
                                   self.color_font, </span><span class="hljs-number"><span class="koboSpan" id="kobo.733.1">2</span></span><span class="koboSpan" id="kobo.734.1">,
                                   cv.LINE_AA)
        fig = plt.figure(figsize=(</span><span class="hljs-number"><span class="koboSpan" id="kobo.735.1">15</span></span><span class="koboSpan" id="kobo.736.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.737.1">15</span></span><span class="koboSpan" id="kobo.738.1">))
        ax = fig.add_subplot(</span><span class="hljs-number"><span class="koboSpan" id="kobo.739.1">111</span></span><span class="koboSpan" id="kobo.740.1">)
        ax.imshow(image)
        plt.show()
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.741.1">The function </span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.742.1">receives, as a parameter, the path to the video file. </span><span class="koboSpan" id="kobo.742.2">After capturing an image from the video file, we read it and transform it from the BGR format to the RGB format. </span><span class="koboSpan" id="kobo.742.3">The </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.743.1">transformation is needed because we want to use library functions that expect the RGB color order. </span><span class="koboSpan" id="kobo.743.2">After we apply the </span><code class="inlineCode"><span class="koboSpan" id="kobo.744.1">detect_faces</span></code><span class="koboSpan" id="kobo.745.1"> function of the MTCNN model to the transformed image, the detector returns a list of extracted JSONs. </span><span class="koboSpan" id="kobo.745.2">Each extraction JSON has the following format:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-punctuation"><span class="koboSpan" id="kobo.746.1">{</span></span><span class="koboSpan" id="kobo.747.1">
   'box'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.748.1">:</span></span> <span class="hljs-punctuation"><span class="koboSpan" id="kobo.749.1">[</span></span><span class="hljs-number"><span class="koboSpan" id="kobo.750.1">906</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.751.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.752.1">255</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.753.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.754.1">206</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.755.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.756.1">262</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.757.1">],</span></span><span class="koboSpan" id="kobo.758.1">
   'confidence'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.759.1">:</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.760.1">0.9999821186065674</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.761.1">,</span></span><span class="koboSpan" id="kobo.762.1">
   'keypoints'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.763.1">:</span></span>
<span class="hljs-punctuation"><span class="koboSpan" id="kobo.764.1">{</span></span><span class="koboSpan" id="kobo.765.1">
       'left_eye'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.766.1">:</span></span><span class="koboSpan" id="kobo.767.1"> (</span><span class="hljs-number"><span class="koboSpan" id="kobo.768.1">965</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.769.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.770.1">351</span></span><span class="koboSpan" id="kobo.771.1">)</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.772.1">,</span></span><span class="koboSpan" id="kobo.773.1">
       'right_eye'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.774.1">:</span></span><span class="koboSpan" id="kobo.775.1"> (</span><span class="hljs-number"><span class="koboSpan" id="kobo.776.1">1064</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.777.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.778.1">354</span></span><span class="koboSpan" id="kobo.779.1">)</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.780.1">,</span></span><span class="koboSpan" id="kobo.781.1">
       'nose'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.782.1">:</span></span><span class="koboSpan" id="kobo.783.1"> (</span><span class="hljs-number"><span class="koboSpan" id="kobo.784.1">1009</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.785.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.786.1">392</span></span><span class="koboSpan" id="kobo.787.1">)</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.788.1">,</span></span><span class="koboSpan" id="kobo.789.1">
       'mouth_left'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.790.1">:</span></span><span class="koboSpan" id="kobo.791.1"> (</span><span class="hljs-number"><span class="koboSpan" id="kobo.792.1">966</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.793.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.794.1">453</span></span><span class="koboSpan" id="kobo.795.1">)</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.796.1">,</span></span><span class="koboSpan" id="kobo.797.1">
       'mouth_right'</span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.798.1">:</span></span><span class="koboSpan" id="kobo.799.1"> (</span><span class="hljs-number"><span class="koboSpan" id="kobo.800.1">1052</span></span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.801.1">,</span></span> <span class="hljs-number"><span class="koboSpan" id="kobo.802.1">457</span></span><span class="koboSpan" id="kobo.803.1">)
     </span><span class="hljs-punctuation"><span class="koboSpan" id="kobo.804.1">}</span></span>
<span class="hljs-punctuation"><span class="koboSpan" id="kobo.805.1">}</span></span>
</code></pre>
<p class="normal"><span class="koboSpan" id="kobo.806.1">In the </span><code class="inlineCode"><span class="koboSpan" id="kobo.807.1">'box'</span></code><span class="koboSpan" id="kobo.808.1"> field is the bounding box of the detected face area. </span><span class="koboSpan" id="kobo.808.2">In the </span><code class="inlineCode"><span class="koboSpan" id="kobo.809.1">'</span></code><code class="inlineCode"><span class="koboSpan" id="kobo.810.1">keypoints'</span></code><span class="koboSpan" id="kobo.811.1"> field are the keys and coordinates of the five objects detected: the left eye, right eye, nose, left-most mouth limit, and right-most mouth limit. </span><span class="koboSpan" id="kobo.811.2">There is an additional field, </span><code class="inlineCode"><span class="koboSpan" id="kobo.812.1">'confidence'</span></code><span class="koboSpan" id="kobo.813.1">, which gives the confidence factor of the model.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.814.1">For real faces, the </span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.815.1">confidence factor is above 0.99 (the maximum is 1). </span><span class="koboSpan" id="kobo.815.2">If the model detected an artifact, or things like a poster with a face image, this factor could be as large as 0.9. </span><span class="koboSpan" id="kobo.815.3">Confidence factors under 0.9 are most likely associated with artifact detection (or false positives).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.816.1">In our </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.817.1">implementation (see the preceding code), we parse the list of detection JSONs and add a rectangle for each face, and a point (or a very small rectangle) for each of the five face features. </span><span class="koboSpan" id="kobo.817.2">On the top of the face bounding box rectangle, we write the confidence factor (rounded to four decimals).</span></p>
<p class="normal"><span class="koboSpan" id="kobo.818.1">Besides the utility scripts for image capture from video and playing videos, and for object detection from video data, we will also reuse the utility scripts for data quality and plotting that we started using in </span><em class="italic"><span class="koboSpan" id="kobo.819.1">Chapter 4</span></em><span class="koboSpan" id="kobo.820.1">.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.821.1">In the next section, we start with a few preparatory activities and continue with a metadata exploration of the competition data. </span><span class="koboSpan" id="kobo.821.2">We will cover, in this section, importing the libraries, a few checks of the data files, as well as a statistical analysis of the metadata files.</span></p>
<h1 class="heading-1" id="_idParaDest-131"><span class="koboSpan" id="kobo.822.1">Metadata exploration</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.823.1">We </span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.824.1">start by importing the utility functions and classes from the utility scripts for data quality, plot utils, video utils, and face object detection. </span><span class="koboSpan" id="kobo.824.2">The following code block shows what we import from the utility scripts:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword"><span class="koboSpan" id="kobo.825.1">from</span></span><span class="koboSpan" id="kobo.826.1"> data_quality_stats </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.827.1">import</span></span><span class="koboSpan" id="kobo.828.1"> missing_data, unique_values, most_frequent_values
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.829.1">from</span></span><span class="koboSpan" id="kobo.830.1"> plot_style_utils </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.831.1">import</span></span><span class="koboSpan" id="kobo.832.1"> set_color_map, plot_count
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.833.1">from</span></span><span class="koboSpan" id="kobo.834.1"> video_utils </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.835.1">import</span></span><span class="koboSpan" id="kobo.836.1"> display_image_from_video, display_images_from_video_list, play_video
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.837.1">from</span></span><span class="koboSpan" id="kobo.838.1"> face_object_detection </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.839.1">import</span></span><span class="koboSpan" id="kobo.840.1"> CascadeObjectDetector, FaceObjectDetector
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.841.1">from</span></span><span class="koboSpan" id="kobo.842.1"> face_detection_mtcnn </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.843.1">import</span></span><span class="koboSpan" id="kobo.844.1"> MTCNNFaceDetector
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.845.1">After we load the data files (the train and test samples), we are ready to start our analysis. </span><span class="koboSpan" id="kobo.845.2">The following code block checks the types of files in </span><code class="inlineCode"><span class="koboSpan" id="kobo.846.1">TRAIN_SAMPLE_FOLDER</span></code><span class="koboSpan" id="kobo.847.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.848.1">train_list = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.849.1">list</span></span><span class="koboSpan" id="kobo.850.1">(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))
ext_dict = []
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.851.1">for</span></span><span class="koboSpan" id="kobo.852.1"> file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.853.1">in</span></span><span class="koboSpan" id="kobo.854.1"> train_list:
    file_ext = file.split(</span><span class="hljs-string"><span class="koboSpan" id="kobo.855.1">'.'</span></span><span class="koboSpan" id="kobo.856.1">)[</span><span class="hljs-number"><span class="koboSpan" id="kobo.857.1">1</span></span><span class="koboSpan" id="kobo.858.1">]
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.859.1">if</span></span><span class="koboSpan" id="kobo.860.1"> (file_ext </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.861.1">not</span></span> <span class="hljs-keyword"><span class="koboSpan" id="kobo.862.1">in</span></span><span class="koboSpan" id="kobo.863.1"> ext_dict):
        ext_dict.append(file_ext)
</span><span class="hljs-built_in"><span class="koboSpan" id="kobo.864.1">print</span></span><span class="koboSpan" id="kobo.865.1">(</span><span class="hljs-string"><span class="koboSpan" id="kobo.866.1">f"Extensions: </span></span><span class="hljs-subst"><span class="koboSpan" id="kobo.867.1">{ext_dict}</span></span><span class="hljs-string"><span class="koboSpan" id="kobo.868.1">"</span></span><span class="koboSpan" id="kobo.869.1">)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.870.1">The result </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.871.1">shows that there are two types of files, JSON files and MP4 files. </span><span class="koboSpan" id="kobo.871.2">The following code checks the content of the JSON file present in </span><code class="inlineCode"><span class="koboSpan" id="kobo.872.1">TRAIN_SAMPLE_FOLDER</span></code><span class="koboSpan" id="kobo.873.1">. </span><span class="koboSpan" id="kobo.873.2">It samples the first five records for files in </span><code class="inlineCode"><span class="koboSpan" id="kobo.874.1">TRAIN_SAMPLE_FOLDER</span></code><span class="koboSpan" id="kobo.875.1">, as included in the JSON file:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.876.1">json_file = [file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.877.1">for</span></span><span class="koboSpan" id="kobo.878.1"> file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.879.1">in</span></span><span class="koboSpan" id="kobo.880.1"> train_list </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.881.1">if</span></span><span class="koboSpan" id="kobo.882.1">  file.endswith(</span><span class="hljs-string"><span class="koboSpan" id="kobo.883.1">'json'</span></span><span class="koboSpan" id="kobo.884.1">)][</span><span class="hljs-number"><span class="koboSpan" id="kobo.885.1">0</span></span><span class="koboSpan" id="kobo.886.1">]
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.887.1">def</span></span> <span class="hljs-title"><span class="koboSpan" id="kobo.888.1">get_meta_from_json</span></span><span class="koboSpan" id="kobo.889.1">(</span><span class="hljs-params"><span class="koboSpan" id="kobo.890.1">path</span></span><span class="koboSpan" id="kobo.891.1">):
    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))
    df = df.T
    </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.892.1">return</span></span><span class="koboSpan" id="kobo.893.1"> df
meta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)
meta_train_df.head()
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.894.1">In </span><em class="italic"><span class="koboSpan" id="kobo.895.1">Figure 9.1,</span></em><span class="koboSpan" id="kobo.896.1"> we show the data sample obtained when we created the DataFrame </span><code class="inlineCode"><span class="koboSpan" id="kobo.897.1">meta_train_df</span></code><span class="koboSpan" id="kobo.898.1"> from the JSON file. </span><span class="koboSpan" id="kobo.898.2">The index is the name of the file. </span><strong class="screenText"><span class="koboSpan" id="kobo.899.1">label</span></strong><span class="koboSpan" id="kobo.900.1"> is either </span><strong class="screenText"><span class="koboSpan" id="kobo.901.1">FAKE</span></strong><span class="koboSpan" id="kobo.902.1"> (for deepfake videos) or </span><strong class="screenText"><span class="koboSpan" id="kobo.903.1">REAL</span></strong><span class="koboSpan" id="kobo.904.1"> (for real videos). </span><span class="koboSpan" id="kobo.904.2">The </span><strong class="screenText"><span class="koboSpan" id="kobo.905.1">split</span></strong><span class="koboSpan" id="kobo.906.1"> field gives the set to which the video belongs (</span><code class="inlineCode"><span class="koboSpan" id="kobo.907.1">train</span></code><span class="koboSpan" id="kobo.908.1">). </span><strong class="screenText"><span class="koboSpan" id="kobo.909.1">original</span></strong><span class="koboSpan" id="kobo.910.1"> is the name of the initial video, from which the deepfake was created.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.911.1"><img alt="A screenshot of a computer code  Description automatically generated" src="../Images/B20963_09_01.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.912.1">Figure 9.1: Sample of files in the train sample folder</span></p>
<p class="normal"><span class="koboSpan" id="kobo.913.1">We also check a few stats about the metadata, using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.914.1">missing_data</span></code><span class="koboSpan" id="kobo.915.1">, </span><code class="inlineCode"><span class="koboSpan" id="kobo.916.1">unique_values</span></code><span class="koboSpan" id="kobo.917.1">, and </span><code class="inlineCode"><span class="koboSpan" id="kobo.918.1">most_frequent_values</span></code><span class="koboSpan" id="kobo.919.1"> functions from the utility script </span><code class="inlineCode"><span class="koboSpan" id="kobo.920.1">data_quality_stats</span></code><span class="koboSpan" id="kobo.921.1">. </span><span class="koboSpan" id="kobo.921.2">These functions were introduced in </span><em class="italic"><span class="koboSpan" id="kobo.922.1">Chapter 3</span></em><span class="koboSpan" id="kobo.923.1">.</span></p>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.924.1">Figure 9.2</span></em><span class="koboSpan" id="kobo.925.1"> shows</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.926.1"> the missing values from </span><code class="inlineCode"><span class="koboSpan" id="kobo.927.1">meta_train_df</span></code><span class="koboSpan" id="kobo.928.1">. </span><span class="koboSpan" id="kobo.928.2">As you can see, </span><strong class="screenText"><span class="koboSpan" id="kobo.929.1">19.25</span></strong><span class="koboSpan" id="kobo.930.1">% of the original fields are missing.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.931.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B20963_09_02.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.932.1">Figure 9.2: Missing values in the sample train data</span></p>
<p class="normal"><span class="koboSpan" id="kobo.933.1">In </span><em class="italic"><span class="koboSpan" id="kobo.934.1">Figure 9.3</span></em><span class="koboSpan" id="kobo.935.1">, we show the unique values from </span><strong class="screenText"><span class="koboSpan" id="kobo.936.1">meta_train_df</span></strong><span class="koboSpan" id="kobo.937.1">. </span><span class="koboSpan" id="kobo.937.2">There are </span><strong class="screenText"><span class="koboSpan" id="kobo.938.1">323</span></strong><span class="koboSpan" id="kobo.939.1"> original values with </span><strong class="screenText"><span class="koboSpan" id="kobo.940.1">209</span></strong><span class="koboSpan" id="kobo.941.1"> unique ones. </span><span class="koboSpan" id="kobo.941.2">The other two fields, </span><strong class="screenText"><span class="koboSpan" id="kobo.942.1">label</span></strong><span class="koboSpan" id="kobo.943.1"> and </span><strong class="screenText"><span class="koboSpan" id="kobo.944.1">split</span></strong><span class="koboSpan" id="kobo.945.1">, have 400 values, with </span><strong class="screenText"><span class="koboSpan" id="kobo.946.1">2</span></strong><span class="koboSpan" id="kobo.947.1"> unique values for </span><strong class="screenText"><span class="koboSpan" id="kobo.948.1">label</span></strong><span class="koboSpan" id="kobo.949.1"> (FAKE and REAL) and </span><strong class="screenText"><span class="koboSpan" id="kobo.950.1">1</span></strong><span class="koboSpan" id="kobo.951.1"> for </span><strong class="screenText"><span class="koboSpan" id="kobo.952.1">split</span></strong><span class="koboSpan" id="kobo.953.1"> (train).</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.954.1"><img alt="A screenshot of a computer  Description automatically generated" src="../Images/B20963_09_03.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.955.1">Figure 9.3: Unique values in sample train data</span></p>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.956.1">Figure 9.4</span></em><span class="koboSpan" id="kobo.957.1"> displays the most frequent values from </span><strong class="screenText"><span class="koboSpan" id="kobo.958.1">meta_train_df</span></strong><span class="koboSpan" id="kobo.959.1">. </span><span class="koboSpan" id="kobo.959.2">From the total of </span><strong class="screenText"><span class="koboSpan" id="kobo.960.1">400</span></strong><span class="koboSpan" id="kobo.961.1"> labels, </span><strong class="screenText"><span class="koboSpan" id="kobo.962.1">323</span></strong><span class="koboSpan" id="kobo.963.1"> or </span><strong class="screenText"><span class="koboSpan" id="kobo.964.1">80.75</span></strong><span class="koboSpan" id="kobo.965.1">% are FAKE. </span><span class="koboSpan" id="kobo.965.2">The most frequent </span><strong class="screenText"><span class="koboSpan" id="kobo.966.1">original</span></strong><span class="koboSpan" id="kobo.967.1"> value is </span><strong class="screenText"><span class="koboSpan" id="kobo.968.1">atvmxvwyns.mp4</span></strong><span class="koboSpan" id="kobo.969.1">, with a frequency of </span><strong class="screenText"><span class="koboSpan" id="kobo.970.1">6</span></strong><span class="koboSpan" id="kobo.971.1"> (that is, it was used in 6 FAKE videos). </span><span class="koboSpan" id="kobo.971.2">All the values in the </span><strong class="screenText"><span class="koboSpan" id="kobo.972.1">split</span></strong><span class="koboSpan" id="kobo.973.1"> column are </span><strong class="screenText"><span class="koboSpan" id="kobo.974.1">train</span></strong><span class="koboSpan" id="kobo.975.1">.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.976.1"><img alt="A screenshot of a white grid with black text  Description automatically generated" src="../Images/B20963_09_04.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.977.1">Figure 9.4: Most frequent values in the sample train data</span></p>
<p class="normal"><span class="koboSpan" id="kobo.978.1">In this analysis, we </span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.979.1">will use a custom color schema, with tones of blues and grays. </span><span class="koboSpan" id="kobo.979.2">The following code block shows the code for the generation of the custom color map:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.980.1">color_list = [</span><span class="hljs-string"><span class="koboSpan" id="kobo.981.1">'#4166AA'</span></span><span class="koboSpan" id="kobo.982.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.983.1">'#06BDDD'</span></span><span class="koboSpan" id="kobo.984.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.985.1">'#83CEEC'</span></span><span class="koboSpan" id="kobo.986.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.987.1">'#EDE8E4'</span></span><span class="koboSpan" id="kobo.988.1">, </span><span class="hljs-string"><span class="koboSpan" id="kobo.989.1">'#C2AFA8'</span></span><span class="koboSpan" id="kobo.990.1">]
cmap_custom = set_color_map(color_list)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.991.1">In </span><em class="italic"><span class="koboSpan" id="kobo.992.1">Figure 9.5</span></em><span class="koboSpan" id="kobo.993.1">, we show the color map.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.994.1"><img alt="A blue and white rectangular object  Description automatically generated" src="../Images/B20963_09_05.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.995.1">Figure 9.5: Most frequent values in the sample train data</span></p>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.996.1">Figure 9.6</span></em><span class="koboSpan" id="kobo.997.1"> shows the </span><strong class="screenText"><span class="koboSpan" id="kobo.998.1">label</span></strong><span class="koboSpan" id="kobo.999.1"> distribution in the sample train dataset. </span><span class="koboSpan" id="kobo.999.2">There are 323 records with the </span><strong class="screenText"><span class="koboSpan" id="kobo.1000.1">FAKE</span></strong><span class="koboSpan" id="kobo.1001.1"> label, and the rest of the labels have a </span><strong class="screenText"><span class="koboSpan" id="kobo.1002.1">REAL</span></strong><span class="koboSpan" id="kobo.1003.1"> value.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1004.1"><img alt="A graph with blue and green bars  Description automatically generated" src="../Images/B20963_09_06.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1005.1">Figure 9.6: Most frequent values in the sample train data</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1006.1">In the next section, we </span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.1007.1">will start analyzing the video data.</span></p>
<h1 class="heading-1" id="_idParaDest-132"><span class="koboSpan" id="kobo.1008.1">Video data exploration</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1009.1">In this section, we </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.1010.1">will visualize a few samples of files, and then we will begin performing object detection to try to capture the features from the images that might have some anomalies when processed to create deepfakes. </span><span class="koboSpan" id="kobo.1010.2">These are mostly the eyes, mouths, and figures.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1011.1">We will start by visualizing sample files, both genuine images and deepfakes. </span><span class="koboSpan" id="kobo.1011.2">We will then apply the first algorithm introduced previously for face, eye, and mouth detection, the one based on Haar cascade. </span><span class="koboSpan" id="kobo.1011.3">We then follow with the alternative algorithm, based on MTCNN.</span></p>
<h2 class="heading-2" id="_idParaDest-133"><span class="koboSpan" id="kobo.1012.1">Visualizing sample files</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1013.1">The</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.1014.1"> following code block selects a few video files from the set of fake videos and then visualizes an image capture from them, using the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1015.1">display_image_from_video</span></code><span class="koboSpan" id="kobo.1016.1"> function from the utility script </span><code class="inlineCode"><span class="koboSpan" id="kobo.1017.1">video_utils</span></code><span class="koboSpan" id="kobo.1018.1">:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1019.1">fake_train_sample_video = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1020.1">list</span></span><span class="koboSpan" id="kobo.1021.1">(meta_train_df.loc[meta_train_df.label==</span><span class="hljs-string"><span class="koboSpan" id="kobo.1022.1">'FAKE'</span></span><span class="koboSpan" id="kobo.1023.1">].sample(</span><span class="hljs-number"><span class="koboSpan" id="kobo.1024.1">3</span></span><span class="koboSpan" id="kobo.1025.1">).index)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1026.1">for</span></span><span class="koboSpan" id="kobo.1027.1"> video_file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1028.1">in</span></span><span class="koboSpan" id="kobo.1029.1"> fake_train_sample_video:
    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.1030.1">The preceding </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.1031.1">code will plot one image capture per each of the three videos. </span><span class="koboSpan" id="kobo.1031.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1032.1">Figure 9.7</span></em><span class="koboSpan" id="kobo.1033.1">, we only show one of these image captures, for the first video:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1034.1"><img alt="A person and person standing in front of a fireplace  Description automatically generated" src="../Images/B20963_09_07.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1035.1">Figure 9.7: Example of an image capture from a fake video</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1036.1">The next code block selects a sample of three real videos and then, for each selected video, creates and plots an image capture:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1037.1">real_train_sample_video = </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1038.1">list</span></span><span class="koboSpan" id="kobo.1039.1">(meta_train_df.loc[meta_train_df.label==</span><span class="hljs-string"><span class="koboSpan" id="kobo.1040.1">'REAL'</span></span><span class="koboSpan" id="kobo.1041.1">].sample(</span><span class="hljs-number"><span class="koboSpan" id="kobo.1042.1">3</span></span><span class="koboSpan" id="kobo.1043.1">).index)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1044.1">for</span></span><span class="koboSpan" id="kobo.1045.1"> video_file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1046.1">in</span></span><span class="koboSpan" id="kobo.1047.1"> real_train_sample_video:
    display_image_from_video(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, video_file))
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.1048.1">In </span><em class="italic"><span class="koboSpan" id="kobo.1049.1">Figure 9.8</span></em><span class="koboSpan" id="kobo.1050.1">, we show one of the images captured from the first real video:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1051.1"><img alt="A person standing in a corner  Description automatically generated" src="../Images/B20963_09_08.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1052.1">Figure 9.8: Example of an image capture from a real video</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1053.1">We </span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.1054.1">would also like to inspect videos that are all derived from the same original video. </span><span class="koboSpan" id="kobo.1054.2">We will pick six videos from the same original video and show one image capture from each video. </span><span class="koboSpan" id="kobo.1054.3">The following code block performs this operation:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1055.1">same_original_fake_train_sample_video = \
        </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1056.1">list</span></span><span class="koboSpan" id="kobo.1057.1">(meta_train_df.loc[meta_train_df.original==</span><span class="hljs-string"><span class="koboSpan" id="kobo.1058.1">'meawmsgiti.mp4'</span></span><span class="koboSpan" id="kobo.1059.1">].index)
display_images_from_video_list(video_path_list=same_original_fake_train_sample_video,
                               data_folder=DATA_FOLDER,
                               video_folder=TRAIN_SAMPLE_FOLDER)
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.1060.1">In </span><em class="italic"><span class="koboSpan" id="kobo.1061.1">Figure 9.9</span></em><span class="koboSpan" id="kobo.1062.1">, we show two of these image captures from several different videos, of which we used the same original file to deepfake.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1063.1"><img alt="A person in a yellow shirt  Description automatically generated" src="../Images/B20963_09_09.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1064.1">Figure 9.9: Image captures from faked videos modified from the same original file</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1065.1">We </span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.1066.1">performed similar checks with videos from the test set. </span><span class="koboSpan" id="kobo.1066.2">Of course, in the case of the test set, we will not be able to know in advance which video is real or not. </span><span class="koboSpan" id="kobo.1066.3">The following code selects image captures from two sample </span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.1067.1">videos from the data:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1068.1">display_images_from_video_list(test_videos.sample(</span><span class="hljs-number"><span class="koboSpan" id="kobo.1069.1">2</span></span><span class="koboSpan" id="kobo.1070.1">).video, DATA_FOLDER, TEST_FOLDER)
</span></code></pre>
<p class="normal"><em class="italic"><span class="koboSpan" id="kobo.1071.1">Figure 9.10</span></em><span class="koboSpan" id="kobo.1072.1"> displays these selected images:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1073.1"><img alt="A person sitting in a chair  Description automatically generated" src="../Images/B20963_09_10.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1074.1">Figure 9.10: Image captures from faked videos modified from the same original file</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1075.1">Let’s now start </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.1076.1">to use the algorithms for face detection introduced in the </span><strong class="keyWord"><span class="koboSpan" id="kobo.1077.1">Face and body detection</span></strong> <strong class="keyWord"><span class="koboSpan" id="kobo.1078.1">utils</span></strong><span class="koboSpan" id="kobo.1079.1"> section.</span></p>
<h2 class="heading-2" id="_idParaDest-134"><span class="koboSpan" id="kobo.1080.1">Performing object detection</span></h2>
<p class="normal"><span class="koboSpan" id="kobo.1081.1">First, let’s </span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.1082.1">use the </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.1083.1">Haar cascade</span></strong><span class="koboSpan" id="kobo.1084.1"> algorithms from the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1085.1">face_object_detection</span></code><span class="koboSpan" id="kobo.1086.1"> module. </span><span class="koboSpan" id="kobo.1086.2">We use the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1087.1">FaceObjectDetector</span></code><span class="koboSpan" id="kobo.1088.1"> object to extract the face, profile face, eyes, and smile. </span><span class="koboSpan" id="kobo.1088.2">The class </span><code class="inlineCode"><span class="koboSpan" id="kobo.1089.1">CascadeObjectDetector</span></code><strong class="bold-italic" style="font-style: italic;"> </strong><span class="koboSpan" id="kobo.1090.1">initializes the specialized cascade classifiers for the aforementioned people attributes (using the specialized imported resource). </span><span class="koboSpan" id="kobo.1090.2">The function </span><code class="inlineCode"><span class="koboSpan" id="kobo.1091.1">detect</span></code><span class="koboSpan" id="kobo.1092.1"> uses a method of the </span><code class="inlineCode"><span class="koboSpan" id="kobo.1093.1">CascadeClassifier</span></code><span class="koboSpan" id="kobo.1094.1"> from OpenCV to detect objects in images. </span><span class="koboSpan" id="kobo.1094.2">For each attribute, we will use a different shape and color to mark/highlight the extracted object, as follows:</span></p>
<ul>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1095.1">Frontal face</span></strong><span class="koboSpan" id="kobo.1096.1">: Green rectangle</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1097.1">Eye</span></strong><span class="koboSpan" id="kobo.1098.1">: Red circle</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1099.1">Smile</span></strong><span class="koboSpan" id="kobo.1100.1">: Red rectangle</span></li>
<li class="bulletList"><strong class="keyWord"><span class="koboSpan" id="kobo.1101.1">Profile face</span></strong><span class="koboSpan" id="kobo.1102.1">: Blue rectangle</span></li>
</ul>
<p class="normal"><span class="koboSpan" id="kobo.1103.1">Note that due to the large amount of false positives, we deactivated the smile detector.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1104.1">We apply the</span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.1105.1"> function for face detection to a selection of images from the train sample videos. </span><span class="koboSpan" id="kobo.1105.2">The following code block performs this operation:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1106.1">same_original_fake_train_sample_video = \
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1107.1">list</span></span><span class="koboSpan" id="kobo.1108.1">(meta_train_df.loc[meta_train_df.original==</span><span class="hljs-string"><span class="koboSpan" id="kobo.1109.1">'kgbkktcjxf.mp4'</span></span><span class="koboSpan" id="kobo.1110.1">].index)
</span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1111.1">for</span></span><span class="koboSpan" id="kobo.1112.1"> video_file </span><span class="hljs-keyword"><span class="koboSpan" id="kobo.1113.1">in</span></span><span class="koboSpan" id="kobo.1114.1"> same_original_fake_train_sample_video[</span><span class="hljs-number"><span class="koboSpan" id="kobo.1115.1">1</span></span><span class="koboSpan" id="kobo.1116.1">:</span><span class="hljs-number"><span class="koboSpan" id="kobo.1117.1">4</span></span><span class="koboSpan" id="kobo.1118.1">]:
    </span><span class="hljs-built_in"><span class="koboSpan" id="kobo.1119.1">print</span></span><span class="koboSpan" id="kobo.1120.1">(video_file)
    face_object_detector.extract_image_objects(video_file=video_file,
                          data_folder=DATA_FOLDER,
                          video_set_folder=TRAIN_SAMPLE_FOLDER,
                          show_smile=</span><span class="hljs-literal"><span class="koboSpan" id="kobo.1121.1">False</span></span><span class="koboSpan" id="kobo.1122.1"> 
                          )
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.1123.1">The preceding code run will yield three image captures for three different videos. </span><span class="koboSpan" id="kobo.1123.2">Each image is decorated with the highlighted objects extracted. </span><span class="koboSpan" id="kobo.1123.3">The following figures</span><em class="italic"> </em><span class="koboSpan" id="kobo.1124.1">show the three image captures with the extracted objects. </span><span class="koboSpan" id="kobo.1124.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1125.1">Figure 9.11a</span></em><span class="koboSpan" id="kobo.1126.1">, we see both the frontal and profile faces detected and one eye detected. </span><em class="italic"><span class="koboSpan" id="kobo.1127.1">Figure 9.11b </span></em><span class="koboSpan" id="kobo.1128.1">shows both the frontal and profile faces detected, and two eyes detected. </span><em class="italic"><span class="koboSpan" id="kobo.1129.1">Figure</span></em> <em class="italic"><span class="koboSpan" id="kobo.1130.1">9.11c</span></em><span class="koboSpan" id="kobo.1131.1"> shows both the frontal and profile faces detected, the two eyes correctly detected, and one false positive (one of the nostrils is detected as an eye). </span><span class="koboSpan" id="kobo.1131.2">The smile detection is not activated in this case (too many false positives).</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1132.1"><img alt="A person in yellow sweater  Description automatically generated" src="../Images/B20963_09_11.a.png"/></span></figure>
<p class="center"><span class="koboSpan" id="kobo.1133.1">a</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.1134.1"><img alt="A person in yellow sweater  Description automatically generated" src="../Images/B20963_09_11.b.png"/></span></p>
<p class="center"><span class="koboSpan" id="kobo.1135.1">b</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1136.1"><img alt="A person in a yellow sweater  Description automatically generated" src="../Images/B20963_09_11.c.png"/></span></figure>
<p class="center"><span class="koboSpan" id="kobo.1137.1">c</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.1138.1">Figure 9.11: Face, face profile, and eye detection in image captures from three different videos</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1139.1">Running </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.1140.1">these algorithms with other images as well, we can see that they are not very robust and frequently yield false positives, as well as incomplete results. </span><span class="koboSpan" id="kobo.1140.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1141.1">Figure 9.12</span></em><span class="koboSpan" id="kobo.1142.1">, we show two examples of such incomplete detections. </span><span class="koboSpan" id="kobo.1142.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1143.1">Figure 9.12a</span></em><span class="koboSpan" id="kobo.1144.1">, only the face was detected. </span><span class="koboSpan" id="kobo.1144.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1145.1">Figure 9.12b</span></em><span class="koboSpan" id="kobo.1146.1">, only one face profile was detected, although two people are present in the scene.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1147.1"><img alt="A person in a black jacket  Description automatically generated" src="../Images/B20963_09_12.a.png"/></span></figure>
<p class="center"><span class="koboSpan" id="kobo.1148.1">a</span></p>
<p class="packt_figref"><em class="italic"><span class="koboSpan" id="kobo.1149.1"><img alt="A person talking to another person  Description automatically generated" src="../Images/B20963_09_12.b.png"/></span></em></p>
<p class="center"><span class="koboSpan" id="kobo.1150.1">b</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.1151.1">Figure 9.12: Face, face profile, and eye detection in image captures from two different videos</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1152.1">In the preceding image, there is also a strange detection; the fire sprinkler in the ceiling is detected as an eye and so is the candle fixture on the far left. </span><span class="koboSpan" id="kobo.1152.2">This type of false detection (false positives) is quite frequent with these filters. </span><span class="koboSpan" id="kobo.1152.3">One common problem is that objects like eyes, noses, or lips are detected in areas where there is no face. </span><span class="koboSpan" id="kobo.1152.4">Since the search is done independently for these different objects, the likelihood of getting such false positives is quite large.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1153.1">With the</span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.1154.1"> alternative solution implemented by us in </span><code class="inlineCode"><span class="koboSpan" id="kobo.1155.1">face_detection_mtcnn</span></code><span class="koboSpan" id="kobo.1156.1">, a unique framework is used to detect simultaneously the face bounding box and the position of face elements like eyes, nose, and lips. </span><span class="koboSpan" id="kobo.1156.2">Let’s compare the results obtained with the Haar cascade algorithm, as shown in </span><em class="italic"><span class="koboSpan" id="kobo.1157.1">Figures 9.11 </span></em><span class="koboSpan" id="kobo.1158.1">and</span><em class="italic"><span class="koboSpan" id="kobo.1159.1"> 9.12</span></em><span class="koboSpan" id="kobo.1160.1">, with the results for the same images obtained with the MTCNN algorithm.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1161.1">In </span><em class="italic"><span class="koboSpan" id="kobo.1162.1">Figure 9.13</span></em><span class="koboSpan" id="kobo.1163.1">, we show one image of the person dressed in yellow; this time, face detection is performed </span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.1164.1">with our </span><strong class="bold-italic" style="font-style: italic;"><span class="koboSpan" id="kobo.1165.1">MTCNNFaceDetector</span></strong><span class="koboSpan" id="kobo.1166.1">:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1167.1"><img alt="A person in a yellow sweater  Description automatically generated" src="../Images/B20963_09_13.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1168.1">Figure 9.13: MTCNN face detection: one genuine face and one artifact detected</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1169.1">Two face objects are detected. </span><span class="koboSpan" id="kobo.1169.2">One is correct, and the second is an artifact. </span><span class="koboSpan" id="kobo.1169.3">The detection JSONs are:</span></p>
<pre class="programlisting code"><code class="hljs-code"><span class="koboSpan" id="kobo.1170.1">Extracted features: {'box': [</span><span class="hljs-number"><span class="koboSpan" id="kobo.1171.1">906</span></span><span class="koboSpan" id="kobo.1172.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1173.1">255</span></span><span class="koboSpan" id="kobo.1174.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1175.1">206</span></span><span class="koboSpan" id="kobo.1176.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1177.1">262</span></span><span class="koboSpan" id="kobo.1178.1">], 'confidence': </span><span class="hljs-number"><span class="koboSpan" id="kobo.1179.1">0.9999821186065674</span></span><span class="koboSpan" id="kobo.1180.1">, 'keypoints': {'left_eye': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1181.1">965</span></span><span class="koboSpan" id="kobo.1182.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1183.1">351</span></span><span class="koboSpan" id="kobo.1184.1">), 'right_eye': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1185.1">1064</span></span><span class="koboSpan" id="kobo.1186.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1187.1">354</span></span><span class="koboSpan" id="kobo.1188.1">), 'nose': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1189.1">1009</span></span><span class="koboSpan" id="kobo.1190.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1191.1">392</span></span><span class="koboSpan" id="kobo.1192.1">), 'mouth_left': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1193.1">966</span></span><span class="koboSpan" id="kobo.1194.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1195.1">453</span></span><span class="koboSpan" id="kobo.1196.1">), 'mouth_right': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1197.1">1052</span></span><span class="koboSpan" id="kobo.1198.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1199.1">457</span></span><span class="koboSpan" id="kobo.1200.1">)}}
Extracted features: {'box': [</span><span class="hljs-number"><span class="koboSpan" id="kobo.1201.1">882</span></span><span class="koboSpan" id="kobo.1202.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1203.1">966</span></span><span class="koboSpan" id="kobo.1204.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1205.1">77</span></span><span class="koboSpan" id="kobo.1206.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1207.1">84</span></span><span class="koboSpan" id="kobo.1208.1">], 'confidence': </span><span class="hljs-number"><span class="koboSpan" id="kobo.1209.1">0.871575653553009</span></span><span class="koboSpan" id="kobo.1210.1">, 'keypoints': {'left_eye': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1211.1">905</span></span><span class="koboSpan" id="kobo.1212.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1213.1">1003</span></span><span class="koboSpan" id="kobo.1214.1">), 'right_eye': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1215.1">926</span></span><span class="koboSpan" id="kobo.1216.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1217.1">985</span></span><span class="koboSpan" id="kobo.1218.1">), 'nose': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1219.1">919</span></span><span class="koboSpan" id="kobo.1220.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1221.1">1002</span></span><span class="koboSpan" id="kobo.1222.1">), 'mouth_left': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1223.1">921</span></span><span class="koboSpan" id="kobo.1224.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1225.1">1024</span></span><span class="koboSpan" id="kobo.1226.1">), 'mouth_right': (</span><span class="hljs-number"><span class="koboSpan" id="kobo.1227.1">942</span></span><span class="koboSpan" id="kobo.1228.1">, </span><span class="hljs-number"><span class="koboSpan" id="kobo.1229.1">1008</span></span><span class="koboSpan" id="kobo.1230.1">)}}
</span></code></pre>
<p class="normal"><span class="koboSpan" id="kobo.1231.1">From the experiments we conducted with a considerable number of samples, we concluded that the real faces will have a confidence factor very close to 1. </span><span class="koboSpan" id="kobo.1231.2">Because the second detected “face” has a confidence of </span><code class="inlineCode"><span class="koboSpan" id="kobo.1232.1">0.87</span></code><span class="koboSpan" id="kobo.1233.1">, we can easily dismiss it. </span><span class="koboSpan" id="kobo.1233.2">Only faces with a confidence factor above </span><code class="inlineCode"><span class="koboSpan" id="kobo.1234.1">0.99</span></code><span class="koboSpan" id="kobo.1235.1"> are actually to be trusted.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1236.1">Let’s see</span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.1237.1"> another example. </span><span class="koboSpan" id="kobo.1237.2">In </span><em class="italic"><span class="koboSpan" id="kobo.1238.1">Figure 9.14</span></em><span class="koboSpan" id="kobo.1239.1">, we compare the results for the same images from </span><em class="italic"><span class="koboSpan" id="kobo.1240.1">Figure 9.12</span></em><span class="koboSpan" id="kobo.1241.1">. </span><span class="koboSpan" id="kobo.1241.2">In both figures, all the faces of the people present in the scene are correctly identified. </span><span class="koboSpan" id="kobo.1241.3">In all the cases, the confidence score is above 0.999. </span><span class="koboSpan" id="kobo.1241.4">No artifacts are incorrectly extracted as human figures. </span><span class="koboSpan" id="kobo.1241.5">The algorithm appears to be more robust than the alternative implementations using Haar cascades.</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1242.1"><img alt="A person in a black jacket  Description automatically generated" src="../Images/B20963_09_14.a.png"/></span></figure>
<p class="center"><span class="koboSpan" id="kobo.1243.1">a</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1244.1"><img alt="A group of women sitting on a couch  Description automatically generated" src="../Images/B20963_09_14.b.png"/></span></figure>
<p class="center"><span class="koboSpan" id="kobo.1245.1">b</span></p>
<p class="packt_figref"><span class="koboSpan" id="kobo.1246.1">Figure 9.14: MTCNN face detection: a scene with one person and a scene with two people</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1247.1">For the next</span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.1248.1"> example, we selected a case where, if there are two people present in the video from which we capture the image, the faces are correctly identified, and the confidence score is high. </span><span class="koboSpan" id="kobo.1248.2">In the same image, an artifact is also identified as a human face:</span></p>
<figure class="mediaobject"><span class="koboSpan" id="kobo.1249.1"><img alt="A person and person standing under a porch  Description automatically generated" src="../Images/B20963_09_15.png"/></span></figure>
<p class="packt_figref"><span class="koboSpan" id="kobo.1250.1">Figure 9.15: MTCNN face detection: a scene with two people</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1251.1">Besides</span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.1252.1"> the two real people, for which the confidence factors are 0.9995 and 0.9999 (rounded to 1), respectively, the face of the </span><em class="italic"><span class="koboSpan" id="kobo.1253.1">Dead Alive</span></em><span class="koboSpan" id="kobo.1254.1"> character on the T-shirt of the first person in the scene is also detected as a face. </span><span class="koboSpan" id="kobo.1254.2">The bounding box is correctly detected, and all the face elements are also detected correctly. </span><span class="koboSpan" id="kobo.1254.3">The only indication that this is a false positive is the lower confidence factor, which in this case is 0.9075. </span><span class="koboSpan" id="kobo.1254.4">Such examples can help us to correctly calibrate our face detection approach. </span><span class="koboSpan" id="kobo.1254.5">Only faces detected with a confidence above 0.95 or even 0.99 should be considered.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1255.1">In the notebook associated with this chapter, </span><em class="italic"><span class="koboSpan" id="kobo.1256.1">Deepfake Exploratory Data Analysis </span></em><span class="koboSpan" id="kobo.1257.1">(</span><a href="https://www.kaggle.com/code/gpreda/deepfake-exploratory-data-analysis"><span class="url"><span class="koboSpan" id="kobo.1258.1">https://www.kaggle.com/code/gpreda/deepfake-exploratory-data-analysis</span></span></a><span class="koboSpan" id="kobo.1259.1">), we provide more examples of face extraction with both the approaches introduced here.</span></p>
<h1 class="heading-1" id="_idParaDest-135"><span class="koboSpan" id="kobo.1260.1">Summary</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1261.1">In this chapter, we began by introducing a series of utility scripts, which are reusable Python modules on Kaggle designed for video data manipulation. </span><span class="koboSpan" id="kobo.1261.2">One such script, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1262.1">video_utils</span></code><span class="koboSpan" id="kobo.1263.1">, is used to visualize images from videos and play them. </span><span class="koboSpan" id="kobo.1263.2">Another script, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1264.1">face_object_detection</span></code><span class="koboSpan" id="kobo.1265.1">, utilizes Haar cascade models for face detection. </span></p>
<p class="normal"><span class="koboSpan" id="kobo.1266.1">The third script, </span><code class="inlineCode"><span class="koboSpan" id="kobo.1267.1">face_detection_mtcnn</span></code><span class="koboSpan" id="kobo.1268.1">, employs MTCNN models to identify faces and key points such as the eyes, nose, and mouth. </span><span class="koboSpan" id="kobo.1268.2">We then examined the metadata and video data from the DFDC competition dataset. </span><span class="koboSpan" id="kobo.1268.3">In this dataset, we applied the aforementioned face detection methods to images from training and test videos, finding the MTCNN model approach to be more robust and accurate, with fewer false positives.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1269.1">As we near the conclusion of our exploration of data, we will reflect on our journey through various data formats, including tabular, text, image, sound, and now video. </span><span class="koboSpan" id="kobo.1269.2">We’ve delved into numerous Kaggle datasets and competition datasets, learning how to conduct exploratory data analysis, create reusable code, establish a visual identity for our notebooks, and weave a narrative with data. </span><span class="koboSpan" id="kobo.1269.3">In some instances, we also introduced feature engineering elements and established a model baseline. </span><span class="koboSpan" id="kobo.1269.4">In one case, we demonstrated the step-by-step refinement of our model to enhance validation metrics. </span><span class="koboSpan" id="kobo.1269.5">The focus of the previous and current chapters has been on crafting high-quality notebooks on Kaggle.</span></p>
<p class="normal"><span class="koboSpan" id="kobo.1270.1">In the upcoming chapter, we will explore the use of large language models from Kaggle, potentially in conjunction with other technologies such as LangChain and vector databases. </span><span class="koboSpan" id="kobo.1270.2">This will demonstrate the vast potential of Generative AI in various applications.</span></p>
<h1 class="heading-1" id="_idParaDest-136"><span class="koboSpan" id="kobo.1271.1">References</span></h1>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1"><span class="koboSpan" id="kobo.1272.1">Deepfake Detection Challenge, Kaggle competition, Identify videos with facial or voice manipulations: </span><a href="https://www.kaggle.com/competitions/deepfake-detection-challenge"><span class="url"><span class="koboSpan" id="kobo.1273.1">https://www.kaggle.com/competitions/deepfake-detection-challenge</span></span></a></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1274.1">Haar Cascades for Face Detection, Kaggle dataset: </span><a href="https://www.kaggle.com/datasets/gpreda/haar-cascades-for-face-detection"><span class="url"><span class="koboSpan" id="kobo.1275.1">https://www.kaggle.com/datasets/gpreda/haar-cascades-for-face-detection</span></span></a></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1276.1">Serkan Peldek – Face Detection with OpenCV, Kaggle notebook: </span><a href="https://www.kaggle.com/code/serkanpeldek/face-detection-with-opencv/"><span class="url"><span class="koboSpan" id="kobo.1277.1">https://www.kaggle.com/code/serkanpeldek/face-detection-with-opencv/</span></span></a></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1278.1">Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao – Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks: </span><a href="https://arxiv.org/abs/1604.02878"><span class="url"><span class="koboSpan" id="kobo.1279.1">https://arxiv.org/abs/1604.02878</span></span></a></li>
<li class="numberedList"><span class="koboSpan" id="kobo.1280.1">Justin Güse – Face Detection using MTCNN — a guide for face extraction with a focus on speed: </span><a href="https://towardsdatascience.com/face-detection-using-mtcnn-a-guide-for-face-extraction-with-a-focus-on-speed-c6d59f82d49"><span class="url"><span class="koboSpan" id="kobo.1281.1">https://towardsdatascience.com/face-detection-using-mtcnn-a-guide-for-face-extraction-with-a-focus-on-speed-c6d59f82d49</span></span></a></li>
</ol>
<h1 class="heading-1"><span class="koboSpan" id="kobo.1282.1">Join our book’s Discord space</span></h1>
<p class="normal"><span class="koboSpan" id="kobo.1283.1">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</span></p>
<p class="normal"><a href="https://packt.link/kaggle"><span class="url"><span class="koboSpan" id="kobo.1284.1">https://packt.link/kaggle</span></span></a></p>
<p class="normal"><span class="koboSpan" id="kobo.1285.1"><img alt="" role="presentation" src="../Images/QR_Code9220780366773140.png"/></span></p>
</div>
</body></html>