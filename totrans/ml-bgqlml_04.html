<html><head></head><body>
		<div id="_idContainer054">
			<h1 id="_idParaDest-52"><em class="italic"><a id="_idTextAnchor052"/>Chapter 3</em>: Introducing BigQuery Syntax</h1>
			<p>The BigQuery dialect is compliant with the standard ANSI 2011 and is quite easy to learn for people who know other dialects and have experience with SQL. The main differences in terms of syntax are represented by BigQuery extensions, which allow us to use advanced features such as <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>). Bringing ML capabilities into SQL allows different roles to access it. This approach has the clear goal of democratizing the use of ML across different functions within a company, generating as much value as possible. With BigQuery ML, Google Cloud is filling the gap between tech-savvy people with ML skills and business analysts who know the company's data very well and have been working on it for years.</p>
			<p>To build your confidence with the BigQuery environment and its dialect, we'll go through the following topics:</p>
			<ul>
				<li>Creating a BigQuery dataset</li>
				<li>Discovering BigQuery SQL</li>
				<li>Diving into BigQuery ML</li>
			</ul>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor053"/>Technical requirements</h1>
			<p>This chapter requires access to a web browser and the following:</p>
			<ul>
				<li>A GCP account to access Google Cloud Console</li>
				<li>A GCP project to host the BigQuery datasets</li>
			</ul>
			<p>Now that we're ready with the technical requirements, let's dive into the creation of a BigQuery dataset.</p>
			<p>Check out the following video to see the Code in Action: <a href="https://bit.ly/3vR8I7f">https://bit.ly/3vR8I7f</a></p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/>Creating a BigQuery dataset</h1>
			<p>Before<a id="_idIndexMarker195"/> jumping into the BigQuery syntax, it is necessary to create a new BigQuery dataset that will employ the data structures created in the next sections. For each hands-on chapter, we'll create a new dataset to segregate each use case and maintain a logical separated structure:</p>
			<ol>
				<li>Access the BigQuery UI by browsing to the GCP Navigation menu from the GCP console and selecting the <strong class="bold">BigQuery</strong> service.</li>
				<li>After selecting the right GCP project in the navigation menu of the BigQuery UI, it is possible to click on the <strong class="bold">Create Dataset</strong> button: <div id="_idContainer049" class="IMG---Figure"><img src="image/B16722_03_001.jpg" alt="Figure 3.1 – Creation of a new BigQuery Dataset&#13;&#10;"/></div><p class="figure-caption">Figure 3.1 – Creation of a new BigQuery Dataset</p></li>
				<li>In the overlay <a id="_idIndexMarker196"/>window that appears on the right of the screen, choose the <strong class="screen-inline">Dataset ID</strong> that you prefer and leave all the other options configured with default values. To host the data structures of this chapter, we suggest using the name <strong class="source-inline">03_bigquery_syntax</strong>. Then, select <strong class="bold">Create dataset</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B16722_03_002.jpg" alt="Figure 3.2 – Create dataset screen&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Create dataset screen</p>
			<p>Now that we've created our first BigQuery dataset, let's take an overview of the main characteristics of the <a id="_idIndexMarker197"/>BigQuery SQL syntax.</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/>Discovering BigQuery SQL</h1>
			<p>BigQuery <a id="_idIndexMarker198"/>supports two different SQL dialects: <strong class="bold">standard SQL</strong> and <strong class="bold">legacy SQL</strong>. In this book, we'll use Standard SQL, but it could be useful to know what Legacy SQL is and <a id="_idIndexMarker199"/>how to enable it if you want to test queries coming from legacy applications.</p>
			<p>As we have already<a id="_idIndexMarker200"/> mentioned, BigQuery was developed as an internal product within Google and was initially realized to process log records. The query engine Dremel was able to support a limited set of SQL operations that are now defined as Legacy SQL.</p>
			<p>In the following screenshot, you can see how to change the <strong class="bold">SQL dialect</strong>:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B16722_03_003.jpg" alt="Figure 3.3 – Screenshot of the Query Settings menu to change SQL dialect&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Screenshot of the Query Settings menu to change SQL dialect</p>
			<p>By default, the BigQuery UI is configured to use Standard SQL, but you are allowed to change the SQL dialect by using the specific option located in the <strong class="bold">Query Settings</strong> of the BigQuery web interface, or by prefacing your queries with the <strong class="source-inline">#legacySQL</strong> keyword in the first line of your SQL statement. The <strong class="bold">Query Settings</strong> button is available under the <strong class="bold">More</strong> button in the <a id="_idIndexMarker201"/>BigQuery UI.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">To develop new use cases, we suggest that you adopt BigQuery Standard SQL, but keep in mind that you could find existing applications that are still based on Legacy SQL. If you find a query that is not validated by the Query Editor, try to switch to Legacy SQL before intervening on the SQL statement.</p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor056"/>CRUD operations</h2>
			<p>In this paragraph, we'll learn how to perform the basic <a id="_idIndexMarker202"/>commands in order to <strong class="bold">Create, Read, Update and Delete</strong> (<strong class="bold">CRUD</strong>) objects in BigQuery. This is not an exhaustive view of all the operations that you can use with BigQuery, but the<a id="_idIndexMarker203"/> goal of this section is to provide you with the minimum knowledge needed to effectively face the next hands-on chapters of this book.</p>
			<h3>Create</h3>
			<p>This category of statements is generally used to<a id="_idIndexMarker204"/> create objects in BigQuery such as tables, views, <strong class="bold">User-Defined Functions</strong> (<strong class="bold">UDFs</strong>), and machine learning <a id="_idIndexMarker205"/>models, or to insert new records into an existing table:</p>
			<ol>
				<li value="1">As a first step, let's create a new empty table in BigQuery:<p class="source-code">CREATE TABLE</p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_table` </p><p class="source-code">  ( id_key INT64,</p><p class="source-code">    description STRING);</p><p>The first two words of the query statement, <strong class="source-inline">CREATE TABLE</strong>, are self-explanatory and are used to start the creation of a new table. After that, we can find the identifier of the object that we're creating. It is composed by the concatenation of the following strings separated by the <strong class="source-inline">.</strong> character:</p><ul><li>The name of the GCP project: <strong class="source-inline">bigqueryml-packt</strong></li><li>The identifier of the BigQuery dataset: <strong class="source-inline">03_bigquery_syntax</strong></li><li>The name of the table to create: <strong class="source-inline">first_table</strong><p>The string of the identifier is also enclosed by the backtick character, <strong class="source-inline">`</strong>. This character delimits the beginning and the end of the name of our object.</p><p>Between the<a id="_idIndexMarker206"/> two round brackets, you can see the list of fields with their data type separated by the comma character. In this example, the table contains only two fields: the numerical <strong class="source-inline">id_key</strong> and the textual <strong class="source-inline">description</strong>.</p><p class="callout-heading">Tip</p><p class="callout">If a table with the same name already exists, it is possible to create a new table replacing the existing one using the <strong class="source-inline">CREATE OR REPLACE TABLE</strong> keywords. This technique is particularly useful when you need to periodically schedule your scripts running them multiple times. These keywords automatically clean the results of the previous executions.</p></li></ul></li>
				<li>Now that we've created our first empty table, let's <strong class="source-inline">INSERT</strong> our first record:<p class="source-code">INSERT INTO</p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_table` VALUES</p><p class="source-code">  ( 1,</p><p class="source-code">    'This is my first record inserted in BigQuery' );</p><p>For the insertion of a new record into our <strong class="source-inline">first_table</strong>, we've used the <strong class="source-inline">INSERT INTO</strong> and <strong class="source-inline">VALUES</strong> keywords. Between the round brackets, we've listed the actual values to insert. In this case, we've chosen the integer number <strong class="source-inline">1</strong> as <strong class="source-inline">id_key</strong> and the string<strong class="source-inline">'This is my first record inserted in BigQuery'</strong> in single quotes.</p></li>
				<li>On top of a table, it is possible to create a <strong class="bold">view</strong>. The view doesn't contain any records but allows you to <a id="_idIndexMarker207"/>access the records of an underlying table with a specific business logic:<p class="source-code">CREATE VIEW</p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_view` AS</p><p class="source-code">  SELECT * FROM </p><p class="source-code">    `bigqueryml-packt.03_bigquery_syntax.first_table`;</p><p>The <strong class="source-inline">CREATE VIEW</strong> statement is similar to the <strong class="source-inline">CREATE TABLE</strong> one, the only difference being that the view structure is based on the <strong class="source-inline">SELECT</strong> statement that follows the <strong class="source-inline">AS</strong> keyword. In<a id="_idIndexMarker208"/> this case, <strong class="source-inline">first_view</strong> has the same structure as <strong class="source-inline">first_table</strong> and doesn't apply any filters or transformations on the records stored in the table.</p></li>
			</ol>
			<h3>Read</h3>
			<p>Read operations are<a id="_idIndexMarker209"/> mainly based on <strong class="source-inline">SELECT</strong> statements and can be applied to different database objects such as tables and views.</p>
			<p>Let's execute a <strong class="source-inline">SELECT</strong> statement on the <strong class="source-inline">first_table</strong> table:</p>
			<p class="source-code">SELECT</p>
			<p class="source-code">  *</p>
			<p class="source-code">FROM</p>
			<p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_table`</p>
			<p class="source-code">WHERE</p>
			<p class="source-code">  id_key=1;</p>
			<p>To read data from a table or a view, it is necessary to use the <strong class="source-inline">SELECT</strong> keyword, followed by the list of the fields to read or the wildcard <strong class="source-inline">*</strong>, then the keyword <strong class="source-inline">FROM</strong> and the identifier of the source data structure. It is also possible to include a <strong class="source-inline">WHERE</strong> clause to express all the logical filters that we want to apply. In this case, we're picking up only the records with <strong class="source-inline">id_key=1</strong> that corresponds to the only record that we've previously inserted into the table.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Using the wildcard <strong class="source-inline">*</strong> is not recommended, especially on tables with a large number of columns. Since BigQuery has columnar storage, selecting only the fields that are really needed can dramatically improve the performance and decrease the computational cost of the query.</p>
			<p>With hierarchical <a id="_idIndexMarker210"/>queries with nested <strong class="source-inline">SELECT</strong> statements, the <strong class="source-inline">WITH</strong> clause can be used to improve the readability of the query:</p>
			<ol>
				<li value="1">As the first step, let's create a nested <strong class="source-inline">SELECT</strong> statement:<p class="source-code">SELECT COUNT(*) FROM (</p><p class="source-code">    SELECT</p><p class="source-code">      *</p><p class="source-code">    FROM</p><p class="source-code">      `bigqueryml-packt.03_bigquery_syntax.first_table`</p><p class="source-code">    WHERE</p><p class="source-code">      id_key=1</p><p class="source-code">  );</p></li>
				<li>After that, we can rewrite the same logic using the <strong class="source-inline">WITH</strong> clause. The query becomes this:<p class="source-code">WITH records_with_clause AS (SELECT *</p><p class="source-code">    FROM</p><p class="source-code">      `bigqueryml-packt.03_bigquery_syntax.first_table`</p><p class="source-code">    WHERE</p><p class="source-code">      id_key=1)</p><p class="source-code">      </p><p class="source-code">SELECT COUNT(*) FROM records_with_clause;</p><p>In the second query, the <strong class="source-inline">WITH</strong> clause embeds the logic that follows the <strong class="source-inline">AS</strong> keyword and is enclosed by round brackets. After the definition of the <strong class="source-inline">WITH</strong> clause with <a id="_idIndexMarker211"/>the name <strong class="source-inline">records_with_clause</strong>, the logic of this query can be recalled in the next <strong class="source-inline">SELECT COUNT</strong> statement.</p><p class="callout-heading">Tip</p><p class="callout">The <strong class="source-inline">WITH</strong> clause doesn't create a temporary table. Using the <strong class="source-inline">WITH</strong> clause improves the readability of the query, especially if there are many nested <strong class="source-inline">SELECT</strong> statements, but it doesn't affect the performance of the query.</p></li>
			</ol>
			<p>BigQuery offers the possibility to leverage many other operators that will not be described in detail in this chapter because they will not be extensively used in the hands-on exercises. These additional operators allow you to do the following:</p>
			<ul>
				<li>Sort the results of a query according to a specific list of fields with the <strong class="source-inline">ORDER BY</strong> clause.</li>
				<li>Apply aggregations on the query results with <strong class="source-inline">COUNT</strong>, <strong class="source-inline">SUM</strong>, <strong class="source-inline">MAX</strong>, <strong class="source-inline">AVG</strong>, and the <strong class="source-inline">GROUP BY</strong> and <strong class="source-inline">HAVING</strong> clauses.</li>
				<li>Manage the array data type using <strong class="source-inline">NEST</strong>, <strong class="source-inline">UNNEST</strong>, <strong class="source-inline">ARRAY_AGG</strong>, and <strong class="source-inline">ARRAY_LENGTH</strong>.</li>
				<li>Join two or more tables with <strong class="source-inline">INNER JOIN</strong>, <strong class="source-inline">LEFT OUTER JOIN</strong>, <strong class="source-inline">RIGHT OUTER JOIN</strong>, and <strong class="source-inline">CROSS JOIN</strong>.</li>
			</ul>
			<h3>Update</h3>
			<p>Although BigQuery was<a id="_idIndexMarker212"/> born as an analytic tool, update operations such as <strong class="source-inline">UPDATE</strong> and <strong class="source-inline">MERGE</strong> are supported and can be used to change existing records in BigQuery tables.</p>
			<p>In order to change the value of a record or a set of records, we can use the <strong class="source-inline">UPDATE</strong> statement in the following way:</p>
			<p class="source-code">UPDATE</p>
			<p class="source-code">    `bigqueryml-packt.03_bigquery_syntax.first_table`</p>
			<p class="source-code">SET</p>
			<p class="source-code">    description= 'This is my updated description'</p>
			<p class="source-code">WHERE </p>
			<p class="source-code">    id_key=1;</p>
			<p>In the first two lines of code, the <strong class="source-inline">UPDATE</strong> keyword is followed by the identifier of the table on which the operation should be applied. After that, the <strong class="source-inline">SET</strong> keyword defines the columns that should be changed. In this case, the <strong class="source-inline">description</strong> will be modified.</p>
			<p>The <strong class="source-inline">WHERE</strong> clause allows you to apply the <strong class="source-inline">UPDATE</strong> operations only to the records that match the filter. In this case, only the records with an <strong class="source-inline">id_key</strong> equal to <strong class="source-inline">1</strong>.</p>
			<p>The other powerful statement to update a table is the <strong class="source-inline">MERGE</strong> function. This function can combine the records of two different tables applying insert, update, and delete operations in a single SQL statement.</p>
			<h3>Delete</h3>
			<p>Delete operations are <a id="_idIndexMarker213"/>particularly useful to delete records or remove objects from BigQuery preventing storage costs:</p>
			<ol>
				<li value="1">As a first step, we can delete a record from the <strong class="source-inline">first_table</strong> table, using the <strong class="source-inline">DELETE</strong> statement as follows:<p class="source-code">DELETE</p><p class="source-code">    `bigqueryml-packt.03_bigquery_syntax.first_table`</p><p class="source-code">WHERE </p><p class="source-code">    id_key=1;</p><p>If we analyze the SQL code, we can see that the <strong class="source-inline">DELETE</strong> keyword is followed by the identifier of the table on which the operation should be applied. The <strong class="source-inline">WHERE</strong> clause filters the set of records to delete. In this case, only the record with an <strong class="source-inline">id_key</strong> equal to <strong class="source-inline">1</strong> is affected.</p></li>
				<li>Another way to remove records from a table is using the <strong class="source-inline">TRUNCATE TABLE</strong> operator. This function allows you to remove all the records with a single statement:<p class="source-code">TRUNCATE TABLE </p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_table`;</p><p>After the <strong class="source-inline">TRUNCATE</strong>, our <strong class="source-inline">first_table</strong> will continue to exist but will not contain any records.</p></li>
				<li>To delete the entire table, including its structure, we can use the <strong class="source-inline">DROP TABLE</strong> keywords:<p class="source-code">DROP TABLE </p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_table`;</p><p>Dropping a table <a id="_idIndexMarker214"/>removes it from the dataset, making the data structure inaccessible. If we explore the list of objects of the <strong class="source-inline">03_bigquery_syntax</strong> dataset, we can see that the <strong class="source-inline">first_table</strong> table is no longer visible:</p><div id="_idContainer052" class="IMG---Figure"><img src="image/B16722_03_004.jpg" alt="Figure 3.4 – The table that was affected by the DROP TABLE statement is no longer visible&#13;&#10;"/></div><p class="figure-caption">Figure 3.4 – The table that was affected by the DROP TABLE statement is no longer visible</p><p>In this case, an interesting aspect is that <strong class="source-inline">first_view</strong>, created on top of the <strong class="source-inline">first_table</strong> table, is still visible.</p></li>
				<li>If we try to<a id="_idIndexMarker215"/> execute a <strong class="source-inline">SELECT</strong> statement on it, the following error will be raised:<div id="_idContainer053" class="IMG---Figure"><img src="image/B16722_03_005.jpg" alt="Figure 3.5 – Querying a view when the underlying table was dropped raises an error&#13;&#10;"/></div><p class="figure-caption">Figure 3.5 – Querying a view when the underlying table was dropped raises an error</p><p>The error, generated by BigQuery, notifies the user that the underlying table is no longer available and cannot be found.</p></li>
				<li>To keep our dataset consistent, it is better to also drop the view with the <strong class="source-inline">DROP VIEW</strong> statement:<p class="source-code">DROP VIEW </p><p class="source-code">  `bigqueryml-packt.03_bigquery_syntax.first_view`;</p><p>Dropping a view is similar to dropping a table, but this operation affects only the metadata because the view doesn't actually store any records.</p></li>
			</ol>
			<p>In this section of the chapter, we've discovered the main operations that we can do with BigQuery SQL; now it's time to dive into BigQuery ML and its syntax.</p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor057"/>Diving into BigQuery ML</h1>
			<p>Developing an ML model in BigQuery involves three main steps:</p>
			<ol>
				<li value="1"><strong class="bold">Model creation</strong>, where you are <a id="_idIndexMarker216"/>required to choose the <strong class="bold">features</strong> and <strong class="bold">labels</strong> of your ML model and the options to tune the ML model. At this stage, BigQuery runs the training of the ML model on the training set that you've chosen.</li>
				<li><strong class="bold">Model evaluation</strong> allows you to test the model trained in the previous step on a different set of records to<a id="_idIndexMarker217"/> prevent any <strong class="bold">overfitting</strong>.</li>
				<li><strong class="bold">Model use</strong>: when the ML model is ready, we can apply it to a new dataset in order to make predictions or classifications of the labels according to the available features.</li>
			</ol>
			<p>In the next paragraphs, we'll take a look at the syntax of these three stages and how these statements are built using stubs of code.</p>
			<h3>Creating the ML model (training)</h3>
			<p>When you've identified <a id="_idIndexMarker218"/>the ML use case and also the set of records to train your model, you can start training the model with the following query:</p>
			<p class="source-code">CREATE MODEL`&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`</p>
			<p class="source-code">TRANSFORM (&lt;list_of_features_transformed&gt;</p>
			<p class="source-code">OPTIONS(&lt;list_of_options&gt;)</p>
			<p class="source-code">AS &lt;select_statement&gt;;</p>
			<p>Very similarly to the creation of a BigQuery table, the statement to train a new model consists of the following:</p>
			<ul>
				<li>The <strong class="source-inline">CREATE MODEL</strong> keywords.</li>
				<li>Then the name of the new ML model. This identifier is composed of the concatenation of the project name, dataset name, and ML model name, separated by the <strong class="source-inline">.</strong> character and enclosed by backticks.</li>
				<li>The <strong class="source-inline">TRANSFORM</strong> clause is not mandatory but is very useful. It allows us to list all the preprocessing transformations applied to the features before training. Putting the preparation functions here allows us to automatically apply the same actions during the actual use of the model.</li>
				<li>A list of <strong class="source-inline">OPTIONS</strong> requires us to specify the <strong class="source-inline">model_type</strong> that we want to use, such as linear regression or logistic regression. This list of options is also used to select the list of labels of the ML model through the <strong class="source-inline">input_label_cols</strong> keyword. Other options can be used to tune the ML model and will be explained in<a id="_idIndexMarker219"/> the next chapters of the book, with the hands-on exercises.</li>
				<li>The <strong class="source-inline">AS</strong> keyword followed by the <strong class="source-inline">SELECT</strong> statement. This statement defines the set of records on which the ML model will be trained.</li>
			</ul>
			<p>In addition to the <strong class="source-inline">CREATE MODEL</strong> statement, we can also use the following:</p>
			<ul>
				<li><strong class="source-inline">CREATE OR REPLACE MODEL</strong> to create a new model or replace the existing one with the same name.</li>
				<li><strong class="source-inline">CREATE MODEL IF NOT EXISTS</strong> to train the new model only if a model with the same name doesn't exist.</li>
			</ul>
			<p>Now that we've understood how to create an ML model in BigQuery ML, let's take a look at the next phase: the evaluation of the model. </p>
			<h3>Evaluating the ML model</h3>
			<p>After training an ML model on a<a id="_idIndexMarker220"/> set of records, it is extremely important to evaluate its performances on a second dataset that's different from the training<a id="_idIndexMarker221"/> one to avoid any <strong class="bold">overfitting</strong>.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">With the term overfitting, we refer to<a id="_idIndexMarker222"/> a situation that could happen when the ML model learns very well from the training dataset but performs negatively on new ones. This usually happens when the model adheres too much to the details of the training dataset and remains conditioned by the noise present in it.</p>
			<p>According to the ML algorithm that we've chosen during the model creation, we can choose among different evaluation functions.</p>
			<h4>Evaluate function</h4>
			<p>This function can be used<a id="_idIndexMarker223"/> with linear regression, logistic regression, <em class="italic">k</em>-means clustering, matrix factorization, and time-series models based on ARIMA:</p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.EVALUATE(</p>
			<p class="source-code">    MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">          `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;evaluation_table&gt;`</p>
			<p class="source-code">    , STRUCT(&lt;threshold&gt; AS threshold));</p>
			<p>The <strong class="source-inline">ML.EVALUATE</strong> function returns only one record with the key performance indicators of the ML model that we've trained and evaluated. The indicator it returns depend on the model type. The query stub is composed of the following:</p>
			<ul>
				<li>An initial <strong class="source-inline">SELECT *</strong> statement that allows us to retrieve all the fields returned by the evaluation stage.</li>
				<li>The call of the evaluation function from the <strong class="source-inline">ML</strong> package: <strong class="source-inline">ML.EVALUATE</strong>.</li>
				<li>The identifier of the ML model with the syntax that we already know very well: project, dataset, and model name.</li>
				<li>The <strong class="source-inline">&lt;evaluation_table&gt;</strong> on which the ML model will be evaluated. This table can be replaced by a <strong class="source-inline">SELECT</strong> statement and is not mandatory. If you don't provide the table for the evaluation stage, BigQuery will use the entire training set or a portion of it to evaluate your ML model.</li>
				<li>An optional <strong class="source-inline">&lt;threshold&gt;</strong> that can be used to evaluate logistic regression models. If this value is not specified, BigQuery will use <strong class="source-inline">0.5</strong> as the default value.<p class="callout-heading">Tip</p><p class="callout">To use the <strong class="source-inline">ML.EVALUATE</strong> function, the name of the fields of the evaluation set should correspond to the name of the fields of the training dataset that we've used during the model creation.</p></li>
			</ul>
			<h4>Confusion matrix function</h4>
			<p>This function returns a<a id="_idIndexMarker224"/> confusion matrix to evaluate the performances of logistic regression and multiclass logistic regression models:</p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.CONFUSION_MATRIX(</p>
			<p class="source-code">    MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">          `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;evaluation_table&gt;`</p>
			<p class="source-code">    , STRUCT(&lt;treshold&gt; AS threshold));</p>
			<p>This function returns two rows and two columns that contain the number of false positives, false negatives, true positives, and true negatives. Compared to the <strong class="source-inline">EVALUATE</strong> function, the only difference in terms of syntax is represented by the use of the <strong class="source-inline">ML.CONFUSION_MATRIX</strong> function.</p>
			<h4>ROC curve function</h4>
			<p>This function can be used only<a id="_idIndexMarker225"/> with logistic regression models and returns multiple records according to the array of thresholds that are passed as input to the function:</p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.ROC_CURVE(</p>
			<p class="source-code">    MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">          `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;evaluation_table&gt;`</p>
			<p class="source-code">    , GENERATE_ARRAY(&lt;treshold_1&gt;, &lt;treshold_2&gt;, &lt;treshold_n&gt; ));</p>
			<p>The only meaningful difference that we can see from the other evaluation functions that we analyzed in the previous paragraphs is the presence of an array of thresholds. The <strong class="source-inline">GENERATE_ARRAY</strong> function creates an array that contains the values of the thresholds separated by the comma character and enclosed by round brackets.</p>
			<p>The output of this function includes the threshold passed in input, the recall value, the rate of false positives, and the number of true positives, false positives, true negatives, and false negatives.</p>
			<p>We have been through <a id="_idIndexMarker226"/>all the evaluation techniques of BigQuery ML models, now it's time to see how to apply them and get the results. </p>
			<h3>Using the ML model</h3>
			<p>When we're satisfied <a id="_idIndexMarker227"/>with the performance of our ML model, the next step is to use it to achieve our outcomes and finally get business value from the implementation.</p>
			<h4>Predict function</h4>
			<p>This function is <a id="_idIndexMarker228"/>applicable to linear regression, logistic regression, multiclass logistic regression, <em class="italic">k</em>-means clustering, and imported TensorFlow models:</p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.PREDICT(</p>
			<p class="source-code">    MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">          `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;features_table&gt;`</p>
			<p class="source-code">    , STRUCT(&lt;treshold&gt; AS threshold));</p>
			<p>The query is composed of the following:</p>
			<ul>
				<li>The <strong class="source-inline">SELECT * FROM</strong> statement to get all the records and fields returned by <strong class="source-inline">ML.PREDICT</strong> function.</li>
				<li>The <strong class="source-inline">ML.PREDICT</strong> keyword, which accepts as input the name of the ML model to use for the prediction (<strong class="source-inline">&lt;ml_model_name&gt;</strong>) and the table (<strong class="source-inline">&lt;features_table&gt;</strong>) that contains the features to execute the predictions.</li>
				<li>Optionally, you can use a <strong class="source-inline">&lt;threshold&gt;</strong> value for the logistic regression models followed by the <strong class="source-inline">AS threshold</strong> keywords.</li>
			</ul>
			<p>The <strong class="source-inline">ML.PREDICT</strong> function<a id="_idIndexMarker229"/> generates and returns a record for each row present in <strong class="source-inline">&lt;features_table&gt;.</strong> Each row is composed of the features and the predicted labels.</p>
			<h4>Forecast function</h4>
			<p>This function can<a id="_idIndexMarker230"/> only be used for time-series ML models: </p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.FORECAST(</p>
			<p class="source-code">    MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">    STRUCT(&lt;horizon_value&gt; AS horizon, </p>
			<p class="source-code">           &lt;confidence_value&gt; AS confidence_level));</p>
			<p>Unlike the <strong class="source-inline">PREDICT</strong> statement, it doesn't require a table as input. It allows us to choose the following:</p>
			<ul>
				<li>A specific <strong class="source-inline">&lt;horizon_value&gt;</strong>. The horizon represents the number of time points that should be forecast. If you don't specify this value, BigQuery will use <strong class="source-inline">3</strong> as the default.</li>
				<li>A <strong class="source-inline">confidence_level</strong>, which represents the percentage of the forecast values that reside in the interval of the prediction.</li>
			</ul>
			<h4>Recommend function</h4>
			<p>This function can <a id="_idIndexMarker231"/>only be used for matrix factorization ML models. It returns a rating for each combination of user and item in the <strong class="source-inline">&lt;user_item_table&gt;</strong> table or in the training table:</p>
			<p class="source-code">SELECT *</p>
			<p class="source-code">FROM ML.RECOMMEND(</p>
			<p class="source-code">     MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`,</p>
			<p class="source-code">          (`&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;user_item_table&gt;`));</p>
			<p>The query is composed of the following:</p>
			<ul>
				<li>The <strong class="source-inline">SELECT * FROM</strong> statement to get all the records and fields that come from the outcome of the <strong class="source-inline">ML.RECOMMEND</strong> function.</li>
				<li>The <strong class="source-inline">ML.RECOMMEND</strong> keyword, which accepts as input the name of the ML model to use for the prediction (<strong class="source-inline">&lt;ml_model_name&gt;</strong>) and, optionally, the input table (<strong class="source-inline">&lt;user_item_table&gt;</strong>), which contains the user and items. If the table is not provided, BigQuery will use the entire training table for the recommendation.</li>
			</ul>
			<p>We've learned how to apply a BigQuery ML model; if the model is no longer needed, it is best to delete it to save resources. Let's take a look at how we can do that.</p>
			<h3>Deleting an ML model</h3>
			<p>Deleting an ML model is quite<a id="_idIndexMarker232"/> straightforward, and the syntax is very similar to the cancellation of a table:</p>
			<p class="source-code">DROP MODEL `&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`;</p>
			<p>With the <strong class="source-inline">DROP MODEL</strong> keywords followed by the identifier of the BigQuery ML model, you can remove the asset from your dataset.</p>
			<p>You can also use the <strong class="source-inline">DROP MODEL IF EXISTS</strong> keywords, which prevents errors if the BigQuery ML model has been already deleted. This operation removes the model only if it is present in the dataset:</p>
			<p class="source-code">DROP MODEL IF EXISTS</p>
			<p class="source-code">`&lt;project_name&gt;.&lt;dataset_name&gt;.&lt;ml_model_name&gt;`;</p>
			<p>When the model is deleted, we <a id="_idIndexMarker233"/>can be sure that no resources are consumed to keep it active in BigQuery.</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor058"/>Summary</h1>
			<p>In this chapter, we've learned the main aspects of the BigQuery syntax. After the creation of a dataset, we've discovered how to create tables, insert records, and read the rows stored in a table. You've also learned how to update existing records and how to remove rows and delete objects that are no longer useful, such as tables and views.</p>
			<p>Completing the overview of the BigQuery SQL syntax, we dived into the main stages of the life cycle of an ML model. The three main phases to realize a use case are the creation, the evaluation, and the use of the ML model. For the training phase, we have found out how to train and create a new model using SQL. After that, we went through all the functions that can be used to monitor the effectiveness of a trained model, evaluating its key performance indicators. Finally, we saw how to use a trained model on a new dataset to infer the results and get predictions, forecasts, or recommendations. At the end of the chapter, we also learned how to delete BigQuery ML models that are no longer useful.</p>
			<p>Now that we have a clear understanding of the syntax and all the capabilities that we can use in BigQuery, it's time to apply all these concepts to our first hands-on use case. In the next chapter, we will develop our first BigQuery ML model to predict the estimated duration of a bike trip for an important bike rental service in New York City.</p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor059"/>Further resources</h1>
			<ul>
				<li><strong class="bold">BigQuery datasets</strong>: <a href="https://cloud.google.com/bigquery/docs/datasets">https://cloud.google.com/bigquery/docs/datasets</a></li>
				<li><strong class="bold">BigQuery SQL syntax</strong>: <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax">https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax</a> </li>
				<li><strong class="bold">BigQuery data types</strong>: <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types">https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types</a></li>
				<li><strong class="bold">Create model syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create</a></li>
				<li><strong class="bold">Evaluate syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate</a></li>
				<li><strong class="bold">Confusion matrix syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-confusion">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-confusion</a></li>
				<li><strong class="bold">ROC curve syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-roc">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-roc</a></li>
				<li><strong class="bold">Predict syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict</a></li>
				<li><strong class="bold">Forecast syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-forecast">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-forecast</a></li>
				<li><strong class="bold">Recommend syntax</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-recommend">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-recommend</a></li>
			</ul>
		</div>
	</body></html>