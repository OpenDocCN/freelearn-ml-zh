<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer098">&#13;
			<h1 id="_idParaDest-90" class="chapter-number"><a id="_idTextAnchor091"/>5</h1>&#13;
			<h1 id="_idParaDest-91"><a id="_idTextAnchor092"/>Exploratory Data Analysis</h1>&#13;
			<p>The previous chapter covered the basic plotting principles using <strong class="source-inline">ggplot2</strong>, including the use of various geometries and themes layers. It turns out that cleaning and massaging the raw data (covered in <a href="B18680_02.xhtml#_idTextAnchor032"><span class="No-Break"><em class="italic">Chapter 2</em></span></a> and <a href="B18680_03.xhtml#_idTextAnchor050"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>) and visualizing the data (covered in <a href="B18680_04.xhtml#_idTextAnchor077"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>) belong to the first stage of a typical data science project workflow – that is, <strong class="bold">exploratory data analysis</strong> (<strong class="bold">EDA</strong>). We will cover this using a few case studies in this chapter. We <a id="_idIndexMarker451"/>will learn how to apply the coding techniques we covered earlier in this book and focus on analyzing the data through the lens <span class="No-Break">of EDA.</span></p>&#13;
			<p>By the end of this chapter, you will know how to uncover the structures of data using numerical and graphical techniques, discover interesting relationships among variables, and spot <span class="No-Break">unusual observations.</span></p>&#13;
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>&#13;
			<ul>&#13;
				<li><span class="No-Break">EDA fundamentals</span></li>&#13;
				<li>EDA <span class="No-Break">in practice</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-92"><a id="_idTextAnchor093"/>Technical requirements</h1>&#13;
			<p>To complete the exercises in this chapter, you will need to have <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li>The latest version of the <strong class="source-inline">yfR</strong> package, which is 1.0.0 at the time <span class="No-Break">of writing</span></li>&#13;
				<li>The latest version of the <strong class="source-inline">corrplot</strong> package, which is 0.92 at the time <span class="No-Break">of writing</span></li>&#13;
			</ul>&#13;
			<p>The code and data for this chapter are available <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R"><span class="No-Break">https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_5/chapter_5.R</span></a><span class="No-Break">.</span></p>&#13;
			<h1 id="_idParaDest-93"><a id="_idTextAnchor094"/>EDA fundamentals</h1>&#13;
			<p>When <a id="_idIndexMarker452"/>facing a new dataset in the form of a table (a DataFrame) in Excel or a dataset, EDA helps us gain insight into the underlying pattern and irregularities of variables in the dataset. This is an important first-step exercise before building any predictive model. As the saying goes, <em class="italic">garbage in, garbage out</em>. When the input variables used for model development suffer from problems, such as missing values or different scales, the resulting model will either perform poorly, converge slowly, or even hit an error in the training stage. Therefore, understanding your data and ensuring the raw materials are in check are critical steps in warrantying a good-performing model <span class="No-Break">later on.</span></p>&#13;
			<p>This is where EAD comes in. Instead of being a rigid statistical procedure, EAD is a set of exploratory analyses that enables you to develop a better understanding of the features and potential relationships in the data. It serves as a transitional analysis to guide modeling later on, involving both the data manipulation and visualization techniques we learned earlier. It helps summarize salient characteristics of the data through various forms of visual aids, facilitating the extraction of <span class="No-Break">important features.</span></p>&#13;
			<p>There are two broad types of EDA: descriptive statistics such as the mean, median, mode, and inter-quantile range, and graphical descriptions such as density plots, histograms, box plots, and <span class="No-Break">so on.</span></p>&#13;
			<p>A typical EAD process includes analyzing categorical and numerical variables, both standalone in univariate analysis and in combination via bivariate and multivariate analysis. Common practices include analyzing the distribution of a given set of variables and examining missing values and outliers. In the following sections, we will start by analyzing different types of data, including categorical and numerical variables. We will then go through a case study to apply and reinforce the techniques covered in previous chapters using <strong class="source-inline">dplyr</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">ggplot2</strong></span><span class="No-Break">.</span></p>&#13;
			<h2 id="_idParaDest-94"><a id="_idTextAnchor095"/>Analyzing categorical data</h2>&#13;
			<p>In this section, we will look at<a id="_idIndexMarker453"/> how to analyze two categorical variables via graphical and numerical summaries. We will use a dataset on comic characters from the Marvel comics universe, which should not be unfamiliar to you if you are a fan of Marvel superheroes. The dataset is published by <strong class="bold">FiveThirtyEight</strong> and hosted on their GitHub page. We can directly read the data from the GitHub repository using the <strong class="source-inline">read_csv()</strong> function from the <strong class="source-inline">readr</strong> package, the data loading arm of the <strong class="source-inline">tidyverse</strong> universe, as shown <a id="_idIndexMarker454"/>in the following <span class="No-Break">code snippet:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; library(readr)&#13;
&gt;&gt;&gt; df = read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/comic-characters/marvel-wikia-data.csv")&#13;
&gt;&gt;&gt; head(df,5)&#13;
# A tibble: 16,376 × 13&#13;
   page_id name              urlslug ID    ALIGN EYE   HAIR  SEX   GSM   ALIVE APPEARANCES&#13;
     &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;&#13;
 1    1678 "Spider-Man (Pet… "\\/Sp… Secr… Good… Haze… Brow… Male… NA    Livi…        4043&#13;
 2    7139 "Captain America… "\\/Ca… Publ… Good… Blue… Whit… Male… NA    Livi…        3360&#13;
 3   64786 "Wolverine (Jame… "\\/Wo… Publ… Neut… Blue… Blac… Male… NA    Livi…        3061&#13;
 4    1868 "Iron Man (Antho… "\\/Ir… Publ… Good… Blue… Blac… Male… NA    Livi…        2961&#13;
 5    2460 "Thor (Thor Odin… "\\/Th… No D… Good… Blue… Blon… Male… NA    Livi…        2258&#13;
 6    2458 "Benjamin Grimm … "\\/Be… Publ… Good… Blue… No H… Male… NA    Livi…        2255&#13;
 7    2166 "Reed Richards (… "\\/Re… Publ… Good… Brow… Brow… Male… NA    Livi…        2072&#13;
 8    1833 "Hulk (Robert Br… "\\/Hu… Publ… Good… Brow… Brow… Male… NA    Livi…        2017&#13;
 9   29481 "Scott Summers (… "\\/Sc… Publ… Neut… Brow… Brow… Male… NA    Livi…        1955&#13;
10    1837 "Jonathan Storm … "\\/Jo… Publ… Good… Blue… Blon… Male… NA    Livi…        1934&#13;
# … with 16,366 more rows, and 2 more variables: `FIRST APPEARANCE` &lt;chr&gt;, Year &lt;dbl&gt;</pre>			<p>Printing out the <a id="_idIndexMarker455"/>DataFrame shows that this dataset contains <strong class="source-inline">16,376</strong> rows and <strong class="source-inline">13</strong> columns, including the character names, IDs, and <span class="No-Break">so on.</span></p>&#13;
			<p>In the next section, we will look at summarizing two categorical variables using the <span class="No-Break">count statistic.</span></p>&#13;
			<h2 id="_idParaDest-95"><a id="_idTextAnchor096"/>Summarizing categorical variables using counts</h2>&#13;
			<p>In this section, we will <a id="_idIndexMarker456"/>cover different ways to<a id="_idIndexMarker457"/> analyze two categorical variables, including using a contingency table and a bar chart. A contingency table<a id="_idIndexMarker458"/> is a useful way to show the total counts of observations that fall into each unique combination of the two categorical variables. Let’s go through an exercise on how to <span class="No-Break">achieve this.</span></p>&#13;
			<h3>Exercise 5.1 – summarizing two categorical variables</h3>&#13;
			<p>In this exercise, we will<a id="_idIndexMarker459"/> focus on two categorical variables: <strong class="source-inline">ALIGN</strong> (indicating whether the character is good, neutral, or bad) and <strong class="source-inline">SEX</strong> (indicating the gender of the character). First, we will look at the unique values of each variable, followed by summarizing the respective total counts <span class="No-Break">when combined:</span></p>&#13;
			<ol>&#13;
				<li>Inspect the unique values of <strong class="source-inline">ALIGN</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; unique(df$ALIGN)&#13;
"Good Characters"    "Neutral Characters" "Bad Characters"     NA&#13;
&gt;&gt;&gt; unique(df$SEX)&#13;
"Male Characters"        "Female Characters"      "Genderfluid Characters" "Agender Characters"     NA</pre><p class="list-inset">The results show that both variables contain <strong class="source-inline">NA</strong> values. Let’s remove the observations with <strong class="source-inline">NA</strong> values in either <strong class="source-inline">ALIGN</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">.</span></p></li>				<li>Remove observations with <strong class="source-inline">NA</strong> values in either <strong class="source-inline">ALIGN</strong> or <strong class="source-inline">SEX</strong> in <strong class="source-inline">df</strong> using the <strong class="source-inline">filter</strong> <span class="No-Break">verb function:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df = df %&gt;%&#13;
  filter(!is.na(ALIGN),&#13;
         !is.na(SEX))</pre><p class="list-inset">We can verify whether the rows with <strong class="source-inline">NA</strong> values have been successfully removed by checking the dimension of the resulting DataFrame and the count of <strong class="source-inline">NA</strong> values in <strong class="source-inline">ALIGN</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">:</span></p><pre class="source-code">&gt;&gt;&gt; dim(df)&#13;
12942    13&#13;
&gt;&gt;&gt; sum(is.na(df$ALIGN))&#13;
0&#13;
&gt;&gt;&gt; sum(is.na(df$SEX))&#13;
0</pre><p class="list-inset">Next, we must create a contingency table to summarize the frequency of each unique combination <span class="No-Break">of values.</span></p></li>				<li>Create a<a id="_idIndexMarker460"/> contingency table between <strong class="source-inline">ALIGN</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; table(df$ALIGN, df$SEX)&#13;
                     Agender Characters Female Characters Genderfluid Characters Male Characters&#13;
  Bad Characters                     20               976                       0            5338&#13;
  Good Characters                    10              1537                       1            2966&#13;
  Neutral Characters                 13               640                       1            1440</pre><p class="list-inset">We can see that most characters are male and bad. Among all male characters, the majority are bad, whereas good or neutral characters are dominant in female characters. Let’s visually present and analyze the proportions using a <span class="No-Break">bar chart.</span></p></li>				<li>Create a bar chart between these two variables <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">ggplot2</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; library(ggplot2)&#13;
&gt;&gt;&gt; ggplot(df, aes(x=SEX, fill=ALIGN)) +&#13;
  geom_bar() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.position = c(0.2, 0.8),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this <a id="_idIndexMarker461"/>code snippet creates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em>. Here, we used the properties in the theme layer to adjust the size of labels on the graph. For example, <strong class="source-inline">axis.text</strong> and <strong class="source-inline">axis.title</strong> are used to increase the size of texts and titles along the axes, <strong class="source-inline">legend.position</strong> is used to move the legend to the upper-left corner, and <strong class="source-inline">legend.key.size</strong> and <strong class="source-inline">legend.text</strong> are used to enlarge the overall display of <span class="No-Break">the legend:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer059" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_001.jpg" alt="Figure 5.1 – Bar chart of ALIGN and SEX" width="1628" height="1033"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Bar chart of ALIGN and SEX</p>&#13;
			<p class="list-inset">Since the<a id="_idIndexMarker462"/> total count of <strong class="source-inline">Agender Characters</strong> and <strong class="source-inline">Genderfluid Characters</strong> is very limited, we can remove these two combinations when plotting the <span class="No-Break">bar chart:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=SEX, fill=ALIGN)) +&#13;
  geom_bar()</pre>			<p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer060" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_002.jpg" alt="Figure 5.2 – Removing low-count combinations from the bar chart" width="1447" height="1034"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Removing low-count combinations from the bar chart</p>&#13;
			<p>Using counts may<a id="_idIndexMarker463"/> not be as intuitive when comparing different combinations. In this case, converting counts into proportions will help present the information on a <span class="No-Break">relative scale.</span></p>&#13;
			<h2 id="_idParaDest-96"><a id="_idTextAnchor097"/>Converting counts into proportions</h2>&#13;
			<p>In this section, we will go over an<a id="_idIndexMarker464"/> exercise that covers conditional <a id="_idIndexMarker465"/>proportions in a contingency table. Unlike the previous unconditional contingency table, conditioning along either dimension of a two-way contingency table results in a different distribution <span class="No-Break">of proportions.</span></p>&#13;
			<h3>Exercise 5.2 – summarizing two categorical variables</h3>&#13;
			<p>In this exercise, we<a id="_idIndexMarker466"/> will learn how to express the previous contingency table using proportions and convert it into a conditional distribution based on a <span class="No-Break">specified dimension:</span></p>&#13;
			<ol>&#13;
				<li>Express the previous contingency table using proportions. Avoid scientific notation (for example, e+10) and keep three <span class="No-Break">decimal places:</span><pre class="source-code">&#13;
&gt;&gt;&gt; options(scipen=999, digits=3)&#13;
&gt;&gt;&gt; count_df = table(df$ALIGN, df$SEX)&#13;
&gt;&gt;&gt; prop.table(count_df)&#13;
                     Agender Characters Female Characters Genderfluid Characters Male Characters&#13;
  Bad Characters              0.0015454         0.0754134               0.0000000       0.4124556&#13;
  Good Characters             0.0007727         0.1187606               0.0000773       0.2291763&#13;
  Neutral Characters          0.0010045         0.0494514               0.0000773       0.1112656</pre><p class="list-inset">The values in the contingency table are now expressed as proportions. Since the proportions are derived by dividing the previous absolute counts by the total sum, we can verify whether the total sum of proportions is equal to one by summing all the values in <span class="No-Break">the table:</span></p><pre class="source-code">&gt;&gt;&gt; sum(prop.table(count_df))&#13;
1</pre></li>				<li>Obtain the contingency table as proportions after conditioning on rows (here, the <span class="No-Break"><strong class="source-inline">ALIGN</strong></span><span class="No-Break"> variable):</span><pre class="source-code">&#13;
&gt;&gt;&gt; prop.table(count_df, margin=1)&#13;
                     Agender Characters Female Characters Genderfluid Characters Male Characters&#13;
  Bad Characters               0.003158          0.154089                0.000000        0.842753&#13;
  Good Characters              0.002215          0.340496                0.000222        0.657067&#13;
  Neutral Characters           0.006208          0.305635                0.000478        0.687679</pre><p class="list-inset">We can verify <a id="_idIndexMarker467"/>the conditioning by calculating the <span class="No-Break">row-wise summations:</span></p><pre class="source-code">&gt;&gt;&gt; rowSums(prop.table(count_df, margin=1))&#13;
    Bad Characters    Good Characters Neutral Characters&#13;
                 1                  1                  1</pre><p class="list-inset">In this code, setting <strong class="source-inline">margin=1</strong> means row-level conditioning. We can also exercise column-level conditioning by <span class="No-Break">setting </span><span class="No-Break"><strong class="source-inline">margin=2</strong></span><span class="No-Break">.</span></p></li>				<li>Obtain the contingency table as proportions after conditioning on columns (for instance, the <span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break"> variable):</span><pre class="source-code">&#13;
&gt;&gt;&gt; prop.table(count_df, margin=2)&#13;
                     Agender Characters Female Characters Genderfluid Characters Male Characters&#13;
  Bad Characters                  0.465             0.310                   0.000           0.548&#13;
  Good Characters                 0.233             0.487                   0.500           0.304&#13;
  Neutral Characters              0.302             0.203                   0.500           0.148</pre><p class="list-inset">Similarly, we can verify the conditioning by calculating the <span class="No-Break">column-wise summations:</span></p><pre class="source-code">&gt;&gt;&gt; colSums(prop.table(count_df, margin=2))&#13;
    Agender Characters      Female Characters Genderfluid Characters        Male Characters&#13;
                     1                      1                      1                      1</pre></li>				<li>Plot the unconditional proportions in a bar chart after applying the same filtering condition to <strong class="source-inline">SEX</strong>. Change the label of the <em class="italic">y</em> axis <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">proportion</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=SEX, fill=ALIGN)) +&#13;
  geom_bar(position="fill") +&#13;
  ylab("proportion") +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this<a id="_idIndexMarker468"/> command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.3</em>, where it is obvious that bad characters are predominantly <span class="No-Break">male characters:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer061" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_003.jpg" alt="Figure 5.3 – Visualizing the unconditional proportions in a bar chart" width="1593" height="1013"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Visualizing the unconditional proportions in a bar chart</p>&#13;
			<p class="list-inset">We can also obtain<a id="_idIndexMarker469"/> a similar result from a different angle by switching the two variables in the <span class="No-Break">bar chart:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=ALIGN, fill=SEX)) +&#13;
  geom_bar(position="fill") +&#13;
  ylab("proportion") +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre>			<p class="list-inset">Running this <a id="_idIndexMarker470"/>command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4</em>, where <strong class="source-inline">ALIGN</strong> is used as the <em class="italic">x</em> axis and <strong class="source-inline">SEX</strong> is used as the <span class="No-Break">grouping variable:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer062" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_004.jpg" alt="Figure 5.4 – Switching variables in the bar chart." width="1629" height="1013"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Switching variables in the bar chart.</p>&#13;
			<p>Next, we will look at describing one categorical variable using a marginal distribution and faceted <span class="No-Break">bar chart.</span></p>&#13;
			<h2 id="_idParaDest-97"><a id="_idTextAnchor098"/>Marginal distribution and faceted bar charts</h2>&#13;
			<p>Marginal distribution<a id="_idIndexMarker471"/> refers to the distribution of one variable after integrating other variables. This means that we are interested in the distribution of one specific variable, no matter how the other variables <span class="No-Break">are distributed.</span></p>&#13;
			<p>In the case of our previous two-way contingency table stored in <strong class="source-inline">count_df</strong>, we can derive the marginal distribution of <strong class="source-inline">SEX</strong> in the form of a frequency count by summing over all possible values of <strong class="source-inline">ALIGN</strong>. That is, we can perform column-wise summation to get the marginal count of <strong class="source-inline">SEX</strong>, as shown in the following <span class="No-Break">code snippet:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; colSums(count_df)&#13;
    Agender Characters      Female Characters Genderfluid Characters         Male Characters&#13;
                    43                   3153                      2                    9744</pre>			<p>This has the same effect as directly obtaining the count of different categories <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; table(df$SEX)&#13;
    Agender Characters      Female Characters Genderfluid Characters         Male Characters&#13;
                    43                   3153                      2                    9744</pre>			<p>Now, what if we would like to obtain the<a id="_idIndexMarker472"/> marginal distribution of one variable for each category of another variable? This can be achieved via <strong class="bold">faceting</strong>, which <a id="_idIndexMarker473"/>breaks the data into <a id="_idIndexMarker474"/>subsets based on the unique values of a categorical variable and constructs a plot for each. To implement this, we can add a faceting layer to <strong class="source-inline">ggplot2</strong>, as shown in the following <span class="No-Break">code snippet:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=SEX)) +&#13;
  geom_bar() +&#13;
  facet_wrap(~ALIGN) +&#13;
  theme(axis.text=element_text(size=15),&#13;
        axis.title=element_text(size=15,face="bold"),&#13;
        strip.text.x = element_text(size = 30))</pre>			<p>Running this code generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.5</em>, which contains three side-by-side bar charts for bad, good, and neutral characters, respectively. This is essentially rearranging the stacked bar chart in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4</em>. Note that faceting can be added by using the <strong class="source-inline">facet_wrap</strong> function, where <strong class="source-inline">~ALIGN</strong> indicates that the faceting is to be performed using the <strong class="source-inline">ALIGN</strong> variable. Note that we used the <strong class="source-inline">strip.text.x</strong> attribute to adjust the text size of the facet <span class="No-Break">grid labels:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer063" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_005.jpg" alt="Figure 5.5 – Faceted bar chart" width="1650" height="919"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Faceted bar chart</p>&#13;
			<p>In addition, we can adjust the <a id="_idIndexMarker475"/>sequence of the individual bar facets by overriding the levels of <strong class="source-inline">ALIGN</strong> after converting it into <span class="No-Break">a factor:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; df$ALIGN = factor(df$ALIGN, levels = c("Bad Characters", "Neutral Characters", "Good Characters"))</pre>			<p>Running the same faceting codes again will now generate <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.6</em>, where the sequence of facets is determined according to the levels <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">ALIGN</strong></span><span class="No-Break">:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer064" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_006.jpg" alt="Figure 5.6 – Arranging the sequence of facets in a faceted bar chart" width="1628" height="1013"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Arranging the sequence of facets in a faceted bar chart</p>&#13;
			<p>In the next section, we will look at different ways to explore <span class="No-Break">numerical variables.</span></p>&#13;
			<h2 id="_idParaDest-98"><a id="_idTextAnchor099"/>Analyzing numerical data</h2>&#13;
			<p>In this section, we will look at <a id="_idIndexMarker476"/>summarizing numerical data using different types of plots for the Marvel dataset. Since there’s an infinite amount of values that a numerical/continuous variable can assume, the frequency table used earlier no longer applies. Instead, we often group the values into pre-specified bins, allowing us to work with ranges instead of <span class="No-Break">single values.</span></p>&#13;
			<h3>Exercise 5.3 – exploring numerical variables</h3>&#13;
			<p>In this exercise, we will<a id="_idIndexMarker477"/> describe a numerical variable using a dot plot, histogram, density plot, and box plot for the <span class="No-Break"><strong class="source-inline">Year</strong></span><span class="No-Break"> variable:</span></p>&#13;
			<ol>&#13;
				<li>Get a summary of the <strong class="source-inline">Year</strong> variable using the <span class="No-Break"><strong class="source-inline">summary()</strong></span><span class="No-Break"> function:</span><pre class="source-code">&#13;
&gt;&gt;&gt; summary(df$Year)&#13;
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's&#13;
   1939    1973    1989    1984    2001    2013     641</pre></li>				<li>Generate <a id="_idIndexMarker478"/>a dotted plot of the <span class="No-Break"><strong class="source-inline">Year</strong></span><span class="No-Break"> variable:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=Year)) +&#13;
  geom_dotplot(dotsize=0.2) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.7</em>, where each dot represents an observation at the corresponding location on the <em class="italic">x</em> axis. Similar observations are then stacked together on top of each top. It should be noted that using a dot plot is not the best option when the number of observations becomes large, with the <em class="italic">y</em> axis becoming meaningless due to technical limitations <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">ggplot2</strong></span><span class="No-Break">:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer065" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_007.jpg" alt="Figure 5.7 – Summarizing the Year variable using a dot plot" width="1628" height="940"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Summarizing the Year variable using a dot plot</p>&#13;
			<ol>&#13;
				<li value="3">Build a histogram of the <span class="No-Break"><strong class="source-inline">Year</strong></span><span class="No-Break"> variable:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=Year)) +&#13;
  geom_histogram() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"))</pre><p class="list-inset">Running this<a id="_idIndexMarker479"/> command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.8</em>, where each value of <strong class="source-inline">Year</strong> is grouped into bins and then the number of observations in each bin is counted to represent the height of each bin. Note that the default number of bins is 30, although this can be overwritten using the <strong class="source-inline">bins</strong> argument. The histogram thus presents the general shape of the distribution of the underlying variable. We can also convert it into a density plot to smooth out the steps <span class="No-Break">between bins:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer066" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_008.jpg" alt="Figure 5.8 – Summarizing the Year variable using a histogram" width="1492" height="973"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – Summarizing the Year variable using a histogram</p>&#13;
			<ol>&#13;
				<li value="4">Build a density plot of the <span class="No-Break"><strong class="source-inline">Year</strong></span><span class="No-Break"> variable:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=Year)) +&#13;
  geom_density() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"))</pre><p class="list-inset">Running this<a id="_idIndexMarker480"/> command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.9</em>, where the distribution is represented as a smooth line. Note that a density plot is recommended only when there are many observations in <span class="No-Break">the dataset:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer067" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_009.jpg" alt="Figure 5.9 – Summarizing the Year variable using a density plot" width="1558" height="973"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – Summarizing the Year variable using a density plot</p>&#13;
			<ol>&#13;
				<li value="5">Build a box plot of the <span class="No-Break"><strong class="source-inline">Year</strong></span><span class="No-Break"> variable:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=Year)) +&#13;
  geom_boxplot() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"))</pre></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer068" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_010.jpg" alt="Figure 5.10 – Summarizing the Year variable using a box plot" width="1640" height="1033"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – Summarizing the Year variable using a box plot</p>&#13;
			<p class="list-inset">Running this <a id="_idIndexMarker481"/>command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.10</em>, where the central box represents the majority (25<span class="superscript">th</span> to 75<span class="superscript">th</span> percentile) of the observations, the middle line in the box denotes the median (50<span class="superscript">th</span> percentile), and the outreaching whiskers include almost all “normal” observations. The outlier observation, which is none in this case, would be represented as dots outside the reach of <span class="No-Break">the whiskers.</span></p>&#13;
			<p class="list-inset">We can also add a faceting layer by <strong class="source-inline">SEX</strong> and observe the change in box plots across <span class="No-Break">different genders.</span></p>&#13;
			<ol>&#13;
				<li value="6">Add a faceting layer to the previous box plot using the <span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break"> variable:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=Year)) +&#13;
  geom_boxplot() +&#13;
  facet_wrap(~SEX) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        strip.text.x = element_text(size = 30))</pre><p class="list-inset">Running this<a id="_idIndexMarker482"/> command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.11</em>. As we can see, most female characters are introduced later than many of the male characters, and recent years feature more female characters than <span class="No-Break">male ones:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer069" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_011.jpg" alt="Figure 5.11 – Faceting the box plot based on SEX" width="1621" height="1013"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Faceting the box plot based on SEX</p>&#13;
			<p>In the next section, we will look at how to visualize data with <span class="No-Break">higher dimensions.</span></p>&#13;
			<h2 id="_idParaDest-99"><a id="_idTextAnchor100"/>Visualization in higher dimensions</h2>&#13;
			<p>The previous example used<a id="_idIndexMarker483"/> facets to present the distribution of a numerical variable in each unique value of a categorical variable. When there is more than one categorical variable, we can apply the same technique and expand the facets accordingly. This allows us to visualize the same numerical variable in higher dimensions that contain more than one categorical variable. Let’s go through an exercise on visualizing the distribution of <strong class="source-inline">Year</strong> by <strong class="source-inline">ALIGN</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">.</span></p>&#13;
			<h3>Exercise 5.4 – visualizing Year by ALIGN and SEX</h3>&#13;
			<p>In this exercise, we will <a id="_idIndexMarker484"/>use the <strong class="source-inline">facet_grid()</strong> function from <strong class="source-inline">ggplot2</strong> to visualize the distribution of <strong class="source-inline">Year</strong> in each unique combination of <strong class="source-inline">ALIGN</strong> and <strong class="source-inline">SEX</strong> using both a density plot and <span class="No-Break">a histogram:</span></p>&#13;
			<ol>&#13;
				<li>Build a density plot of <strong class="source-inline">Year</strong> by <strong class="source-inline">ALIGN</strong> and <strong class="source-inline">SEX</strong> after applying the same filtering condition <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">SEX</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=Year)) +&#13;
  geom_density() +&#13;
  facet_grid(ALIGN ~ SEX, labeller = label_both) +&#13;
  facet_grid(ALIGN ~ SEX, labeller = label_both) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        strip.text.x = element_text(size = 30),&#13;
        strip.text.y = element_text(size = 12))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.12</em>, where we used the <strong class="source-inline">facet_grid()</strong> function to create six histograms, with the columns split by the first argument, <strong class="source-inline">ALIGN</strong>, and the rows split by the second argument, <strong class="source-inline">SEX</strong>. The result shows an increasing trend (more movies were produced) for all different combinations of <strong class="source-inline">ALIGN</strong> and <strong class="source-inline">SEX</strong>. However, since the <em class="italic">y</em> axis shows the relative density only, we would need to switch to a histogram to assess the absolute frequency of occurrence. Note that we used the <strong class="source-inline">strip.text.y</strong> attribute to adjust the text size of the facet grid labels along the <span class="No-Break"><em class="italic">y</em></span><span class="No-Break"> axis:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer070" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_012.jpg" alt="Figure 5.12 – Density plot of Year by ALIGN and SEX" width="1646" height="921"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – Density plot of Year by ALIGN and SEX</p>&#13;
			<ol>&#13;
				<li value="2">Build the same plots <a id="_idIndexMarker485"/>using <span class="No-Break">a histogram:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  filter(!(SEX %in% c("Agender Characters", "Genderfluid Characters"))) %&gt;%&#13;
  ggplot(aes(x=Year)) +&#13;
  geom_histogram() +&#13;
  facet_grid(ALIGN ~ SEX, labeller = label_both) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        strip.text.x = element_text(size = 30),&#13;
        strip.text.y = element_text(size = 12))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.13</em>, where we can see that good female and male characters are steadily increasing in <span class="No-Break">recent years:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer071" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_013.jpg" alt="Figure 5.13 – Histogram of Year by ALIGN and SEX" width="1539" height="954"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Histogram of Year by ALIGN and SEX</p>&#13;
			<p>In the next section, we will try different ways to measure the central concentration of a <span class="No-Break">numerical variable.</span></p>&#13;
			<h2 id="_idParaDest-100"><a id="_idTextAnchor101"/>Measuring the central concentration</h2>&#13;
			<p>There are different ways to measure the <a id="_idIndexMarker486"/>central concentration, or central tendency, of a numerical variable. Depending on the context and purpose, the measure of center is often used to represent a typical observation out of a numerical variable <span class="No-Break">of interest.</span></p>&#13;
			<p>The most popular measure of center is the <a id="_idIndexMarker487"/>mean, which is calculated as the average value of a list of numbers. In other words, we can obtain the mean value by summing all observations divided by the number of observations. This can be achieved using the <strong class="source-inline">mean()</strong> function <span class="No-Break">in R.</span></p>&#13;
			<p>Another measure of center is the median, which<a id="_idIndexMarker488"/> is the middle value after sorting the list of numbers from the smallest to the largest. This can be achieved using the <strong class="source-inline">median()</strong> function <span class="No-Break">in R.</span></p>&#13;
			<p>The third measure of center is the <a id="_idIndexMarker489"/>mode, which represents the most common observation in the list of numbers. Since there is no built-in function for calculating the mode, we must write a customized function to obtain the most frequent observation based on the count of occurrences using the <span class="No-Break"><strong class="source-inline">table()</strong></span><span class="No-Break"> function.</span></p>&#13;
			<p>It is important to look at the shape of the distribution before deciding on the measure of center. For a start, note that the mean value is often drawn toward the long tail of a skewed distribution, a continuous distribution inferred from the list of numbers such as the density plot from earlier. In other words, the mean value is sensitive to the extreme values in the observations. On the other hand, the median will not suffer from such sensitivity since it is simply a measure that divides the ordered observations by half. Therefore, the median is a better and more sensible candidate measure of center when working with a skewed continuous distribution, unless additional treatment on the extreme values, often<a id="_idIndexMarker490"/> treated as outliers, is <span class="No-Break">in place.</span></p>&#13;
			<p>Let’s look at how to obtain the three measures of center via <span class="No-Break">an exercise.</span></p>&#13;
			<h3>Exercise 5.5 – calculating the measure of center</h3>&#13;
			<p>In this exercise, we will <a id="_idIndexMarker491"/>calculate the mean, median, and mode of <strong class="source-inline">APPEARANCES</strong>, which denotes the number of appearances for <span class="No-Break">each character:</span></p>&#13;
			<ol>&#13;
				<li>Calculate the mean <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">APPEARANCES</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; mean(df$APPEARANCES)&#13;
NA</pre><p class="list-inset">The <strong class="source-inline">NA</strong> result suggests that there are <strong class="source-inline">NA</strong> values in the observations of <strong class="source-inline">APPEARANCES</strong>. To verify this, we can look at the summary of this <span class="No-Break">continuous variable:</span></p><pre class="source-code">&gt;&gt;&gt; summary(df$APPEARANCES)&#13;
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's&#13;
      1       1       3      20       9    4043     749</pre><p class="list-inset">Indeed, there are quite a few <strong class="source-inline">NA</strong> values. To calculate the mean value after removing these <strong class="source-inline">NA</strong> observations, we can enable the <strong class="source-inline">na.rm</strong> argument in the <span class="No-Break"><strong class="source-inline">mean()</strong></span><span class="No-Break"> function:</span></p><pre class="source-code">&gt;&gt;&gt; mean(df$APPEARANCES, na.rm = TRUE)&#13;
19.8</pre></li>				<li>Calculate the mean <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">APPEARANCES</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; median(df$APPEARANCES, na.rm = TRUE)&#13;
3</pre><p class="list-inset">When the mean and <a id="_idIndexMarker492"/>median values deviate a lot from each other, this is an obvious sign that we are working with a skewed distribution. In this case, the <strong class="source-inline">APPEARANCES</strong> variable is quite skewed, with the median character appearing three times and the most popular character appearing up to <span class="No-Break">4,043 times.</span></p></li>				<li>Calculate the mode <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">APPEARANCES</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; mode &lt;- function(x){&#13;
  ux &lt;- unique(x)&#13;
  ux[which.max(tabulate(match(x, ux)))]&#13;
}&#13;
&gt;&gt;&gt; mode(df$APPEARANCES)&#13;
1</pre><p class="list-inset">Here, we created a customized function called <strong class="source-inline">mode()</strong> to calculate the mode of a numerical variable, where we first extract a list of the unique values using the <strong class="source-inline">unique()</strong> function, then count the number of times each unique value appears using the <strong class="source-inline">tabulate()</strong> and <strong class="source-inline">match()</strong> functions, and lastly obtain the index of the maximal value using the <strong class="source-inline">which.max()</strong> function. The result shows that the majority of characters only appear once in the entire history of <span class="No-Break">Marvel comics.</span></p><p class="list-inset">Now, let’s look at a detailed breakdown of mean and median appearances <span class="No-Break">by </span><span class="No-Break"><strong class="source-inline">ALIGN</strong></span><span class="No-Break">.</span></p></li>				<li>Calculate the mean and median values of <strong class="source-inline">APPEARANCES</strong> by each level <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">ALIGN</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  group_by(ALIGN) %&gt;%&#13;
  summarise(mean_appear = mean(APPEARANCES, na.rm=TRUE),&#13;
            median_appear = median(APPEARANCES, na.rm=TRUE))&#13;
  ALIGN              mean_appear median_appear&#13;
  &lt;fct&gt;                    &lt;dbl&gt;         &lt;dbl&gt;&#13;
1 Bad Characters            8.64             3&#13;
2 Neutral Characters       20.3              3&#13;
3 Good Characters          35.6              5</pre><p class="list-inset">The result shows <a id="_idIndexMarker493"/>that good characters appear more often than <span class="No-Break">bad ones.</span></p></li>			</ol>&#13;
			<p>Next, we will look at how to measure the variability of a <span class="No-Break">continuous variable.</span></p>&#13;
			<h2 id="_idParaDest-101"><a id="_idTextAnchor102"/>Measuring variability</h2>&#13;
			<p>As with central concentration, several <a id="_idIndexMarker494"/>metrics can be used to measure the variability or dispersion of a continuous variable. Some are sensitive to outliers, such as variance and standard deviation, while<a id="_idIndexMarker495"/> others are robust to outliers, such as <strong class="bold">inter-quantile range</strong> (<strong class="bold">IQR</strong>). Let’s go through an exercise on how to calculate <span class="No-Break">these metrics.</span></p>&#13;
			<p>Note that robust measures such as median and IQR are used in box plots, although more details are hidden compared to the full density of a <span class="No-Break">given variable.</span></p>&#13;
			<h3>Exercise 5.6 – calculating the variability of a continuous variable</h3>&#13;
			<p>In this exercise, we will <a id="_idIndexMarker496"/>calculate different metrics on <a id="_idIndexMarker497"/>variability both manually and using built-in functions. We will start with variance, which is calculated as the average squared difference between each raw value and the mean value. Note that this is how population variance is calculated. To calculate the sample variance, we need to adjust the averaging operation by subtracting 1 from the total number of observations used in the <span class="No-Break">variance calculation.</span></p>&#13;
			<p>In addition, variance is a squared version of the original unit and is thus not easily interpretable. To measure the variability of the data at the same original scale, we can use standard deviation, which is calculated by taking the square root of the variance. Let’s look at how to achieve this <span class="No-Break">in practice:</span></p>&#13;
			<ol>&#13;
				<li>Calculate the population variance of <strong class="source-inline">APPEARANCES</strong> after removing <strong class="source-inline">NA</strong> values. Keep two <span class="No-Break">decimal points:</span><pre class="source-code">&#13;
&gt;&gt;&gt; tmp = df$APPEARANCES[!is.na(df$APPEARANCES)]&#13;
&gt;&gt;&gt; pop_var = sum((tmp - mean(tmp))^2)/length(tmp)&#13;
&gt;&gt;&gt; formatC(pop_var, digits = 2, format = "f")&#13;
"11534.53"</pre><p class="list-inset">Here, we first remove <strong class="source-inline">NA</strong> values from <strong class="source-inline">APPEARANCES</strong> and save the result in <strong class="source-inline">tmp</strong>. Next, we subtract the mean value of <strong class="source-inline">tmp</strong> from each original value, square the result, sum all values, and then divide by the number of observations in <strong class="source-inline">tmp</strong>. This essentially follows the definition of variance, which measures the average variability of each observation to the central tendency – in other words, the <span class="No-Break">mean value.</span></p><p class="list-inset">We can also calculate the <span class="No-Break">sample variance.</span></p></li>				<li>Calculate the sample variance <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">APPEARANCES</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; sample_var = sum((tmp - mean(tmp))^2)/(length(tmp)-1)&#13;
&gt;&gt;&gt; formatC(sample_var, digits = 2, format = "f")&#13;
"11535.48"</pre><p class="list-inset">The result is now slightly different from the population variance. Note that to calculate the sample mean, we simply use one less observation in the denominator. Such adjustment is necessary, especially when we are working with limited sample data, although the difference becomes small as the sample <span class="No-Break">size grows.</span></p><p class="list-inset">We can also calculate sample variance by calling the <span class="No-Break"><strong class="source-inline">var()</strong></span><span class="No-Break"> function.</span></p></li>				<li>Calculate sample variance <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">var()</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; formatC(var(tmp), digits = 2, format = "f")&#13;
"11535.48"</pre><p class="list-inset">The result is aligned with our previous manual calculation of the <span class="No-Break">sample variance.</span></p><p class="list-inset">To obtain the measure of variability at the same unit as the original observations, we can calculate the standard deviation. This can be achieved using the <span class="No-Break"><strong class="source-inline">sd()</strong></span><span class="No-Break"> function.</span></p></li>				<li>Calculate<a id="_idIndexMarker498"/> the standard deviation <a id="_idIndexMarker499"/><span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">sd()</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; sd(tmp)&#13;
107.4</pre><p class="list-inset">Another measure of variability is IQR, which is the difference between the third and first quantiles and quantifies the range of the <span class="No-Break">majority values.</span></p></li>				<li>Calculate the IQR <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">IQR()</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; IQR(tmp)&#13;
8</pre><p class="list-inset">We can also verify the result by calling the <strong class="source-inline">summary()</strong> function, which returns the different <span class="No-Break">quantile values:</span></p><pre class="source-code">&gt;&gt;&gt; summary(tmp)&#13;
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.&#13;
    1.0     1.0     3.0    19.8     9.0  4043.0</pre><p class="list-inset">As discussed earlier, measures such as variance and standard deviation are sensitive to extreme values in the data, while IQR is a robust measure of outliers. We can assess the change to these measures after removing the maximal value <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">tmp</strong></span><span class="No-Break">.</span></p></li>				<li>Calculate the<a id="_idIndexMarker500"/> standard deviation and<a id="_idIndexMarker501"/> IQR after removing the maximum <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">tmp</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; tmp2 = tmp[tmp != max(tmp)]&#13;
&gt;&gt;&gt; sd(tmp2)&#13;
101.04&#13;
&gt;&gt;&gt; IQR(tmp2)&#13;
8</pre><p class="list-inset">The result shows that IQR stays the same after removing the maximum, thus being a more robust measure compared to <span class="No-Break">standard deviation.</span></p><p class="list-inset">We can also calculate these measures by different levels of another <span class="No-Break">categorical variable.</span></p></li>				<li>Calculate the <a id="_idIndexMarker502"/>standard deviation, IQR, and<a id="_idIndexMarker503"/> count of <strong class="source-inline">APPEARANCES</strong> for each level <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">ALIGN</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  group_by(ALIGN) %&gt;%&#13;
  summarise(sd_appear = sd(APPEARANCES, na.rm=TRUE),&#13;
            IQR_appear = IQR(APPEARANCES, na.rm=TRUE),&#13;
            count = n())&#13;
  ALIGN              sd_appear IQR_appear count&#13;
  &lt;fct&gt;                  &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;&#13;
1 Bad Characters          26.4          5  6334&#13;
2 Neutral Characters     112.           8  2094&#13;
3 Good Characters        161.          14  4514</pre></li>			</ol>&#13;
			<p>Next, we will dive deeper into the skewness in the distribution of a <span class="No-Break">continuous variable.</span></p>&#13;
			<h2 id="_idParaDest-102"><a id="_idTextAnchor103"/>Working with skewed distributions</h2>&#13;
			<p>Besides the mean<a id="_idIndexMarker504"/> and standard deviation, we can also characterize the distribution of a continuous variable using modality and skewness. Modality refers to the number of humps that exist in the continuous distribution. For example, a unimodal distribution, the most popular distribution we have seen so far in the form of a bell curve, has one peak across the whole distribution. It can grow into a bimodal distribution when there are two humps and multimodal distribution when there are three humps or more. If there is no discernable mode and the distribution appears flat across the whole support region (the range of the continuous variable), it is referred to as a uniform distribution. <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.14</em> summarizes the distributions of <span class="No-Break">different modalities:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer072" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_014.jpg" alt="Figure 5.14 – Different types of modalities in a distribution" width="1059" height="782"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Different types of modalities in a distribution</p>&#13;
			<p>On the other hand, a <a id="_idIndexMarker505"/>continuous variable may be skewed toward the left or the right or appear symmetric around the central tendency. A right-skewed distribution contains more extreme values on the right tail of the distribution, while a left-skewed distribution has a long tail on the left-hand side. <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.15</em> illustrates the different types of skewness in <span class="No-Break">a distribution:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer073" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_015.jpg" alt="Figure 5.15 – Different types of skewness in a distribution" width="1274" height="458"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.15 – Different types of skewness in a distribution</p>&#13;
			<p>Distribution can also<a id="_idIndexMarker506"/> attribute its skewness to outliers in a continuous variable. When there are multiple outliers in the data, sensitive measures such as mean and variance will become distorted, causing a shift in distribution toward the outliers. Let’s go through an exercise to understand how to deal with skewness and outliers in <span class="No-Break">a distribution.</span></p>&#13;
			<h3>Exercise 5.7 – working with skewness and outliers</h3>&#13;
			<p>In this exercise, we will look at how to <a id="_idIndexMarker507"/>work with a skewed distribution that contains <a id="_idIndexMarker508"/>many extreme values, especially outliers in <span class="No-Break">the data:</span></p>&#13;
			<ol>&#13;
				<li>Visualize the density plot of <strong class="source-inline">APPEARANCES</strong> by <strong class="source-inline">ALIGN</strong> for observations since the year <strong class="source-inline">2000</strong>. Set the transparency level <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">0.2</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; tmp = df %&gt;%&#13;
  filter(Year &gt;= 2000)&#13;
&gt;&gt;&gt; ggplot(tmp, aes(x=APPEARANCES, fill=ALIGN)) +&#13;
  geom_density(alpha=0.2) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.position = c(0.8, 0.8),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.16</em>, where all three distributions are quite skewed toward the right, an obvious sign of many outliers in <span class="No-Break">the data:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer074" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_016.jpg" alt="Figure 5.16 – Density plot of APPEARANCES by ALIGN" width="1608" height="926"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.16 – Density plot of APPEARANCES by ALIGN</p>&#13;
			<ol>&#13;
				<li value="2">Remove <a id="_idIndexMarker509"/>observations whose <strong class="source-inline">APPEARANCES</strong> are above the 90<span class="superscript">th</span> percentile<a id="_idIndexMarker510"/> and generate the <span class="No-Break">same plot:</span><pre class="source-code">&#13;
&gt;&gt;&gt; tmp = tmp %&gt;%&#13;
  filter(APPEARANCES &lt;= quantile(APPEARANCES, 0.9, na.rm=TRUE))&#13;
&gt;&gt;&gt; ggplot(tmp, aes(x=log(APPEARANCES), fill=ALIGN)) +&#13;
  geom_density(alpha=0.2) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.position = c(0.8, 0.8),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.17</em>, where all three distributions are much less right-skewed than before. Removing outliers is one way to work around extreme values, although the information contained in the removed observations is lost. To control the effect of outliers and retain their presence at the same time, we can<a id="_idIndexMarker511"/> transform the continuous variable using the <strong class="source-inline">log()</strong> function, which<a id="_idIndexMarker512"/> brings it to the logarithmic scale. Let’s see how this works <span class="No-Break">in practice:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer075" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_017.jpg" alt="Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers" width="1663" height="1033"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.17 – Density plot of APPEARANCES by ALIGN after removing outliers</p>&#13;
			<ol>&#13;
				<li value="3">Apply log transformation to <strong class="source-inline">APPEARANCES</strong> and re-generate the <span class="No-Break">same plot:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(tmp, aes(x=log(APPEARANCES), fill=ALIGN)) +&#13;
  geom_density(alpha=0.2) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.position = c(0.8, 0.8),&#13;
        legend.key.size = unit(2, 'cm'),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this <a id="_idIndexMarker513"/>command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.18</em>, where the three<a id="_idIndexMarker514"/> density plots appear as a bimodal distribution and not as right-skewed as before. Transforming the continuous variable using the logarithmic function could thus bring the original value to a more <span class="No-Break">controlled scale:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer076" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_018.jpg" alt="Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation" width="1620" height="1013"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.18 – Density plot of APPEARANCES by ALIGN after applying log transformation</p>&#13;
			<p>In the next section, we will go through a case study to enhance our skills when conducting EDA on a <span class="No-Break">new dataset.</span></p>&#13;
			<h1 id="_idParaDest-103"><a id="_idTextAnchor104"/>EDA in practice</h1>&#13;
			<p>In this section, we will analyze a dataset that consists of the stock prices of the top five companies in 2021. First, we will look at how to download and process these stock indexes, followed by performing univariate analysis and bivariate analysis in terms <span class="No-Break">of correlation.</span></p>&#13;
			<h2 id="_idParaDest-104"><a id="_idTextAnchor105"/>Obtaining the stock price data</h2>&#13;
			<p>To obtain the daily stock prices of a <a id="_idIndexMarker515"/>particular ticker, we can use the <strong class="source-inline">yfR</strong> package to download the data from Yahoo! Finance, a vast repository of financial data that covers a large number of markets and assets and has been widely used in both academia and industry. The following exercise illustrates how to download the stock data <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">yfR</strong></span><span class="No-Break">.</span></p>&#13;
			<h3>Exercise 5.8 – downloading stock prices</h3>&#13;
			<p>In this exercise, we will <a id="_idIndexMarker516"/>look at how to specify the different parameters so that we can download stock prices from Yahoo! Finance, including the ticker name and <span class="No-Break">date range:</span></p>&#13;
			<ol>&#13;
				<li>Install and load the <span class="No-Break"><strong class="source-inline">yfR</strong></span><span class="No-Break"> package:</span><pre class="source-code">&#13;
&gt;&gt;&gt; install.packages("yfR")&#13;
&gt;&gt;&gt; library(yfR)</pre><p class="list-inset">Note that we would need to wrap the package name inside a pair of double quotes in the <span class="No-Break"><strong class="source-inline">install.packages()</strong></span><span class="No-Break"> function.</span></p></li>				<li>Specify the starting and end date parameters, as well as the ticker names so that they cover Facebook (now <strong class="source-inline">META</strong>), Netflix (<strong class="source-inline">NFLX</strong>), Google (<strong class="source-inline">GOOG</strong>), Amazon (<strong class="source-inline">AMZN</strong>), and <span class="No-Break">Microsoft (</span><span class="No-Break"><strong class="source-inline">MSFT</strong></span><span class="No-Break">):</span><pre class="source-code">&#13;
&gt;&gt;&gt; first_date = as.Date("2021-01-01")&#13;
&gt;&gt;&gt; last_date = as.Date("2022-01-01")&#13;
&gt;&gt;&gt; my_ticker &lt;- c('META', 'NFLX', 'GOOG', 'AMZN', 'MSFT')</pre><p class="list-inset">Here, the start and end dates are formatted as the <strong class="source-inline">Date</strong> type, and the ticker names are concatenated in <span class="No-Break">a vector.</span></p></li>				<li>Download the<a id="_idIndexMarker517"/> stock prices using the <strong class="source-inline">yf_get()</strong> function and store the result <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df &lt;- yf_get(tickers = my_ticker,&#13;
                         first_date = first_date,&#13;
                         last_date = last_date)</pre><p class="list-inset">Running this command generates the following message, which shows that the data for all five stocks has been downloaded successfully. Each ticker has 252 rows in 2021 since there are 252 trading days in <span class="No-Break">a year:</span></p><pre class="source-code">── Running yfR for 5 stocks | 2021-01-01 --&gt; 2022-01-01 (365 days) ──&#13;
ℹ Downloading data for benchmark ticker ^GSPC&#13;
ℹ (1/5) Fetching data for AMZN&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - found cache file (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 252 valid rows (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 100% of valid prices -- Got it!&#13;
ℹ (2/5) Fetching data for GOOG&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - found cache file (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 252 valid rows (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 100% of valid prices -- Good stuff!&#13;
ℹ (3/5) Fetching data for META&#13;
!   - not cached&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - cache saved successfully&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 252 valid rows (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 100% of valid prices -- Mais contente que cusco de cozinheira!&#13;
ℹ (4/5) Fetching data for MSFT&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - found cache file (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 252 valid rows (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 100% of valid prices -- All OK!&#13;
ℹ (5/5) Fetching data for NFLX&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - found cache file (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 252 valid rows (2021-01-04 --&gt; 2021-12-31)&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/>   - got 100% of valid prices -- Youre doing good!&#13;
ℹ Binding price data&#13;
── Diagnostics ───────────────────────────────────────&#13;
<img src="Images/01.png" alt="" role="presentation" width="29" height="31"/> Returned dataframe with 1260 rows -- Time for some tea?&#13;
ℹ Using 156.6 kB at /var/folders/zf/d5cczq0571n0_x7_7rdn0r640000gn/T//Rtmp7hl9eR/yf_cache for 1 cache files&#13;
ℹ Out of 5 requested tickers, you got 5 (100%)</pre><p class="list-inset">Let’s examine the<a id="_idIndexMarker518"/> structure of <span class="No-Break">the dataset:</span></p><pre class="source-code">&gt;&gt;&gt; str(df)&#13;
tibble [1,260 × 11] (S3: tbl_df/tbl/data.frame)&#13;
 $ ticker                : chr [1:1260] "AMZN" "AMZN" "AMZN" "AMZN" ...&#13;
 $ ref_date              : Date[1:1260], format: "2021-01-04" ...&#13;
 $ price_open            : num [1:1260] 164 158 157 158 159 ...&#13;
 $ price_high            : num [1:1260] 164 161 160 160 160 ...&#13;
 $ price_low             : num [1:1260] 157 158 157 158 157 ...&#13;
 $ price_close           : num [1:1260] 159 161 157 158 159 ...&#13;
 $ volume                : num [1:1260] 88228000 53110000 87896000 70290000 70754000 ...&#13;
 $ price_adjusted        : num [1:1260] 159 161 157 158 159 ...&#13;
 $ ret_adjusted_prices   : num [1:1260] NA 0.01 -0.0249 0.00758 0.0065 ...&#13;
 $ ret_closing_prices    : num [1:1260] NA 0.01 -0.0249 0.00758 0.0065 ...&#13;
 $ cumret_adjusted_prices: num [1:1260] 1 1.01 0.985 0.992 0.999 ...&#13;
 - attr(*, "df_control")= tibble [5 × 5] (S3: tbl_df/tbl/data.frame)&#13;
  ..$ ticker              : chr [1:5] "AMZN" "GOOG" "META" "MSFT" ...&#13;
  ..$ dl_status           : chr [1:5] „OK" „OK" „OK" „OK" ...&#13;
  ..$ n_rows              : int [1:5] 252 252 252 252 252&#13;
  ..$ perc_benchmark_dates: num [1:5] 1 1 1 1 1&#13;
  ..$ threshold_decision  : chr [1:5] "KEEP" "KEEP" "KEEP" "KEEP" ...</pre><p class="list-inset">The data<a id="_idIndexMarker519"/> that’s been downloaded includes information such as the daily opening, closing, highest, and closet prices for <span class="No-Break">each ticker.</span></p></li>			</ol>&#13;
			<p>In the following sections, we will use the adjusted price field, <strong class="source-inline">price_adjusted</strong>, which is adjusted for corporate events such as splits, dividends, and others. This is usually what we would use when analyzing stocks as it represents the actual financial performance of <span class="No-Break">the stockholders.</span></p>&#13;
			<h2 id="_idParaDest-105"><a id="_idTextAnchor106"/>Univariate analysis of individual stock prices</h2>&#13;
			<p>In this section, we will <a id="_idIndexMarker520"/>perform a graphical analysis based on the stock prices. Since the stock prices are time series data that are numerical, we will use plots such as histograms, density plots, and box plots for <span class="No-Break">visualization purposes.</span></p>&#13;
			<h3>Exercise 5.9 – downloading stock prices</h3>&#13;
			<p>In this exercise, we will <a id="_idIndexMarker521"/>start with the time series plots for the five stocks, followed by generating other types of plots suitable for <span class="No-Break">continuous variables:</span></p>&#13;
			<ol>&#13;
				<li>Generate the time series plots for the <span class="No-Break">five plots:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df,&#13;
       aes(x = ref_date, y = price_adjusted,&#13;
           color = ticker)) +&#13;
  geom_line() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.19</em>, where Netflix takes the lead in terms of stock value. However, it also suffers from a huge fluctuation, especially around <span class="No-Break">November 2021:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer093" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_019.jpg" alt="Figure 5.19 – Time series plots of the five stocks" width="1651" height="1040"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.19 – Time series plots of the five stocks</p>&#13;
			<ol>&#13;
				<li value="2">Generate a<a id="_idIndexMarker522"/> histogram for each of the five stocks, with 100 bins for <span class="No-Break">each histogram:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=price_adjusted, fill=ticker)) +&#13;
  geom_histogram(bins=100) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.20</em>, which shows that Netflix has the biggest mean and variance in terms of stock value. Google and Amazon seem to share a similar spread, and the same goes for Facebook <span class="No-Break">and Microsoft:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer094" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_020.jpg" alt="Figure 5.20 – Histograms of the five stocks" width="1597" height="1033"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.20 – Histograms of the five stocks</p>&#13;
			<ol>&#13;
				<li value="3">Generate a<a id="_idIndexMarker523"/> density plot for each of the five stocks. Set the transparency level <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">0.2</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(x=price_adjusted, fill=ticker)) +&#13;
  geom_density(alpha=0.2) +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.21</em>, where the plots are now visually clearer compared to <span class="No-Break">the histograms:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer095" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_021.jpg" alt="Figure 5.21 – Density plots of the five stocks" width="1656" height="1075"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.21 – Density plots of the five stocks</p>&#13;
			<ol>&#13;
				<li value="4">Generate a <a id="_idIndexMarker524"/>box plot for each of the <span class="No-Break">five stocks:</span><pre class="source-code">&#13;
&gt;&gt;&gt; ggplot(df, aes(ticker, price_adjusted, fill=ticker)) +&#13;
  geom_boxplot() +&#13;
  theme(axis.text=element_text(size=18),&#13;
        axis.title=element_text(size=18,face="bold"),&#13;
        legend.text = element_text(size=20))</pre><p class="list-inset">Running this command generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.22</em>. Box plots are good at indicating the central tendency and variation of each stock. For example, Netflix has the biggest mean and variance across all <span class="No-Break">five stocks:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer096" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_022.jpg" alt="Figure 5.22 – Box plots of the five stocks" width="1655" height="1075"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.22 – Box plots of the five stocks</p>&#13;
			<ol>&#13;
				<li value="5">Obtain the <a id="_idIndexMarker525"/>mean, standard deviation, IQR, and count of <span class="No-Break">each stock:</span><pre class="source-code">&#13;
&gt;&gt;&gt; df %&gt;%&#13;
  group_by(ticker) %&gt;%&#13;
  summarise(mean = mean(price_adjusted, na.rm=TRUE),&#13;
            sd = sd(price_adjusted, na.rm=TRUE),&#13;
            IQR = IQR(price_adjusted, na.rm=TRUE),&#13;
            count = n())&#13;
# A tibble: 5 × 5&#13;
  ticker  mean    sd   IQR count&#13;
  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;&#13;
1 AMZN    167.  8.00  10.7   252&#13;
2 GOOG    126. 18.4   31.1   252&#13;
3 META    321. 34.9   44.2   252&#13;
4 MSFT    273. 37.2   58.5   252&#13;
5 NFLX    558. 56.0   87.5   252</pre></li>			</ol>&#13;
			<p>In the next section, we will look at the pairwise correlation between each pair <span class="No-Break">of stocks.</span></p>&#13;
			<h2 id="_idParaDest-106"><a id="_idTextAnchor107"/>Correlation analysis</h2>&#13;
			<p>Correlation measures the <a id="_idIndexMarker526"/>strength of covariation between two variables. There are several ways to calculate the specific value of correlation, with Pearson correlation being the most widely used. Pearson correlation is a value that ranges from -1 to 1, with 1 indicating two perfectly and positively correlated variables and -1 denoting perfect negative correlation. Perfect correlation means that the change in the value of one variable is always proportional to the change in the value of another variable. For example, when <span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Variable">x</span>, the correlation between variable <span class="_-----MathTools-_Math_Variable">x</span> and <span class="_-----MathTools-_Math_Variable">y</span> is 1 since <span class="_-----MathTools-_Math_Variable">y</span> always changes positively in proportion <span class="No-Break">to </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">x</span></span><span class="No-Break">.</span></p>&#13;
			<p>Instead of manually calculating the pairwise correlation between all variables, we can use the <strong class="source-inline">corrplot</strong> package to calculate and visualize pairwise correlations automatically. Let’s go through an exercise on how this can <span class="No-Break">be achieved.</span></p>&#13;
			<h3>Exercise 5.10 – downloading stock prices</h3>&#13;
			<p>In this <a id="_idIndexMarker527"/>exercise, we will first convert the previous DataFrame from long into wide format so that each stock has a separate column indicating the adjusted price across different days/rows. The wide-format dataset will then be used to generate the pairwise <span class="No-Break">correlation plot:</span></p>&#13;
			<ol>&#13;
				<li>Convert the previous dataset into a wide format using the <strong class="source-inline">spread()</strong> function in the <strong class="source-inline">tidyr</strong> package. Save the result <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">wide_df</strong></span><span class="No-Break">:</span><pre class="source-code">&#13;
&gt;&gt;&gt; library(tidyr)&#13;
&gt;&gt;&gt; wide_df &lt;- df %&gt;%&#13;
  select(ref_date, ticker, price_adjusted) %&gt;%&#13;
  spread(ticker, price_adjusted)</pre><p class="list-inset">Here, we first select three variables, with <strong class="source-inline">ref_date</strong> as the row-level date index, <strong class="source-inline">ticker</strong>, whose unique values serve as the columns to be spread across the DataFrame, and <strong class="source-inline">price_adjusted</strong>, to be used to fill in the cells of the wide DataFrame. With <a id="_idIndexMarker528"/>this, we can examine the first few rows of the <span class="No-Break">new dataset:</span></p><pre class="source-code">&gt;&gt;&gt; head(wide_df)&#13;
# A tibble: 6 × 6&#13;
  ref_date    AMZN  GOOG  META  MSFT  NFLX&#13;
  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;&#13;
1 2021-01-04  159.  86.4  269.  214.  523.&#13;
2 2021-01-05  161.  87.0  271.  215.  521.&#13;
3 2021-01-06  157.  86.8  263.  209.  500.&#13;
4 2021-01-07  158.  89.4  269.  215.  509.&#13;
5 2021-01-08  159.  90.4  268.  216.  510.&#13;
6 2021-01-11  156.  88.3  257.  214.  499.</pre><p class="list-inset">Now, the DataFrame has been converted from a long format into a wide format, which will facilitate the creation of correlation plots <span class="No-Break">later on.</span></p></li>				<li>Generate a correlation plot using the <strong class="source-inline">corrplot()</strong> function from the <strong class="source-inline">corrplot</strong> package (to be installed if you have not done <span class="No-Break">so already):</span><pre class="source-code">&#13;
&gt;&gt;&gt; install.packages("corrplot")&#13;
&gt;&gt;&gt; library(corrplot)&#13;
&gt;&gt;&gt; cor_table = cor(wide_df[,-1])&#13;
&gt;&gt;&gt; corrplot(cor_table, method = "circle")</pre><p class="list-inset">Running these <a id="_idIndexMarker529"/>commands generates <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.23</em>. Each circle represents the strength of correlation between the corresponding stocks, where a bigger and darker circle denotes a <span class="No-Break">stronger correlation:</span></p></li>			</ol>&#13;
			<div>&#13;
				<div id="_idContainer097" class="IMG---Figure">&#13;
					<img src="Images/B18680_05_023.jpg" alt="Figure 5.23 – Correlation plot between each pair of stocks" width="975" height="904"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.23 – Correlation plot between each pair of stocks</p>&#13;
			<p class="list-inset">Note that the <a id="_idIndexMarker530"/>correlation plot relies on the <strong class="source-inline">cor_table</strong> variable, which stores the pairwise correlation as a table, as <span class="No-Break">shown here:</span></p>&#13;
			<pre class="source-code">&#13;
&gt;&gt;&gt; cor_table&#13;
      AMZN  GOOG  META  MSFT  NFLX&#13;
AMZN 1.000 0.655 0.655 0.635 0.402&#13;
GOOG 0.655 1.000 0.855 0.945 0.633&#13;
META 0.655 0.855 1.000 0.692 0.267&#13;
MSFT 0.635 0.945 0.692 1.000 0.782&#13;
NFLX 0.402 0.633 0.267 0.782 1.000</pre>			<p>A high correlation between variables may or may not be a good thing. When the dependent variable (also called the target outcome) to be predicted is highly correlated with an independent variable (also called a predictor, feature, or covariate), we would prefer to include this feature in the prediction model due to its high covariation with the target variable. On the other hand, when two features are highly correlated, we tend to ignore one and choose the other or apply some sort of regularization and feature selection approach to downsize the impact of <span class="No-Break">correlated features.</span></p>&#13;
			<h1 id="_idParaDest-107"><a id="_idTextAnchor108"/>Summary</h1>&#13;
			<p>In this chapter, we introduced basic techniques to conduct EDA. We started by going over the common approaches to analyzing and summarizing categorical data, including frequency count and bar charts. We then introduced marginal distribution and faceted bar charts when working with multiple <span class="No-Break">categorical variables.</span></p>&#13;
			<p>Next, we switched to analyzing numerical variables and covered sensitive measures such as central tendency (mean) and variation (variance), as well as robust measures such as median and IQR. Several types of charts are available for visualizing a numerical variable, including histograms, density plots, and box plots, all of which can be combined with another <span class="No-Break">categorical variable.</span></p>&#13;
			<p>Finally, we went through a case study using the stock price data. We started by downloading the real data from Yahoo! Finance and applying all the EDA techniques to analyze the data, followed by creating a correlation plot to indicate the strength of covariation between each pair of variables. This allows us to develop a helpful understanding of the relationship between variables and jump-start the predictive <span class="No-Break">modeling stage.</span></p>&#13;
			<p>In the next chapter, we will cover r markdown, a widely used package to generate interactive reports <span class="No-Break">in R.</span></p>&#13;
		</div>&#13;
	</div></body></html>