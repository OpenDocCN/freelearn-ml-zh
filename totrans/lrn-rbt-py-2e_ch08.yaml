- en: Building ChefBot Hardware and the Integration of Software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](lrn-rbt-py-2e_ch03.html), *Modeling a Differential Robot Using
    ROS and URDF*, we looked at the ChefBot chassis design. In this chapter, we will
    learn how to assemble this robot using those parts. We will also look at the final
    interfacing of the sensors and other electronic components of this robot with
    Tiva-C LaunchPad. After the interfacing, we will learn how to interface the robot
    with the PC and implement autonomous navigation using SLAM and AMCL in the real
    robot.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Building ChefBot hardware
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the ChefBot PC and packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interfacing the ChefBot sensors with Tiva-C Launchpad
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embedded code for ChefBot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding ChefBot ROS packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing SLAM on ChefBot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous navigation in ChefBot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To test the application and codes in this chapter, you will need an Ubuntu 16.04
    LTS PC/laptop with ROS Kinetic installed.
  prefs: []
  type: TYPE_NORMAL
- en: You will also need fabricated robot chassis parts for assembling the robot.
  prefs: []
  type: TYPE_NORMAL
- en: You should have all the sensors and other hardware components that can be integrated
    in the robot.
  prefs: []
  type: TYPE_NORMAL
- en: We have already discussed interfacing individual robot components and sensors
    with Launchpad. In this chapter, we will try to interface the necessary robotic
    components and sensors of ChefBot and program it in such a way that it will receive
    the values from all sensors and control the information from the PC. Launchpad
    will send all sensor values to the PC via a serial port and also receive control
    information (such as reset commands, speed data, and so on) from the PC.
  prefs: []
  type: TYPE_NORMAL
- en: After receiving Serial port data from the Tiva C Launchpad, a ROS Python node
    will receive the serial values and convert them to ROS topics. There are other
    ROS  nodes present in the PC that subscribe to these sensor topics and compute
    robot odometry. The data from the wheel encoders and IMU values combine to calculate
    the odometry of the robot. The robot detects obstacles by subscribing to the ultrasonic
    sensor topic and laser scan and controls the speed of the wheel motors using the
    PID node. This node converts the linear velocity command to a differential wheel
    velocity command. After running these nodes, we can run SLAM to map the area,
    and after running SLAM, we can run the AMCL nodes for localization and autonomous
    navigation.
  prefs: []
  type: TYPE_NORMAL
- en: In the first section of this chapter, *Building ChefBot hardware*, we will learn
    how to assemble the ChefBot hardware using the body parts and electronic components
    of the robot.
  prefs: []
  type: TYPE_NORMAL
- en: Building ChefBot hardware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first section of the robot that needs to be configured is the base plate.
    The base plate consists of two motors and their attached wheels, the caster wheels,
    and the base plate supports. The following image shows the top and bottom view
    of the base plate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c2f37b0-96b3-4745-806a-0f0ff4d719f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Base plate with motors, wheels, and caster wheels
  prefs: []
  type: TYPE_NORMAL
- en: The base plate has a radius of 15 cm, and the motors and their attached wheels
    are mounted on the opposite sides of the plate by cutting two sections from the
    base plate. Two rubber caster wheels are mounted on opposite sides of the base
    plate to achieve a good balance and support for the robot. We can either choose
    ball caster wheels or rubber caster wheels for this robot. The wires of the two
    motors are taken to the top of the base plate through a hole in the center of
    the base plate. To extend the layers of the robot, we will put base plate supports
    to connect the following layers. Now, let's look at the next layer with the middle
    plate and connecting tubes. There are hollow tubes to connect the base plate and
    the middle plate. The hollow tubes can be connected to the base plate support.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows the middle plate and connecting tubes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a94335c-c911-4d6a-a941-7afb5e878bf3.png)'
  prefs: []
  type: TYPE_IMG
- en: Middle plate with connecting tubes
  prefs: []
  type: TYPE_NORMAL
- en: 'The connecting tube will connect the base plate and the middle plate. There
    are four hollow tubes to connect the base plate to the middle plate. One end of
    these tubes is hollow, which can fit the base plate support, and the other end
    has a hard plastic fitting with a hole for a screw. The middle plate has no support,
    except for four holes for the connecting tubes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d21f5c1-0a85-4bc9-94e5-76991cc24ab2.png)'
  prefs: []
  type: TYPE_IMG
- en: Fully assembled robot body
  prefs: []
  type: TYPE_NORMAL
- en: The middle plate male connector helps to connect the middle plate and the top
    of the base plate tubes. We can fit the top plate at the top of the middle plate
    tubes using the four supports on the back of the top plate. We can insert the
    top plate's female connector into the top plate support. Now we have the fully
    assembled body of the robot.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bottom layer of the robot can be used to put the **printed circuit board**
    (**PCB**) and battery. In the middle layer, we can put the Kinect/Orbecc and Intel
    NUC. We can put a speaker and mic if needed. We can use the top plate to carry
    food. The following image shows the PCB prototype of the robot; it consists of
    Tiva-C LaunchPad, a motor driver, level shifters, and provisions to connect two
    motors, ultrasonic sensors, and IMU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b46a5d7-63c6-4f6d-a747-f5838d0d76dd.png)'
  prefs: []
  type: TYPE_IMG
- en: ChefBot PCB prototype
  prefs: []
  type: TYPE_NORMAL
- en: 'The board is powered by a 12 V battery placed on the base plate. The two motors
    can be directly connected to the M1 and M2 male connectors. The NUC PC and Kinect
    are placed on the middle plate. The LaunchPad board and Kinect should be connected
    to the NUC PC via USB. The PC and Kinect are powered using the same 12 V battery
    itself. We can use a lead-acid or lithium-polymer battery. Here, we are using
    a lead-acid cell for testing purposes. Later, we will migrate to a lithium-polymer
    battery for better performance and better backup. The following image shows a
    diagram of the complete, assembled ChefBot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c4a26a5-22c1-422a-85f4-e2887838113b.png)'
  prefs: []
  type: TYPE_IMG
- en: Fully assembled robot body
  prefs: []
  type: TYPE_NORMAL
- en: After assembling all the parts of the robot, we will start working with the
    robot software. ChefBot's embedded code and ROS packages are available in the
    codes under `chapter_8`. Let's get that code and start working with the software.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring ChefBot PC and setting ChefBot ROS packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ChefBot, we are using Intel's NUC PC to handle the robot sensor data and
    the processing of the data. After procuring the NUC PC, we have to install Ubuntu
    16.04 LTS. After the installation of Ubuntu, install the complete ROS and its
    packages that we mentioned in the previous chapters. We can configure this PC
    separately, and after the configuration of all the settings, we can put this into
    the robot. The following are the procedures to install the ChefBot packages on
    the NUC PC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone ChefBot''s software packages from GitHub using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We can clone this code in our laptop and copy the `ChefBot` folder to Intel's
    NUC PC. The `ChefBot` folder consists of the ROS packages of the ChefBot hardware.
    In the NUC PC, create a ROS catkin workspace, copy the `ChefBot` folder, and move
    it inside the `src` directory of the catkin workspace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build and install the source code of ChefBot by simply using the following
    command. This should be executed inside the `catkin` workspace we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If all dependencies are properly installed in the NUC, then the ChefBot packages
    will build and install in this system. After setting the ChefBot packages on the
    NUC PC, we can switch to the embedded code for ChefBot. Now, we can connect all
    the sensors in LaunchPad. After uploading the code in LaunchPad, we can again
    look at the ROS packages and how to run them. The cloned code from GitHub contains
    the Tiva-C LaunchPad code, which is going to be explained in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Interfacing ChefBot sensors to the Tiva-C LaunchPad
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have looked at the interfacing of the individual sensors that we are going
    to use in ChefBot. In this section, we will learn how to integrate sensors into
    the LaunchPad board. The Energia code to program Tiva-C LaunchPad is available
    in the cloned files at GitHub. The connection diagram showing the connection of
    the Tiva-C LaunchPad with the sensors is as follows. From this diagram, we learn
    how the sensors are interconnected with LaunchPad:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f7029c2-a70a-4eee-bc8d-7562c0e74bc9.png)'
  prefs: []
  type: TYPE_IMG
- en: Sensor-interfacing diagram of ChefBot
  prefs: []
  type: TYPE_NORMAL
- en: M1 and M2 are two differential-drive motors that we are using in this robot.
    The kind of motor we are going to use here is a DC geared motor with an encoder
    from Pololu. The motor terminals are connected to the dual **VNH2SP30** motor
    driver from Pololu. One of the motors is connected with reverse polarity because
    in differential steering, one motor rotates in the opposite direction to the other.
    If we send the same control signal to both the motors, each motor will rotate
    in the opposite direction. To avoid this condition, we will swap the cables of
    one motor. The motor driver is connected to Tiva-C LaunchPad through a 3.3 V-5
    V bidirectional level shifter. One of the level shifters we will use here is available
    at [https://www.sparkfun.com/products/12009](https://www.sparkfun.com/products/12009).
  prefs: []
  type: TYPE_NORMAL
- en: The two channels of each encoder are connected to LaunchPad using a level shifter.
    At the moment, we are using one ultrasonic distance sensor for obstacle detection.
    In future, we could increase the number of sensors if required. To get a good
    odometry estimate, we will put the IMU sensor MPU 6050 through an I2C interface.
    The pins are directly connected to LaunchPad because MPU6050 is 3.3 V compatible.
    To reset LaunchPad from the ROS nodes, we are allocating one pin as the output
    and connecting it to the reset pin of LaunchPad. When a specific character is
    sent to LaunchPad, it will set the output pin to high and reset the device. In
    some situations, the error from the calculation may accumulate and affect the
    navigation of the robot. We are resetting LaunchPad to clear this error. To monitor
    the battery level, we are allocating another pin to read the battery value. This
    feature is not currently implemented in the Energia code.
  prefs: []
  type: TYPE_NORMAL
- en: The code you downloaded from GitHub consists of the embedded code and the dependent
    libraries needed to compile this code. We can see the main section of the code
    here, and there is no need to explain all of the sections because we have already
    looked at them.
  prefs: []
  type: TYPE_NORMAL
- en: Embedded code for ChefBot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main sections of the LaunchPad code are discussed in this section. The
    following are the header files used in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The main libraries used in this code are for the purposes of communicating with
    MPU 6050 and processing the incoming serial data to LaunchPad. MPU 6050 can provide
    the orientation in quaternion or Euler values using the inbuilt **digital motion
    processor** (**DMP**). The functions to access DMP are written in `MPU6050_6Axis_MotionApps20.h`.
    This library has dependencies such as `I2Cdev.h` and `Wire.h`; that's why we are
    including this header as well. These two libraries are used for I2C communication.
    The `Messenger.h` library allows you to handle a stream of text data from any
    source and will help you to extract the data from it. The `limits.h` header contains
    the definitions of the maximum limits of various data types.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we include the header files, we need to create an object to handle MPU6050
    and process the incoming serial data using the `Messenger` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'After declaring the messenger object, the main section deals with assigning
    pins for the motor driver, encoder, ultrasonic sensor, MPU 6050, reset, and battery
    pins. Once we have assigned the pins, we can look at the `setup()` function of
    the code. The definition of the `setup()` function is given in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding function contains a custom routine to configure and allocate pins
    for all of the sensors. This function will initialize serial communication with
    a 115,200 baud rate and set pins for the encoder, motor driver, ultrasonic sensors,
    and MPU6050\. The `SetupReset()` function will assign a pin to reset the device,
    as shown in the preceding connection diagram. We have already seen the setup routines
    of each of the sensors in the previous chapters, so there is no need to explain
    the definition of each of these functions. The `Messenger` class handler is attached
    to a function called `OnMssageCompleted()`, which will be called when data is
    input to the `Messenger_Handler`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the main `loop()` function of the code. The main purpose of
    this function is to read and process serial data, as well as send available sensor
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `Read_From_Serial()` function will read serial data from the PC and feed
    data to the `Messenger_Handler` handler for processing purposes. The `Update_Time()`
    function will update the time after each operation in the embedded board. We can
    take this time value to be processed in the PC or use the PC's time instead.
  prefs: []
  type: TYPE_NORMAL
- en: We can compile the code in Energia's IDE and burn the code in LaunchPad. After
    uploading the code, we can look at the ROS nodes for handling the LaunchPad sensor
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a ROS Python driver for ChefBot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After uploading the embedded code to LaunchPad, the next step is to handle
    the serial data from LaunchPad and convert it to ROS topics for further processing.
    The `launchpad_node.py` ROS Python driver node interfaces Tiva-C LaunchPad with
    ROS. The `launchpad_node.py` file is in the `script` folder, which is inside the
    `ChefBot_bringup` package. The following is an explanation of the important code
    sections of `launchpad_node.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The `launchpad_node.py` file imports the preceding modules. The main module
    we can see is `SerialDataGateway`. This is a custom module written to receive
    serial data from the LaunchPad board in a thread. We also need some data types
    of ROS to handle the sensor data. The main function of the node is given in the
    following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The main class of this node is called `Launchpad_Class()`. This class contains
    all the methods to start, stop, and convert serial data to ROS topics. In the
    main function, we will create an object of the `Launchpad_Class()`. After creating
    the object, we will call the `Start()` method, which will start the serial communication
    between Tiva-C LaunchPad and the PC. If we interrupt the driver node by typing
    *Ctrl* + *C*, it will reset LaunchPad and stop the serial communication between
    the PC and LaunchPad.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet is from the constructor function of `Launchpad_Class()`.
    In the following snippet, we will retrieve the port and baud rate of the LaunchPad
    board from the ROS parameters and initialize the `SerialDateGateway` object using
    these parameters. The `SerialDataGateway` object calls the `_HandleReceivedLine()`
    function inside this class when any incoming serial data arrives at the serial
    port. This function will process each line of serial data and extract, convert,
    and insert it in the appropriate headers of each ROS topic data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create the ROS publisher object for sensors such as the encoder, IMU,
    and ultrasonic sensor, as well as for the entirety of the serial data for debugging
    purposes. We will also subscribe the speed commands to the left-hand side and
    right-hand side wheel of the robot. When a speed command arrives on the topic,
    it calls the respective callbacks to send speed commands to the robot''s LaunchPad:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: After setting the ChefBot driver node, we need to interface the robot with a
    ROS navigation stack in order to perform autonomous navigation. The basic requirement
    for doing autonomous navigation is that the robot driver nodes receive velocity
    commands from the ROS navigational stack. The robot can be controlled using teleoperation.
    In addition to these features, the robot must be able to compute its positional
    or odometry data and generate the tf data to be sent into the navigational stack.
    There must be a PID controller to control the robot's motor velocity. The following
    ROS package helps us to perform these functions. The `differential_drive` package
    contains nodes to perform the preceding operation. We are reusing these nodes
    in our package to implement these functionalities. You can find the `differential_drive`
    package in ROS at [http://wiki.ros.org/differential_drive](http://wiki.ros.org/differential_drive).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how these nodes communicate with each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95cb50af-83f4-41cc-9742-0a43880b8852.png)'
  prefs: []
  type: TYPE_IMG
- en: Block diagram of the robot showing the ROS nodes
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of each node in the `ChefBot_bringup` package is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`twist_to_motors.py`: This node will convert a ROS `Twist` command or linear
    and angular velocity to an individual motor velocity target. The target velocities
    are published at a rate of the `~rate` (measured in Hertz) and the publish `timeout_ticks`
    time''s velocity after the `Twist` message stops. The following are the topics
    and parameters that will be published and subscribed to by this node:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Publishing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`lwheel_vtarget(std_msgs/Float32)`: This is the target velocity of the left
    wheel (measured in m/s).'
  prefs: []
  type: TYPE_NORMAL
- en: '`rwheel_vtarget` (`std_msgs`/`Float32`): This is the target velocity of the
    right wheel (measured in m/s).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Subscribing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`Twist` (`geometry_msgs`/`Twist`): This is the target `Twist` command for the
    robot. The linear velocity in the x-direction and the angular velocity theta of
    the Twist messages are used in this robot.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important ROS parameters:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`~base_width` (`float, default: 0.1`): This is the distance between the robot''s
    two wheels in meters.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~rate` (`int, default: 50`): This is the rate at which the velocity target
    is published (Hertz).'
  prefs: []
  type: TYPE_NORMAL
- en: '`~timeout_ticks` (`int, default:2`): This is the number of the velocity target
    message published after stopping the Twist messages.'
  prefs: []
  type: TYPE_NORMAL
- en: '`pid_velocity.py`: This is a simple PID controller to control the speed of
    each motor by taking feedback from the wheel encoders. In a differential drive
    system, we need one PID controller for each wheel. It will read the encoder data
    from each wheel and control the speed of each wheel.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Publishing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`motor_cmd` (`Float32`): This is the final output of the PID controller that
    goes to the motor. We can change the range of the PID output using the `out_min`
    and `out_max` ROS parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: '`wheel_vel` (`Float32`): This is the current velocity of the robot wheel in
    m/s.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Subscribing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`wheel` (`Int16`): This topic is the output of a rotary encoder. There are
    individual topics for each encoder of the robot.'
  prefs: []
  type: TYPE_NORMAL
- en: '`wheel_vtarget` (`Float32`): This is the target velocity in m/s.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important parameters:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`~Kp` (`float``,default: 10`): This parameter is the proportional gain of the
    PID controller.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~Ki` (`float, default: 10`): This parameter is the integral gain of the PID
    controller.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~Kd` (`float, default: 0.001`): This parameter is the derivative gain of the
    PID controller.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~out_min` (`float, default: 255`): This is the minimum limit of the velocity
    value to the motor. This parameter limits the velocity''s value to the motor called
    the `wheel_vel` topic.'
  prefs: []
  type: TYPE_NORMAL
- en: '`~out_max` (`float, default: 255`): This is the maximum limit of the `wheel_vel`
    topic (measured in Hertz).'
  prefs: []
  type: TYPE_NORMAL
- en: '`~rate` (`float, default: 20`): This is the rate of publishing the `wheel_vel`
    topic.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ticks_meter` (`float, default: 20`): This is the number of wheel encoder ticks
    per meter. This is a global parameter because it''s used in other nodes too.'
  prefs: []
  type: TYPE_NORMAL
- en: '`vel_threshold` (`float, default: 0.001`): If the robot velocity drops below
    this parameter, we consider the wheel as stationary. If the velocity of the wheel
    is less than `vel_threshold`, we consider it as zero.'
  prefs: []
  type: TYPE_NORMAL
- en: '`encoder_min` (`int, default: 32768`): This is the minimum value of encoder
    reading.'
  prefs: []
  type: TYPE_NORMAL
- en: '`encoder_max` (`int, default: 32768`): This is the maximum value of encoder
    reading.'
  prefs: []
  type: TYPE_NORMAL
- en: '`wheel_low_wrap` (`int, default: 0.3 * (encoder_max - encoder_min) + encoder_min`):
    These values decide whether the odometry is in a negative or positive direction.'
  prefs: []
  type: TYPE_NORMAL
- en: '`wheel_high_wrap` (`int, default: 0.7 * (encoder_max - encoder_min) + encoder_min`):
    These values decide whether the odometry is in a negative or positive direction.'
  prefs: []
  type: TYPE_NORMAL
- en: '`diff_tf.py`: This node computes the transformation of odometry and broadcasts
    between the odometry frame and the robot''s base frame.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Publishing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`odom` (`nav_msgs`/`odometry`): This publishes the odometry (the current pose
    and twist of the robot).'
  prefs: []
  type: TYPE_NORMAL
- en: '`tf`: This provides the transformation between the odometry frame and the robot
    base link.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Subscribing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`lwheel` (`std_msgs`/`Int16`), `rwheel` (`std_msgs`/`Int16`): These are the
    output values from the left and right encoders of the robot.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ChefBot_keyboard_teleop.py`: This node sends the `Twist` command using controls
    from the keyboard.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Publishing topics:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`cmd_vel_mux`/`input`/`teleop` (`geometry_msgs`/`Twist`): This publishes the
    Twist messages using keyboard commands.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have looked at the nodes in the `ChefBot_bringup` package, we will
    look at the functions of the launch files.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ChefBot ROS launch files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now look at the functions of each of the launch files of the `ChefBot_bringup`
    package:'
  prefs: []
  type: TYPE_NORMAL
- en: '`robot_standalone.launch`: The main function of this launch file is to start
    nodes such as `launchpad_node`, `pid_velocity`, `diff_tf,` and `twist_to_motor`
    to get sensor values from the robot and to send the command velocity to the robot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`keyboard_teleop.launch`: This launch file will start teleoperation using the
    keyboard. It starts the `ChefBot_keyboard_teleop.py` node to perform the keyboard
    teleoperation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`3dsensor.launch` : This file will launch the Kinect OpenNI drivers and start
    publishing the RGB and depth stream. It will also start the depth-to-laser scanner
    node, which will convert point cloud data to laser scan data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gmapping_demo.launch`: This launch file will start the SLAM gmapping nodes
    to map the area surrounding the robot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`amcl_demo.launch`: Using AMCL, the robot can localize and predict where it
    stands on the map. After localizing the robot on the map, we can command the robot
    to move to a position on the map. Then the robot can move autonomously from its
    current position to the goal position.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`view_robot.launch`: This launch file displays the robot URDF model in RViz.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`view_navigation.launch`: This launch file displays all the sensors necessary
    for the navigation of the robot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with ChefBot Python nodes and launch files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already set ChefBot ROS packages in Intel's NUC PC and uploaded the
    embedded code to the LaunchPad board. The next step is to put the NUC PC on the
    robot, configure the remote connection from the laptop to the robot, test each
    node, and work with ChefBot's launch files to perform autonomous navigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main device we should have before working with ChefBot is a good wireless
    router. The robot and the remote laptop have to connect across the same network.
    If the robot PC and remote laptop are on the same network, the user can connect
    from the remote laptop to the robot PC through SSH using its IP. Before putting
    the robot PC in the robot, we should connect the robot PC to the wireless network
    so that once it''s connected to the wireless network, it will remember the connection
    details. When the robot powers up, the PC should automatically connect to the
    wireless network. Once the robot PC is connected to a wireless network, we can
    put it in the actual robot. The following diagram shows the connection diagram
    of the robot and remote PC:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a41b1ab5-d147-4580-bd52-200c97833f09.png)'
  prefs: []
  type: TYPE_IMG
- en: Wireless connection diagram of the robot and remote PC
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram assumes that the ChefBot's IP is `192.168.1.106` and the
    remote PC's IP is `192.168.1.101`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can remotely access the ChefBot terminal using SSH. We can use the following
    command to log in to ChefBot, where `robot` is the username of the ChefBot PC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: When you log in to the ChefBot PC, it will ask for the robot PC password. After
    entering the password of the robot PC, we can access the robot PC terminal. After
    logging in to the robot PC, we can start testing ChefBot's ROS nodes and test
    whether we receive the serial values from the LaunchPad board inside ChefBot.
    Note that you should log in to the ChefBot PC again through SSH if you are using
    a new terminal.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `ChefBot_bringup` package is properly installed on the PC, and if the
    LaunchPad board is connected, then before running the ROS driver node, we can
    run the `miniterm.py` tool to check whether the serial values come to the PC properly
    via USB. We can find the serial device name using the `dmesg` command. We can
    run `miniterm.py` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'If it shows the permission denied message, set the permission of the USB device
    by writing rules on the `udev` folder, which we did in [Chapter 6](lrn-rbt-py-2e_ch06.html),
    *Interfacing Actuators and Sensors to the Robot Controller*, or we can temporarily
    change the permission using the following command. Here, we are assuming that
    `ttyACM0` is the device name of LaunchPad. If the device name is different in
    your PC, then you have to use that name instead of `ttyACM0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything works fine, we will get values such as those shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3892aa3-1b0d-434f-b562-a548b050cc15.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of miniterm.py
  prefs: []
  type: TYPE_NORMAL
- en: The letter `b` is used to indicate the battery reading of the robot; currently,
    it's not implemented. The value is set to zero now. These values are coming from
    the Tiva C Launchpad. There are different approaches to sense the voltage using
    a microcontroller board. One of the approaches is given below ([http://www.instructables.com/id/Arduino-Battery-Voltage-Indicator/](http://www.instructables.com/id/Arduino-Battery-Voltage-Indicator/)). The
    letter `t` indicates the total time elapsed (in microseconds) after the robot
    starts running the embedded code. The second value is the time taken to complete
    one entire operation in LaunchPad (measured in seconds). We can use this value
    if we are performing real-time calculations of the parameters of the robot. At
    the moment, we are not using this value, but we may use it in the future. The
    letter `e` indicates the values of the left and right encoder respectively. Both
    the values are zero here because the robot is not moving. The letter `u` indicates
    the values from the ultrasonic distance sensor. The distance value we get is in
    centimeters. The letter `s` indicates the current wheel speed of the robot. This
    value is used for inspection purposes. Actually, speed is a control output from
    the PC itself.
  prefs: []
  type: TYPE_NORMAL
- en: To convert this serial data to ROS topics, we have to run the drive node called
    `launchpad_node.py`. The following code shows how to execute this node.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we have to run `roscore` before starting any nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Run `launchpad_node.py` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything works fine, we will get the following output in node in the running
    terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33b4d922-bdcb-40e3-825b-47f0a5ac855b.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of launchpad_node.py
  prefs: []
  type: TYPE_NORMAL
- en: 'After running `launchpad_node.py`, we will see the following topics generated,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6bca7d0-4626-4670-8832-22137656699d.png)'
  prefs: []
  type: TYPE_IMG
- en: Topics generated by launchpad_node.py
  prefs: []
  type: TYPE_NORMAL
- en: 'We can view the serial data received by the driver node by subscribing to the
    `/serial` topic. We can use it for debugging purposes. If the serial topic shows
    the same data that we saw in `miniterm.py`, then we can confirm that the nodes
    are working fine. The following screenshot is the output of the `/serial` topic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75a326ff-9de1-4dc0-9de6-91e89366dd20.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of the /serial topic published by the LaunchPad node
  prefs: []
  type: TYPE_NORMAL
- en: After setting the `ChefBot_bringup` package, we can start working with the autonomous
    navigation of ChefBot. Currently, we are accessing only the ChefBot PC's terminal.
    To visualize the robot's model, sensor data, maps, and so on, we have to use RViz
    in the user's PC. We have to do some configuration in the robot and user PC to
    perform this operation. It should be noted that the user's PC should have the
    same software setup as the ChefBot PC.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we have to do is to set the ChefBot PC as a ROS master. We can
    set the ChefBot PC as the ROS master by setting the `ROS_MASTER_URI` value. The
    `ROS_MASTER_URI` setting is a required setting; it informs the nodes about the
    **uniform resource identifier** (**URI**) of the ROS master. When you set the
    same `ROS_MASTER_URI` for the ChefBot PC and the remote PC, we can access the
    topics of the ChefBot PC in the remote PC. So, if we run RViz locally, then it
    will visualize the topics generated in the ChefBot PC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume that the ChefBot PC IP is `192.168.1.106` and the remote PC IP is `192.168.1.10`.
    You can set a static IP for Chefbot PC and remote PC so that the IP will always
    be the same all test otherwise if it is automatic, you may get different IP in
    each test. To set `ROS_MASTER_URI` in each system, the following command should
    be included in the `.bashrc` file in the `home` folder. The following diagram
    shows the setup needed to include the `.bashrc` file in each system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e82976a6-208d-4f60-9012-869eb6ee0428.png)'
  prefs: []
  type: TYPE_IMG
- en: Network configuration for ChefBot
  prefs: []
  type: TYPE_NORMAL
- en: Add these lines at the bottom of `.bashrc` on each PC and change the IP address
    according to your network.
  prefs: []
  type: TYPE_NORMAL
- en: After we establish these settings, we can just start `roscore` on the ChefBot
    PC terminal and execute the `rostopic list` command on the remote PC.
  prefs: []
  type: TYPE_NORMAL
- en: If you see any topics, you are done with the settings. We can first run the
    robot using the keyboard teleoperation to check the robot's functioning and confirm
    whether we get the sensor values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can start the robot driver and other nodes using the following command.
    Note that this should execute in the ChefBot terminal after logging in using SSH:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After launching the robot driver and nodes, start the keyboard teleoperation
    using the following command. This also has to be done on the new terminal of the
    ChefBot PC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To activate Kinect, execute the following command. This command is also executed
    on the ChefBot terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are using Orbecc Astra, use the following launch file to start the sensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the sensor data, we can execute the following command. This will view
    the robot model in RViz and should be executed in the remote PC. If we set up
    the `ChefBot_bringup` package in the remote PC, we can access the following command
    and visualize the robot model and sensor data from the ChefBot PC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot is the output of RViz. We can see the LaserScan and
    PointCloud mapped data in the screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f16c9b4-6fc2-488d-bcc2-247eb87466cc.png)'
  prefs: []
  type: TYPE_IMG
- en: ChefBot LaserScan data in RViz
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding screenshot shows LaserScan in RViz. We need to tick the LaserScan
    topic from the left-hand side section of RViz to show the laser scan data. The
    laser scan data is marked on the viewport. If you want to watch the point cloud
    data from Kinect/Astra, click on the Add button on the left-hand side of RViz
    and select PointCloud2 from the pop-up window. Select Topic |`/camera/depth_registered`
    from the list and you will see an image similar to the one shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e4d4e54-42a6-420c-ab92-84d50d2a5030.png)'
  prefs: []
  type: TYPE_IMG
- en: ChefBot with PointCloud data
  prefs: []
  type: TYPE_NORMAL
- en: After working with sensors, we can perform SLAM to map the room. The following
    procedure helps us to start SLAM on this robot.
  prefs: []
  type: TYPE_NORMAL
- en: Working with SLAM on ROS to build a map of the room
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform gmapping, we have to execute the following commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command starts the robot driver in the ChefBot terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command starts the gmapping process. Note that it should be executed
    on the ChefBot terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Gmapping will only work if the odometry value that is received is proper. If
    the odometry value is received from the robot, we will receive the following message
    for the preceding command. If we get this message, we can confirm that gmapping
    will work fine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d3735e1-9c32-4413-925d-3030d845ab55.png)'
  prefs: []
  type: TYPE_IMG
- en: ChefBot with PointCloud data
  prefs: []
  type: TYPE_NORMAL
- en: 'To start the keyboard teleoperation, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the map that is being created, we need to start RViz on the remote
    system using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'After viewing the robot in RViz, you can move the robot using the keyboard
    and see the map being created. When it has mapped the entire area, we can save
    the map using the following command on the ChefBot PC terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, `test_map` is the name of the map being stored in the
    `home` folder. The following screenshot shows the map of a room created by the
    robot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07e93661-11a3-45c2-a87a-c03139613dfe.png)'
  prefs: []
  type: TYPE_IMG
- en: Mapping a room
  prefs: []
  type: TYPE_NORMAL
- en: After the map is stored, we can work with the localization and autonomous navigation
    functionalities using ROS.
  prefs: []
  type: TYPE_NORMAL
- en: Working with ROS localization and navigation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After building the map, close all the applications and rerun the robot driver
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Start the localization and navigation on the stored map using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Start viewing the robot using the following command in the remote PC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In RViz, we may need to specify the initial pose of the robot using the 2D
    Pose Estimate button. We can change the robot pose on the map using this button.
    If the robot is able to access the map, then we can use the 2D Nav Goal button
    to command the robot to move to the desired position. When we start the localization,
    we can see the particle cloud around the robot by using the AMCL algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/728e0ecb-ea30-44f4-80f6-ccec521b372a.png)'
  prefs: []
  type: TYPE_IMG
- en: Localizing the robot using AMCL
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a screenshot of the robot as it navigates autonomously from
    its current position to the goal position. The goal position is marked as a black
    dot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cdec1d3e-d4c5-419c-bde4-81730c3156dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Autonomous navigation using a map
  prefs: []
  type: TYPE_NORMAL
- en: The black line from the robot to the black dot is the robot's planned path to
    reach the goal position. If the robot is not able to locate the map, we might
    need to fine-tune the parameter files in the `ChefBot_bringup``param` folder.
    For more fine-tuning details, you can go through the AMCL package on ROS at [http://wiki.ros.org/amcl](http://wiki.ros.org/amcl).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was about assembling the hardware of ChefBot and integrating the
    embedded and ROS code into the robot to perform autonomous navigation. We saw
    the robot hardware parts that were manufactured using the design from [Chapter
    6](lrn-rbt-py-2e_ch06.html), *Interfacing Actuators and Sensors to the Robot Controller*.
    We assembled the individual sections of the robot and connected the prototype
    PCB we designed for the robot. This consisted of the LaunchPad board, motor driver,
    left shifter, ultrasonic sensor, and IMU. The LaunchPad board was flashed with
    the new embedded code, which can interface with all sensors in the robot and can
    send or receive data from the PC.
  prefs: []
  type: TYPE_NORMAL
- en: After looking at the embedded code, we configured the ROS Python driver node
    to interface with the serial data from the LaunchPad board. After interfacing
    with the LaunchPad board, we computed the odometry data and differential drive
    control using nodes from the `differential_drive` package that was in the ROS
    repository. We interfaced the robot with the ROS navigation stack. This enabled
    us to use SLAM and AMCL for autonomous navigation. We also looked at SLAM and
    AMCL, created a map, and commanded the robot to navigate autonomously.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the use of the robot ROS driver node?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of the PID controller in navigation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you convert encoder data to odometry data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of SLAM in robot navigation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of AMCL in robot navigation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can read more about the robotic vision package in ROS from the following
    links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://wiki.ros.org/gmapping](http://wiki.ros.org/gmapping)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://wiki.ros.org/amcl](http://wiki.ros.org/amcl)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
