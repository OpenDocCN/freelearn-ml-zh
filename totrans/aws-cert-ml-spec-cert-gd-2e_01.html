<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer017" class="Content">
			<h1 class="chapter-number"><a id="_idTextAnchor017"/>1</h1>
			<h1 id="_idParaDest-15"><a id="_idTextAnchor018"/>Machine Learning Fundamentals</h1>
			<p>For many decades, researchers have been trying to simulate human brain activity through the field known as <strong class="bold">artificial intelligence</strong>, or <strong class="bold">AI</strong> for short. In 1956, a group of people met at the Dartmouth Summer Research Project on Artificial Intelligence, an event that is widely accepted as the first group discussion about AI as it’s known today. Researchers were trying to prove that many aspects of the learning process could be precisely described and, therefore, automated and replicated by a machine. Today, you know they <span class="No-Break">were right!</span></p>
			<p>Many other terms appeared in this field, such as <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) and <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>). These sub-areas of AI have also been evolving for many decades (granted, nothing here is new to the science). However, with the natural advance of the information society and, more recently, the advent of <strong class="bold">big data</strong> platforms, AI applications have been reborn with much more applicability – power (because now there are more computational resources to simulate and implement them) and applicability (because now information <span class="No-Break">is everywhere).</span></p>
			<p>Even more recently, cloud service providers have put AI in the cloud. This helps all sizes of companies to reduce their operational costs and even lets them sample AI applications, considering that it could be too costly for a small company to maintain its own data center to scale an <span class="No-Break">AI application.</span></p>
			<p>An incredible journey of building cutting-edge AI applications has emerged with the popularization of big data and cloud services. In June 2020, one specific technology gained significant attention and put AI on the list of the most discussed topics across the technology industry – its name <span class="No-Break">is ChatGPT.</span></p>
			<p>ChatGPT is a popular AI application that uses large language models (more specifically, <strong class="bold">generative pre-trained transformers</strong>) trained on massive amounts of text data to understand and generate human-like language. These models are designed to process and comprehend the complexities of human language, including grammar, context, <span class="No-Break">and semantics.</span></p>
			<p>Large language models utilize DL techniques (for example, deep neural networks based on transformer architecture) to learn patterns and relationships within textual data. They consist of millions of parameters, making them highly complex and capable of capturing very specific <span class="No-Break">language structures.</span></p>
			<p>Such mixing of terms and different classes of use cases might get one stuck on understanding the practical steps of implementing AI applications. That brings you to the goal of this chapter: being able to describe what the terms AI, ML, and DL mean, as well as understanding all the nuances of an ML pipeline. Avoiding confusion about these terms and knowing what exactly an ML pipeline is will allow you to properly select your services, develop your applications, and master the AWS Machine Learning <span class="No-Break">Specialty exam.</span></p>
			<h2 id="_idParaDest-16"><a id="_idTextAnchor019"/>Making the Most Out of this Book – Your Certification and Beyond</h2>
			<p>This book and its accompanying online resources are designed to be a complete preparation tool for your <span class="No-Break"><strong class="bold">MLS-C01 Exam</strong></span><span class="No-Break">.</span></p>
			<p>The book is written in a way that you can apply everything you’ve learned here even after your certification. The online practice resources that come with this book (<span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.1</em>) are designed to improve your test-taking skills. They are loaded with timed mock exams, interactive flashcards, and exam tips to help you work on your exam readiness from now till your <span class="No-Break">test day.</span></p>
			<p class="callout-heading">Before You Proceed</p>
			<p class="callout">To learn how to access these resources, head over to <a href="B21197_11.xhtml#_idTextAnchor1477"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Accessing the Online Practice Resources</em>, at the end of <span class="No-Break">the book.</span></p>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/B21197_01_01.jpg" alt="Figure 1.1 – Dashboard interface of the online practice resources" width="1650" height="939"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Dashboard interface of the online practice resources</p>
			<p>Here are some tips on how to make the most out of this book so that you can clear your certification and retain your knowledge beyond <span class="No-Break">your exam:</span></p>
			<ol>
				<li>Read each <span class="No-Break">section thoroughly.</span></li>
				<li><strong class="bold">Make ample notes</strong>: You can use your favorite online note-taking tool or use a physical notebook. The free online resources also give you access to an online version of this book. Click the <strong class="source-inline">BACK TO THE BOOK</strong> link from the Dashboard to access the book in <strong class="bold">Packt Reader</strong>. You can highlight specific sections of the <span class="No-Break">book there.</span></li>
				<li><strong class="bold">Chapter Review Questions</strong>: At the end of this chapter, you’ll find a link to review questions for this chapter. These are designed to test your knowledge of the chapter. Aim to score at least <strong class="bold">75%</strong> before moving on to the next chapter. You’ll find detailed instructions on how to make the most of these questions at the end of this chapter in the <em class="italic">Exam Readiness Drill - Chapter Review Questions</em> section. That way, you’re improving your exam-taking skills after each chapter, rather than at <span class="No-Break">the end.</span></li>
				<li><strong class="bold">Flashcards</strong>: After you’ve gone through the book and scored <strong class="bold">75%</strong> more in each of the chapter review questions, start reviewing the online flashcards. They will help you memorize <span class="No-Break">key concepts.</span></li>
				<li><strong class="bold">Mock Exams</strong>: Solve the mock exams that come with the book till your exam day. If you get some answers wrong, go back to the book and revisit the concepts you’re <span class="No-Break">weak in.</span></li>
				<li><strong class="bold">Exam Tips</strong>: Review these from time to time to improve your exam readiness <span class="No-Break">even further.</span></li>
			</ol>
			<p>The main topics of this chapter are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Comparing AI, ML, <span class="No-Break">and DL</span></li>
				<li>Classifying supervised, unsupervised, and <span class="No-Break">reinforcement learning</span></li>
				<li>The CRISP-DM modeling <span class="No-Break">life cycle</span></li>
				<li><span class="No-Break">Data splitting</span></li>
				<li><span class="No-Break">Modeling expectations</span></li>
				<li>Introducing <span class="No-Break">ML frameworks</span></li>
				<li>ML in <span class="No-Break">the cloud</span></li>
			</ul>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor020"/><a id="_idTextAnchor021"/>Comparing AI, ML, and DL</h1>
			<p>AI is a broad field that <a id="_idTextAnchor022"/>studies different ways to create systems and machines that will solve problems by simulating human intelligence. There are<a id="_idTextAnchor023"/> different levels of sophistication to create these programs and machines, which <a id="_idTextAnchor024"/>go from simple rule-based engines to complex self-learning systems. AI covers, but is not limited to, the<a id="_idTextAnchor025"/> <span class="No-Break">following <a id="_idTextAnchor026"/>sub-areas:</span></p>
			<ul>
				<li><span class="No-Break">Robotics</span></li>
				<li><strong class="bold">Natural language </strong><span class="No-Break"><strong class="bold">processing</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">NLP</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Rule-based systems</span></li>
				<li>Machine <span class="No-Break">learning (ML)</span></li>
				<li><span class="No-Break">Computer vision</span></li>
			</ul>
			<p>The area this certification exam focuses on <span class="No-Break">is ML.</span></p>
			<h2 id="_idParaDest-18"><a id="_idTextAnchor027"/><a id="_idTextAnchor028"/>Examining ML</h2>
			<p>ML is a sub-area of AI that aims to<a id="_idTextAnchor029"/> create systems and machines that can learn from experience, without being explicitly programmed. As the name suggests, the system can observe its underlying environment, learn, and adapt itself without<a id="_idTextAnchor030"/> human intervention. Algorithms behind ML systems usually extract and improve knowledge from the data and conditions that are available <span class="No-Break">to them.</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/B21197_01_02.jpg" alt="Figure 1.2 – Hierarchy of AI, ML, and DL" width="1386" height="802"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor031"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Hierarchy of AI, ML, and DL</p>
			<p>You should keep in mind that there are different classes of M<a id="_idTextAnchor032"/>L algorithms. For example, decision tree-based models, probabilistic-based models, and neural network models. Each of these classes might contain dozens of specific algorithms or architectures (some of them will be covered in later sections of <span class="No-Break">this book).</span></p>
			<p>As you might have noticed in <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.2</em>, you can be even more specific and break the ML field down into another very important topic for the Machine Learning Specialty exam: deep learning, or DL <span class="No-Break">for short.</span></p>
			<h2 id="_idParaDest-19">E<a id="_idTextAnchor033"/><a id="_idTextAnchor034"/>xamining DL</h2>
			<p>DL is a subset of ML that aims to <a id="_idTextAnchor035"/>propose algorithms that connect multiple layers to solve a particular problem. The knowledge is then passed through, layer by layer, until the optimal solution is found. The most common type of DL algorithm is deep <span class="No-Break">neural networks.</span></p>
			<p>At the time of writing this book, DL is a very hot topic in the field of ML. Most of the current state-of-the-art algorithms for machine translation, image captioning, and computer vision were proposed in the past few years and are a part of the DL field (GPT-4, used by the ChatGPT application, is one of <span class="No-Break">these algorithms).</span></p>
			<p>Now that you have an <a id="_idTextAnchor036"/>overview of types of AI, take a look at some of the ways you can <span class="No-Break">classify ML.</span></p>
			<h1 id="_idParaDest-20">C<a id="_idTextAnchor037"/><a id="_idTextAnchor038"/>lassifying supervised, unsupervised, and reinforcement learning</h1>
			<p>ML is a very e<a id="_idTextAnchor039"/>xtensive field of study; that’s why it is very important to have a clear definition o<a id="_idTextAnchor040"/>f its sub-divisions. From a very b<a id="_idTextAnchor041"/>road perspective, you can split ML algorithms into two main classes: supervised learning and <span class="No-Break">unsupervised learning.</span></p>
			<h2 id="_idParaDest-21">I<a id="_idTextAnchor042"/><a id="_idTextAnchor043"/>ntroducing supervised learning</h2>
			<p>Supervised algorithms use a <a id="_idTextAnchor044"/>class or label (from the input data) as support to find and validate the optimal solution. In <em class="italic">Table 1.1</em>, there is a dataset that aims to classify fraudulent transactions from a <span class="No-Break">financial company.</span></p>
			<p class="IMG---Figure"><a id="_idTextAnchor045"/></p>
			<table id="table001" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Day of </strong><span class="No-Break"><strong class="bold">the week</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Hour</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Transaction amount</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Merchant type</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Is fraud?</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Mon</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">09:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">1000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Retail</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Tue</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">23:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">5500</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">E-commerce</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Fri</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">14:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">500</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Travel</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Mon</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">10:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">100</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Retail</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Tue</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">22:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">100</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">E-commerce</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Tue</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">22:00</span></p>
						</td>
						<td class="No-Table-Style">
							<p>$<span class="No-Break">6000</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">E-commerce</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.1 – Sample dataset for supervised learning</p>
			<p>The first <a id="_idTextAnchor046"/>four columns are known as <strong class="bold">features</strong> or <strong class="bold">independent variables</strong>, and they can be used by a<a id="_idTextAnchor047"/> supervised algorithm to find fraudulent patterns. For example, by combining those four features (day of the week, EST hour, transaction amount, and merchant type) and six observations (each row is technically one observation), you can infer that e-commerce transactions with a value greater than $5,000 and processed at night are potentially <span class="No-Break">fraudulent cases.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In a real scenario, you will have more observations in order to have statistical support to make this type <span class="No-Break">of inference.</span></p>
			<p>The key point is that you were able to infer a potential fraudulent pattern just because you knew, <em class="italic">a priori</em>, what is fraud and what is not fraud. This information is present in the last column of <em class="italic">Table 1.1</em> and is commonly referred to as a target variable, label, response variable, or dependent<a id="_idTextAnchor048"/> variable. If the input dataset has a target variable, you should be able to apply <span class="No-Break">supervised learning.</span></p>
			<p>In supervised learning, the target variable might store different types of data. For instance, it could be a binary column (yes or no), a multi-class column (class A, B, or C), or even a numerical column (any real number, such as a transaction amount). According to the data type of the target variable, you will find which type of supervised learning your problem refers to. <em class="italic">Table 1.2</em> shows how to <a id="_idTextAnchor049"/>classify supervised learning<a id="_idTextAnchor050"/> into two main groups: <strong class="bold">classification</strong> and <span class="No-Break"><strong class="bold">regression</strong></span><span class="No-Break"> algorithms:</span></p>
			<table id="table002" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Data type of the </strong><span class="No-Break"><strong class="bold">target variable</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Sub data type of the </strong><span class="No-Break"><strong class="bold">target variable</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Type of supervised </strong><span class="No-Break"><strong class="bold">learning applicable</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Categorical</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Binary</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Binary classification</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Categorical</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Multi class</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Multi classification</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Numerical</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">N/A</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Regression</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.2 – Choosing the right type of supervised learning given the target variable</p>
			<p>While classification algorithms predict a class (either binary or multiple classes), regression algorithms predict a real number (either continuous <span class="No-Break">or discrete).</span></p>
			<p>Understanding data types is important to make the right decisions on ML projects. You can split data types into two main <a id="_idTextAnchor051"/>categories: numerical and categorical data. Numerical data can then be split into continuous or discrete subclasses, while categorical data might refer<a id="_idTextAnchor052"/> to ordinal or <span class="No-Break">nominal data:</span></p>
			<ul>
				<li><strong class="bold">Numerical/discrete data</strong> refers to individual and countable items (for example, the number of students in a classroom or the number of items in an online <span class="No-Break">shopping cart).</span></li>
				<li><strong class="bold">Numerical/continuous data</strong> refers to an infinite number of possible measurements and they often carry decimal points (for <span class="No-Break">example, temperature).</span></li>
				<li><strong class="bold">Categorical/nominal data</strong> refers to labeled variables with no quantitative value (for example, name <span class="No-Break">or gender).</span></li>
				<li><strong class="bold">Categorical/ordinal data</strong> adds a sense of order to a labeled variable (for example, education level or employee <span class="No-Break">title level).</span></li>
			</ul>
			<p>In other words, when choosing an algorithm for your project, you should ask yourself: <em class="italic">do I have a target variable? Does it store categorical or numerical data?</em> Answering these questions will put you in a better <a id="_idTextAnchor053"/>position to choose a potential algorithm that will solve <span class="No-Break">your problem.</span></p>
			<p>However, what if you don’t have a target variable? In that case, you are facing an unsupervised learning problem. Unsupervised problems do not provide labeled data; instead, they provide all the independent variables (or features) that will allow unsupervised algorithms to find patterns in the data. The most common type of unsupervised learning is <strong class="bold">clustering</strong>, which aims to group the <a id="_idTextAnchor054"/>observations of the dataset into different clusters, purely based on their features. Observations from the same cluster are expected to be similar to each other, but very different from observations from other clusters. Clustering will be covered in more detail in future chapters of <span class="No-Break">this book.</span></p>
			<p><strong class="bold">Semi-supervised learning</strong> is also present in<a id="_idTextAnchor055"/> the ML literature. This type of algorithm can learn from partially labeled data (some observations contain a label and others <span class="No-Break">do not).</span></p>
			<p>Finally, another learning approach that has been taken by another class of ML algorithms is <strong class="bold">reinforcement learning</strong>. This approach rewards the system based on the good decisions that it has made autonomously; in other<a id="_idTextAnchor056"/> words, the system learns <span class="No-Break">by experience.</span></p>
			<p>You have been learning about approaches and classes of algorithms at a very broad level. However, it is time to get <a id="_idTextAnchor057"/>specific and introduce the <span class="No-Break">term </span><span class="No-Break"><strong class="bold">model</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor058"/><a id="_idTextAnchor059"/>The CRISP-DM modeling life cycle</h1>
			<p><strong class="bold">Modeling</strong> is a very common term <a id="_idTextAnchor060"/>used in ML when you want to specify the steps taken to solve a particular problem. For example, you could create a binary classification model to predict <a id="_idTextAnchor061"/>whether the transactions from <em class="italic">Table 1.1</em> are fraudulent <span class="No-Break">or not.</span></p>
			<p>A model, in this context, represents <a id="_idTextAnchor062"/>all the steps to create a solution as a whole, which includes (but is not limited to) the algorithm. The <strong class="bold">Cross-Industry Standard Process for Data Mining</strong>, more commonly referred to as <strong class="bold">CRISP-DM</strong>, is one of the methodologies that provides guidance on the common steps that you should follow to create models. This methodology is widely used by the market and is covered in the AWS Machine Learning <span class="No-Break">Specialty exam:</span></p>
			<div>
				<div id="_idContainer012" class="IMG---Figure">
					<img src="image/B21197_01_03.jpg" alt="Figure 1.3 – CRISP-DM methodology" width="1552" height="1012"/>
				</div>
			</div>
			<p class="IMG---Figure"><a id="_idTextAnchor063"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – CRISP-DM methodology</p>
			<p>Everything starts with business understanding, which will produce the business objectives (including success criteria), situation assessment, data mining goals, and project plan (with an initial assessment of tools and techniques). During the situation assessment, you should also look into a<a id="_idTextAnchor064"/>n inventory of resources, requirements, assumptions and constraints, risks, terminology, costs, and benefits. Every single assumption and success criterion matters when you <span class="No-Break">are modeling.</span></p>
			<p>The next step is known as data understanding, where you will collect raw data, describe it, explore it, and check its quality. This is an initial assessment of the data that will be used to create the model. Again, data scientists must be skeptical. You must be sure you understand all the nuances of the data and <span class="No-Break">its source.</span></p>
			<p>The data preparation phase is actually the one that usually consumes most of the time during modeling. In this phase, you need to select and filter the data, clean it according to the task that needs to be performed, come up with new attributes, integrate the data with other data sources, and format it as expected by the algorithm that will be applied. These tasks are often <a id="_idTextAnchor065"/>called <span class="No-Break"><strong class="bold">feature engineering</strong></span><span class="No-Break">.</span></p>
			<p>Once the data is prepared, you can finally start the modeling phase. Here is where the algorithms come in. You should s<a id="_idTextAnchor066"/>tart by ensuring the selection of the right technique. Remember: according to the presence or absence of a target variable (and its data type), you will have different algorithms to choose from. Each modeling technique might carry some implicit assumptions of which you have to be aware. For example, if you choose a multiple linear regression algorithm to predict house prices, you should be aware that this type of model expects a linear relationship between the variables of <span class="No-Break">your data.</span></p>
			<p>There are hundreds of algorithms out there and each of them might have its own assumptions. After choosing the ones that you want to test in your project, you should spend some time checking their specifics. In later chapters of this book, you will learn about some <span class="No-Break">of them.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Some algorithms incorporate in their l<a id="_idTextAnchor067"/>ogic a sub-process known as <strong class="bold">feature selection</strong>. This is a step where the most important features will be selected to build your best model. Decision trees are examples of algorithms that perform feature selection automatically. You will learn about feature selection in more detail later on, since there are different ways to select the best variables for <span class="No-Break">your model.</span></p>
			<p>During the modeling phase, you should also design a testing approach for the model, defining which evaluation metrics will be used and how the data will be split. With that in place, you can finally build the model by setting the hyperparameters of the algorithm and feeding the model with data. This process of feeding the algorithm with data to find a good estimator is known as the <strong class="bold">training process</strong>. The data used to f<a id="_idTextAnchor068"/>eed the model is known as <strong class="bold">training data</strong>. There are d<a id="_idTextAnchor069"/>ifferent ways to <a id="_idTextAnchor070"/>organize the training and <strong class="bold">testing data</strong>, which you will learn about in <span class="No-Break">this chapter.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">ML algorithms are built of parameters and hyperparameters. Parameters are learned from the data; for example: a decision-tree-based algorithm might learn from the training data that a particular feature should compose its root level based on information gain assessments. Hyperparameters, on the other hand, are used to control the learning process. Taking the same example about decision trees, you could specify the maximum allowed depth of the tree (regardless of the training data). Hyperparameter tuning is a very important topic in the exam and will be covered in fine-grained detail <span class="No-Break">later on.</span></p>
			<p>Once the model is trained, you can evaluate and review the results in order to propose the next steps. If the results are not acceptable (based on business success criteria), you should go back to earlier steps to check what else can be done to improve the model’s results. It could either be the subtle tuning of the hyperparameters of the algorithm, a new data preparation step, or even the redefinition of business drivers. On the other hand, if the model quality is acceptable, you can move on to the <span class="No-Break">deployment phase.</span></p>
			<p>In this last phase of the CRISP-DM methodology, you have to think about the deployment plan, monitoring, and maintenance of the model. You can look at this step from two perspectives: training and inference. The <strong class="bold">training pipeline</strong> consists of those steps needed to train the model, which <a id="_idTextAnchor071"/>include data preparation, hyperparameter definition, data splitting, and model training itself. Somehow, you must store all the model artifacts somewhere, since they will be used by the next pipeline that needs to be d<a id="_idTextAnchor072"/>eveloped: the <span class="No-Break"><strong class="bold">inference pipeline</strong></span><span class="No-Break">.</span></p>
			<p>The inference pipeline just uses <a id="_idTextAnchor073"/>model artifacts to execute the model against brand-new observations (data that has never been seen by the model during the training phase). For example, if the model was trained to identify fraudulent transactions, this is the time when new transactions will pass through the model to <span class="No-Break">be classified.</span></p>
			<p>In general, models are trained once (through the training pipeline) and executed many times (through the inference pipeline). However, after some time, it is expected that there will be some model d<a id="_idTextAnchor074"/>egradation, also known as <strong class="bold">model drift</strong>. This phenomenon happens because the model is usually trained in a static training set that aims to represent the business scenario at a given point in time; however, businesses evolve, and it might be necessary to retrain the model on more recent data to capture new business aspects. That’s why it is important to keep tracking model performance even after <span class="No-Break">model deployment.</span></p>
			<p>The CRISP-DM methodology is so important to the context of the AWS Machine Learning Specialty exam that, if you look at the four domains covered by AWS, you will realize that they were generalized from the CRISP-DM stages: data engineering, exploratory data analysis, modeling, and ML implementation <span class="No-Break">and operations.</span></p>
			<p>You now understand all the key <a id="_idTextAnchor075"/>stages of a modeling pipeline and you know that the algorithm itself is just part of a larger process! Next, you will see how to split your data to create and validate <span class="No-Break">ML models.</span></p>
			<h1 id="_idParaDest-23">D<a id="_idTextAnchor076"/><a id="_idTextAnchor077"/>ata splitting</h1>
			<p>Training and evaluating ML models are key tasks of the modeling pipeline. ML algorithms need data to find relationships among features in order to make inferences, but those inferences need to be validated before they are moved to <span class="No-Break">production environments.</span></p>
			<p>The dataset used to train ML m<a id="_idTextAnchor078"/>odels is commonly called the training set. This training data must be able to represent the real environment where the model will be used; it will be useless if that requirement is <span class="No-Break">not met.</span></p>
			<p>Coming back to the fraud example presented in <em class="italic">Table 1.1</em>, based on the training data, you found that e-commerce transactions with a value greater than $5,000 and processed at night are potentially fraudulent cases. With that in mind, after applying the model in a production environment, the model is supposed to flag similar cases, as learned during the <span class="No-Break">training process.</span></p>
			<p>Therefore, if those cases only exist in the training set, the model will flag <strong class="bold">false positive</strong> cases in production environments. The opposite s<a id="_idTextAnchor079"/>cenario is also true: if there is a particular fraud case in production data, not reflected in the training data, the model will flag a lot of <strong class="bold">false negative</strong> cases. False p<a id="_idTextAnchor080"/>ositive and false negative ratios are just two of many quality metrics that you can use for model validation. These metrics will be covered in much more detail <span class="No-Break">later on.</span></p>
			<p>By this point, you should have a clear understanding of the importance of having a good training set. Now, supposing you do have a valid training set, how could you have some level of confidence that this model will perform well in production environments? The answer is by using testing and <span class="No-Break">validation sets:</span></p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B21197_01_04.jpg" alt="Figure 1.4 – Data splitting" width="1480" height="347"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor081"/>Figure 1.4 – Data splitting</p>
			<p><span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.4</em> shows the different types of data splitting that you can have during training and inference pipelines. The training data is u<a id="_idTextAnchor082"/>sed to create the model; the testing data is used to extract the final model quality metrics. The testing data <em class="italic">cannot</em> be used during the training process for any reason other than to extract <span class="No-Break">model metrics.</span></p>
			<p>The reason to avoid using the t<a id="_idTextAnchor083"/>esting data during training is simple: you <em class="italic">cannot</em> let the model learn on top of the data that will be used to validate it. This technique of holding one piece of<a id="_idTextAnchor084"/> the data for testing is often called <span class="No-Break"><strong class="bold">hold-out validation</strong></span><span class="No-Break">.</span></p>
			<p>The box on the right side of <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.4</em> represents the pr<a id="_idTextAnchor085"/>oduction data. Production data usually comes in continuously and you have to execute the inference pipeline in order to extract model results from it. No training, nor any other type of recalculation, is performed on top of production data; you just have to pass it through the inference pipeline as <span class="No-Break">it is.</span></p>
			<p>From a technical perspective, most ML libraries implement training steps with the <strong class="source-inline">.fit</strong> method, while inference steps are implemented by the <strong class="source-inline">.transform</strong> <em class="italic">or</em> <strong class="source-inline">.predict</strong> method. Again, this is just a common pattern used by most ML libraries, but be aware that you might find different name conventions across <span class="No-Break">ML libraries.</span></p>
			<p>Still looking at <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.4</em>, there is another box, close to th<a id="_idTextAnchor086"/>e training data, named <strong class="bold">Validation data</strong>. This is a subset of the training set often used to support the creation of the best model, before moving on to the testing phase. You will learn about validation sets in much more detail, but first, you should understand why you <span class="No-Break">need them.</span></p>
			<h2 id="_idParaDest-24">Ov<a id="_idTextAnchor087"/><a id="_idTextAnchor088"/>erfitting and underfitting</h2>
			<p>ML models might suffer from two types of fitting issues: <strong class="bold">overfitting</strong> and <strong class="bold">underfitting</strong>. Overfitting means that your model performs very well on the training data but cannot be generalized to other datasets, such as testing and, even worse, production data. In other words, if you have an ov<a id="_idTextAnchor089"/>erfitted model, it only works on your <span class="No-Break">training data.</span></p>
			<p>When you are building ML models, you want to create solutions that are able to generalize what they have learned and infer decisions on other datasets that follow the same data distribution. A model that on<a id="_idTextAnchor090"/>ly works on the data that it was trained on is useless. Overfitting usually happens due to the large number of features or the lack of configuration of the hyperparameters of <span class="No-Break">the algorithm.</span></p>
			<p>On the other hand, underfitted models cannot fit the data during the training phase. As a result, they are so generic that they can’t perform well within the training, testing, or production data. Underfitting usually happens due to the lack of good features/observations or due to the lack of time to train the model (some algorithms need more iterations to properly fit <span class="No-Break">the model).</span></p>
			<p>Both overfitting and underfitting need to be avoided. There are many modeling techniques to work around them. For instance, you will learn about the commonly used <strong class="bold">cross-validation</strong> technique and its relationship with the validation data box shown in <span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-25">Ap<a id="_idTextAnchor091"/><a id="_idTextAnchor092"/>plying cross-validation and measuring overfitting</h2>
			<p>Cross-validation is a technique wh<a id="_idTextAnchor093"/>ere you split the training set into training and validation sets. The model is then trained on the training set and tested on the validation set. The most common cr<a id="_idTextAnchor094"/>oss-validation strategy is kn<a id="_idTextAnchor095"/>own as <strong class="bold">k-fold cross-validation</strong>, where <em class="italic">k</em> is the number of splits of the <span class="No-Break">training set.</span></p>
			<p>Using k-fold cross-validation and assuming the value of <em class="italic">k</em> equals 10, you are splitting the training set into 10 folds. The model will be trained and tested 10 times. On each iteration, it uses 9 splits for training and leaves one split for testing. After 10 executions, the evaluation metrics extracted from each iteration are averaged and will represent the final model performance during the training phase, as shown in <span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B21197_01_05.jpg" alt="Figure 1.5 – Cross-validation in action" width="1650" height="1013"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">F<a id="_idTextAnchor096"/>igure 1.5 – Cross-validation in action</p>
			<p>Another common cross-validation technique is known as <strong class="bold">leave-one-out cross-validation</strong> (<strong class="bold">LOOCV</strong>). In this approach, the model is exe<a id="_idTextAnchor097"/>cuted many ti<a id="_idTextAnchor098"/>mes and, within each iteration, one observation is separated for testing and all the others are used <span class="No-Break">for training.</span></p>
			<p>There are many advantages of using cr<a id="_idTextAnchor099"/>oss-validation <span class="No-Break">during training:</span></p>
			<ul>
				<li>You mitigate overfitting in the training data since the model is always trained on a particular chunk of data and tested on another chunk that hasn’t been used <span class="No-Break">for training.</span></li>
				<li>You avoid overfitting in the test data since there is no need to keep using the testing data to optimize <span class="No-Break">the model.</span></li>
				<li>You expose the presence of overfitting or underfitting. If the model performance in the training/validation data is very different from the performance observed in the testing data, something <span class="No-Break">is wrong.</span></li>
			</ul>
			<p>It might be worth diving into the third item on that list since it is widely covered in the AWS Machine Learning Specialty ex<a id="_idTextAnchor100"/>am. For instance, assume you are creating a binary classification model, using cross-validation during training, and using a testing set to extract final metrics (hold-out validation). If you get 80% accuracy in the cross-validation results and 50% accuracy in the testing set, it means that the model was overfitted to the training set<a id="_idTextAnchor101"/>, and so cannot be generalized to the <span class="No-Break">testing set.</span></p>
			<p>On the other hand, if you get 50% accuracy in the training set and 80% accuracy in the testing set, there is a systemic issue in the data. It is very likely that the training and testing sets do not follow the <span class="No-Break">same distribution.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Accuracy is a model evaluation metric commonly used on classification models. It measures how often the model made a correct decision during its inference process. That metric was selected just for the sake of dem<a id="_idTextAnchor102"/>onstration, but be aware that there are many other evaluation metrics applicable for each type of model (which will be covered at the <span class="No-Break">appropriate time).</span></p>
			<h2 id="_idParaDest-26">Boo<a id="_idTextAnchor103"/><a id="_idTextAnchor104"/>tstrapping methods</h2>
			<p>Cross-validation is a good strategy to validate ML models, and you should try it in your daily activities as a data sci<a id="_idTextAnchor105"/>entist. However, you should also know about other resampling techniques available out there. <strong class="bold">Bootstrapping</strong> is one <span class="No-Break">of them.</span></p>
			<p>While cross-validation works <em class="italic">with no replacement</em>, a bootstrapping approach works <em class="italic">with replacement</em>. With replacement me<a id="_idTextAnchor106"/>ans that, while you are drawing multiple random samples from a population dataset, the same observation might be duplicated <span class="No-Break">across samples.</span></p>
			<p>Usually, bootstrapping is not used to val<a id="_idTextAnchor107"/>idate models as you do in the traditional cross-validation approach. The reason is simple: since it works with replacement, the same observation used for training could potentially be used for testing, too. This would result in inflated model performance metrics since the estimator is likely to be correct when predicting an observation that was already seen in the <span class="No-Break">training set.</span></p>
			<p>Bootstrapping is often use<a id="_idTextAnchor108"/>d by ML algorithms in an embedded way that requires resampling capabilities to process the data. In this context, bootstrapping is not used to <em class="italic">validate</em> the model but to <em class="italic">create</em> the model. <strong class="bold">Random forest</strong>, which will be covered in <em class="italic"> </em><a href="B21197_06.xhtml#_idTextAnchor708"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><em class="italic">, Applying Machine Learning Algorithms</em>, is one of those algorithms that use bootstrapping internally for <span class="No-Break">model building.</span></p>
			<p>Designing a good dat<a id="_idTextAnchor109"/>a splitting/sampling strategy is crucial to the success of the<a id="_idTextAnchor110"/> model or the algorithm. You should come up with different approaches to split your data, check how the model is performing on each split, and make sure those splits represent the real scenario where the model will <span class="No-Break">be used.</span></p>
			<h2 id="_idParaDest-27">The<a id="_idTextAnchor111"/><a id="_idTextAnchor112"/> variance versus bias trade-off</h2>
			<p>Any ML model is supposed to contain errors. There are th<a id="_idTextAnchor113"/>ree types of errors that you can find in models: <strong class="bold">bias</strong> errors, <strong class="bold">variance</strong> errors, and <strong class="bold">unexplained</strong> errors. The last one, as ex<a id="_idTextAnchor114"/>pected, cannot be explained. It is often related to the context of the problem and the relationships between the variables (you can’t <span class="No-Break">control it).</span></p>
			<p>The other two types of errors can be controlled during modeling. You can say that there is a trade-off between bias and variance errors because one will influence the other. In this case, increasing bias will decrease variance and <span class="No-Break">vice versa.</span></p>
			<p>Bias errors relate to assumptions ta<a id="_idTextAnchor115"/>ken by the model to learn the target function, the one that you want to solve. Some types of algorithms, such as linear algorithms, usually carry over that type of error because they make a lot of assumptions during model training. For example, linear models assume that the relationship present in the data is linear. Linear regression and logistic regression are types of algorithms that, in general, contain high bias. Decision trees, on the other hand, are types of algorithms that make fewer assumptions about the data and contain <span class="No-Break">less bias.</span></p>
			<p>Variance relates to the difference in estimations that the model performs on different training data. Models with high variance usually overfit the training set. Decision trees are examples of algorithms with high variance (they usually rely a lot on specifics of the training set, failing to generalize), and linear and logistic regression are examples of algorithms with low variance. It does not mean that decision trees are bad estimators; it just means that you need to prune (optimize) them <span class="No-Break">during training.</span></p>
			<p>That being said, the goal of any model is to minimize both bias and variance. However, as already mentioned, each one will impact the other in the opposite direction. For the sake of demonstration, consider a decision tree to understand how this <span class="No-Break">trade-off works.</span></p>
			<p>Decision trees are no<a id="_idTextAnchor116"/>nlinear algorithms and often contain low bias and high variance. In order to decrease variance, you can prune the tree and set the <strong class="source-inline">max_depth</strong> hyperparameter (the maximum allowed depth of the tree) to 10. That will force a more generic model, reducing variance. However, that change will also force the model to make more assumptions (since it is now more generic) and <span class="No-Break">increase bias.</span></p>
			<h2 id="_idParaDest-28">Shu<a id="_idTextAnchor117"/><a id="_idTextAnchor118"/>ffling your training set</h2>
			<p>Now that you know what va<a id="_idTextAnchor119"/>riance and data splitting are, you can go a little deeper into the training dataset requirements. You are very likely to find questions around data shuffling in the exam. This process consists of randomizing your training dataset before you start using it to fit <span class="No-Break">an algorithm.</span></p>
			<p>Data shuffling will help the algorithm to reduce variance by creating a more generalizable model. For example, let’s say your training represents a binary classification problem and it is sorted by the target variable (all cases belonging to class “0” appear first, then all the cases belonging to <span class="No-Break">class “1”).</span></p>
			<p>When you fit an algorithm on this sorted data (especially some algorithms that rely on <strong class="bold">batch processing</strong>), it will make strong as<a id="_idTextAnchor120"/>sumptions about the pattern of one of the classes, since it is very likely that it won’t be able to create random batches of data with a good representation of both classes. Once the algorithm builds strong assumptions about the training data, it might be difficult for it to <span class="No-Break">change them.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Some algorithms are able to execute the training process by fitting the data in chunks, also known as batches. This approach lets the mo<a id="_idTextAnchor121"/>del learn more frequently since it will make partial assumptions after processing each batch of data (instead of making decisions only after processing the <span class="No-Break">entire dataset).</span></p>
			<p>On the other hand, there is no need to shuffle the testing set, since it will be used only by the inference process to check <span class="No-Break">model performance.</span></p>
			<h1 id="_idParaDest-29">Mod<a id="_idTextAnchor122"/><a id="_idTextAnchor123"/>eling expectations</h1>
			<p>So far, you have learned about model building, validation, and management. You can now complete the foundations of ML by learning about a couple of other expectations <span class="No-Break">while modeling.</span></p>
			<p>The first one is <strong class="bold">parsimony</strong>. Parsimony describes mo<a id="_idTextAnchor124"/>dels that offer the simplest explanation and fit the best results when compared with other models. Here’s an example: while creating a linear regression model, you realize that adding 10 more features will improve your model’s performance by 0.001%. In this scenario, you should consider whether this performance improvement is worth the cost of parsimony (since your model will become more complex). Sometimes it is worth it, but most of the time it is not. You need to be skeptical and think according to your <span class="No-Break">business case.</span></p>
			<p>Parsimony directly su<a id="_idTextAnchor125"/>pports <strong class="bold">interpretability</strong>. The simpler your model is, the easier it is to explain it. However, there is a battle between in<a id="_idTextAnchor126"/>terpretability and <strong class="bold">predictivity</strong>: if you focus on predictive power, you are likely to lose some interpretability. Again, you must select what is the best situation for your <span class="No-Break">use case.</span></p>
			<h1 id="_idParaDest-30">Int<a id="_idTextAnchor127"/><a id="_idTextAnchor128"/>roducing ML frameworks</h1>
			<p>Being aware of some ML frameworks wi<a id="_idTextAnchor129"/>ll put you in a much better position to pass the AWS Machine Learning Specialty exam. There is no need to master these frameworks since this is not a framework-specific certification; however, knowing some common terms and solutions will help you to understand the context of <span class="No-Break">the problems/questions.</span></p>
			<p><strong class="bold">scikit-learn</strong> is probably the most popular ML <a id="_idTextAnchor130"/>framework that you should be aware of. It is an open source Python package that provides implementations of ML algorithms such as decision trees, support vector machines, linear regression, and many others. It also implements classes for data preprocessing, for example, one-hot encoding, label encoders, principal component analysis, and so on. All these preprocessing methods (and many others) will be covered in later sections of <span class="No-Break">this book.</span></p>
			<p>The downside of scikit-learn is the fact that it needs customization to scale up through multiple machines. There is another ML library that is very popular because of the fact that it can handle multiprocessing str<a id="_idTextAnchor131"/>aight away: <strong class="bold">Spark’s </strong><span class="No-Break"><strong class="bold">ML library</strong></span><span class="No-Break">.</span></p>
			<p>As the name suggests, it is an ML library that ru<a id="_idTextAnchor132"/>ns on top of <strong class="bold">Apache Spark</strong>, which is a unified analytical multi-processing framework used to process data on multiple machines. AWS offers a specific service that allows developers to create Spark clusters with a few cli<a id="_idTextAnchor133"/>cks, known as <strong class="bold">EMR</strong>. Additionally, SageMaker (a fully managed ML service provided by AWS, which you will cover in a separate chapter) is well integrated with <span class="No-Break">Apache Spark.</span></p>
			<p>The Spark ML library is in constant development. As of the time of writing, it offers support to many ML classes of algorithms, such as classification and regression, clustering, and co<a id="_idTextAnchor134"/>llaborative filtering. It also offers support for basic statistics computation, such as correlations and some hypothesis tests, as well as many data transformations, such as one-hot encoding, principal component analysis, min-max scaling, <span class="No-Break">and others.</span></p>
			<p>Another very popular ML fra<a id="_idTextAnchor135"/>mework is known as <strong class="bold">TensorFlow</strong>. This ML framework was created by the Google team and it is used for numerical computation and large-scale ML model development. TensorFlow implements not only traditional ML algorithms but also <span class="No-Break">DL models.</span></p>
			<p>TensorFlow is considered a low-level API for model development, which means that it can be very complex to develop more sop<a id="_idTextAnchor136"/>histicated models, such as <strong class="bold">transformers</strong> (for text mining). As an attempt to facilitate model development, other ML frameworks were built on top of TensorFlow to make it easier. One of these high-level frameworks is <strong class="bold">Keras</strong>. With Keras, developers can cr<a id="_idTextAnchor137"/>eate complex DL models with just a few lines of code. More recently, Keras was incorporated into TensorFlow and it can be now called inside the <span class="No-Break">TensorFlow library.</span></p>
			<p><strong class="bold">MXNet</strong> is another open source DL<a id="_idTextAnchor138"/> library. Using MXNet, you can scale up neural network-based models using multiple GPUs running on multiple machines. It also supports different programming languages, such as Python, R, Scala, <span class="No-Break">and Java.</span></p>
			<p><strong class="bold">Graphical processing unit</strong> (<strong class="bold">GPU</strong>) support is particularly im<a id="_idTextAnchor139"/>portant in DL libraries such as TensorFlow and MXNet. These libraries allow developers to create and deploy neural network-based models with multiple layers. The training process of neural networks relies a lot on matrix operations, which perform much better on GPUs rather than on CPUs. That’s why these DL libraries commonly offer GPU support. AWS also offers EC2 instances with <span class="No-Break">GPU enabled.</span></p>
			<p>These ML frameworks need a special channel to communicate with GPU units. NVIDIA, the most common supplier of GPUs nowadays, has created an API called the <strong class="bold">Compute Unified Device Architecture</strong> (<strong class="bold">CUDA</strong>). CUDA is used to co<a id="_idTextAnchor140"/>nfigure GPU units on NVIDIA devices; for example, setting up caching memory and the number of threads needed to train a neural network model. There is no need to master CUDA or GPU architecture for the AWS Machine Learning Specialty exam, but you definitely need to know what they are and ho<a id="_idTextAnchor141"/>w DL models take advantage <span class="No-Break">of them.</span></p>
			<p>Last, but not least, you should also be aware of some development frameworks widely used by the data science community, but not necessarily to create ML models. These frameworks interoperate with ML libraries to facilitate data manipulation and calculations. For example: <strong class="bold">pandas</strong> is a Python library that pro<a id="_idTextAnchor142"/>vides data processing capabilities and <strong class="bold">NumPy</strong> is an open source Py<a id="_idTextAnchor143"/>thon library that provides <span class="No-Break">numerical computing.</span></p>
			<p>These terms and libraries are so incorporated into data scientists’ daily routines that they might come up during the exam to explain some problem domain for you. Being aware of what they are will help you to quickly understand the context of <span class="No-Break">the question.</span></p>
			<h1 id="_idParaDest-31">ML <a id="_idTextAnchor144"/><a id="_idTextAnchor145"/>in the cloud</h1>
			<p>ML has gone to the cloud and developers can now use it as a service. AWS has implemented ML services at di<a id="_idTextAnchor146"/>fferent levels of abstraction. ML application services, for example, aim to offer out-of-the-box solutions for specific problem domains. <strong class="bold">AWS Lex</strong> is a very cl<a id="_idTextAnchor147"/>ear example of an ML application as a service, where people can implement chatbots with <span class="No-Break">minimum development.</span></p>
			<p><strong class="bold">AWS Rekognition</strong> is another example, which ai<a id="_idTextAnchor148"/>ms to identify objects, people, text, scenes, and activities in images and videos. AWS provides many other ML application services, which will be covered in the next chapter of <span class="No-Break">this book.</span></p>
			<p>Apart from application services, AWS also pro<a id="_idTextAnchor149"/>vides ML development platforms, such as <strong class="bold">SageMaker</strong>. Unlike out-of-the-box services such as AWS Lex and Rekognition, SageMaker is a development platform that will let you build, train, and deploy your own models with much <span class="No-Break">more flexibility.</span></p>
			<p>SageMaker speeds up the de<a id="_idTextAnchor150"/>velopment and deployment process by automatically handling the necessary infrastructure for the training and inference pipelines of your models. Behind the scenes, SageMaker orchestrates other AWS services (such as EC2 instances, load balancers, auto-scaling, and so on) to create a scalable environment for ML projects. SageMaker is probably the most important service that you should master for the AWS Machine Learning Specialty exam, and it will be covered in detail in a separate section. For now, you should focus on understanding the different approaches that AWS uses to offer <span class="No-Break">ML-related services.</span></p>
			<p>The third option that AW<a id="_idTextAnchor151"/>S offers for deploying ML models is the most generic and flexible one: you can deploy ML models by combining different AWS services and managing them individually. This essentially does what SageMaker does for you, building your applications from scratch. For example, you could use EC2 instances, load balancers, auto-scaling, and an API gateway to create an inference pipeline for a pa<a id="_idTextAnchor152"/>rticular model. If you prefer, you can also use AWS serverless architecture to deploy your solution, for example, using <strong class="bold">AWS </strong><span class="No-Break"><strong class="bold">Lambda functions</strong></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-32">Sum<a id="_idTextAnchor153"/><a id="_idTextAnchor154"/>mary</h1>
			<p>You are now heading toward the end of this chapter, in which you have learned about several important topics regarding the foundations of ML. You started the chapter with a theoretical discussion about AI, ML, and DL, and how this entire field has grown over the past few years due to the advent of big data platforms, cloud providers, and <span class="No-Break">AI applications.</span></p>
			<p>You then moved on to the differences between supervised, unsupervised, and reinforcement learning, highlighting some use cases related to each of them. This is likely to be a topic in the AWS Machine Learning <span class="No-Break">Specialty exam.</span></p>
			<p>You learned that an ML model is built in many different stages and the algorithm itself is just one part of the modeling process. You also learned about the expected behaviors of a <span class="No-Break">good model.</span></p>
			<p>You did a deep dive into data splitting, where you learned about different approaches to train and validate models, and you became aware of the mythic battle between variance and bias. You completed the chapter by getting a sense of ML frameworks <span class="No-Break">and services.</span></p>
			<p>Coming up next, you will learn about AWS application services for ML, such as Amazon Polly, Amazon Rekognition, Amazon Transcribe, and many other AI-related AWS services. But first, look at some sample questions to give you an idea of what you can expect in <span class="No-Break">the exam.</span></p>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor155"/>Exam Readiness Drill – Chapter Review Questions</h1>
			<p>Apart from a solid understanding of key concepts, being able to think quickly under time pressure is a skill that will help you ace your certification exam. That is why working on these skills early on in your learning journey <span class="No-Break">is key.</span></p>
			<p>Chapter review questions are designed to improve your test-taking skills progressively with each chapter you learn and review your understanding of key concepts in the chapter at the same time. You’ll find these at the end of <span class="No-Break">each chapter.</span></p>
			<p class="callout-heading">How To Access These Resources</p>
			<p class="callout">To learn how to access these resources, head over to the chapter titled <a href="B21197_11.xhtml#_idTextAnchor1477"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Accessing the Online </em><span class="No-Break"><em class="italic">Practice Resources</em></span><span class="No-Break">.</span></p>
			<p>To open the Chapter Review Questions for this chapter, perform the <span class="No-Break">following steps:</span></p>
			<ol>
				<li>Click the link – <a href="https://packt.link/MLSC01E2_CH01"><span class="No-Break">https://packt.link/MLSC01E2_CH01</span></a><span class="No-Break">.</span><p class="list-inset">Alternatively, you can scan the following <strong class="bold">QR code</strong> (<span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">):</span></p></li>
			</ol>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B21197_01_06.jpg" alt="Figure 1.6 – QR code that opens Chapter Review Questions for logged-in users" width="550" height="150"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.6 – QR code that opens Chapter Review Questions for logged-in users</p>
			<ol>
				<li value="2">Once you log in, you’ll see a page similar to the one shown in <span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B21197_01_07.jpg" alt="Figure 1.7 – Chapter Review Questions for Chapter 1" width="1426" height="858"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.7 – Chapter Review Questions for Chapter 1</p>
			<ol>
				<li value="3">Once ready, start the following practice drills, re-attempting the quiz <span class="No-Break">multiple times.</span></li>
			</ol>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor156"/>Exam Readiness Drill</h2>
			<p>For the first three attempts, don’t worry about the <span class="No-Break">time limit.</span></p>
			<h3 id="_idParaDest-35"><a id="_idTextAnchor157"/>ATTEMPT 1</h3>
			<p>The first time, aim for at least <strong class="bold">40%</strong>. Look at the answers you got wrong and read the relevant sections in the chapter again to fix your <span class="No-Break">learning gaps.</span></p>
			<h3 id="_idParaDest-36"><a id="_idTextAnchor158"/>ATTEMPT 2</h3>
			<p>The second time, aim for at least <strong class="bold">60%</strong>. Look at the answers you got wrong and read the relevant sections in the chapter again to fix any remaining <span class="No-Break">learning gaps.</span></p>
			<h3 id="_idParaDest-37"><a id="_idTextAnchor159"/>ATTEMPT 3</h3>
			<p>The third time, aim for at least <strong class="bold">75%</strong>. Once you score 75% or more, you start working on <span class="No-Break">your timing.</span></p>
			<p class="callout-heading">Tip</p>
			<p class="callout">You may take more than <strong class="bold">three</strong> attempts to reach 75%. That’s okay. Just review the relevant sections in the chapter till you <span class="No-Break">get there.</span></p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor160"/>Working On Timing</h1>
			<p>Target: Your aim is to keep the score the same while trying to answer these questions as quickly as possible. Here’s an example of how your next attempts should <span class="No-Break">look like:</span></p>
			<table id="table003" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Attempt</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Score</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Time Taken</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 5</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">77%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>21 mins <span class="No-Break">30 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 6</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">78%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>18 mins <span class="No-Break">34 seconds</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Attempt 7</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">76%</span></p>
						</td>
						<td class="No-Table-Style">
							<p>14 mins <span class="No-Break">44 seconds</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.3 – Sample timing practice drills on the online platform</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The time limits shown in the above table are just examples. Set your own time limits with each attempt based on the time limit of the quiz on <span class="No-Break">the website.</span></p>
			<p>With each new attempt, your score should stay above <strong class="bold">75%</strong> while your “time taken” to complete should “decrease”. Repeat as many attempts as you want till you feel confident dealing with the <span class="No-Break">time pressure.</span></p>
		</div>
	</div>
</div>
</body></html>