- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Designing and Implementing Large-Scale, Robust ML Software
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计和实现大规模、健壮的机器学习软件
- en: So far, we have learned how to develop ML models, how to work with data, and
    how to create and test the entire ML pipeline. What remains is to learn how we
    can integrate these elements into a **user interface** (**UI**) and how to deploy
    it so that they can be used without the need to program. To do so, we’ll learn
    how to deploy the model complete with a UI and the data storage for the model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何开发机器学习模型，如何处理数据，以及如何创建和测试整个机器学习管道。剩下的是学习如何将这些元素集成到**用户界面**（**UI**）中，以及如何部署它，以便它们可以在不编程的情况下使用。为此，我们将学习如何部署包含UI和数据存储的模型。
- en: In this chapter, we’ll learn how to integrate the ML model with a graphical
    UI programmed in Gradio and storage in a database. We’ll use two examples of ML
    pipelines – an example of the model for predicting defects from our previous chapters
    and a generative AI model to create pictures from a natural language prompt.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将机器学习模型与使用Gradio编写的图形用户界面以及数据库中的存储集成。我们将使用两个机器学习管道的示例——一个是从我们之前章节中预测缺陷的模型示例，以及一个从自然语言提示创建图片的生成式AI模型。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: ML is not alone – elements of a deployed ML-based system
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习并非孤立存在——基于机器学习的部署系统元素
- en: The UI of an ML model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型的UI
- en: Data storage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储
- en: Deploying an ML model for numerical data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署用于数值数据的机器学习模型
- en: Deploying a generative ML model for images
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署用于图像的生成式机器学习模型
- en: Deploying a code completion model as an extension to Visual Studio Code
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将代码补全模型作为Visual Studio Code的扩展部署
- en: ML is not alone
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习并非孤立存在
- en: '[*Chapter 2*](B19548_02.xhtml#_idTextAnchor023) introduced several elements
    of an ML system – storage, data collection, monitoring, and infrastructure, just
    to name a few of them. We need all of them to deploy a model for the users, but
    not all of them are important for the users directly. We need to remember that
    the users are interested in the results, but we need to pay attention to all details
    related to the development of such systems. These activities are often called
    AI engineering.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第二章*](B19548_02.xhtml#_idTextAnchor023)介绍了机器学习系统的几个元素——存储、数据收集、监控和基础设施，仅举几个例子。我们需要所有这些来为用户部署模型，但并非所有这些对用户直接重要。我们需要记住，用户对结果感兴趣，但我们需要注意与这些系统开发相关的所有细节。这些活动通常被称为AI工程。'
- en: The UI is important as it provides the ability to access our models. Depending
    on the use of our software, the interface can be different. So far, we’ve focused
    on the models themselves and on the data that is used to train the models. We
    have not focused on the usability of models and how to integrate them into the
    tools.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: UI很重要，因为它提供了访问我们模型的能力。根据我们软件的使用情况，界面可以不同。到目前为止，我们关注的是模型本身以及用于训练模型的数据。我们还没有关注模型的可用性以及如何将它们集成到工具中。
- en: By extension, as for the UI, we also need to talk about storing data in ML.
    We can use **comma-separated values** (**CSV**) files, but they quickly become
    difficult to handle. They are either too large to read into memory or too cumbersome
    for version control and exchanging data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过扩展，对于UI，我们还需要讨论在机器学习中存储数据。我们可以使用**逗号分隔值**（**CSV**）文件，但它们很快就会变得难以处理。它们要么太大，无法读入内存，要么过于繁琐，不适合版本控制和数据交换。
- en: Therefore, in this chapter, we’ll focus on making the ML system usable. We’ll
    learn how to develop a UI, how to link the system to the database, and how to
    design a Visual Studio Code extension that can complete code in Python.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们将专注于使机器学习系统可用。我们将学习如何开发UI，如何将系统链接到数据库，以及如何设计一个能够完成Python代码的Visual
    Studio Code扩展。
- en: The UI of an ML model
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型的UI
- en: A UI serves as the bridge between the intricate complexities of ML algorithms
    and the end users who interact with the system. It is the interactive canvas that
    allows users to input data, visualize results, control parameters, and gain insights
    from the ML model’s outputs. A well-designed UI empowers users, regardless of
    their technical expertise, to harness the potential of ML for solving real-world
    problems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: UI作为连接机器学习算法的复杂性和与系统交互的最终用户之间的桥梁。它是用户可以输入数据、可视化结果、控制参数并从机器学习模型的输出中获得见解的交互式画布。一个设计良好的UI能够赋予用户，无论其技术专长如何，利用机器学习解决现实世界问题的潜力。
- en: Effective UIs for ML applications prioritize clarity, accessibility, and interactivity.
    Whether the application is aimed at business analysts, healthcare professionals,
    or researchers, the interface should be adaptable to the user’s domain knowledge
    and objectives. Clear communication of the model’s capabilities and limitations
    is vital, fostering trust in the technology and enabling users to make informed
    decisions based on its outputs. Hence my next best practice.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于机器学习应用的有效 UI 应优先考虑清晰度、可访问性和交互性。无论应用的目标用户是商业分析师、医疗保健专业人员还是研究人员，界面都应该适应用户的领域知识和目标。清晰传达模型的能力和限制至关重要，这有助于建立对技术的信任，并使用户能够根据其输出做出明智的决定。因此，我的下一个最佳实践。
- en: 'Best practice #66'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #66'
- en: Focus on the user task when designing the UI of the ML model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 设计 ML 模型的 UI 时，应专注于用户任务。
- en: We can use different types of UIs, but the majority of modern tools gravitate
    around two – web-based interfaces (which require thin clients) and extensions
    (which provide in-situ improvements). ChatGPT is an example of the web-based interface
    to the GPT-4 model, while GitHub CoPilot is an example of the extension interface
    to the same model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用不同类型的 UI，但大多数现代工具都围绕着两种类型——基于网页的界面（需要轻量级客户端）和扩展（提供现场改进）。ChatGPT 是 GPT-4
    模型的基于网页界面的一个例子，而 GitHub CoPilot 是同一模型的扩展界面的一个例子。
- en: 'In the first example, let’s look at how easy it is to deploy an ML app using
    the Gradio framework. Once we have prepared a pipeline for our model, we just
    need a handful of lines of code to make the app. Here are the lines, based on
    the example of a model that exists at Hugging Face, for text classification:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个例子中，让我们看看使用 Gradio 框架部署 ML 应用有多简单。一旦我们为我们的模型准备好了流程，我们只需要几行代码就能创建这个应用。以下是基于
    Hugging Face 上存在的模型示例的代码行，用于文本分类：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first two lines import the necessary libraries – one for the UI (Gradio)
    and one for the pipeline. The second line imports the default text classification
    pipeline from Hugging Face and the last line creates the UI for the pipeline.
    The UI is in the form of a website with input and output buttons, as shown in
    *Figure 13**.1*:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行导入必要的库——一个用于 UI（Gradio）和一个用于流程。第二行从 Hugging Face 导入默认文本分类流程，最后一行创建流程的 UI。UI
    是一个带有输入和输出按钮的网站，如图 *图 13*.*1* 所示：
- en: '![Figure 13.1 – UI for the default text classification pipeline](img/B19548_13_1.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – 默认文本分类流程的 UI](img/B19548_13_1.jpg)'
- en: Figure 13.1 – UI for the default text classification pipeline
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – 默认文本分类流程的 UI
- en: We can test it by inputting some example text. Normally, we would input this
    in a script and provide some sort of analysis, but this is done by the Gradio
    framework for us. We do not even need to link the parameters of the pipeline with
    the elements of the UI.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过输入一些示例文本来测试它。通常，我们会在脚本中输入这些内容并提供某种分析，但这一切都是由 Gradio 框架为我们完成的。我们甚至不需要将流程的参数与
    UI 的元素链接起来。
- en: 'What happens behind the scenes can be explained by observing the output of
    the script in the console (edited for brevity):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 背后发生的事情可以通过观察控制台中的脚本输出（为了简洁而编辑）来解释：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The framework has downloaded the default model, its tokenizers, and the vocabulary
    file and then created the application on the local machine.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 框架已下载默认模型、其分词器和词汇文件，然后在本地机器上创建了应用程序。
- en: 'The result of using this app is presented in *Figure 13**.2*. We input some
    simple text and almost instantly get its classification:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此应用的结果在 *图 13*.*2* 中展示。我们输入一些简单的文本，几乎瞬间就得到了其分类：
- en: '![Figure 13.2 – Data analyzed using the default text classification pipeline](img/B19548_13_2.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 使用默认文本分类流程分析的数据](img/B19548_13_2.jpg)'
- en: Figure 13.2 – Data analyzed using the default text classification pipeline
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 使用默认文本分类流程分析的数据
- en: This kind of integration is a great way to deploy models first and to make sure
    that they can be used without the need to open a Python environment or similar.
    With this, we’ve come to my next best practice.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集成是首先部署模型并确保它们可以在不打开 Python 环境或类似环境的情况下使用的一种很好的方式。有了这个，我们就来到了我的下一个最佳实践。
- en: 'Best practice #67'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #67'
- en: Prepare your models for web deployment.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 准备你的模型以进行网络部署。
- en: Regardless of what kind of models you develop, try to prepare them for web deployment.
    Our models can be then packaged as Docker containers and provided as part of a
    larger system of microservices. Using Gradio is a great example of how such a
    web deployment can be achieved.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你开发什么类型的模型，都尽量为它们准备网络部署。我们的模型可以被打包成Docker容器，作为微服务系统的一部分提供。使用Gradio是一个很好的例子，说明了如何实现这种网络部署。
- en: Data storage
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据存储
- en: So far, we’ve used CSV files and Excel files to store our data. It’s an easy
    way to work with ML, but it is also a local one. However, when we want to scale
    our application and use it outside of just our machine, it is often much more
    convenient to use a real database engine. The database plays a crucial role in
    an ML pipeline by providing a structured and organized repository for storing,
    managing, and retrieving data. As ML applications increasingly rely on large volumes
    of data, integrating a database into the pipeline becomes essential for a few
    reasons.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用CSV文件和Excel文件来存储我们的数据。这是与ML一起工作的简单方法，但也是一种本地方法。然而，当我们想要扩展我们的应用程序并在我们的机器之外使用它时，通常更方便使用真正的数据库引擎。数据库在ML流水线中扮演着至关重要的角色，它提供了一个结构化和组织化的存储库，用于存储、管理和检索数据。随着ML应用越来越多地依赖于大量数据，将数据库集成到流水线中成为几个原因的必要条件。
- en: Databases offer a systematic way to store vast amounts of data, making it easily
    accessible and retrievable. Raw data, cleaned datasets, feature vectors, and other
    relevant information can be efficiently stored in the database, enabling seamless
    access by various components of the ML pipeline.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库提供了一种系统化的方式来存储大量数据，使其易于访问和检索。原始数据、清洗后的数据集、特征向量和其他相关信息可以高效地存储在数据库中，使ML流水线的各个组件能够无缝访问。
- en: In many ML projects, data preprocessing is a critical step that involves cleaning,
    transforming, and aggregating data before feeding it to the model. Databases allow
    you to store intermediate preprocessed data, reducing the need to repeat resource-intensive
    preprocessing steps each time the model is trained. This speeds up the overall
    pipeline and maintains data consistency.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多ML项目中，数据预处理是一个关键步骤，它涉及在将数据输入模型之前对数据进行清理、转换和聚合。数据库允许你存储中间预处理的中间数据，减少了每次训练模型时重复资源密集型预处理步骤的需求。这加快了整个流水线并保持了数据的一致性。
- en: ML pipelines often involve data from diverse sources such as sensors, APIs,
    files, and databases. Having a centralized database simplifies the process of
    integrating different data streams, ensuring that all relevant information is
    readily available for training and inference.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ML流水线通常涉及来自不同来源的数据，例如传感器、API、文件和数据库。拥有一个集中的数据库简化了整合不同数据流的过程，确保所有相关信息都能方便地用于训练和推理。
- en: Even maintaining a record of different dataset versions is important for reproducibility
    and tracking changes. Databases can be used to store different versions of datasets,
    making it easier to roll back to previous versions if needed and facilitating
    collaboration among team members.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 即使维护不同数据集版本的记录对于可重复性和跟踪变化也很重要。数据库可以用来存储数据集的不同版本，如果需要，可以轻松回滚到以前的版本，并促进团队成员之间的协作。
- en: Finally, ML applications that handle large-scale data require efficient data
    management to scale effectively. Databases provide mechanisms for indexing, partitioning,
    and optimizing queries, which enhance performance and allow the pipeline to handle
    increasing data volumes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，处理大规模数据的ML应用需要有效的数据管理来有效扩展。数据库提供了索引、分区和优化查询的机制，这些机制提高了性能，并允许流水线处理不断增长的数据量。
- en: 'So, let’s create a database in SQLite that would contain the same numerical
    data that we used in our previous work:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们在SQLite中创建一个数据库，它将包含我们在之前工作中使用的相同数值数据：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code fragment, we use the `sqlite3` engine to create a database
    and connect to it (`sqlite3.connect`). Once we connect to a database, we need
    a cursor to move around in the database and execute our queries. The next step
    is to import our existing data into the database.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们使用`sqlite3`引擎创建数据库并连接到它（`sqlite3.connect`）。一旦连接到数据库，我们需要一个游标在数据库中移动并执行我们的查询。下一步是将现有数据导入数据库。
- en: 'Now, we can open the Excel file and transfer the data to the database:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以打开Excel文件并将数据传输到数据库中：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding code reads data from an Excel file, processes it using the pandas
    library, and then saves the processed data into an SQLite database. First, the
    code reads an Excel file called `'chapter_12.xlsx'` and extracts data from the
    `'ant_1_3'` sheet. The data is loaded into a pandas DataFrame, `df`. Then, the
    code uses the `create_engine` function from the `sqlalchemy` library to establish
    a connection to an SQLite database. It then creates a connection to a database
    file named `'ant13.db'`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码从 Excel 文件中读取数据，使用 pandas 库进行处理，然后将处理后的数据保存到 SQLite 数据库中。首先，代码读取名为 `'chapter_12.xlsx'`
    的 Excel 文件，并从 `'ant_1_3'` 工作表提取数据。数据被加载到 pandas DataFrame，`df` 中。然后，代码使用 `sqlalchemy`
    库中的 `create_engine` 函数建立与 SQLite 数据库的连接。然后，它创建到名为 `'ant13.db'` 的数据库文件的连接。
- en: 'Then, it uses the built-in `to_sql` function to create a database table based
    on the DataFrame. In this example, the function has the following parameters:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它使用内置的 `to_sql` 函数根据 DataFrame 创建一个数据库表。在这个例子中，该函数有以下参数：
- en: '`''ant_1_3''` is the name of the table in the database where the data will
    be stored.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''ant_1_3''` 是数据库中存储数据的表名。'
- en: '`engine` is the connection to the SQLite database that was created earlier.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`engine` 是之前创建的 SQLite 数据库的连接。'
- en: '`index=False` specifies that the DataFrame index should not be saved as a separate
    column in the database.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`index=False` 指定 DataFrame 的索引不应作为单独的列保存到数据库中。'
- en: '`if_exists=''replace''` indicates that if a table named `''ant_1_3''` already
    exists in the database, it should be replaced with the new data. Other options
    for `if_exists` include `append` (add data to the table if it exists) and `fail`
    (raise an error if the table already exists).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if_exists=''replace''` 表示如果数据库中已存在名为 `''ant_1_3''` 的表，则应使用新数据替换它。`if_exists`
    的其他选项包括 `append`（如果表已存在，则向表中添加数据）和 `fail`（如果表已存在，则引发错误）。'
- en: 'After this, we have our data in a database and can easily share the data across
    multiple ML pipelines. However, in our case, we’ll only demonstrate how to extract
    such data into a DataFrame so that we can use it in a simple ML application:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们已经在数据库中有数据，可以轻松地在多个机器学习管道之间共享数据。然而，在我们的案例中，我们将仅演示如何将此类数据提取到 DataFrame
    中，以便我们可以在简单的机器学习应用程序中使用它：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `'SELECT * FROM ant_1_3'` query selects all columns from the `'ant_1_3'`
    table in the database. The `fetchall()` method retrieves all the rows returned
    by the query and stores them in the data variable. The data variable will be a
    list of tuples, where each tuple represents a row of data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`''SELECT * FROM ant_1_3''` 查询从数据库中的 `''ant_1_3''` 表中选择所有列。`fetchall()` 方法检索查询返回的所有行，并将它们存储在数据变量中。数据变量将是一个元组列表，其中每个元组代表一行数据。'
- en: Then, it creates a pandas DataFrame, `df`, from the data list. Each tuple in
    the list corresponds to a row in the DataFrame, and the columns of the DataFrame
    will be numbered automatically. Finally, the code retrieves the names of the columns
    in the original database table. The `engine.description` attribute holds metadata
    about the result of the executed SQL query. Specifically, it provides information
    about the columns returned by the query. The code then extracts the first element
    of each tuple in `engine.description`, which is the column name, and assigns these
    names to the columns of the DataFrame, `df`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它从数据列表创建一个 pandas DataFrame，名为 `df`。列表中的每个元组对应于 DataFrame 中的行，DataFrame 的列将自动编号。最后，代码检索原始数据库表中的列名。`engine.description`
    属性包含执行 SQL 查询的结果的元数据。具体来说，它提供了关于查询返回的列的信息。然后，代码提取 `engine.description` 中每个元组的第一个元素，即列名，并将这些名称分配给
    DataFrame 的列，`df`。
- en: From there, the workflow with the data is just as we know it – it uses a pandas
    DataFrame.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里开始，数据处理的工作流程就像我们所知的那样——它使用 pandas DataFrame。
- en: In this example, the entire DataFrame fits in the database and the entire database
    can fit into one frame. However, this is not the case for most ML datasets. The
    pandas library has limitations in terms of its size, so when training models such
    as GPT models, we need more data than a DataFrame can hold. For that, we can use
    either the Dataset library from Hugging Face, or we can use databases. We can
    only fetch a limited amount of data, train a neural network on it, validate on
    another data, then fetch a new set of rows, train the neural network a bit more,
    and so on.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，整个DataFrame可以适应数据库，整个数据库也可以适应一个框架。然而，对于大多数机器学习数据集来说，情况并非如此。pandas库在数据量方面存在限制，因此在训练GPT模型等模型时，我们需要比DataFrame能容纳更多的数据。为此，我们可以使用Hugging
    Face的Dataset库，或者我们可以使用数据库。我们只能获取有限的数据量，在它上面训练神经网络，然后在另一组数据上验证，然后获取新的一组行，再训练神经网络更多一些，依此类推。
- en: In addition to making the database on files, which can be a bit slow, the SQLite
    library allows us to create databases in memory, which is much faster, but they
    do not get serialized to our permanent storage – we need to take care of that
    ourselves.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在文件上创建数据库，这可能有点慢之外，SQLite库允许我们在内存中创建数据库，这要快得多，但它们不会被序列化到我们的永久存储中——我们需要自己处理这一点。
- en: 'To create an in-memory database, we can simply change the name of the database
    to `:memory:` in the first script, like this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个内存数据库，我们只需在第一个脚本中将数据库的名称更改为`:memory:`，如下所示：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can use it later on in a similar way, like so:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍后以类似的方式使用它，如下所示：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the end, we need to remember to serialize the database to a file; otherwise,
    it will disappear the moment our system closes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要记住将数据库序列化到文件中；否则，一旦我们的系统关闭，它就会消失：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Using databases together with ML is quite simple if we know how to work with
    DataFrames. The added value, however, is quite large. We can serialize data to
    files, read them into memory, manipulate them, and serialize them again. We can
    also scale up our applications beyond one system and use these systems online.
    However, for that, we need a UI.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们知道如何处理DataFrame，那么将数据库与机器学习结合使用相当简单。然而，其附加价值却相当大。我们可以将数据序列化到文件中，将它们读入内存，进行操作，然后再将它们序列化。我们还可以将我们的应用程序扩展到多个系统之外，并在线使用这些系统。然而，为了做到这一点，我们需要一个用户界面。
- en: With that, we’ve come to my next best practice.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们就来到了我的下一个最佳实践。
- en: 'Best practice #68'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #68'
- en: Try to work with in-memory databases and dump them to disk often.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用内存数据库，并经常将它们转储到磁盘上。
- en: Libraries such as pandas have limitations on how much data they can contain.
    Databases do not. Using an in-memory database provides a combination of the benefits
    of both without these limitations. Storing the data in memory enables fast access,
    and using the database engine does not limit the size of the data. We just need
    to remember to save (dump) the database from the memory to the disk once in a
    while to prevent the loss of data in case of exceptions, errors, defects, or equipment
    failures.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，pandas等库在可以包含的数据量方面存在限制。数据库没有。使用内存数据库提供了两者的优点，而没有这些限制。将数据存储在内存中可以启用快速访问，而使用数据库引擎不会限制数据的大小。我们只需要记住，偶尔将数据库从内存保存（转储）到磁盘上，以防止在异常、错误、缺陷或设备故障的情况下数据丢失。
- en: Deploying an ML model for numerical data
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署用于数值数据的机器学习模型
- en: 'Before we create the UI, we need to define a function that will take care of
    making predictions using a model that we trained in the previous chapter. This
    function takes the parameters as a user would see them and then makes a prediction.
    The following code fragment contains this function:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建UI之前，我们需要定义一个函数，该函数将负责使用我们在上一章中训练的模型进行预测。这个函数接受用户会看到的参数，然后进行预测。以下代码片段包含了这个函数：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This fragment starts by importing three libraries that are important for the
    UI and the modeling. We already know about the pandas library, but the other two
    are as follows:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个片段首先导入了三个对UI和建模都非常重要的库。我们已经知道pandas库，但其他两个如下：
- en: '`gradio`: This library is used to create simple UIs for interactive ML model
    testing. The library makes it very easy to create the UI and connect it to the
    model.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradio`：这个库用于创建简单的UI，以便进行交互式机器学习模型测试。这个库使得创建UI并将其连接到模型变得非常容易。'
- en: '`joblib`: This library is used for saving and loading Python objects, particularly
    ML models. Thanks to this library, we do not need to train the model every time
    the user wants to open the software (UI).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`joblib`：这个库用于保存和加载Python对象，特别是机器学习模型。多亏了这个库，我们不需要每次用户想要打开软件（UI）时都训练模型。'
- en: 'The `predict_defects` function is where we use the model. It is important to
    note that the naming of the parameters is used automatically by the UI to name
    the input boxes (as we’ll see a bit later). It takes six input parameters: `cbo`,
    `dcc`, `exportCoupling`, `importCoupling`, `nom`, and `wmc`. These parameters
    are the same software metrics that we used to train the model. As these parameters
    are input as text or numbers, it is important to convert them into floats, as
    this was the input value of our model. Once they have been converted, we need
    to turn these loose parameters into a single DataFrame that we can use as input
    to the model. First, we must convert it into a dictionary and then use that dictionary
    to create a DataFrame.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_defects` 函数是我们使用模型的地方。需要注意的是，参数的命名被 UI 自动用于命名输入框（我们稍后会看到）。它接受六个输入参数：`cbo`、`dcc`、`exportCoupling`、`importCoupling`、`nom`
    和 `wmc`。这些参数是我们用来训练模型的相同软件度量。由于这些参数作为文本或数字输入，因此将它们转换为浮点数很重要，因为这是我们模型的输入值。一旦转换完成，我们需要将这些自由参数转换成一个我们可以用作模型输入的单个
    DataFrame。首先，我们必须将其转换为字典，然后使用该字典创建一个 DataFrame。'
- en: Once the data is ready, we can load the model using the `model = joblib.load('./chapter_12_decision_tree_model.joblib')`
    command. The last thing we must do is make a prediction using that model. We can
    do this by writing `result = model.predict(df)[0]`. The function ends by returning
    the result of the predictions.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据准备就绪，我们可以使用 `model = joblib.load('./chapter_12_decision_tree_model.joblib')`
    命令加载模型。我们必须做的最后一件事是使用该模型进行预测。我们可以通过编写 `result = model.predict(df)[0]` 来完成。函数通过返回预测结果结束。
- en: There are a few items that are important to note. First, we need a separate
    function to handle the entire workflow since the UI is based on that. This function
    must have the same number of parameters as the number of input elements we have
    on our UI. Second, it is important to note that the names of the columns in the
    DataFrame should be the same as the names of the columns in the training data
    (the names are case-sensitive).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有几点需要注意。首先，我们需要一个单独的函数来处理整个工作流程，因为 UI 是基于这个函数的。这个函数必须具有与我们在 UI 上拥有的输入元素数量相同的参数数量。其次，需要注意的是，DataFrame
    中的列名应该与训练数据（列名区分大小写）中的列名相同。
- en: 'So, the actual UI is handled completely by the Gradio library. This is exemplified
    in the following code fragment:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，实际的 UI 完全由 Gradio 库处理。以下代码片段展示了这一点：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This code fragment demonstrates the integration of the previously defined `predict_defects`
    function with a UI. Gradio is used to create a simple UI that takes input from
    the user, processes it using the provided function, and displays the result. The
    code consists of two statements:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段展示了之前定义的 `predict_defects` 函数与 UI 的集成。使用 Gradio 创建了一个简单的 UI，它从用户那里获取输入，使用提供的函数处理它，并显示结果。代码由两个语句组成：
- en: 'Creating the interface using the `gr.Interface` function with the following
    parameters:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `gr.Interface` 函数创建接口，以下为参数：
- en: '`fn=predict_defects`: This argument specifies the function that will be used
    to process the user input and produce the output. In this case, it’s the `predict_defects`
    function that was defined previously. Please note that the arguments of the function
    are not provided, and the library takes care of extracting them (and their names)
    automatically.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fn=predict_defects`: 这个参数指定了将用于处理用户输入并生成输出的函数。在这种情况下，它是之前定义的 `predict_defects`
    函数。请注意，函数的参数没有提供，库会自动提取它们（及其名称）。'
- en: '`inputs`: This argument specifies the types of inputs the interface should
    expect. In this case, it lists six input parameters, each of the `''number''`
    type. These correspond to the `cbo`, `dcc`, `exportCoupling`, `importCoupling`,
    `nom`, and `wmc` parameters in the `predict_defects` function.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inputs`: 这个参数指定了接口应该期望的输入类型。在这种情况下，它列出了六个输入参数，每个参数都是 `''number''` 类型。这些对应于
    `predict_defects` 函数中的 `cbo`、`dcc`、`exportCoupling`、`importCoupling`、`nom` 和 `wmc`
    参数。'
- en: '`outputs`: This argument specifies the output format that the interface should
    display to the user. In this case, it’s a text box labeled `''N/A''`. Since our
    model is binary, we only use 1 and 0 as the output. To mark the fact that the
    model has not been used yet, we start with the `''``N/A''` label.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`outputs`: 这个参数指定了接口应该向用户显示的输出格式。在这种情况下，它是一个标记为 `''N/A''` 的文本框。由于我们的模型是二进制的，我们只使用
    1 和 0 作为输出。为了标记模型尚未使用的事实，我们以 `''``N/A''` 标签开始。'
- en: 'Launching the interface (`demo.launch()`): This line of code starts the UI
    in a web browser window, allowing users to interact with it.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动界面（`demo.launch()`）：这一行代码在浏览器窗口中启动UI，使用户能够与之交互。
- en: The UI that was created using Gradio has input fields where the user can provide
    values for the software metrics (`cbo`, `dcc`, `exportCoupling`, `importCoupling`,
    `nom`, `wmc`). Once the user provides these values and submits the form, the `predict_defects`
    function will be called with the provided input values. The predicted result (whether
    defects will be present or not) will be displayed in the text box labeled 'Will
    contain defects?'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Gradio创建的UI具有输入字段，用户可以提供软件指标（`cbo`、`dcc`、`exportCoupling`、`importCoupling`、`nom`、`wmc`）的值。一旦用户提供了这些值并提交了表单，`predict_defects`函数将使用提供的输入值被调用。预测结果（是否存在缺陷）将在标记为'将包含缺陷?'的文本框中显示。
- en: 'We can start this application by typing the following in the command prompt:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在命令提示符中输入以下内容来启动此应用程序：
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This starts a local web server and provides us with the address of it. Once
    we open the page with the app, we’ll see the following UI:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这启动了一个本地Web服务器并提供了它的地址。一旦我们打开带有应用程序的页面，我们将看到以下UI：
- en: '![Figure 13.3 – UI for the defect prediction model created using Gradio](img/B19548_13_3.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图13.3 – 使用Gradio创建的缺陷预测模型UI](img/B19548_13_3.jpg)'
- en: Figure 13.3 – UI for the defect prediction model created using Gradio
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – 使用Gradio创建的缺陷预测模型UI
- en: The UI is structured into two columns – the right-hand column with the result
    and the left-hand column with the input data. At the moment, the input data is
    the default, and therefore the prediction value is N/A, as per our design.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: UI分为两列 – 右侧列显示结果，左侧列显示输入数据。目前，输入数据是默认的，因此预测值是N/A，正如我们的设计。
- en: 'We can fill in the data and press the **Submit** button to obtain the values
    of the prediction. This is shown in *Figure 13**.4*:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以填写数据并按下**提交**按钮以获取预测值。这如图*图13**.4*所示：
- en: '![Figure 13.4 – UI with the prediction outcome](img/B19548_13_4.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4 – 包含预测结果的UI](img/B19548_13_4.jpg)'
- en: Figure 13.4 – UI with the prediction outcome
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – 包含预测结果的UI
- en: Once we fill in data to make predictions, we can submit it; at this point, our
    outcome shows that the module with these characteristics would contain defects.
    It’s also quite logical – for any module that has 345 inputs, we could almost
    guarantee that there would be some defects. It’s just too complex.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们填写数据以进行预测，我们就可以提交它；此时，我们的结果显示具有这些特征的模块将包含缺陷。这也很有逻辑性 – 对于任何有345个输入的模块，我们几乎可以保证会有一些缺陷。它只是太复杂了。
- en: This model, and the UI, are only available locally on our computer. We can,
    however, share it with others and even embed it in websites, if we change just
    one line. Instead of `demo.launch()` without parameters, we can supply one parameter
    – `demo.launch(share=True)`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型和UI仅在我们电脑的本地可用。然而，如果我们只更改一行，我们就可以与他人共享它，甚至将其嵌入到网站上。我们可以用`demo.launch(share=True)`代替不带参数的`demo.launch()`。
- en: Although we’ve used Gradio as an example of the UI, it illustrates that it is
    rather easy to link an existing model to a UI. We can input the data manually
    and get a prediction from the model. Whether the UI is programmed in Gradio or
    any other framework becomes less important. The difficulty may differ – for example,
    we may need to program the link between the input text boxes and model parameters
    manually – but the essence is the same.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们以Gradio作为UI的示例，但它说明了将现有模型链接到UI相当容易。我们可以手动输入数据并从模型中获得预测。UI是用Gradio还是任何其他框架编程变得不那么重要。难度可能不同
    – 例如，我们可能需要手动编程输入文本框和模型参数之间的链接 – 但本质是相同的。
- en: Deploying a generative ML model for images
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署用于图像的生成式机器学习模型
- en: The Gradio framework is very flexible and allows for quickly deploying models
    such as generative AI stable diffusion models – image generators that work similarly
    to the DALL-E model. The deployment of such a model is very similar to the deployment
    of the numerical model we covered previously.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio框架非常灵活，允许快速部署如生成式AI稳定扩散模型等模型 – 与DALL-E模型类似工作的图像生成器。此类模型的部署与我们之前覆盖的数值模型的部署非常相似。
- en: 'First, we need to create a function that will generate images based on one
    of the models from Hugging Face. The following code fragment shows this function:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个函数，该函数将根据Hugging Face中的一个模型生成图像。以下代码片段显示了此函数：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code fragment starts by importing the necessary libraries. Here, we’ll
    notice that there is another library – `diffusers` – which is an interface to
    image generation networks. The function imports a pre-trained model from the Hugging
    Face hub. The model is `"xyn-ai/anything-v4.0"`. It is a variant of the Anything
    4.0 model, cloned by one of the users. The `StableDiffusionPipeline.from_pretrained()`
    function is used to load the model as a pipeline for image generation. The `torch_dtype`
    parameter is set to `torch.float16`, which indicates the data type to be used
    for computations (lower precision for faster processing).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段首先导入必要的库。在这里，我们会注意到还有一个库——`diffusers`，它是图像生成网络的接口。函数从 Hugging Face hub
    导入一个预训练模型。该模型是 `"xyn-ai/anything-v4.0"`，它是 Anything 4.0 模型的一个变体，由一位用户克隆。使用 `StableDiffusionPipeline.from_pretrained()`
    函数将模型作为图像生成的管道加载。`torch_dtype` 参数设置为 `torch.float16`，表示用于计算的 数据类型（为了更快的处理速度，使用较低的精度）。
- en: The image is generated using the pipeline bypassing the prompt as an argument
    to the `pipe()` function. The generated images are accessed using the `images[0]`
    attribute. The `prompt` parameter is provided through the parameter of the function,
    which is supplied by the UI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像是通过绕过将提示作为 `pipe()` 函数的参数来生成的。生成的图像是通过 `images[0]` 属性访问的。`prompt` 参数通过函数的参数提供，该参数由
    UI 提供。
- en: The function returns the image, which is then captured by the UI and displayed.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回图像，然后由 UI 捕获并显示。
- en: 'The code for the UI is also quite straightforward once we know the code from
    the previous example:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们知道了前一个示例中的代码，UI 的代码也相当简单：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Compared to the previous example, this code contains only one input parameter,
    which is the prompt that’s used to generate the image. It also has one output,
    which is the image itself. We use the `''image''` class to indicate that it is
    an image and should be displayed as such. The output of this model is presented
    in *Figure 13**.5*:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个示例相比，这段代码只包含一个输入参数，即用于生成图像的提示。它还有一个输出，即图像本身。我们使用 `'image'` 类来表示它是一个图像，应该以图像的形式显示。该模型的输出在
    *图 13.5* 中展示：
- en: '![Figure 13.5 – Image generated from the Anything 4.0 model using the “car
    and sun” prompt](img/B19548_13_5.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – 使用“汽车和太阳”提示从 Anything 4.0 模型生成的图像](img/B19548_13_5.jpg)'
- en: Figure 13.5 – Image generated from the Anything 4.0 model using the “car and
    sun” prompt
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – 使用“汽车和太阳”提示从 Anything 4.0 模型生成的图像
- en: Please note that the model is not perfect as the generated car has distortion
    artifacts – for example, the right-hand taillight has not been generated perfectly.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于生成的汽车存在扭曲伪影，因此模型并不完美——例如，右后尾灯并没有完美生成。
- en: Deploying a code completion model as an extension
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将代码补全模型作为扩展部署
- en: So far, we’ve learned how to deploy models online and on the Hugging Face hub.
    These are good methods and provide us with the ability to create a UI for our
    models. However, these are standalone tools that require manual input and provide
    an output that we need to use manually – for example, paste into another tool
    or save to disk.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何在网络上和 Hugging Face hub 上部署模型。这些方法是好的，并为我们提供了创建模型 UI 的能力。然而，这些是独立的工具，需要手动输入，并提供了我们需要手动使用的输出——例如，粘贴到另一个工具或保存到磁盘。
- en: In software engineering, many tasks are automated and many modern tools provide
    an ecosystem of extensions and add-ins. GitHub Copilot is such an add-in to Visual
    Studio 2022 and an extension to Visual Studio Code – among other tools. ChatGPT
    is both a standalone web tool and an add-in to Microsoft’s Bing search engine.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中，许多任务都是自动化的，许多现代工具提供了一整套扩展和插件。GitHub Copilot 就是 Visual Studio 2022 的一个插件，也是
    Visual Studio Code 等其他工具的扩展。ChatGPT 既是独立的网络工具，也是微软 Bing 搜索引擎的插件。
- en: Therefore, in the last part of this chapter, we’ll package our models as an
    extension to a programming environment. In this section, we learn how to create
    an extension to complete code, just like GitHub CoPilot. Naturally, we won’t use
    the CodeX model from CoPilot, but Codeparrot’s model for the Python programming
    language. We’ve seen this model before, so let’s dive deeper into the actual extension.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章的最后部分，我们将我们的模型打包为编程环境的扩展。在本节中，我们将学习如何创建一个扩展以完成代码，就像 GitHub CoPilot 一样。自然地，我们不会使用
    CoPilot 的 CodeX 模型，而是使用 Codeparrot 的 Python 编程语言模型。我们之前已经见过这个模型，所以让我们深入了解实际的扩展。
- en: 'We need a few tools to develop the extension. Naturally, we need Visual Studio
    Code itself and the Python programming environment. We also need the Node.js toolkit
    to create the extension. We installed it from nodejs.org. Once we have installed
    it, we can use Node.js’s package manager to install Yeoman and the framework to
    develop the extension. We can do that by using the following command in the command
    prompt:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些工具来开发扩展。自然地，我们需要 Visual Studio Code 本身和 Python 编程环境。我们还需要 Node.js 工具包来创建扩展。我们从
    nodejs.org 安装了它。一旦安装完成，我们可以使用 Node.js 的包管理器来安装 Yeoman 和用于开发扩展的框架。我们可以在命令提示符中使用以下命令来完成：
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Once the packages have been installed, we need to create the skeleton code
    for our extension by typing the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了这些包，我们需要通过输入以下内容来为我们的扩展创建骨架代码：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will bring up the menu that we need to fill in:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将弹出我们需要填写的菜单：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We need to choose the first option, which is a new extension that uses Typescript.
    It is the easiest way to start writing the extension. We could develop a very
    powerful extension using the language pack and language protocol, but for this
    first extension, simplicity beats power.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择第一个选项，即使用 TypeScript 的新扩展。这是开始编写扩展的最简单方法。我们可以使用语言包和语言协议开发一个非常强大的扩展，但在这个第一个扩展中，简洁胜过强大。
- en: 'We need to make a few decisions about the setup of our extension, so let’s
    do that now:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要就我们扩展的设置做出一些决定，所以现在让我们来做这件事：
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We call our extension `mscopilot` and do not create much additional code –
    no Git repository and no webpack. Again, simplicity is the key for this example.
    Once the folder has been created, we need one more package from Node.js to interact
    with Python:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的扩展命名为 `mscopilot` 并不创建很多额外的代码——没有 Git 仓库和没有 webpack。在这个例子中，简洁是关键。一旦文件夹创建完成，我们需要从
    Node.js 中获取一个额外的包来与 Python 交互：
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After we click on the last entry, we get a new folder named `mscopilot`; we
    can enter it with the `code .` command. It opens Visual Studio Code, where we
    can fill the template with the code for our new extension. Once the environment
    opens, we need to navigate to the `package.json` file and change a few things.
    In that file, we need to find the `contributes` section and make a few changes,
    as shown here:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 点击最后一个条目后，我们会得到一个名为 `mscopilot` 的新文件夹；我们可以使用 `code .` 命令进入它。它将打开 Visual Studio
    Code，在那里我们可以用为新扩展编写的代码填充模板。一旦环境打开，我们需要导航到 `package.json` 文件并更改一些内容。在该文件中，我们需要找到
    `contributes` 部分，并做一些修改，如下所示：
- en: '[PRE18]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In the preceding code fragment, we added some information stating that our
    extension has one new function – `logSelectedText` – and that it will be available
    via the *Ctrl* + *Shift* + *L* key combination on Windows (and a similar one on
    Mac). We need to remember that the command name includes the name of our extension
    so that the extension manager knows that this command belongs to our extension.
    Now, we need to go to the `extension.ts` file and add the code for our command.
    The code following fragment contains the first part of the code – the setup for
    the extension and its activation:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们添加了一些信息，说明我们的扩展有一个新的功能——`logSelectedText`——并且它将通过 Windows 上的 *Ctrl*
    + *Shift* + *L* 键组合（以及 Mac 上类似的组合）可用。我们需要记住，命令名称包括我们扩展的名称，这样扩展管理器就知道这个命令属于我们的扩展。现在，我们需要转到
    `extension.ts` 文件并添加我们命令的代码。以下代码片段包含代码的第一部分——扩展的设置和激活：
- en: '[PRE19]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This function just logs that our extension has been activated. Since the extension
    is rather invisible to the user (and it should be), it is a good practice to use
    the log file to store the information that has been instantiated.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数只是记录我们的扩展已被激活。由于扩展对用户来说相当不可见（而且应该是这样），使用日志文件来存储已实例化的信息是一种良好的做法。
- en: 'Now, we add the code that will get the selected text, instantiate the Parrot
    model, and add the suggestion to the editor:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们添加将获取所选文本、实例化 Parrot 模型并将建议添加到编辑器的代码：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This code registers our `''mscopilot.logSelectedText''` command. We made this
    visible to the extension manager in the previous file – `package.json`. When this
    command is executed, it performs the following steps. The important part is the
    interaction between the code in TypeScript and the code in Python. Since we’re
    using the Hugging Face model, the easiest way is to use the same scripts that
    we’ve used so far in this book. However, since the extensions are written in TypeScript
    (or JavaScript), we need to embed the Python code in TypeScript, add a variable
    to it, and capture the outcome:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码注册了我们的 `'mscopilot.logSelectedText'` 命令。我们在之前的文件——`package.json`——中使这个命令对扩展管理器可见。当这个命令执行时，它执行以下步骤。重要的是
    TypeScript 代码和 Python 代码之间的交互。由于我们使用的是 Hugging Face 模型，最简单的方法是使用本书中迄今为止使用的相同脚本。然而，由于扩展是用
    TypeScript（或 JavaScript）编写的，我们需要在 TypeScript 中嵌入 Python 代码，向其中添加一个变量，并捕获结果：
- en: First, imports the required libraries – `python-shell` and `path` – which are
    needed to execute Python scripts from within a Node.js environment.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入所需的库——`python-shell` 和 `path`——这些库是执行 Node.js 环境中的 Python 脚本所必需的。
- en: Next, it sets up the Python interpreter via `C:/Python311/python.exe`, which
    will be used to run Python scripts. This is important for ensuring that the correct
    Python environment is used, even when using a virtual environment. If we do not
    specify it, we need to find it in the script, which is a bit tricky in the user
    environment.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它通过 `C:/Python311/python.exe` 设置 Python 解释器，这将用于运行 Python 脚本。这对于确保使用正确的 Python
    环境非常重要，即使在使用虚拟环境时也是如此。如果我们没有指定它，我们需要在脚本中找到它，这在用户环境中可能有点棘手。
- en: After, it sets the active text editor and the selected text. We need this selection
    so that we can send the prompt to the model. In our case, we’ll simply send the
    selection to the model and get the suggested code.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，它设置活动文本编辑器和选定的文本。我们需要这个选择，以便我们可以将提示信息发送到模型。在我们的例子中，我们将简单地发送选择的内容到模型，并获取建议的代码。
- en: Then, it prepares the prompt, which means that it creates a string variable
    that we use in the code of the Python script.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它准备提示信息，这意味着它创建了一个字符串变量，我们在 Python 脚本的代码中使用这个变量。
- en: Next, it defines the Python script, where the connection to the ML model is
    established. Our Python script is defined as a multi-line string (`scriptText`)
    using a template literal. This script utilizes the Hugging Face Transformers library’s
    `pipeline` function to perform text generation using the `codeparrot-small` model.
    The Python code is in boldface, and we can see that the string is complemented
    with the prompt, which is the selected text in the active editor.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它定义了 Python 脚本，其中建立了与 ML 模型的连接。我们的 Python 脚本被定义为多行字符串（`scriptText`），使用模板字面量。这个脚本利用
    Hugging Face Transformers 库的 `pipeline` 函数，使用 `codeparrot-small` 模型进行文本生成。Python
    代码以粗体显示，我们可以看到字符串与提示信息相补充，即活动编辑器中的选定文本。
- en: Then, it displays short information to the user since the model requires some
    time to load and make an inference. It may take up to a minute (for the first
    execution) to get the inference as the model needs to be downloaded and set up.
    Therefore, it is important to display a message that we’re starting the inference.
    A message is displayed to the user using `vscode.window.showInformationMessage`,
    indicating that the code generation process is about to start.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它向用户显示简短的信息，因为模型需要一些时间来加载和进行推理。第一次执行可能需要一分钟（因为模型需要下载和设置）。因此，显示一条消息，说明我们正在开始推理是很重要的。使用
    `vscode.window.showInformationMessage` 向用户显示一条消息，表明代码生成过程即将开始。
- en: After, it runs the Python script (`scriptText`) using `python.PythonShell.runString`.
    The script’s output is captured in the `messages` array. We lost control over
    the execution for a while since we waited for the Python script to finish; it
    provided us with a suggestion for code completion.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，它使用 `python.PythonShell.runString` 运行 Python 脚本（`scriptText`）。脚本的输出被捕获在 `messages`
    数组中。我们暂时失去了对执行的掌控，因为我们等待 Python 脚本完成；它为我们提供了一个代码补全的建议。
- en: Next, it pastes the generated code from the response (`messages`) array into
    a single string (`snippet`). The snippet is then pasted into the active text editor
    at the position of the selected text, effectively replacing the selected text
    with the generated code. Since the first element of the response from the model
    is the prompt, we can simply just replace the selection with the snippet.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，它将响应中的生成代码（`messages` 数组）粘贴到一个单独的字符串（`snippet`）中。然后，该片段被粘贴到活动文本编辑器中选中文本的位置，有效地用生成的代码替换了选中的文本。由于模型响应的第一个元素是提示，我们可以简单地用片段替换选择。
- en: Finally, it displays the completion message after the code generation process.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在代码生成过程完成后，它显示完成消息。
- en: 'Now, we have an extension that we can test. We can execute it by pressing the
    *F5* key. This brings up a new instance of Visual Studio, where we can type a
    piece of code to be completed, as shown in *Figure 13**.6*:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个可以测试的扩展。我们可以通过按 *F5* 键来执行它。这会打开一个新的 Visual Studio 实例，在那里我们可以输入要完成的代码片段，如图
    *图 13*.*6* 所示：
- en: '![Figure 13.6 – A test instance of some Visual Studio code with our extension
    activated. The selected text is used as the prompt for the model](img/B19548_13_6.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 激活我们的扩展的一些 Visual Studio 代码的测试实例。选中的文本用作模型的提示](img/B19548_13_6.jpg)'
- en: Figure 13.6 – A test instance of some Visual Studio code with our extension
    activated. The selected text is used as the prompt for the model
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 激活我们的扩展的一些 Visual Studio 代码的测试实例。选中的文本用作模型的提示
- en: 'Once we press *Ctrl* + *Shift* + *L*, as we defined in the `package.json` file,
    our command is activated. This is indicated by the messages in the lower right-hand
    corner of the environment in *Figure 13**.7*:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们按下 *Ctrl* + *Shift* + *L*，正如我们在 `package.json` 文件中定义的那样，我们的命令就会被激活。这可以通过环境右下角的消息来指示，如图
    *图 13*.*7* 所示：
- en: '![Figure 13.7 – Starting to generate the code. The message box and the log
    information indicate that our command is working](img/B19548_13_7.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – 开始生成代码。消息框和日志信息表明我们的命令正在工作](img/B19548_13_7.jpg)'
- en: Figure 13.7 – Starting to generate the code. The message box and the log information
    indicate that our command is working
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – 开始生成代码。消息框和日志信息表明我们的命令正在工作
- en: 'After a few seconds, we get a suggestion from the Parrot model, which we must
    then paste into the editor, as shown in *Figure 13**.8*:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，我们从 Parrot 模型获得建议，然后必须将其粘贴到编辑器中，如图 *图 13*.*8* 所示：
- en: '![Figure 13.8 – Code suggestion from the Parrot model pasted into the editor](img/B19548_13_8.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.8 – 将来自 Parrot 模型的代码建议粘贴到编辑器中](img/B19548_13_8.jpg)'
- en: Figure 13.8 – Code suggestion from the Parrot model pasted into the editor
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 – 将来自 Parrot 模型的代码建议粘贴到编辑器中
- en: Here, we can see that our extension is rather simple and gets all the suggestions
    from the model. So, in addition to the proper code (`return "Hello World!"`),
    it included more than we needed. We could write more interesting logic, parse
    the code, and clean it – the sky is the limit. I leave it to you to continue this
    work and to make it better. My job was to illustrate that writing a GitHub CoPilot-like
    tool is not as difficult as it may seem.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的扩展相当简单，并从模型获取所有建议。因此，除了正确的代码（`return "Hello World!"`）之外，它还包括了我们不需要的更多内容。我们可以编写更有趣的逻辑，解析代码，并清理它
    – 天空才是极限。我将这项工作留给你来完成，并使其变得更好。我的工作是用来说明编写 GitHub CoPilot 类似的工具并不像看起来那么困难。
- en: With this, we’ve come to my final best practice for this chapter.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个，我们来到了本章的最后一项最佳实践。
- en: 'Best practice #69'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #69'
- en: If your model/software aims to help in the daily tasks of your users, make sure
    that you develop it as an add-in.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的模型/软件旨在帮助用户处理日常任务，确保你将其开发为一个插件。
- en: Although we could use the Codeparrot model from the Gradio interface, it would
    not be appreciated. Programmers would have to copy their code to a web browser,
    click a button, wait for the suggestion, and paste it back into their environment.
    By providing an extension to Visual Studio Code, we can tap into the workflow
    of software developers. The only extra task is to select the text to complete
    and press *Ctrl* + *Shift* + *L*; I’m sure that this could be simplified even
    more, just like GitHub Copilot does.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以使用来自 Gradio 界面的 Codeparrot 模型，但这可能不会被欣赏。程序员需要将他们的代码复制到网页浏览器中，点击一个按钮，等待建议，并将其粘贴回他们的环境中。通过为
    Visual Studio Code 提供一个扩展，我们可以利用软件开发者的工作流程。唯一的额外任务是选择要完成的文本并按 *Ctrl* + *Shift*
    + *L*；我相信这可以进一步简化，就像 GitHub Copilot 所做的那样。
- en: Summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter concludes the third part of this book. It also concludes the most
    technical part of our journey through the best practices. We’ve learned how to
    develop ML systems and how to deploy them. These activities are often called AI
    engineering, which is the term that places the focus on the development of software
    systems rather than the models themselves. This term also indicates that testing,
    deploying, and using ML is much more than training, validating, and testing the
    models.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束了本书的第三部分。它也结束了我们通过最佳实践之旅中最技术性的部分。我们学习了如何开发机器学习系统以及如何部署它们。这些活动通常被称为人工智能工程，这个术语将重点放在软件系统的开发上，而不是模型本身。这个术语还表明，测试、部署和使用机器学习要远比训练、验证和测试模型复杂得多。
- en: Naturally, there is even more to this. Just developing and deploying AI software
    is not enough. We, as software engineers or AI engineers, need to consider the
    implications of our actions. Therefore, in the next part of this book, we’ll explore
    the concepts of bias, ethics, and the sustainable use of the fruits of our work
    – AI software systems.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这里还有更多。仅仅开发和部署人工智能软件是不够的。作为软件工程师或人工智能工程师，我们需要考虑我们行为的后果。因此，在这本书的下一部分，我们将探讨偏见、伦理以及我们工作成果——人工智能软件系统的可持续使用等概念。
- en: References
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Rana, R., et al. A framework for adoption of machine learning in industry
    for software defect prediction. In 2014 9th International Conference on Software
    Engineering and Applications (ICSOFT-EA).* *2014\. IEEE.*'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Rana, R.，等人。在软件缺陷预测中采用机器学习的框架。在2014年第9届软件工程与应用国际会议（ICSOFT-EA）上。* *2014年。IEEE。*'
- en: '*Bosch, J., H.H. Olsson, and I. Crnkovic, Engineering ai systems: A research
    agenda. Artificial Intelligence Paradigms for Smart Cyber-Physical Systems, 2021:*
    *p. 1-19.*'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Bosch, J.，H.H. Olsson，和I. Crnkovic。人工智能系统的工程：研究议程。智能网络物理系统的人工智能范式，2021年：*
    *p. 1-19。*'
- en: '*Giray, G., A software engineering perspective on engineering machine learning
    systems: State of the art and challenges. Journal of Systems and Software, 2021\.
    180:* *p. 111031.*'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Giray, G.。从软件工程的角度看机器学习系统的工程：现状与挑战。系统与软件杂志，2021年。180：* *p. 111031。*'
