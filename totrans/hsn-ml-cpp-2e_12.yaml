- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Exporting and Importing Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出和导入模型
- en: In this chapter, we’ll discuss how to save and load model parameters during
    and after training. This is important because model training can take days or
    even weeks. Saving intermediate results allows us to load them later for evaluation
    or production use.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何在训练期间和之后保存和加载模型参数。这很重要，因为模型训练可能需要几天甚至几周。保存中间结果允许我们在以后进行评估或生产使用时加载它们。
- en: Such regular save operations can be beneficial in the case of a random application
    crash. Another substantial feature of any **machine learning** (**ML**) framework
    is its ability to export the model architecture, which allows us to share models
    between frameworks and makes model deployment easier. The main topic of this chapter
    is to show how to export and import model parameters such as weights and bias
    values with different C++ libraries. The second part of this chapter is all about
    the **Open Neural Network Exchange** (**ONNX**) format, which is currently gaining
    popularity among different ML frameworks and can be used to share trained models.
    This format is suitable for sharing model architectures as well as model parameters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种常规的保存操作在随机应用程序崩溃的情况下可能有益。任何 **机器学习**（**ML**）框架的另一个重要特性是它导出模型架构的能力，这使我们能够在框架之间共享模型，并使模型部署更加容易。本章的主要内容是展示如何使用不同的
    C++ 库导出和导入模型参数，如权重和偏置值。本章的第二部分全部关于 **开放神经网络交换**（**ONNX**）格式，该格式目前在不同的 ML 框架中越来越受欢迎，可以用于共享训练模型。此格式适用于共享模型架构以及模型参数。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: ML model serialization APIs in C++ libraries
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++ 库中的 ML 模型序列化 API
- en: Delving into the ONNX format
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入了解 ONNX 格式
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following are the technical requirements for this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为本章的技术要求：
- en: The `Dlib` library
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dlib` 库'
- en: The `mlpack` library
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack` 库'
- en: The `F``lashlight` library
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`F``lashlight` 库'
- en: The `pytorch` library
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch` 库'
- en: The `onnxruntime` framework
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`onnxruntime` 框架'
- en: A modern C++ compiler with C++20 support
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 C++20 的现代 C++ 编译器
- en: CMake build system version >= 3.8
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake 构建系统版本 >= 3.8
- en: 'The code files for this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter12).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在本书的 GitHub 仓库中找到：[https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition/tree/main/Chapter12)。
- en: ML model serialization APIs in C++ libraries
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: C++ 库中的 ML 模型序列化 API
- en: 'In this section, we’ll discuss the ML model sharing APIs that are available
    in the `Dlib`, `F``lashlight`, `mlpack`, and `pytorch` libraries. There are three
    main types of sharing ML models among the different C++ libraries:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论 `Dlib`、`F``lashlight`、`mlpack` 和 `pytorch` 库中可用的 ML 模型共享 API。在不同的
    C++ 库之间共享 ML 模型主要有三种类型：
- en: Share model parameters (weights)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享模型参数（权重）
- en: Share the entire model’s architecture
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享整个模型的架构
- en: Share both the model architecture and its trained parameters
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享模型架构及其训练参数
- en: In the following sections, we’ll look at what API is available in each library
    and emphasize what type of sharing it supports.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下各节中，我们将查看每个库中可用的 API，并强调它支持哪种类型的共享。
- en: Model serialization with Dlib
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Dlib 进行模型序列化
- en: The `Dlib` library uses the serialization API for `decision_function` and neural
    network objects. Let’s learn how to use it by implementing a real example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib` 库使用 `decision_function` 和神经网络对象的序列化 API。让我们通过实现一个真实示例来学习如何使用它。'
- en: 'First, we’ll define the types for the neural network, regression kernel, and
    training sample:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将定义神经网络、回归核和训练样本的类型：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we’ll generate the training data with the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用以下代码生成训练数据：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, `x` represents the predictor variable, while `y` represents the target
    variable. The target variable, `y`, is salted with uniform random noise to simulate
    real data. These variables have a linear dependency, which is defined with the
    following function:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`x` 代表预测变量，而 `y` 代表目标变量。目标变量 `y` 被均匀随机噪声盐化，以模拟真实数据。这些变量具有线性依赖关系，该关系由以下函数定义：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once we’ve generated the data, we normalize it using the `vector_normalizer`
    type object. Objects of this type can be reused after training to normalize data
    with the learned mean and standard deviation. The following snippet shows how
    it’s implemented:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 生成数据后，我们使用`vector_normalizer`类型的对象对其进行归一化。这种类型的对象在训练后可以重复使用，以使用学习到的均值和标准差对数据进行归一化。以下代码片段展示了其实现方式：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, we train the `decision_function` object for kernel ridge regression
    with the `krr_trainer` type object:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`krr_trainer`类型的对象训练核岭回归的`decision_function`对象：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that we initialized the trainer object with the instance of the `KernelType`
    object.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用`KernelType`对象的实例初始化了训练器对象。
- en: 'Now that we have the trained `decision_function` object, we can serialize it
    into a file with a stream object that’s returned by the `serialize` function:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了训练好的`decision_function`对象，我们可以使用`serialize`函数返回的流对象将其序列化到文件中：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This function takes the name of the file for storage as an input argument and
    returns an output stream object. We used the `<<` operator to put the learned
    weights of the regression model into the file. The serialization approach we used
    in the preceding code example only saves model parameters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将文件存储的名称作为输入参数，并返回一个输出流对象。我们使用了`<<`运算符将回归模型学习到的权重放入文件。在先前的代码示例中使用的序列化方法仅保存模型参数。
- en: 'The same approach can be used to serialize almost all ML models in the `D``lib`
    library. The following code shows how to use it to serialize the parameters of
    a neural network:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的方法可以用来序列化`Dlib`库中的几乎所有机器学习模型。以下代码展示了如何使用它来序列化神经网络的参数：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For neural networks, there’s also the `net_to_xml` function, which saves the
    model structure. However, there’s no function to load this saved structure into
    our program in the library API. It’s the user’s responsibility to implement a
    loading function.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络，还有一个`net_to_xml`函数，它保存模型结构。然而，库API中没有函数可以将保存的结构加载到我们的程序中。这是用户的责任来实现加载函数。
- en: The `net_to_xml` function exists if we wish to share the model between frameworks,
    as depicted in the `Dlib` documentation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望在不同框架之间共享模型，可以使用`net_to_xml`函数，如`Dlib`文档中所示。
- en: 'To check that parameter serialization works as expected, we can generate new
    test data to evaluate a loaded model on it:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查参数序列化是否按预期工作，我们可以生成新的测试数据来评估加载的模型：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that we’ve reused the `normalizer` object. In general, the parameters of
    the `normalizer` object should also be serialized and loaded because, during evaluation,
    we need to transform new data into the same statistical characteristics that we
    used for the training data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已经重用了`normalizer`对象。一般来说，`normalizer`对象的参数也应该进行序列化和加载，因为在评估过程中，我们需要将新数据转换为我们用于训练数据的相同统计特性。
- en: 'To load a serialized object in the `Dlib` library, we can use the `deserialize`
    function. This function takes the filename and returns the input stream object:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要在`Dlib`库中加载序列化的对象，我们可以使用`deserialize`函数。此函数接受文件名并返回一个输入流对象：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we discussed previously, in the `Dlib` library, serialization only stores
    model parameters. So, to load them, we need to use the model object with the same
    properties that it had before serialization was performed.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在`Dlib`库中，序列化仅存储模型参数。因此，要加载它们，我们需要使用在序列化之前具有相同属性的模型对象。
- en: For a regression model, this means that we should instantiate a decision function
    object with the same kernel type.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归模型，这意味着我们应该实例化一个与相同核类型相对应的决策函数对象。
- en: 'For a neural network model, this means that we should instantiate a network
    object of the same type that we used for serialization, as can be seen in the
    following code block:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络模型，这意味着我们应该实例化一个与序列化时使用的相同类型的网络对象，如下面的代码块所示：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this section, we saw that the `Dlib` serialization API allows us to save
    and load ML model parameters but has limited options to serialize and load model
    architectures. In the next section, we’ll look at the `Shogun` library model’s
    serialization API.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解到`Dlib`序列化API允许我们保存和加载机器学习模型参数，但在序列化和加载模型架构方面选项有限。在下一节中，我们将探讨`Shogun`库模型序列化API。
- en: Model serialization with Flashlight
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flashlight进行模型序列化
- en: The `Flashlight` library can save and load models and parameters into a binary
    format. It uses the `Cereal` C++ library internally for serialization. An example
    of this functionality is shown in the following example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`Flashlight`库可以将模型和参数保存和加载到二进制格式中。它内部使用`Cereal` C++库进行序列化。以下示例展示了这一功能。'
- en: 'As in the previous example, we’ll start by creating some sample training data:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如前例所示，我们首先创建一些示例训练数据：
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, we created a vector, `x`, with random data and used it to create our target
    variable, `y`, by applying a linear dependency formula. We wrapped our independent
    and target vectors into a `BatchDataset` object called `batch_dataset`, which
    we’ll use to train a sample neural network.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个包含随机数据的向量`x`，并通过应用线性依赖公式来创建我们的目标变量`y`。我们将独立和目标向量包装到一个名为`batch_dataset`的`BatchDataset`对象中，我们将使用它来训练一个示例神经网络。
- en: 'The following code shows our neural network definition:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了我们的神经网络定义：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, it’s the same feedforward network that we used in the previous
    example, but this time for Flashlight.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这是我们之前示例中使用的相同的正向传播网络，但这次是为Flashlight设计的。
- en: 'The following code sample shows how to train the model:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了如何训练模型：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we used the same training approach that we used previously. First, we
    defined the `loss` object and the `sgd` optimizer object. Then, we used the two
    loops over epochs and over batches to train the model. In the internal loop, we
    applied the model to get new predicted values from training batch data. Then,
    we used the `loss` object to calculate the MSE value with the batch target values.
    We also used the `backward` method of the loss value variable to calculate the
    gradients. Finally, we used the `sgd` optimizer object to update the model parameters
    with the `step` method.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了之前使用的相同训练方法。首先，我们定义了`loss`对象和`sgd`优化器对象。然后，我们使用两个循环来训练模型：一个循环遍历epoch，另一个循环遍历批次。在内循环中，我们将模型应用于训练批次数据以获取新的预测值。然后，我们使用`loss`对象使用批次目标值计算MSE值。我们还使用了损失值变量的`backward`方法来计算梯度。最后，我们使用`sgd`优化器对象的`step`方法更新模型参数。
- en: 'Now that we have the trained model, we have two ways to save it in the `F``lashlight`
    library:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了训练好的模型，我们有两种方法可以在`Flashlight`库中保存它：
- en: Serialize the whole model with the architecture and weights.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 序列化整个模型及其架构和权重。
- en: Serialize only the model weights.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅序列化模型权重。
- en: 'For the first option—that is, serialize the whole model with the architecture—we
    can do the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一种选项——即序列化整个模型及其架构——我们可以这样做：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here, `model.dat` is the name of the file where we’ll save the model. To load
    such a file, we can use the following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`model.dat`是我们将保存模型的文件名。要加载此类文件，我们可以使用以下代码：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this case, we created a new empty object called `model_loaded` . This new
    object is just the `fl::Sequential` container object without particular layers.
    All the layers and parameter values were loaded with the `fl::load` function.
    Once we’ve loaded the model, we can use it as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们创建了一个名为`model_loaded`的新空对象。这个新对象只是一个没有特定层的`fl::Sequential`容器对象。所有层和参数值都是通过`fl::load`函数加载的。一旦我们加载了模型，我们就可以这样使用它：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here, `new_x` is some new data that we’re using for evaluation purposes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`new_x`是我们用于评估目的的一些新数据。
- en: Such an approach when you store the whole model can be useful for applications
    that contain different models but have the same input and output interfaces as
    it can help you easily change or upgrade a model in production, for example.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当您存储整个模型时，这种方法对于包含不同模型但具有相同输入和输出接口的应用程序可能很有用，因为它可以帮助您轻松地在生产中更改或升级模型，例如。
- en: 'The second option, which involves only saving the parameter (weight) values
    of a network, can be useful if we need to retrain a model regularly or if we share
    or reuse only some part of the model or its parameters. To do this, we can use
    the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选项，仅保存网络的参数（权重）值，如果我们需要定期重新训练模型，或者如果我们只想共享或重用模型或其参数的某些部分，这可能是有用的。为此，我们可以使用以下代码：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here, we used the `params` method of the `model` object to get all the model’s
    parameters. This method returns the `std::vector` sequence of parameters for all
    model sub-modules. So, you can only manage some of them. To load saved parameters,
    we can use the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`model`对象的`params`方法来获取所有模型参数。此方法返回所有模型子模块的参数的`std::vector`序列。因此，您只能管理其中的一些。要加载已保存的参数，我们可以使用以下代码：
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: First, we created the empty `params` container. Then, with the `fl::load` function,
    we loaded parameter values into it. To be able to update particular sub-module
    parameter values, we used the `setParams` method. The `'setParams'` method takes
    a value and an integer position where we want to set this value. We saved all
    the model parameters so that we could take them back into the model sequentially.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了空的 `params` 容器。然后，使用 `fl::load` 函数将参数值加载到其中。为了能够更新特定子模块的参数值，我们使用了 `setParams`
    方法。`'setParams'` 方法接受一个值和一个整数位置，我们想要设置这个值。我们保存了所有模型参数，以便我们可以按顺序将它们放回模型中。
- en: Unfortunately, there’s no way to load models and weights from other formats
    into the `Flashlight` library. So, if you need to load from another format, you
    have to write a converter and use the `setParams` method to set particular values.
    In the next section, we’ll delve into the `mlpack` library’s serialization API.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有方法可以将其他格式的模型和权重加载到 `Flashlight` 库中。因此，如果您需要从其他格式加载，您必须编写一个转换器并使用 `setParams`
    方法设置特定值。在下一节中，我们将深入了解 `mlpack` 库的序列化 API。
- en: Model serialization with mlpack
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 mlpack 进行模型序列化
- en: 'The `mlpack` library only implements model parameter serialization. This serialization
    is based on functionality that exists in the Armadillo math library, which is
    used as the backend for mlpack. This means we can save parameter values in different
    file formats using the mlpack API. They are as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlpack` 库仅实现了模型参数序列化。这种序列化基于存在于 Armadillo 数学库中的功能，该库被用作 mlpack 的后端。这意味着我们可以使用
    mlpack API 以不同的文件格式保存参数值。具体如下：'
- en: '`.csv`, or optionally `.txt`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.csv`，或者可选的 `.txt`'
- en: '`.txt`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.txt`'
- en: '`.txt`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.txt`'
- en: '`.pgm`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.pgm`'
- en: '`.ppm`'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ppm`'
- en: '`.bin`'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.bin`'
- en: '`.bin`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.bin`'
- en: '`.hdf5`, `.hdf`, `.h5`, or `.he5`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.hdf5`、`.hdf`、`.h5` 或 `.he5`'
- en: 'Let’s look at a minimal example of model creation and parameter management
    with mlpack. First, we need a model. The following code shows the function we
    can use to create one:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用 mlpack 创建模型和参数管理的最小示例。首先，我们需要一个模型。以下代码展示了我们可以使用的创建模型的功能：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `create_model` function creates the feedforward network with several linear
    layers. Note that we made this model use `MSE` as the loss function and added
    the zero parameter initializer. Now that we have a model, we need some data to
    train it. The following code shows how to create linear dependent data:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_model` 函数创建了一个具有多个线性层的前馈网络。请注意，我们使此模型使用 `MSE` 作为损失函数并添加了零参数初始化器。现在我们有了模型，我们需要一些数据来训练它。以下代码展示了如何创建线性相关数据：'
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, we created two single-dimensional vectors, similar to what we did for
    the `Flashlight` sample but using the Armadillo matrix API. Notice that we used
    the `t()` transpose method for the `x` vector since mlpack uses the column dimension
    for its training features.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了两个单维向量，类似于我们在 `Flashlight` 示例中所做的，但使用了 Armadillo 矩阵 API。请注意，我们使用了 `t()`
    转置方法对 `x` 向量进行操作，因为 mlpack 使用列维度作为其训练特征。
- en: 'Now, we can connect all the components and perform model training:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以连接所有组件并执行模型训练：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, we created the `Adam` algorithm optimizer object and used it in the model’s
    `Train` method with the two data vectors we created previously. Now, we have the
    trained model and are ready to save its parameters. This can be done as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了 `Adam` 算法优化器对象，并在模型的 `Train` 方法中使用我们之前创建的两个数据向量。现在，我们有了训练好的模型，准备保存其参数。这可以按以下方式完成：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: By default, the `data::Save` function automatically determines the file format
    to save with based on the provided filename extension. Here, we used the `Parameters`
    method of the model object to get the parameter values. This method returns a
    big matrix with all values. We also passed `true` as the third parameter to make
    the `save` function throw an exception in case of failure. By default, it will
    just return `false`; this is something you have to check manually.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`data::Save` 函数会根据提供的文件名扩展名自动确定要保存的文件格式。在这里，我们使用了模型对象的 `Parameters` 方法来获取参数值。此方法返回一个包含所有值的矩阵。我们还传递了
    `true` 作为第三个参数，以便在失败的情况下 `save` 函数抛出异常。默认情况下，它将只返回 `false`；这是您必须手动检查的事情。
- en: 'We can use the `mlpack::data::Load` function to load parameter values, as shown
    here:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `mlpack::data::Load` 函数来加载参数值，如下所示：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Here, we created the `new_model` object; this is the same model but with parameters
    initialized as zero. Then, we used the `mlpack::data::Load` function to load parameter
    values from the file. Once again, we used the `Parameters` method to get the reference
    to the internal parameter values matrix and passed it to the `load` function.
    The third argument of the `load` function we set to `true` so that we can get
    an exception in case of errors.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了`new_model`对象；这是一个与之前相同的模型，但参数初始化为零。然后，我们使用`mlpack::data::Load`函数从文件中加载参数值。再次使用`Parameters`方法获取内部参数值矩阵的引用，并将其传递给`load`函数。我们将`load`函数的第三个参数设置为`true`，以便在出现错误时可以抛出异常。
- en: 'Now that we’ve initialized the model, we can use it to make predictions:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经初始化了模型，我们可以用它来进行预测：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, we created an output matrix, `prediction`, and used the `Predict` method
    of the `new_model` object for model evaluation. Note that `new_x` is some new
    data that we wish to get predictions for.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个输出矩阵`prediction`，并使用`new_model`对象的`Predict`方法进行模型评估。请注意，`new_x`是我们希望对其获取预测的一些新数据。
- en: Note that you can’t load other frameworks’ file formats into mlpack, so you
    have to create converters if you need them. In the next section, we’ll look at
    the `pytorch` library’s serialization API.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你不能将其他框架的文件格式加载到mlpack中，因此如果你需要，你必须创建转换器。在下一节中，我们将查看`pytorch`库的序列化API。
- en: Model serialization with PyTorch
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch进行模型序列化
- en: 'In this section, we’ll discuss two approaches to network parameter serialization
    that are available in the `pytorch` C++ library:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论在`pytorch` C++库中可用的两种网络参数序列化方法：
- en: The `torch::save` function
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch::save`函数'
- en: An object of the `torch::serialize::OutputArchive` type for writing parameters
    into the `OutputArchive` object
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`torch::serialize::OutputArchive`类型的对象，用于将参数写入`OutputArchive`对象
- en: Let’s start by preparing the neural network.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从准备神经网络开始。
- en: Initializing the neural network
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化神经网络
- en: 'Let’s start by generating the training data. The following code snippet shows
    how we can do this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从生成训练数据开始。以下代码片段显示了我们可以如何做到这一点：
- en: '[PRE24]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Usually, we want to utilize as many hardware resources as possible. So, first,
    we checked whether a GPU with CUDA technology was available in the system by using
    the `torch::cuda::is_available()` call:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们希望尽可能利用硬件资源。因此，首先，我们通过使用`torch::cuda::is_available()`调用检查系统中是否有带有CUDA技术的GPU可用：
- en: '[PRE25]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We defined the `dist` object so that we could generate the uniformly distributed
    real values in the `–1` to `1` range:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了`dist`对象，以便我们可以在`-1`到`1`的范围内生成均匀分布的实数：
- en: '[PRE26]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, we generated 1,000 predictor variable values and shuffled them. For each
    value, we calculated the target value with the linear function that we used in
    the previous examples—that is, `func`. Here’s what this looks like:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们生成了1,000个预测变量值并将它们打乱。对于每个值，我们使用在之前的示例中使用的线性函数计算目标值——即`func`。下面是这个过程的示例：
- en: '[PRE27]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, all the values were moved into the `torch::Tensor` objects with `torch::tensor`
    function calls. Notice that we used a previously detected device for tensor creation.
    Once we moved all the values to tensors, we used the `torch::stack` function to
    concatenate the predictor and target values in two distinct single tensors. This
    was required so that we could perform data normalization with the `pytorch` library’s
    linear algebra routines:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，所有值都通过`torch::tensor`函数调用移动到`torch::Tensor`对象中。请注意，我们使用了之前检测到的设备来创建张量。一旦我们将所有值移动到张量中，我们就使用`torch::stack`函数将预测值和目标值连接到两个不同的单张量中。这是必要的，以便我们可以使用`pytorch`库的线性代数例程进行数据归一化：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Finally, we used the `torch::mean` and `torch::std` functions to calculate the
    mean and standard deviation of the predictor values and normalized them.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用了`torch::mean`和`torch::std`函数来计算预测值的平均值和标准差，并将它们进行了归一化处理。
- en: 'In the following code, we’re defining the `NetImpl` class, which implements
    our neural network:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们定义了`NetImpl`类，该类实现了我们的神经网络：
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we defined our neural network model as a network with three fully connected
    neuron layers with a linear activation function. Each layer is of the `torch::nn::Linear`
    type.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将我们的神经网络模型定义为一个具有三个全连接神经元层和线性激活函数的网络。每个层都是`torch::nn::Linear`类型。
- en: In the constructor of our model, we initialized all the network parameters with
    small random values. We did this by iterating over all the network modules (see
    the `modules` method call) and applying the `torch::nn::init::normal_` function
    to the parameters that were returned by the `named_parameters()` module’s method.
    Biases were initialized to zeros with the `torch::nn::init::zeros_` function.
    The `named_parameters()` method returned objects consisting of a string name and
    a tensor value, so for initialization, we used its `value` method.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们模型的构造函数中，我们使用小的随机值初始化了所有网络参数。我们通过遍历所有网络模块（参见`modules`方法调用）并应用`torch::nn::init::normal_`函数到由`named_parameters()`模块方法返回的参数来实现这一点。偏差使用`torch::nn::init::zeros_`函数初始化为零。`named_parameters()`方法返回由字符串名称和张量值组成的对象，因此对于初始化，我们使用了它的`value`方法。
- en: 'Now, we can train the model with our generated training data. The following
    code shows how we can train our model:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用我们生成的训练数据来训练模型。以下代码展示了我们如何训练我们的模型：
- en: '[PRE30]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: To utilize all our hardware resources, we moved the model to the selected computational
    device. Then, we initialized an optimizer. In our case, the optimizer used the
    `Adam` algorithm. After, we ran a standard training loop over the epochs where,
    for each epoch, we took the training batch, cleared the optimizer’s gradients,
    performed a forward pass, computed the loss, performed a backward pass, and updated
    the model weights with the optimizer step.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用所有我们的硬件资源，我们将模型移动到选定的计算设备。然后，我们初始化了一个优化器。在我们的例子中，优化器使用了`Adam`算法。之后，我们在每个epoch上运行了一个标准的训练循环，其中对于每个epoch，我们取训练批次，清除优化器的梯度，执行前向传递，计算损失，执行反向传递，并使用优化器步骤更新模型权重。
- en: To select a batch of training data from the dataset, we used the tensor’s `narrow`
    method, which returned a new tensor with a reduced dimension. This function takes
    a new number of dimensions as the first parameter, the start position as the second
    parameter, and the number of elements to remain as the third parameter. We also
    used the `unsqueeze` method to add a batch dimension; this is required by the
    PyTorch API for the forward pass.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据集中选择一批训练数据，我们使用了张量的`narrow`方法，该方法返回了一个维度减少的新张量。此函数接受新的维度数量作为第一个参数，起始位置作为第二个参数，以及要保留的元素数量作为第三个参数。我们还使用了`unsqueeze`方法来添加一个批次维度；这是PyTorch
    API进行前向传递所必需的。
- en: As we mentioned previously, there are two approaches we can use to serialize
    model parameters in `pytorch` in the C++ API (the Python API provides even more
    reach). Let’s look at them.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，我们可以使用两种方法在C++ API中的`pytorch`序列化模型参数（Python API提供了更多的功能）。让我们来看看它们。
- en: Using the torch::save and torch::load functions
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用torch::save和torch::load函数
- en: 'The first approach we can take to save model parameters is using the `torch::save`
    function, which recursively saves parameters from the passed module:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取的第一种保存模型参数的方法是使用`torch::save`函数，该函数递归地保存传递的模块的参数：
- en: '[PRE31]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: To use it correctly with our custom modules, we need to register all the sub-modules
    in the parent one with the `register_module` module’s method.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确地与我们的自定义模块一起使用，我们需要使用`register_module`模块的方法将所有子模块在父模块中注册。
- en: 'To load the saved parameters, we can use the `torch::load` function:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载保存的参数，我们可以使用`torch::load`函数：
- en: '[PRE32]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The function fills the passed module parameters with the values that are read
    from a file.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将读取自文件的值填充到传递的模块参数中。
- en: Using PyTorch archive objects
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PyTorch存档对象
- en: 'The second approach is to use an object of the `torch::serialize::OutputArchive`
    type and write the parameters we want to save into it. The following code shows
    how to implement the `SaveWeights` method for our model. This method writes all
    the parameters and buffers that exist in our module to the `archive` object, and
    then it uses the `save_to` method to write them in a file:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是用`torch::serialize::OutputArchive`类型的对象，并将我们想要保存的参数写入其中。以下代码展示了如何实现我们模型的`SaveWeights`方法。此方法将我们模块中存在的所有参数和缓冲区写入`archive`对象，然后它使用`save_to`方法将它们写入文件：
- en: '[PRE33]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: It’s also important to save buffer tensors. Buffers can be retrieved from a
    module with the `named_buffers` module’s method. These objects represent the intermediate
    values that are used to evaluate different modules. For example, we can be running
    mean and standard deviation values for the batch normalization module. In this
    case, we need them to continue being trained if we used serialization to save
    the intermediate steps and if our training process was stopped for some reason.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 保存缓冲区张量也很重要。可以使用 `named_buffers` 模块的 `named_buffers` 方法从模块中检索缓冲区。这些对象代表用于评估不同模块的中间值。例如，我们可以是批归一化模块的运行均值和标准差值。在这种情况下，如果我们使用序列化来保存中间步骤并且由于某种原因训练过程停止，我们需要它们继续训练。
- en: 'To load parameters that have been saved this way, we can use the `torch::serialize::InputArchive`
    object. The following code shows how to implement the `LoadWeights` method for
    our model:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载以这种方式保存的参数，我们可以使用 `torch::serialize::InputArchive` 对象。以下代码展示了如何为我们的模型实现 `LoadWeights`
    方法：
- en: '[PRE34]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Here, the `LoadWeights` method uses the `load_from` method of the `archive`
    object to load parameters from the file. First, we took the parameters and buffers
    from our module with the `named_parameters` and `named_buffers` methods and filled
    in their values incrementally with the `read` method of the `archive` object.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`LoadWeights` 方法使用 `archive` 对象的 `load_from` 方法从文件中加载参数。首先，我们使用 `named_parameters`
    和 `named_buffers` 方法从我们的模块中获取参数和缓冲区，并使用 `archive` 对象的 `read` 方法逐步填充它们的值。
- en: Notice that we used an instance of the `torch::NoGradGuard` class to tell the
    `pytorch` library that we won’t be performing any model calculation or graph-related
    operations. It’s essential to do this because the `pytorch` library’s construct
    calculation graph and any unrelated operations can lead to errors.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用 `torch::NoGradGuard` 类的实例来告诉 `pytorch` 库我们不会执行任何模型计算或图相关操作。这样做是必要的，因为
    `pytorch` 库构建计算图和任何无关操作都可能导致错误。
- en: 'Now, we can use the new instance of our `model_loaded` model with `load` parameters
    to evaluate the model on some test data. Note that we need to switch the model
    to the evaluation model with the `eval` method. Generated test data values should
    also be converted into tensor objects with the `torch::tensor` function and moved
    to the same computational device that our model uses. The following code shows
    how we can implement this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用新的 `model_loaded` 模型实例，并带有 `load` 参数来评估一些测试数据上的模型。请注意，我们需要使用 `eval`
    方法将模型切换到评估模式。生成的测试数据值也应使用 `torch::tensor` 函数转换为张量对象，并将其移动到与我们的模型使用的相同计算设备上。以下代码展示了我们如何实现这一点：
- en: '[PRE35]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In this section, we looked at two types of serialization in the `pytorch` library.
    The first approach involved using the `torch::save` and `torch::load` functions,
    which easily save and load all the model parameters, respectively. The second
    approach involved using objects of the `torch::serialize::InputArchive` and `torch::serialize::OutputArchive`
    types so that we can select what parameters we want to save and load.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了 `pytorch` 库中的两种序列化类型。第一种方法涉及使用 `torch::save` 和 `torch::load` 函数，分别轻松保存和加载所有模型参数。第二种方法涉及使用
    `torch::serialize::InputArchive` 和 `torch::serialize::OutputArchive` 类型的对象，这样我们就可以选择我们想要保存和加载的参数。
- en: In the next section, we’ll discuss the ONNX file format, which allows us to
    share our ML model architecture and model parameters among different frameworks.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论 ONNX 文件格式，它允许我们在不同的框架之间共享我们的 ML 模型架构和模型参数。
- en: Delving into the ONNX format
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨 ONNX 格式
- en: The ONNX format is a special file format that’s used to share neural network
    architectures and parameters between different frameworks. It’s based on Google’s
    Protobuf format and library. The reason why this format exists is to test and
    run the same neural network model in different environments and on different devices.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX 格式是一种特殊的文件格式，用于在不同框架之间共享神经网络架构和参数。它基于 Google 的 Protobuf 格式和库。这种格式存在的原因是测试和在不同的环境和设备上运行相同的神经网络模型。
- en: Usually, researchers use a programming framework that they know how to use to
    develop a model, and then run this model in a different environment for production
    purposes or if they want to share their model with other researchers or developers.
    This format is supported by all leading frameworks, including PyTorch, TensorFlow,
    MXNet, and others. However, there’s a lack of support for this format from the
    C++ API of these frameworks and at the time of writing, they only have a Python
    interface for dealing with the ONNX format. Despite this, Microsoft provides the
    `onnxruntime` framework to run inference with this format directly with different
    backbends, such as CUDA, CPUs, or even NVIDIA TensorRT.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，研究人员会使用他们熟悉的编程框架来开发模型，然后在不同环境中运行这个模型，用于生产目的或者他们想要与其他研究人员或开发者共享模型。这种格式得到了所有主流框架的支持，包括PyTorch、TensorFlow、MXNet以及其他。然而，这些框架的C++
    API对这种格式的支持不足，在撰写本文时，它们只为处理ONNX格式提供了Python接口。尽管如此，微软提供了`onnxruntime`框架，可以直接使用不同的后端，如CUDA、CPU或甚至NVIDIA
    TensorRT来运行推理。
- en: Before we dive into the specifics of using the framework for our use case, it’s
    important to consider certain limitations so that we can approach the problem
    statement in a well-rounded way. Sometimes, exporting to the ONNX format can be
    problematic due to the lack of certain operators or functions, which can limit
    the types of models that can be exported. Also, there can be limited support for
    dynamic dimensions for tensors and limited support for conditional operators,
    which limits our ability to use models with dynamic computational graphs and implement
    complex algorithms. These limitations depend on the target hardware. You’ll find
    that embedded devices have the most restrictions and that some of these problems
    can only be found in the inference runtime. However, there is one big advantage
    of using ONNX—usually, it’s possible to run such a model on a variety of different
    tensor math acceleration hardware.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨使用框架解决我们具体用例的细节之前，考虑某些限制因素是很重要的，这样我们可以全面地处理问题陈述。有时，由于缺少某些操作符或函数，导出为ONNX格式可能会出现问题，这可能会限制可以导出的模型类型。此外，对张量的动态维度和条件操作符的支持可能有限，这限制了使用具有动态计算图和实现复杂算法的模型的能力。这些限制取决于目标硬件。你会发现嵌入式设备有最多的限制，而且其中一些问题只能在推理运行时发现。然而，使用ONNX有一个很大的优势——通常，这样的模型可以在各种不同的张量数学加速硬件上运行。
- en: TorchScript has fewer limitations for model operators and structure than ONNX.
    It’s usually possible to export models with dynamic computational graphs that
    have been traced with all the required branches. However, there can be restrictions
    on hardware where you’ll have to infer your model. For example, usually, it’s
    not possible to use mobile GPUs or NPUs for inference with TorchScript. ExecuTorch
    should solve this problem in the future.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 与ONNX相比，TorchScript对模型操作符和结构的限制更少。通常，可以导出具有所有所需分支的动态计算图模型。然而，在您必须推断模型的地方可能会有硬件限制。例如，通常无法使用移动GPU或NPUs进行TorchScript推理。ExecTorch应该在将来解决这个问题。
- en: To utilize the available hardware as much as possible, we can use different
    inference engines from particular vendors. Usually, it’s possible to convert a
    model in the ONNX format or that’s using another method into its internal format
    to perform inference on a specific GPU or NPU. Examples of such engines include
    OpenVINO for Intel hardware, TensorRT from NVIDIA, ArmNN for ARM-based processors,
    and QNN for Qualcomm NPUs.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能多地利用可用硬件，我们可以使用特定供应商的不同推理引擎。通常，可以将ONNX格式或使用其他方法的模型转换为内部格式，以在特定的GPU或NPU上进行推理。此类引擎的例子包括Intel硬件的OpenVINO、NVIDIA的TensorRT、基于ARM处理器的ArmNN以及Qualcomm
    NPUs的QNN。
- en: Now that we’ve understood the best way in which we can utilize the framework,
    let’s understand how to use the ResNet neural network architecture for image classification.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何最好地利用这个框架，接下来让我们了解如何使用ResNet神经网络架构进行图像分类。
- en: Using the ResNet architecture for image classification
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ResNet架构进行图像分类
- en: 'Generally, we, as developers, don’t need to know how the ONNX format works
    internally because we’re only interested in the files where the model has been
    saved. As mentioned previously, internally, the ONNX format is a Protobuf-formatted
    file. The following code shows the first part of the ONNX file, which describes
    how to use the ResNet neural network architecture for image classification:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，作为开发者，我们不需要了解ONNX格式内部是如何工作的，因为我们只对保存模型的文件感兴趣。如前所述，内部上，ONNX格式是一个Protobuf格式的文件。以下代码展示了ONNX文件的第一部分，它描述了如何使用ResNet神经网络架构进行图像分类：
- en: '[PRE36]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Usually, ONNX files come in binary format to reduce file size and increase loading
    speed.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，ONNX文件以二进制格式提供，以减少文件大小并提高加载速度。
- en: Now, let’s learn how to use the `onnxruntime` API to load and run ONNX models.
    The ONNX community provides pre-trained models for the most popular neural network
    architectures in the publicly available Model Zoo ([https://github.com/onnx/models](https://github.com/onnx/models)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何使用`onnxruntime` API加载和运行ONNX模型。ONNX社区为公开可用的模型库中最流行的神经网络架构提供了预训练模型([https://github.com/onnx/models](https://github.com/onnx/models))。
- en: There are a lot of ready-to-use models that can be used to solve different ML
    tasks. For example, we can use the `ResNet-50` model for image classification
    tasks ([https://github.com/onnx/models/tree/main/validated/vision/classification/resnet/model/resnet50-v1-7.onnx](https://github.com/onnx/models/tree/main/validated/vision/classification/resnet/model/resnet50-v1-7.onnx)).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多现成的模型可以用于解决不同的机器学习任务。例如，我们可以使用`ResNet-50`模型来进行图像分类任务([https://github.com/onnx/models/tree/main/validated/vision/classification/resnet/model/resnet50-v1-7.onnx](https://github.com/onnx/models/tree/main/validated/vision/classification/resnet/model/resnet50-v1-7.onnx))。
- en: For this model, we have to download the corresponding `synset` file with image
    class descriptions to be able to return classification results in a human-readable
    manner. You can find the file at [https://github.com/onnx/models/blob/main/validated/vision/classification/synset.txt](https://github.com/onnx/models/blob/main/validated/vision/classification/synset.txt).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个模型，我们必须下载相应的包含图像类别描述的`synset`文件，以便能够以人类可读的方式返回分类结果。您可以在[https://github.com/onnx/models/blob/main/validated/vision/classification/synset.txt](https://github.com/onnx/models/blob/main/validated/vision/classification/synset.txt)找到该文件。
- en: 'To be able to use the `onnxruntime` C++ API, we have to use the following header:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用`onnxruntime` C++ API，我们必须使用以下头文件：
- en: '[PRE37]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Then, we have to create the global shared `onnxruntime` environment and a model
    evaluation session, as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须创建全局共享的`onnxruntime`环境和模型评估会话，如下所示：
- en: '[PRE38]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The `session` object takes a model’s filename as its input argument and automatically
    loads it. Here, we passed the name of the downloaded model. The last parameter
    is the `SessionOptions` type object, which can be used to specify a particular
    device executor, such as CUDA. The `env` object holds some shared runtime state.
    The most valuable state is the logging data and the logging level, which can configured
    with a constructor argument.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`session`对象将模型的文件名作为其输入参数，并自动加载它。在这里，我们传递了下载的模型的名称。最后一个参数是`SessionOptions`类型的对象，它可以用来指定特定的设备执行器，例如CUDA。`env`对象包含一些共享的运行时状态。最有价值的状态是日志数据和日志级别，这些可以通过构造函数参数进行配置。'
- en: 'Once we’ve loaded a model, we can access its parameters, such as the number
    of model inputs, the number of model outputs, and parameter names. Such information
    will be very useful if you didn’t know it beforehand because you need input parameter
    names to run inference. We can discover such model information as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们加载了一个模型，我们可以访问其参数，例如模型输入的数量、模型输出的数量和参数名称。如果您事先不知道这些信息，这些信息将非常有用，因为您需要输入参数名称来运行推理。我们可以按照以下方式发现此类模型信息：
- en: '[PRE39]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, we created a function header and initialized the memory allocator for
    strings. Now, we can print the input parameter information:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个函数头并初始化了字符串内存分配器。现在，我们可以打印输入参数信息：
- en: '[PRE40]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Once we’ve discovered the input parameters, we can print the output parameter
    information, as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们发现了输入参数，我们可以按照以下方式打印输出参数信息：
- en: '[PRE41]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Here, we used the `session` object to discover model properties. Using the `GetInputCount`
    and `GetOutputCount` methods, we got the number of corresponding input and output
    parameters. Then, we used the `GetInputNameAllocated` and `GetOutputNameAllocated`
    methods to get the parameter names by their indices. Notice that these methods
    require the `allocator` object. Here, we used the default one that was initialized
    at the top of the `show_model_info` function.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`session`对象来发现模型属性。通过使用`GetInputCount`和`GetOutputCount`方法，我们得到了相应的输入和输出参数的数量。然后，我们使用`GetInputNameAllocated`和`GetOutputNameAllocated`方法通过它们的索引来获取参数名称。请注意，这些方法需要`allocator`对象。在这里，我们使用了在`show_model_info`函数顶部初始化的默认对象。
- en: We can get the additional parameter type information with the `GetInputTypeInfo`
    and `GetOutputTypeInfo` methods by using their corresponding parameter indices.
    Then, by using these parameter type information objects, we can get the tensor
    information with the `GetTensorTypeAndShapeInfo` method. The most important piece
    of information here is the tensor shape that we got with the `GetShape` method
    of the `tensor_onfo` object. It’s important because we need to use particular
    shapes for the model input and output tensors. The shape is represented as a vector
    of integers. Now, using the `show_model_info` function, we can get model input
    and output parameter information, create the corresponding tensors, and fill them
    with data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用相应的参数索引，使用`GetInputTypeInfo`和`GetOutputTypeInfo`方法获取额外的参数类型信息。然后，通过使用这些参数类型信息对象，我们可以使用`GetTensorTypeAndShapeInfo`方法获取张量信息。这里最重要的信息是使用`tensor_onfo`对象的`GetShape`方法获取的张量形状。它很重要，因为我们需要为模型输入和输出张量使用特定的形状。形状表示为整数向量。现在，使用`show_model_info`函数，我们可以获取模型输入和输出参数信息，创建相应的张量，并将数据填充到它们中。
- en: In our case, the input is a tensor of size `1 x 3 x 224 x 224`, which represents
    the RGB image for classification. The `onnxruntime` session object takes `Ort::Value`
    type objects as input and fills them as outputs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，输入是一个大小为`1 x 3 x 224 x 224`的张量，它代表了用于分类的RGB图像。`onnxruntime`会话对象接受`Ort::Value`类型对象作为输入并将它们作为输出填充。
- en: 'The following snippet shows how to prepare the input tensor for the model:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段展示了如何为模型准备输入张量：
- en: '[PRE42]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'First, we defined constants that represent an input image’s width and height.
    Then, we created the `input_shape` object, which defines the full shape of the
    tensor, including its batch dimension. With the shape, we created the `input_image`
    vector to hold the exact image data. This data container was filled with the `read_image`
    function, something we’ll take a closer look at shortly. Finally, we created the
    `input_tensor` object with the `Ort::Value::CreateTensor` function, which takes
    the `memory_info` object and the references to the data and shape containers.
    The `memory_info` object was created with parameters to allocate the input tensor
    on the host CPU device. The output tensor can be created in the same way:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义了代表输入图像宽度和高度的常量。然后，我们创建了`input_shape`对象，它定义了张量的完整形状，包括其批次维度。有了形状，我们创建了`input_image`向量来保存确切的图像数据。这个数据容器被`read_image`函数填充，我们将在稍后对其进行详细探讨。最后，我们使用`Ort::Value::CreateTensor`函数创建了`input_tensor`对象，它接受`memory_info`对象和数据以及形状容器的引用。`memory_info`对象使用分配输入张量在主机CPU设备上的参数创建。输出张量也可以用同样的方式创建：
- en: '[PRE43]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Note that the `onnxruntime` API allows us to create an empty output tensor
    that will be initialized automatically. We can do this as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到`onnxruntime` API允许我们创建一个空的输出张量，它将被自动初始化。我们可以这样做：
- en: '[PRE44]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, we can use the `Run` method for evaluation purposes:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`Run`方法进行评估：
- en: '[PRE45]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Here, we defined the input and output parameters’ names and constants and created
    the `run_options` object with default initialization. The `run_options` object
    can be used to log verbosity configuration, while the `Run` method can be used
    to evaluate the model. Notice that the input and output tensors were passed as
    pointers to arrays with corresponding element numbers. In our case, we specified
    single input and output elements.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义了输入和输出参数的名称和常量，并使用默认初始化创建了`run_options`对象。`run_options`对象可以用来配置日志的详细程度，而`Run`方法可以用来评估模型。请注意，输入和输出张量作为指针传递到数组中，并指定了相应的元素数量。在我们的案例中，我们指定了单个输入和输出元素。
- en: 'The output of this model is image scores (probabilities) for each of the 1,000
    classes of the `ImageNet` dataset, which was used to train the model. The following
    code shows how to decode the model’s output:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的输出是针对`ImageNet`数据集的1,000个类别的图像得分（概率），该数据集用于训练模型。以下代码展示了如何解码模型的输出：
- en: '[PRE46]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Here, we iterated over each element of the result tensor data—that is, the `result`
    vector object we initialized earlier. This `result` object was filled with actual
    data values during model evaluation. Then, we placed the score values and class
    indices in the vector of corresponding pairs. This vector was sorted by score,
    in descending order. Then, we printed five classes with the maximum score.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们遍历了结果张量数据中的每个元素——即我们之前初始化的`result`向量对象。在模型评估期间，这个`result`对象被填充了实际的数据值。然后，我们将得分值和类别索引放入相应的对向量中。这个向量按得分降序排序。然后，我们打印了得分最高的五个类别。
- en: In this section, we looked at an example of how to deal with the ONNX format
    with the `onnxruntime` framework. However, we still need to learn how to load
    input images into tensor objects, something we use for the model’s input.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过`onnxruntime`框架的示例了解了如何处理ONNX格式。然而，我们仍需要学习如何将输入图像加载到张量对象中，这是我们用于模型输入的部分。
- en: Loading images into onnxruntime tensors
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将图像加载到onnxruntime张量中
- en: Let’s learn how to load image data according to the model’s input requirements
    and memory layout. Previously, we initialized an `input_image` vector of the corresponding
    size. The model expects the input images to be normalized and three-channel RGB
    images whose shapes are `N x 3 x H x W`, where *N* is the batch size and *H* and
    *W* are expected to be at least 224 pixels wide. Normalization assumes that the
    images are loaded into the`[0, 1]` range and then normalized using means equal
    to `[0.485, 0.456, 0.406]` and standard deviations equal to `[0.229,` `0.224,
    0.225]`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何根据模型的输入要求和内存布局加载图像数据。之前，我们初始化了一个相应大小的`input_image`向量。模型期望输入图像是归一化的，并且是三个通道的RGB图像，其形状为`N
    x 3 x H x W`，其中*N*是批处理大小，*H*和*W*至少应为224像素宽。归一化假设图像被加载到`[0, 1]`范围内，然后使用均值`[0.485,
    0.456, 0.406]`和标准差`[0.229, 0.224, 0.225]`进行归一化。
- en: 'Let’s assume that we have the following function definition to load images:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个以下函数定义来加载图像：
- en: '[PRE47]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let’s write its implementation. To load images, we’ll use the `OpenCV` library:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写它的实现。为了加载图像，我们将使用`OpenCV`库：
- en: '[PRE48]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Here, we read the image from a file with the `cv::imread` function. If the image
    dimensions aren’t equal to the ones that have been specified, we need to resize
    the image with the `cv::resize` function and then crop the image if the image’s
    dimensions exceed the ones that have been specified.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`cv::imread`函数从文件中读取图像。如果图像的尺寸不等于已指定的尺寸，我们需要使用`cv::resize`函数调整图像大小，然后如果图像的尺寸超过指定的尺寸，还需要裁剪图像。
- en: 'Then, we must convert the image into the floating-point type and RGB format:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须将图像转换为浮点类型和RGB格式：
- en: '[PRE49]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Once formatting is complete, we can split the image into three separate channels
    with red, green, and blue colors. We should also normalize the color values. The
    following code shows how to do this:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 格式化完成后，我们可以将图像分成三个单独的通道，分别是红色、绿色和蓝色。我们还应该对颜色值进行归一化。以下代码展示了如何进行这一操作：
- en: '[PRE50]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Here, each channel was subtracted by the corresponding mean and divided by the
    corresponding standard deviation for the normalization process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每个通道都被减去相应的均值，并除以相应的标准差，以进行归一化处理。
- en: 'Then, we should concatenate the channels:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们应该将通道连接起来：
- en: '[PRE51]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: In this case, the normalized channels were concatenated into one contiguous
    image with the `cv::vconcat` function.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，归一化后的通道被`cv::vconcat`函数连接成一个连续的图像。
- en: 'The following code shows how to copy an OpenCV image into the `image_data`
    vector:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何将OpenCV图像复制到`image_data`向量中：
- en: '[PRE52]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Here, the image data was copied into a vector of floats, which was initialized
    with the specified dimensions. The OpenCV image data was accessed with the `cv::Mat::data`
    type member. We cast the image data into the floating-point type because this
    member variable is of the `unsigned char *` type. The pixel’s data was copied
    with the standard `std::copy_n` function. This function was used to fill the `input_image`
    vector with actual image data. Then, the reference to the `input_image` vector
    data was used in the `CreateTensor` function to initialize the `Ort::Value` object.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，图像数据被复制到一个由指定维度初始化的浮点向量中。使用`cv::Mat::data`类型成员访问OpenCV图像数据。我们将图像数据转换为浮点类型，因为该成员变量是`unsigned
    char *`类型。使用标准的`std::copy_n`函数复制像素数据。这个函数被用来填充`input_image`向量中的实际图像数据。然后，使用`input_image`向量数据的引用在`CreateTensor`函数中初始化`Ort::Value`对象。
- en: Another important function that was used in the ONNX format example was a function
    that can read class definitions from a `synset` file. We’ll take a look at this
    in the next section.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在ONNX格式示例中，还使用了一个可以从`synset`文件中读取类定义的函数。我们将在下一节中查看这个函数。
- en: Reading the class definition file
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取类定义文件
- en: 'In this example, we used the `read_classes` function to load the map of objects.
    Here, the key was an image class index and the value was a textual class description.
    This function is trivial and reads the `synset` file line by line. In such a file,
    each line contains a number and a class description string, separated by a space.
    The following code shows its definition:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了`read_classes`函数来加载对象映射。在这里，键是一个图像类索引，值是一个文本类描述。这个函数很简单，逐行读取`synset`文件。在这样的文件中，每一行包含一个数字和一个由空格分隔的类描述字符串。以下代码展示了其定义：
- en: '[PRE53]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Notice that we used the `std::getline` function in the internal `while` loop
    to tokenize a single line string. We did this by specifying the third parameter
    that defines the delimiter character value.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在内部`while`循环中使用了`std::getline`函数来对单行字符串进行分词。我们通过指定定义分隔符字符值的第三个参数来实现这一点。
- en: In this section, we learned how to load the `synset` file, which represents
    the correspondence between class names and their IDs. We used this information
    to map a class ID that we got as a classification result to its string representation,
    which we showed to a user.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何加载`synset`文件，该文件表示类名与它们ID之间的对应关系。我们使用这些信息将作为分类结果得到的类ID映射到其字符串表示形式，并将其展示给用户。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to save and load model parameters in different
    ML frameworks. We saw that all the frameworks we used in the `Flashlight`, `mlpack`,
    `Dlib`, and `pytorch` libraries have an API for model parameter serialization.
    Usually, these are quite simple functions that work with model objects and some
    input and output streams. We also discussed the serialization API, which can be
    used to save and load the overall model architecture. At the time of writing,
    some of the frameworks we used don’t fully support such functionality. For example,
    the `Dlib` library can export neural networks in XML format but can’t load them.
    The PyTorch C++ API lacks exporting functionality, but it can load and evaluate
    model architectures that have been exported from the Python API with its TorchScript
    functionality. However, the `pytorch` library does provide access to the library
    API, which allows us to load and evaluate models saved in the ONNX format from
    C++. However, note that you can export a model into the ONNX format from the PyTorch
    Python API that was previously exported into TorchScript and loaded, for example.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何在不同的机器学习框架中保存和加载模型参数。我们了解到，我们在`Flashlight`、`mlpack`、`Dlib`和`pytorch`库中使用的所有框架都有一个用于模型参数序列化的API。通常，这些函数很简单，与模型对象和一些输入输出流一起工作。我们还讨论了可以用于保存和加载整体模型架构的序列化API。在撰写本文时，我们使用的某些框架并不完全支持此类功能。例如，`Dlib`库可以以XML格式导出神经网络，但不能加载它们。PyTorch
    C++ API缺少导出功能，但它可以加载和评估从Python API导出并使用TorchScript功能加载的模型架构。然而，`pytorch`库确实提供了对库API的访问，这允许我们从C++中加载和评估保存为ONNX格式的模型。然而，请注意，您可以从之前导出为TorchScript并加载的PyTorch
    Python API中导出模型到ONNX格式。
- en: We also briefly looked at the ONNX format and realized that it’s quite a popular
    format for sharing models among different ML frameworks. It supports almost all
    operations and objects that are used to serialize complex neural network models
    effectively. At the time of writing, it’s supported by all popular ML frameworks,
    including TensorFlow, PyTorch, MXNet, and others. Also, Microsoft provides the
    ONNX runtime implementation, which allows us to run the ONNX model’s inference
    without having to depend on any other frameworks.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还简要地了解了ONNX格式，并意识到它是一种在不同的机器学习框架之间共享模型非常流行的格式。它支持几乎所有用于有效地序列化复杂神经网络模型的操作和对象。在撰写本文时，它得到了所有流行的机器学习框架的支持，包括TensorFlow、PyTorch、MXNet和其他框架。此外，微软提供了ONNX运行时实现，这使得我们可以在不依赖任何其他框架的情况下运行ONNX模型的推理。
- en: At the end of this chapter, we developed a C++ application that can be used
    to run inference on the ResNet-50 model, which was trained and exported in ONNX
    format. This application was made with the onnxruntime C++ API so that we could
    load the model and evaluate it on the loaded image for classification.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章末尾，我们开发了一个C++应用程序，可以用来在ResNet-50模型上进行推理，该模型是在ONNX格式下训练和导出的。这个应用程序是用onnxruntime
    C++ API制作的，这样我们就可以加载模型并在加载的图像上进行分类评估。
- en: In the next chapter, we’ll discuss how to deploy ML models that have been developed
    with C++ libraries to mobile devices.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何将使用C++库开发的机器学习模型部署到移动设备上。
- en: Further reading
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Dlib documentation: [http://Dlib.net/](http://dlib.net/)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dlib文档：[http://Dlib.net/](http://dlib.net/)
- en: 'PyTorch C++ API: [https://pytorch.org/cppdocs/](https://pytorch.org/cppdocs/)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch C++ API：[https://pytorch.org/cppdocs/](https://pytorch.org/cppdocs/)
- en: 'ONNX official page: [https://onnx.ai/](https://onnx.ai/)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ONNX官方页面：[https://onnx.ai/](https://onnx.ai/)
- en: 'ONNX Model Zoo: [https://github.com/onnx/models](https://github.com/onnx/models)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ONNX模型库：[https://github.com/onnx/models](https://github.com/onnx/models)
- en: 'ONNX ResNet models for image classification: [https://github.com/onnx/models/blob/main/validated/vision/classification/resnet](https://github.com/onnx/models/blob/main/validated/vision/classification/resnet)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ONNX ResNet模型用于图像分类：[https://github.com/onnx/models/blob/main/validated/vision/classification/resnet](https://github.com/onnx/models/blob/main/validated/vision/classification/resnet)
- en: '`onnxruntime` C++ examples: [https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`onnxruntime` C++示例：[https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/c_cxx)'
- en: 'Flashlight documentation: [https://fl.readthedocs.io/en/stable/index.html](https://fl.readthedocs.io/en/stable/index.html)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flashlight文档：[https://fl.readthedocs.io/en/stable/index.html](https://fl.readthedocs.io/en/stable/index.html)
- en: 'mlpack documentation: [https://rcppmlpack.github.io/mlpack-doxygen/](https://rcppmlpack.github.io/mlpack-doxygen/)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mlpack文档：[https://rcppmlpack.github.io/mlpack-doxygen/](https://rcppmlpack.github.io/mlpack-doxygen/)
