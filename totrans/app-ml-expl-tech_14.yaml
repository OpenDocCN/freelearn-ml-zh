- en: '*Chapter 11*: End User-Centered Artificial Intelligence'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the last 10 chapters of this book, we have traveled over the entire landscape
    of **Explainable AI** (**XAI**), covering different types of explainability methods
    used in practice for different dimensions of explainability (*data*, *model*,
    *outcome*, and the *end users*). XAI is an active field of research that I think
    is yet to reach its full potential. But the field is growing rapidly, along with
    the broader domain of AI, and we will witness many new algorithms, approaches,
    and tools being developed in the future. Most likely, the new methods and tools
    of XAI will be better than the existing ones and will be able to tackle some of
    the *open challenges of XAI* discussed in [*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209),
    *XAI Industry Best Practices*. Unfortunately, we cannot extend the scope of this
    book to cover all possible approaches to XAI. However, the goal of this book is
    to provide a blend of conceptual understanding of the field with the required
    practical skills so that it is a useful starting point for beginners, and even
    add to the knowledge of experts for an applied knowledge of XAI.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed the recommended practices for implementing
    an explainable **Machine Learning** (**ML**) system from the industry perspective.
    We also discussed the existing challenges of XAI and some recommended ways to
    mitigate the challenges. Considering these existing challenges, in this chapter,
    we will focus on the ideology of **End User-Centered Artificial Intelligence**
    (**ENDURANCE**). This is a term that is often used to refer to sustainable and
    scalable AI solutions that are built, keeping the user in the center. It is recommended
    that you read the previous chapter before starting this chapter for a better understanding.
    ENDURANCE is neither a new algorithm nor a new, sophisticated tool for XAI. Instead,
    it is a practice; it is a methodical discipline to bridge the AI-end user gaps.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will be particularly useful for researchers from the field of AI
    and **Human-Computer Interaction** (**HCI**) who view XAI from a *multidisciplinary
    perspective*. It is also useful for business leaders who want to drive problem
    solving using AI, considering a seamless **User Experience** (**UX**). For AI
    developers and thought leaders, this chapter will help you to design your AI solutions
    keeping the end user in the center and promoting AI adoption.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter focuses on the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: User-centered XAI/ML systems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rapid XAI prototyping using EUCA
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efforts toward increasing user acceptance of AI/ML systems using XAI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing delightful UX
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What's next in XAI?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's proceed with the first topic of discussion in the next section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: User-centered XAI/ML systems
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For most industrial problems, AI solutions are developed in isolation and users
    are only introduced in the final stages of the development process after a minimum
    viable solution is ready. With this conventional approach, it is often found that
    product leads or product managers tend to focus on projecting the solution from
    the development team's perspective to meet the goals of the users. Well, this
    approach is absolutely fine, and it might work really well for certain use cases
    that require the technical team to develop through abstraction. However, if the
    users are not involved in the early stages of the implementation process, it has
    been often found that the users are reluctant to adopt the solution. So, the ENDURANCE
    ideology is focused on developing solutions by involving final users right from
    the design phase of the solution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数工业问题，AI解决方案都是在孤立的情况下开发的，用户仅在最小可行解决方案准备好的开发过程的最后阶段被引入。采用这种传统方法，常常发现产品负责人或产品经理倾向于从开发团队的视角来预测解决方案，以满足用户的目标。嗯，这种方法绝对没问题，并且对于需要技术团队通过抽象进行开发的某些用例来说，可能会非常有效。然而，如果用户没有在实施过程的早期阶段参与，常常发现用户不愿意采用该解决方案。因此，ENDURANCE理念专注于从解决方案的设计阶段就涉及最终用户来开发解决方案。
- en: The ENDURANCE ideology focuses on the principles of HCI and emphasizes the importance
    of *distributed cognition* of the user. With this ideology, the entire solution
    comprising the **User Interface** (**UI**), *AI algorithms*, *underlying dataset*,
    *XAI component*, and *end user's experience* is considered collectively as a *system*,
    rather than considering the individual components in isolation. This ensures that
    explainability is baked into the system instead of being offered as an add-on
    service for the user. From what I have observed, most industrial AI solutions
    are developed in isolation as a separate component and then added to the main
    software system as an *add-on* or *premium feature*. Similarly, the XAI component
    is also considered an add-on feature after being developed in isolation. Consequently,
    the seamless UX can get hampered, and the main benefits of the AI solution and
    the XAI component may not be realized to their full potential. This is why we
    should focus on the design and development of the entire user-centric XAI/ML system.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ENDURANCE理念专注于人机交互（HCI）的原则，并强调用户*分布式认知*的重要性。根据这一理念，整个解决方案，包括**用户界面**（**UI**）、*AI算法*、*底层数据集*、*XAI组件*和*最终用户体验*，被视为一个整体系统，而不是孤立地考虑各个组件。这确保了可解释性被内置于系统中，而不是作为提供给用户的附加服务。从我观察到的来看，大多数工业AI解决方案都是作为单独的组件在孤立的情况下开发的，然后作为*附加功能*或*高级功能*添加到主软件系统中。同样，XAI组件也是在孤立开发后被视为附加功能。因此，无缝的用户体验可能会受到影响，AI解决方案和XAI组件的主要好处可能无法充分发挥。这就是为什么我们应该关注整个以用户为中心的XAI/ML系统的设计和开发。
- en: Next, let's discuss the various aspects of end user-centric XAI that we should
    consider while designing the solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论在设计解决方案时应该考虑的以最终用户为中心的XAI的各个方面。
- en: Different aspects of end user-centric XAI
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以最终用户为中心的XAI的不同方面
- en: In this section, we will discuss the different principles of human factors that
    should be integrated while designing the XAI system using the ENDURANCE ideology
    for bridging the AI and end user gap.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论在设计XAI系统时应该整合的不同人因原则，使用ENDURANCE理念来弥合AI和最终用户之间的差距。
- en: Goal relevance
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标相关性
- en: The primary questions that the field of HCI tries to address are *Who are the
    users?* and *What are their needs?* Or in other words, it tries to understand
    the *goal relevance* of the solution for the user. If the solution provided is
    not effectively solving the problem by meeting the needs of the users without
    introducing other challenges, it is not relevant. Not considering the goal relevance
    is probably one of the main reasons why the majority of AI solutions are either
    scrapped or adopted with a lot of skepticism.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人机交互领域试图解决的主要问题是*用户是谁？*和*他们的需求是什么？*或者换句话说，它试图理解解决方案对用户的*目标相关性*。如果提供的解决方案没有通过满足用户需求来有效解决问题，而没有引入其他挑战，那么它是不相关的。不考虑目标相关性可能是大多数AI解决方案被废弃或带着很多怀疑态度采用的主要原因之一。
- en: The recommended approach to evaluate goal relevance is by checking whether the
    users can achieve their goals without the introduction of other challenges. Along
    with goal relevance, I often recommend assessing the impact of the solution. The
    impact of the solution can be qualitatively measured by taking the user's feedback
    when the solution is absent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 评估目标相关性的推荐方法是检查用户是否能够在不引入其他挑战的情况下实现他们的目标。除了目标相关性之外，我经常建议评估解决方案的影响。当解决方案不存在时，可以通过收集用户的反馈来定性衡量解决方案的影响。
- en: Connecting the user needs with the strengths of AI
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将用户需求与AI优势联系起来
- en: As discussed before, in most industrial use cases, XAI is used in isolation
    to provide explainability without considering the user needs. Instead, using the
    ideology of ENDURANCE, XAI should connect the user needs with the strength of
    the AI algorithm. Once the user needs are identified, *translate the user needs
    into data needs and model needs*. If the underlying dataset is not sufficient
    to meet all the user needs, use **data-centric XAI** to communicate the limitations
    of the dataset to the user. If the model needs are identified, use XAI to interpret
    the working of the model, and tune accordingly to meet the needs of the user.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在大多数工业用例中，XAI被单独使用以提供可解释性，而不考虑用户需求。相反，使用ENDURANCE的理念，XAI应该将用户需求与AI算法的优势联系起来。一旦确定了用户需求，*将用户需求转化为数据需求和模型需求*。如果基础数据集不足以满足所有用户需求，则使用**以数据为中心的XAI**向用户传达数据集的限制。如果确定了模型需求，则使用XAI来解释模型的工作原理，并相应调整以满足用户需求。
- en: But this process can be challenging as it involves identifying the existing
    *mental model* of the user. With the introduction of AI and XAI, the existing
    workflow should not get disrupted.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个过程可能具有挑战性，因为它涉及到识别用户的现有*心理模型*。随着AI和XAI的引入，现有的工作流程不应被打乱。
- en: Moreover, it is also recommended that using XAI, you try to explain whether
    the AI solution is adding any unique value. But design the explainability methods
    to justify the advantages and not the underlying technology used. For example,
    if the system conveys to the user that complex deep learning algorithms are used
    to predict the outcome, it does not increase the confidence of the user. Instead,
    if the system conveys that the intelligent solution helps the user to reach their
    goal five times faster than the conventional approach, the user will agree to
    adopt the solution.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还建议使用XAI尝试解释AI解决方案是否增加了任何独特的价值。但设计可解释性方法以证明优势，而不是所使用的底层技术。例如，如果系统向用户传达使用复杂的深度学习算法来预测结果，这并不会增加用户的信心。相反，如果系统传达智能解决方案可以帮助用户比传统方法快五倍地达到目标，用户将同意采用该解决方案。
- en: User interface – a medium to connect users with the AI solution
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户界面 - 连接用户与AI解决方案的媒介
- en: Considering the conventional approaches, most AI practitioners are focused only
    on developing accurate AI models giving much less focus to the user's interaction
    with the model. Generally, the user's interaction with the AI component is decided
    by the software engineering teams; unfortunately, in most organizations, the data
    science and AI teams work in silos. But it is the UI that controls the level of
    visibility, explainability, or interpretability of the AI models and plays a vital
    role in influencing the user's trust in the system.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到传统方法，大多数AI从业者只专注于开发准确的AI模型，而对用户与模型之间的交互关注较少。通常，用户与AI组件的交互由软件工程团队决定；不幸的是，在大多数组织中，数据科学和AI团队是孤立的。但UI控制着AI模型的可视化、可解释性或可理解性的水平，并在影响用户对系统的信任方面发挥着至关重要的作用。
- en: 'In [*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209), *XAI Industry Best
    Practices*, while discussing **Interactive Machine Learning** (**IML**), we discussed
    how the user''s interaction with the system through the UI gives more confidence
    to the user about the working of the AI/ML system. Hence, the UI should be in
    alignment with the AI model and its explainability methods to calibrate the user''s
    trust. You can find out more about calibrating the user''s trust using the UI
    in the People + AI Guidebook from Google PAIR: [https://pair.withgoogle.com/chapter/explainability-trust/](https://pair.withgoogle.com/chapter/explainability-trust/).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Involvement of the end user early in the development process of the solution
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike conventional approaches, the user-centric approach recommends involving
    the final user(s) early in the development process. The end user should in fact
    be involved from the design phase of the UI of the system, so that the needs of
    the user are correctly mapped into the interface. Similar to the design and development
    life cycle of the solution, explainability should also be evolved in an iterative
    process by taking continuous feedback from the user.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: As the ENDURANCE ideology views the XAI/ML system as one solution, the entire
    solution should have a *design phase*, *prototype phase*, *development phase*,
    and *evaluation phase*. These four phases would collectively form *one iteration
    of design and development*. Likewise, the entire solution should be matured in
    several iterations, keeping the user involved in every single phase of each iteration.
    This process is also in alignment with the *agile methodology* followed in software
    engineering. Involvement of the user in every phase ensures that useful feedback
    is collected for evaluating whether the user's needs are being met by the solution.
    Early involvement also ensures that the users are familiar with the design and
    working of the new system. Users' familiarity with the system increases the adoption
    rate of the system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Connecting feedback with personalization
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As discussed in the previous section, the importance of the user's feedback
    in every phase of the design and development of the solution is inevitable. But
    sometimes, a general framework of a solution doesn't fulfill all needs of the
    user.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: For example, when using counterfactual examples, it is technically possible
    to generate an example using all the features used for the prediction. But suppose
    the user is only interested in changing a specific set of actionable variables.
    In that case, the controlled counterfactuals should modify only the features that
    are interesting to the user. It has been found that a tailor-made personalized
    solution is often more useful to the end user than a generalized solution. So,
    using the feedback obtained from the user, try to provide a personalized solution
    meeting the specific pain points of the user.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Contextual and actionable AI
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we previously discussed in [*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209),
    *XAI Industry Best Practices*, explanations should be contextual and actionable.
    The entire XAI/ML system should also be in alignment with the user's actions and
    should have context awareness. XAI plays a vital role in connecting AI to the
    user's action and modifying any AI solution into a contextual AI solution.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '*Oliver Brdiczka*, in his article *Contextual AI: The Next Frontier of Artificial
    Intelligence* ([https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence](https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence)),
    defined the following four pillars of contextual AI:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '**Intelligible**: Contextual AI systems should be able to explain its knowledge
    and working.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive**: Contextual AI systems should be able to adapt to the different
    needs of the user in a different environment.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customizable**: The users should be able to control or modify the system
    to meet their needs.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Context-aware**: The system should be able to perceive things at the same
    level as a human.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows the four different components of contextual AI:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Four components of contextual AI (inspired by https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18216_11_001.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – Four components of contextual AI (inspired by https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: So, considering user-centric approaches, the XAI component of XAI/ML systems
    should provide actionable insights and it should be contextual to further bridge
    the gap between AI and end users. Now that we have discussed the user-centric
    approaches to bridge possible gaps between AI and end users, considering the open
    challenges of XAI discussed in [*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209),
    *XAI Industry Best Practices*, let's discuss making rapid XAI prototypes using
    the **End User-Centric Explainable Artificial Intelligence** (**EUCA**) framework.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Rapid XAI prototyping using EUCA
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we discussed the key ingredients of a user-centered
    XAI/ML system. In this section, the importance of rapid prototyping in the ENDURANCE
    ideology will be emphasized. *Rapid prototyping* is a concept that is predominantly
    adopted in software engineering as software is probably the most malleable thing
    created by mankind. Building fast prototypes is an approach for collecting useful
    user feedback early in the development process of a software product. Hence, even
    for designing user-centered XAI/ML systems, rapid prototyping is very important.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '*Jin et al.*, in their research work *EUCA: the End-User-Centered Explainable
    AI Framework* ([https://arxiv.org/abs/2102.02437](https://arxiv.org/abs/2102.02437)),
    introduced a toolkit called EUCA. EUCA is a very interesting framework primarily
    designed by UX researchers, HCI researchers and designers, AI scientists, and
    developers for building rapid XAI prototypes for non-technical end users. The
    official GitHub repository for the EUCA framework is available at [https://github.com/weinajin/end-user-xai](https://github.com/weinajin/end-user-xai).
    It is strongly recommended to use EUCA to build low-fidelity prototypes and iteratively
    improve the prototype based on continuous user feedback for XAI/ML systems.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The following important components are offered by this framework:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 12 explanatory forms for designing human-friendly explanations
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Corresponding XAI algorithms for integrating with functional prototypes
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Associated design templates and examples of their usage
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suggested prototyping workflows
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed strengths and weaknesses of various explanation methods obtained from
    their user study findings
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scientific analysis of diverse explanation needs of end users (such as calibration
    of trust, detection of bias, and resolution of disagreements with AI)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure illustrates the different types of explanation methods
    currently supported by the EUCA framework:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Different types of explanation methods supported in EUCA'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18216_11_002.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – Different types of explanation methods supported in EUCA
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: This framework is a great starting point and definitely recommended for building
    rapid XAI prototypes. Next, let's discuss some additional efforts that can be
    made to increase user acceptance of AI/ML systems.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Efforts toward increasing user acceptance of AI/ML systems using XAI
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will discuss some recommended practices to increase the
    acceptance of AI/ML systems using XAI. In most software systems, the **User Acceptance
    Testing** (**UAT**) phase is used to determine the *go* or *no-go* for software.
    Similarly, before the final production phase, more and more organizations prefer
    doing a robust UAT process for AI/ML systems. But *how important is the explainability
    of AI algorithms, when doing UAT of AI/ML systems?* *Can explainability increase
    the user acceptance of AI?* The short answer is *yes*! Let''s go through the following
    points to understand why:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**User acceptance is a testimony of the user''s trust** – Since XAI can increase
    the user''s trust in AI, it increases the chance of the user''s acceptance of
    the solution. Now, trust is something that cannot just be established during the
    UAT phase; rather, trust should be established from the beginning and maintained
    throughout the development process. The capabilities and limitations of the system
    should be communicated from the beginning to set a clear expectation of what is
    possible and what is not possible.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Risk tolerance estimation as UAT criteria** – It is quite obvious that AI
    systems cannot be 100% accurate every single time. It is not practically possible
    to achieve systems that have zero error or zero failure. But as a recommended
    practice, it is important to document the possible failure points for the system
    and the consequences of the potential failures of the system are termed **risk**.
    **Risk tolerance** is the maximum permissible error that the system can make without
    causing a huge impact. So, during the UAT phase, it is important to define the
    risks of the solution and have an estimation of the maximum risk tolerance of
    the user. The system''s ability to perform within the risk tolerance should be
    considered a success criterion for the UAT process.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将风险容忍度估计作为UAT标准** – 很明显，AI系统不可能每次都100%准确。实现零错误或零失败的系统在实际上是不可能的。但作为一种推荐做法，记录系统的可能故障点和潜在故障的后果被称为**风险**。**风险容忍度**是系统在不造成巨大影响的情况下可以犯的最大允许错误。因此，在UAT阶段，定义解决方案的风险并估计用户最大风险容忍度非常重要。系统在风险容忍度内的性能应被视为UAT过程的成功标准。'
- en: '**Perform as many user studies as possible before the UAT process** – User
    studies and qualitative and quantitative analysis of the user''s feedback are
    certain ways by which the impact and trust of the system can be assessed. So,
    perform multiple user studies before the UAT process and ensure that the users
    are accepting the prototype solutions before directly moving the system into production.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在UAT（用户验收测试）过程之前尽可能多地执行用户研究** – 用户研究和用户反馈的定性和定量分析是评估系统影响力和信任度的确定方式。因此，在UAT过程之前进行多次用户研究，并确保用户在接受原型解决方案之前直接将系统投入生产。'
- en: The preceding approaches are certain ways to increase user acceptance, but ultimately,
    user acceptance depends on the overall UX. In the next section, we will discuss
    further the importance of providing a delightful UX.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的方法是提高用户接受度的确定方式，但最终，用户接受度取决于整体用户体验。在下一节，我们将进一步讨论提供愉悦用户体验的重要性。
- en: Providing a delightful UX
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供愉悦的用户体验
- en: 'In this section, we will focus on the importance of overall UX to promote the
    adoption of XAI/ML systems. *Aaron Walter*, in his book *Designing for Emotion*
    ([https://abookapart.com/products/designing-for-emotion](https://abookapart.com/products/designing-for-emotion)),
    mentioned some of the foundational elements of user needs that must be met before
    higher motivation can influence the behavior of the user. According to his hierarchy
    of user needs, *pleasurable* or *delightful* UX is at the top of the pyramid.
    The following figure shows Aaron Walter''s hierarchy of user needs:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注整体用户体验的重要性，以促进XAI/ML系统的采用。*阿伦·沃尔特*在他的书《情感设计》([https://abookapart.com/products/designing-for-emotion](https://abookapart.com/products/designing-for-emotion))中提到了在更高动机影响用户行为之前必须满足的用户需求的基础要素。根据他的用户需求层次结构，*愉悦*或*令人愉悦*的UX位于金字塔的顶端。以下图显示了阿伦·沃尔特的用户需求层次结构：
- en: '![Figure 11.3 – Aaron Walter''s hierarchy of user needs'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.3 – 阿伦·沃尔特的用户需求层次结构'
- en: '](img/B18216_11_003.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18216_11_003.jpg]'
- en: Figure 11.3 – Aaron Walter's hierarchy of user needs
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 – 阿伦·沃尔特的用户需求层次结构
- en: This hierarchy of user needs defines the fundamental needs of the end user that
    should be fulfilled before any advanced needs of the user are addressed. So, if
    a system is only *functional*, *reliable*, and *usable*, it is not sufficient
    for adopting the system unless the overall UX is delightful and enjoyable! Hence,
    XAI/ML systems should also consider providing a seamless overall experience to
    truly bridge the AI-end user gap.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用户需求层次结构定义了在解决用户的高级需求之前应该满足的最终用户的基本需求。因此，如果一个系统仅仅是*功能性*、*可靠*和*可用*，那么除非整体用户体验是愉悦和令人享受的，否则采用该系统是不够的！因此，XAI/ML系统也应考虑提供无缝的整体体验，以真正弥合AI与最终用户之间的差距。
- en: This brings us to the end of the last chapter of this book. We will summarize
    the key topics of discussion in the next section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的上一章到此结束。我们将在下一节总结讨论的关键主题。
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have primarily discussed using the ideology of ENDURANCE
    for the design and development of XAI/ML systems. We have discussed the importance
    of using XAI to steer us toward the main goals of the end user for building XAI/ML
    systems. Using some of the principles and recommended best practices presented
    in the chapter, we can bridge the gap between AI and the end user to a great extent!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: This also brings us to the end of this book! Congratulations on reaching the
    end! This book was carefully designed to include conceptual understanding of various
    XAI concepts and jargon, practical examples to use popular XAI frameworks for
    applied problem solving, real-life examples and experiences from an industrial
    perspective, and references to important research literature to further expand
    your knowledge. This book introduced you to the field of XAI from both the industrial
    perspective as well as an academic research perspective. The open challenges and
    the next phases of XAI research topics discussed in this book are important research
    problems that are being explored by the AI research community.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Even though this book touched on almost every aspect of the field of XAI, clearly
    there are lots more to explore and unravel. My recommendation is not to restrict
    yourself to what was offered by this book. Instead, use this book as a reference
    starting point but explore and apply the knowledge gained from this book to practical
    use cases and step forward to contribute to the community!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please refer to the following resources to gain additional information:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '*People + AI Guidebook from Google PAIR*: [https://pair.withgoogle.com/chapter/explainability-trust/](https://pair.withgoogle.com/chapter/explainability-trust/)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Jin et al.*, *EUCA: the End-User-Centered Explainable AI Framework*: [https://arxiv.org/abs/2102.02437](https://arxiv.org/abs/2102.02437)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EUCA: End-User-Centered Explainable AI Framework GitHub repository*: [https://github.com/weinajin/end-user-xai](https://github.com/weinajin/end-user-xai)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Aaron Walter*, *Designing for Emotion*: [https://abookapart.com/products/designing-for-emotion](https://abookapart.com/products/designing-for-emotion)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Oliver Brdiczka*, *Contextual AI: The Next Frontier of Artificial Intelligence*:[https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence](https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
