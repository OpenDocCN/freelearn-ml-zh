- en: Deep Learning Image Classification with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to classify images using TensorFlow. First,
    we will use a pre-trained model, and then we'll proceed with training our own
    model using custom images.
  prefs: []
  type: TYPE_NORMAL
- en: Toward the end of the chapter, we will make use of the GPU to help us speed
    up our computations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A deep introduction to TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a pre-trained model (Inception) for image classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retraining with our own images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speeding up computation with the GPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Along with knowledge of Python and the basics of image processing and computer
    vision, you will need the following libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA CUDA® Deep Neural Network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code used in the chapter has been added to the following GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3)'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll go deeper into TensorFlow and see how we can build a
    general-purpose image classifier using its deep learning method.
  prefs: []
  type: TYPE_NORMAL
- en: This will be an extension of what we learned in Chapter 2, *Handwritten Digit
    Recognition with scikit-learn and TensorFlow,* where we learned how to classify
    handwritten digits. However, this method is quite a bit more powerful, as it will
    work on general images of people, animals, food, everyday objects, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: To start, let's talk a little bit about what TensorFlow does, and the general
    workflow of TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, what is a tensor? Wikipedia states this:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"In mathematics, tensors are geometric objects that describe linear relations
    between geometric vectors, scalars, and other tensors... Given a reference basis
    of vectors, a tensor can be represented as an organized multi-dimensional array
    of numerical values."*'
  prefs: []
  type: TYPE_NORMAL
- en: However, according to Google, the makers of TensorFlow, a tensor is any multi-dimensional
    array with any data type. Essentially, according to Google, a tensor can mean
    basically anything.
  prefs: []
  type: TYPE_NORMAL
- en: Google has generalized the word so much that it doesn't really mean a lot, and
    personally I don't like that (coming from an engineering and physics background).
    However, TensorFlow is so powerful and useful that I'm going to get over it. Just
    be aware that if you're ever worried about misusing the word *tensor*, don't be,
    because Google completely misuses it anyway.
  prefs: []
  type: TYPE_NORMAL
- en: For now, all we need to know is that within TensorFlow, a tensor is some sort
    of data; usually a multi-dimensional array, but it could be basically anything,
    such as images or text. With that in mind, TensorFlow is, in general, a high-performance
    numerical library. It is primarily geared toward machine learning, but that doesn't
    mean that it's exclusively made for machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow can also be used for simulations, solving complex partial differential
    equations, and just about anything numerical. We're only concerned with machine
    learning and, in particular, deep learning in this chapter. We are going to be
    using it for its main purpose, but just be aware that it's generally used for
    constructing and analyzing complex numerical models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go into building a classifier, I want to share a little bit about
    how we would generally use TensorFlow for very basic usage. Start as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re going to change directories, and make sure that we can load key libraries
    and display images and so forth, using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we import `tensorflow` and `numpy`, using the standard convention:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Since we performed `pylab inline`, we don't explicitly need to import `numpy`,
    but it's a good practice in general. If we want to copy some of this code out
    to other scripts, we need to make sure that `numpy` is imported.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with a simple TensorFlow example. We''re just going to perform
    some really basic arithmetic. Define some constants within TensorFlow, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: These constants can be just scalars, as we defined, or they could be vectors
    or matrices. We're just going to add them together. When we do that, we can define
    our constants.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define constants, and then we create a TensorFlow session using the `with`
    clause. When it goes outside the `with` clause, we''ll close the TensorFlow session,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`Session` can be important depending on what resources we''re using, for example,
    if we''re using a GPU and we want to release it, but in this section, we''re just
    going to be talking about the `Session` using the CPU.'
  prefs: []
  type: TYPE_NORMAL
- en: Within our `Session`, TensorFlow has operator overloading where it makes sense.
    It understands what is meant by `a+b`, where `a` and `b` are both TensorFlow constants. It
    also understands arithmetic operations such as multiply (`*`), minus (`-`), divide
    (`/`), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''re going to do the same thing using a different method, by creating `placeholder`
    variables, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Often, we need to construct our model. That's what TensorFlow is based on, it's
    basically an input-output model. So, we have our input, which could be numbers,
    images, words, or whatever. We generally need to find placeholders before we input
    our data, and then define and construct our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, we''re just defining addition, just as we would normally define
    it, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This could be something more complex such as building a neural network, a **convolutional
    neural network** (**CNN**), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: We'll see a bit of that momentarily, but for now we define our inputs, our model,
    our operations, and so on, and we create what is called a *graph*, which will
    take our inputs and map them to the desired outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we''re going to create a `session`, and then we''re going to run
    our operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, we have to tell it what the values are, and then it does exactly
    what we expect, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c00971ea-14ad-4385-8110-bc8d991bd7a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Nothing too exciting—this is just so we understand a little bit about what TensorFlow
    is doing. We'll take advantage of some higher-level libraries for this chapter,
    but this is important if we want to go further in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we''re going to do matrix multiplication. As mentioned earlier,
    the constants can be more than just scalars. In this case, we''re defining matrices, a
    2 by 2 matrix and a 2 by 1 matrix, using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We define our matrices as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we tell it to multiply matrices, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We create our session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we run it, and then print the results. The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d42cb84-37b0-4191-9e76-247f5a004f9a.png)'
  prefs: []
  type: TYPE_IMG
- en: Again, very basic, but very important in the future. We're not going to define
    our full network in this lesson, because that's very complex and very time-consuming
    to execute, but just mention the general steps for creating our own CNN.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to create what is known as layers, define our input, and then we
    create a bunch of layers and stack them together and define how they're connected.
    We then find the output layer and then we have to define some other things like
    how we're going to train and how we're going to evaluate it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Again, this is just for our knowledge. Deep learning is a difficult subject,
    figuring out the necessary architecture and exactly how to train, which is beyond
    the scope of this chapter (although I would invite you to learn more about it).
    Here, we're just going to see how we can utilize what's already done—but if you
    want to go further, this is where you would start.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we're going to see how to use a pre-trained model, Inception,
    to perform our image classification.
  prefs: []
  type: TYPE_NORMAL
- en: Using Inception for image classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to use a pre-trained model, Inception, from Google
    to perform image classification. We'll then move on and build our own model—or,
    at least do some retraining on the model in order to train on our own images and
    classify our own objects.
  prefs: []
  type: TYPE_NORMAL
- en: For now, we want to see what we can do with a model that's already trained,
    which would take a lot of time to reproduce from scratch. Let's get started with
    the code.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go back to Jupyter Notebook. The Notebook file can be found at [https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/Chapter04](https://github.com/PacktPublishing/Computer-Vision-Projects-with-OpenCV-and-Python-3/Chapter04).
  prefs: []
  type: TYPE_NORMAL
- en: In order to run the code, we're going to need to download a file from TensorFlow's
    website, from the following link: [http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz](http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz).
    This is the Inception model.
  prefs: []
  type: TYPE_NORMAL
- en: The model was trained in 2015\. It contains a couple of files that define the
    model, the *graph* as it is called, defining the input-output relation between
    the input images that we provide it and the output classification.
  prefs: []
  type: TYPE_NORMAL
- en: It also contains some labeling data because the output isn't class names; it
    is numbers. This is modified from Google own TensorFlow's example, to make it
    easier to understand and run in Jupyter Notebook and reduce the amount of code.
    However, we need to change that.
  prefs: []
  type: TYPE_NORMAL
- en: Get the file and completely unzip it. On Windows, readers might use 7-Zip, which
    will give a TGZ file. Make sure to then untar the TGZ file to get the TXT, PBTXT,
    and PB files, particularly the PB file, as that is the one that actually contains
    the trained model.
  prefs: []
  type: TYPE_NORMAL
- en: We create a file called `inceptiondict`, rather than using Google's own convoluted
    file for mapping the class numbers to the class name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `inceptiondict` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/496f7a1f-36c0-41db-8c62-cfb74534d5dc.png)'
  prefs: []
  type: TYPE_IMG
- en: This file has a thousand classes. It would take a very long time to train this
    yourself, but we don't have to; we can take advantage of this and build off it,
    as we'll see later.
  prefs: []
  type: TYPE_NORMAL
- en: This file is interesting to look at if we want to know what kinds of images
    we'll be able to recognize within this pre-built model. There are a lot of animals
    in the file, some common items, fruits, musical instruments, different kinds of
    fish; it even recognizes the Japanese game *shoji*, apparently.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to import this file as a dictionary called `inceptiondict`, which
    will map numbers to their corresponding class descriptions; for example, class
    `1` maps to the description `"goldfish, Carassius auratus"`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s explore the main code. Firstly, we import the file as `inceptiondict`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have our `run_inference_on_image` function, where `image` is a filename.
    It is not the file data—we haven't loaded that yet—just the filename for the image
    that we want to classify.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we check to make sure that filename exists, and create an error if it
    doesn''t. If it does exist, then we use TensorFlow''s own loading mechanism in
    order to read that filename, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We were talking about the graph file before. Unzip the the crucial `classify_image_graph_def.pb` file
    from the TGZ file to the current directory. Open that as a binary by using TensorFlow''s
    own file loading mechanism, and then we''re going to create our graph definition
    from that, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are just loading the pre-trained model. Google already did the hard
    work for us, and we're going to read from that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, as we did previously, we need to create our TensorFlow session. We do
    that with the `with` clause, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This model already has multiple layers called tensors. We need to extract the
    `softmax` layer.
  prefs: []
  type: TYPE_NORMAL
- en: The output of our model isn't just going to be that something was detected 100%;
    what it does is give a probability for each one. We might have, for example, a
    90% probability that our image is some sort of cat, a 20% probability that it's
    a squirrel, and 0.01% that it's a chair or something. Yes, you do get some wild
    classifications sometimes, although typically those probabilities are very small.
  prefs: []
  type: TYPE_NORMAL
- en: Some fraction of probability is calculated for each one of the thousand classes. Of
    course, the vast majority of them are going to be zero or very, very close to
    zero.
  prefs: []
  type: TYPE_NORMAL
- en: We want to extract the next-to-last layer, containing 2048 close descriptions
    of the image and the input image that provides the JPEG encoding of the image.
    Note that we didn't load the raw image data in a two-dimensional or three-dimensional
    vector (or tensor as they call it)—we still have it in JPEG encoding. We're just
    defining our variables to extract the outputs and find the inputs.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy's `squeeze` gets rid of all singleton dimensions. So, if we have a 1 by
    1000, this will convert it to a 1000 by 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, so, we understand the inputs and outputs within our session. Just for
    understanding''s sake, we only want to extract the top five predictions, and we''re
    going to filter out predictions that have a probability of less than 10%. At most,
    we''re going to get five predictions, but it usually will be less as we disregard
    anything below 10%, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We run the model and get the output of the image, and then we sort by our top
    five. We then iterate over those top predictions and convert to a human string
    by running the output's `node_id` through our `inceptiondict` dictionary. We read
    the `score`, and then we only print the output if the `score` is greater than
    10%.
  prefs: []
  type: TYPE_NORMAL
- en: We're just defining the function, we're not running it, so this should be instantaneous
    to run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''re going to run this on some images. There are some sample images
    in a `sample_imgs` subdirectory. What we want do is test this, so just uncomment
    out one of these following lines to define our `image` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Then, we're going to create a figure, look at what we see using the `imshow` function,
    and then use the `run_inference_on_image` function, which will output the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the preceding block of code with our `cropped_panda.jpg` picture, uncomment
    the panda picture line. We can see the picture in the following output. It has
    classified it with about 90% probability as a `panda`, `giant panda`, or other
    synonym, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3e0d0533-7f24-4ce6-b682-6ba2cfd74dea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s try it on something else. How about our `bicycle2.jpg` file? Uncomment
    the `bicycle2.jpg` line while commenting back the `cropped_panda.jpg` line, and
    we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d65a051f-efee-4c1e-9858-8828f8245b18.png)'
  prefs: []
  type: TYPE_IMG
- en: It has classified the picture with 91% probability as a `mountain bike`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are getting a little specific here. Let''s try now with the `garbagecan.jpg`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dfa410be-077c-4300-9284-bc03611180a3.png)'
  prefs: []
  type: TYPE_IMG
- en: It wasn't as confident here, only about 67% probability in its classification.
    Sometimes that's the best we can do, but that's not too bad. That was the most
    likely result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try the `bunny.jpg` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39d8e0ef-3a4f-4f22-846c-c5eedff42afd.png)'
  prefs: []
  type: TYPE_IMG
- en: Alright, 87% probability that we have a rabbit. Looks pretty good.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s try the `trombone.jpg` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df167616-f3f9-46de-97fb-0c58d795e430.png)'
  prefs: []
  type: TYPE_IMG
- en: Wow, very certain. Over 99% probability that the picture is of a `trombone`—very
    good.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re a fan of a certain popular TV show, you might be wondering whether
    the classifier can recognize a hot dog. The answer to that is yes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7085af23-dd09-4e00-b4b7-6d2dfa96cb8a.png)'
  prefs: []
  type: TYPE_IMG
- en: It does recognize a `hotdog`, with 97% confidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we''re going to run our classifier on `dog.jpg`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cdd42cb6-d6ac-418f-bfc9-9c791a2ec34d.png)'
  prefs: []
  type: TYPE_IMG
- en: Whoever trained this model was apparently a dog lover, so they defined a bunch
    of different dog classes. We get `Irish wolfhound`, `Russian wolfhound`, `gazelle
    hound`, and others returned. It seems to think that it's one of those!
  prefs: []
  type: TYPE_NORMAL
- en: This is working pretty well. If what we need happens to fall within those 1,000
    classes, then we're in good shape here. You should be able to adapt the code in
    the Jupyter Notebook to your needs. Hopefully, deep learning and image classification
    don't seem quite as intimidating as they did before.
  prefs: []
  type: TYPE_NORMAL
- en: So, with that, we're going to move on to the next section, where we do some
    retraining with our own images and classify objects that are not already in Google's
    training database.
  prefs: []
  type: TYPE_NORMAL
- en: Retraining with our own images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we're going to go beyond what we did with the pre-built classifier
    and use our own images with our own labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing I should mention is that this isn''t really training from scratch
    with deep learning—there are multiple layers and algorithms for training the whole
    thing, which are very time-consuming—but we can take advantage of something called
    *transfer learning*, where we take the first few layers that were trained with
    a very large number of images, as illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e63aeb4-46f6-4056-9ebb-35158efdabb3.png)'
  prefs: []
  type: TYPE_IMG
- en: It's one of the caveats of deep learning that having a few hundred or a few
    thousand images isn't enough. You need hundreds of thousands or even millions
    of samples in order to get good results, and gathering that much data is very
    time-consuming. Also, running it on a personal computer, which I expect most people
    are using, is not computationally feasible.
  prefs: []
  type: TYPE_NORMAL
- en: But the good news is that we can take layers from our pre-existing model and
    just do some tweaking at the end, and get some very good results. We're taking
    advantage of the pre-training by using input features that were trained on hundreds
    of thousands or millions of images, and transferring them to image types that
    the model has never seen before.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we borrow some code from TensorFlow Hub ([https://www.tensorflow.org/hub/](https://www.tensorflow.org/hub/)). But
    we have to make some tweaks to make it run more easily with reduced code and make
    it so that we can just drop it into our Jupyter Notebook and run it.
  prefs: []
  type: TYPE_NORMAL
- en: In order to get started, we need some images on which to train, and different
    ways of doing that. Google has kindly provided a sample called `flower_photos` at
    the following link: [http://download.tensorflow.org/example_images/flower_photos.tgz](http://download.tensorflow.org/example_images/flower_photos.tgz).
    Once again, it's a TGZ file, so download the file and thoroughly unzip it.
  prefs: []
  type: TYPE_NORMAL
- en: You'll get a `flower_photos` directory, which will contain some subdirectories
    of different kinds of flowers such as tulips, dandelions, and so on, which were
    not among the 1,000 original classes. Those directory names will serve as the
    labels for those images. All we have to do is unzip them and then input flower
    photos in the our code.
  prefs: []
  type: TYPE_NORMAL
- en: A cheap method to get a whole lot of photos is to use the Fatkun Batch Download
    plugin for Chrome ([https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf?hl=en](https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf?hl=en)).
    Using this, we can go somewhere like Google Image Search and search for whatever
    kind of object we want—animal, food, and so on—and grab hundreds of images pretty
    quickly.
  prefs: []
  type: TYPE_NORMAL
- en: There are similar plugins for Firefox, or whatever web browser you are using.
    As long as you don't mind using those kinds of images, if they will suit your
    needs then this is a good way to do it.
  prefs: []
  type: TYPE_NORMAL
- en: After you're finished with the flower photos, I would suggest grabbing your
    own images. Think of something that you'd like to train on, something that you
    think would be useful. Try to get at least 100 images of each class and grab multiple
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: For illustration purposes, I decided to classify some toys. Maybe you're running
    a toy store and you're taking inventory, or you're a collector and you want to
    know what exactly is in there—you just have a bunch of photos, and you want to
    classify them.
  prefs: []
  type: TYPE_NORMAL
- en: 'I created four subfolders called `barbie`, `gi joe`, `my little pony`, and
    `transformers`, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cc11a67-080f-4674-90a6-1854428df2cc.png)'
  prefs: []
  type: TYPE_IMG
- en: Each folder contains over 100 images of each type. The filenames are not important—just
    the directory names are going to be used for the labeling.
  prefs: []
  type: TYPE_NORMAL
- en: So you can test whether or not it's working, you need to separate out some images.
    If you test on images that you trained on, then you're kind of cheating—you don't
    really know whether or not your model has generalized. So, make sure to pull out
    some images from that directory and put them in a separate directory for now.
  prefs: []
  type: TYPE_NORMAL
- en: The code for retraining is introduced in the Jupyter Notebook file itself, so
    we're not going to go through the whole thing. We've created a file called `retrained.py`,
    which is based on the TensorFlow Hub version, but is more easily dropped into
    existing code and a lot of the variables are already taken care of.
  prefs: []
  type: TYPE_NORMAL
- en: 'All we need to do is import the `retrain` function, and then we retrain on
    our `toy_images` folder, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This generally takes a while. If you run the code on the `flower_photos` directory,
    that will take about half an hour, especially if doing it on a CPU and not a GPU.
    The `toy_images` example will take a little less time, because there aren't as
    many images.
  prefs: []
  type: TYPE_NORMAL
- en: Training in general with machine learning is the time-consuming portion; that's
    what's going to tie up your computer for long periods. Running images through
    a classifier is quick, as we saw before, but training can take minutes, hours,
    days, or possibly even longer. In this case, we're looking at up to half an hour,
    depending on how many images are present.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a couple of minutes, our `retrained` function has run successfully, with
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d731320-2415-4076-af7c-1d63c38173bf.png)'
  prefs: []
  type: TYPE_IMG
- en: I've turned down some of the verbosity in the `retrain` function, as otherwise
    it spits out a lot of messages that don't mean much. You can go into the code
    if you want and turn that up, if you're concerned it's not running successfully,
    but it should run just fine as long as everything's set up correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s confirm that it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We're going to look for that `.pb` file (Python binary file), which will be
    the output of what we did. So, that's the model, the input-output model, or graph
    as it's typically called in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: 'After running the code, we should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a5d97b2-603e-48c0-8898-c115bd18620b.png)'
  prefs: []
  type: TYPE_IMG
- en: We have this file called `output_graph.pb`. That's the one we just created; you
    should see this file in your directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for running your images isn''t quite as complicated. Loading our `output_graph.pb` graph
    file is similar to what we did before when we loaded the Inception model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `read_tensor_from_image_file` function helps in reading data from the image
    file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: There are some defaults here, but they don't matter. Images don't necessarily
    need to be `299` by `299`. We're just dealing with JPEGs here, but if we have
    files in PNG, GIF, or BMP formats, the model can handle that. We just decode the
    images, put them into our variable, and store and return them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As said before, the labels come from the directories. The following code will
    load the created `output_labels.txt` it''s going to load it from `output_labels.txt`,
    and that''s going to be our dictionary of sorts, as defined by our subdirectory
    names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows the `label_image` function. To find an image you know,
    give the correct filename, but there is a default just in case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: I have hardcoded these in for simplicity. If you want to change stuff, you can,
    but I think that having it written there makes things easy to read and understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'We load our graph file, read our data from the image file, and read layer names
    from the new model that we created, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We're just going to read the input and output layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We define our session and get our results from `output_operation`. Again, we
    sort it to the `top_k` variable, and print the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: There are a lot of classes, but we're actually going to see it's always just
    going to be one result here.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try our code again. As discussed, we separated a couple of images out
    into a separate directory, because we don't want to test on our training images,
    as that proves nothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test the retrained model on our first `transformers1.jpg` image. The
    model is to display the image and tell us what the classification results were:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dcae58c2-27dc-481e-91d7-0ae2a5777014.png)'
  prefs: []
  type: TYPE_IMG
- en: The model classified the image with a very high probability that this was a
    `transformers`. Since our images are distinct enough, and there are fewer classes,
    it's going to work very nicely. We see there is a 99.9% probability the picture
    is of a Transformer, a small probability that it is a GI Joe, and it's most definitely
    not a Barbie or a My Little Pony.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use *Ctrl + /* to comment and uncomment lines in the code in Jupyter
    Notebook, and press *Ctrl + Enter* to run the code again with the `transformer2.jpg`
    picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3adb0534-4ca0-41d6-8677-fa47e1374330.png)'
  prefs: []
  type: TYPE_IMG
- en: The output is `transformers` again. This time the model thinks it is slightly
    more likely to be a Barbie than a GI Joe, but the probability is insignificant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try again with the `mylittlepony1.jpg` picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db308670-2a26-4ff4-8e9f-cd2a92732552.png)'
  prefs: []
  type: TYPE_IMG
- en: And yes, it definitely looks like other images in the `my little pony` subfolder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take another picture, `mylittlepony3.jpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1908b3b8-7218-43e2-bd3d-a0693597ea7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Again, no problem classifying the image. Let''s take a look at `gijoe2.jpg`
    too:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d080b044-e64e-46fc-a8f9-9a0c5102b643.png)'
  prefs: []
  type: TYPE_IMG
- en: There's a high probability of it being a `gi joe`, `transformers` and `barbie` are
    more likely than `my little pony`, but again all those probabilities are insignificant—it's
    definitely a `gi joe`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s try it on `barbie1.jpg`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2074a3ed-55c3-4e38-beb4-419eb189c6eb.png)'
  prefs: []
  type: TYPE_IMG
- en: Again, definitely classified as a `barbie`, and `my little pony` was the second
    most likely, perhaps because of the colors; there tends to be more pink and purple
    on Barbie and My Little Pony toys.
  prefs: []
  type: TYPE_NORMAL
- en: Now we know how we can use our own images to retrain a pre-existing model. With
    not a lot of coding or CPU time, we can create a custom image classifier for our
    own purposes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we're going to talk about speeding up the computations
    with the help of your GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Speeding up computation with your GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll talk briefly about speeding up computations with your
    GPU. The good news is that TensorFlow is actually very smart about using the GPU,
    so if you have everything set up, then it's pretty simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what things look like if we have the GPU properly set up. First,
    import TensorFlow as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we print `tensorflow.Session()`. This just gives us information about
    our CPU and GPU (if it is properly set up):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1703197-abb0-4678-a930-ad0f6aee9785.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see from the output, we're using a laptop with a GeForce GTX 970M,
    which is CUDA-compatible. This is needed in order to run TensorFlow with the GPU.
    If everything is set up properly, you will see a message very similar to the preceding
    output for your GPU, your card model, and details about it such as its memory
    and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is smart about it. We can override it ourselves, but that's only
    a good idea if we know what we're doing and we're willing to put in the extra
    work. Unless we know what we're doing, we're not going to get improved performance,
    so just leave the default settings.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequent sections will run just fine on a CPU, just not quite as fast.
  prefs: []
  type: TYPE_NORMAL
- en: The bad news about TensorFlow using the GPU is that setting it up isn't quite
    as straightforward. We previously covered the `pip` command, for example, `pip
    install tensorflow` and `pip install tensorflow-gpu`, which is a starting point,
    but we'll still need CUDA to be installed.
  prefs: []
  type: TYPE_NORMAL
- en: I have version 9.0 installed. If you have a Quadro GPU or some sort of workstation,
    Tesla, or one of those specialized cards, you should use CUDA version 9.1\. It's
    platform-dependent, depending on what kind of GPU you have and, more particularly,
    what kind of operating system, so we can't go into full details here.
  prefs: []
  type: TYPE_NORMAL
- en: What's important to know is that we can't just install `tensorflow-gpu`; we
    have to install CUDA. Download and install CUDA for your operating system from
    the NVIDIA website ([https://developer.nvidia.com/cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)).
  prefs: []
  type: TYPE_NORMAL
- en: In addition to that, TensorFlow requires the **NVIDIA CUDA® Deep Neural Network**
    (**cuDNN**) library, which is a big DLL file for Windows, or a shared object (`.SO`)
    file for Linux. It's similar for macOS as well. It's just one file, which needs
    to be in your path. I generally copy it over to my `CUDA` directory.
  prefs: []
  type: TYPE_NORMAL
- en: If you do have one, try to install CUDA, do try to install cuDNN, and try to
    get TensorFlow working. Hopefully, that will speed up computations for you.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to classify images using a pre-trained model
    based on TensorFlow. We then retrained our model to work with custom images.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we had a brief overview of how to speed up the classification process
    by carrying out the computation on a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Using the examples covered in this book, you will be able to carry your our
    custom projects using Python, OpenCV, and TensorFlow.
  prefs: []
  type: TYPE_NORMAL
