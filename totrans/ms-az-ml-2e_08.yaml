- en: '*Chapter 6*: Feature Engineering and Labeling'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第6章*：特征工程和标注'
- en: In the previous chapter, we learned how to clean our data and do basic statistical
    analysis. In this chapter, we will delve into two more types of actions we must
    perform before we can start our ML training. These two steps are the most important
    of all besides efficiently cleaning your dataset, and to be good at them, you
    will require a high amount of experience. This chapter will give you a basis to
    build upon.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何清理我们的数据并进行基本统计分析。在本章中，我们将深入探讨在开始我们的机器学习训练之前必须执行的两种更多类型的操作。这两个步骤是所有步骤中最重要的，除了高效地清理数据集之外，而且要擅长它们，你需要有大量的经验。本章将为你提供一个基础来构建。
- en: In the first section, we will learn about feature engineering. We will understand
    the process, how to select predictive features from our dataset, and what methods
    exist to transform features from our dataset to make them usable for our ML algorithm.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们将学习特征工程。我们将了解这个过程，如何从我们的数据集中选择预测特征，以及将我们的数据集中的特征转换为可用于我们的机器学习算法的方法。
- en: In the second section, we will look at data labeling. Most ML algorithms fall
    into the category of supervised learning, which means they require labeled training
    data. We will look at some typical scenarios that require labels and learn how
    Azure Machine Learning can help with this tedious task.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二部分，我们将探讨数据标注。大多数机器学习算法属于监督学习类别，这意味着它们需要标注的训练数据。我们将探讨一些需要标签的典型场景，并学习Azure机器学习如何帮助完成这项繁琐的任务。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding and applying feature engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解和应用特征工程
- en: Handling data labeling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理数据标注
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will use the following Python libraries and versions to
    perform feature engineering on different datasets.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下Python库和版本来对不同的数据集进行特征工程。
- en: '`azureml-sdk 1.34.0`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-sdk 1.34.0`'
- en: '`azureml-widgets 1.34.0`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-widgets 1.34.0`'
- en: '`azureml-dataprep 2.20.0`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureml-dataprep 2.20.0`'
- en: '`pandas 1.3.2`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas 1.3.2`'
- en: '`numpy 1.19.5`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy 1.19.5`'
- en: '`scikit-learn 0.24.2`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scikit-learn 0.24.2`'
- en: '`seaborn 0.11.2`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seaborn 0.11.2`'
- en: '`plotly 5.3.1`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plotly 5.3.1`'
- en: '`umap_learn 0.5.1`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`umap_learn 0.5.1`'
- en: '`statsmodels 0.13.0`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`statsmodels 0.13.0`'
- en: '`missingno 0.5.0`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`missingno 0.5.0`'
- en: Similar to previous chapters, you can execute this code using either a local
    Python interpreter or a notebook environment hosted in Azure Machine Learning.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章类似，你可以使用本地Python解释器或Azure机器学习中的笔记本环境执行此代码。
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中所有的代码示例都可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06)。
- en: Understanding and applying feature engineering
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解和应用特征工程
- en: '**Feature engineering** is the general term that describes the process of transforming
    existing features in our dataset, creating missing features, and eventually selecting
    the most predictive features from our dataset to start the ML training process
    with a given ML algorithm. These cannot just be seen as some mathematical functions
    we must apply to our data. This is an art form and doing it well makes the difference
    between a mediocre and highly performing predictive model. If you want to understand
    where you should invest your time, feature engineering is the step where you can
    have the most impact on the quality of your final ML model. To create this impact
    and be efficient, we must consider the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**是一个通用术语，描述了将我们数据集中的现有特征进行转换、创建缺失特征，并最终从我们的数据集中选择最具有预测性的特征以使用给定的机器学习算法开始机器学习训练过程的过程。这些不能仅仅被视为我们必须应用于我们的数据的某些数学函数。这是一种艺术形式，做得好可以区分一个平庸和高度表现的预测模型。如果你想知道你应该在哪里投入时间，特征工程是你可以对最终机器学习模型的质量产生最大影响的步骤。为了产生这种影响并提高效率，我们必须考虑以下因素：'
- en: '**ML algorithm requirements**: Do the features have to be in a specific format
    or range? How do I best avoid overfitting and underfitting the model?'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习算法要求**：特征是否需要特定的格式或范围？我如何最好地避免模型过拟合和欠拟合？'
- en: '**Domain knowledge**: Are the given features sufficient for our model? Can
    we create additional features or derive features that contain more predictive
    information?'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域知识**：给定的特征是否足够用于我们的模型？我们能否创建包含更多预测信息的附加特征或派生特征？'
- en: In this section, we'll define the different classes of feature engineering techniques
    and then look at some of the most prominent methods to apply to different types
    of datasets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将定义不同的特征工程技术类别，然后探讨一些应用于不同类型数据集的最显著方法。
- en: Important Note
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Keep in mind that the usefulness of a specific feature engineering method depends
    on the utilized type of features (categorical, continuous, text, image, audio)
    and the chosen ML algorithm.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，特定特征工程方法的有用性取决于所使用的特征类型（分类、连续、文本、图像、音频）以及所选的机器学习算法。
- en: Classifying feature engineering techniques
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程技术分类
- en: 'Broadly speaking, feature engineering methods can be grouped into the following
    categories:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 广义而言，特征工程方法可以归纳为以下类别：
- en: '**Feature creation**: Create new features from the given set of features or
    additional information sources.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征创建**：从给定的特征集或额外的信息源中创建新的特征。'
- en: '**Feature transformation**: Transform single features to make them useful and
    stable for the utilized ML algorithm.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征转换**：转换单个特征，使其对所使用的机器学习算法有用且稳定。'
- en: '**Feature extraction**: Create derived features from the original data.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**：从原始数据中创建派生特征。'
- en: '**Feature selection**: Choose the most prominent and predictive features.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**：选择最突出和最具预测性的特征。'
- en: Let's look at each of these categories and what they entail.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些类别及其包含的内容。
- en: Feature creation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征创建
- en: The first step to take in feature engineering is finding all the features that
    should be included in the model. To be good at this, you must have an intimate
    understanding of the relevant domain or know someone who is a **subject matter
    expert** (**SME**) in the domain. In the end, we want to be sure that we consider
    any type of data point that is predictive and that is feasible to acquire in a
    reasonable amount of time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程的第一步是找到模型中应包含的所有特征。要擅长这一点，你必须对相关领域有深入了解，或者知道该领域的**领域专家**（SME）。最后，我们想要确保我们考虑了任何具有预测性且在合理时间内可以获取的数据点。
- en: 'In turn, we must understand all the methods that can help us create new features
    in our dataset, either taken from additional sources or the initial dataset. Typically,
    these methods can be classified as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来，我们必须理解所有可以帮助我们在数据集中创建新特征的方法，无论是来自额外来源还是初始数据集。通常，这些方法可以按以下方式分类：
- en: '**Adding missing predictive features**: We add external information that is
    missing to achieve a more predictive model.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**添加缺失的预测特征**：我们添加外部缺失信息，以实现更具有预测性的模型。'
- en: '**Combining the available features**: We create new features by combining already
    available features in our dataset.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结合可用特征**：我们通过结合数据集中已有的特征来创建新的特征。'
- en: Why do we have to change already existing features in our dataset?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们必须更改数据集中已经存在的特征？
- en: The reason for this is that a lot of connections between features and labels,
    that we understand, may not be clear to the utilized ML algorithm. Therefore,
    it is a good idea to think about what features or representations of the available
    features we would assume are necessary to make it easier for the ML algorithm
    to grasp the intrinsic connections.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于，我们理解的许多特征与标签之间的联系可能对所使用的机器学习算法来说并不明显。因此，考虑哪些特征或可用特征的表示我们认为对于使机器学习算法更容易把握内在联系是很有帮助的。
- en: Let's look at some examples to understand this better.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些例子，以便更好地理解这一点。
- en: Imagine that you have a dataset for predicting house prices, like the one we
    examined in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing
    Data Analysis and Visualization*. Furthermore, imagine that the features we have
    are the **length** and **width** of the house or apartment. In this case, it is
    probably useful to combine these two features to create a new one called the **surface
    area**. In addition, if the **type** of building is missing (house, flat, condo,
    and so on), we may want to add this from other sources since we know the type
    has an impact on the price of a property.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一个用于预测房价的数据集，就像我们在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)“执行数据分析与可视化”中考察的那样。此外，想象一下我们拥有的特征是房屋或公寓的**长度**和**宽度**。在这种情况下，将这两个特征结合起来创建一个名为**面积**的新特征可能是有用的。此外，如果缺少**建筑类型**（房屋、公寓、联排别墅等），我们可能需要从其他来源添加这个信息，因为我们知道类型会影响房产的价格。
- en: Important Note
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you create new features from existing ones, it is typically wise to only
    stick with the newly created feature by dropping those initial features from the
    dataset.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从现有特征中创建新特征，通常明智的做法是只保留新创建的特征，从数据集中删除那些初始特征。
- en: Now, imagine the amount of money a person spends throughout their life. Being
    young, this might be very little. When they grow older, they may have mortgages
    and children and eventually, their spending may drop when their children move
    out of the house, and they are nearing retirement. As this would form something
    of a parabolic relationship between **age** and **cost of living**, it may not
    be easy for an ML algorithm to grasp this. Therefore, one possible option is to
    square the values of the **cost of living** feature to emphasize higher costs
    and deemphasize lower costs.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一下一个人在其一生中花费的金额。年轻时，这可能会非常少。随着年龄的增长，他们可能会有抵押贷款和子女，最终，当他们的子女搬出家时，他们的支出可能会下降，他们接近退休。由于这会在**年龄**和**生活成本**之间形成某种抛物线关系，因此，对于机器学习算法来说，可能不容易掌握这一点。因此，一个可能的选择是将**生活成本**特征的值平方，以强调更高的成本，并降低较低的成本的重要性。
- en: In the previous two examples, we used our domain knowledge to create new features.
    But what if we do not have this at our disposal?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个例子中，我们使用了我们的领域知识来创建新的特征。但如果我们没有这种知识怎么办？
- en: 'There is a way to create new features mathematically using the so-called **polynomial
    extension**. The idea is to create new features by raising the value of a feature
    to a certain power and multiplying it by one or multiple other features. Here,
    we define the **degree** as the maximum power a single feature can be raised to,
    and we define the **order** as the number of features we allow to be multiplied
    by each other. The following diagram shows all the possible combinations for a
    degree of 2 and order of 2 on the left-hand side, and a degree of 3 and order
    of 3 on the right-hand side:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以通过所谓的**多项式扩展**在数学上创建新特征。这个想法是通过将一个特征的值提升到一定的幂，并乘以一个或多个其他特征来创建新特征。在这里，我们定义**度**为单个特征可以提升到的最大幂，我们定义**顺序**为我们允许相互乘积的特征的数量。以下图表显示了左侧阶数为2，顺序为2的所有可能组合，以及右侧阶数为3，顺序为3的所有可能组合：
- en: '![Figure 6.1 – Possible combinations for polynomial extension  (degree=2, order=2
    on the left/degree=2, order=3 on the right) ](img/B17928_06_01.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 多项式扩展的可能组合（左侧为阶数=2，顺序=2；右侧为阶数=2，顺序=3）](img/B17928_06_01.jpg)'
- en: Figure 6.1 – Possible combinations for polynomial extension (degree=2, order=2
    on the left/degree=2, order=3 on the right)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 多项式扩展的可能组合（左侧为阶数=2，顺序=2；右侧为阶数=3，顺序=3）
- en: You should only consider a maximum order of 3 because, as shown in the preceding
    diagram, even with a degree of 2, this operation already creates too many combinations.
    Still, this automatic process may lead to much better predictive features than
    the originating ones.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该只考虑最大阶数为3，因为，如图所示，即使阶数为2，这个操作也已经产生了太多的组合。然而，这个自动过程可能比原始的特征产生更好的预测特征。
- en: To try this method, you can use the `PolynomialFeatures` class from the `sklearn`
    library ([https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试这种方法，你可以使用`sklearn`库中的`PolynomialFeatures`类（[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)）。
- en: With all these methods in mind, we can create new features in our dataset that
    might be easier for our ML algorithm to handle and contain more precise, predictive
    information.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑了所有这些方法之后，我们可以在我们的数据集中创建新的特征，这些特征可能更容易被我们的机器学习算法处理，并且包含更精确、更具预测性的信息。
- en: Next, let's look at some methods that let us change a single feature by transforming
    its values or its representation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看一些让我们可以通过转换其值或其表示来改变单个特征的方法。
- en: Feature transformation
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征转换
- en: '**Feature transformation** is about manipulating a feature to change its value
    or create a new representation of the same. The following list covers the types
    of transformations we can perform on single features:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征转换**是关于操纵特征以改变其值或创建相同特征的新表示。以下列表涵盖了我们可以对单个特征执行的转换类型：'
- en: '**Discretization**: Divide feature values into different groups or intervals
    to reduce complexity. This can be done on numerical or categorical features.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散化**：将特征值划分为不同的组或区间以降低复杂性。这可以在数值或分类特征上完成。'
- en: '**Splitting**: Split a feature into multiple elements. This is typically done
    on datetime and string values.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拆分**：将特征拆分为多个元素。这通常是在日期时间和字符串值上进行的。'
- en: '**Categorical encoding**: Represent a categorical feature numerically, by creating
    new numerical features while following specific methods.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类编码**：通过创建新的数值特征并遵循特定方法来数值化分类特征。'
- en: '**Scaling**: Transform a continuous feature so that it fits into a specified
    range of values.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩放**：将连续特征转换为一个适合特定值范围的值。'
- en: '**Standardization**: Transform a continuous feature so that it represents a
    normal distribution with a mean of 0 and a standard deviation of 1.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**：将连续特征转换为一个具有均值为0和标准差为1的正态分布。'
- en: '**Normalization**: Transform a vector (row) of multiple continuous features
    individually into a so-called unit norm (unit magnitude).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化**：将多个连续特征的向量（行）分别转换为一个所谓的单位范数（单位大小）。'
- en: '`square`, `square root`, `exp`, `log`, and so on).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`square`、`square root`、`exp`、`log`等。'
- en: 'In [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, we used the `log` function to calculate the logarithm of all
    house price values. We did this to reduce the impact that a handful of outliers
    would have on our ML training. Therefore, the main reason to transform features
    is to adapt the feature to the possible mathematical requirements of the given
    ML algorithm. Often, you may run into the following requirements of the ML algorithm:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)，“执行数据分析与可视化”中，我们使用了`log`函数来计算所有房价值的对数。我们这样做是为了减少少数异常值对我们机器学习训练的影响。因此，转换特征的主要原因是使特征适应给定机器学习算法的可能数学要求。通常，你可能会遇到以下机器学习算法的要求：
- en: '**Numerical format**: The algorithm requires all the features to be numerical.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值格式**：算法要求所有特征都是数值的。'
- en: '**Same scale**: The algorithm requires all the predictive features to be on
    the same scale, maybe even with a mean of 0 and a standard deviation of 1.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相同尺度**：算法要求所有预测特征都在相同的尺度上，甚至可能具有均值为0和标准差为1。'
- en: '**Mathematical theory**: The domain itself may require certain transformations
    based on mathematical theory. For example, a price feature for predictions concerning
    economic theory should nearly always be transformed with the natural logarithm.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数学理论**：域本身可能需要根据数学理论进行某些转换。例如，对于涉及经济理论的预测，价格特征几乎总是需要用自然对数进行转换。'
- en: '`[-1,1]`.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[-1,1]`.'
- en: '**Complexity**: Most algorithms require very precise features. Therefore, reducing
    the complexity of the possible values a feature can take is often worthwhile.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性**：大多数算法都需要非常精确的特征。因此，降低特征可能取值的复杂性通常是有价值的。'
- en: An example would be discretizing features. One such method is called **binning**,
    which transforms numerical continuous values into a handful of discrete values.
    We will see this in action on text data in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112),
    *Advanced Feature Extraction with NLP*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，离散化特征。其中一种方法称为**分箱**，它将数值连续值转换为少量离散值。我们将在[*第七章*](B17928_07_ePub.xhtml#_idTextAnchor112)，“使用NLP的高级特征提取”中看到这一方法的应用。
- en: Another example would be splitting datetime features. Imagine that we want to
    predict the amount of traffic on a certain road at specific times of the day.
    Let's assume that we got a feature denoting the **date and time** of our recording
    and the **number of cars** we tracked at that point. To make a better prediction,
    one idea would be to create three new features, denoting whether it is a *workday*,
    *weekend*, or *holiday*. There will be less traffic on a Sunday at 7 A.M. compared
    to a workday morning at 7 A.M.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是将日期时间特征分割。想象一下，我们想要预测一天中特定时间某条道路上的交通量。假设我们得到了一个表示我们记录的**日期和时间**以及在那个点追踪的**汽车数量**的特征。为了做出更好的预测，一个想法是创建三个新的特征，表示是否是**工作日**、**周末**或**假日**。与工作日上午7点相比，星期天上午7点的交通量会更少。
- en: 'Let''s learn how to perform this transformation. The following screenshot shows
    our initial small dataset and the first transformation adding `day of the week`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何执行这种转换。以下截图显示了我们的初始小型数据库和添加`星期几`的第一个转换：
- en: '![Figure 6.2 – Dataset with a new weekday feature   ](img/B17928_06_02.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 包含新工作日特征的数据库](img/B17928_06_02.jpg)'
- en: Figure 6.2 – Dataset with a new weekday feature
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 包含新工作日特征的数据库
- en: 'In the next step, we must enrich the data by adding a new categorical feature
    called `daytype`, which denotes whether a day is either a weekday, a weekend,
    or a holiday:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们必须通过添加一个名为`daytype`的新分类特征来丰富数据，该特征表示一天是工作日、周末还是假日：
- en: '![Figure 6.3 – Dataset enrichment  ](img/B17928_06_03.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – 数据库丰富化](img/B17928_06_03.jpg)'
- en: Figure 6.3 – Dataset enrichment
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 数据库丰富化
- en: 'Theoretically, we are done. But our ML algorithm may beg to differ here. Our
    ML model may make up a natural order for our categorical data that does not exist
    or it simply cannot handle categorical data. In this case, it is prudent to **encode**
    our categorical data with numerical values. One such method is called **one-hot
    encoding**, which transforms a categorical feature into multiple numerical features
    by creating a new feature with two valid values (0 or 1) for every existing category.
    The following screenshot shows this encoding for our example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，我们已经完成了。但我们的机器学习算法可能在这里有不同的看法。我们的机器学习模型可能会为我们的分类数据创建一个不存在的自然顺序，或者它简单地无法处理分类数据。在这种情况下，明智的做法是将我们的分类数据用数值进行**编码**。一种这样的方法称为**独热编码**，它通过为每个现有类别创建一个具有两个有效值（0或1）的新特征，将分类特征转换为多个数值特征。以下截图显示了我们对示例的这种编码：
- en: '![ Figure 6.4 – One-hot encoding the new feature ](img/B17928_06_04.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – 对新特征进行独热编码](img/B17928_06_04.jpg)'
- en: Figure 6.4 – One-hot encoding the new feature
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 对新特征进行独热编码
- en: Here, we created three new features named `holiday`, `weekday`, and `weekend`,
    each representing our initial categories. Where a sample had this initial category,
    the value of that feature is set to `1`; otherwise, it is set to `0`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了三个新的特征，分别命名为`holiday`、`weekday`和`weekend`，每个特征代表我们的初始类别。如果一个样本具有这个初始类别，那么该特征的值设置为`1`；否则，设置为`0`。
- en: What have we done in this example? We transformed a very unintuitive datetime
    feature into something with more predictive power by splitting the feature into
    components, adding external knowledge through feature creation, and performing
    categorical encoding on the created feature.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们做了什么？我们通过分割特征，添加外部知识通过特征创建，并在创建的特征上执行分类编码，将一个非常不直观的日期时间特征转换成具有更多预测力的特征。
- en: Now that we have a good grasp of feature transformation, let's look at what
    falls under feature extraction.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经很好地掌握了特征转换，让我们看看什么是特征提取的范畴。
- en: Feature extraction
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征提取
- en: With **feature extraction**, we group all the methods that do not manipulate
    features by simple means but extract useful information from a high-dimensional
    dataset. This is typically done by using complex mathematical algorithms or ML
    algorithms.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**特征提取**，我们将所有不通过简单手段操纵特征但能从高维数据集中提取有用信息的方法分组在一起。这通常是通过使用复杂的数学算法或机器学习算法来完成的。
- en: Extraction is often required when the underlying dataset is too complex to be
    processed, so it needs to be brought into a simplified form while keeping its
    predictive value.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '当底层数据集过于复杂而难以处理时，通常需要提取，同时保持其预测价值，将其转化为简化的形式。 '
- en: 'The following are some typical extraction types for different scenarios:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些不同场景下的典型提取类型：
- en: '**High-dimensional reduction**: Create representative features based on an
    *n*-dimensional dataset.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高维降维**：基于n维数据集创建代表性特征。'
- en: '**Feature detection**: Find points of interest in every image in an image dataset.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征检测**：在图像数据集中的每张图像中找到感兴趣点。'
- en: '**Word embeddings**: Create numeric encodings for words in a text dataset.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词嵌入**：为文本数据集中的单词创建数值编码。'
- en: '**Signal processing**: Extract the characteristics of sound waves from an audio
    dataset.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信号处理**：从音频数据集中提取声音波的特征。'
- en: We discussed high-dimensional reduction methods in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*, when we looked at visualizing high-dimensional
    datasets. In a process like **principal component analysis** (**PCA**), the dataset
    is projected onto a two- or three-dimensional space by creating principal component
    vectors. Instead of only using this method for visualization, we could use these
    calculated vectors as derived and less complex features that represent our dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)“执行数据分析和可视化”中讨论了高维降维方法，当时我们探讨了可视化高维数据集。在**主成分分析**（PCA）这样的过程中，数据集通过创建主成分向量被投影到二维或三维空间。我们不仅可以使用这种方法进行可视化，还可以使用这些计算向量作为派生和更简单的特征，这些特征代表我们的数据集。
- en: Important Note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: High-dimensional reduction techniques can be used for feature extraction, but
    keep in mind that we lose our intrinsic understanding of the features. Instead
    of features called suburbs or rooms, we end up with features called Principal
    Component 1 and Principal Component 2.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 高维降维技术可用于特征提取，但请注意，我们失去了对特征的内禀理解。我们最终得到的不是称为郊区或房间的特征，而是称为主成分1和主成分2的特征。
- en: Looking at the other scenarios, it seems that extraction typically happens when
    we are working with complex datasets made up of text, image, or audio data. In
    all these cases, there are specific methods to consider when extracting information
    from the raw data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 观察其他场景，似乎提取通常发生在我们处理由文本、图像或音频数据组成的复杂数据集时。在这些所有情况下，当我们从原始数据中提取信息时，都有特定的方法需要考虑。
- en: In the case of an image dataset, we might be interested in key areas or points
    of interest, including finding edges and objects. In [*Chapter 10*](B17928_10_ePub.xhtml#_idTextAnchor165),
    *Training Deep Neural Networks on Azure*, you will see that such image extraction
    steps are done automatically by **deep neural networks**, removing the need to
    perform manual feature extraction on images in a lot of cases.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像数据集的情况下，我们可能对关键区域或感兴趣点感兴趣，包括寻找边缘和对象。在[*第10章*](B17928_10_ePub.xhtml#_idTextAnchor165)“在Azure上训练深度神经网络”中，你会看到这样的图像提取步骤是由**深度神经网络**自动完成的，从而消除了在许多情况下对图像进行手动特征提取的需要。
- en: In the case of text data, we can use extraction methods such as **bag of words**
    and **TF-IDF**, both of which help create numerical representations of text, capturing
    meaning and semantic relationships. We will have an in-depth look at these methods
    in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112), *Advanced Feature Extraction
    with NLP*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本数据的情况下，我们可以使用诸如**词袋模型**和**TF-IDF**之类的提取方法，这两种方法都有助于创建文本的数值表示，捕捉意义和语义关系。我们将在[*第7章*](B17928_07_ePub.xhtml#_idTextAnchor112)“使用NLP的高级特征提取”中深入探讨这些方法。
- en: In the case of audio data, we can use signal processing to extract information
    and new features from the source. In this scenario, there are also two domains
    – the time domain and the frequency domain – that we can pull information from.
    From the time domain, we would typically extract something like the **amplitude
    envelope**, which is the maximum amplitude of the signal per frame, the **root
    mean square energy**, which hints at the loudness of the signal, and the **zero-crossing
    rate**, which is the number of times the wave is crossing the horizontal time
    axis. If you must work with data from this domain, make yourself comfortable with
    such processing techniques.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在音频数据的情况下，我们可以使用信号处理从源数据中提取信息和新的特征。在这种情况下，也存在两个领域——时域和频域——我们可以从中提取信息。从时域来看，我们通常会提取诸如**幅度包络**这样的内容，它是每帧信号的峰值幅度，**均方根能量**，它暗示了信号的响度，以及**过零率**，即波穿越水平时间轴的次数。如果你必须处理来自这个领域的数据，请让自己熟悉这样的处理技术。
- en: Important Note
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A lot of feature extraction and feature transformation techniques are already
    embedded in common ML frameworks and algorithms, removing the need for you to
    manually touch features. Have a good understanding of what the algorithm does
    by itself and what you need to do manually when you're preprocessing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 许多特征提取和特征转换技术已经嵌入到常见的机器学习框架和算法中，无需您手动触摸特征。通过理解算法本身做什么以及您在预处理时需要手动做什么，来获得良好的理解。
- en: So far, we've learned how to create new features, transform features, and extract
    features from our dataset. Now, let's look at some methods that can help us select
    the most predictive feature from our feature set.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何创建新特征、转换特征以及从我们的数据集中提取特征。现在，让我们看看一些可以帮助我们从特征集中选择最具预测性的特征的方法。
- en: Feature selection
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征选择
- en: With **feature selection**, we define all the methods that help us understand
    how valuable and predictive a feature is for the target so that we can choose
    a useful subset of our feature variables for training. The reasons to reduce complexity
    are two-fold. On the one hand, we want the simplicity to make the model **explainable**
    while on the other, we want to avoid **overfitting** the model. With too much
    input information, we will end up with a model that, in most cases, will perfectly
    fit our training data and nothing else but will perform poorly on unseen data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通过**特征选择**，我们定义了所有帮助我们理解特征对目标有价值性和预测性的方法，以便我们可以选择有用的特征变量子集进行训练。减少复杂性的原因有两个。一方面，我们希望简单性使模型**可解释**；另一方面，我们希望避免模型**过拟合**。当输入信息过多时，我们最终会得到一个模型，在大多数情况下，这个模型会完美地拟合我们的训练数据，但除了这些之外，它在未见过的数据上的表现会很差。
- en: 'Generally, there are three different types of feature selection methods, as
    follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有三种不同类型的特征选择方法，如下所示：
- en: '**Filter-based methods**: These define a derived metric, that is not the target
    error rate, to measure the quality of a subset of features.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于过滤的方法**：这些方法定义了一个派生指标，即不是目标错误率，来衡量特征子集的质量。'
- en: '**Wrapper-based methods**: These use greedy search algorithms to run a prediction
    model on different combinations of feature subsets.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于包装的方法**：这些方法使用贪婪搜索算法在不同的特征子集组合上运行预测模型。'
- en: '**Embedded methods**: These are specific selection methods that are already
    embedded into our final ML model.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入式方法**：这些是已经嵌入到我们最终机器学习模型中的特定选择方法。'
- en: Filter-based methods can be very efficient in terms of computational resources
    but are only evaluated against a simpler filter. Typically, statistical measures
    such as correlation, mutual information, and entropy are used as metrics in these
    approaches.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 基于过滤的方法在计算资源方面可以非常高效，但仅与一个更简单的过滤方法进行评估。通常，这些方法中使用统计指标，如相关性、互信息和熵作为度量标准。
- en: 'On the other hand, wrapper-based methods are computationally intense. At the
    same time, they can find a great performing feature set since the same error function
    or metric is being used for the selection of the features as the one that''s being
    used in the actual model training. The downside of this approach is that without
    an independent metric, the selected subset is only useful for the chosen ML training
    algorithm. Typically, this is done by performing one of the following processes:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，基于包装的方法计算密集。同时，它们可以找到性能极佳的特征集，因为用于特征选择的错误函数或指标与实际模型训练中使用的相同。这种方法的不利之处在于，如果没有独立的指标，选定的子集仅对所选的机器学习训练算法有用。通常，这是通过执行以下过程之一来完成的：
- en: '**Step forward feature selection**: Features are added one by one based on
    the training results of each feature until the model does not improve its performance.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逐步前进特征选择**：根据每个特征的训练结果逐个添加特征，直到模型不再提高其性能。'
- en: '**Step backward feature selection**: The model is evaluated with the full set
    of features. These features are subsequently removed until a predefined number
    of features is reached. This removal is done in a round-robin fashion.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逐步后退特征选择**：使用完整特征集评估模型。然后，这些特征被逐一移除，直到达到预定义的特征数量。这种移除是循环进行的。'
- en: '**Exhaustive feature selection**: All the feature subsets are evaluated, which
    is the most expensive method.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**穷举特征选择**：评估所有特征子集，这是最昂贵的方法。'
- en: Finally, a selection method is called an embedded method when the selection
    step is part of the model learning algorithm itself. Embedded methods often combine
    the qualities of filter and wrapper methods through the fact that the learning
    algorithm takes advantage of its selection process and performs selection and
    training at the same time. Typical examples of embedded methods are ensemble models,
    **Lasso**, and **Ridge**.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当选择步骤是模型学习算法本身的一部分时，选择方法被称为嵌入式方法。嵌入式方法通常通过学习算法利用其选择过程，同时进行选择和训练，从而结合过滤器和包装方法的特性。嵌入式方法的典型例子是集成模型、**Lasso**和**Ridge**。
- en: You may have realized this by now, but we used such methods in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*. The **Pearson correlation coefficient**
    we used for generating a correlation matrix is a derived metric, so it falls under
    the filter-based selection methods. In addition, we used an **ensemble decision
    tree model** to calculate feature importance for our dataset. This helped us get
    a clear understanding of which features may have more influence on the target
    than others. This ensemble method utilizes the **random forest** approach. A random
    forest not only implements the so-called **bagging** technique to randomly select
    a subset of samples to train on but also takes a random selection of features
    rather than using all the features to grow each tree. Therefore, for feature selection,
    random forests fall into the embedded category.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能现在已经意识到了，我们在[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)，*执行数据分析与可视化*中使用了这样的方法。我们用于生成相关矩阵的**皮尔逊相关系数**是一个派生指标，因此它属于基于过滤器的选择方法。此外，我们还使用了一个**集成决策树模型**来计算数据集的特征重要性。这有助于我们清楚地了解哪些特征可能比其他特征对目标有更大的影响。这种集成方法利用了**随机森林**方法。随机森林不仅实现了所谓的**袋装**技术，随机选择样本子集进行训练，而且还随机选择特征，而不是使用所有特征来生长每一棵树。因此，对于特征选择，随机森林属于嵌入式类别。
- en: We will have a more detailed look at the tree-based ensemble classifier, as
    well as bagging and boosting, in [*Chapter 9*](B17928_09_ePub.xhtml#_idTextAnchor152),
    *Building ML Models Using Azure Machine Learning*.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第9章*](B17928_09_ePub.xhtml#_idTextAnchor152)，*使用Azure机器学习构建ML模型*中更详细地查看基于树的集成分类器，以及袋装和提升。
- en: Besides all these mathematical approaches to feature selection, sometimes, a
    more manual approach might be far superior. For example, when we removed the postal
    code from our **Melbourne housing dataset** in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*, we did so because we understood
    that the postal code and the suburbs contain the same information, which made
    them redundant. We did this because we have domain knowledge and understand the
    relationship between postal codes and suburbs. Note that this additional knowledge
    lessens the burden for the model to learn these connections by itself.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有这些特征选择的数学方法之外，有时，更手动的方法可能更优越。例如，当我们从[*第5章*](B17928_05_ePub.xhtml#_idTextAnchor085)，*执行数据分析与可视化*中的**墨尔本住房数据集**中删除邮政编码时，我们这样做是因为我们理解邮政编码和郊区包含相同的信息，这使得它们是冗余的。我们这样做是因为我们具有领域知识，并了解邮政编码和郊区之间的关系。请注意，这种额外的知识减轻了模型自己学习这些联系的压力。
- en: Important Note
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For feature engineering, the more outside knowledge about the data or the domain,
    the simpler a lot of these preprocessing steps can get, or they become avoidable
    altogether.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征工程，对数据或领域了解的更多外部知识，可以使许多预处理步骤变得更加简单，或者完全避免。
- en: We will iterate this notion throughout this book as it needs to be ingrained
    into everything you do so that you get more efficient and better at working with
    data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中反复阐述这一概念，因为它需要融入你做的每一件事，以便你更高效、更擅长处理数据。
- en: We now have a general understanding of the general types of feature engineering
    we can perform. In the next section, we will provide an overview of the most prominent
    methods and drill deeper into some of them.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在对可以执行的一般特征工程类型有了总体了解。在下一节中，我们将概述最显著的方法，并深入探讨其中的一些方法。
- en: Discovering feature transformation and extraction methods
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现特征转换和提取方法
- en: 'Now that we have a good grasp of the types of feature engineering action we
    can apply to our feature, let''s look at some of the most prominent feature engineering
    techniques and their names. The following table provides a good overview of most
    of the well-known methods in the different categories we have learned about:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经很好地掌握了我们可以应用于特征的特征工程动作类型，让我们来看看一些最突出的特征工程技术和它们的名称。以下表格提供了我们所学不同类别中大多数已知方法的良好概述：
- en: '![Figure 6.5 – Overview of different feature engineering methods  ](img/B17928_06_05.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 不同特征工程方法的概述](img/B17928_06_05.jpg)'
- en: Figure 6.5 – Overview of different feature engineering methods
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 不同特征工程方法的概述
- en: Keep in mind that this list is far from exhaustive and as we mentioned previously,
    some of these methods are already implemented as part of specific ML algorithms.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个列表远非详尽无遗，正如我们之前提到的，其中一些方法已经作为特定机器学习算法的一部分得到实现。
- en: In the following sections, we will look at some of these. Feel free to download
    the `01_feateng_examples.ipynb` file in the GitHub repository for this chapter,
    which contains the code for the upcoming examples. If you would like to learn
    more about some of the feature extraction methods we will cover, we will come
    back to them in the upcoming chapters. For the methods we won't cover, feel free
    to research them.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨其中的一些。您可以自由下载GitHub仓库中该章节的`01_feateng_examples.ipynb`文件，其中包含即将到来的示例的代码。如果您想了解更多关于我们将要介绍的一些特征提取方法，我们将在接下来的章节中回到它们。对于我们将不介绍的方法，请自由研究它们。
- en: Scaling, standardization, and normalization
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缩放、标准化和归一化
- en: Since all the scaling and normalization methods are very similar to each other,
    we will discuss all of them in detail here.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有缩放和归一化方法彼此之间非常相似，我们在这里将详细讨论它们。
- en: 'Let''s begin with the so-called **StandardScaler**. This scaling transforms
    our feature values so that the resulting value distribution has a mean (µ) of
    0 and a standard deviation (s) of 1\. The formula to apply to each value looks
    like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从所谓的**StandardScaler**开始。这种缩放将我们的特征值转换，使得结果值分布的均值（µ）为0，标准差（s）为1。应用于每个值的公式看起来如下：
- en: '![](img/Formula_06_01.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_06_01.png)'
- en: Here, µ is the mean value of the given distribution and s is the standard deviation
    of the given distribution. With this, we can convert every value, ![](img/Formula_06_02.png),
    into a new scaled value, ![](img/Formula_06_03.png).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，µ是给定分布的均值，s是给定分布的标准差。有了这个，我们可以将每个值，![](img/Formula_06_02.png)，转换成一个新的缩放值，![](img/Formula_06_03.png)。
- en: 'The following diagram shows how this scaler changes the shape of multiple distributions:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了该缩放器如何改变多个分布的形状：
- en: '![Figure 6.6 – StandardScaler distribution (left: before scaling, right: after
    scaling) ](img/B17928_06_06.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – StandardScaler分布（左：缩放前，右：缩放后）](img/B17928_06_06.jpg)'
- en: 'Figure 6.6 – StandardScaler distribution (left: before scaling, right: after
    scaling)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – StandardScaler分布（左：缩放前，右：缩放后）
- en: You should only use this scaler if the underlying distribution is *normally
    distributed*, as this is the requirement.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当底层分布是*正态分布*时，才应使用此缩放器，因为这符合要求。
- en: Next, we will look at the **MinMaxScaler**. This scaling method is very similar
    to standardization, except that we are not working with the mean or standard deviation
    of the value distribution; instead, we are scaling the values to a range of [0,1]
    or [-1,1] (if negative values exist). Scaling a feature like this will often increase
    the performance of ML algorithms as they are typically better at handling small-scale
    values.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨**MinMaxScaler**。这种缩放方法与标准化非常相似，只是我们不是在处理值分布的均值或标准差；相反，我们将值缩放到[0,1]或[-1,1]（如果存在负值）的范围内。以这种方式缩放特征通常会提高机器学习算法的性能，因为它们通常更擅长处理小规模值。
- en: 'Mathematically, this scaling is defined as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这种缩放定义为以下：
- en: '![](img/Formula_06_04.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_06_04.png)'
- en: Here, ![](img/Formula_06_05.png) defines the minimum value and ![](img/Formula_06_06.png)
    defines the maximum value in our initial distribution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/Formula_06_05.png)定义了初始分布的最小值，而![](img/Formula_06_06.png)定义了初始分布的最大值。
- en: The MinMaxScaler is a good choice if the minimum and maximum values are well-defined
    – think about the color intensity in an RGB picture. Furthermore, we can change
    the formula to influence the resulting range of values.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最小值和最大值定义良好，MinMaxScaler是一个不错的选择 – 想想RGB图片中的颜色强度。此外，我们可以改变公式以影响结果的值范围。
- en: Important Note
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: The StandardScaler and the MinMaxScaler are both very susceptible to outliers
    in a distribution, which, in turn, can skew certain ML algorithms.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: A lot of ML algorithms pay more attention to large values, so they have a problem
    with outliers. A scaler fittingly named **RobustScaler** was defined to tackle
    this behavior. This scaler uses the **interquartile range** (**IQR**) instead
    of the standard deviation as a measure of dispersion and uses the **median** value
    instead of the mean value of the distribution as a measure of central tendency.
    The interquartile range denotes the middle 50% of the distribution, which means
    it is the difference between the 75th percentile and the 25th percentile.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the mathematical scaling function looks like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_07.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_06_08.png) denotes the median of the distribution, ![](img/Formula_06_09.png)
    denotes the value where the first quartile starts, and ![](img/Formula_06_10.png)
    denotes the value where the third quartile starts.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Why does this scaler work better with outliers?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: In the previous formulas, the biggest outlier would still be falling into the
    predefined interval because the maximum outlier would be ![](img/Formula_06_11.png).
    Therefore, the further the outlier is from the bulk of the data points, the more
    the center values would be scaled toward 0\. On the other hand, with the RobustScaler,
    all the data points in the middle 50% would be scaled into the unit distance,
    and everything above or below this would be scaled to the appropriate values outside
    of the main interval while keeping the relative distance between the values in
    the middle of the distribution intact.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, the median and the interquartile range are not influenced greatly
    by outliers, so this scaler is not influenced greatly by outliers.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at all these scalars on a sample distribution. For this, we will
    take the `Price` column of the `Price` column and the distribution resulting from
    applying each scaling method we''ve discussed:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Distribution scaled using multiple scaling methods ](img/B17928_06_07.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Distribution scaled using multiple scaling methods
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, **StandardScaler** creates a distribution with a mean of 0 and
    a standard deviation of 1, **MinMaxScaler** scales the values between 0 and 1,
    and **RobustScaler** sets the mean to 0\. Looking at the box plots in *Figure
    6.8* and *Figure 6.9*, we can see the differences in their distributions. Please
    note the scale of the *y* axis as well:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Box plot for StandardScaler and RobustScaler ](img/B17928_06_08.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Box plot for StandardScaler and RobustScaler
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparing the following box plot to *Figure 6.8*, we can see the difference
    in their distribution:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Box plot for MinMaxScaler ](img/B17928_06_09.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Box plot for MinMaxScaler
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have some idea of how to scale a feature, let's talk about normalization.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalization** is the process of taking a vector (row) of feature values
    and scaling them to a **unit magnitude**, typically to simplify mathematical processes
    such as **cosine similarity**.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化**是将特征值向量（行）缩放到**单位模长**的过程，通常是为了简化如**余弦相似度**这样的数学过程。'
- en: Let's start by understanding a process where this normalization step can be
    of help. The cosine similarity describes how similar two different vectors are
    to each other. In an n-dimensional room, are they pointing in the same direction,
    are they perpendicular to each other, or are they facing in the opposite direction?
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解一个可以从中受益的归一化步骤。余弦相似度描述了两个不同向量之间的相似程度。在一个n维空间中，它们是否指向同一方向，是否相互垂直，或者是否面向相反方向？
- en: Such calculations can, for example, help us understand how similar text documents
    are to each other, by taking a vector of word counts or similar information and
    comparing them with each other.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这样的计算可以帮助我们理解文本文档之间的相似性，通过取词频向量或类似信息并比较它们来实现。
- en: 'Therefore, to understand document similarity, we must calculate a cosine between
    vectors using the following formula:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了理解文档相似性，我们必须使用以下公式计算向量之间的余弦值：
- en: '![](img/Formula_06_12.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![公式_06_12.png](img/Formula_06_12.png)'
- en: 'As you can see, to make this calculation, we must calculate the magnitude of
    each vector – for example, ![](img/Formula_06_13.png). This magnitude is defined
    as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，为了进行这个计算，我们必须计算每个向量的模——例如，![公式_06_13.png](img/Formula_06_13.png)。这个模定义为以下内容：
- en: '![](img/Formula_06_14.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![公式_06_14.png](img/Formula_06_14.png)'
- en: This single vector magnitude calculation is quite expensive to perform. Now,
    imagine that we have a dataset that contains hundreds of thousands of documents.
    We would have to calculate this every time for every combination of vectors (samples)
    in our dataset. Wouldn't it be easier to have all these vector magnitudes equal
    to 1? This would greatly simplify the calculation of the cosine.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个单独的向量模长计算相当昂贵。现在，假设我们有一个包含数十万个文档的数据集。我们每次都必须为数据集中每个向量的组合（样本）计算这个值。如果所有这些向量模长都等于1，不是会更容易吗？这将极大地简化余弦的计算。
- en: 'Therefore, the idea is to normalize all the samples in our dataset to achieve
    a unit magnitude by scaling them appropriately, as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的想法是通过适当缩放所有样本，将数据集中的所有样本归一化到单位模长，如下所示：
- en: '![](img/Formula_06_15.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![公式_06_15.png](img/Formula_06_15.png)'
- en: In this equation, ![](img/Formula_06_16.png) denotes our initial vector, ![](img/Formula_06_17.png)
    denotes the magnitude of the initial vector, and ![](img/Formula_06_18.png) denotes
    our scaled vector with the unit magnitude.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，![公式_06_16.png](img/Formula_06_16.png)表示我们的初始向量，![公式_06_17.png](img/Formula_06_17.png)表示初始向量的模，![公式_06_18.png](img/Formula_06_18.png)表示我们缩放到单位模长的缩放向量。
- en: 'This normalization is called **L2 Norm** and is one of three typical normalization
    methods. Let''s look at how the magnitude of a vector is calculated in this and
    all the other metrics:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这种归一化称为**L2范数**，是三种典型归一化方法之一。让我们看看在这个以及其他所有度量中如何计算向量的模：
- en: '**L1 Norm**: This calculates the magnitude as the sum of the absolute values
    of the vector components.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L1范数**：这个计算将向量的模定义为向量各分量绝对值的和。'
- en: '**L2 Norm**: This calculates the traditional vector magnitude (as described).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L2范数**：这个计算的是传统的向量模长（如上所述）。'
- en: '**Max Norm**: This calculates the magnitude as the absolute value of the elements
    of the vector.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大范数**：这个计算的是向量的元素绝对值的模。'
- en: The L1 Norm and the Max Norm cannot be used for cosine similarity as they do
    not calculate the mathematically defined vector magnitude. So, let's look at how
    those two are calculated.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: L1范数和最大范数不能用于余弦相似度，因为它们没有计算数学上定义的向量模。所以，让我们看看这两个是如何计算的。
- en: 'The L1 Norm is mathematically defined as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: L1范数在数学上定义为以下内容：
- en: '![](img/Formula_06_19.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![公式_06_19.png](img/Formula_06_19.png)'
- en: The L1 Norm is often used to regularize the values in the dataset when you're
    fitting an ML algorithm. It keeps the coefficient small, which makes the model
    training process less complex.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: L1范数常用于在拟合机器学习算法时正则化数据集中的值。它保持系数较小，这使得模型训练过程更简单。
- en: 'The Max Norm is mathematically defined as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最大范数在数学上定义为以下内容：
- en: '![](img/Formula_06_20.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![公式_06_20.png](img/Formula_06_20.png)'
- en: The Max Norm is also used for regularization, typically in **neural networks**
    to keep the weights low at the connections between neurons. It also helps with
    performing less extreme backpropagation runs to stabilize the ML algorithm's learning.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have a good grasp of the usefulness of scaling and
    normalization. Next, we'll look at some methods we can use to transform categorical
    values into numerical representations.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Categorical encoding
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we looked at feature transformation as a concept, we looked at an example
    where we applied **one-hot encoding**. This method creates new features with two
    possible values (0,1) for *every* available category in the initial categorical
    feature. This can be helpful, but a categorical feature of high cardinality would
    blow up the feature space dramatically. Therefore, when using this method, we
    must figure out if every single category is predictive or not.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: In our previous example, instead of using a category with the days of the week
    (Monday through Saturday), we opted for only three categories, namely weekday,
    weekend, and holiday. In such a scenario, one-hot encoding is quite helpful.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Besides this method, there are other ways to encode categorical features. The
    most basic of them would be **label encoding**. In label encoding, we replace
    every category with a numeric label (0,..,*n*), thus making it a numeric feature.
    Through this, we did not add any additional information to this feature.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'The next idea would be to add some intrinsic information from the whole dataset
    and ingrain it into the values we must encode. Some options for this idea are
    as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '**Count encoding**: Replace each category with the absolute number of observations
    of this category in the whole dataset.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequency encoding**: Replace each category with the relative number (the
    percentage) of observations of this category in the whole dataset.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target encoding**: Replace each category with the mean value of the target
    that''s been calculated from each entry of this category throughout the whole
    dataset.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To understand these methods, let''s assume that we have a dataset that contains
    the favorite snack item of 25 people as one of the features and their likelihood
    of buying a new snack product a company produces as the target. The following
    table shows the original values and all three encodings we have discussed:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Count, frequency, and target encoding example ](img/B17928_06_10.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Count, frequency, and target encoding example
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: With these methods, we can ingrain additional information into the feature,
    making it easier for an ML algorithm to understand relationships.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's talk about `Rare`, thus grouping them into one category. This
    helps reduce the overall complexity and should especially be done if the `Rare`
    category will still be a small part of the overall category distribution. You
    can compare this to grouping small parties under the *Others* label in an election
    graph, while primarily showing the major parties.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们谈谈`Rare`，因此将它们归为一类。这有助于降低整体复杂性，特别是如果`Rare`类别仍然只是整体类别分布的一小部分时，更应该这样做。你可以将这比作在选举图中将小党派归入*其他*标签，而主要展示大党派。
- en: At this point, you should have a good understanding of different encoding techniques.
    In the next section, we will discuss how we can try out these techniques on a
    real dataset.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该对不同的编码技术有了很好的理解。在下一节中，我们将讨论我们如何在真实数据集上尝试这些技术。
- en: Testing feature engineering techniques on a tabular dataset
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在表格数据集上测试特征工程技术
- en: In [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, we did some cleaning and statistical analysis on the **Melbourne
    Housing dataset**. After looking through a set of possible feature engineering
    methods in the previous section, you may have realized that we used some of these
    methods when we were working with our dataset.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)《执行数据分析与可视化》中，我们对**墨尔本住房数据集**进行了一些清理和统计分析。在上一节查看了一系列可能的特征工程方法之后，你可能已经意识到我们在处理数据集时使用了其中的一些方法。
- en: As an exercise, think about where we left off and, keeping the feature engineering
    options in mind, what we could do now to create new useful features, transform
    the given features, and eventually select the most prominent and predictive features
    in our dataset.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，思考我们之前停在了哪里，并考虑到特征工程选项，我们现在可以做什么来创建新的有用特征，转换给定的特征，并最终在我们的数据集中选择最突出和最具预测性的特征。
- en: For inspiration, have a look at the `02_fe_melbhousing.ipynb` file in the GitHub
    repository for this chapter.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得灵感，请查看GitHub仓库中本章的`02_fe_melbhousing.ipynb`文件。
- en: In the final section of this chapter, we will leave the feature space behind
    and concentrate on the target or label for our ML training – to be more precise,
    on the cases where we are missing the labels.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们将放下特征空间，专注于我们的机器学习训练的目标或标签——更准确地说，是那些缺少标签的情况。
- en: Handling data labeling
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据标注
- en: 'In this section, we will look at one of the most time-consuming and important
    tasks when it comes to preprocessing our dataset for ML training: **data labeling**.
    As we learned while looking at high-dimensional reduction and other ML techniques
    in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, for most scenarios, it is vitally important to have labels
    attached to our samples. As we discussed in [*Chapter 1*](B17928_01_ePub.xhtml#_idTextAnchor015),
    *Understanding the End-to-End Machine Learning Process*, there are only a few
    scenarios where unsupervised learning models are sufficient, such as a model that
    clusters emails as spam or not spam. In most cases, we want to use a supervised
    model, which means we will require labels.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨在为机器学习训练预处理数据集时最耗时且最重要的任务之一：**数据标注**。正如我们在[*第一章*](B17928_01_ePub.xhtml#_idTextAnchor015)《理解端到端机器学习流程》中学习到的那样，对于大多数场景，将标签附加到我们的样本上至关重要。正如我们在[*第五章*](B17928_05_ePub.xhtml#_idTextAnchor085)《执行数据分析与可视化》中查看高维降维和其他机器学习技术时讨论的，在大多数情况下，我们希望使用监督模型，这意味着我们需要标签。
- en: In the following sections, we will discuss what scenarios require us to do manual
    labeling and how Azure Machine Learning can help us be as efficient as possible
    to perform this monotonous task.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将讨论哪些场景需要我们进行手动标注，以及Azure机器学习如何帮助我们尽可能高效地完成这项单调的任务。
- en: Analyzing scenarios that require labels
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析需要标签的场景
- en: We will start by looking at the types of datasets we have discussed so far and
    in which scenarios we will need to perform manual labeling.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先查看我们迄今为止讨论过的数据集类型，以及我们需要在哪些场景下进行手动标注。
- en: Numerical and categorical data
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数值数据和分类数据
- en: As we saw when we worked with the **Melbourne Housing dataset**, for tabular
    datasets, we may often have a column that can be used as the label. In our case,
    it was the price column that we could use as a label since our goal for ML was
    to predict house prices based on specific feature inputs.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: But even if this column was missing, we could have incorporated other datasets,
    such as one that shows the mean price for houses in different suburbs of Melbourne,
    to calculate a reasonable value for each of our dataset samples.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the main advantage over any of the other scenarios we will discuss
    next is that in a dataset made up of numerical and categorical features with clear
    meaning (not the pixel values of an image), we can use logic and mathematical
    functions to create a numerical label, or we can classify samples into a categorical
    label in an automated fashion. This means we do not have to look at every sample
    manually to define its label.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Natural language processing
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's start by looking at text data. You may think that a categorical entry
    would also be text in a sense, but typically, categorical data can also be exchanged
    with mathematical values without you losing much.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Text data, on the other hand, denote blocks of words, such as those in this
    book, so they are much more complicated. Look at the following two sentences or
    utterances:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '*I would like to book a plane ticket for December 23rd, 2020 from Dubai to
    Paris.*'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '*The room wasn''t cleaned, and the heating wouldn''t work.*'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: How would we label these utterances? Once again, this very much depends on our
    goal for training. Maybe we just want to put these utterances into groups, such
    as order, greeting, or statement. In that scenario, every utterance would receive
    one label. On the other hand, we may want to drill down into the meaning of the
    words in the sentence. For our first utterance, we may want to understand the
    meaning of the order to offer an answer by showing possible flight options. For
    the second utterance, we may want to understand the sentiment since it is a statement
    about the quality of a hotel room.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we need to start labeling single words or phrases in the utterance
    itself, while looking for the semantic meaning.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: We will come back to this topic in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112),
    *Advanced Feature Extraction with NLP*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we talk about ML modeling for images, we are typically trying to understand
    and learn about one of the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '**Image classification**: Classify an image into one or more classes. Typical
    use cases include image searches, library management, and sentiment analysis of
    a person.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object detection**: Localize specific objects in an image. Typical use cases
    include pedestrian detection, traffic flow analysis, and object counting.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image segmentation**: Assign each pixel of an image to a specific segment.
    Typical use cases include precise environment analysis for self-driving cars and
    pixel-precise anomaly detection in an X-ray or MRI picture.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows an example of these three types:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Different image processing methods ](img/B17928_06_11.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Different image processing methods
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: For these methods, the process of labeling them becomes more complicated, the
    further we go down the list. For classification, we can just put one or more labels
    on an image. For object detection, we start drawing so-called bounding boxes or
    polygons on the image. Finally, image segmentation becomes very complicated as
    we must assign labels for each pixel of the image. For this, highly specialized
    tooling is required.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: As we will see shortly, we can use the data labeling tool from Azure Machine
    Learning Studio to do classification, object detection, and, to some degree, segmentation
    for image labeling tasks.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Audio annotation
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, let''s talk about annotating audio data. When it comes to ML modeling
    for audio data, the following scenarios are possible:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech-to-text**: Run real-time transcription, voice assistants, pronunciation
    assessments, and similar solutions.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech translation**: Translate speech to trigger actions in an application
    or device.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speaker recognition**: Verify and identify speakers by their voice characteristics.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, annotating audio data means that we must take out snippets from
    an audio file and label these snippets accordingly. The following diagram shows
    a simple example of this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Audio labeling process ](img/B17928_06_12.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Audio labeling process
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, this labeling task is also not very straightforward and
    requires specialized tooling.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: We have seen a lot of scenarios so far, where labeling is of utmost importance.
    Now, let's try to label some images ourselves.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Performing data labeling for image classification using the Azure Machine Learning
    labeling service
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will be using the data labeling service in Azure Machine
    Learning Studio to label some assets. As we learned in [*Chapter 3*](B17928_03_ePub.xhtml#_idTextAnchor054),
    *Preparing the Azure Machine Learning Workspace*, navigate to the Azure Machine
    Learning Studio and click on **Data Labeling** at the lower end of the menu, as
    shown in the following screenshot:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Azure Machine Learning Studio ](img/B17928_06_13.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – Azure Machine Learning Studio
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'On the following screen, click **Add Project**, which will take you to the
    following view:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Creation wizard for a labeling project ](img/B17928_06_14.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – Creation wizard for a labeling project
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start the exercise, let''s look at what kind of labeling tasks we
    can perform with the service. As shown in the preceding screenshot, we can work
    with image and text data as our data source. Switching between the **Image** and
    **Text** options on-screen, we have the following choices:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Classification Multi-class**: Attach a single label to each image.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image Classification Multi-label**: Attach multiple labels to each image.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object Detection (Bounding Box)**: Draw one or multiple boxes around an object
    on an image.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instance Segmentation (Polygon)**: Draw complex polygons around an object
    on an image.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Classification Multi-class**: Attach a single label to a piece of text.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Classification Multi-label**: Attach one or multiple labels to a piece
    of text.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, there are a lot of helpful options when it comes to image data.
    We can even highlight and tag very specific pieces in an image by using a **bounding
    box** or a **polygon**. Using polygons, you are technically able to do a complete
    **image segmentation**, but it is quite hard to assign each pixel to a class with
    this tool.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: For text data, however, there are some limitations. We do not have the option
    to label specific words or phrases in a piece of text, as we discussed in the
    previous section. At the time of writing, the only option is to single- or multi-label
    a text block.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we will be working with images. To not make using this tool for
    the first time too complex, we will start by attaching a single label to images
    in an image dataset. In the following steps, we will create an image dataset and
    a corresponding labeling project:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Before going through the wizard, let's look for a suitable image dataset to
    use. We will be using the **STL-10 dataset** ([https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)).
    This dataset contains a huge amount of small 96x96 images that can be divided
    into 10 classes (**airplane**, **bird**, **car**, **cat**, **deer**, **dog**,
    **horse**, **monkey**, **ship**, and **truck**). These 10 classes will be our
    labels. As the original page only offers us the images in binary format, we need
    to find a different source. On **Kaggle**, you often find these types of datasets
    prepared in different formats.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to [https://www.kaggle.com/jessicali9530/stl10](https://www.kaggle.com/jessicali9530/stl10)
    and download `test_images`, which is a set of 8,000 files in `png` format. Normally,
    we would use the `unlabeled_images` set, but since there are 100,000 of them,
    we will leave them be for now.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you haven't done so already, download the files for this chapter to your
    device and create a new folder called `images` under the `chapter06` folder.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Extract all 8,000 images to the `images` folder. After that, open the `03_reg_unlabeled_data.ipynb`
    file. In this file, you will find the code we have been using so far to connect
    to our workspace and datastore. Please replace `datastore_name` with the one you
    have been given in your ML workspace. The last code snippet of the first cell
    reads as follows:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `upload_directory` method will, with one call, upload all the files from
    the `images` folder to the datastore location you defined in the target and will
    create a file dataset object called `file_ds`. Once the upload is complete, we
    can register our new dataset with the following code:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you navigate to the **Datasets** tab in Azure Machine Learning Studio, you
    will see our newly registered dataset. Under the **Explore** tab, you will see
    a subset of the images, including image metadata and a preview of the images.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have registered our dataset, we can set up our labeling project.
    Go back to the wizard, as shown in *Figure 6.14*, enter `STL10_Labeling` as the
    project name, and choose **Image Classification Multi-class** as the type. Click
    **Next**.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the next screen, Microsoft will give you the option to hire a workforce from
    the **Azure Marketplace** to perform your labeling work. This can be a helpful
    tool, as you will soon learn how tedious this task can be. For now, we do not
    require additional help. Click **Next**.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can choose the dataset to work on. Select our newly create dataset,
    named `STL10_unlabeled`, and click **Next**.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will see an option called **Incremental Refresh**. This feature updates the
    project once a day if new images have been added to the underlying dataset. We
    are not planning on doing this here, so leave it as-is and click **Next**.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following screen asks us to define our labels. `airplane`, `bird`, `car`,
    `cat`, `deer`, `dog`, `horse`, `monkey`, `ship`, and `truck` as labels. Then,
    click **Next**.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second to last screen allows us to enter **Labeling instructions**. These
    are useful if we are not working alone on the project or we have ordered a workforce
    to do the job. Here, we can give them instructions. For us, as we are working
    alone, this is unnecessary. So, click **Next**.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we have the option to use **ML-assisted labeling**. If we do not activate
    this option, we would have to label all 8,000 images by ourselves without help.
    Please be aware that activating this option requires a GPU compute cluster that
    runs for a couple of minutes every time the assisting ML model is retrained. We
    will choose the **Use default** option, which will create an appropriate cluster
    for us. Click **Create project**. This will bring us back to the overview. When
    the cluster has been created, click on the project's name to get to the overview
    page.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see a dashboard similar to the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – The dashboard for the labeling project ](img/B17928_06_15.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – The dashboard for the labeling project
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: 'The dashboard is divided into the following views:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '**Progress**: This shows the number of assets being labeled. In our case, we
    are working with 8,000 images. It also shows the status for each asset (**Completed**,
    **Skipped**, **Needs review**, and **Incomplete**).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label class distribution**: This view will show a bar chart of which label
    has been used and how many times to classify an image.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Labeler performance**: This view shows how many assets each labeler has processed.
    In our case, only our name will be shown there.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task queue**: This view shows what tasks are in the pipeline. At the moment,
    we need to label 150 images manually before the next training phase or the next
    check occurs.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML-assisted labeling experiment**: This view shows the running or already
    run training experiments for the assisting ML model.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you switch the view to the **Data** tab, you will see some previews for images
    and you can review the already labeled images. This is helpful when you're working
    in a team, where a couple of people are working on labeling the images and some
    are reviewing their labeling efforts.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you look at the `DefLabelNC6`.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the overview page of this cluster:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Labeling cluster dashboard ](img/B17928_06_16.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – Labeling cluster dashboard
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the machines that are being used for the nodes sport 6 cores,
    56 GB of RAM, and a Tesla K80 GPU. Always check the pricing page ([https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/))
    when you're creating any type of compute instance on Azure. As shown on that page,
    the node we are using is called **NC6** and costs around $3 per hour. The cluster
    node shows that the cluster is **Idle**, so there are no costs. Later, you can
    check the **Runs** tabs for the duration of the training runs to understand the
    pricing implications. At the moment, a good, educated guess would be that we will
    need 2 to 4 hours for the ML-assisted support in our labeling project.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'So, before we start labeling the images, let''s understand what ML-assisted
    labeling does. When you switch back to the dashboard of our labeling project,
    you will see three options under **Task queue**, as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '**Manual**: This denotes the assets we must handle without support at any given
    point.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustered**: This denotes the assets where a clustering model was being used
    on the already labeled assets. When you work on these assets, they will be shown
    to you in groups of images that the model thinks belong to the same class.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prelabeled**: This denotes the assets where a classification model was trained
    on the already labeled assets. In this case, it predicted labels for unlabeled
    assets. When you''re working on those images, you will be shown the suggested
    labels and have to check if the model was correct.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s start labeling. When you click **Label data**, you will see the
    following view:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Labeling task view ](img/B17928_06_17.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – Labeling task view
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: From this view, you can see the asset in the middle. With the controls up top,
    you can **Zoom in** and change the **Brightness** and **Contrast** properties
    of the image. If you are unsure about these options, you can select **Skip** for
    now. On the right, you can choose the appropriate label. If you are happy with
    your choice, you can click **Submit**.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Do this for a couple of images to get a grip on things. After that, look at
    the controls at the top right. Here, we can change how many assets are shown to
    us at the same time (1, 4, 6, or 9). I would suggest displaying 6 assets at the
    same time. In addition, to label pictures, you can multi-select them and use the
    keyboard numbers 1 to 9 (as shown on the right of the preceding screenshot) to
    label faster.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Now, to see the ML-assisted labeling being triggered, you will need to manually
    label around 400 to 600 images. You can decide if this is a good use of your time,
    but it is a good exercise to do as it gives you a perspective of how tedious this
    task is.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Eventually, the training will be triggered, as shown in the following screenshot:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – Triggered training run for labeling ](img/B17928_06_18.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – Triggered training run for labeling
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'I had to label 616 assets manually before the first labeling training would
    be triggered. As we can see, the tool shows the distribution of label classes
    that were encountered during the labeling process at that point. As with any other
    training, this creates an experiment with runs. You can find these under `Experiments`
    in the ML workspace, as shown in the following screenshot:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Experiment run for ML-assisted labeling ](img/B17928_06_19.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 – Experiment run for ML-assisted labeling
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, just continue to label assets. Eventually, you will either be
    shown clustered images, defined by **Tasks clustered** at the top of the page
    (see *Figure 6.20*):'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Data labeling showing clustered images ](img/B17928_06_20.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 – Data labeling showing clustered images
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'Or you''ll be shown prelabeled images, defined by **Tasks prelabeled** at the
    top of the page (see *Figure 6.21*):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Data labeling showing prelabeled images ](img/B17928_06_21.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 – Data labeling showing prelabeled images
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: With that, you've seen how you can utilize ML modeling to label your assets
    and how Azure Machine Learning Studio makes this process easier. As you should
    understand by now, this is a time-consuming task, but it needs to be done if you
    wish to achieve much better results in your ML training down the line.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at how to prepare our features through feature engineering
    and how to prepare our labels through labeling.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: In the first section, we learned that feature engineering includes creating
    new and missing features, transforming existing features, extracting features
    from a high-dimensional dataset, and using methods to select the most predictive
    feature for ML training.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: In the second section, we learned that labeling is essential and tedious. Therefore,
    tooling such as Azure Machine Learning data labeling can be a blessing to alleviate
    this time-consuming task.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: The key takeaway from this chapter is that creating, transforming, and selecting
    predictive features has the biggest impact on the quality of the ML model. No
    other step in the ML pipeline will have more influence on its outcome.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: To pull off quality feature engineering, you must have intimate knowledge of
    the domain (or you must know someone with that knowledge) and a clear grasp of
    how the chosen ML algorithm works internally. This includes understanding the
    mathematical theory, the required data structure the algorithm expects as input,
    and the feature engineering methods that are applied automatically when you're
    fitting the model.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see feature engineering in action. We will look
    at how to perform feature extraction on text data for natural language processing.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
