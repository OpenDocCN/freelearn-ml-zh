- en: '*Chapter 6*: Feature Engineering and Labeling'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to clean our data and do basic statistical
    analysis. In this chapter, we will delve into two more types of actions we must
    perform before we can start our ML training. These two steps are the most important
    of all besides efficiently cleaning your dataset, and to be good at them, you
    will require a high amount of experience. This chapter will give you a basis to
    build upon.
  prefs: []
  type: TYPE_NORMAL
- en: In the first section, we will learn about feature engineering. We will understand
    the process, how to select predictive features from our dataset, and what methods
    exist to transform features from our dataset to make them usable for our ML algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In the second section, we will look at data labeling. Most ML algorithms fall
    into the category of supervised learning, which means they require labeled training
    data. We will look at some typical scenarios that require labels and learn how
    Azure Machine Learning can help with this tedious task.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and applying feature engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling data labeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will use the following Python libraries and versions to
    perform feature engineering on different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '`azureml-sdk 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureml-widgets 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureml-dataprep 2.20.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas 1.3.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy 1.19.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scikit-learn 0.24.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seaborn 0.11.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`plotly 5.3.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`umap_learn 0.5.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`statsmodels 0.13.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`missingno 0.5.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to previous chapters, you can execute this code using either a local
    Python interpreter or a notebook environment hosted in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter06).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and applying feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Feature engineering** is the general term that describes the process of transforming
    existing features in our dataset, creating missing features, and eventually selecting
    the most predictive features from our dataset to start the ML training process
    with a given ML algorithm. These cannot just be seen as some mathematical functions
    we must apply to our data. This is an art form and doing it well makes the difference
    between a mediocre and highly performing predictive model. If you want to understand
    where you should invest your time, feature engineering is the step where you can
    have the most impact on the quality of your final ML model. To create this impact
    and be efficient, we must consider the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ML algorithm requirements**: Do the features have to be in a specific format
    or range? How do I best avoid overfitting and underfitting the model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain knowledge**: Are the given features sufficient for our model? Can
    we create additional features or derive features that contain more predictive
    information?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we'll define the different classes of feature engineering techniques
    and then look at some of the most prominent methods to apply to different types
    of datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the usefulness of a specific feature engineering method depends
    on the utilized type of features (categorical, continuous, text, image, audio)
    and the chosen ML algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying feature engineering techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Broadly speaking, feature engineering methods can be grouped into the following
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Feature creation**: Create new features from the given set of features or
    additional information sources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature transformation**: Transform single features to make them useful and
    stable for the utilized ML algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature extraction**: Create derived features from the original data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature selection**: Choose the most prominent and predictive features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at each of these categories and what they entail.
  prefs: []
  type: TYPE_NORMAL
- en: Feature creation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step to take in feature engineering is finding all the features that
    should be included in the model. To be good at this, you must have an intimate
    understanding of the relevant domain or know someone who is a **subject matter
    expert** (**SME**) in the domain. In the end, we want to be sure that we consider
    any type of data point that is predictive and that is feasible to acquire in a
    reasonable amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In turn, we must understand all the methods that can help us create new features
    in our dataset, either taken from additional sources or the initial dataset. Typically,
    these methods can be classified as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adding missing predictive features**: We add external information that is
    missing to achieve a more predictive model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combining the available features**: We create new features by combining already
    available features in our dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do we have to change already existing features in our dataset?
  prefs: []
  type: TYPE_NORMAL
- en: The reason for this is that a lot of connections between features and labels,
    that we understand, may not be clear to the utilized ML algorithm. Therefore,
    it is a good idea to think about what features or representations of the available
    features we would assume are necessary to make it easier for the ML algorithm
    to grasp the intrinsic connections.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at some examples to understand this better.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that you have a dataset for predicting house prices, like the one we
    examined in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing
    Data Analysis and Visualization*. Furthermore, imagine that the features we have
    are the **length** and **width** of the house or apartment. In this case, it is
    probably useful to combine these two features to create a new one called the **surface
    area**. In addition, if the **type** of building is missing (house, flat, condo,
    and so on), we may want to add this from other sources since we know the type
    has an impact on the price of a property.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: If you create new features from existing ones, it is typically wise to only
    stick with the newly created feature by dropping those initial features from the
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine the amount of money a person spends throughout their life. Being
    young, this might be very little. When they grow older, they may have mortgages
    and children and eventually, their spending may drop when their children move
    out of the house, and they are nearing retirement. As this would form something
    of a parabolic relationship between **age** and **cost of living**, it may not
    be easy for an ML algorithm to grasp this. Therefore, one possible option is to
    square the values of the **cost of living** feature to emphasize higher costs
    and deemphasize lower costs.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous two examples, we used our domain knowledge to create new features.
    But what if we do not have this at our disposal?
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a way to create new features mathematically using the so-called **polynomial
    extension**. The idea is to create new features by raising the value of a feature
    to a certain power and multiplying it by one or multiple other features. Here,
    we define the **degree** as the maximum power a single feature can be raised to,
    and we define the **order** as the number of features we allow to be multiplied
    by each other. The following diagram shows all the possible combinations for a
    degree of 2 and order of 2 on the left-hand side, and a degree of 3 and order
    of 3 on the right-hand side:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Possible combinations for polynomial extension  (degree=2, order=2
    on the left/degree=2, order=3 on the right) ](img/B17928_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Possible combinations for polynomial extension (degree=2, order=2
    on the left/degree=2, order=3 on the right)
  prefs: []
  type: TYPE_NORMAL
- en: You should only consider a maximum order of 3 because, as shown in the preceding
    diagram, even with a degree of 2, this operation already creates too many combinations.
    Still, this automatic process may lead to much better predictive features than
    the originating ones.
  prefs: []
  type: TYPE_NORMAL
- en: To try this method, you can use the `PolynomialFeatures` class from the `sklearn`
    library ([https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)).
  prefs: []
  type: TYPE_NORMAL
- en: With all these methods in mind, we can create new features in our dataset that
    might be easier for our ML algorithm to handle and contain more precise, predictive
    information.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's look at some methods that let us change a single feature by transforming
    its values or its representation.
  prefs: []
  type: TYPE_NORMAL
- en: Feature transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Feature transformation** is about manipulating a feature to change its value
    or create a new representation of the same. The following list covers the types
    of transformations we can perform on single features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Discretization**: Divide feature values into different groups or intervals
    to reduce complexity. This can be done on numerical or categorical features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Splitting**: Split a feature into multiple elements. This is typically done
    on datetime and string values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorical encoding**: Represent a categorical feature numerically, by creating
    new numerical features while following specific methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling**: Transform a continuous feature so that it fits into a specified
    range of values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization**: Transform a continuous feature so that it represents a
    normal distribution with a mean of 0 and a standard deviation of 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normalization**: Transform a vector (row) of multiple continuous features
    individually into a so-called unit norm (unit magnitude).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`square`, `square root`, `exp`, `log`, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, we used the `log` function to calculate the logarithm of all
    house price values. We did this to reduce the impact that a handful of outliers
    would have on our ML training. Therefore, the main reason to transform features
    is to adapt the feature to the possible mathematical requirements of the given
    ML algorithm. Often, you may run into the following requirements of the ML algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Numerical format**: The algorithm requires all the features to be numerical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Same scale**: The algorithm requires all the predictive features to be on
    the same scale, maybe even with a mean of 0 and a standard deviation of 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mathematical theory**: The domain itself may require certain transformations
    based on mathematical theory. For example, a price feature for predictions concerning
    economic theory should nearly always be transformed with the natural logarithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[-1,1]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complexity**: Most algorithms require very precise features. Therefore, reducing
    the complexity of the possible values a feature can take is often worthwhile.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example would be discretizing features. One such method is called **binning**,
    which transforms numerical continuous values into a handful of discrete values.
    We will see this in action on text data in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112),
    *Advanced Feature Extraction with NLP*.
  prefs: []
  type: TYPE_NORMAL
- en: Another example would be splitting datetime features. Imagine that we want to
    predict the amount of traffic on a certain road at specific times of the day.
    Let's assume that we got a feature denoting the **date and time** of our recording
    and the **number of cars** we tracked at that point. To make a better prediction,
    one idea would be to create three new features, denoting whether it is a *workday*,
    *weekend*, or *holiday*. There will be less traffic on a Sunday at 7 A.M. compared
    to a workday morning at 7 A.M.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s learn how to perform this transformation. The following screenshot shows
    our initial small dataset and the first transformation adding `day of the week`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Dataset with a new weekday feature   ](img/B17928_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Dataset with a new weekday feature
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next step, we must enrich the data by adding a new categorical feature
    called `daytype`, which denotes whether a day is either a weekday, a weekend,
    or a holiday:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Dataset enrichment  ](img/B17928_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Dataset enrichment
  prefs: []
  type: TYPE_NORMAL
- en: 'Theoretically, we are done. But our ML algorithm may beg to differ here. Our
    ML model may make up a natural order for our categorical data that does not exist
    or it simply cannot handle categorical data. In this case, it is prudent to **encode**
    our categorical data with numerical values. One such method is called **one-hot
    encoding**, which transforms a categorical feature into multiple numerical features
    by creating a new feature with two valid values (0 or 1) for every existing category.
    The following screenshot shows this encoding for our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 6.4 – One-hot encoding the new feature ](img/B17928_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – One-hot encoding the new feature
  prefs: []
  type: TYPE_NORMAL
- en: Here, we created three new features named `holiday`, `weekday`, and `weekend`,
    each representing our initial categories. Where a sample had this initial category,
    the value of that feature is set to `1`; otherwise, it is set to `0`.
  prefs: []
  type: TYPE_NORMAL
- en: What have we done in this example? We transformed a very unintuitive datetime
    feature into something with more predictive power by splitting the feature into
    components, adding external knowledge through feature creation, and performing
    categorical encoding on the created feature.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good grasp of feature transformation, let's look at what
    falls under feature extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With **feature extraction**, we group all the methods that do not manipulate
    features by simple means but extract useful information from a high-dimensional
    dataset. This is typically done by using complex mathematical algorithms or ML
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Extraction is often required when the underlying dataset is too complex to be
    processed, so it needs to be brought into a simplified form while keeping its
    predictive value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some typical extraction types for different scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High-dimensional reduction**: Create representative features based on an
    *n*-dimensional dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature detection**: Find points of interest in every image in an image dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Word embeddings**: Create numeric encodings for words in a text dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Signal processing**: Extract the characteristics of sound waves from an audio
    dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We discussed high-dimensional reduction methods in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*, when we looked at visualizing high-dimensional
    datasets. In a process like **principal component analysis** (**PCA**), the dataset
    is projected onto a two- or three-dimensional space by creating principal component
    vectors. Instead of only using this method for visualization, we could use these
    calculated vectors as derived and less complex features that represent our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: High-dimensional reduction techniques can be used for feature extraction, but
    keep in mind that we lose our intrinsic understanding of the features. Instead
    of features called suburbs or rooms, we end up with features called Principal
    Component 1 and Principal Component 2.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the other scenarios, it seems that extraction typically happens when
    we are working with complex datasets made up of text, image, or audio data. In
    all these cases, there are specific methods to consider when extracting information
    from the raw data.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of an image dataset, we might be interested in key areas or points
    of interest, including finding edges and objects. In [*Chapter 10*](B17928_10_ePub.xhtml#_idTextAnchor165),
    *Training Deep Neural Networks on Azure*, you will see that such image extraction
    steps are done automatically by **deep neural networks**, removing the need to
    perform manual feature extraction on images in a lot of cases.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of text data, we can use extraction methods such as **bag of words**
    and **TF-IDF**, both of which help create numerical representations of text, capturing
    meaning and semantic relationships. We will have an in-depth look at these methods
    in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112), *Advanced Feature Extraction
    with NLP*.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of audio data, we can use signal processing to extract information
    and new features from the source. In this scenario, there are also two domains
    – the time domain and the frequency domain – that we can pull information from.
    From the time domain, we would typically extract something like the **amplitude
    envelope**, which is the maximum amplitude of the signal per frame, the **root
    mean square energy**, which hints at the loudness of the signal, and the **zero-crossing
    rate**, which is the number of times the wave is crossing the horizontal time
    axis. If you must work with data from this domain, make yourself comfortable with
    such processing techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: A lot of feature extraction and feature transformation techniques are already
    embedded in common ML frameworks and algorithms, removing the need for you to
    manually touch features. Have a good understanding of what the algorithm does
    by itself and what you need to do manually when you're preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've learned how to create new features, transform features, and extract
    features from our dataset. Now, let's look at some methods that can help us select
    the most predictive feature from our feature set.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With **feature selection**, we define all the methods that help us understand
    how valuable and predictive a feature is for the target so that we can choose
    a useful subset of our feature variables for training. The reasons to reduce complexity
    are two-fold. On the one hand, we want the simplicity to make the model **explainable**
    while on the other, we want to avoid **overfitting** the model. With too much
    input information, we will end up with a model that, in most cases, will perfectly
    fit our training data and nothing else but will perform poorly on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, there are three different types of feature selection methods, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Filter-based methods**: These define a derived metric, that is not the target
    error rate, to measure the quality of a subset of features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wrapper-based methods**: These use greedy search algorithms to run a prediction
    model on different combinations of feature subsets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Embedded methods**: These are specific selection methods that are already
    embedded into our final ML model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filter-based methods can be very efficient in terms of computational resources
    but are only evaluated against a simpler filter. Typically, statistical measures
    such as correlation, mutual information, and entropy are used as metrics in these
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, wrapper-based methods are computationally intense. At the
    same time, they can find a great performing feature set since the same error function
    or metric is being used for the selection of the features as the one that''s being
    used in the actual model training. The downside of this approach is that without
    an independent metric, the selected subset is only useful for the chosen ML training
    algorithm. Typically, this is done by performing one of the following processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step forward feature selection**: Features are added one by one based on
    the training results of each feature until the model does not improve its performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Step backward feature selection**: The model is evaluated with the full set
    of features. These features are subsequently removed until a predefined number
    of features is reached. This removal is done in a round-robin fashion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exhaustive feature selection**: All the feature subsets are evaluated, which
    is the most expensive method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, a selection method is called an embedded method when the selection
    step is part of the model learning algorithm itself. Embedded methods often combine
    the qualities of filter and wrapper methods through the fact that the learning
    algorithm takes advantage of its selection process and performs selection and
    training at the same time. Typical examples of embedded methods are ensemble models,
    **Lasso**, and **Ridge**.
  prefs: []
  type: TYPE_NORMAL
- en: You may have realized this by now, but we used such methods in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*. The **Pearson correlation coefficient**
    we used for generating a correlation matrix is a derived metric, so it falls under
    the filter-based selection methods. In addition, we used an **ensemble decision
    tree model** to calculate feature importance for our dataset. This helped us get
    a clear understanding of which features may have more influence on the target
    than others. This ensemble method utilizes the **random forest** approach. A random
    forest not only implements the so-called **bagging** technique to randomly select
    a subset of samples to train on but also takes a random selection of features
    rather than using all the features to grow each tree. Therefore, for feature selection,
    random forests fall into the embedded category.
  prefs: []
  type: TYPE_NORMAL
- en: We will have a more detailed look at the tree-based ensemble classifier, as
    well as bagging and boosting, in [*Chapter 9*](B17928_09_ePub.xhtml#_idTextAnchor152),
    *Building ML Models Using Azure Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Besides all these mathematical approaches to feature selection, sometimes, a
    more manual approach might be far superior. For example, when we removed the postal
    code from our **Melbourne housing dataset** in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085),
    *Performing Data Analysis and Visualization*, we did so because we understood
    that the postal code and the suburbs contain the same information, which made
    them redundant. We did this because we have domain knowledge and understand the
    relationship between postal codes and suburbs. Note that this additional knowledge
    lessens the burden for the model to learn these connections by itself.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: For feature engineering, the more outside knowledge about the data or the domain,
    the simpler a lot of these preprocessing steps can get, or they become avoidable
    altogether.
  prefs: []
  type: TYPE_NORMAL
- en: We will iterate this notion throughout this book as it needs to be ingrained
    into everything you do so that you get more efficient and better at working with
    data.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a general understanding of the general types of feature engineering
    we can perform. In the next section, we will provide an overview of the most prominent
    methods and drill deeper into some of them.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering feature transformation and extraction methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have a good grasp of the types of feature engineering action we
    can apply to our feature, let''s look at some of the most prominent feature engineering
    techniques and their names. The following table provides a good overview of most
    of the well-known methods in the different categories we have learned about:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Overview of different feature engineering methods  ](img/B17928_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Overview of different feature engineering methods
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that this list is far from exhaustive and as we mentioned previously,
    some of these methods are already implemented as part of specific ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will look at some of these. Feel free to download
    the `01_feateng_examples.ipynb` file in the GitHub repository for this chapter,
    which contains the code for the upcoming examples. If you would like to learn
    more about some of the feature extraction methods we will cover, we will come
    back to them in the upcoming chapters. For the methods we won't cover, feel free
    to research them.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling, standardization, and normalization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since all the scaling and normalization methods are very similar to each other,
    we will discuss all of them in detail here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s begin with the so-called **StandardScaler**. This scaling transforms
    our feature values so that the resulting value distribution has a mean (µ) of
    0 and a standard deviation (s) of 1\. The formula to apply to each value looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, µ is the mean value of the given distribution and s is the standard deviation
    of the given distribution. With this, we can convert every value, ![](img/Formula_06_02.png),
    into a new scaled value, ![](img/Formula_06_03.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how this scaler changes the shape of multiple distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – StandardScaler distribution (left: before scaling, right: after
    scaling) ](img/B17928_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6 – StandardScaler distribution (left: before scaling, right: after
    scaling)'
  prefs: []
  type: TYPE_NORMAL
- en: You should only use this scaler if the underlying distribution is *normally
    distributed*, as this is the requirement.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at the **MinMaxScaler**. This scaling method is very similar
    to standardization, except that we are not working with the mean or standard deviation
    of the value distribution; instead, we are scaling the values to a range of [0,1]
    or [-1,1] (if negative values exist). Scaling a feature like this will often increase
    the performance of ML algorithms as they are typically better at handling small-scale
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, this scaling is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_04.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_06_05.png) defines the minimum value and ![](img/Formula_06_06.png)
    defines the maximum value in our initial distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The MinMaxScaler is a good choice if the minimum and maximum values are well-defined
    – think about the color intensity in an RGB picture. Furthermore, we can change
    the formula to influence the resulting range of values.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: The StandardScaler and the MinMaxScaler are both very susceptible to outliers
    in a distribution, which, in turn, can skew certain ML algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of ML algorithms pay more attention to large values, so they have a problem
    with outliers. A scaler fittingly named **RobustScaler** was defined to tackle
    this behavior. This scaler uses the **interquartile range** (**IQR**) instead
    of the standard deviation as a measure of dispersion and uses the **median** value
    instead of the mean value of the distribution as a measure of central tendency.
    The interquartile range denotes the middle 50% of the distribution, which means
    it is the difference between the 75th percentile and the 25th percentile.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the mathematical scaling function looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_07.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_06_08.png) denotes the median of the distribution, ![](img/Formula_06_09.png)
    denotes the value where the first quartile starts, and ![](img/Formula_06_10.png)
    denotes the value where the third quartile starts.
  prefs: []
  type: TYPE_NORMAL
- en: Why does this scaler work better with outliers?
  prefs: []
  type: TYPE_NORMAL
- en: In the previous formulas, the biggest outlier would still be falling into the
    predefined interval because the maximum outlier would be ![](img/Formula_06_11.png).
    Therefore, the further the outlier is from the bulk of the data points, the more
    the center values would be scaled toward 0\. On the other hand, with the RobustScaler,
    all the data points in the middle 50% would be scaled into the unit distance,
    and everything above or below this would be scaled to the appropriate values outside
    of the main interval while keeping the relative distance between the values in
    the middle of the distribution intact.
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, the median and the interquartile range are not influenced greatly
    by outliers, so this scaler is not influenced greatly by outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at all these scalars on a sample distribution. For this, we will
    take the `Price` column of the `Price` column and the distribution resulting from
    applying each scaling method we''ve discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Distribution scaled using multiple scaling methods ](img/B17928_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Distribution scaled using multiple scaling methods
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see, **StandardScaler** creates a distribution with a mean of 0 and
    a standard deviation of 1, **MinMaxScaler** scales the values between 0 and 1,
    and **RobustScaler** sets the mean to 0\. Looking at the box plots in *Figure
    6.8* and *Figure 6.9*, we can see the differences in their distributions. Please
    note the scale of the *y* axis as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Box plot for StandardScaler and RobustScaler ](img/B17928_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Box plot for StandardScaler and RobustScaler
  prefs: []
  type: TYPE_NORMAL
- en: 'Comparing the following box plot to *Figure 6.8*, we can see the difference
    in their distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Box plot for MinMaxScaler ](img/B17928_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Box plot for MinMaxScaler
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have some idea of how to scale a feature, let's talk about normalization.
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalization** is the process of taking a vector (row) of feature values
    and scaling them to a **unit magnitude**, typically to simplify mathematical processes
    such as **cosine similarity**.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by understanding a process where this normalization step can be
    of help. The cosine similarity describes how similar two different vectors are
    to each other. In an n-dimensional room, are they pointing in the same direction,
    are they perpendicular to each other, or are they facing in the opposite direction?
  prefs: []
  type: TYPE_NORMAL
- en: Such calculations can, for example, help us understand how similar text documents
    are to each other, by taking a vector of word counts or similar information and
    comparing them with each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, to understand document similarity, we must calculate a cosine between
    vectors using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, to make this calculation, we must calculate the magnitude of
    each vector – for example, ![](img/Formula_06_13.png). This magnitude is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_14.png)'
  prefs: []
  type: TYPE_IMG
- en: This single vector magnitude calculation is quite expensive to perform. Now,
    imagine that we have a dataset that contains hundreds of thousands of documents.
    We would have to calculate this every time for every combination of vectors (samples)
    in our dataset. Wouldn't it be easier to have all these vector magnitudes equal
    to 1? This would greatly simplify the calculation of the cosine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the idea is to normalize all the samples in our dataset to achieve
    a unit magnitude by scaling them appropriately, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_15.png)'
  prefs: []
  type: TYPE_IMG
- en: In this equation, ![](img/Formula_06_16.png) denotes our initial vector, ![](img/Formula_06_17.png)
    denotes the magnitude of the initial vector, and ![](img/Formula_06_18.png) denotes
    our scaled vector with the unit magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: 'This normalization is called **L2 Norm** and is one of three typical normalization
    methods. Let''s look at how the magnitude of a vector is calculated in this and
    all the other metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**L1 Norm**: This calculates the magnitude as the sum of the absolute values
    of the vector components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L2 Norm**: This calculates the traditional vector magnitude (as described).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max Norm**: This calculates the magnitude as the absolute value of the elements
    of the vector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The L1 Norm and the Max Norm cannot be used for cosine similarity as they do
    not calculate the mathematically defined vector magnitude. So, let's look at how
    those two are calculated.
  prefs: []
  type: TYPE_NORMAL
- en: 'The L1 Norm is mathematically defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_19.png)'
  prefs: []
  type: TYPE_IMG
- en: The L1 Norm is often used to regularize the values in the dataset when you're
    fitting an ML algorithm. It keeps the coefficient small, which makes the model
    training process less complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Max Norm is mathematically defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_06_20.png)'
  prefs: []
  type: TYPE_IMG
- en: The Max Norm is also used for regularization, typically in **neural networks**
    to keep the weights low at the connections between neurons. It also helps with
    performing less extreme backpropagation runs to stabilize the ML algorithm's learning.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have a good grasp of the usefulness of scaling and
    normalization. Next, we'll look at some methods we can use to transform categorical
    values into numerical representations.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical encoding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we looked at feature transformation as a concept, we looked at an example
    where we applied **one-hot encoding**. This method creates new features with two
    possible values (0,1) for *every* available category in the initial categorical
    feature. This can be helpful, but a categorical feature of high cardinality would
    blow up the feature space dramatically. Therefore, when using this method, we
    must figure out if every single category is predictive or not.
  prefs: []
  type: TYPE_NORMAL
- en: In our previous example, instead of using a category with the days of the week
    (Monday through Saturday), we opted for only three categories, namely weekday,
    weekend, and holiday. In such a scenario, one-hot encoding is quite helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Besides this method, there are other ways to encode categorical features. The
    most basic of them would be **label encoding**. In label encoding, we replace
    every category with a numeric label (0,..,*n*), thus making it a numeric feature.
    Through this, we did not add any additional information to this feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next idea would be to add some intrinsic information from the whole dataset
    and ingrain it into the values we must encode. Some options for this idea are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Count encoding**: Replace each category with the absolute number of observations
    of this category in the whole dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frequency encoding**: Replace each category with the relative number (the
    percentage) of observations of this category in the whole dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Target encoding**: Replace each category with the mean value of the target
    that''s been calculated from each entry of this category throughout the whole
    dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To understand these methods, let''s assume that we have a dataset that contains
    the favorite snack item of 25 people as one of the features and their likelihood
    of buying a new snack product a company produces as the target. The following
    table shows the original values and all three encodings we have discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Count, frequency, and target encoding example ](img/B17928_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Count, frequency, and target encoding example
  prefs: []
  type: TYPE_NORMAL
- en: With these methods, we can ingrain additional information into the feature,
    making it easier for an ML algorithm to understand relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's talk about `Rare`, thus grouping them into one category. This
    helps reduce the overall complexity and should especially be done if the `Rare`
    category will still be a small part of the overall category distribution. You
    can compare this to grouping small parties under the *Others* label in an election
    graph, while primarily showing the major parties.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have a good understanding of different encoding techniques.
    In the next section, we will discuss how we can try out these techniques on a
    real dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Testing feature engineering techniques on a tabular dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, we did some cleaning and statistical analysis on the **Melbourne
    Housing dataset**. After looking through a set of possible feature engineering
    methods in the previous section, you may have realized that we used some of these
    methods when we were working with our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: As an exercise, think about where we left off and, keeping the feature engineering
    options in mind, what we could do now to create new useful features, transform
    the given features, and eventually select the most prominent and predictive features
    in our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For inspiration, have a look at the `02_fe_melbhousing.ipynb` file in the GitHub
    repository for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the final section of this chapter, we will leave the feature space behind
    and concentrate on the target or label for our ML training – to be more precise,
    on the cases where we are missing the labels.
  prefs: []
  type: TYPE_NORMAL
- en: Handling data labeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will look at one of the most time-consuming and important
    tasks when it comes to preprocessing our dataset for ML training: **data labeling**.
    As we learned while looking at high-dimensional reduction and other ML techniques
    in [*Chapter 5*](B17928_05_ePub.xhtml#_idTextAnchor085), *Performing Data Analysis
    and Visualization*, for most scenarios, it is vitally important to have labels
    attached to our samples. As we discussed in [*Chapter 1*](B17928_01_ePub.xhtml#_idTextAnchor015),
    *Understanding the End-to-End Machine Learning Process*, there are only a few
    scenarios where unsupervised learning models are sufficient, such as a model that
    clusters emails as spam or not spam. In most cases, we want to use a supervised
    model, which means we will require labels.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will discuss what scenarios require us to do manual
    labeling and how Azure Machine Learning can help us be as efficient as possible
    to perform this monotonous task.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing scenarios that require labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by looking at the types of datasets we have discussed so far and
    in which scenarios we will need to perform manual labeling.
  prefs: []
  type: TYPE_NORMAL
- en: Numerical and categorical data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we saw when we worked with the **Melbourne Housing dataset**, for tabular
    datasets, we may often have a column that can be used as the label. In our case,
    it was the price column that we could use as a label since our goal for ML was
    to predict house prices based on specific feature inputs.
  prefs: []
  type: TYPE_NORMAL
- en: But even if this column was missing, we could have incorporated other datasets,
    such as one that shows the mean price for houses in different suburbs of Melbourne,
    to calculate a reasonable value for each of our dataset samples.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the main advantage over any of the other scenarios we will discuss
    next is that in a dataset made up of numerical and categorical features with clear
    meaning (not the pixel values of an image), we can use logic and mathematical
    functions to create a numerical label, or we can classify samples into a categorical
    label in an automated fashion. This means we do not have to look at every sample
    manually to define its label.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language processing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's start by looking at text data. You may think that a categorical entry
    would also be text in a sense, but typically, categorical data can also be exchanged
    with mathematical values without you losing much.
  prefs: []
  type: TYPE_NORMAL
- en: 'Text data, on the other hand, denote blocks of words, such as those in this
    book, so they are much more complicated. Look at the following two sentences or
    utterances:'
  prefs: []
  type: TYPE_NORMAL
- en: '*I would like to book a plane ticket for December 23rd, 2020 from Dubai to
    Paris.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The room wasn''t cleaned, and the heating wouldn''t work.*'
  prefs: []
  type: TYPE_NORMAL
- en: How would we label these utterances? Once again, this very much depends on our
    goal for training. Maybe we just want to put these utterances into groups, such
    as order, greeting, or statement. In that scenario, every utterance would receive
    one label. On the other hand, we may want to drill down into the meaning of the
    words in the sentence. For our first utterance, we may want to understand the
    meaning of the order to offer an answer by showing possible flight options. For
    the second utterance, we may want to understand the sentiment since it is a statement
    about the quality of a hotel room.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we need to start labeling single words or phrases in the utterance
    itself, while looking for the semantic meaning.
  prefs: []
  type: TYPE_NORMAL
- en: We will come back to this topic in [*Chapter 7*](B17928_07_ePub.xhtml#_idTextAnchor112),
    *Advanced Feature Extraction with NLP*.
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When we talk about ML modeling for images, we are typically trying to understand
    and learn about one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image classification**: Classify an image into one or more classes. Typical
    use cases include image searches, library management, and sentiment analysis of
    a person.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object detection**: Localize specific objects in an image. Typical use cases
    include pedestrian detection, traffic flow analysis, and object counting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image segmentation**: Assign each pixel of an image to a specific segment.
    Typical use cases include precise environment analysis for self-driving cars and
    pixel-precise anomaly detection in an X-ray or MRI picture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows an example of these three types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Different image processing methods ](img/B17928_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Different image processing methods
  prefs: []
  type: TYPE_NORMAL
- en: For these methods, the process of labeling them becomes more complicated, the
    further we go down the list. For classification, we can just put one or more labels
    on an image. For object detection, we start drawing so-called bounding boxes or
    polygons on the image. Finally, image segmentation becomes very complicated as
    we must assign labels for each pixel of the image. For this, highly specialized
    tooling is required.
  prefs: []
  type: TYPE_NORMAL
- en: As we will see shortly, we can use the data labeling tool from Azure Machine
    Learning Studio to do classification, object detection, and, to some degree, segmentation
    for image labeling tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Audio annotation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, let''s talk about annotating audio data. When it comes to ML modeling
    for audio data, the following scenarios are possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech-to-text**: Run real-time transcription, voice assistants, pronunciation
    assessments, and similar solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speech translation**: Translate speech to trigger actions in an application
    or device.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speaker recognition**: Verify and identify speakers by their voice characteristics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, annotating audio data means that we must take out snippets from
    an audio file and label these snippets accordingly. The following diagram shows
    a simple example of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Audio labeling process ](img/B17928_06_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Audio labeling process
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, this labeling task is also not very straightforward and
    requires specialized tooling.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen a lot of scenarios so far, where labeling is of utmost importance.
    Now, let's try to label some images ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Performing data labeling for image classification using the Azure Machine Learning
    labeling service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will be using the data labeling service in Azure Machine
    Learning Studio to label some assets. As we learned in [*Chapter 3*](B17928_03_ePub.xhtml#_idTextAnchor054),
    *Preparing the Azure Machine Learning Workspace*, navigate to the Azure Machine
    Learning Studio and click on **Data Labeling** at the lower end of the menu, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Azure Machine Learning Studio ](img/B17928_06_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – Azure Machine Learning Studio
  prefs: []
  type: TYPE_NORMAL
- en: 'On the following screen, click **Add Project**, which will take you to the
    following view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Creation wizard for a labeling project ](img/B17928_06_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – Creation wizard for a labeling project
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start the exercise, let''s look at what kind of labeling tasks we
    can perform with the service. As shown in the preceding screenshot, we can work
    with image and text data as our data source. Switching between the **Image** and
    **Text** options on-screen, we have the following choices:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Classification Multi-class**: Attach a single label to each image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image Classification Multi-label**: Attach multiple labels to each image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object Detection (Bounding Box)**: Draw one or multiple boxes around an object
    on an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instance Segmentation (Polygon)**: Draw complex polygons around an object
    on an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Classification Multi-class**: Attach a single label to a piece of text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Classification Multi-label**: Attach one or multiple labels to a piece
    of text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, there are a lot of helpful options when it comes to image data.
    We can even highlight and tag very specific pieces in an image by using a **bounding
    box** or a **polygon**. Using polygons, you are technically able to do a complete
    **image segmentation**, but it is quite hard to assign each pixel to a class with
    this tool.
  prefs: []
  type: TYPE_NORMAL
- en: For text data, however, there are some limitations. We do not have the option
    to label specific words or phrases in a piece of text, as we discussed in the
    previous section. At the time of writing, the only option is to single- or multi-label
    a text block.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we will be working with images. To not make using this tool for
    the first time too complex, we will start by attaching a single label to images
    in an image dataset. In the following steps, we will create an image dataset and
    a corresponding labeling project:'
  prefs: []
  type: TYPE_NORMAL
- en: Before going through the wizard, let's look for a suitable image dataset to
    use. We will be using the **STL-10 dataset** ([https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)).
    This dataset contains a huge amount of small 96x96 images that can be divided
    into 10 classes (**airplane**, **bird**, **car**, **cat**, **deer**, **dog**,
    **horse**, **monkey**, **ship**, and **truck**). These 10 classes will be our
    labels. As the original page only offers us the images in binary format, we need
    to find a different source. On **Kaggle**, you often find these types of datasets
    prepared in different formats.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to [https://www.kaggle.com/jessicali9530/stl10](https://www.kaggle.com/jessicali9530/stl10)
    and download `test_images`, which is a set of 8,000 files in `png` format. Normally,
    we would use the `unlabeled_images` set, but since there are 100,000 of them,
    we will leave them be for now.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you haven't done so already, download the files for this chapter to your
    device and create a new folder called `images` under the `chapter06` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Extract all 8,000 images to the `images` folder. After that, open the `03_reg_unlabeled_data.ipynb`
    file. In this file, you will find the code we have been using so far to connect
    to our workspace and datastore. Please replace `datastore_name` with the one you
    have been given in your ML workspace. The last code snippet of the first cell
    reads as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `upload_directory` method will, with one call, upload all the files from
    the `images` folder to the datastore location you defined in the target and will
    create a file dataset object called `file_ds`. Once the upload is complete, we
    can register our new dataset with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If you navigate to the **Datasets** tab in Azure Machine Learning Studio, you
    will see our newly registered dataset. Under the **Explore** tab, you will see
    a subset of the images, including image metadata and a preview of the images.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have registered our dataset, we can set up our labeling project.
    Go back to the wizard, as shown in *Figure 6.14*, enter `STL10_Labeling` as the
    project name, and choose **Image Classification Multi-class** as the type. Click
    **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the next screen, Microsoft will give you the option to hire a workforce from
    the **Azure Marketplace** to perform your labeling work. This can be a helpful
    tool, as you will soon learn how tedious this task can be. For now, we do not
    require additional help. Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we can choose the dataset to work on. Select our newly create dataset,
    named `STL10_unlabeled`, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will see an option called **Incremental Refresh**. This feature updates the
    project once a day if new images have been added to the underlying dataset. We
    are not planning on doing this here, so leave it as-is and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following screen asks us to define our labels. `airplane`, `bird`, `car`,
    `cat`, `deer`, `dog`, `horse`, `monkey`, `ship`, and `truck` as labels. Then,
    click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second to last screen allows us to enter **Labeling instructions**. These
    are useful if we are not working alone on the project or we have ordered a workforce
    to do the job. Here, we can give them instructions. For us, as we are working
    alone, this is unnecessary. So, click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we have the option to use **ML-assisted labeling**. If we do not activate
    this option, we would have to label all 8,000 images by ourselves without help.
    Please be aware that activating this option requires a GPU compute cluster that
    runs for a couple of minutes every time the assisting ML model is retrained. We
    will choose the **Use default** option, which will create an appropriate cluster
    for us. Click **Create project**. This will bring us back to the overview. When
    the cluster has been created, click on the project's name to get to the overview
    page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see a dashboard similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – The dashboard for the labeling project ](img/B17928_06_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – The dashboard for the labeling project
  prefs: []
  type: TYPE_NORMAL
- en: 'The dashboard is divided into the following views:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Progress**: This shows the number of assets being labeled. In our case, we
    are working with 8,000 images. It also shows the status for each asset (**Completed**,
    **Skipped**, **Needs review**, and **Incomplete**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label class distribution**: This view will show a bar chart of which label
    has been used and how many times to classify an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Labeler performance**: This view shows how many assets each labeler has processed.
    In our case, only our name will be shown there.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Task queue**: This view shows what tasks are in the pipeline. At the moment,
    we need to label 150 images manually before the next training phase or the next
    check occurs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML-assisted labeling experiment**: This view shows the running or already
    run training experiments for the assisting ML model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you switch the view to the **Data** tab, you will see some previews for images
    and you can review the already labeled images. This is helpful when you're working
    in a team, where a couple of people are working on labeling the images and some
    are reviewing their labeling efforts.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you look at the `DefLabelNC6`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the overview page of this cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Labeling cluster dashboard ](img/B17928_06_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – Labeling cluster dashboard
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the machines that are being used for the nodes sport 6 cores,
    56 GB of RAM, and a Tesla K80 GPU. Always check the pricing page ([https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/ml-server-ubuntu/))
    when you're creating any type of compute instance on Azure. As shown on that page,
    the node we are using is called **NC6** and costs around $3 per hour. The cluster
    node shows that the cluster is **Idle**, so there are no costs. Later, you can
    check the **Runs** tabs for the duration of the training runs to understand the
    pricing implications. At the moment, a good, educated guess would be that we will
    need 2 to 4 hours for the ML-assisted support in our labeling project.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, before we start labeling the images, let''s understand what ML-assisted
    labeling does. When you switch back to the dashboard of our labeling project,
    you will see three options under **Task queue**, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manual**: This denotes the assets we must handle without support at any given
    point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustered**: This denotes the assets where a clustering model was being used
    on the already labeled assets. When you work on these assets, they will be shown
    to you in groups of images that the model thinks belong to the same class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prelabeled**: This denotes the assets where a classification model was trained
    on the already labeled assets. In this case, it predicted labels for unlabeled
    assets. When you''re working on those images, you will be shown the suggested
    labels and have to check if the model was correct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s start labeling. When you click **Label data**, you will see the
    following view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Labeling task view ](img/B17928_06_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – Labeling task view
  prefs: []
  type: TYPE_NORMAL
- en: From this view, you can see the asset in the middle. With the controls up top,
    you can **Zoom in** and change the **Brightness** and **Contrast** properties
    of the image. If you are unsure about these options, you can select **Skip** for
    now. On the right, you can choose the appropriate label. If you are happy with
    your choice, you can click **Submit**.
  prefs: []
  type: TYPE_NORMAL
- en: Do this for a couple of images to get a grip on things. After that, look at
    the controls at the top right. Here, we can change how many assets are shown to
    us at the same time (1, 4, 6, or 9). I would suggest displaying 6 assets at the
    same time. In addition, to label pictures, you can multi-select them and use the
    keyboard numbers 1 to 9 (as shown on the right of the preceding screenshot) to
    label faster.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to see the ML-assisted labeling being triggered, you will need to manually
    label around 400 to 600 images. You can decide if this is a good use of your time,
    but it is a good exercise to do as it gives you a perspective of how tedious this
    task is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Eventually, the training will be triggered, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – Triggered training run for labeling ](img/B17928_06_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – Triggered training run for labeling
  prefs: []
  type: TYPE_NORMAL
- en: 'I had to label 616 assets manually before the first labeling training would
    be triggered. As we can see, the tool shows the distribution of label classes
    that were encountered during the labeling process at that point. As with any other
    training, this creates an experiment with runs. You can find these under `Experiments`
    in the ML workspace, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Experiment run for ML-assisted labeling ](img/B17928_06_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 – Experiment run for ML-assisted labeling
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, just continue to label assets. Eventually, you will either be
    shown clustered images, defined by **Tasks clustered** at the top of the page
    (see *Figure 6.20*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Data labeling showing clustered images ](img/B17928_06_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 – Data labeling showing clustered images
  prefs: []
  type: TYPE_NORMAL
- en: 'Or you''ll be shown prelabeled images, defined by **Tasks prelabeled** at the
    top of the page (see *Figure 6.21*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Data labeling showing prelabeled images ](img/B17928_06_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 – Data labeling showing prelabeled images
  prefs: []
  type: TYPE_NORMAL
- en: With that, you've seen how you can utilize ML modeling to label your assets
    and how Azure Machine Learning Studio makes this process easier. As you should
    understand by now, this is a time-consuming task, but it needs to be done if you
    wish to achieve much better results in your ML training down the line.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at how to prepare our features through feature engineering
    and how to prepare our labels through labeling.
  prefs: []
  type: TYPE_NORMAL
- en: In the first section, we learned that feature engineering includes creating
    new and missing features, transforming existing features, extracting features
    from a high-dimensional dataset, and using methods to select the most predictive
    feature for ML training.
  prefs: []
  type: TYPE_NORMAL
- en: In the second section, we learned that labeling is essential and tedious. Therefore,
    tooling such as Azure Machine Learning data labeling can be a blessing to alleviate
    this time-consuming task.
  prefs: []
  type: TYPE_NORMAL
- en: The key takeaway from this chapter is that creating, transforming, and selecting
    predictive features has the biggest impact on the quality of the ML model. No
    other step in the ML pipeline will have more influence on its outcome.
  prefs: []
  type: TYPE_NORMAL
- en: To pull off quality feature engineering, you must have intimate knowledge of
    the domain (or you must know someone with that knowledge) and a clear grasp of
    how the chosen ML algorithm works internally. This includes understanding the
    mathematical theory, the required data structure the algorithm expects as input,
    and the feature engineering methods that are applied automatically when you're
    fitting the model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see feature engineering in action. We will look
    at how to perform feature extraction on text data for natural language processing.
  prefs: []
  type: TYPE_NORMAL
