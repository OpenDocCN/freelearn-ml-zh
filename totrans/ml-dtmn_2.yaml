- en: Getting Started with Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we saw what machine learning predictive models are and
    formed a basic understanding of how they work. In this chapter, we will demonstrate
    the working of neural net models and move on to another type of model, the (**Support
    Vector Machines**)
  prefs: []
  type: TYPE_NORMAL
- en: '**SVMs **model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the topics that will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Demonstrating a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrating SVMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrating a neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's jump to a hands-on example of neural networks. The software that we are
    using is the SPSS Modeler, provided by IBM. But feel free to use any data-mining
    software package.
  prefs: []
  type: TYPE_NORMAL
- en: Running a neural network model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to run our first neural network, we will have to bring in the data
    that we will be using, if you are using IBM SPSS Modeler you can follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the data using the **Var. File** node, and bring it up to the canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/12e7de96-8016-4b88-a24e-812d2d542a76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Attach the dataset to the source node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9cd347ff-f70c-4e83-8a7c-cf342f6f015e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the triple dot box on the right side of file box and navigate to your
    data; we are using `Electronics_Data` here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2804182-e81c-4e77-953e-b35725d99f87.png)'
  prefs: []
  type: TYPE_IMG
- en: Click **Open**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go on to the **Types** tab to check whether the data was read correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/532eed80-0100-4e2d-828d-69070f850889.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **Read Values** button; click **OK** on the prompt that pops up
    next, and you will see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06c0e854-2a0a-4cac-956d-9ca895f8105f.png)'
  prefs: []
  type: TYPE_IMG
- en: It looks like the data was read correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will not use the first variable, **ID**,and hence we will set its measurement
    to **Typeless**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1259a997-e195-4b9c-bcc7-aa01ce0a7820.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now specify our **Status **target variable and set its **Role** to **Target**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/93571dba-6986-445a-a17b-ab899590c0a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Now Modeler knows that the **Status** is the variable that it will be predicting.
    It will use the other fields to predict the outcome variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the data that you have added; for this, go to the **Output**
    palette at the bottom of the canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2e132e68-e93f-4a22-9e30-838f426dba1f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Connect the source node, `Electronics_Data`, to the Output Table node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ee2ccc8-d43c-4ba1-86c7-7367e39c333c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the stream by clicking the **Run Selection** (pentagon icon) button, beside
    the Play icon, located above the canvas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will see the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2de35d3b-9714-43fa-8cb1-cbbbc24a9176.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, we have a table with **19 fields and 5,003 records**, and this means
    that we have 17 predictors in this dataset if we eliminate the target field and
    the ID field that we aren't using. We are going to predict the status field to
    check whether we have lost or retained a customer, based on the amount of items
    people have purchased, the total revenue, whether they have used discounts, the
    way in which they paid for the goods, the location, and other additional customer
    characteristics. Close this window to move ahead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on to building any model, make sure to split your dataset into
    a `Training` and `Testing` dataset just to replicate your results and to verify
    the consistency in the model that we are building. For doing this, go to the **Field
    Ops** panel and connect the source node to the **Partition** node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1b44e65f-adbb-4617-9d46-05e2625b7c23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This **Partition** node will create two versions of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e980a232-e2a4-4d3c-8d09-a5a3af7f6a49.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, `50` of the data will be training and the other `50` of the dataset will
    be testing the dataset, respectively. Click **OK**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now build our model. For this, go on to the **Modeling** panel and
    connect the **Partition** node to the **Neural Net** model by clicking once on
    both of them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4c61c34d-4b80-46aa-9f59-b4304214336f.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, you can see that **Status**, the variable to be predicted by the neural
    network, is already captured and a neural network will be built for it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Neural Net** stat node to see the details of the neural network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8345d326-bc52-4701-9c20-cce71b8e5c44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see that there is a target variable, and our 17 **Predictors** are
    specified by the neural network. The **Predictors** can be of any field type:
    continuous, categorical, or any other type. You can also decide to not include
    some of these **Predictors**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Build Options** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9dd99758-9922-4ff6-a7a5-9b10f138ef2f.png)'
  prefs: []
  type: TYPE_IMG
- en: These questions are to know what you want to do with the model, whether you
    want to build a new model or continue training an existing one. You can select
    any objective here; we will be creating a standard model for our example, and
    we will discuss other options in later chapters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can see the type of model that you wish to build by clicking on the **Basics**
    tab under **Build Options**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d627489c-744b-4582-b4cd-fb670069abdb.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we have two options, the **Multilayer Perceptron (MLP)** model,
    which we saw in this chapter earlier, and the **Radial Basis Function (RBF)**
    model. RBFs are preferred when you have things such as clustered predictors, but
    for our example the multilayer perceptron model is the best choice. The Hidden
    layers option allows you specify the number of Hidden layers you need in your
    model. Currently, we will select **Automatically compute number of units**. Hence,
    the model will automatically compute the number of hidden layers for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go on to the **Shopping Rules** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8a3b22c9-cb90-4a2b-8940-84aa0de8c770.png)'
  prefs: []
  type: TYPE_IMG
- en: Our model will run through many iterations and it will stop when it's no longer
    improving; however, it can stop for other reasons as well. For example, it can
    stop after a certain amount of time has passed and the default, as you can see
    in the screenshot, is set to `15` minutes, but you can change this. You could
    also have the model stop after it's gone through a certain number of iterations,
    or you could tell the model to stop once it's reached a certain level of accuracy.
    Hence, these are some other ways in which you can stop running the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Ensembles** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c2e04487-ea0e-4bde-9a01-e982a92c0050.png)'
  prefs: []
  type: TYPE_IMG
- en: This option enables us to build multiple versions of a model; let's keep this
    at the default values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go on to the **Advanced** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b3d0bf86-3b5a-48e5-8460-6fa00ba71686.png)'
  prefs: []
  type: TYPE_IMG
- en: We know that neural nets will eventually learn the patterns in the data if you
    let them run for long enough. This can be an undesirable feature because we don't
    want to capitalize on chance, therefore we want hold some data back, and we can
    set the value of data to hold for each iteration using this option—in this case,
    of the training dataset is `30.0` is held back from the training dataset in every
    iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the random seed, as we know, we will be running our model multiple
    times (the that we find the global solution and not get stuck on a sub-optimal
    solution), and we can generate the random seed. Each time you click on the Generate
    button, you will get a different random seed (or starting point).
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, neural nets do not run with missing values; they need complete data,
    and you can select what needs to be done with the missing values using the **Advanced**
    tab **Missing values in Predictors** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Delete listwise**: If there is missing information on any one of the variables,
    that whole case will be eliminated from the model.'
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impute missing values**: In this case, there are missing values, these will
    be replaced by the model defaults so you won''t have any control over what Modeler
    does with them. Hence, my suggestion is to replace the missing values even before
    you start building a model.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Go to the **Model Options** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f16fd42f-6aa3-44e7-963e-8765dec261c2.png)'
  prefs: []
  type: TYPE_IMG
- en: The model is automatically going to give you or calculate the predictor importance.
    It'll let you know which fields are the most important in the model. In terms
    of what the model is going to provide, it's going to provide a prediction, and
    it's also going to provide a confidence in that prediction score. Typically, you
    should see the probability of a predicted value; that's the most useful.
  prefs: []
  type: TYPE_NORMAL
- en: You can also ask instead to get the increase in probability from the category
    that was predicted from the next-most-likely outcome. You can get predicted probabilities
    for the categorical targets for all the different categories if you like, as well.
  prefs: []
  type: TYPE_NORMAL
- en: The propensity scores end up being extremely useful, and we'll discuss them
    later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Run** to run the model. Now the model has been built:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/262594be-f964-4948-b5b2-f75c0cd660cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's see what we have found.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To see the results, click on the **Status** generated model that was added automatically
    after the model was built.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following observations are required for the testing dataset. Let''s understand
    them in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see a **Model Summary**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a7d9e613-c434-4d7e-8848-055abe5eedbc.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see what our target is; we know that we ran a multilayer perceptron
    model and then it gives you the information as to why the model stopped, and you
    can see that it stopped because the error cannot be further decreased. Basically,
    this means that the model was not improving anymore and we have one hidden layer
    and that hidden layer has seven neurons. We can also see that on the training
    dataset the overall accuracy was about **79%**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the next tab on the right side, the **Predictor Importance** tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2bf865bc-81a4-4a3a-98dc-12824b0113e2.png)'
  prefs: []
  type: TYPE_IMG
- en: This gives you information on predictor importance. Hence, you can observe which
    predictors are the most important and contribute largely to the predictions. This
    is showing the most important predictors. In our case, the **Speakers** predictor tops
    the list. To see the importance of more predictors, you can just drag the scale
    down toward the left.
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification for Status **is our next observation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4edfc538-96d7-40ed-b6db-7a7ae5e0d034.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can see that how accurately we're predicting each one of the two groups
    in the training dataset; notice the overall percent correctly predicted. You can
    even switch to the cell-counts view form the **Style** tab at the bottom.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go down a little further and click on the next tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2562f170-3aa6-4a33-bd08-7d3ffebad538.png)'
  prefs: []
  type: TYPE_IMG
- en: This is showing us the actual neural net model. We are predicting the variable
    status; we had one hidden layer, and that hidden layer had seven neurons, and
    this is what we can see here. You can see the connections from each one of the
    predictors to the neurons in the hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also switch the **Style** from **Effects** to **Coefficients**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/111fa051-8e9e-41c8-a1a5-122de468bfc4.png)'
  prefs: []
  type: TYPE_IMG
- en: The thicker the line, the more important the predictor is in that equation,
    and you can even see the coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the final icon to get this information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6d271bc8-456c-4e81-be3b-c8bfef4ef586.png)'
  prefs: []
  type: TYPE_IMG
- en: This just gives us information in terms of which field was our target and which
    ones are our predictors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Close the window, and now we will see information about our training dataset.
    To do this, connect the model that we have to the **Table** icon:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ef1c7ba-b8b0-4988-a473-64aa73f4a78f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And you can run the Table node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64661ed0-dfa9-48fe-b6fc-4acfee1cee29.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, you will have the two new fields, **$N-Status**, the prediction field,
    and **$NC-Status**, the confidence in that prediction. Here, we have the data
    for the training as well as the testing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the accuracy of the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s analyze the accuracy of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to check the accuracy of the overall model, go to the **Output** palette
    and connect your model to the **Analysis** node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3a0be592-d179-4525-8f3e-fdb7548d2232.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **An****alysis** node and check the **Coincidence matrices (for
    symbolic targets)**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3e13b0a0-93f7-4443-adbb-473f407e7196.png)'
  prefs: []
  type: TYPE_IMG
- en: The **Coincidence matrices (for symbolic targets)** is checked to give us additional
    information in terms of the breakdown of how accurate the model was.
  prefs: []
  type: TYPE_NORMAL
- en: 'On clicking **Run**, you can see the overall accuracy in the training and testing
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7f5ae29c-afe6-4b87-82f6-7aa85d3f8adb.png)'
  prefs: []
  type: TYPE_IMG
- en: Remember we have seen the same accuracy result previously when we saw the model
    summary, around 79%. There is a slight drop in the accuracy of the testing dataset
    when compared to the training dataset, but it shouldn't matter much. The difference
    between the accuracy of both the datasets can be anywhere within 5% for the model
    to be reliable enough.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, our training and testing data is pretty similar, and this means that
    we have built a consistent and reliable model that we can trust!
  prefs: []
  type: TYPE_NORMAL
- en: If you look at the **Confidence Matrix for $N-Status** part of the analysis,
    you can see that in the training dataset, we correctly predicted **790** people
    that are **Churned** and **1,146** people that are current customers. In the testing
    dataset, we correctly predicted **745** people who are **Churned**, and **1,231**
    people who are current customers.
  prefs: []
  type: TYPE_NORMAL
- en: Model performance on testing partition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we will running a Neural Net model multiple times, it is a good idea
    to create a couple of tables that show what was found:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e87496ed-bddf-4a4b-bd8e-5ab6a9dc266a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also create a table of the top 10 predictors that are based on the
    seed that you used in the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9487f71f-b03c-4fb5-84b1-34d0b050193a.png)'
  prefs: []
  type: TYPE_IMG
- en: To evaluate the performance of your model, you can rerun the model in the same
    way as we have done until now multiple times and check the accuracy of the model
    each time you run it. You can even run it with a different seed and a different
    starting point. Therefore, the results obtained will be slightly different but
    fairly similar. As you know, we rerun the model multiple times to find the best
    possible solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check the consistency in the results, you can keep expanding your model
    performance table in this manner each time you rerun the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de529e94-4429-4fbb-8bf1-f6768178338f.png)'
  prefs: []
  type: TYPE_IMG
- en: Out of these models, you can choose the model that makes the most sense. For
    example, as you can see, the last entry with the seed of 5000 has the highest
    overall accuracy. It also has the highest number of accuracy in predicting churned
    customers. But it has the lowest accuracy in predicting the current customers.
    Hence, you can identify which solution is the most important for you and choose
    your best model accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The top 10 predictors for every rerun will also change with slight changes
    in the results. You can document the top 10 predictors each time you run the model
    and expand the top 10 predictors table that you created earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c712f3c3-6aa1-4248-a4b3-5585480e7b9f.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, many predictors continue to be the most important, such as the
    premier predictor, whereas there are some predictors that appear only once or
    twice—for example, the **Number employees** predictor. These kinds of tables with
    a list of top 10 predictors can also help you to select the model that you need.
    You can also use this information to create a new version of a model where you
    don't want to use the predictors that you used initially but want to use only
    the predictors that either appear as the most common predictors in terms of the
    top ten or any predictor that appeared in the top ten.
  prefs: []
  type: TYPE_NORMAL
- en: Because we are already reducing the number of predictors, this would not only
    simplify the understanding of the model but also, ultimately, would end up creating
    a simpler model than in some cases, and this can actually be more accurate because
    you're getting rid of the extra noise that some of those other predictors might
    bring in.
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Support Vector Machines **(**SVMs**) models were built to predict categorical
    and continuous outcomes and are especially good when you have many predictors.
    They were developed for difficult predicting situations where linear models were
    unable to separate the categories of the outcome field. They too work like black
    boxes, hiding their complex work in predicting results. Let''s get an insight
    into how SVMs work.'
  prefs: []
  type: TYPE_NORMAL
- en: Working with Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose, for example, there is a kind of data that cannot be separated using
    a single line as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e346474e-c64a-418f-90a0-1627031e37fe.png)'
  prefs: []
  type: TYPE_IMG
- en: Consider these shapes to be different types of data. As you can see, we won't
    be able to separate a cluster of data by just drawing a single line between them.
    But the same job of differentiating can be done easily if a complex curve, such
    as a circle, is drawn instead of a line, just as in the diagram.
  prefs: []
  type: TYPE_NORMAL
- en: The main task of an SVM is to transform original data from this complex space
    to another space where the function that separates the data points is much simpler.
    This task is known as the **kernel transformation**.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **kernel function** is a mathematical function that transforms the data.
    The reason why it''s called an **SVM** is that the vectors form the boundaries
    between different groups of data, as shown in this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff159c75-3537-4b39-946d-71e10bf54976.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, we have placed circles below and the squares above, and the boundaries
    are the vectors. These vector boundaries are separating the two groups. Vectors
    are the cases that act like boundaries between groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, at this point, we can have several solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e79c6d30-37ee-4360-8550-06d2ea8b8289.png)'
  prefs: []
  type: TYPE_IMG
- en: This shows that we no longer need a circle or complex curves to separate the
    groups of data.
  prefs: []
  type: TYPE_NORMAL
- en: But what is the best solution?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We ultimately need to find the best solution. The best solution will be the
    one that will maximize the separation between the groups while balancing the trade-off
    of potentially overfitting the function on new data. This new data includes a
    weight factor or a regularization factor that adds a penalty to the function to
    maximize the margin between the vectors while minimizing the error, as shown in
    the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b03c20aa-d4e3-4339-b14a-8c1cf6e0c782.png)'
  prefs: []
  type: TYPE_IMG
- en: Types of kernel functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In **SPSS Modeler**, there are four different types of kernel functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear**: A simple function that works well with few nonlinear relationships'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polynomial**: A more complex function that works well with some nonlinear
    relationships'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RBF (Radial Basis Function)**: Similar to an RNN neural network that works
    well with nonlinear relationships'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid**: Similar to a two-layer neural network that works well with nonlinear
    relationships'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrating SVMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will run an SVM model and see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, get your dataset just the way you did for neural networks, partition
    the dataset into a training and testing dataset, and create a scenario such as
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b74f1a49-9340-4bc8-ba4b-79a31b864424.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how to run SVMs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the **Modeling** palette and connect the partition node to **SVM**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/745cb57d-3b91-4c9d-be9d-b3d023c729b6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Go to the **Expert** tab and select the **Expert** option in **Mode**. Remember,
    whenever you run an **SVM** model, you must always run it in **Expert** mode because
    this is a model that requires constant changes on the default values based on
    the status of your model. The **Expert** mode will enable us to change the values
    easily when required:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/de507e6a-245e-4529-bdb2-e7ef597d2704.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s discuss these options in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: You can tick the **Append all probabilities** box when you have categorical
    outcomes. But, for now, let's keep it on default.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The stopping criteria can also be changed, though you don't need to modify it
    that often.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The regularization parameter is set to `10` by default, and you can select any
    values from `2` to `10`. The higher the value of the regularization parameter,
    the more overfitting is done on your model and it is more likely to get better
    results on the training dataset, but on the testing dataset, the results could
    drop off. Hence, let's change the regularization parameter value to `5`, because
    it is a middle value that will give us a consistent model that works well for
    both the training as well as the testing dataset. And if you get a consistent
    model at value `5`, you can increase this to `7`, to overfit the model just a
    little better, to get slightly better results. If you don't get consistent results
    at a value set to `5`, then we can reduce this to `3` or so to try to overfit
    less. Hence, we will need to modify the regularization parameter based on our
    results.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The regression precision parameter or epsilon is a pretty low value that is
    meant for errors. We want our errors to be lower than the value that is set in
    this field. This parameter only works when there is a continuous outcome field,
    which is not the case for our dataset.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There are four types of kernel transformations that we have seen; linear is
    the simplest one, and we will start off with it. We can first test the model with
    a linear transformation, and if it does well, we can increase the complexity by
    selecting any other kind of transformation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a summary of the values that we have selected for the **Expert** tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54e27845-827c-45e3-ac63-6777689f6adf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **Analyze** tab. Let''s see what this tab includes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can calculate the propensity scores for this model; we will talk about this
    in later chapters.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The predictor importance can also be calculated. Here, for SVMs, this is not
    checked by default. The reason being that SVMs take a fairly long time to build
    the model if you select this option to calculate the predictor importance. You
    will run this model multiple times and change a lot of the parameters in the meantime.
    And finally when you find your best solution, or your ideal model, you will rerun
    the model, and that will be the time when you can check the option of calculating
    predictor importance. This will save a lot of time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Click on **Run**. You will see a model built like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9af08443-8017-417e-937b-1caec8688866.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, connect the generated model to the table to see the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/baab8f4d-b79a-4ccb-a25a-ce30d5a4edfb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on **Table** and then click **Run**. If you scroll to the end, you will
    find predictions under **$S-Status** and **$SP-Status**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/59c06026-fa7e-455e-952b-e83ee8a79ebd.png)'
  prefs: []
  type: TYPE_IMG
- en: You can also see that we have got results for both the training and testing
    datasets, even though the model was built on the testing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You can now close the table's window, and click on the model, **Status**, to
    check the summary and model settings. Click on **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The model is currently like a black box. We don't know how we got the results
    and how it predicted the values. Let's find out.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just as we did with the neural nets model, we will check the accuracy of the
    model that we have built. For this, select **Status** and go to the **Output**
    palette and select **Analyze**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27dd6ef2-3b19-49c0-ae31-371b2982c0a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on **Analysis**, and as we have done before for the neural nets, click
    on **Coincidence matrices (for symbolic targets)** and click on **Run**; you will
    get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0872da9a-0377-41d2-a31c-244f0b091d70.png)'
  prefs: []
  type: TYPE_IMG
- en: Hence, we have a very consistent model, currently!
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, let''s document the results in a table such as this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/982a2560-30ea-40b4-9d6e-9a21303682b0.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, in addition to the table made for neural nets, we have a type
    of model that we have used and even the regularization parameter value with which
    this was obtained. We have got a very consistent model, using the kernel transformation
    type as linear and the regularization parameter value set to **5**. But this also
    means that we can try with a slightly better value of the regularization parameter
    and see whether we can get a better solution. Let's move on to finding a better
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Trying additional solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Go back to the **SVM** model, **Status**, and click on the **Expert** tab.
    You can change the regularization parameter to something higher, as the model
    was consistent at `5`; consider this an exercise. But, instead, we will change
    the **Kernel type** for our next run to the most complex **Sigmoid** type. It
    is not recommended to change the **Bias** value. But you can change **Gamma** for
    better results, and you can experiment on those values later. For now, we will
    keep them on default, and click on **Run**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3dc04c94-1591-4578-a094-ba78f1aff532.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **Analyze** tab, and then click on **Run**. Here is our result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49d9a7a6-c3f3-469a-9a1b-3f8f6d47bee5.png)'
  prefs: []
  type: TYPE_IMG
- en: The model is consistent, but as you can see, the accuracy percentage is significantly
    lower than what we found in our linear model. Hence, this model has not done a
    better job compared to what the linear model did. This means that the Sigmoid
    type didn't work well.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the conclusion that the best type of kernel transformation
    suited for our dataset is the most simple, linear transformation. Because the
    data is also not really that complex either. But, you must rerun the model multiple
    times to verify your results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my analysis from the models that I ran:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfa784d9-3657-49f2-bf82-b78310c8b1cd.png)'
  prefs: []
  type: TYPE_IMG
- en: You can now see which type of kernel transformation worked in which manner with
    each of the predictors. You can select predictors that are important to you and
    select that as the best model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to work with neural network models. Then we moved
    on to cover SVM models and demonstrated how SVM works. We have seen how to work
    with different types of kernel transformations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at machine learning models in more detail.
  prefs: []
  type: TYPE_NORMAL
