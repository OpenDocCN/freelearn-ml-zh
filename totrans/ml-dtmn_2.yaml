- en: Getting Started with Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始学习机器学习
- en: In the last chapter, we saw what machine learning predictive models are and
    formed a basic understanding of how they work. In this chapter, we will demonstrate
    the working of neural net models and move on to another type of model, the (**Support
    Vector Machines**)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了机器学习预测模型是什么，并对其工作原理形成了基本理解。在本章中，我们将展示神经网络模型的工作原理，并继续介绍另一种类型的模型，即（**支持向量机**）。
- en: '**SVMs **model.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**模型。'
- en: 'The following are the topics that will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Demonstrating a neural network
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示神经网络
- en: Support Vector Machines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Demonstrating SVMs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示支持向量机
- en: Demonstrating a neural network
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展示神经网络
- en: Let's jump to a hands-on example of neural networks. The software that we are
    using is the SPSS Modeler, provided by IBM. But feel free to use any data-mining
    software package.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个神经网络的实战例子来跳转。我们使用的软件是IBM提供的SPSS Modeler，但您也可以自由使用任何数据挖掘软件包。
- en: Running a neural network model
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行神经网络模型
- en: 'In order to run our first neural network, we will have to bring in the data
    that we will be using, if you are using IBM SPSS Modeler you can follow these
    steps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行我们的第一个神经网络，我们需要引入我们将要使用的数据，如果您使用IBM SPSS Modeler，可以按照以下步骤操作：
- en: 'Get the data using the **Var. File** node, and bring it up to the canvas:'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**变量文件**节点获取数据，并将其拖拽到画布上：
- en: '![](img/12e7de96-8016-4b88-a24e-812d2d542a76.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/12e7de96-8016-4b88-a24e-812d2d542a76.png)'
- en: 'Attach the dataset to the source node:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集附加到源节点：
- en: '![](img/9cd347ff-f70c-4e83-8a7c-cf342f6f015e.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9cd347ff-f70c-4e83-8a7c-cf342f6f015e.png)'
- en: 'Click on the triple dot box on the right side of file box and navigate to your
    data; we are using `Electronics_Data` here:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 点击文件框右侧的三点菜单，导航到您的数据；这里我们使用`Electronics_Data`：
- en: '![](img/d2804182-e81c-4e77-953e-b35725d99f87.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d2804182-e81c-4e77-953e-b35725d99f87.png)'
- en: Click **Open**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**打开**。
- en: 'Go on to the **Types** tab to check whether the data was read correctly:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到**类型**选项卡，检查数据是否正确读取：
- en: '![](img/532eed80-0100-4e2d-828d-69070f850889.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/532eed80-0100-4e2d-828d-69070f850889.png)'
- en: 'Click on the **Read Values** button; click **OK** on the prompt that pops up
    next, and you will see this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**读取值**按钮；在弹出的提示中点击**确定**，您将看到以下内容：
- en: '![](img/06c0e854-2a0a-4cac-956d-9ca895f8105f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/06c0e854-2a0a-4cac-956d-9ca895f8105f.png)'
- en: It looks like the data was read correctly.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来数据读取正确。
- en: 'We will not use the first variable, **ID**,and hence we will set its measurement
    to **Typeless**:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将不会使用第一个变量**ID**，因此我们将将其测量设置为**无类型**：
- en: '![](img/1259a997-e195-4b9c-bcc7-aa01ce0a7820.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1259a997-e195-4b9c-bcc7-aa01ce0a7820.png)'
- en: 'Let''s now specify our **Status **target variable and set its **Role** to **Target**:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们指定我们的**状态**目标变量，并将其**角色**设置为**目标**：
- en: '![](img/93571dba-6986-445a-a17b-ab899590c0a2.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/93571dba-6986-445a-a17b-ab899590c0a2.png)'
- en: Now Modeler knows that the **Status** is the variable that it will be predicting.
    It will use the other fields to predict the outcome variable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Modeler知道**状态**是它将要预测的变量。它将使用其他字段来预测结果变量。
- en: 'Take a look at the data that you have added; for this, go to the **Output**
    palette at the bottom of the canvas:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看您已添加的数据；为此，请转到画布底部的**输出**调色板：
- en: '![](img/2e132e68-e93f-4a22-9e30-838f426dba1f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2e132e68-e93f-4a22-9e30-838f426dba1f.png)'
- en: 'Connect the source node, `Electronics_Data`, to the Output Table node:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将源节点`Electronics_Data`连接到输出表节点：
- en: '![](img/0ee2ccc8-d43c-4ba1-86c7-7367e39c333c.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0ee2ccc8-d43c-4ba1-86c7-7367e39c333c.png)'
- en: 'Run the stream by clicking the **Run Selection** (pentagon icon) button, beside
    the Play icon, located above the canvas:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击画布上播放图标旁边的**运行选择**（五角星图标）按钮来运行流：
- en: 'You will see the following data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到以下数据：
- en: '![](img/2de35d3b-9714-43fa-8cb1-cbbbc24a9176.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2de35d3b-9714-43fa-8cb1-cbbbc24a9176.png)'
- en: Hence, we have a table with **19 fields and 5,003 records**, and this means
    that we have 17 predictors in this dataset if we eliminate the target field and
    the ID field that we aren't using. We are going to predict the status field to
    check whether we have lost or retained a customer, based on the amount of items
    people have purchased, the total revenue, whether they have used discounts, the
    way in which they paid for the goods, the location, and other additional customer
    characteristics. Close this window to move ahead.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on to building any model, make sure to split your dataset into
    a `Training` and `Testing` dataset just to replicate your results and to verify
    the consistency in the model that we are building. For doing this, go to the **Field
    Ops** panel and connect the source node to the **Partition** node:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1b44e65f-adbb-4617-9d46-05e2625b7c23.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: 'This **Partition** node will create two versions of the dataset:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e980a232-e2a4-4d3c-8d09-a5a3af7f6a49.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Hence, `50` of the data will be training and the other `50` of the dataset will
    be testing the dataset, respectively. Click **OK**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now build our model. For this, go on to the **Modeling** panel and
    connect the **Partition** node to the **Neural Net** model by clicking once on
    both of them:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4c61c34d-4b80-46aa-9f59-b4304214336f.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: Hence, you can see that **Status**, the variable to be predicted by the neural
    network, is already captured and a neural network will be built for it.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Neural Net** stat node to see the details of the neural network:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8345d326-bc52-4701-9c20-cce71b8e5c44.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: 'You can see that there is a target variable, and our 17 **Predictors** are
    specified by the neural network. The **Predictors** can be of any field type:
    continuous, categorical, or any other type. You can also decide to not include
    some of these **Predictors**.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Build Options** tab:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9dd99758-9922-4ff6-a7a5-9b10f138ef2f.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: These questions are to know what you want to do with the model, whether you
    want to build a new model or continue training an existing one. You can select
    any objective here; we will be creating a standard model for our example, and
    we will discuss other options in later chapters.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can see the type of model that you wish to build by clicking on the **Basics**
    tab under **Build Options**:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d627489c-744b-4582-b4cd-fb670069abdb.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: As you can see, we have two options, the **Multilayer Perceptron (MLP)** model,
    which we saw in this chapter earlier, and the **Radial Basis Function (RBF)**
    model. RBFs are preferred when you have things such as clustered predictors, but
    for our example the multilayer perceptron model is the best choice. The Hidden
    layers option allows you specify the number of Hidden layers you need in your
    model. Currently, we will select **Automatically compute number of units**. Hence,
    the model will automatically compute the number of hidden layers for us.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'Go on to the **Shopping Rules** tab:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8a3b22c9-cb90-4a2b-8940-84aa0de8c770.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: Our model will run through many iterations and it will stop when it's no longer
    improving; however, it can stop for other reasons as well. For example, it can
    stop after a certain amount of time has passed and the default, as you can see
    in the screenshot, is set to `15` minutes, but you can change this. You could
    also have the model stop after it's gone through a certain number of iterations,
    or you could tell the model to stop once it's reached a certain level of accuracy.
    Hence, these are some other ways in which you can stop running the model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Ensembles** tab:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c2e04487-ea0e-4bde-9a01-e982a92c0050.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: This option enables us to build multiple versions of a model; let's keep this
    at the default values.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'Go on to the **Advanced** tab:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b3d0bf86-3b5a-48e5-8460-6fa00ba71686.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: We know that neural nets will eventually learn the patterns in the data if you
    let them run for long enough. This can be an undesirable feature because we don't
    want to capitalize on chance, therefore we want hold some data back, and we can
    set the value of data to hold for each iteration using this option—in this case,
    of the training dataset is `30.0` is held back from the training dataset in every
    iteration.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the random seed, as we know, we will be running our model multiple
    times (the that we find the global solution and not get stuck on a sub-optimal
    solution), and we can generate the random seed. Each time you click on the Generate
    button, you will get a different random seed (or starting point).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, neural nets do not run with missing values; they need complete data,
    and you can select what needs to be done with the missing values using the **Advanced**
    tab **Missing values in Predictors** option:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '**Delete listwise**: If there is missing information on any one of the variables,
    that whole case will be eliminated from the model.'
  id: totrans-64
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Impute missing values**: In this case, there are missing values, these will
    be replaced by the model defaults so you won''t have any control over what Modeler
    does with them. Hence, my suggestion is to replace the missing values even before
    you start building a model.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Go to the **Model Options** tab:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f16fd42f-6aa3-44e7-963e-8765dec261c2.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: The model is automatically going to give you or calculate the predictor importance.
    It'll let you know which fields are the most important in the model. In terms
    of what the model is going to provide, it's going to provide a prediction, and
    it's also going to provide a confidence in that prediction score. Typically, you
    should see the probability of a predicted value; that's the most useful.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: You can also ask instead to get the increase in probability from the category
    that was predicted from the next-most-likely outcome. You can get predicted probabilities
    for the categorical targets for all the different categories if you like, as well.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: The propensity scores end up being extremely useful, and we'll discuss them
    later.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Run** to run the model. Now the model has been built:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/262594be-f964-4948-b5b2-f75c0cd660cd.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: Let's see what we have found.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting results
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To see the results, click on the **Status** generated model that was added automatically
    after the model was built.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'The following observations are required for the testing dataset. Let''s understand
    them in detail:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'You will see a **Model Summary**:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a7d9e613-c434-4d7e-8848-055abe5eedbc.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: You can see what our target is; we know that we ran a multilayer perceptron
    model and then it gives you the information as to why the model stopped, and you
    can see that it stopped because the error cannot be further decreased. Basically,
    this means that the model was not improving anymore and we have one hidden layer
    and that hidden layer has seven neurons. We can also see that on the training
    dataset the overall accuracy was about **79%**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the next tab on the right side, the **Predictor Importance** tab:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2bf865bc-81a4-4a3a-98dc-12824b0113e2.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
- en: This gives you information on predictor importance. Hence, you can observe which
    predictors are the most important and contribute largely to the predictions. This
    is showing the most important predictors. In our case, the **Speakers** predictor tops
    the list. To see the importance of more predictors, you can just drag the scale
    down toward the left.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification for Status **is our next observation:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4edfc538-96d7-40ed-b6db-7a7ae5e0d034.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: Here, we can see that how accurately we're predicting each one of the two groups
    in the training dataset; notice the overall percent correctly predicted. You can
    even switch to the cell-counts view form the **Style** tab at the bottom.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go down a little further and click on the next tab:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2562f170-3aa6-4a33-bd08-7d3ffebad538.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: This is showing us the actual neural net model. We are predicting the variable
    status; we had one hidden layer, and that hidden layer had seven neurons, and
    this is what we can see here. You can see the connections from each one of the
    predictors to the neurons in the hidden layer.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also switch the **Style** from **Effects** to **Coefficients**:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/111fa051-8e9e-41c8-a1a5-122de468bfc4.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: The thicker the line, the more important the predictor is in that equation,
    and you can even see the coefficients.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the final icon to get this information:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6d271bc8-456c-4e81-be3b-c8bfef4ef586.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: This just gives us information in terms of which field was our target and which
    ones are our predictors.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'Close the window, and now we will see information about our training dataset.
    To do this, connect the model that we have to the **Table** icon:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ef1c7ba-b8b0-4988-a473-64aa73f4a78f.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: 'And you can run the Table node:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64661ed0-dfa9-48fe-b6fc-4acfee1cee29.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Here, you will have the two new fields, **$N-Status**, the prediction field,
    and **$NC-Status**, the confidence in that prediction. Here, we have the data
    for the training as well as the testing dataset.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，您将有两个新的字段，**$N-Status**，预测字段，以及**$NC-Status**，对该预测的置信度。这里，我们有训练数据集以及测试数据集的数据。
- en: Analyzing the accuracy of the model
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析模型的准确性
- en: 'Let''s analyze the accuracy of the model:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析模型的准确性：
- en: 'In order to check the accuracy of the overall model, go to the **Output** palette
    and connect your model to the **Analysis** node:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查整体模型的准确性，请转到**输出**调色板并将您的模型连接到**分析**节点：
- en: '![](img/3a0be592-d179-4525-8f3e-fdb7548d2232.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3a0be592-d179-4525-8f3e-fdb7548d2232.png)'
- en: 'Click on the **An****alysis** node and check the **Coincidence matrices (for
    symbolic targets)**:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**分析**节点并检查**巧合矩阵（对于符号目标）**：
- en: '![](img/3e13b0a0-93f7-4443-adbb-473f407e7196.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3e13b0a0-93f7-4443-adbb-473f407e7196.png)'
- en: The **Coincidence matrices (for symbolic targets)** is checked to give us additional
    information in terms of the breakdown of how accurate the model was.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**巧合矩阵（对于符号目标）**被检查以提供关于模型准确性的分解的额外信息。'
- en: 'On clicking **Run**, you can see the overall accuracy in the training and testing
    dataset:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**运行**，您可以在训练和测试数据集中看到整体准确性：
- en: '![](img/7f5ae29c-afe6-4b87-82f6-7aa85d3f8adb.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7f5ae29c-afe6-4b87-82f6-7aa85d3f8adb.png)'
- en: Remember we have seen the same accuracy result previously when we saw the model
    summary, around 79%. There is a slight drop in the accuracy of the testing dataset
    when compared to the training dataset, but it shouldn't matter much. The difference
    between the accuracy of both the datasets can be anywhere within 5% for the model
    to be reliable enough.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们之前在查看模型摘要时看到了相同的准确性结果，大约是79%。与训练数据集相比，测试数据集的准确性略有下降，但这不应有很大影响。两个数据集之间的准确性差异可以在5%以内，这样模型就足够可靠了。
- en: Hence, our training and testing data is pretty similar, and this means that
    we have built a consistent and reliable model that we can trust!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的训练数据和测试数据非常相似，这意味着我们已经构建了一个一致且可靠的模型，我们可以信赖它！
- en: If you look at the **Confidence Matrix for $N-Status** part of the analysis,
    you can see that in the training dataset, we correctly predicted **790** people
    that are **Churned** and **1,146** people that are current customers. In the testing
    dataset, we correctly predicted **745** people who are **Churned**, and **1,231**
    people who are current customers.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看分析中的**$N-Status**置信矩阵部分，您可以看到在训练数据集中，我们正确预测了**790**个已**流失**的客户和**1,146**个当前客户。在测试数据集中，我们正确预测了**745**个已**流失**的客户和**1,231**个当前客户。
- en: Model performance on testing partition
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试数据集上的模型性能
- en: 'Since we will running a Neural Net model multiple times, it is a good idea
    to create a couple of tables that show what was found:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将多次运行神经网络模型，创建几个显示所发现内容的表格是个好主意：
- en: '![](img/e87496ed-bddf-4a4b-bd8e-5ab6a9dc266a.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e87496ed-bddf-4a4b-bd8e-5ab6a9dc266a.png)'
- en: 'You can also create a table of the top 10 predictors that are based on the
    seed that you used in the model:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以创建一个基于模型中使用的种子的前10个预测因子的表格：
- en: '![](img/9487f71f-b03c-4fb5-84b1-34d0b050193a.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9487f71f-b03c-4fb5-84b1-34d0b050193a.png)'
- en: To evaluate the performance of your model, you can rerun the model in the same
    way as we have done until now multiple times and check the accuracy of the model
    each time you run it. You can even run it with a different seed and a different
    starting point. Therefore, the results obtained will be slightly different but
    fairly similar. As you know, we rerun the model multiple times to find the best
    possible solution.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估您模型的性能，您可以像我们之前多次做的那样重新运行模型，并在每次运行时检查模型的准确性。您甚至可以用不同的种子和不同的起点来运行它。因此，获得的结果会有所不同，但相当相似。如您所知，我们多次重新运行模型以找到最佳解决方案。
- en: 'To check the consistency in the results, you can keep expanding your model
    performance table in this manner each time you rerun the model:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查结果的一致性，您可以在每次重新运行模型时以这种方式扩展您的模型性能表：
- en: '![](img/de529e94-4429-4fbb-8bf1-f6768178338f.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/de529e94-4429-4fbb-8bf1-f6768178338f.png)'
- en: Out of these models, you can choose the model that makes the most sense. For
    example, as you can see, the last entry with the seed of 5000 has the highest
    overall accuracy. It also has the highest number of accuracy in predicting churned
    customers. But it has the lowest accuracy in predicting the current customers.
    Hence, you can identify which solution is the most important for you and choose
    your best model accordingly.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些模型中，你可以选择最有意义的模型。例如，正如你所见，最后一个种子为5000的条目具有最高的整体准确率。它在预测流失客户方面也具有最高的准确率。但在预测当前客户方面准确率最低。因此，你可以确定对你最重要的解决方案，并据此选择最佳模型。
- en: 'The top 10 predictors for every rerun will also change with slight changes
    in the results. You can document the top 10 predictors each time you run the model
    and expand the top 10 predictors table that you created earlier:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 每次重新运行时，前10个预测因子也会随着结果的微小变化而变化。每次运行模型时，你可以记录前10个预测因子，并扩展你之前创建的前10个预测因子表：
- en: '![](img/c712f3c3-6aa1-4248-a4b3-5585480e7b9f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c712f3c3-6aa1-4248-a4b3-5585480e7b9f.png)'
- en: As you can see, many predictors continue to be the most important, such as the
    premier predictor, whereas there are some predictors that appear only once or
    twice—for example, the **Number employees** predictor. These kinds of tables with
    a list of top 10 predictors can also help you to select the model that you need.
    You can also use this information to create a new version of a model where you
    don't want to use the predictors that you used initially but want to use only
    the predictors that either appear as the most common predictors in terms of the
    top ten or any predictor that appeared in the top ten.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，许多预测因子继续是最重要的，例如首要预测因子，而有些预测因子只出现一次或两次——例如，**员工数量**预测因子。这类列出前10个预测因子的表格也可以帮助你选择所需的模型。你还可以利用这些信息创建一个新版本模型，其中你不想使用最初使用的预测因子，而只想使用那些作为前十个中最常见的预测因子或任何在前十个中出现的预测因子。
- en: Because we are already reducing the number of predictors, this would not only
    simplify the understanding of the model but also, ultimately, would end up creating
    a simpler model than in some cases, and this can actually be more accurate because
    you're getting rid of the extra noise that some of those other predictors might
    bring in.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在减少预测因子的数量，这不仅会简化对模型的了解，而且最终会创建一个比某些情况下更简单的模型，这实际上可能更准确，因为你正在去除那些其他预测因子可能带来的额外噪声。
- en: Support Vector Machines
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support Vector Machines **(**SVMs**) models were built to predict categorical
    and continuous outcomes and are especially good when you have many predictors.
    They were developed for difficult predicting situations where linear models were
    unable to separate the categories of the outcome field. They too work like black
    boxes, hiding their complex work in predicting results. Let''s get an insight
    into how SVMs work.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机（SVMs**）模型是为了预测分类和连续结果而构建的，当有多个预测因子时尤其出色。它们是为了解决线性模型无法分离结果字段类别等难以预测的情况而开发的。它们也像黑盒一样工作，隐藏了预测结果中的复杂工作。让我们深入了解SVM是如何工作的。'
- en: Working with Support Vector Machines
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与支持向量机（SVM）一起工作
- en: 'Suppose, for example, there is a kind of data that cannot be separated using
    a single line as shown in this diagram:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，例如，有一种数据无法使用如图所示的单一线条进行分离：
- en: '![](img/e346474e-c64a-418f-90a0-1627031e37fe.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e346474e-c64a-418f-90a0-1627031e37fe.png)'
- en: Consider these shapes to be different types of data. As you can see, we won't
    be able to separate a cluster of data by just drawing a single line between them.
    But the same job of differentiating can be done easily if a complex curve, such
    as a circle, is drawn instead of a line, just as in the diagram.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些形状视为不同类型的数据。正如你所见，我们无法仅通过在它们之间画一条线来分离数据簇。但如果用复杂的曲线，如圆形，而不是直线，就可以轻松完成区分的任务，就像图中所展示的那样。
- en: The main task of an SVM is to transform original data from this complex space
    to another space where the function that separates the data points is much simpler.
    This task is known as the **kernel transformation**.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）的主要任务是将原始数据从这种复杂空间转换到另一个空间，在这个空间中，分离数据点的函数要简单得多。这项任务被称为**核变换**。
- en: Kernel transformation
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核变换
- en: 'The **kernel function** is a mathematical function that transforms the data.
    The reason why it''s called an **SVM** is that the vectors form the boundaries
    between different groups of data, as shown in this diagram:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff159c75-3537-4b39-946d-71e10bf54976.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: Hence, we have placed circles below and the squares above, and the boundaries
    are the vectors. These vector boundaries are separating the two groups. Vectors
    are the cases that act like boundaries between groups.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, at this point, we can have several solutions:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e79c6d30-37ee-4360-8550-06d2ea8b8289.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: This shows that we no longer need a circle or complex curves to separate the
    groups of data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: But what is the best solution?
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We ultimately need to find the best solution. The best solution will be the
    one that will maximize the separation between the groups while balancing the trade-off
    of potentially overfitting the function on new data. This new data includes a
    weight factor or a regularization factor that adds a penalty to the function to
    maximize the margin between the vectors while minimizing the error, as shown in
    the following diagram:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b03c20aa-d4e3-4339-b14a-8c1cf6e0c782.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
- en: Types of kernel functions
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In **SPSS Modeler**, there are four different types of kernel functions:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear**: A simple function that works well with few nonlinear relationships'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Polynomial**: A more complex function that works well with some nonlinear
    relationships'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RBF (Radial Basis Function)**: Similar to an RNN neural network that works
    well with nonlinear relationships'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sigmoid**: Similar to a two-layer neural network that works well with nonlinear
    relationships'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrating SVMs
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will run an SVM model and see how it works.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, get your dataset just the way you did for neural networks, partition
    the dataset into a training and testing dataset, and create a scenario such as
    this:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b74f1a49-9340-4bc8-ba4b-79a31b864424.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how to run SVMs:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the **Modeling** palette and connect the partition node to **SVM**:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/745cb57d-3b91-4c9d-be9d-b3d023c729b6.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: 'Go to the **Expert** tab and select the **Expert** option in **Mode**. Remember,
    whenever you run an **SVM** model, you must always run it in **Expert** mode because
    this is a model that requires constant changes on the default values based on
    the status of your model. The **Expert** mode will enable us to change the values
    easily when required:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/de507e6a-245e-4529-bdb2-e7ef597d2704.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: 'Let''s discuss these options in detail:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: You can tick the **Append all probabilities** box when you have categorical
    outcomes. But, for now, let's keep it on default.
  id: totrans-158
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The stopping criteria can also be changed, though you don't need to modify it
    that often.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The regularization parameter is set to `10` by default, and you can select any
    values from `2` to `10`. The higher the value of the regularization parameter,
    the more overfitting is done on your model and it is more likely to get better
    results on the training dataset, but on the testing dataset, the results could
    drop off. Hence, let's change the regularization parameter value to `5`, because
    it is a middle value that will give us a consistent model that works well for
    both the training as well as the testing dataset. And if you get a consistent
    model at value `5`, you can increase this to `7`, to overfit the model just a
    little better, to get slightly better results. If you don't get consistent results
    at a value set to `5`, then we can reduce this to `3` or so to try to overfit
    less. Hence, we will need to modify the regularization parameter based on our
    results.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化参数默认设置为`10`，您可以选择从`2`到`10`的任何值。正则化参数的值越高，模型上的过拟合就越多，并且更有可能在训练数据集上获得更好的结果，但在测试数据集上，结果可能会下降。因此，让我们将正则化参数值更改为`5`，因为它是一个中间值，将为我们提供一个在训练和测试数据集上都表现良好的稳定模型。如果您在`5`的值上得到一个稳定的模型，您可以将其增加到`7`，以略微增加过拟合，以获得略微更好的结果。如果您在`5`的值上没有得到一致的结果，那么我们可以将其减少到`3`左右，以尝试减少过拟合。因此，我们将需要根据我们的结果修改正则化参数。
- en: The regression precision parameter or epsilon is a pretty low value that is
    meant for errors. We want our errors to be lower than the value that is set in
    this field. This parameter only works when there is a continuous outcome field,
    which is not the case for our dataset.
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归精度参数或epsilon是一个相当低的值，用于表示误差。我们希望我们的误差低于在此字段中设置的值。此参数仅在存在连续结果字段时才起作用，而我们的数据集并非如此。
- en: There are four types of kernel transformations that we have seen; linear is
    the simplest one, and we will start off with it. We can first test the model with
    a linear transformation, and if it does well, we can increase the complexity by
    selecting any other kind of transformation.
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经看到了四种类型的核变换；线性是最简单的一种，我们将从这里开始。我们可以首先用线性变换测试模型，如果表现良好，我们可以通过选择任何其他类型的变换来增加复杂性。
- en: 'Here is a summary of the values that we have selected for the **Expert** tab:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们在**专家**标签页中选择的值的摘要：
- en: '![](img/54e27845-827c-45e3-ac63-6777689f6adf.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/54e27845-827c-45e3-ac63-6777689f6adf.png)'
- en: 'Click on the **Analyze** tab. Let''s see what this tab includes:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**分析**标签页。让我们看看这个标签页包括什么：
- en: We can calculate the propensity scores for this model; we will talk about this
    in later chapters.
  id: totrans-166
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以计算此模型的倾向得分；我们将在后面的章节中讨论这一点。
- en: The predictor importance can also be calculated. Here, for SVMs, this is not
    checked by default. The reason being that SVMs take a fairly long time to build
    the model if you select this option to calculate the predictor importance. You
    will run this model multiple times and change a lot of the parameters in the meantime.
    And finally when you find your best solution, or your ideal model, you will rerun
    the model, and that will be the time when you can check the option of calculating
    predictor importance. This will save a lot of time.
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测变量重要性也可以计算。在这里，对于SVMs，默认情况下不检查这一点。原因在于，如果您选择此选项来计算预测变量重要性，SVMs构建模型会花费相当长的时间。您将多次运行此模型，并在其间更改许多参数。最后，当您找到最佳解决方案或理想模型时，您将重新运行模型，那时您就可以检查计算预测变量重要性的选项。这将节省大量时间。
- en: 'Click on **Run**. You will see a model built like this:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**运行**。您将看到一个构建如下模型：
- en: '![](img/9af08443-8017-417e-937b-1caec8688866.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9af08443-8017-417e-937b-1caec8688866.png)'
- en: 'Now, connect the generated model to the table to see the results:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将生成的模型连接到表格中查看结果：
- en: '![](img/baab8f4d-b79a-4ccb-a25a-ce30d5a4edfb.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/baab8f4d-b79a-4ccb-a25a-ce30d5a4edfb.png)'
- en: 'Click on **Table** and then click **Run**. If you scroll to the end, you will
    find predictions under **$S-Status** and **$SP-Status**:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**表格**，然后点击**运行**。如果您滚动到末尾，您将在**$S-状态**和**$SP-状态**下找到预测：
- en: '![](img/59c06026-fa7e-455e-952b-e83ee8a79ebd.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59c06026-fa7e-455e-952b-e83ee8a79ebd.png)'
- en: You can also see that we have got results for both the training and testing
    datasets, even though the model was built on the testing dataset.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以看到，尽管模型是基于测试数据集构建的，但我们已经得到了训练和测试数据集的结果。
- en: You can now close the table's window, and click on the model, **Status**, to
    check the summary and model settings. Click on **OK**.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在可以关闭表格窗口，并点击模型，**状态**，以检查摘要和模型设置。点击**确定**。
- en: The model is currently like a black box. We don't know how we got the results
    and how it predicted the values. Let's find out.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the results
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just as we did with the neural nets model, we will check the accuracy of the
    model that we have built. For this, select **Status** and go to the **Output**
    palette and select **Analyze**:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/27dd6ef2-3b19-49c0-ae31-371b2982c0a6.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: 'Click on **Analysis**, and as we have done before for the neural nets, click
    on **Coincidence matrices (for symbolic targets)** and click on **Run**; you will
    get this:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0872da9a-0377-41d2-a31c-244f0b091d70.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Hence, we have a very consistent model, currently!
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, let''s document the results in a table such as this one:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/982a2560-30ea-40b4-9d6e-9a21303682b0.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: As you can see, in addition to the table made for neural nets, we have a type
    of model that we have used and even the regularization parameter value with which
    this was obtained. We have got a very consistent model, using the kernel transformation
    type as linear and the regularization parameter value set to **5**. But this also
    means that we can try with a slightly better value of the regularization parameter
    and see whether we can get a better solution. Let's move on to finding a better
    solution.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Trying additional solutions
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Go back to the **SVM** model, **Status**, and click on the **Expert** tab.
    You can change the regularization parameter to something higher, as the model
    was consistent at `5`; consider this an exercise. But, instead, we will change
    the **Kernel type** for our next run to the most complex **Sigmoid** type. It
    is not recommended to change the **Bias** value. But you can change **Gamma** for
    better results, and you can experiment on those values later. For now, we will
    keep them on default, and click on **Run**:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3dc04c94-1591-4578-a094-ba78f1aff532.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
- en: 'Click on the **Analyze** tab, and then click on **Run**. Here is our result:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49d9a7a6-c3f3-469a-9a1b-3f8f6d47bee5.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
- en: The model is consistent, but as you can see, the accuracy percentage is significantly
    lower than what we found in our linear model. Hence, this model has not done a
    better job compared to what the linear model did. This means that the Sigmoid
    type didn't work well.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the conclusion that the best type of kernel transformation
    suited for our dataset is the most simple, linear transformation. Because the
    data is also not really that complex either. But, you must rerun the model multiple
    times to verify your results.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my analysis from the models that I ran:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfa784d9-3657-49f2-bf82-b78310c8b1cd.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: You can now see which type of kernel transformation worked in which manner with
    each of the predictors. You can select predictors that are important to you and
    select that as the best model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how to work with neural network models. Then we moved
    on to cover SVM models and demonstrated how SVM works. We have seen how to work
    with different types of kernel transformations.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用神经网络模型。然后我们继续介绍了SVM模型，并演示了SVM的工作原理。我们了解了如何处理不同类型的核变换。
- en: In the next chapter, we will look at machine learning models in more detail.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更详细地探讨机器学习模型。
