- en: '*Chapter 1*: Opportunities and Challenges'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Machine Learning** (**ML**) and data science are winning a popularity contest
    of sorts, as witnessed by their headline coverage in the popular and professional
    press and by expanding job openings across the technology landscape. Students
    typically learn ML techniques using their own computers on relatively small datasets.
    Those who enter the field often find themselves in the much different setting
    of a large company buzzing with workers performing specialized job roles, while
    collaborating with others scattered across the nation or world. Both data science
    students and data science workers have a few key things in common – they are in
    an exciting and growing field that businesses deem ever more critical to their
    future, and the data they thrive on is becoming exponentially more abundant and
    diverse.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: There are huge opportunities for ML in enterprises because the transformational
    impacts of ML on businesses, customers, patients, and so on are diverse, widespread,
    lucrative, and life-changing. A backdrop of urgency exists as well from competitors
    who are all attempting the same thing. Enterprises are thus incented to invest
    in significant ML transformations and to supply the necessary data, tooling, production
    systems, and people to journey toward ML success. But challenges loom large as
    well, and these challenges commonly revolve around scale. The challenges of scale
    take on many forms inherent to ML at an enterprise level.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will define and explore the challenge of ML at scale by
    covering the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ML at scale
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ML life cycle and three challenge areas for ML at scale
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O.ai's answer to these challenges
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML at scale
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book is about implementing ML at scale and how to use H2O.ai technology
    to succeed in doing so. What specifically do we mean by ML at scale? We can see
    three contexts and challenges of scale during the ML life cycle – building models
    from large datasets, deploying these models in enterprise production environments,
    and executing the full range of ML activities within the complexities of enterprise
    processes and stakeholders. This is summarized in the following figure:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – The challenges of ML at scale'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16721_01_01.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.1 – The challenges of ML at scale
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Let's drill down further on these challenges. Before doing so, we will oversee
    a generic conception of the ML life cycle, which will be useful as a reference
    throughout the book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The ML life cycle and three challenge areas for ML at scale
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ML life cycle is a process that data scientists and enterprise stakeholders
    follow to build ML models and put them into production environments, where they
    make predictions and achieve value. In this section, we will define a simplified
    ML life cycle and elaborate on two broad areas that present special challenges
    for ML at scale.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: A simplified ML life cycle
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will use the following ML life cycle representation. The goal is to achieve
    a simplified depiction that we can all recognize as central to ML while avoiding
    attempts at a canonical definition. Let''s use it as our working framework for
    discussion:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下机器学习生命周期表示。目标是实现一个简化的描述，我们都能认识到它是机器学习的核心，同时避免试图给出一个权威的定义。让我们将其作为讨论的工作框架：
- en: '![Figure 1.2 – A simplified ML life cycle'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2 – 简化的机器学习生命周期'
- en: '](img/B16721_01_02.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_01_02.jpg]'
- en: Figure 1.2 – A simplified ML life cycle
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 简化的机器学习生命周期
- en: The following is a brief articulation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简要的阐述。
- en: Model building
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建
- en: 'Model building is a highly iterative process with frequent and unpredictable
    feedback loops along the way toward building a predictive model that is worthy
    of deploying in a business context. The steps can be summarized as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建是一个高度迭代的流程，在构建一个值得在商业环境中部署的预测模型的过程中，会有频繁且不可预测的反馈循环。步骤可以总结如下：
- en: '**Data ingestion**: Data is pulled from sources or a storage layer in the model
    building environment. There is often significant work onward from here in finding
    and accessing potentially useful data sources and transforming the data into a
    useable form. Typically, this is done as part of a larger data pipeline and architecture.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取**：从数据源或模型构建环境中的存储层中提取数据。通常，在此之后会有大量工作，用于寻找和访问可能有用的数据源，并将数据转换为可用的形式。通常，这作为更大数据管道和架构的一部分来完成。'
- en: '**Data exploration**: Data is explored to understand its qualities (for example,
    data profiling, correlation analysis, outlier detection, and data visualization).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索**：探索数据以了解其特性（例如，数据概览、相关性分析、异常检测和数据可视化）。'
- en: '**Data manipulation**: Data is cleaned (for example, the imputation of missing
    data, the reduction of categorical features, and normalization) and new features
    are engineered.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据处理**：数据被清理（例如，缺失数据的插补、分类特征的降维和归一化）并生成新的特征。'
- en: '**Model training**: An ML algorithm, scoring metric, and validation method
    are selected, and the model is tuned across a range of hyperparameters and tested
    against a test dataset.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练**：选择一个机器学习算法、评分指标和验证方法，并在一系列超参数范围内调整模型，然后使用测试数据集对其进行测试。'
- en: '**Model evaluation and explainability**: A fit of the model is diagnosed for
    performance metrics, overfitting, and other diagnostics; model explainability
    is used to validate against domain knowledge, to explain the model decisions at
    individual and global levels, and to guard against institutional risks such as
    unfair bias against demographic groups.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估和可解释性**：对模型的拟合进行诊断，以评估性能指标、过拟合和其他诊断；使用模型可解释性来验证领域知识，解释模型在个体和全局层面的决策，并防范如对人口群体不公平偏见等机构风险。'
- en: '**Model deployment**: The model is deployed as a scoring artifact to a software
    system and live scoring is made.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：将模型作为评分工件部署到软件系统中，并进行实时评分。'
- en: '**Model monitoring**: The model is monitored to detect whether the data fed
    into it changes over time compared to the distribution of data it was trained
    on. This is called data drift and usually leads to the decreased predictive power
    of the model. This usually triggers the need to retrain the model with a more
    current dataset and then redeploy the updated model. The model may also be monitored
    for other patterns, such as whether it is biasing decisions against a particular
    demographic group and whether malicious attacks are being made to try to cause
    the model to malfunction.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：监控模型以检测输入数据随时间变化是否与训练数据分布不同。这被称为数据漂移，通常会导致模型预测能力的下降。这通常触发需要使用更当前的数据集重新训练模型，然后重新部署更新后的模型。模型也可能被监控以检测其他模式，例如是否对特定人口群体做出偏见决策，以及是否正在尝试通过恶意攻击导致模型故障。'
- en: As mentioned, a key property in the workflow is the unknown number and sequence
    of iteration pathways taken between these steps before a model is deployed or
    before the project is deemed unsuccessful in reaching that stage.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，工作流程中的一个关键属性是在模型部署之前或项目被认为未能达到该阶段之前，在这些步骤之间采取的未知数量和顺序的迭代路径。
- en: The model building challenge – state-of-the-art models at scale
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型构建挑战 – 规模化的最先进模型
- en: Let's, for now, define a large dataset as any dataset that exceeds your ability
    to build ML models on your laptop or local workstation. It may be too large because
    your libraries simply crash or because they take an unreasonable amount of time
    to complete. This may occur during model training or during data ingestion, exploration,
    and manipulation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义大数据集为任何超出您在笔记本电脑或本地工作站上构建机器学习模型能力的数据集。这可能是因为您的库直接崩溃，或者因为它们需要不合理的时间来完成。这种情况可能发生在模型训练期间，也可能发生在数据摄入、探索和操作期间。
- en: 'We can see four separate challenges of building ML models from large data volumes,
    with each contributing to a larger problem in general that we call the *friction
    of iteration*. This is represented in the following diagram:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到从大数据量构建机器学习模型时存在的四个单独的挑战，每个挑战都导致了一个更大的问题，我们称之为*迭代的摩擦*。这在上面的图中表示：
- en: '![Figure 1.3 – The challenge of model building with large data volumes'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.3 – 大数据量建模的挑战'
- en: '](img/B16721_01_03.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_01_03.jpg]'
- en: Figure 1.3 – The challenge of model building with large data volumes
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 大数据量建模的挑战
- en: Let's elaborate on this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细说明这一点。
- en: Challenge one – data size and location
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一大挑战 – 数据大小和位置
- en: 'Enterprises collect and store vast amounts of diverse data and that is a boon
    to the data scientist looking to build accurate models. These datasets are either
    stored across many systems or centralized in a common storage layer (data lake)
    such as the **Hadoop Distributed File System** (**HDFS**) or **AWS S3**. Architecting
    and making data available to internal consumers is a major effort and challenge
    for an enterprise. However, the data scientist starting the ML life cycle with
    large datasets typically cannot move that data, once it becomes accessible, to
    a local environment due to either security reasons or high volume of data.. The
    consequence is that the data scientist must either do one of the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 企业收集和存储了大量的多样化数据，这对希望构建准确模型的数据科学家来说是一大福音。这些数据集要么存储在许多系统中，要么集中在一个共同的存储层（数据湖）中，例如**Hadoop分布式文件系统**（**HDFS**）或**AWS
    S3**。为内部消费者架构和提供数据是一项重大的努力和挑战。然而，数据科学家在开始使用大数据集的机器学习生命周期时，由于安全原因或数据量过大，一旦数据变得可访问，通常无法将其移动到本地环境。结果是，数据科学家必须做以下之一：
- en: Move operations on the data (in other words, move the compute) to the data itself.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据操作（换句话说，将计算）移动到数据本身。
- en: Move data to a high-compute environment that they are authorized to use.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据移动到他们有权使用的计算密集型环境。
- en: Challenge two – data size and data manipulation
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二大挑战 – 数据大小和数据操作
- en: Manipulating data can be compute-intensive, and attempting to do so against
    insufficient resources either will cause the compute to fail (for example, the
    script, library, or tool will crash) or take an unreasonably long amount of time.
    Who wants to wait 10 hours to join and filter table data when it can be done in
    10 minutes? What you might consider an unreasonable amount of time is obviously
    relative to the dataset size; terabytes of data will always take longer to process
    than a few megabytes. Regardless, the speed of your data processing is critical
    to reducing the sum time of your iterations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 操作数据可能非常计算密集，如果尝试在资源不足的情况下进行，可能会导致计算失败（例如，脚本、库或工具会崩溃）或花费不合理的长时间。谁愿意等待10小时来连接和过滤表数据，而实际上可以在10分钟内完成？您可能认为不合理的时间显然与数据集大小有关；处理数以兆字节计的数据总是比处理几兆字节的数据需要更长的时间。无论如何，您数据处理的速度对于减少迭代总时间至关重要。
- en: Challenge three – data size and data exploration
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第三大挑战 – 数据大小和数据探索
- en: Challenges of data size during data exploration are identical to those during
    data manipulation. The data may be so large that your processing crashes or takes
    an unreasonable amount of time to complete while exploring models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索期间的数据大小挑战与数据操作期间的数据大小挑战相同。数据可能如此之大，以至于在探索模型时，您的处理会崩溃或花费不合理的时间来完成。
- en: Challenge four – data size and model training
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第四大挑战 – 数据大小和模型训练
- en: ML algorithms are extremely *compute-intensive* because they step through each
    record of a dataset and perform complex calculations each time, and then iterate
    these calculations against the dataset repeatedly to optimize toward a training
    metric and thus learn a predictive mathematical pattern among the noise. Our compute
    environment is particularly pressured during model training.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法极其**计算密集型**，因为它们会遍历数据集的每一条记录，并在每次遍历中进行复杂的计算，然后反复对这些计算进行迭代，以优化训练指标，从而在噪声中学习预测数学模式。我们的计算环境在模型训练期间尤其紧张。
- en: Up until now, we have been discussing dataset size in relative terms; that is,
    large data volumes are those that cause operations on them to either fail or take
    a long time to complete in a given compute environment.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们一直在相对意义上讨论数据集的大小；也就是说，大量数据量是那些在给定计算环境中导致操作失败或需要很长时间才能完成的数据量。
- en: In absolute terms, data scientists often explore the largest dataset possible
    to understand it and then **sample** it for model training. Others always try
    to use the largest dataset for model training. However, accurate models can be
    built from 10 GB or less of sampled or unsampled data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从绝对意义上讲，数据科学家通常会探索尽可能大的数据集来理解它，然后**抽样**用于模型训练。其他人总是试图使用最大的数据集进行模型训练。然而，从10 GB或更少的数据中，无论是抽样还是未抽样，都可以构建出准确模型。
- en: The key to proper use of sampling is that you have followed appropriate statistical
    and theoretical practices, and not that you are forced to do so because your ML
    processing will crash or take a long time to complete due to large data volumes.
    The latter is a bad practice that produces inferior models and H2O.ai overcomes
    this by allowing model building with massive data volumes.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正确使用抽样的关键是，你已经遵循了适当的统计和理论实践，而不是因为你被迫这样做，因为你的机器学习处理会因为大量数据而崩溃或需要很长时间才能完成。后者是一种不良实践，会产生劣质模型，而H2O.ai通过允许使用大量数据进行模型构建来克服这一点。
- en: 'There are also cases when data sampling may not lead to an acceptable model.
    In other words, the data scientist may need hundreds of gigabytes or a terabyte
    or more of data to build a valuable model. These are cases when the following
    applies:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 也有这样的情况，数据抽样可能不会导致一个可接受的模型。换句话说，数据科学家可能需要数百GB或更多数据来构建一个有价值的模型。在这些情况下，以下适用：
- en: The data scientist does not trust the sampling to produce the best model and
    feels that each small gain in lift warrants the use of the full dataset.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家不相信抽样能产生最佳模型，并认为每次提升的微小收益都值得使用完整的数据集。
- en: The data scientist does not want to segment the data into separate datasets
    and thus separate model building exercises, or the larger stakeholder group wants
    a single model in production that predicts against all segments versus many that
    each predicts against a single segment.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家不想将数据分割成单独的数据集，从而进行单独的模型构建练习，或者更大的利益相关者群体希望有一个单一的模型在生产中预测所有细分市场，而不是每个细分市场都预测一个单一的市场。
- en: The data is highly dimensional, sparse, or both. In this case, a large number
    of records are needed to reduce variance and overfitting to a training dataset.
    This type of dataset is typical for anomaly detection, recommendation engines,
    predictive maintenance, security threat detection, personalized medicine, and
    so on. It is worth noting that the future will bring us more and more data, and
    thus highly dimensional and sparse datasets will become more common.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据具有高度维度、稀疏性，或者两者兼而有之。在这种情况下，需要大量记录来减少训练数据集的方差和过拟合。这种类型的数据库在异常检测、推荐引擎、预测性维护、安全威胁检测、个性化医疗等领域很典型。值得注意的是，未来将带给我们越来越多的数据，因此高度维度和稀疏的数据库将变得更加普遍。
- en: The data is extremely imbalanced. The target variable is very rare in the dataset
    and a massive dataset is needed to avoid underfitting, overfitting, or weighting
    the target variable from these infrequent records.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据极度不平衡。目标变量在数据集中非常罕见，需要大量数据集来避免欠拟合、过拟合或从这些不频繁的记录中加权目标变量。
- en: The data is highly volatile. Each subset of data that is collected is unrepresentative
    of the others and thus sampling or cross-validation folds may not be representative.
    Time series forecasting may be particularly sensitive to this problem, especially
    when forecast categories are highly granular (for example, yearly, monthly, daily,
    and hourly) against a single validation dataset.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据非常波动。收集到的每个数据子集都不代表其他数据，因此采样或交叉验证折可能不具有代表性。时间序列预测可能特别容易受到这个问题的影响，尤其是在预测类别对单个验证数据集非常细粒度（例如，按年、月、日和小时）时。
- en: The friction of iteration
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迭代的摩擦
- en: Model building is a highly iterative process and anything that slows it down
    we call the friction of iteration. These causes can be due to the challenges of
    working with large data volumes, as previously discussed. They can also arise
    from simple workflow patterns such as switching among systems between each iteration
    or launching new environments to work on an iteration.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建是一个高度迭代的过程，任何减慢其速度的因素我们称之为迭代的摩擦。这些原因可能是由于之前讨论过的处理大量数据时的挑战。它们也可能源于简单的流程模式，例如在每次迭代之间在系统之间切换或在迭代上工作的新环境中启动。
- en: Any slowness during a single iteration may seem acceptable but when multiplied
    across the seemingly endless iterations from the project beginning to failure
    or success, the cost in time from this friction becomes significant, and reducing
    friction can be valuable. As we will see in the next section, slow model building
    delays the main goal of ML in an enterprise – achieving business value.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个迭代过程中出现的任何缓慢可能看起来是可以接受的，但当从项目开始到失败或成功看似无尽的迭代中乘以时，这种摩擦造成的时间成本变得显著，减少摩擦可能是有价值的。正如我们将在下一节中看到的，缓慢的模型构建延迟了企业在机器学习中的主要目标
    – 实现业务价值。
- en: The business challenge – getting your models into enterprise production systems
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业挑战 – 将你的模型引入企业生产系统
- en: 'The bare truth about ML initiatives is that they do not really achieve value
    until they are deployed to a live scoring environment. Models must meet evaluation
    criteria and be put into production to be deemed successful. Until that happens,
    from a business standpoint, little is achieved. This may seem a bit harsh, but
    it is typically how success is defined in data science initiatives. The following
    diagram maps this thinking onto the ML life cycle:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目的裸真相是，直到它们被部署到实际评分环境中，它们实际上并没有实现价值。模型必须满足评估标准并投入生产才能被认为是成功的。直到那时，从商业角度来看，所取得的成就很少。这听起来可能有些苛刻，但在数据科学项目中，成功通常就是这样定义的。以下图表将这种思考映射到机器学习生命周期：
- en: '![Figure 1.4 – The ML life cycle value chain'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – 机器学习生命周期价值链'
- en: '](img/B16721_01_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_01_04.jpg)'
- en: Figure 1.4 – The ML life cycle value chain
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 机器学习生命周期价值链
- en: The friction of iteration from this view is thus a cost. Time taken to iterate
    through model building is time taken from getting business results. In other words,
    lower friction translates to less time to build and deploy a model to achieve
    business value, and more time to work on other problems and thus more models per
    quarter or year.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，迭代的摩擦因此是一种成本。用于模型构建的迭代所需的时间是从获得业务结果中抽取的时间。换句话说，较低的摩擦意味着构建和部署模型以实现业务价值所需的时间更少，而有更多的时间来处理其他问题，从而在每季度或每年产生更多的模型。
- en: From the same point of view, **time to** **deploy a model** is viewed as a cost
    for similar reasons. The model deployment step may seem like a simple one-step
    sequence of transitioning the model to DevOps, but typically it is not. Anything
    that makes a model easier and more repeatable to deploy, document, and govern
    helps businesses achieve value sooner.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从同样的角度来看，**部署模型的时间**被视为一种成本，原因类似。模型部署步骤可能看起来像是一个简单的将模型过渡到DevOps的单步序列，但通常并非如此。任何使模型更容易部署、文档化和管理的因素都有助于企业更快地实现价值。
- en: Let's now continue expanding on a larger landscape of enterprise stakeholders
    that data scientists must work with to build models that ultimately achieve business
    value.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在继续扩大企业利益相关者的范围，数据科学家必须与他们合作，以构建最终实现业务价值的模型。
- en: The navigation challenge – navigating the enterprise stakeholder landscape
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导航挑战 – 导航企业利益相关者景观
- en: 'The data scientist in any enterprise does not work in isolation. There are
    multiple stakeholders who become involved directly in the ML life cycle or, more
    broadly, in the business cycle of initiating and consuming ML projects. Who might
    some of these stakeholders be? At a bare minimum, they include the business stakeholder
    who funded the ML project, the administrator providing the data scientist with
    permissions and capabilities, the DevOps or engineering team members who are responsible
    for model deployment and the infrastructure supporting it, perhaps marketing or
    sales associates whose functions are impacted directly by the model, and any other
    representatives of the internal or external consumers of the model. In more heavily
    regulated industries such as banking, insurance, or pharmaceuticals, these might
    include representatives or offices of various audit and risk functions – data
    risk, code risk, model risk, legal risk, reputational risk, compliance, external
    regulators, and so on. The following figure shows a general view:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 任何企业中的数据科学家都不是孤立工作的。有多个利益相关者直接参与机器学习生命周期，或者更广泛地说，参与启动和消费机器学习项目的商业周期。这些利益相关者可能包括谁？至少包括资助机器学习项目的商业利益相关者、向数据科学家提供权限和能力的管理员、负责模型部署及其基础设施的
    DevOps 或工程团队成员、其职能直接受模型影响的营销或销售合作伙伴，以及模型内部或外部消费者的任何其他代表。在银行、保险或制药等高度监管的行业中，这些可能包括各种审计和风险职能的代表或办公室——数据风险、代码风险、模型风险、法律风险、声誉风险、合规性、外部监管机构等。以下图表展示了一个一般视图：
- en: '![Figure 1.5 – Data scientists working with enterprise stakeholders and processes'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.5 – 数据科学家与企业利益相关者和流程合作'
- en: '](img/B16721_01_05.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_01_05.jpg)'
- en: Figure 1.5 – Data scientists working with enterprise stakeholders and processes
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 数据科学家与企业利益相关者和流程合作
- en: Stakeholder interaction is thus complex. What leads to this complexity? Obviously,
    the specialization and siloing of job functions make things complex, and this
    is further amplified by the scale of the enterprise. A larger dynamic of creating
    repeatable processes and minimizing risk contributes as well. Explaining this
    complexity is the task of a different book, but its reality in the enterprise
    is inescapable. To a data scientist, the ability to recognize, influence, negotiate
    with, deliver to, and ultimately build trust with these various stakeholders is
    imperative to successful ML solutions at scale.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 利益相关者之间的互动因此变得复杂。是什么导致了这种复杂性？显然，职业功能的专门化和隔离使得事情变得复杂，而企业的规模进一步放大了这一点。创建可重复的过程和最小化风险的更大动态也起到了作用。解释这种复杂性是另一本书的任务，但在企业中的现实是无法避免的。对于数据科学家来说，能够识别、影响、协商、交付并最终与这些不同的利益相关者建立信任，对于成功实施规模化的机器学习解决方案至关重要。
- en: Now that we have understood the ML life cycle and the challenges inherent in
    its successful execution at scale, it is time for a brief introduction to how
    H2O.ai solves these challenges.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了机器学习生命周期及其在规模化成功执行中固有的挑战，是时候简要介绍 H2O.ai 如何解决这些挑战了。
- en: H2O.ai's answer to these challenges
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: H2O.ai 对这些挑战的回应
- en: 'H2O.ai provides software to build ML models at scale and overcome the challenges
    of doing so – model building at scale, model deployment at scale, and dealing
    with enterprise stakeholders'' concerns and inherent friction along the way. These
    components are described in brief in the following diagram:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: H2O.ai 提供软件以规模化构建机器学习模型，并克服构建过程中的挑战——规模化模型构建、规模化模型部署，以及在整个过程中处理企业利益相关者的关注点和固有的摩擦。以下图表简要描述了这些组件：
- en: '![Figure 1.6 – H2O ML at scale'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6 – H2O ML 规模化'
- en: '](img/B16721_01_06.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_01_06.jpg)'
- en: Figure 1.6 – H2O ML at scale
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – H2O ML 规模化
- en: Subsequent chapters of this book elaborate on how these components are used
    to build and deploy state-of-the-art models within the complexities of the enterprise
    environment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本书后续章节详细阐述了如何使用这些组件在企业环境的复杂性中构建和部署最先进的模型。
- en: 'Let''s try to understand these components at first glance:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先尝试对这些组件进行初步了解：
- en: '**H2O Core**: This is open source software that distributes state-of-the-art
    ML algorithms and data manipulations over a specified number of servers on Kubernetes,
    Hadoop, or Spark environments. Data is partitioned in memory across the designated
    number of servers and ML algorithm computation is run in parallel using it.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O核心**：这是开源软件，在Kubernetes、Hadoop或Spark环境中指定数量的服务器上分发最先进的机器学习算法和数据操作。数据在指定的服务器数量之间在内存中分区，并使用它并行运行机器学习算法计算。'
- en: This architecture creates horizontal scalability of model building to hundreds
    of gigabytes or terabytes of data and generally fast processing times at lower
    data volumes. Data scientists work with familiar IDEs, languages, and algorithms
    and are abstracted away from the underlying architecture. Thus, for example, a
    data scientist can run an XGBoost model in Python from a Jupyter notebook against
    500 GB of data in Hadoop, similar to doing so with data loaded into their laptop.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构创建了模型构建的水平可扩展性，可以处理数百GB或TB的数据，并且在数据量较低时通常具有较快的处理时间。数据科学家使用熟悉的IDE、语言和算法，并且从底层架构中抽象出来。因此，例如，数据科学家可以从Jupyter笔记本中在Python中运行XGBoost模型，针对Hadoop中的500GB数据，类似于将数据加载到他们的笔记本电脑中。
- en: H2O Core is often referred to as **H2O Open Source** and comes in two forms,
    **H2O-3** and **Sparkling Water**, which we will elaborate on in subsequent chapters.
    H2O Core can be run as a scaled-down sandbox on a single server or laptop.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: H2O核心通常被称为**H2O开源**，有两种形式，**H2O-3**和**Sparkling Water**，我们将在后续章节中详细说明。H2O核心可以作为缩小的沙盒在单个服务器或笔记本电脑上运行。
- en: '**H2O Enterprise Steam**: This is a web UI or API for data scientists to self-provision
    and manage their individual H2O Core environments. Self-provisioning includes
    auto-calculation of horizontal scaling based on user inputs that describe the
    data. Enterprise Steam is also used by administrators to manage users, including
    defining boundaries for their resource consumption, and to configure H2O Core
    integration against Hadoop, Spark, or Kubernetes.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O企业版蒸汽**：这是一个数据科学家可以自助配置和管理他们各自的H2O核心环境的Web UI或API。自助配置包括根据用户描述数据的输入自动计算水平扩展。企业版蒸汽也被管理员用来管理用户，包括定义他们资源消耗的边界，以及配置H2O核心与Hadoop、Spark或Kubernetes的集成。'
- en: '**H2O MOJO**: This is an easy-to-deploy scoring artifact exportable from models
    built from H2O Core. MOJOs are low latency (typically < 100 ms or faster) Java
    binaries that can run on any **Java Virtual Machine (JVM)** and thus serve predictions
    on diverse software systems, such as REST servers, database clients, Amazon SageMaker,
    Kafka queues, Spark pipelines, Hive **user-defined functions (UDFs)**, and **Internet
    of Things (IoT)** devices.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O魔豆**：这是一个易于部署的评分工件，可以从H2O核心构建的模型中导出。MOJOs是低延迟（通常小于100毫秒或更快）的Java二进制文件，可以在任何**Java虚拟机（JVM）**上运行，因此可以在各种软件系统上提供预测，例如REST服务器、数据库客户端、Amazon
    SageMaker、Kafka队列、Spark管道、Hive **用户定义函数（UDFs）**和**物联网（IoT）**设备。'
- en: '**APIs**: Each component has a rich set of APIs so that you can automate workflows,
    including **continuous integration and continuous delivery (CI/CD)** and retraining
    pipelines.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**APIs**：每个组件都有一套丰富的API，这样您就可以自动化工作流程，包括**持续集成和持续部署（CI/CD）**和重新训练管道。'
- en: The focus of this book is on building and deploying state-of-the-art models
    at scale using H2O Core with help from Enterprise Steam and deploying those models
    as MOJOs within the complexities of enterprise environments.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本书重点介绍使用H2O核心在帮助企业环境中部署最先进的模型，并使用企业版蒸汽帮助构建这些模型，将这些模型作为MOJOs部署。
- en: H2O at Scale and H2O AI Cloud
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: H2O大规模和H2O AI云
- en: We refer to **H2O at scale** in this book as H2O Enterprise Steam, H2O Core,
    and H2O Mojo because it addresses the ML at scale challenges described earlier
    in this chapter, especially through the distributed ML scalability that H2O Core
    provides for model building.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将**大规模的H2O**称为H2O企业版蒸汽、H2O核心和H2O魔豆，因为它解决了本章前面描述的大规模机器学习挑战，特别是通过H2O核心为模型构建提供的分布式机器学习可扩展性。
- en: Note that H2O.ai offers a larger end-to-end ML platform called the **H2O AI
    Cloud**. The H2O AI Cloud integrates a hyper-advanced AutoML tool (called **H2O
    Driverless AI**) and other model building engines, an MLOps scoring, monitoring,
    and governance environment (called **H2O MLOps**), and a low-code software development
    kit, or SDK (called **H2O Wave**) with H2O API hooks to build AI applications
    that publish to the **App Store**. It also integrates H2O at scale as defined
    in this book.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，H2O.ai提供了一个更大的端到端ML平台，称为**H2O AI Cloud**。H2O AI Cloud集成了超先进的AutoML工具（称为**H2O
    Driverless AI**）和其他模型构建引擎，一个MLOps评分、监控和治理环境（称为**H2O MLOps**），以及一个低代码软件开发工具包（SDK），称为**H2O
    Wave**，它具有H2O API钩子，用于构建发布到**App Store**的AI应用程序。它还集成了本书中定义的H2O大规模。
- en: H2O at scale can be deployed as standalone or as part of the H2O AI Cloud. As
    a standalone implementation, Enterprise Steam is not in fact required, but for
    reasons elaborated on later in this book, Enterprise Steam is deemed essential
    for enterprise implementations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: H2O大规模可以部署为独立系统或作为H2O AI Cloud的一部分。作为一个独立实现，企业蒸汽实际上不是必需的，但正如本书后面详细阐述的原因，企业蒸汽被认为对企业实施是必不可少的。
- en: The majority of this book is focused on H2O at scale. The last part of the book
    will extend our understanding to the H2O AI Cloud and how H2O at scale components
    can leverage this larger integrated platform and vice versa.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的大部分内容都集中在H2O大规模上。本书的最后部分将扩展我们的理解，以涵盖H2O AI Cloud以及H2O大规模组件如何利用这个更大的集成平台，反之亦然。
- en: Summary
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have set the stage for understanding and implementing ML
    at scale using H2O.ai technology. We have defined multiple forms of scale in an
    enterprise setting and articulated the challenges to ML from model building, model
    deployment, and enterprise stakeholder perspectives. We have anchored these challenges
    ultimately to the end goal of ML – providing business value. Finally, we briefly
    introduced H2O at scale components used by enterprises to overcome these challenges
    and achieve business value.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为使用H2O.ai技术理解和实施大规模机器学习（ML）奠定了基础。我们定义了企业环境中多种形式的规模，并从模型构建、模型部署和企业利益相关者的角度阐述了ML面临的挑战。我们最终将这些挑战锚定到ML的最终目标——提供商业价值。最后，我们简要介绍了企业用于克服这些挑战并实现商业价值的H2O大规模组件。
- en: In the next chapter, we'll start to understand these components in greater technical
    detail so that we can start writing code and doing data science.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地了解这些组件的技术细节，以便我们可以开始编写代码和进行数据科学。
