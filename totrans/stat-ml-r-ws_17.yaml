- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Bayesian Statistics
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è´å¶æ–¯ç»Ÿè®¡å­¦
- en: In this chapter, we will introduce the Bayesian inference framework, covering
    its core components and implementation details. Bayesian inference introduces
    a useful framework that provides an educated guess on the predictions of the target
    outcome as well as quantified uncertainty estimates. Starting from a prior distribution
    that embeds domain expertise, the Bayesian inference approach allows us to continuously
    learn updated information from the data and update the posterior distribution
    to form a more realistic view of the underlying parameters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»è´å¶æ–¯æ¨æ–­æ¡†æ¶ï¼Œæ¶µç›–å…¶æ ¸å¿ƒç»„ä»¶å’Œå®ç°ç»†èŠ‚ã€‚è´å¶æ–¯æ¨æ–­å¼•å…¥äº†ä¸€ä¸ªæœ‰ç”¨çš„æ¡†æ¶ï¼Œå®ƒæä¾›äº†å¯¹ç›®æ ‡ç»“æœé¢„æµ‹çš„åˆç†çŒœæµ‹ä»¥åŠé‡åŒ–çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚ä»åŒ…å«é¢†åŸŸä¸“ä¸šçŸ¥è¯†çš„å…ˆéªŒåˆ†å¸ƒå¼€å§‹ï¼Œè´å¶æ–¯æ¨æ–­æ–¹æ³•å…è®¸æˆ‘ä»¬ä»æ•°æ®ä¸­æŒç»­å­¦ä¹ æ›´æ–°ä¿¡æ¯ï¼Œå¹¶æ›´æ–°åéªŒåˆ†å¸ƒï¼Œä»¥å½¢æˆå¯¹æ½œåœ¨å‚æ•°çš„æ›´ç°å®çš„è§‚ç‚¹ã€‚
- en: By the end of this chapter, you will have grasped essential skills when working
    with the Bayesian inference framework. You will learn the core theory behind Bayesâ€™
    theorem and its use in the Bayesian linear regression model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ç»“æŸæ—¶ï¼Œä½ å°†æŒæ¡ä½¿ç”¨è´å¶æ–¯æ¨æ–­æ¡†æ¶çš„åŸºæœ¬æŠ€èƒ½ã€‚ä½ å°†å­¦ä¹ è´å¶æ–¯å®šç†çš„æ ¸å¿ƒç†è®ºå’Œå®ƒåœ¨è´å¶æ–¯çº¿æ€§å›å½’æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« æˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»è¦å†…å®¹ï¼š
- en: Introducing Bayesian statistics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»‹ç»è´å¶æ–¯ç»Ÿè®¡å­¦
- en: Diving deeper into Bayesian inference
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·±å…¥äº†è§£è´å¶æ–¯æ¨æ–­
- en: The full Bayesian inference procedure
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„è´å¶æ–¯æ¨æ–­è¿‡ç¨‹
- en: Bayesian linear regression with a categorical variable
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸¦æœ‰åˆ†ç±»å˜é‡çš„è´å¶æ–¯çº¿æ€§å›å½’
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æŠ€æœ¯è¦æ±‚
- en: 'To run the code in this chapter, you will need to have the latest versions
    of the following packages:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¿è¡Œæœ¬ç« ä¸­çš„ä»£ç ï¼Œä½ éœ€è¦æ‹¥æœ‰ä»¥ä¸‹è½¯ä»¶åŒ…çš„æœ€æ–°ç‰ˆæœ¬ï¼š
- en: '`ggplot2`, 3.4.0'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ggplot2`, 3.4.0'
- en: '`ggridges`, 0.5.4'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ggridges`, 0.5.4'
- en: '`rjags`, 4.13'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rjags`, 4.13'
- en: '`coda`, 0.19.4'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coda`, 0.19.4'
- en: Please note that the versions mentioned along with the packages in the preceding
    list are the latest ones while I am writing this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå‰é¢æåˆ°çš„è½¯ä»¶åŒ…ç‰ˆæœ¬æ˜¯åœ¨æˆ‘æ’°å†™æœ¬ç« æ—¶çš„æœ€æ–°ç‰ˆæœ¬ã€‚
- en: All the code and data for this chapter is available at [https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_14/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_14/working.R).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« çš„æ‰€æœ‰ä»£ç å’Œæ•°æ®å‡å¯åœ¨[https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_14/working.R](https://github.com/PacktPublishing/The-Statistics-and-Machine-Learning-with-R-Workshop/blob/main/Chapter_14/working.R)æ‰¾åˆ°ã€‚
- en: Introducing Bayesian statistics
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»è´å¶æ–¯ç»Ÿè®¡å­¦
- en: The Bayesian approach to statistics and **machine learning** (**ML**) provides
    a logical, transparent, and interpretable framework. This is a uniform framework
    that can build problem-specific models for both statistical inference and prediction.
    In particular, Bayesian inference offers a method to figure out unknown or unobservable
    quantities given known facts (observed data), employing probability to describe
    the uncertainty over the possible values of unknown quantitiesâ€”namely, random
    variables of interest.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯æ–¹æ³•åœ¨ç»Ÿè®¡å­¦å’Œ**æœºå™¨å­¦ä¹ **ï¼ˆ**ML**ï¼‰ä¸­æä¾›äº†ä¸€ä¸ªé€»è¾‘æ¸…æ™°ã€é€æ˜ä¸”å¯è§£é‡Šçš„æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå¯ä»¥ä¸ºç»Ÿè®¡æ¨æ–­å’Œé¢„æµ‹æ„å»ºç‰¹å®šé—®é¢˜çš„æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œè´å¶æ–¯æ¨æ–­æä¾›äº†ä¸€ç§æ–¹æ³•ï¼Œåœ¨å·²çŸ¥äº‹å®ï¼ˆè§‚å¯Ÿæ•°æ®ï¼‰çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ¦‚ç‡æè¿°æœªçŸ¥é‡çš„å¯èƒ½å€¼çš„ä¸ç¡®å®šæ€§â€”â€”å³æ„Ÿå…´è¶£çš„éšæœºå˜é‡ã€‚
- en: Using Bayesian statistics, we are able to express our prior assumption about
    unknown quantities and adjust this based on the observed data. It provides the
    Bayesian versions of common statistical procedures such as hypothesis testing
    and linear regression, covered in *Chapters 11*, *Statistics estimation*, and
    *12*, *Linear Regression in R*. Compared to the frequentist approach, which we
    have adopted in all the models covered so far, the Bayesian approach additionally
    allows us to construct problem-specific models that can make the best use of the
    data in a continuous learning fashion (via the Bayesian posterior update, to be
    covered in the following section).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è´å¶æ–¯ç»Ÿè®¡å­¦ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè¡¨è¾¾æˆ‘ä»¬å¯¹æœªçŸ¥é‡çš„å…ˆéªŒå‡è®¾ï¼Œå¹¶æ ¹æ®è§‚å¯Ÿæ•°æ®è°ƒæ•´è¿™ä¸€å‡è®¾ã€‚å®ƒæä¾›äº†å¸¸è§çš„ç»Ÿè®¡ç¨‹åºï¼ˆå¦‚å‡è®¾æ£€éªŒå’Œçº¿æ€§å›å½’ï¼‰çš„è´å¶æ–¯ç‰ˆæœ¬ï¼Œè¿™äº›å†…å®¹åœ¨*ç¬¬11ç« *ï¼Œ*ç»Ÿè®¡ä¼°è®¡*å’Œ*ç¬¬12ç« *ï¼Œ*Rä¸­çš„çº¿æ€§å›å½’*ä¸­æœ‰æ‰€æ¶‰åŠã€‚ä¸è¿„ä»Šä¸ºæ­¢æˆ‘ä»¬é‡‡ç”¨çš„é¢‘ç‡ä¸»ä¹‰æ–¹æ³•ç›¸æ¯”ï¼Œè´å¶æ–¯æ–¹æ³•è¿˜å…è®¸æˆ‘ä»¬æ„å»ºç‰¹å®šé—®é¢˜çš„æ¨¡å‹ï¼Œä»¥è¿ç»­å­¦ä¹ çš„æ–¹å¼ï¼ˆé€šè¿‡è´å¶æ–¯åéªŒæ›´æ–°ï¼Œå°†åœ¨ä¸‹ä¸€èŠ‚ä¸­ä»‹ç»ï¼‰å……åˆ†åˆ©ç”¨æ•°æ®ã€‚
- en: For example, the unknown quantities correspond to the parameters we are trying
    to estimate in a linear or logistic regression model. Instead of treating them
    as fixed quantities and using the principle of maximum likelihood to estimate
    their values, the Bayesian approach treats them as moving variables with their
    respective probability distribution of possible values.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼ŒæœªçŸ¥é‡å¯¹åº”äºæˆ‘ä»¬åœ¨çº¿æ€§æˆ–é€»è¾‘å›å½’æ¨¡å‹ä¸­è¯•å›¾ä¼°è®¡çš„å‚æ•°ã€‚æˆ‘ä»¬ä¸æ˜¯å°†å®ƒä»¬è§†ä¸ºå›ºå®šé‡ï¼Œå¹¶ä½¿ç”¨æœ€å¤§ä¼¼ç„¶åŸç†æ¥ä¼°è®¡å®ƒä»¬çš„å€¼ï¼Œè€Œæ˜¯è´å¶æ–¯æ–¹æ³•å°†å®ƒä»¬è§†ä¸ºå…·æœ‰å„è‡ªå¯èƒ½å€¼æ¦‚ç‡åˆ†å¸ƒçš„ç§»åŠ¨å˜é‡ã€‚
- en: Let us get a first glimpse of the famous Bayesian theorem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¦–å…ˆäº†è§£ä¸€ä¸‹è‘—åçš„è´å¶æ–¯å®šç†ã€‚
- en: A first look into the Bayesian theorem
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆæ¢è´å¶æ–¯å®šç†
- en: The Bayesian theorem describes the relationship between conditional probabilities
    of statistical quantities. In the context of linear regression, we would treat
    the parameter Î² as a random variable instead of fixed quantities as we did with
    linear regression in [*Chapter 12*](B18680_12.xhtml#_idTextAnchor258). For example,
    in a simple linear regression model y = Î²x, instead of obtaining the single best
    parameter Î²Â * by minimizing the **ordinary least squares** (**OLS**) given the
    available data (x, y), we would instead treat Î² as a random variable that follows
    a specific distribution.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯å®šç†æè¿°äº†ç»Ÿè®¡é‡æ¡ä»¶æ¦‚ç‡ä¹‹é—´çš„å…³ç³»ã€‚åœ¨çº¿æ€§å›å½’çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬ä¼šå°†å‚æ•° Î² è§†ä¸ºä¸€ä¸ªéšæœºå˜é‡ï¼Œè€Œä¸æ˜¯åƒæˆ‘ä»¬åœ¨[*ç¬¬12ç« *](B18680_12.xhtml#_idTextAnchor258)ä¸­å¤„ç†çº¿æ€§å›å½’é‚£æ ·å°†å…¶è§†ä¸ºå›ºå®šé‡ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹
    y = Î²x ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šé€šè¿‡æœ€å°åŒ–ç»™å®šæ•°æ® (x, y) çš„**æ™®é€šæœ€å°äºŒä¹˜æ³•**ï¼ˆ**OLS**ï¼‰æ¥è·å¾—å•ä¸ªæœ€ä½³å‚æ•° Î²ï¼Œè€Œæ˜¯å°† Î² è§†ä¸ºä¸€ä¸ªéµå¾ªç‰¹å®šåˆ†å¸ƒçš„éšæœºå˜é‡ã€‚
- en: 'Doing this involves two distributions about Î², the parameter of interest, as
    follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åšè¿™ä»¶äº‹æ¶‰åŠåˆ°å…³äº Î² çš„ä¸¤ä¸ªåˆ†å¸ƒï¼Œå³æ„Ÿå…´è¶£çš„å‚æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: The first distribution is the **prior distribution** P(Î²), which corresponds
    to a subjective distribution we assign to Î² before we observe any data. This distribution
    encapsulates our prior belief about the probabilities of possible values of Î²
    before we observe any actual data.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªåˆ†å¸ƒæ˜¯**å…ˆéªŒåˆ†å¸ƒ** P(Î²)ï¼Œè¿™å¯¹åº”äºæˆ‘ä»¬åœ¨è§‚å¯Ÿä»»ä½•æ•°æ®ä¹‹å‰åˆ†é…ç»™ Î² çš„ä¸»è§‚åˆ†å¸ƒã€‚è¿™ä¸ªåˆ†å¸ƒå°è£…äº†æˆ‘ä»¬åœ¨è§‚å¯Ÿä»»ä½•å®é™…æ•°æ®ä¹‹å‰å¯¹ Î² å¯èƒ½å€¼æ¦‚ç‡çš„å…ˆéªŒä¿¡å¿µã€‚
- en: The second distribution is the **posterior distribution** P(Î²|x, y), which corresponds
    to the updated belief about this distribution after we observe the data. This
    is the distribution we want to estimate through the update. Such an update is
    necessary in order to conform our prior belief to what we actually observe in
    reality.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªåˆ†å¸ƒæ˜¯**åéªŒåˆ†å¸ƒ** P(Î²|x, y)ï¼Œè¿™å¯¹åº”äºè§‚å¯Ÿæ•°æ®åæˆ‘ä»¬å¯¹è¯¥åˆ†å¸ƒæ›´æ–°çš„ä¿¡å¿µã€‚è¿™æ˜¯æˆ‘ä»¬å¸Œæœ›é€šè¿‡æ›´æ–°æ¥ä¼°è®¡çš„åˆ†å¸ƒã€‚è¿™ç§æ›´æ–°æ˜¯ä¸ºäº†ä½¿æˆ‘ä»¬çš„å…ˆéªŒä¿¡å¿µä¸æˆ‘ä»¬åœ¨ç°å®ä¸­å®é™…è§‚å¯Ÿåˆ°çš„ç›¸ç¬¦åˆã€‚
- en: Naturally, we would hope that the posterior distribution P(Î²|x, y) stays closer
    to what the data reflects as the training size gets large, and correspondingly
    stays further away from the prior belief. Here, the data refers to (x, y). To
    proceed with the update, the data would enter as what we call the likelihood function
    P(y|x, Î²), also referred to as the **generative model**. That is, P(y|x, Î²) represents
    the likelihood (similar to probability, although in an unnormalized way) of observing
    the target y given the input feature x and parameter value Î², where we have treated
    Î² as a specific value instead of a random variable. In other words, we would first
    sample from the distribution P(Î²) to obtain a concrete value of Î², and then follow
    the specific observation model to obtain the actual data point y given the input
    feature x. For example, we would assume a normal distribution for the observation
    model if the errors are assumed to follow a normal distribution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶åœ°ï¼Œæˆ‘ä»¬å¸Œæœ›éšç€è®­ç»ƒè§„æ¨¡çš„å¢å¤§ï¼ŒåéªŒåˆ†å¸ƒ P(Î²|x, y) è¶Šæ¥è¶Šæ¥è¿‘æ•°æ®åæ˜ çš„å†…å®¹ï¼Œå¹¶ä¸”ç›¸åº”åœ°è¶Šæ¥è¶Šè¿œç¦»å…ˆéªŒä¿¡å¿µã€‚åœ¨è¿™é‡Œï¼Œæ•°æ®æŒ‡çš„æ˜¯ (x, y)ã€‚ä¸ºäº†è¿›è¡Œæ›´æ–°ï¼Œæ•°æ®å°†ä»¥æˆ‘ä»¬æ‰€è¯´çš„ä¼¼ç„¶å‡½æ•°
    P(y|x, Î²) çš„å½¢å¼è¿›å…¥ï¼Œä¹Ÿè¢«ç§°ä¸º**ç”Ÿæˆæ¨¡å‹**ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼ŒP(y|x, Î²) è¡¨ç¤ºåœ¨ç»™å®šè¾“å…¥ç‰¹å¾ x å’Œå‚æ•°å€¼ Î² çš„æƒ…å†µä¸‹è§‚å¯Ÿç›®æ ‡ y çš„ä¼¼ç„¶ï¼ˆç±»ä¼¼äºæ¦‚ç‡ï¼Œå°½ç®¡æ˜¯éå½’ä¸€åŒ–çš„æ–¹å¼ï¼‰ï¼Œæˆ‘ä»¬å°†
    Î² è§†ä¸ºä¸€ä¸ªç‰¹å®šçš„å€¼è€Œä¸æ˜¯ä¸€ä¸ªéšæœºå˜é‡ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä»åˆ†å¸ƒ P(Î²) ä¸­é‡‡æ ·ä»¥è·å¾— Î² çš„å…·ä½“å€¼ï¼Œç„¶åæ ¹æ®ç‰¹å®šçš„è§‚å¯Ÿæ¨¡å‹ï¼Œåœ¨ç»™å®šè¾“å…¥ç‰¹å¾ x çš„æƒ…å†µä¸‹è·å¾—å®é™…æ•°æ®ç‚¹
    yã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾è¯¯å·®éµå¾ªæ­£æ€åˆ†å¸ƒï¼Œæˆ‘ä»¬ä¼šå‡è®¾è§‚å¯Ÿæ¨¡å‹ä¸ºæ­£æ€åˆ†å¸ƒã€‚
- en: 'Now, we are ready to compile these three quantities together via the following
    Bayesian theorem:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡é€šè¿‡ä»¥ä¸‹è´å¶æ–¯å®šç†å°†è¿™äº›ä¸‰ä¸ªé‡ä¸€èµ·ç¼–è¯‘ï¼š
- en: P(Î² | x, y) = Â P(y|x, Î²)P(Î²)Â _Â P(y|x)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: P(Î² | x, y) = Â P(y|x, Î²)P(Î²)Â _Â P(y|x)
- en: Here, P(y|x) is referred to as the evidence, which acts as a normalizing constant
    to ensure that the posterior distribution is a valid probability distribution,
    meaning each probability is non-negative and sums (or integrates) to 1.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼ŒP(y|x) è¢«ç§°ä¸ºè¯æ®ï¼Œå®ƒä½œä¸ºå½’ä¸€åŒ–å¸¸æ•°ï¼Œç¡®ä¿åéªŒåˆ†å¸ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¿™æ„å‘³ç€æ¯ä¸ªæ¦‚ç‡éƒ½æ˜¯éè´Ÿçš„ï¼Œå¹¶ä¸”æ€»å’Œï¼ˆæˆ–ç§¯åˆ†ï¼‰ä¸º 1ã€‚
- en: '*Figure 14**.1* illustrates the Bayesian theorem:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾14.1* å±•ç¤ºäº†è´å¶æ–¯å®šç†ï¼š'
- en: '![Figure 14.1 â€“ Illustrating the Bayesian theorem that calculates the posterior
    distribution â€‹Pâ€‹(<?AID d835?><?AID df37?>â€Š|â€Šx,â€‰y)â€‹â€‹](img/B18680_14_001.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.1 â€“ è¯´æ˜è´å¶æ–¯å®šç†è®¡ç®—åéªŒåˆ†å¸ƒ P(ğœ· | x, y)](img/B18680_14_001.jpg)'
- en: Figure 14.1 â€“ Illustrating the Bayesian theorem that calculates the posterior
    distribution P(ğœ· | x, y)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.1 â€“ è¯´æ˜è´å¶æ–¯å®šç†è®¡ç®—åéªŒåˆ†å¸ƒ P(ğœ· | x, y)
- en: Note that the prior distribution P(Î²) in Bayesian linear regression could be
    chosen to model our prior belief about the parameter Î², which is something not
    available when using the frequentist framework in OLS-based linear regression.
    In practice, we often go with a normal prior distribution, but it could be any
    distribution that captures the prior belief about the probabilities of possible
    values of Î² before we observe any data. The Bayesian framework thus allows us
    to incorporate the prior knowledge into the modeling in a principled manner. For
    example, if we believe that all features should have similar effects, we can then
    configure the prior distributions of the coefficients to be centered around the
    same value.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè´å¶æ–¯çº¿æ€§å›å½’ä¸­çš„å…ˆéªŒåˆ†å¸ƒ P(Î²) å¯ä»¥é€‰æ‹©æ¥æ¨¡æ‹Ÿæˆ‘ä»¬å¯¹å‚æ•° Î² çš„å…ˆéªŒä¿¡å¿µï¼Œè¿™åœ¨ä½¿ç”¨åŸºäº OLS çš„çº¿æ€§å›å½’çš„é¢‘ç‡æ´¾æ¡†æ¶æ—¶æ˜¯ä¸å¯ç”¨çš„ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸é‡‡ç”¨æ­£æ€å…ˆéªŒåˆ†å¸ƒï¼Œä½†å®ƒå¯ä»¥æ˜¯ä»»ä½•åœ¨è§‚å¯Ÿä»»ä½•æ•°æ®ä¹‹å‰æ•æ‰
    Î² å¯èƒ½å€¼æ¦‚ç‡çš„å…ˆéªŒä¿¡å¿µçš„åˆ†å¸ƒã€‚å› æ­¤ï¼Œè´å¶æ–¯æ¡†æ¶å…è®¸æˆ‘ä»¬ä»¥åŸåˆ™æ€§çš„æ–¹å¼å°†å…ˆéªŒçŸ¥è¯†çº³å…¥å»ºæ¨¡ä¸­ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºæ‰€æœ‰ç‰¹å¾åº”è¯¥æœ‰ç›¸ä¼¼çš„å½±å“ï¼Œæˆ‘ä»¬å°±å¯ä»¥é…ç½®ç³»æ•°çš„å…ˆéªŒåˆ†å¸ƒä»¥å›´ç»•ç›¸åŒçš„å€¼ä¸ºä¸­å¿ƒã€‚
- en: Since the parameter Î² follows a posterior distribution P(Î² | x, y), the resulting
    prediction yÂ * given a new input data xÂ * will not be a single number, as in the
    case of the frequentist approach. Instead, we will obtain a series of possible
    values of yÂ *, which follows a posterior predictive distribution P( yÂ *| xÂ *,
    Î²). That is, the prediction yÂ * is treated as a random variable due to the randomness
    in the parameter Î². We can then use this distribution to understand the uncertainty
    in the resulting predictions. For example, if the posterior predictive distribution
    P( yÂ *| xÂ *, Î²) is wide, the resulting predictions, which are sampled from P(
    yÂ *| xÂ *, Î²), contain a higher degree of uncertainty. On the other hand, if the
    distribution is narrow, the resulting predictions are more concentrated and thus
    more confident. The posterior distribution P(Î² | x, y) will also continue to evolve
    as new data becomes available.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå‚æ•° Î² éµå¾ªåéªŒåˆ†å¸ƒ P(Î² | x, y)ï¼Œç»™å®šæ–°çš„è¾“å…¥æ•°æ® x çš„ç»“æœé¢„æµ‹ y å°†ä¸ä¼šæ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—ï¼Œæ­£å¦‚é¢‘ç‡æ´¾æ–¹æ³•ä¸­çš„æƒ…å†µã€‚ç›¸åï¼Œæˆ‘ä»¬å°†è·å¾—ä¸€ç³»åˆ—å¯èƒ½çš„
    y å€¼ï¼Œè¿™äº›å€¼éµå¾ªåéªŒé¢„æµ‹åˆ†å¸ƒ P( y*| x*, Î²)ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç”±äºå‚æ•° Î² çš„éšæœºæ€§ï¼Œé¢„æµ‹ y è¢«è§†ä¸ºä¸€ä¸ªéšæœºå˜é‡ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªåˆ†å¸ƒæ¥ç†è§£ç»“æœé¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåéªŒé¢„æµ‹åˆ†å¸ƒ
    P( y*| x*, Î²) è¾ƒå®½ï¼Œé‚£ä¹ˆä» P( y*| x*, Î²) ä¸­é‡‡æ ·çš„ç»“æœé¢„æµ‹å°†åŒ…å«æ›´é«˜çš„ä¸ç¡®å®šæ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœåˆ†å¸ƒè¾ƒçª„ï¼Œç»“æœé¢„æµ‹å°†æ›´åŠ é›†ä¸­ï¼Œå› æ­¤æ›´åŠ è‡ªä¿¡ã€‚éšç€æ–°æ•°æ®çš„å‡ºç°ï¼ŒåéªŒåˆ†å¸ƒ
    P(Î² | x, y) ä¹Ÿå°†ç»§ç»­æ¼”å˜ã€‚
- en: The next section introduces more on the generative model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªéƒ¨åˆ†å°†ä»‹ç»æ›´å¤šå…³äºç”Ÿæˆæ¨¡å‹çš„å†…å®¹ã€‚
- en: Understanding the generative model
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç†è§£ç”Ÿæˆæ¨¡å‹
- en: In Bayesian inference, the generative model specifies the probability distribution
    that governs how the data is generated. For example, when the available target
    data is binary, we could assume it is generated following a Bernoulli distribution
    with a parameter p that represents the probability of success. To get a list of
    binary outcomes, we would first assign a probability value to p and then use this
    Bernoulli distribution to generate binary labels by repeated sampling from this
    distribution.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è´å¶æ–¯æ¨ç†ä¸­ï¼Œç”Ÿæˆæ¨¡å‹æŒ‡å®šäº†æ§åˆ¶æ•°æ®å¦‚ä½•ç”Ÿæˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œå½“å¯ç”¨çš„ç›®æ ‡æ•°æ®æ˜¯äºŒè¿›åˆ¶æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾å®ƒæ˜¯æŒ‰ç…§å‚æ•° p çš„ä¼¯åŠªåˆ©åˆ†å¸ƒç”Ÿæˆçš„ï¼Œå…¶ä¸­ p
    ä»£è¡¨æˆåŠŸçš„æ¦‚ç‡ã€‚ä¸ºäº†å¾—åˆ°ä¸€ç³»åˆ—çš„äºŒè¿›åˆ¶ç»“æœï¼Œæˆ‘ä»¬é¦–å…ˆä¸º p åˆ†é…ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªä¼¯åŠªåˆ©åˆ†å¸ƒé€šè¿‡ä»è¿™ä¸ªåˆ†å¸ƒä¸­é‡å¤é‡‡æ ·æ¥ç”ŸæˆäºŒè¿›åˆ¶æ ‡ç­¾ã€‚
- en: Let us go through an exercise to understand the generative process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç»ƒä¹ æ¥ç†è§£ç”Ÿæˆè¿‡ç¨‹ã€‚
- en: Exercise 14.1 â€“ Generating binary outcomes
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 14.1 â€“ ç”ŸæˆäºŒè¿›åˆ¶ç»“æœ
- en: 'In this exercise, we will generate a list of binary outcomes based on a Bernoulli
    distribution. This involves comparing a random sample from a uniform distribution
    valued between `0` and `1` to the preset probability of success. Follow the next
    steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†æ ¹æ®ä¼¯åŠªåˆ©åˆ†å¸ƒç”Ÿæˆä¸€ç³»åˆ—äºŒè¿›åˆ¶ç»“æœã€‚è¿™æ¶‰åŠåˆ°å°†æ¥è‡ªå‡åŒ€åˆ†å¸ƒçš„ `0` åˆ° `1` ä¹‹é—´çš„éšæœºæ ·æœ¬ä¸é¢„è®¾çš„æˆåŠŸæ¦‚ç‡è¿›è¡Œæ¯”è¾ƒã€‚éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š
- en: 'We begin with generating a random number in the range of `0` and `1` using
    a uniform distribution:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å‡åŒ€åˆ†å¸ƒç”Ÿæˆä¸€ä¸ªä»‹äº `0` å’Œ `1` èŒƒå›´å†…çš„éšæœºæ•°ï¼š
- en: '[PRE0]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Again, remember to set the random seed for reproducibility purposes.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å†æ¬¡æé†’ï¼Œä¸ºäº†å¯é‡å¤æ€§ï¼Œè¯·è®¾ç½®éšæœºç§å­ã€‚
- en: 'Next, we compare the number to a preset probability of `0.2`:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ•°å­—ä¸é¢„è®¾çš„æ¦‚ç‡ `0.2` è¿›è¡Œæ¯”è¾ƒï¼š
- en: '[PRE1]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This completes the generation of a single binary number. Now, let us expand
    it to 10 numbers.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™å®Œæˆäº†å•ä¸ªäºŒè¿›åˆ¶æ•°çš„ç”Ÿæˆã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†å…¶æ‰©å±•åˆ° 10 ä¸ªæ•°å­—ã€‚
- en: 'With the help of the following code, weâ€™ll generate 10 binary numbers:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä»¥ä¸‹ä»£ç çš„å¸®åŠ©ä¸‹ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆ 10 ä¸ªäºŒè¿›åˆ¶æ•°ï¼š
- en: '[PRE2]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we used a `for` loop to repeatedly generate a uniform random number, compare
    it with the preset probability of success, and then store the result in a vector.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ `for` å¾ªç¯é‡å¤ç”Ÿæˆå‡åŒ€éšæœºæ•°ï¼Œå°†å…¶ä¸é¢„è®¾çš„æˆåŠŸæ¦‚ç‡è¿›è¡Œæ¯”è¾ƒï¼Œç„¶åå°†ç»“æœå­˜å‚¨åœ¨å‘é‡ä¸­ã€‚
- en: 'Convert the vector to numbers `0` and `1`, as follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å‘é‡è½¬æ¢ä¸º `0` å’Œ `1` æ•°å­—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE3]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that we have observed 1 instance of success out of 10 draws, despite a
    20% probability of success. As the sample size increases, we would expect the
    empirical probability of success (10% in this case) to be close to the theoretical
    value (20%).
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå°½ç®¡æˆåŠŸçš„æ¦‚ç‡ä¸º 20%ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ° 10 æ¬¡æŠ½å–ä¸­æœ‰ 1 æ¬¡æˆåŠŸã€‚éšç€æ ·æœ¬é‡çš„å¢åŠ ï¼Œæˆ‘ä»¬é¢„è®¡æˆåŠŸçš„ç»éªŒæ¦‚ç‡ï¼ˆæœ¬ä¾‹ä¸­ä¸º 10%ï¼‰å°†æ¥è¿‘ç†è®ºå€¼ï¼ˆ20%ï¼‰ã€‚
- en: 'It turns out that this generative model corresponds to a binomial process or
    a binomial distribution, which allows us to generate binary outcomes in one shot.
    Specifically, we can use the `rbinom``()` function to simulate data from a binomial
    distribution, as shown in the following code snippet:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œè¿™ä¸ªç”Ÿæˆæ¨¡å‹å¯¹åº”äºäºŒé¡¹è¿‡ç¨‹æˆ–äºŒé¡¹åˆ†å¸ƒï¼Œè¿™å…è®¸æˆ‘ä»¬ä¸€æ¬¡æ€§ç”ŸæˆäºŒè¿›åˆ¶ç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `rbinom()` å‡½æ•°æ¥æ¨¡æ‹ŸäºŒé¡¹åˆ†å¸ƒçš„æ•°æ®ï¼Œå¦‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ‰€ç¤ºï¼š
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, `n` is the number of samples to be generated from the generative model,
    `size` is the number of trials to run, and `prob` is the underlying probability
    of success valued between `0.0` and `1.0`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`n` æ˜¯ä»ç”Ÿæˆæ¨¡å‹ä¸­ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ï¼Œ`size` æ˜¯è¦è¿è¡Œçš„è¯•éªŒæ¬¡æ•°ï¼Œ`prob` æ˜¯ä»‹äº `0.0` å’Œ `1.0` ä¹‹é—´çš„æˆåŠŸåŸºç¡€æ¦‚ç‡ã€‚
- en: Note that we are essentially working with a known parameter p, which is the
    probability of success. In practice, this would be an unknown parameter, something
    we are interested in estimating from the data. Bayesian inference would allow
    us to do that, with the assistance of a prior distribution and the likelihood
    function, as introduced in the following section.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬æœ¬è´¨ä¸Šæ˜¯åœ¨å¤„ç†ä¸€ä¸ªå·²çŸ¥çš„å‚æ•° pï¼Œå³æˆåŠŸçš„æ¦‚ç‡ã€‚åœ¨å®è·µä¸­ï¼Œè¿™å°†æ˜¯æœªçŸ¥å‚æ•°ï¼Œæ˜¯æˆ‘ä»¬ä»æ•°æ®ä¸­æ„Ÿå…´è¶£ä¼°è®¡çš„ä¸œè¥¿ã€‚è´å¶æ–¯æ¨ç†å°†å…è®¸æˆ‘ä»¬è¿™æ ·åšï¼Œåœ¨ä¸‹ä¸€èŠ‚ä¸­ä»‹ç»çš„å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶å‡½æ•°çš„å¸®åŠ©ä¸‹ã€‚
- en: Understanding prior distributions
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç†è§£å…ˆéªŒåˆ†å¸ƒ
- en: A prior distribution, an essential component of Bayesian inference, represents
    the prior knowledge or belief about the underlying parameter before we observe
    the actual data. It essentially specifies the probability distribution of the
    parameters based on domain-specific preference or expertise. If we have a valid
    reason to believe that certain values of the parameters are more likely, we can
    choose a prior distribution that reflects this preference.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å…ˆéªŒåˆ†å¸ƒï¼Œè´å¶æ–¯æ¨ç†çš„ä¸€ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œè¡¨ç¤ºåœ¨æˆ‘ä»¬è§‚å¯Ÿå®é™…æ•°æ®ä¹‹å‰å¯¹æ½œåœ¨å‚æ•°çš„å…ˆéªŒçŸ¥è¯†æˆ–ä¿¡å¿µã€‚å®ƒæœ¬è´¨ä¸ŠåŸºäºç‰¹å®šé¢†åŸŸçš„åå¥½æˆ–ä¸“ä¸šçŸ¥è¯†æŒ‡å®šå‚æ•°çš„æ¦‚ç‡åˆ†å¸ƒã€‚å¦‚æœæˆ‘ä»¬æœ‰åˆç†çš„ç†ç”±ç›¸ä¿¡æŸäº›å‚æ•°å€¼æ›´æœ‰å¯èƒ½ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€ä¸ªåæ˜ è¿™ç§åå¥½çš„å…ˆéªŒåˆ†å¸ƒã€‚
- en: The prior distribution, denoted as P(Î²), treats Î² as a random variable and specifies
    its probability distribution. That is, it tells us which values of Î² are more
    likely than others. In our running example on Bayesian linear regression, the
    prior distribution for Î² is often chosen to be a multivariate Gaussian distribution.
    This is mainly for mathematical convenience, as the Gaussian distribution has
    nice properties that make it easier to work with. However, if we have no prior
    preference, a uniform distribution (which gives the same probability to all possible
    choices and is thus uninformed) could be a good candidate.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å…ˆéªŒåˆ†å¸ƒï¼Œè¡¨ç¤ºä¸ºP(Î²)ï¼Œå°†Î²è§†ä¸ºä¸€ä¸ªéšæœºå˜é‡å¹¶æŒ‡å®šå…¶æ¦‚ç‡åˆ†å¸ƒã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬å“ªäº›Î²çš„å€¼æ¯”å…¶ä»–å€¼æ›´æœ‰å¯èƒ½ã€‚åœ¨æˆ‘ä»¬å…³äºè´å¶æ–¯çº¿æ€§å›å½’çš„è¿è¡Œç¤ºä¾‹ä¸­ï¼ŒÎ²çš„å…ˆéªŒåˆ†å¸ƒé€šå¸¸é€‰æ‹©ä¸ºå¤šå…ƒé«˜æ–¯åˆ†å¸ƒã€‚è¿™ä¸»è¦æ˜¯å‡ºäºæ•°å­¦ä¸Šçš„ä¾¿åˆ©ï¼Œå› ä¸ºé«˜æ–¯åˆ†å¸ƒå…·æœ‰ä¸€äº›è‰¯å¥½çš„æ€§è´¨ï¼Œä½¿å¾—å®ƒæ›´å®¹æ˜“å¤„ç†ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æ²¡æœ‰å…ˆéªŒåå¥½ï¼Œå‡åŒ€åˆ†å¸ƒï¼ˆå¯¹æ‰€æœ‰å¯èƒ½çš„é€‰æ‹©ç»™äºˆç›¸åŒçš„æ¦‚ç‡ï¼Œå› æ­¤æ˜¯æ— ä¿¡æ¯çš„ï¼‰å¯èƒ½æ˜¯ä¸€ä¸ªå¥½çš„å€™é€‰è€…ã€‚
- en: Note that we can also use the prior to impose a form of regularization on the
    model. By choosing a prior distribution that favors smaller values of the parameters
    (such as a Gaussian distribution centered at `0`), we can discourage the model
    from finding solutions with large coefficients, thus preventing overfitting.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨å…ˆéªŒå¯¹æ¨¡å‹æ–½åŠ ä¸€ç§æ­£åˆ™åŒ–çš„å½¢å¼ã€‚é€šè¿‡é€‰æ‹©ä¸€ä¸ªåå¥½è¾ƒå°å‚æ•°å€¼çš„å…ˆéªŒåˆ†å¸ƒï¼ˆä¾‹å¦‚ï¼Œä»¥`0`ä¸ºä¸­å¿ƒçš„é«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥é˜»æ­¢æ¨¡å‹æ‰¾åˆ°å…·æœ‰å¤§ç³»æ•°çš„è§£ï¼Œä»è€Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
- en: 'In the following code snippet, we randomly generate 10 samples of P(Î²) following
    a uniform distribution between `0` and `0.2`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬éšæœºç”Ÿæˆ10ä¸ªP(Î²)æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬éµå¾ªåœ¨`0`å’Œ`0.2`ä¹‹é—´çš„å‡åŒ€åˆ†å¸ƒï¼š
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When we model the probability of success p âˆˆ [0,1] as a random variable, we
    often assign a beta distribution as the prior. For example, in the following code
    snippet, we generate 1,000 samples of p from the beta distribution p âˆ¼ Beta(35,55)
    using the `rbeta()` function, followed by showing its density plot after converting
    it to a DataFrame format:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å°†æˆåŠŸçš„æ¦‚ç‡p âˆˆ [0,1]å»ºæ¨¡ä¸ºä¸€ä¸ªéšæœºå˜é‡æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å°†è´å¡”åˆ†å¸ƒä½œä¸ºå…ˆéªŒåˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨`rbeta()`å‡½æ•°ä»è´å¡”åˆ†å¸ƒp
    âˆ¼ Beta(35,55)ä¸­ç”Ÿæˆ1,000ä¸ªpçš„æ ·æœ¬ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºDataFrameæ ¼å¼åå±•ç¤ºå…¶å¯†åº¦å›¾ï¼š
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Running the preceding code will generate the output shown in *Figure 14**.2*.
    It shows a prior concentration of the probability of success close to `0.4`, within
    the range of `0` and `1`:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œå‰é¢çš„ä»£ç å°†ç”Ÿæˆ*å›¾14.2*æ‰€ç¤ºçš„è¾“å‡ºã€‚å®ƒæ˜¾ç¤ºäº†æˆåŠŸæ¦‚ç‡åœ¨`0`å’Œ`1`èŒƒå›´å†…çš„`0.4`é™„è¿‘çš„å…ˆéªŒé›†ä¸­ï¼š
- en: '![Figure 14.2 â€“ Visualizing the density plot of the prior distribution](img/B18680_14_002.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.2 â€“ å¯è§†åŒ–å…ˆéªŒåˆ†å¸ƒçš„å¯†åº¦å›¾](img/B18680_14_002.jpg)'
- en: Figure 14.2 â€“ Visualizing the density plot of the prior distribution
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.2 â€“ å¯è§†åŒ–å…ˆéªŒåˆ†å¸ƒçš„å¯†åº¦å›¾
- en: 'The Beta(a, b) distribution is defined on the interval from `0` to `1`, thus
    providing a natural and flexible prior to the probability random variable. We
    can tune the `Beta` shape parameters a and b to produce alternative prior models.
    In the following code snippet, we compare the origina`l` `B``e``t``a``(``35``,``55``)`
    prior distributions with two alternatives: `B``e``t``a``(``1``,` `1``)` and `B``e``t``a``(``100``,`
    `100``)`. We then plot all three prior distributions together:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Beta(a, b)åˆ†å¸ƒå®šä¹‰åœ¨ä»`0`åˆ°`1`çš„åŒºé—´ä¸Šï¼Œå› æ­¤ä¸ºæ¦‚ç‡éšæœºå˜é‡æä¾›äº†ä¸€ä¸ªè‡ªç„¶ä¸”çµæ´»çš„å…ˆéªŒã€‚æˆ‘ä»¬å¯ä»¥è°ƒæ•´`Beta`å½¢çŠ¶å‚æ•°aå’Œbä»¥äº§ç”Ÿä¸åŒçš„å…ˆéªŒæ¨¡å‹ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†åŸå§‹`Beta(35,55)`å…ˆéªŒåˆ†å¸ƒä¸ä¸¤ç§æ›¿ä»£æ–¹æ¡ˆï¼š`Beta(1,1)`å’Œ`Beta(100,100)`ã€‚ç„¶åæˆ‘ä»¬å°†æ‰€æœ‰ä¸‰ä¸ªå…ˆéªŒåˆ†å¸ƒä¸€èµ·ç»˜åˆ¶å‡ºæ¥ï¼š
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code returns the output shown in *Figure 14**.3*. Each prior
    distribution has a different preference region. For example, distribution B is
    close to a uniform distribution and has no specific preference, while distribution
    C places a strong preference for `0.5`, as indicated by the peak value around
    `0.5` and a narrow spread:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å‰é¢çš„ä»£ç è¿”å›*å›¾14.3*æ‰€ç¤ºçš„è¾“å‡ºã€‚æ¯ä¸ªå…ˆéªŒåˆ†å¸ƒéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„åå¥½åŒºåŸŸã€‚ä¾‹å¦‚ï¼Œåˆ†å¸ƒBæ¥è¿‘å‡åŒ€åˆ†å¸ƒï¼Œæ²¡æœ‰ç‰¹å®šçš„åå¥½ï¼Œè€Œåˆ†å¸ƒCå¯¹`0.5`æœ‰å¼ºçƒˆçš„åå¥½ï¼Œå¦‚å³°å€¼åœ¨`0.5`é™„è¿‘å’Œç‹­çª„çš„åˆ†å¸ƒæ‰€æŒ‡ç¤ºï¼š
- en: '![Figure 14.3 â€“ Visualizing three different prior distributions](img/B18680_14_003.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.3 â€“ å¯è§†åŒ–ä¸‰ç§ä¸åŒçš„å…ˆéªŒåˆ†å¸ƒ](img/B18680_14_003.jpg)'
- en: Figure 14.3 â€“ Visualizing three different prior distributions
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.3 â€“ å¯è§†åŒ–ä¸‰ç§ä¸åŒçš„å…ˆéªŒåˆ†å¸ƒ
- en: In the next section, weâ€™ll introduce you to the likelihood function.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨ä»‹ç»ä¼¼ç„¶å‡½æ•°ã€‚
- en: Introducing the likelihood function
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»ä¼¼ç„¶å‡½æ•°
- en: The likelihood function describes how likely the observed data is, given a set
    of fixed model parameters. In a parametric model (a model that assumes a certain
    set of parameters), the likelihood is the probability of the observed data as
    a function of the parameters. The specific form of the likelihood function depends
    on the distribution (more specifically, the observation model) assumed for the
    data. For example, if we assume the data follows a normal distribution, the likelihood
    function would take the form of a normal probability density function.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼¼ç„¶å‡½æ•°æè¿°äº†åœ¨ç»™å®šä¸€ç»„å›ºå®šæ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œè§‚å¯Ÿåˆ°çš„æ•°æ®æœ‰å¤šå¯èƒ½ã€‚åœ¨å‚æ•°æ¨¡å‹ï¼ˆå‡è®¾ä¸€ç»„ç‰¹å®šå‚æ•°çš„æ¨¡å‹ï¼‰ä¸­ï¼Œä¼¼ç„¶æ˜¯è§‚å¯Ÿæ•°æ®çš„æ¦‚ç‡ä½œä¸ºå‚æ•°çš„å‡½æ•°ã€‚ä¼¼ç„¶å‡½æ•°çš„å…·ä½“å½¢å¼å–å†³äºæ•°æ®æ‰€å‡è®¾çš„åˆ†å¸ƒï¼ˆæ›´å…·ä½“åœ°è¯´ï¼Œæ˜¯è§‚æµ‹æ¨¡å‹ï¼‰ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å‡è®¾æ•°æ®éµå¾ªæ­£æ€åˆ†å¸ƒï¼Œä¼¼ç„¶å‡½æ•°å°†é‡‡ç”¨æ­£æ€æ¦‚ç‡å¯†åº¦å‡½æ•°çš„å½¢å¼ã€‚
- en: 'Let us look at a concrete example. Suppose we are developing a simple linear
    regression model with standard normal errors, expressed as y = Î²x + Ïµ, where Ïµ
    âˆ¼ N(0,1). Here, we have ignored the intercept term and only considered the slope.
    For a specific data point ( xÂ i, yÂ i), we can express the likelihood lÂ i as the
    probability evaluated at the probability density function of the error term:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ã€‚å‡è®¾æˆ‘ä»¬æ­£åœ¨å¼€å‘ä¸€ä¸ªå…·æœ‰æ ‡å‡†æ­£æ€è¯¯å·®çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œè¡¨ç¤ºä¸º y = Î²x + Ïµï¼Œå…¶ä¸­ Ïµ âˆ¼ N(0,1)ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¿½ç•¥äº†æˆªè·é¡¹ï¼Œåªè€ƒè™‘äº†æ–œç‡ã€‚å¯¹äºç‰¹å®šçš„æ•°æ®ç‚¹
    (x_i, y_i)ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¼¼ç„¶ l_i è¡¨ç¤ºä¸ºåœ¨è¯¯å·®é¡¹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸Šçš„æ¦‚ç‡è¯„ä¼°ï¼š
- en: lÂ i = Â 1Â _Â âˆšÂ _Â 2Ï€Â Â  eÂ âˆ’(yÂ iâˆ’Î²xÂ i)Â 2Â _Â 2
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: l_i = 1 / âˆš2Ï€ e^(-(y_iâˆ’Î²x_i)^2 / 2)
- en: 'Since the dataset consists of a total of n input-output pairs, the joint likelihood
    of all data points can be expressed as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ•°æ®é›†ç”±æ€»å…± n ä¸ªè¾“å…¥è¾“å‡ºå¯¹ç»„æˆï¼Œæ‰€æœ‰æ•°æ®ç‚¹çš„è”åˆä¼¼ç„¶å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ï¼š
- en: L = Î Â i=1Â nÂ  lÂ i = (Â 1Â _Â âˆšÂ _Â 2Ï€Â Â )Â n eÂ âˆ’âˆ‘Â i=1Â nÂ Â (yÂ iâˆ’Î²xÂ i)Â 2Â _Â 2
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: L = Î  i=1 n l_i = (1 / âˆš2Ï€)^n e^âˆ’âˆ‘ i=1 n (y_iâˆ’Î²x_i)^2 / 2
- en: 'In practice, we would often work with the log-likelihood after introducing
    the log transformation, as shown here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå¼•å…¥å¯¹æ•°å˜æ¢åå¤„ç†å¯¹æ•°ä¼¼ç„¶ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: logL = log(Â 1Â _Â âˆšÂ _Â 2Ï€Â Â )Â n eÂ âˆ’âˆ‘Â i=1Â nÂ Â (yÂ iâˆ’Î²xÂ i)Â 2Â _Â 2Â  = âˆ’ 0.5nlog2Ï€ âˆ’ 0.5âˆ‘Â i=1Â nÂ (yÂ i
    âˆ’ Î² xÂ i)Â 2
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: logL = log(1 / âˆš2Ï€)^n e^âˆ’âˆ‘ i=1 n (y_iâˆ’Î²x_i)^2 / 2 = âˆ’0.5nlog2Ï€ âˆ’ 0.5âˆ‘ i=1 n
    (y_i âˆ’ Î² x_i)^2
- en: 'Compared to the objective function used in OLS-based linear regression, we
    find that the exponent term âˆ‘Â i=1Â nÂ Â (yÂ i âˆ’ Î² xÂ i)Â 2 is exactly the sum of squared
    errors. When using the maximum likelihood estimation procedure, these two different
    objective functions become equivalent to each other. In other words, we have the
    following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŸºäº OLS çš„çº¿æ€§å›å½’ä¸­ä½¿ç”¨çš„ç›®æ ‡å‡½æ•°ç›¸æ¯”ï¼Œæˆ‘ä»¬å‘ç°æŒ‡æ•°é¡¹ âˆ‘ i=1 n (y_i âˆ’ Î² x_i)^2 æ­£å¥½æ˜¯å¹³æ–¹è¯¯å·®çš„æ€»å’Œã€‚å½“ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡è¿‡ç¨‹æ—¶ï¼Œè¿™ä¸¤ä¸ªä¸åŒçš„ç›®æ ‡å‡½æ•°å˜å¾—å½¼æ­¤ç­‰ä»·ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹ï¼š
- en: logL â‰ˆ âˆ’ âˆ‘Â i=1Â nÂ (yÂ i âˆ’ Î² xÂ i)Â 2
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: logL â‰ˆ âˆ’ âˆ‘ i=1 n (y_i âˆ’ Î² x_i)^2
- en: Here, we ignored the constant term (Â 1Â _Â âˆšÂ _Â 2Ï€Â )Â n at the last step.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬å¿½ç•¥äº†å¸¸æ•°é¡¹ (1 / âˆš2Ï€)^nã€‚
- en: 'Let us go through an example of how to calculate the joint likelihood of a
    set of observed data. In the following code listing, we create a list of data
    points in `x` and `y` and a simple linear regression model with coefficient `b`
    to generate the predicted values in `y_pred`, along with the residual terms in
    residuals:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¾‹å­æ¥äº†è§£å¦‚ä½•è®¡ç®—ä¸€ç»„è§‚å¯Ÿæ•°æ®çš„è”åˆä¼¼ç„¶ã€‚åœ¨ä¸‹é¢çš„ä»£ç åˆ—è¡¨ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«æ•°æ®ç‚¹ `x` å’Œ `y` çš„åˆ—è¡¨ï¼Œä»¥åŠä¸€ä¸ªå…·æœ‰ç³»æ•° `b`
    çš„ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œä»¥ç”Ÿæˆé¢„æµ‹å€¼ `y_pred`ï¼Œä»¥åŠæ®‹å·®é¡¹ `residuals`ï¼š
- en: '[PRE8]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can then plug in the closed-form expression for the joint likelihood and
    calculate the total log-likelihood, as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†è”åˆä¼¼ç„¶çš„é—­å¼è¡¨è¾¾å¼ä»£å…¥ï¼Œå¹¶è®¡ç®—æ€»å¯¹æ•°ä¼¼ç„¶ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let us look at another example of the binomial model. As discussed earlier,
    when the underlying parameter p represents the probability of success, we can
    use the `rbinom()` function to obtain the probability of observing a certain outcome
    (number of successes) in a total number of draws and with a specific probability
    of success. In the following code snippet, we first create a vector of probabilities
    to indicate different probabilities of success and calculate the corresponding
    likelihood in a total of 1,000 trials of sampling from a binomial model Bin(p,
    10), where 10 is the total number of draws. Lastly, we visualize all likelihood
    functions via a stacked density plot using the `geom_density_ridges()` function
    from the `ggridges` package:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹äºŒé¡¹æ¨¡å‹çš„å¦ä¸€ä¸ªä¾‹å­ã€‚å¦‚å‰æ‰€è¿°ï¼Œå½“æ½œåœ¨å‚æ•° p ä»£è¡¨æˆåŠŸçš„æ¦‚ç‡æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `rbinom()` å‡½æ•°æ¥è·å¾—åœ¨æ€»æŠ½å–æ¬¡æ•°ä¸­è§‚å¯Ÿåˆ°ç‰¹å®šç»“æœï¼ˆæˆåŠŸæ¬¡æ•°ï¼‰çš„æ¦‚ç‡ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ¦‚ç‡å‘é‡æ¥è¡¨ç¤ºä¸åŒçš„æˆåŠŸæ¦‚ç‡ï¼Œå¹¶è®¡ç®—ä»äºŒé¡¹æ¨¡å‹
    Bin(p, 10)ï¼ˆå…¶ä¸­ 10 æ˜¯æ€»æŠ½å–æ¬¡æ•°ï¼‰ä¸­æŠ½å–çš„ 1,000 æ¬¡è¯•éªŒä¸­çš„å¯¹åº”ä¼¼ç„¶ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ `ggridges` åŒ…ä¸­çš„ `geom_density_ridges()`
    å‡½æ•°é€šè¿‡å †å å¯†åº¦å›¾å¯è§†åŒ–æ‰€æœ‰ä¼¼ç„¶å‡½æ•°ï¼š
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code results in the following output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ä»£ç äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š
- en: '![Figure 14.4 â€“ Visualizing the stacked density plot as the likelihood functions
    of different sampling from the binomial distribution](img/B18680_14_004.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.4 â€“ å¯è§†åŒ–å †å å¯†åº¦å›¾ä½œä¸ºæ¥è‡ªäºŒé¡¹åˆ†å¸ƒä¸åŒæŠ½æ ·çš„ä¼¼ç„¶å‡½æ•°](img/B18680_14_004.jpg)'
- en: Figure 14.4 â€“ Visualizing the stacked density plot as the likelihood functions
    of different sampling from the binomial distribution
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.4 â€“ å¯è§†åŒ–å †å å¯†åº¦å›¾ä½œä¸ºæ¥è‡ªäºŒé¡¹åˆ†å¸ƒä¸åŒæŠ½æ ·çš„ä¼¼ç„¶å‡½æ•°
- en: The next section introduces the posterior model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªéƒ¨åˆ†ä»‹ç»äº†åéªŒæ¨¡å‹ã€‚
- en: Introducing the posterior model
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼•å…¥åéªŒæ¨¡å‹
- en: A posterior distribution represents what we know about unknown parameters after
    observing the available data. It combines the prior beliefs, expressed via the
    prior distribution, with the evidence presented by the data, expressed in the
    likelihood function, to form a new distribution over the possible parameter values,
    which can be either discrete or continuous.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: åéªŒåˆ†å¸ƒä»£è¡¨äº†è§‚å¯Ÿå¯ç”¨æ•°æ®åæˆ‘ä»¬å¯¹æœªçŸ¥å‚æ•°çš„äº†è§£ã€‚å®ƒç»“åˆäº†é€šè¿‡å…ˆéªŒåˆ†å¸ƒè¡¨è¾¾çš„å‰éªŒä¿¡å¿µå’Œæ•°æ®é€šè¿‡ä¼¼ç„¶å‡½æ•°æä¾›çš„è¯æ®ï¼Œå½¢æˆä¸€ä¸ªæ–°åˆ†å¸ƒï¼Œè¦†ç›–å¯èƒ½çš„å‚æ•°å€¼ï¼Œè¿™äº›å€¼å¯ä»¥æ˜¯ç¦»æ•£çš„æˆ–è¿ç»­çš„ã€‚
- en: 'Based on Bayesâ€™ theorem, the posterior distribution is proportional to the
    product of the prior distribution and the likelihood function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè´å¶æ–¯å®šç†ï¼ŒåéªŒåˆ†å¸ƒä¸å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶å‡½æ•°çš„ä¹˜ç§¯æˆæ¯”ä¾‹ï¼š
- en: P(Î² | x, y) âˆ P(y|x, Î²)P(Î²)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: P(Î² | x, y) âˆ P(y|x, Î²)P(Î²)
- en: Note that we do not need to know the evidence term in the denominator when solving
    the optimal value of the parameter Î², since P(y|x) is totally independent of Î².
    As we gather more data and update our beliefs, the posterior distribution would
    often become more sharply peaked around the true parameter value, indicating an
    increased level of confidence.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œåœ¨æ±‚è§£å‚æ•° Î² çš„æœ€ä¼˜å€¼æ—¶ï¼Œæˆ‘ä»¬ä¸éœ€è¦çŸ¥é“åˆ†æ¯ä¸­çš„è¯æ®é¡¹ï¼Œå› ä¸º P(y|x) ä¸ Î² å®Œå…¨ç‹¬ç«‹ã€‚éšç€æˆ‘ä»¬æ”¶é›†æ›´å¤šæ•°æ®å¹¶æ›´æ–°æˆ‘ä»¬çš„ä¿¡å¿µï¼ŒåéªŒåˆ†å¸ƒé€šå¸¸ä¼šå›´ç»•çœŸå®å‚æ•°å€¼å˜å¾—æ›´åŠ å°–é”ï¼Œè¿™è¡¨æ˜ç½®ä¿¡åº¦æœ‰æ‰€æé«˜ã€‚
- en: However, when we need to know P(y|x) in order to calculate P(Î² | x, y), the
    task is not so straightforward since a closed-form solution may not be available,
    or the parameters are multi-dimensional and prohibit a direct calculation of nested
    integration. In such cases, we would often resort to numerical methods such as
    **Markov chain Monte Carlo** (**MCMC**) or approximate methods such as variational
    inference.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå½“æˆ‘ä»¬éœ€è¦çŸ¥é“ P(y|x) ä»¥è®¡ç®— P(Î² | x, y) æ—¶ï¼Œä»»åŠ¡å¹¶ä¸é‚£ä¹ˆç›´æ¥ï¼Œå› ä¸ºå¯èƒ½æ²¡æœ‰å°é—­å½¢å¼çš„è§£ï¼Œæˆ–è€…å‚æ•°æ˜¯å¤šç»´çš„ï¼Œè¿™é˜»æ­¢äº†ç›´æ¥è®¡ç®—åµŒå¥—ç§¯åˆ†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæ±‚åŠ©äºæ•°å€¼æ–¹æ³•ï¼Œå¦‚**é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›**ï¼ˆ**MCMC**ï¼‰æˆ–è¿‘ä¼¼æ–¹æ³•ï¼Œå¦‚å˜åˆ†æ¨æ–­ã€‚
- en: Let us go through an exercise to understand the overall inference process. We
    will use the `rjags` package to do the calculations based on our running example.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç»ƒä¹ æ¥äº†è§£æ•´ä½“æ¨ç†è¿‡ç¨‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `rjags` åŒ…æ ¹æ®æˆ‘ä»¬çš„è¿è¡Œç¤ºä¾‹è¿›è¡Œè®¡ç®—ã€‚
- en: Exercise 14.2 â€“ Obtaining the posterior distribution
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  14.2 â€“ è·å–åéªŒåˆ†å¸ƒ
- en: 'In this exercise, we will use the `rjags` package to perform Bayesian inference,
    including specifying the model architecture and obtaining the posterior distribution
    for the underlying parameter. Follow the next steps:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `rjags` åŒ…è¿›è¡Œè´å¶æ–¯æ¨ç†ï¼ŒåŒ…æ‹¬æŒ‡å®šæ¨¡å‹æ¶æ„å’Œè·å–æ½œåœ¨å‚æ•°çš„åéªŒåˆ†å¸ƒã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: 'We begin with defining the likelihood function as a binomial distribution (using
    `dbin`) with parameters `p` for the probability of success and `n` for the total
    number of samples. We will also, define the prior distribution for `p` as a beta
    distribution (using `dbeta`) with parameters `a` and `b`:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¼¼ç„¶å‡½æ•°ä¸ºä¸€ä¸ªäºŒé¡¹åˆ†å¸ƒï¼ˆä½¿ç”¨`dbin`ï¼‰ï¼Œå‚æ•°`p`ä»£è¡¨æˆåŠŸæ¦‚ç‡ï¼Œ`n`ä»£è¡¨æ ·æœ¬æ€»æ•°ã€‚æˆ‘ä»¬è¿˜å°†å®šä¹‰å‚æ•°`p`çš„å…ˆéªŒåˆ†å¸ƒä¸ºä¸€ä¸ªè´å¡”åˆ†å¸ƒï¼ˆä½¿ç”¨`dbeta`ï¼‰ï¼Œå‚æ•°ä¸º`a`å’Œ`b`ï¼š
- en: '[PRE11]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we specify `textConnection(bayes_model)` to pass the model specification
    string to `jags`. The data argument is a list specifying the observed data and
    the parameters for the prior distribution.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œæˆ‘ä»¬æŒ‡å®š`textConnection(bayes_model)`å°†æ¨¡å‹è§„èŒƒå­—ç¬¦ä¸²ä¼ é€’ç»™`jags`ã€‚æ•°æ®å‚æ•°æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‡å®šäº†è§‚å¯Ÿåˆ°çš„æ•°æ®å’Œå…ˆéªŒåˆ†å¸ƒçš„å‚æ•°ã€‚
- en: 'Next, we draw samples from the posterior distribution:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»åéªŒåˆ†å¸ƒä¸­æŠ½å–æ ·æœ¬ï¼š
- en: '[PRE12]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, the `coda.samples()` function is used to run MCMC simulations and draw
    samples of the parameter. The `n.iter` argument specifies the number of iterations
    for the MCMC simulation.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œä½¿ç”¨`coda.samples()`å‡½æ•°è¿è¡ŒMCMCæ¨¡æ‹Ÿå¹¶æŠ½å–å‚æ•°æ ·æœ¬ã€‚`n.iter`å‚æ•°æŒ‡å®šäº†MCMCæ¨¡æ‹Ÿçš„è¿­ä»£æ¬¡æ•°ã€‚
- en: 'Finally, we plot the posterior:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ç»˜åˆ¶åéªŒåˆ†å¸ƒå›¾ï¼š
- en: '[PRE13]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Running the preceding code will result in the output shown in *Figure 14**.5*:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‰é¢çš„ä»£ç å°†äº§ç”Ÿ*å›¾14.5*ä¸­æ˜¾ç¤ºçš„è¾“å‡ºï¼š
- en: '![Figure 14.5 â€“ Visualizing the posterior distribution for the underlying parameter
    (probability of success)](img/B18680_14_005.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.5 â€“ å¯è§†åŒ–åŸºç¡€å‚æ•°ï¼ˆæˆåŠŸæ¦‚ç‡ï¼‰çš„åéªŒåˆ†å¸ƒ](img/B18680_14_005.jpg)'
- en: Figure 14.5 â€“ Visualizing the posterior distribution for the underlying parameter
    (probability of success)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.5 â€“ å¯è§†åŒ–åŸºç¡€å‚æ•°ï¼ˆæˆåŠŸæ¦‚ç‡ï¼‰çš„åéªŒåˆ†å¸ƒ
- en: In the next section, weâ€™ll dive deeper into Bayesian inference, starting by
    introducing the normal-normal model, a commonly used type of model in Bayesian
    inference.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ›´æ·±å…¥åœ°æ¢è®¨è´å¶æ–¯æ¨ç†ï¼Œé¦–å…ˆä»‹ç»æ­£æ€-æ­£æ€æ¨¡å‹ï¼Œè¿™æ˜¯è´å¶æ–¯æ¨ç†ä¸­å¸¸ç”¨çš„ä¸€ç§æ¨¡å‹ç±»å‹ã€‚
- en: Diving deeper into Bayesian inference
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ·±å…¥è´å¶æ–¯æ¨ç†
- en: Bayesian inference is a statistical method that makes use of conditional probability
    to update the prior beliefs about the parameters of a statistical model given
    the observed data. The output of Bayesian inference is a posterior distribution,
    which is a probability distribution that represents our updated beliefs about
    the parameter after observing the data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è´å¶æ–¯æ¨ç†æ˜¯ä¸€ç§ç»Ÿè®¡æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨æ¡ä»¶æ¦‚ç‡æ¥æ›´æ–°å…³äºç»Ÿè®¡æ¨¡å‹å‚æ•°çš„å…ˆéªŒä¿¡å¿µï¼ŒåŸºäºè§‚å¯Ÿåˆ°çš„æ•°æ®ã€‚è´å¶æ–¯æ¨ç†çš„è¾“å‡ºæ˜¯ä¸€ä¸ªåéªŒåˆ†å¸ƒï¼Œå®ƒè¡¨ç¤ºæˆ‘ä»¬åœ¨è§‚å¯Ÿæ•°æ®åå¯¹å‚æ•°æ›´æ–°çš„ä¿¡å¿µã€‚
- en: When calculating the exact posterior distribution is difficult, we would often
    resort to MCMC, which is a technique for estimating the distribution of a random
    variable. Itâ€™s a method commonly used to generate samples from the posterior distribution
    in Bayesian inference, especially when the dimensionality of the model parameters
    is high, making an analytical solution intractable.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è®¡ç®—ç²¾ç¡®çš„åéªŒåˆ†å¸ƒå¾ˆå›°éš¾æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæ±‚åŠ©äºMCMCï¼Œè¿™æ˜¯ä¸€ç§ä¼°è®¡éšæœºå˜é‡åˆ†å¸ƒçš„æŠ€æœ¯ã€‚å®ƒæ˜¯è´å¶æ–¯æ¨ç†ä¸­ä»åéªŒåˆ†å¸ƒä¸­ç”Ÿæˆæ ·æœ¬çš„å¸¸ç”¨æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡å‹å‚æ•°çš„ç»´åº¦å¾ˆé«˜æ—¶ï¼Œä½¿å¾—è§£æè§£å˜å¾—ä¸å¯è¡Œã€‚
- en: The following section introduces the normal-normal model and uses MCMC to estimate
    its posterior distribution.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ­£æ€-æ­£æ€æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨MCMCæ¥ä¼°è®¡å…¶åéªŒåˆ†å¸ƒã€‚
- en: Introducing the normal-normal model
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»æ­£æ€-æ­£æ€æ¨¡å‹
- en: The normal-normal model is another foundational model in Bayesian inference.
    It refers to the case when the likelihood is normally distributed and the prior
    is also normally distributed, both following a bell-shaped curve. This type of
    model is often used in Bayesian statistics as it has a closed-form solution for
    the posterior distribution, which also happens to be normally distributed.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£æ€-æ­£æ€æ¨¡å‹æ˜¯è´å¶æ–¯æ¨ç†ä¸­çš„å¦ä¸€ä¸ªåŸºç¡€æ¨¡å‹ã€‚å®ƒæŒ‡çš„æ˜¯å½“ä¼¼ç„¶å‡½æ•°å’Œå…ˆéªŒåˆ†å¸ƒéƒ½æ˜¯æ­£æ€åˆ†å¸ƒï¼Œä¸”éƒ½éµå¾ªé’Ÿå½¢æ›²çº¿çš„æƒ…å†µã€‚è¿™ç±»æ¨¡å‹åœ¨è´å¶æ–¯ç»Ÿè®¡ä¸­ç»å¸¸è¢«ä½¿ç”¨ï¼Œå› ä¸ºå®ƒå¯¹åéªŒåˆ†å¸ƒæœ‰å°é—­å½¢å¼çš„è§£ï¼Œè€Œè¿™ä¸ªè§£æ°å¥½ä¹Ÿæ˜¯æ­£æ€åˆ†å¸ƒã€‚
- en: Let us look at a concrete exercise of the normal-normal model using MCMC-based
    Bayesian inference.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªåŸºäºMCMCçš„è´å¶æ–¯æ¨ç†çš„normal-normalæ¨¡å‹çš„å…·ä½“ç»ƒä¹ æ¥è§‚å¯Ÿã€‚
- en: Exercise 14.3 â€“ Working with the normal-normal model
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 14.3 â€“ ä½¿ç”¨æ­£æ€-æ­£æ€æ¨¡å‹
- en: 'In this exercise, we will define a normal likelihood function whose mean follows
    a normal prior and whose standard deviation follows a uniform prior. We will then
    use `rjags` to obtain the posterior estimates for the mean and the standard deviation.
    Follow the next steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªæ­£æ€ä¼¼ç„¶å‡½æ•°ï¼Œå…¶å‡å€¼éµå¾ªæ­£æ€å…ˆéªŒåˆ†å¸ƒï¼Œè€Œæ ‡å‡†å·®éµå¾ªå‡åŒ€å…ˆéªŒåˆ†å¸ƒã€‚ç„¶åæˆ‘ä»¬å°†ä½¿ç”¨`rjags`æ¥è·å–å‡å€¼å’Œæ ‡å‡†å·®çš„åéªŒä¼°è®¡ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
- en: 'Letâ€™s start with simulating 100 data points that follow a normal distribution
    with a true mean of `2` and a true standard deviation of `1`:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ¨¡æ‹Ÿ100ä¸ªéµå¾ªå…·æœ‰çœŸå®å‡å€¼`2`å’ŒçœŸå®æ ‡å‡†å·®`1`çš„æ­£æ€åˆ†å¸ƒçš„æ•°æ®ç‚¹å¼€å§‹ï¼š
- en: '[PRE14]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we specify the model architecture, including a normal likelihood function
    for the data, a normal prior distribution for the mean variable, and a uniform
    prior for the standard deviation variable. The normal prior is parameterized by
    `0` and `0.1` for the mean and standard deviation, respectively, and the uniform
    prior ranges from `0` to `10`:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æŒ‡å®šæ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬æ•°æ®çš„ä¸€ä¸ªæ­£æ€ä¼¼ç„¶å‡½æ•°ã€å‡å€¼å˜é‡çš„æ­£æ€å…ˆéªŒåˆ†å¸ƒå’Œæ ‡å‡†å·®å˜é‡çš„å‡åŒ€å…ˆéªŒã€‚æ­£æ€å…ˆéªŒç”±`0`å’Œ`0.1`åˆ†åˆ«å‚æ•°åŒ–å‡å€¼å’Œæ ‡å‡†å·®ï¼Œè€Œå‡åŒ€å…ˆéªŒçš„èŒƒå›´ä»`0`åˆ°`10`ï¼š
- en: '[PRE15]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding model states that each observation in our data (`y[i]`) follows
    a normal distribution with mean `mu` and precision, `prec`, (defined as the reciprocal
    of the variance, hence `prec <- pow(sigma, -2)`). The mean `mu` follows a normal
    distribution with mean `0` and precision close to `0`, which corresponds to a
    relatively large variance and, therefore, a weak prior belief about `mu`. The
    standard deviation, `sigma`, follows a uniform distribution from `0` to `10`,
    which expresses complete uncertainty about its value between these two bounds.
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å‰é¢çš„æ¨¡å‹è¡¨æ˜ï¼Œæˆ‘ä»¬æ•°æ®ä¸­çš„æ¯ä¸ªè§‚æµ‹å€¼ï¼ˆ`y[i]`ï¼‰éµå¾ªä¸€ä¸ªå…·æœ‰å‡å€¼`mu`å’Œç²¾åº¦`prec`çš„æ­£æ€åˆ†å¸ƒï¼ˆå®šä¹‰ä¸ºæ–¹å·®çš„å€’æ•°ï¼Œå› æ­¤`prec <- pow(sigma,
    -2)`ï¼‰ã€‚å‡å€¼`mu`éµå¾ªä¸€ä¸ªå…·æœ‰å‡å€¼`0`å’Œæ¥è¿‘`0`çš„ç²¾åº¦çš„æ­£æ€åˆ†å¸ƒï¼Œè¿™å¯¹åº”äºç›¸å¯¹è¾ƒå¤§çš„æ–¹å·®ï¼Œå› æ­¤å¯¹`mu`çš„å…ˆéªŒä¿¡å¿µè¾ƒå¼±ã€‚æ ‡å‡†å·®`sigma`éµå¾ªä¸€ä¸ªä»`0`åˆ°`10`çš„å‡åŒ€åˆ†å¸ƒï¼Œè¿™è¡¨è¾¾äº†åœ¨è¿™ä¸¤ä¸ªç•Œé™ä¹‹é—´å¯¹å…¶å€¼çš„å®Œå…¨ä¸ç¡®å®šæ€§ã€‚
- en: 'Next, compile the model in `jags` and burn in the Markov chain, as follows:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œåœ¨`jags`ä¸­ç¼–è¯‘æ¨¡å‹å¹¶çƒ§å°½é©¬å°”å¯å¤«é“¾ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE16]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, the `burn-in` period is a number of initial iterations that we discard
    when performing Bayesian inference, under the assumption that the resulting chain
    may not have converged during this period. The idea is to let the Markov chain
    burn in until it reaches a distribution that is stable and reflective of the posterior
    distribution we are interested in. In this case, we would discard the first 1,000
    iterations of the Markov chain, and these are not used in the subsequent analysis.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`burn-in`æœŸæ˜¯ä¸€ç³»åˆ—åˆå§‹è¿­ä»£æ¬¡æ•°ï¼Œæˆ‘ä»¬åœ¨è¿›è¡Œè´å¶æ–¯æ¨ç†æ—¶å°†å…¶ä¸¢å¼ƒï¼Œå‡è®¾åœ¨æ­¤æœŸé—´äº§ç”Ÿçš„é“¾å¯èƒ½æ²¡æœ‰æ”¶æ•›ã€‚æƒ³æ³•æ˜¯è®©é©¬å°”å¯å¤«é“¾çƒ§å°½ï¼Œç›´åˆ°å®ƒè¾¾åˆ°ä¸€ä¸ªç¨³å®šä¸”èƒ½åæ˜ æˆ‘ä»¬æ„Ÿå…´è¶£çš„åç»­åˆ†å¸ƒçš„åˆ†å¸ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä¸¢å¼ƒé©¬å°”å¯å¤«é“¾çš„å‰1,000æ¬¡è¿­ä»£ï¼Œè¿™äº›è¿­ä»£åœ¨åç»­åˆ†æä¸­ä¸è¢«ä½¿ç”¨ã€‚
- en: 'Here, we generate samples from the posterior distribution:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»åéªŒåˆ†å¸ƒä¸­ç”Ÿæˆæ ·æœ¬ï¼š
- en: '[PRE17]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, the `summary()` function provides useful summary statistics for the posterior
    samples of `mu` and `sigma`, including their means, medians, and credible intervals.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`summary()`å‡½æ•°ä¸º`mu`å’Œ`sigma`çš„åéªŒæ ·æœ¬æä¾›äº†æœ‰ç”¨çš„æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®ƒä»¬çš„å‡å€¼ã€ä¸­ä½æ•°å’Œå¯ä¿¡åŒºé—´ã€‚
- en: 'Finally, letâ€™s visualize the results by running the following command:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œé€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¯è§†åŒ–ç»“æœï¼š
- en: '[PRE18]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Running the preceding line of code will generate the output shown in *Figure
    14**.6*, which shows trace plots and density plots for the posterior samples of
    `mu` and `sigma`:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‰é¢çš„ä»£ç è¡Œå°†ç”Ÿæˆå¦‚*å›¾14*.6æ‰€ç¤ºçš„è¾“å‡ºï¼Œè¯¥å›¾æ˜¾ç¤ºäº†`mu`å’Œ`sigma`çš„åéªŒæ ·æœ¬çš„è½¨è¿¹å›¾å’Œå¯†åº¦å›¾ï¼š
- en: '![Figure 14.6 â€“ Visualizing the trace plots and density plots for the posterior
    samples](img/B18680_14_006.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.6 â€“ å¯è§†åŒ–åéªŒæ ·æœ¬çš„è½¨è¿¹å›¾å’Œå¯†åº¦å›¾](img/B18680_14_006.jpg)'
- en: Figure 14.6 â€“ Visualizing the trace plots and density plots for the posterior
    samples
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.6 â€“ å¯è§†åŒ–åéªŒæ ·æœ¬çš„è½¨è¿¹å›¾å’Œå¯†åº¦å›¾
- en: In the next section, we will discuss more on the MCMC.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥è®¨è®ºMCMCã€‚
- en: Introducing MCMC
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»MCMC
- en: A Markov chain is a mathematical model that transits from one state to another
    within a finite or countable number of possible states. It is a sequence of random
    variables where the future state depends only on the present state and not on
    the sequence of events before it. This property is known as the **Markov property**,
    or **memorylessness**.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: é©¬å°”å¯å¤«é“¾æ˜¯ä¸€ä¸ªæ•°å­¦æ¨¡å‹ï¼Œåœ¨æœ‰é™æˆ–å¯æ•°çš„å¯èƒ½çŠ¶æ€ä¹‹é—´ä»ä¸€ä¸ªçŠ¶æ€è¿‡æ¸¡åˆ°å¦ä¸€ä¸ªçŠ¶æ€ã€‚å®ƒæ˜¯ä¸€ç³»åˆ—éšæœºå˜é‡ï¼Œå…¶ä¸­æœªæ¥çš„çŠ¶æ€åªå–å†³äºå½“å‰çŠ¶æ€ï¼Œè€Œä¸å–å†³äºå®ƒä¹‹å‰çš„äº‹ä»¶åºåˆ—ã€‚è¿™ä¸ªç‰¹æ€§è¢«ç§°ä¸º**é©¬å°”å¯å¤«æ€§è´¨**ï¼Œæˆ–**æ— è®°å¿†æ€§**ã€‚
- en: In the context of statistical inference, we can sample from complex probability
    distributions and create models of sequence data via Monte Carlo simulations,
    and thus the term MCMC. MCMC algorithms construct a Markov chain of parameter
    values where the stationary distribution of the chain is the posterior distribution
    of the underlying parameters. The chain is generated by iteratively proposing
    new parameter values and accepting or rejecting these candidate values based on
    a preset rule, ensuring that the samples converge to the posterior distribution.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»Ÿè®¡æ¨æ–­çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä»å¤æ‚çš„æ¦‚ç‡åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ï¼Œå¹¶é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿåˆ›å»ºåºåˆ—æ•°æ®çš„æ¨¡å‹ï¼Œå› æ­¤æœ¯è¯­ MCMCã€‚MCMC ç®—æ³•æ„å»ºå‚æ•°å€¼çš„é©¬å°”å¯å¤«é“¾ï¼Œå…¶ä¸­é“¾çš„å¹³ç¨³åˆ†å¸ƒæ˜¯æ½œåœ¨å‚æ•°çš„åéªŒåˆ†å¸ƒã€‚é“¾æ˜¯é€šè¿‡è¿­ä»£æå‡ºæ–°çš„å‚æ•°å€¼å¹¶æ ¹æ®é¢„è®¾è§„åˆ™æ¥å—æˆ–æ‹’ç»è¿™äº›å€™é€‰å€¼æ¥ç”Ÿæˆçš„ï¼Œç¡®ä¿æ ·æœ¬æ”¶æ•›åˆ°åéªŒåˆ†å¸ƒã€‚
- en: 'Let us analyze the details of the previous MCMC chain. In the following code
    snippet, we convert the chain to a DataFrame and print its first few rows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åˆ†æä¹‹å‰ MCMC é“¾çš„ç»†èŠ‚ã€‚åœ¨ä¸‹é¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæˆ‘ä»¬å°†é“¾è½¬æ¢ä¸º DataFrame å¹¶æ‰“å°å…¶å‰å‡ è¡Œï¼š
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'These are MCMC samples generated to approximate the posterior distribution
    for `mu` and `sigma`, respectively. Each sample depends on the previous sample
    only and is unrelated to other prior samples. We can plot these samples in a line
    plot called a trace plot, as shown in the following code snippet:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯ç”Ÿæˆä»¥è¿‘ä¼¼ `mu` å’Œ `sigma` çš„åéªŒåˆ†å¸ƒçš„ MCMC æ ·æœ¬ã€‚æ¯ä¸ªæ ·æœ¬ä»…ä¾èµ–äºå‰ä¸€ä¸ªæ ·æœ¬ï¼Œä¸å…¶ä»–å…ˆéªŒæ ·æœ¬æ— å…³ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ ·æœ¬ç»˜åˆ¶åœ¨ç§°ä¸ºè¿¹å›¾çš„çº¿å›¾ä¸­ï¼Œå¦‚ä¸‹ä»£ç ç‰‡æ®µæ‰€ç¤ºï¼š
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Running the preceding code generates the output shown in *Figure 14**.7*. A
    trace plot is a commonly used diagnostic tool in MCMC. It is a graphical representation
    of the values of the samples at each iteration or step of the MCMC algorithm.
    In this case, the trace plot shows no obvious trend, suggesting that both chains
    have converged stably:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œä¸Šè¿°ä»£ç ç”Ÿæˆ *å›¾ 14.7* ä¸­æ˜¾ç¤ºçš„è¾“å‡ºã€‚è¿¹å›¾æ˜¯ MCMC ä¸­å¸¸ç”¨çš„è¯Šæ–­å·¥å…·ã€‚å®ƒæ˜¯ MCMC ç®—æ³•æ¯æ¬¡è¿­ä»£æˆ–æ­¥éª¤ä¸­æ ·æœ¬å€¼çš„å›¾å½¢è¡¨ç¤ºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿¹å›¾æ²¡æœ‰æ˜æ˜¾çš„è¶‹åŠ¿ï¼Œè¡¨æ˜ä¸¤æ¡é“¾éƒ½ç¨³å®šæ”¶æ•›ï¼š
- en: '![Figure 14.7 â€“ Visualizing the trace plots of MCMC chains](img/B18680_14_007.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.7 â€“ æ˜¾ç¤º MCMC é“¾çš„è¿¹å›¾](img/B18680_14_007.jpg)'
- en: Figure 14.7 â€“ Visualizing the trace plots of MCMC chains
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.7 â€“ æ˜¾ç¤º MCMC é“¾çš„è¿¹å›¾
- en: 'Let us observe the first 100 samples using `ggplot()` for `mu`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ `ggplot()` è§‚å¯Ÿ `mu` çš„å‰ 100 ä¸ªæ ·æœ¬ï¼š
- en: '[PRE21]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Running the preceding code generates the output shown in *Figure 14**.8*. We
    can see that the sampler moves to another region after sufficiently exploring
    the previous region:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œä¸Šè¿°ä»£ç ç”Ÿæˆ *å›¾ 14.8* ä¸­æ˜¾ç¤ºçš„è¾“å‡ºã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°é‡‡æ ·å™¨åœ¨å……åˆ†æ¢ç´¢äº†å‰ä¸€ä¸ªåŒºåŸŸåç§»åŠ¨åˆ°äº†å¦ä¸€ä¸ªåŒºåŸŸï¼š
- en: '![Figure 14.8 â€“ Visualizing the first 100 iterations of the mu chain](img/B18680_14_008.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.8 â€“ æ˜¾ç¤º mu é“¾çš„å‰ 100 æ¬¡è¿­ä»£](img/B18680_14_008.jpg)'
- en: Figure 14.8 â€“ Visualizing the first 100 iterations of the mu chain
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.8 â€“ æ˜¾ç¤º mu é“¾çš„å‰ 100 æ¬¡è¿­ä»£
- en: 'Note that we can also display the density plot only by setting `trace = FALSE`,
    as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»…é€šè¿‡è®¾ç½® `trace = FALSE` æ¥æ˜¾ç¤ºå¯†åº¦å›¾ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE22]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code returns the output shown in *Figure 14**.9*:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ä»£ç è¿”å›äº† *å›¾ 14.9* ä¸­æ˜¾ç¤ºçš„è¾“å‡ºï¼š
- en: '![Figure 14.9 â€“ Visualizing the density plot of both chains](img/B18680_14_009.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.9 â€“ æ˜¾ç¤ºä¸¤æ¡é“¾çš„å¯†åº¦å›¾](img/B18680_14_009.jpg)'
- en: Figure 14.9 â€“ Visualizing the density plot of both chains
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.9 â€“ æ˜¾ç¤ºä¸¤æ¡é“¾çš„å¯†åº¦å›¾
- en: In practice, we would often run multiple chains in MCMC. This allows us to check
    whether all chains converge to the same distribution, which is a critical step
    to ensure that MCMC sampling is done correctly. Since each chain in MCMC starts
    at a different initial point, running multiple chains could help check whether
    the posterior distribution is dependent on the starting values. When all chains
    converge to the same distribution regardless of the initial points, we have a
    higher level of confidence in the stability and robustness of the MCMC process.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šè¿è¡Œå¤šä¸ª MCMC é“¾ã€‚è¿™å…è®¸æˆ‘ä»¬æ£€æŸ¥æ‰€æœ‰é“¾æ˜¯å¦æ”¶æ•›åˆ°ç›¸åŒçš„åˆ†å¸ƒï¼Œè¿™æ˜¯ç¡®ä¿ MCMC é‡‡æ ·æ­£ç¡®æ‰§è¡Œçš„å…³é”®æ­¥éª¤ã€‚ç”±äº MCMC ä¸­çš„æ¯ä¸ªé“¾éƒ½æ˜¯ä»ä¸åŒçš„åˆå§‹ç‚¹å¼€å§‹çš„ï¼Œè¿è¡Œå¤šä¸ªé“¾å¯ä»¥å¸®åŠ©æ£€æŸ¥åéªŒåˆ†å¸ƒæ˜¯å¦ä¾èµ–äºèµ·å§‹å€¼ã€‚å½“æ‰€æœ‰é“¾æ— è®ºåˆå§‹ç‚¹å¦‚ä½•éƒ½æ”¶æ•›åˆ°ç›¸åŒçš„åˆ†å¸ƒæ—¶ï¼Œæˆ‘ä»¬å¯¹
    MCMC è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œé²æ£’æ€§æœ‰æ›´é«˜çš„ä¿¡å¿ƒã€‚
- en: 'The following code snippet runs MCMC over four chains:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç ç‰‡æ®µåœ¨å››ä¸ªé“¾ä¸Šè¿è¡Œ MCMCï¼š
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can check the trace plot as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å¦‚ä¸‹æ£€æŸ¥è¿¹å›¾ï¼š
- en: '[PRE24]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As shown in *Figure 14**.10*, all four chains have more or less converged to
    a stable state:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ *å›¾ 14.10* æ‰€ç¤ºï¼Œæ‰€æœ‰å››ä¸ªé“¾æˆ–å¤šæˆ–å°‘éƒ½æ”¶æ•›åˆ°äº†ä¸€ä¸ªç¨³å®šçŠ¶æ€ï¼š
- en: '![Figure 14.10 â€“ Visualizing the density plot of both chains](img/B18680_14_010.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.10 â€“ å¯è§†åŒ–ä¸¤ä¸ªé“¾çš„å¯†åº¦å›¾](img/B18680_14_010.jpg)'
- en: Figure 14.10 â€“ Visualizing the density plot of both chains
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.10 â€“ å¯è§†åŒ–ä¸¤ä¸ªé“¾çš„å¯†åº¦å›¾
- en: 'Finally, we can check the summary of the MCMC samples, as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥MCMCæ ·æœ¬çš„æ‘˜è¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE25]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In the next section, we will cover the full Bayesian inference procedure, including
    quantifying the posterior uncertainty and making predictions based on the posterior
    distribution of the parameters.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å®Œæ•´çš„è´å¶æ–¯æ¨ç†è¿‡ç¨‹ï¼ŒåŒ…æ‹¬é‡åŒ–åéªŒä¸ç¡®å®šæ€§å’ŒåŸºäºå‚æ•°åéªŒåˆ†å¸ƒè¿›è¡Œé¢„æµ‹ã€‚
- en: The full Bayesian inference procedure
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„è´å¶æ–¯æ¨ç†è¿‡ç¨‹
- en: The full Bayesian inference starts by specifying the model architecture, including
    the prior distribution for unknown (unobserved) parameters and the likelihood
    function that determines how the data is generated. We can then perform MCMC to
    infer the posterior distribution of these parameters given the observed dataset.
    Finally, we can use the posterior distribution to either quantify the uncertainty
    about these parameters or make predictions for new input data with quantified
    uncertainty about the predictions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„è´å¶æ–¯æ¨ç†é¦–å…ˆéœ€è¦æŒ‡å®šæ¨¡å‹æ¶æ„ï¼ŒåŒ…æ‹¬æœªçŸ¥ï¼ˆæœªè§‚æµ‹ï¼‰å‚æ•°çš„å…ˆéªŒåˆ†å¸ƒä»¥åŠç¡®å®šæ•°æ®ç”Ÿæˆæ–¹å¼çš„ä¼¼ç„¶å‡½æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡ŒMCMCæ¥æ¨æ–­ç»™å®šè§‚æµ‹æ•°æ®é›†çš„è¿™äº›å‚æ•°çš„åéªŒåˆ†å¸ƒã€‚æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åéªŒåˆ†å¸ƒæ¥é‡åŒ–è¿™äº›å‚æ•°çš„ä¸ç¡®å®šæ€§ï¼Œæˆ–è€…å¯¹æ–°è¾“å…¥æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¹¶é‡åŒ–é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚
- en: The following exercise illustrates this process using the `mtcars` dataset.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ç»ƒä¹ ä½¿ç”¨ `mtcars` æ•°æ®é›†è¯´æ˜äº†è¿™ä¸ªè¿‡ç¨‹ã€‚
- en: Exercise 14.4 â€“ Performing full Bayesian inference
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  14.4 â€“ æ‰§è¡Œå®Œæ•´è´å¶æ–¯æ¨ç†
- en: 'In this exercise, we will perform Bayesian linear regression with a single
    feature and two unknown parameters: `intercept` and `slope`. The model looks at
    the relationship between car weight (`wt`) and horsepower (`hp`) in the `mtcars`
    dataset. Follow the next steps:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å•ä¸ªç‰¹å¾å’Œä¸¤ä¸ªæœªçŸ¥å‚æ•°ï¼ˆ`intercept` å’Œ `slope`ï¼‰æ‰§è¡Œè´å¶æ–¯çº¿æ€§å›å½’ã€‚è¯¥æ¨¡å‹ç ”ç©¶ `mtcars` æ•°æ®é›†ä¸­æ±½è½¦é‡é‡
    (`wt`) å’Œé©¬åŠ› (`hp`) ä¹‹é—´çš„å…³ç³»ã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: 'Specify a Bayesian inference model where each target `wt` is modeled as a realization
    of a random variable following a normal distribution. The `mean` parameter is
    a linear combination of two parameters (`a` for `intercept` and `b` for `slope`)
    with the corresponding input feature. Both `a` and `b` follow a normal distribution,
    and the `variance` parameter follows a uniform distribution. The code is illustrated
    in the following snippet:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‡å®šä¸€ä¸ªè´å¶æ–¯æ¨ç†æ¨¡å‹ï¼Œå…¶ä¸­æ¯ä¸ªç›®æ ‡ `wt` è¢«å»ºæ¨¡ä¸ºæœä»æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡çš„å®ç°ã€‚`mean` å‚æ•°æ˜¯ä¸¤ä¸ªå‚æ•°ï¼ˆ`a` ä¸º `intercept`ï¼Œ`b`
    ä¸º `slope`ï¼‰ä¸ç›¸åº”è¾“å…¥ç‰¹å¾çš„çº¿æ€§ç»„åˆã€‚`a` å’Œ `b` éƒ½æœä»æ­£æ€åˆ†å¸ƒï¼Œè€Œ `variance` å‚æ•°æœä»å‡åŒ€åˆ†å¸ƒã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†ä»£ç ï¼š
- en: '[PRE26]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Compile the model with three chains and control the random seed for model reproducibility:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸‰ä¸ªé“¾ç¼–è¯‘æ¨¡å‹ï¼Œå¹¶æ§åˆ¶éšæœºç§å­ä»¥å®ç°æ¨¡å‹çš„å¯é‡å¤æ€§ï¼š
- en: '[PRE27]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Run a burn-in period of `three` iterations:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿è¡Œ`ä¸‰æ¬¡`è¿­ä»£çš„é¢„çƒ­æœŸï¼š
- en: '[PRE28]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'MCMC samples from the posterior distribution of the parameters, as seen here:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‚æ•°åéªŒåˆ†å¸ƒçš„MCMCæ ·æœ¬ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š
- en: '[PRE29]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create a trace plot of the MCMC samples to assess convergence, as follows:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºMCMCæ ·æœ¬çš„è¿¹å›¾ä»¥è¯„ä¼°æ”¶æ•›æ€§ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE30]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Running the preceding code generates the output shown in *Figure 14**.11*,
    suggesting a decent convergence for all three parameters:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‰é¢çš„ä»£ç ç”Ÿæˆå¦‚å›¾ *14*.11 æ‰€ç¤ºçš„è¾“å‡ºï¼Œè¡¨æ˜æ‰€æœ‰ä¸‰ä¸ªå‚æ•°éƒ½æœ‰è‰¯å¥½çš„æ”¶æ•›æ€§ï¼š
- en: '![Figure 14.11 â€“ Visualizing the trace plots of all three parameters](img/B18680_14_011.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.11 â€“ å¯è§†åŒ–æ‰€æœ‰ä¸‰ä¸ªå‚æ•°çš„è¿¹å›¾](img/B18680_14_011.jpg)'
- en: Figure 14.11 â€“ Visualizing the trace plots of all three parameters
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 14.11 â€“ å¯è§†åŒ–æ‰€æœ‰ä¸‰ä¸ªå‚æ•°çš„è¿¹å›¾
- en: 'Calculate the mean of the posterior distributions for parameters `a` and `b`,
    and use these mean values to make point predictions and plot the prediction line
    on a scatterplot of the data, as follows:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—å‚æ•° `a` å’Œ `b` çš„åéªŒåˆ†å¸ƒçš„å‡å€¼ï¼Œå¹¶ä½¿ç”¨è¿™äº›å‡å€¼è¿›è¡Œç‚¹é¢„æµ‹ï¼Œå¹¶åœ¨æ•°æ®çš„æ•£ç‚¹å›¾ä¸Šç»˜åˆ¶é¢„æµ‹çº¿ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE31]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here, we use the mean of the posterior distribution as the parameter value
    to make a point prediction for each input feature. The commands generate the output
    shown in *Figure 14**.12*:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨åéªŒåˆ†å¸ƒçš„å‡å€¼ä½œä¸ºå‚æ•°å€¼ï¼Œå¯¹æ¯ä¸ªè¾“å…¥ç‰¹å¾è¿›è¡Œç‚¹é¢„æµ‹ã€‚ç”Ÿæˆçš„è¾“å‡ºå¦‚å›¾ *14*.12 æ‰€ç¤ºï¼š
- en: '![Figure 14.12 â€“ Making points predictions using the mean value of the posterior
    distributions for each parameter](img/B18680_14_012.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 14.12 â€“ ä½¿ç”¨æ¯ä¸ªå‚æ•°åéªŒåˆ†å¸ƒçš„å‡å€¼è¿›è¡Œç‚¹é¢„æµ‹](img/B18680_14_012.jpg)'
- en: Figure 14.12 â€“ Making points predictions using the mean value of the posterior
    distributions for each parameter
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.12 â€“ ä½¿ç”¨æ¯ä¸ªå‚æ•°çš„åéªŒåˆ†å¸ƒçš„å‡å€¼è¿›è¡Œç‚¹é¢„æµ‹
- en: It is worth noting that Bayesian linear regression offers quantified uncertainty
    compared to frequentist linear regression covered in previous chapters. Such uncertainty
    comes in the form of credible intervals, which differ from the confidence interval.
    Specifically, we obtain the credible interval by treating the parameter as a random
    variable and the data as a fixed quantity, which makes more sense as we only get
    to observe the data once in most cases.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸ä¹‹å‰ç« èŠ‚ä¸­ä»‹ç»çš„é¢‘ç‡ä¸»ä¹‰çº¿æ€§å›å½’ç›¸æ¯”ï¼Œè´å¶æ–¯çº¿æ€§å›å½’æä¾›äº†é‡åŒ–çš„ä¸ç¡®å®šæ€§ã€‚è¿™ç§ä¸ç¡®å®šæ€§ä»¥å¯ä¿¡åŒºé—´ï¼ˆcredible intervalsï¼‰çš„å½¢å¼å‡ºç°ï¼Œä¸ç½®ä¿¡åŒºé—´ä¸åŒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡å°†å‚æ•°è§†ä¸ºéšæœºå˜é‡ï¼Œå°†æ•°æ®è§†ä¸ºå›ºå®šé‡æ¥è·å¾—å¯ä¿¡åŒºé—´ï¼Œè¿™åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æˆ‘ä»¬åªèƒ½è§‚å¯Ÿä¸€æ¬¡æ•°æ®æ—¶æ›´æœ‰æ„ä¹‰ã€‚
- en: 'Compute the `a` and `b` using the `HPDinterval()` function and plot the confidence
    intervals in the histogram, as follows:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`HPDinterval()`å‡½æ•°è®¡ç®—`a`å’Œ`b`ï¼Œå¹¶åœ¨ç›´æ–¹å›¾ä¸­ç»˜åˆ¶ç½®ä¿¡åŒºé—´ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE32]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Running the commands generates the output shown in *Figure 14**.13*. Here,
    we calculate the 95% credible interval by default:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‘½ä»¤ç”Ÿæˆ*å›¾14.13*æ‰€ç¤ºçš„è¾“å‡ºã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é»˜è®¤è®¡ç®—95%çš„å¯ä¿¡åŒºé—´ï¼š
- en: '![Figure 14.13 â€“ Visualizing the posterior distribution and credible interval
    of the model parameters](img/B18680_14_013.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.13 â€“ å¯è§†åŒ–æ¨¡å‹å‚æ•°çš„åéªŒåˆ†å¸ƒå’Œå¯ä¿¡åŒºé—´](img/B18680_14_013.jpg)'
- en: Figure 14.13 â€“ Visualizing the posterior distribution and credible interval
    of the model parameters
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.13 â€“ å¯è§†åŒ–æ¨¡å‹å‚æ•°çš„åéªŒåˆ†å¸ƒå’Œå¯ä¿¡åŒºé—´
- en: 'Finally, make posterior predictions for a new input value, 120, and plot the
    posterior predictive distribution based on the list of posterior samples for the
    parameters, as follows:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¯¹æ–°è¾“å…¥å€¼120è¿›è¡ŒåéªŒé¢„æµ‹ï¼Œå¹¶åŸºäºå‚æ•°çš„åéªŒæ ·æœ¬åˆ—è¡¨ç»˜åˆ¶åéªŒé¢„æµ‹åˆ†å¸ƒï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE33]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Running the commands generates the output shown in *Figure 14**.14*. This posterior
    predictive distribution captures the modelâ€™s uncertainty about the prediction:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‘½ä»¤ç”Ÿæˆ*å›¾14.14*æ‰€ç¤ºçš„è¾“å‡ºã€‚æ­¤åçš„éªŒé¢„æµ‹åˆ†å¸ƒæ•æ‰äº†æ¨¡å‹å¯¹é¢„æµ‹çš„ä¸ç¡®å®šæ€§ï¼š
- en: '![Figure 14.14 â€“ Visualizing the posterior predictive distribution for a new
    input feature](img/B18680_14_014.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.14 â€“ å¯è§†åŒ–æ–°è¾“å…¥ç‰¹å¾çš„åéªŒé¢„æµ‹åˆ†å¸ƒ](img/B18680_14_014.jpg)'
- en: Figure 14.14 â€“ Visualizing the posterior predictive distribution for a new input
    feature
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.14 â€“ å¯è§†åŒ–æ–°è¾“å…¥ç‰¹å¾çš„åéªŒé¢„æµ‹åˆ†å¸ƒ
- en: The next section covers a Bayesian linear regression model using a categorical
    input variable.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€èŠ‚å°†ä»‹ç»ä½¿ç”¨åˆ†ç±»è¾“å…¥å˜é‡çš„è´å¶æ–¯çº¿æ€§å›å½’æ¨¡å‹ã€‚
- en: Bayesian linear regression with a categorical variable
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¸¦æœ‰åˆ†ç±»å˜é‡çš„è´å¶æ–¯çº¿æ€§å›å½’
- en: When the predictor is categorical, such as a binary feature, we would set one
    parameter for each corresponding category. The following exercise demonstrates
    such an example.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å½“é¢„æµ‹å˜é‡æ˜¯åˆ†ç±»å˜é‡ï¼Œä¾‹å¦‚äºŒå…ƒç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬ä¼šå¯¹æ¯ä¸ªå¯¹åº”çš„ç±»åˆ«è®¾ç½®ä¸€ä¸ªå‚æ•°ã€‚ä»¥ä¸‹ç»ƒä¹ æ¼”ç¤ºäº†è¿™æ ·ä¸€ä¸ªä¾‹å­ã€‚
- en: Exercise 14.5 â€“ Performing Bayesian inference with a categorical variable
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 14.5 â€“ ä½¿ç”¨åˆ†ç±»å˜é‡è¿›è¡Œè´å¶æ–¯æ¨ç†
- en: 'In this exercise, we will examine the relationship between `am` (automatic
    or manual transmission, a categorical variable) and `mpg` (miles per gallon, a
    continuous variable). We will define the mean of the normal likelihood for `mpg`
    as a function of `am`, with a different mean `mu[i]` for each level of `am`. Weâ€™ll
    also give `mu` a normal prior and standard deviation `s` a uniform prior. Follow
    the next steps:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥`am`ï¼ˆè‡ªåŠ¨æˆ–æ‰‹åŠ¨å˜é€Ÿï¼Œä¸€ä¸ªåˆ†ç±»å˜é‡ï¼‰ä¸`mpg`ï¼ˆæ¯åŠ ä»‘è‹±é‡Œæ•°ï¼Œä¸€ä¸ªè¿ç»­å˜é‡ï¼‰ä¹‹é—´çš„å…³ç³»ã€‚æˆ‘ä»¬å°†å®šä¹‰`mpg`çš„æ­£æ€ä¼¼ç„¶å‡å€¼ä½œä¸º`am`çš„å‡½æ•°ï¼Œæ¯ä¸ª`am`çº§åˆ«æœ‰ä¸åŒçš„å‡å€¼`mu[i]`ã€‚æˆ‘ä»¬è¿˜å°†ç»™`mu`ä¸€ä¸ªæ­£æ€å…ˆéªŒï¼Œç»™æ ‡å‡†å·®`s`ä¸€ä¸ªå‡åŒ€å…ˆéªŒã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: 'Specify the aforementioned model architecture, as follows:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰ç…§ä»¥ä¸‹æ–¹å¼æŒ‡å®šä¸Šè¿°æ¨¡å‹æ¶æ„ï¼š
- en: '[PRE34]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Compile the model, generate the posterior samples, and show the convergence
    plots:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¼–è¯‘æ¨¡å‹ï¼Œç”ŸæˆåéªŒæ ·æœ¬ï¼Œå¹¶æ˜¾ç¤ºæ”¶æ•›å›¾ï¼š
- en: '[PRE35]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Running the preceding code generates the output shown in *Figure 14**.15*,
    suggesting a decent convergence of all model parameters:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿è¡Œå‰é¢çš„ä»£ç ç”Ÿæˆ*å›¾14.15*æ‰€ç¤ºçš„è¾“å‡ºï¼Œè¡¨æ˜æ‰€æœ‰æ¨¡å‹å‚æ•°çš„æ”¶æ•›æ€§è‰¯å¥½ï¼š
- en: '![Figure 14.15 â€“ Visualizing the convergence plots](img/B18680_14_015.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.15 â€“ å¯è§†åŒ–æ”¶æ•›å›¾](img/B18680_14_015.jpg)'
- en: Figure 14.15 â€“ Visualizing the convergence plots
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.15 â€“ å¯è§†åŒ–æ”¶æ•›å›¾
- en: 'Plot the distribution of the dataset along with the mean estimate of parameters
    for both levels of the categorical variable, as follows:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰ç…§ä»¥ä¸‹æ–¹å¼ç»˜åˆ¶æ•°æ®é›†çš„åˆ†å¸ƒä»¥åŠåˆ†ç±»å˜é‡ä¸¤ä¸ªçº§åˆ«çš„å‚æ•°å‡å€¼ä¼°è®¡ï¼š
- en: '[PRE36]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The preceding code will generate the output shown in *Figure 14**.16*:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ä»£ç å°†ç”Ÿæˆ*å›¾14.16*ä¸­æ‰€ç¤ºçš„ç»“æœï¼š
- en: '![Figure 14.16 â€“ Visualizing the distribution and the mean estimates of the
    dataset](img/B18680_14_016.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾14.16 â€“ å¯è§†åŒ–æ•°æ®é›†çš„åˆ†å¸ƒå’Œå‡å€¼ä¼°è®¡](img/B18680_14_016.jpg)'
- en: Figure 14.16 â€“ Visualizing the distribution and the mean estimates of the dataset
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14.16 â€“ å¯è§†åŒ–æ•°æ®é›†çš„åˆ†å¸ƒå’Œå‡å€¼ä¼°è®¡
- en: Summary
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: This chapter provides a comprehensive introduction to Bayesian statistics, beginning
    with an exploration of the fundamental Bayesâ€™ theorem. We delved into its components,
    starting with understanding the generative model, which helps us simulate data
    and examine how changes in parameters affect the data generation process.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å…¨é¢ä»‹ç»äº†è´å¶æ–¯ç»Ÿè®¡ï¼Œä»å¯¹è´å¶æ–¯å®šç†çš„åŸºæœ¬æ¢è®¨å¼€å§‹ã€‚æˆ‘ä»¬æ·±å…¥ç ”ç©¶äº†å…¶ç»„æˆéƒ¨åˆ†ï¼Œä»ç†è§£ç”Ÿæˆæ¨¡å‹å¼€å§‹ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ¨¡æ‹Ÿæ•°æ®å¹¶æ£€æŸ¥å‚æ•°å˜åŒ–å¦‚ä½•å½±å“æ•°æ®ç”Ÿæˆè¿‡ç¨‹ã€‚
- en: We then focused on understanding the prior distribution, an essential part of
    Bayesian statistics that represents our prior knowledge about an uncertain parameter.
    This was followed by an introduction to the likelihood function, a statistical
    function that determines how likely it is for a set of observations to occur given
    specific parameter values.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä¸“æ³¨äºç†è§£å…ˆéªŒåˆ†å¸ƒï¼Œè¿™æ˜¯è´å¶æ–¯ç»Ÿè®¡çš„ä¸€ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œå®ƒä»£è¡¨äº†æˆ‘ä»¬å¯¹äºä¸€ä¸ªä¸ç¡®å®šå‚æ•°çš„å…ˆéªŒçŸ¥è¯†ã€‚éšåï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¼¼ç„¶å‡½æ•°ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿè®¡å‡½æ•°ï¼Œå®ƒå†³å®šäº†åœ¨ç»™å®šçš„å‚æ•°å€¼ä¸‹ï¼Œä¸€ç»„è§‚æµ‹å€¼å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚
- en: Next, we introduced the concept of the posterior model. This combines our prior
    distribution and likelihood to give a new probability distribution that represents
    updated beliefs after having seen the data. We also explored more complex models,
    such as the normal-normal model, wherein both the likelihood and the prior are
    normally distributed. We further investigated the mechanics of Bayesian inference
    through the MCMC method, a powerful tool for estimating the distribution of parameters
    and making predictions. A detailed walk-through of the full Bayesian inference
    procedure accompanied this.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»‹ç»äº†åéªŒæ¨¡å‹çš„æ¦‚å¿µã€‚è¿™ç»“åˆäº†æˆ‘ä»¬çš„å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶å‡½æ•°ï¼Œç»™å‡ºä¸€ä¸ªæ–°çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå®ƒä»£è¡¨äº†åœ¨çœ‹åˆ°æ•°æ®åçš„æ›´æ–°ä¿¡å¿µã€‚æˆ‘ä»¬è¿˜æ¢è®¨äº†æ›´å¤æ‚çš„æ¨¡å‹ï¼Œä¾‹å¦‚æ­£æ€-æ­£æ€æ¨¡å‹ï¼Œå…¶ä¸­ä¼¼ç„¶å’Œå…ˆéªŒéƒ½æ˜¯æ­£æ€åˆ†å¸ƒçš„ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡MCMCæ–¹æ³•ç ”ç©¶äº†è´å¶æ–¯æ¨ç†çš„æœºåˆ¶ï¼Œè¿™æ˜¯ä¸€ç§å¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºä¼°è®¡å‚æ•°åˆ†å¸ƒå’Œè¿›è¡Œé¢„æµ‹ã€‚å®Œæ•´çš„è´å¶æ–¯æ¨ç†è¿‡ç¨‹çš„è¯¦ç»†è¯´æ˜ä¼´éšç€è¿™ä¸€éƒ¨åˆ†ã€‚
- en: Lastly, we discussed Bayesian linear regression with a categorical variable,
    which extends the methodology to models that include categorical predictors.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å…·æœ‰åˆ†ç±»å˜é‡çš„è´å¶æ–¯çº¿æ€§å›å½’ï¼Œè¿™æ‰©å±•äº†æ–¹æ³•åˆ°åŒ…æ‹¬åˆ†ç±»é¢„æµ‹å› å­çš„æ¨¡å‹ã€‚
- en: Congratulations! Youâ€™ve successfully navigated to the end of this book, a testament
    to your dedication and effort. This journey, hopefully enriching for you and certainly
    so for me, marks a significant milestone in your ongoing exploration of the dynamic
    field of statistics and ML. Iâ€™m honored that you chose this book as a companion
    in this voyage, and I trust it has laid a solid foundation for your future pursuits.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼æ‚¨å·²æˆåŠŸåˆ°è¾¾æœ¬ä¹¦çš„ç»“å°¾ï¼Œè¿™æ˜¯æ‚¨å¥‰çŒ®å’ŒåŠªåŠ›çš„è¯æ˜ã€‚è¿™æ¬¡æ—…ç¨‹ï¼Œå¸Œæœ›å¯¹æ‚¨æ¥è¯´å¯Œæœ‰æˆæ•ˆï¼Œå¯¹æˆ‘è€Œè¨€å½“ç„¶ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œæ ‡å¿—ç€æ‚¨åœ¨åŠ¨æ€çš„ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ é¢†åŸŸæŒç»­æ¢ç´¢ä¸­çš„ä¸€ä¸ªé‡è¦é‡Œç¨‹ç¢‘ã€‚æˆ‘å¾ˆè£å¹¸æ‚¨é€‰æ‹©è¿™æœ¬ä¹¦ä½œä¸ºè¿™æ¬¡èˆªè¡Œçš„ä¼´ä¾£ï¼Œæˆ‘ç›¸ä¿¡å®ƒä¸ºæ‚¨çš„æœªæ¥è¿½æ±‚å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚
