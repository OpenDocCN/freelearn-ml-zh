- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Principles of Data-Centric ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn the key principles of data-centric ML. We’ll
    cover the foundational principles of data-centricity in this chapter to provide
    a high-level structure and framework to work through and refer to throughout the
    rest of this book. These principles will give you important context – or the *why*
    – before we dive into the specific techniques and approaches associated with each
    principle in the following chapters – or the *what*.
  prefs: []
  type: TYPE_NORMAL
- en: As you read through the principles, remember that data-centric ML is an extension
    – and not a replacement – of a model-centric approach. Essentially, model-centric
    and data-centric techniques work together to glean the most value from your efforts.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a good understanding of each of the
    principles and how they work together to form a framework for data-centricity.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Principle 1 – data should be the center of ML development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principle 2 – leverage annotators and **subject-matter experts** (**SMEs**)
    effectively
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principle 3 – use ML to improve your data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principle 4 – follow ethical, responsible, and well-governed ML practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, all you need is the right data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A few years ago, I (Jonas) was leading a team of data scientists tasked with
    an interesting but challenging problem. The financial services business we worked
    for attracted many new online visitors wanting to open new accounts with us through
    the company’s website. However, a significant number of potential customers couldn’t
    complete the account opening process for unknown reasons, which is why the company
    turned to its data scientists for help.
  prefs: []
  type: TYPE_NORMAL
- en: 'This problem of unopened accounts and lost customers was multifaceted, but
    we were determined to find every needle in the haystack. The account opening process
    was rather straightforward, designed to make it easy for someone to open a new
    account in less than 10 minutes with no support. For the customer, the steps were
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Enter personal details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify identity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Verify contact details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept the terms and conditions and open an account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process worked most of the time, but things were going wrong in *steps
    2* and *3* for a significant proportion of applicants. If someone’s identity couldn’t
    be verified online (*step 2*), the individual would have to be verified in person,
    which was an obvious detractor for many, and it caused a significant drop-off.
  prefs: []
  type: TYPE_NORMAL
- en: The problems arising in *step 3* were less obvious. About 10% of users would
    quit their journey at this point, even though most of the hard work had already
    been done. Why would someone go through this whole process and then decide not
    to proceed after all?
  prefs: []
  type: TYPE_NORMAL
- en: We collected all the relevant data points we could get our hands on, but unfortunately,
    we didn’t have a very deep dataset to work on because the account opening process
    was so simple and these were new customers. We profiled our dataset and used various
    supervised and unsupervised ML techniques to tease out any behaviors that correlated
    with accounts not opening, but nothing stuck out in our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: We decided to dig deeper. Since these clients shared their contact information,
    we could match their phone numbers with our phone call records and obtain the
    recorded conversations with matching phone numbers. We pulled out hundreds of
    call recordings and started listening in.
  prefs: []
  type: TYPE_NORMAL
- en: 'Soon after, a clear pattern emerged: “I clicked the **Verify contact details**
    button, but never received a verification code,” said one recorded caller. “I’ve
    waited for 10 minutes, but the code hasn’t come through yet,” said another. Users
    weren’t getting through because they weren’t sent the final verification code
    as a text message – even when it was resent by call center agents. But this wasn’t
    the case for all new users, so what was going wrong for this particular group?'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we continued to listen to call recordings, another faint signal emerged:
    “I shouldn’t have come back,” said one user. “Your systems haven’t gotten any
    better since the last time I was here,” said another.'
  prefs: []
  type: TYPE_NORMAL
- en: We had a look at closed customer accounts and sure enough, these people had
    been customers of ours in the past. The issue was simply that the enterprise system
    was treating these users as existing customers and therefore not sending out the
    required text messages, no matter how many times it was prompted by users or staff.
    The issue was occurring around 200 times a week, meaning the business was missing
    out on 10,000 new customers a year. Why didn’t anyone pick up on this issue earlier?
  prefs: []
  type: TYPE_NORMAL
- en: Only a proportion of the 200 occurrences would generate a call, and with hundreds
    of call center staff on duty throughout the week, it seemed like a rare glitch
    that only happened now and then. No one individual could see the issue because
    it was too infrequent and impossible for our models to flag. After all, the initial
    dataset had too much noise and not enough signal.
  prefs: []
  type: TYPE_NORMAL
- en: We only got to the bottom of it and found our needle in the haystack because
    we followed the four principles of data-centricity discussed in this chapter.
    Let’s explore each of these principles in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Principle 1 – data should be the center of ML development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we discussed in [*Chapter* *2*](B19297_02.xhtml#_idTextAnchor028)*, From
    Model-Centric to Data-Centric – ML’s Evolution,* the predominant model-centric
    approach is lacking in several ways: computing and storage have been commoditized,
    algorithms have become practically automated and highly data-dependent, models
    are accessible but less malleable, and deep learning and AutoML tools are available
    everywhere. But the data? Well, that’s still the wildcard.'
  prefs: []
  type: TYPE_NORMAL
- en: Rather than relying on powerful computing and storage environments and sophisticated
    algorithms that demand excess amounts of data to give us the incremental uplift
    in model accuracy, a better approach is to be driven by data – specifically, by
    the data that is available and relevant to the problem at hand.
  prefs: []
  type: TYPE_NORMAL
- en: Data is unique to every company, problem, and situation, and the data-centric
    paradigm recognizes this by putting the spotlight and development efforts on the
    data before the model. Data is no longer a static asset that can be collected
    at the beginning and forgotten about; it is now a unique commodity that needs
    to be leveraged to its full potential to make better predictions. We will argue
    that in many cases, a company’s proprietary data is its only truly unique competitive
    advantage – so long as it’s leveraged.
  prefs: []
  type: TYPE_NORMAL
- en: By focusing on the data, data-centricity helps companies distinguish themselves
    from their competitors. Most companies have access to the same algorithms and
    plenty of computing and storage, but the data they use and the insights they gain
    from that data can give them a decisive edge over the competition.
  prefs: []
  type: TYPE_NORMAL
- en: In our observation, focusing on data quality also brings substantial benefits
    to an organization besides getting better data. Focusing on data quality means
    going beyond simple data refinement because quality data is a critical component
    of business operations.
  prefs: []
  type: TYPE_NORMAL
- en: For data quality to improve, there is typically a need to digitize and automate
    processes and to create strong accountability for process adherence. Strong data
    governance processes will assign ownership, stewardship, and accountability for
    data quality, which, in turn, relies on data collection standards and processes
    to be followed, measured, and managed.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality is often a symptom of the quality of underlying processes and adherence
    to these processes. If an organization is good at collecting high-quality data,
    it is also likely to have good processes more generally. As companies improve
    data collection, they drive better accountability, accuracy, reliability, and
    overall consistency in their operations. Hence, focusing on data quality can have
    far-reaching consequences beyond improved data integrity and reliability. It is
    an essential driver of operational excellence.
  prefs: []
  type: TYPE_NORMAL
- en: If we think back to the example of missing verification codes discussed at the
    beginning of this chapter, no amount of model selection, parameter tuning, or
    feature engineering on the existing dataset would have revealed the root cause
    of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'This issue could only be discovered and solved by collecting the right data
    for the problem at hand. In this case, the missing data points were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Verification codes weren’t being received
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This was only the case for previous customers who returned to open a new account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discovery of the verification code issue resulted in two key changes to
    the way the business operated. Firstly, the IT department fixed the code responsible
    for triggering verification codes being sent, which, all else being equal, resulted
    in a substantial uplift in new account openings. Secondly, the call center team
    established a central process for logging client tech issues, no matter how small,
    so we could discover *the tip of the iceberg* of any new system issues. In other
    words, it was now accepted culture that collecting high-quality data is central
    to improving operational processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This was a mindset shift for frontline staff in two ways. Firstly, there was
    a newfound appreciation for data as a powerful asset that could be aggregated
    and analyzed to understand the bigger picture of their work. Secondly, frontline
    teams now felt empowered: if I do my bit to capture and call out important issues,
    there is a chance we can fix them.'
  prefs: []
  type: TYPE_NORMAL
- en: Our data scientists also gained a different appreciation for data collection
    and curation as a key part of *their* role. Seeing the impact they could have
    by walking in the shoes of customers and frontline staff created a profound shift
    in the way the team solved problems. Rather than accepting data (quality) as given,
    data engineering now permeated all steps of the model development and deployment
    process.
  prefs: []
  type: TYPE_NORMAL
- en: A checklist for data-centricity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To stay true to the first principle of data-centric ML, it is incredibly valuable
    to have a checklist of data-focused tasks to complete as you work through an ML
    project. Here is our checklist, spread across the five steps in the model development
    life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – identify the business problem, scope the project, and define the data
    needs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first part of any ML project should always be to clearly define the problem
    you’re trying to solve; this should be done in collaboration with key stakeholders
    such as end users and SMEs. Identifying data gaps will be a lot easier when you
    have a clear definition of the problem you’re solving, and what success looks
    like when the problem has been solved.
  prefs: []
  type: TYPE_NORMAL
- en: A strong modeling dataset contains both *content* and *context*. Content is
    a specific object, event, or status you’re measuring and context describes the
    circumstances in which the object, event, or status occurred. In our previous
    missing verification code example, the content is the *(missing) verification
    code* and the context is *for former,* *returning customers*.
  prefs: []
  type: TYPE_NORMAL
- en: A critical element in defining the project scope is outlining the process you’re
    trying to model. We do this by getting relevant end users and SMEs in a room with
    data scientists for as long as it takes to map out the process or situation underlying
    the business problem. This allows all participants to get a deep understanding
    of the content and context of the problem, while also identifying important data
    points needed for the model build.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a checklist of questions to consider during this step:'
  prefs: []
  type: TYPE_NORMAL
- en: Have we clearly defined the problem we’re trying to solve?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is it the right problem to solve in the first place?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What outcomes are we looking to achieve by solving the problem?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we mapped out the key parts of the problem with SMEs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the critical steps or moments in the process according to SMEs, and
    does our data capture these appropriately?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do our data points contain both *content* and *context*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What biases could arise from the solution that we need to look out for later?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will any groups or segments be treated unfairly as a result of these biases?
    How can we identify these during the validation phase (*step 4*)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is it legal and ethical to use all features in our dataset?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the outputs be internally or externally audited?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 2 – prepare and label data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For many data scientists, data preparation is a dreaded task. We certainly agree
    that data preparation can be both repetitive and time-consuming, but as proponents
    of data-centric ML, we encourage you to embrace it as the most important part
    of the job.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation involves collecting, cleaning, structuring, enhancing, and
    augmenting your input data to increase the signal and reduce noise in the dataset.
    These tasks can be both technically challenging and rewarding – especially when
    you start seeing those AUC scores increase. By now, you are aware that this part
    of the process is likely to give you very powerful modeling outcomes if you put
    in the right kind of effort.
  prefs: []
  type: TYPE_NORMAL
- en: The following checklist is useful for guiding you through the data preparation
    process. We will teach you how to do these tasks in plenty of detail throughout
    the rest of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the checklist questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Have we performed a technical validation of data quality? (See [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*,
    Techniques for* *Data Cleaning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we enhance the strength of our dataset by cleaning it? (See [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*,
    Techniques for* *Data Cleaning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we need to collect additional data or enhance the quality of the existing
    dataset using human labelers? (See [*Chapter 4*](B19297_04.xhtml#_idTextAnchor056)*,
    Data Labeling Is a* *Collaborative Process*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we need to define specific labeling rules and train SMEs? (See [*Chapter
    4*](B19297_04.xhtml#_idTextAnchor056)*, Data Labeling Is a* *Collaborative Process*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we improve data quality or impute missing values using programmatic labeling?
    (See [*Chapter 6*](B19297_06.xhtml#_idTextAnchor089)*, Techniques for Programmatic
    Labeling in* *Machine Learning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Should we use synthetic data to augment or enhance certain classes in the data?
    (See [*Chapter 7*](B19297_07.xhtml#_idTextAnchor111)*, Using Synthetic Data in
    Data-Centric* *Machine Learning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we need to preserve the privacy of individuals in the dataset? (See [*Chapter
    7*](B19297_07.xhtml#_idTextAnchor111)*, Using Synthetic Data in Data-Centric*
    *Machine Learning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does our dataset contain biased classes and do we need to adjust these? (See
    [*Chapter 8*](B19297_08.xhtml#_idTextAnchor125)*, Techniques for Identifying and*
    *Removing Bias*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does our dataset contain enough of the right kinds of rare events? Do we need
    to add more or remove outliers? (See [*Chapter 9*](B19297_09.xhtml#_idTextAnchor141)*,
    Dealing with Edge Cases and Rare Events in* *Machine Learning*.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we engineer new features from the existing dataset?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 3 – train the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model training phase is where data-centric and model-centric ML principles
    come together to create synergy. Again, it is important to highlight that you
    should not discard everything you already know about how to build and enhance
    ML models based on a model-centric approach. Data-centricity simply gives you
    an additional set of tools in your toolbox and allows you to amplify the impact
    of your models.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection is an important part of this synergistic process because it
    filters out features that aren’t useful (and in the worst case, problematic) for
    your model. Generally speaking, it is desirable to have fewer attributes contributing
    to your model because it reduces unwanted noise and makes the model easier to
    explain.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to consider feature selection as part of the model selection
    process because a model and its input data go hand in hand to produce predictions.
    They are intrinsically linked to each other. Practically speaking, this means
    you should pick the features *with* the model and not use a static dataset of
    pre-selected features to choose between models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the checklist questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Do you suspect your data to be dirty (for example, wrong labels, missing values,
    meaningless patterns, or irrelevant outputs)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we improve model accuracy by improving the quality of the dataset? The long
    list of data-centric techniques outlined in this book is designed to help you
    with this task!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do our engineered features suggest any relationships in the data that require
    us to collect additional data (features or observations)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do our (engineered) features suggest any relationships in the data that we should
    verify with SMEs? Rather than assuming our new features are correct, any influential
    correlations should be cross-checked with SMEs to ensure their relevance and validity
    within the context of the solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we reduce the number of features in our model without losing predictive
    power? By applying dimensionality reduction techniques or feature selection methods,
    we may be able to decrease the number of features in our model without significantly
    compromising its predictive accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 4 – evaluate performance, fairness, and bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data-centric approach to ML puts a strong emphasis on detecting bias and
    fairness issues during model evaluation. To validate the accuracy of an ML model,
    you should still start with traditional validation tasks such as splitting data
    into training and testing sets, performing cross-validation, and producing confusion
    matrices. The following checklist assumes that you will already be doing these
    tasks, using standard performance evaluation using metrics such as accuracy, precision,
    recall, F1 score, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Bias detection is an important tool for uncovering potential unfairness and
    discrimination in ML models. This can be done by creating confusion matrices for
    each subgroup separately to compare false positive and false negative rates across
    groups, and assessing demographic parity (equal representation) and equal opportunity
    (equal true positive rate) or equal odds (equal false positive rate) across groups.
    Disparities between subgroups, such as those related to gender or race, are common
    examples of sources of bias or unfairness.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the checklist questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Can we improve model performance by improving data quality or collecting new
    features?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can we detect any bias or unfairness toward particular groups or segments?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there any large correlations between sensitive attributes and predictions
    made by the model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does the model perform on unseen data concerning fairness and bias?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll cover techniques for identifying and removing bias in [*Chapter 8*](B19297_08.xhtml#_idTextAnchor125)*,
    Techniques for Identifying and* *Removing Bias*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – deploy and monitor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Effective monitoring of ML models also relies on data-centric principles. When
    monitoring model performance, it is important to include data quality, data coverage,
    data relevance, and labeling consistency metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality refers to the accuracy, completeness, and consistency of data,
    while data coverage refers to having enough data points to make confident predictions
    in the first place. Data relevance ensures that the data used to train the model
    is suitable for the task. Finally, data labeling consistency ensures that the
    data points used for training the model have correct labels.
  prefs: []
  type: TYPE_NORMAL
- en: Several techniques and tools can help data scientists monitor ML models effectively.
    For example, data drift detection helps detect changes in data characteristics,
    such as mean, variance, and distribution. Similarly, outlier detection helps identify
    data points that differ significantly from the common distribution. Also, bias
    detection techniques help identify and correct instances of bias in ML models.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to relying on reporting and metrics to monitor ML models, it is
    crucial to understand that monitoring is an ongoing process that requires the
    involvement of stakeholders beyond the data science team. Stakeholders may include
    SMEs, business owners, and end users. These stakeholders should collaborate to
    evaluate the model’s performance, interpret the results, and identify any issues
    that need to be addressed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the checklist questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Are the data sources used in the model automated, consistent, and reliable?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we designed a monitoring and reporting plan that captures failures, biases,
    and drift?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does our monitoring quantify data quality, data coverage, data relevance, and
    labeling consistency?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we set up a mechanism for end users to provide continuous feedback on model
    performance?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our checklist questions are designed to make you think about data quality, and
    the impacts thereof, at each step in the model development process. In other words,
    they are an addition to – and not a replacement for – more model-centric development
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Data-centricity requires a mindset shift from “I’ll build the best model with
    this data” to “How can we make the best dataset to solve this particular problem?”
    To do that, we need the whole organization involved in a coordinated effort. This
    brings us to the second principle of data-centric ML.
  prefs: []
  type: TYPE_NORMAL
- en: Principle 2 – leverage annotators and SMEs effectively
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No matter where we are in the AI hype cycle when you read this, it is unlikely
    that AI and ML development has evolved past the point where human input and labeling
    are needed.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, we have experienced a large increase in the sophistication
    of AI technologies, especially in the field of generative AI. Despite this, it
    remains a fact that even the most powerful and revolutionary AI technologies,
    such as ChatGPT, rely on small armies of human labelers to refine and advance
    their capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'These individuals review and annotate data samples, which are then fed back
    into the model to improve its understanding of natural language and context. Some
    of the key methodologies and techniques that are employed by human labelers include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Domain expertise**: Labelers with subject matter expertise can provide valuable
    insights and annotations that help the model better comprehend specific topics
    and domains.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Active learning**: This approach involves prioritizing data samples that
    the model finds ambiguous or challenging, enabling labelers to focus on areas
    where their input can have the greatest impact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diversity of perspectives**: By involving labelers from diverse backgrounds
    and with varied experiences, the model can be exposed to a broader range of linguistic
    nuances, cultural contexts, and perspectives, improving its overall performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality control**: Regular audits and evaluations of labeler output can help
    ensure consistent annotation quality and adherence to guidelines, which is essential
    for effective model training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In short, human annotators are integral to ML, and the quality of our models
    depends on our ability to train, organize, and collaborate with these annotators.
    Broadly speaking, there are three ways to leverage SMEs in the ML development
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: As direct labelers of data points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As verifiers of output quality and detectors of undesired outputs such as toxic
    content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As knowledge experts who can help us codify labeling rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging SMEs effectively requires a mindset shift from just creating labeling
    rules for annotators (although this is still important) to using the combined
    strengths of SMEs and data scientists to cover the problem space through well-defined
    labeling rules.
  prefs: []
  type: TYPE_NORMAL
- en: Our experience is that following this approach gives us much more than robust
    labeling functions. It helps us track down ambiguous examples and sharpen model
    performance, but just as importantly, it allows data scientists and SMEs to collaborate.
    As data scientists learn about the subject matter and SMEs learn how data science
    works, it creates a flywheel effect leading to new ideas, insights, and knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore each of the three human labeling approaches in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Direct labeling with human annotators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary benefit of human-annotated data is its accuracy. Humans can recognize
    patterns and subjectivity in ways that computers cannot. This means that the labels
    assigned to the data may be more accurate than those generated by automated processes.
    Additionally, humans can provide context to the data that would otherwise be lost
    in an automated process.
  prefs: []
  type: TYPE_NORMAL
- en: Human-annotated data also offers greater flexibility than automated processes.
    Annotators can customize their labeling process according to specific needs or
    requirements, allowing them to tailor the annotations to fit their project’s goals.
    This makes it easier for machines to interpret the data accurately and quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, human-annotated data can be cost-effective compared to other methods
    of labeling. This is mainly true when datasets are small- to medium-sized.
  prefs: []
  type: TYPE_NORMAL
- en: Small datasets might consist of a few hundred to a few thousand observations,
    often manageable by a small team of human annotators. Medium-sized datasets may
    have tens of thousands of observations. While still possible to manually label,
    the complexity and time required start to increase, making it less economically
    viable.
  prefs: []
  type: TYPE_NORMAL
- en: When faced with larger datasets, manual annotation can become repetitive and
    prone to mistakes due to the sheer volume and potential complexity of the data.
    At this scale, the intricacies in the data could also increase, requiring a more
    nuanced understanding that may be challenging for human annotators to maintain
    consistently.
  prefs: []
  type: TYPE_NORMAL
- en: For larger or more complex datasets, we recommend going down the path of programmatic
    labeling, which we’ll discuss next. Interestingly, a hybrid approach can also
    be effective, where a subset of the large dataset is manually labeled to serve
    as training data for the programmatic labeling algorithm. This way, you can leverage
    the accuracy of human annotation and the scalability of ML, ensuring high-quality
    labels, even for large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Think back to the story of the missing verification codes we outlined at the
    beginning of this chapter. Once we had isolated the phone calls that were related
    to the yet-to-be-discovered issue, we chose to manually listen to hundreds of
    calls rather than use ML techniques to pick up themes. Why?
  prefs: []
  type: TYPE_NORMAL
- en: Because we wanted to make sure we understood the *content* and the *context*
    of these interactions and a human was just more likely to do that job well. At
    the same time, we were only listening to a few hundred calls, not millions, so
    human annotation was the most cost-effective way to find the signal in the noise
    and pinpoint our needle-in-the-haystack issue.
  prefs: []
  type: TYPE_NORMAL
- en: While labeling by humans is an essential part of the data-centric approach,
    there are several pitfalls and mistakes to avoid when using human labelers. In
    [*Chapter 4*](B19297_04.xhtml#_idTextAnchor056), *Data Labeling Is a Collaborative
    Process*, we will teach you how to get the most out of SMEs and human annotators
    while managing the potential downsides.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying output quality with human annotators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, even very sophisticated AI solutions such as ChatGPT
    are heavily reliant on human annotators to guide algorithms to the optimal outcome.
    ChatGPT has been built on a mix of supervised learning and a technique called
    **reinforcement learning from human** **feedback** (**RLHF**).
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning is an area of ML where an agent learns to make decisions
    by interacting with an environment. The agent’s objective is to select actions
    that maximize the cumulative reward over time. However, defining a suitable reward
    function for complex tasks can be challenging.
  prefs: []
  type: TYPE_NORMAL
- en: That’s where human feedback comes into play. In RLHF, an AI agent learns from
    rewards and penalties provided by humans, rather than a predefined reward function.
    This approach combines the power of ML algorithms with the intuition, experience,
    and knowledge of human experts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The AI agent interacts with the environment and takes action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Human observers assess the agent’s actions and provide feedback in the form
    of rewards or penalties.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agent uses this feedback to update its learning and improve its decision-making
    over time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Through these interactions, the AI agent learns to perform complex tasks by
    incorporating human guidance.
  prefs: []
  type: TYPE_NORMAL
- en: There are several benefits to using RLHF. Primarily, human feedback allows the
    AI agent to learn from the wealth of knowledge and experience that humans possess.
    This approach enables agents to learn complex behaviors that may be difficult
    to achieve with traditional algorithms. At the same time, the learning process
    can be tailored to specific needs or goals by adjusting the feedback provided
    by human experts.
  prefs: []
  type: TYPE_NORMAL
- en: The drawbacks of having humans in the loop are that humans can make mistakes
    or provide inconsistent feedback, which may affect the agent’s learning. Furthermore,
    training an AI agent using human feedback can be a slow process, as it requires
    continuous input from human experts. In other words, it tends to be labor intensive
    and potentially costly as a result. For this reason, it’s important to develop
    an upfront estimate of the human and financial resources required for such a project
    to ensure its viability.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that SMEs can be incredibly valuable contributors to
    almost any ML exercise. For example, we often use SMEs to help us review the outputs
    of our models because it allows us to discover new contexts in the problem space
    that should become features in the training data.
  prefs: []
  type: TYPE_NORMAL
- en: In the example of missing verification codes, we discovered the root of the
    problem by first developing a deep knowledge of the specific failure point by
    interviewing call center staff (one type of SME) and listening to call recordings
    (becoming SMEs ourselves). Once we had narrowed down the possible issue, we dug
    into the inner workings of the core system with our colleagues from the IT department
    (another type of SME) to verify the glitch.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is not the same as reinforcement learning, but it highlights the
    value of involving SMEs throughout the whole development process, even if it requires
    manual input.
  prefs: []
  type: TYPE_NORMAL
- en: Codifying labeling rules with programmatic labeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The traditional method of labeling using human annotators is sometimes a bottleneck
    in the process that can prevent us from creating high-quality training sets in
    a way that is both efficient and cost-effective. This is typically an issue when
    we’re dealing with large datasets. Time- and cost-efficient training has become
    increasingly important as ML models become more complex and datasets become larger.
  prefs: []
  type: TYPE_NORMAL
- en: Enter programmatic labeling. At its core, programmatic labeling is a process
    of automatically assigning labels to data points based on predefined rules or
    algorithms. The main advantage of programmatic labeling over manual labeling is
    that it can be done much faster and more accurately than manual labeling – once
    there is a robust labeling function in place. This makes it ideal for large datasets
    where manual labeling would take too long or be too costly.
  prefs: []
  type: TYPE_NORMAL
- en: The process of programmatic labeling begins with defining the labels that need
    to be assigned to each data point. This can be done manually by SMEs or through
    automated methods such as **natural language processing** (**NLP**) algorithms
    or rule-based systems. Once the labels have been defined, they can then be applied
    to the data points using either supervised or unsupervised learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main benefits of programmatic labeling are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalability**: Programmatic labeling can handle large volumes of data more
    efficiently than manual labeling, enabling faster model training and iteration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency**: Automated labeling methods ensure a consistent application
    of rules and criteria across the entire dataset, reducing variability and potential
    errors that may arise from human subjectivity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-effectiveness**: By automating the labeling process, organizations can
    save on the time and resources required to train, manage, and compensate human
    labelers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Speed**: Programmatic labeling can process and annotate data much more quickly
    than manual labeling, accelerating the overall ML pipeline'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced human error**: Automation minimizes the risk of human error and inconsistencies
    that can be introduced during manual labeling'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reproducibility**: The automated labeling process is easily replicable, ensuring
    that results can be reproduced and verified across different datasets and projects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptability**: Programmatic labeling algorithms can be fine-tuned and updated
    as needed to accommodate changing requirements, new data sources, or evolving
    project goals'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**24/7 availability**: Unlike human labelers, programmatic labeling can operate
    continuously without breaks or downtime, allowing for uninterrupted progress in
    ML projects'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will show you how to use specific programmatic labeling techniques in [*Chapter
    6*](B19297_06.xhtml#_idTextAnchor089)*, Techniques for Programmatic Labeling in*
    *Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Programmatic labeling techniques are often all that’s required to lift the quality
    of your data. However, in some cases, relationships between features are too complex
    for rules-based algorithms to do the job. This brings us to the third principle
    of data-centric ML.
  prefs: []
  type: TYPE_NORMAL
- en: Principle 3 – use ML to improve your data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as we can use a programmatic or algorithmic approach to label our data,
    we can also use ML to identify data points that may be wrong or ambiguous. By
    leveraging developments in explainability, error analysis, and semi-supervised
    approaches, we can create new labels and find data points to improve or discard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some practical steps to generate better input data with ML:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Toss out noisy examples**: Sometimes, more data is not always better. Noisy
    data can lead to inaccurate predictions. By removing noisy examples, we can improve
    the quality of our input data. For instance, if you’re analyzing customer reviews
    and some reviews are filled with random characters or irrelevant information,
    those can be considered as “noisy” and removed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use techniques to focus on a subset of data to improve**: Not all data has
    the same value. We can focus on a subset of data to improve the quality of our
    input data. For example, if you’re analyzing sales data, you might focus on the
    subset of data from your most profitable region to get the most return on your
    efforts, all else being equal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expand available label data by leveraging ML generalization from expert input**:
    ML can be used to expand the available label data by using expert input to achieve
    similar precision and greater coverage. An expert in bird species, for example,
    could provide input on a limited set of images, and ML could use this to accurately
    label a larger set of images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use semi-supervised approaches**: Semi-supervised approaches, including weak
    learning and active learning, can be used to identify data points that require
    SME review. For example, you might use active learning to identify customer emails
    that need to be reviewed by a human for sentiment analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use explainability**: Explainability is essential in identifying patterns
    in data and ensuring that models make sense. Complex models require a model-specific
    or model-agnostic approach to explainability, including local and global methods
    and SHAP values. For example, using SHAP values can help you understand why your
    model predicted a certain outcome in a loan approval process, ensuring the decision-making
    is transparent and explainable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use error analysis**: Error analysis can help identify patterns in data where
    models are making mistakes, helping to improve the quality of our input data.
    For instance, if your model is incorrectly identifying cats as something else
    in image recognition, error analysis can help you figure out where and why it’s
    making these mistakes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The techniques required to perform these steps will be outlined throughout the
    subsequent chapters of this book.
  prefs: []
  type: TYPE_NORMAL
- en: By applying these steps in production, we can identify performance drifts in
    labeling functions or models. Additionally, we can identify data points that require
    human review, leading to better quality input data and improved prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The use of ML to improve input data quality is a fundamental shift in the traditional
    approach to ML. It requires a mindset shift from using ML models to make the best
    prediction to using ML to identify the data points that are not helping model
    performance. After all, the goal of data-centric ML is to increase signal and
    reduce noise in our input data.
  prefs: []
  type: TYPE_NORMAL
- en: Embracing a data-centric approach also provides us with a unique opportunity
    to collect and refine data in a manner that is inherently aligned with ethical,
    responsible, and well-governed ML practices. This shift in focus allows us to
    design our data strategies not just around performance enhancement but also around
    principles of fairness, transparency, and accountability.
  prefs: []
  type: TYPE_NORMAL
- en: As we proceed, we will explore how this approach can help us to embed ethics
    at the very core of our data collection and refinement processes. This way, we
    can ensure that improved data quality goes hand in hand with maintaining the integrity
    and trustworthiness of our ML applications.
  prefs: []
  type: TYPE_NORMAL
- en: Principle 4 – follow ethical, responsible, and well-governed ML practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ethical and responsible ML practices become increasingly important as data-centricity
    allows us to tackle more high-stakes challenges. This requires you to consider
    factors such as transparency, fairness, and accountability when designing algorithms
    so that they do not discriminate against certain groups or individuals. Additionally,
    those responsible for implementing these systems must be aware of how they work
    and understand their limitations so that they can make informed decisions about
    their use.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, ethical and responsible ML practices are generally not as developed
    as they should be. In 2021, the IBM Institute for Business Value and Oxford Economics
    conducted a study1 where 75% of executives ranked AI ethics as important; however,
    fewer than 20% of executives strongly agreed that their organizations’ practices
    aligned with their declared principles and values.
  prefs: []
  type: TYPE_NORMAL
- en: As practitioners of data-centric ML, we need to consider that the term *data
    quality* is much broader than the objective accuracy of individual data points.
    High-quality data should also allow us to identify and monitor potential ethical
    issues throughout the ML development process and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: AI ethics and responsibility is not just a tick-box exercise, but a potential
    source of differentiation. Organizations that pay attention to AI ethics are more
    likely to be trusted by their customers, while organizations that overlook it
    are likely to suffer customer backlash and reputational damage2.
  prefs: []
  type: TYPE_NORMAL
- en: The story of the UK’s 2020 *school grading fiasco* highlights what can happen
    when you ignore ethical considerations while using ML in high-stakes environments.
    During the COVID-19 pandemic, students across the UK were unable to sit their
    exams because of lockdowns. Instead, an algorithm was used to grade students’
    exam results, resulting in a significant number of students receiving lower grades
    than they deserved. This caused uproar among students, teachers, and the academic
    community as it was seen as unfair and unjust.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm used by Ofqual, the UK regulator responsible for regulating qualifications,
    exams, and assessments, was designed to standardize grades across different schools
    to make them comparable. It considered factors such as prior attainment and school
    performance. However, it did not consider individual student performance or teacher
    assessments, which resulted in many students receiving lower grades than they
    should have.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, the model favored students from private institutions and wealthy areas,
    significantly impacting high-performing individuals from public, state-funded
    schools. Consequently, numerous students lost their university admissions due
    to the lowered exam scores. This caused a great deal of distress among the students
    who had worked hard for their exams only to be let down by an algorithm that did
    not accurately reflect their abilities. In the end, the grades awarded by the
    algorithm were canceled, and replaced by a fairer but more manual grading approach.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid similar incidents such as the UK grading disaster from occurring in
    the future, AI systems must be designed with ethical considerations in mind from
    the outset. Overall, this incident highlights some of the ethical issues associated
    with AI systems and demonstrates why it is important for us to consider these
    issues when designing and implementing them. It also serves as a reminder that
    we must ensure these systems are transparent, fair, and accountable if we want
    them to be effective tools for decision-making in our society.
  prefs: []
  type: TYPE_NORMAL
- en: We will be discussing specific ways to deal with ambiguity in labeling in [*Chapter
    4*](B19297_04.xhtml#_idTextAnchor056)*, Data Labeling Is a Collaborative Process*
    and show you a range of techniques for identifying and removing bias in [*Chapter
    8*](B19297_08.xhtml#_idTextAnchor125)*, Techniques for Identifying and* *Removing
    Bias*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we outlined the four principles of data-centric ML. By following
    these principles, you will be able to create ML models that are based on high-quality
    data that has been enhanced, cross-checked, and verified by humans, labeling functions,
    and ML techniques.
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to get more signals out of our data, which, in turn, increases
    our ability to build powerful models on small or large datasets. Lastly, we can
    capture ethical considerations throughout the development life cycle, which ultimately
    ensures we’re using our powers for good.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore specific ways you can structure, optimize,
    and govern the process of using human annotators for your ML projects.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action](https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action),
    accessed on 1 June 2023'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/](https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/),
    accessed on 1 June 2023'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
