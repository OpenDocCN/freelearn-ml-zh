- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Principles of Data-Centric ML
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据中心化机器学习的原则
- en: In this chapter, you will learn the key principles of data-centric ML. We’ll
    cover the foundational principles of data-centricity in this chapter to provide
    a high-level structure and framework to work through and refer to throughout the
    rest of this book. These principles will give you important context – or the *why*
    – before we dive into the specific techniques and approaches associated with each
    principle in the following chapters – or the *what*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以数据为中心的机器学习的关键原则。我们将在本章中介绍数据中心化的基础原则，以提供一个高级结构和框架，供你在本书的其余部分进行工作并参考。这些原则将在我们深入探讨下一章中与每个原则相关的具体技术和方法之前——即“为什么”——为你提供重要的背景信息。
- en: As you read through the principles, remember that data-centric ML is an extension
    – and not a replacement – of a model-centric approach. Essentially, model-centric
    and data-centric techniques work together to glean the most value from your efforts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读原则时，请记住，以数据为中心的机器学习是模型中心方法的扩展——而不是替代品。本质上，模型中心化和数据中心化技术协同工作，以从你的努力中获得最大价值。
- en: By the end of this chapter, you will have a good understanding of each of the
    principles and how they work together to form a framework for data-centricity.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将对每个原则及其如何共同形成一个以数据为中心的框架有很好的理解。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Principle 1 – data should be the center of ML development
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 1 – 数据应该是机器学习发展的中心
- en: Principle 2 – leverage annotators and **subject-matter experts** (**SMEs**)
    effectively
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 2 – 有效利用标注者和**主题专家**（**SMEs**）
- en: Principle 3 – use ML to improve your data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 3 – 使用机器学习来改进你的数据
- en: Principle 4 – follow ethical, responsible, and well-governed ML practices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原则 4 – 遵循道德、负责任和良好治理的机器学习实践
- en: Sometimes, all you need is the right data
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有时候，你所需要的只是正确的数据
- en: A few years ago, I (Jonas) was leading a team of data scientists tasked with
    an interesting but challenging problem. The financial services business we worked
    for attracted many new online visitors wanting to open new accounts with us through
    the company’s website. However, a significant number of potential customers couldn’t
    complete the account opening process for unknown reasons, which is why the company
    turned to its data scientists for help.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，我（乔纳斯）领导着一个数据科学家团队，他们面临着一个有趣但具有挑战性的问题。我们工作的金融服务业务吸引了大量新的在线访客，他们希望通过公司的网站向我们开设新账户。然而，由于未知原因，相当数量的潜在客户无法完成开户流程，这就是为什么公司转向数据科学家寻求帮助的原因。
- en: 'This problem of unopened accounts and lost customers was multifaceted, but
    we were determined to find every needle in the haystack. The account opening process
    was rather straightforward, designed to make it easy for someone to open a new
    account in less than 10 minutes with no support. For the customer, the steps were
    as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个未激活账户和失去客户的问题是多方面的，但我们决心在草堆中找到每一根针。开户流程相当直接，旨在使某人能够在10分钟内（无需支持）轻松开设新账户。对于客户来说，步骤如下：
- en: Enter personal details.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入个人详细信息。
- en: Verify identity.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证身份。
- en: Verify contact details.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证联系信息。
- en: Accept the terms and conditions and open an account.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受条款和条件并开设账户。
- en: This process worked most of the time, but things were going wrong in *steps
    2* and *3* for a significant proportion of applicants. If someone’s identity couldn’t
    be verified online (*step 2*), the individual would have to be verified in person,
    which was an obvious detractor for many, and it caused a significant drop-off.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程在大多数情况下都有效，但对于相当一部分申请人来说，在**步骤 2**和**步骤 3**中出现了问题。如果某人的身份无法在线验证（**步骤 2**），那么个人必须亲自验证，这对许多人来说是一个明显的减分项，并导致了显著的用户流失。
- en: The problems arising in *step 3* were less obvious. About 10% of users would
    quit their journey at this point, even though most of the hard work had already
    been done. Why would someone go through this whole process and then decide not
    to proceed after all?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 3**中出现的这些问题不太明显。大约10%的用户会在这一点上放弃他们的旅程，尽管大部分艰苦的工作已经完成。为什么有人会经历整个过程，然后最终决定不继续进行？
- en: We collected all the relevant data points we could get our hands on, but unfortunately,
    we didn’t have a very deep dataset to work on because the account opening process
    was so simple and these were new customers. We profiled our dataset and used various
    supervised and unsupervised ML techniques to tease out any behaviors that correlated
    with accounts not opening, but nothing stuck out in our analysis.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了我们能得到的所有相关数据点，但遗憾的是，我们没有一个非常深入的数据集来工作，因为账户开设过程非常简单，这些是新客户。我们对数据集进行了分析，并使用了各种监督和无监督的机器学习技术来找出与账户未开设相关的任何行为，但我们的分析中没有突出的事物。
- en: We decided to dig deeper. Since these clients shared their contact information,
    we could match their phone numbers with our phone call records and obtain the
    recorded conversations with matching phone numbers. We pulled out hundreds of
    call recordings and started listening in.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定深入挖掘。由于这些客户分享了他们的联系信息，我们可以将他们的电话号码与我们的通话记录相匹配，并获取与匹配电话号码的录音对话。我们提取了数百个通话录音并开始收听。
- en: 'Soon after, a clear pattern emerged: “I clicked the **Verify contact details**
    button, but never received a verification code,” said one recorded caller. “I’ve
    waited for 10 minutes, but the code hasn’t come through yet,” said another. Users
    weren’t getting through because they weren’t sent the final verification code
    as a text message – even when it was resent by call center agents. But this wasn’t
    the case for all new users, so what was going wrong for this particular group?'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 很快，一个清晰的模式出现了：“我点击了**验证联系信息**按钮，但从未收到验证码，”一位录音中的呼叫者说。“我已经等了10分钟，但验证码还没有到来，”另一位说。用户无法通过验证，因为他们没有收到作为短信的最终验证码——即使呼叫中心的工作人员重新发送了。但并非所有新用户都遇到这种情况，那么这个特定群体出了什么问题？
- en: 'As we continued to listen to call recordings, another faint signal emerged:
    “I shouldn’t have come back,” said one user. “Your systems haven’t gotten any
    better since the last time I was here,” said another.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续收听通话录音，另一个微弱的信号出现了：“我不应该回来，”一位用户说。“自从我上次来这里，你们的系统并没有变得更好，”另一位说。
- en: We had a look at closed customer accounts and sure enough, these people had
    been customers of ours in the past. The issue was simply that the enterprise system
    was treating these users as existing customers and therefore not sending out the
    required text messages, no matter how many times it was prompted by users or staff.
    The issue was occurring around 200 times a week, meaning the business was missing
    out on 10,000 new customers a year. Why didn’t anyone pick up on this issue earlier?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们查看了一些关闭的客户账户，果然，这些人以前是我们的客户。问题很简单，企业系统将这些用户视为现有客户，因此没有发送所需的短信，无论用户或工作人员提示多少次。这个问题每周大约发生200次，这意味着企业每年失去了10,000名新客户。为什么没有人早点发现这个问题？
- en: Only a proportion of the 200 occurrences would generate a call, and with hundreds
    of call center staff on duty throughout the week, it seemed like a rare glitch
    that only happened now and then. No one individual could see the issue because
    it was too infrequent and impossible for our models to flag. After all, the initial
    dataset had too much noise and not enough signal.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 只有200次中的少数几次会生成呼叫，而且由于整个星期都有数百名呼叫中心工作人员值班，这似乎是一个罕见的故障，只偶尔发生。没有人能看出问题，因为它太不频繁，我们的模型也无法标记。毕竟，初始数据集噪音太多，信号不足。
- en: We only got to the bottom of it and found our needle in the haystack because
    we followed the four principles of data-centricity discussed in this chapter.
    Let’s explore each of these principles in more detail.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以能够找到这个问题的根源，并从混乱中找到我们的“针”，是因为我们遵循了本章讨论的数据中心化的四个原则。让我们更详细地探讨这些原则中的每一个。
- en: Principle 1 – data should be the center of ML development
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则1——数据应该是机器学习发展的中心
- en: 'As we discussed in [*Chapter* *2*](B19297_02.xhtml#_idTextAnchor028)*, From
    Model-Centric to Data-Centric – ML’s Evolution,* the predominant model-centric
    approach is lacking in several ways: computing and storage have been commoditized,
    algorithms have become practically automated and highly data-dependent, models
    are accessible but less malleable, and deep learning and AutoML tools are available
    everywhere. But the data? Well, that’s still the wildcard.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第2章*](B19297_02.xhtml#_idTextAnchor028)*从以模型为中心到以数据为中心——机器学习的演变*中讨论的那样，占主导地位的模式中心方法在几个方面存在不足：计算和存储已经商品化，算法已经实际上自动化并且高度依赖数据，模型是可访问的但不太灵活，深度学习和AutoML工具无处不在。但数据呢？嗯，那还是未知数。
- en: Rather than relying on powerful computing and storage environments and sophisticated
    algorithms that demand excess amounts of data to give us the incremental uplift
    in model accuracy, a better approach is to be driven by data – specifically, by
    the data that is available and relevant to the problem at hand.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是依赖于强大的计算和存储环境以及需要大量数据的复杂算法来给我们带来模型准确性的增量提升，一个更好的方法是由数据驱动——具体来说，是由手头问题可用且相关的数据驱动。
- en: Data is unique to every company, problem, and situation, and the data-centric
    paradigm recognizes this by putting the spotlight and development efforts on the
    data before the model. Data is no longer a static asset that can be collected
    at the beginning and forgotten about; it is now a unique commodity that needs
    to be leveraged to its full potential to make better predictions. We will argue
    that in many cases, a company’s proprietary data is its only truly unique competitive
    advantage – so long as it’s leveraged.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据对每个公司、问题和情况都是独特的，数据驱动的范式通过在模型之前将焦点和开发努力放在数据上，来认可这一点。数据不再是可以在一开始收集后就被遗忘的静态资产；现在它是一种独特的商品，需要充分利用其全部潜力以做出更好的预测。我们将论证，在许多情况下，公司的专有数据是其唯一的真正独特的竞争优势——只要得到充分利用。
- en: By focusing on the data, data-centricity helps companies distinguish themselves
    from their competitors. Most companies have access to the same algorithms and
    plenty of computing and storage, but the data they use and the insights they gain
    from that data can give them a decisive edge over the competition.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过关注数据，数据驱动的范式帮助公司区别于其竞争对手。大多数公司都能访问相同的算法和大量的计算和存储，但他们使用的数据以及从这些数据中获得的见解可以给他们带来决定性的竞争优势。
- en: In our observation, focusing on data quality also brings substantial benefits
    to an organization besides getting better data. Focusing on data quality means
    going beyond simple data refinement because quality data is a critical component
    of business operations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的观察中，关注数据质量除了获得更好的数据外，还为组织带来了实质性的好处。关注数据质量意味着超越简单的数据精炼，因为高质量数据是业务运营的关键组成部分。
- en: For data quality to improve, there is typically a need to digitize and automate
    processes and to create strong accountability for process adherence. Strong data
    governance processes will assign ownership, stewardship, and accountability for
    data quality, which, in turn, relies on data collection standards and processes
    to be followed, measured, and managed.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高数据质量，通常需要数字化和自动化流程，并创建对流程遵守的强大问责制。强大的数据治理流程将分配数据质量的拥有权、监护权和问责制，这反过来又依赖于遵循、衡量和管理的数据收集标准和流程。
- en: Data quality is often a symptom of the quality of underlying processes and adherence
    to these processes. If an organization is good at collecting high-quality data,
    it is also likely to have good processes more generally. As companies improve
    data collection, they drive better accountability, accuracy, reliability, and
    overall consistency in their operations. Hence, focusing on data quality can have
    far-reaching consequences beyond improved data integrity and reliability. It is
    an essential driver of operational excellence.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量通常是底层过程质量和对这些过程遵守情况的症状。如果一个组织擅长收集高质量数据，那么它也更有可能拥有良好的通用流程。随着公司改进数据收集，它们推动更好的问责制、准确性、可靠性和整体一致性。因此，关注数据质量可以产生深远的影响，而不仅仅是改善数据完整性和可靠性。它是运营卓越的关键驱动因素。
- en: If we think back to the example of missing verification codes discussed at the
    beginning of this chapter, no amount of model selection, parameter tuning, or
    feature engineering on the existing dataset would have revealed the root cause
    of the problem.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾本章开头讨论的缺失验证码的例子，对现有数据集进行任何模型选择、参数调整或特征工程都不会揭示问题的根本原因。
- en: 'This issue could only be discovered and solved by collecting the right data
    for the problem at hand. In this case, the missing data points were as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题只能通过收集手头问题的正确数据来发现和解决。在这种情况下，缺失的数据点如下：
- en: Verification codes weren’t being received
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证码没有被接收
- en: This was only the case for previous customers who returned to open a new account
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这仅适用于之前客户返回并开设新账户的情况
- en: The discovery of the verification code issue resulted in two key changes to
    the way the business operated. Firstly, the IT department fixed the code responsible
    for triggering verification codes being sent, which, all else being equal, resulted
    in a substantial uplift in new account openings. Secondly, the call center team
    established a central process for logging client tech issues, no matter how small,
    so we could discover *the tip of the iceberg* of any new system issues. In other
    words, it was now accepted culture that collecting high-quality data is central
    to improving operational processes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 验证码问题的发现导致业务运营方式发生了两项关键变化。首先，IT部门修复了负责触发发送验证码的代码，在其他条件相同的情况下，这导致了新账户开设数量的显著增加。其次，客服中心团队建立了一个中央流程来记录客户的技术问题，无论大小，这样我们就能发现任何新系统问题的“冰山一角”。换句话说，现在公认的文化是收集高质量数据是改进运营流程的核心。
- en: 'This was a mindset shift for frontline staff in two ways. Firstly, there was
    a newfound appreciation for data as a powerful asset that could be aggregated
    and analyzed to understand the bigger picture of their work. Secondly, frontline
    teams now felt empowered: if I do my bit to capture and call out important issues,
    there is a chance we can fix them.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这对一线员工在两个方面产生了心态转变。首先，他们对数据作为一项强大的资产有了新的认识，这项资产可以汇总和分析，以了解他们工作的整体情况。其次，一线团队现在感到更有权力：如果我做好我的部分工作，捕捉和指出重要问题，就有机会修复它们。
- en: Our data scientists also gained a different appreciation for data collection
    and curation as a key part of *their* role. Seeing the impact they could have
    by walking in the shoes of customers and frontline staff created a profound shift
    in the way the team solved problems. Rather than accepting data (quality) as given,
    data engineering now permeated all steps of the model development and deployment
    process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据科学家也对数据收集和整理作为他们角色关键部分有了不同的认识。通过站在客户和一线员工的角度看问题，他们看到了他们能够产生的影响，这使团队解决问题的方法发生了深刻的变化。而不是接受数据（质量）作为既定事实，数据工程现在渗透到模型开发和部署过程的每个步骤。
- en: A checklist for data-centricity
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中心的清单
- en: To stay true to the first principle of data-centric ML, it is incredibly valuable
    to have a checklist of data-focused tasks to complete as you work through an ML
    project. Here is our checklist, spread across the five steps in the model development
    life cycle.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了忠实于数据中心的机器学习第一原则，在处理机器学习项目时拥有一个数据聚焦的任务清单非常有价值。以下是我们的清单，分布在模型开发生命周期中的五个步骤中。
- en: Step 1 – identify the business problem, scope the project, and define the data
    needs
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1步 – 确定业务问题，界定项目范围，并定义数据需求
- en: The first part of any ML project should always be to clearly define the problem
    you’re trying to solve; this should be done in collaboration with key stakeholders
    such as end users and SMEs. Identifying data gaps will be a lot easier when you
    have a clear definition of the problem you’re solving, and what success looks
    like when the problem has been solved.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习项目的第一部分始终应该是清楚地定义你试图解决的问题；这应该与关键利益相关者，如最终用户和行业专家合作完成。当你对你要解决的问题有一个清晰的定义，以及问题解决后的成功样子时，识别数据差距会容易得多。
- en: A strong modeling dataset contains both *content* and *context*. Content is
    a specific object, event, or status you’re measuring and context describes the
    circumstances in which the object, event, or status occurred. In our previous
    missing verification code example, the content is the *(missing) verification
    code* and the context is *for former,* *returning customers*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个强大的建模数据集包含内容和上下文。内容是你正在测量的特定对象、事件或状态，上下文描述了对象、事件或状态发生的情境。在我们之前的缺失验证码示例中，内容是*(缺失的)验证码*，上下文是*对于以前，*
    *回归客户*。
- en: A critical element in defining the project scope is outlining the process you’re
    trying to model. We do this by getting relevant end users and SMEs in a room with
    data scientists for as long as it takes to map out the process or situation underlying
    the business problem. This allows all participants to get a deep understanding
    of the content and context of the problem, while also identifying important data
    points needed for the model build.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 定义项目范围的一个关键要素是概述你试图模拟的过程。我们通过将相关最终用户和行业专家与数据科学家一起放在一个房间里，直到他们能够绘制出业务问题背后的过程或情况，来做到这一点。这使所有参与者能够深入了解问题的内容和背景，同时确定构建模型所需的重要数据点。
- en: 'Here is a checklist of questions to consider during this step:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步骤中，以下是一些需要考虑的问题清单：
- en: Have we clearly defined the problem we’re trying to solve?
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否清楚地定义了我们试图解决的问题？
- en: Is it the right problem to solve in the first place?
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是不是我们首先应该解决的问题？
- en: What outcomes are we looking to achieve by solving the problem?
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过解决这个问题的我们期望实现什么结果？
- en: Have we mapped out the key parts of the problem with SMEs?
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否已经与专家一起确定了问题的关键部分？
- en: What are the critical steps or moments in the process according to SMEs, and
    does our data capture these appropriately?
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据专家的意见，过程中的关键步骤或时刻是什么，我们的数据是否适当地捕捉了这些？
- en: Do our data points contain both *content* and *context*?
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据点是否包含*内容*和*上下文*？
- en: What biases could arise from the solution that we need to look out for later?
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从我们的解决方案中可能会产生哪些偏差，我们需要在以后留意这些偏差？
- en: Will any groups or segments be treated unfairly as a result of these biases?
    How can we identify these during the validation phase (*step 4*)?
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些偏差会导致任何群体或部分受到不公平对待吗？我们如何在验证阶段（*步骤4*）识别这些偏差？
- en: Is it legal and ethical to use all features in our dataset?
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的数据集中使用所有特征是否合法和道德？
- en: Will the outputs be internally or externally audited?
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出将进行内部或外部审计吗？
- en: Step 2 – prepare and label data
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤2 – 准备和标记数据
- en: For many data scientists, data preparation is a dreaded task. We certainly agree
    that data preparation can be both repetitive and time-consuming, but as proponents
    of data-centric ML, we encourage you to embrace it as the most important part
    of the job.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多数据科学家来说，数据准备是一项令人畏惧的任务。我们确实认为数据准备既可能是重复的，也可能是耗时的，但作为数据为中心的机器学习的倡导者，我们鼓励您将其视为工作中最重要的部分。
- en: Data preparation involves collecting, cleaning, structuring, enhancing, and
    augmenting your input data to increase the signal and reduce noise in the dataset.
    These tasks can be both technically challenging and rewarding – especially when
    you start seeing those AUC scores increase. By now, you are aware that this part
    of the process is likely to give you very powerful modeling outcomes if you put
    in the right kind of effort.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备涉及收集、清理、结构化、增强和增强您的输入数据，以增加数据集中的信号并减少噪声。这些任务可能既具有技术挑战性，又具有回报性——特别是当您开始看到AUC分数上升时。到目前为止，您已经意识到，如果您投入正确的努力，这个过程可能会给您带来非常强大的建模结果。
- en: The following checklist is useful for guiding you through the data preparation
    process. We will teach you how to do these tasks in plenty of detail throughout
    the rest of this book.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下清单对于指导您完成数据准备过程非常有用。我们将在本书的其余部分详细教授您如何执行这些任务。
- en: 'Here are the checklist questions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是清单问题：
- en: Have we performed a technical validation of data quality? (See [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*,
    Techniques for* *Data Cleaning*.)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否对数据质量进行了技术验证？（见[*第5章*](B19297_05.xhtml#_idTextAnchor070)*，数据清理技术*。）
- en: Can we enhance the strength of our dataset by cleaning it? (See [*Chapter 5*](B19297_05.xhtml#_idTextAnchor070)*,
    Techniques for* *Data Cleaning*.)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否通过清理数据来增强数据集的强度？（见[*第5章*](B19297_05.xhtml#_idTextAnchor070)*，数据清理技术*。）
- en: Do we need to collect additional data or enhance the quality of the existing
    dataset using human labelers? (See [*Chapter 4*](B19297_04.xhtml#_idTextAnchor056)*,
    Data Labeling Is a* *Collaborative Process*.)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要收集额外数据或使用人工标记员提高现有数据集的质量吗？（见[*第4章*](B19297_04.xhtml#_idTextAnchor056)*，数据标记是一个*协作过程*。）
- en: Do we need to define specific labeling rules and train SMEs? (See [*Chapter
    4*](B19297_04.xhtml#_idTextAnchor056)*, Data Labeling Is a* *Collaborative Process*.)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要定义特定的标记规则并培训专家吗？（见[*第4章*](B19297_04.xhtml#_idTextAnchor056)*，数据标记是一个*协作过程*。）
- en: Can we improve data quality or impute missing values using programmatic labeling?
    (See [*Chapter 6*](B19297_06.xhtml#_idTextAnchor089)*, Techniques for Programmatic
    Labeling in* *Machine Learning*.)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否通过程序化标记提高数据质量或填补缺失值？（见[*第6章*](B19297_06.xhtml#_idTextAnchor089)*，机器学习中程序化标记的技术*。）
- en: Should we use synthetic data to augment or enhance certain classes in the data?
    (See [*Chapter 7*](B19297_07.xhtml#_idTextAnchor111)*, Using Synthetic Data in
    Data-Centric* *Machine Learning*.)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否应该使用合成数据来增强或提高数据中某些类别的质量？（见[*第7章*](B19297_07.xhtml#_idTextAnchor111)*，在数据为中心的机器学习中使用合成数据*。）
- en: Do we need to preserve the privacy of individuals in the dataset? (See [*Chapter
    7*](B19297_07.xhtml#_idTextAnchor111)*, Using Synthetic Data in Data-Centric*
    *Machine Learning*.)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要保护数据集中个人的隐私？（见[*第7章*](B19297_07.xhtml#_idTextAnchor111)*，在数据为中心的机器学习中使用合成数据*。）
- en: Does our dataset contain biased classes and do we need to adjust these? (See
    [*Chapter 8*](B19297_08.xhtml#_idTextAnchor125)*, Techniques for Identifying and*
    *Removing Bias*.)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据集是否包含有偏见的类别，我们需要调整这些类别吗？（参见[*第8章*](B19297_08.xhtml#_idTextAnchor125)*，识别和*
    *消除偏见* *的技术。）
- en: Does our dataset contain enough of the right kinds of rare events? Do we need
    to add more or remove outliers? (See [*Chapter 9*](B19297_09.xhtml#_idTextAnchor141)*,
    Dealing with Edge Cases and Rare Events in* *Machine Learning*.)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据集是否包含足够数量的正确类型的罕见事件？我们需要添加更多或删除异常值吗？（参见[*第9章*](B19297_09.xhtml#_idTextAnchor141)*，在*
    *机器学习* *中处理边缘情况和罕见事件。）
- en: Can we engineer new features from the existing dataset?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否从现有数据集中工程化新的特征？
- en: Step 3 – train the model
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步 – 训练模型
- en: The model training phase is where data-centric and model-centric ML principles
    come together to create synergy. Again, it is important to highlight that you
    should not discard everything you already know about how to build and enhance
    ML models based on a model-centric approach. Data-centricity simply gives you
    an additional set of tools in your toolbox and allows you to amplify the impact
    of your models.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练阶段是数据中心化和模型中心化机器学习原则结合在一起以产生协同效应的地方。再次强调，重要的是不要丢弃你基于模型中心方法已经知道的所有关于如何构建和增强机器模型的知识。数据中心化只是给你工具箱中额外的一套工具，并允许你放大模型的影响。
- en: Feature selection is an important part of this synergistic process because it
    filters out features that aren’t useful (and in the worst case, problematic) for
    your model. Generally speaking, it is desirable to have fewer attributes contributing
    to your model because it reduces unwanted noise and makes the model easier to
    explain.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是这一协同过程的重要组成部分，因为它筛选出对模型无用（在最坏的情况下，可能是有问题的）特征。一般来说，希望有更少的属性对模型做出贡献是可取的，因为这减少了不必要的噪声，并使模型更容易解释。
- en: It is important to consider feature selection as part of the model selection
    process because a model and its input data go hand in hand to produce predictions.
    They are intrinsically linked to each other. Practically speaking, this means
    you should pick the features *with* the model and not use a static dataset of
    pre-selected features to choose between models.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑特征选择作为模型选择过程的一部分是很重要的，因为模型及其输入数据是手牵手产生预测的。它们本质上是相互联系的。实际上，这意味着你应该与模型一起选择特征，而不是使用静态的预选特征数据集来选择模型。
- en: 'Here are the checklist questions:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是清单问题：
- en: Do you suspect your data to be dirty (for example, wrong labels, missing values,
    meaningless patterns, or irrelevant outputs)?
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你怀疑你的数据是否脏（例如，错误的标签、缺失值、无意义的模式或不相关的输出）？
- en: Can we improve model accuracy by improving the quality of the dataset? The long
    list of data-centric techniques outlined in this book is designed to help you
    with this task!
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否通过提高数据集的质量来提高模型的准确性？本书中概述的长期数据中心化技术列表旨在帮助你完成这项任务！
- en: Do our engineered features suggest any relationships in the data that require
    us to collect additional data (features or observations)?
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们工程化的特征是否表明数据中存在需要我们收集额外数据（特征或观察）的关系？
- en: Do our (engineered) features suggest any relationships in the data that we should
    verify with SMEs? Rather than assuming our new features are correct, any influential
    correlations should be cross-checked with SMEs to ensure their relevance and validity
    within the context of the solution.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们（工程化）的特征是否表明数据中存在任何我们应该与行业专家（SMEs）验证的关系？与其假设我们的新特征是正确的，不如将任何有影响力的相关性与行业专家交叉检查，以确保它们在解决方案的上下文中相关性和有效性。
- en: Can we reduce the number of features in our model without losing predictive
    power? By applying dimensionality reduction techniques or feature selection methods,
    we may be able to decrease the number of features in our model without significantly
    compromising its predictive accuracy.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否在不损失预测能力的情况下减少模型中的特征数量？通过应用降维技术或特征选择方法，我们可能能够减少模型中的特征数量，而不会显著降低其预测准确性。
- en: Step 4 – evaluate performance, fairness, and bias
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 评估性能、公平性和偏见
- en: The data-centric approach to ML puts a strong emphasis on detecting bias and
    fairness issues during model evaluation. To validate the accuracy of an ML model,
    you should still start with traditional validation tasks such as splitting data
    into training and testing sets, performing cross-validation, and producing confusion
    matrices. The following checklist assumes that you will already be doing these
    tasks, using standard performance evaluation using metrics such as accuracy, precision,
    recall, F1 score, and more.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以数据为中心的机器学习方法在模型评估期间对检测偏见和公平性问题给予了高度重视。为了验证机器学习模型的准确性，您仍然应该从传统的验证任务开始，例如将数据分为训练集和测试集，执行交叉验证，并生成混淆矩阵。以下清单假设您将已经执行这些任务，使用标准性能评估，使用如准确率、精确率、召回率、F1分数等指标。
- en: Bias detection is an important tool for uncovering potential unfairness and
    discrimination in ML models. This can be done by creating confusion matrices for
    each subgroup separately to compare false positive and false negative rates across
    groups, and assessing demographic parity (equal representation) and equal opportunity
    (equal true positive rate) or equal odds (equal false positive rate) across groups.
    Disparities between subgroups, such as those related to gender or race, are common
    examples of sources of bias or unfairness.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 偏见检测是揭示机器学习模型中潜在的不公平性和歧视的重要工具。这可以通过为每个子组单独创建混淆矩阵来实现，以比较各组之间的假阳性率和假阴性率，并评估各组之间的群体平衡（平等代表）和机会平等（平等的真阳性率）或等概率（平等的假阳性率）。与性别或种族相关的子组间的差异是偏见或不公平的常见来源。
- en: 'Here are the checklist questions:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是清单问题：
- en: Can we improve model performance by improving data quality or collecting new
    features?
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否通过提高数据质量或收集新特征来提升模型的表现？
- en: Can we detect any bias or unfairness toward particular groups or segments?
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否检测到对特定群体或部分的任何偏见或不公平？
- en: Are there any large correlations between sensitive attributes and predictions
    made by the model?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 敏感属性与模型做出的预测之间是否存在任何大的相关性？
- en: How does the model perform on unseen data concerning fairness and bias?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在处理未见过的数据时，在公平性和偏见方面的表现如何？
- en: We’ll cover techniques for identifying and removing bias in [*Chapter 8*](B19297_08.xhtml#_idTextAnchor125)*,
    Techniques for Identifying and* *Removing Bias*.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第8章*](B19297_08.xhtml#_idTextAnchor125)*，*识别和消除偏见的技术*中介绍识别和消除偏见的技术。
- en: Step 5 – deploy and monitor
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第5步 – 部署和监控
- en: Effective monitoring of ML models also relies on data-centric principles. When
    monitoring model performance, it is important to include data quality, data coverage,
    data relevance, and labeling consistency metrics.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的有效监控也依赖于以数据为中心的原则。在监控模型性能时，包括数据质量、数据覆盖范围、数据相关性和标注一致性指标是很重要的。
- en: Data quality refers to the accuracy, completeness, and consistency of data,
    while data coverage refers to having enough data points to make confident predictions
    in the first place. Data relevance ensures that the data used to train the model
    is suitable for the task. Finally, data labeling consistency ensures that the
    data points used for training the model have correct labels.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量指的是数据的准确性、完整性和一致性，而数据覆盖范围指的是拥有足够的数据点来首先做出自信的预测。数据相关性确保用于训练模型的数据适合该任务。最后，数据标注一致性确保用于训练模型的数据点具有正确的标签。
- en: Several techniques and tools can help data scientists monitor ML models effectively.
    For example, data drift detection helps detect changes in data characteristics,
    such as mean, variance, and distribution. Similarly, outlier detection helps identify
    data points that differ significantly from the common distribution. Also, bias
    detection techniques help identify and correct instances of bias in ML models.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 几种技术和工具可以帮助数据科学家有效地监控机器学习模型。例如，数据漂移检测有助于检测数据特征的变化，如均值、方差和分布。同样，异常值检测有助于识别与常见分布显著不同的数据点。此外，偏见检测技术有助于识别和纠正机器学习模型中的偏见实例。
- en: In addition to relying on reporting and metrics to monitor ML models, it is
    crucial to understand that monitoring is an ongoing process that requires the
    involvement of stakeholders beyond the data science team. Stakeholders may include
    SMEs, business owners, and end users. These stakeholders should collaborate to
    evaluate the model’s performance, interpret the results, and identify any issues
    that need to be addressed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了依赖报告和指标来监控ML模型之外，理解监控是一个持续的过程，需要数据科学团队以外的利益相关者的参与至关重要。利益相关者可能包括领域专家、业务所有者和最终用户。这些利益相关者应协作评估模型的表现，解释结果，并确定需要解决的问题。
- en: 'Here are the checklist questions:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是清单问题：
- en: Are the data sources used in the model automated, consistent, and reliable?
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型中使用的数据源是否自动化、一致且可靠？
- en: Have we designed a monitoring and reporting plan that captures failures, biases,
    and drift?
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否设计了一个监控和报告计划，以捕捉失败、偏差和漂移？
- en: Does our monitoring quantify data quality, data coverage, data relevance, and
    labeling consistency?
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的监控是否量化了数据质量、数据覆盖范围、数据相关性和标签一致性？
- en: Have we set up a mechanism for end users to provide continuous feedback on model
    performance?
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否为最终用户提供了对模型性能进行持续反馈的机制？
- en: Our checklist questions are designed to make you think about data quality, and
    the impacts thereof, at each step in the model development process. In other words,
    they are an addition to – and not a replacement for – more model-centric development
    tasks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的设计清单问题旨在让您在模型开发过程的每一步都思考数据质量及其影响。换句话说，它们是对更多以模型为中心的开发任务的补充，而不是替代。
- en: Data-centricity requires a mindset shift from “I’ll build the best model with
    this data” to “How can we make the best dataset to solve this particular problem?”
    To do that, we need the whole organization involved in a coordinated effort. This
    brings us to the second principle of data-centric ML.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化需要从“我将用这些数据构建最好的模型”的心态转变为“我们如何构建最佳数据集来解决这个特定问题？”为了做到这一点，我们需要整个组织参与协调一致的努力。这使我们来到了数据中心化机器学习的第二个原则。
- en: Principle 2 – leverage annotators and SMEs effectively
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则2 – 有效利用标注者和领域专家
- en: No matter where we are in the AI hype cycle when you read this, it is unlikely
    that AI and ML development has evolved past the point where human input and labeling
    are needed.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您在阅读此内容时AI炒作周期处于哪个阶段，AI和ML开发不太可能已经发展到不再需要人类输入和标注的阶段。
- en: In recent years, we have experienced a large increase in the sophistication
    of AI technologies, especially in the field of generative AI. Despite this, it
    remains a fact that even the most powerful and revolutionary AI technologies,
    such as ChatGPT, rely on small armies of human labelers to refine and advance
    their capabilities.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们在AI技术的复杂性方面经历了大幅增长，尤其是在生成AI领域。尽管如此，一个事实仍然存在，即即使是功能最强大、最具革命性的AI技术，如ChatGPT，也依赖于由人类标注者组成的小型军队来完善和提升其能力。
- en: 'These individuals review and annotate data samples, which are then fed back
    into the model to improve its understanding of natural language and context. Some
    of the key methodologies and techniques that are employed by human labelers include
    the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些个人会审查和标注数据样本，然后这些样本会被反馈到模型中，以提升其对自然语言和上下文的理解。人类标注者采用的一些关键方法和技巧包括以下内容：
- en: '**Domain expertise**: Labelers with subject matter expertise can provide valuable
    insights and annotations that help the model better comprehend specific topics
    and domains.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域专业知识**：具有主题领域专业知识的标注者可以提供有价值的见解和标注，帮助模型更好地理解特定主题和领域。'
- en: '**Active learning**: This approach involves prioritizing data samples that
    the model finds ambiguous or challenging, enabling labelers to focus on areas
    where their input can have the greatest impact.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动学习**：这种方法涉及优先处理模型认为模糊或具有挑战性的数据样本，使标注者能够专注于他们输入可以产生最大影响的领域。'
- en: '**Diversity of perspectives**: By involving labelers from diverse backgrounds
    and with varied experiences, the model can be exposed to a broader range of linguistic
    nuances, cultural contexts, and perspectives, improving its overall performance.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视角多样性**：通过涉及来自不同背景和具有不同经验水平的标注者，模型可以接触到更广泛的语言细微差别、文化背景和观点，从而提高其整体性能。'
- en: '**Quality control**: Regular audits and evaluations of labeler output can help
    ensure consistent annotation quality and adherence to guidelines, which is essential
    for effective model training.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量控制**：定期审计和评估标注器的输出可以帮助确保标注质量的一致性和遵循指南，这对于有效的模型训练至关重要。'
- en: 'In short, human annotators are integral to ML, and the quality of our models
    depends on our ability to train, organize, and collaborate with these annotators.
    Broadly speaking, there are three ways to leverage SMEs in the ML development
    process:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，人工标注员对于机器学习至关重要，我们模型的质量取决于我们训练、组织和与这些标注员合作的能力。从广义上讲，在机器学习开发过程中利用行业专家的方式有三种：
- en: As direct labelers of data points
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为数据点的直接标注员
- en: As verifiers of output quality and detectors of undesired outputs such as toxic
    content
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为输出质量验证者和不良输出（如有害内容）的检测器
- en: As knowledge experts who can help us codify labeling rules
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为知识专家，他们可以帮助我们制定标注规则
- en: Leveraging SMEs effectively requires a mindset shift from just creating labeling
    rules for annotators (although this is still important) to using the combined
    strengths of SMEs and data scientists to cover the problem space through well-defined
    labeling rules.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 有效利用行业专家需要从仅为标注员创建标注规则（尽管这仍然很重要）的心态转变到利用行业专家和数据科学家结合的强项，通过明确的标注规则覆盖问题空间。
- en: Our experience is that following this approach gives us much more than robust
    labeling functions. It helps us track down ambiguous examples and sharpen model
    performance, but just as importantly, it allows data scientists and SMEs to collaborate.
    As data scientists learn about the subject matter and SMEs learn how data science
    works, it creates a flywheel effect leading to new ideas, insights, and knowledge.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的经验表明，采用这种方法不仅提供了强大的标注功能，还有助于我们追踪模糊的例子并提高模型性能，但同样重要的是，它允许数据科学家和行业专家进行合作。随着数据科学家了解主题内容，行业专家学习数据科学的工作方式，这会产生一个飞轮效应，导致新想法、洞察和知识的产生。
- en: Let’s explore each of the three human labeling approaches in more detail.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地探讨三种人工标注方法。
- en: Direct labeling with human annotators
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接由人工标注员进行标注
- en: The primary benefit of human-annotated data is its accuracy. Humans can recognize
    patterns and subjectivity in ways that computers cannot. This means that the labels
    assigned to the data may be more accurate than those generated by automated processes.
    Additionally, humans can provide context to the data that would otherwise be lost
    in an automated process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 人工标注数据的主要优势是其准确性。人类能够以计算机无法做到的方式识别模式和主观性。这意味着分配给数据的标签可能比自动化过程生成的标签更准确。此外，人类可以提供自动化过程中可能丢失的数据背景。
- en: Human-annotated data also offers greater flexibility than automated processes.
    Annotators can customize their labeling process according to specific needs or
    requirements, allowing them to tailor the annotations to fit their project’s goals.
    This makes it easier for machines to interpret the data accurately and quickly.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 人工标注数据也比自动化流程提供了更大的灵活性。标注员可以根据具体需求或要求定制他们的标注过程，使他们能够调整标注以适应项目目标。这使得机器能够更准确、更快速地解释数据。
- en: Finally, human-annotated data can be cost-effective compared to other methods
    of labeling. This is mainly true when datasets are small- to medium-sized.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，与其它标注方法相比，人工标注数据可能更具成本效益。这一点在数据集规模从小到中等时尤为正确。
- en: Small datasets might consist of a few hundred to a few thousand observations,
    often manageable by a small team of human annotators. Medium-sized datasets may
    have tens of thousands of observations. While still possible to manually label,
    the complexity and time required start to increase, making it less economically
    viable.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 小型数据集可能包含几百到几千个观察值，通常可以由一个小型标注团队管理。中型数据集可能有数万个观察值。虽然手动标注仍然是可能的，但随着复杂性和所需时间的增加，它开始变得在经济上不太可行。
- en: When faced with larger datasets, manual annotation can become repetitive and
    prone to mistakes due to the sheer volume and potential complexity of the data.
    At this scale, the intricacies in the data could also increase, requiring a more
    nuanced understanding that may be challenging for human annotators to maintain
    consistently.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 面对更大的数据集时，由于数据量巨大和潜在的复杂性，手动标注可能会变得重复且容易出错。在这个规模上，数据中的复杂性也可能增加，需要更细腻的理解，这可能对标注员保持一致性构成挑战。
- en: For larger or more complex datasets, we recommend going down the path of programmatic
    labeling, which we’ll discuss next. Interestingly, a hybrid approach can also
    be effective, where a subset of the large dataset is manually labeled to serve
    as training data for the programmatic labeling algorithm. This way, you can leverage
    the accuracy of human annotation and the scalability of ML, ensuring high-quality
    labels, even for large datasets.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更大或更复杂的数据集，我们建议走程序化标注的道路，我们将在下一部分进行讨论。有趣的是，混合方法也可以有效，其中大型数据集的一个子集被手动标注，作为程序化标注算法的训练数据。这样，你可以利用人工标注的准确性和机器学习的可扩展性，确保即使是大型数据集也能获得高质量的标签。
- en: Think back to the story of the missing verification codes we outlined at the
    beginning of this chapter. Once we had isolated the phone calls that were related
    to the yet-to-be-discovered issue, we chose to manually listen to hundreds of
    calls rather than use ML techniques to pick up themes. Why?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们在本章开头概述的丢失验证码的故事。一旦我们确定了与尚未发现的议题相关的电话，我们选择手动监听数百个电话，而不是使用机器学习技术来捕捉主题。为什么？
- en: Because we wanted to make sure we understood the *content* and the *context*
    of these interactions and a human was just more likely to do that job well. At
    the same time, we were only listening to a few hundred calls, not millions, so
    human annotation was the most cost-effective way to find the signal in the noise
    and pinpoint our needle-in-the-haystack issue.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们想确保我们理解了这些交互的内容和上下文，而人类更有可能做好这项工作。同时，我们只听了数百个电话，而不是数百万个，所以人工标注是找到噪声中的信号和定位我们“大海捞针”问题的最经济有效的方式。
- en: While labeling by humans is an essential part of the data-centric approach,
    there are several pitfalls and mistakes to avoid when using human labelers. In
    [*Chapter 4*](B19297_04.xhtml#_idTextAnchor056), *Data Labeling Is a Collaborative
    Process*, we will teach you how to get the most out of SMEs and human annotators
    while managing the potential downsides.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然人工标注是数据驱动方法的重要组成部分，但在使用人工标注员时，有一些陷阱和错误需要避免。在[*第4章*](B19297_04.xhtml#_idTextAnchor056)《数据标注是一个协作过程》中，我们将教你如何最大限度地发挥专家和人工标注员的作用，同时管理潜在的负面影响。
- en: Verifying output quality with human annotators
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用人工标注员验证输出质量
- en: As mentioned previously, even very sophisticated AI solutions such as ChatGPT
    are heavily reliant on human annotators to guide algorithms to the optimal outcome.
    ChatGPT has been built on a mix of supervised learning and a technique called
    **reinforcement learning from human** **feedback** (**RLHF**).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，即使是像ChatGPT这样非常复杂的AI解决方案，也严重依赖人工标注员来引导算法达到最佳结果。ChatGPT是基于监督学习和一种称为**人类反馈强化学习**（RLHF）的技术构建的。
- en: Reinforcement learning is an area of ML where an agent learns to make decisions
    by interacting with an environment. The agent’s objective is to select actions
    that maximize the cumulative reward over time. However, defining a suitable reward
    function for complex tasks can be challenging.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是机器学习的一个领域，其中代理通过与环境的互动来学习做出决策。代理的目标是选择能够最大化累积奖励的行动。然而，为复杂任务定义合适的奖励函数可能具有挑战性。
- en: That’s where human feedback comes into play. In RLHF, an AI agent learns from
    rewards and penalties provided by humans, rather than a predefined reward function.
    This approach combines the power of ML algorithms with the intuition, experience,
    and knowledge of human experts.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是人类反馈发挥作用的地方。在RLHF中，AI代理从人类提供的奖励和惩罚中学习，而不是从预定义的奖励函数中学习。这种方法结合了机器学习算法的力量与人类专家的直觉、经验和知识。
- en: 'The process involves the following steps:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程包括以下步骤：
- en: The AI agent interacts with the environment and takes action.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理与环境互动并采取行动。
- en: Human observers assess the agent’s actions and provide feedback in the form
    of rewards or penalties.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人类观察者评估代理的行为，并以奖励或惩罚的形式提供反馈。
- en: The agent uses this feedback to update its learning and improve its decision-making
    over time.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理使用这些反馈来更新其学习并随着时间的推移改进其决策。
- en: Through these interactions, the AI agent learns to perform complex tasks by
    incorporating human guidance.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些交互，AI代理学会通过结合人类指导来执行复杂任务。
- en: There are several benefits to using RLHF. Primarily, human feedback allows the
    AI agent to learn from the wealth of knowledge and experience that humans possess.
    This approach enables agents to learn complex behaviors that may be difficult
    to achieve with traditional algorithms. At the same time, the learning process
    can be tailored to specific needs or goals by adjusting the feedback provided
    by human experts.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RLHF（强化学习与人类反馈）的好处有几个。首先，人类反馈使得AI代理能够从人类所拥有的丰富知识和经验中学习。这种方法使得代理能够学习复杂的行为，这些行为可能用传统的算法难以实现。同时，通过调整人类专家提供的反馈，学习过程可以针对特定的需求或目标进行定制。
- en: The drawbacks of having humans in the loop are that humans can make mistakes
    or provide inconsistent feedback, which may affect the agent’s learning. Furthermore,
    training an AI agent using human feedback can be a slow process, as it requires
    continuous input from human experts. In other words, it tends to be labor intensive
    and potentially costly as a result. For this reason, it’s important to develop
    an upfront estimate of the human and financial resources required for such a project
    to ensure its viability.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环中有人类存在的不利之处在于，人类可能会犯错误或提供不一致的反馈，这可能会影响代理的学习。此外，使用人类反馈训练AI代理可能是一个缓慢的过程，因为它需要人类专家的持续输入。换句话说，它往往劳动密集且可能成本高昂。因此，重要的是要提前估计此类项目所需的人类和财务资源，以确保其可行性。
- en: It’s important to note that SMEs can be incredibly valuable contributors to
    almost any ML exercise. For example, we often use SMEs to help us review the outputs
    of our models because it allows us to discover new contexts in the problem space
    that should become features in the training data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，行业专家几乎可以成为任何机器学习练习的极其宝贵的贡献者。例如，我们经常使用行业专家来帮助我们审查模型的输出，因为这使我们能够发现问题空间中的新上下文，这些上下文应该成为训练数据中的特征。
- en: In the example of missing verification codes, we discovered the root of the
    problem by first developing a deep knowledge of the specific failure point by
    interviewing call center staff (one type of SME) and listening to call recordings
    (becoming SMEs ourselves). Once we had narrowed down the possible issue, we dug
    into the inner workings of the core system with our colleagues from the IT department
    (another type of SME) to verify the glitch.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在缺失验证码的例子中，我们通过首先通过采访呼叫中心工作人员（一种行业专家）和听取通话录音（我们自己成为行业专家）来深入了解具体的失败点，从而发现了问题的根源。一旦我们缩小了可能的问题范围，我们就与IT部门的同事（另一种行业专家）一起深入核心系统的内部运作，以验证故障。
- en: This approach is not the same as reinforcement learning, but it highlights the
    value of involving SMEs throughout the whole development process, even if it requires
    manual input.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法与强化学习不同，但它强调了在整个开发过程中涉及行业专家的价值，即使这需要人工输入。
- en: Codifying labeling rules with programmatic labeling
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用程序化标注来规范标注规则
- en: The traditional method of labeling using human annotators is sometimes a bottleneck
    in the process that can prevent us from creating high-quality training sets in
    a way that is both efficient and cost-effective. This is typically an issue when
    we’re dealing with large datasets. Time- and cost-efficient training has become
    increasingly important as ML models become more complex and datasets become larger.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用人工标注的传统方法有时是过程中的瓶颈，可能会阻止我们以既高效又经济的方式创建高质量的训练集。这通常是在处理大量数据集时出现的问题。随着机器学习模型变得更加复杂，数据集变得更大，时间和成本效益高的训练变得越来越重要。
- en: Enter programmatic labeling. At its core, programmatic labeling is a process
    of automatically assigning labels to data points based on predefined rules or
    algorithms. The main advantage of programmatic labeling over manual labeling is
    that it can be done much faster and more accurately than manual labeling – once
    there is a robust labeling function in place. This makes it ideal for large datasets
    where manual labeling would take too long or be too costly.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 进入程序化标注。从本质上讲，程序化标注是一个基于预定义的规则或算法自动为数据点分配标签的过程。程序化标注相对于人工标注的主要优势是，它可以比人工标注更快、更准确地完成——一旦建立了稳健的标注功能。这使得它非常适合大型数据集，在这些数据集中，人工标注可能耗时过长或成本过高。
- en: The process of programmatic labeling begins with defining the labels that need
    to be assigned to each data point. This can be done manually by SMEs or through
    automated methods such as **natural language processing** (**NLP**) algorithms
    or rule-based systems. Once the labels have been defined, they can then be applied
    to the data points using either supervised or unsupervised learning algorithms.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 程序化标注的过程始于定义需要分配给每个数据点的标签。这可以通过SMEs手动完成，或者通过自动化方法，如**自然语言处理**（**NLP**）算法或基于规则的系统来完成。一旦定义了标签，就可以使用监督学习或无监督学习算法将它们应用于数据点。
- en: 'The main benefits of programmatic labeling are as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 程序化标注的主要好处如下：
- en: '**Scalability**: Programmatic labeling can handle large volumes of data more
    efficiently than manual labeling, enabling faster model training and iteration'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：程序化标注可以比人工标注更高效地处理大量数据，从而实现更快的模型训练和迭代。'
- en: '**Consistency**: Automated labeling methods ensure a consistent application
    of rules and criteria across the entire dataset, reducing variability and potential
    errors that may arise from human subjectivity'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：自动化的标注方法确保在整个数据集中一致地应用规则和标准，减少变异性以及可能由人为主观性引起的潜在错误。'
- en: '**Cost-effectiveness**: By automating the labeling process, organizations can
    save on the time and resources required to train, manage, and compensate human
    labelers'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益**：通过自动化标注过程，组织可以节省在培训、管理和补偿人工标注员所需的时间和资源。'
- en: '**Speed**: Programmatic labeling can process and annotate data much more quickly
    than manual labeling, accelerating the overall ML pipeline'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：程序化标注可以比人工标注更快地处理和标注数据，从而加速整个机器学习流程。'
- en: '**Reduced human error**: Automation minimizes the risk of human error and inconsistencies
    that can be introduced during manual labeling'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少人为错误**：自动化最小化了在人工标注过程中可能引入的人为错误和不一致性风险。'
- en: '**Reproducibility**: The automated labeling process is easily replicable, ensuring
    that results can be reproduced and verified across different datasets and projects'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复性**：自动化的标注过程易于复制，确保结果可以在不同的数据集和项目中重复和验证。'
- en: '**Adaptability**: Programmatic labeling algorithms can be fine-tuned and updated
    as needed to accommodate changing requirements, new data sources, or evolving
    project goals'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性**：程序化标注算法可以根据需要微调和更新，以适应不断变化的需求、新的数据源或不断发展的项目目标。'
- en: '**24/7 availability**: Unlike human labelers, programmatic labeling can operate
    continuously without breaks or downtime, allowing for uninterrupted progress in
    ML projects'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**24/7可用性**：与人工标注员不同，程序化标注可以持续运行，无需休息或停机时间，从而确保机器学习项目进展不间断。'
- en: We will show you how to use specific programmatic labeling techniques in [*Chapter
    6*](B19297_06.xhtml#_idTextAnchor089)*, Techniques for Programmatic Labeling in*
    *Machine Learning*.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第6章*](B19297_06.xhtml#_idTextAnchor089)“*机器学习中的程序化标注技术*”中向您展示如何使用特定的程序化标注技术。
- en: Programmatic labeling techniques are often all that’s required to lift the quality
    of your data. However, in some cases, relationships between features are too complex
    for rules-based algorithms to do the job. This brings us to the third principle
    of data-centric ML.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 程序化标注技术通常足以提高数据质量。然而，在某些情况下，特征之间的关系过于复杂，基于规则的算法无法完成这项工作。这使我们来到了数据为中心的机器学习的第三原则。
- en: Principle 3 – use ML to improve your data
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则3 – 使用机器学习改进你的数据
- en: Just as we can use a programmatic or algorithmic approach to label our data,
    we can also use ML to identify data points that may be wrong or ambiguous. By
    leveraging developments in explainability, error analysis, and semi-supervised
    approaches, we can create new labels and find data points to improve or discard.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们可以使用程序化或算法方法来标注我们的数据一样，我们也可以使用机器学习来识别可能错误或不明确的数据点。通过利用可解释性、错误分析和半监督方法的发展，我们可以创建新的标签并找到改进或丢弃的数据点。
- en: 'Here are some practical steps to generate better input data with ML:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些使用机器学习生成更好输入数据的实际步骤：
- en: '**Toss out noisy examples**: Sometimes, more data is not always better. Noisy
    data can lead to inaccurate predictions. By removing noisy examples, we can improve
    the quality of our input data. For instance, if you’re analyzing customer reviews
    and some reviews are filled with random characters or irrelevant information,
    those can be considered as “noisy” and removed.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use techniques to focus on a subset of data to improve**: Not all data has
    the same value. We can focus on a subset of data to improve the quality of our
    input data. For example, if you’re analyzing sales data, you might focus on the
    subset of data from your most profitable region to get the most return on your
    efforts, all else being equal.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expand available label data by leveraging ML generalization from expert input**:
    ML can be used to expand the available label data by using expert input to achieve
    similar precision and greater coverage. An expert in bird species, for example,
    could provide input on a limited set of images, and ML could use this to accurately
    label a larger set of images.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use semi-supervised approaches**: Semi-supervised approaches, including weak
    learning and active learning, can be used to identify data points that require
    SME review. For example, you might use active learning to identify customer emails
    that need to be reviewed by a human for sentiment analysis.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use explainability**: Explainability is essential in identifying patterns
    in data and ensuring that models make sense. Complex models require a model-specific
    or model-agnostic approach to explainability, including local and global methods
    and SHAP values. For example, using SHAP values can help you understand why your
    model predicted a certain outcome in a loan approval process, ensuring the decision-making
    is transparent and explainable.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use error analysis**: Error analysis can help identify patterns in data where
    models are making mistakes, helping to improve the quality of our input data.
    For instance, if your model is incorrectly identifying cats as something else
    in image recognition, error analysis can help you figure out where and why it’s
    making these mistakes.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The techniques required to perform these steps will be outlined throughout the
    subsequent chapters of this book.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: By applying these steps in production, we can identify performance drifts in
    labeling functions or models. Additionally, we can identify data points that require
    human review, leading to better quality input data and improved prediction accuracy.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: The use of ML to improve input data quality is a fundamental shift in the traditional
    approach to ML. It requires a mindset shift from using ML models to make the best
    prediction to using ML to identify the data points that are not helping model
    performance. After all, the goal of data-centric ML is to increase signal and
    reduce noise in our input data.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Embracing a data-centric approach also provides us with a unique opportunity
    to collect and refine data in a manner that is inherently aligned with ethical,
    responsible, and well-governed ML practices. This shift in focus allows us to
    design our data strategies not just around performance enhancement but also around
    principles of fairness, transparency, and accountability.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 采用数据中心的做法也为我们提供了一个独特的机会，以符合伦理、负责任和良好治理的机器学习实践的方式收集和精炼数据。这种关注点的转变使我们能够设计我们的数据策略，不仅围绕性能提升，还围绕公平、透明和问责制原则。
- en: As we proceed, we will explore how this approach can help us to embed ethics
    at the very core of our data collection and refinement processes. This way, we
    can ensure that improved data quality goes hand in hand with maintaining the integrity
    and trustworthiness of our ML applications.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续前进的过程中，我们将探讨这种方法如何帮助我们将伦理嵌入到我们的数据收集和精炼过程的内核。这样，我们可以确保提高数据质量与保持我们机器学习应用的完整性和可靠性相辅相成。
- en: Principle 4 – follow ethical, responsible, and well-governed ML practices
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则4 - 遵循道德、负责任和良好治理的机器学习实践
- en: Ethical and responsible ML practices become increasingly important as data-centricity
    allows us to tackle more high-stakes challenges. This requires you to consider
    factors such as transparency, fairness, and accountability when designing algorithms
    so that they do not discriminate against certain groups or individuals. Additionally,
    those responsible for implementing these systems must be aware of how they work
    and understand their limitations so that they can make informed decisions about
    their use.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据中心的兴起，我们能够应对更多高风险挑战，道德和负责任的机器学习实践变得越来越重要。这要求你在设计算法时考虑透明度、公平性和问责制等因素，以确保它们不会歧视某些群体或个人。此外，负责实施这些系统的人必须了解它们的工作原理，并理解它们的局限性，以便他们可以就其使用做出明智的决定。
- en: Unfortunately, ethical and responsible ML practices are generally not as developed
    as they should be. In 2021, the IBM Institute for Business Value and Oxford Economics
    conducted a study1 where 75% of executives ranked AI ethics as important; however,
    fewer than 20% of executives strongly agreed that their organizations’ practices
    aligned with their declared principles and values.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 很不幸，道德和负责任的机器学习实践通常不如应有的那样发达。在2021年，IBM商业价值研究所和牛津经济研究所进行了一项研究1，其中75%的高管将AI伦理视为重要；然而，不到20%的高管强烈同意他们的组织实践与声明的原则和价值观相一致。
- en: As practitioners of data-centric ML, we need to consider that the term *data
    quality* is much broader than the objective accuracy of individual data points.
    High-quality data should also allow us to identify and monitor potential ethical
    issues throughout the ML development process and beyond.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据中心的机器学习从业者，我们需要考虑的是，“数据质量”这个术语比单个数据点的客观准确性要广泛得多。高质量的数据还应使我们能够在整个机器学习开发过程及其之外识别和监控潜在的伦理问题。
- en: AI ethics and responsibility is not just a tick-box exercise, but a potential
    source of differentiation. Organizations that pay attention to AI ethics are more
    likely to be trusted by their customers, while organizations that overlook it
    are likely to suffer customer backlash and reputational damage2.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能伦理和责任不仅仅是打勾作业，它可能是一个潜在的差异化来源。关注AI伦理的组织更有可能获得客户的信任，而忽视它的组织可能会遭受客户的反感和声誉损害2。
- en: The story of the UK’s 2020 *school grading fiasco* highlights what can happen
    when you ignore ethical considerations while using ML in high-stakes environments.
    During the COVID-19 pandemic, students across the UK were unable to sit their
    exams because of lockdowns. Instead, an algorithm was used to grade students’
    exam results, resulting in a significant number of students receiving lower grades
    than they deserved. This caused uproar among students, teachers, and the academic
    community as it was seen as unfair and unjust.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 英国2020年*学校评级丑闻*的故事突显了在高风险环境中使用机器学习时忽视伦理考虑可能发生的事情。在COVID-19大流行期间，由于封锁，英国各地的学生无法参加考试。相反，使用了一个算法来评定学生的考试成绩，导致大量学生获得的分数低于他们应得的分数。这引起了学生、教师和学术界的强烈不满，因为它被视为不公平和不公正。
- en: The algorithm used by Ofqual, the UK regulator responsible for regulating qualifications,
    exams, and assessments, was designed to standardize grades across different schools
    to make them comparable. It considered factors such as prior attainment and school
    performance. However, it did not consider individual student performance or teacher
    assessments, which resulted in many students receiving lower grades than they
    should have.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Instead, the model favored students from private institutions and wealthy areas,
    significantly impacting high-performing individuals from public, state-funded
    schools. Consequently, numerous students lost their university admissions due
    to the lowered exam scores. This caused a great deal of distress among the students
    who had worked hard for their exams only to be let down by an algorithm that did
    not accurately reflect their abilities. In the end, the grades awarded by the
    algorithm were canceled, and replaced by a fairer but more manual grading approach.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: To avoid similar incidents such as the UK grading disaster from occurring in
    the future, AI systems must be designed with ethical considerations in mind from
    the outset. Overall, this incident highlights some of the ethical issues associated
    with AI systems and demonstrates why it is important for us to consider these
    issues when designing and implementing them. It also serves as a reminder that
    we must ensure these systems are transparent, fair, and accountable if we want
    them to be effective tools for decision-making in our society.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: We will be discussing specific ways to deal with ambiguity in labeling in [*Chapter
    4*](B19297_04.xhtml#_idTextAnchor056)*, Data Labeling Is a Collaborative Process*
    and show you a range of techniques for identifying and removing bias in [*Chapter
    8*](B19297_08.xhtml#_idTextAnchor125)*, Techniques for Identifying and* *Removing
    Bias*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we outlined the four principles of data-centric ML. By following
    these principles, you will be able to create ML models that are based on high-quality
    data that has been enhanced, cross-checked, and verified by humans, labeling functions,
    and ML techniques.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to get more signals out of our data, which, in turn, increases
    our ability to build powerful models on small or large datasets. Lastly, we can
    capture ethical considerations throughout the development life cycle, which ultimately
    ensures we’re using our powers for good.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore specific ways you can structure, optimize,
    and govern the process of using human annotators for your ML projects.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action](https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action),
    accessed on 1 June 2023'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/](https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/),
    accessed on 1 June 2023'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[解码AI在商业成果中的信任与伦理](https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/),
    访问于2023年6月1日'
