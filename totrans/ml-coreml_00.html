<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">We are living on the verge of a new era of computing, an era where computers are becoming more of a companion than a tool. The devices we carry in our pockets will soon better understand our world and us a lot better, and this will have a profound impact on how we interact with and use them.</p>
<p class="mce-root">But right now, a lot of these exciting advancements are stuck in the labs of researchers and not in the hands of designers and developers, making them usable and accessible to users. This is not because the details are locked away; on the contrary, in most cases they are freely available. </p>
<p class="mce-root">This gap is somewhat due to our contentment with sticking to what we know, having the user do all the work, making them tap on the buttons. If nothing else, I hope this book makes you curious about what is out there and how it can be used to create new experiences, or improve existing ones. </p>
<p class="mce-root">Within the pages of this book, you will find a series of examples to help you build an understanding of how deep neural networks work and how they can be applied.</p>
<p class="mce-root">This book focuses on a set of models for a better understanding of images and photos, specifically looking at how they can be adapted and applied on the iOS platform. This narrow focus of image-based models and the iOS platform is intentional; I find that the visual nature of images makes the concepts easier to, well, visualize, and the iPhone provides the perfect candidate and environment for experimentation.</p>
<p class="mce-root">So, as you go through this book, I encourage you to start thinking about new ways of how these models can be used and what new experiences you could create. With that being said, let's get started! </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p>This book will appeal to three broad groups of people. The first are intermediate iOS developers who are interested in learning and applying <strong>machine learning</strong> (<strong>ML</strong>); some exposure to ML concepts may be beneficial but are not essential as this book covers the intuition behind the concepts and models used throughout it.</p>
<p>The second group are those who have experience in ML but not in iOS development and are looking for a resource to help them to get the grips with Core ML; for this group, it is recommended to complement this book with a book that covers the fundamentals of iOS development. </p>
<p>The last group are experienced iOS developers and ML practitioners who are curious to see how various models have been applied in the context of the iOS platform. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p><a href="7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Machine Learning</em><span>, provides a brief introduction to ML, including some explanation of the core concepts, the types of problems, algorithms, and general workflow of creating and using a ML models. The chapter concludes by exploring some examples where ML is being applied.<br/></span></p>
<p><a href="e62127d6-36b4-4a52-8878-52de22374010.xhtml" target="_blank">Chapter 2</a>, <em>Introduction to Apple Core ML</em><span>, introduces Core ML, discussing what it is, what it is not, and the general workflow for using it.<br/></span></p>
<p><a href="5cf26de5-5f92-4d1d-8b83-3e28368df233.xhtml" target="_blank">Chapter 3</a>, <em>Recognizing Objects in the World</em><span>, walks through building a Core ML application from start to finish. By the end of the chapter, we would have been through the whole process of obtaining a model, importing it into the project, and making use of it.</span></p>
<p><a href="a89287b3-5c90-4f77-801f-371f7a8f2d36.xhtml" target="_blank">Chapter 4</a>, <em>Emotion Detection with CNNs</em><span>, explores the possibilities of computers understanding us better, specifically our mood. We start by building our intuition of how ML can learn to infer your mood, and then put this to practice by building an application that does just that. We also use this as an opportunity to introduce the Vision framework and see how it complements Core ML. </span></p>
<p><a href="6365f272-41e9-4511-a564-dc0f8db5d3ca.xhtml" target="_blank">Chapter 5</a>, <em>Locating Objects in the World</em><span>, goes beyond recognizing a single object to being able to recognize and locate multiple objects within a single image through object detection. After building our understanding of how it works, we move on to applying it to a visual search application that filters not only by object but also by composition of objects. In this chapter, we'll also get an opportunity to extend Core ML by implementing customer layers. </span></p>
<p><a href="40971e0d-b260-42e1-a9fb-5c4a56b0ebb2.xhtml" target="_blank">Chapter 6</a>, <em>Creating Art with Style Transfer</em><span>, uncovers the secrets behind the popular photo effects application, Prisma. We start by discussing how a model can be taught to differentiate between the style and content of an image, and then go on to build a version of  Prisma that applies a style from one image to another. We wrap up this chapter by looking at ways to optimize the model. </span></p>
<p><a href="8c90b4c8-30dc-4096-88f5-d9705f13f147.xhtml" target="_blank">Chapter 7</a>, <em>Assisted Drawing with CNNs</em><span>, walks through building an application that can recognize a users sketch using the same concepts that have been introduced in previous chapters. Once what the user is trying to sketch has been recognized, we look at how we can find similar substitutes using the feature vectors from a CNN. </span></p>
<p><a href="9be42b58-ce74-4863-8a3c-7ae3060cdc14.xhtml" target="_blank">Chapter 8</a>, <em>Assisted Drawing with RNNs</em>, builds on the previous chapter and explores replacing the the <strong>convolution neural network</strong> (<strong>CNN</strong>) with a <strong>recurrent neural network</strong> (<strong>RNN</strong>) for sketch classification, thus introducing RNNs and showing how they can be applied to images. Along with a discussion on learning sequences, we will also delve into the details of how to download and compile Core ML models remotely. </p>
<p><a href="a5ab58d1-0d7c-45e7-aea0-e9da1a7f3f4e.xhtml" target="_blank">Chapter 9</a>, <em>Object Segmentation Using CNNs</em><span>, walks through building an <em>ActionShot</em> photography application. And in doing so, we introduce another model and accompanying concepts, and get some hands-on experience of preparing and processing data.</span></p>
<p><span><a href="d358bddb-d137-4dfb-abcd-b6f9647edf9f.xhtml" target="_blank">Chapter 10</a>, <em>An Introduction to Create ML</em></span><span>, is the last chapter. We introduce Create ML, a framework for creating and training Core ML models within Xcode using Swift. By the end of this chapter, you will know how to quickly create, train, and deploy a custom models. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<p>To be able to follow through the examples in this book, you will need the following software:</p>
<ul>
<li>macOS 10.13 or higher </li>
<li>Xcode 9.2 or higher </li>
<li>iOS 11.0 or higher (device and simulator) </li>
</ul>
<p>For the examples that are dependent on Core ML 2, you will need the following software:</p>
<ul>
<li>macOS 10.14 </li>
<li>Xcode 10.0 beta </li>
<li>iOS 12 (device and simulator)</li>
</ul>
<p>It's recommended that you use <a href="https://notebooks.azure.com">https://notebooks.azure.com</a> (or some other Jupyter notebook service provider) to follow the examples using the Core ML Tools Python package, but those wanting to run locally or train their model will need the following software:</p>
<ul>
<li>Python 2.7 </li>
<li>Jupyter Notebooks 1.0</li>
<li>TensorFlow 1.0.0 or higher</li>
<li>NumPy 1.12.1 or higher</li>
<li>Core ML Tools 0.9 (and 2.0 for Core ML 2 examples)  </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p>You can download the example code files for this book from your account at <a href="http://www.packtpub.com" target="_blank">www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support" target="_blank">www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>You can download the code files by following these steps:</p>
<ol>
<li>Log in or register at <a href="http://www.packtpub.com/support" target="_blank">www.packtpub.com</a>.</li>
<li>Select the <span class="packt_screen">SUPPORT</span> tab.</li>
<li>Click on <span class="packt_screen">Code Downloads &amp; Errata</span>.</li>
<li>Enter the name of the book in the <span class="packt_screen">Search</span> box and follow the onscreen instructions.</li>
</ol>
<p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul>
<li>WinRAR/7-Zip for Windows</li>
<li>Zipeg/iZip/UnRarX for Mac</li>
<li>7-Zip/PeaZip for Linux</li>
</ul>
<p><span>The code bundle for the book is also hosted on GitHub at</span><span> <a href="https://github.com/PacktPublishing/Machine-Learning-with-Core-ML" target="_blank">https://github.com/PacktPublishing/Machine-Learning-with-Core-ML</a></span><span>. </span><span>In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p><span> </span><span>We also have other code bundles from our rich catalog of books and videos available at</span><span> </span><strong><span class="Object"><a href="https://github.com/PacktPublishing/" target="_blank">https://github.com/PacktPublishing/</a></span></strong><span>. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p>We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf" target="_blank">http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p>There are a number of text conventions used throughout this book.</p>
<p><kbd>CodeInText</kbd>: <span>Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: "At the top of the class, we have the <kbd>VideoCaptureDelegate</kbd> protocol defined."</p>
<p>A block of code is set as follows:</p>
<pre>public protocol VideoCaptureDelegate: class {<br/>    func onFrameCaptured(<br/>      videoCapture: VideoCapture, <br/>      pixelBuffer:CVPixelBuffer?, <br/>      timestamp:CMTime)<br/>}</pre>
<p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre>@IBOutlet var previewView:CapturePreviewView!<br/>@IBOutlet var classifiedLabel:UILabel!<br/> <br/><strong>let videoCapture : VideoCapture = VideoCapture()</strong></pre>
<p><strong>Bold</strong>: Indicates a new term, an important word, or w<span>ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "Select <span class="packt_screen">System info</span> from the <span class="packt_screen">Administration</span> panel.</span><span>"</span></p>
<div class="packt_infobox">Warnings or important notes appear like this.</div>
<div class="packt_tip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p>Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong>General feedback</strong>: Email <kbd>feedback@packtpub.com</kbd> and mention the book title in the subject of your message. If you have questions about any aspect of this book, please email us at <kbd>questions@packtpub.com</kbd>.</p>
<p><strong>Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/submit-errata" target="_blank">www.packtpub.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p><strong>Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd>copyright@packtpub.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong>If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p>Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p>For more information about Packt, please visit <a href="https://www.packtpub.com/" target="_blank">packtpub.com</a>.<a href="https://www.packtpub.com/" target="_blank"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>