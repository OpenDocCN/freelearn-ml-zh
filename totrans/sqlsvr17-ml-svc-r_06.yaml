- en: Predictive Modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测建模
- en: 'Predictive modeling is a process that is using advanced statistics and probability
    algorithms to predict outcomes, based on a pretrained and built model or function.
    These algorithms can be groups in a family of algorithms based on the outcome
    of the predicted variable. The outcome is usually the forecasted value that explains
    the future behavior. Several variables or input data consist of a mathematical
    function, also called the model (hence also data modeling), and these input data
    are trying to explain or predict the outcome. To better understand predictive
    modeling, the chapter will consist of the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 预测建模是一个过程，它使用高级统计和概率算法来预测结果，基于预训练和构建的模型或函数。这些算法可以根据预测变量的结果分为算法家族。结果通常是预测的值，它解释了未来的行为。几个变量或输入数据组成一个数学函数，也称为模型（因此也称为数据建模），这些输入数据试图解释或预测结果。为了更好地理解预测建模，本章将包括以下主题：
- en: Data modeling
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据建模
- en: Advanced predictive algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级预测算法
- en: Predictive analytics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测分析
- en: Deploying and using predictive solutions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署和使用预测解决方案
- en: Performing prediction with R Services in SQL Server database
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在SQL Server数据库中使用R服务进行预测
- en: 'The focus in this chapter will be on delivering insight into understanding
    how predictive modeling can be used in SQL Server 2016/2017, using R on your typical
    business problem. In the enterprise environment, a business problem can be defined
    in a very broad aspect. For example, in medicine, a typical problem that predictive
    modeling can help understand and solve is, will the change of the ingredient A
    and B for the medicine C, help cure the disease? Furthermore, in the metallurgic
    industry, can we simulate how an anti-corrosion coating paint will age through
    time—or in retails, how can a customer select a better product in a store based
    on their needs or behavior? One can say, our everyday life is intertwined with
    predictions and forecast. Usually, every logistical problem all of us are facing
    is a simple question on a potentially very relevant topic: if I leave home for
    work 5 minutes later, will this affect my driving time if I take one shortcut
    and so on and so forth. Literally, we can say, our everyday decisions are the
    sum of all actions we take with a given output.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点将在于深入探讨如何在SQL Server 2016/2017中使用R来解决典型的商业问题，以了解预测建模的应用。在企业环境中，一个商业问题可以从一个非常广泛的方面来定义。例如，在医学领域，预测建模可以帮助理解和解决的一个典型问题可能是：药物C中成分A和B的变化是否有助于治愈疾病？此外，在冶金行业，我们能否模拟防腐蚀涂料漆随时间老化的过程——或者在零售业，顾客如何根据他们的需求或行为在商店中选择更好的产品？可以说，我们的日常生活与预测和预测息息相关。通常，我们所有人面对的每一个物流问题都是一个关于可能非常相关主题的简单问题：如果我晚5分钟离开家去上班，如果我走一条捷径，这会影响我的驾驶时间吗？等等。实际上，我们可以说，我们的日常决策是我们采取的所有行动的输出总和。
- en: Data modeling
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据建模
- en: Data modeling is a process where we try to find a function (or the so-called
    model) with a set of independent variables or input data. Just like in data warehousing,
    where modeling is referring to establishing the conceptual framework based on
    the physical data structure and with the help of ORM or UML (even CRC) diagrams
    one explores the structures in data the same is seen with exploring the structures
    when doing predictive analysis. In case of the latter, data modeling is exploring
    the structures (or relations) between two or more variables. These relations can
    be presented as a function and are essentially stored as a model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模是一个过程，我们试图找到一组独立变量或输入数据的一个函数（或所谓的模型）。就像在数据仓库中，建模是指基于物理数据结构建立概念框架，并在ORM或UML（甚至CRC）图的帮助下探索数据结构，这与在预测分析中探索结构时看到的是一样的。在后一种情况下，数据建模是探索两个或多个变量之间的结构（或关系）。这些关系可以表示为一个函数，并且本质上存储为模型。
- en: 'To start modeling, we will use some of the Microsoft data available at the
    following GitHub repository:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始建模，我们将使用以下GitHub仓库中可用的Microsoft数据：
- en: '[https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/machine-learning-services/python/getting-started/rental-prediction](https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/machine-learning-services/python/getting-started/rental-prediction)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/machine-learning-services/python/getting-started/rental-prediction](https://github.com/Microsoft/sql-server-samples/tree/master/samples/features/machine-learning-services/python/getting-started/rental-prediction)'
- en: 'Do not get confused at this Python example:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在这个Python示例中感到困惑：
- en: '![](img/00087.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Downloading this database will download the `TutorialDB.bak` file, which you
    simply restore to your SQL Server instance, where R in-database is installed.
    This database is included as part of the accompanying code that comes with this
    chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Part of modeling data is to set up the understanding of how predictions at
    a later phase will work. Therefore, in this phase, we will create an understanding
    of the variables and their relation to each other. Create restore from the downloaded
    file and run the following restore from the backup T-SQL command:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Alternatively, you can simply use the `RESTORE` command in SSMS:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00088.gif)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: You will now have the database restored and the `dbo.rental_data` table at your
    use. For now, this will be enough.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'With the dataset ready, we can now start modeling the data by exploring and
    understanding the variables and the relations among them. This quick exploration
    can be performed in SQL Operation Studio (link to download: [https://docs.microsoft.com/en-us/sql/sql-operations-studio/download](https://docs.microsoft.com/en-us/sql/sql-operations-studio/download)),
    where we will use a simple query:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Besides the standard table view of the results, this will also give a nice
    chart viewer, where a simple graphical representation of variables will give you
    better insights into the data:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00089.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: 'But without the general understanding of descriptive statistics, we will not
    continue. So, using the `rxSummary` function from the `RevoScaleR` package will
    give the desired results:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following are the results as a simple descriptive statistics table:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00090.gif)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: 'Exploring the uni- and bi-variate statistics was part of the previous [Chapter
    5](part0081.html#2D7TI0-e3f81285367248f4bbc6431bcd4f926d),* RevoScaleR Package,*
    but here we will focus more on bi- and multi-variate statistics. Before we begin,
    let''s explore the correlations some more. Based on exploring the variable names
    and descriptive statistics, common sense will tell us that during the holidays,
    the rental count should be higher. Checking this can be done using the correlation
    coefficient. The following is a simple example:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will give you the idea of the bi-variate relationship of `0.332`. This
    is a weak correlation but a positive one:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00091.gif)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: This simply means that if the `RentalCount` variable gets higher, the number
    of holidays also increases. This indeed makes sense, since if more holidays are
    coming, more rentals are expected.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can continue exploring and searching for the correlations by combining
    each of the variables. This is similar to making a CROSS JOIN, but there are easier
    ways to do this. One is, of course, by using common sense and selecting the meaningful
    correlations:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And we get the following results as shown in the figure below. Interpretation
    and understanding of the results is of high importance. So, the holiday time is
    by far the most correlative variable with rental count variable. Neither the day
    of the week, nor the year, play any significant role. There is a very tiny, yet
    negative correlation of `-0.110` between `Month` and `RentalCount`, which can
    be understood as higher months might have lower rental counts and vice versa.
    Since this correlation is so weak, it is meaningless to make a fuss over of this
    particular correlation (even if it makes or does not make any sense):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00092.gif)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, one can explore the distribution of the values within each variable
    by plotting the boxplots:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00093.gif)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: 'The second way is to plot the diagram of correlations between the variables.
    One way to do it is to invoke the `corrplot` R library, which gives you a very
    powerful and useful visualization of correlation. I tend to create the following
    code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Code copied and slightly changed from the corrplot lattice documentation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'This procedure can be directly implemented and used in SSRS or in Power BI
    suit or Excel; the visual is as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00094.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: In a single graph, a trained eye will immediately see the correlations and their
    statistical significance. So, the `0.33 RentalCount` and `Holiday` is visible
    here, but also the `RentalCount` and `Snow` is of `0.19` positive correlation.
    But if we want to explore the behavior of the values dispersion (variance), we
    can also include the analysis of variance.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are working with large datasets or XDF data formats, `RevoScaleR` package
    also comes equipped with functions that compute and calculate correlation matrixes.
    Here is an R code using `rxCovCor` (or, alternatively, one can use `rxCor` or
    `rxCov`):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This gives the same results as all the previous calculation of correlations:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00095.gif)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: This output also has the ability to see the standard deviations, means and sum
    of weights, but the best part is that it stores the results in a data frame, which
    can be easily imported or used with other T-SQL tables. The results can be invoked
    using `allCov$CovCor` (R language stores the results as an object of lists and
    each list can be retrieved by using a dollar sign `$` and referencing the name
    of the list—in this case, `CovCor`).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'When we want to further investigate our so-far highest correlation between
    the `RentalCount` and `Holiday`, **Analysis Of Variance **(**ANOVA**) will be
    the appropriate method. We will compare two groups (or levels) of variable `Holiday`
    (`0` is not a holiday while `1 ` is a holiday) and whether there is a difference
    between the rental counts. By doing so, calculating F-statistics and its significance
    will tell us the ratio of between-group variance to within-group variance:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After running the T-SQL code with R code for statistical calculation of ANOVA,
    the output result is created in such manner that it returns the F-Statistic and
    statistical significance. The following figure shows results returned:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00096.gif)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: Results tell us that the F-Statistic is statistically significant—even though
    it is small—and this means that the means are most likely not equal (and we would
    be, in this case, rejecting the null hypothesis). To find where the difference
    lies, `TukeyHDS` test would give us further information.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to illustrate the difference, since we will not go into the details, we
    can use the `stripchart` visualization of the difference between the holiday distribution
    of the rentals:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00097.gif)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: 'With the R code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The distribution of the cases can tell us that on holidays an average of `400`
    or higher rental counts are made, whereas on a normal day, there is a huge density
    of counts between `10` and `50`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'When determining which features (variables) are good for further analysis and
    predictive algorithms, we can use the Decrease Gini mean calculation. One of the
    Gini mean functions is available in `randomForest` package, so, let''s call the
    function and see which variables are to be used:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With T-SQL code we are returning the decreased Gini coefficient:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00098.gif)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
- en: '`Gini` coefficient can also be represented visually as a scatter plot, so that
    the user can immediately determine which variables contribute most to the model.
    For the sake of brevity, the code for this graph is included in the code but not
    in the book.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00099.gif)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: One can now determine, which of the following variables play any role or contribute
    gain in the model. The **MeanDecreaseGini** was drawn as `varImpPlot(fit_RF)`.
    Technically, this is how one can determine which variables or input parameters
    have the least or most impact, but each of these techniques will give you some
    of the aspects—what can be good in the model, and what may not. Comparing the
    `Holiday` variable in the correlation matrix and mean decrease plot, you can see
    that it gives different methods and different results. Most significant are the
    ones where particular variables do not play any importance whatsoever through
    several different methods.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Advanced predictive algorithms and analytics
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have examined the data preparation and data exploration functions
    available in the `RevoScaleR` package. Besides these functions, predicting classification
    or regression problems can also be done, especially when dealing with large datasets.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'I will mention only few of these. The complete list is available online ([https://docs.microsoft.com/en-us/machine-learning-server/r-reference/revoscaler/revoscaler](https://docs.microsoft.com/en-us/machine-learning-server/r-reference/revoscaler/revoscaler))
    and some of the points are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`rxLinMod`: This is used for building and predicting a linear model'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rxLogit`: This is used for building and predicting the logistic regression
    model'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxLogit`：这个函数用于构建和预测逻辑回归模型'
- en: '`rxGlm`: This is used for creating a generalized linear model'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxGlm`：这个函数用于创建广义线性模型'
- en: '`rxDTree`: This is used for creating a classification or regression tree'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxDTree`：这个函数用于创建分类或回归树'
- en: '`rxBTrees`: This is used for building a classification or regression decision
    forest—that is using a stochastic gradient boosting algorithm'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxBTrees`：这个函数用于构建分类或回归决策森林——即使用随机梯度提升算法'
- en: '`rxDForest`: This is used for building a classification or regression decision
    forest model'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxDForest`：这个函数用于构建分类或回归决策森林模型'
- en: '`rxNaiveBayes`: This is used for building a Naive Bayes classification model'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rxNaiveBayes`：这个函数用于构建朴素贝叶斯分类模型'
- en: All these algorithms are part of a family of supervised algorithms, where the
    only unsupervised (or undirected) algorithm available in `RevoScaleR` package
    is `rxKMeans`, which is used for dealing with clustering.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些算法都是监督算法家族的一部分，其中`RevoScaleR`包中唯一的无监督（或非指导）算法是`rxKMeans`，它用于处理聚类。
- en: 'Using the same dataset as we did earlier, we plug in and start using `rxLinMod`
    and `rxGlm` for demonstrating how this can be used within T-SQL:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前使用的相同数据集，我们插入并开始使用`rxLinMod`和`rxGlm`来演示如何在T-SQL中使用它们：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Both will give you the predicted values based on the inputted dataset, along
    with the newly predicted values:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个都会根据输入的数据集提供预测值，以及新的预测值：
- en: '![](img/00100.gif)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00100.gif)'
- en: 'A curious eye will tell you that the predicted values are far-off from the
    original values. So, the prediction formula in both cases was trying to predict
    variable `RentalCount` based on variables: `Year`, `Month`, `Day`, `WeekDay`,
    `Snow`, and `Holiday`. The formula is set as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好奇的眼睛会告诉你，预测值与原始值相差甚远。因此，两种情况下的预测公式都在尝试根据变量：`Year`（年）、`Month`（月）、`Day`（日）、`WeekDay`（星期几）、`Snow`（雪）和`Holiday`（假日）来预测变量`RentalCount`。公式设置如下：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Comparing the variables `RentalCount_Pred` and `RentalCount` will show the difference/offset
    from the real and predicted values.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 比较变量`RentalCount_Pred`和`RentalCount`将显示真实值和预测值之间的差异/偏移量。
- en: 'In the preceding sample, you can also compare the results of all the three
    algorithms. If you run comparison with all three datasets, observation by observation,
    you can see immediately which algorithms performed best:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您还可以比较所有三个算法的结果。如果您对所有三个数据集进行逐个观察的比较，您可以立即看到哪些算法表现最好：
- en: '![](img/00101.jpeg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00101.jpeg)'
- en: So, the yellow bar represents the original values, and by far the best hit is
    the decision trees algorithm, given the upper formula and understanding the insights
    of the data. The graph just represents a randomly taken observation. This can
    also be achieved by calculating the accuracy or measure that calculates how much
    deviation had accrued from the original values.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，黄色条形表示原始值，迄今为止，决策树算法在给定上述公式并理解数据洞察的情况下，是最准确的。图表仅代表随机选取的观察结果。这也可以通过计算准确度或衡量标准来实现，该标准计算了与原始值之间的偏差程度。
- en: Deploying and using predictive solutions
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署和使用预测解决方案
- en: When developing the in-database solution and creating it for continuous development
    (and also deployment), several aspects should be taken into consideration. First
    of all, the environment where data scientists will be working. You might give
    them a powerful, standalone server or even allocate proper seats in the cloud.
    They will need it, especially when training the model. This is extremely important,
    as you don't want to have your highly-paid statisticians and mathematicians wait
    for the models to compute and generate. So, enabling the route to a highly scalable
    CPU and RAM powerful computations is a must. Second to this, you have to get the
    data there. Whether it's on cloud or on premises, getting data there (and later
    also, back) should not be overlooked, as this might also be the point where you
    will lose precious time. And, lastly, having the environment set with proper settings,
    environment variables, packages, and all paths to proprietary software enabled
    is also of importance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '`RevoScaleR` package comes equipped with a function for easily switching the
    computational environments. We will now invoke a simple command in R:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: By doing this, you can set the local computational environment (that is, the
    client's machine) or the server side, where—in this case—a standalone R Server
    would reside. With a simple function call, the computational context (or simple
    environment) is switched, as course, keeping in mind that all the data resides
    on both sides (so that you avoid the unneeded data transferring) and that all
    the server environment variables are set correctly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: For training the model, several good practices can be chosen. Splitting the
    data for training, testing or training, and testing and validating are several
    practices. Also, a very good practice is to test the percentage of training/testing/validating
    datasets. You might get a 50/50 or 60/40 or 70/30 percentage, but usually you
    carry out and decide this when mining the data. After that, you should also consider
    validation of the data; several aspects are available, from **leave one out**
    (**LOO**) or 10-folds or 5-folds for choosing the validation data for validating
    the results.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Not going into the topic too deep, and to make this demo simpler, we can decide
    to do a 70/30 percentage on the spot. Since we have the pleasure of the T-SQL
    database here, we can select and store the training subset in a table, or create
    a view, or decide which 70% we want to take.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This also heavily depends on your business model. The first approach simply
    takes 70% of the data from the original dataset, whereas the second select statement
    takes roughly 70% of the original data, but makes a split based on the year of
    the rental. This might have a crucial impact on how the model will behave and
    also how you want the decision to be affected by this, especially the business
    model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'Once this is cleared and covered, a best practice is to store the trained model
    in the tables for faster predictions. We will now create a table as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Since the `set.seed` is defined, you will always get the same subset, wherever
    you run this code. If you want to get different results, you should comment it
    out.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the sampling is done again, based on the problem you are predicting, you
    need to define your prediction formula. In this case, I am using a formula converter
    to create a proper formula:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Creating a formula through a procedure, making it not hard coded, is also a
    very useful approach, especially in the corporate environment where data scientists
    will set up the pool of independent variables and later the data engineer would
    choose which to include, prior to pushing the data to compute the model and deploy
    it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: The process of bi-variate and multi-variate statistics can also give the data
    engineers and stewards better insights and understanding of what and how the data
    is operating and correlating, and that there are no unwanted correlations or variables
    that just do not function.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'With this cleared up, we can set up and build the procedures that will run
    the model training and have the models stored in the database. Due to the space
    limits of this chapter, I will only show the creation of one procedure; the rest
    of the procedures can be found in the accompanying chapter materials:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'The procedure for random forest in T-SQL would look like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: I have added something extra to the procedure, such that every time the model
    is trained, an extra is added. This is accuracy, which will also give the data
    engineer and stewards in the later phases a good insight into deciding which model
    outperforms the others.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'You can simply run the procedure as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This will populate the destination table where the models are kept. The results
    should be stored in the table `[dbo].[Rental_data_models]`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00102.gif)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: Once this is done, you need to have the evaluation procedure set as well that
    will help determine which model functions the best. However, this part can be
    done using Power BI, or reporting services, or simply just R.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'This is part of R code that can be included in your visualization tool for
    easier comprehension:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The observed values should tell you which model is performing best. Once you
    have done this, you can choose the model and see how the predictions can be done.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Performing predictions with R Services in the SQL Server database
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Calling stored procedures is the easiest way to organize your code and start
    predicting right away.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, only a sample will be shown here of how to create a stored procedure
    to predict new datasets:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Once this is done, you can start predicting using the following code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And, as a result, you will get a predicted value for the variables of `Year`,
    `Month`, `Day`, `WeekDay`, `Holiday`, and `Snow`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00103.gif)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: 'Intentionally, the field `OrigPredictedCount` was set to `0`, but the new predicted
    value is the value of `278.996` and that is based on the input variables. While
    checking how the model learned, it is best to also check the original value:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 故意将字段`OrigPredictedCount`设置为`0`，但新的预测值是`278.996`，这是基于输入变量的。在检查模型学习情况时，最好也检查原始值：
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We see that there is no values in month`= 5`, so the model must have it learned
    from other values:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到在`month`= 5`中没有值，因此模型必须从其他值中学习：
- en: '![](img/00104.gif)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00104.gif)'
- en: Now that we have covered the supervised predictive algorithms, let's quickly
    jump into the cluster—part of the functions that `RevoScaleR` package supports
    as the only undirected algorithm.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了监督预测算法，让我们快速跳入聚类——`RevoScaleR`包支持的唯一无向算法的一部分。
- en: 'The following is the example of how to create a simple clustering:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何创建简单聚类的示例：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following is the output, which is the presentation of the clusters:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出是聚类的展示：
- en: '![](img/00105.gif)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00105.gif)'
- en: To explore the clustering and play with different number of clusters, one thing
    for sure would be to use R code directly or to create a report for exploring the
    characteristics of clusters using Power BI, Excel, or SSRS.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要探索聚类并尝试不同的聚类数量，直接使用R代码或创建一个报告来使用Power BI、Excel或SSRS探索聚类特征，这是肯定的事情。
- en: Adding some additional information on cluster centers, statistics as `withinSS`,
    `betweenSS`, `totSS`, and others will also help us to understand the clusters.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 添加有关聚类中心、统计信息如`withinSS`、`betweenSS`、`totSS`等额外信息也将帮助我们理解聚类。
- en: Scree plot is also an additional and very nice presentation of choosing the
    correct number of clusters. Adding such graphics into a report will also help
    the user choose the right number of clusters and help them understand what and
    how clusters are formed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Scree图也是选择正确聚类数量的额外且非常棒的表现方式。将此类图形添加到报告中也有助于用户选择正确的聚类数量，并帮助他们理解聚类是如何形成的。
- en: 'Scree plot R code is used for determining where elbow is happening and does
    whether it has the right number of clusters; if so, three clusters would be an
    optimum number:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Scree图R代码用于确定肘部在哪里发生，以及它是否有正确的聚类数量；如果是的话，三个聚类将是一个最佳数量：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'On this plot we can see where the elbow is being created and we can determine
    that the best solution is three clusters:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，我们可以看到肘部在哪里形成，我们可以确定最佳解决方案是三个聚类：
- en: '![](img/00106.gif)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00106.gif)'
- en: 'Putting everything together into a report (SSRS report) makes exploring even
    better:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容整合到报告中（SSRS报告）使探索更加完善：
- en: '![](img/00107.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00107.jpeg)'
- en: 'The user can change the number of clusters by selecting the desired number
    and the report will change accordingly. The report is based on three additional
    procedures that export the graphs based on the inputted number of clusters:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以通过选择所需的聚类数量来更改聚类数量，报告将相应地更改。该报告基于三个额外的过程，这些过程基于输入的聚类数量导出图形：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Running this in SSMS will give you a var binary string, but adding the result
    of this procedure as an image in SSRS or Power BI/Excel will yield a plot derived
    from R.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在SSMS中运行此操作将给出一个var binary字符串，但将此过程的结果作为图像添加到SSRS或Power BI/Excel中，将得到一个由R生成的图表。
- en: Adding a nice visualization to your exploratory project upon building a predictive
    analytics system is definitely a very nice wrap-up for business and end users,
    as well as for the data wranglers and engineers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建预测分析系统后，为探索性项目添加一个漂亮的可视化效果，对于商业用户、数据整理员和工程师来说，无疑是一个非常好的总结。
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have covered the extensible functionalities of the `RevoScaleR`
    package to deliver fast and good predictions based on the explored datasets. In
    the previous chapter *Statistical learning with RevoScaleR package*, we have covered
    data exploration, preparation and simple and bi-variate statistics. This chapter
    showed how `RevoScaleR` package was designed to work with large datasets (that
    overcome the limitations of RAM and single CPU), enabling spill to disk and multi
    threading. The same procedures can be used as well in database instances of R,
    for delivering the predictions to your business and data residing in the database.
    We have covered this aspect as well, exploring different algorithms and comparing
    the solutions. Once you have your model selected, you may want to use the `PREDICT`
    clause. which is a new feature in SQL Server 2017 with a slightly altered architecture.
    Please note that currently (at the time of writing this chapter) the model size
    can not exceed 100 MB if you want to use `PREDICT` clause. Currently, only `RevoScaleR`
    and `MicrosoftML` packages are supported to use this clause, and not even all
    `RevoScaleR` (and MicrosoftML) algorithms are supported—currently supported are
    `rxLinMod`, `rxLogit`, `rxBTrees`, `rxDtree`, `rxdForest`. However, this real-time
    scoring with `PREDICT` clause will definitely develop and evolve in the next release
    of SQL Server.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: We need to predict a classification or regression problem. The majority of the
    problems can be supported using `RevoScaleR` package and many of these algorithms
    were also empowered by a new set of additional classifiers available in the `MicrosoftML`
    package. Exploring both packages will give your decision-making a much-needed
    boost. Also, storing serialized models into the database is an optimal way of
    storing and calling trained models (functions) that can be retrained by adding
    a simple logic implementation using SQL Server agents or triggers.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 07](part0102.html#318PC0-e3f81285367248f4bbc6431bcd4f926d), *Operationalizing
    R Code*, you will learn how to operationalize your model and solution and explore
    different ways how to do it and some good practices.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
