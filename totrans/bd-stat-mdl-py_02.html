<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer041">
<h1 class="chapter-number" id="_idParaDest-26"><a id="_idTextAnchor029"/>2</h1>
<h1 id="_idParaDest-27"><a id="_idTextAnchor030"/>Distributions of Data</h1>
<p><a id="_idTextAnchor031"/>In this chapter, we will cover the essential aspects of data and distributions. We will start by covering the types of data and distributions of data. Having covered the essential measurements of distributions, we will describe the normal distribution and its important properties, including the central limit theorem. Finally, we will cover resampling methods such as permutations and transformation methods such as log transformations. This chapter covers the foundational knowledge necessary to begin <span class="No-Break">statistical modeling.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Understanding <span class="No-Break">data types</span></li>
<li>Measuring and <span class="No-Break">describing distributions</span></li>
<li>The normal distribution and the central <span class="No-Break">limit theorem</span></li>
<li><span class="No-Break">Bootstrapping</span></li>
<li><span class="No-Break">Permutations</span></li>
<li><span class="No-Break">Transformations</span></li>
</ul>
<h1 id="_idParaDest-28"><a id="_idTextAnchor032"/>Technical requirements</h1>
<p>This chapter will make use of <span class="No-Break">Python 3.8.</span></p>
<p>The code for this chapter can be found here – <a href="https://github.com/PacktPublishing/Building-Statistical-Models-in-Python">https://github.com/PacktPublishing/Building-Statistical-Models-in-Python</a> – in the <span class="No-Break"><strong class="source-inline">ch2</strong></span><span class="No-Break"> folder.</span></p>
<p>Please set up a virtual environment or Anaconda environment with the following <span class="No-Break">packages installed:</span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline">numpy==1.23.0</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">scipy==1.8.1</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">matplotlib==3.5.2</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">pandas==1.4.2</strong></span></li>
<li><span class="No-Break"><strong class="source-inline">statsmodels==0.13.2</strong></span></li>
</ul>
<h1 id="_idParaDest-29"><a id="_idTextAnchor033"/>Understanding data types</h1>
<p>Before <a id="_idIndexMarker076"/>discussing data distributions, it would be useful to understand the types of data. Understanding data types is critical because the type of data determines what kind of analysis can be used since the type of data determines what operations can be used with the data (this will become clearer through the examples in this chapter). There are four distinct types <span class="No-Break">of data:</span></p>
<ul>
<li><span class="No-Break">Nominal data</span></li>
<li><span class="No-Break">Ordinal data</span></li>
<li><span class="No-Break">Interval data</span></li>
<li><span class="No-Break">Ratio data</span></li>
</ul>
<p>These types of data can also be grouped into two sets. The first two types of data (nominal and ordinal) are <strong class="bold">qualitative data</strong>, generally <a id="_idIndexMarker077"/>non-numeric categories. The last two types of<a id="_idIndexMarker078"/> data (interval and ratio) are <strong class="bold">quantitative data</strong>, generally <span class="No-Break">numeric values.</span></p>
<p>Let’s start with <span class="No-Break">nominal data.</span></p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor034"/>Nominal data</h2>
<p>Nominal data is <a id="_idIndexMarker079"/>data labeled with distinct groupings. As an example, take machines in a sign factory. It is common for factories to source machines <a id="_idIndexMarker080"/>from different suppliers, which would also have different model numbers. For example, the example factory may have 3 of <strong class="bold">Model A</strong> and 5 of <strong class="bold">Model B</strong> (see <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.1</em>). The machines would make up a set of nominal data where <strong class="bold">Model A</strong> and <strong class="bold">Model B</strong> are the distinct group labels. With nominal data, there is only one operation that can be performed: equality. Each member of a group is equal while members from different groups are unequal. In our factory example, a <strong class="bold">Model A</strong> machine would be equal to another <strong class="bold">Model A</strong> machine while a <strong class="bold">Model B</strong> machine would be unequal to a <strong class="bold">Model </strong><span class="No-Break"><strong class="bold">A</strong></span><span class="No-Break"> machine.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer021">
<img alt="Figure 2.1 – Two groups of machines in a factory" height="331" src="image/B18945_02_001.jpg" width="596"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – Two groups of machines in a factory</p>
<p>As we can see, with this type of data, we can only group items together under labels. With the next type of data, we will introduce a new <span class="No-Break">feature: order.</span></p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor035"/>Ordinal data</h2>
<p>The<a id="_idIndexMarker081"/> next type <a id="_idIndexMarker082"/>of data is like nominal data but exhibits an order. The data can be labeled into distinct groups and the groups can be ordered. We call this type of data ordinal data. Continuing with the factory example, let’s suppose that there is a <strong class="bold">Model C</strong> machine, and <strong class="bold">Model C</strong> is supplied by the same vendor as <strong class="bold">Model B</strong>. However, <strong class="bold">Model C</strong> is the high-performance version, which generates higher output. In this case, <strong class="bold">Model B</strong> and <strong class="bold">Model C</strong> are ordinal data because <strong class="bold">Model B</strong> is a lower-output machine, and <strong class="bold">Model C</strong> is a higher-output machine, which creates a natural order. For instance, we can put the model labels in ascending order of performance: <strong class="bold">Model B</strong>, <strong class="bold">Model C</strong>. University education levels are another example of ordinal data with the levels BS, MS, and PhD. As mentioned, the new operation for this type of data is ordering, meaning the data can be sorted. Thus, ordinal data supports order and equality. While this type of data can be ordered in ascending or descending order, we cannot add or subtract the data, meaning <strong class="bold">Model B</strong> + <strong class="bold">Model C</strong> is not a meaningful statement. The next type of data we will discuss will support addition <span class="No-Break">and subtraction.</span></p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor036"/>Interval data</h2>
<p>The<a id="_idIndexMarker083"/> next type of data, interval data, is used to describe data that <a id="_idIndexMarker084"/>exists on an interval scale but does not have a clear definition of zero. This means the difference between two data points is meaningful. Take the Celsius temperature scale, for example. The data points are numeric, and the data points are evenly spaced at an interval (for example, 20 and 40 are both 10 degrees away from 30). In this example of the temperature scale, the definition of 0 is arbitrary. For Celsius, 0 happens to be set at water’s freezing point, but this is an arbitrary choice made by the designers of the scale. So, the interval data type supports equality, ordering, <span class="No-Break">and addition/subtraction.</span></p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor037"/>Ratio data</h2>
<p>The <a id="_idIndexMarker085"/>final data type<a id="_idIndexMarker086"/> is ratio data. Like interval data, ratio data is ordered numeric data, but unlike interval data, ratio data has an absolute 0. Absolute 0 means that if the value of a ratio-type variable is zero, none of that variable exists or is present. For example, consider wait times for rides at an amusement park. If no<a id="_idIndexMarker087"/> one is in line<a id="_idIndexMarker088"/> for the ride, the wait time is 0; new guests can ride the amusement ride immediately. There is no meaningful negative measurement for wait times. A wait time of 0 is the absolute minimum value. Ratio data also supports meaningful multiplication/division, making ratio data the type of data with the most <span class="No-Break">supported operations.</span></p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor038"/>Visualizing data types</h2>
<p>Data visualization<a id="_idIndexMarker089"/> is a critical step for understanding distributions<a id="_idIndexMarker090"/> and identifying properties of data. In this chapter (and throughout this book), we will utilize <strong class="source-inline">matplotlib</strong> for visualizing data. While other Python libraries can be used for visualizing data, <strong class="source-inline">matplotlib</strong> is the de facto standard plotting library for Python. In this section, we will begin using <strong class="source-inline">matplotlib</strong> to visualize the four types of data <span class="No-Break">discussed previously.</span></p>
<h3>Plotting qualitative data types</h3>
<p>Since <a id="_idIndexMarker091"/>the first two types of data are <a id="_idIndexMarker092"/>categorical, we will use a bar chart to visualize these distributions of data. Example bar charts are shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer022">
<img alt="Figure 2.2 – Nominal data in a bar chart (left) and ordinal data in a bar chart (right)" height="480" src="image/B18945_02_002.jpg" width="1039"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – Nominal data in a bar chart (left) and ordinal data in a bar chart (right)</p>
<p>The left <a id="_idIndexMarker093"/>bar chart in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.2</em> shows the <a id="_idIndexMarker094"/>distribution of the <strong class="bold">Model A</strong> machines and <strong class="bold">Model B</strong> machines given in the factory example. The right bar chart shows an example distribution of the education levels of a team of engineers. Note that in the education level bar chart, the <em class="italic">x</em>-axis labels are ordered from the lowest level of education to the highest level <span class="No-Break">of education.</span></p>
<p>The code used to generate <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.2</em> is <span class="No-Break">shown next.</span></p>
<p>The code has three <span class="No-Break">main parts.</span></p>
<ul>
<li><strong class="bold">The </strong><span class="No-Break"><strong class="bold">library imports</strong></span><span class="No-Break">:</span></li>
</ul>
<p>In this case, we are only importing <strong class="source-inline">pyplot</strong> from <strong class="source-inline">matplotlib</strong>, which is canonically imported <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">plt</strong></span><span class="No-Break">.</span></p>
<ul>
<li><strong class="bold">The code for </strong><span class="No-Break"><strong class="bold">data creation</strong></span><span class="No-Break">:</span></li>
</ul>
<p>After the <strong class="source-inline">import</strong> statement, there are a few statements to create the data we will plot. The data for the first plot is stored in two Python lists: <strong class="source-inline">label</strong> and <strong class="source-inline">counts</strong>, which contain the machine labels and the number of machines, respectively. It’s worth noting that each of these two lists contains the same number of elements (two elements). The education data is stored similarly. While in this example, we are using simple example data, in later chapters, we will have additional steps for retrieving and <span class="No-Break">formatting data.</span></p>
<ul>
<li><strong class="bold">The code for plotting </strong><span class="No-Break"><strong class="bold">the data</strong></span><span class="No-Break">:</span></li>
</ul>
<p>The final <a id="_idIndexMarker095"/>step is plotting the data. Since<a id="_idIndexMarker096"/> we are plotting two sets of data in this example, we use the <strong class="source-inline">subplots</strong> method, which will create a grid of plots. The first two arguments to <strong class="source-inline">subplots</strong> are the number of rows and the number of columns for the grid of figures. In our case, the number of rows is <strong class="source-inline">1</strong> and the number of columns is <strong class="source-inline">2</strong>. The <strong class="source-inline">subplots</strong> method returns two objects; the figure, <strong class="source-inline">fig</strong>, and the axes, <strong class="source-inline">ax</strong>. The first returned object, <strong class="source-inline">fig</strong>, has high-level controls over the figure, such as saving the figure, showing the figure in a new window, and many others. The second object, <strong class="source-inline">ax</strong>, will either be an individual axis object or an array of axis objects. In our case, <strong class="source-inline">ax</strong> is an array of axes objects – since our grid has two plots, indexing into <strong class="source-inline">ax</strong> gives us the axes object. We use the <strong class="source-inline">bar</strong> method of an axes object to create a bar chart. The <strong class="source-inline">bar</strong> method has two required arguments. The first required argument is the list of labels. The second argument is the bar heights that correspond to each label, which is why the two lists must have the same length. The other three methods, <strong class="source-inline">set_title</strong>, <strong class="source-inline">set_ylabel</strong>, and <strong class="source-inline">set_xlabel</strong>, set the values for the corresponding plot attributes: <strong class="source-inline">title</strong>, <strong class="source-inline">ylabel</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">x-label</strong></span><span class="No-Break">.</span></p>
<p>Finally, the figure is created <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">fig.show()</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
import matplotlib.pyplot as plt
label = ['model A', 'model B']
counts = [3, 5]
edu_label = ['BS', 'MS', 'PhD']
edu_counts = [10, 5, 2]
fig, ax = plt.subplots(1, 2, figsize=(12, 5))
ax[0].bar(label, counts)
ax[0].set_title('Counts of Machine Models')
ax[0].set_ylabel('Count')
ax[0].set_xlabel('Machine Model')
ax[1].bar(edu_label, edu_counts)
ax[1].set_title('Counts of Education Level')
ax[1].set_ylabel('Count')
ax[1].set_xlabel('Education Level')
fig.show()</pre>
<p>Now let’s look <a id="_idIndexMarker097"/>at how to plot data from<a id="_idIndexMarker098"/> the other two <span class="No-Break">data types.</span></p>
<h3>Plotting quantitative data types</h3>
<p>Since<a id="_idIndexMarker099"/> the last two data types are numeric, we <a id="_idIndexMarker100"/>will use a histogram to visualize the distributions. Two example histograms are shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer023">
<img alt="Figure 2.3 – Nominal data in a bar chart (left) and ordinal data in a bar chart (right)" height="479" src="image/B18945_02_003.jpg" width="1054"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – Nominal data in a bar chart (left) and ordinal data in a bar chart (right)</p>
<p>The<a id="_idIndexMarker101"/> left histogram is synthetic wait time data (ratio data) that might represent wait times at an amusement park. The right<a id="_idIndexMarker102"/> histogram is temperature data (interval data) for the Dallas-Fort Worth area during April and May of 2022 (pulled <span class="No-Break">from </span><a href="https://www.iweathernet.com/texas-dfw-weather-records"><span class="No-Break">https://www.iweathernet.com/texas-dfw-weather-records</span></a><span class="No-Break">).</span></p>
<p>The code used to generate <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.3</em> is shown next. Again, the code has three main parts, the library imports, the code for data creation, and the code for plotting <span class="No-Break">the data.</span></p>
<p>Like in the previous example, <strong class="source-inline">matplotlib</strong> is imported as <strong class="source-inline">plt</strong>. In this example, we also import a function from <strong class="source-inline">scipy</strong>; however, this function is only used for generating sample data to work with and we will not discuss it at length here. For our purposes, just think of <strong class="source-inline">skewnorm</strong> as producing an array of numbers. This code block is very similar to the previous <span class="No-Break">code block.</span></p>
<p>The main difference is the method used for plotting the data, <strong class="source-inline">hist</strong>, which creates a histogram. The <strong class="source-inline">hist</strong> method has one required argument, which is the sequence of numbers to plot in the histogram. The second argument used in this example is <strong class="source-inline">bins</strong>, which effectively controls the granularity of the histogram – granularity increases with more bins. The bin count of a histogram can be adjusted for the desired visual effect and is generally set experimentally for the <span class="No-Break">data plotted:</span></p>
<pre class="source-code">
from scipy.stats import skewnorm
import matplotlib.pyplot as plt
a = 4
x = skewnorm.rvs(a, size=3000) + 0.5
x = x[x &gt; 0]
dfw_highs = [
    85, 87, 75, 88, 80, 86, 90, 94, 93, 92, 90, 92, 94,
    93, 97, 90, 95, 96, 96, 95, 92, 70, 79, 73, 88, 92,
    94, 93, 95, 76, 78, 86, 81, 95, 77, 71, 69, 88, 86,
    89, 84, 82, 77, 84, 81, 79, 75, 75, 91, 86, 86, 84,
    82, 68, 75, 78, 82, 83, 85]
fig, ax = plt.subplots(1,2, figsize=(12, 5))
ax[0].hist(x, bins=30)
ax[0].set_xlabel('Wait Time (hr)')
ax[0].set_ylabel('Frequency')
ax[0].set_title('Wait Times');
ax[1].hist(dfw_highs, bins=7)
ax[1].set_title('High Temperatures for DFW (4/2022-5/2022)')
ax[1].set_ylabel('Frequency')
ax[1].set_xlabel('Temperature (F)')
fig.show()</pre>
<p>In this <a id="_idIndexMarker103"/>section, we had a glimpse into <a id="_idIndexMarker104"/>how varied data and distributions can appear. Since distributions of data appear in many shapes and sizes in the wild, it is useful to have methods for describing distributions. In the next section, we will discuss the measurements <a id="_idIndexMarker105"/>available for distributions, how those measurements are performed, and the types of data that can <span class="No-Break">be measured.</span></p>
<h1 id="_idParaDest-35"><a id="_idTextAnchor039"/>Measuring and describing distributions</h1>
<p>The <a id="_idIndexMarker106"/>distributions of data found in the wild come in many shapes and sizes. This section<a id="_idIndexMarker107"/> will discuss how distributions are measured and which measurements apply to the four types of data. These measurements will provide methods to compare and contrast different distributions. The measurements discussed in this section can be broken into the <span class="No-Break">following categories:</span></p>
<ul>
<li><span class="No-Break">Central tendency</span></li>
<li><span class="No-Break">Variability</span></li>
<li><span class="No-Break">Shape</span></li>
</ul>
<p>These measurements are <a id="_idIndexMarker108"/>called <strong class="bold">descriptive statistics</strong>. The <a id="_idIndexMarker109"/>descriptive statistics discussed in this section are commonly used in statistical summaries <span class="No-Break">of data.</span></p>
<h2 id="_idParaDest-36"><a id="_idTextAnchor040"/>Measuring central tendency</h2>
<p>There<a id="_idIndexMarker110"/> are <a id="_idIndexMarker111"/>three types of measurement of <span class="No-Break">central tendency:</span></p>
<ul>
<li><span class="No-Break">Mode</span></li>
<li><span class="No-Break">Median</span></li>
<li><span class="No-Break">Mean</span></li>
</ul>
<p>Let’s discuss each one <span class="No-Break">of them.</span></p>
<h3>Mode</h3>
<p>The<a id="_idIndexMarker112"/> first measurement of central tendency we will discuss is the mode. The mode of a dataset is simply the most commonly occurring instance. Using the machines in the factory as an example (see <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.1</em>), the mode of the dataset would be model B. In the example, there are 3 of model A and 5 of model B, therefore, making model B the most common – <span class="No-Break">the mode.</span></p>
<p>A dataset can be one of <span class="No-Break">the following:</span></p>
<ul>
<li>Unimodal – having <span class="No-Break">one mode</span></li>
<li>Multimodal – having more than <span class="No-Break">one mode</span></li>
</ul>
<p>In the preceding example, the data <span class="No-Break">is unimodal.</span></p>
<p>Using the factory example again, let’s imagine that there are 3 of <strong class="bold">Model A</strong>, 5 of <strong class="bold">Model B</strong>, and 5 of <strong class="bold">Model D</strong> (a new model). Then, the dataset will have two modes: <strong class="bold">Model B</strong> and <strong class="bold">Model D</strong>, as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer024">
<img alt="Figure 2.4 – Multimodel distribution of machines in a factory" height="405" src="image/B18945_02_004.jpg" width="847"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4 – Multimodel distribution of machines in a factory</p>
<p>Therefore, this dataset <span class="No-Break">is multimodal.</span></p>
<p class="callout-heading">Mode and Data Types</p>
<p class="callout">These examples of modes have used nominal data, but all four types of data support the mode because all four data types support the <span class="No-Break">equality operation.</span></p>
<p>While the<a id="_idIndexMarker113"/> mode refers to the most common instance, in multimodal cases of continuous data, the term mode is often used in a less strict sense. For example, the distribution in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.5</em> would commonly be referred to as multimodal even though the peaks of the distribution are not the same magnitude. However, with nominal and ordinal data, it is more common to use the stricter definition of <em class="italic">most common</em> when referring to the modality of <span class="No-Break">a distribution.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer025">
<img alt="Figure 2.5 – A multimodal distribution of data" height="463" src="image/image_00_005.jpg" width="709"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5 – A multimodal distribution of data</p>
<p>Now, we will look at how to calculate the mode with code using <strong class="source-inline">scipy</strong>. The <strong class="source-inline">scipy</strong> library contains functions for calculating descriptive statistics in the <strong class="source-inline">stats</strong> module. In this example, we import <strong class="source-inline">mode</strong> from <strong class="source-inline">scipy.stats</strong> and calculate the mode of the following numbers, <strong class="source-inline">1, 2, 3, 4, 4, 4, </strong><span class="No-Break"><strong class="source-inline">5, 5</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
from scipy.stats import mode
m = mode([1,2,3,4,4,4,5,5])
print(
    f"The mode is {m.mode[0]} with a count of"
    f" {m.count[0]} instances"
)
# The mode is 4 with a count of 3 instances</pre>
<p>The <strong class="source-inline">mode</strong> function<a id="_idIndexMarker114"/> returns a <strong class="source-inline">mode</strong> object containing <strong class="source-inline">mode</strong> and <strong class="source-inline">count</strong> members. Unsurprisingly, the <strong class="source-inline">mode</strong> and <strong class="source-inline">count</strong> members contain the modes of the dataset and the number of times the modes appear, respectively. Note that <strong class="source-inline">mode</strong> and <strong class="source-inline">count</strong> members are indexable (like lists) because a dataset can contain <span class="No-Break">multiple modes.</span></p>
<h3>Median</h3>
<p>The next <a id="_idIndexMarker115"/>measure of the center is the median. The median<a id="_idIndexMarker116"/> is the middle value occurring when the values are arranged in <span class="No-Break">an order.</span></p>
<p class="callout-heading">Median and Data Types</p>
<p class="callout">This measure can be performed on ordinal data, interval data, and ratio data, but not on <span class="No-Break">nominal data.</span></p>
<p>We will discuss two <span class="No-Break">cases here.</span></p>
<h4>Finding the median when the number of instances is odd</h4>
<p>Finding <a id="_idIndexMarker117"/>the median of some numeric data is shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.6</em>. The data is sorted, then the median <span class="No-Break">is identified.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer026">
<img alt="Figure 2.6 – Identifying the median with an odd number of instances" height="260" src="image/B18945_02_006.jpg" width="574"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.6 – Identifying the median with an odd number of instances</p>
<p>In the <a id="_idIndexMarker118"/>preceding example, the instances are odd in number (7 instances), which have a center value. However, if the number of instances had been even, it would not have been possible to just take the middle number after sorting <span class="No-Break">the values.</span></p>
<h4>Finding the median when the number of instances is even</h4>
<p>When <a id="_idIndexMarker119"/>there are an even number of instances, the average of the two middle-most values is taken. Unlike the mode, there is no concept of multiple medians for the same series of data. An example with an even number of instances (8 instances) is shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer027">
<img alt="Figure 2.7 – Identifying the median with an even number of instances" height="398" src="image/B18945_02_007.jpg" width="682"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.7 – Identifying the median with an even number of instances</p>
<p>Now, let’s see how to calculate the median of a dataset with <strong class="source-inline">numpy</strong>. Like <strong class="source-inline">scipy</strong>, <strong class="source-inline">numpy</strong> contains functions for calculating descriptive statistics. We will calculate the median for the eight numbers listed in the <span class="No-Break">preceding example:</span></p>
<pre class="source-code">
import numpy as np
values = [85, 99, 70, 71, 86, 88, 94, 105]
median = np.median(values)
print(f"The median value is {median:.2f}")
# The median value is 87.00</pre>
<p>The<a id="_idIndexMarker120"/> result of the median calculation is 87, as expected. Note that the <strong class="source-inline">median</strong> function returns a single value, in contrast to the <strong class="source-inline">mode</strong> function in the previous <span class="No-Break">code example.</span></p>
<h3>Mean</h3>
<p>The <a id="_idIndexMarker121"/>next center measure is the mean, which is commonly referred to as the average. The mean is defined by the <span class="No-Break">following equation:</span></p>
<p><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>Let me explain the equation in words. To calculate the mean, we must add all the values together, then divide the sum by the number of values. Please refer to the following example. The 7 numbers are first added together, which brings the total sum to 593. This sum is then divided by the number of instances, resulting in a value <span class="No-Break">of 84.7.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer028">
<img alt="Figure 2.8 – Finding the mean" height="265" src="image/B18945_02_008.jpg" width="672"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.8 – Finding the mean</p>
<p>Note that<a id="_idIndexMarker122"/> the mean and the median of these values (84.7 and 86, respectively) are not the same value. In general, the mean and median will not be the same value, but there are special cases where the mean and median <span class="No-Break">will converge.</span></p>
<p class="callout-heading">Mean and Data Types</p>
<p class="callout">As for the supported data types, the mean is valid for interval and ratio data since the values are <span class="No-Break">added together.</span></p>
<p>Now, we will look at how to calculate the mean with <strong class="source-inline">numpy</strong>. The following code example shows the calculation of the mean for the values in the <span class="No-Break">previous example:</span></p>
<pre class="source-code">
import numpy as np
values = [85, 99, 70, 71, 86, 88, 94]
mean = np.mean(values)
print(f"The mean value is {mean:.1f}")
# The mean value is 84.7</pre>
<p>Like the <strong class="source-inline">median</strong> function, the <strong class="source-inline">mean</strong> function returns a <span class="No-Break">single number.</span></p>
<p>Before concluding this section on center measures, it is worth discussing the use of the mean and median in various situations. As mentioned previously, the median and mean will, in general, be different values. This is an effect driven by the shape of <span class="No-Break">the distribution.</span></p>
<p class="callout-heading">Shape impacts on Mean and Median</p>
<p class="callout">If the distribution is symmetric, the mean and median will tend to converge. However, if the distribution is not symmetric, the mean and median <span class="No-Break">will diverge.</span></p>
<p>The<a id="_idIndexMarker123"/> degree to which the measures diverge is driven by how asymmetric the distribution is. Four example distributions are given in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.6</em> to show this effect. Distributions 1 and 2 show the mean pulled toward a higher value than the median. The mean is pulled toward values with a larger absolute value. This is an important <a id="_idIndexMarker124"/>effect of the mean to be aware of when a dataset contains (or may contain) <strong class="bold">outlier values</strong> (often called outliers or influential points), which will tend to pull the mean in their direction. Unlike the mean, the median is not affected by outliers if outliers account for a smaller percentage of the data. Outliers will be discussed further in the <em class="italic">Measuring </em><span class="No-Break"><em class="italic">variability</em></span><span class="No-Break"> section.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer029">
<img alt="Figure 2.9 – Two asymmetric distributions and two symmetric distributions" height="699" src="image/B18945_02_009.jpg" width="729"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.9 – Two asymmetric distributions and two symmetric distributions</p>
<p>The next <a id="_idIndexMarker125"/>category of measurements for distributions is measures <span class="No-Break">of variability.</span></p>
<h2 id="_idParaDest-37"><a id="_idTextAnchor041"/>Measuring variability</h2>
<p>By variability, we <a id="_idIndexMarker126"/>essentially mean how wide a <a id="_idIndexMarker127"/>distribution is. The measurements in this category are <span class="No-Break">as follows:</span></p>
<ul>
<li><span class="No-Break">Range</span></li>
<li><span class="No-Break">Quartile ranges</span></li>
<li><span class="No-Break">Tukey fences</span></li>
<li><span class="No-Break">Variance</span></li>
</ul>
<p>Let’s discuss each <span class="No-Break">of them.</span></p>
<h3>Range</h3>
<p>The range <a id="_idIndexMarker128"/>is simply the difference between the maximum value and the minimum value in the distribution. Like the mean, the range will be affected by outliers since it depends on the max and min values. However, there is another variability method that, like the median, is robust to the presence <span class="No-Break">of outliers.</span></p>
<p>Let’s take a look at calculating a range with code <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">numpy</strong></span><span class="No-Break">:</span></p>
<pre class="source-code">
import numpy as np
values = [85, 99, 70, 71, 86, 88, 94, 105]
max_value = np.max(values)
min_value = np.min(values)
range_ = max_value - min_value
print(f"The data have a range of {range_}"
      f" with max of {max_value}"
      f" and min of {min_value}")
# The data have a range of 35 with max of 105 and min of 70</pre>
<p>While <strong class="source-inline">numpy</strong> does<a id="_idIndexMarker129"/> not have a range function, the range can be calculated using the <strong class="source-inline">min</strong> and <strong class="source-inline">max</strong> functions provided <span class="No-Break">by </span><span class="No-Break"><strong class="source-inline">numpy</strong></span><span class="No-Break">.</span></p>
<h3>Quartile ranges</h3>
<p>The <a id="_idIndexMarker130"/>next measures of variability are determined by sorting the data and then dividing the data into four equal sections. The boundaries of the four sections are the quartiles, which are called <span class="No-Break">the following:</span></p>
<ul>
<li>The lower <span class="No-Break">quartile (Q1)</span></li>
<li>The middle <span class="No-Break">quartile (Q2)</span></li>
<li>The upper <span class="No-Break">quartile (Q3)</span></li>
</ul>
<p>An example of quartiles is shown as follows. Like the median, quartiles are robust to outliers so long as the outliers are a small percentage of the dataset. Note that the middle quartile is, in fact, the median. An adjusted range measurement that is less sensitive to outliers than the normal range discussed in the <em class="italic">Range</em> section is the middle quartile, the <strong class="bold">interquartile range</strong> (<strong class="bold">IQR</strong>). The <a id="_idIndexMarker131"/>IQR is the difference between the upper and lower quartiles (Q3 - Q1). While this range is less sensitive to outliers, it only contains 50% of the data. Thus, making the interquartile range likely to be <em class="italic">less representative of the total variation</em> of <span class="No-Break">the data.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer030">
<img alt="Figure 2.10 – Q1, Q2, and Q3" height="352" src="image/B18945_02_010.jpg" width="606"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.10 – Q1, Q2, and Q3</p>
<p>We <a id="_idIndexMarker132"/>can calculate the quartiles and IQR range using <strong class="source-inline">numpy</strong> and <strong class="source-inline">scipy</strong>. In the following code example, we use the <strong class="source-inline">quantiles</strong> function to calculate the quartiles. We will not discuss <strong class="source-inline">quantiles</strong> here, other than to mention that <strong class="source-inline">quantiles</strong> are a generalization where the data can be split into any number of equal parts. Since we are splitting the data into four equal parts for quartiles, the <strong class="source-inline">quantiles</strong> values used for the calculation are 0.25, 0.5, and 0.75. Quartiles Q1 and Q3 could then be used to calculate the IQR. However, we could also use the <strong class="source-inline">iqr</strong> function from <strong class="source-inline">scipy</strong> to make <span class="No-Break">the calculation:</span></p>
<pre class="source-code">
import numpy as np
from scipy import stats
values = [85, 99, 70, 71, 86, 88, 94]
quartiles = np.quantile(values, [0.25, 0.5, 0.75],
    method="closest_observation")
print(f"The quartiles are Q1: {quartiles[0]},
    Q2: {quartiles[1]}, Q3: {quartiles[2]}")
iqr = stats.iqr(values,interpolation='closest_observation')
print(f"The interquartile range is {iqr}")
# The quartiles are Q1: 71, Q2: 85, Q3: 88
# The interquartile range is 17</pre>
<p>Note the use of the <strong class="source-inline">method</strong> and <strong class="source-inline">interpolation</strong> keyword arguments in the <strong class="source-inline">quantiles</strong> function and the <strong class="source-inline">iqr</strong> function, respectively. Several options can be used for these keyword arguments, which will lead to <span class="No-Break">different results.</span></p>
<p>Quartiles are often visualized with a boxplot. The following <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.11</em> shows the main parts of a boxplot. A boxplot is made up of two <span class="No-Break">main parts:</span></p>
<ul>
<li><span class="No-Break">The box</span></li>
<li><span class="No-Break">The whiskers</span></li>
</ul>
<p>The <a id="_idIndexMarker133"/>box part represents 50% of the data that is contained by the IQR. The whiskers are drawn starting from the edge of the boxes to a length of k * IQR, where k is commonly chosen to be 1.5. Any values beyond the whiskers are <span class="No-Break">considered outliers.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer031">
<img alt="Figure 2.11 – Parts of a box and whisker plot" height="478" src="image/B18945_02_011.jpg" width="845"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.11 – Parts of a box and whisker plot</p>
<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.12</em> shows how histograms and boxplots visualize the variability of a symmetric and asymmetric distribution. Notice how the boxplot of the asymmetric data is compressed on the left and expanded on the right, while the other boxplot is clearly symmetric. While a boxplot is useful for visualizing the symmetry of the data and the presence of outliers, the modality of the distribution would not <span class="No-Break">be evident.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer032">
<img alt="Figure 2.12 – Comparison of boxplots and histograms for asymmetric and symmetric distributions" height="693" src="image/B18945_02_012.jpg" width="726"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.12 – Comparison of boxplots and histograms for asymmetric and symmetric distributions</p>
<p>When exploring, it is <a id="_idIndexMarker134"/>common to use multiple visualizations since each type of visualization has its own advantages and disadvantages. It is common to use multiple visualizations since each type of visualization has its own advantages <span class="No-Break">and disadvantages.</span></p>
<h3>Tukey fences</h3>
<p>In the last<a id="_idIndexMarker135"/> few sections on measurements, the concept of outliers has appeared a few times. Outliers are values that are atypical compared to the main distribution, or anomalous values. While there are methods for classifying data points as outliers, there is no generally robust method for classifying data points as outliers. Defining outliers typically should be informed by the use case of the data analysis, as there will be different factors to consider based on the application domain. However, it is worth mentioning the common technique shown in the boxplot example <a id="_idIndexMarker136"/>called Tukey fences. The lower and upper Tukey fences are based on the IQR and defined <span class="No-Break">as follows:</span></p>
<ul>
<li><span class="_-----MathTools-_Math_Variable">L</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">w</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Q</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">k</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">(</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">I</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Q</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">R</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">)</span></span></li>
<li><span class="_-----MathTools-_Math_Variable">U</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable">c</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Q</span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">k</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base">(</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">I</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">Q</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">R</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">)</span></span></li>
</ul>
<p>As mentioned earlier, k is often chosen to be 1.5 as a default value, but there may be a more appropriate value for a given <span class="No-Break">application domain.</span></p>
<p>Now let’s take a look at how to calculate Tukey fences with <strong class="source-inline">numpy</strong> and <strong class="source-inline">scipy</strong>. This code example will build upon the previous example since there is no function to calculate the fences directly. We will again calculate the quartiles and the IQR with <strong class="source-inline">numpy</strong> and <strong class="source-inline">scipy</strong>. Then, we apply these operations to the values listed in the <span class="No-Break">preceding equations:</span></p>
<pre class="source-code">
import numpy as np
from scipy import stats
values = stats.norm.rvs(10, size=3000)
q1, q3 = np.quantile(values, [.25, .75],
    method='closest_observation')
iqr = stats.iqr(values,interpolation='closest_observation')
lower_fence = q1 - iqr * 1.5
upper_fence = q3 + iqr * 1.5
# may vary due to randomness in data generation
print(f"The lower fence is {lower_fence:.2f} and the upper
    fence is {upper_fence:.2f}")
# The lower fence is 7.36 and the upper fence is 12.67</pre>
<p>In this<a id="_idIndexMarker137"/> case, we used both <strong class="source-inline">numpy</strong> and <strong class="source-inline">scipy</strong>; however, the <strong class="source-inline">scipy</strong> calculation could be replaced with <strong class="source-inline">Q3-Q1</strong> as <span class="No-Break">mentioned previously.</span></p>
<h3>Variance</h3>
<p>The last measure<a id="_idIndexMarker138"/> of variability that will be covered in this section is variance. Variance is a measure of dispersion that can be understood as how <em class="italic">spread out</em> the numbers are from the average value. The formula for variance, denoted <span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span>, is <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span></p>
<p>In this equation, the term (<span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span>) is considered the deviation from the mean, which leads to another measure that is closely related to variance – the standard deviation, which is the square root of variance. The formula for standard deviation, denoted <span class="_-----MathTools-_Math_Variable">σ</span>, is <span class="No-Break">given here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">__________</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>In general, a wider distribution will have a larger variance and a larger standard deviation, but these values are not as easy to interpret as a range or IQR. These concepts will be covered more in detail in the next section, in the context of the normal distribution, which will provide clearer intuition for what these <span class="No-Break">values measure.</span></p>
<p>Again, these values will be calculated with code using <strong class="source-inline">numpy</strong>. The functions for variance and standard deviation are <strong class="source-inline">var</strong> and <span class="No-Break"><strong class="source-inline">std</strong></span><span class="No-Break">, respectively:</span></p>
<pre class="source-code">
import numpy as np
values = [85, 99, 70, 71, 86, 88, 94]
variance = np.var(values)
standard_dev = np.std(values)
print(f"The variance is {variance:.2f} and the standard
    deviation is {standard_dev:.2f}")
# The variance is 101.06 and the standard deviation is 10.05</pre>
<h2 id="_idParaDest-38"><a id="_idTextAnchor042"/>Measuring shape</h2>
<p>The <a id="_idIndexMarker139"/>next type of measure has to do with the shapes <a id="_idIndexMarker140"/>of distributions. They are <span class="No-Break">as follows:</span></p>
<ul>
<li><span class="No-Break">Skewness</span></li>
<li><span class="No-Break">Kurtosis</span></li>
</ul>
<p>Let’s discuss each <span class="No-Break">of them.</span></p>
<h3>Skewness</h3>
<p>The first<a id="_idIndexMarker141"/> measurement is skewness. Put simply, skewness is measurement asymmetry [<em class="italic">1</em>]. An example<a id="_idIndexMarker142"/> of skewed distributions is shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">.</span></p>
<p>There are two types of <span class="No-Break">skewed distributions:</span></p>
<ul>
<li><span class="No-Break">Left-skewed</span></li>
<li><span class="No-Break">Right-skewed</span></li>
</ul>
<p>A distribution is skewed in the direction of the dominant tail, meaning that a distribution with a dominant tail to the right is right-skewed and a distribution with a dominant tail to the left is left-skewed (as shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer033">
<img alt="Figure 2.13 – Distributions demonstrating skewness" height="1021" src="image/B18945_02_013.jpg" width="636"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.13 – Distributions demonstrating skewness</p>
<p>The <a id="_idIndexMarker143"/>formula <a id="_idIndexMarker144"/>for skewness will not be shown here since it can be calculated trivially with modern software packages. The output of the skewness calculation can be used to determine the skewness and the direction of the skew. If the skewness value is 0 or near 0, the distribution does not exhibit strong skewness. If the skewness is positive, the distribution is right-skewed, and if the skewness value is negative, the <a id="_idIndexMarker145"/>distribution is left-skewed. The larger the absolute value of the skewness value, the more the distribution exhibits skewness. An example of how to calculate<a id="_idIndexMarker146"/> skewness with <strong class="source-inline">scipy</strong> is shown in the following <span class="No-Break">code example:</span></p>
<pre class="source-code">
from scipy.stats import skewnorm, norm
from scipy.stats import skew as skew_calc
# generate data
skew_left = -skewnorm.rvs(10, size=3000) + 4
skew_right = skewnorm.rvs(10, size=3000) + 3
symmetric = norm.rvs(10, size=3000)
# calculate skewness
skew_left_value = skew_calc(skew_left)
skew_right_value = skew_calc(skew_right)
symmetric_value = skew_calc(symmetric)
# Output may vary some due to randomness of generated data
print(f"The skewness value of this left skewed
    distribution is {skew_left_value:.3f}")
print(f"The skewness value of this right skewed
    distribution is {skew_right_value:.3f}")
print(f"The skewness value of this symmetric distribution
    is {symmetric_value:.3f}")</pre>
<p>The other shape measurement covered in this section <span class="No-Break">is kurtosis.</span></p>
<h3>Kurtosis</h3>
<p>Kurtosis is a <a id="_idIndexMarker147"/>measurement of how heavy or light the tail of a distribution is relative to the normal distribution [<em class="italic">2</em>]. While the normal distribution <a id="_idIndexMarker148"/>has not been covered in depth yet, the idea of kurtosis can still be discussed. A light-tailed distribution means that more of the data is near or around the mode of the distribution. In contrast, a heavy-tailed distribution means that more of the data is at the edges of the distribution than near the mode. A light-tailed distribution, a normal distribution, and a heavy-tailed distribution are shown in <span class="No-Break"><em class="italic">Figure 2</em></span><span class="No-Break"><em class="italic">.14</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer034">
<img alt="Figure 2.14 – Distributions demonstrating tailedness with reference to a normal distribution" height="1012" src="image/image_00_014.jpg" width="624"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.14 – Distributions demonstrating tailedness with reference to a normal distribution</p>
<p>The<a id="_idIndexMarker149"/> formula<a id="_idIndexMarker150"/> for kurtosis will not be shown here since it can be calculated trivially with modern software packages. If the kurtosis value is 0 or near 0, the distribution does not exhibit kurtosis. If the kurtosis value is negative, the distribution exhibits light-tailedness, and if the kurtosis value is positive, the <a id="_idIndexMarker151"/>distribution exhibits heavy-tailedness. An example of how to calculate kurtosis with <strong class="source-inline">scipy</strong> is shown in the<a id="_idIndexMarker152"/> following <span class="No-Break">code example:</span></p>
<pre class="source-code">
from scipy.stats import norm
from scipy.stats import gennorm
from scipy.stats import kurtosis
# generate data
light_tailed = gennorm.rvs(5, size=3000)
symmetric = norm.rvs(10, size=3000)
heavy_tailed = gennorm.rvs(1, size=3000)
# calculate skewness
light_tailed_value = kurtosis(light_tailed)
heavy_tailed_value = kurtosis(heavy_tailed)
symmetric_value = kurtosis(symmetric)
# Output may vary some due to randomness of generated data
print(f"The kurtosis value of this light-tailed
    distribution is {light_tailed_value:.3f}")
print(f"The kurtosis value of this heavy_tailed
    distribution is {heavy_tailed_value:.3f}")
print(f"The kurtosis value of this normal
    distribution is {symmetric_value:.3f}")</pre>
<p>In this section, we walked through the common descriptive statistics that are used for measuring and describing distributions of data. These measurements provide a common language for describing and comparing distributions. The concepts discussed in this chapter are<a id="_idIndexMarker153"/> fundamental to many of the concepts discussed in future chapters. In the next section, we<a id="_idIndexMarker154"/> will discuss the normal distribution and describe the normal distribution using <span class="No-Break">these measurements.</span></p>
<h1 id="_idParaDest-39"><a id="_idTextAnchor043"/>The normal distribution and central limit theorem</h1>
<p>When discussing the <a id="_idIndexMarker155"/>normal distribution, we refer to the bell-shaped, <strong class="bold">standard normal distribution</strong>, which is <a id="_idIndexMarker156"/>formally synonymous with <a id="_idIndexMarker157"/>the <strong class="bold">Gaussian distribution</strong>, named after Carl Friedrich Gauss, an 18th- and 19th-century mathematician and physicist who – among other things – contributed to the concepts of approximation, and, in 1795, invented the method of least squares and the normal distribution, which is commonly used in statistical modeling techniques, such as least squares regression [<em class="italic">3</em>]. The standard normal distribution, also referred to<a id="_idIndexMarker158"/> as a <strong class="bold">parametric</strong> distribution, is characterized by a symmetrical distribution with a probability of data point dispersion consistent around the mean – that is, the data appears near the mean more frequently than data farther away. Since the location data dispersed within this distribution follows the laws of probability, we can call this a <strong class="bold">standard normal probability distribution</strong>. As an<a id="_idIndexMarker159"/> aside, a distribution in statistics that is not a probability distribution is generated through non-probability sampling based on non-random selection, whereas a probability distribution is based on random sampling. Both probability-based and non-probability-based distributions can have a standard normal distribution. The standard normal distribution exhibits neither skew nor kurtosis. It has equal variance throughout and frequently occurs in nature. The <strong class="bold">Empirical Rule</strong> is<a id="_idIndexMarker160"/> used to describe this distribution as having three pertinent standard deviations centered around the mean, <strong class="bold">μ</strong>. There are two distinct assumptions about <span class="No-Break">this distribution:</span></p>
<ul>
<li>The first, second, and third standard deviations contain 68%, 95%, and 99.7% of the measurements <span class="No-Break">dispersed, respectively</span></li>
<li>The mean, median, and mode are all equal to <span class="No-Break">each other</span></li>
</ul>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer035">
<img alt="Figure 2.15 – The standard normal distribution" height="524" src="image/B18945_02_015.jpg" width="978"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.15 – The standard normal distribution</p>
<p>Two <a id="_idIndexMarker161"/>common forms<a id="_idIndexMarker162"/> of a normal distribution are <span class="No-Break">as follows:</span></p>
<ul>
<li>The probability <span class="No-Break">density distribution</span></li>
<li>The cumulative <span class="No-Break">density distribution</span></li>
</ul>
<p>As mentioned before, the <a id="_idIndexMarker163"/>probability density distribution is <a id="_idIndexMarker164"/>based on random sampling, whereas the <a id="_idIndexMarker165"/>cumulative density distribution is<a id="_idIndexMarker166"/> based on accumulated data, which is not <span class="No-Break">necessarily random.</span></p>
<p>The two-tailed probability density function <a id="_idIndexMarker167"/>of the standard normal distribution <span class="No-Break">is this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Variable">π</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>The <a id="_idIndexMarker168"/>left-tailed cumulative function of the standard normal distribution <span class="No-Break">is this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∫</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Symbol">∞</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Variable">π</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>With respect to statistical modeling, the normal distribution represents balance and symmetry. This is important when building statistical models as many models assume normal distribution and are not robust to many deviations from that assumption, as they are built around a mean. Consequently, if variables in such a model are not normally <a id="_idIndexMarker169"/>distributed, the model’s errors will be increased and inconsistent, thus diminishing the model’s stability. When considering multiple variables in a statistical model, their interaction is more easily approximated when both are <span class="No-Break">normally distributed.</span></p>
<p>In the following <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.16</em>, in the left plot, variables X and Y interact with each other and create a centralized dispersion around a mean. In this case, modeling Y using X with a mean line or linear distance can be done reasonably well. However, if the two variables’ distributions were skewed, as in the plot on the right, this would result in non-constant variance between the two, resulting in an unequal distribution of errors and <span class="No-Break">unreliable output.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<img alt="Figure 2.16 – Bivariate normal (left) and skewed (right) distributions" height="812" src="image/B18945_02_16.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.16 – Bivariate normal (left) and skewed (right) distributions</p>
<p>In the <a id="_idIndexMarker170"/>case of linear classification and regression models, this will mean some results are better than others while some will likely be very bad. This can be difficult to assess at times using basic model metrics and requires deeper model analysis to prevent trusting what could end up being misleading results. Furthermore, deployment into a production environment would be very risky. More on this will be discussed in <a href="B18945_06.xhtml#_idTextAnchor104"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-40"><a id="_idTextAnchor044"/>The Central Limit Theorem</h2>
<p>When<a id="_idIndexMarker171"/> sampling data, it is common to encounter the issue of non-normal data. This may be for multiple reasons, such as the population not having a normal distribution or the sample being misrepresentative of the population. The Central Limit Theorem, which is important in statistical inference, postulates that if random samples of <em class="italic">n</em> observations are taken from a population that has a specific mean, μ, and <strong class="bold">standard deviation</strong>, <strong class="bold">σ</strong>, the<a id="_idIndexMarker172"/> sampling distribution constructed from the means of the randomly selected sub-sample distributions will approximate a <a id="_idIndexMarker173"/>normal distribution having roughly the same mean, μ, and standard deviation, calculated as <span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span>, as the population. The next section will use bootstrapping to demonstrate the Central Limit Theorem in action. A later section discussing transformations will provide techniques for reshaping data distributions that do not conform to normal distributions so that tools requiring normal distributions can still be <span class="No-Break">effectively applied.</span></p>
<h1 id="_idParaDest-41"><a id="_idTextAnchor045"/>Bootstrapping</h1>
<p>Bootstrapping <a id="_idIndexMarker174"/>is a method of resampling that uses random sampling – typically with replacement – to generate statistical estimates about a population by resampling from subsets of the sampled distribution, such as <span class="No-Break">the following:</span></p>
<ul>
<li><span class="No-Break">Confidence intervals</span></li>
<li><span class="No-Break">Standard error</span></li>
<li>Correlation coefficients (<span class="No-Break">Pearson’s correlation)</span></li>
</ul>
<p>The idea is that repeatedly sampling different random subsets of a sample distribution and taking the average each time, given enough repeats, will begin to approximate the true population using each subsample’s average. This follows directly the concept of the Central Limit Theorem, which to be restated, asserts that sampling means begins to approximate normal sampling distributions, centered around the original distribution’s mean, as sample sizes and counts increase. Bootstrapping is useful when a limited quantity of samples exists in a distribution relative to the amount needed for a specific test, but inference <span class="No-Break">is needed.</span></p>
<p>As discussed in <a href="B18945_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>,<em class="italic"> Sampling and Generalization</em>, constraints such as time and expense are common reasons for obtaining samples rather than populations. Because the underlying concept of bootstrapping is to make assumptions about the population using samples, it is not beneficial to apply this technique to populations as the true statistical parameters – such as the percentiles and variance – of a population are known. Regarding sample preparation, the balance of attributes in the sample should represent the true approximation of the population. Otherwise, the results will likely be misleading. For example, if the population of species <a id="_idIndexMarker175"/>within a zoo is a split of 40% reptiles and 60% mammals and we want to bootstrap their longevity to identify the confidence intervals for their lifespans, it would be necessary to ensure the dataset to which bootstrapping was applied contained a split of 40% reptiles and 60% mammals; a split of 15% reptiles and 85% mammals, for example, would lead to misleading results. In other words, the sample stratification should be balanced in proportion to <span class="No-Break">the population.</span></p>
<h2 id="_idParaDest-42"><a id="_idTextAnchor046"/>Confidence intervals</h2>
<p>As<a id="_idIndexMarker176"/> mentioned before, one useful application of bootstrapping is to create confidence intervals around sparsely defined or limited datasets – that is to say, datasets with a wide range of values without many samples. Consider an example of bootstrapping to perform a hypothesis test using a 95% confidence interval using the <strong class="source-inline">"Duncan"</strong> dataset in <strong class="source-inline">statsmodels</strong>, which contains incomes by profession, type, education, and prestige. While this is the full dataset, consider this dataset a sample since the sampling method is not mentioned and it is not likely to consider all incomes for all workers of every profession and type. To obtain the dataset, we first load the <strong class="source-inline">matplotlib</strong>, <strong class="source-inline">statsmodels</strong>, <strong class="source-inline">pandas</strong>, and <strong class="source-inline">numpy</strong> libraries. We then download the dataset and store it as a <strong class="source-inline">pandas</strong> DataFrame in the <strong class="source-inline">df_duncan</strong> variable. Following this, we recode the “<strong class="source-inline">prof"</strong>, <strong class="source-inline">"wc"</strong>, and <strong class="source-inline">"bc"</strong> types as <strong class="source-inline">"professional"</strong>, <strong class="source-inline">"white-collar"</strong>, and <strong class="source-inline">"blue collar"</strong>, respectively. Finally, we create two separate <strong class="source-inline">pandas</strong> DataFrames; one for professional job types and another for blue-collar job types, as these are the two subsets we will analyze <span class="No-Break">using bootstrapping:</span></p>
<pre class="source-code">
import matplotlib.pyplot as plt, statsmodels.api as sm, pandas as pd, numpy as np, scipy.stats
df_duncan = sm.datasets.get_rdataset("Duncan",
    "carData").data
df_duncan.loc[df_duncan['type'] == 'prof',
    'type'] = 'professional'
df_duncan.loc[df_duncan['type'] == 'wc',
    'type'] = 'white-collar'
df_duncan.loc[df_duncan['type'] == 'bc',
    'type'] = 'blue-collar'
df_professional = df_duncan.loc[(
    df_duncan['type'] == 'professional')]
df_blue_collar = df_duncan.loc[(
    df_duncan['type'] == 'blue-collar')]</pre>
<div>
<div class="IMG---Figure" id="_idContainer037">
<img alt="Figure 2.17 – Table displaying the first five rows of the statsmodels Duncan data" height="575" src="image/B18945_02_017.jpg" width="1344"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.17 – Table displaying the first five rows of the statsmodels Duncan data</p>
<p>We then<a id="_idIndexMarker177"/> build a set of plotting functions, as seen next. In <strong class="source-inline">plot_distributions()</strong>, we denote <strong class="source-inline">p=5</strong>, meaning the p-value will be significant at a significance level of 0.05 (1.00 - 0.05 = 0.95, hence, 95% confidence). We then divide this value by 2 since this will be a two-sided test, meaning we want to know the full interval rather than just one bound (discussed in <a href="B18945_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> as a representative test statistic). Regarding the plots, we visualize the data using histograms (the <strong class="source-inline">hist()</strong> function) in <strong class="source-inline">matplotlib</strong> and then plot the 95% sampling confidence intervals using the <strong class="source-inline">axvline()</strong> functions, which we build using the <strong class="source-inline">numpy</strong> <span class="No-Break">function </span><span class="No-Break"><strong class="source-inline">percentile()</strong></span><span class="No-Break">.</span></p>
<p class="callout-heading">Percentile in Bootstrapping</p>
<p class="callout">When applied to the original data, the percentile is only that, but when applied to the bootstrapped sampling distribution, it is the <span class="No-Break">confidence interval.</span></p>
<p>To state the<a id="_idIndexMarker178"/> confidence interval simply, a 95% confidence interval means that for every 100 sample means taken, 95 of them will fall within this interval. In the <strong class="source-inline">numpy</strong> <strong class="source-inline">percentile()</strong> function, we use <strong class="source-inline">p=5</strong> to support that 1-p is the confidence level, where <em class="italic">p</em> is the level of significance (think <em class="italic">p-value</em>, where any value at or lower than <em class="italic">p</em> is significant). Since the test is two-tailed, we divide <em class="italic">p</em> by 2 and split 2.5 in the left tail and 2.5 in the right since we have a symmetrical, standard normal distribution. The <strong class="source-inline">subplot(2,1,...)</strong> code creates two rows and one column. Axis 0 of the figure is used for professional incomes and axis 1 is used for <span class="No-Break">blue-collar incomes:</span></p>
<pre class="source-code">
def plot_distributions(n_replicas, professional_sample, blue_collar_sample, professional_label, blue_collar_label, p=5):
    fig, ax = plt.subplots(2, 1, figsize=(10,8))
    ax[0].hist(professional_sample, alpha=.3, bins=20)
    ax[0].axvline(professional_sample.mean(),
        color='black', linewidth=5)
# sampling distribution mean
    ax[0].axvline(np.percentile(professional_sample, p/2.),
        color='red', linewidth=3, alpha=0.99)
# 95% CI Lower limit (if bootstrapping)
    ax[0].axvline(np.percentile(professional_sample,
        100-p/2.), color='red', linewidth=3, alpha=0.99)
# 95% CI Upper Limit  (if bootstrapping)
    ax[0].title.set_text(str(professional_label) +
        "\nn = {} Resamples".format(n_replicas))
    ax[1].hist(blue_collar_sample, alpha=.3, bins=20)
    ax[1].axvline(blue_collar_sample.mean(), color='black',
        linewidth=5) # sampling distribution mean
    ax[1].axvline(np.percentile(blue_collar_sample, p/2.),
        color='red', linewidth=3, alpha=0.99)
# 95% CI Lower limit (if bootstrapping)
    ax[1].axvline(np.percentile(blue_collar_sample,
        100-p/2.), color='red', linewidth=3, alpha=0.99)
# 95% CI Upper Limit (if bootstrapping)
    ax[1].title.set_text(str(blue_collar_label) +
        "\nn = {} Resamples".format(n_replicas))
    if n_replicas &gt; 1:
        print("Lower confidence interval limit: ",
            np.percentile(round(professional_sample,4),
            p/2.))
        print("Upper confidence interval limit: ",
            np.percentile(round(professional_sample,4),
            100-p/2.))
        print("Mean: ", round(professional_sample,
            4).mean())
        print("Standard Error: ",
            round(professional_sample.std() /
            np.sqrt(n_replicas), 4) )
        print("Lower confidence interval limit: ",
            np.percentile(round(blue_collar_sample,4),
            p/2.))
        print("Upper confidence interval limit: ",
            np.percentile(round(blue_collar_sample,4),
            100-p/2.))
        print("Mean: ", round(blue_collar_sample,4).mean())
        print("Standard Error: ",
            round(blue_collar_sample.std() /
            np.sqrt(n_replicas), 4) )
    else:
        print("At least two samples required to create the following statistics:\nConfidence Intervals\nMean\nStandard Error")</pre>
<p>In the original <a id="_idIndexMarker179"/>dataset, there are 18 income data points for <strong class="source-inline">professional</strong> job types and 21 data points for <strong class="source-inline">blue-collar</strong> job types. The 95% confidence interval for the professional job type ranges from 29.50 to 79.15 with an average of 60.06. That interval ranges from 7.00 to 64.00 for blue-collar job types with a mean of 23.76. Based on <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.18</em>, there is a reasonable overlap between the income differences, which causes the overlapping confidence intervals. Consequently, it<a id="_idIndexMarker180"/> would be reasonable to assume there is no statistically significant difference in incomes between blue-collar and professional job types. However, this dataset has a very limited volume <span class="No-Break">of samples:</span></p>
<pre class="source-code">
n_replicas=0
plot_distributions(n_replicas=n_replicas,
professional_sample=df_professional['income'],
    blue_collar_sample=df_blue_collar['income'],
    professional_label="Professional",
    blue_collar_label="Blue Collar")</pre>
<div>
<div class="IMG---Figure" id="_idContainer038">
<img alt="Figure 2.18 – Original data distributions with 95th percentile lines" height="660" src="image/B18945_02_018.jpg" width="825"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.18 – Original data distributions with 95th percentile lines</p>
<p>In the following code, using <strong class="source-inline">pandas</strong>’ <strong class="source-inline">.sample()</strong> function, we randomly resample 50% (<strong class="source-inline">frac=0.5</strong>) of the income values from each distribution 1,000 times and calculate a new mean each time, appending it to the Python lists ending with <strong class="source-inline">_bootstrap_means</strong>. Using those lists, we derive new 95% confidence intervals. <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.19</em> shows, with respect to the standard deviations and income values in the dataset, the new sample distributions using the average of each resampled subset. The <strong class="source-inline">replace=True</strong> argument allows for resampling the same record multiple times (in the event that should randomly occur), which is a requirement <span class="No-Break">of bootstrapping.</span></p>
<p>After<a id="_idIndexMarker181"/> performing the bootstrapping procedure, we can see income has started to distribute in a roughly standard normal, Gaussian form. Notably, from this experiment, the confidence intervals no longer overlap. The implication of the separation of the confidence intervals between the professional and blue-collar groups is that with a 95% level of confidence, it can be shown there is a statistically significant difference between the incomes of the two job types. The confidence interval for the professional income levels is now 48.66 to 69.89 with a mean of 60.04, and for blue-collar, 14.60 to 35.90 with a mean <span class="No-Break">of 23.69:</span></p>
<pre class="source-code">
n_replicas = 1000
professional_bootstrap_means = pd.Series(
    [df_professional.sample(frac=0.5, replace=True)
    ['income'].mean() for i in range(n_replicas)])
blue_collar_bootstrap_means = pd.Series(
    [df_blue_collar.sample(frac=0.5, replace=True)
    ['income'].mean() for i in range(n_replicas)])</pre>
<div>
<div class="IMG---Figure" id="_idContainer039">
<img alt="Figure 2.19 – Distributions of the 95% confidence interval for 1,000 bootstrapped sampling means" height="660" src="image/B18945_02_019.jpg" width="825"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.19 – Distributions of the 95% confidence interval for 1,000 bootstrapped sampling means</p>
<p>Here, you <a id="_idIndexMarker182"/>can notice the distribution more closely clusters around the mean with tighter <span class="No-Break">confidence intervals.</span></p>
<p>As mentioned before, bootstrapping can be used to obtain different statistical parameters of the distribution beyond the <span class="No-Break">confidence intervals.</span></p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor047"/>Standard error</h2>
<p>Another <a id="_idIndexMarker183"/>commonly used metric is the standard error, <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span>. We  can calculate this using the last variables, <strong class="source-inline">p</strong><strong class="source-inline">rofessional_bootstrap_means</strong>, and <strong class="source-inline">blue_collar_bootstrap_means</strong>, as these contain the new distributions of means obtained through the bootstrapping process. We can also see that standard error – calculated by dividing the standard deviation by the square root of the number of samples (or in our case, <strong class="source-inline">n_replicas</strong>, representing the count of averages obtained from each random re-subsample) – decreases as the volume resamples increases. We use the following code to calculate the standard error of the professional and blue-collar type income bootstrapped means. The following table, <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.20</em>, shows that the standard error reduces as <span class="No-Break"><em class="italic">n</em></span><span class="No-Break"> increases:</span></p>
<pre class="source-code">
scipy.stats.sem(professional_bootstrap_means)
scipy.stats.sem(blue_collar_bootstrap_means)</pre>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">n</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Professional </strong><span class="No-Break"><strong class="bold">Standard Error</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Blue-Collar </strong><span class="No-Break"><strong class="bold">Standard Error</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">10 replicas</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.93</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.09</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">10,000 replicas</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.03</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.04</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.20 – Table of standard errors for n = 10 and n = 10,000 bootstrap replicas</p>
<p>Another <a id="_idIndexMarker184"/>use case for bootstrapping is Pearson’s correlation, which we will discuss in the <span class="No-Break">following section.</span></p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor048"/>Correlation coefficients (Pearson’s correlation)</h2>
<p>Typically, this<a id="_idIndexMarker185"/> is difficult to find using a small sample size since correlation depends on the covariance of two variables. As <a id="_idIndexMarker186"/>the variables overlap more significantly, their correlation is higher. However, if the overlap is the result of a small sample size or sampling error, this correlation may be representative. <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.21</em> shows a table of correlation at different counts of bootstrap subsamples. As the distributions form more native distinctions, the correlation diminishes from a small positive correlation to an amount <span class="No-Break">approximating zero.</span></p>
<p>To test correlation on a sample of 10 records from the original dataset, see <span class="No-Break">the following:</span></p>
<pre class="source-code">
df_prof_corr = df_professional.sample(n=10)
df_blue_corr = df_blue_collar.sample(n=10)
corr, _ = scipy.stats.pearsonr(df_prof_corr['income'],
    df_blue_corr['income'])</pre>
<p>To test correlation on samples of <span class="No-Break">bootstrapped means:</span></p>
<pre class="source-code">
n_replicas = n_replicas
professional_bootstrap_means = pd.Series([df_prof_corr.sample(frac=0.5,replace=False).income.mean()for i in range(n_replicas)])
blue_collar_bootstrap_means = pd.Series([df_blue_corr.sample(frac=0.5, replace=False).income.mean() for i in range(n_replicas)])
corr, _ = scipy.stats.pearsonr(
    professional_bootstrap_means,
    blue_collar_bootstrap_means)
print(corr)</pre>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">n</strong></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Pearson’s </strong><span class="No-Break"><strong class="bold">Correlation Coefficient</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>10 samples from <span class="No-Break">original data</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.32</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">10 replicas</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.22</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">10,000 replicas</span></p>
</td>
<td class="No-Table-Style">
<p>-<span class="No-Break">0.003</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.21 – Table of Pearson’s correlation coefficients alongside the original samples</p>
<p>It is <a id="_idIndexMarker187"/>common <a id="_idIndexMarker188"/>to run around 1,000 to 10,000 bootstrap replicas. However, this depends on the type of data being bootstrapped. For example, if bootstrapping data from a human genome sequence dataset, it may be useful to bootstrap a sample 10 million times, but if bootstrapping a simple dataset, it may be useful to bootstrap 1,000 times or less. Ultimately, the researcher should perform a visual inspection of the distributions of the <a id="_idIndexMarker189"/>means to determine whether the results appear logical compared to what is expected. As common with <a id="_idIndexMarker190"/>statistics, it is best to have some domain knowledge or subject-matter expertise to help validate findings, as this will likely be the best for deciding bootstrap <span class="No-Break">replication counts.</span></p>
<p>Bootstrapping is also used in machine learning, where it underlies the concept of <strong class="bold">bootstrap aggregation</strong>, also <a id="_idIndexMarker191"/>called <strong class="bold">bagging</strong>, a process that combines outputs of <a id="_idIndexMarker192"/>predictive models built upon bootstrap subsample distributions. <strong class="bold">Random Forest</strong> is <a id="_idIndexMarker193"/>one popular algorithm that performs this operation. The purpose of bootstrapping in bagging algorithms is to preserve the low-bias behavior of non-parametric (more to be discussed on this in later chapters) classification, but also reduce variance, thus using bootstrapping as a way to minimize the significance of the bias-variance trade-off in <span class="No-Break">modeling errors.</span></p>
<p>In the following section, we will consider another non-parametric test called permutation testing using <span class="No-Break">resampling data.</span></p>
<h1 id="_idParaDest-45"><a id="_idTextAnchor049"/>Permutations</h1>
<p>Before jumping<a id="_idIndexMarker194"/> into this testing analysis, we will review some basic knowledge of permutations <span class="No-Break">and combinations.</span></p>
<h2 id="_idParaDest-46"><a id="_idTextAnchor050"/>Permutations and combinations</h2>
<p>Permutations and combinations <a id="_idIndexMarker195"/>are two mathematical techniques for taking a set of objects to create subsets from a population but in two different ways. The order of objects matters in permutations but does not matter <span class="No-Break">in combinations.</span></p>
<p>In order to understand these concepts easily, we will consider two examples. There are 10 people at an evening party. The organizer of the party wants to give 3 prizes of $1,000, $500, and $200 randomly to 3 people. The question is <em class="italic">how many ways are there to distribute the prizes?</em> Another example is that the organizer will give 3 equal prizes of $500 to 3 people out of 10 at the party. The organizer really does not care which prize is<a id="_idIndexMarker196"/> given to whom among the 3 selected people. Huy, Paul, and Stuart are our winners in <a id="_idIndexMarker197"/>these two examples but, in the first example, different situations may play out, for instance, if Paul wins the $200 prize, $500 prize, or $<span class="No-Break">1,000 prize.</span></p>
<table class="No-Table-Style" id="table003">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">$</strong><span class="No-Break"><strong class="bold">1,000</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">$</strong><span class="No-Break"><strong class="bold">500</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">$</strong><span class="No-Break"><strong class="bold">200</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Stuart</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Paul</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Huy</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.22 – Table of distributed prizes given to Huy, Paul, and Stuart</p>
<p>However, in the second example, because the 3 prizes have the same value of $500, the order of prize arrangements does <span class="No-Break">not matter.</span></p>
<p>Let us take a closer look at these two permutations and combinations examples. The first example is a permutation example. Since the pool has 10 people, we have 10 possibilities in choosing one person from the pool to give the $1,000 prize. If this person is chosen to win the $1,000 prize, then there are only 9 possibilities in choosing another person to give the $500 prize, and finally, we have 8 possibilities in choosing a person from the pool to give the $200 prize. Then, we have 10*9*8 = 720 ways to distribute the prizes. The mathematical formula for the permutations <span class="No-Break">is this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span> is the number of permutations, <span class="_-----MathTools-_Math_Variable">n</span> is the total number of objects in a set, and <span class="_-----MathTools-_Math_Variable">r</span> is the number of objects that can be chosen from the set. In this example, <span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span> and <span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span> so then we <span class="No-Break">see this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">P</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">10,3</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">9</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">8</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">7</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">6</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">5</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">4</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">___________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Number">7</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">6</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">5</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">4</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Number">*</span><span class="_-----MathTools-_Math_Number">9</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">*</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">8</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">720</span></span></p>
<p>There<a id="_idIndexMarker198"/> are 720 ways to select 3 people from the 10 people at the party to whom to distribute the 3 prizes of $1,000, $500, <span class="No-Break">and $200.</span></p>
<p>In Python, there<a id="_idIndexMarker199"/> is a package called <strong class="source-inline">itertools</strong> to help us to find permutations directly. Readers can<a id="_idIndexMarker200"/> check out the following link – <a href="https://docs.python.org/3/library/itertools.xhtml">https://docs.python.org/3/library/itertools.xhtml</a> – for more information related to this package. We need to import this package into the Python environment <span class="No-Break">for permutations:</span></p>
<pre class="source-code">
from itertools import permutations
# list of 10 people in the party
people = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']
# all the ways that the 3 prizes are distributed
perm = permutations(people, 3)
list_perm = list(perm)
print(f"There are {len(list_perm)} ways to distribute the prizes!")</pre>
<p>In the preceding Python code, we created a list, <strong class="source-inline">people</strong>, containing 10 people, <strong class="source-inline">P1</strong> to <strong class="source-inline">P10</strong>, and then use the <strong class="source-inline">permutations</strong> function from <strong class="source-inline">itertools</strong> to get all the ways to distribute the prizes. This method takes a list of 10 people as input and returns an object list of tuples containing all the possibilities in choosing 3 people from this pool of 10 people to whom to distribute the prizes of $1,000, $500, and $200. Because there are 720 ways to distribute the prizes, here we will just print the 10 first ways that the Python <span class="No-Break">code produced:</span></p>
<pre class="source-code">
print(f"The 10 first ways to distribute the prizes: \n
    {list_perm[:10]} ")</pre>
<p>The output <a id="_idIndexMarker201"/>of the preceding code is the 10 first ways to distribute <span class="No-Break">the prizes:</span></p>
<p><strong class="source-inline">[('P1', 'P2', 'P3'), ('P1', 'P2', 'P4'), ('P1', 'P2', 'P5'), ('P1', 'P2', 'P6'), ('P1', '</strong><span class="No-Break"><strong class="source-inline">P2', 'P7')]</strong></span></p>
<p>If we have 10 different gifts, each<a id="_idIndexMarker202"/> person who participates in the party can take one gift home. How many ways are there to distribute these gifts? There are 3,628,800 ways. That is a really big number! The reader can check with the <span class="No-Break">following code:</span></p>
<pre class="source-code">
#list of 10 people in the party
people = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']
# all the ways that the 10 different gifts are distributed
perm = permutations(people)
list_perm = list(perm)
print(f"There are {len(list_perm)}
    ways to distributed the gifts!")</pre>
<p>Going back to the second example, because the 3 prizes have the same value of $500, the order of the 3 selected people does not matter. Then, if the 3 selected people are Huy, Paul, and Stuart, as in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.22</em>, there are 6 ways to distribute the prizes in the first example. Then, there is only 1 way to distribute the same amount of $500 to Huy, Paul, and Stuart. The mathematical formula of combinations <span class="No-Break">is this:</span></p>
<p><span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">)</span> is the <a id="_idIndexMarker203"/>number of combinations, <span class="_-----MathTools-_Math_Variable">n</span> is the total number of objects in a set, and <span class="_-----MathTools-_Math_Variable">r</span> is the number of objects that can be chosen from the set. Similarly, we can calculate that <span class="No-Break">there are</span></p>
<p><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Number">10</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">!</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">10.9</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">.</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">8</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1.2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">.</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">720</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">6</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">120</span></span></p>
<p>ways to distribute 3 prizes <span class="No-Break">of $500.</span></p>
<p>In Python, we also<a id="_idIndexMarker204"/> use the <strong class="source-inline">itertools</strong> package but, instead of the <strong class="source-inline">permutations</strong> function, we import the <span class="No-Break"><strong class="source-inline">combinations</strong></span><span class="No-Break"> function:</span></p>
<pre class="source-code">
 from itertools import combinations
# list of 10 people in the party
people = ['P1','P2','P3','P4','P5','P6','P7','P8','P9','P10']
# all the ways that the 3 prizes are distributed
comb = combinations(people, 3)
list_comb = list(comb)
print(f"There are {len(list_comb)} ways to distribute the prizes!")</pre>
<h2 id="_idParaDest-47"><a id="_idTextAnchor051"/>Permutation testing</h2>
<p>Permutation testing<a id="_idIndexMarker205"/> is a non-parametric test that does not make the required assumption of normally distributed data. Both bootstrapping and permutations are useful for resampling techniques but best for different uses, one for estimating statistical parameters (bootstrapping) and another for hypothesis testing. Permutation testing is used to test the null hypothesis between two samples generated from the same population. It has different <a id="_idIndexMarker206"/>names such as <strong class="bold">exact testing</strong>, <strong class="bold">randomization testing</strong>, and <span class="No-Break"><strong class="bold">re-randomization testing</strong></span><span class="No-Break">.</span></p>
<p>First, we <a id="_idIndexMarker207"/>go to<a id="_idIndexMarker208"/> see a simple <a id="_idIndexMarker209"/>example for better understanding before implementing the code in Python. We suppose that there are 2 groups of people, one group representing children (A) and another group representing people over 40 years old (B) <span class="No-Break">as follows:</span></p>
<p><strong class="source-inline">A</strong> = [3,5,4] and <strong class="source-inline">B</strong> = [<span class="No-Break">43,41,56,78,54]</span></p>
<p>The mean difference in age between the two samples A and <span class="No-Break">B is</span></p>
<p><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">43</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">41</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">56</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">78</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">54</span><span class="_-----MathTools-_Math_Number">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">5</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">5</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">4</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">50.4</span></span></p>
<p>We merge A and B into a single set, denoted as P <span class="No-Break">as follows:</span></p>
<p><strong class="source-inline">P = </strong><span class="_-----MathTools-_Math_Base">[</span><span class="No-Break"><span class="_-----MathTools-_Math_Number">3,5</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator">,</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">4,43,41,56,78,54</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">]</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator">.</span></span></p>
<p>Then, we take a permutation of P, for example, <span class="No-Break">the following:</span></p>
<p><strong class="source-inline">P_new = [3,54, 78, 41, 4, 43, </strong><span class="No-Break"><strong class="source-inline">5, 56]</strong></span></p>
<p>Next, we redivide <strong class="source-inline">P_new</strong> into 2 subsets called <strong class="source-inline">A_new</strong> and <strong class="source-inline">B_new</strong>, which have the same size as A and <span class="No-Break">B, respectively:</span></p>
<p><strong class="source-inline">A_new</strong> = [3,54,78] and <strong class="source-inline">B_new</strong> = [<span class="No-Break">41,4,43,5,56]</span></p>
<p>Then, the mean difference in age between <strong class="source-inline">A_new</strong> and <strong class="source-inline">B_new</strong> is 15.2, which is lower than the original mean difference in age between A and B (50.4). In other words, the permutated <strong class="source-inline">P_new</strong> does not contribute to the p-value. We can observe that only one permutation drawn from all possible permutations of P is greater than or equal to the original mean difference itself, P. Now we will implement the code <span class="No-Break">in Python:</span></p>
<pre class="source-code">
import numpy as np
# create permutation testing function
def permutation_testing(A,B,n_iter=1000):
#A, B are 2 lists of samples to test the hypothesis,
#n_iter is number of iterations with the default is 1000
    differences = []
    P = np.array(A+B)
    original_mean = np.array(A).mean()- np.array(B).mean()
    for i in range(n_iter):
      np.random.shuffle(P)#create a random permutation of P
      A_new = P[:len(A)] # having the same size of A
      B_new = P[-len(B):] # having the same size of B
      differences.append(A_new.mean()-B_new.mean())
    #Calculate p_value
    p_value = round(1-(float(len(np.where(
        differences&lt;=original_mean)[0]))/float(n_iter)),2)
    return p_value</pre>
<p>In the preceding<a id="_idIndexMarker210"/> Python code, A and B are two samples and we want to know whether they are from the same larger population; <strong class="source-inline">n_ter</strong> is the number of iterations that we want to perform; here, 1,000 is the default number <span class="No-Break">of iterations.</span></p>
<p>Let’s perform permutation testing for the two groups of people in the example with <span class="No-Break">10,000 iterations:</span></p>
<pre class="source-code">
A = [3,5,4]
B = [43,41,56,78,54]
permutation_testing(A,B,n_iter=10000)</pre>
<p>The p-value obtained is 0.98. That means that we fail to reject the null hypothesis, or there is not <a id="_idIndexMarker211"/>enough evidence to confirm that samples A and B are from the same <span class="No-Break">larger population.</span></p>
<p>Next, we will explore an important and necessary step in many statistical tests requiring the normal <span class="No-Break">distribution assumption.</span></p>
<h1 id="_idParaDest-48"><a id="_idTextAnchor052"/>Transformations</h1>
<p>In this section, we <a id="_idIndexMarker212"/>will consider <span class="No-Break">three transformations:</span></p>
<ul>
<li><span class="No-Break">Log transformation</span></li>
<li>Square <span class="No-Break">root transformation</span></li>
<li>Cube <span class="No-Break">root transformation</span></li>
</ul>
<p>First, we will <a id="_idIndexMarker213"/>import the <strong class="source-inline">numpy</strong> package to create a random <a id="_idIndexMarker214"/>sample drawn <a id="_idIndexMarker215"/>from a Beta distribution. The documentation on Beta distributions can be <span class="No-Break">found here:</span></p>
<p><a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.beta.xhtml"><span class="No-Break">https://numpy.org/doc/stable/reference/random/generated/numpy.random.beta.xhtml</span></a></p>
<p>The sample, <strong class="source-inline">df</strong>, has 10,000 values. We also use <strong class="source-inline">matplotlib.pyplot</strong> to create different histogram plots. Second, we transform the original data by using a log transformation, square root transformation, and cube root transformation, and we draw <span class="No-Break">four histograms:</span></p>
<pre class="source-code">
import numpy as np
import matplotlib.pyplot as plt
np.random.seed(42) # for reproducible purpose
# create a random data
df = np.random.beta(a=1, b=10, size = 10000)
df_log = np.log(df) #log transformation
df_sqrt = np.sqrt(df) # Square Root transformation
df_cbrt = np.cbrt(df) # Cube Root transformation
plt.figure(figsize = (10,10))
plt.subplot(2,2,1)
plt.hist(df)
plt.title("Original Data")
plt.subplot(2,2,2)
plt.hist(df_log)
plt.title("Log Transformation")
plt.subplot(2,2,3)
plt.hist(df_sqrt)
plt.title("Square Root Transformation")
plt.subplot(2,2,4)
plt.hist(df_cbrt)
plt.title("Cube Root Transformation")
plt.show()</pre>
<p>The following is the<a id="_idIndexMarker216"/> output of <span class="No-Break">the code:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<img alt="Figure 2.23 – Histograms of the original and transformed data" height="1044" src="image/B18945_02_023.jpg" width="1063"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.23 – Histograms of the original and transformed data</p>
<p>Using <a id="_idIndexMarker217"/>transformation, we<a id="_idIndexMarker218"/> can see the transformed histograms are more normally distributed than the original one. It seems that the best transformation in this example is cube root transformation. With real-world data, it is important to determine whether a transformation is needed, and, if so, which transformation should <span class="No-Break">be used.</span></p>
<p>Other data transformation methods, for example, finding duplicate data, dealing with missing values, and feature scaling will be discussed in hands-on, real-world use cases in Python in the <span class="No-Break">following chapters.</span></p>
<h1 id="_idParaDest-49"><a id="_idTextAnchor053"/>Summary</h1>
<p>In the first section of this chapter, we learned about types of data and how to visualize these types of data. Then, we covered how to describe and measure attributes of data distribution. We learned about the standard normal distribution, why it’s important, and how the central limit theorem is applied in practice by demonstrating bootstrapping. We also learned how bootstrapping can make use of non-normally distributed data to test hypotheses using confidence intervals. Next, we covered mathematical knowledge as permutations and combinations and introduced permutation testing as another non-parametric test in addition to bootstrapping. We finished the chapter with different data transformation methods that are useful in many situations when performing statistical tests requiring normally <span class="No-Break">distributed data.</span></p>
<p>In the next chapter, we will take a detailed look at hypothesis testing and discuss how to draw statistical conclusions from the results of the tests. We will also look at errors that can occur in statistical tests and how to select <span class="No-Break">statistical power.</span></p>
<h1 id="_idParaDest-50"><a id="_idTextAnchor054"/>References</h1>
<ul>
<li>[<em class="italic">1</em>] Skewness – <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm"><span class="No-Break">https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm</span></a></li>
<li>[<em class="italic">2</em>] Kurtosis – <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm#:~:text=Kurtosis%20is%20a%20measure%20of,would%20be%20the%20extreme%20case"><span class="No-Break">https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm#:~:text=Kurtosis%20is%20a%20measure%20of,would%20be%20the%20extreme%20case</span></a><span class="No-Break">.</span></li>
<li>[<em class="italic">3</em>] Normal Distribution – <em class="italic">C.F. GAUSS AND THE METHOD OF LEAST SQUARES</em>, <em class="italic">ŚLĄSKI PRZEGLĄD STATYSTYCZNY Silesian Statistical Review</em>, Nr 12(18), O. Sheynin, <span class="No-Break">Sep. 1999</span></li>
</ul>
</div>
</div></body></html>