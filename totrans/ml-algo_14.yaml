- en: A Brief Introduction to Deep Learning and TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we're going to briefly introduce deep learning with some examples
    based on TensorFlow. This topic is quite complex and needs dedicated books; however,
    our goal is to allow the reader to understand some basic concepts that can be
    useful before starting a complete course. In the first section, we're presenting
    the structure of artificial neural networks and how they can be transformed in
    a complex computational graph with several different layers. In the second one,
    instead, we're going to introduce the basic concepts concerning TensorFlow and
    we'll show some examples based on algorithms already discussed in previous chapters.
    In the last section, we briefly present Keras, a high-level deep learning framework
    and we build an example of image classification using a convolutional neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning at a glance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning has become very famous in the last few decades, thanks to hundreds
    of applications that are changing the way we interact with many electronic (and
    non-electronic) systems. Speech, text, and image recognition; autonomous vehicles;
    and intelligent bots (just to name a few) are common applications normally based
    on deep learning models and have outperformed any previous classical approach.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand what a deep architecture is (considering that this is only
    a brief introduction), we need to step back and talk about standard artificial
    neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An **artificial neural network** (**ANN**) or simply neural network is a directed
    structure that connects an input layer with an output one. Normally, all operations
    are differentiable and the overall vectorial function can be easily written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7c98e70-61e6-42ad-b597-10f44309e086.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f927c9b8-7a07-41c1-82c4-c9c3f783da73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The adjective "neural" comes from two important elements: the internal structure
    of a basic computational unit and the interconnections among them. Let''s start
    with the former. In the following figure, there''s a schematic representation
    of an artificial neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36f956de-358a-4cd5-97e8-d62ac8b2a1af.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A neuron core is connected with *n* input channels, each of them characterized
    by a synaptic weight *w[i]*. The input is split into its components and they are
    multiplied by the corresponding weight and summed. An optional bias can be added
    to this sum (it works like another weight connected to a unitary input). The resulting
    sum is filtered by an activation function *f[a]* (for example a sigmoid, if you
    recall how a logistic regression works) and the output is therefore produced.
    In [Chapter 5](9d0c9c1c-e5b3-46a1-b331-c9689a687edf.xhtml), *Logistic Regression*,
    we also discussed perceptrons (the first artificial neural networks), which correspond
    exactly to this architecture with a binary-step activation function. On the other
    hand, even a logistic regression can be represented as a single neuron neural
    network, where *f[a](x)* is a sigmoid. The main problem with this architecture
    is that it''s intrinsically linear because the output is always a function of
    the dot product between the input vector and the weight one. You already know
    all the limitations that such a system has; therefore it''s necessary to step
    forward and create the first **Multi-layer Perceptron** (**MLP**). In the following
    figure, there''s a schematic representation of an MLP with an n-dimensional input,
    *p* hidden neurons, and a *k*-dimensional output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/535b5780-b621-46d8-b69f-e5175b4e8b4f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are three layers (even though the number can be larger): the input layer,
    which receives the input vectors; a hidden layer; and the output one, which is
    responsible for producing the output. As you can see, every neuron is connected
    to all the neurons belonging the next layer and now we have two weight matrices, *W
    = (w[ij])*and *H = (h[jk])*, using the convention that the first index is referred
    to the previous layer and the second to the following one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the net input to each hidden neuron and the corresponding output
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b2ac7fde-a8f3-4379-a6d2-16798579d9bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the same way, we can compute the network output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5cc3888c-04f9-4496-a850-bf4db9162ca7.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the network has become highly non-linear and this feature allows
    us to model complex scenarios that were impossible to manage with linear methods.
    But how can we determine the values for all synaptic weights and biases? The most
    famous algorithm is called **back-propagation** and it works in a very simple
    way (the only important assumption is that both *f[a](x)* must be differentiable).
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we need to define an error (loss) function; for many classification
    tasks, it can be the total squared error:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8837b97-25d9-4e7d-8fa8-e72caba6d0ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here we have assumed to have *N* input samples. Expanding it, we obtain:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06d71310-d0c2-4823-be4a-728e2ddbcf32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This function depends on all variables (weights and biases), but we can start
    from the bottom and consider first only *h*[*jk* ](for simplicity I''m not considering
    the biases as normal weights); therefore we can compute the gradients and update
    the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[![](img/ac32ae69-659c-462f-abd5-92a88181bd25.png) ]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same way, we can derive the gradient with respect to *w[ij]*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d120e71-d46d-4944-ae88-f7eb430334c6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the term alpha (which is proportional to the error delta) is
    back-propagated from the output layer to the hidden one. If there are many hidden
    layers, this procedure should be repeated recursively until the first layer. The
    algorithm adopts the gradient descent method; therefore it updates the weights
    iteratively until convergence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5173acce-f8f1-41f0-8077-137731ad6016.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the parameter `eta` (Greek letter in the formula) is the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: In many real problems, the stochastic gradient descent method is adopted (read
    [https://en.wikipedia.org/wiki/Stochastic_gradient_descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent), for
    further information), which works with batches of input samples, instead of considering
    the entire dataset. Moreover, many optimizations can be employed to speed up the
    convergence, but they are beyond the scope of this book. In Goodfellow I., Bengio
    Y., Courville A., *Deep Learning*, MIT Press*,* the reader can find all the details
    about the majority of them. For our purposes, it's important to know that we can
    build a complex network and, after defining a global loss function, optimize all
    the weights with a standard procedure. In the section dedicated to TensorFlow,
    we're going to show an example of MLP, but we're not implementing the learning
    algorithm because, luckily, all optimizers have already been built and can be
    applied to every architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Deep architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLPs are powerful, but their expressiveness is limited by the number and the
    nature of the layers. Deep learning architectures, on the other side, are based
    on a sequence of heterogeneous layers which perform different operations organized
    in a computational graph. The output of a layer, correctly reshaped, is fed into
    the following one, until the output, which is normally associated with a loss
    function to optimize. The most interesting applications have been possible thanks
    to this stacking strategy, where the number of variable elements (weights and
    biases) can easily reach over 10 million; therefore, the ability to capture small
    details and generalize them exceeds any expectations. In the following section,
    I'm going to introduce briefly the most important layer types.
  prefs: []
  type: TYPE_NORMAL
- en: Fully connected layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A fully connected (sometimes called dense) layer is made up of n neurons and
    each of them receives all the output values coming from the previous layer (like
    the hidden layer in a MLP). It can be characterized by a weight matrix, a bias
    vector, and an activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/647ecc9f-9608-4cee-bfd3-5b1c2f8ec657.png)'
  prefs: []
  type: TYPE_IMG
- en: 'They are normally used as intermediate or output layers, in particular when
    it''s necessary to represent a probability distribution. For example, a deep architecture
    could be employed for an image classification with *m* output classes. In this
    case, the *softmax* activation function allows having an output vector where each
    element is the probability of a class (and the sum of all outputs is always normalized
    to 1.0). In this case, the argument is considered as a **logit** or the logarithm
    of a probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7898100d-7f45-46c5-8c3e-aa550424f86b.png)'
  prefs: []
  type: TYPE_IMG
- en: '*W[i]* is the i-th row of *W***. **The probability of a class *y**[i]*** is
    obtained by applying the *softmax* function to each *logit*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76e5ef7e-e437-44d0-8258-7215cffb1605.png)'
  prefs: []
  type: TYPE_IMG
- en: This type of output can easily be trained using a cross-entropy loss function,
    as already discussed for logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Convolutional layers are normally applied to bidimensional inputs (even though
    they can be used for vectors and 3D matrices) and they became particularly famous
    thanks to their extraordinary performance in image classification tasks. They
    are based on the discrete convolution of a small kernel *k* with a bidimensional
    input (which can be the output of another convolutional layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d8eb5e0-ef8d-42c1-bdba-0342cd94c16f.png)'
  prefs: []
  type: TYPE_IMG
- en: A layer is normally made up of n fixed-size kernels, and their values are considered
    as weights to learn using a back-propagation algorithm. A convolutional architecture,
    in most cases, starts with layers with few larger kernels (for example, 16 (8
    x 8) matrices) and feeds their output to other layers with a higher number of
    smaller kernels (32 (5 x 5), 128 (4 x 4), and 256 (3 x 3)). In this way, the first
    layers should learn to capture more generic features (such as orientation), while
    the following ones will be trained to capture smaller and smaller elements (such
    as the position of eyes, nose, and mouth in a face). The output of the last convolutional
    layer is normally flattened (transformed into a 1D vector) and used as input for
    one or more fully connected layers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, there''s a schematic representation of a convolution
    over a picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f6d3092-71f1-456f-989a-500996f968b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Each square set of 3 x 3 pixels is convoluted with a Laplacian kernel and transformed
    into a single value, which corresponds to the sum of upper, lower, left, and right
    pixels (considering the centre) minus four times the central one. We're going
    to see a complete example using this kernel in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: 'To reduce the complexity when the number of convolutions is very high, one
    or more **pooling layers** can be employed. Their task is to transform each group
    of input points (pixels in an image) into a single value using a predefined strategy.
    The most common pooling layers are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Max pooling**: Every bidimensional group of (*m* x *n*) pixels is transformed
    into a single pixel whose value is the greatest in the group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average pooling**: Every bidimensional group of (*m* x *n*) pixels is transformed
    into a single pixel whose value is the average of the group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this way, the dimensionality of the original matrix can be reduced with a
    loss of information, but that can often be discarded (in particular in the first
    layers where the granularity of the features is coarse). Another important category
    of layers are the **zero-padding** ones. They work by adding null values (0) before
    and after the input (1D) or at the left, right, top and bottom side of 2D input.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A dropout layer is used to prevent overfitting of the network by randomly setting
    a fixed number of input elements to 0\. This layer is adopted during the training
    phase, but it's normally deactivated during test, validation, and production phases.
    Dropout networks can exploit higher learning rates, moving in different directions
    on the loss surface (setting to zero a few random input values in the hidden layers
    is equivalent to training different sub-models) and excluding all the error-surface
    areas that don't lead to a consistent optimization. Dropout is very useful in
    very big models, where it increases the overall performance and reduces the risk
    of freezing some weights and overfitting the model.
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A recurrent layer is made up of particular neurons that present recurrent connections
    so as to bind the state at time *t* to its previous values (in general, only one).
    This category of computational cells is particularly useful when it's necessary
    to capture the temporal dynamics of an input sequence. In many situations, in
    fact, we expect an output value that must be correlated with the history of the
    corresponding inputs. But an MLP, as well as the other models that we've discussed,
    are stateless. Therefore, their output is determined only by the current input.
    RNNs overcome this problem by providing an internal memory which can capture short-term
    and long-term dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: The most common cells are **Long Short-Term Memory** (**LSTM**) and **Gated
    Recurrent Unit** (**GRU**) and they can both be trained using a standard back-propagation
    approach. As this is only an introduction, I cannot go deeper (RNN mathematical
    complexity is non-trivial); however, it's useful to remember that whenever a temporal
    dimension must be included in a deep model, RNNs offer stable and powerful support.
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a computational framework created by Google and has become one
    of the most diffused deep-learning toolkits. It can work with both CPUs and GPUs
    and already implements most of the operations and structures required to build
    and train a complex model. TensorFlow can be installed as a Python package on
    Linux, Mac, and Windows (with or without GPU support); however, I suggest you
    follow the instructions provided on the website (the link can be found in the
    infobox at the end of this chapter) to avoid common mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main concept behind TensorFlow is the computational graph, or a set of
    subsequent operations that transform an input batch into the desired output. In
    the following figure, there''s a schematic representation of a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ec9a5336-23d5-4470-acb6-735806039a53.png)'
  prefs: []
  type: TYPE_IMG
- en: Starting from the bottom, we have two input nodes (**a** and **b**), a transpose
    operation (that works on **b**), a matrix multiplication and a mean reduction.
    The **init** block is a separate operation, which is formally part of the graph,
    but it's not directly connected to any other node; therefore it's autonomous (indeed,
    it's a global initializer).
  prefs: []
  type: TYPE_NORMAL
- en: 'As this one is only a brief introduction, it''s useful to list all of the most
    important strategic elements needed to work with TensorFlow so as to be able to
    build a few simple examples that can show the enormous potential of this framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Graph**: This represents the computational structure that connects a generic
    input batch with the output tensors through a directed network made of operations.
    It''s defined as a `tf.Graph()` instance and normally used with a Python context
    manager.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Placeholder**: This is a reference to an external variable, which must be
    explicitly supplied when it''s requested for the output of an operation that uses
    it directly or indirectly. For example, a placeholder can represent a variable
    `x`, which is first transformed into its squared value and then summed to a constant
    value. The output is then `x²+c`, which is materialized by passing a concrete
    value for `x`. It''s defined as a `tf.placeholder()` instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable**: An internal variable used to store values which are updated by
    the algorithm. For example, a variable can be a vector containing the weights
    of a logistic regression. It''s normally initialized before a training process
    and automatically modified by the built-in optimizers. It''s defined as a `tf.Variable()`
    instance. A variable can also be used to store elements which must not be considered
    during training processes; in this case, it must be declared with the parameter
    `trainable=False`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Constant**: A constant value defined as a `tf.constant()` instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operation**: A mathematical operation that can work with placeholders, variables,
    and constants. For example, the multiplication of two matrices is an operation
    defined as `tf.matmul(A, B)`. Among all operations, gradient calculation is one
    of the most important. TensorFlow allows determining the gradients starting from
    a determined point in the computational graph, until the origin or another point
    that must be logically before it. We''re going to see an example of this operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session**: This is a sort of wrapper-interface between TensorFlow and our
    working environment (for example, Python or C++). When the evaluation of a graph
    is needed, this macro-operation will be managed by a session, which must be fed
    with all placeholder values and will produce the required outputs using the requested
    devices. For our purposes, it''s not necessary to go deeper into this concept;
    however, I invite the reader to retrieve further information from the website
    or from one of the resources listed at the end of this chapter. It''s declared
    as an instance of `tf.Session()` or, as we''re going to do, an instance of `tf.InteractiveSession()`.
    This type of session is particularly useful when working with notebooks or shell
    commands, because it places itself automatically as the default one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Device**: A physical computational device, such as a CPU or a GPU. It''s
    declared explicitly through an instance of the class `tf.device()` and used with
    a context manager. When the architecture contains more computational devices,
    it''s possible to split the jobs so as to parallelize many operations. If no device
    is specified, TensorFlow will use the default one (which is the main CPU or a
    suitable GPU if all the necessary components are installed).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can now analyze some simple examples using these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Computing gradients
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The option to compute the gradients of all output tensors with respect to any
    connected input or node is one of the most interesting features of TensorFlow,
    because it allows us to create learning algorithms without worrying about the
    complexity of all transformations. In this example, we first define a linear dataset
    representing the function *f(x) = x* in the range (-100, 100):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding plot is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f6bdb853-a204-4bfa-87e6-ad1790513c93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we want to use TensorFlow to compute:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7d221f9-5369-4dd5-b9b2-d1f40ae217d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The first step is defining a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Within the context of this graph, we can define our input placeholder and other
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: A placeholder is generally defined with a type (first parameter), a shape, and
    an optional name. We've decided to use a `tf.float32` type because this is the
    only type also supported by GPUs. Selecting `shape=(None, 1)` means that it's
    possible to use any bidimensional vectors with the second dimension equal to 1.
  prefs: []
  type: TYPE_NORMAL
- en: The first operation computes the third power if `Xt` is working on all elements.
    The second operation computes all the gradients of `Y` with respect to the input
    placeholder `Xt`. The last operation will repeat the gradient computation, but
    in this case, it uses `Yd`, which is the output of the first gradient operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now pass some concrete data to see the results. The first thing to do
    is create a session connected with this graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'By using this session, we ask any computation using the method `run()`. All
    the input parameters must be supplied through a feed-dictionary, where the key
    is the placeholder, while the value is the actual array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We needed to reshape our array to be compliant with the placeholder. The first
    argument of `run()` is a list of tensors that we want to be computed. In this
    case, we need all operation outputs. The plot of each of them is shown in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5184642f-a567-4058-8295-14625558a3dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As expected, they represent respectively: *x³*, *3x²*, and *6x*.'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we can try a more complex example implementing a logistic regression algorithm.
    The first step, as usual, is creating a dummy dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The dataset is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a090ec57-21aa-417d-8bee-4aeee20ed613.png)'
  prefs: []
  type: TYPE_IMG
- en: 'At this point, we can create the graph and all placeholders, variables, and
    operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The placeholder `Xt` is needed for the points, while `Yt` represents the labels.
    At this point, we need to involve a couple of variables: if you remember, they
    store values that are updated by the training algorithm. In this case, we need
    a weight vector `W` (with two elements) and a single `bias`. When a variable is
    declared, its initial value must be provided; we''ve decided to set both to zero
    using the function `tf.zeros()`, which accepts as argument the shape of the desired
    tensor.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can compute the output (if you don''t remember how logistic regression
    works, please step back to [Chapter 5](9d0c9c1c-e5b3-46a1-b331-c9689a687edf.xhtml),
    *Logistic Regression*) in two steps: first the sigmoid exponent `Ye` and then
    the actual binary output `Yc`, which is obtained by rounding the sigmoid value.
    The training algorithm for a logistic regression minimizes the negative log-likelihood,
    which corresponds to the cross-entropy between the real distribution `Y` and `Yc`.
    It''s easy to implement this loss function; however, the function `tf.log()` is
    numerically unstable (when its value becomes close to zero, it tends to negative
    infinity and yields a `NaN` value); therefore, TensorFlow has implemented a more
    robust function, `tf.nn.sigmoid_cross_entropy_with_logits()`, which computes the
    cross-entropy assuming the output is produced by a sigmoid. It takes two parameters,
    the `logits` (which corresponds to the exponent `Ye`) and the target `labels`,
    that are stored in `Yt`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can work with one of the most powerful TensorFlow features: the training
    optimizers. After defining a loss function, it will be dependent on placeholders,
    constants, and variables. A training optimizer (such as `tf.train.GradientDescentOptimizer()`),
    through its method `minimize()`, accepts the loss function to optimize. Internally,
    according to every specific algorithm, it will compute the gradients of the loss
    function with respect to all trainable variables and will apply the corresponding
    corrections to the values. The parameter passed to the optimizer is the learning
    rate.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we have defined an extra operation called `training_step`, which
    corresponds to a single stateful update step. It doesn't matter how complex the
    graph is; all trainable variables involved in a loss function will be optimized
    with a single instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it''s time to train our logistic regression. The first thing to do is to
    ask TensorFlow to initialize all variables so that they are ready when the operations
    have to work with them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we can create a simple training loop (it should be stopped when
    the loss stops decreasing; however, we have a fixed number of iterations):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, at each iteration we ask TensorFlow to compute the loss function
    and a training step, and we always pass the same dictionary containing `X` and
    `Y`. At the end of this loop, the loss function is stable and we can check the
    quality of this logistic regression by plotting the separating hyperplane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/61e3843b-4a4d-418f-9db2-7ae07aa0b78d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The result is approximately equivalent to the one obtained with the scikit-learn
    implementation. If we want to know the values of both coefficients (weights) and
    intercept (bias), we can ask TensorFlow to retrieve them by calling the method
    `eval()` on each variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Classification with a multi-layer perceptron
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can now build an architecture with two dense layers and train a classifier
    for a more complex dataset. Let''s start by creating it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Even if we have only two classes, the dataset has three features and three
    clusters per class; therefore it''s almost impossible that a linear classifier
    can separate it with very high accuracy. A plot of the dataset is shown in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/76c390a4-fc1c-4d6b-95ad-be58f677d82b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For benchmarking purposes, it''s useful to test a logistic regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The score computed on the test set is about 71%, which is not really bad but
    below an acceptable threshold. Let''s try with an MLP with 50 hidden neurons (with
    hyperbolic tangent activation) and 1 sigmoid output neuron. The hyperbolic tangent
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/301cace9-c3c1-40e4-acb8-315d536b31f9.png)'
  prefs: []
  type: TYPE_IMG
- en: And it's bounded asymptotically between -1.0 and 1.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are not going to implement each layer manually, but we''re using the built-in
    class `tf.contrib.layers.fully_connected()`. It accepts the input tensor or placeholder as
    the first argument and the number of layer-output neurons as the second one. The
    activation function can be specified using the attribute `activation_fn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As in the previous example, we have defined two placeholders, `Xt` and `Yt`,
    and two fully connected layers. The first one accepts as input `Xt` and has 50
    output neurons (with `tanh` activation), while the second accepts as input the
    output of the previous layer (`layer_1`) and has only one sigmoid neuron, representing
    the class. The rounded output is provided by `Yo`, while the loss function is
    the total squared error, and it's implemented using the function `tf.nn.l2_loss()` computed
    on the difference between the output of the network (`layer_2`) and the target
    class placeholder `Yt`. The training step is implemented using a standard gradient
    descent optimizer, as for the logistic regression example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now implement a training loop, splitting our dataset into a fixed number
    of batches (the number of samples is defined in the variable `batch_size`) and
    repeating a complete cycle for `nb_epochs` epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: As it's possible to see, without particular attention to all details, the accuracy
    computed on the test set is 94%. This is an acceptable value, considering the
    structure of the dataset. In Goodfellow I., Bengio Y., Courville A., *Deep Learning*,
    MIT Press*, *the reader will find details of many important concepts that can
    still improve the performance and speed up the convergence process.
  prefs: []
  type: TYPE_NORMAL
- en: Image convolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Even if we''re not building a complete deep learning model, we can test how
    convolution works with a simple example. The input image we''re using is already
    provided by `SciPy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The original picture is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/22e0ad00-5f44-4708-acc4-f8e0addbcdde.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We''re going to apply a Laplacian filter, which emphasizes the boundary of
    each shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The kernel must be repeated twice because the TensorFlow convolution function
    `tf.nn.conv2d` expects an input and an output filter. We can now build the graph
    and test it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The parameters `strides` is a four-dimensional vector (each value corresponds
    to the input dimensions, so the first is the batch and the last one is the number
    of channels) that specifies how many pixels the sliding window must shift. In
    this case, we want to cover all the image shifting pixel to pixel. The parameter
    `padding` determines how the new dimensions must be computed and whether it's
    necessary to apply a zero padding. In our case, we're using the value `SAME`,
    which computes the dimensions by rounding off to the next integer the original
    dimensions divided by the corresponding strides value (as the latter are both
    1.0, the resulting image size will be exactly like the original one).
  prefs: []
  type: TYPE_NORMAL
- en: 'The output image is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dfb8bb16-70eb-4c94-acb1-1e047180c38d.png)'
  prefs: []
  type: TYPE_IMG
- en: The installation instructions for every operating system can be found on [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/).
  prefs: []
  type: TYPE_NORMAL
- en: A quick glimpse inside Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Keras ([https://keras.io](https://keras.io)) is a high-level deep learning
    framework that works seamlessly with low-level backends like TensorFlow, Theano
    or CNTK. In Keras a model is like a sequence of layers where each output is fed
    into the following computational block until the final layer is reached. The generic
    structure of a model is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The class `Sequential` defines a generic empty model, that already implements
    all the methods needed to `add` layers, `compile` the model according to the underlying
    framework, to `fit` and `evaluate` the model and to `predict` the output given
    an input. All the most common layers are already implemented, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Dense, Dropout and Flattening layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional (1D, 2D and 3D) layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pooling layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero padding layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RNN layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A model can be compiled using several loss functions (like MSE or cross-entropy)
    and all the most diffused Stochastic Gradient Descent optimization algorithms
    (like RMSProp or Adam). For further details about the mathematical foundation
    of these methods, please refer to Goodfellow I., Bengio Y., Courville A., *Deep
    Learning*, MIT Press. As it''s impossible to discuss all important elements in
    such a short space, I prefer to create a complete example of image classification
    based on a convolutional network. The dataset we''re going to use is the CIFAR-10
    ([https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html))
    which is made up of 60000 small RGB images (32 x 32) belonging to 10 different
    categories (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck).
    In the following figure, a subset of images is shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e758d067-bd32-4d83-86aa-eaa275fed875.png)'
  prefs: []
  type: TYPE_IMG
- en: Since the last release, Keras allows us to download this dataset using a built-in
    function; therefore, no further actions are required to use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is loading the dataset and splitting it into training and test
    subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The training dataset contains 50000 images, while the test set 10000\. Now it's
    possible to build the model. We want to use a few convolutional layers to capture
    the specific elements of each category. As explained in the previous section,
    these particular layers can learn to identify specific geometric properties and
    generalize in an excellent way. In our small architecture, we start with a (5
    x 5) filter size to capture all the low-level features (like the orientation)
    and proceed by increasing the number of filters and reducing their size. In this
    way, the high-level features (like the shape of a wheel or the relative position
    of eyes, nose, and mouth) can also be captured.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The first instruction creates a new empty model. At this point, we can all
    the layers we want to include in the computational graph. The most common parameters
    of a convolutional layer are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The number of filters**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kernel size** (as tuple)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strides** (the default value is [1, 1]). This parameter specifies how many
    pixels the sliding window must consider when shifting on the image. [1, 1] means
    that no pixels are discarded. [2, 2] means that every horizontal and vertical
    shift will have a width of 2 pixels and so forth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activation** (the default value is None, meaning that the identity function
    will be used)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input shape** (only for the first layer is this parameter mandatory)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our first layer has 32 (5 x 5) filters with a **ReLU** (**Rectified Linear
    Unit**) activation. This function is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09fbf182-d47a-4c52-ac17-d45f21dc2afd.png)'
  prefs: []
  type: TYPE_IMG
- en: The second layer reduces the dimensionality with a max pooling considering (2
    x 2) blocks. Then we apply another convolution with 64 (4 x 4) filters followed
    by a zero padding (1 pixel at the top, bottom, left and right side of the input)
    and finally, we have the third convolutional layer with 128 (3 x 3) filters followed
    by a max pooling and a zero padding.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we need to flatten the output of the last layer, so to work
    like in a MLP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'A dropout (with a probability of 0.2) is applied to the output of the last
    zero-padding layer; then this multidimensional value is flattened and transformed
    in a vector. This value is fed into a fully-connected layer with 128 neurons and
    ReLU activation. Another dropout is applied to the output (to prevent the overfitting)
    and, finally, this vector is fed into another fully connected layer with 10 neurons
    with a *softmax* activation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c01a96a0-0c0e-400d-a23e-003f70d8b2e5.png)'
  prefs: []
  type: TYPE_IMG
- en: In this way, the output of the model represents a discrete probability distribution
    (each value is the probability of the corresponding class).
  prefs: []
  type: TYPE_NORMAL
- en: 'The last step before training the model is compiling it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Keras will transform the high-level description into low-level operations (like
    the ones we have discussed in the previous section) with a categorical cross-entropy
    loss function (see the example of TensorFlow logistic regression) and the Adam
    optimizer. Moreover, it will apply an accuracy metric to dynamically evaluate
    the performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, the model can be trained. We need only two preliminary operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing the images so they have values between 0 and 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the one-hot encoding to the integer label
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first operation can be simply performed by dividing the dataset by 255,
    while the second can be easily carried out using the built-in function `to_categorical()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to train with batches made up of 32 images and for a period of 15 epochs.
    The reader is free to change all these values to compare the results. The output
    provided by Keras shows the progress in the learning phase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'At the end of the 15th epoch, the accuracy on the training set is about 84%
    (a very good result). The final operation is evaluating the model with the test
    set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The final validation accuracy is lower (about 72%) than the one achieved during
    the training phase. This is a normal behavior for deep models, therefore, when
    optimizing the algorithm, it's always a good practice to use the cross validation
    or a well-defined test set (with the same distribution of the training set and
    25-30% of total samples).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we have presented a very simple architecture, but the reader can
    go deeper into these topics and create more complex models (Keras also contains
    some very famous pre-trained architectures like VGG16/19 and Inception V3 that
    can also be used to perform image classifications with 1000 categories).
  prefs: []
  type: TYPE_NORMAL
- en: 'All the information needed to install Keras with different backends, and the
    official documentation can be found on the website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://keras.io](https://keras.io)'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Goodfellow I., Bengio Y., Courville A., *Deep Learning*, MIT Press
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abrahams S., Hafner D., *TensorFlow for Machine Intelligence: A Hands-On Introduction
    to Learning Algorithms*, Bleeding Edge Press'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bonaccorso G., *Neural Artistic Style Transfer with Keras*, [https://github.com/giuseppebonaccorso/Neural_Artistic_Style_Transfer](https://github.com/giuseppebonaccorso/Neural_Artistic_Style_Transfer)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky A, Learning Multiple Layers of Features from Tiny Images, 2009 ([https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have briefly discussed some basic deep learning concepts,
    and the reader should now understand what a computational graph is and how it
    can be modeled using TensorFlow. A deep architecture, in fact, can be seen as
    a sequence of layers connected to each other. They can have different characteristics
    and purposes, but the overall graph is always a directed structure that associates
    input values with a final output layer. Therefore, it's possible to derive a global
    loss function that will be optimized by a training algorithm. We also saw how
    TensorFlow computes the gradients of an output tensor with respect to any previous
    connected layer and therefore how it's possible to implement the standard back-propagation
    strategy seamlessly to deep architectures. We did not discuss actual deep learning
    problems and methods because they require much more space; however, the reader
    can easily find many valid resources to continue his/her exploration in this fascinating
    field.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we're going to summarize many of the concepts previously
    discussed in order to create complex machine learning architectures.
  prefs: []
  type: TYPE_NORMAL
