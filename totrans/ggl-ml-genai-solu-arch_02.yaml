- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: AI/ML Concepts, Real-World Applications, and Challenges
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能/机器学习概念、实际应用和挑战
- en: This chapter will introduce basic concepts that will be explored in more detail
    throughout the rest of the book. We understand that readers of this book may be
    starting from different stages in their **artificial intelligence/machine learning**
    (**AI/ML**) journey, whereby some readers may already be advanced practitioners
    who are familiar with running AI/ML workloads while others may be newer to AI/ML
    in general. For this reason, we will briefly describe important fundamental concepts
    as required throughout the book to ensure that all readers have a common baseline
    upon which to build their understanding of the topics we discuss. Readers who
    are newer to AI/ML will benefit from learning the important underlying concepts
    rather than diving straight into the deep end of each topic without a baseline
    context, and advanced practitioners should find them to be useful knowledge refreshers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍将在本书其余部分更详细探讨的基本概念。我们理解本书的读者可能处于他们**人工智能/机器学习**（**AI/ML**）旅程的不同阶段，其中一些读者可能已经是熟悉运行AI/ML工作负载的高级从业者，而其他人可能对AI/ML总体上较为陌生。因此，我们将根据需要简要描述本书中的重要基本概念，以确保所有读者都有一个共同的起点，以便构建他们对所讨论主题的理解。对于AI/ML的新手来说，学习重要的基础概念比在没有基础背景的情况下直接深入每个主题更有益，而对于高级从业者来说，这些概念应该是有用的知识更新。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Terminology—AI, ML, **deep learning** (**DL**), and **generative** **AI** (**GenAI**)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语——人工智能（AI）、机器学习（ML）、**深度学习**（**DL**）和**生成式人工智能**（**GenAI**）
- en: A brief history of AI/ML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能/机器学习（AI/ML）简史
- en: ML approaches and use cases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习方法与用例
- en: A brief discussion of ML basic concepts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对机器学习基本概念的简要讨论
- en: Common challenges in developing ML applications
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发机器学习应用中的常见挑战
- en: By the end of this chapter, you will understand the common types of AI/ML approaches
    and their real-world applications, as well as some historical background on the
    development of AI/ML concepts. Finally, you will learn about common types of challenges
    and pitfalls that companies encounter when they begin to implement AI/ML workloads.
    This is a particularly important part of the book, especially for the solutions
    architect role, and it provides real-world insights that are not found in academic
    courses; these insights come from years of experience in the field, working on
    large-scale AI/ML projects with many different companies.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解常见的AI/ML方法及其实际应用，以及AI/ML概念发展的一些历史背景。最后，您将了解公司在开始实施AI/ML工作负载时可能遇到的一些常见挑战和陷阱。这部分在本书中尤为重要，特别是对于解决方案架构师角色，它提供了在学术课程中找不到的实战见解；这些见解来自在多个公司进行大规模AI/ML项目多年的经验。
- en: Terminology – AI, ML, DL, and GenAI
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语——AI、ML、DL和GenAI
- en: Here, we describe how the terms *AI* and *ML* relate to each other. It should
    be noted that these terms are often used interchangeably, as well as the abbreviated
    term, *AI/ML*, which serves as an umbrella term to encapsulate both AI and ML.
    We also describe how the terms *DL* and *GenAI* fit in under the umbrella of AI/ML.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们描述了术语*AI*和*ML*之间的关系。需要注意的是，这些术语通常可以互换使用，以及缩写术语*AI/ML*，它作为一个总括术语，用于包含人工智能和机器学习。我们还描述了术语*DL*和*GenAI*如何在AI/ML的范畴下定位。
- en: We’ll begin by briefly including officially-accepted definitions of the terms
    *AI* and *ML*. We have chosen to include definitions from the *Collins English
    Dictionary*, in which AI is defined as “*a type of computer technology concerned
    with making machines work in an intelligent way, similar to the way that the human
    mind works*” and ML is defined as “*a branch of artificial intelligence in which
    a computer generates rules underlying or based on raw data that has been fed into
    it.*” The term *DL* has not yet been officially included as a dictionary term,
    but the *Collins English Dictionary* lists it as a new word suggestion, with the
    proposed definition of “*a type of machine learning concerned with artificial
    neural networks allowing advanced pattern recognition.*” We understand that official
    dictionary definitions don’t always explain the concepts completely, but it’s
    important to include them for reference, and we will cover these concepts in more
    detail as we progress through the book. All of those terms constitute what we
    are now beginning to refer to as “Traditional AI”, to distinguish it from GenAI,
    which is a much newer, and quite different concept. There will be an entire section
    of this book dedicated to GenAI, so this distinction will become clearer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先简要介绍官方认可的*AI*和*ML*的定义。我们选择包含来自*柯林斯英语词典*的定义，其中AI被定义为“*一种关注使机器以类似人类大脑工作方式工作的计算机技术*”，而ML被定义为“*人工智能的一个分支，其中计算机根据输入的原始数据生成规则。*”术语*DL*尚未被正式列为词典术语，但*柯林斯英语词典*将其列为新词建议，建议定义为“*一种关注人工神经网络的高级模式识别的机器学习类型*。”我们理解官方词典定义并不总是完全解释概念，但包含它们作为参考是很重要的，随着我们继续阅读本书，我们将更详细地介绍这些概念。所有这些术语构成了我们现在开始称之为“传统AI”的内容，以区别于GenAI，后者是一个更新且截然不同的概念。本书将有一个专门章节介绍GenAI，因此这种区别将变得更加清晰。
- en: 'As a general rule, DL is considered to be a sub-field of ML, and ML is considered
    to be a sub-field of AI. GenAI can be seen as a sub-field within DL, because it
    uses Deep Neural Networks and concepts from Natural Language Processing in its
    application. You will often see them graphically represented in literature as
    a set of concentric circles, whereby AI is the broadest field, ML is nested as
    a sub-field within AI, and DL is nested as a sub-field within ML. I’m adding to
    this conceptual representation by including GenAI within the field of DL, although
    it is more of an association rather than a strict sub-category:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，DL被视为ML的一个子领域，ML被视为AI的一个子领域。GenAI可以被视为DL中的一个子领域，因为它在其应用中使用了深度神经网络和自然语言处理的概念。你经常在文献中看到它们以同心圆的形式图形化表示，其中AI是最广泛的领域，ML作为AI中的一个子领域嵌套，DL作为ML中的一个子领域嵌套。我在这个概念表示中增加了GenAI在DL领域的位置，尽管这更多是一种关联而非严格的子类别：
- en: '![Figure 1.1: Depicting the relationship between the terms AI, ML, DL, and
    GenAI](img/B18143_01_1.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1：描述AI、ML、DL和GenAI之间的关系](img/B18143_01_1.jpg)'
- en: 'Figure 1.1: Depicting the relationship between the terms AI, ML, DL, and GenAI'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：描述AI、ML、DL和GenAI之间的关系
- en: Now that we have covered some basic terminology regarding AI/ML, let’s briefly
    discuss its history and understand how the AI/ML industry has developed so far.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了一些关于AI/ML的基本术语，让我们简要地讨论一下其历史，并了解AI/ML行业至今的发展情况。
- en: A brief history of AI/ML
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI/ML的简要历史
- en: If we traveled back in time by only a few years — to the year 2015 — and compared
    the state of the AI/ML industry to what it is today, we would see that relatively
    few companies had commercially implemented large-scale AI/ML use cases at that
    point. Although we would find academic research being performed in this space,
    we wouldn’t regularly hear AI/ML being discussed in mainstream media, and successful
    commercial or industrial implementations had mainly been achieved only by some
    of the world’s largest, industry-leading technology or niche companies. Jumping
    forward by just 2 years, we find that by the end of 2017, the tech industry is
    abuzz with discussions of AI/ML, and it seems to be the main topic—or at least
    one of the main topics—on everybody’s mind.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只回到几年前——回到2015年——并将当时的人工智能/机器学习行业的状况与今天相比，我们会发现当时相对很少有公司已经商业化了大规模的人工智能/机器学习用例。尽管我们会发现在这个领域进行的学术研究，但我们不会经常在主流媒体中听到关于人工智能/机器学习的讨论，而成功的商业或工业应用主要只由世界上一些最大的、行业领先的技术或细分市场公司实现。再向前推进两年，我们发现到2017年底，科技行业正充斥着关于人工智能/机器学习的讨论，这似乎是每个人心中——至少是主要话题之一。
- en: Based on our time-traveling adventure, one would not be faulted for believing
    that AI/ML is a brand-new term that suddenly emerged only in the past few years.
    In reality, however, these concepts have been developing over many decades. As
    the next step in our time-traveling journey, we travel further back in time to
    the 1950s. The first use of the term *artificial intelligence* is credited to
    Professor John McCarthy in 1955 (McCarthy et al. 1955), and a number of other
    important developments that contributed significantly to this field of science
    took place during the 1950s, such as Alan Turing’s 1950 paper, *Computing Machinery
    and Intelligence*, in which he posed the question, “*Can machines think?*” (Turing,
    1950), and Frank Rosenblatt’s work on the “Perceptron” (Rosenblatt, 1957), which
    we’ll look at in more detail later in this book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的时间旅行冒险，人们可能会认为人工智能/机器学习是一个全新的术语，仅在过去的几年中突然出现。然而，实际上，这些概念已经发展了几十年。作为我们时间旅行之旅的下一步，我们进一步回到20世纪50年代。1955年，约翰·麦卡锡教授首次使用“人工智能”这个术语（麦卡锡等，1955年），在20世纪50年代还发生了一系列对这一科学领域有重大贡献的重要发展，例如艾伦·图灵1950年的论文《计算机与智能》，在其中他提出了问题，“*机器能思考吗？*”（图灵，1950），以及弗兰克·罗森布拉特对“感知器”的研究（罗森布拉特，1957），我们将在本书的后续部分更详细地探讨这一点。
- en: As an extension of our time-traveling journey, it should be noted that AI/ML
    algorithms today use mathematical concepts that were originally discovered and
    formulated centuries or millennia ago. For example, many of the algorithms we
    will explore in this book use concepts from linear algebra and calculus, which
    have been in use for centuries, and when we learn about cost functions, training,
    and evaluation, we will be using concepts from Euclidean geometry, such as the
    Pythagorean theorem, which dates back millennia. Interestingly, although Pythagoras
    is believed to have lived around 2,500 years ago, there is some evidence that
    concepts from the “Pythagorean theorem” were already understood and used by previous
    civilizations such as the Babylonians of Mesopotamia more than 1,000 years before
    his birth (Götze, 1945, 37-38). How fascinating it is that some of our most cutting-edge
    DL algorithms today use the same mathematical constructs that were used by ancient
    civilizations in the Bronze Age! In the 1960’s and 1970’s, the practice of using
    computers to perform statistical analysis and modeling on data began to grow significantly,
    and specialized software such as **Statistical Analysis System** (**SAS**) and
    **Statistical Package for the Social Sciences** (**SPSS**) emerged for these purposes.
    These tools were generally used for **in-memory** processing, meaning that all
    of the data used with these tools would be loaded into memory on a single computing
    machine. In the next section, you will see why it’s important to call this out.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们时间旅行旅程的延伸，应该注意的是，今天的人工智能/机器学习算法使用的是几个世纪或几千年前最初发现和制定的数学概念。例如，本书中将要探讨的许多算法都使用了线性代数和微积分的概念，这些概念已经使用了几个世纪，当我们学习关于成本函数、训练和评估时，我们将使用欧几里得几何的概念，例如勾股定理，其历史可以追溯到几千年以前。有趣的是，尽管人们认为毕达哥拉斯生活在约2500年前，但有一些证据表明，在毕达哥拉斯出生前1000多年，美索不达米亚的巴比伦人等之前的文明已经理解和使用了“勾股定理”的概念（Götze，1945，37-38）。多么令人着迷啊，我们今天一些最前沿的深度学习算法使用了与青铜时代古老文明相同的数学结构！在20世纪60年代和70年代，使用计算机对数据进行统计分析建模的做法开始显著增长，并出现了专门用于这些目的的软件，如**统计分析系统**（**SAS**）和**社会科学统计软件包**（**SPSS**）。这些工具通常用于**内存内**处理，这意味着使用这些工具的所有数据都将加载到单个计算机的内存中。在下一节中，你将看到为什么这一点很重要。
- en: 'Next, we travel forward in time, to the present day, and one of the questions
    that come to mind is this: If all of this started back in the 1950s, why does
    it seem that AI and ML are concepts that everybody has suddenly become enthusiastic
    about only in the past few years? Why did we not see such widespread adoption
    and success of AI/ML implementations before now? A number of factors have contributed
    to the gap in time that has been experienced between when these concepts originally
    began to be researched and when they finally started to gain publicly noticeable
    traction in the industry during the past few years (see the “AI Winter,” for example).
    As we will see in later chapters of this book, one such factor is that AI/ML use
    cases generally require large amounts of data and extensive computing resources.
    This is one of the reasons why—until recently—AI/ML research was usually being
    performed only by entities that could afford to amass these required resources,
    such as large technology companies, well-established research institutions, and
    government bodies.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们穿越到现代，心中浮现的一个问题是这样的：如果这一切始于20世纪50年代，为什么感觉上人工智能和机器学习是最近几年突然让每个人都热情高涨的概念？为什么在此之前我们没有看到人工智能/机器学习实施如此广泛的应用和成功？许多因素导致了这些概念最初开始研究时和它们在过去几年中在行业中开始获得公众明显关注之间的时间差距（例如，参见“人工智能寒冬”）。正如我们在本书的后续章节中将会看到的，其中一个因素是AI/ML用例通常需要大量的数据和广泛的计算资源。这也是为什么——直到最近——AI/ML研究通常只由能够负担得起积累这些所需资源的实体进行，例如大型科技公司、成熟的科研机构和政府部门。
- en: What has changed in recent years to help AI/ML break out beyond the exclusive
    realm of large corporations and research institutions? How have smaller companies,
    and even amateur hobbyists, suddenly obtained access to the resources required
    to train, host, and evaluate ML models and experiment with new ideas on how to
    apply AI/ML to an ever-increasing plethora of interesting new use cases? One of
    the primary contributors to this sudden revolution has been “cloud computing,”
    as well as iterative tooling development for building and running AI/ML workloads,
    and advances in DL approaches.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，是什么改变了，帮助AI/ML突破大型企业和研究机构的专属领域？小型公司，甚至业余爱好者，是如何突然获得训练、托管和评估ML模型以及实验如何将AI/ML应用于日益增多的有趣新用例所需资源的？这一突然革命的主要贡献者之一是“云计算”，以及构建和运行AI/ML工作负载的迭代工具开发，以及深度学习方法的进步。
- en: AI/ML and cloud computing
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI/ML和云计算
- en: To understand in more detail how cloud computing has helped to suddenly revolutionize
    AI/ML research and real-world application, let’s consider the types of resources
    that are required to train, host, evaluate, and manage ML models. While we could
    use a laptop or a home computer to train and evaluate a relatively simple model
    on a small dataset, as we want to scale out our research and use cases, we would
    quickly find that the computing resources on our personal computer would not be
    sufficient to train larger models and the hard drive(s) in our personal computer
    would not be large enough to store the required datasets. These were also the
    limitations experienced by the statistical modeling tools such as SAS and SPSS
    that we mentioned in the previous section, which processed data “in-memory” on
    a single machine.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更详细地了解云计算是如何突然革命化AI/ML研究和实际应用的，让我们考虑训练、托管、评估和管理ML模型所需的资源类型。虽然我们可以使用笔记本电脑或家用电脑在小型数据集上训练和评估一个相对简单的模型，但当我们想要扩展我们的研究和用例时，我们会很快发现我们个人电脑上的计算资源不足以训练更大的模型，而我们个人电脑的硬盘空间也不足以存储所需的数据集。这些也是我们在上一节中提到的统计建模工具（如SAS和SPSS）所遇到的限制，这些工具在单台机器上“内存中”处理数据。
- en: To illustrate this concept, we’re going to scale up our use cases in a series
    of steps. If we were to scale up only slightly beyond the resources of the most
    powerful personal computer on the market, we would need to run our workload on
    a hardware “server,” which contains more powerful computing resources, and we
    could attach multiple large-capacity hard drives to this server, potentially as
    a **Redundant Array of Independent Disks** (**RAID**) array (formerly **Redundant
    Array of Inexpensive Disks**). This is still something that an individual person
    could perform in their home, but powerful servers—especially the “latest and greatest”
    servers on the market—can be quite expensive to purchase, and it would require
    a bit more technical knowledge to set up the server and configure the RAID array.
    At this point, we are already extending outside the realm of all but the most
    dedicated amateur hobbyists.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个概念，我们将分步骤扩大我们的用例。如果我们仅仅稍微超出市场上最强大的个人电脑的资源，我们就需要在硬件“服务器”上运行我们的工作负载，这个服务器包含更强大的计算资源，并且我们可以将多个大容量硬盘连接到这个服务器上，可能是一个**独立磁盘冗余阵列**（**RAID**）数组（以前称为**廉价磁盘冗余阵列**）。这仍然是一个个人可以在家中完成的事情，但强大的服务器——尤其是市场上“最新和最优秀”的服务器——购买起来可能相当昂贵，并且设置服务器和配置RAID数组需要更多的技术知识。在这个阶段，我们已经开始超出除了最热衷的业余爱好者之外的所有领域。
- en: Scaling beyond the resources of the most powerful hardware server on the market
    would require us to create a cluster of servers. Apart from the additional expense
    of purchasing multiple servers and their attached disks, this would also require
    more advanced technical knowledge to build and configure a network that links
    the servers together appropriately. This would not be an economically viable approach
    for most hobbyists, but it may still make some sense for a small company.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 超出市场上最强大的硬件服务器的资源范围，将需要我们创建一个服务器集群。除了购买多个服务器及其连接的硬盘的额外费用外，这还需要更多的技术知识来构建和配置一个将服务器适当连接在一起的网络。这对大多数业余爱好者来说可能不是一个经济可行的方案，但对于小型公司来说可能仍然是有意义的。
- en: Next, let’s scale all the way up to some of today’s most advanced DL use cases,
    which can take weeks or months to train, on hundreds of high-powered and very
    expensive servers. If we wanted to run these kinds of workloads completely by
    ourselves, we would need to build a data center, hire teams of experts to install
    hundreds of servers, build and configure a complex network to link them all together
    appropriately, and perform multiple other supporting activities to get our infrastructure
    set up. Let’s imagine for a moment that we want to create a start-up company that
    will use DL to implement a new breakthrough idea that we’ve devised. Simply building
    the data center could take a couple of years and would cost many millions of dollars,
    before we could ever start experimenting with our idea. This would not be a viable
    option.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将范围扩展到今天一些最先进的深度学习（DL）用例，这些用例的训练可能需要数周或数月，并且需要在数百台高性能且非常昂贵的服务器上进行。如果我们想完全自行运行这些类型的工作负载，我们需要建立一个数据中心，雇佣专家团队来安装数百台服务器，构建和配置一个复杂的网络来将它们适当连接在一起，并执行多项其他支持活动以设置我们的基础设施。让我们暂时想象一下，我们想要创建一家初创公司，该公司将使用深度学习（DL）来实现我们设计的新突破性想法。仅仅建立一个数据中心就可能需要几年时间，并且可能花费数百万美元，在我们能够开始实验我们的想法之前。这显然不是一个可行的选择。
- en: With cloud computing, however, we could simply write a script or click some
    links and buttons on a cloud computing provider’s website, and it would spin up
    all of the servers we need within minutes. We could then perform our experiments
    — iteratively train and evaluate our models — and then simply shut down the servers
    when our work is done. As you can imagine, this is infinitely easier, cheaper,
    and more achievable than trying to build and manage our own data centers. This
    now provides small companies and limited-funding researchers or hobbyists with
    access to compute power and resources that were previously only available to very
    large organizations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，借助云计算，我们只需简单地编写一个脚本或在云计算提供商的网站上点击一些链接和按钮，就可以在几分钟内启动我们需要的所有服务器。然后我们可以进行实验——迭代训练和评估我们的模型——并在我们的工作完成后简单地关闭服务器。正如您所想象的那样，这比试图建立和管理我们自己的数据中心要容易、便宜得多，并且更容易实现。现在，这为小型公司和资金有限的研究人员或爱好者提供了访问计算能力和资源的途径，这些资源以前仅限于非常大型组织。
- en: Note that it was not only the ability to more easily create and access the required
    hardware infrastructure that helped revolutionize the AI/ML industry. Relevant
    software tools and frameworks have also been evolving over time, as well as the
    amount of data that has become available. While the tools such as SAS and SPSS
    that were developed in the 1960’s and 1970’s were sufficient for performing statistical
    modeling on datasets that could fit in memory on a single machine, the rapid growth
    in popularity of the Internet caused a dramatic increase in the amount of data
    that companies could gather and produce. In parallel, libraries were developed
    in languages such as Python, which made activities such as data processing, analysis,
    and modeling much easier. I can confidently say that it is a lot easier to perform
    many kinds of modeling use cases with libraries such as scikit-learn, PyTorch,
    and Keras, than it was with the earlier tools mentioned above. Still, many of
    today’s machine learning algorithms can be seen as an evolutions of traditional
    statistical modeling techniques, which have been enhanced to handle larger and
    more complex use cases. In addition to this, tools such as Apache Hadoop and Apache
    Spark, which I will discuss in more detail later in this book, made it possible
    to implement use cases that could span beyond the limits of a single machine,
    and therefore handle much larger datasets.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，不仅更容易创建和访问所需的硬件基础设施帮助革命化了人工智能/机器学习（AI/ML）行业，相关的软件工具和框架也在随着时间的推移而发展，以及可用数据的数量。虽然20世纪60年代和70年代开发的SAS和SPSS等工具足以在单个机器的内存中执行数据集的统计建模，但互联网的快速普及导致公司可以收集和产生的数据量急剧增加。与此并行，开发了Python等语言的库，这使得数据处理、分析和建模等活动变得更加容易。我可以自信地说，使用scikit-learn、PyTorch和Keras等库进行许多类型的建模用例，比使用上面提到的早期工具要容易得多。尽管如此，许多今天的机器学习算法可以被视为传统统计建模技术的演变，这些技术得到了增强，以处理更大和更复杂的用例。此外，Apache
    Hadoop和Apache Spark等工具（我将在本书的后面部分更详细地讨论），使得实现可以跨越单机限制的用例成为可能，因此可以处理更大的数据集。
- en: So far, in our discussion of scaling out our use cases, we have mainly focused
    on training and evaluating ML models, but those activities are only a subset of
    what’s required to create an ML application that is actually used in the real
    world. Throughout this book, we will often use the term *in production* to refer
    to the concept of creating, hosting, and serving AI/ML applications that are used
    in the real world, outside of a laboratory testing environment.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在我们的扩展用例讨论中，我们主要关注的是模型训练和评估，但这些活动只是创建实际用于现实世界的机器学习应用程序所需活动的一个子集。在本书中，我们将经常使用“在生产中”这个术语来指代创建、托管和提供在现实世界（实验室测试环境之外）使用的AI/ML应用程序的概念。
- en: Even large, well-established organizations with teams of experienced data scientists
    often find that successfully hosting an ML application in production can be more
    complex and challenging than the model training and evaluation process. Let’s
    now take a look at how cloud computing can provide additional value for addressing
    these challenges beyond simply spinning up the required compute and storage resources.
    In later chapters in this book, we will discuss all of the steps in a typical
    ML project in great detail, but for now, let’s consider at a high level what kinds
    of resources and infrastructure would be required to host an ML model in production
    if cloud computing did not exist.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是大型、成熟的组织，拥有经验丰富的数据科学家团队，也常常发现成功托管生产中的机器学习应用程序可能比模型训练和评估过程更复杂、更具挑战性。现在，让我们看看云计算如何能够提供额外的价值，以解决这些挑战，而不仅仅是启动所需的计算和存储资源。在本书的后续章节中，我们将详细讨论典型机器学习项目中的所有步骤，但在此，让我们从高层次上考虑，如果不存在云计算，托管生产中的机器学习模型需要哪些资源和基础设施。
- en: 'In addition to the activities required for model training and evaluation, such
    as constructing the data centers, installing the servers, building and configuring
    a complex network, and maintaining all of the hardware over time, we would need
    to perform many other activities to actually host and serve an ML model for production
    usage. For example, it would be necessary to create an interface to expose our
    model to end users or other systems. The most likely approach would be to use
    a web-based interface, in which case we would need to build a cluster of web servers
    and configure and manage those web servers on an ongoing basis. We would need
    to develop and build an application on those web servers to expose our model to
    web clients, and then install and configure load balancers and distribute load
    across our web servers. All of this infrastructure would, of course, need to be
    secured appropriately. *Figure 1**.2* shows an example of the kind of infrastructure
    you may need to set up; bear in mind that you may need to duplicate that infrastructure
    for each layer in your solution—for example, you would need to duplicate that
    infrastructure multiple times for your web server layer, your application server
    layer, and your model serving layer. The diagram shows two load balancers and
    routers for redundancy, in case one of those components fails:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型训练和评估所需的各项活动，例如构建数据中心、安装服务器、构建和配置复杂网络以及随着时间的推移维护所有硬件之外，我们还需要执行许多其他活动，以实际托管和为生产使用提供机器学习模型。例如，我们需要创建一个接口，以便将我们的模型暴露给最终用户或其他系统。最可能的方法是使用基于网络的界面，在这种情况下，我们需要构建一个由多个网络服务器组成的集群，并持续配置和管理这些服务器。我们需要在这些网络服务器上开发和构建一个应用程序，以便将我们的模型暴露给网络客户端，然后安装和配置负载均衡器，并在我们的网络服务器之间分配负载。当然，所有这些基础设施都需要得到适当的保护。*图1.2*展示了你可能需要设置的此类基础设施的示例；请记住，你可能需要为你的解决方案中的每一层复制该基础设施——例如，你可能需要多次复制该基础设施以用于你的网络服务器层、应用程序服务器层和模型托管层。图中显示了两个负载均衡器和路由器，以实现冗余，以防其中任何一个组件出现故障：
- en: '![Figure 1.2: Example infrastructure for model hosting](img/B18143_01_2.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2：模型托管示例基础设施](img/B18143_01_2.jpg)'
- en: 'Figure 1.2: Example infrastructure for model hosting'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：模型托管示例基础设施
- en: Unfortunately, most data scientists are not also networking experts, web server
    configuration experts, and security experts, so even if we had a team of the best
    data scientists who had created a breakthrough model, we would need many other
    teams of dedicated experts just to build and maintain the infrastructure required
    to expose that model to clients. On the other hand, if we wanted to use a service
    such as Vertex AI on Google Cloud, it would automatically build and manage all
    of this infrastructure for us, and we could go from laboratory testing to production
    hosting within minutes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，大多数数据科学家并不是同时还是网络专家、网络服务器配置专家和安全专家，所以即使我们有一支由最佳数据科学家组成的团队，他们已经创建了一个突破性的模型，我们仍然需要许多其他专门专家团队来构建和维护将这个模型向客户展示所需的基础设施。另一方面，如果我们想使用像谷歌云上的Vertex
    AI这样的服务，它将自动为我们构建和管理所有这些基础设施，我们可以在几分钟内从实验室测试过渡到生产托管。
- en: It’s important to note that without cloud computing, companies wouldn’t just
    find it less convenient to build their AI/ML workloads, but it would also be prohibitive
    – that is, large companies wouldn’t invest in building the required infrastructure
    unless they were sure their application was going to be successful in advance,
    which is a very difficult thing to forecast. Smaller companies wouldn’t be able
    to get started without significant up-front investments in infrastructure expenses,
    which most would not be able to obtain. As such, AI/ML research, experimentation,
    and eventual implementation in the real world would be far less prevalent and
    achievable without cloud computing.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，如果没有云计算，公司不仅会发现构建他们的AI/ML工作负载不太方便，而且这也会变得难以承受——也就是说，除非大公司事先确信他们的应用程序将会成功，否则他们不会投资建设所需的基础设施，而这是非常难以预测的。较小的公司如果没有在基础设施费用上进行重大前期投资，就无法开始，而大多数公司都无法获得这些资金。因此，没有云计算，人工智能/机器学习的研究、实验以及在现实世界中的最终实施将会远不如现在普遍和可行。
- en: Speaking of implementing AI/ML in the real world, let’s take a look at the different
    kinds of AI/ML approaches and some of their real-world use cases.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到在现实世界中实施人工智能/机器学习时，让我们来看看不同的人工智能/机器学习方法和它们的一些实际应用案例。
- en: ML approaches and use cases
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习方法和应用案例
- en: 'AI/ML applications are usually intended to make some kind of prediction based
    on input data, with perhaps the exception of Generative AI, because Generative
    AI is intended to generate content rather than simply making predictions. In order
    to make predictions, ML models first need to be **trained**, and how they are
    trained depends on the approach being used. While ML is a broad concept that encompasses
    many different fields of research, with endless new use cases being created almost
    every day, the industry generally groups ML approaches into three high-level categories:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能/机器学习应用程序通常旨在根据输入数据做出某种预测，也许除了生成式人工智能之外，因为生成式人工智能旨在生成内容，而不仅仅是做出预测。为了做出预测，机器学习模型首先需要被**训练**，而它们的训练方式取决于所采用的方法。虽然机器学习是一个广泛的概念，涵盖了众多不同的研究领域，并且几乎每天都有无数新的应用案例被创造出来，但该行业通常将机器学习方法分为三个高级类别：
- en: '**Supervised** **learning** (**SL**)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**（**SL**）'
- en: '**Unsupervised** **learning** (**UL**)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**（**UL**）'
- en: '**Reinforcement** **learning** (**RL**)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）'
- en: SL
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**监督学习**（**SL**）'
- en: SL is the most commonly used type of ML in the industry and perhaps the easiest
    to describe. The term *supervised* indicates that we are informing the ML model
    of the correct answers during the training process. For example, let’s imagine
    that we want to train a model to be able to identify photographs of cats. In this
    case, we would use thousands or millions of photographs in our training set, and
    we would tell the model which photographs contain cats and which ones do not.
    We do this via a process called **labeling**, which we will describe in more detail
    in later chapters. If trained correctly, our model would learn how to distinguish
    input features that identify a cat in each photograph. If we then presented new
    photographs that the model had never seen before (that is, that were not included
    in the training set), our model would be able to identify whether those photographs
    contained cats. More specifically, for each photograph, our model would be able
    to predict the probability that it contains a cat, based on observed features
    in the photograph.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是工业界最常用的机器学习类型，也许也是最容易描述的。术语“监督”表明我们在训练过程中向机器学习模型告知正确答案。例如，让我们想象我们想要训练一个模型能够识别猫的照片。在这种情况下，我们会使用数千或数百万张照片作为我们的训练集，并告诉模型哪些照片包含猫，哪些不包含。我们通过一个称为**标记**的过程来完成这项工作，我们将在后面的章节中更详细地描述它。如果训练得当，我们的模型将学会如何区分每张照片中识别猫的特征。如果我们向模型展示它以前从未见过的照片（即，那些没有包含在训练集中的照片），我们的模型将能够识别这些照片是否包含猫。更具体地说，对于每张照片，我们的模型将能够根据照片中的观察特征预测它包含猫的概率。
- en: 'There are two subcategories of SL: classification and regression.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习（SL）有两个子类别：分类和回归。
- en: Classification
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: 'Our cat-identification model described previously is an example of a classification
    use case in which our model can classify whether our photo contains a cat. Classification
    is further broken down into binary classification or multi-class classification.
    Binary classification provides a “yes” or “no” prediction. For example, in this
    case, we would ask the model, “Does this photograph contain a cat?”, and the model
    would respond with either “Yes” or “No.” If we were to train our model to identify
    many different types of objects, then it would be capable of performing multi-class
    classification, and we could ask a broader question such as, “What do you see
    in this photograph?”. In this case, the model could respond with multiple different
    object classifications, including “cat” (if it sees a cat in the photograph),
    among other objects that it predicts to exist in the photograph (see *Figure 1**.3*):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前描述的猫识别模型是一个分类用例的例子，其中我们的模型可以判断我们的照片是否包含猫。分类进一步细分为二分类或多分类。二分类提供“是”或“否”的预测。例如，在这种情况下，我们会问模型，“这张照片包含猫吗？”，而模型会回答“是”或“否”。如果我们训练我们的模型来识别许多不同类型的对象，那么它将能够执行多分类，我们可以提出更广泛的问题，例如，“你在这张照片中看到了什么？”在这种情况下，模型可以回答多个不同的对象分类，包括“猫”（如果它在照片中看到了猫），以及其他它预测存在于照片中的对象（参见*图1**.3*）：
- en: '![Figure 1.3: Classification of cat and flowers in a photograph](img/B18143_01_3.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3：照片中猫和花的分类](img/B18143_01_3.jpg)'
- en: 'Figure 1.3: Classification of cat and flowers in a photograph'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：照片中猫和花的分类
- en: Real-world applications of classification
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类在实际中的应用
- en: Of course, classification can be used for much more important use cases than
    identifying pictures of cats. An example of an important real-world classification
    use case is in medical diagnoses, whereby an ML model can predict the presence
    of a medical condition in a patient based on input data such as physical symptoms
    or a radiology image.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，分类可以用于比识别猫的图片更为重要的用例。一个重要的实际分类用例是医疗诊断，其中机器学习模型可以根据输入数据（如身体症状或放射学图像）预测患者是否存在某种医疗状况。
- en: Regression
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归
- en: While classification is useful when there are discrete answers to our questions,
    regression is used when we deal with “continuous variables,” whereby the answer
    to our question could be any value in a continuum, such as 0.1, 2.3, 9894.6, 105,
    or 0.00000487\. To introduce some terminology, the inputs that we provide to our
    model are referred to as “input variables,” and the variables that we wish to
    predict are referred to as “target variables” or “dependent variables.”
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的问题有离散答案时，分类是有用的，而当我们要处理“连续变量”时，则使用回归。在这种情况下，我们问题的答案可以是连续体中的任何值，例如0.1、2.3、9894.6、105或0.00000487。为了引入一些术语，我们提供给模型的输入被称为“输入变量”，而我们希望预测的变量被称为“目标变量”或“因变量”。
- en: Note
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When we use the term *regression* here, we are referring to linear regression.
    This is not to be confused with logistic regression, which is actually a type
    of classification that we will cover later in this book.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在这里使用术语 *回归* 时，我们指的是线性回归。这不要与逻辑回归混淆，逻辑回归实际上是一种分类，我们将在本书的后面部分介绍。
- en: 'The aim of linear regression is to define a linear function that maps input
    variables to an output target variable. For example, we may want to predict the
    grade a student will achieve on an exam based on the number of hours they spent
    studying, from data we have regarding previous students’ grades and how many hours
    they spent studying. We could graph the data as follows (see *Figure 1**.4*),
    where the stars represent each student in the dataset; that is, they represent
    each student’s grade and the number of hours they spent studying:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的目标是定义一个线性函数，将输入变量映射到输出目标变量。例如，我们可能想根据学生花费的学习时间预测他们在考试中能获得的分数，基于我们有关以前学生成绩和学习时间的数据。我们可以将数据绘制如下（参见
    *图1**.4*），其中星号代表数据集中的每个学生；也就是说，它们代表每个学生的成绩和他们花费的学习时间：
- en: '![Figure 1.4: Student grades and hours studying](img/B18143_01_4.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图1.4：学生成绩与学习时间](img/B18143_01_4.jpg)'
- en: 'Figure 1.4: Student grades and hours studying'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：学生成绩与学习时间
- en: As we can see in the diagram, there appears to be a relationship or correlation
    between the grades achieved and the number of hours spent studying; that is, students
    who studied for longer hours generally got higher grades.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，成绩与学习时间之间似乎存在某种关系或相关性；也就是说，学习时间较长的学生通常能获得更高的成绩。
- en: 'A linear regression model trained on this dataset would try to find the function
    or line that best represents that relationship. You may remember from school that
    a simple line function is often represented by the formula *y = ax + b*, where
    *a* is a multiple of *x*, and *b* is where the line intercepts the *y* axis. To
    find the most accurate function, the linear regression process tries to define
    a line that minimizes the distance between that line and each of the data points
    (stars), which may look something like *Figure 1**.5*. The distances between the
    line and some of the data points are shown in red for reference. In later sections,
    we’ll discuss in more detail how those distances are calculated:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集上训练的线性回归模型将试图找到最能代表这种关系的函数或直线。你可能还记得，从学校里学到的简单直线函数通常表示为公式 *y = ax + b*，其中
    *a* 是 *x* 的倍数，而 *b* 是直线与 *y* 轴的交点。为了找到最准确的功能，线性回归过程试图定义一条线，该线与每个数据点（星号）之间的距离最小化，这可能看起来像
    *图1**.5*。线与一些数据点之间的距离用红色表示以供参考。在后面的章节中，我们将更详细地讨论这些距离是如何计算的：
- en: '![Figure 1.5: Linear regression function](img/B18143_01_5.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图1.5：线性回归函数](img/B18143_01_5.jpg)'
- en: 'Figure 1.5: Linear regression function'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：线性回归函数
- en: 'With this function, we could now estimate or predict future student grades
    based on the number of hours they spend studying. For example, if a student spends
    10 hours studying, we would predict that they would achieve a grade of approximately
    70% based on what we see in *Figure 1**.6*:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个函数，我们现在可以根据学生花费的学习时间来估计或预测未来的学生成绩。例如，如果一个学生花费了10个小时学习，根据我们在 *图1**.6* 中看到的情况，我们会预测他们能获得大约70%的成绩：
- en: '![Figure 1.6: Applying linear regression function](img/B18143_01_6.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图1.6：应用线性回归函数](img/B18143_01_6.jpg)'
- en: 'Figure 1.6: Applying linear regression function'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：应用线性回归函数
- en: Real-world applications of linear regression
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 线性回归的实际应用
- en: Regression is one of the most widely used types of ML, and it is useful for
    many different business use cases. It’s the quintessential example of “predicting
    the future” that is often attributed to the power of ML. Business leaders often
    want to predict numbers that relate to the performance of their business, such
    as predicting sales for the next quarter, based on historical sales and other
    market data. Whenever you have numerical metrics that you can track, and sufficient
    historical features relating to those metrics, you can try to predict or “forecast”
    the future values of those metrics, from stock market prices and housing prices
    to blood pressure measurements in various medical scenarios.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是机器学习中最广泛使用的一种类型，它适用于许多不同的商业用例。它是“预测未来”的典范，通常归功于机器学习的力量。商业领导者通常希望预测与业务绩效相关的数字，例如根据历史销售和其他市场数据预测下一季度的销售额。每当你有可以追踪的数值指标，并且有足够的历史特征与这些指标相关联时，你就可以尝试预测或“预测”这些指标的未来的值，从股市价格和房价到各种医疗场景中的血压测量。
- en: UL
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UL
- en: With UL, we do not train the model on a dataset in which the entries are labeled
    with the correct answers. Instead, we ask the model to find unknown or non-predetermined
    patterns in the data. An analogy we could use here is that in SL, we are teaching
    the model about what exists in the data, whereas in UL, the model is teaching
    us about what exists in the data, such as underlying trends among various data
    points in our dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用UL时，我们不是在标注了正确答案的数据集上训练模型。相反，我们要求模型在数据中寻找未知或非预定的模式。我们可以用这样一个类比来说明：在SL中，我们是在教模型关于数据中存在什么，而在UL中，模型是在教我们关于数据中存在什么，比如数据集中各种数据点之间的潜在趋势。
- en: 'The most common type of UL is something known as “clustering,” whereby data
    points are grouped together based on some kinds of similarities that are observed
    by the model. *Figure 1**.7* provides a visual representation of this concept,
    showing the input data on the left and the resulting data clusters on the right:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的UL类型是所谓的“聚类”，其中数据点根据模型观察到的某些相似性被分组在一起。*图1.7*提供了这个概念的可视化表示，显示了左侧的输入数据和右侧的结果数据簇：
- en: '![Figure 1.7: Clustering](img/B18143_01_7.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图1.7：簇类](img/B18143_01_7.jpg)'
- en: 'Figure 1.7: Clustering'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：簇类
- en: Real-world applications of UL
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UL的现实世界应用
- en: An example of a real-world application of clustering would be for categorizing
    groups of customers with similar purchasing preferences. You may have noticed
    this being utilized when you are purchasing an item online and you see recommendations
    for other items that may interest you, accompanied by a message such as “people
    who purchased this item also purchased these other items.”
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 簇类算法在现实世界中的应用实例之一就是将具有相似购买偏好的客户群体进行分类。你可能已经注意到，当你在线购买商品时，会看到一些推荐其他可能感兴趣的商品，并伴随有诸如“购买此商品的用户也购买了这些其他商品”之类的信息。
- en: Another important real-world use case is fraud detection, in which case one
    of the clusters could represent legitimate transactions and another cluster could
    represent unusual or potentially fraudulent transactions, or anything that does
    not match the characteristics of legitimate transactions could be flagged as potentially
    fraudulent. As new transactions occur, the model could group them accordingly
    based on their input characteristics and could trigger a warning response if a
    transaction appears to be fraudulent. Have you ever received notifications or
    questions from your bank when you tried to use your credit card on the first day
    of vacation in a new location? That’s because the bank’s ML models determined
    that the characteristics of the transaction were abnormal in some way; in this
    case, it was a transaction from a location that is far from where you usually
    use your card.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的现实世界用例是欺诈检测，在这种情况下，一个簇可能代表合法交易，另一个簇可能代表异常或潜在的欺诈交易，或者任何不符合合法交易特征的东西都可能被标记为潜在的欺诈。随着新交易的进行，模型可以根据它们的输入特征相应地将它们分组，如果交易看起来是欺诈性的，则可能触发警告响应。你有没有在假期第一天在新地点使用信用卡时收到过银行的通知或询问？这是因为银行的机器学习模型确定交易的某些特征异常；在这种情况下，是来自你通常不使用信用卡的地方的交易。
- en: Note
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Clustering can actually be considered as a type of unsupervised classification.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 簇类实际上可以被视为一种无监督分类。
- en: RL
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RL
- en: 'In RL, the mechanism for training a model is quite different from the previous
    two approaches. To introduce some terminology, we say that the model uses an **agent**
    that has an overall goal it wants to achieve (the desired model output). The agent
    interacts with its **environment** by sending **actions** to the environment.
    The environment evaluates the actions and provides feedback in the form of a **reward**
    signal, which indicates whether or not the actions contribute to achieving the
    overall goal, and **observations**, which describe the current state of the environment.
    See *Figure 1**.8* for a visual representation of this process. To make a very
    broad analogy, this is similar to how we train some animals, such as dogs. For
    example, if the dog performs a desired action, then the trainer rewards it with
    a tasty treat. Conversely, if the dog does something undesirable, the trainer
    may reprimand it in some way. In the case of RL, the model randomly attempts different
    actions in its environment. If an action or set of actions is deemed to contribute
    to achieving the overall goal, then the environment provides a positive reward
    as feedback to the agent, whereas if the action is considered to be detrimental
    to achieving the overall goal, then the environment provides a negative reward
    as feedback to the agent. In this case, the reward is usually just a numeric value,
    such as 0.5 or -0.2, rather than a tasty treat, because unfortunately for ML models,
    they aren’t yet complex enough to enjoy tasty treats:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，训练模型的机制与之前两种方法截然不同。为了介绍一些术语，我们说模型使用一个**代理**，该代理有一个它想要实现的整体目标（即期望的模型输出）。代理通过向环境发送**动作**与它的**环境**进行交互。环境评估这些动作，并以**奖励**信号的形式提供反馈，该信号指示动作是否有助于实现整体目标，以及**观察**，它描述了环境的当前状态。参见
    *图 1*.*8* 对此过程的视觉表示。做一个非常广泛的类比，这类似于我们训练某些动物，例如狗。例如，如果狗执行了一个期望的动作，那么训练者会奖励它美味的食物。相反，如果狗做了某些不期望的事情，训练者可能会以某种方式责备它。在强化学习的情况下，模型在其环境中随机尝试不同的动作。如果一个动作或一系列动作被认为有助于实现整体目标，那么环境会向代理提供积极的奖励作为反馈，而如果动作被认为对实现整体目标有害，那么环境会向代理提供消极的奖励作为反馈。在这种情况下，奖励通常只是一个数值，例如
    0.5 或 -0.2，而不是美味的食物，因为不幸的是，对于机器学习模型来说，它们还不够复杂，无法享受美味的食物：
- en: '![Figure 1.8: RL](img/B18143_01_8.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8：强化学习](img/B18143_01_8.jpg)'
- en: 'Figure 1.8: RL'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8：强化学习
- en: The model’s environment is the space within which the goal and all possible
    actions exist, and the observations are features of the environment. This can
    be a physical environment, such as when a robot is moving around in a physical
    space, or something abstract, based on the problem that the model is trying to
    address. For example, you could create a model that becomes an expert in playing
    a game such as chess or a video game. The model will begin by trying all kinds
    of random actions, most of which may seem silly or bizarre at first, but based
    on feedback from the environment, the model’s actions will gradually become more
    relevant and may eventually outperform the actions of human experts in that task.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的环境是存在目标和所有可能动作的空间，观察是环境的特征。这可以是一个物理环境，例如当机器人在一个物理空间中移动时，或者基于模型试图解决的问题的某种抽象。例如，你可以创建一个模型，使其成为国际象棋或电子游戏等游戏的专家。模型将首先尝试所有种类的随机动作，其中大多数一开始可能看起来很愚蠢或奇怪，但基于环境的反馈，模型的动作将逐渐变得更加相关，并可能最终在该任务中超越人类专家的动作。
- en: RL could actually be considered a type of SL because feedback is provided to
    the model when it makes a prediction, and the model learns and makes improvements
    based on that feedback. However, it differs from the standard concept of SL, which
    we described previously, because we are not providing labeled correct answers
    as part of the training process. Instead, the model is provided with signals that
    help it understand what kinds of actions it should perform in order to progress
    toward achieving the required goal.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习实际上可以被认为是一种**监督学习**（SL），因为当模型做出预测时，会提供反馈给模型，模型根据这些反馈进行学习和改进。然而，它与之前描述的标准监督学习概念不同，因为我们没有在训练过程中提供标记的正确答案。相反，模型被提供了一些信号，帮助它理解它应该执行哪些类型的动作，以便朝着实现所需的目标前进。
- en: Real-world applications of RL
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习的实际应用
- en: RL is not yet as widely adopted in the industry as “traditional” SL and UL,
    but some interesting applications are emerging. In addition to the gaming use
    cases mentioned in a previous paragraph, one of the most recognizable applications
    of RL is in robotic navigation and self-driving cars. In this application, the
    car could be considered as the model agent, whereby it performs actions such as
    accelerating, braking, and steering the wheels. Sensors on the car, such as cameras
    and lidar sensors, provide observations on the state of the environment. If the
    actions performed by the car help it to achieve a goal such as navigating a course
    or self-parking without hitting any obstacles, then it would receive positive
    rewards, whereas if it collided with an obstacle, then it would receive a negative
    reward. Over time, it could learn to navigate the course or self-park and avoid
    obstacles.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）在工业界的应用还没有像“传统”的监督学习（SL）和无监督学习（UL）那样广泛，但一些有趣的应用正在出现。除了前一段提到的游戏用例之外，强化学习最显著的应用之一是在机器人导航和自动驾驶汽车中。在这个应用中，汽车可以被看作是模型代理，它执行诸如加速、制动和转向车轮等动作。汽车上的传感器，如摄像头和激光雷达传感器，提供关于环境状态的信息。如果汽车执行的动作帮助它实现目标，例如导航路线或自动泊车而不撞到任何障碍物，那么它会收到正面的奖励；而如果它撞到障碍物，则会收到负面的奖励。随着时间的推移，它可能学会导航路线或自动泊车并避开障碍物。
- en: Another important real-world application of RL is in healthcare, where it has
    shown promising results for use cases such as medical imaging diagnoses (Zhou
    et al., 2021, 1-39) and determining what kinds of medical treatments work for
    individual patients based on their conditions, via mechanisms such as **dynamic
    treatment** **regimes** (**DTRs**).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习在医疗保健领域的另一个重要实际应用是，它在医疗影像诊断（周等，2021，1-39）以及根据患者状况确定哪些类型的医疗治疗对他们有效等方面显示出有希望的结果，这些是通过诸如**动态治疗方案**（DTRs）等机制实现的。
- en: Now that we’ve discussed the different types of ML approaches and examples of
    their real-world use cases, let’s take a look at some of the underlying concepts
    that form the basis for how these ML implementations work.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了不同类型的机器学习方法和它们的实际应用案例，让我们来看看构成这些机器学习实现基础的一些基本概念。
- en: A brief discussion of ML basic concepts
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习基本概念的简要讨论
- en: Mathematics is the hidden magic behind ML, and pretty much all ML algorithms
    function by using mathematics to find relationships and patterns in data. This
    book focuses on practical implementations of AI/ML on Google Cloud; it is not
    a theoretical academic course, so we will not go into a lot of detail on the mathematical
    equations upon which ML models operate, but we will include mathematical formulae
    for reference where relevant throughout the book, and here we present some basic
    concepts that are widely used in AI/ML algorithms. There are plenty of academic
    materials available for learning each of these concepts in more detail. As an
    architect, understanding the mathematical concepts could be considered an extracurricular
    credit rather than a requirement; you usually would not need to dive into the
    mathematical details of ML algorithms in your day-to-day work, but if you want
    to have a better understanding of how some of the algorithms work, you can review
    these concepts in more detail.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数学是机器学习（ML）背后的隐藏魔法，几乎所有机器学习算法都是通过使用数学来在数据中找到关系和模式来工作的。本书侧重于在谷歌云上实现人工智能/机器学习的实际应用；它不是理论学术课程，因此我们不会深入探讨机器学习模型所依赖的数学方程式，但我们会根据需要包含数学公式作为参考，并在本书中介绍一些在人工智能/机器学习算法中广泛使用的基本概念。关于这些概念的详细学习，有大量的学术材料可供参考。作为一个架构师，理解数学概念可以被视为课外学分而不是必需品；你通常不需要深入研究机器学习算法的数学细节来完成日常工作，但如果你想更好地理解某些算法的工作原理，你可以更详细地审查这些概念。
- en: Linear algebra
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性代数
- en: 'In ML, we make frequent use of vectors and matrices to store and represent
    information. To briefly cover some definitions, *Collins Dictionary* defines a
    vector as “*a variable quantity, such as force, that has size and direction*”
    and a matrix as “*an arrangement of numbers, symbols, or letters in rows and columns
    which is used in solving mathematical problems.*” Let’s take a look at what this
    really means. Representing information in matrices is most easily demonstrated
    if we use tabular data as an example. Consider the information in *Table 1.1*,
    which represents house sales in King County, Washington (excerpted from a Kaggle
    dataset: [https://www.kaggle.com/datasets/harlfoxem/housesalesprediction](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction)):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）中，我们经常使用向量和矩阵来存储和表示信息。为了简要介绍一些定义，*柯林斯词典*将向量定义为“*具有大小和方向的变量量，例如力*”，将矩阵定义为“*一种用于解决数学问题的数字、符号或字母的行列排列*”。让我们看看这究竟意味着什么。如果我们使用表格数据作为例子，矩阵中信息的表示就最容易演示了。考虑*表1.1*中的信息，它代表了华盛顿州金县的销售房屋（摘自Kaggle数据集：[https://www.kaggle.com/datasets/harlfoxem/housesalesprediction](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction))：
- en: '![Table 1.1: King County house sales](img/B18143_01_9.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![表1.1：金县房屋销售](img/B18143_01_9.jpg)'
- en: 'Table 1.1: King County house sales'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1：金县房屋销售
- en: 'The dataset depicted in *Table 1.1* has 7 rows (not including the title row)
    and 13 columns, where each row represents a single house sale, which we consider
    a data point or an observation in our dataset, and each column represents individual
    features of the data points. We can consider each row and each column to be vectors.
    Bear in mind that a vector can also be considered as a matrix with one row or
    one column (that is, a one-dimensional vector). So, for each individual house
    purchase in our dataset, we have a vector that contains each of the features of
    that house. Let’s imagine that we want to predict the price of houses based on
    the features (other than the price) of each house. We would want to find the function
    that best describes the relationship between the price and all of the other features,
    and linear regression is one way in which we could do this. In this case, we would
    want to find the set of values by which we should multiply each feature and then
    add all of the results of those multiplications together in order to correctly
    estimate the price of each house. This means that each feature would have a corresponding
    multiplier (or “coefficient”). In order to efficiently compute the multiplications
    of the features and the coefficients and then add all of the results together,
    we could represent all of the coefficients also as a vector and calculate the
    dot product of the feature vector and the coefficient vector. We’ll take a minute
    here to clarify what it means to calculate the dot product. If we have two vectors,
    *A* and *B*, where *A = [a b c]*, and *B = [d e f]*, the dot product is calculated
    as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*表1.1*中所示的数据集有7行（不包括标题行）和13列，其中每一行代表一个单独的房屋销售，我们将其视为数据集中的数据点或观察值，每一列代表数据点的单个特征。我们可以将每一行和每一列视为向量。请注意，向量也可以被视为只有一行或一列的矩阵（即一维向量）。因此，对于数据集中每个单独的房屋购买，我们都有一个包含该房屋所有特征的向量。让我们想象一下，如果我们想根据每栋房屋的特征（除了价格）来预测房价。我们希望找到描述价格与其他所有特征之间关系的最佳函数，线性回归就是实现这一目标的一种方法。在这种情况下，我们希望找到一组值，通过这些值乘以每个特征，然后将所有乘法的结果相加，以正确估计每栋房屋的价格。这意味着每个特征都有一个相应的乘数（或“系数”）。为了有效地计算特征和系数的乘积并将所有结果相加，我们可以将所有系数也表示为一个向量，并计算特征向量和系数向量的点积。我们在这里花一点时间来澄清计算点积的含义。如果我们有两个向量*A*和*B*，其中*A*
    = [a b c]*，*B* = [d e f]*，点积的计算如下：'
- en: '*a*d + b*e +* *c*f*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*a*d + b*e + c*f*'
- en: 'To illustrate, let’s take the first row of *Table 1.1* (without the price)
    as a feature vector; it would look like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，让我们以*表1.1*的第一行（不包括价格）作为特征向量；它看起来是这样的：
- en: '[PRE0]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let’s create an initial vector of random coefficients (we can just create
    random coefficients at first and improve our guesses later during the model training
    process), which needs to have the same number of elements as our preceding feature
    vector:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个初始的随机系数向量（我们最初可以创建随机系数，然后在模型训练过程中改进我们的猜测），它需要与前面的特征向量具有相同数量的元素：
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When calculating the dot product, there are rules regarding the shapes of each
    vector, but we are omitting those details here for simplicity. We will go deeper
    into those details in later chapters.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算点积时，有一些关于每个向量形状的规则，但为了简单起见，我们在这里省略了这些细节。我们将在后面的章节中深入探讨这些细节。
- en: 'The dot product of our feature vector and coefficient vector is shown here:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的特征向量和系数向量的点积在此处显示：
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'From our first guess at what the coefficients should be, we estimate that the
    price of the house in *row 1* of *Table 1.1* would be $996.663\. However, we can
    see in *Table 1.1* that the actual price of that house was $221,900\. We can now
    calculate the error resulting from our guess as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们对系数应该是什么的第一个猜测开始，我们估计*表1.1*中第1行的房价将是$996.663。然而，我们可以从*表1.1*中看到，那所房子的实际价格是$221,900。现在我们可以计算由于我们的猜测而产生的误差，如下所示：
- en: '[PRE3]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We often refer to this as the **loss** or the **cost** of our linear function,
    and it is similar to what was represented by the red lines in *Figure 1**.5* earlier,
    where this value represents the “distance” from the correct answer; that is, how
    far away our guess is from the correct answer. This is the first step in the learning
    process, and in later sections, we will want to find coefficients that minimize
    this error.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将这称为线性函数的**损失**或**成本**，它类似于之前*图1.5*中用红色线条表示的内容，其中这个值代表“距离”正确答案；也就是说，我们的猜测与正确答案有多远。这是学习过程的第一步，在后面的章节中，我们将希望找到使这个误差最小化的系数。
- en: Calculus
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微积分
- en: 'One common use of calculus in ML is in the error minimization process mentioned
    previously. In later chapters, we will define something called a **loss function**
    (or a **cost function**), and we will use mechanisms such as “Gradient descent”
    (described later) to minimize that loss function. In that case, we will use calculus
    to derive the slope at various points on the curve that represents the loss function,
    and we will use that information to work toward minimizing the cost function (see
    *Figure 1**.9*):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 微积分在机器学习中的一个常见用途是之前提到的误差最小化过程。在后面的章节中，我们将定义一个称为**损失函数**（或**成本函数**）的概念，我们将使用“梯度下降”（稍后描述）等机制来最小化该损失函数。在这种情况下，我们将使用微积分推导出表示损失函数的曲线上的各个点的斜率，并利用这些信息来努力最小化成本函数（参见*图1.9*）：
- en: '![Figure 1.9: The slope at a point on a function curve (source: https://commons.wikimedia.org/wiki/File:Parabola_tangent.png)](img/B18143_01_10.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图1.9：函数曲线上某点的斜率（来源：https://commons.wikimedia.org/wiki/File:Parabola_tangent.png）](img/B18143_01_10.jpg)'
- en: 'Figure 1.9: The slope at a point on a function curve (source: https://commons.wikimedia.org/wiki/File:Parabola_tangent.png)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9：函数曲线上某点的斜率（来源：https://commons.wikimedia.org/wiki/File:Parabola_tangent.png）
- en: Statistics and probability
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计与概率
- en: ML models don’t provide answers as definite facts. Instead, the results from
    an ML model are often provided as approximations, probabilities, or inferences.
    We most commonly call the results from an ML model invocation an **inference**.
    Referencing our cat classification model from earlier in this chapter, a model
    that we would use to identify cats in a photograph would usually respond to us
    with the “probability” of a cat existing in the photograph. For example, the model
    may tell us that it is 97.3% sure that it sees a cat in the photograph. One of
    the main goals of ML is to ensure that these probabilities are as accurate as
    possible. A model would not be effective if it says it’s 100% sure it sees a cat,
    but there is actually no cat in the photograph. In the case of binary classification,
    where the response is either true or false, there would generally be a threshold
    above which we consider the probability response to be true or below which we
    would consider it to be false. For example, we could determine that anything above
    72.3% probability is deemed to be positive, and anything below that threshold
    is negative. The threshold value would vary based on the use case and is one of
    the parameters that need to be determined when building such models.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型不提供确定的答案。相反，机器学习模型的结果通常以近似值、概率或推断的形式提供。我们通常将机器学习模型调用的结果称为 **推断**。以本章前面提到的猫分类模型为例，我们用来识别照片中猫的模型通常会告诉我们照片中存在猫的概率。例如，模型可能会告诉我们它有
    97.3% 的把握认为照片中有一只猫。机器学习的主要目标之一是确保这些概率尽可能准确。如果模型说它有 100% 的把握看到猫，但实际上照片中没有猫，那么这个模型将不会有效。在二元分类的情况下，响应要么为真要么为假，通常会有一个阈值，高于该阈值我们认为概率响应为真，低于该阈值我们认为为假。例如，我们可以确定任何超过
    72.3% 概率的都被认为是正面的，而低于该阈值的被认为是负面的。阈值值会根据用例而变化，并且在构建此类模型时需要确定的一个参数。
- en: If we break the process down a bit further, in the case of the cat classification
    model, it has observed some features in the photograph, and based on previous
    training in which it has seen those kinds of features (or features similar to
    those), it estimates the probability of a cat being present in the photograph.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个过程进一步分解，以猫分类模型为例，它已经观察到了照片中的某些特征，并且基于之前训练中它看到的那些类型的特征（或与那些特征相似的特征），它估计照片中存在猫的概率。
- en: 'We will also see later in this book that statistical analysis plays an important
    role in the early stages of an ML project when data scientists are exploring how
    datasets can be used to address a business problem. In such data exploration activities,
    data scientists usually analyze the statistical distributions of values for each
    of the variables or features in the dataset. For example, when exploring a dataset,
    data scientists often want to see statistical information regarding each of the
    numeric variables in the data, such as the mean, median, mode, and the minimum
    and maximum range in the values; see *Figure 1**.10*, in which the statistical
    distributions of some features from our house sales dataset are shown:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续内容中，我们还将看到，统计分析在机器学习项目的早期阶段起着重要作用，当时数据科学家正在探索如何使用数据集来解决业务问题。在这些数据探索活动中，数据科学家通常会分析数据集中每个变量或特征的值统计分布。例如，在探索数据集时，数据科学家通常会想查看有关数据中每个数值变量的统计信息，例如均值、中位数、众数以及值的最大和最小范围；参见
    *图 1**.10*，其中展示了我们的房屋销售数据集中一些特征的统计分布：
- en: '![Figure 1.10: Statistical distributions of dataset features](img/B18143_01_11.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10：数据集特征的统计分布](img/B18143_01_11.jpg)'
- en: 'Figure 1.10: Statistical distributions of dataset features'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10：数据集特征的统计分布
- en: Metrics
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标
- en: Note
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We also introduce the term *data science* here. While data science is a broad
    scientific field, for the purposes of this book, we use the term *data science*
    to incorporate all of the steps required to create an ML model, including all
    data preparation and processing steps.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还引入了术语 *数据科学*。虽然数据科学是一个广泛的科学领域，但为了本书的目的，我们使用术语 *数据科学* 来涵盖创建机器学习模型所需的所有步骤，包括所有数据准备和处理步骤。
- en: Data science and ML are fields in which we constantly strive for improvement,
    whether it’s to improve the accuracy of our models, how quickly they train and
    perform, or how much compute power they use. There’s a well-known saying, “*What
    isn’t measured cannot be improved*” (this is actually an approximation of slightly
    different observations from Peter Drucker and Lord Kelvin), and this saying holds
    a lot of truth; in order to improve something in a methodical way, you need to
    be able to measure some attribute of that thing. For this reason, metrics are
    an essential component of any ML project, and selecting the correct metric to
    monitor can have a critical impact on the success of an ML implementation.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和机器学习是我们在模型准确性、训练和执行速度，以及计算能力使用上不断追求改进的领域。有一句众所周知的话，“*未衡量的无法改进*”（这实际上是彼得·德鲁克和开尔文勋爵不同观察的近似），这句话蕴含着很多真理；为了有系统地改进某事物，你需要能够衡量该事物的某些属性。因此，度量标准是任何机器学习项目的必要组成部分，选择正确的度量标准进行监控可以对机器学习实施的成败产生重大影响。
- en: Apart from operational metrics, such as measuring the latency of responses from
    your ML models, there are also various metrics for measuring how accurate an ML
    model’s inferences are.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 除了操作指标，例如测量你的机器学习模型响应的延迟，还有各种用于衡量机器学习模型推断准确性的指标。
- en: For example, in linear regression, it’s common to measure the **Mean Absolute
    Error** (**MAE**), **Mean Squared Error** (**MSE**), or **Root Mean Squared Error**
    (**RMSE**), while for classification use-cases, we often use metrics such as Accuracy
    and Precision. We will explore all of these metrics, and many others, in later
    chapters.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在线性回归中，通常测量**平均绝对误差**（**MAE**）、**均方误差**（**MSE**）或**均方根误差**（**RMSE**），而对于分类用例，我们通常使用准确率和精确度等指标。我们将在后面的章节中探讨所有这些指标以及许多其他指标。
- en: Having discussed some of the underlying theory and mathematical concepts that
    are used in ML, let’s bring the discussion back to the real world again, and let’s
    take a look at what kinds of challenges exist for companies when they try to implement
    ML workloads.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了机器学习中使用的某些基本理论和数学概念之后，让我们再次将讨论带回现实世界，并看看公司在尝试实施机器学习工作负载时存在哪些挑战。
- en: Common challenges in developing ML applications
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发机器学习应用中的常见挑战
- en: Companies typically run into common kinds of challenges when they embark on
    an AI/ML development journey, and it is often a key requirement of an architect’s
    role to understand common challenges in a given problem space. As an architect,
    if you are not aware of challenges and how to address them, it’s unlikely that
    you will design an appropriate solution. In this section, we introduce the most
    frequently encountered challenges and pitfalls at a high level, and in later sections
    of this book, we discuss ways to address or alleviate some of these hurdles of
    AI/ML development.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当公司开始AI/ML开发之旅时，通常会遇到常见的挑战类型，而理解特定问题空间中的常见挑战通常是架构师角色的关键要求。作为一名架构师，如果你不了解挑战以及如何解决它们，那么你不太可能设计出合适的解决方案。在本节中，我们将从高层次介绍最常遇到的一些挑战和陷阱，并在本书的后续章节中讨论解决或减轻这些AI/ML发展障碍的方法。
- en: Gathering, processing, and labeling data
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集、处理和标注数据
- en: Data is the key ingredient in ML because, in general, ML models cannot function
    without data. There’s an often-quoted adage that data scientists spend up to 80%
    of their time working on finding, cleaning, and processing data before they can
    begin to make use of it for analytical or data science purposes. This is an important
    concept to understand; that is, data scientists are not tasked simply with finding
    relevant data, although that is, in itself, often a difficult task; they also
    need to convert that data to a state that can be used efficiently by ML algorithms.
    Not only may data be unusable for many kinds of ML models in its raw format, but
    a data scientist may also need to combine data from many different sources, each
    with different formats and different problems that need to be addressed in the
    raw data before it can be used by an ML model. Also, the available data may not
    be sufficient to make the kinds of predictions that we’d like to get from an ML
    model, and data scientists often need to invent ways to generate new data by cleverly
    using what’s available from their existing data sources. We will cover this in
    more detail when we discuss a practice known as “feature engineering” later in
    this book.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是机器学习的关键成分，因为通常情况下，机器学习模型没有数据就无法运行。有一个经常引用的谚语说，数据科学家在开始使用数据进行分析或数据科学目的之前，可能要花费高达80%的时间来寻找、清理和处理数据。这是一个重要的概念，也就是说，数据科学家不仅要找到相关的数据，尽管这本身就是一个困难的任务；他们还需要将数据转换成可以被机器学习算法高效使用的状态。数据在原始格式下可能对许多类型的机器学习模型来说无法使用，数据科学家可能还需要将来自许多不同来源的数据结合起来，每个来源都有不同的格式和不同的问题需要解决，才能使原始数据被机器学习模型使用。此外，可用的数据可能不足以做出我们希望从机器学习模型中获得的那种预测，数据科学家通常需要通过巧妙地使用现有数据源中的数据来发明生成新数据的方法。我们将在本书后面讨论一个称为“特征工程”的实践时更详细地介绍这一点。
- en: Data quality impact on model performance
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据质量对模型性能的影响
- en: The effectiveness of a data scientist in performing the aforementioned tasks
    can have drastic impacts on how well or poorly the resulting ML models function
    because the data that is fed into ML models usually has a direct influence on
    the model’s output accuracy. Bear in mind that for some business applications,
    a tiny difference in the ML model’s accuracy can result in a difference of millions
    of dollars in revenue for business owners. Another well-known expression that
    describes this process well is “garbage in, garbage out.” The concept is quite
    simple; if the data you feed into the model doesn’t accurately represent what
    you’re trying to predict, the model will not be able to make accurate predictions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在执行上述任务时的有效性可以对最终生成的机器学习模型的表现产生极大的影响，因为输入到机器学习模型中的数据通常会对模型的输出准确性产生直接影响。请记住，对于某些商业应用来说，机器学习模型准确性的微小差异可能会导致企业主收入差异数百万美元。另一个很好地描述这一过程的常见表达是“垃圾输入，垃圾输出”。这个概念相当简单；如果你输入到模型中的数据不能准确代表你试图预测的内容，那么模型将无法做出准确的预测。
- en: It’s not just a model’s outputs that are affected by the quality or contents
    of the data. Large ML models can be expensive and time-consuming to train, and
    inadequately prepared data can increase the time and expense required to train
    a model. As an architect or data scientist, these factors play a fundamental role
    in how we design our workloads because an architect’s purpose is not just to design
    solutions that address technical challenges, but often what will be equally or
    even more important will be the cost of implementing the solution. If we designed
    a solution that would be too expensive to implement, then the project may not
    get approval to proceed, or the company may lose money by implementing the solution.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅模型的输出会受到数据质量或内容的影响。大型机器学习模型训练起来可能既昂贵又耗时，而准备不足的数据可能会增加模型训练所需的时间和费用。作为一个架构师或数据科学家，这些因素在我们设计工作负载时起着根本的作用，因为架构师的目的不仅仅是设计解决技术挑战的方案，而且通常实施解决方案的成本同样甚至可能更为重要。如果我们设计了一个实施起来过于昂贵的解决方案，那么项目可能无法获得继续进行的批准，或者公司可能会因为实施该解决方案而亏损。
- en: Bias and fairness
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 偏差与公平性
- en: Another important concept that we will cover in more detail in this book is
    the concept of bias and fairness. The goal and challenge in this regard is to
    ensure that the data we use to train and evaluate ML models represents a fair
    distribution of all relevant classes for our dataset. For example, if our model
    will make predictions that will affect people’s lives, such as approving a loan
    or a credit card application, we need to ensure that the dataset used to train
    the model fairly represents all relevant demographic groups and does not become
    inadvertently biased in relation to any particular demographic groups.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中我们将更详细地探讨的另一个重要概念是偏差和公平性的概念。在这方面，我们的目标和挑战是确保我们用于训练和评估机器学习模型的训练数据代表了所有相关类别的公平分布。例如，如果我们的模型将做出影响人们生活的预测，例如批准贷款或信用卡申请，我们需要确保用于训练模型的训练数据公平地代表了所有相关的社会群体，并且不会无意中偏向任何特定的社会群体。
- en: Data labeling
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据标注
- en: 'In addition to the challenges described previously, another substantial challenge
    exists specifically for **supervised ML** (**SML**) applications. As we discussed
    earlier in this chapter, SML models learn from labels in the data that provide
    the “correct” answer for each data entry. See *Figure 1**.11* for an example,
    in which the dataset contains labels describing whether or not students passed
    their exams, in addition to other details regarding those exams, such as the grade
    received and the number of hours spent studying. However, usually, these datasets
    and the related labels need to be generated or created somehow, and considering
    that some datasets may contain millions of data points, it can be difficult, time-consuming,
    and error-prone to label all of the data accurately:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '除了之前描述的挑战之外，对于**监督机器学习**（**SML**）应用还存在另一个具体的重大挑战。正如我们在本章前面讨论的那样，SML模型从数据中的标签中学习，这些标签为每个数据条目提供了“正确”的答案。参见*图1.11*的示例，其中数据集包含描述学生是否通过考试的标签，以及有关这些考试的其它细节，例如获得的分数和花费的学习时间。然而，通常，这些数据集和相关标签需要以某种方式生成或创建，考虑到某些数据集可能包含数百万个数据点，准确标注所有数据可能很困难、耗时且容易出错： '
- en: '![Figure 1.11: Example of labels (highlighted in green) in a dataset](img/B18143_01_12.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图1.11：数据集中标签（绿色突出显示）的示例](img/B18143_01_12.jpg)'
- en: 'Figure 1.11: Example of labels (highlighted in green) in a dataset'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11：数据集中标签（绿色突出显示）的示例
- en: Data governance and regulatory compliance
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据治理和合规性
- en: It’s important to control how data is being stored and processed within your
    company and who has access to the data. Special care must be taken with regard
    to sensitive data — for example, data that contains customers’ personal details
    such as their address, date of birth, or credit card number. There are specific
    regulations that need to be upheld in this regard, such as the **California Consumer
    Privacy Act** (**CCPA**), the **Children’s Online Privacy Protection Act** (**COPPA**),
    the **General Data Protection Regulation** (**GDPR**), and the **Health Insurance
    Portability and Accountability Act** (**HIPAA**), which outline detailed rules
    on how specific types of data must be handled. For companies that operate on an
    international scale, abiding by all of the varying regulations in different countries
    can be quite complicated. When data scientists are gathering, storing, exploring,
    processing, and labeling data, they need to keep these security requirements in
    mind, and as an AI/ML solutions architect, you will need to ensure that the data
    storage and processing infrastructure facilitates adhering to these regulations
    and other important information security practices. We will cover each of Google
    Cloud’s relevant data storage and processing infrastructure options in this book
    and provide additional guidance on data governance concepts where appropriate.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 控制数据在公司内部存储和处理的方式以及谁有权访问数据非常重要。在敏感数据方面必须格外小心——例如，包含客户个人详细信息的数据，如他们的地址、出生日期或信用卡号码。在这方面有一些具体的法规需要遵守，例如**加利福尼亚消费者隐私法案**（**CCPA**）、**儿童在线隐私保护法案**（**COPPA**）、**通用数据保护条例**（**GDPR**）和**健康保险可携带性和问责法案**（**HIPAA**），这些法规详细说明了特定类型的数据必须如何处理。对于在国际上运营的公司来说，遵守不同国家的所有不同法规可能相当复杂。当数据科学家收集、存储、探索、处理和标记数据时，他们需要牢记这些安全要求，并且作为人工智能/机器学习解决方案架构师，你需要确保数据存储和处理基础设施能够促进遵守这些法规和其他重要的信息安全实践。本书将涵盖Google
    Cloud的相关数据存储和处理基础设施选项，并在适当的地方提供关于数据治理概念的其他指导。
- en: Data and model lineage
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据和模型血缘关系
- en: Data science contains the word “science” for a reason. As with most scientific
    fields, it involves iterative experimentation. When data scientists create new
    models, they usually go through a complex process in which they need to experiment
    with different datasets, different transformations on the datasets, different
    algorithms and parameters, and other supporting activities and resources. A team
    of data scientists could try hundreds of different combinations of steps before
    they create the desired model, and each of those steps has inputs and outputs.
    If a data scientist has a breakthrough discovery and creates a killer new model,
    and then they leave the company or something happens to them, we would not be
    able to recreate their work unless they kept detailed notes of all of the steps
    they took to create that model, including all input and output artifacts that
    were used and created by each step.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学包含“科学”这个词是有原因的。与大多数科学领域一样，它涉及迭代实验。当数据科学家创建新的模型时，他们通常需要经历一个复杂的过程，在这个过程中，他们需要尝试不同的数据集、数据集上的不同转换、不同的算法和参数，以及其他支持活动和资源。一个数据科学团队在创建所需的模型之前可能需要尝试数百种不同的步骤组合，并且每个步骤都有输入和输出。如果一个数据科学家有突破性的发现并创建了一个杀手级的新模型，然后他们离开公司或发生了一些事情，除非他们详细记录了创建该模型所采取的所有步骤，包括每个步骤使用和创建的所有输入和输出工件，否则我们无法重新创建他们的工作。
- en: This is also important during the experimentation process, in which data scientists
    may want to collaborate with other scientists on their team or on other teams.
    If a data scientist gets some promising results from an experiment, they could
    share the details with their peers, who could validate the results or build on
    top of them by combining the outputs of other experiments they had performed.
    This kind of collaboration is fundamental to many kinds of scientific research
    and is often required for significant progress to occur.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，这同样很重要，数据科学家可能希望与团队中的其他科学家或其他团队中的科学家合作。如果一个数据科学家从实验中获得了一些有希望的结果，他们可以与同事分享这些细节，同事可以验证这些结果或通过结合他们进行的其他实验的输出在它们之上构建。这种合作对于许多类型的科学研究是基本的，并且对于取得重大进展通常是必需的。
- en: Data and model lineage refers to this process of tracking all of the steps and
    their associated inputs and outputs that were required to create a model. It’s
    not only important for collaboration and progress but also for governance purposes
    and fairness in AI/ML development; it’s also important to understand how a model
    was created and which data artifacts, algorithms, and parameters were used along
    the way.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和模型血缘关系指的是跟踪创建模型所需的所有步骤及其相关的输入和输出这一过程。这不仅对协作和进步很重要，而且对治理目的和人工智能/机器学习发展的公平性也很重要；了解模型是如何创建的，以及沿途使用了哪些数据工件、算法和参数也很重要。
- en: As companies begin to perform AI/ML research, they often do not have robust
    lineage tracking mechanisms in place, and collaboration at scale can be hampered
    as a result. Even worse, companies sometimes find themselves using models for
    which nobody has a good understanding of how they work or how they were created.
    This is not a good position to be in if you want to update those models or they
    need to be audited for compliance reasons. Later in this book, we’ll see how Google
    Cloud’s Vertex AI platform can help to ensure that data and model lineage are
    being tracked appropriately.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 随着公司开始进行人工智能/机器学习研究，它们往往没有建立稳健的血缘跟踪机制，因此大规模的协作可能会受到影响。更糟糕的是，公司有时发现自己使用的是没有人真正了解其工作原理或创建方式的模型。如果你想要更新这些模型或需要审计以符合规定，这并不是一个好的位置。在本书的后面部分，我们将看到Google
    Cloud的Vertex AI平台如何帮助确保数据模型血缘关系得到适当的跟踪。
- en: Organizational challenges
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织挑战
- en: Most large companies have evolved over time and generally consist of multiple
    organizations that are loosely connected to each other. As large companies begin
    to experiment with AI/ML, research often takes place organically in each organization
    without coordination between the different parts of the company. When this happens,
    knowledge and data are often not shared adequately — or at all — across the company,
    and this leads to the formation of silos within each organization, which in turn
    create obstacles that impede the company’s overall success regarding AI/ML solution
    development. As an AI/ML solutions architect, you will need to advise company
    leadership on how to structure their organizations and their corporate policies
    to make their AI/ML journey as successful as possible.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数大型公司随着时间的推移而发展，通常由多个相互松散连接的组织组成。当大型公司开始尝试人工智能/机器学习时，研究通常在每个组织内部自发进行，而公司不同部分之间没有协调。当这种情况发生时，知识和数据往往在公司内部没有得到充分共享——或者根本就没有共享——这导致每个组织内部形成孤岛，进而为公司的整体成功在人工智能/机器学习解决方案开发方面设置障碍。作为一名人工智能/机器学习解决方案架构师，你需要向公司领导建议如何构建他们的组织和公司政策，以使他们的人工智能/机器学习之旅尽可能成功。
- en: Let’s imagine that we own a large company, and a data science team in one organization
    — let’s call it “Organization A” — in our company has spent the past year gathering,
    cleaning, and experimenting with a large dataset, and they finally had some success
    in training an ML model that is providing promising results. Let’s also imagine
    that — similar to most companies — the organizations that make up our business
    operate mainly independently of each other, with little communication between
    them unless it is required as part of regular business operations. Now, another
    organization in our company, named “Organization B,” starts exploring AI/ML, and
    they have a similar use case to Organization A. Because the organizations operate
    independently and do not regularly communicate with each other, Organization B
    will start from scratch and will spend the next year wasting their time doing
    work that has already been completed elsewhere in the company.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设想我们拥有一家大型公司，公司内部的一个组织——让我们称它为“组织A”——在过去的一年里一直在收集、清洗和实验一个大型数据集，他们最终在训练一个提供有希望结果的机器学习模型上取得了一些成功。让我们再设想一下——类似于大多数公司——构成我们业务的其他组织主要相互独立运作，除非作为常规业务运营的一部分，否则它们之间很少有沟通。现在，我们公司中的另一个组织，名为“组织B”，开始探索人工智能/机器学习，并且他们有与组织A相似的使用案例。由于组织独立运作并且不经常相互沟通，组织B将从头开始，将在接下来的一年里浪费时间做已经在公司其他地方完成的工作。
- en: Now, let’s imagine that our company consists of 20 large organizations, each
    with hundreds of product development teams. Consider how much time would be wasted
    if even just 20% of those product development teams started creating AI/ML workloads
    without communicating with each other. It may be hard to believe, but this is
    how most large companies operate when they begin to experiment with AI/ML.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设我们的公司由20个大型组织组成，每个组织都有数百个产品开发团队。考虑一下，如果其中只有20%的产品开发团队在没有相互沟通的情况下开始创建AI/ML工作负载，将会浪费多少时间。这可能很难相信，但这就是大多数大型公司在开始尝试AI/ML时是如何运作的。
- en: 'There are mainly four different types of silos that form in the scenarios described
    previously, and they are related to the following four topics:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前描述的场景中，主要存在四种不同类型的孤岛，它们与以下四个主题相关：
- en: Knowledge
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识
- en: Data
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据
- en: AI/ML models
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI/ML模型
- en: Tooling and development
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具和开发
- en: Knowledge silos
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识孤岛
- en: 'This one is pretty straightforward: if organizations are not sharing knowledge
    effectively with each other, teams all across the company will waste time trying
    to solve similar problems from scratch again and again.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点相当直接：如果组织之间没有有效地共享知识，公司各个团队将浪费时间一次又一次地从头开始解决类似的问题。
- en: Data silos
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据孤岛
- en: 'We’ve already talked about the importance and difficulty of getting access
    to data; especially getting access to clean, processed data that is ready to be
    used for training ML models. In most companies, each organization (and, possibly,
    each team) will build its own datasets. If a team in Organization B wanted to
    get access to a dataset that was built by Organization A, they would first need
    to learn of the existence of that dataset (which requires some knowledge sharing
    to occur). Then, they would need to request access to the data, which can often
    go through months of escalations through upper management just to get the required
    approvals. Next, a multi-month project would need to be carried out in order to
    actually set up the integration between the Organization A and Organization B
    systems. In an industry where AI/ML use cases and opportunities are evolving so
    quickly, these are the kinds of obstacles and processes that kill a company’s
    ability to rapidly innovate in this space. *Figure 1**.12* shows an example of
    data silos in a company. You will soon learn about ways to effectively and securely
    share datasets between organizations in order to break down data silos:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了获取数据的重要性及其难度；特别是获取干净、处理过的数据，这些数据已准备好用于训练ML模型。在大多数公司中，每个组织（以及可能每个团队）都会构建自己的数据集。如果组织B中的团队想要获取由组织A构建的数据集，他们首先需要了解该数据集的存在（这需要一些知识共享的发生）。然后，他们需要请求访问数据，这通常需要通过上级管理层的数月升级才能获得所需的批准。接下来，需要执行一个多个月的项目，以便实际上在组织A和组织B的系统之间建立集成。在一个AI/ML用例和机会发展如此迅速的行业中，这些都是阻碍公司在这个领域快速创新的障碍和流程。*图1.12*展示了公司中数据孤岛的例子。你将很快了解在组织之间有效和安全地共享数据集的方法，以打破数据孤岛：
- en: '![Figure 1.12: An example of data silos](img/B18143_01_13.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图1.12：数据孤岛的例子](img/B18143_01_13.jpg)'
- en: 'Figure 1.12: An example of data silos'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12：数据孤岛的例子
- en: Model silos
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型孤岛
- en: This is an extension of the knowledge and data silo concepts. Just as with knowledge
    and datasets, some kinds of models can be reused once they’ve been developed.
    If a team in Organization A has created a useful model, and that model could be
    reused by other teams in the company, then we should ensure that such sharing
    is enabled not only by our corporate structure, culture, and policies but also
    by our AI/ML development infrastructure. To understand this in more detail, you
    will learn how to share models, what kinds of requirements that entails, and how
    our AI/ML development tools and infrastructure can help or hinder this process.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对知识和数据孤岛概念的扩展。正如知识和数据集一样，一旦开发出来，某些类型的模型就可以被重复使用。如果一个团队在组织A中创建了一个有用的模型，并且该模型可以被公司中的其他团队重复使用，那么我们应该确保这种共享不仅通过我们的企业结构、文化和政策，而且通过我们的AI/ML开发基础设施来实现。为了更详细地了解这一点，你将学习如何共享模型，这需要哪些类型的需求，以及我们的AI/ML开发工具和基础设施如何帮助或阻碍这一过程。
- en: Tooling and development silos
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工具和开发孤岛
- en: In large companies, various development teams may use different tools and methodologies
    to build their AI/ML workloads. The selection of those tools and methodologies
    is often based on arbitrary factors such as what kinds of tools the employees
    used at previous companies. Employees in each organization or team will install
    their chosen tools on their machines and start developing in an ad hoc manner.
    For example, Employee A in the Organization B organization will install and use
    a tool named `scikit-learn` for their development and will use MySQL databases
    to store their application data, while Employee B in the Organization B organization
    will install and use PyTorch for their development and will use Oracle databases
    to store their application data. Next, Employee A may leave the company, and a
    new employee, Employee C, will be hired, and they will prefer using TensorFlow
    and some other type of database. This “wild west” approach makes it very difficult
    for employees and teams to collaborate and share artifacts at scale across the
    company.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型公司中，不同的开发团队可能会使用不同的工具和方法来构建他们的AI/ML工作负载。这些工具和方法的选择通常基于一些任意因素，例如员工在之前公司使用过哪些工具。每个组织或团队中的员工都会在自己的机器上安装他们选择的工具，并以一种临时的方式开始开发。例如，B组织中的员工A将安装并使用名为`scikit-learn`的工具进行开发，并使用MySQL数据库存储他们的应用程序数据，而B组织中的员工B将安装并使用PyTorch进行开发，并使用Oracle数据库存储他们的应用程序数据。接下来，如果员工A离开公司，新员工C将被雇佣，他们可能会更倾向于使用TensorFlow和某些其他类型的数据库。这种“野性西部”的方法使得员工和团队在公司范围内进行协作和共享工件变得非常困难。
- en: In later chapters, we will go into detail on how to prevent, fix, and design
    around these pitfalls, but for now, it’s critical to highlight the importance
    of standardization. As companies begin to build their data science strategies,
    they should standardize as much as possible. Standardize the toolsets that will
    be used for AI/ML development and the types of data systems and formats that will
    be used. Establish company practices that encourage knowledge sharing and simplify
    data and model sharing across teams and organizations in a secure manner. Without
    these strategies, it will be difficult to collaborate and innovate rapidly at
    scale. One caveat is that you will need to find the balance between standardization
    and flexibility. Lack of standardization leads to the problems mentioned previously,
    but if your standardization strategy is too rigid, it could hinder your developers’
    productivity. For example, it would be too rigid to force all of your developers
    to use only one type of database and only one specific programming language or
    framework. Different tools are best suited to different use cases, and your company
    should provide guidelines to your employees on what tools are recommended for
    which use cases.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将详细介绍如何防止、修复和设计这些陷阱，但到目前为止，强调标准化的重要性是至关重要的。随着公司开始构建他们的数据科学战略，他们应该尽可能地标准化。标准化用于AI/ML开发的工具集以及将使用的数据系统和格式类型。建立公司实践，鼓励知识共享，并以安全的方式简化团队和组织之间的数据和模型共享。没有这些策略，将难以快速进行大规模的协作和创新。一个注意事项是，您需要在标准化和灵活性之间找到平衡。缺乏标准化会导致之前提到的问题，但如果您的标准化策略过于僵化，可能会阻碍开发者的生产力。例如，强迫所有开发者只使用一种类型的数据库和一种特定的编程语言或框架将会过于僵化。不同的工具最适合不同的用例，您的公司应该为员工提供指南，说明哪些工具适用于哪些用例。
- en: Operationalization and ongoing management of AI/ML models
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI/ML模型的实施和持续管理
- en: By now, it’s hopefully pretty clear that AI/ML model development can be complicated
    and challenging. However, even when you’ve successfully created a model that makes
    useful predictions, your work is still not done. Companies often find it difficult
    to bring a model out into the real world even though it has been working well
    in the lab. We already covered some of the infrastructural and logistical activities
    that need to be performed in order to host a model, but what introduces additional
    complexity is that most models need to evolve over time, because the environment
    in which they operate will almost inevitably evolve and change over time. This
    is similar to regular software development, in which we need to update our applications
    in order to provide new functionality or to react to changes in how our customers
    are using our products.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，希望已经很清楚，AI/ML模型开发可能很复杂且具有挑战性。然而，即使你已经成功创建了一个能够做出有用预测的模型，你的工作仍未完成。公司往往发现，即使模型在实验室中表现良好，也很难将其带入现实世界。我们已经讨论了一些需要执行的基础设施和后勤活动，以便托管模型，但增加复杂性的是，大多数模型需要随着时间的推移而演变，因为它们运行的
    环境几乎不可避免地会随着时间的推移而演变和变化。这与常规软件开发类似，我们需要更新我们的应用程序以提供新功能或对我们的客户如何使用我们的产品做出反应。
- en: Another important factor is knowing when we may need to update our models. When
    our models are running in the real world, we need to monitor them on an ongoing
    basis in order to determine whether they continue to adequately meet the business
    needs they were created to address.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要因素是了解何时我们需要更新我们的模型。当我们的模型在现实世界中运行时，我们需要持续监控它们，以确定它们是否继续满足它们被创建来解决的业务需求。
- en: In this book, you’ll learn about the unique requirements for monitoring and
    updating AI/ML models and how traditional software DevOps mechanisms are not sufficient
    by themselves for these purposes, but how we can build upon those mechanisms to
    suit the needs of AI/ML workloads.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，你将了解监控和更新AI/ML模型的独特要求，以及传统的软件DevOps机制本身不足以满足这些目的，但我们如何在此基础上构建机制以适应AI/ML工作负载的需求。
- en: Edge cases
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘情况
- en: The term *edge cases* is being used as a pun with a double meaning here. In
    traditional software development, edge cases are abnormal or extreme use cases
    that can cause anomalous behavior. However, in this case, we also refer to the
    concept of edge computing, which is a sub-field of cloud computing that focuses
    on providing compute resources as close as possible to customers with low-latency
    requirements (see *Figure 1**.13*). We refer to the locations of these compute
    resources as “edge locations” because they exist outside the core cloud computing
    infrastructure locations, and they generally have limited resources in comparison
    to core cloud computing infrastructure locations.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“边缘情况”一词被用作双关语，具有双重含义。在传统的软件开发中，边缘情况是可能导致异常行为的异常或极端用例。然而，在这种情况下，我们还指的是边缘计算的概念，这是云计算的一个子领域，它专注于为具有低延迟要求的客户尽可能提供计算资源（见*图1*.13）。我们将这些计算资源的位置称为“边缘位置”，因为它们存在于核心云计算基础设施位置之外，并且与核心云计算基础设施位置相比，它们通常资源有限。
- en: ML models often require powerful compute resources in order to function, and
    this can present challenges for edge computing use cases due to limited resources
    at edge locations.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型通常需要强大的计算资源才能运行，而这可能给边缘计算用例带来挑战，因为边缘位置的资源有限。
- en: However, some ML models need to operate at or close to the “edge.” For example,
    consider a self-driving car, which needs to perform actions to navigate in its
    environment. Before and after each action, it needs to consult an ML model to
    determine the best next actions to perform. In this case, it cannot use a model
    that is hosted in a far-away data center because it cannot wait for an API request
    to travel over the internet to a server in the cloud, and then wait for the server
    to provide a response before it decides what to do next. Instead, it needs to
    make decisions and react to its environment within milliseconds. This is a clear
    use case for edge computing.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一些ML模型需要在或接近“边缘”处运行。例如，考虑一辆自动驾驶汽车，它需要在其环境中执行操作以导航。在每个动作之前和之后，它需要咨询ML模型以确定下一步的最佳操作。在这种情况下，它不能使用托管在遥远数据中心中的模型，因为它不能等待API请求通过互联网到达云中的服务器，然后再等待服务器提供响应，然后它才能决定下一步做什么。相反，它需要在毫秒内做出决定并对环境做出反应。这是一个边缘计算的明确用例。
- en: 'In later chapters, we explore some of the requirements and solutions for these
    scenarios and how to address them for AI/ML workloads:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续章节中，我们将探讨这些场景的一些需求和解决方案以及如何应对人工智能/机器学习工作负载：
- en: '![Figure 1.13: Edge computing](img/B18143_01_14.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13：边缘计算](img/B18143_01_14.jpg)'
- en: 'Figure 1.13: Edge computing'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：边缘计算
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced basic terminology related to AI/ML and some background
    information on how AI/ML has developed over time. We also explored different AI/ML
    approaches that exist today and some of their applications in the real world.
    Finally, and perhaps most importantly, we summarized common challenges and pitfalls
    that companies typically run into when they begin to implement AI/ML workloads.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了与人工智能/机器学习相关的基本术语以及人工智能/机器学习随时间发展的一些背景信息。我们还探讨了目前存在的不同人工智能/机器学习方法和它们在现实世界中的应用。最后，也许是最重要的，我们总结了公司在开始实施人工智能/机器学习工作负载时通常会遇到的常见挑战和陷阱。
- en: In the coming chapters, we will dive deeper into the model development process.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将更深入地探讨模型开发过程。
