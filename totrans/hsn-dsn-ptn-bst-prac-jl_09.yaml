- en: Performance Patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能模式
- en: This chapter includes patterns related to improving system performance. High
    performance is a major requirement in scientific computing, artificial intelligence,
    machine learning, and big data processing. Why is that?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括与提高系统性能相关的模式。高性能是科学计算、人工智能、机器学习和大数据处理的主要要求。为什么是这样？
- en: In the past decade, data has grown almost exponentially thanks to the scalability
    from the cloud. Think about the **Internet of Things** (**IoT**). Sensors are
    all around us—home security systems, personal assistants, and even room temperature
    controls are collecting tons of data continuously. Furthermore, the data being
    collected is stored and analyzed by companies that want to build smarter products.
    Use cases such as these demand more computing power and speed.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，由于云的可扩展性，数据几乎呈指数级增长。想想看**物联网**（**IoT**）。传感器无处不在——家庭安全系统、个人助理，甚至是室温控制都在持续收集大量数据。此外，收集到的数据被希望构建更智能产品的公司存储和分析。这样的用例需要更多的计算能力和速度。
- en: I once debated with a colleague about the use of cloud technologies for solving
    computationally intensive problems. Computing resources are definitely available
    in the cloud, but they are not free. It is therefore quite important that computer
    programs are designed to be more efficient and optimized to avoid unnecessary
    costs in the cloud.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经与一位同事就使用云计算技术来解决计算密集型问题进行了辩论。云计算中确实有计算资源，但它们不是免费的。因此，设计计算机程序以更加高效和优化，以避免在云中产生不必要的成本，这一点非常重要。
- en: Fortunately, the Julia programming language allows us to easily utilize CPU
    resources to the fullest extent. The way to make things fast is not difficult
    as long as some rules are followed. The online Julia reference manual already
    contains some tips. This chapter provides further patterns that are used extensively
    by veteran Julia developers to increase performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Julia编程语言允许我们轻松地充分利用CPU资源。只要遵循一些规则，让事情变得快速并不困难。在线的Julia参考手册已经包含了一些技巧。本章提供了由经验丰富的Julia开发者广泛使用的进一步模式，以提升性能。
- en: 'We will go over the following design patterns:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨以下设计模式：
- en: Global constant
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局常量
- en: Struct of arrays
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数组结构
- en: Shared arrays
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享数组
- en: Memoization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存
- en: Barrier function
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 障碍函数
- en: Let's get started!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The sample source code is located at [https://github.com/PacktPublishing/Hands-on-Design-Patterns-and-Best-Practices-with-Julia/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-on-Design-Patterns-and-Best-Practices-with-Julia/tree/master/Chapter06).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 示例源代码位于[https://github.com/PacktPublishing/Hands-on-Design-Patterns-and-Best-Practices-with-Julia/tree/master/Chapter06](https://github.com/PacktPublishing/Hands-on-Design-Patterns-and-Best-Practices-with-Julia/tree/master/Chapter06)。
- en: The code is tested in a Julia 1.3.0 environment.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 代码在Julia 1.3.0环境中进行了测试。
- en: The global constant pattern
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局常量模式
- en: Global variables are generally considered evil. I'm not kidding—they are evil.
    If you don't believe me, just google it. There are many reasons why they are bad,
    but in Julia land, they can also be a contributor to poor application performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 全局变量通常被认为是有害的。我不是在开玩笑——它们确实是有害的。如果你不相信我，只需在谷歌上搜索一下。它们之所以不好，有很多原因，但在Julia语言中，它们也可能成为应用性能不佳的诱因。
- en: Why do we want to use global variables? In the Julia language, variables are
    either in the global or local scope. For example, all variable assignments at
    the top level of a module are considered global. Variables that appear inside
    functions are local. Consider an application that connects to an external system—a
    handle object is typically created upon connection. Such handle objects can be
    kept in a global variable because all functions in the module can access the variable
    without having to pass it around as a function argument. That's the convenience
    factor. Also, this handler object only needs to be created once, and then it can
    be used at any time for subsequent actions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要使用全局变量？在Julia语言中，变量要么在全局作用域，要么在局部作用域。例如，模块顶层所有的变量赋值都被认为是全局的。出现在函数内部的变量是局部的。考虑一个连接外部系统的应用程序——在连接时通常会创建一个句柄对象。这样的句柄对象可以保存在全局变量中，因为模块中的所有函数都可以访问这个变量，而无需将其作为函数参数传递。这就是便利性因素。此外，这个句柄对象只需要创建一次，然后可以在后续操作中随时使用。
- en: Unfortunately, global variables also come with a cost. It may not be obvious
    at first, but it does hurt performance—indeed, quite badly, in some cases. In
    this section, we will discuss how bad global variables hurt performance and how
    the problem can be remedied by using global constants.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，全局变量也伴随着成本。一开始可能不明显，但它确实会影响性能——在某些情况下，影响相当严重。在本节中，我们将讨论全局变量如何影响性能，以及如何通过使用全局常量来解决这个问题。
- en: Benchmarking performance with global variables
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用全局变量进行性能基准测试
- en: 'Sometimes, it is convenient to use global variables because they are accessible
    from anywhere in the code. However, application performance may suffer when using
    global variables. Let''s figure out together how badly performance is affected.
    Here is a very simple function that just adds two numbers together:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，使用全局变量很方便，因为它们可以从代码的任何地方访问。然而，当使用全局变量时，应用程序的性能可能会受到影响。让我们一起找出性能受到了多么严重的影响。这是一个非常简单的函数，它只是将两个数字相加：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To benchmark this code, we will use the great `BenchmarkTools.jl` package,
    which can repeatedly run the code many times and report back some performance
    statistics. Let''s get started:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了基准测试这段代码，我们将使用伟大的`BenchmarkTools.jl`包，它可以多次运行代码并报告一些性能统计数据。让我们开始吧：
- en: '![](img/b6c8821c-a510-40bd-a34c-c358e06a8750.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6c8821c-a510-40bd-a34c-c358e06a8750.png)'
- en: 'It seems a little slow for just adding two numbers. Let''s get rid of the global
    variable and just add the numbers using two function arguments. We can define
    the new function as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于仅仅加两个数字来说，这似乎有点慢。让我们去掉全局变量，只使用两个函数参数来加这些数字。我们可以定义新的函数如下：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s benchmark this new function:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来基准测试这个新函数：
- en: '![](img/d5f2a094-899d-4de8-bfe5-5c627677127f.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5f2a094-899d-4de8-bfe5-5c627677127f.png)'
- en: That's *unbelievable*! Taking away the reference to the global variable sped
    up the function by almost 900 times. To understand where the performance hit came
    from, we can use the built-in introspection tool from Julia to see the generated
    LLVM code.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是太令人难以置信了！移除对全局变量的引用使函数的速度提高了近900倍。为了了解性能下降的原因，我们可以使用Julia的内置内省工具来查看生成的LLVM代码。
- en: 'Here''s the generated code for the faster one. It is clean and contains just
    a single `add` instruction:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是更快版本的生成代码。它很干净，只包含一个`add`指令：
- en: '![](img/6cb895c9-a4f4-4efc-83e3-792ae74f2b6a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6cb895c9-a4f4-4efc-83e3-792ae74f2b6a.png)'
- en: 'On the other hand, the function that uses global variable generated this ugly
    code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用全局变量的函数生成了以下丑陋的代码：
- en: '![](img/b94445a0-33b5-423a-bc2e-6b004dc86363.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b94445a0-33b5-423a-bc2e-6b004dc86363.png)'
- en: Why is that? Shouldn't the compiler be smarter? The answer is that the compiler
    cannot really assume that the global variable is always an integer. Because it
    is a variable, which means it can be changed at any time, the compiler must generate
    code that can handle any data type, to stay on the safe side. Well, such additional
    flexibility introduces a huge overhead in this case.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会这样？编译器不应该更聪明吗？答案是编译器实际上无法假设全局变量总是整数。因为它是一个变量，这意味着它可以随时更改，编译器必须生成能够处理任何数据类型的代码，以确保安全。好吧，这种额外的灵活性在这种情况下引入了巨大的开销。
- en: Enjoying the speed of global constants
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 享受全局常量的速度
- en: 'To improve performance, let''s create a global constant by using the `const`
    keyword. Then, we can define a new function that accesses the constant, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高性能，让我们使用`const`关键字创建一个全局常量。然后，我们可以定义一个新的函数来访问这个常量，如下所示：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s benchmark its performance now:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在基准测试它的性能：
- en: '![](img/88b2394b-71ec-4415-a994-b86a09e4a250.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/88b2394b-71ec-4415-a994-b86a09e4a250.png)'
- en: '*This is perfect!* If we introspect the function again, we get the following
    clean code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*这是完美的!* 如果我们再次内省这个函数，我们得到以下整洁的代码：'
- en: '![](img/2ca377d5-b17a-4d31-a112-55f4a111e85a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ca377d5-b17a-4d31-a112-55f4a111e85a.png)'
- en: Next, we will discuss how to use a global variable (not a constant) and still
    make it slightly better.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论如何使用全局变量（不是常量）并使其稍微好一些。
- en: Annotating variables with type information
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用类型信息注释变量
- en: It is best when we can just use global constants. But what if the variable *does*
    need to be changed during the life cycle of the application? For example, maybe
    it is a global counter that keeps track of the number of visitors on a website.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们只需使用全局常量时，这是最好的。但如果变量在应用程序的生命周期中确实需要更改呢？例如，它可能是一个全局计数器，用于跟踪网站上的访问者数量。
- en: 'At first, we may be tempted to do the following, but we quickly realized that
    Julia does not support annotating global variables with type information:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我们可能会想这样做，但很快我们就意识到Julia不支持用类型信息注释全局变量：
- en: '![](img/4f7fa24e-cffe-4e4c-96be-43c4b440c536.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4f7fa24e-cffe-4e4c-96be-43c4b440c536.png)'
- en: 'Instead, what we can do is to annotate the variable type within the function
    itself, as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以做的是在函数内部注释变量类型，如下所示：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s see how it performs:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它的性能如何：
- en: '![](img/4a157480-d95c-4fcb-b082-0efe16f5dc3f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4a157480-d95c-4fcb-b082-0efe16f5dc3f.png)'
- en: That's quite a speed boost compared to the untyped version of 31 ns! However,
    it is still far away from the global constant solution.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与未类型化的31纳秒版本相比，这已经是一个相当大的速度提升了！然而，它仍然远远落后于全局常量解决方案。
- en: Understanding why constants help performance
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解常数如何帮助性能
- en: 'The compiler has a lot more freedom when dealing with constants because of
    the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于以下原因，编译器在处理常数时拥有更多的自由度：
- en: The value does not change.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值不会改变。
- en: The type of the constant does not change.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常数的类型不会改变。
- en: This will become clear after we look into some simple examples.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看一些简单的例子之后，这会变得清楚。
- en: 'Let''s take a look at the following function:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下函数：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we just follow the logic, then it is not difficult to see that it always
    returns a value of 10\. Let''s just unroll it quickly here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只遵循逻辑，那么不难看出它总是返回值为`10`。让我们快速展开它：
- en: The `a` variable has a value of 6.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a`变量有一个值为`6`。'
- en: The `b` variable has a value of `a + 1`, which is 7.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b`变量有一个值为`a + 1`，即`7`。'
- en: Because the `b` variable is greater than 1, it returns 10.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为`b`变量大于`1`，它返回`10`。
- en: From the compiler's perspective, the `a` variable can be inferred as a constant
    because it is assigned but never changed, and likewise for the `b` variable.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从编译器的角度来看，`a`变量可以被推断为常数，因为它被赋值但从未改变，同样对于`b`变量也是如此。
- en: 'We can take a look at the code generated by Julia for this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看看Julia为这个生成的代码：
- en: '![](img/c30489a9-dd5f-4b5d-bf3d-4f3332042207.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c30489a9-dd5f-4b5d-bf3d-4f3332042207.png)'
- en: The Julia compiler goes through several stages. In this case, we can use the `@code_typed` macro,
    which shows the code that has been generated where all type information has been
    resolved.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Julia编译器会经过几个阶段。在这种情况下，我们可以使用`@code_typed`宏，它显示了所有类型信息都已解决的生成的代码。
- en: '*Voila!* The compiler has figured it all out and just returns a value of `10`
    for this function.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*哇!* 编译器已经全部弄明白了，并只为这个函数返回了一个值为`10`。'
- en: 'We realize that a couple of things have happened here:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们意识到这里发生了一些事情：
- en: When the compiler saw the multiplication of two constant values (`2 * 3`), it
    computed the final value of `6` for `a`. This process is called **constant folding**.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当编译器看到两个常数值的乘法（`2 * 3`）时，它计算了`a`的最终值为`6`。这个过程被称为**常数折叠**。
- en: When the compiler inferred `a` as a value of `6`, it calculated `b` as a value
    of `7`. This process is called **constant propagation**.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当编译器推断出`a`的值为`6`时，它计算出`b`的值为`7`。这个过程被称为**常数传播**。
- en: When the compiler inferred `b` as a value of `7`, it pruned away the `else`-branch
    from the `if-then-else` operation. This process is called **dead code elimination**.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当编译器推断出`b`的值为`7`时，它从`if-then-else`操作中剪除了`else`分支。这个过程被称为**死代码消除**。
- en: Julia's compiler optimization is truly state of the art. These are just some
    of the examples that we can get a performance boost automatically without having
    to refactor a lot of code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Julia的编译器优化真正是处于一流水平。这些只是我们可以自动获得性能提升的一些例子，而无需重构大量代码。
- en: Passing global variables as function arguments
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将全局变量作为函数参数传递
- en: There is another way to tackle the problem of global variables. In a performance-sensitive
    function, rather than accessing the global variable directly, we can pass the
    global variable into the function as an argument.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决全局变量问题的方法是，在一个性能敏感的函数中，而不是直接访问全局变量，我们可以将全局变量作为参数传递给函数。
- en: 'Let''s refactor the code earlier in this section by adding a second argument,
    as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过添加第二个参数来重构本节中较早的代码，如下所示：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we can call the function by passing in the variable. Let''s benchmark
    the code as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过传递变量来调用函数。让我们按照以下方式基准测试代码：
- en: '![](img/d3e10bf7-9df8-4770-a931-3f43258d2429.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d3e10bf7-9df8-4770-a931-3f43258d2429.png)'
- en: '*Fantastic!* It''s as fast as treating it as a constant. Where''s the magic?
    As it turns out, Julia''s compiler automatically generates specialized functions
    according to the type of its arguments. In this case, when we pass the variable
    as an integer value, the function is compiled to the most optimized version because
    the types of the arguments are known. It is fast now for the same reason as using
    constants.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*太棒了!* 它的速度和将其视为常量一样快。魔法在哪里？实际上，Julia的编译器会根据其参数的类型自动生成专门的函数。在这种情况下，当我们以整数值传递变量时，函数被编译为最优化版本，因为参数的类型是已知的。它现在之所以快，是因为和用常量一样的原因。'
- en: Of course, you may argue that it defeats the purpose of using global variables.
    Nonetheless, the flexibility is there and it can be used when you really need
    to get to the most optimal performance.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可能会争辩说这违背了使用全局变量的初衷。然而，这种灵活性确实存在，并且在你真正需要获得最佳性能时可以加以利用。
- en: When using `BenchmarkTools.jl` macros, we must interpolate global variables
    using the dollar-sign prefix. Otherwise, the time that it takes to reference the
    global variable is included in the performance test.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`BenchmarkTools.jl`宏时，我们必须使用美元符号前缀来插值全局变量。否则，引用全局变量所需的时间将包括在性能测试中。
- en: Hiding a variable inside a global constant
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在全局常量中隐藏变量
- en: Before we conclude this section, there is yet another alternative to keep the
    flexibility of global variables while not losing too much performance. We can
    call it a **global variable placeholder**.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本节之前，还有一个替代方案可以在不损失太多性能的情况下保持全局变量的灵活性。我们可以称之为**全局变量占位符**。
- en: As it may have become clear to you by now, Julia can generate highly optimized
    code whenever the type of a variable is known at compilation time. Hence, one
    way to solve the problem is to create a constant placeholder and store a value
    inside the placeholder.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你可能已经清楚，Julia可以在编译时知道变量类型的情况下生成高度优化的代码。因此，解决这个问题的方法之一是创建一个常量占位符并在其中存储值。
- en: 'Consider this code:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The global constant is assigned a `Ref` object. In Julia, a `Ref` object is
    nothing but a placeholder where the type of the enclosed object is known. You
    can try this in the Julia REPL:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 全局常量被分配了一个`Ref`对象。在Julia中，`Ref`对象不过是一个占位符，其中包含的对象类型是已知的。你可以在Julia REPL中尝试这个操作：
- en: '![](img/dcc14ebe-314a-46d9-b985-80d71519d3b2.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dcc14ebe-314a-46d9-b985-80d71519d3b2.png)'
- en: As we can see, the value inside `Ref(10)` has a type of `Int64` according to
    the type signature, `Base.RefValue{Int64}`. Similarly, the type of the value inside
    `Ref("abc")` is `String`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，根据类型签名`Base.RefValue{Int64}`，`Ref(10)`内部的值类型为`Int64`。同样，`Ref("abc")`内部的值类型为`String`。
- en: To fetch the value inside a `Ref` object, we can just use the index operator
    with no argument. Hence, in the preceding code, we use `semi_constant[]`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取`Ref`对象内部的值，我们可以使用不带参数的索引运算符。因此，在前面的代码中，我们使用了`semi_constant[]`。
- en: 'What would be the performance overhead of this extra indirection? Let''s benchmark
    the code as usual:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这种额外的间接引用会增加多少性能开销？让我们像往常一样对代码进行基准测试：
- en: '![](img/3b832665-11e3-4b60-a7e6-8bfacc12fe95.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b832665-11e3-4b60-a7e6-8bfacc12fe95.png)'
- en: That's not bad. Although it is far from the optimal performance of using global
    constant, it is still approximately 15 times faster than using a plain global
    variable.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不坏。虽然它的性能远未达到使用全局常量的最优性能，但它仍然比使用普通全局变量快大约15倍。
- en: 'Because `Ref` object is just a placeholder, the underlying value can also be
    assigned:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`Ref`对象只是一个占位符，所以底层值也可以被赋值：
- en: '![](img/34530746-060f-4740-83f8-f278311b3d8a.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34530746-060f-4740-83f8-f278311b3d8a.png)'
- en: In summary, the use of `Ref` allows us to simulate global variables without
    sacrificing too much performance.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，使用`Ref`允许我们在不牺牲太多性能的情况下模拟全局变量。
- en: Turning to some real-life examples
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转向一些现实生活中的例子
- en: Global constants are very common among Julia packages. It is not too surprising
    because constants are also used to avoid hardcoding values directly in functions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在Julia包中，全局常量非常常见。这并不令人惊讶，因为常量也用于避免在函数中直接硬编码值。
- en: Example 1 – SASLib.jl package
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 1 – SASLib.jl 包
- en: In the `SASLib.jl` package, most constants are defined in the `constants.jl`
    file located at [https://github.com/tk3369/SASLib.jl/blob/master/src/constants.jl](https://github.com/tk3369/SASLib.jl/blob/master/src/constants.jl).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在`SASLib.jl`包中，大多数常量都定义在位于[https://github.com/tk3369/SASLib.jl/blob/master/src/constants.jl](https://github.com/tk3369/SASLib.jl/blob/master/src/constants.jl)的`constants.jl`文件中。
- en: 'Here''s a fragment of the code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码片段：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Using these constants allows the file-reading functions to perform well.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些常量可以使文件读取函数表现良好。
- en: Example 2 – PyCall.jl package
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 2 – PyCall.jl包
- en: 'The `PyCall.jl` package''s documentation suggests the user stores a Python
    object using the global variable placeholder technique. The following excerpt
    can be found in its documentation:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`PyCall.jl`包的文档建议用户使用全局变量占位符技术存储Python对象。以下摘录可以在其文档中找到：'
- en: '"For a type-stable global constant, initialize the constant to `PyNULL()` at
    the top level, and then use the `copy!` function in your module''s `__init__`
    function to mutate it to its actual value."'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: “对于类型稳定的全局常量，在顶层将常量初始化为`PyNULL()`，然后在模块的`__init__`函数中使用`copy!`函数将其修改为其实际值。”
- en: A type-stable global constant is generally what we want for high-performance
    code. Basically, when the module is initialized, this global constant can be initialized
    with a value of `PyNULL()`. This constant is really just a placeholder object
    that can be mutated with the actual value later.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 类型稳定的全局常量通常是高性能代码所希望的。基本上，当模块初始化时，这个全局常量可以用`PyNULL()`的值初始化。这个常量实际上只是一个占位符对象，稍后可以用实际值修改。
- en: This technique is similar to the use of `Ref` as mentioned in the *Hiding a
    variable inside a global constant* section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术与在*隐藏全局常量中的变量*部分中提到的使用`Ref`类似。
- en: Considerations
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑事项
- en: If a global variable can be replaced as a global constant, then it should always
    be done. The reason for doing that is more than performance alone. Constants have
    the nice property of guaranteeing that their values are unchanged throughout the
    application life cycle. In general, the fewer global state changes, the more robust
    the program. Mutating states is traditionally a source of hard-to-find bugs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个全局变量可以被替换为全局常量，那么它应该始终这样做。这样做的原因不仅仅是性能。常量有一个很好的特性，即保证它们在整个应用程序生命周期中的值保持不变。一般来说，全局状态变化越少，程序越健壮。修改状态是传统上难以发现的错误来源。
- en: At times, we may get into a situation that we cannot avoid using global variables.
    That's too bad. However, before we feel sad about that, we could also check whether
    the system performance is materially affected or not.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能会遇到不得不使用全局变量的情况。这很糟糕。然而，在我们为此感到悲伤之前，我们也可以检查系统性能是否受到了实质性影响。
- en: In the preceding example of adding two numbers, accessing the global variable
    carries a relatively large cost because the actual operation is so simple and
    efficient. Hence, more work is done in terms of getting access to the global variable.
    On the other hand, if we have a more complex function that takes much longer,
    say, 500 nanoseconds, then the extra 25 nanosecond overhead becomes much less
    significant. In that case, we may as well ignore the issue as the overhead becomes
    immaterial.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的加法示例中，访问全局变量成本相对较高，因为实际操作非常简单和高效。因此，在获取全局变量的访问方面做了更多的工作。另一方面，如果我们有一个更复杂的函数，耗时更长，比如500纳秒，那么额外的25纳秒开销就变得不那么重要了。在这种情况下，我们可以忽略这个问题，因为开销变得微不足道。
- en: Finally, we should always watch out when too many global variables are used.
    The problem multiplies when more global variables are used. How many are too many?
    It really depends on your situation, but it does not hurt to think about the application
    design and ask yourself whether the application is designed properly.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应该始终注意当使用过多的全局变量时。当使用更多全局变量时，问题会成倍增加。多少算太多？这完全取决于你的情况，但思考应用程序设计和问自己应用程序是否设计得当是有益的。
- en: In the next section, we will discuss a pattern that helps to improve system
    performance just by laying out data differently in memory.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论一种通过在内存中不同布局数据来提高系统性能的模式。
- en: The struct of arrays pattern
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数组结构模式
- en: In recent years, modern CPU architecture has got fancier to meet today's demands.
    Due to various physical constraints, it is a lot more difficult to attain higher
    processor speed. Many Intel processors now support a technology called **Single
    Instruction, Multiple Data** (**SIMD**). By utilizing **Streaming SIMD Extension**
    (**SSE**) and **Advanced Vector Extensions** (**AVX**) registers, several mathematical
    operations can be executed within a single CPU cycle.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，为了满足今天的需要，现代CPU架构变得更加复杂。由于各种物理限制，达到更高的处理器速度变得更加困难。许多英特尔处理器现在支持一种称为**单指令多数据**（**SIMD**）的技术。通过利用**流式SIMD扩展**（**SSE**）和**高级向量扩展**（**AVX**）寄存器，可以在单个CPU周期内执行多个数学运算。
- en: That is nice, but one of the pre-requisites of utilizing these fancy CPU instructions
    is to make sure that the data is located in a contiguous memory block in the first
    place. That brings us to our topic here. How do we orient our data in a contiguous
    memory block? You may find the solution in this section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但使用这些花哨的 CPU 指令的一个先决条件是确保数据最初位于连续的内存块中。这把我们带到了这里的话题。我们如何将数据定位在连续的内存块中？你可能会在这个部分找到解决方案。
- en: Working with a business domain model
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与业务领域模型一起工作
- en: When designing an application, we often create an object model that mimics business
    domain concepts. The idea is to clearly articulate data in a form that feels most
    natural to the programmer.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计应用程序时，我们通常会创建一个对象模型，该模型模仿业务领域概念。目的是以对程序员来说最自然的形式清晰地阐述数据。
- en: Let's say we need to retrieve customers' data from a relational database. A
    customer record may be stored in a `CUSTOMER` table, and each customer is stored as
    a row in the table. When we fetch customer data from the database, we can construct
    a `Customer` object and push that into an array. Similarly, when we work with
    NoSQL databases, we may receive data as JSON documents and put them into an array
    of objects. In both cases, we can see that data is represented as an array of
    objects. Applications are usually designed to work with objects as defined using
    the `struct` statement.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要从关系型数据库中检索客户数据。客户记录可能存储在 `CUSTOMER` 表中，每个客户作为表中的一行存储。当我们从数据库中检索客户数据时，我们可以构建一个
    `Customer` 对象并将其推入一个数组。同样，当我们与 NoSQL 数据库一起工作时，我们可能会以 JSON 文档的形式接收数据，并将它们放入对象数组中。在这两种情况下，我们可以看到数据被表示为对象的数组。应用程序通常被设计成使用
    `struct` 语句定义的对象进行操作。
- en: Let's take a look at a use case for analyzing taxi data coming from New York
    City. The data is publicly available as several CSV files. For illustration purposes,
    we have downloaded the data for December 2018 and truncated it to 100,000 records.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看分析来自纽约市出租车数据的用例。这些数据作为几个 CSV 文件公开可用。为了说明目的，我们已经下载了 2018 年 12 月的数据，并将其截断到
    100,000 条记录。
- en: The full data file can be downloaded from [https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq](https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的数据文件可以从 [https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq](https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq)
    下载。
- en: For convenience, a smaller file with 100,000 records is available from our GitHub
    site at [https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-Julia-1.0/raw/master/Chapter06/StructOfArraysPattern/yellow_tripdata_2018-12_100k.csv](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-Julia-1.0/raw/master/Chapter06/StructOfArraysPattern/yellow_tripdata_2018-12_100k.csv).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，一个包含 100,000 条记录的小文件可以从我们的 GitHub 网站获取，网址为 [https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-Julia-1.0/raw/master/Chapter06/StructOfArraysPattern/yellow_tripdata_2018-12_100k.csv](https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-Julia-1.0/raw/master/Chapter06/StructOfArraysPattern/yellow_tripdata_2018-12_100k.csv)。
- en: 'First, we define a type called `TripPayment`, as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个名为 `TripPayment` 的类型，如下所示：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To read the data into memory, we will take advantage of the `CSV.jl` package.
    Let''s define a function to read the file into a vector:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据读入内存，我们将利用 `CSV.jl` 包。让我们定义一个函数来将文件读入一个向量：
- en: '[PRE9]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, when we fetch the data, we end up with an array. In this example, we have
    downloaded 100,000 records, as shown in the following screenshot:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们获取数据时，我们最终得到一个数组。在这个例子中，我们下载了 100,000 条记录，如下面的截图所示：
- en: '![](img/1ed1f4bb-8d9c-4730-9939-6a9e396706a0.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1ed1f4bb-8d9c-4730-9939-6a9e396706a0.png)'
- en: 'Now, suppose that we need to analyze this dataset. In many data analysis use
    cases, we simply calculate various statistics for some of the attributes in the
    payment records. For example, we may want to find the average fare amount, as
    follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们需要分析这个数据集。在许多数据分析用例中，我们只是计算支付记录中某些属性的统计信息。例如，我们可能想找到平均车费金额，如下所示：
- en: '![](img/0e00f27a-6eae-4d7e-9144-f36e56d4915c.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e00f27a-6eae-4d7e-9144-f36e56d4915c.png)'
- en: This should be a fairly fast operation already because it uses a generator syntax
    and avoids allocation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该是一个相当快的操作，因为它使用了生成器语法并避免了分配。
- en: Some Julia functions accept generator syntax, which can be written just like
    an array comprehension without the square brackets. It is very memory efficient
    because it avoids allocating memory for the intermediate object.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一些 Julia 函数接受生成器语法，可以像数组推导式一样编写，无需使用方括号。因为它避免了为中间对象分配内存，所以它非常节省内存。
- en: 'The only thing is that it needs to access the `fare_amount` field for every
    record. If we benchmark the function, it shows the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要注意的是，它需要为每条记录访问`fare_amount`字段。如果我们对函数进行基准测试，它将显示以下结果：
- en: '![](img/2351facb-3126-45e7-a9d8-5aaed47d2a0d.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2351facb-3126-45e7-a9d8-5aaed47d2a0d.png)'
- en: 'How do we know whether it runs at optimal speed? We don''t unless we try to
    do it differently. Because all we are doing is calculating the mean of 100,000
    floating-point numbers, we can easily replicate that with a simple array. Let''s
    replicate the data in a separate array:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道它是否以最佳速度运行？除非我们尝试以不同的方式做，否则我们不知道。因为我们所做的只是计算10万个浮点数的平均值，我们可以很容易地用简单的数组来复制这个操作。让我们在单独的数组中复制数据：
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we can benchmark the `mean` function by passing the array as is:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过直接传递数组来基准测试`mean`函数：
- en: '![](img/e767bfde-5d70-473c-a2c6-72df4905136e.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e767bfde-5d70-473c-a2c6-72df4905136e.png)'
- en: '*Whoa!* What''s happening here? It is 24x faster than before.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*哇!* 这里发生了什么？它的速度比之前快了24倍。'
- en: In this case, the compiler was able to make use of the more advanced CPU instructions.
    Because Julia arrays are dense arrays, that is, data is compactly stored in a
    contiguous block of memory, it enables the compiler to fully optimize the operation.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，编译器能够利用更高级的CPU指令。因为Julia数组是密集数组，也就是说数据紧凑地存储在连续的内存块中，这使得编译器能够完全优化操作。
- en: Converting data into an array seems to be a decent solution. However, just imagine
    that you have to create these temporary arrays for every single field. It is not
    much fun anymore as there is a possibility to miss a field while doing so. Is
    there a better way to solve this problem?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据转换为数组似乎是一个不错的解决方案。然而，想象一下，你必须为每个单独的字段创建这些临时数组。这样做不再有趣，因为有可能在这个过程中遗漏一个字段。有没有更好的方法来解决这个问题？
- en: Improving performance using a different data layout
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用不同的数据布局来提高性能
- en: The problem we just saw is caused by the use of an array of structs. What we
    really want is a struct of arrays. Notice the difference between arrays of structs
    and structs of arrays?
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才看到的问题是由使用结构数组引起的。我们真正想要的是数组结构。注意结构数组与数组结构的区别？
- en: In an array of structs, to access a field for an object, the program must first
    index into the object and then find the field via a predetermined offset in memory.
    For example, the `passenger_count` field in the `TripPayment` object is the fourth
    field of the struct where the preceding three fields are `Int64`, `String`, and
    `String types`. So, the offset to the fourth field is 24\. An array of structs
    has a row-oriented layout as every row is stored in a contiguous block of memory.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在结构数组中，为了访问对象的字段，程序必须首先索引到对象，然后通过内存中的预定偏移量找到字段。例如，`TripPayment`对象中的`passenger_count`字段是结构中的第四个字段，前面的三个字段是`Int64`、`String`和`String`类型。因此，第四个字段的偏移量是24。结构数组具有行导向的布局，因为每一行都存储在连续的内存块中。
- en: We now introduce the concept of struct of arrays. In a struct of arrays, we
    take a column-oriented approach. In this case, we only maintain a single object
    for the entire dataset. Within the object, each field represents an array of a
    particular field of the original record. For example, the `fare_amount` field
    would be stored as an array of fare amounts in this object. The column-oriented
    format is optimized for high-performance computing because the data values in
    the array all have the same type. In addition, they are also more compact in memory.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在介绍数组结构的概念。在数组结构中，我们采用列导向的方法。在这种情况下，我们只为整个数据集维护一个单一的对象。在对象内部，每个字段代表原始记录中特定字段的数组。例如，`fare_amount`字段将在这个对象中以票价金额的数组形式存储。列导向的格式针对高性能计算进行了优化，因为数组中的数据值都具有相同的类型。此外，它们在内存中也更加紧凑。
- en: A struct is typically aligned into 8-byte memory blocks in a 64-bit system.
    For example, a struct that contains just two fields of `Int32` and `Int16` types
    still consumes 8 bytes even though 6 bytes are enough to store the data. The two
    extra bytes are used to pad the data structure to an 8-byte boundary.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在64位系统中，结构通常被对齐到8字节内存块。例如，只包含两个字段`Int32`和`Int16`类型的结构仍然消耗8字节，尽管只需要6字节来存储数据。额外的两个字节用于填充数据结构以达到8字节的边界。
- en: In the following sections, we will look into how to implement this pattern and
    confirm that performance has improved.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨如何实现这种模式，并确认性能是否有所提高。
- en: Constructing a struct of arrays
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建数组结构
- en: 'It is easy and straightforward to construct a struct of arrays. After all,
    we were able to quickly do that for a single field earlier. For completeness,
    this is how we can design a new data type for storing the same trip payment data
    in a column-oriented format. The following code shows that this pattern helps
    to improve performance:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 构造数组结构既简单又直接。毕竟，我们之前能够快速为一个单个字段做到这一点。为了完整性，这是我们可以设计的新数据类型，用于以列格式存储相同的行程付款数据。以下代码显示这种模式有助于提高性能：
- en: '[PRE11]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Notice that every field has been turned into `Vector{T}`, where `T` is the original
    data type of the particular field. It looks quite ugly but we are willing to sacrifice
    ugliness here for performance reasons.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个字段都已转换为 `Vector{T}`，其中 `T` 是特定字段的原始数据类型。这看起来相当丑陋，但我们愿意为了性能牺牲这一点。
- en: The general rule of thumb is that we should just **Keep It Simple** (**KISS**).
    Under certain circumstances, when we do need higher runtime performance, we could
    bend a little.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一般原则是，我们应该**保持简单**（**KISS**）。在特定情况下，当我们确实需要更高的运行时性能时，我们可以稍微弯曲一下。
- en: 'Now, although we have a data type that is more optimized for performance, we
    still need to populate it with data for testing. In this case, it can be achieved
    quite easily using array comprehension syntax:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尽管我们有一个更优化性能的数据类型，但我们仍然需要用数据填充它以进行测试。在这种情况下，可以使用数组推导语法轻松实现：
- en: '[PRE12]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'When we''re done, we can prove to ourselves that the new object structure is
    indeed optimized:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成时，我们可以证明给自己，新的对象结构确实得到了优化：
- en: '![](img/84f64c6f-bc48-499b-8d94-e7c79571ab0c.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/84f64c6f-bc48-499b-8d94-e7c79571ab0c.png)'
- en: Yes, it now has great performance, as we expected.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它现在具有我们预期的出色性能。
- en: Using the StructArrays package
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 StructArrays 包
- en: The ugliness of the preceding columnar struct left us in a very unsatisfied
    state. Not only do we need to create a new data type with tons of `Vector` fields,
    we also have to create a constructor function to convert our array of structs
    into the new type.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 前一列结构的不美观让我们感到非常不满意。我们不仅需要创建一个包含大量 `Vector` 字段的新数据类型，还必须创建一个构造函数来将我们的结构体数组转换为新的类型。
- en: We can recognize the power of Julia when we get to use powerful packages in
    its ecosystem. To fully implement this pattern, we will introduce the `StructArrays.jl`
    package, which automates most of the mundane tasks in turning an array of structs
    into a struct of arrays.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 Julia 生态系统中的强大包时，我们可以认识到 Julia 的强大之处。为了完全实现这种模式，我们将引入 `StructArrays.jl`
    包，该包自动处理将结构体数组转换为数组结构的大部分繁琐任务。
- en: 'In fact, the usage of `StructArrays` is embarrassingly simple:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，`StructArrays` 的使用非常简单：
- en: '[PRE13]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s take a quick look at the content. First of all, we can treat `sa` just
    like the original array—for example, we can take the first three elements of the
    array as before:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看其内容。首先，我们可以像处理原始数组一样处理 `sa`——例如，我们可以像以前一样取数组的头三个元素：
- en: '![](img/2d939db7-ba66-4b72-aff8-2fd1cf4b068f.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2d939db7-ba66-4b72-aff8-2fd1cf4b068f.png)'
- en: 'If we pick just one record, it comes back with the original `TripPayment` object:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只选择一条记录，它将返回原始的 `TripPayment` 对象：
- en: '![](img/45b3f966-82b6-401e-bd64-52be7717fc80.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/45b3f966-82b6-401e-bd64-52be7717fc80.png)'
- en: 'Just to make sure that there is no mistake, we can also check the type of the
    first record:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保没有错误，我们还可以检查第一条记录的类型：
- en: '![](img/591c6b3b-eb14-40e1-8a1a-91fe8121e596.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/591c6b3b-eb14-40e1-8a1a-91fe8121e596.png)'
- en: 'Hence, the new `sa` object works just like before. Now, the difference comes
    in when we need to access all of the data from a single field. For example, we
    can get the `fare_amount` field as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，新的 `sa` 对象仍然像以前一样工作。现在，当我们需要从单个字段访问所有数据时，差异就出现了。例如，我们可以如下获取 `fare_amount`
    字段：
- en: '![](img/21356317-9519-4dab-844e-5a6906b2d3f0.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/21356317-9519-4dab-844e-5a6906b2d3f0.png)'
- en: 'Because the type is already materialized as a *dense array*, we can expect
    superb performance when doing numerical or statistical analysis on this field,
    as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 因为类型已经作为 *密集数组* 实现了，所以我们可以在进行数值或统计分析时期待该字段有出色的性能，如下所示：
- en: '![](img/49c5f557-8aa1-43b5-82f7-32a6776442e0.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/49c5f557-8aa1-43b5-82f7-32a6776442e0.png)'
- en: What is a `DenseArray`? It is actually an abstract type for which all elements
    in the array are allocated in a contiguous block of memory. `DenseArray` is a
    super-type of array.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是 `DenseArray`？它实际上是一个抽象类型，其中数组的所有元素都分配在连续的内存块中。`DenseArray` 是数组的超类型。
- en: Julia supports dynamic arrays by default, which means the size of the array
    can grow when we push more data into it. When it allocates more memory, it copies existing
    data over to the new memory location.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Julia默认支持动态数组，这意味着当我们向数组中推送更多数据时，数组的大小可以增长。当它分配更多内存时，它会将现有数据复制到新的内存位置。
- en: To avoid excessive memory reallocation, the current implementation uses a sophisticated
    algorithm to increase the size of memory allocation—fast enough to avoid excessive
    reallocation but conservative enough to not over-allocate memory.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过多的内存重新分配，当前实现使用了一种复杂的算法来增加内存分配的大小——足够快以避免过多的重新分配，但足够保守以避免过度分配内存。
- en: Understanding the space versus time trade-off
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解空间与时间的权衡
- en: The `StructArrays.jl` package provides a convenient mechanism to quickly turn
    an array of structs into a struct of arrays. We must recognize that the price
    we are paying is an additional copy of the data in memory. Hence, we are once
    again getting into the classic space versus time trade-off in computing.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`StructArrays.jl`包提供了一个方便的机制，可以快速将结构数组转换为数组结构。我们必须认识到我们付出的代价是在内存中数据的额外副本。因此，我们再次陷入了计算中的经典空间与时间的权衡。'
- en: 'Let''s quickly look into our use case again. We can use the `Base.summarysize` function
    in the Julia REPL to see the memory footprint:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次快速查看我们的用例。我们可以在Julia REPL中使用`Base.summarysize`函数来查看内存占用：
- en: '![](img/4e2b3396-19e2-43bc-ac89-72ecac1610a0.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4e2b3396-19e2-43bc-ac89-72ecac1610a0.png)'
- en: The `Base.summarysize` function returns the size of the object in bytes. We
    divided the number `1024` twice to arrive at the mega-byte unit. It is interesting
    to see that the struct of arrays, `sa`, is more memory efficient than the original
    array of structs, `records`. Nevertheless, we have two copies of data in memory.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`Base.summarysize`函数返回对象的字节数。我们将数字`1024`除以两次，得到兆字节单位。有趣的是，数组结构`sa`比原始结构数组`records`更节省内存。然而，我们在内存中有两个数据副本。'
- en: 'Fortunately, we do have some options here if we want to conserve memory. First,
    we may just discard the original data in the `records` variable if we no longer
    need the data in that structure. We can even force the garbage collector to run,
    as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，如果我们想节省内存，我们确实有一些选择。首先，如果我们不再需要该结构中的数据，我们可以简单地丢弃`records`变量中的原始数据。我们甚至可以强制垃圾收集器运行，如下所示：
- en: '![](img/27df9a41-047e-4546-8b21-7361fc6eab58.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/27df9a41-047e-4546-8b21-7361fc6eab58.png)'
- en: Second, we can discard the `sa` variable when we are done with the computation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，当我们完成计算后，我们可以丢弃`sa`变量。
- en: Handling nested object structures
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理嵌套对象结构
- en: The preceding sample case works fine for any flat data structure. Nowadays,
    it is not uncommon to design types that contain other composite types. Let's drill
    down a little bit deeper to see how we can handle such a nested structure.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例案例适用于任何平面数据结构。如今，设计包含其他复合类型的类型并不罕见。让我们深入探讨一下，看看我们如何处理这种嵌套结构。
- en: 'First, suppose that we want to separate the fields related to the fare in a
    separate composite data type:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，假设我们想要将与票价相关的字段分离到单独的复合数据类型中：
- en: '[PRE14]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can adjust the file reader slightly:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍微调整文件读取器：
- en: '[PRE15]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After we read the data, the array of trip payment data would look like the
    following:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们读取数据后，行程支付数据的数组将如下所示：
- en: '![](img/d98bcb93-8d70-4324-b6e0-f7d69dddb29d.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d98bcb93-8d70-4324-b6e0-f7d69dddb29d.png)'
- en: 'If we just create `StructArray` as before, we cannot extract the `fare_amount`
    field:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像以前一样只创建`StructArray`，我们就无法提取`fare_amount`字段：
- en: '![](img/97b5134f-b460-4efa-b67b-68b31c7440d8.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/97b5134f-b460-4efa-b67b-68b31c7440d8.png)'
- en: 'To achieve the same result at a level deeper, we can use the `unwrap` option:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在更深层次上达到相同的结果，我们可以使用`unwrap`选项：
- en: '![](img/ea510a52-e760-47e0-a56b-8ba0d3781cea.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ea510a52-e760-47e0-a56b-8ba0d3781cea.png)'
- en: The value of the `unwrap` keyword argument is basically a function that accepts
    a data type for a particular field. If the function returns `true`, then that
    particular field will be constructed with a nested `StructArray`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`unwrap`关键字参数的值基本上是一个接受特定字段数据类型的函数。如果函数返回`true`，则该特定字段将使用嵌套`StructArray`构建。'
- en: 'We can now access the `fare_amount` field with another level of indirection
    as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过另一层间接访问`fare_amount`字段，如下所示：
- en: '![](img/1700346f-7b1a-4f47-a289-38f90ab5adcb.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1700346f-7b1a-4f47-a289-38f90ab5adcb.png)'
- en: Using the `unwrap` keyword argument, we can easily walk through the entire data
    structure and create a `StructArray` object that allows us to access any data
    element in a compact array structure. From this point on, application performance
    can be improved.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `unwrap` 关键字参数，我们可以轻松地遍历整个数据结构，并创建一个允许我们访问紧凑数组结构中任何数据元素的 `StructArray` 对象。从这一点开始，应用性能可以得到提升。
- en: Considerations
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑事项
- en: When designing applications, we ought to determine what is the most important
    thing that is valued by our users. Similarly, when working on data analysis or
    data science projects, we should think about what we care about the most. A customer-first
    approach is essential in any decision-making process.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计应用程序时，我们应该确定用户最重视的是什么。同样，在从事数据分析或数据科学项目时，我们应该考虑我们最关心的是什么。在任何决策过程中，以客户为中心的方法都是至关重要的。
- en: Let's assume that our priority is to achieve better performance. Then, the next
    question is which part of the system requires optimization? If the part is slowed
    down due to the use of an array of structs, how much do we gain in speed when
    we employ the struct of arrays pattern? Is the performance gain noticeable—is
    it measured in milliseconds, minutes, hours, or days?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的优先级是实现更好的性能。那么，下一个问题是系统的哪个部分需要优化？如果部分由于使用结构体数组而变慢，我们采用结构体数组模式时能获得多少速度提升？性能提升是否明显——是按毫秒、分钟、小时还是天数来衡量的？
- en: Further, we need to consider system constraints. We like to think that the sky
    is the limit. But then coming back to reality, we are limited in system resources
    all over the place—the number of CPU cores, available memory, and disk space,
    as well other limits imposed by our system administrators, such as, maximum number
    of opened files and processes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要考虑系统限制。我们喜欢认为天空是极限。但回到现实中，我们在系统资源方面到处受限——CPU 核心数、可用内存和磁盘空间，以及其他系统管理员强加的限制，例如，最大打开文件数和进程数。
- en: While struct of arrays can improve performance, there is an overhead in allocating
    memory for the new arrays. If the data size is large, the allocation and data
    copy operation will take some time as well.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 struct of arrays 可以提高性能，但为新数组分配内存会有开销。如果数据量很大，分配和数据复制操作也会花费一些时间。
- en: In the next section, we will look into another pattern that helps to conserve
    memory and allows distributed computing— shared arrays.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨另一种有助于节省内存并允许分布式计算的模式——共享数组。
- en: The shared array pattern
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享数组模式
- en: Modern operating systems can handle many concurrent processes and fully utilize
    all processor cores. When it comes to distributed computing, a larger task is
    typically broken down into smaller ones such that multiple processes can execute
    the tasks concurrently. Sometimes, the results of these individual executions
    may need to be combined or aggregated for final delivery. This process is called
    **reduction**.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现代操作系统可以处理许多并发进程并充分利用所有处理器核心。当涉及到分布式计算时，通常将更大的任务分解成更小的任务，以便多个进程可以并发执行任务。有时，这些个别执行的结果可能需要合并或汇总以供最终交付。这个过程被称为**归约**。
- en: This concept is reincarnated in various forms. For example, in functional programming,
    it is common to implement data processes using map-reduce. The mapping process
    takes a list and applies a function to each element, and the reduction process
    combines the results. In big data processing, Hadoop uses a similar form of map-reduce,
    except that it runs across multiple machines in a cluster. The `DataFrames` package
    contains functions that perform the Split-Apply-Combine pattern. These all present
    pretty much the same concept.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念以各种形式重生。例如，在函数式编程中，通常使用 map-reduce 来实现数据处理。映射过程将列表应用于每个元素，而归约过程则合并结果。在大数据处理中，Hadoop
    使用类似的 map-reduce 形式，但它在集群中的多台机器上运行。`DataFrames` 包含执行 Split-Apply-Combine 模式的函数。这些都基本上是相同的概念。
- en: Sometimes, parallel worker processes need to communicate with each other. In
    general, processes can talk to each other by passing data via some form of **Inter-Process
    Communication** (**IPC**). There are many ways to do that—sockets, Unix domain
    sockets, pipes, named pipes, message queues, shared memory, and memory maps.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，并行工作进程需要相互通信。通常，进程可以通过某种形式的**进程间通信**（**IPC**）相互交谈。有很多种方法可以做到这一点——套接字、Unix
    域套接字、管道、命名管道、消息队列、共享内存和内存映射。
- en: Julia ships with a standard library called `SharedArrays`, which interfaces
    with the operating system's shared memory and memory map interface. This facility
    allows Julia processes to communicate with each other by sharing a central data
    source.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Julia附带一个名为`SharedArrays`的标准库，该库与操作系统的共享内存和内存映射接口进行交互。这种设施允许Julia进程通过共享中央数据源相互通信。
- en: In this section, we will take a look at how `SharedArrays` can be used for high-performance
    computing.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何使用`SharedArrays`进行高性能计算。
- en: Introducing a risk management use case
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍风险管理用例
- en: In a risk management use case, we want to estimate the volatility of portfolio
    returns using a process called Monte Carlo simulation. The concept is pretty simple.
    First, we develop a risk model based on historical data. Second, we use the model
    to predict the future in 10,000 ways. Finally, we look at the distribution of
    security returns in the portfolio and gauge how much the portfolio gains or losses
    in each of those scenarios.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在风险管理用例中，我们想要使用蒙特卡洛模拟过程来估计投资组合收益的波动性。概念相当简单。首先，我们根据历史数据开发一个风险模型。其次，我们使用该模型以10,000种方式预测未来。最后，我们查看投资组合中证券收益的分布，并评估在每种情景下投资组合的收益或损失。
- en: Portfolios are often measured against benchmarks. For example, a stock portfolio
    may be benchmarked against the S&P 500 Index. The reason is that portfolio managers
    are typically rewarded for earning *alpha*, a term for describing the excess return
    that is over and above the benchmark's return. In other words, the portfolio manager
    is rewarded for their skills in picking the right stocks.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合通常与基准进行比较。例如，股票投资组合可能以标准普尔500指数为基准。原因是投资组合经理通常因获得*alpha*而获得奖励，alpha是描述超过基准收益的超额收益的术语。换句话说，投资组合经理因其在挑选正确股票方面的技能而获得奖励。
- en: In the fixed income market, the problem is a little more challenging. Unlike
    the stock market, typical fixed income benchmarks are quite large, up to 10,000
    bonds. In assessing portfolio risk, we often want to analyze the sources of return.
    Did the value of a portfolio go up because it was riding the wave in a bull market,
    or did it go down because everyone is selling? The risk that correlates to market
    movement is called **systematic risk**. Another source of return relates to the
    individual bond. For example, if the issuer of the bond is doing well and making
    good profit, then the bond has a lower risk and the price goes up. This kind of
    movement due to the specific individual bond is called **idiosyncratic risk**.
    For a global portfolio, some bonds are exposed to **currency risk** as well. From
    a computational complexity perspective, to estimate the returns of the benchmark
    index 10,000 ways, we have to perform *10,000 future scenarios x 10,000 securities
    x 3 sources of returns = 300 million* pricing calculations.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定收益市场中，问题要稍微复杂一些。与股市不同，典型的固定收益基准规模相当大，高达10,000个债券。在评估投资组合风险时，我们通常想要分析收益的来源。投资组合的价值上升是因为它在牛市中乘风破浪，还是因为大家都开始抛售而下降？与市场波动相关的风险被称为**系统性风险**。收益的另一个来源与个别债券有关。例如，如果债券发行商经营良好，盈利丰厚，那么债券的风险就会降低，价格也会上涨。这种由于特定个别债券引起的波动被称为**特定风险**。对于全球投资组合，一些债券还面临着**汇率风险**。从计算复杂性的角度来看，为了估计10,000个基准指数的收益，我们必须进行*10,000个未来情景
    x 10,000个证券 x 3个收益来源 = 3亿*次定价计算。
- en: Coming back to our simulation example, we can generate 10,000 possible future
    scenarios of the portfolio, and the results are basically a set of returns across
    all such scenarios. The returns data is stored on disk and is now ready for additional
    analysis. Here comes the problem—an asset manager has to analyze over 1,000 portfolios,
    and each portfolio may require access to returns data varying between 10,000 to
    50,000 bonds depending on the size of the benchmark index. Unfortunately, the
    production server is limited in memory but has plenty of CPU resources. How can
    we fully utilize our hardware to perform the analysis as quickly as possible?
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的模拟示例，我们可以生成10,000种可能的投资组合未来情景，结果基本上是一组所有这些情景的收益数据。收益数据存储在磁盘上，现在已准备好进行进一步分析。然而，问题来了——资产管理员必须分析超过1,000个投资组合，每个投资组合可能需要访问10,000到50,000个债券的收益数据，具体取决于基准指数的大小。不幸的是，生产服务器内存有限，但CPU资源充足。我们如何充分利用我们的硬件，尽可能快地完成分析？
- en: 'Let''s quickly summarize our problem:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速总结一下我们的问题：
- en: 'Hardware:'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件：
- en: 16 vCPU
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 16个vCPU
- en: 32 GB RAM
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 32 GB RAM
- en: 'Security returns data:'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全收益数据：
- en: Stored in 100,000 individual files
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储在 100,000 个单独的文件中
- en: Each file contains a 10,000 x 3 matrix (10,000 future states and 3 return sources)
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个文件包含一个 10,000 x 3 的矩阵（10,000 个未来状态和 3 个回报来源）
- en: Total memory footprint is ~22 GB
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总内存占用约为 ~22 GB
- en: 'Task:'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务：
- en: Calculate statistical measures (standard deviation, skewness, and kurtosis)
    for all security returns across the 10,000 future states.
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 10,000 个未来状态中的所有证券回报计算统计指标（标准差、偏度和峰度）。
- en: Do that as quickly as possible!
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽快完成这项工作！
- en: The naive way to just load all of the files sequentially. Needless to say, loading
    100,000 files one by one is not going to be very fast no matter how small the
    files are. We are going to use the Julia distributed computing facility to get
    it done.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法就是按顺序加载所有文件。不用说，无论文件多小，逐个加载 100,000 个文件都不会很快。我们将使用 Julia 分布式计算功能来完成这项工作。
- en: Preparing data for the example
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备示例数据
- en: To follow the subsequent code for this pattern, we can prepare some test data.
    Before you run the code here, make sure that you have enough disk space for the
    test data. You will need approximately 22 GB of free space.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 要遵循后续代码中的此模式，我们可以准备一些测试数据。在运行这里的代码之前，请确保你有足够的磁盘空间来存储测试数据。你需要大约 22 GB 的空闲空间。
- en: 'Rather than putting 100,000 files in a single directory, we can split them
    into 100 sub-directories. So, let''s just create the directories first. A simple
    function is created for that purpose:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是将 100,000 个文件放在单个目录中，我们可以将它们分成 100 个子目录。所以，让我们首先创建这些目录。为此创建了一个简单的函数：
- en: '[PRE16]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can assume that every security is identified by a numerical index value
    between 1 and 100,000. Let''s define a function that generates the path to find
    the file:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以假设每个证券都有一个介于 1 和 100,000 之间的数值索引。让我们定义一个函数来生成查找文件的路径：
- en: '[PRE17]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The function is designed to hash the file into one of the 100 sub-directories.
    Let''s see how it works:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数被设计为将文件哈希到 100 个子目录之一。让我们看看它是如何工作的：
- en: '[PRE18]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: So, the first 100 securities are located in directories called `0`, `1`, ...,
    `99`. The 101^(st) security starts wrapping and goes back to directory `0`. For
    consistency reasons, the filename contains the security index minus 1.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前 100 个证券位于名为 `0`、`1`、...、`99` 的目录中。第 101 个证券开始循环并回到目录 `0`。出于一致性原因，文件名包含证券索引减
    1。
- en: 'Now we are ready to generate the test data. Let''s define a function as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好生成测试数据。让我们定义一个如下所示的功能：
- en: '[PRE19]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To generate all test files, we just need to call this function by passing `nfiles` with
    a value of 100,000\. By the end of this exercise, you should have test files scattered
    in all 100 sub-directories. Note that the `generate_test_data` function will take
    a few minutes to generate all the test data. Let''s do that now:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成所有测试文件，我们只需通过传递 `nfiles` 参数值为 100,000 调用此函数。在这个练习结束时，你应该会在所有 100 个子目录中散布着测试文件。请注意，`generate_test_data`
    函数生成所有测试数据需要几分钟时间。我们现在就来做这件事：
- en: '![](img/99083063-29a9-481c-8f3a-eda572dc7038.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99083063-29a9-481c-8f3a-eda572dc7038.png)'
- en: 'When it is done, let''s quickly take a look at our data files in a Terminal:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当它完成时，让我们快速查看终端中的数据文件：
- en: '![](img/9a49f834-4f81-44b6-920e-26d6f524b42b.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a49f834-4f81-44b6-920e-26d6f524b42b.png)'
- en: We're now ready to tackle the problem using the shared array pattern. Let's
    get started.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备使用共享数组模式来解决这个问题。让我们开始吧。
- en: Overview of a high-performance solution
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高性能解决方案概述
- en: The beauty of `SharedArrays` is that the data is maintained as a single copy,
    and multiple processes can have both read and write access. It is a perfect solution
    to our problem.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`SharedArrays` 的美妙之处在于数据保持为单个副本，并且多个进程可以同时具有读写访问权限。这是我们问题的完美解决方案。'
- en: 'In this solution, we will do the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个解决方案中，我们将执行以下操作：
- en: The master program creates a shared array.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主程序创建一个共享数组。
- en: Using a distributed `for` loop, the master program commands worker processes
    to read each individual file into a specific segment of the array.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分布式 `for` 循环，主程序命令工作进程将每个单独的文件读入数组的特定段。
- en: Again, using a distributed `for` loop, the master program commands worker process
    to perform statistical analysis.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，使用分布式 `for` 循环，主程序命令工作进程执行统计分析。
- en: As we have 16 vCPUs, we can utilize all of them.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有 16 个 vCPU，我们可以利用它们全部。
- en: In practice, we should probably utilize fewer vCPUs so that we can leave some
    room for the operating system itself. Your mileage may vary depending on what
    else is running on the same server. The best approach is to test various configurations
    and determine the optimal settings.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可能应该使用更少的vCPUs，这样我们就可以为操作系统本身留出一些空间。你的使用情况可能会根据同一服务器上运行的其他内容而有所不同。最佳方法是测试各种配置并确定最佳设置。
- en: Populating data in the shared array
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在共享数组中填充数据
- en: 'The security return files are distributed and stored in 100 different directories.
    Where it gets stored is based upon a simple formula: *file index **modulus** 100*,
    where the *file index* is the numerical identifier for each security, numbered
    between 1 to 100,000.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 安全返回文件分布在100个不同的目录中。它们存储的位置基于一个简单的公式：*文件索引 **modulus** 100*，其中*文件索引*是每个安全的数值标识符，编号在1到100,000之间。
- en: Each data file is in a simple binary format. The upstream process has calculated
    three source returns for 10,000 future states, as in a 10,000 x 3 matrix. The
    layout is column-oriented, meaning that the first 10,000 numbers are used for
    the first return source, the next 10,000 numbers are for the second return source,
    and so on.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据文件都采用简单的二进制格式。上游进程已经为10,000个未来状态计算了3个源返回，就像一个10,000 x 3的矩阵。布局是列导向的，这意味着前10,000个数字用于第一个返回源，接下来的10,000个数字用于第二个返回源，依此类推。
- en: 'Before we start using distributed computing functions, we must spawn worker
    processes. Julia comes with a convenient command-line option (`-p`) that the user
    can specify the number of worker processes up front as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用分布式计算函数之前，我们必须启动工作进程。Julia提供了一个方便的命令行选项（`-p`），用户可以事先指定工作进程的数量，如下所示：
- en: '![](img/5ca28f21-f785-4ffe-90fa-082cc0f2468f.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5ca28f21-f785-4ffe-90fa-082cc0f2468f.png)'
- en: When the REPL comes up, we would already have 16 processes running and ready
    to go. The `nworkers` function confirms that all 16 worker processes are available.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 当REPL启动时，我们已经有16个进程正在运行并准备就绪。`nworkers`函数确认所有16个工作进程都是可用的。
- en: 'Let''s look into the code now. First, we must load `Distributed` and `SharedArrays`
    packages:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看代码。首先，我们必须加载`Distributed`和`SharedArrays`包：
- en: '[PRE20]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To make sure that the worker processes know where to find the files, we have
    to change directory on all of them:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保工作进程知道在哪里找到文件，我们必须在它们中更改目录：
- en: '[PRE21]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `@everywhere` macro executes the statement on all worker processes.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`@everywhere` 宏会在所有工作进程中执行该语句。'
- en: 'The main program looks like this:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 主程序看起来是这样的：
- en: '[PRE22]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this case, we are creating a 3-dimensional shared array. Then, we call the
    `load_data!` function to read all 100,000 files and shovel the data into the valuation
    matrix. How does the `load_data!` function work? Let''s take a look:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们正在创建一个三维共享数组。然后，我们调用`load_data!`函数来读取所有100,000个文件并将数据推入估值矩阵。`load_data!`函数是如何工作的？让我们看看：
- en: '[PRE23]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It's a very simple `for` loop that just calls the `read_val_file!` function
    with an index number. Notice the use of two macros here—`@distributed` and `@sync`.
    First, the `@distributed` macro does the magic by sending the body of the `for` loop
    to the worker processes. In general, the master program here does not wait for
    the worker processes to return. However, the `@sync` macro blocks until all jobs
    are completely finished.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的`for`循环，它只是用索引号调用`read_val_file!`函数。注意这里使用了两个宏——`@distributed`和`@sync`。首先，`@distributed`宏通过将`for`循环的主体发送到工作进程来实现魔法。一般来说，这里的master程序不会等待工作进程返回。然而，`@sync`宏会阻塞，直到所有作业都完全完成。
- en: 'How does it actually read the binary file? Let''s see:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 它实际上是如何读取二进制文件的？让我们看看：
- en: '[PRE24]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, the function first locates the path of the data file. Then, it opens the
    file and reads all the binary data into a byte array. Since the data is just 64-bit
    floating pointer numbers, we use the `reinterpret` function to parse the data
    into an array of `Float64` values. We do expect 30,000 `Float64` values here in
    each file, representing 10,000 future states and 3 source returns. When the data
    is ready, we just save them into the array for the particular index.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，函数首先定位数据文件的位置。然后，它打开文件并将所有二进制数据读取到一个字节数组中。由于数据只是64位浮点数，我们使用`reinterpret`函数将数据解析为一个`Float64`值的数组。我们预计每个文件中都有30,000个`Float64`值，代表10,000个未来状态和3个源返回。当数据准备好后，我们只需将它们保存到特定索引的数组中。
- en: 'We also use the `@everywhere` macro to ensure that the function is defined
    and made available to all worker processes. The `locate_file` function is a little
    less interesting. It is included here for completeness:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用`@everywhere`宏来确保函数被定义并可供所有工作进程使用。`locate_file`函数稍微有点无趣。它被包含在这里以示完整性：
- en: '[PRE25]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To load the data files in parallel, we can define a `load_data!` function as
    follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了并行加载数据文件，我们可以定义一个`load_data!`函数，如下所示：
- en: '[PRE26]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here, we just put the `@sync` and `@distributed` macros in front of a `for` loop.
    Julia automatically schedules and distributes the call among all work processes. Now
    that everything is set up, we can run the program:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只是在`for`循环前放置了`@sync`和`@distributed`宏。Julia会自动调度并将调用分配给所有工作进程。现在一切准备就绪，我们可以运行程序：
- en: '[PRE27]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We simply create a valuation `SharedArray` object. Then, we pass it to the
    `load_data!` function for processing:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单地创建一个估值`SharedArray`对象。然后，我们将其传递给`load_data!`函数进行处理：
- en: '![](img/40798cd2-7a61-4a6e-ba4b-36bba294fc47.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/40798cd2-7a61-4a6e-ba4b-36bba294fc47.png)'
- en: It only took about three minutes to load 100,000 files into memory using 16
    parallel processes. *That's pretty good!*
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 仅需大约三分钟，就使用16个并行进程将10万个文件加载到内存中。*这相当不错！*
- en: If you try to run the program in your own environment but encounter an error,
    it may be due to system constraints. Refer to the later section, *Configuring
    system settings for shared memory usage*, for more information.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试在自己的环境中运行程序但遇到错误，那可能是因为系统限制。请参考后面的部分，*配置系统设置以使用共享内存*，获取更多信息。
- en: It turns out that this exercise is still IO-bound. CPU utilization hovered just
    around 5% during the load process. Should the problem demand incremental computation,
    we could possibly leverage the remaining CPU resource by spawning other asynchronous
    processes that operate on data and just got loaded into memory.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，这个练习仍然是I/O受限的。在加载过程中，CPU利用率始终在5%左右。如果问题需要增量计算，我们可能可以通过启动其他异步进程来利用剩余的CPU资源，这些进程在数据被加载到内存后操作数据。
- en: Analyzing data directly on a shared array
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在共享数组上直接分析数据
- en: Using shared arrays allows us to perform parallel operations on the data from
    a single memory space. As long as we do not mutate the data, then these operations
    can run independently without conflicts. This type of problem is called *embarrassingly
    parallel*.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 使用共享数组允许我们在单个内存空间上对数据进行并行操作。只要我们不修改数据，这些操作就可以独立运行，不会发生冲突。这种类型的问题被称为*令人尴尬的并行*。
- en: 'To illustrate the power of multi-processing, let''s first benchmark a simple
    function that calculates the standard deviation of the returns across all securities:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明多进程的强大功能，我们先对一个非常简单的函数进行基准测试，该函数计算所有证券的回报率的标准差：
- en: '[PRE28]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The value of `n` represents number of securities.  The value of `nattr` represents
    number of sources of return. Let''s see how much time it takes for a single process. The
    best timing was 5.286 seconds:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`n`的值代表证券的数量。`nattr`的值代表回报来源的数量。让我们看看单个进程需要多少时间。最佳时间记录为5.286秒：'
- en: '![](img/6ee6bc24-1814-4c85-9f1d-578a99d03435.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6ee6bc24-1814-4c85-9f1d-578a99d03435.png)'
- en: The `@benchmark` macro provides some statistics about the performance benchmark.
    Sometimes, it is useful to see the distribution and have an idea about how much
    GC impacts performance.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`@benchmark`宏提供了一些关于性能基准的统计数据。有时，查看分布并了解GC对性能的影响是有用的。'
- en: The `seconds=30` parameter was specified because this function takes seconds
    to run. The default parameter value is 5 seconds, and that would not allow the
    benchmark to collect enough samples for reporting.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`seconds=30`参数被指定是因为这个函数需要秒来运行。默认参数值是5秒，这不会允许基准测试收集足够的样本以进行报告。'
- en: 'We are now ready to run the program in parallel. First, we need to make sure
    that all child processes have the dependent packages loaded:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以并行运行程序了。首先，我们需要确保所有子进程都已加载了依赖的包：
- en: '[PRE29]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we can define a distributed function, as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以定义一个分布式函数，如下所示：
- en: '[PRE30]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This function looks very similar to the previous one, with some exceptions:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数看起来与上一个非常相似，有一些例外：
- en: We have allocated a new shared array, `result`, to store the computed data.
    This array is 2-dimensional because we are reducing the third dimension into a
    single standard deviation value. This array is accessible by all worker processes.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经分配了一个新的共享数组`result`来存储计算数据。这个数组是二维的，因为我们把第三维减少到一个标准差值。这个数组可以被所有工作进程访问。
- en: The `@distributed` macro in front of the `for` loop is used to automatically
    distribute the work, in other words, the body of the `for` loop, to the worker
    processes.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `for` 循环前面的 `@distributed` 宏用于自动将工作（换句话说，`for` 循环的主体）分布到工作进程中。
- en: The `@sync` macro in front of the `for` loop makes the system wait until all
    of the work is done.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `for` 循环前面的 `@sync` 宏使得系统等待直到所有工作完成。
- en: 'We can now benchmark the performance of this new function using the same 16
    worker processes:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用相同的16个工作进程来基准测试这个新函数的性能：
- en: '![](img/3ca5af15-5673-46dd-ae1b-b28a96bf02f8.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3ca5af15-5673-46dd-ae1b-b28a96bf02f8.png)'
- en: Compared to the performance of a single process, this is approximately 6x faster
    than before.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 与单个进程的性能相比，这比之前快了大约6倍。
- en: Understanding the overhead of parallel processing
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解并行处理的开销
- en: Have you noticed something interesting here? Since we have 16 worker processes,
    we would have expected that the parallel processing function to be close to 16
    times faster. But the result came in at around 6 times, which is somewhat less
    than we expected. Why is that?
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有注意到这里有什么有趣的地方？由于我们有16个工作进程，我们本期望并行处理函数的速度接近16倍。但结果只达到了大约6倍，这比我们预期的要少。为什么？
- en: The answer is that it is just a matter of scale. There is some performance overhead
    to use the parallel processing facility. Typically, this overhead can be ignored
    because it is immaterial when compared to the amount of work being performed.
    In this particular example, calculating standard deviation is a really trivial
    computation. So, in relative terms, the overhead of coordinating remote function
    calls and collecting results overshadows the actual work itself.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是这只是规模问题。使用并行处理设施会有一些性能开销。通常，这种开销可以忽略不计，因为它与正在执行的工作量相比微不足道。在这个特定的例子中，计算标准差是一项非常简单的计算。因此，从相对意义上讲，协调远程函数调用和收集结果的开销超过了实际工作本身。
- en: 'Perhaps we should prove it. Let''s just do a little more work and calculate
    skewness and kurtosis in addition to standard deviation:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我们应该证明这一点。让我们再做一些工作，除了计算标准差之外，还要计算偏度和峰度：
- en: '[PRE31]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The parallel processing version is similar:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 并行处理版本类似：
- en: '[PRE32]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Let''s compare their performance now:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在比较一下它们的性能：
- en: '![](img/80ed0ef1-3b83-46f8-b933-0b2a7a2f481a.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/80ed0ef1-3b83-46f8-b933-0b2a7a2f481a.png)'
- en: The parallel process is now 9x faster, as shown in the preceding. If we continue
    on this path and do more non-trivial computation, then we would expect a higher
    impact up to somewhere closer to 16x difference.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，并行处理现在快了9倍。
- en: Configuring system settings for shared memory usage
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置系统设置以使用共享内存
- en: The magic of `SharedArrays` come from the use of memory map and shared memory
    facilities in the operating system. When dealing with large amounts of data, we
    may need to configure the system to handle the volume.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`SharedArrays` 的魔法来自于操作系统中对内存映射和共享内存功能的利用。当处理大量数据时，我们可能需要配置系统以处理数据量。'
- en: Adjusting system kernel parameters
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整系统内核参数
- en: 'The Linux operating system has a limit on the size of shared memory. To find
    out what that is, we can use the `ipcs` command:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Linux操作系统对共享内存的大小有限制。要找出这个限制是多少，我们可以使用 `ipcs` 命令：
- en: '![](img/2f6ae1e3-49c1-4606-9c44-97fa10349c7d.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2f6ae1e3-49c1-4606-9c44-97fa10349c7d.png)'
- en: 'The `E` unit may look a little unfamiliar. It''s in exabytes, which basically
    mean 18 zeros: `kilo`, `mega`, `giga`, `tera`, `peta`, and `exa`. Get it? So,
    we''re in luck here, because the limit is so high that we will probably never
    reach. However, if you see a small number, then you may need to reconfigure the
    system. The three kernel parameters are as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '`E` 单位可能看起来有些不熟悉。它是以艾字节为单位的，基本上意味着18个零：`kilo`、`mega`、`giga`、`tera`、`peta` 和
    `exa`。明白了吗？所以，我们很幸运，因为限制如此之高，我们可能永远也达不到。然而，如果你看到一个很小的数字，那么你可能需要重新配置系统。三个内核参数如下：'
- en: Maximum number of segments (SHMMNI)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大段数（SHMMNI）
- en: Maximum segment size (SHMMAX)
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大段大小（SHMMAX）
- en: Maximum total shared memory (SHMALL)
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大总共享内存（SHMALL）
- en: 'We can find out the actual values using the `sysctl` command:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `sysctl` 命令找到实际值：
- en: '![](img/3d6c6676-4fb5-4855-9fbd-dd7832911227.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3d6c6676-4fb5-4855-9fbd-dd7832911227.png)'
- en: 'To adjust the values, we can again use the `sysctl` command. For example, to
    set the maximum segment size (`shmmax`) to 128 GiB, we can do the following:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 为了调整值，我们再次可以使用 `sysctl` 命令。例如，要将最大段大小（`shmmax`）设置为128 GiB，我们可以这样做：
- en: '![](img/6c10ef33-5b2f-46c1-8147-fb6110b5ba99.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6c10ef33-5b2f-46c1-8147-fb6110b5ba99.png)'
- en: We can see that the kernel setting is now updated.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到内核设置已经更新。
- en: Configuring a shared memory device
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置共享内存设备
- en: 'It is not enough to just change the system limits as shown in the preceding
    section. The Linux kernel actually uses the `/dev/shm` device as an in-memory
    backing store for shared memory. We can find out the size of the device using
    the regular `df` command:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 仅如前所述更改系统限制是不够的。实际上，Linux内核将`/dev/shm`设备用作共享内存的内存后端存储。我们可以使用常规的`df`命令来找出设备的大小：
- en: '![](img/b6305740-ce86-4c5f-9402-8b0ec6c1f737.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b6305740-ce86-4c5f-9402-8b0ec6c1f737.png)'
- en: 'At the current state, the `/dev/shm` device is unused as shown in the preceding.
    The overall size of the block device is 16 GiB. As an exercise, let''s now open
    a Julia REPL and create `SharedArray`:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前状态下，如前所述，`/dev/shm`设备未被使用。整个块设备的大小为16 GiB。作为一个练习，现在让我们打开一个Julia REPL并创建`SharedArray`：
- en: '![](img/497f7a1d-d304-47ab-8b76-dde3bd146aeb.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/497f7a1d-d304-47ab-8b76-dde3bd146aeb.png)'
- en: 'Re-running the `df` command, we can see that `/dev/shm` is now used:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行`df`命令，我们可以看到`/dev/shm`现在正在使用：
- en: '![](img/89ce04c0-03c3-47a6-95c2-9a0b0dab1035.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/89ce04c0-03c3-47a6-95c2-9a0b0dab1035.png)'
- en: 'Now that we know `SharedArray` uses the `/dev/shm` device, how can we increase
    the size to accommodate our problem, which requires more than 22 GiB? It can be
    done using the `mount` command with a new size:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道`SharedArray`使用的是`/dev/shm`设备，我们该如何增加其大小以适应我们的问题，该问题需要超过22 GiB的空间？可以使用带有新大小的`mount`命令来实现：
- en: '![](img/4bbd27b7-904d-4e2f-abba-56c95e2806d5.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4bbd27b7-904d-4e2f-abba-56c95e2806d5.png)'
- en: The size of `/dev/shm` is now clearly shown as `28G`.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '`/dev/shm`的大小现在清楚地显示为`28G`。'
- en: Debugging the shared memory size issue
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试共享内存大小问题
- en: 'What happens if we exceed the size of the shared memory device if we have forgotten
    to increase the size as described earlier? Let''s say we need to allocate 20 GiB
    but there is only 16 GiB:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们忘记按照前面描述的方式增加大小，而超出了共享内存设备的大小，会发生什么？比如说，我们需要分配20 GiB，但只有16 GiB：
- en: '![](img/a79c1524-d21b-4eed-801e-62a129a38c0d.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a79c1524-d21b-4eed-801e-62a129a38c0d.png)'
- en: 'There is no error even though we have exceeded the limit! Are we getting a
    free ride? The answer is no. It turns out that Julia does not know the limit has
    been breached. We can even work with the array *up close and personal* to the
    16 GiB mark:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 即使超出了限制，我们也没有错误！我们是不是在免费乘坐？答案是，不是。实际上，Julia并不知道限制已被违反。我们甚至可以与16 GiB标记附近的数组进行“亲密接触”：
- en: '![](img/65d91dad-4d67-4836-82d6-9577cc8a0a31.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/65d91dad-4d67-4836-82d6-9577cc8a0a31.png)'
- en: 'The preceding code simply sets the first 15 GiB of memory to `0x01`. No error
    is shown so far. Going back to the shell, we can check the size of `/dev/shm`
    again. Clearly, 15 GiB is in use:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码只是将前15 GiB的内存设置为`0x01`。到目前为止没有显示错误。回到shell中，我们再次检查`/dev/shm`的大小。显然，15 GiB正在使用中：
- en: '![](img/6a13b028-c67d-4aa6-933e-3b0ac611ebd1.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6a13b028-c67d-4aa6-933e-3b0ac611ebd1.png)'
- en: 'Now, if we continue to assign values to the later part of the array, we get
    an ugly Bus error and a long stack trace:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们继续给数组后部分赋值，我们会得到一个难看的总线错误和长长的堆栈跟踪：
- en: '![](img/8457ac45-5f3b-413c-941c-2f4b4906d725.png)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8457ac45-5f3b-413c-941c-2f4b4906d725.png)'
- en: You may wonder why Julia cannot be smarter and tell you up front that you do
    not have enough shared memory space. As it turns out, it's the same behavior if
    you had used the underlying operating system's `mmap` function. Honestly, Julia
    just does not have any more information about the system constraint.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么Julia不能更聪明一些，提前告诉你没有足够的共享内存空间。实际上，如果你使用了底层操作系统的`mmap`函数，也会有同样的行为。坦白说，Julia对系统约束没有任何更多信息。
- en: Sometimes, a C function's manual page can be useful and provide some hints.
    For example, the documentation about the `mmap` call indicates that a SIGBUS signal
    will be thrown when the program attempts to access an unreachable portion of the
    memory buffer. The manual page can be found at [https://linux.die.net/man/2/mmap](https://linux.die.net/man/2/mmap).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，一个C函数的手册页可能会有用，并提供一些提示。例如，关于`mmap`调用的文档表明，当程序尝试访问内存缓冲区中不可达的部分时，将会抛出一个SIGBUS信号。手册页可以在[https://linux.die.net/man/2/mmap](https://linux.die.net/man/2/mmap)找到。
- en: Ensuring worker processes have access to code and data
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保工作进程可以访问代码和数据
- en: 'When developing parallel computation, a beginner often runs into the following
    issues:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发并行计算时，初学者经常会遇到以下问题：
- en: '**Functions not defined in the worker processes: **This can be a symptom of
    a library package not being loaded, or a function that was only defined in the
    current process but not defined in the worker processes. Both issues can be resolved
    by using the `@everywhere` macro as shown in the preceding examples.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作者进程中未定义的函数**：这可能表明库包未加载，或者一个仅在当前进程中定义但未在工作者进程中定义的函数。这两个问题都可以通过使用前面示例中显示的
    `@everywhere` 宏来解决。'
- en: '**Data not available in the worker processes: **This can be a symptom of the
    data being stored as a variable in the current processes but not passed to the
    worker processes. `SharedArray` is convenient because it is automatically made
    available to worker processes. For other cases, the programmer generally has two
    options:'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作者进程中不可用的数据**：这可能表明数据作为变量存储在当前进程中，但没有传递给工作者进程。`SharedArray` 非常方便，因为它会自动提供给工作者进程。对于其他情况，程序员通常有两个选择：'
- en: Explicitly pass the data via function arguments.
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确通过函数参数传递数据。
- en: 'If the data is in a global variable, then it can be transferred using the `@everywhere`
    macro, as follows:'
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据存储在全局变量中，则可以使用 `@everywhere` 宏进行传输，如下所示：
- en: '[PRE33]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: For more advanced use cases, the `ParallelDataTransfer.jl` package provides
    several helpful functions to facilitate data transfer among the master process
    and worker processes.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的使用案例，`ParallelDataTransfer.jl` 包提供了一些有用的函数，以促进主进程和工作者进程之间的数据传输。
- en: Avoiding race conditions among parallel processes
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免并行过程中的竞态条件
- en: '`SharedArrays` provides an easy conduit for sharing data across multiple processes.
    At the same time, a `SharedArray` is by design a global variable across all worker
    processes. As a general rule of thumb for every parallel program, extreme care
    should be given when the array is mutated. If the same memory address needs to
    be written by multiple processes, then these operations must be synchronized or
    the program could crash easily.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '`SharedArrays` 提供了一种简单的方法，可以在多个进程之间共享数据。同时，`SharedArray` 按设计是所有工作者进程的全局变量。对于每个并行程序，通常的规则是，在数组被变异时应该给予极大的关注。如果需要多个进程写入相同的内存地址，那么这些操作必须同步，否则程序可能会轻易崩溃。'
- en: The best option is to avoid mutation whenever possible.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳选择是尽可能避免变异。
- en: An alternative is to assign each worker a mutually exclusive set of slots in
    the array so that they do not collide with each other.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是为每个工作者分配数组中互斥的槽位，这样他们就不会相互冲突。
- en: Working with the constraints of shared arrays
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与共享数组的约束一起工作
- en: 'Elements in a `SharedArray` must be *bits type*. What does that mean? The formal
    definition of bits type can be summarized as follows:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '`SharedArray` 中的元素必须是*位类型*。这意味着什么？位类型的正式定义可以总结如下：'
- en: The type is immutable.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型是不可变的。
- en: The type contains only primitive types or other bits types.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该类型只包含原始类型或其他位类型。
- en: 'The following `OrderItem` type is a bits type because all fields are primitive
    types:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `OrderItem` 类型是位类型，因为所有字段都是原始类型：
- en: '[PRE34]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following `Customer` type is not a bits type because it contains a reference
    to `String`, which is neither a primitive type nor a bits type:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `Customer` 类型不是位类型，因为它包含对 `String` 的引用，而 `String` 既不是原始类型也不是位类型：
- en: '[PRE35]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s try to create `SharedArray` for a bits type. The following code confirms
    that it works properly:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试为位类型创建 `SharedArray`。以下代码确认它工作正常：
- en: '![](img/4712c21d-01c9-426d-ad50-b370085cd0a9.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4712c21d-01c9-426d-ad50-b370085cd0a9.png)'
- en: 'If we try to create `SharedArray` with a non-bits type such as a mutable struct
    type, an error will result:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试使用非位类型（如可变结构类型）创建 `SharedArray`，则会导致错误：
- en: '![](img/d7034c0d-e743-4c89-acde-cc8e9b017467.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d7034c0d-e743-4c89-acde-cc8e9b017467.png)'
- en: In summary, Julia's shared array is a great way to distribute data to multiple
    parallel processes for high-performance computing. The programming interface is
    also very easy to use.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Julia 的共享数组是向多个并行进程分配数据以进行高性能计算的好方法。编程接口也非常易于使用。
- en: In the next section, we will look into a pattern that improves performance by
    exploiting the space-time trade-off.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨一种通过利用时空权衡来提高性能的模式。
- en: The memoization pattern
  id: totrans-373
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存模式
- en: In 1968, an interesting article was published—it envisioned that computers should
    be able to learn from experience during execution and improve their own efficiency.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1968 年，发表了一篇有趣的文章——它设想计算机应该在执行过程中从经验中学习并提高自己的效率。
- en: In developing software, we often face a situation where the speed of execution
    is constrained by many factors. Maybe a function needs to read a large amount
    of historical data from disk (also known as I/O-bound). Or a function just needs
    to perform some complex calculation that takes a lot of time (also known as CPU-bound).
    When these functions are called repeatedly, application performance can suffer
    greatly.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件开发过程中，我们经常面临执行速度受多种因素限制的情况。可能是一个函数需要从磁盘（也称为I/O绑定）读取大量历史数据。或者，一个函数只需要执行一些耗时较多的复杂计算（也称为CPU绑定）。当这些函数被反复调用时，应用程序的性能可能会受到严重影响。
- en: Memoization is a powerful concept to address these problems. In recent years,
    it has become more popular as functional programming is becoming more mainstream.
    The idea is really simple. When a function is called for the first time, the return
    value is stored in a cache. If the function is called again with the exact same
    argument as before, we can look up the value from the cache and return the result
    immediately.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆化是一个强大的概念，用于解决这些问题。近年来，随着函数式编程变得越来越主流，它变得越来越流行。这个想法真的很简单。当一个函数第一次被调用时，其返回值被存储在缓存中。如果函数再次以与之前完全相同的参数被调用，我们可以从缓存中查找该值并立即返回结果。
- en: As you will see later in this section, memoization is a specific form of caching
    where the return data of a function call is cached according to the arguments
    being passed to the function.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在本节后面将看到的，记忆化是一种特定的缓存形式，其中函数调用的返回数据根据传递给函数的参数进行缓存。
- en: Introducing the Fibonacci function
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入斐波那契函数
- en: 'In functional programming, recursion is a common technique for computation.
    Sometimes, we may fall into a performance pitfall unknowingly. A classic example
    is the generation of a Fibonacci sequence, which is defined as follows:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中，递归是计算中的一种常见技术。有时，我们可能无意中陷入性能陷阱。一个经典的例子是生成斐波那契序列，它被定义为如下：
- en: '![](img/c33798f1-b1a1-4b1e-85cb-88cf2e05f396.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c33798f1-b1a1-4b1e-85cb-88cf2e05f396.png)'
- en: 'It works well functionally but it is not very efficient. Why? It is because
    the function is recursively defined, and the same function is called multiple
    times with the same arguments. Let''s take a look at the computation graph when
    finding the sixth Fibonacci number, where each `f(n)` node represents a call to
    the `fib` function:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 它在函数式编程中效果很好，但效率不高。为什么？因为它是以递归方式定义的函数，并且多次以相同的参数调用相同的函数。让我们看看寻找第六个斐波那契数时的计算图，其中每个`f(n)`节点代表对`fib`函数的调用：
- en: '![](img/d77512b9-8018-4131-9c85-41ce8c6d9ce5.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d77512b9-8018-4131-9c85-41ce8c6d9ce5.png)'
- en: As you can see, the function is called many times, especially for those that
    are at the beginning part of the sequence. To calculate `fib(6)`, we end up calling
    the function 15 times! And this is like a snowball, getting worse very quickly.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，函数被多次调用，尤其是那些位于序列开头部分的函数。为了计算`fib(6)`，我们最终调用了该函数15次！而且这就像一个雪球，迅速恶化。
- en: Improving the performance of the Fibonacci function
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高斐波那契函数的性能
- en: 'First, let''s analyze how bad the performance is by revising the function to
    keep track of the number of executions. The code is as follows:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们通过修改函数以跟踪执行次数来分析性能有多糟糕。代码如下：
- en: '[PRE36]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Every time the `fib` function is called, it keeps tracks a counter. If the value
    of `n` is smaller than `3`, then it returns the count of `1` along with the result.
    If `n` is a larger number, then it aggregates the counts from the recursive calls
    to `fib` function.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 每次调用`fib`函数时，它都会跟踪一个计数器。如果`n`的值小于`3`，则返回`1`的计数以及结果。如果`n`是一个更大的数字，则从对`fib`函数的递归调用中聚合计数。
- en: 'Let''s run it several times with various input values:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用不同的输入值运行它几次：
- en: '![](img/46c45877-c458-4688-9327-28a040dae00e.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46c45877-c458-4688-9327-28a040dae00e.png)'
- en: This simple example just illustrated how quickly it turns into a disaster when
    the computer has no memory about what it did before. A high school student would
    be able to calculate `fib(20)` manually with just 18 additions, discounting the
    first two numbers of the sequence. Our nice little function calls itself over
    13,000 items!
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的例子仅仅说明了当计算机没有关于之前做了什么的记忆时，它会如何迅速变成灾难。一个高中生只需用18次加法就能手动计算`fib(20)`，不考虑序列的前两个数字。我们这个不错的小函数会调用自己超过13,000次！
- en: 'Let''s now put back the original code and benchmark the function. To illustrate
    the problem, I will start with `fib(40)`:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们恢复原始代码并基准测试该函数。为了说明问题，我将从`fib(40)`开始：
- en: '![](img/0a6f947b-432a-46fd-a066-e7f37228baa2.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
- en: For this task, the function should really return instantly. The 430 millisecond
    feels like an eternity in computer time!
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use memoization to solve this problem. Here is our first attempt:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: First of all, we have created a dictionary object called `fib_cache` to store
    the results of previous calculations. Then, the core logic for the Fibonacci sequence
    is captured in this private function, `_fib`.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: The `fib` function works by first looking up the input argument from the `fib_cache`
    dictionary. If the value is found, it returns the value. Otherwise, it invokes
    the private function, `_fib`, and updates the cache before returning the value.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'The performance should be much better now. Let''s test it quickly:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bf205143-755b-4ae0-8c18-349cf1b3fdc9.png)'
  id: totrans-399
  prefs: []
  type: TYPE_IMG
- en: We should be must happier with the performance result by now.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: We have used a `Dict` object to cache calculation results here for demonstration
    purposes. In reality, we can optimize it further by using an array as a cache.
    The lookup from an array should be a lot faster than a dictionary key lookup.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Note that an array cache works well for the `fib` function because it takes
    a positive integer argument. For more complex functions, a `Dict` cache would
    be more appropriate.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: Automating the construction of a memoization cache
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While we are quite happy with the result in the preceding implementation, it
    feels a little unsatisfactory because we have to write the same code every time
    we need to memoize a new function. Wouldn't it be nice if the cache is automatically
    maintained? Realistically, we just need one cache for each function that we want
    to memoize.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s do it a little differently. The thought is that we should be able
    to build a higher-order function that takes an existing function and return a
    memoized version of it. Before we get there, let''s first redefine our `fib` function
    as an anonymous function, as follows:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'For now, we have added a `println` statement just so that we can validate the
    correctness of our implementation. If it works properly, `fib` should not be called
    millions of times. Moving on, we can define a `memoize` function as follows:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `memoize` function first creates a local variable called `memo` for storing
    previous return values. Then, it returns an anonymous function that captures the
    `memo` variable, performs cache lookup, and calls `f` functions when it is needed.
    This coding style of capturing a variable in an anonymous function is called a
    **closure**. Now, we can use the `memoize` function to build a cache-aware `fib`
    function:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s also prove that it does not call the original `fib` function too many
    times. For example, running `fib(6)` should be no more than 6 calls:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1cee8a1-3c1c-4069-b16e-31e576af7c0a.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
- en: 'That looks satisfactory. If we run the function again with any input less than
    or equal to 6, then the original logic should not be called at all, and all results
    should be returned straight from the cache. However, if the input is larger than
    6, then it calculates the ones above 6\. Let''s try that now:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82adab99-9b14-4c83-89d3-eb0a5e7860bd.png)'
  id: totrans-414
  prefs: []
  type: TYPE_IMG
- en: We cannot conclude what we did is good enough until we benchmark the new code.
    Let's do it now.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17ac42d4-ee15-4999-a35d-c79d011a3306.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
- en: The original function took 433 ms to compute `fib(400)`. This memoized version
    only takes 50 ns. This is a huge difference.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the constraint with generic functions
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One drawback of the preceding method is that we must define the original function
    as an anonymous function rather than a generic function. That seems to be a major
    constraint. The question is why doesn't it work with generic function?
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do a quick test by starting a new Julia REPL, defining the original
    `fib` function again, and wrapping it with the same `memoize` function:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1bd0fc0-fdeb-495e-96b5-b2a356bab3b1.png)'
  id: totrans-421
  prefs: []
  type: TYPE_IMG
- en: 'The problem is that `fib` is already defined as a generic function, and it
    cannot be bound to a new anonymous function, which is what is being returned from
    the `memoize` function. To work around the issue, we may be tempted to assign
    the memoized function with a new name:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'However, it does not really work because the original `fib` function makes
    a recursive call to itself rather than the new memoized version. To see it more
    clearly, we can unroll a call as follows:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Call the function as `fib_fast(6)`.
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `fib_fast` function, it checks whether the cache contains a key that
    equals 6.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The answer is no, so it calls `fib(5)`.
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `fib` function, since `n` is `5` and is greater than `3`, it calls `fib(4)`
    and `fib(3)` recursively.
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, the original `fib` function got called rather than the memoized
    version, so we are back to the same problem before. Hence, if the function being
    memoized uses recursion, then we must write the function as an anonymous function.
    Otherwise, it would be okay to create a memoized function with a new name.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: Supporting functions that take multiple arguments
  id: totrans-430
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In practice, we would probably encounter functions that are more complex than
    this. For example, the function that requires speed-up probably requires multiple
    arguments and possibly keyword arguments as well. Our `memoize` function in the
    previous section assumes a single argument, so it would not work properly.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple way to fix this is illustrated as follows:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The anonymous function being returned now covers any number of positional arguments
    and keyword arguments as specified in the splatted arguments, `args...` and `kwargs...`.
    We can quickly test this with a dummy function as follows:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, we can create the fast version as follows:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s test the memoized function with a few different cases:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8a2049e1-1fef-459e-bf9e-b1d1627a1ee5.png)'
  id: totrans-439
  prefs: []
  type: TYPE_IMG
- en: It's working great!
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: Handling mutable data types in the arguments
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we did not pay much attention to the arguments or keyword arguments
    being passed to the function. Care must be taken when any of those arguments are
    mutable. Why? Because our current implementation uses the arguments as the key
    of the dictionary cache. If we mutate the key of a dictionary, it could lead to
    unexpected results.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that we have a function that takes 2 seconds to run:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Knowing that it''s quite slow, we happily memoize it as usual:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Initially, it seems to work perfectly, as it has always been:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e526f15-b390-475b-aff1-4fc1018d7d36.png)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
- en: 'However, we are shocked by the following observation:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c494dcd-0233-4a83-92ba-f550f1640f71.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
- en: '*Bummer!* Rather than returning a value of `21`, it returns the previous result
    as if `-6` were not inserted to the array. Out of curiosity, let''s push one more
    value to the array and try again:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e520ace-52df-4451-bcfa-cacda611732f.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
- en: 'It''s working again. Why is that happening? To understand that, let''s recap
    how the `memoize` function was written:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As you can see, we are caching the data using the `(args, kwargs)` tuple as
    the key of the dictionary object. The problem is that the argument being passed
    to the memoized `sum_abs` function is a mutable object. The dictionary object
    gets *confused* when the key is mutated. In that case, it may or may not locate
    the key anymore.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: When we added `-6` to the array, it found the same object in the dictionary
    and returned the cached result. When we added `7` to the array, it could not find
    the object. Hence, the function does not work 100% of the time.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix this issue, we need to make sure that the content of the arguments are
    considered, not just the memory address of the container. A common practice is
    to apply a `hash` function to the thing that we wish to use as a key to the dictionary.
    Here''s one implementation:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The initial value of the `h` variable is randomly selected. On a 64-bit system,
    we can generate it with a call to `rand(UInt64)`. The `hash` function is a generic
    function defined in the `Base` module. We will keep it simple here for illustration
    purposes. In reality, a better implementation would support a 32-bit system as
    well.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: 'The `memoize` function can now be rewritten to utilize such a hashing scheme:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1292b06-fc26-42cd-bfa7-6f5d6bcc1f12.png)'
  id: totrans-461
  prefs: []
  type: TYPE_IMG
- en: We can test it again more extensively. Let's redefine the `sum_abs` function
    again using the new `memoize` function. Then, we run a loop and capture the calculation
    result and timing.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is shown as follows:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/235a693a-2447-431c-b66a-4b7174ddb109.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
- en: '*Fantastic!* It now returns the correct result even though the input data has
    been mutated.'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Memoizing generic functions with macros
  id: totrans-466
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Earlier, we discussed that generic functions cannot be supported by the `memoize`
    function. It would be most awesome if we can just annotate the functions as memoized
    while they are being defined. For example, the syntax would be like this:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'It turns out that there''s already an awesome package called `Memoize.jl` that
    does the exact same thing. It is indeed quite convenient:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c88cbb9-ec27-474c-9945-fda4f353f0fd.png)'
  id: totrans-470
  prefs: []
  type: TYPE_IMG
- en: 'Here, we can observe the following:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: The first call to `fib(40)` was quite fast already, which is an indication that
    the cache is utilized.
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second call to `fib(40)` was almost instant, which means that the result
    was just a cache lookup.
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The third call to `fib(39)` was almost instant, which means that the result
    was just a cache lookup.
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should be advised that `Memoize.jl` does not support mutable data as arguments
    either. It carries the same problem that we described in the preceding section
    because it uses the objects' memory addresses as the key to the dictionary.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Turning to real-life examples
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memoization is used in some open source packages. The actual usage may be more
    common in private applications and data analysis. Let's see some use cases for
    memoization in the following sections.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Symata.jl
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Symata.jl` package provides support for Fibonacci polynomials. As we may
    have realized, the implementation of Fibonacci polynomials is also recursive just
    like the Fibonacci sequence problem we discussed earlier in this section. `Symata.jl`
    uses the `Memoize.jl` package to create the `_fibpoly` function as follows:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Omega.jl
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Omega.jl` package implements its own memoization cache. Interestingly,
    it ensures proper return type from the cache lookup using the `Core.Compiler.return_type`
    function. It is done to avoid type instability problems. In *The **barrier function pattern*
    section later in this chapter, we will discuss more the problem of type instability
    and how to deal with the issue. Check out the following code example:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Considerations
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memoization can only be applied to *pure* functions.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: 'What is a pure function? A function is called pure when it always returns the
    same value given the same input. It may seem intuitive for every function to behave
    that way but in practice, it is not that straightforward. Some functions are not
    pure due to reasons such as these:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: A function uses a random number generator and is expected to return random results.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A function relies on data from an external source that produces different data
    at different times.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the memoization pattern uses function arguments as the key of the in-memory
    cache, it will always return the same result for the same key.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: Another consideration is that we should be aware of the extra memory overhead
    due to the use of a cache. It is important to choose the right cache invalidation
    strategy for the specific use case. Typical cache invalidation strategies include
    **Least Recently Used** (**LRU**), **First-In, First-Out** (**FIFO**), and time-based
    expiration.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing the Caching.jl package
  id: totrans-491
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several packages that can make memoization easier. Some are mentioned
    here:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '`Memoize.jl` provides a `@memoize` macro. It''s very easy to use.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Anamnesis.jl` provides a `@anamnesis` macro. It has more functionalities than
    `Memoize.jl`.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Caching.jl` was created with the ambition to provide more functionalities
    such as persistence to disk, compression, and cache size management.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we can take a look at `Caching.jl` as it is developed more recently and
    has great features.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build a memoized CSV file reader as follows:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12cb7ee8-c416-4d03-b36c-c322c4bbda03.png)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
- en: The `@cache` macro makes a memoized version of the `read_csv` function. To confirm
    that a file is read only once, we inserted a `println` statement and timed the
    file read operation.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: 'For demonstration purposes, we have downloaded a copy of the film permits file
    from the City of New York. The file is available from [https://catalog.data.gov/dataset/film-permits](https://catalog.data.gov/dataset/film-permits).
    Let''s read the data file now:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3aa1355-bc14-491f-9beb-8a6728f00486.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
- en: Here, we can see that the file is read only once. If we call `read_csv` again
    with the same filename, then the same object is returned instantly.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: 'We can examine the cache. Before doing that, let''s see what properties `read_csv`
    supports:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9bb30aac-fd20-443a-a00e-9bf450e669db.png)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
- en: 'Without looking at the manual, we can guess that the `cache` property represents
    the cache. Let''s take a quick look:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06ccd591-911a-4a91-a157-ba8dc6e35c66.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
- en: 'We can also persist the cache to disk. Let''s examine the name and size of
    the cache file:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fd22c071-0026-41cc-8cc2-f8cc13aea2fd.png)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
- en: 'The location of the cache file is found in the `filename` property. The file
    does not exist until the `@persist!` macro was used to persist data to disk. We
    can also see how many objects are present in memory or on disk by just examining
    the function `itself` from the REPL:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/21eedbd3-51ee-41ad-8ff3-84249d4ff7ca.png)'
  id: totrans-510
  prefs: []
  type: TYPE_IMG
- en: 'The `@empty!` macro can be used to purge the in-memory cache:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f97c9cc-09ba-4765-9736-c35e380b27b4.png)'
  id: totrans-512
  prefs: []
  type: TYPE_IMG
- en: 'Interestingly, because the on-disk cache still exists, we can still utilize
    it without having to re-populate the memory cache:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f8b658f-2b8f-446f-a8e5-9d61d32c9d5e.png)'
  id: totrans-514
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we can synchronize the memory and disk caches:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac89faf5-cb75-4957-a7a7-35c7a819dad3.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
- en: The `Caching.jl` package has more functionalities that are not shown here. Hopefully,
    we have got an idea of what it is capable of already.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look into a pattern that can be used to address the type-instability
    problem, which is a common issue causing performance problems.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: The barrier function pattern
  id: totrans-519
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While Julia is designed as a dynamic language, it also aims for high performance.
    The magic comes from its state-of-the-art compiler. When the type of variables
    is known in a function, the compiler can generate highly optimized code. However,
    when the type of a variable is unstable, the compiler has to compile more generic
    code that works with any data types. In some sense, Julia can be forgiving—it
    never fails on you even when it comes with a cost against runtime performance.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: What makes the type of a variable *unstable*? It means that in some circumstances
    the variable may be one type, and in other circumstances, it may be another type.
    This section will discuss such a type instability problem, how it may arise, and
    what we can do about it.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: Barrier function is a pattern that can be used to solve performance problems
    due to type instability. So, let's see how to achieve that.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
- en: Identifying type-unstable functions
  id: totrans-523
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Julia, there is no need to specify the type of variables. In fact, to be
    more precise, variables are not typed. Variables are merely bindings to values,
    and values are typed. That is what makes Julia programs dynamic. However, such
    flexibility comes with a cost. Because the compiler must generate code that supports
    all possible types that may come up during runtime, it is unable to generate optimized
    code.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a simple function that just returns an array of random numbers:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: If the `n` argument is odd, then it returns an array of random `Int` values.
    Otherwise, it returns an array of random `Float64` values.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: 'This innocent function is actually type-unstable. We can use the `@code_warntype`
    facility to check:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79870010-f89e-4e5d-9243-fb62731a99e6.png)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
- en: The `@code_warntype` macro displays an **Intermediate Representation** (**IR**)
    of the code. An IR is generated by the compiler after it understand the flow and
    data type of every line in that code. For our purpose here, we do not need to
    understand everything printed on screen but we can pay attention to the highlighted
    text as related to the data types generated from the code. In general, when you
    see red text, it would also be a red flag.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the compiler has figured that the result of this function can
    be an array of `Float64` or an array of `Int64`. Hence, the return type is just `Union{Array{Float64,1},
    Array{Int64,1}}`.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: In general, more red signs from the `@code_warntype` output indicates more type
    instability problems in the code.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: The function does exactly what we want to do. But when it's used in the body
    of another function, the type instability problem further affects runtime performance. We
    can use a barrier function to solve this problem.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: Understanding performance impact
  id: totrans-534
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a function is called, the type of its arguments are known and then the
    function is compiled with the exact data types from its arguments. This is called* specialization*. What
    exactly is a barrier function? It simply exploits Julia's function specialization
    to *stabilize* the type of variable as part of a function call. We will continue
    the preceding example to illustrate the technique.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create a simple function that makes use of the type unstable
    function, as mentioned earlier:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The `double_sum_of_random_data` function is just a simple function that returns
    the sum of doubled random numbers generated by the `random_data` function. If
    we just benchmark the function with either an odd or an even number argument,
    it comes back with the following results:'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c281dda-c3a9-4d28-bcc0-6e8d027620ed.png)'
  id: totrans-539
  prefs: []
  type: TYPE_IMG
- en: 'The timing is better for the call with an input value of `100001`, most likely
    because the random number generator for `Int` is better than the one for `Float64`.
    Let''s see what `@code_warntype` comes back for this function:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c4c9973-410d-4185-ab08-f6b3b767e3c7.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
- en: As you can see, there are tons of red marks around. The type instability issue
    of a single function has a larger impact on other functions that use it.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: Developing barrier functions
  id: totrans-543
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A barrier function involves refactoring a piece of logic from an existing function
    into a new, separate function. When it''s done, all data required by the new function
    will be passed as function arguments. Continuing with the preceding example, we
    can factor out the logic that calculates the doubled sum of data as follows:'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Then, we just modify the original function to make use of this function:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Does it really improve performance? Let''s run the test:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/158c750f-974c-47d4-891b-fbc4d57f1c59.png)'
  id: totrans-549
  prefs: []
  type: TYPE_IMG
- en: It turns out to have a huge difference for the `Float64` case—the elapsed time
    went from 347 to 245 microseconds. Comparing the floating-point sum versus integer
    sum cases, the result also makes perfect sense because summing integers is generally
    faster than summing floating-point numbers.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with a type-unstable output variable
  id: totrans-551
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What we haven't noticed is another type instability problem concerning the accumulator.
    In the preceding example, the `double_sum` function has a `total` variable that
    keeps track of the doubled numbers. The problem is that the variable was defined
    as an integer, but then the array may contain floating-pointer numbers instead.
    This problem can be easily revealed by running `@code_warntype` against both scenarios.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output of `@code_warntype` for when an array of integers is passed
    into the function:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89141bb9-cfe6-4a36-a9aa-a02b9182dc1f.png)'
  id: totrans-554
  prefs: []
  type: TYPE_IMG
- en: 'Compare it with the output when an array of `Float64` is passed:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d7a6dd4-9a34-4e2a-9c35-f4edf2f3d6e3.png)'
  id: totrans-556
  prefs: []
  type: TYPE_IMG
- en: If we call the function with an array of integers, then the type is stable.
    If we call the function with an array of floats, then we see the type instability
    issue.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: 'How do we fix this? Well, there are standard `Base` functions for creating
    type-stable zeros or ones. For example, rather than hardcoding the initial value
    of `total` to be an integer zero, we can do the following instead:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: If we look into the `@code_warntype` output of the `double_sum_of_random_data`
    function, it is much better than before. I will let you do this exercise and compare
    the `@code_warntype` output with the prior one.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar solution makes use of the parametric method:'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-562
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The `T`  type parameter is used to initialize the `total` variable to the properly
    typed value of zero.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of performance gotcha is sometimes difficult to catch. To ensure
    optimized code is generated, it is always a good practice to use the following
    functions for an accumulator or an array that stores output values:'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: '`zero` and `zeros` create a value of 0 or an array of 0s for the desired type.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`one` and `ones` create a value of 1 or an array of 1s for the desired type.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`similar` creates an array of the same type as the array argument.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, we can create a value of 0 or an array of 0s for any numeric types
    as follows:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16e42dcf-9fed-4de6-9d8b-7d70389088a9.png)'
  id: totrans-569
  prefs: []
  type: TYPE_IMG
- en: 'Likewise, the `one` and `ones` functions work the same way:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/da6e68f1-dac2-42a5-9a3a-b551beef19a9.png)'
  id: totrans-571
  prefs: []
  type: TYPE_IMG
- en: 'If we want to create an array that looks like another one (in other words,
    has the same type, shape, and size), then we can use the `similar` function:'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/944cce80-c2f4-49e5-8c01-e9a5c8918b00.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
- en: Note that the `similar` function does not zero out the content of the array.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: 'The `axes` function may come in handy when we need to create an array of zeros
    that matches the same dimensions of another array:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0efd33ad-6ce6-4dd9-ac99-e27dd2fc44af.png)'
  id: totrans-576
  prefs: []
  type: TYPE_IMG
- en: Next, we will look into a way to debug type instability issues.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: Using the @inferred macro
  id: totrans-578
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Julia comes with a handy macro in the `Test` package that can be used to check
    whether the return type of a function matches the *inferred* return type of the
    function. The inferred return type is simply the type that we see from the `@code_warntype`
    output before.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we can check the notorious `random_data` function from the beginning
    of this section:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dadfd917-89f6-4d9e-b427-d92337237f7a.png)'
  id: totrans-581
  prefs: []
  type: TYPE_IMG
- en: The macro reports an error whenever the actual returned type differs from the
    inferred return type. It could be a useful tool to validate the type instability
    problem as part of an automated test suite in the continuous integration pipeline.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: The primary reason to use a barrier function is to improve performance where
    the type instability problem exists. If we think about it more deeply, it also has
    the side benefit of forcing us to create smaller functions. Smaller functions
    are easier to read and debug and perform better.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: We have now concluded all patterns in this chapter.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-585
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored several patterns related to performance.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
- en: First, we discussed how global variables hurt performance and the technique
    of the global constant pattern. We looked into how the compiler optimizes performance
    by doing constant folding, constant propagation, and dead branch elimination.
    We also learned how to create a constant placeholder for wrapping a global variable.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: We discussed how to utilize the struct of arrays pattern to turn an array of
    structs into a struct of arrays. The new layout of the data structure allows better
    CPU optimization and, hence, better performance. We took advantage of a very useful
    package, `StructArrays`, for automating such data structure transformation. We
    reviewed a financial services use case where a large amount of data needs to be
    loaded into memory and used by many parallel processes. We implemented the shared
    array pattern and went over some tricks to configure shared memory properly in
    the operating system.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: We learned about the memoization pattern for caching function call results.
    We did a sample implementation using a dictionary cache and made it work with
    functions taking various arguments and keyword arguments. We also found a way
    to support mutable objects as function arguments. Finally, we discussed the barrier
    function pattern. We saw how performance can be degraded by type-unstable variables.
    We learned that splitting logic into a separate function allows the compiler to
    produce more optimal code.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will examine several patterns that improve system maintainability.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-591
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why does the use of global variables impact performance?
  id: totrans-592
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What would be a good alternative to using a global variable when it cannot be
    replaced by a constant?
  id: totrans-593
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does a struct of arrays perform better than an array of structs?
  id: totrans-594
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the limitations of `SharedArray`?
  id: totrans-595
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an alternative to multi-core computation instead of using parallel processes?
  id: totrans-596
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What care must be taken when using the memoization pattern?
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the magic behind barrier functions in improving performance?
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
