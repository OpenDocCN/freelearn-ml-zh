<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Object Detection Using Ada Boost and Haar Cascades</h1></div></div></div><p>This chapter shows a very interesting feature of OpenCV—detecting faces in an image or a video stream. In the latter case, we <a id="id176" class="indexterm"/>call it <strong>face tracking</strong>. In order to do so, this chapter dives into machine-learning algorithms, specifically supervised learning with boosting. We will cover<a id="id177" class="indexterm"/> the <strong>Viola-Jones classifier</strong> and its theory as well as the details on how to use the face-trained classifiers that are bundled with OpenCV.</p><p>In this chapter, we will be covering the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The boosting theory</li><li class="listitem" style="list-style-type: disc">Viola-Jones classifier</li><li class="listitem" style="list-style-type: disc">Detecting faces</li><li class="listitem" style="list-style-type: disc">Learning new objects</li></ul></div><p>By the end of this chapter, you will be able to understand the theory behind face classifiers through boosting, and the Viola-Jones classifier. You will also know how to use straightforward face classifiers. Besides, you will be able to create your own object classifier for different objects.</p><div><div><div><div><h1 class="title"><a id="ch05lvl1sec40"/>The boosting theory</h1></div></div></div><p>The problem <a id="id178" class="indexterm"/>of detecting a face in an image can be posed in a simpler way. We could iterate the whole image through several smaller windows and create a classifier that will tell whether a window is a face or not. The windows that correctly identify the face will be the coordinates of face detection.</p><p>Now, what exactly is a classifier and how can it be built? In machine learning, the problem of classification has been deeply explored and it is posed as the identification of which of the set of categories a given observation belongs to, based on a <a id="id179" class="indexterm"/>previously trained set of known category memberships. This could be something like if a given image belongs to the banana, apple, or grape category, for instance, in a fruit classification application. In the case of face detection, there are two categories—face and non-face.</p><p>This section describes a meta-algorithm, which is basically a templated algorithm to create a strong classifier using a set of weak learners. These weak learners are classifiers based on some features that although not able to divide the whole set in the two categories, they do a good job for some of the sets. Let's say that a weak learner could be a classifier that looks for a mustache in order to tell whether a given face is of a man. Even if it might not find all men in the set, it will do a good job for the ones who have mustaches.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec14"/>AdaBoost</h2></div></div></div><p><strong>AdaBoosting</strong>, from <a id="id180" class="indexterm"/>Adaptive Boosting, is not actually an algorithm, but it's a meta-algorithm that will help us with building a classifier. Its main mission is to build a great classifier out <a id="id181" class="indexterm"/>of weak classifiers, which are just better by chance. Its final form is a weighted combination of the given classifiers, as given in the following equation:</p><div><img src="img/3972OS_05_05.jpg" alt="AdaBoost"/></div><p>The sign operator will return <code class="literal">+1</code> when the expression in parenthesis is positive, and <code class="literal">-1</code> otherwise. Note that it is a binary classifier that yields <em>yes</em> or <em>no</em>, or it could be <em>does belong</em> or <em>does not belong</em>, or simply <code class="literal">+1</code> or <code class="literal">-1</code>. So, <img src="img/3972OS_05_06.jpg" alt="AdaBoost"/> is the weight assigned to the given classifier <img src="img/3972OS_05_07.jpg" alt="AdaBoost"/> for a given input <em>x</em> in a set of <em>T</em> classifiers.</p><p>For instance, in a group of people, one wants to know whether any given person <em>p</em> is a man or woman. Let's say we have some weak classifiers, which are good guesses, such as:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><img src="img/3972OS_05_08.jpg" alt="AdaBoost"/>: If the height is greater than 5 feet and 9 inches (~175 cm), then the person is a male or else female. Of course, there are several women taller than men, but on an average, men are taller.
</li><li class="listitem" style="list-style-type: disc"><img src="img/3972OS_05_09.jpg" alt="AdaBoost"/>: If a person has long hair, then the person is a female or else male. Again, there are several long haired men, but, on an average, women usually have longer hair.
</li><li class="listitem" style="list-style-type: disc"><img src="img/3972OS_05_10.jpg" alt="AdaBoost"/>: If a person has a beard, then the person is a male or else female. Here, we can misclassify shaved men.
</li></ul></div><p>Let's say we have this random set of people:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Name/Feature</p>
</th><th style="text-align: left" valign="bottom">
<p>Height (h1)</p>
</th><th style="text-align: left" valign="bottom">
<p>Hair (h2)</p>
</th><th style="text-align: left" valign="bottom">
<p>Beard (h3)</p>
</th><th style="text-align: left" valign="bottom">
<p>Gender (f(x))</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Katherine</p>
</td><td style="text-align: left" valign="top">
<p>1.69</p>
</td><td style="text-align: left" valign="top">
<p>Long</p>
</td><td style="text-align: left" valign="top">
<p>Absent</p>
</td><td style="text-align: left" valign="top">
<p>Female</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Dan</p>
</td><td style="text-align: left" valign="top">
<p>1.76</p>
</td><td style="text-align: left" valign="top">
<p>Short</p>
</td><td style="text-align: left" valign="top">
<p>Absent</p>
</td><td style="text-align: left" valign="top">
<p>Male</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Sam</p>
</td><td style="text-align: left" valign="top">
<p>1.80</p>
</td><td style="text-align: left" valign="top">
<p>Short</p>
</td><td style="text-align: left" valign="top">
<p>Absent</p>
</td><td style="text-align: left" valign="top">
<p>Male</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Laurent</p>
</td><td style="text-align: left" valign="top">
<p>1.83</p>
</td><td style="text-align: left" valign="top">
<p>Short</p>
</td><td style="text-align: left" valign="top">
<p>Present</p>
</td><td style="text-align: left" valign="top">
<p>Male</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Sara</p>
</td><td style="text-align: left" valign="top">
<p>1.77</p>
</td><td style="text-align: left" valign="top">
<p>Short</p>
</td><td style="text-align: left" valign="top">
<p>Absent</p>
</td><td style="text-align: left" valign="top">
<p>Female</p>
</td></tr></tbody></table></div><p>Classifier <code class="literal">h1</code> will <a id="id182" class="indexterm"/>correctly<a id="id183" class="indexterm"/> classify three people, while <code class="literal">h2</code> will get it right for four people, and <code class="literal">h3</code> will work for three people. We would then select <code class="literal">h2</code>, which was the best, for the one that minimizes the weighted error, and set its alpha. We would then increase weight for wrongly classified data (Sara) and decrease weight for all the others (Katherine, Dan, Sam, and Laurent). We would then look for the best classifier on the new distribution. Now that Sara is on the spot, either <code class="literal">h2</code> or <code class="literal">h3</code> would be selected, depending on the error, since <code class="literal">h1</code> gets Sara wrong with a higher weight. We would then continue for the <code class="literal">T</code> weak classifiers, in our case 3.</p><p>The algorithm for AdaBoost goes like this:</p><div><img src="img/3972OS_05_02.jpg" alt="AdaBoost"/></div><p>Fortunately, OpenCV already implements boosting. The following example can be found in the <code class="literal">boost</code> project from <code class="literal">Chapter 5</code>, and it shows how to deal with the <code class="literal">Boost</code> class, with the preceding example. We first create a 5 x 3 matrix called <code class="literal">data</code>. This matrix stores our training dataset, and will be used by <code class="literal">Boost</code> to create a classifier. Then, we feed the matrix just like in the preceding table. The first column is the height. Hair and beard are given values one or zero. When the hair is short, we put <code class="literal">zero</code>, when it's long, we put <code class="literal">one</code>. In case the beard is present, its value is <code class="literal">one</code> or else <code class="literal">zero</code>. These values are set using the Mat's <code class="literal">put</code> function. Note that the fact of being a man or a woman does not go into the <code class="literal">data</code> matrix since it is actually the output we want for our classifier. This way, a 5 x 1 column matrix <code class="literal">responses</code> is created. It simply stores <code class="literal">zero</code> for female and <code class="literal">one</code> for male.</p><p>Then, a <code class="literal">Boost</code> class is instantiated, and we set parameters for the training through the <code class="literal">CvBoostParams</code> its setters. We have set the boost type to<a id="id184" class="indexterm"/> be <strong>Discrete Adaboost</strong> using the <code class="literal">setBoostType</code> method, passing <code class="literal">Boost.DISCRETE</code> as a parameter. Other variants of boosting are known <a id="id185" class="indexterm"/>as <strong>Real AdaBoost</strong>, <strong>LogitBoost</strong>, and <strong>Gentle AdaBoost</strong>. The setWeakCount method sets the number <a id="id186" class="indexterm"/>of weak classifiers <a id="id187" class="indexterm"/>used. In our case, it was <code class="literal">3</code>. The next <a id="id188" class="indexterm"/>setting tells <a id="id189" class="indexterm"/>that if the number of samples in a node is less than this parameter, then the node will not be split. Actually, the default value is <code class="literal">10</code>, and it won't work with such a small dataset, so it is set to <code class="literal">4</code> so that it will work with this dataset. It is important to note that Boost derives from DTrees, which is decision-trees related. That's why, it uses the node terminology.</p><p>After parameters are set, the boost classifier is trained using the <code class="literal">data</code> and <code class="literal">responses</code> matrices through the <code class="literal">train</code> method. Here follows this method signature:</p><div><pre class="programlisting">public boolean train(Mat trainData, int tflag, Mat responses)</pre></div><p>This is the <code class="literal">trainData</code> training matrix with the features, and the <code class="literal">responses</code> matrix is the one with classification data. The <code class="literal">tflag</code> parameter will tell whether the features are put in rows or columns.</p><p>After that, predicting is a simple matter of creating a new row matrix with the input parameters for height, hair size, and beard presence, and passing it to the <code class="literal">Boost</code> <code class="literal">predict</code> function. Its output will classify the input as male or female:</p><div><pre class="programlisting">public class App
{
  static{ System.loadLibrary(Core.NATIVE_LIBRARY_NAME); }
  
  public static void main(String[] args) throws Exception {
    
    Mat data = new Mat(5, 3, CvType.CV_32FC1, new Scalar(0));
    
    data.put(0, 0, new float[]{1.69f, 1, 0});
    data.put(1, 0, new float[]{1.76f, 0, 0});
    data.put(2, 0, new float[]{1.80f, 0, 0});
    data.put(3, 0, new float[]{1.77f, 0, 0});
    data.put(4, 0, new float[]{1.83f, 0, 1});
    
    Mat responses = new Mat(5, 1, CvType.CV_32SC1, new Scalar(0));
    
    responses.put(0,0, new int[]{0,1,1,0,1});
    
   
    
    Boost boost = Boost.create();
    boost.setBoostType(Boost.DISCRETE);
    boost.setWeakCount(3);
    boost.setMinSampleCount(4);
    
    boost.train(data, Ml.ROW_SAMPLE, responses);
    
    //This will simply show the input data is correctly classified
    
    for(int i=0;i&lt;5;i++){
      System.out.println("Result = " + boost.predict(data.row(i)));
    }
    
    Mat newPerson = new Mat(1,3,CvType.CV_32FC1, new Scalar(0));
    newPerson.put(0, 0, new float[]{1.60f, 1,0});
    System.out.println(newPerson.dump());
    System.out.println("New (woman) = " + boost.predict(newPerson));
    
    newPerson.put(0, 0, new float[]{1.8f, 0,1});
    System.out.println("New (man) = " + boost.predict(newPerson));
    
    newPerson.put(0, 0, new float[]{1.7f, 1,0});
    System.out.println("New (?) = " + boost.predict(newPerson));
    
  }
}</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec41"/>Cascade classifier detection and training</h1></div></div></div><p>One might be wondering how OpenCV could detect faces as this would be a very straightforward task for a couple-of-month old baby, and it looks quite complicated to tell a computer how to accomplish it. We will divide the problem in two parts—<em>object detection</em>, which is applying a classifier and retrieving the object position when the classifier says so, and <em>training</em> a new classifier to learn new objects that should be mostly rigid.</p><p>OpenCV Cascade Classifier initially implemented a face-detection technique known as the <em>Viola-Jones</em> detector, first developed by Paul Viola and Michael Jones, which uses the so-<a id="id190" class="indexterm"/>called Haar-like features, named after Alfréd Haar wavelets. These features are based on thresholds of sums and differences of rectangular regions of raw image values. Later, this classifier also enabled the use <a id="id191" class="indexterm"/>of <strong>Local Binary Patterns</strong> (<strong>LBP</strong>) features, which are integer values in contrast to Haar-like features; this results in faster training times, but similar quality.</p><p>Although using a <a id="id192" class="indexterm"/>cascade classifier in OpenCV is quite straightforward, it is important to know how it works to understand the usage boundaries. As a thumb rule, it should work fine on objects that are consistently textured and mostly rigid. The cascade classifier is presented with a set of size and histogram equalized images that are labeled as either containing or not containing an interest object. The classifier iterates through several smaller windows that cover the whole image, so it will tend to rarely find an object. For instance, group pictures will have faces in just a couple of coordinates, while the rest of the image should be labeled as not having a face. Since it should maximize rejection, the OpenCV cascade classifier uses a form of AdaBoost classifier organized as a rejection cascade, which means non-object patches should be dropped as early as possible.</p><p>Features thresholds can be used as weak classifiers to build a strong classifier using AdaBoost, as we have learned in this chapter. After we calculate a feature, we can decide on this question: <em>Is this value above or below a given threshold?</em> If the answer is <code class="literal">true</code>, the object is a face, for instance, or else it is not. We generally use a single feature for this decision, but this number can be set in training. Using AdaBoost, we build the classifier as a weighted sum of the weak classifiers like this:</p><div><img src="img/3972OS_05_03.jpg" alt="Cascade classifier detection and training"/></div><p>Here, <img src="img/3972OS_05_13.jpg" alt="Cascade classifier detection and training"/> is the function associated to each feature <code class="literal">i</code>, which returns <code class="literal">+1</code> in case the feature value is above some threshold and <code class="literal">-1</code> in case it is below. Boosting is used to correctly quantify <a id="id193" class="indexterm"/>each of the weights <img src="img/3972OS_05_14.jpg" alt="Cascade classifier detection and training"/> related to the features. The Viola-Jones classifier builds each node of the tree as the signal of a weighted sum, like in the function <code class="literal">F</code>. Once this function is set, it yields a node for the Viola-Jones classifier, and all the surviving data from higher up in the cascade is then used to train the next node and so on. The final tree looks similar to this:</p><div><img src="img/3972OS_05_04.jpg" alt="Cascade classifier detection and training"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec42"/>Detection</h1></div></div></div><p>OpenCV already <a id="id194" class="indexterm"/>comes with several previously-trained cascades that are ready to be used. Among them, we can find front and profile face detectors as well as eye, body, mouth, nose, lower-body, and upper-body detectors. In this section, we will cover how to use them. The complete source can be found in the project <code class="literal">cascade</code> in this chapter.</p><p>The following code shows how to load a trained cascade:</p><div><pre class="programlisting">private void loadCascade() {
  String cascadePath = "src/main/resources/cascades/lbpcascade_frontalface.xml";
  faceDetector = new CascadeClassifier(cascadePath);
}</pre></div><p>Most of the action happens in the class <code class="literal">CascadeClassifier</code>, from the <code class="literal">objdetect</code> package. This class wraps cascade loading and object detection. The constructor with strings already loads the cascade from the given path. In case you want to postpone the cascade name, you can use the empty constructor and the <code class="literal">load</code> method.</p><p>The <code class="literal">runMainLoop</code> method, which is not shown here, will simply grab an image from the webcam and pass it to <code class="literal">detectAndDrawFace</code>, which will put the initialized classifier to work. The following is the <code class="literal">detectAndDrawFace</code> method:</p><div><pre class="programlisting">private void detectAndDrawFace(Mat image) {
  MatOfRect faceDetections = new MatOfRect();
  faceDetector.detectMultiScale(image, faceDetections);
  for (Rect rect : faceDetections.toArray()) {
    Core.rectangle(image, new Point(rect.x, rect.y), new Point(rect.x + rect.width, rect.y + rect.height), new Scalar(0, 255, 0));
  }
}</pre></div><p>Firstly, we instantiate the <code class="literal">faceDetections</code> object, which is a <code class="literal">MatOfRect</code> container (a special container for <code class="literal">Rect</code>). Then, we run the <code class="literal">detectMultiScale</code> method, passing the received image <a id="id195" class="indexterm"/>and the <code class="literal">MatOfRect</code> as parameters. This is where the cascade detector is run. The algorithm will scan the image using a sliding window, running the cascade classifier for each of the windows. It will also run this procedure with different scales of the image. By default, it will reduce the image scale by 1.1 for each attempt. In case at least three detections happen, also by default, in three different scales, the coordinate is considered a hit, and it will be a part of the <code class="literal">faceDetections</code> array, added to the width and height of the detected object.</p><p>The <code class="literal">for</code> loop simply iterates through the returned rectangles and draws them in green over the original image.</p></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec43"/>Training</h1></div></div></div><p>Although OpenCV is already <a id="id196" class="indexterm"/>packaged with several cascade classifiers, there might be a need for detecting some particular object, or class of object, of your choice. Creating a custom cascade classifier is not straightforward since it requires thousands of images from which all the variance should be removed. For instance, if a classifier for faces is being created, all the images should have their eyes aligned. In this section, we will describe the process of creating a cascade classifier using OpenCV.</p><p>In order to train a cascade, some tools have been provided in OpenCV. They can be found in the <code class="literal">opencv/build/x86/vc11/bin</code> directory. The <code class="literal">opencv_createsamples</code> and <code class="literal">opencv_traincascade</code> executables are used for preparing a training dataset of positive samples and for generating the cascade classifier, respectively.</p><p>In order to give a good idea of the process, we have included files from UIUC Image Database for Car Detection, collected by Shivani Agarwal, Aatif Awan, and Dan Roth. These files are available in the <code class="literal">cardata</code> directory from <code class="literal">Chapter 5</code>. The following instructions rely on being at this folder to work.</p><div><div><h3 class="title"><a id="note08"/>Note</h3><p><strong>Positive samples – pictures that contain the target image</strong></p><p>Negative samples are the arbitrary images that must not contain the object that is intended to be <a id="id197" class="indexterm"/>detected.</p></div></div><p>To create your own cascade classifier, gather hundreds of pictures of the target, making sure that these pictures show enough variance to give a good idea of the class of the object being detected.</p><p>Then, use the <code class="literal">opencv_createsamples</code> tool to prepare a training dataset of positive and test samples. This yields a binary file with the <code class="literal">.vec</code> extension, which contains positive samples generated from a given marked up dataset. No distortion is applied; they are only resized to target samples' size and stored in the <code class="literal">vec-file</code> output. The reader should issue the following command:</p><div><pre class="programlisting">opencv_createsamples -info cars.info -num 550 -w 48 -h 24 -vec cars.vec.</pre></div><p>The preceding command will read file <code class="literal">cars.info</code>, which contains, in each line, the path to an image followed by a number <em>n</em>. This number is the quantity of object instances present in the image. Following this, there are <em>n</em> coordinates of the object bounding <code class="literal">rectangle (x, y, width, height)</code>. These are the examples of valid lines:</p><div><pre class="programlisting">images/image1.jpg  1  90 100 45 45
images/image2.jpg  2  200 300 50 50   100 30 25 25</pre></div><p>The parameters <code class="literal">-w</code> and <code class="literal">-h</code> give the width and height of the output samples that we want to be generated. This should be kept small enough so that in the image we are searching for object in the later object detection, the size of the object in the image will be greater than this size. The <code class="literal">-num</code> parameter tells the number of these samples.</p><p>In order to create a classifier for a given <code class="literal">.vec</code> file, use the <code class="literal">opencv_traincascade</code> tool. This application will read positive samples from the file given through the <code class="literal">-vec</code> parameter as well as some negative samples from a file given by the <code class="literal">-bg</code> parameter. The negative samples file simply points to an image in each of the lines, which are arbitrary ones and must not contain the object that is intended to be detected. In order to use this tool, issue the following command:</p><div><pre class="programlisting">opencv_traincascade -data data -vec cars.vec -bg cars-neg.info -numPos 500 -numNeg 500 -numStages 10 -w 48 -h 24 -featureType LBP</pre></div><p>The parameters <code class="literal">-numPos</code> and <code class="literal">-numNeg</code> are used to specify the number of positive and negative samples used in training for every classifier stage, while <code class="literal">-numStages</code> specifies the number of cascade stages to be trained. The last <code class="literal">-featureType</code> parameter sets which type <a id="id198" class="indexterm"/>of feature is to be used and can be selected from Haar-like features or LBP. As stated before, LBP features are integer values in contrast to Haar features, so detection and training will be much faster with LBP, but their quality can be the same, depending on the training. More parameters can be used to fine-tune the training, such as the false alarm rate, maximum tree depth, and minimal hit rate. The reader should refer to documentation for these settings. Now, regarding the training time, even on fast machines, it can take from a couple of hours to a few days. But, if you don't want to wait for final results, and are impatient to check how the classifier would work, you can get the intermediate classifier XML file using the following command:</p><div><pre class="programlisting">convert_cascade --size="48x24" haarcascade haarcascade-inter.xml</pre></div><p>Here <code class="literal">48</code> and <code class="literal">24</code> are the width and height for minimum possible detection and are similar to <code class="literal">–w</code> and <code class="literal">–h</code> in the <code class="literal">opencv_traincascade</code> command.</p><p>Once you have issued the previous command, a file called <code class="literal">cascade.xml</code> is created in the folder passed as the <code class="literal">-data</code> parameter. Other files created in this folder can be safely deleted after training has been succeeded. Now, it can be loaded and used through the <code class="literal">CascadeClassifier</code> class, just as described in the preceding <em>Detection</em> section. Simply use this file instead of the <code class="literal">lbpcascade_frontalface.xml</code> file given in that example.</p><p>The following screenshot shows one correct detection of a toy car using the trained cascade as well as one wrong detection, which is a false positive:</p><div><img src="img/3972OS_05_01.jpg" alt="Training"/></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec44"/>References</h1></div></div></div><p>Refer to the video, <em>OpenCV Tutorial: Training your own detector</em>, <em>Packt Publishing</em>, (<a class="ulink" href="https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video">https://www.packtpub.com/application-development/opencv-computer-vision-application-programming-video</a>) by Sebastian Montabone.</p></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec45"/>Summary</h1></div></div></div><p>This chapter has provided the reader with several interesting concepts. We have covered a solid background on the boosting theory as well as working on a practical example. Then, we also covered OpenCV's Viola-Jones cascade classifier, and a hands-on approach was applied in order to use a classifier through the <code class="literal">CascadeClassifier</code> class. After that, we covered a complete, real-world example for creating a new car classifier, which can be adapted for any mostly rigid object of your preference.</p><p>In the next chapter, we will study and practice the field of background subtraction using pure image-processing methods through frame differencing and averaging background, and the interesting Kinect device for depth maps.</p></div></body></html>