- en: Probabilistic Graphical Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get into **Bayesian network** (**BN**) concepts, we should be aware
    of the theories of probability. So, we will try to touch upon them and build the
    foundation of BNs.
  prefs: []
  type: TYPE_NORMAL
- en: We already know that probability is the degree of certainty/uncertainty of an
    event occurring. However, it can be also termed as the degree of belief, which
    is more commonly used when we talk about BN.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we toss a fair coin, we say that the degree of belief around the event
    of heads/tails happening is *0.5*. It implies that our belief of heads happening
    is as strong as tails. The probability can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p(Heads)=p(tails)=0.5*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will cover a few key concepts before moving on to the body of the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of discrete distribution, a probability mass function is used to
    find out the probability, *p(X= x),* where *X* is a discrete random variable and
    *x* is a real value number.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of continuous distribution, probability density function is used
    to find out the probability *p(X <= x)*. In this scenario, a probability curve
    is plotted and the area under the curve (integration) helps us with the probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conditional probability is to understand this, a cricket match can be the perfect
    example. Suppose there is a game scheduled between India and Australia and we
    are trying to pass on our belief of India triumphing. Do you think that the probability
    will be impacted by the team selected by India? Will the probability of India
    winning the match be impacted if *Virat Kohli* and *Rohit Sharma* are part of
    the team? So, *p(India winning|Rohit and Virat are playing)* denotes the probability
    of India winning, given that *Rohit* and *Virat* are playing. Essentially, it
    means that the probability of one event is dependent on the probability of another
    event. It is called **conditional probability**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The probability of *x*, given *y*, can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d915c396-9cd1-4e99-a87b-87d09498b0a7.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/2d7ed028-8228-43d2-9fa1-cc9eef4f53bf.png)'
  prefs: []
  type: TYPE_IMG
- en: The chain rule computes the joint distribution of a set of random variables
    using their conditional probabilities. From conditional probability, we know that ![](img/0d8baa2a-6492-4518-a44b-2a2b63b30ea9.png).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It implies that if there are ![](img/0672cc86-ade2-4aaf-836a-b708c703e6a4.png)
    events. The joint probability distribution turns out like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46cd6ec1-a45e-40fa-8b9c-b1a4a9599281.png)'
  prefs: []
  type: TYPE_IMG
- en: Bayes rule
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bayes rule is one of the building blocks of probability theory. It stems from
    conditional probability and joint probability and extends beyond.
  prefs: []
  type: TYPE_NORMAL
- en: We will explain this in a simple way by again taking an example from cricket.
    In cricket, pitch condition varies as you go from one place to another and it
    is one of the factors that can be significant when deciding the team. The outcome
    can also be dependent upon it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say the Indian team goes to Australia for a game and we have to predict
    the belief of an Indian player scoring a century (100 runs) in the game. If that
    player has got experience of playing in that country, we might say with strong
    belief that he might score a century. But, there is another player who is a first-timer
    in this country. What would the the prior belief be for him? Of course, many would
    have less belief that he would score a century.
  prefs: []
  type: TYPE_NORMAL
- en: However, our prior belief will change as we see the way the player is performing.
    That is, more data about the player will be at our disposal as more games are
    played by that player. Based on that, posterior belief will keep getting updated.
    It changes a lot, largely due to the observations or more data (which is called
    **likelihood**). Bayes rule is based on these concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that *A[i]* forms a mutually exhaustive event with *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c0b99e6-fbc9-4a8a-82a8-ed1d6c118885.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The probability of *B* will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc060e81-1231-4d98-9a89-0ea9f32c00dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We get the probability of B from conditional probability like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47e9c056-9487-4eef-8f0a-4b9e52d70eee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Hence:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/83f0e512-2d1b-41a9-ab86-40bab786697f.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/49120dc1-9adc-4b5c-9077-4d270ce66994.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, extracting the value of ![](img/263394a6-45d1-4214-aa22-754050d46121.png)from
    equation 2 and putting it in equation 1, we get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5f4ca75-60d9-4d37-9aed-e8230fa8d3a8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After replacing the value of *P(B)* from the preceding equation, we get this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ea3cba87-2548-4ee7-a977-c03b76bd40c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Have a look at equation 3 first. This is called **Bayes rule**.
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A|B)* is called **posterior**, which needs to be estimated. In the preceding
    example, this would be the probability of scoring a century given that the player
    has got the earlier experience of playing there.'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(B|A)* is called the **likelihood**, which is the probability of observing
    the new evidence, given our initial hypothesis. For example, the probability of
    a player having previous experience in playing cricket get to score a century.'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A)* is called the **prior**, which is the probability of our hypothesis
    without any additional prior information.'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(B)* is called the **marginal likelihood**, which is the total probability
    of observing the evidence.'
  prefs: []
  type: TYPE_NORMAL
- en: Bayes network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bayes network is a type of probabilistic graphical model that can be used to
    build models to address business problems. Applications of this are quite wide.
    For example, it can be used in anomaly detection, predictive modeling, diagnostics,
    automated insights, and many other applications.
  prefs: []
  type: TYPE_NORMAL
- en: It is totally understandable that a few words used here would have been alien
    to you till now. For example, what do we mean by graphical here?
  prefs: []
  type: TYPE_NORMAL
- en: 'A graph forms out of a set of nodes and edges. Nodes are represented by *N={N1,N2…..Nn}*,
    where independent variables are sitting at every node. Edges are the connectors
    between nodes. Edges can be denoted by *E={E1, E2…..En}* and can be of two types:'
  prefs: []
  type: TYPE_NORMAL
- en: Directed, represented by ![](img/843f2b04-9067-42f3-8aac-5703ddad0bd4.png)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Undirected, represented by:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/dc8df9c5-ea52-4fe6-a967-8a6cbe2d18fa.png)'
  prefs: []
  type: TYPE_IMG
- en: With the help of nodes and edges, a relationship between the variables is exhibited.
    It can be a conditional independence relationship or a conditional dependence
    relationship. BN is one a techniques that can introduce causality amongst variables.
    Although causality is not an essential part of it, having this (causality) in
    the network can make the structure quite compact.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see it through an example. There are a number of variables, such as
    waking up late, an accident on the highway, a rainy day, a traffic jam, they will
    be late for work, and being late for a meeting. If an individual has got up late,
    it means being late for work. An accident on the highway can cause a traffic jam
    and, in turn, this will result in being late for work. On a rainy day, the roads
    can be more prone to accidents and, also, there can be slow-moving traffic that
    will cause a traffic jam and, in turn, this will result in being late for work.
    The following diagram explains the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b493814-db85-499c-adc3-b85469f6d528.png)'
  prefs: []
  type: TYPE_IMG
- en: This kind of network is called a **directed acyclic graph**. Acyclic means that
    there is no cycle in the network. We are talking about a relationship between
    variables here. For example, waking up late and being late for a meeting are typically
    not independent. But they are conditionally independent, given being late for
    work.
  prefs: []
  type: TYPE_NORMAL
- en: Also, it might seem that waking up late has no connection and relationship with
    an accident on the highway. That is, they may appear to be independent of each
    other. However, if you know the value of being late for work, then these two can
    be called conditionally independent.
  prefs: []
  type: TYPE_NORMAL
- en: So, BN allows conditional independence between nodes. At the same time, it is
    an efficient representation of joint probability distribution, which is enabled
    by a chain rule.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that X represents n independent variables or nodes. Arcs or a directed
    arrow represents the probabilistic dependence or independence amongst variables.
    An absence of an arc would mean probabilistic independence. The network is a directed
    acyclic graph wherein the local probability distribution is kept at each node,
    which is also called the **conditional probability table** (**CPT**).
  prefs: []
  type: TYPE_NORMAL
- en: If we talk about the previous network, then we need the probability distribution
    required to address the whole network. For the purpose of simplicity, we will
    keep all the nodes as Boolean.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilities of nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's look at the probability at each node and find out how many probabilities
    would appear there.
  prefs: []
  type: TYPE_NORMAL
- en: 'The nodes carrying **Late Wake-up** and **Rainy Day** are the parent nodes
    as there are no nodes leading to such nodes. The different nodes can be seen in
    the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Node (Late Wake-up)**: Being one of the parent nodes, we will be looking
    just to find out the probability of waking up late. Hence, the count of probability
    to be found out is 1 here.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Node (Rainy Day)**: Like the late wake-up node, the count of probability
    is 1 here as well.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Node (Accident on the highway)**: As it is a child node of rainy day, it
    talks about the probability of the accident given the rainy day and the probability
    of the accident given it''s not a rainy day. So, the count of probability is 2
    here.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Node (Traffic Jam)**: It has got two parents (rainy day and accident). Rainy
    day has got two values, which are true and false, the same as accident. Combining
    both will yield four different combinations. Hence, the count of probability will
    be 4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Node (Late for work) and Node (Late for meeting)**: A similar explanation
    applies to these two nodes as well. The count for the probabilities of these is
    4:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4ed44c12-fbe1-4882-b3c3-8e62ccabe38a.png)'
  prefs: []
  type: TYPE_IMG
- en: The total number of probabilities are 1 + 2 + 1 + 4 + 4 + 4 = 16.
  prefs: []
  type: TYPE_NORMAL
- en: 'Had it been just a normal joint probability distribution instead of BN, we
    would have had 2⁶-1 probabilities. Hence, BN makes the network quite compact.
    Also, another more basic assumption we have to be mindful of is that each node
    is conditionally independent of its non-descendants given its immediate parents.
    For example, waking up late and being late for a meeting are conditionally independent
    in the case that **late for work** is also there. Generally, we can express BN
    in the following manner, which displays how joint distribution can be translated
    into a compact structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/422192d3-e973-47a9-a21d-db60c6679cf0.png)'
  prefs: []
  type: TYPE_IMG
- en: If *G* is the graph, *X[i] *is a node in the graph *G*, and *P* are the parents of
    the *X[i] *node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few notes about the equations:'
  prefs: []
  type: TYPE_NORMAL
- en: The right-hand side of the equation is the application of the chain rule, which
    exhibits conditional independence relations. It is a graph-structured approximation
    of the joint probability distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, the graph has to be acyclic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can provide the convenience to display the relationship among various events.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s take a simple scenario to showcase the CPT. The following is the
    combination of three events as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If it rains, the dog starts barking and the man skips work:'
  prefs: []
  type: TYPE_NORMAL
- en: Probability of rain (yes/no)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability that the dog will bark (yes/no)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability that the man will skip work (yes/no)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s have the network prepared as a directed acyclic graph. All these nodes
    reflect an event, and directed arrows are conditional probabilities. We will see
    here how to read this graph:'
  prefs: []
  type: TYPE_NORMAL
- en: Connector 1 indicates the probability of the dog barking if it rains
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connector 2 indicates the probability of the man skipping his work if the dog
    barks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the flow chart for both the probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db88ed17-07f6-443a-951d-a166d5bd2681.png)'
  prefs: []
  type: TYPE_IMG
- en: CPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s do the CPT for connector 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **The dog barks** | **The dog doesn''t bark** | **Aggregate** |'
  prefs: []
  type: TYPE_TB
- en: '| It rains |                10 |               4 |           14 |'
  prefs: []
  type: TYPE_TB
- en: '| It doesn''t rain |                 8 |               5 |           13 |'
  prefs: []
  type: TYPE_TB
- en: '| Aggregate |               18 |               9 |           27 |'
  prefs: []
  type: TYPE_TB
- en: 'Here, we are talking about the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Probability *(Dog barks|It rains) = 10/14*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability *(Dog doesn't bark | It rain) = 4/14*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability *(Dog barks | It doesn't rain) = 8/13*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability *(Dog doesn't bark | It doesn't rain) = 5/13*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|  | ** The dog barks** | ** The dog doesn''t bark** |'
  prefs: []
  type: TYPE_TB
- en: '| It rains |                10/14 |               4/14 |'
  prefs: []
  type: TYPE_TB
- en: '| It doesn''t rain |                 8/13 |               5/13 |'
  prefs: []
  type: TYPE_TB
- en: 'The following diagram shows the probabilities in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/538aa2c0-2f3d-4f2a-8474-75084cc619ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's say if the probability of *rain = P(rain) =0.6* then the probability of
    *no rain = P(no rain) = 0.4*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that the CPT for the man skipping work is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ** The man skips work** | ** The man doesn''t skip work** |'
  prefs: []
  type: TYPE_TB
- en: '| The dog barks |                0.8 |               0.2 |'
  prefs: []
  type: TYPE_TB
- en: '| The dog doesn''t bark |                0.3 |               0.7 |'
  prefs: []
  type: TYPE_TB
- en: The probability of every event has to be calculated with respect to the parent
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'And now, we are supposed to find out the probability of *the man skipping work
    and the dog barks but it doesn''t rain = P (Man skips work, the dog barks, it
    doesn''t rain)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*= P (Man skips work|the dog barks) *P (the dog barks|it doesn''t rain) *P(it
    doesn''t rain)*'
  prefs: []
  type: TYPE_NORMAL
- en: '*=0.8 * (8/13) *0.4*'
  prefs: []
  type: TYPE_NORMAL
- en: '*=0.1969*'
  prefs: []
  type: TYPE_NORMAL
- en: Example of the training and test set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a use case and work it out in Python. We are going to use Titanic
    data from Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data has been split into two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: Training set (`train.csv`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test set (`test.csv`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data is about the passengers who traveled on the Titanic. It captures their
    features:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pclass`: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gender`: Gender'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Age`: Age in years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sibsp`: Number of siblings/spouses aboard the Titanic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parch`: Number of parents/children aboard the Titanic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ticket`: Ticket number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fare Passenger`: Fare'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cabin`: Cabin number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`embarked`: Port of embarkation `C = Cherbourg`, `Q = Queenstown`, and `S =
    Southampton`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have got to build the model to predict whether or not they survived the
    sinking of the Titanic. Initially, import the parameters as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We are loading the datasets here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We have to look for the number of unique values for each variable since BNs
    are discrete models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/369f0c2b-19d4-460a-b90e-1ccaef31c735.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to save our system from too much computation and to avoid load on
    it, we will reduce the number of variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following  output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/71bcddd7-91e1-4575-8709-56c819730aef.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we are left with six variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we have to discretize continuous variables in case they needs to be made
    part of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7ead451e-3999-4bf8-ae9b-fc81d5e89ff8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s do the pre-processing now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'For `traindf` and `testdf`, we use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to save this data, since the `pyAgrum` library accepts only files as
    inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/951fb491-5531-4d0a-96ff-1048878d600b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it''s time to build the model. Here, you need to be watchful while choosing
    the `RangeVariable` and `LabelizedVariable` variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc93a989-6af8-416f-9bdb-bcee069b4e22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For `learnBN()`, we use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/025f896e-13c7-4d3e-b6e7-c642d2518f37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have the model, let''s try to extract the information from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8cc11cf8-4fbc-4674-af45-8c6f08f34bdc.png)'
  prefs: []
  type: TYPE_IMG
- en: The entropy of a variable means that the greater the value, the more uncertain
    the variable's marginal probability distribution is. The lower the value of entropy,
    the lower the uncertainty. The `Decade` variable has got the highest entropy,
    which means that it is evenly distributed. Parch has got low entropy and distribution
    is non-even.
  prefs: []
  type: TYPE_NORMAL
- en: A consequence of how entropy is calculated is that entropy tends to get bigger
    if the random variable has many modalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding the inference gives us a view of the marginal probability distribution
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1187b06c-9572-4108-ad35-05dbd51037e7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s see how classification can be done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb4a872f-7093-4004-b45e-6da27d41c44e.png)'
  prefs: []
  type: TYPE_IMG
- en: More than 40% of passengers survived here. But, we are not pushing any conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we want to find out what the chances of a young male surviving are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8485e3f0-faa9-4022-ac86-f8121bf48189.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the chances are 20.6%.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we have to find out the chances of an old lady surviving, we go about it
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ff5217b-890f-4ca3-aee7-e437280a3e31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, in order to evaluate the model to find out how good it is, we will plot
    the ROC curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c257983-9e0b-4b3d-bada-0acb872a5b45.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, **AUC** comes out to be **0.893508** and it's quite decent.
  prefs: []
  type: TYPE_NORMAL
- en: We are done with the modeling part here. Also, we have learned about probability
    theory, Bayesian networks, the calculation of CPT, and how to execute it in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has given us an understanding of probability theory. Also, the
    application of probability theory has been put into use. We got an idea of Bayes
    rule and BNs and how it is formed. We got our hands dirty with the calculation
    of a CPT.  Finally, we looked at a use case to understand how classification can
    be done with the help of BNs. The readers will now have the skill to have an in-depth
    knowledge of Bayes rules and BNs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will study selected topics in deep learning.
  prefs: []
  type: TYPE_NORMAL
