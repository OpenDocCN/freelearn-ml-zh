- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: The Machine Learning Development Process
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习开发过程
- en: In this chapter, we will define how the work for any successful **machine learning**
    (**ML**) software engineering project can be divided up. Basically, we will answer
    the question of how you *actually organize the doing* of a successful ML project.
    We will not only discuss the process and workflow but we will also set up the
    tools you will need for each stage of the process and highlight some important
    best practices with real ML code examples.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将定义如何将任何成功的**机器学习**（**ML**）软件工程项目的工作进行划分。基本上，我们将回答您如何*实际上组织一个成功的ML项目*的问题。我们不仅将讨论流程和工作流程，还将为流程的每个阶段设置所需的工具，并通过真实的ML代码示例突出一些重要的最佳实践。
- en: 'In this edition, there will be more details on an important data science and
    ML project management methodology: **Cross-Industry Standard Process for Data
    Mining** (**CRISP-DM**). This will include a discussion of how this methodology
    compares to traditional Agile and Waterfall methodologies and will provide some
    tips and tricks for applying it to your ML projects. There are also far more detailed
    examples to help you get up and running with **continuous integration/continuous
    deployment** (**CI/CD**) using GitHub Actions, including how to run ML-focused
    processes such as automated model validation. The advice on getting up and running
    in an **Interactive Development Environment** (**IDE**) has also been made more
    tool-agnostic, to allow for those using any appropriate IDE. As before, the chapter
    will focus heavily on a “four-step”methodology I propose that encompasses a *discover,
    play, develop, deploy* workflow for your ML projects. This project workflow will
    be compared with the CRISP-DM methodology, which is very popular in data science
    circles. We will also discuss the appropriate development tooling and its configuration
    and integration for a successful project. We will also cover version control strategies
    and their basic implementation, and setting up CI/CD for your ML project. Then,
    we will introduce some potential execution environments as the target destinations
    for your ML solutions. By the end of this chapter, you will be set up for success
    in your Python ML engineering project. This is the foundation on which we will
    build everything in subsequent chapters.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一版中，我们将更详细地介绍一个重要的数据科学和机器学习项目管理方法：**跨行业标准数据挖掘流程**（**CRISP-DM**）。这包括讨论这种方法与传统敏捷和瀑布方法的比较，并提供一些将此方法应用于您的机器学习项目的技巧和窍门。还有更多详细的示例，帮助您使用GitHub
    Actions开始**持续集成/持续部署**（**CI/CD**），包括如何运行专注于机器学习的流程，如自动模型验证。关于在**交互式开发环境**（**IDE**）中启动的建议也已经变得更加工具无关，以便使用任何合适的IDE。与之前一样，本章将重点介绍我提出的“四步”方法，该方法涵盖了您的机器学习项目的*发现、玩耍、开发、部署*工作流程。这个项目工作流程将与在数据科学领域非常流行的CRISP-DM方法进行比较。我们还将讨论适当的发展工具及其配置和集成，以确保项目成功。我们还将涵盖版本控制策略及其基本实施，以及为您的机器学习项目设置CI/CD。然后，我们将介绍一些潜在的执行环境，作为您的机器学习解决方案的目标目的地。到本章结束时，您将为您的Python机器学习工程项目成功做好准备。这是我们将在后续章节中构建一切的基础。
- en: As usual, we will conclude the chapter by summarizing the main points and highlighting
    what this means as we work through the rest of the book.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们将通过总结本章的主要观点并强调在阅读本书其余部分时这些观点的意义来结束本章。
- en: Finally, it is also important to note that although we will frame the discussion
    here in terms of ML challenges, most of what you will learn in this chapter can
    also be applied to other Python software engineering projects. My hope is that
    the investment in building out these foundational concepts in detail will be something
    you can leverage again and again in all of your work.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，值得注意的是，尽管我们在这里将讨论框架定为ML挑战，但本章中您将学到的许多内容也可以应用于其他Python软件工程项目。我的希望是，在详细构建这些基础概念的投资将能够让您在所有工作中反复利用。
- en: 'We will explore all of this in the following sections and subsections:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下章节和子章节中探讨所有这些内容：
- en: Setting up our tools
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置我们的工具
- en: 'Concept to solution in four steps:'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从概念到解决方案的四个步骤：
- en: Discover
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现
- en: Play
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玩耍
- en: Develop
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发
- en: Deploy
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: There is plenty of exciting stuff to get through and lots to learn – so let’s
    get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多令人兴奋的内容需要消化和很多知识需要学习——让我们开始吧！
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'As in *Chapter 1*, *Introduction to ML Engineering* if you want to run the
    examples provided here, you can create a Conda environment using the environment
    YAML file provided in the `Chapter02` folder of the book’s GitHub repository:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如同 *第 1 章*，*机器学习工程简介* 中所述，如果您想运行这里提供的示例，您可以使用本书 GitHub 仓库 `Chapter02` 文件夹中提供的环境
    YAML 文件创建一个 Conda 环境：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'On top of this, many of the examples in this chapter will require the use of
    the following software and packages. These will also stand you in good stead for
    following the examples in the rest of the book:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本章中的许多示例将需要使用以下软件和包。这些也将为你在本书其他部分的示例提供良好的基础：
- en: Anaconda
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda
- en: PyCharm Community Edition, VS Code, or another Python-compatible IDE
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCharm Community Edition，VS Code 或其他兼容 Python 的 IDE
- en: Git
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Git
- en: 'You will also need the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要以下内容：
- en: An Atlassian Jira account. We will discuss this more later in the chapter, but
    you can sign up for one for free at [https://www.atlassian.com/software/jira/free](https://www.atlassian.com/software/jira/free).
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Atlassian Jira 账户。我们将在本章后面进一步讨论这个问题，但您可以在[https://www.atlassian.com/software/jira/free](https://www.atlassian.com/software/jira/free)免费注册一个账户。
- en: An AWS account. This will also be covered in the chapter, but you can sign up
    for an account at [https://aws.amazon.com/](https://aws.amazon.com/). You will
    need to add payment details to sign up for AWS, but everything we do in this book
    will only require the free tier solutions.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 AWS 账户。这将在本章中讨论，但您可以在[https://aws.amazon.com/](https://aws.amazon.com/)注册一个账户。注册
    AWS 需要添加付款详情，但本书中我们将只使用免费层解决方案。
- en: The technical steps in this chapter were all tested on both a Linux machine
    running Ubuntu 22.04 LTS with a user profile that had admin rights and on a Macbook
    Pro M2 with the setup described in *Chapter 1*, *Introduction to ML Engineering.*
    If you are running the steps on a different system, then you may have to consult
    the documentation for that specific tool if the steps do not work as planned.
    Even if this is the case, most of the steps will be the same, or very similar,
    for most systems. You can also check out all of the code for this chapter in the
    book’s repository at [https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02).
    The repo will also contain further resources for getting the code examples up
    and running.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的技术步骤都在运行 Ubuntu 22.04 LTS 的 Linux 机器上进行了测试，该机器有一个具有管理员权限的用户配置文件，以及一个按照 *第
    1 章*，*机器学习工程简介* 中描述的设置运行的 Macbook Pro M2。如果您在运行不同系统上的步骤时，如果步骤没有按预期工作，您可能需要查阅该特定工具的文档。即使如此，大多数步骤对于大多数系统来说都将相同或非常相似。您还可以在本书的
    GitHub 仓库[https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Python-Second-Edition/tree/main/Chapter02)中查看本章的所有代码。该仓库还将包含进一步的资源，以帮助您将代码示例运行起来。
- en: Setting up our tools
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置我们的工具
- en: 'To prepare for the work in the rest of this chapter, and indeed the rest of
    the book, it will be helpful to set up some tools. At a high level, we need the
    following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备本章以及本书其余部分的工作，设置一些工具将会很有帮助。从高层次来看，我们需要以下工具：
- en: Somewhere to code
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于编码的地方
- en: Something to track our code changes
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于跟踪我们的代码更改的内容
- en: Something to help manage our tasks
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于帮助我们管理任务的内容
- en: Somewhere to provision infrastructure and deploy our solution
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于配置基础设施和部署我们的解决方案的地方
- en: 'Let’s look at how to approach each of these in turn:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一看看如何处理这些问题：
- en: '**Somewhere to code**: First, although the weapon of choice for coding by data
    scientists is of course Jupyter Notebook, once you begin to make the move toward
    ML engineering, it will be important to have an IDE to hand. An IDE is basically
    an application that comes with a series of built-in tools and capabilities to
    help you to develop the best software that you can. **PyCharm** is an excellent
    example for Python developers and comes with a wide variety of plugins, add-ons,
    and integrations useful to ML engineers. You can download the Community Edition
    from JetBrains at [https://www.jetbrains.com/pycharm/](https://www.jetbrains.com/pycharm/).
    Another popular development tool is the lightweight but powerful source code editor
    VS Code. Once you have successfully installed PyCharm, you can create a new project
    or open an existing one from the **Welcome to PyCharm** window, as shown in *Figure
    2.1*:![Figure 2.1 – Opening or creating your PyCharm project ](img/B19525_02_01.png)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编写代码的地方**：首先，尽管数据科学家选择编码的武器当然是Jupyter Notebook，但一旦您开始向ML工程转型，拥有一个IDE将变得非常重要。IDE基本上是一个包含一系列内置工具和功能的应用程序，可以帮助您开发出最好的软件。**PyCharm**是Python开发者的一个优秀例子，它提供了许多对ML工程师有用的插件、附加组件和集成。您可以从JetBrains下载社区版，网址为[https://www.jetbrains.com/pycharm/](https://www.jetbrains.com/pycharm/)。另一个流行的开发工具是轻量但强大的源代码编辑器VS
    Code。一旦您成功安装了PyCharm，您可以从**欢迎使用PyCharm**窗口创建一个新项目或打开一个现有项目，如图*图2.1*所示：![图2.1 –
    打开或创建您的PyCharm项目](img/B19525_02_01.png)'
- en: 'Figure 2.1: Opening or creating your PyCharm project.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.1：打开或创建您的PyCharm项目。
- en: '**Something to track code changes**: Next on the list is a code version control
    system. In this book, we will use **GitHub** but there are a variety of solutions,
    all freely available, that are based on the same underlying open-source **Git**
    technology. Later sections will discuss how to use these as part of your development
    workflow, but first, if you do not have a version control system set up, you can
    navigate to [github.com](http://github.com) and create a free account. Follow
    the instructions on the site to create your first repository, and you will be
    shown a screen that looks something like *Figure 2.2*. To make your life easier
    later, you should select **Add a README file** and **Add .gitignore** (then select
    **Python**). The README file provides an initial Markdown file for you to get
    started with and somewhere to describe your project. The `.gitignore` file tells
    your Git distribution to ignore certain types of files that in general are not
    important for version control. It is up to you whether you want the repository
    to be public or private and what license you wish to use. The repository for this
    book uses the **MIT license**:![Figure 2.2 – Setting up your GitHub repository
    ](img/B19525_02_02.png)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪代码变更的内容**：接下来在列表中是代码版本控制系统。在这本书中，我们将使用**GitHub**，但基于相同底层开源**Git**技术的解决方案有很多，所有这些解决方案都是免费提供的。后面的章节将讨论如何将这些工具作为您开发工作流程的一部分，但首先，如果您还没有设置版本控制系统，您可以导航到[github.com](http://github.com)并创建一个免费账户。按照网站上的说明创建您的第一个仓库，您将看到一个类似于*图2.2*的屏幕。为了使您的生活更轻松，您应该选择**添加README文件**和**添加.gitignore**（然后选择**Python**）。README文件为您提供了一个初始的Markdown文件，以便您开始使用，并描述您的项目。`.gitignore`文件告诉您的Git分布忽略某些类型的文件，这些文件通常对版本控制不重要。您可以选择将仓库设置为公开或私有，以及您希望使用的许可证。这本书的仓库使用**MIT许可证**：![图2.2
    – 设置您的GitHub仓库](img/B19525_02_02.png)'
- en: 'Figure 2.2: Setting up your GitHub repository.'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.2：设置您的GitHub仓库。
- en: 'Once you have set up your IDE and version control system, you need to make
    them talk to each other by using the Git plugins provided with PyCharm. This is
    as simple as navigating to **VCS** | **Enable Version Control Integration** and
    selecting **Git**. You can edit the version control settings by navigating to
    **File** | **Settings** | **Version** **Control**; see *Figure 2.3*:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦您设置了IDE和版本控制系统，您需要通过使用PyCharm提供的Git插件使它们相互通信。这就像导航到**VCS** | **启用版本控制集成**并选择**Git**一样简单。您可以通过导航到**文件**
    | **设置** | **版本** **控制**来编辑版本控制设置；请参阅*图2.3*：
- en: '![Figure 2.3 – Configuring version control with PyCharm ](img/B19525_02_03.png)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图2.3 – 使用PyCharm配置版本控制](img/B19525_02_03.png)'
- en: 'Figure 2.3: Configuring version control with PyCharm.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.3：使用PyCharm配置版本控制。
- en: '**Something to help manage our tasks**: You are now ready to write Python and
    track your code changes, but are you ready to manage or participate in a complex
    project with other team members? For this, it is often useful to have a solution
    where you can track tasks, issues, bugs, user stories, and other documentation
    and items of work. It also helps if this has good integration points with the
    other tools you will use. In this book, we will use **Jira** as an example of
    this. If you navigate to [https://www.atlassian.com/software/jira](https://www.atlassian.com/software/jira),
    you can create a free cloud Jira account and then follow the interactive tutorial
    within the solution to set up your first board and create some tasks. *Figure
    2.4* shows the task board for this book project, called **Machine Learning Engineering
    in Python** (**MEIP**):![](img/B19525_02_04.png)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一些帮助我们管理任务的东西**：您现在可以编写 Python 代码并跟踪您的代码更改，但您准备好与其他团队成员一起管理或参与一个复杂的项目了吗？为此，拥有一个可以跟踪任务、问题、错误、用户故事和其他文档和工作项的解决方案通常很有用。如果这个解决方案与其他您将使用的工具有良好的集成点，那就更好了。在这本书中，我们将使用**Jira**作为这个示例。如果您导航到[https://www.atlassian.com/software/jira](https://www.atlassian.com/software/jira)，您可以创建一个免费的云
    Jira 账户，然后在该解决方案中遵循交互式教程来设置您的第一个看板并创建一些任务。*图 2.4*显示了本书项目（称为**Python 机器学习工程**，**MEIP**）的任务板：![](img/B19525_02_04.png)'
- en: 'Figure 2.4: The task board for this book in Jira.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.4：本书在 Jira 中的任务板。
- en: '**Somewhere to provision infrastructure and deploy our solution**: Everything
    that you have just installed and set up is tooling that will really help take
    your workflow and software development practices to the next level. The last piece
    of the puzzle is having the tools, technologies, and infrastructure available
    for deploying the end solution. The management of computing infrastructure for
    applications was (and often still is) the provision of dedicated infrastructure
    teams, but with the advent of public clouds, there has been real democratization
    of this capability for people working across the spectrum of software roles. In
    particular, modern ML engineering is very dependent on the successful implementation
    of cloud technologies, usually through the main public cloud providers such as
    **Amazon Web Services** (**AWS**), **Microsoft Azure**, or **Google Cloud Platform**
    (**GCP**). This book will utilize tools found in the AWS ecosystem, but all of
    the tools and techniques you will find here have equivalents in the other clouds.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一个用于部署基础设施和部署我们的解决方案的地方**：您刚刚安装和设置的一切都是工具，这些工具将真正帮助您将工作流程和软件开发实践提升到下一个层次。最后一部分是拥有部署最终解决方案所需的工具、技术和基础设施。为应用程序管理计算基础设施（过去和现在通常仍然是）提供专门的团队，但随着公共云的出现，这种能力对于从事软件各个角色的员工来说已经实现了真正的民主化。特别是，现代机器学习工程非常依赖于云计算技术的成功实施，通常是通过主要的公共云提供商，如**亚马逊网络服务**（**AWS**）、**微软Azure**或**谷歌云平台**（**GCP**）。本书将利用
    AWS 生态系统中的工具，但您在这里找到的所有工具和技术在其他云中都有等效项。'
- en: The flip side of the democratization of capabilities that the cloud brings is
    that teams who own the deployment of their solutions have to gain new skills and
    understanding. I am a strong believer in the principle that “*you build it, you
    own it, you run it*” as far as possible, but this means that as an ML engineer,
    you will have to be comfortable with a host of potential new tools and principles,
    as well as *owning* the performance of your deployed solution. *With great power
    comes great responsibility* and all that. In *Chapter 5*, *Deployment Patterns
    and Tools*, we will dive into this topic in detail.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 云带来的能力民主化的一面是，拥有其解决方案部署权的团队必须掌握新的技能和理解。我坚信“*你建它，你拥有它，你运行它*”的原则，但这意味着作为一个机器学习工程师，您将不得不熟悉大量潜在的新工具和原则，以及*拥有*您部署的解决方案的性能。*权力越大，责任越大*，诸如此类。在*第
    5 章*，*部署模式和工具*中，我们将详细探讨这个话题。
- en: Let’s talk through setting this up.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈如何设置它。
- en: Setting up an AWS account
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 AWS 账户
- en: 'As previously stated, you don’t have to use AWS, but that’s what we’re going
    to use throughout this book. Once it’s set up here, you can use it for everything
    we’ll do:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，您不必使用 AWS，但我们将在这本书的整个过程中使用它。一旦在这里设置好，您就可以用它来做我们将会做的所有事情：
- en: To set up an AWS account, navigate to [aws.amazon.com](http://aws.amazon.com)
    and select **Create Account**. You will have to add some payment details but everything
    we mention in this book can be explored through the *free tier* of AWS, where
    you do not incur a cost below a certain threshold of consumption.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使这更加具体。每个阶段的主要焦点和输出可以总结如下，如图2.1表所示：
- en: 'Once you have created your account, you can navigate to the AWS Management
    Console, where you can see all the services that are available to you (see *Figure
    2.5*):'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您创建了账户，您就可以导航到AWS管理控制台，在那里您可以查看所有可用的服务（见*图2.5*）：
- en: '![Figure 2.5 – The AWS Management Console ](img/B19525_02_05.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – AWS管理控制台](img/B19525_02_05.png)'
- en: 'Figure 2.5: The AWS Management Console.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：AWS管理控制台。
- en: With our AWS account ready to go, let’s look at the four steps that cover the
    whole process.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的AWS账户准备就绪后，让我们看看涵盖整个过程的四个步骤。
- en: Concept to solution in four steps
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '| **阶段** | **输出** |'
- en: 'All ML projects are unique in some way: the organization, the data, the people,
    and the tools and techniques employed will never be exactly the same for any two
    projects. This is good, as it signifies progress as well as the natural variety
    that makes this such a fun space to work in.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所有机器学习项目在某种程度上都是独特的：组织、数据、人员、使用的工具和技术在任何两个项目中都不会完全相同。这是好事，因为它标志着进步，以及使这个领域如此有趣的自然多样性。
- en: That said, no matter the details, broadly speaking, all successful ML projects
    actually have a good deal in common. They require the translation of a business
    problem into a technical problem, a lot of research and understanding, proofs
    of concept, analyses, iterations, the consolidation of work, the construction
    of the final product, and its deployment to an appropriate environment. That is
    ML engineering in a nutshell!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，无论细节如何，从广义上讲，所有成功的机器学习项目实际上有很多共同之处。它们需要将业务问题转化为技术问题，进行大量的研究和理解，概念验证，分析，迭代，工作整合，最终产品的构建，以及将其部署到适当的环境。这就是机器学习工程的精髓！
- en: 'Developing this a bit further, you can start to bucket these activities into
    rough categories or stages, the results of each being necessary inputs for later
    stages. This is shown in *Figure 2.6*:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步发展这一点，您可以将这些活动开始归类为粗略的类别或阶段，每个阶段的成果都是后续阶段必要的输入。这如图2.6所示：
- en: '![Figure 2.6 – The stages that any ML project goes through as part of the ML
    development process ](img/B19525_02_06.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 任何机器学习项目在机器学习开发过程中所经历的各个阶段](img/B19525_02_06.png)'
- en: 'Figure 2.6: The stages that any ML project goes through as part of the ML development
    process.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：任何机器学习项目在机器学习开发过程中所经历的各个阶段。
- en: Each category of work has a slightly different flavor, but taken together, they
    provide the backbone of any good ML project. The next few sections will develop
    the details of each of these categories and begin to show you how they can be
    used to build your ML engineering solutions. As we will discuss later, it is also
    not necessary for you to tackle your entire project in four steps like this; you
    can actually work through each of these steps for a specific feature or part of
    your overall project. This will be covered in the *Selecting a software development
    methodology* section.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作类别都有其独特的风味，但综合起来，它们构成了任何良好机器学习项目的骨架。接下来的几节将详细阐述每个类别的细节，并开始展示如何使用它们来构建您的机器学习工程解决方案。正如我们稍后将要讨论的，您也不必像这样分四步完成整个项目；您实际上可以为特定功能或整体项目的一部分逐个完成这些步骤。这将在*选择软件开发方法*部分中介绍。
- en: 'Let’s make this a bit more real. The main focus and outputs of every stage
    can be summarized as shown in *Table 2.1*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置AWS账户，请导航到[aws.amazon.com](http://aws.amazon.com)并选择**创建账户**。您需要添加一些付款详情，但本书中提到的所有内容都可以通过AWS的*免费层*进行探索，在那里您不会因消费低于一定阈值而产生费用。
- en: '| **Stage** | **Outputs** |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: 四步从概念到解决方案
- en: '| Discover | Clarity on the business question.Clear arguments for ML over another
    approach.Definition of the KPIs and metrics you want to optimize.A sketch of the
    route to value. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | 输出 |'
- en: '| Play | Detailed understanding of the data.Working proof of concept.Agreement
    on the model/algorithm/logic that will solve the problem.Evidence that a solution
    is doable within realistic resource scenarios.Evidence that good ROI can be achieved.
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | 详细理解数据。工作原理的概念验证。对解决问题所采用的模型/算法/逻辑达成一致。在现实资源场景中实现解决方案的证据。实现良好投资回报率的证据。
    |'
- en: '| Develop | A working solution that can be hosted on appropriate and available
    infrastructure.Thorough test results and performance metrics (for algorithms and
    software).An agreed retraining and model deployment strategy.Unit tests, integration
    tests, and regression tests.Solution packaging and pipelines. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 开发 | 开发一个可以在适当和可用的基础设施上托管的工作解决方案。详尽的测试结果和性能指标（针对算法和软件）。达成一致的再培训和模型部署策略。单元测试、集成测试和回归测试。解决方案打包和管道。
    |'
- en: '| Deploy | A working and tested deployment process.Provisioned infrastructure
    with appropriate security and performance characteristics.Mode retraining and
    management processes.An end-to-end working solution! |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 部署 | 一个工作且经过测试的部署流程。配备适当的安全性和性能特性的基础设施。模式再培训和管理工作流程。端到端的工作解决方案！ |'
- en: 'Table 2.1: The outputs of the different stages of the ML development process.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1：机器学习开发过程不同阶段的输出。
- en: IMPORTANT NOTE
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You may think that an ML engineer only really needs to consider the latter two
    stages, *develop*, and *deploy*, and that earlier stages are owned by the data
    scientist or even a business analyst. We will indeed focus mainly on these stages
    throughout this book and this division of labor can work very well. It is, however,
    crucially important that if you are going to build an ML solution, you understand
    all of the motivations and development steps that have gone before – you wouldn’t
    build a new type of rocket without understanding where you want to go first, would
    you?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为机器学习工程师只需要真正考虑后两个阶段，*开发*和*部署*，而早期阶段由数据科学家或甚至业务分析师负责。我们确实会在整本书中主要关注这些阶段，并且这种劳动分工可以非常有效。然而，如果你打算构建一个机器学习解决方案，理解所有之前的动机和开发步骤至关重要——你不了解你想要去哪里，难道会建造一种新的火箭吗？
- en: Comparing this to CRISP-DM
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与CRISP-DM的比较
- en: 'The high-level categorization of project steps that we will outline in the
    rest of this chapter has many similarities to, and some differences from, an important
    methodology known as CRISP-DM. This methodology was published in 1999 and has
    since gathered a large following as a way to understand how to build any data
    project. In CRISP-DM, there are six different phases of activity, covering similar
    ground to that outlined in the four steps described in the previous section:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的其余部分概述的项目步骤的高级分类与一个重要的方法论CRISP-DM有许多相似之处，也有一些不同。这个方法论于1999年发布，自那时起，它已成为理解如何构建任何数据项目的一种方式。在CRISP-DM中，有六个不同的活动阶段，涵盖了与上一节中描述的四个步骤类似的内容：
- en: '**Business understanding**: This is all about getting to know the business
    problem and domain area. This becomes part of the *Discover* phase in the four-step
    model.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**业务理解**：这全部关于了解业务问题和领域。在四步模型中，这成为*发现*阶段的一部分。'
- en: '**Data understanding**: Extending the knowledge of the business domain to include
    the state of the data, its location, and how it is relevant to the problem. Also
    included in the *Discover* phase.'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据理解**：将业务领域的知识扩展到包括数据的状态、其位置以及它与问题的相关性。这也包括在*发现*阶段。'
- en: '**Data preparation**: Starting to take the data and transform it for downstream
    use. This will often have to be iterative. Captured in the *Play* stage.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：开始获取数据并将其转换为下游使用。这通常需要迭代。在*玩耍*阶段进行捕捉。'
- en: '**Modeling**: Taking the prepared data and then developing analytics on top
    of it; this could now include ML of various levels of sophistication. This is
    an activity that occurs both in the *Play* and *Develop* phases of the four-step
    methodology.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**建模**：对准备好的数据进行处理，并在其上开发分析；这现在可能包括不同复杂程度的机器学习。这是一个在四步方法论中的*玩耍*和*开发*阶段都会发生的活动。'
- en: '**Evaluation**: This stage is concerned with confirming whether the solution
    will meet the business requirements and performing a holistic review of the work
    that has gone before. This helps confirm if anything was overlooked or could be
    improved upon. This is very much part of the *Develop* and *Deploy* phases; in
    the methodology we will describe in this chapter, these tasks are very much more
    baked in across the project.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估**：这一阶段关注的是确认解决方案是否满足业务需求，并对之前的工作进行全面的审查。这有助于确认是否有什么被忽略或可以改进的地方。这非常是*开发*和*部署*阶段的一部分；在我们本章将描述的方法论中，这些任务在整个项目中都得到了很好的整合。'
- en: '**Deployment**: In CRISP-DM, this was originally focused on deploying simple
    analytics solutions like dashboards or scheduled ETL pipelines that would run
    the decided-upon analytics models.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署**：在CRISP-DM中，这最初是专注于部署简单的分析解决方案，如仪表板或计划中的ETL管道，这些管道将运行已决定的分析模型。'
- en: In the world of model ML engineering, this stage can represent, well, anything
    talked about in this book! CRISP-DM suggests sub-stages around planning and then
    reviewing the deployment.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在模型机器学习工程的世界里，这一阶段可以代表这本书中提到的任何内容！CRISP-DM建议在规划和审查部署方面有子阶段。
- en: As you can see from the list, many steps in CRISP-DM cover similar topics to
    those outlined in the four steps I propose. CRISP-DM is extremely popular across
    the data science community and so its merits are definitely appreciated by a huge
    number of data professionals across the world. Given this, you might be wondering,
    “Why bother developing something else then?” Let me convince you of why this is
    a good idea.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从列表中看到的，CRISP-DM中的许多步骤涵盖了与我提出的四个步骤中概述的类似主题。CRISP-DM在数据科学社区中非常受欢迎，因此其优点肯定得到了全世界大量数据专业人士的认可。鉴于这一点，您可能会想，“为什么还要开发其他的东西呢？”让我说服您为什么这是一个好主意。
- en: 'The CRISP-DM methodology is just another way to group the important activities
    of any data project in order to give them some structure. As you can perhaps see
    from the brief description of the stages I gave above and if you do further research,
    CRISP-DM has some potential drawbacks for use in a modern ML engineering project:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-DM方法论只是将任何数据项目的重要活动分组以提供结构的一种方式。您可能从上面我给出的阶段简要描述中看到，如果您进行进一步的研究，CRISP-DM在用于现代机器学习工程项目的使用中可能存在一些潜在的缺点：
- en: The process outlined in CRISP-DM is relatively rigid and quite linear. This
    can be beneficial for providing structure but might inhibit moving fast in a project.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CRISP-DM中概述的过程相对僵化且相当线性。这可以为提供结构带来好处，但可能会阻碍项目中的快速进展。
- en: The methodology is very big on documentation. Most steps detail writing some
    kind of report, review, or summary. Writing and maintaining good documentation
    is absolutely critical in a project but there can be a danger of doing too much.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该方法非常重视文档。大多数步骤都详细说明了编写某种类型的报告、审查或总结。在项目中编写和维护良好的文档至关重要，但过度编写文档也可能存在风险。
- en: CRISP-DM was written in a world before “big data” and large-scale ML. It is
    unclear to me whether its details still apply in such a different world, where
    classic extract-transform-load patterns are only one of so many.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CRISP-DM是在“大数据”和大规模机器学习出现之前的世界中编写的。对我来说，不清楚其细节是否仍然适用于这样一个不同的世界，在那里经典的提取-转换-加载模式只是众多模式之一。
- en: CRISP-DM definitely comes from the data world and then tries to move toward
    the idea of a deployable solution in the last stage. This is laudable, but in
    my opinion, this is not enough. ML engineering is a different discipline in the
    sense that it is far closer to classic software engineering than not. This is
    a point that this book will argue time and again. It is therefore important to
    have a methodology where the concepts of deployment and development are aligned
    with software and modern ML techniques all the way through.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CRISP-DM无疑源自数据世界，并在最后阶段试图向可部署解决方案的概念迈进。这是值得赞扬的，但在我看来，这还不够。机器学习工程是一个不同的学科，因为它与经典软件工程的距离远比接近。这本书将反复论证这一点。因此，拥有一个将部署和开发的概念与软件和现代机器学习技术完全一致的方法非常重要。
- en: The *four-step* methodology attempts to alleviate some of these challenges and
    does so in a way that constantly makes reference to software engineering and ML
    skills and techniques. This does not mean that you should never use CRISP-DM in
    your projects; it might just be the perfect thing! As with many of the concepts
    introduced in this book, the important thing is to have many tools in your toolkit
    so that you can select the one most appropriate for the job at hand.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**四步法**试图缓解这些挑战，并以不断参考软件工程和机器学习技能和技术的方式进行。这并不意味着你永远不应该在你的项目中使用CRISP-DM；它可能正是完美的选择！就像这本书中介绍的大多数概念一样，重要的是要拥有许多工具在你的工具箱中，以便你可以选择最适合当前工作的那个。'
- en: Given this, let’s now go through the four steps in detail.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在让我们详细地过一遍这四个步骤。
- en: Discover
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现
- en: Before you start working to build any solution, it is vitally important that
    you understand the problem you are trying to solve. This activity is often termed
    **discovery** in business analysis and is crucial if your ML project is going
    to be a success.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始构建任何解决方案之前，了解你试图解决的问题至关重要。这项活动在商业分析中通常被称为**发现**，如果你的机器学习项目要取得成功，这是至关重要的。
- en: 'The key things to do during the discovery phase are the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现阶段需要做的关键事情如下：
- en: '*Speak to the customer! And then speak to them again*: You must understand
    the end user requirements in detail if you are to design and build the right system.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*与客户沟通！然后再与他们沟通*：如果你要设计和构建正确的系统，你必须详细了解最终用户的需求。'
- en: '*Document everything*: You will be judged on how well you deliver against the
    requirements, so make sure that all of the key points from your discussion are
    documented and signed off by members of your team and the customer or their appropriate
    representative.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*记录一切*：你将根据你满足要求的好坏来评判，所以请确保你的讨论中的所有关键点都得到了团队成员和客户或其适当代表的记录和批准。'
- en: '*Define the metrics that matter*: It is very easy at the beginning of a project
    to get carried away and to feel like you can solve any and every problem with
    the amazing new tool you are going to build. Fight this tendency as aggressively
    as you can, as it can easily cause major headaches later on. Instead, steer your
    conversations toward defining a single or very small number of metrics that define
    what success will look like.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义重要的指标*：在项目开始时，很容易被冲昏头脑，感觉自己可以用即将构建的神奇新工具解决任何问题。尽可能强烈地抵制这种倾向，因为它很容易在以后造成严重的头痛。相反，将你的对话引导到定义一个或非常少的指标，这些指标定义了成功将是什么样子。'
- en: '*Start finding out where the data lives!*: If you can start working out what
    kind of systems you will have to access to get the data you need, this saves you
    time later and can help you find any major issues before they derail your project.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始找出数据在哪里！*：如果你能开始确定你需要访问哪些系统来获取所需的数据，这将节省你以后的时间，并有助于你在项目脱轨之前发现任何重大问题。'
- en: Using user stories
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用用户故事
- en: 'Once you have spoken to the customer (a few times), you can start to define
    some **user stories**. User stories are concise and consistently formatted expressions
    of what the user or customer wants to see and the acceptance criteria for that
    feature or unit of work. For example, we may want to define a user story based
    on the taxi ride example from *Chapter 1*, *Introduction to ML Engineering*: “As
    a user of our internal web service, I want to see anomalous taxi rides and be
    able to investigate them further.”'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你与客户（几次）交谈过，你就可以开始定义一些**用户故事**。用户故事是对用户或客户想要看到的内容以及该功能或工作单元的验收标准的简洁且格式一致的表述。例如，我们可能想根据*第1章*，*机器学习工程简介*中的出租车行程示例定义一个用户故事：“作为我们内部网络服务的用户，我希望看到异常的出租车行程，并能够进一步调查。”
- en: Let’s begin!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: To add this in Jira, select the **Create** button.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在Jira中添加此内容，请选择**创建**按钮。
- en: Next, select **Story**.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，选择**故事**。
- en: Then, fill in the details as you deem appropriate.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，根据需要填写细节。
- en: 'You have now added a user story to your work management tool! This allows you
    to do things such as create new tasks and link them to this user story or update
    its status as your project progresses:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经将一个用户故事添加到你的工作管理工具中！这让你可以做诸如创建新任务并将它们链接到这个用户故事或更新其状态等事情：
- en: '![Figure 2.8 – An example user story in Jira ](img/B19525_02_07.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – Jira中的一个示例用户故事](img/B19525_02_07.png)'
- en: 'Figure 2.7: An example user story in Jira.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：Jira中的一个示例用户故事。
- en: The data sources you use are particularly crucial to understand. As you know,
    *garbage in, garbage out*, or even worse, *no data, no go*! The particular questions
    you have to answer about the data are mainly centered around **access**, **technology**,
    **quality**, and **relevance**.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用的数据源尤其重要，需要理解。正如你所知，“垃圾进，垃圾出”，或者更糟，“没有数据，就没有进展”！你必须回答的数据的特定问题主要集中在**访问**、**技术**、**质量**和**相关性**上。
- en: For access and technology, you are trying to pre-empt how much work the data
    engineers have to do to start their pipeline of work and how much this will hold
    up the rest of the project. It is therefore crucial that you get this one right.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于访问和技术，你试图预先了解数据工程师开始他们的工作流程需要做多少工作，以及这会耽误整个项目多少时间。因此，正确地完成这一点至关重要。
- en: A good example would be if you find out quite quickly that the main bulk of
    data you will need lives in a legacy internal financial system with no real modern
    APIs and no access request mechanism for non-finance team members. If its main
    backend is on-premises and you need to migrate locked-down financial data to the
    cloud, but this makes your business nervous, then you know you have a lot of work
    to do before you type a line of code. If the data already lives in an enterprise
    data lake that your team has access to, then you are obviously in a better position.
    Any challenge is surmountable if the value proposition is strong enough, but finding
    all this out early will save you time, energy, and money later on.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的例子是，如果你很快发现你需要的绝大部分数据都存在于没有真正现代API和没有非财务团队成员访问请求机制的遗留内部财务系统中。如果其主要后端是本地部署的，你需要将锁定在云端的财务数据迁移过来，但这会让你的业务感到紧张，那么你知道在编写第一行代码之前还有很多工作要做。如果数据已经存在于你的团队可以访问的企业数据湖中，那么你显然处于更好的位置。如果价值主张足够强大，任何挑战都是可以克服的，但尽早找出这些情况将为你节省时间、精力和金钱。
- en: Relevance is a bit harder to find out before you kick off, but you can begin
    to get an idea. For example, if you want to perform the inventory forecast we
    discussed in *Chapter 1*, *Introduction to ML Engineering*, do you need to pull
    in customer account information? If you want to create the classifier of *premium*
    or *non-premium* customers as marketing targets, also mentioned in *Chapter 1*,
    *Introduction to ML Engineering*, do you need to have data on social media feeds?
    The question as to what is relevant will often be less clear-cut than for these
    examples but an important thing to remember is that you can always come back to
    it if you really missed something important. You are trying to capture the most
    important design decisions early, so common sense and lots of stakeholder and
    subject-matter expert engagement will go a long way.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动之前，相关性可能更难找到，但你可以开始形成一些想法。例如，如果你想执行我们在*第一章*，*机器学习工程导论*中讨论的库存预测，你是否需要拉取客户账户信息？如果你想创建*高端*或*非高端*客户的分类器，作为营销目标，这也如*第一章*，*机器学习工程导论*中提到的，你是否需要社交媒体数据？关于相关性的问题通常不会像这些例子那样明确，但一个重要的事情要记住的是，如果你真的错过了什么重要的东西，你总是可以回过头来。你试图尽早捕捉到最重要的设计决策，所以常识和大量的利益相关者和领域专家参与将大有裨益。
- en: Data quality is something that you can try to anticipate a little before moving
    forward in your project with some questions to current users or consumers of the
    data or those involved in its entry processes. To get a more quantitative understanding
    though, you will often just need to get your data scientists working with the
    data in a hands-on manner.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目前进之前，你可以尝试通过向当前的数据用户或消费者或参与其输入过程的人员提出一些问题来预测数据质量。但要获得更定量的理解，你通常只需要让你的数据科学家以动手的方式与数据一起工作。
- en: In the next section, we will look at how we develop proof-of-concept ML solutions
    in the most research-intensive phase, *Play*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何在最具研究密集性的阶段，即*Play*阶段，开发概念验证机器学习解决方案。
- en: Play
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Play
- en: In the **play** stage of the project, your aim is to work out whether solving
    the task even at the proof-of-concept level is feasible. To do this, you might
    employ the usual data science bread-and-butter techniques of exploratory data
    analysis and explanatory modeling we mentioned in the last chapter before moving
    on to creating an ML model that does what you need.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目的**play**阶段，你的目标是确定即使在概念验证级别解决任务是否可行。为此，你可能会在创建满足你需求的机器学习模型之前，采用我们在上一章中提到的常规数据科学技术，如探索性数据分析和解释性建模。
- en: 'In this part of the process, you are not overly concerned with details of implementation,
    but with exploring the realms of possibility and gaining an in-depth understanding
    of the data and the problem, which goes beyond initial discovery work. Since the
    goal here is not to create *production-ready* code or to build reusable tools,
    you should not worry about whether or not the code you are writing is of the highest
    quality, or using sophisticated patterns. For example, it will not be uncommon
    to see code that looks something like the following examples (taken, in fact,
    from the repo for this book):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个流程的这一部分，你不必过分关注实现的细节，而是要探索可能性领域，并深入理解数据和问题，这超出了初步发现工作。由于这里的目的是不创建*生产就绪*的代码或构建可重用的工具，因此你不必担心你编写的代码是否质量最高，或者是否使用了复杂的模式。例如，看到以下示例（实际上是从本书的repo中摘取的）的代码并不罕见：
- en: '![Figure 2.9 – Some example prototype code that will be created during the
    play stage ](img/B19525_02_08.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 在游戏阶段将创建的一些示例原型代码](img/B19525_02_08.png)'
- en: 'Figure 2.8: Some example prototype code that will be created during the play
    stage.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：在游戏阶段将创建的一些示例原型代码。
- en: 'Even a quick glance at these screenshots tells you a few things:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 只需快速浏览这些截图，就能告诉你一些事情：
- en: The code is in a Jupyter notebook, which is run by a user interactively in a
    web browser.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码位于Jupyter笔记本中，由用户在网页浏览器中交互式运行。
- en: The code sporadically calls methods to simply check or explore elements of the
    data (for example, `df.head()` and `df.dtypes`).
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码偶尔会调用方法来简单地检查或探索数据元素（例如，`df.head()`和`df.dtypes`）。
- en: There is ad hoc code for plotting (and it’s not very intuitive!).
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于绘图（而且它并不直观！）有专门的代码。
- en: There is a variable called `tmp`, which is not very descriptive.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个名为`tmp`的变量，描述性不强。
- en: All of this is absolutely fine in this more exploratory phase, but one of the
    aims of this book is to help you understand what is required to take code like
    this and make it into something suitable for your production ML pipelines. The
    next section starts us along this path.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些在这个更探索性的阶段都是绝对可以接受的，但本书的一个目标就是帮助你理解将此类代码转化为适合你生产机器学习管道所需的要素。下一节将开始引导我们走上这条道路。
- en: Develop
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发
- en: As we have mentioned a few times already, one of the aims of this book is to
    get you thinking about the fact that you are building software products that just
    happen to have ML in them. This means a steep learning curve for some of us who
    have come from more mathematical and algorithmic backgrounds. This may seem intimidating
    but do not despair! The good news is that we can reuse a lot of the best practices
    and techniques honed through the software engineering community over several decades.
    There is nothing new under the sun.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前已经提到几次，本书的一个目标就是让你思考这样一个事实：你正在构建的软件产品恰好包含了机器学习。这意味着对于我们这些来自更数学和算法背景的人来说，学习曲线可能会很陡峭。这可能会让人感到害怕，但不要绝望！好消息是，我们可以重用几十年来软件工程社区锤炼的许多最佳实践和技术。太阳之下无新事。
- en: This section explores several of those methodologies, processes, and considerations
    that can be employed in the development phase of our ML engineering projects.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了在机器学习工程项目的开发阶段可以采用的一些方法、流程和考虑因素。
- en: Selecting a software development methodology
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择软件开发方法
- en: One of the first things we could and should shamelessly replicate as ML engineers
    is the software development methodologies that are utilized in projects across
    the globe. One category of these, often referred to as **Waterfall**, covers project
    workflows that fit quite naturally with the idea of building something complex
    (think a building or a car). In Waterfall methodologies, there are distinct and
    sequential phases of work, each with a clear set of outputs that are needed before
    moving on to the next phase. For example, a typical Waterfall project may have
    phases that broadly cover requirements-gathering, analysis, design, development,
    testing, and deployment (sound familiar?). The key thing is that in a Waterfall-flavored
    project, when you are in the *requirements-gathering* phase, you should *only*
    be working on gathering requirements, when in the testing phase, you should *only*
    be working on testing, and so on. We will discuss the pros and cons of this for
    ML in the next few paragraphs after introducing another set of methodologies.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们作为机器学习工程师，可以而且应该毫无顾忌地复制全球项目中使用的软件开发方法。这些方法中的一类，通常被称为**瀑布模型**，涵盖了适合构建复杂事物的项目工作流程（想想建筑或汽车）。在瀑布模型中，有明确且顺序性的工作阶段，每个阶段都有在进入下一阶段之前所需的明确输出。例如，典型的瀑布项目可能包含涵盖需求收集、分析、设计、开发、测试和部署等阶段（听起来熟悉吗？）。关键在于，在瀑布风格的项目中，当你处于**需求收集**阶段时，你应该**只**专注于收集需求，当处于测试阶段时，你应该**只**专注于测试，依此类推。在介绍另一套方法之后，我们将在接下来的几段中讨论这种方法在机器学习中的优缺点。
- en: The other set of methodologies, termed **Agile**, began its life after the introduction
    of the **Agile Manifesto** in 2001 ([https://agilemanifesto.org/](https://agilemanifesto.org/)).
    At the heart of Agile development are the ideas of flexibility, iteration, incremental
    updates, failing fast, and adapting to changing requirements. If you are from
    a research or scientific background, this concept of flexibility and adaptability
    based on results and new findings may sound familiar.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 另一套方法，称为**敏捷**，是在2001年**敏捷宣言**（[https://agilemanifesto.org/](https://agilemanifesto.org/)）发布之后出现的。敏捷开发的核心理念是灵活性、迭代、增量更新、快速失败和适应变化的需求。如果你来自研究或科学背景，这种基于结果和新发现灵活性和适应性的概念可能听起来很熟悉。
- en: What may not be so familiar to you if you have this type of scientific or academic
    background is that you can still embrace these concepts within a relatively strict
    framework that is centered around delivery outcomes. Agile software development
    methodologies are all about finding the balance between experimentation and delivery.
    This is often done by introducing the concepts of **ceremonies** (such as **Scrums**
    and **Sprint** **Retrospectives**) and **roles** (such as **Scrum Master** and
    **Product Owner**).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你具有这种科学或学术背景，可能不太熟悉的是，你仍然可以在一个以交付结果为中心的相对严格的框架内接受这些概念。敏捷软件开发方法的核心是寻找实验和交付之间的平衡。这通常通过引入**仪式**（如**Scrum**和**Sprint**回顾）和**角色**（如**Scrum
    Master**和**产品负责人**）来实现。
- en: 'Further to this, within Agile development, there are two variants that are
    extremely popular: **Scrum** and **Kanban**. Scrum projects are centered around
    short units of work called **Sprints** where the idea is to make additions to
    the product from ideation through to deployment in that small timeframe. In Kanban,
    the main idea is to achieve a steady **flow** of tasks from an organized backlog
    into work in progress through to completed work.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在敏捷开发中，有两种非常流行的变体：**Scrum**和**Kanban**。Scrum项目围绕称为**Sprint**的短期工作单元展开，其理念是在这个短暂的时间内从构思到部署对产品的添加。在Kanban中，主要理念是实现从有序的待办事项到进行中工作，再到完成工作的稳定**流程**。
- en: All of these methodologies (and many more besides) have their merits and their
    detractions. You do not have to be married to any of them; you can chop and change
    between them. For example, in an ML project, it may make sense to do some *post-deployment*
    work that has a focus on maintaining an already existing service (sometimes termed
    a *business-as-usual* activity) such as further model improvements or software
    optimizations in a Kanban framework. It may make sense to do the main delivery
    of your core body of work in Sprints with very clear outcomes. But you can chop
    and change and see what fits best for your use cases, your team, and your organization.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法（以及更多）都有其优点和缺点。你不必对其中任何一种方法产生依赖；你可以在它们之间随意切换。例如，在一个机器学习项目中，进行一些*部署后*的工作可能是有意义的，这些工作专注于维护现有的服务（有时被称为*常规业务*活动），例如进一步改进模型或软件优化在看板框架中。在Sprint中明确结果的主要交付可能是有意义的。但你可以随意切换，看看哪种最适合你的用例、你的团队和你的组织。
- en: 'But what makes applying these types of workflows to ML projects different?
    What do we need to think about in this world of ML that we didn’t before? Well,
    some of the key points are the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 但将这类工作流程应用于机器学习项目有什么不同？在这个机器学习的世界中，我们需要考虑哪些以前没有考虑过的问题？好吧，一些关键点如下：
- en: '*You don’t know what you don’t know*: You cannot know whether you will be able
    to solve the problem until you have seen the data. Traditional software engineering
    is not as critically dependent on the data that will flow through the system as
    ML engineering is. We can know how to solve a problem in principle, but if the
    appropriate data does not exist in sufficient quantity or is of poor quality,
    then we can’t solve the problem in practice.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你不知道你不知道的*：在你看到数据之前，你无法知道你是否能够解决问题。传统的软件工程不像机器学习工程那样严重依赖于将通过系统的数据。原则上我们可以知道如何解决问题，但如果适当的数据数量不足或质量差，那么在实践中我们无法解决问题。'
- en: '*Your system is alive*: If you build a classic website, with its backend database,
    shiny frontend, amazing load-balancing, and other features, then realistically,
    if the resource is there, it can just run forever. Nothing fundamental changes
    about the website and how it runs over time. Clicks still get translated into
    actions and page navigation still happens the same way. Now, consider putting
    some ML-generated advertising content based on typical user profiles in there.
    What is a *typical user profile* and does that change with time? With more traffic
    and more users, do behaviors that we never saw before become *the new normal?*
    Your system is learning all the time and that leads to the problems of *model
    drift* and *distributional shift*, as well as more complex update and rollback
    scenarios.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你的系统是活生生的*：如果你构建了一个经典的网站，拥有其后端数据库、闪亮的用户界面、惊人的负载均衡和其他功能，那么实际上，如果资源存在，它可以永远运行。网站及其运行方式在时间上不会发生根本性的变化。点击仍然会被转换成操作，页面导航仍然以相同的方式进行。现在，考虑在其中加入一些基于典型用户档案的机器学习生成的广告内容。什么是*典型用户档案*，它会随时间变化吗？随着流量和用户的增加，我们以前从未见过的行为是否变成了*新常态*？你的系统一直在学习，这导致了*模型漂移*和*分布偏移*的问题，以及更复杂的更新和回滚场景。'
- en: '*Nothing is certain*: When building a system that uses rule-based logic, you
    know what you are going to get each and every time. *If X*, *then Y* means just
    that, always. With ML models, it is often much harder to know what the answer
    is when you ask the question, which is in fact why these algorithms are so powerful.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*没有什么是确定的*：在构建使用基于规则的逻辑的系统时，你知道每次会得到什么。*如果X，那么Y*的意思就是如此，始终如此。对于机器学习模型，当你提问时，往往很难知道答案是什么，这正是这些算法之所以强大的原因。'
- en: But it does mean that you can have unpredictable behavior, either for the reasons
    discussed previously or simply because the algorithm has learned something that
    is not obvious about the data to a human observer, or, because ML algorithms can
    be based on probabilistic and statistical concepts, results come attached to some
    uncertainty or *fuzziness*. A classic example is when you apply logistic regression
    and receive the probability of the data point belonging to one of the classes.
    It’s a probability so you cannot say with certainty that it is the case; just
    how likely it is! This is particularly important to consider when the outputs
    of your ML system will be leveraged by users or other systems to make decisions.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 但这也意味着你可能会有不可预测的行为，无论是由于之前讨论的原因，还是因为算法学习到了人类观察者不明显的数据信息，或者，因为机器学习算法可以基于概率和统计概念，结果会附带一些不确定性或*模糊性*。一个经典的例子是当你应用逻辑回归并收到数据点属于某一类别的概率时。这是一个概率值，你不能确定地说它是这种情况；只是有多大的可能性！这在你的机器学习系统的输出将被用户或其他系统用于做出决策时尤其重要。
- en: 'Given these issues, in the next section, we’ll try and understand what development
    methodologies can help us when we build our ML solutions. In *Table 2.2*, we can
    see some advantages and disadvantages of each of these Agile methodologies for
    different stages and types of ML engineering projects:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些问题，在下一节中，我们将尝试了解哪些开发方法论可以帮助我们在构建机器学习解决方案时。在*表2.2*中，我们可以看到这些敏捷方法论在不同阶段和类型的机器学习（ML）工程项目中的优缺点：
- en: '| **Methodology** | **Pros** | **Cons** |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| **方法论** | **优点** | **缺点** |'
- en: '| Agile | Flexibility is expected.Faster dev to deploy cycles. | If not well
    managed, can easily have scope drift.Kanban or Sprints may not work well for some
    projects. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 敏捷 | 预期具有灵活性，更快的开发到部署周期。 | 如果管理不善，容易发生范围漂移。看板或冲刺可能不适合某些项目。 |'
- en: '| Waterfall | Clearer path to deployment.Clear staging and ownership of tasks.
    | Lack of flexibility.Higher admin overheads. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 水晶球模型 | 清晰的部署路径，明确任务的阶段和所有权。 | 缺乏灵活性，更高的管理开销。 |'
- en: 'Table 2.2: Agile versus Waterfall for ML development.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.2：敏捷与水晶球模型在机器学习（ML）开发中的应用。
- en: Let’s move on to the next section!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续下一节！
- en: Package management (conda and pip)
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 包管理（conda和pip）
- en: If I told you to write a program that did anything in data science or ML without
    using any libraries or packages and just pure Python, you would probably find
    this quite difficult to achieve in any reasonable amount of time, and incredibly
    boring! This is a good thing. One of the really powerful features of developing
    software in Python is that you can leverage an extensive ecosystem of tools and
    capabilities relatively easily. The flip side of this is that it would be very
    easy for managing the dependencies of your code base to become a very complicated
    and hard-to-replicate task. This is where package and environment managers such
    as `pip` and `conda` come in.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我告诉你编写一个不使用任何库或包，仅使用纯Python进行数据科学或机器学习（ML）的程序，你可能觉得在合理的时间内完成这项任务非常困难，而且极其无聊！这是好事。在Python中开发软件的一个真正强大的特性是，你可以相对容易地利用一个广泛的工具和功能生态系统。另一方面，这也意味着管理代码库的依赖可能会变得非常复杂且难以复制。这就是包和环境管理器如`pip`和`conda`发挥作用的地方。
- en: '`pip` is the standard package manager in Python and the one recommended for
    use by the Python Package Authority.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip`是Python的标准包管理器，也是Python包权威机构推荐使用的。'
- en: It retrieves and installs Python packages from `PyPI`, the `Python Package Index`.
    `pip` is super easy to use and is often the suggested way to install packages
    in tutorials and books.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 它从`PyPI`，即`Python包索引`中检索和安装Python包。`pip`使用非常简单，通常在教程和书籍中建议作为安装包的方式。
- en: '`conda` is the *package and environment* manager that comes with the Anaconda
    and Miniconda Python distributions. A key strength of `conda` is that although
    it comes from the Python ecosystem, and it has excellent capabilities there, it
    is actually a more general package manager. As such, if your project requires
    dependencies outside Python (the NumPy and SciPy libraries being good examples),
    then although `pip` can install these, it can’t track all the non-Python dependencies,
    nor manage their versions. With `conda`, this is solved.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`conda`是Anaconda和Miniconda Python发行版附带的一个**包和环境**管理器。`conda`的一个关键优势是，尽管它来自Python生态系统，并且在那里具有出色的功能，但它实际上是一个更通用的包管理器。因此，如果你的项目需要Python之外的依赖（例如NumPy和SciPy库是很好的例子），尽管`pip`可以安装这些依赖，但它无法跟踪所有非Python依赖，也无法管理它们的版本。使用`conda`，这个问题就解决了。'
- en: You can also use `pip` within `conda` environments, so you can get the best
    of both worlds or use whatever you need for your project. The typical workflow
    that I use is to use `conda` to manage the environments I create and then use
    that to install any packages I think may require non-Python dependencies that
    perhaps are not captured well within `pip`, and then I can use `pip` most of the
    time within the created `conda` environment. Given this, throughout the book,
    you may see `pip` or `conda` installation commands used interchangeably. This
    is perfectly fine.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在 `conda` 环境中使用 `pip`，因此您可以同时获得两者的最佳之处，或者使用您项目所需的任何工具。我通常使用的典型工作流程是使用 `conda`
    管理我创建的环境，然后使用它来安装任何可能需要非 Python 依赖项的包，这些依赖项可能没有在 `pip` 中得到很好的处理，然后我可以在创建的 `conda`
    环境中使用 `pip` 大部分时间。鉴于这一点，在本书中，您可能会看到 `pip` 或 `conda` 安装命令交替使用。这是完全可以接受的。
- en: To get started with Conda, if you haven’t already, you can download the **Individual**
    distribution installer from the Anaconda website ([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)).
    Anaconda comes with some Python packages already installed, but if you want to
    start from a completely empty environment, you can download Miniconda from the
    same website instead (they have the exact same functionality; you just start from
    a different base).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Conda，如果您还没有，您可以从 Anaconda 网站下载 **个人** 分发安装程序（[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)）。Anaconda
    已经预装了一些 Python 包，但如果您想从一个完全空的环境开始，您可以从同一网站下载 Miniconda（它们具有完全相同的功能；只是您从不同的基础开始）。
- en: The Anaconda documentation is very helpful for getting you up to speed with
    the appropriate commands, but here is a quick tour of some of the key ones.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda 文档对于您熟悉适当的命令非常有帮助，但这里简要介绍一下其中的一些关键命令。
- en: 'First, if we want to create a `conda` environment called `mleng` with Python
    version 3.8 installed, we simply execute the following in our terminal:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果我们想创建一个名为 `mleng` 的 `conda` 环境并安装 Python 3.8 版本，我们只需在我们的终端中执行以下命令：
- en: '[PRE1]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can then activate the `conda` environment by running the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过运行以下命令来激活 `conda` 环境：
- en: '[PRE2]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This means that any new `conda` or `pip` commands will install packages in this
    environment and not system-wide.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着任何新的 `conda` 或 `pip` 命令都将在此环境中安装包，而不是系统范围内。
- en: 'We often want to share the details of our environment with others working on
    the same project, so it can be useful to export all the package configurations
    to a `.yml` file:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常希望与他人共享我们环境的详细信息，以便他们可以在同一项目中工作，因此将所有包配置导出到 `.yml` 文件中可能很有用：
- en: '[PRE3]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The GitHub repository for this book contains a file called `mleng-environment.yml`
    for you to create your own instance of the `mleng` environment. The following
    command creates an environment with this configuration using this file:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 本书 GitHub 仓库中包含一个名为 `mleng-environment.yml` 的文件，您可以使用此文件创建 `mleng` 环境的实例。以下命令使用此文件创建具有此配置的环境：
- en: '[PRE4]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This pattern of creating a `con``da` environment from an environment file is
    a nice way to get your environments set up for running the examples in each of
    the chapters in the book. So, the *Technical requirements* section in each chapter
    will point to the name of the correct environment YAML file contained in the book’s
    repository.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从环境文件创建 `conda` 环境的模式是设置书中每一章示例运行环境的一个好方法。因此，每一章的 *技术要求* 部分将指向书中仓库中包含的正确环境 YAML
    文件名称。
- en: These commands, coupled with your classic `conda` or `pip install` command,
    will set you up for your project quite nicely!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令与您经典的 `conda` 或 `pip install` 命令结合使用，将为您的项目设置得相当好！
- en: '[PRE5]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Or
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE6]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: I think it’s always a good practice to have many options for doing something,
    and in general, this is good engineering practice. So given that, now that we
    have covered the classic Python environment and package managers in `conda` and
    `pip`, we will cover one more package manager. This is a tool that I like for
    its ease of use and versatility. I think it provides a nice extension of the capabilities
    of `conda` and `pip` and can be used to complement them nicely. This tool is called
    Poetry and it is what we turn to now.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为拥有多种执行某事的方法总是好的，而且通常这是良好的工程实践。因此，既然我们已经介绍了经典的 Python 环境、`conda` 和 `pip` 包管理器，我们将介绍另一个包管理器。这是一个我喜欢其易用性和多功能性的工具。我认为它为
    `conda` 和 `pip` 提供了很好的功能扩展，并且可以很好地补充它们。这个工具叫做 Poetry，我们现在就转向它。
- en: Poetry
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Poetry
- en: Poetry is another package manager that has become very popular in recent years.
    It allows you to manage your project’s dependencies and package information into
    a single configuration file in a similar way to the environment YAML file we discussed
    in the section on Conda. Poetry’s strength lies in its far superior ability to
    help you manage complex dependencies and ensure “deterministic” builds, meaning
    that you don’t have to worry about the dependency of a package updating in the
    background and breaking your solution. It does this via the use of “lock files”
    as a core feature, as well as in-depth dependency checking. This means that reproducibility
    can often be easier in Poetry. It is important to call out that Poetry is focused
    on Python package management specifically, while Conda can also install and manage
    other packages, for example, C++ libraries. One way to think of Poetry is that
    it is like an upgrade of the `pip` Python installation package, but one that also
    has some environment management capability. The next steps will explain how to
    set up and use Poetry for a very basic use case.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Poetry 是另一种近年来变得非常流行的包管理器。它允许您以类似于我们在 Conda 部分讨论的环境 YAML 文件的方式，将项目的依赖项和包信息管理到一个单独的配置文件中。Poetry
    的优势在于其远超其他工具的复杂依赖项管理能力，并确保“确定性”构建，这意味着您不必担心包在后台更新而破坏您的解决方案。它是通过使用“锁定文件”作为核心功能以及深入的依赖项检查来实现的。这意味着在
    Poetry 中，可重复性通常更容易实现。重要的是要指出，Poetry 专注于特定的 Python 包管理，而 Conda 也可以安装和管理其他包，例如 C++
    库。可以这样理解 Poetry：它就像是 `pip` Python 安装包的升级版，但同时也具备一些环境管理功能。接下来的步骤将解释如何设置和使用 Poetry
    以进行非常基本的用例。
- en: 'We will build on this with some later examples in the book. First, follow these
    steps:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的一些后续示例中继续这一内容。首先，按照以下步骤操作：
- en: 'First, as usual, we will install Poetry:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，像往常一样，我们将安装 Poetry：
- en: '[PRE7]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After Poetry is installed, you can create a new project using the `poetry new`
    command, followed by the name of your project:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Poetry 后，您可以使用 `poetry new` 命令创建一个新的项目，后面跟上是您项目的名称：
- en: '[PRE8]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will create a new directory named `mleng-with-python` with the necessary
    files and directories for a Python project. To manage your project’s dependencies,
    you can add them to the `pyproject.toml` file in the root directory of your project.
    This file contains all of the configuration information for your project, including
    its dependencies and package metadata.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建一个名为 `mleng-with-python` 的新目录，其中包含 Python 项目的必要文件和目录。要管理您项目的依赖项，您可以将它们添加到项目根目录下的
    `pyproject.toml` 文件中。此文件包含您项目的所有配置信息，包括其依赖项和包元数据。
- en: 'For example, if you are building a ML project and want to use the `scikit-learn`
    library, you would add the following to your `pyproject.toml` file:'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，如果您正在构建一个机器学习项目并想使用 `scikit-learn` 库，您会在 `pyproject.toml` 文件中添加以下内容：
- en: '[PRE9]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You can then install the dependencies for your project by running the following
    command. This will install the `scikit-learn` library and any other dependencies
    specified in your `pyproject.toml` file:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以通过运行以下命令安装您项目的依赖项。这将安装 `scikit-learn` 库以及您在 `pyproject.toml` 文件中指定的任何其他依赖项：
- en: '[PRE10]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To use a dependency in your project, you can simply import it in your Python
    code like so:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在您的项目中使用依赖项，您只需像这样在 Python 代码中导入它即可：
- en: '[PRE11]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, getting started with Poetry is very easy. We will return to
    using Poetry throughout the book in order to give you examples that complement
    the knowledge of Conda that we will develop. *Chapter 4*, *Packaging Up*, will
    discuss this in detail and will show you how to get the most out of Poetry.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，开始使用 Poetry 非常简单。我们将在本书中多次使用 Poetry，以便为您提供与我们将开发的 Conda 知识相补充的示例。*第 4 章*，*打包*，将详细讨论这一点，并展示如何充分利用
    Poetry。
- en: Code version control
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码版本控制
- en: If you are going to write code for real systems, you are almost certainly going
    to do it as part of a team. You are also going to make your life easier if you
    can have a clean audit trail of changes, edits, and updates so that you can see
    how the solution has developed. Finally, you are going to want to cleanly and
    safely separate out the stable versions of the solution that you are building
    and that can be deployed versus more transient developmental versions. All of
    this, thankfully, is taken care of by source code version control systems, the
    most popular of which is **Git**.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将要为真实系统编写代码，你几乎肯定将会作为团队的一部分来做。如果你能够有一个清晰的变更、编辑和更新审计记录，那么你会更容易看到解决方案是如何发展的。最后，你将想要干净且安全地将你正在构建的稳定版本与可以部署的版本以及更短暂的开发版本分开。幸运的是，所有这些都可以由源代码版本控制系统来处理，其中最受欢迎的是**Git**。
- en: 'We will not go into how Git works under the hood here (there are whole books
    on the topic!) but we will focus on understanding the key practical elements of
    using it:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会在这里深入探讨Git底层是如何工作的（关于这个话题有整本书的讨论！）但我们将会关注理解使用Git的关键实践要素：
- en: 'You already have a GitHub account from earlier in the chapter, so the first
    thing to do is to create a repository with Python as the language and initialize
    `README.md` and `.gitignore` files. The next thing to do is to get a local copy
    of this repository by running the following command in Bash, Git Bash, or another
    terminal:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你在章节的早期已经有一个GitHub账户了，所以首先要做的是创建一个以Python为语言的仓库，并初始化`README.md`和`.gitignore`文件。接下来要做的是通过在Bash、Git
    Bash或其他终端中运行以下命令来获取这个仓库的本地副本：
- en: '[PRE12]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that you have done this, go into the `README.md` file and make some edits
    (anything will do). Then, run the following commands to tell Git to *monitor*
    this file and to save your changes locally with a message briefly explaining what
    these are:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经完成了这个步骤，进入`README.md`文件并进行一些编辑（任何内容都可以）。然后，运行以下命令来告诉Git监控这个文件，并使用简短的消息保存你的更改：
- en: '[PRE13]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This now means that your local Git instance has stored what you’ve changed and
    is ready to share that with the remote repo.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这现在意味着你的本地Git实例已经存储了你所做的更改，并准备好与远程仓库共享这些更改。
- en: 'You can then incorporate these changes into the `main` branch by doing the
    following:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以通过以下步骤将这些更改合并到`main`分支：
- en: '[PRE14]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If you now go back to the GitHub site, you will see that the changes have taken
    place in your remote repository and that the comments you added have accompanied
    the change.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你现在回到GitHub网站，你会看到你的远程仓库中发生了更改，你添加的评论也伴随着这个更改。
- en: 'Other people in your team can then get the updated changes by running the following:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的团队成员可以通过运行以下命令来获取更新的更改：
- en: '[PRE15]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: These steps are the absolute basics of Git and there is a ton more you can learn
    online. What we will do now, though, is start setting up our repo and workflow
    in a way that is relevant to ML engineering.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤是Git的绝对基础，你可以在网上学到更多。不过，我们现在要做的是以与机器学习工程相关的方式设置我们的仓库和工作流程。
- en: Git strategies
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Git策略
- en: The presence of a strategy for using version control systems can often be a
    key differentiator between the data science and ML engineering aspects of a project.
    It can sometimes be overkill to define a strict Git strategy for exploratory and
    basic modeling stages (*Discover* and *Play*) but if you want to engineer something
    for deployment (and you are reading this book, so this is likely where your head
    is at), then it is fundamentally important.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个项目中，使用版本控制系统的策略通常可以成为区分数据科学和机器学习工程方面的重要因素。在探索性和基本建模阶段（*发现*和*玩耍*）定义严格的Git策略可能有些过度，但如果你想要为部署构建某些内容（而且你正在阅读这本书，所以这很可能是你的目标），那么这基本上是非常重要的。
- en: Great, but what do we mean by a Git strategy?
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，但我们所说的Git策略是什么意思呢？
- en: Well, let’s imagine that we just try to develop our solution without a shared
    direction on how to organize the versioning and code.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，让我们假设我们试图在没有共享版本组织和代码组织方向的情况下开发我们的解决方案。
- en: 'ML engineer *A* wants to start building some of the data science code into
    a Spark ML pipeline (more on this later) so creates a branch from `main` called
    `pipeline1spark`:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工程师*A*想要开始将一些数据科学代码构建到Spark ML管道中（关于这一点稍后会有更多介绍），因此从`main`分支创建了一个名为`pipeline1spark`的分支：
- en: '[PRE16]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'They then get to work on the branch and writes some nice code in a new file
    called `pipeline.py`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 他们然后开始在这个分支上工作，并在一个名为`pipeline.py`的新文件中编写了一些优秀的代码：
- en: '[PRE17]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Great, they’ve made some excellent progress in translating some previous `sklearn`
    code into Spark, which was deemed more appropriate for the use case. They then
    keep working in this branch because it has all of their additions, and they think
    it’s better to do everything in one place. When they want to push the branch to
    the remote repository, they run the following commands:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，他们已经将一些之前的 `sklearn` 代码翻译成了 Spark，这被认为更适合用例。然后他们继续在这个分支上工作，因为它包含了他们所有的添加，他们认为最好在一个地方完成所有工作。当他们想要将分支推送到远程仓库时，他们运行以下命令：
- en: '[PRE18]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'ML engineer *B* comes along, and they want to use ML engineer *A*’s pipeline
    code and build some extra steps around it. They know engineer *A*’s code has a
    branch with this work, so they know enough about Git to create another branch
    with *A*’s code in it, which *B* calls `pipeline`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工程师 *B* 加入进来，他们想使用机器学习工程师 *A* 的管道代码，并在其周围构建一些额外的步骤。他们知道工程师 *A* 的代码有一个包含这项工作的分支，所以他们足够了解
    Git，可以创建一个包含 *A* 代码的另一个分支，*B* 称之为 `pipeline`：
- en: '[PRE19]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'They then add some code to read the parameters for the model from a variable:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 他们接着添加了一些代码来从变量中读取模型的参数：
- en: '[PRE20]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Cool, engineer *B* has made an update that is starting to abstract away some
    of the parameters. They then push their new branch to the remote repository:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷，工程师 *B* 做了一个更新，开始抽象掉一些参数。然后他们把新的分支推送到远程仓库：
- en: '[PRE21]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally, ML engineer *C* joins the team and wants to get started on the code.
    Opening up Git and looking at the branches, they see there are three:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，机器学习工程师 *C* 加入到团队中，并想开始编写代码。打开 Git 并查看分支，他们看到有三个：
- en: '[PRE22]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So, which one should be taken as the most up to date? If they want to make
    new edits, where should they branch from? It isn’t clear, but more dangerous than
    that is if they are tasked with pushing deployment code to the execution environment,
    they may think that `main` has all the relevant changes. On a far busier project
    that’s been going on for a while, they may even branch off from `main` and duplicate
    some of *B* and *C*’s work! In a small project, you would waste time going on
    this wild goose chase; in a large project with many different lines of work, you
    would have very little chance of maintaining a good workflow:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，哪个应该被视为最新的？如果他们想进行新的编辑，他们应该从哪里分支？这并不清楚，但更危险的是，如果他们被要求将部署代码推送到执行环境，他们可能会认为
    `main` 包含了所有相关更改。在一个已经进行了很长时间且非常繁忙的项目中，他们甚至可能会从 `main` 分支中分支出来，并复制一些 *B* 和 *C*
    的工作！在一个小项目中，你会浪费时间进行这种无谓的追逐；在一个大项目中有许多不同的工作线，你几乎不可能保持良好的工作流程：
- en: '[PRE23]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If these commits both get pushed to the `main` branch at the same time, then
    we will get what is called a **merge conflict**, and in each case, the engineer
    will have to choose which piece of code to keep, the current or new example. This
    would look something like this if engineer *A* pushed their changes to `main`
    first:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这两个提交同时推送到 `main` 分支，那么我们就会得到所谓的**合并冲突**，在这种情况下，工程师将不得不选择保留哪段代码，是当前的还是新的示例。如果工程师
    *A* 首先将其更改推送到 `main`，这看起来可能如下所示：
- en: '[PRE24]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The delimiters in the code show that there has been a merge conflict and that
    it is up to the developer to select which of the two versions of the code they
    want to keep.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的分隔符表明存在合并冲突，并且取决于开发者选择保留哪两个代码版本。
- en: IMPORTANT NOTE
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Although, in this simple case, we could potentially trust the engineers to select
    the *better* code, allowing situations like this to occur very frequently is a
    huge risk to your project. This not only wastes a huge amount of precious development
    time but it could also mean that you actually end up with worse code!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在这个简单的情况下，我们可能可以信任工程师选择**更好的**代码，但允许这种情况频繁发生对你的项目来说是一个巨大的风险。这不仅会浪费大量宝贵的发展时间，还可能意味着你最终得到的代码质量更差！
- en: The way to avoid confusion and extra work like this is to have a very clear
    strategy for the use of the version control system in place, such as the one we
    will now explore.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 避免混淆和额外工作的方法是制定一个非常清晰的策略，用于实施版本控制系统，例如我们现在将要探讨的策略。
- en: The Gitflow workflow
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Gitflow 工作流程
- en: The biggest problem with the previous example was that all of our hypothetical
    engineers were actually working on the same piece of code in different places.
    To stop situations like this, you have to create a process that your team can
    all follow – in other words, a version control strategy or workflow.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 之前示例的最大问题是，我们假设的所有工程师实际上都在不同地方工作着同一块代码。为了阻止这种情况发生，你必须创建一个团队都可以遵循的过程——换句话说，一个版本控制策略或工作流程。
- en: One of the most popular of these strategies is the **Gitflow workflow**. This
    builds on the basic idea of having branches that are dedicated to features and
    extends it to incorporate the concept of releases and hotfixes, which are particularly
    relevant to projects with a continuous deployment element.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略中最受欢迎之一是**Gitflow工作流程**。它基于拥有专门用于功能的分支的基本想法，并将其扩展到包含发布和热修复的概念，这对于具有持续部署元素的项目尤其相关。
- en: 'The main idea is we have several types of branches, each with clear and specific
    reasons for existing:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是我们有几种类型的分支，每种分支都有明确和具体的存在原因：
- en: '**Main** contains your official releases and should only contain the stable
    version of your code.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主分支**包含您的官方发布版本，应只包含代码的稳定版本。'
- en: '**Dev** acts as the main point for branching from and merging to for most work
    in the repository; it contains the ongoing development of the code base and acts
    as a staging area before `main`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发分支**是大多数仓库中从其分支和合并到的主要点；它包含代码库的持续开发，并在`main`之前作为预发布区域。'
- en: '**Feature** branches should not be merged straight into the `main` branch;
    everything should branch off from `dev` and then be merged back into `dev`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能分支**不应直接合并到`main`分支；所有内容都应该从`dev`分支开始，然后合并回`dev`。'
- en: '**Release** branches are created from `dev` to kick off a build or release
    process before being merged into `main` and `dev` and then deleted.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布分支**从`dev`创建，在合并到`main`和`dev`并删除之前启动构建或发布过程。'
- en: '**Hotfix** branches are for removing bugs in deployed or production software.
    You can branch this from `main` before merging into `main` and `dev` when done.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**热修复分支**用于从已部署或生产软件中移除错误。您可以在合并到`main`和`dev`之前从`main`分支创建此分支。'
- en: 'This can all be summarized diagrammatically as in *Figure 2.9*, which shows
    how the different branches contribute to the evolution of your code base in the
    Gitflow workflow:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都可以用图2.9进行图解总结，该图显示了不同分支在Gitflow工作流程中如何贡献于代码库的演变：
- en: '![Figure 2.11 – The Gitflow Workflow ](img/B19525_02_09.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11 – Gitflow工作流程](img/B19525_02_09.png)'
- en: 'Figure 2.9: The Gitflow workflow.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：Gitflow工作流程。
- en: This diagram is taken from [https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/](https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/).
    More details can be found at [https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此图来自[https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/](https://lucamezzalira.com/2014/03/10/git-flow-vs-github-flow/)。更多详情可以在[https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow)找到。
- en: 'If your ML project can follow this sort of strategy (and you don’t need to
    be completely strict about this if you want to adapt it), you will likely see
    a drastic improvement in productivity, code quality, and even documentation:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的机器学习项目可以遵循这种策略（如果您想进行适应性调整，则不需要对此过于严格），您可能会看到生产率、代码质量和甚至文档的显著提高：
- en: '![Figure 2.12 – Example code changes upon a pull request in GitHub ](img/B19525_02_10.png)Figure
    2.10: Example code changes upon a pull request in GitHub.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.12 – GitHub上拉取请求的示例代码更改](img/B19525_02_10.png)图2.10：GitHub上拉取请求的示例代码更改。'
- en: One important aspect we haven’t discussed yet is the concept of code reviews.
    These are triggered in this process by what is known as a **pull request**, where
    you make known your intention to merge into another branch and allow another team
    member to review your code before this executes. This is the natural way to introduce
    code review to your workflow. You do this whenever you want to merge your changes
    and update them into dev or main branches. The proposed changes can then be made
    visible to the rest of the team, where they can be debated and iterated on with
    further commits before completing the merge.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未讨论的一个重要方面是代码审查的概念。这些审查通过所谓的**拉取请求**触发，您通过拉取请求表明您合并到另一个分支的意图，并允许其他团队成员在执行之前审查您的代码。这是将代码审查引入工作流程的自然方式。您可以在想要合并更改并更新到dev或main分支时进行此操作。建议的更改然后可以呈现给整个团队，他们可以在合并完成之前通过进一步的提交进行辩论和迭代。
- en: This enforces code review to improve quality, as well as creating an audit trail
    and safeguards for updates. *Figure 2.10* shows an example of how changes to code
    are made visible for debate during a pull request in GitHub.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这强制进行代码审查以提高质量，同时创建审计跟踪和更新保障。*图2.10*展示了在GitHub拉取请求期间如何使代码更改可见以供辩论的示例。
- en: Now that we have discussed some of the best practices for applying version control
    to your code, let’s explore how to version control the models you produce during
    your ML project.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了一些将版本控制应用于您的代码的最佳实践，让我们探索如何在机器学习项目中实现模型的版本控制。
- en: Model version control
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型版本控制
- en: In any ML engineering project, it is not only code changes that you have to
    track clearly but also changes in your models. You want to track changes not only
    in the modeling approach but also in performance when new or different data is
    fed into your chosen algorithms. One of the best tools for tracking these kinds
    of changes and providing version control of ML models is **MLflow**, an open-source
    platform from **Databricks** under the stewardship of the Linux Foundation.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何机器学习工程项目中，您不仅要清晰地跟踪代码更改，还要跟踪模型的变化。您希望跟踪的不仅仅是建模方法的变化，还包括当新的或不同的数据输入到您选择的算法中时的性能变化。跟踪这些变化并提供机器模型版本控制的最佳工具之一是**MLflow**，这是一个由Linux基金会监管的开源平台，由**Databricks**提供。
- en: 'To install MLflow, run the following command in your chosen Python environment:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装MLflow，请在您选择的Python环境中运行以下命令：
- en: '[PRE25]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The main aim of MLflow is to provide a platform via which you can log model
    experiments, artifacts, and performance metrics. It does this through some very
    simple APIs provided by the Python `mlflow` library, interfaced to selected storage
    solutions through a series of centrally developed and community plugins. It also
    comes with functionality for querying, analyzing, and importing/exporting data
    via a **Graphical User Interface** (**GUI**), which will look something like *Figure
    2.11*:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow的主要目标是提供一个平台，通过该平台您可以记录模型实验、工件和性能指标。它是通过Python `mlflow`库提供的非常简单的API实现的，通过一系列中央开发社区插件与选定的存储解决方案接口。它还提供了通过**图形用户界面**（**GUI**）查询、分析和导入/导出数据的功能，其外观类似于*图2.11*：
- en: '![Figure 2.13 – The MLflow Tracking Server UI with some forecasting runs ](img/B19525_02_11.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图2.13 – MLflow跟踪服务器UI和一些预测运行](img/B19525_02_11.png)'
- en: 'Figure 2.11: The MLflow tracking server UI with some forecasting runs.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11：MLflow跟踪服务器UI和一些预测运行。
- en: 'The library is extremely easy to use. In the following example, we will take
    the sales forecasting example from *Chapter 1*, *Introduction to ML Engineering*,
    and add some basic MLflow functionality for tracking performance metrics and saving
    the trained Prophet model:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图书馆的使用极其简单。以下示例中，我们将从*第一章*，*机器学习工程导论*中的销售预测示例开始，并添加一些基本的MLflow功能以跟踪性能指标和保存训练好的Prophet模型：
- en: 'First, we make the relevant imports, including MLflow’s `pyfunc` module, which
    acts as a general interface for saving and loading models that can be written
    as Python functions. This facilitates working with libraries and tools not natively
    supported in MLflow (such as the `fbprophet` library):'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们进行相关的导入，包括MLflow的`pyfunc`模块，它作为可以编写为Python函数的模型的保存和加载的通用接口。这有助于与MLflow原生不支持（如`fbprophet`库）的库和工具一起工作：
- en: '[PRE26]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To create a more seamless integration with the forecasting models from `fbprophet`,
    we define a small wrapper class that inherits from the `mlflow.pyfunc.PythonModel`
    object:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了与`fbprophet`的预测模型实现更无缝的集成，我们定义了一个小的包装类，它继承自`mlflow.pyfunc.PythonModel`对象：
- en: '[PRE27]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We now wrap the functionality for training and prediction into a single helper
    function called `train_predict()` to make running multiple times simpler. We will
    not define all of the details inside this function here but let’s run through
    the main pieces of MLflow functionality contained within it.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们将训练和预测的功能封装到一个名为`train_predict()`的单个辅助函数中，以便简化多次运行。我们不会在这里定义这个函数的所有细节，但让我们浏览一下其中包含的MLflow功能的主要部分。
- en: 'First, we need to let MLflow know that we are now starting a training run we
    wish to track:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要让MLflow知道我们现在开始一个希望跟踪的训练运行：
- en: '[PRE28]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Inside this loop, we then define and train the model, using parameters defined
    elsewhere in the code:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个循环内部，我们定义并训练模型，使用代码中其他地方定义的参数：
- en: '[PRE29]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We then perform some cross-validation to calculate some metrics we would like
    to log:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们进行交叉验证来计算我们想要记录的一些指标：
- en: '[PRE30]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can log these metrics, for example, the **Root Mean Squared Error** (**RMSE**)
    here, to our MLflow server:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将这些指标记录下来，例如，这里的**均方根误差**（**RMSE**），到我们的MLflow服务器：
- en: '[PRE31]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then finally, we can use our model wrapper class to log the model and print
    some information about the run:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以使用我们的模型包装类来记录模型并打印一些关于运行的信息：
- en: '[PRE32]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: With only a few extra lines, we have started to perform version control on our
    models and track the statistics of different runs!
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只需添加几行额外的代码，我们就已经开始对我们的模型进行版本控制并跟踪不同运行状态的统计数据了！
- en: 'There are many different ways to save the ML model you have built to MLflow
    (and in general), which is particularly important when tracking model versions.
    Some of the main options are as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 将你构建的机器学习模型保存到 MLflow（以及一般情况）有许多不同的方法，这在跟踪模型版本时尤其重要。以下是一些主要选项：
- en: '**pickle**: `pickle` is a Python library for object serialization that is often
    used for the export of ML models that are written in `scikit-learn` or pipelines
    in the wider `scipy` ecosystem ([https://docs.python.org/3/library/pickle.xhtml#module-pickle](https://docs.python.org/3/library/pickle.xhtml#module-pickle)).
    Although it is extremely easy to use and often very fast, you must be careful
    when exporting your models to `pickle` files because of the following:'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pickle**：`pickle` 是一个用于对象序列化的 Python 库，通常用于导出在 `scikit-learn` 或更广泛的 `scipy`
    生态系统中的管道。尽管它非常容易使用且通常非常快，但在将你的模型导出为 `pickle` 文件时必须小心，因为以下原因：'
- en: '**Versioning**: When you pickle an object, you have to unpickle it in other
    programs using the *same version of pickle* for stability reasons. This adds more
    complexity to managing your project.'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制**：当你 pickle 一个对象时，你必须使用与其他程序中相同的 `pickle` 版本来反序列化它，出于稳定性的原因。这增加了管理你的项目的复杂性。'
- en: '**Security**: The documentation for `pickle` states clearly that it is *not
    secure* and that it is very easy to construct malicious pickles, which will execute
    dangerous code upon unpickling. This is a very important consideration, especially
    as you move toward production.'
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：`pickle` 的文档明确指出它是不安全的，并且很容易构造恶意的 pickle，这些 pickle 在反序列化时会执行危险的代码。这是一个非常重要的考虑因素，尤其是在你向生产环境迈进时。'
- en: In general, as long as the lineage of the `pickle` files you use is known and
    the source is trusted, they are OK to use and a very simple and fast way to share
    your models!
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通常，只要你知道你使用的 `pickle` 文件的历史来源并且来源是可信的，它们就可以安全使用，并且是一种简单快速地分享你的模型的方法！
- en: '**joblib**: `joblib` is a general-purpose pipelining library in Python that
    is very powerful but lightweight. It has a lot of really useful capabilities centered
    around caching, parallelizing, and compression that make it a very versatile tool
    for saving and reading in your ML pipelines. It is also particularly fast for
    storing large `NumPy` arrays, so is useful for data storage. We will use `joblib`
    more in later chapters. It is important to note that `joblib` suffers from the
    same security issues as `pickle`, so knowing the lineage of your `joblib` files
    is incredibly important.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**joblib**：`joblib` 是一个功能强大但轻量级的 Python 通用管道库。它围绕缓存、并行化和压缩等许多非常有用的功能，使其成为保存和读取你的机器学习管道的非常通用的工具。它对于存储大型
    `NumPy` 数组也非常快，因此对于数据存储很有用。我们将在后面的章节中更多地使用 `joblib`。重要的是要注意，`joblib` 与 `pickle`
    一样存在相同的安全问题，因此了解你的 `joblib` 文件的历史来源至关重要。'
- en: '**JSON**: If `pickle` and `joblib` aren’t appropriate, you can serialize your
    model and its parameters in JSON format. This is good because JSON is a standardized
    text serialization format that is commonly used across a variety of solutions
    and platforms. The caveat to using JSON serialization of your models is that you
    often have to manually define the JSON structure with the relevant parameters
    you want to store. So, it can create a lot of extra work. Several ML libraries
    in Python have their own export to JSON functionality, for example, the deep learning
    package Keras, but they can all result in quite different formats.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JSON**：如果 `pickle` 和 `joblib` 不适用，你可以将你的模型及其参数序列化为 JSON 格式。这很好，因为 JSON 是一种标准化的文本序列化格式，在许多解决方案和平台上广泛使用。但是，使用
    JSON 序列化你的模型有一个缺点，那就是你通常必须手动定义包含你想要存储的相关参数的 JSON 结构。因此，这可能会产生大量的额外工作。Python 中的一些机器学习库都有自己的导出为
    JSON 的功能，例如深度学习包 Keras，但它们都可以产生相当不同的格式。'
- en: '**MLeap**: MLeap is a serialization format and execution engine based on the
    **Java Virtual Machine** (**JVM**). It has integrations with Scala, PySpark, and
    Scikit-Learn but you will often see it used in examples and tutorials for saving
    Spark pipelines, especially for models built with Spark ML. This focus means it
    is not the most flexible of formats but is very useful if you are working in the
    **Spark ecosystem**.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLeap**：MLeap是基于**Java虚拟机**（**JVM**）的序列化格式和执行引擎。它与Scala、PySpark和Scikit-Learn有集成，但您通常会在示例和教程中看到它用于保存Spark管道，特别是对于使用Spark
    ML构建的模型。这种关注意味着它不是最灵活的格式，但如果您在**Spark生态系统**中工作，它非常有用。'
- en: '**ONNX**: The **Open Neural Network Exchange** (**ONNX**) format is aimed at
    being completely cross-platform and allowing the exchange of models between the
    main ML frameworks and ecosystems. The main downside of ONNX is that (as you can
    guess from the name) it is mainly aimed at neural network-based models, with the
    exception of its `scikit-learn` API. It is an excellent option if you are building
    a neural network though.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ONNX**：**开放神经网络交换**（**ONNX**）格式旨在实现完全跨平台，并允许主要机器学习框架和生态系统之间交换模型。ONNX的主要缺点是（正如您可以从其名称中猜到的）它主要针对基于神经网络的模型，除了其`scikit-learn`
    API之外。如果您正在构建神经网络，这仍然是一个极好的选择。'
- en: In *Chapter 3*, *From Model to Model Factory*, we will export our models to
    MLflow using some of these formats, but they are all compatible with MLflow and
    so you should feel comfortable using them as part of your ML engineering workflow.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第3章**，**从模型到模型工厂**中，我们将使用这些格式中的一些将我们的模型导出到MLflow，但它们都与MLflow兼容，因此您应该在使用它们作为您机器学习工程工作流程的一部分时感到舒适。
- en: The final section of this chapter will introduce some important concepts for
    planning how you wish to deploy your solution, prefacing more detailed discussions
    later in the book.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后一节将介绍一些重要的概念，用于规划您希望如何部署您的解决方案，为书中稍后更详细的讨论做铺垫。
- en: Deploy
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署
- en: 'The final stage of the ML development process is the one that really matters:
    how do you get the amazing solution you have built out into the real world and
    solve your original problem? The answer has multiple parts, some of which will
    occupy us more thoroughly later in this book but will be outlined in this section.
    If we are to successfully deploy our solution, first of all, we need to know our
    deployment options: what infrastructure is available and is appropriate for the
    task? We then need to get the solution from our development environment onto this
    production infrastructure so that, subject to appropriate orchestration and controls,
    it can execute the tasks we need it to and surface the results where it has to.
    This is where the concepts of **DevOps** and **MLOps** come into play.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习开发过程的最后阶段才是真正重要的：您如何将您构建的令人惊叹的解决方案带入现实世界并解决您最初的问题？答案有多个部分，其中一些将在本书稍后更详细地探讨，但将在本节中概述。如果我们想要成功部署我们的解决方案，首先，我们需要了解我们的部署选项：有什么基础设施可供选择，并且适合这项任务？然后，我们需要将解决方案从我们的开发环境转移到这个生产基础设施上，以便在适当的编排和控制下，它能够执行我们需要的任务，并在需要的地方展示结果。这就是**DevOps**和**MLOps**概念发挥作用的地方。
- en: Let’s elaborate on these two core concepts, laying the groundwork for later
    chapters and exploring how to begin deploying our work.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细阐述这两个核心概念，为后续章节奠定基础，并探讨如何开始部署我们的工作。
- en: Knowing your deployment options
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解您的部署选项
- en: 'In *Chapter 5*, *Deployment Patterns and Tools*, we will cover in detail what
    you need to get your ML engineering project from the **develop** to **deploy**
    stage, but to pre-empt that and provide a taster of what is to come, let’s explore
    the different types of deployment options we have at our disposal:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第5章**，**部署模式和工具**中，我们将详细介绍您需要将您的机器学习工程项目从**开发**阶段过渡到**部署**阶段，但为了提前预告并为您提供即将到来的内容的预览，让我们探索我们可用的不同部署选项：
- en: '**On-premises deployment**: The first option we have is to ignore the public
    cloud altogether and deploy our solutions in-house on owned infrastructure. This
    option is particularly popular and necessary for a lot of large institutions with
    a lot of legacy software and strong regulatory constraints on data location and
    processing. The basic steps for deploying on-premises are the same as deploying
    on the cloud but often require a lot more involvement from other teams with particular
    specialties. For example, if you are in the cloud, you often do not need to spend
    a lot of time configuring networking or implementing load balancers, whereas on-premises
    solutions will require these.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地部署**：我们拥有的第一个选择是完全忽略公有云，并在我们拥有的基础设施上内部部署我们的解决方案。这个选项对于许多拥有大量遗留软件和强烈数据位置和数据处理监管约束的大型机构来说尤其受欢迎和必要。本地部署的基本步骤与云上部署相同，但通常需要来自其他具有特定专业知识的团队的大量参与。例如，如果你在云上，你通常不需要花很多时间配置网络或实现负载均衡器，而本地解决方案将需要这些。'
- en: The big advantage of on-premises deployment is security and peace of mind that
    none of your data is going to traverse your company firewall. The big downsides
    are that it requires a larger investment upfront for hardware and that you have
    to expend a lot of effort to successfully configure and manage that hardware effectively.
    We will not be discussing on-premises deployment in detail in this book, but all
    of the concepts we will employ around software development, packaging, environment
    management, and training and prediction systems still apply.
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本地部署的大优势是安全性和安心感，即你的数据不会穿越公司的防火墙。缺点是它需要更大的前期硬件投资，而且你必须付出大量努力才能有效地配置和管理该硬件。在这本书中，我们不会详细讨论本地部署，但我们将在软件开发、打包、环境管理、培训和预测系统等方面使用的所有概念仍然适用。
- en: '**Infrastructure-as-a-Service** (**IaaS**): If you are going to use the cloud,
    one of the lowest levels of abstraction you have access to for deployment is IaaS
    solutions. These are typically based on the concept of virtualization, such that
    servers with a variety of specifications can be spun up at the user’s will. These
    solutions often abstract away the need for maintenance and operations as part
    of the service. Most importantly, they allow extreme scalability of your infrastructure
    as you need it. Have to run 100 more servers next week? No problem, just scale
    up your IaaS request and there it is. Although IaaS solutions are a big step up
    from fully managed on-premises infrastructure, there are still several things
    you need to think about and configure. The balance in cloud computing is always
    over how easy you want things to be versus what level of control you want to have.
    IaaS maximizes control but minimizes (relative) ease compared to some other solutions.
    In **AWS**, **Simple Storage Service** (**S3**) and **Elastic Compute Cloud**
    (**EC2**) are good examples of IaaS offerings.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即服务**（**IaaS**）：如果你打算使用云，你可用于部署的最低抽象级别之一是IaaS解决方案。这些通常基于虚拟化的概念，即可以根据用户的意愿启动具有各种规格的服务器。这些解决方案通常将维护和操作的需求抽象化，作为服务的一部分。最重要的是，它们允许你的基础设施在需要时具有极端的可扩展性。下周需要运行100多台服务器？没问题，只需扩展你的IaaS请求，它就会出现。尽管IaaS解决方案比完全管理的本地基础设施迈出了很大一步，但仍有几件事情你需要考虑和配置。云计算中的平衡始终在于你希望事情有多容易，以及你希望有多少控制权。与某些其他解决方案相比，IaaS最大化了控制权，但最小化了（相对的）易用性。在**AWS**中，**简单存储服务**（**S3**）和**弹性计算云**（**EC2**）是IaaS提供的良好例子。'
- en: '**Platform-as-a-Service** (**PaaS**): PaaS solutions are the next level up
    in terms of abstraction and usually provide you with a lot of capabilities without
    needing to know exactly what is going on under the hood. This means you can focus
    solely on the development tasks that the platform is geared up to support, without
    worrying about underlying infrastructure at all. One good example is **AWS** **Lambda**
    functions, which are serverless functions that can scale almost without limit.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平台即服务**（**PaaS**）：PaaS解决方案在抽象层面上是下一个级别，通常提供许多功能，而无需了解底层具体发生什么。这意味着你可以专注于平台准备支持的开发任务，而无需担心任何底层基础设施。一个很好的例子是**AWS
    Lambda**函数，这是一种无服务器函数，几乎可以无限制地扩展。'
- en: All you are required to do is enter the main piece of code you want to execute
    inside the function. Another good example is **Databricks**, which provides a
    very intuitive UI on top of the **Spark cluster** infrastructure, with the ability
    to provision, configure, and scale up these clusters almost seamlessly.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的只是将你想要在函数内部执行的主要代码块输入进去。另一个很好的例子是**Databricks**，它提供了在**Spark集群**基础设施之上的非常直观的用户界面，几乎无缝地提供、配置和扩展这些集群。
- en: Being aware of these different options and their capabilities can help you design
    your ML solution and ensure that you focus your team’s engineering effort where
    it is most needed and will be most valuable. If your ML engineer is working on
    configuring routers, for example, you have definitely gone wrong somewhere.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些不同选项及其功能可以帮助你设计你的机器学习解决方案，并确保你将团队的技术努力集中在最需要和最有价值的地方。例如，如果你的机器学习工程师正在配置路由器，那么你肯定在某些地方犯了错误。
- en: But once you have selected the components you’ll use and provisioned the infrastructure,
    how do you integrate these together and manage your deployment and update cycles?
    This is what we will explore now.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 但一旦你选择了要使用的组件并配置了基础设施，你该如何将这些组件集成在一起并管理你的部署和更新周期呢？这正是我们现在要探讨的。
- en: Understanding DevOps and MLOps
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解DevOps和MLOps
- en: A very powerful idea in modern software development is that your team should
    be able to continuously update your code base as needed, while testing, integrating,
    building, packaging, and deploying your solution should be as automated as possible.
    This then means these processes can happen on an almost continual basis without
    big pre-planned **buckets** of time being assigned to update cycles. This is the
    main idea behind **CI/CD**. CI/CD is a core part of **DevOps** and its ML-focused
    cousin **MLOps**, which both aim to bring together software development and post-deployment
    operations. Several of the concepts and solutions we will develop in this book
    will be built up so that they naturally fit within an MLOps framework.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现代软件开发中的一个非常有力的观点是，你的团队应该能够根据需要持续更新代码库，同时测试、集成、构建、打包和部署解决方案应该尽可能地自动化。这意味着这些流程可以几乎持续不断地进行，而不需要分配大块预先计划的时间来更新周期。这就是**CI/CD**背后的主要思想。CI/CD是**DevOps**及其以机器学习为重点的表亲**MLOps**的核心部分，它们都旨在将软件开发和部署后的运营结合起来。本书中我们将开发的一些概念和解决方案将构建得自然地适合MLOps框架。
- en: The CI part is mainly focused on the stable incorporation of ongoing changes
    to the code base while ensuring functionality remains stable. The CD part is all
    about taking the resultant stable version of the solution and pushing it to the
    appropriate infrastructure.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: CI部分主要关注稳定地将持续变更集成到代码库中，同时确保功能保持稳定。CD部分则是将解决方案的稳定版本推送到适当的基础设施。
- en: '*Figure 2.12* shows a high-level view of this process:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.12*展示了这一过程的高级视图：'
- en: '![Figure 2.14 – A high-level view of CI/CD processes ](img/B19525_02_12.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图2.14 – CI/CD流程的高级视图](img/B19525_02_12.png)'
- en: 'Figure 2.12: A high-level view of CI/CD processes.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12：CI/CD流程的高级视图。
- en: In order to make CI/CD a reality, you need to incorporate tools that help automate
    tasks that you would traditionally perform manually in your development and deployment
    process. For example, if you can automate the running of tests upon merging of
    code, or the pushing of your code artifacts/models to the appropriate environment,
    then you are well on your way to CI/CD.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使CI/CD成为现实，你需要整合帮助自动化你传统上在开发和部署过程中手动执行的任务的工具。例如，如果你可以在代码合并时自动运行测试，或者将你的代码工件/模型推送到适当的环境，那么你就已经走上了CI/CD的道路。
- en: We can break this out further and think of the different types of tasks that
    fall into the DevOps or MLOps lifecycles for a solution. Development tasks will
    typically cover all of the activities that take you from a blank screen on your
    computer to a working piece of software. This means that development is where
    you spend most of your time in a DevOps or MLOps project. This covers everything
    from writing the code to formatting it correctly and testing it.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步分解，并考虑解决方案的DevOps或MLOps生命周期中落入的不同类型任务。开发任务通常涵盖从电脑上的空白屏幕到可工作的软件的所有活动。这意味着在DevOps或MLOps项目中，你大部分时间都花在开发上。这包括从编写代码到正确格式化并测试它的一切。
- en: '*Table 2.3* splits out these typical tasks and provides some details on how
    they build on each other, as well as typical tools you could use in your Python
    stack for enabling them.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 2.3* 将这些典型任务分开，并提供了一些关于它们如何相互依赖以及您可以在 Python 栈中使用的典型工具的详细信息。'
- en: '| **Lifecycle Stage** | **Activity** | **Details** | **Tools** |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| **生命周期阶段** | **活动** | **详细信息** | **工具** |'
- en: '| Dev | Testing | Unit tests: tests aimed at testing the functionality smallest
    pieces of code. | pytest or unittest |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 开发 | 测试 | 单元测试：针对测试代码最小功能部分的测试。 | pytest 或 unittest |'
- en: '| Integration tests: ensure that interfaces within the code and to other solutions
    work. | Selenium |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 集成测试：确保代码内部和其他解决方案之间的接口正常工作。 | Selenium |'
- en: '| Acceptance tests: business focused tests. | Behave |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 接受测试：业务导向的测试。 | Behave |'
- en: '| UI tests: ensuring any frontends behave as expected. |  |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| UI 测试：确保任何前端按预期运行。 |  |'
- en: '| Linting | Raise minor stylistic errors and bugs. | flake8 or bandit |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 代码风格检查 | 报告小的风格错误和错误。 | flake8 或 bandit |'
- en: '| Formatting | Enforce well-formatted code automatically. | black or sort |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 格式化 | 自动执行格式良好的代码。 | black 或 sort |'
- en: '| Building | The final stage of bringing the solution together. | Docker, twine,
    or pip |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 构建 | 将解决方案整合的最后阶段。 | Docker, twine 或 pip |'
- en: 'Table 2.3: Details of the development activities carried out in any DevOps
    or MLOps project.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.3：任何 DevOps 或 MLOps 项目中执行的开发活动的详细信息。
- en: Next, we can think about the ML activities within MLOps, which this book will
    be very concerned with. This covers all of the tasks that a classic Python software
    engineer would not have to worry about, but that are crucially important to get
    right for ML engineers like us. This includes the development of capabilities
    to automatically train the ML models, to run the predictions or inferences the
    model should generate, and to bring that together inside code pipelines. It also
    covers the staging and management of the versions of your models, which heavily
    complements the idea of versioning your application code, as we do using tools
    like Git. Finally, an ML engineer also has to consider that they have to build
    out specific monitoring capabilities for the operational mode of their solution,
    which is not covered in traditional DevOps workflows. For an ML solution, you
    may have to consider monitoring things like precision, recall, the f1-score, population
    stability, entropy, and data drift in order to know if the model component of
    your solution is behaving within a tolerable range. This is very different from
    classic software engineering as it requires a knowledge of how ML models work,
    how they can go wrong, and a real appreciation of the importance of data quality
    to all of this. This is why ML engineering is such an exciting place to be! See
    *Table 2.4* for some more details on these types of activities.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以考虑 MLOps 中的机器学习活动，本书将非常关注这些内容。这包括一个经典的 Python 软件工程师通常不需要担心，但对于我们这样的机器学习工程师来说至关重要的所有任务。这包括开发自动训练机器学习模型的能力，运行模型应生成的预测或推理，并在代码管道中将它们整合在一起。它还包括模型版本的管理和部署，这极大地补充了使用像
    Git 这样的工具对应用程序代码进行版本控制的想法。最后，机器学习工程师还必须考虑他们必须为解决方案的操作模式构建特定的监控能力，这在传统的 DevOps
    工作流程中并未涵盖。对于机器学习解决方案，您可能需要考虑监控诸如精确度、召回率、f1 分数、人口稳定性、熵和数据漂移等因素，以了解您的解决方案中的模型组件是否在可容忍的范围内运行。这与经典的软件工程非常不同，因为它需要了解机器学习模型的工作原理，它们可能出错的方式，以及对数据质量重要性的真正认识。这就是为什么机器学习工程是一个如此令人兴奋的地方！请参阅
    *表 2.4* 了解这些类型活动的更多详细信息。
- en: '| **Lifecycle Stage** | **Activity** | **Details** | **Tools** |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| **生命周期阶段** | **活动** | **详细信息** | **工具** |'
- en: '| ML | Training | Train the model . | Any ML package. |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习 | 训练 | 训练模型。 | 任何机器学习包。 |'
- en: '| Predicting | Run the predictions or inference steps. | Any ML package. |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 预测 | 运行预测或推理步骤。 | 任何机器学习包。 |'
- en: '| Building | Creating the pipelines and application logic in which the model
    is embedded. | sklearn pipelines, Spark ML pipelines, ZenML. |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 构建 | 创建模型嵌入的管道和应用逻辑。 | sklearn 管道、Spark ML 管道、ZenML。 |'
- en: '| Staging | Tag and release the appropriate version of your models and pipelines.
    | MLflow or Comet.ml. |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 部署 | 标记和发布您模型和管道的适当版本。 | MLflow 或 Comet.ml. |'
- en: '| Monitoring | Track the solution performance and raise alerts when necessary.
    | Seldon, Neptune.ai, Evidently.ai, or Arthur.ai. |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 监控 | 跟踪解决方案性能并在必要时发出警报。 | Seldon, Neptune.ai, Evidently.ai 或 Arthur.ai. |'
- en: 'Table 2.4: Details on the ML-centered activities carried out during an MLOps
    project.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.4：MLOps 项目中执行的以机器学习为中心活动的详细信息。
- en: Finally, in either DevOps or MLOps, there is the Ops piece, which refers to
    Operations. This is all about how the solution will actually run, how it will
    alert you if there is an issue, and if it can recover successfully. Naturally
    then, operations will cover activities relating to the final packaging, build,
    and release of your solution. It also has to cover another type of monitoring,
    which is different from the performance monitoring of ML models. This monitoring
    has more of a focus on infrastructure utilization, stability, and scalability,
    on solution latency, and on the general running of the wider solution. This part
    of the DevOps and MLOps lifecycle is quite mature in terms of tooling, so there
    are many options available. Some information to get you started is presented in
    *Table 2.5*.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 DevOps 或 MLOps 中，有 Operations 部分，这指的是运维。这全部关于解决方案的实际运行方式，如果出现问题，它将如何通知你，以及它是否能够成功恢复。自然地，运维将涵盖与解决方案的最终打包、构建和发布相关的活动。它还必须涵盖另一种类型的监控，这与
    ML 模型的性能监控不同。这种监控更多地关注基础设施利用率、稳定性和可扩展性，关注解决方案的延迟，以及更广泛解决方案的一般运行。在 DevOps 和 MLOps
    生命周期中，这部分在工具方面相当成熟，因此有很多选项可供选择。以下是在 *表 2.5* 中提供的一些启动信息。
- en: '| **Lifecycle Stage** | **Activity** | **Details** | **Tools** |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| **生命周期阶段** | **活动** | **详情** | **工具** |'
- en: '| Ops | Releasing | Taking the software you have built and storing it somewhere
    central for reuse. | Twine, pip, GitHub, or BitBucket. |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| Ops | 发布 | 将你构建的软件存储在某个中央位置以供重用。 | Twine、pip、GitHub 或 BitBucket。 |'
- en: '| Deploying | Pushing the software you have built to the appropriate target
    location and environment. | Docker, GitHub Actions, Jenkins, TravisCI, or CircleCI.
    |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 部署 | 将你构建的软件推送到适当的目标位置和环境。 | Docker、GitHub Actions、Jenkins、TravisCI 或 CircleCI。
    |'
- en: '| Monitoring | Tracking the performance and utilization of the underlying infrastructure
    and general software performance, alerting where necessary. | DataDog, Dynatrace,
    or Prometheus. |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 监控 | 跟踪底层基础设施和一般软件性能的性能和利用率，在必要时发出警报。 | DataDog、Dynatrace 或 Prometheus。 |'
- en: 'Table 2.5: Details of the activities carried out in order to make a solution
    operational in a DevOps or MLOps project.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.5：在 DevOps 或 MLOps 项目中使解决方案可操作所执行的活动详情。
- en: Now that we have elucidated the core concepts needed across the MLOps lifecycle,
    in the next section, we will discuss how to implement CI/CD practices so that
    we can start making this a reality in our ML engineering projects. We will also
    extend this to cover automated testing of the performance of your ML models and
    pipelines, and to perform automated retraining of your ML models.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经阐明了 MLOps 生命周期中所需的核心概念，在下一节中，我们将讨论如何实施 CI/CD 实践，以便我们可以在我们的 ML 工程项目中将其变为现实。我们还将扩展这一内容，涵盖对您的
    ML 模型和管道性能的自动测试，以及对您的 ML 模型的自动重新训练。
- en: Building our first CI/CD example with GitHub Actions
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 GitHub Actions 构建我们的第一个 CI/CD 示例
- en: We will use GitHub Actions as our CI/CD tool in this book, but there are several
    other tools available that do the same job. GitHub Actions is available to anyone
    with a GitHub account, has a very useful set of documentation, [https://docs.github.com/en/actions](https://docs.github.com/en/actions),
    and is extremely easy to start using, as we will show now.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中使用 GitHub Actions 作为我们的 CI/CD 工具，但还有其他一些工具可以完成同样的工作。GitHub Actions 对任何拥有
    GitHub 账户的人来说都是可用的，它有一套非常有用的文档，[https://docs.github.com/en/actions](https://docs.github.com/en/actions)，并且非常容易开始使用，正如我们现在将展示的那样。
- en: 'When using GitHub Actions, you have to create a `.yml` file that tells GitHub
    when to perform the required actions and, of course, what actions to perform.
    This `.yml` file should be put in a folder called `.github/workflows` in the root
    directory of your repository. You will have to create this if it doesn’t already
    exist. We will do this in a new branch called `feature/actions`. Create this branch
    by running:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 GitHub Actions 时，你必须创建一个 `.yml` 文件，告诉 GitHub 何时执行所需操作，当然，执行什么操作。这个 `.yml`
    文件应该放在你的仓库根目录下的 `.github/workflows` 文件夹中。如果它还不存在，你必须创建它。我们将在一个名为 `feature/actions`
    的新分支中这样做。通过运行以下命令创建这个分支：
- en: '[PRE33]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Then, create a `.yml` file called `github-actions-basic.yml`. In the following
    steps, we will build up this example `.yml` file for a Python project where we
    automatically install dependencies, run a **linter** (a solution to check for
    bugs, syntax errors, and other issues), and then run some unit tests. This example
    comes from the GitHub Starter Workflows repository ([https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml](https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml)).
    Open up `github-actions-basic.yml` and then execute the following:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，创建一个名为`github-actions-basic.yml`的`.yml`文件。在以下步骤中，我们将构建这个`.yml`文件示例，用于Python项目，其中我们将自动安装依赖项，运行一个**代码检查器**（用于检查错误、语法错误和其他问题）的解决方案，然后运行一些单元测试。此示例来自GitHub
    Starter Workflows存储库（[https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml](https://github.com/actions/starter-workflows/blob/main/ci/python-package-conda.yml)）。打开`github-actions-basic.yml`文件，然后执行以下操作：
- en: 'First, you define the name of the GitHub Actions workflow and what Git event
    will trigger it:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，您定义GitHub Actions工作流程的名称以及什么Git事件将触发它：
- en: '[PRE34]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You then list the jobs you want to execute as part of the workflow, as well
    as their configuration. For example, here we have one job called `build`, which
    we want to run on the latest Ubuntu distribution, and we want to attempt the build
    using several different versions of Python:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您然后列出您想要作为工作流程一部分执行的工作，以及它们的配置。例如，这里有一个名为`build`的工作，我们希望在最新的Ubuntu发行版上运行它，并尝试使用几个不同的Python版本进行构建：
- en: '[PRE35]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You then define the steps that execute as part of the job. Each step is separated
    by a hyphen and is executed as a separate command. It is important to note that
    the `uses` keyword grabs standard GitHub Actions; for example, in the first step,
    the workflow uses the **v2** version of the `checkout` action, and the second
    step sets up the Python versions we want to run in the workflow:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您然后定义作为工作一部分执行的步骤。每个步骤由一个连字符分隔，并作为单独的命令执行。重要的是要注意，`uses`关键字获取标准的GitHub Actions；例如，在第一步中，工作流程使用`checkout`动作的**v2**版本，第二步设置在工作流程中要运行的Python版本：
- en: '[PRE36]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The next step installs the relevant dependencies for the solution using `pip`
    and a `requirements.txt` file (but you can use `conda` of course!):'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步使用`pip`和`requirements.txt`文件（但当然您也可以使用`conda`）安装解决方案的相关依赖项：
- en: '[PRE37]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We then run some linting:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们运行一些代码检查：
- en: '[PRE38]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Finally, we run our tests using our favorite Python testing library. For this
    step, we do not want to run through the entire repository, as it is quite complex,
    so for this example, we use the `working-directory` keyword to only run `pytest`
    in that directory.
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用我们最喜欢的Python测试库运行我们的测试。对于这一步，我们不想运行整个仓库，因为它相当复杂，所以在这个例子中，我们使用`working-directory`关键字只在该目录中运行`pytest`。
- en: 'Since it contains a simple test function in `test_basic.py`, this will automatically
    pass:'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于它包含在`test_basic.py`中的简单测试函数，这将自动通过：
- en: '[PRE39]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We have now built up the GitHub Actions workflow; the next stage is to show
    it running. This is taken care of automatically by GitHub, all you have to do
    is push to the remote repository. So, add the edited `.yml` file, commit it, and
    then push it:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了GitHub Actions工作流程；下一步是展示其运行。这由GitHub自动处理，您只需将更改后的`.yml`文件推送到远程仓库即可。因此，添加编辑后的`.yml`文件，提交它，然后推送它：
- en: '[PRE40]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: After you have run these commands in the terminal, you can navigate to the GitHub
    UI and then click on **Actions** in the top menu bar. You will then be presented
    with a view of all action runs for the repository like that in *Figure 2.13.*
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中运行这些命令后，您可以导航到GitHub UI，然后在顶部菜单栏中点击**操作**。您将看到所有操作运行的视图，如图2.13所示。
- en: '![](img/B19525_02_13.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19525_02_13.png)'
- en: 'Figure 2.13: The GitHub Actions run as viewed from the GitHub UI.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13：从GitHub UI查看的GitHub Actions运行。
- en: If you then click on the run, you will be presented with details of all jobs
    that ran within the **Actions** run, as shown in *Figure 2.14*.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您点击运行，您将看到**操作**运行中所有工作的详细信息，如图2.14所示。
- en: '![](img/B19525_02_14.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19525_02_14.png)'
- en: 'Figure 2.14: GitHub Actions run details from the GitHub UI.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14：GitHub Actions运行细节，从GitHub UI查看。
- en: Finally, you can go into each job and see the steps that were executed, as shown
    in *Figure 2.15*. Clicking on these will also show the outputs from each of the
    steps. This is extremely useful for analyzing any failures in the run.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以进入每个工作，查看执行的步骤，如图2.15所示。点击这些步骤也会显示每个步骤的输出。这对于分析运行中的任何失败非常有用。
- en: '![](img/B19525_02_15.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19525_02_15.png)'
- en: 'Figure 2.15: The GitHub Actions run steps as shown on the GitHub UI.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15：GitHub Actions 运行步骤，如图所示在 GitHub UI 上。
- en: What we have shown so far is an example of CI. For this to be extended to cover
    CD, we need to include steps that push the produced solution to its target host
    destination. Examples are building a Python package and publishing it to `pip`,
    or creating a pipeline and pushing it to another system for it to be picked up
    and run. This latter example will be covered with an **Airflow DAG** in *Chapter
    5*, *Deployment Patterns and Tools*. And that, in a nutshell, is how you start
    building your CI/CD pipelines. As mentioned, later in the book, we will build
    workflows specific to our ML solutions.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止所展示的是一个 CI 的例子。为了将其扩展到覆盖 CD，我们需要包括将生成的解决方案推送到目标主机目的地的步骤。例如，构建一个 Python
    包并将其发布到 `pip`，或者创建一个流水线并将其推送到另一个系统以便被拾取并运行。这个后者的例子将在 *第5章*，*部署模式和工具* 中进行介绍。简而言之，这就是你开始构建你的
    CI/CD 流水线的方式。正如之前提到的，在本书的后面，我们将构建针对我们机器学习解决方案的特定工作流程。
- en: Now we will look at how we take CI/CD concepts to the next level for ML engineering
    and build some tests for our model performance, which can then also be triggered
    as part of continuous processes.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探讨如何将 CI/CD 概念提升到机器学习工程的下一个层次，并为我们的模型性能构建一些测试，这些测试可以作为持续过程的一部分被触发。
- en: Continuous model performance testing
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续模型性能测试
- en: As ML engineers, we not only care about the core functional behavior of the
    code we are writing; we also have to care about the models that we are building,
    This is an easy thing to forget, as traditional software projects do not have
    to consider this component.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习工程师，我们不仅关心我们编写的代码的核心功能行为；我们还要关心我们构建的模型。这很容易被忘记，因为传统的软件项目不需要考虑这个组件。
- en: The process I will now walk you through shows how you can take some base reference
    data and start to build up some different flavors of tests to give confidence
    that your model will perform as expected when you deploy it.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在要向您展示的过程将展示如何从一些基础参考数据开始，逐步构建不同类型的测试，以增强你对模型在部署时能够按预期运行的信心。
- en: 'We have already introduced how to test automatically with Pytest and GitHub
    Actions, the good news is that we can just extend this concept to include the
    testing of some model performance metrics. To do this, you need a few things in
    place:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了如何使用 Pytest 和 GitHub Actions 进行自动测试，好消息是我们可以将这个概念扩展到包括一些模型性能指标的测试。为此，你需要准备以下几件事情：
- en: Within the action or tests, you need to retrieve the reference data for performing
    the model validation. This can be done by pulling from a remote data store like
    an object store or a database, as long as you provide the appropriate credentials.
    I would suggest storing these as secrets in Github. Here, we will use a dataset
    generated in place using the `sklearn` library as a simple example.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在操作或测试中，你需要检索用于执行模型验证的参考数据。这可以通过从远程数据存储（如对象存储或数据库）中拉取来完成，只要提供适当的凭证。我建议将这些存储在
    Github 的秘密中。在这里，我们将使用 `sklearn` 库生成的一个数据集作为简单的例子。
- en: You need to retrieve the model or models you wish to test from some location
    as well. This could be a full-fledged model registry or some other storage mechanism.
    The same points around access and secrets management as in *point 1* apply. Here
    we will pull a model from the `Hugging Face Hub` (more on Hugging Face in *Chapter
    3*), but this could equally have been an MLflow Tracking instance or some other
    tool.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还需要从某个位置检索你想要测试的模型或模型。这可能是一个完整的模型注册表或其他存储机制。与 *第1点* 中提到的访问和秘密管理相同的要点同样适用。在这里，我们将从
    `Hugging Face Hub`（关于 Hugging Face 的更多内容请见 *第3章*）中拉取一个模型，但这同样可能是一个 MLflow Tracking
    实例或其他工具。
- en: You need to define the tests you want to run and that you are confident will
    achieve the desired outcome. You do not want to write tests that are far too sensitive
    and trigger failed builds for spurious reasons, and you also want to try and define
    tests that are useful for capturing the types of failures you would want to flag.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要定义你想要运行的测试，并且对你能够实现预期结果有信心。你不想编写过于敏感的测试，以免因无关原因触发失败的构建，同时你也想尝试定义一些有助于捕捉你想要标记的失败类型的测试。
- en: 'For *point 1*, here we grab some data from the `sklearn` library and make it
    available to the tests through a `pytest fixture`:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *第1点*，这里我们从 `sklearn` 库中抓取一些数据，并通过 `pytest fixture` 使其可用于测试：
- en: '[PRE41]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: For *point 2*, I will use the `Hugging Face Hub` package to retrieve the stored
    model. As mentioned in the bullets above, you will need to adapt this to whatever
    model storage mechanism you are accessing. The repository in this case is public
    so there is no need to store any secrets; if you did need to do this, please use
    the GitHub Secrets store.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**第2点**，我将使用`Hugging Face Hub`包来检索存储的模型。如上所述的要点中提到，您需要根据您访问的模型存储机制进行适配。在这种情况下，仓库是公开的，因此无需存储任何机密信息；如果您确实需要这样做，请使用GitHub
    Secrets存储。
- en: '[PRE42]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now, we just need to write the tests. Let’s start simple with a test that confirms
    that the predictions of the model produce the correct object types:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要编写测试。让我们从一个确认模型预测产生正确对象类型的简单测试开始：
- en: '[PRE43]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We can then write a test to assert some specific conditions on the performance
    of the model on the test dataset is met:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以编写一个测试来断言测试数据集上模型性能满足某些特定条件：
- en: '[PRE44]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The previous test can be thought of as something like a data-driven unit test
    and will make sure that if you change something in the model (perhaps you change
    some feature engineering step in the pipeline or you change a hyperparameter),
    you will not breach the desired performance criteria. Once these tests have been
    successfully added to the repo, on the next push, the GitHub action will be triggered
    and you will see that the model performance test runs successfully.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的测试可以被视为一种类似数据驱动的单元测试，并确保如果您在模型中做了更改（例如，您可能在管道中更改了一些特征工程步骤或更改了一个超参数），您不会违反期望的性能标准。一旦这些测试成功添加到仓库中，在下次推送时，GitHub动作将被触发，您将看到模型性能测试运行成功。
- en: This means we are performing some continuous model validation as part of our
    CI/CD process!
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们正在将连续模型验证作为CI/CD过程的一部分进行执行！
- en: '![](img/B19525_02_16.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19525_02_16.png)'
- en: 'Figure 2.16: Successfully executing model validation tests as part of a CI/CD
    process using GitHub Actions.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16：使用GitHub Actions作为CI/CD过程的一部分成功执行模型验证测试。
- en: More sophisticated tests can be built upon this simple concept, and you can
    adapt the environment and packages used to suit your needs.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的测试可以在此基础上构建，并且您可以调整环境和包以适应您的需求。
- en: Continuous model training
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续模型训练
- en: An important extension of the “continuous” concept in ML engineering is to perform
    continuous training. The previous section showed how to trigger some ML processes
    for testing purposes when pushing code; now, we will discuss how to extend this
    for the case where you want to trigger retraining of the model based on a code
    change. Later in this book, we will learn a lot about training and retraining
    ML models based on a variety of different triggers like data or model drift in
    *Chapter 3*, *From Model to Model Factory*, and about how to deploy ML models
    in general in *Chapter 5*, *Deployment Patterns and Tools*. Given this, we will
    not cover the details of deploying to different targets here but instead show
    you how to build continuous training steps into your CI/CD pipelines.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习工程中，“持续”概念的一个重要扩展是执行持续训练。上一节展示了如何通过推送代码来触发一些测试目的的ML过程；现在，我们将讨论如何扩展这一过程，以便在您想要根据代码更改触发模型重新训练的情况下。在本书的后面部分，我们将学习到很多关于基于各种不同触发器（如数据或模型漂移）对ML模型进行训练和重新训练的知识，例如在第3章“从模型到模型工厂”中，以及如何在第5章“部署模式和工具”中一般性地部署ML模型。鉴于这一点，我们在此不会详细讨论部署到不同目标的具体细节，而是向您展示如何将连续训练步骤构建到您的CI/CD管道中。
- en: This is actually simpler than you probably think. As you have hopefully noticed
    by now, CI/CD is really all about automating a series of steps, which are triggered
    upon particular events occurring during the development process. Each of these
    steps can be very simple or more complex, but fundamentally it is always just
    other programs we are executing in the specified order upon activating the trigger
    event.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这比你可能想象的要简单。如您现在可能已经注意到的，CI/CD实际上就是关于自动化一系列步骤，这些步骤在开发过程中的特定事件发生时被触发。这些步骤中的每一个都可以非常简单或更复杂，但本质上，我们只是在触发事件激活时按照指定顺序执行的其他程序。
- en: In this case, since we are concerned with continuous training, we should ask
    ourselves, when would we want to retrain during code development? Remember that
    we are ignoring the most obvious cases of retraining on a schedule or upon a drift
    in model performance or data quality, as these are touched on in later chapters.
    If we only consider that the code is changing for now, the natural answer is to
    train only when there is a substantial change to the code.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，由于我们关注的是持续训练，我们应该问自己，在代码开发过程中，我们希望在何时重新训练？记住，我们正在忽略最明显的重新训练案例，即按计划或模型性能或数据质量漂移时进行重新训练，这些内容将在后面的章节中涉及。如果我们现在只考虑代码的变化，那么自然的答案是只有在代码有实质性变化时才进行训练。
- en: For example, if a trigger was fired every time we committed our code to version
    control, this would likely result in a lot of costly compute cycles being used
    for not much gain, as the ML model will likely not perform very differently in
    each case. We could instead limit the triggering of retraining to only occur when
    a pull request is merged into the main branch. In a project, this is an event
    that signifies a new software feature or functionality has been added and has
    now been incorporated into the core of the solution.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果每次我们将代码提交到版本控制时都会触发一个触发器，这很可能会导致大量的计算周期被用于微小的收益，因为机器学习模型在每个情况下可能不会有很大的不同。我们可以改为仅当拉取请求合并到主分支时才触发重新训练。在一个项目中，这是一个标志着新软件功能或功能已被添加并已纳入解决方案核心的事件。
- en: 'As a reminder, when building CI/CD in GitHub Actions, you create or edit `YAML`
    files contained in the `.github` folder of your Git repository. If we want to
    trigger a training process upon a pull request, then we can add something like:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，当在GitHub Actions中构建CI/CD时，你会在Git仓库的`.github`文件夹中创建或编辑`YAML`文件。如果我们想在拉取请求上触发训练过程，那么我们可以添加类似以下内容：
- en: '[PRE45]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'And then we need to define the steps for pushing the appropriate training script
    to the target system and running it. First, this would likely require some fetching
    of access tokens. Let’s assume this is for AWS and that you have loaded your appropriate
    AWS credentials as GitHub Secrets; for more information, see *Chapter 5*, *Deployment
    Patterns and Tools*. We would then be able to retrieve these in the first step
    of a `deploy-trainer` job:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要定义将适当的训练脚本推送到目标系统并运行它的步骤。首先，这很可能会需要获取一些访问令牌。假设这是针对AWS，并且你已经将相应的AWS凭证作为GitHub
    Secrets加载；更多详细信息，请参阅*第5章*，*部署模式和工具*。然后我们就能在`deploy-trainer`工作的第一步中检索到这些令牌：
- en: '[PRE46]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'You may then want to copy your repository files to a target **S3** destination;
    perhaps they contain modules that the main training script needs to run. You could
    then do something like this:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想将你的仓库文件复制到目标**S3**目的地；也许它们包含主训练脚本运行所需的模块。然后你可以做类似这样的事情：
- en: '[PRE47]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'And finally, you would want to run some sort of process that uses these files
    to perform the training. There are so many ways to do this that I have left the
    specifics out for this example. Many ways for deploying ML processes will be covered
    in *Chapter 5*, *Deployment Patterns and Tools*:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能需要运行某种使用这些文件进行训练的过程。有如此多的方法可以做到这一点，我在这个例子中省略了具体细节。关于部署机器学习过程的各种方法将在*第5章*，*部署模式和工具*中介绍：
- en: '[PRE48]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: And with that, you have all the key pieces you need to run continuous ML model
    training to complement the other section on continuous model performance testing.
    This is how you bring the DevOps concept of CI/CD to the world of MLOps!
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，你就拥有了运行持续机器学习模型训练所需的所有关键部件，以补充其他关于持续模型性能测试的部分。这就是如何将DevOps的CI/CD概念带入MLOps的世界！
- en: Summary
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter was all about building a solid foundation for future work. We discussed
    the development steps common to all ML engineering projects, which we called “*Discover,
    Play, Develop, Deploy*,” and contrasted this way of thinking against traditional
    methodologies like CRISP-DM. In particular, we outlined the aim of each of these
    steps and their desired outputs.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要讲述了为未来工作打下坚实基础的内容。我们讨论了所有机器学习工程项目中常见的开发步骤，我们称之为“*发现、探索、开发、部署*”，并将这种思维方式与传统方法如CRISP-DM进行了对比。特别是，我们概述了每个步骤的目标及其期望的输出。
- en: This was followed by a high-level discussion of tooling and a walkthrough of
    the main setup steps. We set up the tools for developing our code, keeping track
    of the changes to that code, managing our ML engineering project, and finally,
    deploying our solutions.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们进行了关于工具的高级讨论，并介绍了主要设置步骤。我们设置了开发代码的工具，跟踪代码的更改，管理我们的机器学习工程项目，最后部署我们的解决方案。
- en: In the rest of the chapter, we went through the details for each of the four
    steps we outlined previously, with a particular focus on the *Develop* and *Deploy*
    stages. Our discussion covered everything from the pros and cons of Waterfall
    and Agile development methodologies to environment management and then software
    development best practices. We explored how to package your ML solution and what
    deployment infrastructure is available for you to use, and outlined the basics
    of setting up your DevOps and MLOps workflows. We finished up the chapter by discussing,
    in some detail, how to apply testing to our ML code, including how to automate
    this testing as part of CI/CD pipelines. This was then extended into the concepts
    of continuous model performance testing and continuous model training.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们详细介绍了我们之前概述的四个步骤的细节，特别关注了*开发*和*部署*阶段。我们的讨论涵盖了从瀑布式和敏捷开发方法论的优缺点到环境管理，再到软件开发最佳实践的各个方面。我们探讨了如何打包您的机器学习解决方案，以及可供您使用的部署基础设施，并概述了设置您的
    DevOps 和 MLOps 工作流程的基本知识。我们通过详细讨论如何将测试应用于我们的机器学习代码来结束本章，包括如何将此测试自动化作为 CI/CD 管道的一部分。然后，我们将这些概念扩展到持续模型性能测试和持续模型训练。
- en: In the next chapter, we will turn our attention to how to build out the software
    for performing the automated training and retraining of your models using a lot
    of the techniques we have discussed here.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将关注如何使用我们在此处讨论的许多技术来构建执行模型自动训练和再训练的软件。
- en: Join our community on Discord
  id: totrans-383
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussion with the author and other
    readers:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mle](https://packt.link/mle)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mle](https://packt.link/mle)'
- en: '![](img/QR_Code102810325355484.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code102810325355484.png)'
