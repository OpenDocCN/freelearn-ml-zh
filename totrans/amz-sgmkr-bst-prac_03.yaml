- en: 'Chapter 2: Data Science Environments'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will get an overview of how to create managed data science
    environments to scale and create repeatable environments for your model-building
    activities. In this chapter, you will get a brief overview of the **machine**
    **learning** (**ML**) use case, including the dataset that will be used throughout
    the chapters in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that will be covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning use case and dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating data science environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need an AWS account to run the examples included in this chapter. Full
    code examples included in the book are available on GitHub at [https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter02](https://github.com/PacktPublishing/Amazon-SageMaker-Best-Practices/tree/main/Chapter02).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
    Portions of the code are included within the chapter to call out specific technical
    concepts; however, please refer to the GitHub repository for the full code required
    to complete the hands-on activities that go along with this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning use case and dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we will be using examples to demonstrate the best practices
    that apply across the ML life cycle. For this, we'll focus on a single ML use
    case and use an open dataset with data relating to the ML use case.
  prefs: []
  type: TYPE_NORMAL
- en: The primary use case we'll explore in this book is predicting air quality readings.
    Given a location (weather station) and date, we'll try to predict a value for
    a particular type of air quality measurement (for example, pm25 or o3). We'll
    treat this as a regression problem and explore XGBoost and neural network-based
    model approaches.
  prefs: []
  type: TYPE_NORMAL
- en: For this, we'll use a dataset from OpenAQ ([https://registry.opendata.aws/openaq/](https://registry.opendata.aws/openaq/))
    that includes air quality data from public data sources. The dataset that we will
    use is the `realtime` dataset ([https://openaq-fetches.s3.amazonaws.com/index.html](https://openaq-fetches.s3.amazonaws.com/index.html))
    and the `realtime-parquet-gzipped` dataset ([https://openaq-fetches.s3.amazonaws.com/index.html](https://openaq-fetches.s3.amazonaws.com/index.html)),
    which includes daily reports from multiple stations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The daily reports are in JSON format. Each record contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A timestamp (both UTC and local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parameter ID (pm25)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Location (station ID)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Value (numeric)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Units for value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: City
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attribution (link to station website)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Averaging period (for example, 1 hour)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coordinates (lat/lon)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Country code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Source name (short version of station name)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Source type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile (true/false)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's now look at how to create data science environments.
  prefs: []
  type: TYPE_NORMAL
- en: Creating data science environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we introduced high-level Amazon SageMaker features
    that can often be used in isolation or together for end-to-end capabilities. In
    this section, we will focus on creating consistent and repeatable governed data
    science environments that can take advantage of the features discussed in the
    first section.
  prefs: []
  type: TYPE_NORMAL
- en: To build, train, and deploy models using Amazon SageMaker, ML builders need
    access to select AWS resources spanning the ML development life cycle. Because
    many different personas may be responsible for building ML models, the term ML
    builder refers to any individual tasked with model building. This could include
    data scientists, ML engineers, or data analysts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data science development** environments provide ML builders with the AWS
    resources they need to build and train models. A data science environment could
    be as simple as an AWS account with access to Amazon SageMaker as well as AWS
    services commonly used with Amazon SageMaker, such as Amazon S3, AWS Glue, or
    Amazon EMR. While this may work for small teams, it does not scale well to larger
    teams or provide repeatability as new projects get created or new team members
    join the team.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon SageMaker offers three core options in building, training, and tuning
    models, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**API/SDK**: Training and tuning jobs can be started with the SageMaker API,
    which can be accessed through the high-level SageMaker Python SDK, lower-level
    AWS SDKs such as boto3 for Python, or the AWS CLI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon SageMaker Studio**: Amazon SageMaker Studio has built-in notebooks
    as part of an integrated workbench that includes native integrations with other
    Amazon SageMaker features and feature visualizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon SageMaker notebook instances**: SageMaker notebook instances provide
    a compute instance with attached storage hosting the Jupyter Notebook application.
    These notebooks come preinstalled with packages, libraries, and kernels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This section will focus only on Amazon SageMaker Studio and Amazon SageMaker
    notebook instances for setting up data science environments. Similar approaches
    can be applied in using the SageMaker API or SDK from a data science environment
    hosted outside of SageMaker. We'll first highlight the two common approaches using
    **Infrastructure-as-Code** (**IaC**)/**Configuration-as-Code** (**CaC**) as well
    as building a common catalog of data science environments. We will expand on each
    option in more detail in later sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a repeatable mechanism for creating data science sandbox environments,
    it is recommended to utilize IaC/CaC to define the intended configuration and
    controls to implement for your sandbox environments. Let''s see what the two processes
    refer to:'
  prefs: []
  type: TYPE_NORMAL
- en: IaC refers to the process of provisioning and managing infrastructure using
    code instead of relying on manual setup, which is not only slow but also prone
    to error and inconsistencies across environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cac refers to the process of managing the configuration of resources through
    code. Because this is all defined via code, it can be managed as source code and
    reused for consistency across environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Iac/CaC can be taken a step further by providing data science environments
    through a service, such as AWS Service Catalog, that is purposely built for centrally
    creating and managing catalogs of IT services that are approved for use on AWS.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 2.1* illustrates the most common approaches for setting up governed
    data science environments. Each of these options will be discussed in detail in
    this section. At a minimum, it''s recommended to adopt an automated approach,
    which would include options 2 and 3 in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Approaches for creating data science sandbox environments'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Approaches for creating data science sandbox environments
  prefs: []
  type: TYPE_NORMAL
- en: A manual approach to provisioning and providing access to AWS services for ML
    builders creates challenges when scaling multiple ML builders and managing governance
    beyond a small team.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the introduction of AWS CloudFormation, or an equivalent service providing
    IaC/CaC capabilities, data science environments can be repeatedly created as well
    as provide additional capabilities such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment governance**: AWS CloudFormation allows you to define the intended
    state of your data science environment in terms of which resources get provisioned
    as well as how they get provisioned. This allows you to enforce configurations
    such as cost allocation tags, encrypted storage, or control access to pre-approved
    resources such as specific instance types for notebook instance compute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency**: As ML builder teams grow, there is a need to gain operational
    efficiencies by provisioning environments with reduced manual effort and increased
    consistency. IaC/CaC allows for data science environments to be automatically
    provisioned and provides consistency through code and automation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved management capabilities**: AWS CloudFormation not only allows you
    to automatically build a data science environment, but it also allows you to quickly
    deprovision a data science environment that is no longer in use. This capability
    reduces environment sprawl and ensures that you are not paying for resources that
    are no longer in use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using IaC/CaC to provision and manage data science environments is often sufficient
    in being able to consistently enable ML builders. However, providing these data
    science environments through a central catalog of IT services adds an additional
    layer of operational efficiencies, such as *reducing manual approvals*, *reducing
    hand-offs in siloed teams*, and *providing centralized governance by ensuring
    environments are provisioned across teams using only approved configurations*.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS Service Catalog allows administrators to centrally define and manage a
    portfolio of approved products or configurations defined through AWS CloudFormation
    templates. The addition of AWS Service Catalog for managing a portfolio of products
    used to create data science environments enables additional capabilities over
    standalone IaC/CaC, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-service capabilities**: Using only IaC/CaC to provision and configure
    AWS resources can often result in delays while requests are approved, tracked,
    and, ultimately, the environment is provisioned by the AWS Admin. AWS Service
    Catalog allows ML builders, or approved designated project resources, to automatically
    request and provision a data science environment that is preconfigured according
    to standards that you define.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Applying constraints and access controls**: With AWS Service Catalog, constraints
    and access controls can be centrally defined and applied consistently across teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service management**: While AWS Service Catalog utilizes AWS CloudFormation,
    it also includes capabilities to manage the life cycle of these templates or products
    across versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AWS Service Catalog allows ML builders, or an approved resource, to request
    and instantiate a data science environment using approved products contained in
    an AWS Service Catalog portfolio. An AWS Service Catalog portfolio can exist in
    a separate AWS account and be shared across AWS accounts to establish a company
    or business unit standard for governing the configuration and provisioning of
    products. Products within a portfolio contain the pre-configured templates, using
    IaC/CaC, that should be used to provision or instantiate the data science environment
    for an ML builder:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – AWS Service Catalog – anatomy of a portfolio'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – AWS Service Catalog – anatomy of a portfolio
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this chapter, we'll cover considerations to consistently create
    data science environments through IaC/CaC, as well as advanced capabilities allowing
    you to provide those environments across multiple teams through a governed catalog
    of IT services. Each of these will be covered for both Amazon SageMaker notebook
    instances as well as Amazon SageMaker Studio. First, we'll cover the use of IaC/CaC
    to create repeatable data science environments.
  prefs: []
  type: TYPE_NORMAL
- en: Creating repeatability through IaC/CaC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using AWS CloudFormation to provision and configure the AWS resources and access
    required for SageMaker model-building activities allows teams to create a repeatable
    pattern that can be shared across teams and used to consistently create data science
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: A CloudFormation template lets you programmatically describe the desired AWS
    resources, configurations, and dependencies that should be provisioned when that
    template is launched as a stack. Key considerations when building AWS CloudFormation
    templates for data science environments include what resources should be provisioned,
    how they should be configured, and what permissions ML builders need for model-building
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: What resources are required?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AWS CloudFormation lets you define the AWS services to automatically provision
    via a template using supported resources and resource types. As an example, Amazon
    SageMaker is a supported resource, and a SageMaker notebook instance is a supported
    resource type. A CloudFormation resource type is represented in a consistent format,
    as shown in *Figure 2.3*, whether you are building your CloudFormation template
    as JSON or YAML:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – AWS CloudFormation resource type for an Amazon SageMaker notebook
    instance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – AWS CloudFormation resource type for an Amazon SageMaker notebook
    instance
  prefs: []
  type: TYPE_NORMAL
- en: This means teams can automatically provision and configure a notebook instance
    through a CloudFormation template. However, a notebook instance alone is typically
    not enough for a data science environment. For a basic environment, you typically
    need a notebook instance, an S3 bucket, and an AWS IAM SageMaker execution role
    to execute API calls from within your notebook environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to a basic environment, there may be a need to provision other
    resources as part of a data science environment. Additional resources to provision
    fall into a few key categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AWS::EMR::Cluster` resource type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AWS::CodeCommit::Repository` resource type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: b. `AWS::ECR::Repository` resource type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Identity resources**: This category includes any additional policies or service
    roles that need to be created to use AWS resources. For example, to utilize AWS
    Step Functions, or the Data Science Python SDK, for creating ML workflows, a service-level
    IAM execution role needs to be created. The creation of this role can be specified
    in your CloudFormation template. The role should also include permissions that
    allow access to AWS services and actions that will be used in your ML workflow,
    such as AWS Glue for data preparation and Amazon SageMaker for training jobs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How should the resources be configured?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each resource that gets provisioned through a CloudFormation template includes
    a set of properties that define how a resource should be configured. Defining
    these properties through code allows you to consistently provision resources that
    are configured according to pre-defined specifications. Properties include important
    configuration options, such as launching environments with a VPC attached or enforcing
    controls such as encryption at rest. CloudFormation also allows for **parameters**
    that can be defined in the template and passed in when launching a CloudFormation
    stack.
  prefs: []
  type: TYPE_NORMAL
- en: What permissions are needed?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After you've identified the AWS resources and resource types that need to be
    provisioned for your data science environment, you need to identify the permissions
    that are also required to be able to access the notebook environment and the underlying
    APIs required for model building.
  prefs: []
  type: TYPE_NORMAL
- en: There is some variance between Amazon SageMaker notebook instances and Amazon
    SageMaker Studio discussed in the sections below; however, in both cases, a basic
    environment requires an IAM SageMaker execution role. Depending on the intent
    of the CloudFormation template, you need to consider the additional allowed AWS
    API calls and actions that the SageMaker execution role will need access to. For
    example, if your data science team uses AWS Glue for data preparation activities,
    the IAM SageMaker execution role needs to allow access to the corresponding AWS
    Glue API actions.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the AWS CloudFormation templates that will be used to create and consistently
    enforce controls in your data science environment, a few planning tasks should
    be considered before building those templates:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you should identify the patterns for the resources that should be provisioned
    together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Second, you should identify how those resources should be configured.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, you need to identify the minimum permissions that need to be in place
    for the provisioned resources to integrate seamlessly as well as the permissions
    required for an ML builder to operate within those provisioned environments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Typically, several patterns are built supporting different environment patterns
    that may be needed for varying use cases or multiple teams. The following sections
    include detailed sample scenarios for both Amazon SageMaker notebook instances
    and Amazon SageMaker Studio. For either scenario, the sections can be read independently
    of one another and contain some duplicated information so that they can exist
    independently.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker notebook instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Building data science environments that utilize Amazon SageMaker notebook instances
    typically includes the provisioning of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A notebook instance (required)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An S3 bucket (optional)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An IAM execution role (optional if using an existing one)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any other resources identified as needed by ML builder teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An Amazon S3 bucket is noted as optional above because many organizations have
    existing S3 buckets that are used for data science model-building activities.
    In these cases, the data science environment may instead include permissions to
    access an existing S3 bucket. *Figure 2.2* shows a basic data science environment
    template that provisions a SageMaker notebook instance, an Amazon S3 bucket, and
    creates a SageMaker execution role that is attached to the notebook instance.
    The template can be used to instantiate multiple environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Notebook instance-based data science environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Notebook instance-based data science environment
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippets from a CloudFormation template show a pattern that
    can be used to quickly provision a data science environment using controls pre-approved
    by security and administrative teams and implemented through code. In the first
    section of the template, we identify parameters that are configurable each time
    a new template is launched. Parameters allow you to pass in data used in the provisioning
    and configuration of resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next section of the template, we identify the resources to provision
    and configure for your data science environment. The Properties of each resource
    identify the configuration and controls to provision. These controls can include
    configuration such as ensuring the storage volume attached to the notebook instance
    is encrypted and that the notebook instance is provisioned with a VPC attached:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the template snippets here, we are asking for a pre-configured VPC as a parameter
    on input; however, you could also include the creation of a new VPC within your
    CloudFormation template depending on your needs. We also include the notebook
    instance type and storage size as parameters that are configurable with each new
    launched template. Configurations that are likely to change for different ML use
    cases are good candidates that convert into configurable parameters that can be
    defined while launching a stack.
  prefs: []
  type: TYPE_NORMAL
- en: Once the template is uploaded to Amazon S3 and validated, it can be launched
    repeatedly for each new data science environment needed. Launching the stack can
    be done through the AWS console, AWS CLI, or the AWS SDK. This is most frequently
    done from an administrative account using cross-account privileges to ensure control
    in the roles that can define and provision environments versus the users who use
    the provisioned environments.
  prefs: []
  type: TYPE_NORMAL
- en: After the CloudFormation stack is completed, an ML builder can then access their
    environment through the provisioned Amazon SageMaker notebook instances via the
    AWS console. To access the notebook instance, the sign-in credentials for the
    ML builder must have the IAM permissions to send a `CreatePresignedNotebookInstanceUrl`
    API request.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Building data science environments that utilize Amazon SageMaker Studio includes
    the provisioning of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A new user within an existing Studio domain (required)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An S3 bucket (optional)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An IAM execution role (optional if using an existing one)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any other resources or configurations identified as needed by ML builder teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An Amazon S3 bucket is noted as optional above because many organizations have
    existing S3 buckets that are used for data science model-building activities.
    In these cases, the data science environment may instead include permissions to
    access an existing S3 bucket. *Figure 2.5* shows a basic data science environment
    template that provisions a new user in SageMaker Studio, an Amazon S3 bucket,
    and creates a SageMaker execution role that is attached to the Studio domain user.
    The template can be used to instantiate multiple user environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Amazon SageMaker Studio-based data science environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Amazon SageMaker Studio-based data science environment
  prefs: []
  type: TYPE_NORMAL
- en: 'The CloudFormation template below shows a pattern that can be used to quickly
    provision an integrated data science workbench environment using Amazon SageMaker
    Studio, giving ML builders access to Studio notebooks as well as other integrated
    features inside SageMaker Studio. Again, the first section contains the parameters
    that allow you to define how to provision and configure the environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next section of the template, we identify the resources to provision
    and configure for your data science environment. Again, the properties of each
    resource identify the configuration and controls to provision as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the CloudFormation template, we are adding a new user to an existing Studio
    domain. A `AWS:SageMaker:Domain` resource type. Creating a Studio domain is a
    one-time activity per AWS account and per AWS region, so this would be considered
    a prerequisite to creating users within your Studio domain. In addition, some
    regulated workloads enforce account-level isolation per ML builder, so in these
    cases, your CloudFormation template may include the setup of a Studio domain.
    However, the most common pattern is multiple users per Studio domain.
  prefs: []
  type: TYPE_NORMAL
- en: Once the template is built and validated, it is ready to be deployed after uploading
    the template to Amazon S3 and launching the stack through the AWS console, AWS
    CLI, or the AWS SDK. Again, this is most frequently done from an administrative
    account using cross-account privileges to ensure control in the roles that can
    define and provision environments versus the users who use the provisioned environments.
  prefs: []
  type: TYPE_NORMAL
- en: After the CloudFormation stack is completed, an ML builder can access the Studio
    environment and create notebooks through the Studio IDE with AWS IAM sign-in credentials
    or through AWS SSO credentials and the generated Studio URL.
  prefs: []
  type: TYPE_NORMAL
- en: Providing and creating data science environments as IT services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a governed catalog of IT services that includes data science environments
    is a way to build on the concepts of using IaC/CaC for repeatability by adding
    a central catalog of approved IT services across teams. This is especially useful
    for large companies or enterprises that rely on central IT or infrastructure teams
    to provision AWS resources. Creating a central catalog using AWS Service Catalog
    allows the added benefits of ensuring compliance with corporate standards, accelerating
    the ability of ML builders to quickly gain access to data science environments,
    managing versions of products offered through the catalog, and integrating with
    third-party **IT Service** **Management** (**ITSM**) software for change control.
  prefs: []
  type: TYPE_NORMAL
- en: 'For model building using Amazon SageMaker, AWS Service Catalog allows teams
    to take the AWS CloudFormation templates discussed in the previous section and
    offer those templates as versioned products inside a central portfolio of products.
    The approved configurations for those products can be centrally managed and governed.
    AWS Service Catalog lets teams control the users who have access to launch a product,
    which means admins can also provide self-service capabilities to ML builders to
    ensure that they have quick access to governed data science environments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Centrally managed data science environments using AWS Service
    Catalog'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Centrally managed data science environments using AWS Service Catalog
  prefs: []
  type: TYPE_NORMAL
- en: When products are added to a portfolio, you can optionally add product constraints.
    **Product constraints** allow you to add controls in terms of how an ML builder
    uses products. Several constraint types are allowed, including launch, notification,
    template, stack set, and tag update constraints. Each of these constraint types
    can be applied to any product; however, launch and template constraints have unique
    considerations for data science environments.
  prefs: []
  type: TYPE_NORMAL
- en: A launch constraint allows you to specify the IAM role that AWS Service Catalog
    assumes for provisioning AWS resources for a product within a portfolio. This
    follows the recommended practice of granting least privilege by providing ML builders
    with access to the resources that get provisioned, but not allowing ML builders
    access to provision resources outside of AWS Service Catalog.
  prefs: []
  type: TYPE_NORMAL
- en: For data science environments, a launch constraint can be added to a product
    in the portfolio using a pre-defined IAM role that is assumed for provisioning
    resources. This means you do not need to grant privileges for actions such as
    creating a new IAM role or working with AWS CloudFormation to the ML builder directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'A template constraint is a JSON-formatted text file that defines rules describing
    when an ML builder can use the templates, and which values they can specify for
    the parameters defined in the AWS CloudFormation template. Each rule has two properties:
    *a rule condition* (optional) and *assertions* (required).'
  prefs: []
  type: TYPE_NORMAL
- en: The rule condition determines when the rule takes effect, and the assertion
    describes the values a user can specify for a specific parameter. For data science
    environments, template constraints can be used for defining allowable configurations
    such as instance types via assertions. You can also add a rule condition to that
    assertion that limits the allowed instances within specific environments.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Service Catalog provides added benefits over using AWS CloudFormation by
    creating a centralized portfolio for *data science environments* that contains
    managed products for provisioning data science environments. The first step is
    to create a portfolio, which can be done through the AWS CLI, AWS SDK, or AWS
    console, as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a portfolio in AWS Service Catalog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a portfolio, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From AWS Service Catalog service, select **Create portfolio**:![Figure 2.7 –
    AWS Service Catalog – creating a new portfolio
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17249_02_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.7 – AWS Service Catalog – creating a new portfolio
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Define your portfolio by entering the following under `Data Science Environments`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Service catalog portfolio of approved products for provisioning data science
    environments for ML builders`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Owner**: Your name'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Create** button to create the portfolio. You will then see a **Success**
    message, indicating the portfolio is available to add products.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As products are added to the portfolio and provisioned, AWS Service Catalog
    provides visibility for admins to view all provisioned products and perform administrative
    tasks, such as identifying user resource allocation. ML builders also have a central
    view of all the provisioned products they have requested:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – List of all provisioned products'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – List of all provisioned products
  prefs: []
  type: TYPE_NORMAL
- en: The unique aspects of products for SageMaker notebook instances and SageMaker
    Studio are largely handled within the CloudFormation templates. The high-level
    steps to create a product are consistent between the two types of data science
    environments. The following sections include detailed sample scenarios extending
    the CloudFormation templates previously created for both Amazon SageMaker notebook
    instances and Amazon SageMaker Studio.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker notebook instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A new product can be added to an AWS Service Catalog portfolio using the AWS
    CLI, AWS SDK, or the AWS console. When a new product is added to a portfolio,
    the CloudFormation template that defines that environment must be uploaded to
    an S3 bucket and provided as input. In this example, the previous CloudFormation
    template will be used in addition to several other parameters required on input,
    as shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: From within the portfolio created, select **Upload new product**:![Figure 2.9
    – AWS Service Catalog – uploading a new product to the portfolio
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17249_02_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.9 – AWS Service Catalog – uploading a new product to the portfolio
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Under `https://…`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The default location for templates used on launched stacks is `https://s3.<region>.amazonaws.com/cf-templates-<hash>-region/notebook-instance-environment.yaml`,
    or you can upload the CloudFormation template provided for this chapter directly
    to an S3 bucket you choose.
  prefs: []
  type: TYPE_NORMAL
- en: '`release-1.0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Initial product release`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The **Support details** section includes the information about the support
    contacts and support information. Enter the following for each field specified
    and leave any field not specified blank:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Email contact**: Your email@mail.com.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After filling in the information as described in the preceding steps, scroll
    to the bottom, select **Review**, and then **Create Product**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product will now be visible within the product list for the **Data Science
    Environments** portfolio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After adding the product to the portfolio, constraints can be added to the
    product. **Constraints** are optional but offer additional recommended enforcement
    of practices, such as least privilege, and additional controls to enforce best
    practices such as cost optimization. To enforce minimum privileges, a launch constraint
    can be added to the product by first creating a launch IAM role that will be assumed
    when provisioning a product as documented in AWS Service Catalog product documentation:
    [https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this IAM policy for this role, you''ll need to add each service that the
    product provisions to the action list. Therefore, in this case, the following
    IAM policy may be overly permissive for your needs, in which case you can scope
    the role down to specific actions, conditions, and resources for your use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the launch role and the policy to dictate permissions, the role
    needs to be applied to the product as a launch constraint, as shown in the following
    screenshot. The detailed instructions to apply a launch constraint are included
    in the existing AWS product documentation, [https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/constraints-launch.html),
    under **Applying a Launch Constraint** -> **To assign the role to a product**.
    After applying the IAM role to the product launch constraint, you''ll see the
    constraint listed for the product, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – AWS Constraints'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – AWS Constraints
  prefs: []
  type: TYPE_NORMAL
- en: The launch constraint tells Service Catalog to assume the `ServiceCatalog`-`DataScienceProducts`
    role when an end user launches the product. This role contains the policy we created
    with the privileges needed to provision and configure all the resources in the
    `CloudFormation` template for that product.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will add a template constraint to limit the options for instance
    type size that is available to end users. This allows the implementation of cost
    controls on the type of instance that can be provisioned. You can optionally implement
    multiple constraints such as storage size. Template constraints are added as documented
    in the AWS product documentation: [https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_constraints_template-constraints.html](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_constraints_template-constraints.html).
    The specific template constraint JSON is listed in the following code block, where
    we are identifying that only the noted instance types are approved and available
    for use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the preceding template constraint, you''ll now see two constraints
    for this product in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – AWS Service Catalog – applied constraint'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17249_02_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – AWS Service Catalog – applied constraint
  prefs: []
  type: TYPE_NORMAL
- en: The product is then available, with the constraints we identified, within the
    Data Science Environment portfolio and can be made available for self-service
    provisioning by ML builders.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, the CloudFormation template to create a data science environment
    in SageMaker Studio will be used to create a new product inside the data science
    environment portfolio. Again, a new product can be added to an AWS Service Catalog
    portfolio using the AWS CLI, AWS SDK, or the AWS console. When a new product is
    added to a portfolio, the CloudFormation template that defines that environment
    must be uploaded to an S3 bucket and provided as input. The steps to add a product
    require administrative privileges in Service Catalog and are performed in the
    **Administration** view:'
  prefs: []
  type: TYPE_NORMAL
- en: From within the `Data Science Environments` portfolio, click on **Upload new
    product**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `Basic SageMaker Studio Environment`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note: The default location for templates used on launched stacks is `https://s3.<region>.amazonaws.com/cf-templates-<hash>-region/studio-environment.yaml`,
    or you can upload the CloudFormation template provided for this chapter directly
    to an S3 bucket of your choosing.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`release-1.0`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Initial product release`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For **Support details**, this section includes information about the support
    contacts and support information. Enter the following, leaving any field not specified
    blank:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Email contact**: Your email@mail.com'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After filling in the information as described in the preceding steps, scroll
    to the bottom, select **Review**, and then **Create Product**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The product will now be visible within the product list for the **Data Science
    Environments** portfolio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After adding the product to the portfolio, constraints can be added to the product.
    You can then add a launch constraint, to enforce minimum privileges, and template
    constraints based on your use case using the same steps performed under your notebook
    instance product steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'After configuring the products, they can be made available for self-service
    provisioning by ML builders. ML builders must be granted access to the AWS Service
    Catalog end user view in the AWS console. Please refer to the following documentation
    for details on sharing your portfolio and granting access to end users: [https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html).'
  prefs: []
  type: TYPE_NORMAL
- en: This section covered the advantages of using IaC/CaC (AWS CloudFormation) and
    a centrally managed catalog of IT services (AWS Service Catalog) to create data
    science environments at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Please head over to the *References* section to find additional reference links
    that you may find useful after reading this section.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you saw how to map SageMaker capabilities to different phases
    of the ML life cycle. You got a quick look at important SageMaker capabilities
    and saw how to set up your own SageMaker environment.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter further covered the advantages of using IaC/CaC (AWS CloudFormation)
    as well as a centrally managed catalog of IT services (AWS Service Catalog) to
    create data science environments at scale. The approaches discussed provide the
    guidance needed to reduce manual effort, provide consistency, accelerate access
    to model-building services, and enforce governance controls within model-building
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn more about labeling data for ML projects.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some of the references that you might find useful after reading
    this section:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon SageMaker notebook instances: [https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon SageMaker Studio Onboarding:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Amazon SageMaker Studio:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/)
    [https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Notebook Comparison:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-comparison.html](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-comparison.html)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'AWS Service Catalog:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/servicecatalog/](https://aws.amazon.com/servicecatalog/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'AWS CloudFormation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/cloudformation/](https://aws.amazon.com/cloudformation/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
