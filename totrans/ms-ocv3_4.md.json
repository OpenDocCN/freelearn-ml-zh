["```py\n    #include <opencv2/opencv.hpp> \n    using namespace cv; \n    class foo { \n      public: \n      Mat a; \n      type_b b; \n      void write(FileStorage &fs) const{ \n        assert(fs.isOpened()); \n        fs<< \"{\" << \"a\"  << a << \"b\"  << b << \"}\"; \n      } \n      void read(const FileNode& node){ \n        assert(node.type() == FileNode::MAP); \n        node[\"a\"] >> a; node[\"b\"] >> b; \n      } \n    };\n\n```", "```py\n    void write(FileStorage& fs, const string&, const foo& x) { \n      x.write(fs); \n    } \n    void read(const FileNode& node, foo& x,const foo& default){ \n      if(node.empty())x = d; else x.read(node); \n    }\n\n```", "```py\n    template<class T> \n    T load_ft(const char* fname){ \n      T x; FileStorage f(fname,FileStorage::READ); \n      f[\"ft object\"] >> x; f.release(); return x; \n    } \n    template<class T> \n    void save_ft(const char* fname,const T& x){ \n      FileStorage f(fname,FileStorage::WRITE); \n      f << \"ft object\" << x; f.release(); \n    }\n\n```", "```py\n    #include \"opencv_hotshots/ft/ft.hpp\" \n    #include \"foo.hpp\" \n    int main() { \n      ... \n      foo A; save_ft<foo>(\"foo.xml\",A); \n      ... \n      foo B = load_ft<foo>(\"foo.xml\"); \n      ... \n    }\n\n```", "```py\n    class ft_data{ \n      public: \n      vector<int> symmetry; \n      vector<Vec2i> connections; \n      vector<string> imnames; \n      vector<vector<Point2f>> points; \n      ... \n    }\n\n```", "```py\n    Mat \n    ft_data::get_image( \n      const int idx,   //index of image to load from file \n      const int flag) { //0=gray,1=gray+flip,2=rgb,3=rgb+flip \n        if((idx < 0) || (idx >= (int)imnames.size()))return Mat(); \n        Mat img,im; \n        if(flag < 2) img = imread(imnames[idx],0); \n        else         img = imread(imnames[idx],1); \n        if(flag % 2 != 0) flip(img,im,1); \n        else              im = img; \n        return im; \n      }\n\n```", "```py\n    vector<Point2f> \n    ft_data::get_points( \n    const int idx,        //index of image corresponding to points\n    const bool flipped) { //is the image flipped around the y-axis? \n      if((idx < 0) || (idx >= (int)imnames.size())) \n      return vector<Point2f>(); \n      vector<Point2f> p = points[idx]; \n      if(flipped){ \n        Mat im = this->get_image(idx,0); int n = p.size(); \n        vector<Point2f> q(n); \n        for(int i = 0; i < n; i++){       \n          q[i].x = im.cols-1-p[symmetry[i]].x; \n          q[i].y = p[symmetry[i]].y; \n        } return q; \n      } else return p; \n    }\n\n```", "```py\n    void ft_data::rm_incomplete_samples(){ \n      int n = points[0].size(),N = points.size(); \n      for(int i = 1; i < N; i++)n = max(n,int(points[i].size())); \n      for(int i = 0; i < int(points.size()); i++){ \n        if(int(points[i].size()) != n){ \n          points.erase(points.begin()+i); \n          imnames.erase(imnames.begin()+i); i--; \n        } else { \n          int j = 0; \n          for(; j < n; j++) { \n            if((points[i][j].x <= 0) || \n            (points[i][j].y <= 0))break; \n          } \n          if(j < n) { \n            points.erase(points.begin()+i); \n            imnames.erase(imnames.begin()+i); i--; \n          } \n        } \n      } \n    }\n\n```", "```py\n    ft_data D;                          //instantiate data structure \n    ...                                 //populate data \n    save_ft<ft_data>(\"mydata.xml\",D);   //save data\n\n```", "```py\n    class shape_model { //2d linear shape model \n      public: \n      Mat p; //parameter vector (kx1) CV_32F \n      Mat V; //linear subspace (2nxk) CV_32F \n      Mat e; //parameter variance (kx1) CV_32F \n      Mat C; //connectivity (cx2) CV_32S \n      ... \n      void calc_params( \n      const vector<Point2f>&pts,  //points to compute parameters \n      const Mat &weight = Mat(),    //weight/point (nx1) CV_32F \n      const float c_factor = 3.0); //clamping factor \n      ... \n      vector<Point2f>              //shape described by parameters \n      calc_shape(); \n      ... \n      void train( \n      const vector<vector<Point2f>>&p, //N-example shapes \n      const vector<Vec2i>&con = vector<Vec2i>(),//connectivity \n      const float frac = 0.95, //fraction of variation to retain \n      const int kmax = 10);   //maximum number of modes to retain \n      ... \n    }\n\n```", "```py\n    #define fl at<float> \n    Mat shape_model::procrustes ( \n    const Mat &X,       //interleaved raw shape data as columns \n    const int itol,     //maximum number of iterations to try \n    const float ftol)   //convergence tolerance \n    { \n      int N = X.cols,n = X.rows/2; Mat Co,P = X.clone();//copy \n      for(int i = 0; i < N; i++){ \n        Mat p = P.col(i);            //i'th shape \n        float mx = 0,my = 0;         //compute centre of mass... \n        for(int j = 0; j < n; j++) { //for x and y separately \n          mx += p.fl(2*j); my += p.fl(2*j+1); \n        } \n        mx /= n; my /= n; \n        for(int j = 0; j < n; j++) {  //remove center of mass \n          p.fl(2*j) -= mx; p.fl(2*j+1) -= my; \n        } \n      } \n      for(int iter = 0; iter < itol; iter++) {     \n        Mat C = P*Mat::ones(N,1,CV_32F)/N; //compute normalized... \n        normalize(C,C);                    //canonical shape \n        if(iter > 0) { if(norm(C,Co) < ftol) break; } //converged? \n        Co = C.clone();                               //remember current estimate \n        for(int i = 0; i < N; i++){ \n          Mat R = this->rot_scale_align(P.col(i),C); \n          for(int j = 0; j < n; j++) { //apply similarity transform \n            float x = P.fl(2*j,i), y = P.fl(2*j+1,i); \n            P.fl(2*j  ,i) = R.fl(0,0)*x + R.fl(0,1)*y; \n            P.fl(2*j+1,i) = R.fl(1,0)*x + R.fl(1,1)*y; \n          } \n        } \n      } return P; //returned procrustes aligned shapes \n    }\n\n```", "```py\n    Mat shape_model::rot_scale_align( \n      const Mat &src, //[x1;y1;...;xn;yn] vector of source shape \n      const Mat &dst) //destination shape \n      { \n        //construct linear system \n        int n = src.rows/2; \n        float a=0, b=0, d=0; \n        for(int i = 0; i < n; i++) { \n          d+= src.fl(2*i)*src.fl(2*i  )+src.fl(2*i+1)*src.fl(2*i+1); \n          a+= src.fl(2*i)*dst.fl(2*i  )+src.fl(2*i+1)*dst.fl(2*i+1); \n          b+= src.fl(2*i)*dst.fl(2*i+1)-src.fl(2*i+1)*dst.fl(2*i  ); \n        } \n        a /= d; b /= d;//solve linear system \n        return (Mat_<float>(2,2) << a,-b,b,a); \n      }\n\n```", "```py\n    SVD svd(dY*dY.t()); \n    int m = min(min(kmax,N-1),n-1); \n    float vsum = 0; for(int i = 0; i < m; i++)vsum += svd.w.fl(i); \n    float v = 0; int k = 0; \n    for(k = 0; k < m; k++){ \n      v += svd.w.fl(k); if(v/vsum >= frac){k++; break;} \n    } \n    if(k > m)k = m; \n    Mat D = svd.u(Rect(0,0,k,2*n));\n\n```", "```py\n    Mat R = this->calc_rigid_basis(Y); //compute rigid subspace \n    Mat P = R.t()*Y; Mat dY = Y - R*P; //project-out rigidity\n\n```", "```py\n    V.create(2*n,4+k,CV_32F);                  //combined subspace \n    Mat Vr = V(Rect(0,0,4,2*n)); R.copyTo(Vr); //rigid subspace  \n    Mat Vd = V(Rect(4,0,k,2*n)); D.copyTo(Vd); //nonrigid subspace\n\n```", "```py\n    p = V.t()*s;\n\n```", "```py\n    Mat Q = V.t()*X;               //project raw data onto subspace \n    for(int i = 0; i < N; i++) {   //normalize coordinates w.r.t scale \n      float v = Q.fl(0,i); Mat q = Q.col(i); q /= v; \n    } \n    e.create(4+k,1,CV_32F); multiply(Q,Q,Q); \n    for(int i = 0; i < 4+k; i++) { \n      if(i < 4)  e.fl(i) = -1;     //no clamping for rigid coefficients \n      else       e.fl(i) = Q.row(i).dot(Mat::ones(1,N,CV_32F))/(N-1); \n    }\n\n```", "```py\n    void shape_model::clamp(const float c) { \n      //clamping as fraction of standard deviation \n      double scale = p.fl(0);        //extract scale \n      for(int i = 0; i < e.rows; i++) { \n        if(e.fl(i) < 0)continue;       //ignore rigid components \n        float v = c*sqrt(e.fl(i));     //c*standard deviations box \n        if(fabs(p.fl(i)/scale) > v) {  //preserve sign of coordinate \n          if(p.fl(i) > 0) p.fl(i) =  v*scale; //positive threshold \n          else            p.fl(i) = -v*scale; //negative threshold \n        } \n      } \n    }\n\n```", "```py\n    ft_data data = load_ft<ft_data>(argv[1]); \n    data.rm_incomplete_samples();\n\n```", "```py\n    vector<vector<Point2f>> points; \n    for(int i = 0; i < int(data.points.size()); i++) { \n      points.push_back(data.get_points(i,false)); \n      if(mirror)points.push_back(data.get_points(i,true)); \n    }\n\n```", "```py\n    shape_model smodel;       \n    smodel.train(points,data.connections,frac,kmax);\n\n```", "```py\n   save_ft(argv[2],smodel);\n\n```", "```py\n    shape_model smodel = load_ft<shape_model>(argv[1]);\n\n```", "```py\n    int n = smodel.V.rows/2; \n    float scale = calc_scale(smodel.V.col(0),200); \n    float tranx = \n      n*150.0/smodel.V.col(2).dot(Mat::ones(2*n,1,CV_32F)); \n    float trany = \n      n*150.0/smodel.V.col(3).dot(Mat::ones(2*n,1,CV_32F));\n\n```", "```py\n    vector<float> val; \n    for(int i = 0; i < 50; i++)val.push_back(float(i)/50); \n    for(int i = 0; i < 50; i++)val.push_back(float(50-i)/50); \n    for(int i = 0; i < 50; i++)val.push_back(-float(i)/50); \n    for(int i = 0; i < 50; i++)val.push_back(-float(50-i)/50);\n\n```", "```py\n    Mat img(300,300,CV_8UC3); namedWindow(\"shape model\"); \n    while(1) { \n      for(int k = 4; k < smodel.V.cols; k++){ \n        for(int j = 0; j < int(val.size()); j++){ \n          Mat p = Mat::zeros(smodel.V.cols,1,CV_32F); \n          p.at<float>(0) = scale; \n          p.at<float>(2) = tranx; \n          p.at<float>(3) = trany; \n          p.at<float>(k) = scale*val[j]*3.0* \n          sqrt(smodel.e.at<float>(k));   \n          p.copyTo(smodel.p); img = Scalar::all(255); \n          vector<Point2f> q = smodel.calc_shape(); \n          draw_shape(img,q,smodel.C); \n          imshow(\"shape model\",img); \n          if(waitKey(10) == 'q')return 0; \n        } \n      } \n    }\n\n```", "```py\n    class patch_model{ \n      public: \n      Mat P; //normalized patch \n      ... \n      Mat                          //response map \n      calc_response( \n      const Mat &im,               //image patch of search region \n      const bool sum2one = false); //normalize to sum-to-one? \n      ... \n      void train(const vector<Mat>&images, //training image patches \n      const Size psize,                    //patch size \n      const float var = 1.0,               //ideal response variance \n      const float lambda = 1e-6,           //regularization weight \n      const float mu_init = 1e-3,          //initial step size \n      const int nsamples = 1000,           //number of samples \n      const bool visi = false);            //visualize process? \n      ... \n    };\n\n```", "```py\n    void patch_model::train( \n      const vector<Mat>&images, //featured centered training images \n      const Size psize,          //desired patch model size \n      const float var,           //variance of annotation error \n      const float lambda,        //regularization parameter \n      const float mu_init,       //initial step size \n      const int nsamples,        //number of stochastic samples \n      const bool visi) {         //visualise training process \n        int N = images.size(),n = psize.width*psize.height; \n        int dx = wsize.width-psize.width;      //center of response map \n        int dy = wsize.height-psize.height;    //... \n        Mat F(dy,dx,CV_32F);                   //ideal response map \n        for(int y = 0; y < dy; y++) { \n          float vy = (dy-1)/2 - y; \n          for(int x = 0; x < dx; x++) {\n            float vx = (dx-1)/2 - x; \n            F.fl(y,x) = exp(-0.5*(vx*vx+vy*vy)/var); //Gaussian \n          } \n        } \n        normalize(F,F,0,1,NORM_MINMAX); //normalize to [0:1] range \n\n        //allocate memory \n        Mat I(wsize.height,wsize.width,CV_32F); \n        Mat dP(psize.height,psize.width,CV_32F); \n        Mat O = Mat::ones(psize.height,psize.width,CV_32F)/n; \n        P = Mat::zeros(psize.height,psize.width,CV_32F); \n\n        //optimise using stochastic gradient descent \n        RNG rn(getTickCount()); //random number generator \n        double mu=mu_init,step=pow(1e-8/mu_init,1.0/nsamples); \n        for(int sample = 0; sample < nsamples; sample++){ \n          int i = rn.uniform(0,N); //randomly sample image index \n          I = this->convert_image(images[i]); dP = 0.0; \n          for(int y = 0; y < dy; y++) { //compute stochastic gradient \n            for(int x = 0; x < dx; x++){ \n              Mat Wi=I(Rect(x,y,psize.width,psize.height)).clone(); \n              Wi -= Wi.dot(O); normalize(Wi,Wi); //normalize \n              dP += (F.fl(y,x) - P.dot(Wi))*Wi; \n            } \n          }     \n          P += mu*(dP - lambda*P); //take a small step \n          mu *= step;              //reduce step size \n          ... \n        } return; \n      }\n\n```", "```py\n    I += 1.0; log(I,I);\n\n```", "```py\n    class patch_models { \n      public: \n      Mat reference;      //reference shape [x1;y1;...;xn;yn] \n      vector<patch_model> patches; //patch model/facial feature \n      ... \n      void train(ft_data &data,        //annotated image and shape data \n        const vector<Point2f>&ref,       //reference shape \n        const Size psize,           //desired patch size \n        const Size ssize,           //training search window size \n        const bool mirror = false,  //use mirrored training data \n        const float var = 1.0,      //variance of annotation error \n        const float lambda = 1e-6,  //regularisation weight \n        const float mu_init = 1e-3, //initial step size \n        const int nsamples = 1000,  //number of samples \n        const bool visi = false);   //visualise training procedure? \n        ... \n        vector<Point2f>//location of peak responses/feature in image \n  calc_peaks( \n          const Mat &im,    //image to detect features in \n          const vector<Point2f>&points, //current estimate of shape \n          const Size ssize = Size(21,21)); //search window size \n          ... \n      };\n\n```", "```py\n    Mat S = this->calc_simil(pt),A(2,3,CV_32F); \n    A.fl(0,0) = S.fl(0,0); A.fl(0,1) = S.fl(0,1); \n    A.fl(1,0) = S.fl(1,0); A.fl(1,1) = S.fl(1,1); \n    A.fl(0,2) = pt.fl(2*i  ) - (A.fl(0,0)*(wsize.width -1)/2 + \n    A.fl(0,1)*(wsize.height-1)/2); \n    A.fl(1,2) = pt.fl(2*i+1) - (A.fl(1,0)*(wsize.width -1)/2 + \n    A.fl(1,1)*(wsize.height-1)/2); \n    Mat I; warpAffine(im,I,A,wsize,INTER_LINEAR+WARP_INVERSE_MAP);\n\n```", "```py\n    vector<Point2f> \n    patch_models::calc_peaks(const Mat &im, \n    const vector<Point2f>&points,const Size ssize){ \n    int n = points.size(); assert(n == int(patches.size())); \n    Mat pt = Mat(points).reshape(1,2*n); \n    Mat S = this->calc_simil(pt); \n    Mat Si = this->inv_simil(S); \n    vector<Point2f> pts = this->apply_simil(Si,points); \n    for(int i = 0; i < n; i++){ \n      Size wsize = ssize + patches[i].patch_size(); \n      Mat A(2,3,CV_32F),I;      \n      A.fl(0,0) = S.fl(0,0); A.fl(0,1) = S.fl(0,1); \n      A.fl(1,0) = S.fl(1,0); A.fl(1,1) = S.fl(1,1); \n      A.fl(0,2) = pt.fl(2*i  ) - (A.fl(0,0)*(wsize.width -1)/2 + \n      A.fl(0,1)*(wsize.height-1)/2); \n      A.fl(1,2) = pt.fl(2*i+1) - (A.fl(1,0)*(wsize.width -1)/2 + \n      A.fl(1,1)*(wsize.height-1)/2); \n      warpAffine(im,I,A,wsize,INTER_LINEAR+WARP_INVERSE_MAP); \n      Mat R = patches[i].calc_response(I,false); \n      Point maxLoc; minMaxLoc(R,0,0,0,&maxLoc); \n      pts[i] = Point2f(pts[i].x + maxLoc.x - 0.5*ssize.width, \n      pts[i].y + maxLoc.y - 0.5*ssize.height); \n    } return this->apply_simil(S,pts);\n\n```", "```py\n    ft_data data = load_ft<ft_data>(argv[1]); \n    data.rm_incomplete_samples();\n\n```", "```py\n    shape_model smodel = load_ft<shape_model>(argv[2]);\n\n```", "```py\n    smodel.p = Scalar::all(0.0); \n    smodel.p.fl(0) = calc_scale(smodel.V.col(0),width); \n    vector<Point2f> r = smodel.calc_shape();\n\n```", "```py\n    patch_models pmodel;       \n    pmodel.train(data,r,Size(psize,psize),Size(ssize,ssize));\n\n```", "```py\n    class face_detector{ //face detector for initialisation \n      public: \n      string detector_fname; //file containing cascade classifier \n      Vec3f detector_offset; //offset from center of detection \n      Mat reference;         //reference shape \n      CascadeClassifier detector; //face detector \n\n      vector<Point2f>  //points describing detected face in image \n      detect(const Mat &im,          //image containing face \n        const float scaleFactor = 1.1,//scale increment \n        const int minNeighbours = 2,  //minimum neighborhood size \n      const Size minSize = Size(30,30));//minimum window size \n\n      void train(ft_data &data,         //training data \n        const string fname,             //cascade detector \n        const Mat &ref,                 //reference shape \n        const bool mirror = false,      //mirror data? \n        const bool visi = false,        //visualize training? \n        const float frac = 0.8,       //fraction of points in detection \n        const float scaleFactor = 1.1,  //scale increment \n        const int minNeighbours = 2,    //minimum neighbourhood size \n      const Size minSize = Size(30,30)); //minimum window size \n      ... \n    };\n\n```", "```py\n    Mat gray; //convert image to grayscale and histogram equalize \n    if(im.channels() == 1)  gray = im; \n    else                    cvtColor(im,gray,CV_RGB2GRAY); \n    Mat eqIm; equalizeHist(gray,eqIm); \n    vector<Rect> faces; //detect largest face in image \n    detector.detectMultiScale(eqIm,faces,scaleFactor, minNeighbours,0 \n      |CV_HAAR_FIND_BIGGEST_OBJECT \n      |CV_HAAR_SCALE_IMAGE,minSize); \n    if(faces.size() < 1) { return vector<Point2f>(); } \n\nRect R = faces[0]; Vec3f scale = detector_offset*R.width; \n int n = reference.rows/2; vector<Point2f> p(n); \n for(int i = 0; i < n; i++){ //predict face placement \n p[i].x = scale[2]*reference.fl(2*i  ) + R.x + 0.5 * R.width  + \n scale[0]; \n p[i].y = scale[2]*reference.fl(2*i+1) + R.y + 0.5 * R.height + \n scale[1]; \n } return p;\n\n```", "```py\ndetector.load(fname.c_str()); detector_fname = fname; reference = ref.clone();\n\n```", "```py\n    if(this->enough_bounded_points(pt,faces[0],frac)){ \n      Point2f center = this->center_of_mass(pt); \n      float w = faces[0].width; \n      xoffset.push_back((center.x - \n        (faces[0].x+0.5*faces[0].width ))/w); \n      yoffset.push_back((center.y - \n        (faces[0].y+0.5*faces[0].height))/w); \n      zoffset.push_back(this->calc_scale(pt)/w); \n    }\n\n```", "```py\n    Mat X = Mat(xoffset),Xsort,Y = Mat(yoffset),Ysort,Z =    \n      Mat(zoffset),Zsort; \n    cv::sort(X,Xsort,CV_SORT_EVERY_COLUMN|CV_SORT_ASCENDING); \n    int nx = Xsort.rows; \n    cv::sort(Y,Ysort,CV_SORT_EVERY_COLUMN|CV_SORT_ASCENDING); \n    int ny = Ysort.rows; \n    cv::sort(Z,Zsort,CV_SORT_EVERY_COLUMN|CV_SORT_ASCENDING); \n    int nz = Zsort.rows; \n    detector_offset = \n      Vec3f(Xsort.fl(nx/2),Ysort.fl(ny/2),Zsort.fl(nz/2));\n\n```", "```py\n    ft_data data = load_ft<ft_data>(argv[2]); \n    shape_model smodel = load_ft<shape_model>(argv[3]); \n    smodel.set_identity_params(); \n    vector<Point2f> r = smodel.calc_shape(); \n    Mat ref = Mat(r).reshape(1,2*r.size());\n\n```", "```py\n    face_detector detector; \n    detector.train(data,argv[1],ref,mirror,true,frac); \n    save_ft<face_detector>(argv[4],detector);\n\n```", "```py\n    class face_tracker{ \n      public: \n      bool tracking;          //are we in tracking mode? \n      fps_timer timer;        //frames/second timer \n      vector<Point2f> points; //current tracked points \n      face_detector detector; //detector for initialisation \n      shape_model smodel;     //shape model \n      patch_models pmodel;    //feature detectors \n\n      face_tracker(){tracking = false;} \n\n      int                             //0 = failure \n      track(const Mat &im,            //image containing face \n      const face_tracker_params &p =  //fitting parameters \n      face_tracker_params());     //default tracking parameters \n\n      void \n      reset(){                            \n        //reset tracker \n        tracking = false; timer.reset(); \n      } \n      ... \n      protected: \n      ... \n      vector<Point2f>   //points for fitted face in image \n      fit(const Mat &image,//image containing face \n      const vector<Point2f>&init,   //initial point estimates \n      const Size ssize = Size(21,21),//search region size \n      const bool robust = false,     //use robust fitting? \n      const int itol = 10,    //maximum number of iterations \n      const float ftol = 1e-3);      //convergence tolerance \n    };\n\n```", "```py\n    int face_tracker:: \n    track(const Mat &im,const face_tracker_params &p) { \n      Mat gray; //convert image to grayscale \n      if(im.channels()==1)  gray=im; \n      else                  cvtColor(im,gray,CV_RGB2GRAY); \n      if(!tracking) //initialize \n      points = detector.detect(gray,p.scaleFactor, \n        p.minNeighbours,p.minSize); \n      if((int)points.size() != smodel.npts()) return 0; \n      for(int level = 0; level < int(p.ssize.size()); level++) \n      points = this->fit(gray,points,p.ssize[level], \n        p.robust,p.itol,p.ftol); \n      tracking = true; timer.increment();  return 1; \n    }\n\n```", "```py\n    smodel.calc_params(init); \n    vector<Point2f> pts = smodel.calc_shape(); \n    vector<Point2f> peaks = pmodel.calc_peaks(image,pts,ssize);\n\n```", "```py\n    smodel.calc_params(peaks);         \n    pts = smodel.calc_shape();\n\n```", "```py\n    face_tracker tracker; \n    tracker.smodel = load_ft<shape_model>(argv[1]); \n    tracker.pmodel = load_ft<patch_models>(argv[2]); \n    tracker.detector = load_ft<face_detector>(argv[3]); \n    save_ft<face_tracker>(argv[4],tracker);\n\n```"]