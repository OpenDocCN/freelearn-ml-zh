["```py\nimport argparse\n\nimport cv2\nimport numpy as np\n\nfrom classes import CLASSES_90\nfrom sort import Sort\n```", "```py\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-i\", \"--input\",\n                    help=\"Video path, stream URI, or camera ID \", default=\"demo.mkv\")\nparser.add_argument(\"-t\", \"--threshold\", type=float, default=0.3,\n                    help=\"Minimum score to consider\")\nparser.add_argument(\"-m\", \"--mode\", choices=['detection', 'tracking'], default=\"tracking\",\n                    help=\"Either detection or tracking mode\")\n\nargs = parser.parse_args()\n```", "```py\nif args.input.isdigit():\n    args.input = int(args.input)\n```", "```py\nTRACKED_CLASSES = [\"car\", \"person\"]\nBOX_COLOR = (23, 230, 210)\nTEXT_COLOR = (255, 255, 255)\nINPUT_SIZE = (300,300)\n```", "```py\nconfig = \"./ssd_mobilenet_v1_coco_2017_11_17.pbtxt.txt\"\nmodel = \"frozen_inference_graph.pb\"\ndetector = cv2.dnn.readNetFromTensorflow(model,config)\n```", "```py\ndef illustrate_box(image: np.ndarray, box: np.ndarray, caption: str) -> None:\n```", "```py\nrows, cols = frame.shape[:2]\n```", "```py\npoints = box.reshape((2, 2)) * np.array([cols, rows])\np1, p2 = points.astype(np.int32)\n```", "```py\ncv2.rectangle(image, tuple(p1), tuple(p2), BOX_COLOR, thickness=4)\n```", "```py\ncv2.putText(\n    image,\n    caption,\n    tuple(p1),\n    cv2.FONT_HERSHEY_SIMPLEX,\n    0.75,\n    TEXT_COLOR,\n    2)\n```", "```py\ndef illustrate_detections(dets: np.ndarray, frame: np.ndarray) -> np.ndarray:\n    class_ids, scores, boxes = dets[:, 0], dets[:, 1], dets[:, 2:6]\n    for class_id, score, box in zip(class_ids, scores, boxes):\n        illustrate_box(frame, box, f\"{CLASSES_90[int(class_id)]} {score:.2f}\")\n    return frame\n```", "```py\ncap = cv2.VideoCapture(args.input)\n```", "```py\nfor res, frame in iter(cap.read, (False, None)):\n```", "```py\ndetector.setInput(\n    cv2.dnn.blobFromImage(\n        frame,\n        size=INPUT_SIZE,\n        swapRB=True,\n        crop=False))\n```", "```py\ndetections = detector.forward()[0, 0, :, 1:]\n```", "```py\nscores = detections[:, 1]\ndetections = detections[scores > 0.3]\n```", "```py\nif args.mode == \"detection\":\n    out = illustrate_detections(detections, frame)\n    cv2.imshow(\"out\", out)\n```", "```py\nif cv2.waitKey(1) == 27:\n    exit()\n```", "```py\ndetector = cv2.dnn.readNetFromDarknet(\"yolov3-tiny.cfg\", \"yolov3-tiny.weights\")\n```", "```py\nINPUT_SIZE = (320, 320)\n```", "```py\nwith open(\"coco.names\") as f:\n    CLASSES_90 = f.read().split(\"\\n\")\n```", "```py\ndetector.setInput(\n    cv2.dnn.blobFromImage(\n        frame,\n        scalefactor=1 / 255.0,\n        size=INPUT_SIZE,\n        swapRB=True,\n        crop=False))\n```", "```py\ncenters = detections[:, 0:2]\n```", "```py\nsizes = detections[:, 2:4]\n```", "```py\nscores_one_hot = detections[:, 5:]\n```", "```py\nclass_ids = np.argmax(scores_one_hot, axis=1)\n```", "```py\nscores = np.max(scores_one_hot, axis=1)\n```", "```py\ndetections = np.concatenate(\n    (class_ids[:, None], scores[:, None], centers - sizes / 2, centers + sizes / 2), axis=1)\ndetections = detections[scores > 0.3]\n```", "```py\ndef iou(a: np.ndarray, b: np.ndarray) -> float:\n```", "```py\na_tl, a_br = a[:4].reshape((2, 2))\nb_tl, b_br = b[:4].reshape((2, 2))\n```", "```py\nint_tl = np.maximum(a_tl, b_tl)\n```", "```py\nint_br = np.minimum(a_br, b_br)\n```", "```py\na_area = np.product(a_br - a_tl)\nb_area = np.product(b_br - b_tl)\n```", "```py\nint_area = np.product(np.maximum(0., int_br - int_tl))\n```", "```py\nreturn int_area / (a_area + b_area - int_area)\n```", "```py\nTRACKED_CLASSES = [\"car\", \"person\"]\nmots = {CLASSES_90.index(tracked_class): Sort()\n            for tracked_class in TRACKED_CLASSES}\n```", "```py\ndef track(dets: np.ndarray,\n          illustration_frame: np.ndarray = None):\n    for class_id, mot in mots.items():\n```", "```py\nclass_dets = dets[dets[:, 0] == class_id]\n```", "```py\nsort_boxes = mot.update(class_dets[:, 2:6])\n```", "```py\nif illustration_frame is not None:\n    for box in sort_boxes:\n        illustrate_box(illustration_frame, box[:4],\n            f\"{CLASSES_90[class_id]} {int(box[4])}\")\n```", "```py\ndef illustrate_tracking_info(frame: np.ndarray) -> np.ndarray:\n    for num, (class_id, tracker) in enumerate(trackers.items()):\n        txt = f\"{CLASSES_90[class_id]}:Total:{tracker.count} Now:{len(tracker.trackers)}\"\n        cv2.putText(frame, txt, (0, 50 * (num + 1)),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, TEXT_COLOR, 2)\n    return frame\n```", "```py\nif args.mode == \"tracking\"\n    out = frame\n    track(detections, frame)\n    illustrate_tracking_info(out)\n```", "```py\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\nfrom typing import Tuple\nimport cv2\n```", "```py\ndef bbox_to_observation(bbox):\n    x, y = (bbox[0:2] + bbox[2:4]) / 2\n```", "```py\n    w, h = bbox[2:4] - bbox[0:2]\n```", "```py\n    s = w * h\n```", "```py\n    r = w / h\n```", "```py\n    return np.array([x, y, s, r])[:, None].astype(np.float64)\n```", "```py\ndef state_to_bbox(x):\n    center_x, center_y, s, r, _, _, _ = x.flatten()\n```", "```py\n    w = np.sqrt(s * r)\n    h = s / w\n```", "```py\n    center = np.array([center_x, center_y])\n```", "```py\n    half_size = np.array([w, h]) / 2\n    corners = center - half_size, center + half_size\n```", "```py\n    return np.concatenate(corners).astype(np.float64)\n```", "```py\nclass KalmanBoxTracker:\n    def __init__(self, bbox, label):\n```", "```py\n        self.id = label\n        self.time_since_update = 0\n        self.hit_streak = 0\n```", "```py\n        self.kf = cv2.KalmanFilter(dynamParams=7, measureParams=4, type=cv2.CV_64F)\n```", "```py\n        self.kf.transitionMatrix = np.array(\n            [[1, 0, 0, 0, 1, 0, 0],\n             [0, 1, 0, 0, 0, 1, 0],\n             [0, 0, 1, 0, 0, 0, 1],\n             [0, 0, 0, 1, 0, 0, 0],\n             [0, 0, 0, 0, 1, 0, 0],\n             [0, 0, 0, 0, 0, 1, 0],\n             [0, 0, 0, 0, 0, 0, 1]], dtype=np.float64)\n```", "```py\n        self.kf.processNoiseCov = np.diag([10, 10, 10, 10, 1e4, 1e4, 1e4]).astype(np.float64)\n```", "```py\n        self.kf.measurementMatrix = np.array(\n            [[1, 0, 0, 0, 0, 0, 0],\n             [0, 1, 0, 0, 0, 0, 0],\n             [0, 0, 1, 0, 0, 0, 0],\n             [0, 0, 0, 1, 0, 0, 0]], dtype=np.float64)\n```", "```py\n        self.kf.measurementNoiseCov = np.diag([10, 10, 1e3, 1e3]).astype(np.float64)\n\n```", "```py\n        self.kf.statePost = np.vstack((convert_bbox_to_z(bbox), [[0], [0], [0]]))\n        self.kf.errorCovPost = np.diag([1, 1, 1, 1, 1e-2, 1e-2, 1e-4]).astype(np.float64)\n```", "```py\n    def update(self, bbox):\n        self.time_since_update = 0\n        self.hit_streak += 1\n\n        self.kf.correct(bbox_to_observation(bbox))\n```", "```py\n    def predict(self):\n        if self.time_since_update > 0:\n            self.hit_streak = 0\n```", "```py\n        self.time_since_update += 1\n```", "```py\n        return state_to_bbox(self.kf.predict())\n```", "```py\ndef associate_detections_to_trackers(detections: np.ndarray, trackers: np.ndarray,\n          iou_threshold: float = 0.3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n```", "```py\niou_matrix = np.zeros((len(detections), len(trackers)), dtype=np.float32)\n```", "```py\nfor d, det in enumerate(detections):\n    for t, trk in enumerate(trackers):\n        iou_matrix[d, t] = iou(det, trk)\n```", "```py\nrow_ind, col_ind = linear_sum_assignment(-iou_matrix)\n```", "```py\nmatched_indices = np.transpose(np.array([row_ind, col_ind]))\n```", "```py\niou_values = np.array([iou_matrix[detection, tracker]\n                       for detection, tracker in matched_indices])\n```", "```py\ngood_matches = matched_indices[iou_values > 0.3]\n```", "```py\nunmatched_detections = np.array(\n    [i for i in range(len(detections)) if i not in good_matches[:, 0]])\n```", "```py\nunmatched_trackers = np.array(\n    [i for i in range(len(trackers)) if i not in good_matches[:, 1]])\n```", "```py\nreturn good_matches, unmatched_detections, unmatched_trackers\n```", "```py\nclass Sort:\n    def __init__(self, max_age=2, min_hits=3):\n        self.max_age = max_age\n        self.min_hits = min_hits\n        self.trackers = []\n        self.count = 0\n```", "```py\ndef next_id(self):\n    self.count += 1\n    return self.count\n```", "```py\ndef update(self, dets):\n```", "```py\nself.trackers = [\n    tracker for tracker in self.trackers if not np.any(\n        np.isnan(\n            tracker.predict()))]\n```", "```py\ntrks = np.array([tracker.current_state for tracker in self.trackers])\n```", "```py\nmatched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(\n    dets, trks)\n```", "```py\nfor detection_num, tracker_num in matched:\n    self.trackers[tracker_num].update(dets[detection_num])\n```", "```py\nfor i in unmatched_dets:\n    self.trackers.append(KalmanBoxTracker(dets[i, :], self.next_id()))\n```", "```py\nret = np.array([np.concatenate((trk.current_state, [trk.id + 1]))\n                for trk in self.trackers\n                if trk.time_since_update < 1 and trk.hit_streak >= self.min_hits])\n```", "```py\nself.trackers = [\n    tracker for tracker in self.trackers if tracker.time_since_update <= self.max_age]\n```", "```py\nreturn ret\n```"]