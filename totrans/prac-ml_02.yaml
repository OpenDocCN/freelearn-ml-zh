- en: Chapter 2. Machine learning and Large-scale datasets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. 机器学习和大规模数据集
- en: We have seen a dramatic change in the way data has been handled in the recent
    past with the advent of big data. The field of Machine learning has seen the need
    to include scaling up strategies to handle the new age data requirements. This
    actually means that some of the traditional Machine learning implementations will
    not all be relevant in the context of big data now. Infrastructure and tuning
    requirements are now the challenges with the need to store and process large scale
    data complimented by the data format complexities.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近过去，随着大数据的出现，数据处理的方式发生了戏剧性的变化。机器学习领域已经看到需要包括扩展策略来处理新时代的数据需求。这实际上意味着在大数据的背景下，一些传统的机器学习实现将不再相关。现在，基础设施和调整需求是挑战，需要存储和处理大规模数据，并辅以数据格式复杂性。
- en: With the evolution of hardware architectures, accessibility of cheaper hardware
    with distributed architectures and new programming paradigms for simplified parallel
    processing options, which can now be applied to many learning algorithms, we see
    a rising interest in scaling up the Machine learning systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着硬件架构的演变，更便宜且具有分布式架构的硬件的可用性以及新的编程范式以简化并行处理选项，这些现在可以应用于许多学习算法，我们看到对扩展机器学习系统的兴趣正在上升。
- en: 'The topics listed next are covered in-depth in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了以下主题：
- en: An introduction to big data and typical challenges of large-scale Machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据简介和大规模机器学习的典型挑战
- en: The motivation behind scaling up and scaling out Machine learning, and an overview
    of parallel and distributed processing for huge datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展和扩展机器学习的动机，以及针对大型数据集的并行和分布式处理概述
- en: An overview of Concurrent Algorithm design, Big O notations, and task decomposition
    techniques for achieving parallelism
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发算法设计概述、大O符号和任务分解技术以实现并行性
- en: The advent of cloud frameworks to provide cloud clustering, distributed data
    storage, fault tolerance, and high availability coupled with effective utilization
    of computational resources
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云框架的出现，提供云集群、分布式数据存储、容错和高可用性，以及有效利用计算资源
- en: Frameworks and platform options for implementing large-scale Machine learning
    (Parallel Processing Frameworks such as MapReduce in **Massive Parallel Processing**
    (**MPP**), MRI, platforms as GPU, FPGA, and Multicore)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施大规模机器学习的框架和平台选项（例如在**大规模并行处理**（**MPP**）、MRI、GPU、FPGA和多核平台上的并行处理框架）
- en: Big data and the context of large-scale Machine learning
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据和大规模机器学习的背景
- en: 'I have covered some of the core aspects of big data in my previous Packt book
    titled *Getting Started with Greenplum for Big Data Analytics*. In this section,
    we will quickly recap some of the core aspects of big data and its impact in the
    field of Machine learning:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前出版的Packt书籍《Greenplum大数据分析入门》中，我已经涵盖了大数据的一些核心方面。在本节中，我们将快速回顾大数据的核心方面及其在机器学习领域的影响：
- en: 'The definition of large-scale is a scale of terabytes, petabytes, exabytes,
    or higher. This is typically the volume that cannot be handled by traditional
    database engines. The following chart lists the orders of magnitude that represents
    data volumes:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模的定义是千兆字节、太字节、艾字节或更高的规模。这通常是传统数据库引擎无法处理的数据量。以下图表列出了表示数据量的数量级：
- en: '| Multiples of bytes |'
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 字节倍数 |'
- en: '| --- |'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- |'
- en: '| **SI decimal prefixes** | **Binary Usage** |'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **国际单位制十进制前缀** | **二进制用法** |'
- en: '| **Name(Symbol)** | **Value** |'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **名称（符号）** | **值** |'
- en: '| Kilobyte (KB) | 103 | 210 |'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Kilobyte (KB) | 103 | 210 |'
- en: '| Megabyte (MB) | 106 | 220 |'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Megabyte (MB) | 106 | 220 |'
- en: '| Gigabyte (GB) | 109 | 230 |'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Gigabyte (GB) | 109 | 230 |'
- en: '| Terabyte (TB) | 1012 | 240 |'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Terabyte (TB) | 1012 | 240 |'
- en: '| Petabyte (PB) | 1015 | 250 |'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Petabyte (PB) | 1015 | 250 |'
- en: '| Exabyte (EB) | 1018 | 260 |'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Exabyte (EB) | 1018 | 260 |'
- en: '| Zettabyte (ZB) | 1021 | 270 |'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Zettabyte (ZB) | 1021 | 270 |'
- en: '| Yottabyte (YB) | 1024 | 280 |'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| Yottabyte (YB) | 1024 | 280 |'
- en: Data formats that are referred to in this context are distinct; they are generated
    and consumed, and need not be structured (for example, DBMS and relational data
    stores). Now, there are new sources of data; this data can be generated by social
    networking sites, equipment, and more. This can be streaming data that is heterogeneous
    in nature (for example, videos, emails, tweets, and so on). Again, none of the
    traditional data marts / data stores and data mining applications support these
    formats today.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在此背景下提到的数据格式是独特的；它们被生成和消费，不需要结构化（例如，DBMS 和关系型数据存储）。现在，有新的数据来源；这些数据可以由社交网站、设备等生成。这可以是异构的流数据（例如，视频、电子邮件、推文等）。再次强调，今天没有任何传统的数据集市/数据存储和数据挖掘应用支持这些格式。
- en: Additionally, all the large-scale processing always happened in batches, but
    we are now seeing the need to support *real-time* processing capabilities. The
    new **Lambda Architectures** (**LA**) address the need to support both batch and
    real-time data ingestion and processing.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，所有大规模处理总是批量进行的，但现在我们看到需要支持**实时**处理能力。新的**Lambda 架构**（**LA**）解决了支持批量数据和实时数据摄取及处理的需求。
- en: Overall, the response time windows are shrinking and this adds to the challenge.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总体而言，响应时间窗口正在缩小，这增加了挑战。
- en: 'Let''s recap the four key characteristics of big data. All of these need special
    tools, frameworks, infrastructure, and capabilities:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下大数据的四个关键特征。所有这些都需要特殊的工具、框架、基础设施和能力：
- en: Higher volumes (to the degree of petabytes )
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的数据量（达到PB级别）
- en: The need for availability/accessibility of data (more real-time)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的可用性/可访问性需求（更实时）
- en: Diversified data formats
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多样化的数据格式
- en: The increase in unlabeled data, and thus the **Noise**![Big data and the context
    of large-scale Machine learning](img/B03980_02_01.jpg)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未标记数据的增加，因此产生了**噪声**![大数据和大规模机器学习的背景](img/B03980_02_01.jpg)
- en: Functional versus Structural – A methodological mismatch
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 功能性 vs 结构性 – 方法论上的不匹配
- en: We could never have imagined even five years ago that Relational Databases or
    non-relational databases like object databases will become only a single kind
    of database technology, and not the database technology in itself. Internet-scale
    data processing has changed the way we process data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至无法想象五年前，关系型数据库或非关系型数据库如对象数据库将只成为单一类型的数据库技术，而不是数据库技术本身。互联网规模的数据处理改变了我们处理数据的方式。
- en: The new generation architectures, such as Facebook, Wikipedia, Salesforce, and
    more, are founded on principles and paradigms, which are radically different from
    the well-established theoretical foundations on which the current data management
    technologies are developed.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 新一代架构，如Facebook、Wikipedia、Salesforce等，建立在原则和范式上，这些原则和范式与当前数据管理技术发展的稳固理论基础截然不同。
- en: Commoditizing information
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 商品化信息
- en: The Apple App Store, SaaS, Ubiquitous Computing, Mobility, Cloud-Based Multi-Tenant
    architectures have unleashed, in business terms, an ability to commoditize information
    delivery. This model changes almost all the architecture decision making—as we
    now need to think in terms of what is the "units of information" that can be offered
    and billed as services, instead of thinking in terms of the **Total Cost of Ownership**
    (**TCO**) of the solution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果应用商店、SaaS、普适计算、移动性、基于云的多租户架构在商业层面上释放了商品化信息传递的能力。这种模式几乎改变了所有的架构决策——我们现在需要从“可以提供并作为服务计费的信息单元”的角度来思考，而不是从解决方案的**总拥有成本**（**TCO**）的角度来思考。
- en: Theoretical limitations of RDBMS
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RDBMS 的理论局限性
- en: As Michael Stonebreaker, the influential database theorist, has been writing
    in recent times, at the heart of the Internet-Scale Architectures is a new theoretical
    model of data processing and management. The theories of database management are
    now more than three decades old, and they were designed for mainframe-type computing
    environments and unreliable electronic components. Nature and the capabilities
    of systems and applications have since evolved significantly. With reliability
    becoming a quality attribute of the underlying environment, systems are composed
    of parallel processing cores, and the nature of data creation and usage has undergone
    tremendous change. In order to conceptualize solutions for these new environments,
    we need to approach the designing of solution architectures from a computing perspective
    and not only from an engineering perspective.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如有影响力的数据库理论家迈克尔·斯坦纳布雷克最近所写，互联网规模架构的核心是一个新的数据处理和管理理论模型。数据库管理的理论现在已有三十多年历史，它们是为大型机类型的计算环境和不可靠的电子组件设计的。自然和系统及应用的特性自那时起已经发生了显著变化。随着可靠性成为底层环境的质量属性，系统由并行处理核心组成，数据创建和使用的性质也经历了巨大的变化。为了概念化这些新环境下的解决方案，我们需要从计算的角度来设计解决方案架构，而不仅仅是工程角度。
- en: 'Six major forces that are driving the data revolution today are:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当前推动数据革命六大主要力量是：
- en: Massive Parallel Processing
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模并行处理
- en: Commoditized Information Delivery
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用信息传递
- en: Ubiquitous Computing and Mobile Devices
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普遍计算和移动设备
- en: Non-RDBMS and Semantic Databases
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非关系型数据库和语义数据库
- en: Community Computing
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社区计算
- en: Cloud Computing
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云计算
- en: '**Hadoop** and **MapReduce** have unleashed massive parallel processing of
    data on a colossal scale, and have made the complex computing algorithms in a
    programmatic platform. This has changed analytics and Business Intelligence forever.
    Similarly, the web services and API-driven architectures have made information
    delivery commoditized on an enormous scale.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hadoop** 和 **MapReduce** 在巨规模上释放了数据的并行处理能力，并将程序平台中的复杂计算算法化。这永远地改变了分析和商业智能。同样，基于Web服务和API驱动的架构使信息传递在巨大规模上实现了通用化。'
- en: Today, it is possible to build very large systems in such a way that each subsystem
    or component is a complete platform in itself, hosted and managed by a different
    entity altogether.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以以这种方式构建非常大的系统，即每个子系统或组件本身就是一个完整的平台，由完全不同的实体托管和管理。
- en: 'Dijkstra once made an insightful remark that:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 迪杰斯特拉曾有过一个深刻的见解：
- en: '*"Computer Science is no more about computers than astronomy is about telescopes"*'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"计算机科学并不比天文学需要望远镜更多，天文学并不比望远镜需要天文学"*'
- en: He would perhaps be a happy man today, as computing has liberated itself from
    the clutches of a personal computer, also known as workstations and servers. Most
    of our information consumption today is from the devices that we hardly call computers.
    Mobile devices, wearable devices, and information everywhere are changing the
    way data is created, assembled, consumed, and analyzed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 他今天可能会感到高兴，因为计算已经摆脱了个人计算机（也称为工作站和服务器）的束缚。我们今天的大部分信息消费都来自我们几乎不称之为计算机的设备。移动设备、可穿戴设备和无处不在的信息正在改变数据创建、组装、消费和分析的方式。
- en: As the limitations of the traditional databases have been exposed, in recent
    years, many special purpose databases have emerged—in-memory, columnar, graph-DB,
    and semantic stores are all now commercially available.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 随着传统数据库局限性的暴露，近年来，许多专用数据库应运而生——内存数据库、列式数据库、图数据库和语义存储现在都可在商业上获得。
- en: The previously mentioned innovations have changed the traditional data architecture
    completely. Especially, the semantic computing, ontology-driven modelling of information
    has turned data design over its head. Philosophically, data architecture is going
    through an factual underpinning. In the traditional data models, we first design
    the "data model"—a fixed, design time understanding of the world and its future.
    A data model fixes the meaning of data forever into a fixed structure. A table
    is nothing but a category, a set of something. As a result, data has to mean if
    we understand the set/category to which it belongs. For example, if we design
    an automobile processing system into some categories, such as four-wheelers, two-wheelers,
    commercial vehicles, and so on, then this division itself has a relevant meaning
    embedded into it. The data that is stored in each of these categories does not
    reveal the purpose of the design that is embedded in the way the categories are
    designed. For example, another system might view the world of automobiles regarding
    of its drivetrain—electric, petroleum powered, nuclear powered, and so on.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的创新完全改变了传统的数据架构。特别是，语义计算、基于本体论的信息建模彻底颠覆了数据设计。从哲学上讲，数据架构正在经历事实基础的转变。在传统的数据模型中，我们首先设计“数据模型”——这是对世界及其未来的固定、设计时理解。数据模型将数据的含义永久固定在固定的结构中。表不过是一个类别，一组事物。因此，数据必须意味着如果我们理解它所属的集合/类别。例如，如果我们把汽车处理系统设计成一些类别，如四轮车、两轮车、商用车辆等，那么这种划分本身就嵌入了一个相关的意义。存储在每个这些类别中的数据并没有揭示嵌入在类别设计方式中的设计目的。例如，另一个系统可能会从驱动方式——电动、石油驱动、核驱动等——的角度看待汽车世界。
- en: This categorization itself reveals the purpose of the system in some manner,
    which is impossible to obtain the attributes of any single record. Semantic and
    Metadata-Driven architectures can turn such a data model over its head. In a metadata
    model, it is the object that exists first.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分类本身以某种方式揭示了系统的目的，这是无法从任何单个记录的属性中获得的。语义和元数据驱动架构可以彻底颠覆这样的数据模型。在元数据模型中，首先存在的是对象。
- en: 'Some of the core characteristics of how data is stored and managed in an RDBMS-based
    storage system are as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于关系型数据库管理系统（RDBMS）的存储系统中，数据存储和管理的一些核心特性如下：
- en: Data is stored in a table that is typically characterized by rows and columns
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储在通常由行和列特征化的表中
- en: Tables are linked using relationships between data attributes
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表通过数据属性之间的关系相互链接
- en: It is known for efficiency and flexibility
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以其效率和灵活性而闻名
- en: This supports normalization techniques that reduce data duplication
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这支持了减少数据重复的规范化技术
- en: 'On the other hand:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面：
- en: The metadata driven / NoSQL / Semantic data architectures are free from relationships
    that tie down the purpose of the usage of data
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据驱动/NoSQL/语义数据架构不受限制数据使用目的的关系束缚
- en: The focus is more on accommodating constant changes in business requirements
    that results in least changes in the software system being built
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重点是更多地适应业务需求的持续变化，这导致构建的软件系统变化最小
- en: Support for large datasets with distributed storage techniques, with lowered
    storage costs is of great importance in the metadata driven / NoSQL /semantic
    data architecture
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持使用分布式存储技术处理大型数据集，降低存储成本在元数据驱动/NoSQL/语义数据架构中非常重要
- en: Scaling-up versus Scaling-out storage
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩容与扩展存储
- en: 'With the advent of big data, there is now a need to scale data storage equipment
    to be able to store the petabyte-scale data. There are two ways of scaling storage
    equipment:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大数据时代的到来，现在需要扩展数据存储设备以存储达到拍字节级的数据。扩展存储设备有两种方式：
- en: Scaling-up (vertical scalability)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩容（垂直可扩展性）
- en: Scaling-out (horizontal scalability)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展（水平可扩展性）
- en: '**Scaling up** or vertical scalability is about adding more resources to the
    existing system that in turn increases the ability to hold more data. Here, resources
    can mean RAM, computation power, hard drive, and more.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**扩容**或垂直可扩展性是指向现有系统添加更多资源，从而增加存储更多数据的能力。在这里，资源可以指RAM、计算能力、硬盘驱动器等。'
- en: '**Scaling out** or horizontal scalability is about adding new components to
    the system. This requires the data to be stored and distributed, and there are
    tasks that can be parallelized. This usually adds complexity to the system, and
    most of the time requires a redesign of the system.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**向外扩展**或水平可扩展性是指向系统中添加新组件。这需要数据被存储和分发，并且存在可以并行化的任务。这通常会增加系统的复杂性，并且大多数情况下需要重新设计系统。'
- en: All the big data technologies work on and support the scaling out of the infrastructure.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的大数据技术都在基础设施的向外扩展上工作并支持。
- en: '![Scaling-up versus Scaling-out storage](img/B03980_02_02.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![向上扩展与向外扩展的存储](img/B03980_02_02.jpg)'
- en: '| Scaling up (Vertical Scalability) | Scaling out (Horizontal Scalability)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 向上扩展（垂直可扩展性） | 向外扩展（水平可扩展性） |'
- en: '| --- | --- |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Lesser and high capacity server | More and moderate, or low capacity server
    |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 较低容量和容量较高的服务器 | 更多和适中的，或低容量服务器 |'
- en: '| There could be a threshold beyond which an infrastructure can cease to scale
    vertically | There is no limit, the infrastructure can be scaled on a need basis
    without any impact on the design |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 可能存在一个阈值，超过这个阈值，基础设施将无法垂直扩展 | 没有上限，基础设施可以根据需要扩展，而不会对设计产生影响 |'
- en: '| Can accommodate larger VMs | Runs with lower VMs and can be affected by failure
    in the host |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 可以容纳更大的虚拟机 | 使用较低的虚拟机，并且可能受到主机故障的影响 |'
- en: '| Shared everything data architecture | Shared nothing data architecture |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 所有共享的数据架构 | 无共享数据架构 |'
- en: '| Higher TCO | Relatively lower and variable costs |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 较高总拥有成本 | 相对较低且可变成本 |'
- en: '| Lower network equipment | Needs relatively larger number of equipments (routers,
    switches, and more…) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 较低的网络设备 | 需要相对较多的设备（路由器、交换机等） |'
- en: Distributed and parallel computing strategies
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式和并行计算策略
- en: Though distributed and parallel processing have been around for several years
    now, but with the advent of usability priorities needed for cost-effective solutions,
    these strategies have become critical for the Machine learning tasks.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分布式和并行处理已经存在多年，但随着对成本效益解决方案所需可用性优先级的出现，这些策略已成为机器学习任务的关键。
- en: The following diagram depicts Flynn's taxonomy for computing. The categorization
    is done based on the number of data streams versus the number of instruction streams.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图解展示了弗林分类法。分类是基于数据流数量与指令流数量的比较。
- en: '![Distributed and parallel computing strategies](img/B03980_02_03.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![分布式和并行计算策略](img/B03980_02_03.jpg)'
- en: '**Single Instruction Single Data** (**SISD**): This is a case of a single processor
    with no parallelism in data or instruction. A single instruction is executed on
    a single data in a sequential manner, for example, a uniprocessor.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单指令单数据**（**SISD**）：这是一个没有数据或指令并行的单个处理器的例子。单个指令以顺序方式在单个数据上执行，例如，单处理器。'
- en: '**Multiple Instruction Single Data** (**MISD**): Here, multiple instructions
    operate on a single data stream; a typical example can be fault tolerance.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多指令单数据**（**MISD**）：在这里，多个指令在一个数据流上操作；一个典型的例子可以是容错性。'
- en: '**Single Instruction Multiple Data** (**SIMD**): This is a case of natural
    parallelism; a single instruction triggers operation on multiple data streams.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单指令多数据**（**SIMD**）：这是一个自然并行的例子；单个指令触发对多个数据流的操作。'
- en: '**Multiple Instructions Multiple Data** (**MIMD**): This is a case where multiple
    independent instructions operate on multiple and independent data streams. Since
    the data streams are multiple, the memory can either be shared or distributed.
    Distributed processing can be categorized here. The previous figure depicts MIMD
    and a variation in a "distributed" context.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多指令多数据**（**MIMD**）：这是一个多个独立指令在多个独立数据流上操作的例子。由于数据流是多个的，内存可以是共享的或分布式的。分布式处理可以归类在这里。前面的图示描绘了MIMD及其在“分布式”环境中的变化。'
- en: 'The following diagram explains parallel processor architectures and categorization:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图解解释了并行处理器架构和分类：
- en: '![Distributed and parallel computing strategies](img/B03980_02_04.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![分布式和并行计算策略](img/B03980_02_04.jpg)'
- en: 'One of the critical requirements of parallel/distributed processing systems
    is High Availability and fault tolerance. There are several programming paradigms
    to implement parallelism. The following list details the important ones:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 并行/分布式处理系统的关键需求之一是高可用性和容错性。有几种编程范式可以实现并行性。以下列表详细说明了重要的几个：
- en: '**The Master/Workers Model**: Master model is the driver where the work is
    held and then disseminated to the workers. Pivotal Greenplum Database and HD (Pivotal''s
    Hadoop''s distribution) modules implement this pattern.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主/从模型**：主模型是工作保持和随后分发给从属者的驱动器。Pivotal Greenplum 数据库和 HD（Pivotal 的 Hadoop
    发行版）模块实现了这种模式。'
- en: '**The Producer/Consumer Model**: Here, there is no owner who triggers the work.
    Producer generates work items and consumer subscribes and executes asynchronously.
    The **Enterprise Service Bus** (**ESB**) based data integration systems implement
    this pattern.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产者/消费者模型**：在这里，没有所有者来触发工作。生产者生成工作项，消费者订阅并异步执行。基于**企业服务总线**（**ESB**）的数据集成系统实现了这种模式。'
- en: '![Distributed and parallel computing strategies](img/B03980_02_05.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![分布式和并行计算策略](img/B03980_02_05.jpg)'
- en: 'In theory, there are two types of parallelization; one is data parallelization,
    the other one is execution or task parallelization:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，有两种类型的并行化；一种是数据并行化，另一种是执行或任务并行化：
- en: '**Data parallelization**: It deals with running the same computations with
    multiple inputs in parallel. In the Machine learning world, this is a case where
    we consider running the same algorithm across different data samples without really
    worrying about how the data samples are distributed.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据并行化**：它涉及并行运行具有多个输入的相同计算。在机器学习领域，这是一个我们考虑在不同数据样本上运行相同算法，而不真正关心数据样本如何分布的情况。'
- en: '**Execution or Task parallelization**: Unlike data parallelization, this is
    about breaking the functionality into multiple pieces and running them in a parallel
    manner. These pieces of work may work on the same dataset, but this is possible
    only for the tasks that can be parallelized and have no dependencies between the
    sub tasks.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行或任务并行化**：与数据并行化不同，这是将功能分解成多个部分并以并行方式运行。这些工作部分可能处理相同的数据集，但这仅适用于可以并行化且子任务之间没有依赖关系的任务。'
- en: Task parallelization can be fine grained or coarse grained.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 任务并行化可以是细粒度或粗粒度。
- en: 'There are many distributed platform options to bring efficiency and scale to
    Machine learning algorithms and can process large datasets. Some of the options
    include:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多分布式平台选项可以将效率扩展到机器学习算法并处理大数据集。一些选项包括：
- en: '**Field-Programmable Gate Arrays** (**FPGAs**)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**现场可编程门阵列**（**FPGA**）'
- en: '**Graphics Processing Units** (**GPUs**)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形处理单元**（**GPU**）'
- en: '**High-Performance Computing** (**HPC**)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高性能计算**（**HPC**）'
- en: Multicore and multi-processor parallel systems
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多核和多处理器并行系统
- en: Cloud Infrastructures for virtual-large scale clusters
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为虚拟大规模集群的云基础设施
- en: Besides the multiple platform options available, there are other highly adopted
    frameworks available that have out-of-box APIs for building Machine learning algorithms.
    The choice of this framework depends on the choice of hardware in particular.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可用的多个平台选项外，还有其他广泛采用的框架，它们提供了构建机器学习算法的即插即用 API。这个框架的选择特别取决于硬件的选择。
- en: It is important that we take an option that can take maximum advantage of the
    existing architecture, and suits the choice of learning algorithm and the data
    structure.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是我们要选择一个能够充分利用现有架构、适合学习算法和数据结构选择的选项。
- en: 'Machine learning: Scalability and Performance'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习：可扩展性和性能
- en: 'There are two important ways in which Machine learning algorithms can be scaled:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法可以通过两种重要方式扩展：
- en: Sampling
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采样
- en: Distributed systems with parallel processing
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于并行处理的分布式系统
- en: It is possible to concurrently execute a given learning algorithm as separate
    chunks of work and consolidate the results. This sounds like a fairly simple way
    of parallelizing and being able to scale and perform well on a bigger dataset.
    This comes with an assumption that the datasets are discrete and there isn't any
    dependency between these distributed sets of data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 可以并发执行给定的学习算法作为单独的工作块，并合并结果。这听起来像是一种相当简单的并行化方式，能够在更大的数据集上实现扩展和良好的性能。这假设数据集是离散的，并且这些分布式数据集之间没有依赖关系。
- en: By the virtue of the proliferation of data sources, we now have access to large
    sets that are already distributed, and this brings in a need for the ability to
    have the learning algorithms running in a distributed mode.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据源的激增，我们现在可以访问已经分布的大型数据集，这需要我们具备在分布式模式下运行学习算法的能力。
- en: 'There are now a variety of options for distributed and parallel framework for
    Machine learning. Let''s look at some key differentiating factors between these
    platforms:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有许多用于机器学习的分布式和并行框架的选项。让我们看看这些平台之间的一些关键区别因素：
- en: The degree of granularity in parallelization is a critical aspect. Support for
    fine-grained versus coarse-grained parallelization is what it refers to. A lower
    degree of granularity defines a fine-grained task parallelization, while a higher
    level of granularity defines coarse-grained task parallelization.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行化的粒度程度是一个关键方面。支持细粒度与粗粒度并行化是指什么。较低的粒度定义了细粒度任务并行化，而较高的粒度定义了粗粒度任务并行化。
- en: The degree to which algorithm customization is supported.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法定制支持的程度。
- en: Support for mixing a variety of programming paradigms.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持混合各种编程范式。
- en: The ease with which datasets can be scaled-out.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集扩展的容易程度。
- en: The degree to which batch and real-time processing is supported.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持批处理和实时处理的程度。
- en: Given a problem context, the choice of the platform and programming framework
    should be guided by the previous criteria.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的问题背景下，平台和编程框架的选择应受先前标准的指导。
- en: 'Following are some key metrics to measure the computational performance of
    parallel algorithms:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关键指标，用于衡量并行算法的计算性能：
- en: '**Performance** is the ratio of solution time for the sequential algorithms
    versus parallel process'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**是顺序算法与并行处理之间的解决方案时间的比率'
- en: '**Efficiency** or **Throughput** measures the ratio of performance across multiple
    processors'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**或**吞吐量**衡量的是多个处理器之间性能的比率'
- en: '**Scalability** is the percentage improvement in efficiency with the growing
    number of processors'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**是随着处理器数量的增加，效率提高的百分比'
- en: The next section covers some key characteristics of the Machine learning problem
    that motivate scaling-up the Machine learning algorithms.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将介绍机器学习问题的一些关键特性，这些特性促使我们扩展机器学习算法。
- en: Too many data points or instances
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据点或实例过多
- en: We now see that in most of the Machine learning problems, there is an abundance
    of datasets and in many cases, all these data points are relevant in model building
    and refining. These data points can potentially run into terabyte scale with all
    their relevance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在看到，在大多数机器学习问题中，数据集非常丰富，在许多情况下，所有这些数据点在模型构建和细化中都是相关的。这些数据点可能达到太字节规模，并且具有所有相关性。
- en: This brings in a need to support distributed storage and a bandwidth to process
    these data points in the cluster. High-capacity storage systems with the ability
    to run parallel programming language paradigms like MapReduce and LINQ are used
    here.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了支持分布式存储和集群中处理这些数据点的带宽的需求。这里使用的是具有运行并行编程语言范式（如MapReduce和LINQ）能力的高容量存储系统。
- en: Too many attributes or features
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 属性或特征过多
- en: The datasets that form an input to a building model can come with too many features,
    attributes, or dimensions. In this case, the Machine learning algorithms group
    the dependent or more relevant attributes and run the algorithms in iteration.
    These kind of datasets can be seen in case of Text mining and **Natural language
    processing** (**NLP**), where the number of features can run into multiples of
    millions. In this case, parallelizing the computation across features can get
    us to solve the problem effectively by the way of eliminating irrelevant features.
    Random forest and Decision trees are some of the examples. Also, some specific
    feature selection techniques such as the regularization methods will be covered
    in the chapters to come.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 构成构建模型输入的数据集可能包含过多的特征、属性或维度。在这种情况下，机器学习算法将相关或更相关的属性分组，并在迭代中运行算法。这类数据集在文本挖掘和**自然语言处理**（**NLP**）的情况下可以见到，其中特征的数量可能达到数百万的倍数。在这种情况下，通过消除无关特征的方式并行化跨特征的计算可以有效地解决问题。随机森林和决策树是一些例子。此外，一些特定的特征选择技术，如正则化方法，将在后续章节中介绍。
- en: Shrinking response time windows – need for real-time responses
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缩小响应时间窗口 - 需要实时响应
- en: There are certain Machine learning requirements such as speech recognition that
    will demand a real-time response from the systems. In these applications, response
    time from a Machine learning implementation is critical, and the response itself
    will become irrelevant otherwise. Parallelization can bring in this efficiency.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 某些机器学习需求，如语音识别，将要求系统提供实时响应。在这些应用中，机器学习实现的响应时间至关重要，否则响应本身将变得无关紧要。并行化可以带来这种效率。
- en: Latency and performance of the model are more important a problem to deal with
    than the throughput. There are many use cases where this latency in inference
    can invalidate the model itself, as the response becomes obsolete.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的延迟和性能问题比吞吐量问题更重要。在许多用例中，这种推理延迟可能会使模型本身失效，因为响应变得过时。
- en: For these kinds of problems, highly parallelized hardware architectures such
    as GPUs or FPGAs will be very effective.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这类问题，高度并行化的硬件架构，如GPU或FPGA，将非常有效。
- en: Highly complex algorithm
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高度复杂的算法
- en: This is a case where the algorithm of choice itself is complex, for example,
    a computational intensive function or any non-linear models. Let's take an example
    of a text or image content; it is inherently non-linear in nature. This complexity
    can easily be addressed using distributed computing.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个选择算法本身就很复杂的情况，例如，计算密集型函数或任何非线性模型。以文本或图像内容为例；它本质上是非线性的。这种复杂性可以通过分布式计算轻松解决。
- en: There are many ways we can solve these problems and one way is to prioritize
    features and still target for higher accuracies. However this will remove the
    automation part in the learning. There always needs to be a step that engineers
    the features before running the algorithm.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有多种方法可以解决这个问题，其中一种方法是优先考虑特征，并仍然追求更高的准确性。然而，这将消除学习中的自动化部分。在运行算法之前，总需要有一个工程师特征的过程。
- en: The cases where there is more data complexity, there is a computational complexity.
    Unless the platform is scaled, there is no way to get the learning process run
    faster.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据复杂性更高的情况下，存在计算复杂性。除非平台进行扩展，否则没有方法可以使学习过程运行得更快。
- en: Multicore and GPU systems are apt for this kind of requirement. They bring in
    both; storage scale and computational efficiency.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 多核和GPU系统非常适合这种需求。它们带来了存储规模和计算效率的双重优势。
- en: Feed forward, iterative prediction cycles
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前馈，迭代预测周期
- en: There are some unique use cases in the Machine learning space that do not stop
    at one level of execution of the algorithm. The algorithm runs iteratively and
    sequentially where the output from an iteration feeds into another iteration.
    This is critical for the outcome of the model. There can also be a need to consolidate
    the inferences across all the iterations that are run sequentially. This can make
    the model execution process quite complex. We can deal with inference process
    as a one-shot process, which will bring up the computational costs, or there can
    be stages of parallelization of individual tasks.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域有一些独特的用例，它们不会停止在算法执行的一个级别。算法是迭代和顺序运行的，其中一次迭代的输出会输入到另一个迭代中。这对于模型的输出至关重要。还可能需要合并所有顺序运行的迭代的推断。这可以使模型执行过程相当复杂。我们可以将推断过程视为一次性的过程，这将增加计算成本，或者可以有单个任务的并行化阶段。
- en: 'Some real-world examples are:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一些现实世界的例子包括：
- en: Speech recognition
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别
- en: Machine translation
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器翻译
- en: Model selection process
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型选择过程
- en: In some cases, we will need to run multiple models in parameters on the same
    training and test sets with the different priority of features, and compare the
    accuracy to choose an appropriate model for the given problem domain. These trials
    can run in parallel as there will not be any dependencies between these models.
    The complexity increases when we will have to tune the parameters of learning
    algorithms and evaluate across multiple executions to infer from the learning.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们需要在相同的训练和测试集上运行多个模型，这些模型的特征优先级不同，并比较准确性以选择给定问题域的适当模型。这些试验可以并行运行，因为这些模型之间没有任何依赖关系。当我们必须调整学习算法的参数并在多次执行中进行评估以从学习中进行推断时，复杂性会增加。
- en: The very fact that there is no dependency between the executions makes it highly
    parallelizable and requires no intercommunication. One of the examples of this
    use case is statistical significance testing. The usefulness of the parallel platforms
    is obvious for these tasks, as they can be easily performed concurrently without
    the need to parallelize actual learning and inference algorithms.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 由于执行之间没有依赖关系，这使得它高度可并行化，并且不需要交互通信。这个用例的一个例子是统计显著性测试。对于这些任务，并行平台的有用性很明显，因为它们可以很容易地并发执行，而无需并行化实际的学习和推理算法。
- en: Potential issues in large-scale Machine learning
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大规模机器学习中的潜在问题
- en: 'Let''s now look at some potential issues encountered in the large-scale Machine
    learning implementations:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在大规模机器学习实现中可能遇到的一些潜在问题：
- en: '**Parallel execution**: Managing the accuracy of the parallel execution requires
    special care and a different design paradigm.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行执行**：管理并行执行的准确性需要特别的关注和不同的设计范式。'
- en: '**Load balancing** and **managing skews**: With data and execution now distributed
    and running parallel, it is very imperative to manage the data and compute skews.
    No single node will need to take relatively more data storage or computations.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡**和**管理偏差**：随着数据和执行现在分布并行运行，管理数据和计算偏差变得非常迫切。不需要任何单个节点承担相对更多的数据存储或计算。'
- en: '**Monitoring**: With a variety of hardware, effective monitoring and automatic
    recovery systems need to be placed.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：需要放置各种硬件的有效监控和自动恢复系统。'
- en: '**Fault tolerance**: A foolproof failover and recovery system is a mandate.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**：一个万无一失的故障转移和恢复系统是强制性的。'
- en: '**Auto scaling**: The scaling out and scaling up process is automatic.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动扩展**：扩展和升级过程是自动的。'
- en: '**Job scheduling**: *Batch* jobs will need to be scheduled.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作业调度**：需要安排*批处理*作业。'
- en: '**Workflow Management**: Choreography and Orchestration process to coordinate
    and monitor work execution among the nodes of the cluster.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流管理**：协调和监控集群节点间工作执行的过程编排和编排。'
- en: Algorithms and Concurrency
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法和并发
- en: Let's now look at some basics of algorithms in general, the time complexity;
    and the order of magnitude measurements, before we start talking about building
    concurrency in executing algorithms, then explore the approaches to parallelizing
    algorithms.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始讨论在执行算法中构建并发性之前，让我们先看看算法的一些基础知识，时间复杂度；以及量级测量，然后探索并行化算法的方法。
- en: 'An algorithm can be defined as a sequence of steps that takes an input to produce
    the desired output. They are agnostic technology representations; let''s look
    at a sorting algorithm example:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一个算法可以被定义为一系列步骤，它将输入转换为所需的输出。它们是无关技术表示；让我们看看一个排序算法的例子：
- en: '[PRE0]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following algorithm is an insertion-sort algorithm:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个插入排序算法：
- en: '[PRE1]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For measuring the time and space complexity of algorithms, one of the elements
    is the input size. The time complexity is a measure of how "fast enough" the algorithm
    is for the defined needs; more importantly, how the algorithm would react when
    the volume of the data is increased.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测量算法的时间和空间复杂度，一个元素是输入大小。时间复杂度是算法对于定义的需求“足够快”的度量；更重要的是，当数据量增加时，算法将如何反应。
- en: 'Frequency count is one of the key measures for an algorithm. It is a prediction
    of how many times each instruction of the algorithm will run for an execution.
    For example:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 频率计数是算法的一个关键度量。它是对算法的每个指令在执行过程中将运行多少次的预测。例如：
- en: '| Instruction | Code | Frequency count (FC) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 指令 | 代码 | 频率计数 (FC) |'
- en: '| --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 1 |'
- en: '[PRE2]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '| n+1 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| n+1 |'
- en: '| 2 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 2 |'
- en: '[PRE3]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '| N |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| N |'
- en: '| 3 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 3 |'
- en: '[PRE4]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '| N |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| N |'
- en: '| 4 |   | 3n +1 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 4 |   | 3n +1 |'
- en: The FC measure is relatively meaningless unless it considers the relative performance
    to volume. There is another measure called "order of magnitude" that is an estimate
    of performance versus data volume. The *Big-O* is a measure of the rate at which
    the algorithm performance degrades as the function of the amount of data that
    it requires to process.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: FC度量在未考虑相对性能与体积的关系时相对没有意义。还有一个叫做“量级”的度量，它是性能与数据体积的估计。*Big-O*是算法性能随所需处理的数据量增加而下降的速率的度量。
- en: For example, *O(n)* represents linear performance degradation and *O(n2)* represents
    quadratic performance degradation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*O(n)*代表线性性能下降，而*O(n^2)*代表二次性能下降。
- en: Developing concurrent algorithms
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发并发算法
- en: 'The first step in developing a parallel algorithm is to decompose the problem
    into tasks that can be executed concurrently. A given problem may be decomposed
    into tasks in many different ways. Tasks may be of same or different sizes:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 开发并行算法的第一步是将问题分解为可以并发执行的任务。给定的问题可以以多种不同的方式分解为任务。任务可以是相同或不同的大小：
- en: Task dependency graph is a directed graph with nodes corresponding to tasks
    and edges indicating that the result of one task is required for processing the
    next task.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 任务依赖图是一个有向图，节点对应任务，边表示一个任务的结果是处理下一个任务所必需的。
- en: 'Example: This is the database query processing.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：这是数据库查询处理。
- en: 'Consider the following execution of the query:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下查询的执行：
- en: '[PRE5]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'on the following database:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下数据库上：
- en: '![Developing concurrent algorithms](img/B03980_02_06.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![开发并发算法](img/B03980_02_06.jpg)'
- en: There can be fine-grained and coarse-grained task decomposition. The degree
    of concurrency increases as the decomposition becomes finer.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 可以有细粒度和粗粒度任务分解。随着分解变得更加精细，并发度增加。
- en: 'There are many decomposition techniques and there is no single best way of
    doing it. Following are some techniques:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多分解技术，并没有一种单一的最好方法。以下是一些技术：
- en: Recursive decomposition
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归分解
- en: Data decomposition
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分解
- en: Exploratory decomposition
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性分解
- en: Speculative decomposition
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 投射性分解
- en: Decomposition results in several tasks and some characteristics of these tasks
    critically affect the performance of the parallel algorithms. Some of these features
    are task interactions (inter-task communication), the size of data that each task
    handles, and the task size. Some important aspects that need to be kept in mind
    while designing parallel execution algorithms include decoupling tasks in such
    a way that there is minimal interaction and handling granularity trade-offs.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 分解会产生多个任务，这些任务的一些特性会严重影响并行算法的性能。这些特性包括任务交互（任务间通信）、每个任务处理的数据大小以及任务大小。在设计并行执行算法时需要考虑的一些重要方面包括以最小化交互和处理粒度权衡的方式解耦任务。
- en: Technology and implementation options for scaling-up Machine learning
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展机器学习的技术和实现选项
- en: In this section, we will explore some parallel programming techniques and distributed
    platform options that Machine learning implementations can adopt. The Hadoop platform
    will be introduced in the next chapter, and we will look into some practical examples
    starting from [Chapter 3](ch03.html "Chapter 3. An Introduction to Hadoop's Architecture
    and Ecosystem"), *An Introduction to Hadoop's Architecture and Ecosystem* with
    some real-world examples.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一些机器学习实现可以采用的并行编程技术和分布式平台选项。Hadoop 平台将在下一章介绍，我们将从[第 3 章](ch03.html
    "第 3 章。Hadoop 架构和生态系统的介绍")，*Hadoop 架构和生态系统的介绍*，以及一些实际例子开始探讨一些实际例子。
- en: MapReduce programming paradigm
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MapReduce 编程范式
- en: MapReduce is a parallel programming paradigm that abstracts the parallelizing
    computing and data complexities in a distributed computing environment. It works
    on the concept of taking the compute function to the data rather than taking the
    data to the compute function.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 是一种并行编程范式，它抽象了分布式计算环境中的并行计算和数据复杂性。它基于将计算函数带到数据而不是将数据带到计算函数的概念。
- en: MapReduce is more of a programming framework that comes with many built-in functions
    that the developer need not worry about building, and can alleviate many implementation
    complexities like data partitioning, scheduling, managing exceptions, and intersystem
    communications.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 更像是一个带有许多内置函数的编程框架，开发者无需担心构建，可以减轻许多实现复杂性，如数据分区、调度、异常管理和跨系统通信。
- en: 'The following figure depicts a typical composition of the MapReduce function:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 MapReduce 函数的典型组成：
- en: '![MapReduce programming paradigm](img/B03980_02_07.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![MapReduce 编程范式](img/B03980_02_07.jpg)'
- en: MapReduce was originally designed and adopted by Google as a programming model
    for processing large data sets on a cluster with parallel processing over distributed
    storage.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 最初由 Google 设计并采用，作为在具有并行处理分布式存储的集群上处理大型数据集的编程模型。
- en: The MapReduce paradigm now has become an industry standard and many platforms
    are internally built on this paradigm and support MapReduce implementation. For
    example, Hadoop is an open source implementation that can be run either in-house
    or on cloud computing services such as, **Amazon EC2** with elastic MapReduce.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 模式现在已经成为行业标准，许多平台都是基于这个模式内部构建的，并支持 MapReduce 实现。例如，Hadoop 是一个开源实现，可以在内部运行或在云计算服务上运行，例如，**Amazon
    EC2** 配备弹性 MapReduce。
- en: This has, at the core, the `Map()` and `Reduce()` functions that are capable
    of running in parallel across the nodes in the cluster. The `Map()` function works
    on the distributed data and runs the required functionality in parallel, and the
    `Reduce()` function runs a summary operation of the data.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这在核心上具有 `Map()` 和 `Reduce()` 函数，这些函数能够在集群的节点上并行运行。`Map()` 函数在分布式数据上工作，并行运行所需的功能，而
    `Reduce()` 函数运行数据的汇总操作。
- en: High Performance Computing (HPC) with Message Passing Interface (MPI)
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用消息传递接口（MPI）进行高性能计算（HPC）
- en: MPI is designed to provide access to advanced parallel hardware, and is meant
    to work with heterogeneous networks and clusters. It is an impressive specification
    and provides a portable way to implement the parallel programs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: MPI 被设计用来提供访问高级并行硬件的能力，旨在与异构网络和集群一起工作。这是一个令人印象深刻的规范，提供了一种可移植的方式来实现并行程序。
- en: 'Message passing is a process of data transfer and synchronization between the
    sender and the receiver. The following figure demonstrates the message passing
    between sender and receiver:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递是发送者和接收者之间数据传输和同步的过程。以下图展示了发送者和接收者之间的消息传递：
- en: '![High Performance Computing (HPC) with Message Passing Interface (MPI)](img/B03980_02_09.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![使用消息传递接口（MPI）进行高性能计算（HPC）](img/B03980_02_09.jpg)'
- en: The processes can be grouped; the message sharing between the sender and the
    receiver needs to happen in the same context. Communicator thus is a combination
    of a group and the context. The data in a message is sent or received as triples.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过程可以被分组；发送者和接收者之间的消息共享需要在相同上下文中发生。因此，通信者是一个组合了组和上下文的概念。消息中的数据以三元组的形式发送或接收。
- en: MPI can be used to achieve portability and can improve performance through parallel
    processing. It can support unique data structures, and libraries can be built
    for reuse. MPI does not support liberal fault tolerance.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: MPI 可以用于实现可移植性，并通过并行处理提高性能。它可以支持独特的数据结构，并且可以构建库以供重用。MPI 不支持宽松的错误容忍。
- en: Language Integrated Queries (LINQ) framework
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言集成查询（LINQ）框架
- en: The LINQ framework is a general-purpose system for large-scale data and parallel
    computing. Similar to the MapReduce paradigm, it comes with a high level of abstraction
    that comes with base implementations, and helps developers reduce the development
    complexities of the parallel and distributed execution.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: LINQ 框架是一个用于大规模数据和并行计算的一般用途系统。类似于 MapReduce 模式，它附带基础实现的高层次抽象，有助于开发者减少并行和分布式执行的开发复杂性。
- en: With the Machine learning functions moving out of general data handling and
    operating on diverse data types including documents, images, and graphs, the need
    for generic implementation paradigms is increasing. This framework pertains to
    the .NET languages only.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习函数从通用数据处理中移出，并在包括文档、图像和图在内的多种数据类型上操作，对通用实现模式的需求正在增加。此框架仅适用于 .NET 语言。
- en: Manipulating datasets with LINQ
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 LINQ 操作数据集
- en: LINQ is shipped with a set of functions that operate on collections of .NET
    objects. These collections are modified by the LINQ functions that contain the
    .NET datatypes.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: LINQ 随带一套在 .NET 对象集合上操作的功能。这些集合通过包含 .NET 数据类型的 LINQ 函数被修改。
- en: '![Manipulating datasets with LINQ](img/B03980_02_10.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![使用 LINQ 操作数据集](img/B03980_02_10.jpg)'
- en: Graphics Processing Unit (GPU)
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图形处理单元（GPU）
- en: GPUs are electronic circuits designed to handle the memory requirements and
    rapidly create images in the frame buffers for visual display.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 是设计用来处理内存需求并在帧缓冲区中快速创建用于视觉显示的图像的电子电路。
- en: GPUs have been consistently supporting growing computational capabilities. They
    were initially meant to handle image processing and rendering, but the advanced
    GPUs are now positioned as self-contained, general purpose computing platforms.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 一直支持不断增长的计算能力。它们最初是用来处理图像处理和渲染的，但先进的 GPU 现在被视为自包含的通用计算平台。
- en: While CPUs are designed to perform well on heterogeneous workloads, GPUs are
    built for tasks that are meant to ensure the availability of massive datasets
    and run in a parallel manner.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CPU旨在在异构工作负载上表现良好，但GPU是为确保大量数据集的可用性而构建的，并且以并行方式运行的任务。
- en: '![Graphics Processing Unit (GPU)](img/B03980_02_11.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图形处理单元（GPU）](img/B03980_02_11.jpg)'
- en: GPUs are mainly used in deep learning and training neural networks that can
    potentially need larger training datasets, lesser computational power, and storage
    space optimization. They are being employed in solving both classification and
    prediction problems in the cloud. Most of the social media companies have been
    in the list of early adopters for GPUs.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: GPU主要用于深度学习和训练可能需要更大训练数据集、较少计算能力和存储空间优化的神经网络。它们被用于解决云中的分类和预测问题。大多数社交媒体公司都曾是GPU的早期采用者。
- en: Note
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: With GPUs, pre-recorded speech or multimedia content can be transcribed much
    more quickly. Compared to a CPU implementation we are able to perform recognition
    up to 33x faster.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPU，预先录制的语音或多媒体内容可以转录得更快。与CPU实现相比，我们能够以高达33倍的速度进行识别。
- en: Field Programmable Gate Array (FPGA)
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场可编程门阵列（FPGA）
- en: FPGAs are emerging in many areas of HPC. FPGAs can be used in the context of
    massive parallel processing. In this section, we will look at understanding some
    of the architecture and implementation aspects of FPGA.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: FPGAs正在HPC（高性能计算）的许多领域崭露头角。FPGA可以在大规模并行处理的环境中应用。在本节中，我们将探讨理解FPGA的一些架构和实现方面的内容。
- en: FPGAs are known to provide high performance. They support different parallel
    computation applications. They have an on-chip memory to facilitate easy memory
    access to the processor. Above all, the memory is coupled to the algorithm logic
    and this means that we will not need any additional high-speed memory.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 已知FPGA提供高性能。它们支持不同的并行计算应用。它们具有片上内存，便于处理器轻松访问内存。最重要的是，内存与算法逻辑相耦合，这意味着我们不需要任何额外的快速内存。
- en: '![Field Programmable Gate Array (FPGA)](img/B03980_02_12.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![场可编程门阵列（FPGA）](img/B03980_02_12.jpg)'
- en: FPGA contains an enormous number of **Configurable Logical Blocks** (**CLB**);
    each of these CLBs are connected using programmable interfaces that pass signals
    among them. The I/O blocks are the connections points for CLBs to the outside
    world.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: FPGA包含大量的**可配置逻辑块**（**CLB**）；这些CLB通过可编程接口连接，传递它们之间的信号。I/O块是CLB与外部世界的连接点。
- en: FPGAs offer a variety of paradigms that help speed up computations in a hardware
    and software design. FPGAs are cost effective and the hardware resources are used
    in an optimal way. IBM Netezza leverages FPGA architecture.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: FPGAs提供各种范式，有助于加速硬件和软件设计中的计算。FPGA具有成本效益，并且硬件资源以最佳方式使用。IBM Netezza利用FPGA架构。
- en: Multicore or multiprocessor systems
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多核或多处理器系统
- en: Multiprocessor systems usually have multiple CPUs that need not necessarily
    be on the same chip. The new age multiprocessors are on the same physical board,
    and the communication happens via high-speed connection interfaces.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 多处理器系统通常具有多个CPU，这些CPU不一定在同一个芯片上。新一代的多处理器位于同一物理板上，通信通过高速连接接口进行。
- en: '![Multicore or multiprocessor systems](img/B03980_02_13.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![多核或多处理器系统](img/B03980_02_13.jpg)'
- en: Multicore processors represent a family of processors that may contain many
    CPUs on one chip (such as two, four, and eight. In case of multicore systems,
    the efficiency of the multi-threading implementation is determined by how well-parallel
    the code is written).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 多核处理器代表了一类处理器，可能在一个芯片上包含许多CPU（例如两个、四个和八个。在多核系统中，多线程实现的效率取决于代码的并行程度）。
- en: Further to all the hardware and infrastructure advancements, we have just seen
    that the cloud frameworks for Machine learning are picking up considerable traction
    based on their ability to scale Machine learning processes at an optimal cost.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有硬件和基础设施的进步之外，我们刚刚看到，基于其能够在最佳成本下扩展机器学习过程的能力，云框架在机器学习领域正获得相当大的关注。
- en: With the emergence of cloud computing, infrastructure service providers, such
    as Amazon Web Services, offer access to virtually unlimited computing power on
    demand that can be paid for, based on the usage.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 随着云计算的出现，基础设施服务提供商，如亚马逊网络服务（Amazon Web Services），提供基于使用情况付费的、几乎无限的按需计算能力。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter we have explored the qualifiers of large datasets, their common
    characteristics, the problems of repetition, and the reasons for the hyper-growth
    in volumes; in fact, the big data context.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了大数据集的限定条件、它们的共同特征、重复的问题以及数据量超高速增长的原因；实际上，这是大数据的背景。
- en: The need for applying conventional Machine learning algorithms to large datasets
    has given rise to new challenges for Machine learning practitioners. Traditional
    Machine learning libraries do not quite support, processing huge datasets. Parallelization
    using modern parallel computing frameworks, such as MapReduce, have gained popularity
    and adoption; this has resulted in the birth of new libraries that are built over
    these frameworks.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 将传统机器学习算法应用于大数据集的需要为机器学习从业者带来了新的挑战。传统的机器学习库并不完全支持处理大规模数据集。使用现代并行计算框架，如MapReduce，进行并行化已经变得流行并被广泛采用；这导致了基于这些框架的新库的诞生。
- en: The concentration was on methods that are suitable for massive data, and have
    potential for the parallel implementation. The landscape of Machine learning applications
    has changed dramatically in the last decade. Throwing more machines doesn't always
    prove to be a solution. There is a need to revisit traditional algorithms and
    models in the way they are being executed as now an another dimension in the study
    of Machine learning techniques is the scalability, parallel execution, load balancing,
    fault tolerance, and dynamic scheduling.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 重点关注适合大规模数据的方法，并且具有并行实施的潜力。在过去十年中，机器学习应用领域的格局发生了巨大变化。仅仅增加机器并不总是能证明是一个解决方案。需要重新审视传统算法和模型在执行方式上的问题，因为现在机器学习技术研究的另一个维度是可扩展性、并行执行、负载均衡、容错性和动态调度。
- en: We have also taken a look at the emerging parallelization and distribution architectures
    and frameworks in the context of large datasets, and understood the need for scaling
    up and scaling out Machine learning. Furthermore, we have recapped the internals
    of some parallel and distributed platform techniques for Machine learning such
    as MapReduce, GPUs, FGPA, and more.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了在大数据集背景下出现的并行化和分布式架构和框架，并理解了扩展机器学习的需求。此外，我们还回顾了一些并行和分布式平台技术，如MapReduce、GPU、FPGA等在机器学习中的应用。
- en: In the next chapter, we will look at how Hadoop is the best platform for large-scale
    Machine learning.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨Hadoop是如何成为大规模机器学习最佳平台的。
