<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Machine Learning Review"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Machine Learning Review</h1></div></div></div><p>Recent years have seen the revival of <span class="strong"><strong>artificial intelligence</strong></span> (<span class="strong"><strong>AI</strong></span>) and machine learning in particular, both in <a id="id0" class="indexterm"/>academic circles and the industry. In the last decade, AI has seen dramatic successes that eluded practitioners in the intervening years since the original promise of the field gave way to relative decline until its re-emergence in the last few years.</p><p>What made these successes possible, in large part, was the impetus provided by the need to process the prodigious amounts of ever-growing data, key algorithmic advances by dogged researchers in deep learning, and the inexorable increase in raw computational power driven by Moore's Law. Among the areas of AI leading the resurgence, machine learning has seen spectacular developments, and continues to find the widest applicability in an array of domains. The use of machine learning to help in complex decision making at the highest levels of business and, at the same time, its enormous success in improving the accuracy of what are now everyday applications, such as searches, speech recognition, and personal assistants on mobile phones, have made its effects commonplace in the family room and the board room alike. Articles breathlessly extolling the power of deep learning can be found today not only in the popular science and technology press but also in mainstream outlets such as <span class="emphasis"><em>The New York Times</em></span> and <span class="emphasis"><em>The Huffington Post</em></span>. Machine learning has indeed become ubiquitous in a relatively short time.</p><p>An <span class="emphasis"><em>ordinary</em></span> user encounters machine learning in many ways in their day-to-day activities. Most e-mail providers, including Yahoo and Gmail, give the user automated sorting and categorization of e-mails into headings such as Spam, Junk, Promotions, and so on, which is made possible using text mining, a branch of machine learning. When shopping online for products <a id="id1" class="indexterm"/>on e-commerce websites, such as <a class="ulink" href="https://www.amazon.com/">https://www.amazon.com/</a>, or watching movies from content providers, such as Netflix, one is offered recommendations for other products and content by so-called recommender systems, another branch of machine learning, as an effective way to retain customers.</p><p>Forecasting the weather, estimating real estate prices, predicting voter turnout, and even election results—all use some form of machine learning to see into the future, as it were.</p><p>The ever-growing availability of data and the promise of systems that can enrich our lives by learning from that data place a growing demand on the skills of the limited workforce of professionals in the field of data science. This demand is particularly acute for well-trained experts who know their way around the landscape of machine learning techniques in the more popular languages, such as Java, Python, R, and increasingly, Scala. Fortunately, thanks to the thousands of contributors in the open source community, each of these languages has a rich and rapidly growing set of libraries, frameworks, and tutorials that make state-of-the-art techniques accessible to anyone with an internet connection and a computer, for the most part. Java is an important vehicle for this spread of tools and technology, especially in large-scale machine learning projects, owing to its maturity and stability in enterprise-level deployments and the portable JVM platform, not to mention the legions of professional programmers who have adopted it over the years. Consequently, mastery of the skills so lacking in the workforce today will put any aspiring professional with a desire to enter the field at a distinct advantage in the marketplace.</p><p>Perhaps you already apply machine learning techniques in your professional work, or maybe you simply have a hobbyist's interest in the subject. If you're reading this, it's likely you can already bend Java to your will, no problem, but now you feel you're ready to dig deeper and learn how to use the best of breed open source ML Java frameworks in your next data science project. If that is indeed you, how fortuitous is it that the chapters in this book are designed to do all that and more!</p><p>Mastery of a subject, especially one that has such obvious applicability as machine learning, requires more than an understanding of its core concepts and familiarity with its mathematical underpinnings. Unlike an introductory treatment of the subject, a book that purports to help you master the subject must be heavily focused on practical aspects in addition to introducing more advanced topics that would have stretched the scope of the introductory material. To warm up before we embark on sharpening our skills, we will devote this chapter to a quick review of what we already know. For the ambitious novice with little or no prior exposure to the subject (who is nevertheless determined to get the fullest benefit from this book), here's our advice: make sure you do not skip the rest of this chapter; instead, use it as a springboard to explore unfamiliar concepts in more depth. Seek out external resources as necessary. Wikipedia them. Then jump right back in.</p><p>For the rest of this chapter, we will review the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">History and definitions</li><li class="listitem" style="list-style-type: disc">What is not machine learning?</li><li class="listitem" style="list-style-type: disc">Concepts and terminology</li><li class="listitem" style="list-style-type: disc">Important branches of machine learning</li><li class="listitem" style="list-style-type: disc">Different data types in machine learning</li><li class="listitem" style="list-style-type: disc">Applications of machine learning</li><li class="listitem" style="list-style-type: disc">Issues faced in machine learning</li><li class="listitem" style="list-style-type: disc">The meta-process used in most machine learning projects </li><li class="listitem" style="list-style-type: disc">Information on some well-known tools, APIs, and resources that we will employ in this book</li></ul></div><div class="section" title="Machine learning – history and definition"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec08"/>Machine learning – history and definition</h1></div></div></div><p>It <a id="id2" class="indexterm"/>is difficult to give an exact history, but the definition of machine <a id="id3" class="indexterm"/>learning we use today finds its usage as early as the 1860s. In Rene Descartes' <span class="emphasis"><em>Discourse on the Method</em></span>, he refers to <span class="emphasis"><em>Automata</em></span> and says:</p><div class="blockquote"><blockquote class="blockquote"><p>For we can easily understand a machine's being constituted so that it can utter words, and even emit some responses to action on it of a corporeal kind, which brings about a change in its organs; for instance, if touched in a particular part it may ask what we wish to say to it; if in another part it may exclaim that it is being hurt, and so on.</p></blockquote></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note02"/>Note</h3><p>
<a class="ulink" href="http://www.earlymoderntexts.com/assets/pdfs/descartes1637.pdf">http://www.earlymoderntexts.com/assets/pdfs/descartes1637.pdf</a>
</p><p>
<a class="ulink" href="https://www.marxists.org/reference/archive/descartes/1635/discourse-method.htm">https://www.marxists.org/reference/archive/descartes/1635/discourse-method.htm</a>
</p></div></div><p>Alan Turing, in his famous publication <span class="emphasis"><em>Computing Machinery and Intelligence</em></span> gives basic insights into the goals of machine learning by asking the question "Can machines think?".</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note03"/>Note</h3><p>
<a class="ulink" href="http://csmt.uchicago.edu/annotations/turing.htm">http://csmt.uchicago.edu/annotations/turing.htm</a>
</p><p>
<a class="ulink" href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf">http://www.csee.umbc.edu/courses/471/papers/turing.pdf</a>
</p></div></div><p>Arthur Samuel in 1959 wrote, <span class="emphasis"><em>"Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed."</em></span>.</p><p>Tom Mitchell in recent times gave a more exact definition of machine learning: <span class="emphasis"><em>"A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E."</em></span>
</p><p>Machine learning has a <a id="id4" class="indexterm"/>relationship with several areas:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Statistics</strong></span>: It uses the elements of data sampling, estimation, hypothesis testing, learning theory, and statistical-based modeling, to name a few</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Algorithms and computation</strong></span>: It uses the basic concepts of search, traversal, parallelization, distributed <a id="id5" class="indexterm"/>computing, and so on from basic computer science</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Database and knowledge discovery</strong></span>: For its ability to store, retrieve, and access information in various formats</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Pattern recognition</strong></span>: For <a id="id6" class="indexterm"/>its ability to find interesting patterns from the data to explore, visualize, and predict</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Artificial intelligence</strong></span>: Though it is considered a branch of artificial intelligence, it <a id="id7" class="indexterm"/>also has relationships with other branches, such as heuristics, optimization, evolutionary computing, and so on</li></ul></div></div></div>
<div class="section" title="What is not machine learning?"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec09"/>What is not machine learning?</h1></div></div></div><p>It is important to recognize areas that share a connection with machine learning but cannot themselves be considered part of machine learning. Some disciplines may overlap to a smaller or larger extent, yet the principles underlying machine learning are quite distinct:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Business intelligence (BI) and reporting</strong></span>: Reporting <span class="strong"><strong>key performance indicators</strong></span> (<span class="strong"><strong>KPI's</strong></span>), querying <a id="id8" class="indexterm"/>OLAP for slicing, dicing, and drilling into the data, dashboards, and so on that form the central <a id="id9" class="indexterm"/>components of BI are not machine learning.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Storage and ETL</strong></span>: Data storage and ETL are key elements in any machine learning process, but, by themselves, they don't qualify as machine learning.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Information retrieval, search, and queries</strong></span>: The ability to retrieve data or documents based on search criteria or indexes, which form the basis of information retrieval, are not really machine learning. Many forms of machine learning, such as semi-supervised learning, can rely on the searching of similar data for modeling, but that doesn't qualify searching as machine learning.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Knowledge representation and reasoning</strong></span>: Representing knowledge for performing complex tasks, such as ontology, expert systems, and semantic webs, does not qualify as machine learning.</li></ul></div></div>
<div class="section" title="Machine learning &#x2013; concepts and terminology"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Machine learning – concepts and terminology</h1></div></div></div><p>In <a id="id10" class="indexterm"/>this section, we will describe the different concepts and terms<a id="id11" class="indexterm"/> normally used in machine learning:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data or dataset</strong></span>: The basics of machine learning rely on understanding the data. The data or dataset normally refers to content available in structured or unstructured format for use in machine learning. Structured datasets have specific formats, and an unstructured dataset is normally in the form of some free-flowing text. Data can be available in various storage types or formats. In structured data, every element known as an instance or an example or row follows a predefined structure. Data can also be categorized by size: small or medium data have a few hundreds to thousands of instances, whereas <span class="emphasis"><em>big</em></span> data refers to a large volume, mostly in millions or billions, that cannot be stored or accessed using common devices or fit in the memory of such devices.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Features, attributes, variables, or dimensions</strong></span>: In structured datasets, as mentioned before, there are predefined elements with their own semantics and data type, which are known variously as features, attributes, metrics, indicators, variables, or dimensions.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data types</strong></span>: The features defined earlier need some form of typing in many machine learning algorithms or techniques. The most commonly used data types are as follows:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Categorical or nominal</strong></span>: This indicates well-defined categories or values present in the dataset. For example, eye color—black, blue, brown, green, grey; document content type—text, image, video.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Continuous or numeric</strong></span>: This indicates a numeric nature of the data field. For example, a person's weight measured by a bathroom scale, the temperature reading from a sensor, or the monthly balance in dollars on a credit card account.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Ordinal</strong></span>: This denotes data that can be ordered in some way. For example, garment size—small, medium, large; boxing weight classes: heavyweight, light heavyweight, middleweight, lightweight, and bantamweight.</li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Target or label</strong></span>: A feature or set of features in the dataset, which is used for learning from training data and predicting in an unseen dataset, is known as a target or a label. The term "ground truth" is also used in some domains. A label can have any form as specified before, that is, categorical, continuous, or ordinal.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Machine learning model</strong></span>: Each machine learning algorithm, based on what it learned from the dataset, maintains the state of its learning for predicting or giving insights into future <a id="id12" class="indexterm"/>or unseen data. This is referred to as the machine learning model.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Sampling</strong></span>: Data sampling is an essential step in machine learning. Sampling means choosing a subset <a id="id13" class="indexterm"/>of examples from a population <a id="id14" class="indexterm"/>with the intent of treating the behavior seen in the (smaller) sample as being representative of the behavior of the (larger) population. In order for the sample to be representative of the population, care must be taken in the way the sample is chosen. Generally, a population consists of every object sharing the properties of interest in the problem domain, for example, all people eligible to vote in the general election, or all potential automobile owners in the next four years. Since it is usually prohibitive (or impossible) to collect data for all the objects in a population, a well-chosen subset is selected for the purpose of analysis. A crucial consideration in the sampling process is that the sample is unbiased with respect to the population. The following are types of probability-based sampling:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Uniform random sampling</strong></span>: This refers to sampling that is done over a <a id="id15" class="indexterm"/>uniformly distributed population, that is, each object has an equal probability of being chosen.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Stratified random sampling</strong></span>: This refers to the sampling method <a id="id16" class="indexterm"/>used when the data can be categorized into multiple classes. In such cases, in order to ensure all categories are represented in the sample, the population is divided into distinct strata based on these classifications, and each stratum is sampled in proportion to the fraction of its class in the overall population. Stratified sampling is common when the population density varies across categories, and it is important to compare these categories with the same statistical power. Political polling often involves stratified sampling when it is known that different demographic groups vote in significantly different ways. Disproportional representation of each group in a random sample can lead to large errors in the outcomes of the polls. When we control for demographics, we can avoid oversampling the majority over the other groups.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Cluster sampling</strong></span>: Sometimes there are natural groups among the <a id="id17" class="indexterm"/>population being studied, and each group is representative of the whole population. An example is data that spans many geographical regions. In cluster sampling, you take a random subset of the groups followed by a random sample from within each of those groups to construct the full data sample. This kind of sampling can reduce the cost of data collection without compromising the fidelity of distribution in the population.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Systematic sampling</strong></span>: Systematic or interval sampling is used when there is a certain ordering present in the sampling frame (a finite set of <a id="id18" class="indexterm"/>objects treated as the population and taken to be the source of data for sampling, for example, the corpus of Wikipedia articles, arranged lexicographically by title). If the sample is then selected by starting at a random object and skipping a constant <span class="emphasis"><em>k</em></span> number of objects before selecting the next one, that is called systematic sampling. The value of <span class="emphasis"><em>k</em></span> is calculated as the ratio of the population to the sample size.</li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Model evaluation metrics</strong></span>: Evaluating models for performance is generally based <a id="id19" class="indexterm"/>on different evaluation metrics for different types of learning. In classification, it is generally based on accuracy, <span class="strong"><strong>receiver operating characteristics</strong></span> (<span class="strong"><strong>ROC</strong></span>) curves, training speed, memory requirements, false positive ratio, and so on, to name a few (see <a class="link" href="ch02.html" title="Chapter 2. Practical Approach to Real-World Supervised Learning">Chapter 2</a>, <span class="emphasis"><em>Practical Approach to Real-World Supervised Learning</em></span>). In clustering, the number of clusters found, cohesion, separation, and so on form the general metrics (see <a class="link" href="ch03.html" title="Chapter 3. Unsupervised Machine Learning Techniques">Chapter 3</a>, <span class="emphasis"><em>Unsupervised Machine Learning Techniques</em></span>). In stream-based learning, apart from the standard metrics mentioned earlier, adaptability, speed of learning, and robustness to sudden changes are some of the conventional metrics for evaluating the performance of the learner (see <a class="link" href="ch05.html" title="Chapter 5. Real-Time Stream Machine Learning">Chapter 5</a>, <span class="emphasis"><em>Real-Time Stream Machine Learning</em></span>).</li></ul></div><p>To illustrate these concepts, a concrete example in the form of a commonly used sample weather dataset is given. The data gives a set of weather conditions and a label that indicates whether the subject decided to play a game of tennis on the day or not:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>@relation weather</strong></span>

<span class="strong"><strong>@attribute outlook {sunny, overcast, rainy}</strong></span>
<span class="strong"><strong>@attribute temperature numeric</strong></span>
<span class="strong"><strong>@attribute humidity numeric</strong></span>
<span class="strong"><strong>@attribute windy {TRUE, FALSE}</strong></span>
<span class="strong"><strong>@attribute play {yes, no}</strong></span>

<span class="strong"><strong>@data</strong></span>
<span class="strong"><strong>sunny,85,85,FALSE,no</strong></span>
<span class="strong"><strong>sunny,80,90,TRUE,no</strong></span>
<span class="strong"><strong>overcast,83,86,FALSE,yes</strong></span>
<span class="strong"><strong>rainy,70,96,FALSE,yes</strong></span>
<span class="strong"><strong>rainy,68,80,FALSE,yes</strong></span>
<span class="strong"><strong>rainy,65,70,TRUE,no</strong></span>
<span class="strong"><strong>overcast,64,65,TRUE,yes</strong></span>
<span class="strong"><strong>sunny,72,95,FALSE,no</strong></span>
<span class="strong"><strong>sunny,69,70,FALSE,yes</strong></span>
<span class="strong"><strong>rainy,75,80,FALSE,yes</strong></span>
<span class="strong"><strong>sunny,75,70,TRUE,yes</strong></span>
<span class="strong"><strong>overcast,72,90,TRUE,yes</strong></span>
<span class="strong"><strong>overcast,81,75,FALSE,yes</strong></span>
<span class="strong"><strong>rainy,71,91,TRUE,no</strong></span>
</pre></div><p>The dataset is in the format of an <span class="strong"><strong>ARFF</strong></span> (<span class="strong"><strong>attribute-relation file format</strong></span>) file. It consists of a header giving the information about features or attributes with their data types and actual comma-separated data following the data tag. The dataset has five features, namely <code class="literal">outlook</code>, <code class="literal">temperature</code>, <code class="literal">humidity</code>, <code class="literal">windy</code>, and <code class="literal">play</code>. The features <code class="literal">outlook</code> and <code class="literal">windy</code> are categorical features, while <code class="literal">humidity</code> and <code class="literal">temperature</code> are continuous. The feature <code class="literal">play</code> is the target and is categorical.</p></div>
<div class="section" title="Machine learning &#x2013; types and subtypes"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Machine learning – types and subtypes</h1></div></div></div><p>We <a id="id20" class="indexterm"/>will now explore different subtypes or branches of machine <a id="id21" class="indexterm"/>learning. Though the following list is not comprehensive, it covers the most well-known types:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Supervised learning</strong></span>: This is the most popular branch of machine learning, which is <a id="id22" class="indexterm"/>about learning from labeled <a id="id23" class="indexterm"/>data. If the data type of the label is categorical, it becomes a classification problem, and if numeric, it is known as a regression problem. For example, if the goal of using of the dataset is the detection of fraud, which has categorical values of either true or false, we are dealing with a classification problem. If, on the other hand, the target is to predict the best price to list the sale of a home, which is a numeric dollar value, the problem is one of regression. The following figure illustrates labeled data that warrants the use of classification techniques, such as logistic regression that is suitable for linearly separable data, that is, when there exists a line that can cleanly separate the two classes. For higher dimensional data that may be linearly separable, one speaks of a separating hyperplane:<div class="mediaobject"><img src="graphics/B05137_01_01.jpg" alt="Machine learning – types and subtypes"/><div class="caption"><p>Linearly separable data</p></div></div><div class="mediaobject"><img src="graphics/B05137_01_02.jpg" alt="Machine learning – types and subtypes"/><div class="caption"><p>An example of a dataset that is not linearly separable.</p></div></div><p>This type of problem calls for classification techniques, such as support vector machines.</p></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Unsupervised learning</strong></span>: Understanding the data and exploring it for building machine <a id="id24" class="indexterm"/>learning models when the labels are not given is <a id="id25" class="indexterm"/>called unsupervised learning. Clustering, manifold learning, and outlier detection are techniques that are covered under this topic, which are dealt with in detail in <a class="link" href="ch03.html" title="Chapter 3. Unsupervised Machine Learning Techniques">Chapter 3</a>, <span class="emphasis"><em>Unsupervised Machine Learning Techniques</em></span>. Examples of problems that require unsupervised learning are many. Grouping customers <a id="id26" class="indexterm"/>according to their purchasing <a id="id27" class="indexterm"/>behavior is one example. In the case of biological data, tissues samples can be clustered based on similar gene expression values using unsupervised learning techniques.<p>The following figure represents data with inherent structure that can be revealed as distinct clusters using an unsupervised learning technique, such as k-means:</p><div class="mediaobject"><img src="graphics/B05137_01_03.jpg" alt="Machine learning – types and subtypes"/><div class="caption"><p>Clusters in data</p></div></div><p>Different techniques are used to detect global outliers—examples that are anomalous with respect to the entire dataset, and local outliers—examples that are misfits in their neighborhood. In the following figure, the notion of local and global outliers is illustrated for a two-feature dataset:</p><div class="mediaobject"><img src="graphics/B05137_01_04.jpg" alt="Machine learning – types and subtypes"/><div class="caption"><p>Local and global outliers</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Semi-supervised learning</strong></span>: When the dataset has only some labeled data and a large<a id="id28" class="indexterm"/> amount of data that is <a id="id29" class="indexterm"/>not labeled, learning from such a dataset is called <span class="strong"><strong>semi-supervised learning</strong></span>. When dealing with financial data with the goal of detecting fraud, for example, there may be a large amount of unlabeled data and only a small number of known fraud and non-fraud transactions. In such cases, semi-supervised learning may be applied.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Graph mining</strong></span>: Mining data <a id="id30" class="indexterm"/>represented as graph <a id="id31" class="indexterm"/>structures is known as <span class="strong"><strong>graph mining</strong></span>. It is the basis of social network analysis and structure analysis in different bioinformatics, web mining, and community mining applications.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Probabilistic graph modeling and inferencing</strong></span>: Learning and exploiting conditional <a id="id32" class="indexterm"/>dependence structures <a id="id33" class="indexterm"/>present between features <a id="id34" class="indexterm"/>expressed as a graph-based model comes under the branch of <span class="strong"><strong>probabilistic graph modeling</strong></span>. Bayesian networks and <a id="id35" class="indexterm"/>Markov random fields are two classes of such models.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Time-series forecasting</strong></span>: This refers to a form of learning where data has distinct <a id="id36" class="indexterm"/>temporal behavior and the<a id="id37" class="indexterm"/> relationship with time is modeled. A common example is in financial forecasting, where the performance of stocks in a certain sector may be the target of the predictive model.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Association analysis</strong></span>: This is <a id="id38" class="indexterm"/>a form of learning where data is in the form of an item set or market basket, and <a id="id39" class="indexterm"/>association rules are modeled to explore and predict the relationships between the items. A common example in association analysis is to learn the relationships between the most common items bought by customers when they visit the grocery store.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Reinforcement learning</strong></span>: This is a form of learning where machines learn to maximize <a id="id40" class="indexterm"/>performance based on <a id="id41" class="indexterm"/>feedback in the form of rewards or penalties received from the environment. A recent example that famously used reinforcement learning, among other techniques, was AlphaGo, the machine developed by Google that decisively beat the World Go Champion Lee Sedol in March 2016. Using a reward and penalty scheme, the model first trained on millions of board positions in the supervised learning stage, then played itself in the reinforcement learning stage to ultimately become good enough to triumph over the best human player.<div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note04"/>Note</h3><p>
<a class="ulink" href="http://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/">http://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/</a> </p><p>
<a class="ulink" href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf">https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf</a>
</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Stream learning or incremental learning</strong></span>: Learning <a id="id42" class="indexterm"/>in a supervised, unsupervised, or semi-supervised manner <a id="id43" class="indexterm"/>from stream data in real time <a id="id44" class="indexterm"/>or pseudo-real time is called stream or incremental <a id="id45" class="indexterm"/>learning. Learning the behaviors of sensors from different types of industrial systems for categorizing into normal and abnormal is an application that needs real-time feeds and real-time detection.</li></ul></div></div>
<div class="section" title="Datasets used in machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Datasets used in machine learning</h1></div></div></div><p>To <a id="id46" class="indexterm"/>learn from data, we must be able to understand <a id="id47" class="indexterm"/>and manage data in all forms. Data originates from many different sources, and consequently, datasets may differ widely in structure or have little or no structure at all. In this section, we present a high-level classification of datasets with commonly occurring examples.</p><p>Based on their structure, or the lack thereof, datasets may be classified as containing the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Structured data</strong></span>: Datasets with structured data are more amenable to being used as input<a id="id48" class="indexterm"/> to most machine learning algorithms. The <a id="id49" class="indexterm"/>data is in the form of records or rows following a well-known format with features that are either columns in a table or fields delimited by separators or tokens. There is no explicit relationship between the records or instances. The dataset is available chiefly in flat files or relational databases. The records of financial transactions at a bank shown in the following figure are an example of structured data:<div class="mediaobject"><img src="graphics/B05137_01_05.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Financial card transactional data with labels of fraud</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Transaction or market data</strong></span>: This is a special form of structured data where each entry <a id="id50" class="indexterm"/>corresponds to a collection of items. Examples <a id="id51" class="indexterm"/>of market datasets are the lists of grocery <a id="id52" class="indexterm"/>items purchased by different customers or movies <a id="id53" class="indexterm"/>viewed by customers, as shown in the following table:<div class="mediaobject"><img src="graphics/B05137_01_06.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Market dataset for items bought from grocery store</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Unstructured data</strong></span>: Unstructured data is normally not available in well-known <a id="id54" class="indexterm"/>formats, unlike structured data. Text data, image, and <a id="id55" class="indexterm"/>video data are different formats of unstructured data. Usually, a transformation of some form is needed to extract features from these forms of data into a structured dataset so that traditional <a id="id56" class="indexterm"/>machine learning algorithms can be <a id="id57" class="indexterm"/>applied.<div class="mediaobject"><img src="graphics/B05137_01_07.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Sample text data, with no discernible structure, hence unstructured. Separating spam from normal messages (ham) is a binary classification problem. Here true positives (spam) and true negatives (ham) are distinguished by their labels, the second token in each instance of data. SMS Spam Collection Dataset (UCI Machine Learning Repository), source: Tiago A. Almeida from the Federal University of Sao Carlos.</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Sequential data</strong></span>: Sequential <a id="id58" class="indexterm"/>data have an explicit notion of "order" to them. The order can be some relationship between <a id="id59" class="indexterm"/>features and a time variable in time series data, or it can be symbols repeating in some form in genomic datasets. Two examples of sequential data are weather data and genomic sequence data. The following figure shows the relationship between time and the sensor level for weather:<div class="mediaobject"><img src="graphics/B05137_01_08.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Time series from sensor data</p></div></div><p>Three genomic sequences are taken into consideration to show the repetition of the sequences <code class="literal">CGGGT</code> and <code class="literal">TTGAAAGTGGTG</code> in all three genomic sequences:</p><div class="mediaobject"><img src="graphics/B05137_01_09.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Genomic sequences of DNA as a sequence of symbols.</p></div></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Graph data</strong></span>: Graph <a id="id60" class="indexterm"/>data is characterized by the presence of relationships <a id="id61" class="indexterm"/>between entities in the data to form a graph structure. Graph datasets may be in a structured record format or an unstructured format. Typically, the graph relationship has to be mined from the dataset. Claims in the insurance domain can be considered structured records containing relevant claim details with claimants related through addresses, phone numbers, and so on. This can be viewed in a graph structure. Using the World Wide Web as an example, we have web pages available as unstructured data containing links, and graphs of relationships between web pages that can be built using web links, producing some of the most extensively mined graph datasets today:<div class="mediaobject"><img src="graphics/B05137_01_10.jpg" alt="Datasets used in machine learning"/><div class="caption"><p>Insurance claim data, converted into a graph structure showing the relationship between vehicles, drivers, policies, and addresses </p></div></div></li></ul></div></div>
<div class="section" title="Machine learning applications"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec13"/>Machine learning applications</h1></div></div></div><p>Given <a id="id62" class="indexterm"/>the rapidly growing use of machine learning in diverse areas of human endeavor, any attempt to list typical applications in the different industries where some form of machine learning is in use must necessarily be incomplete. Nevertheless, in this section, we list a broad set of machine learning applications by domain and the type of learning employed:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Domain/Industry</p>
</th><th style="text-align: left" valign="bottom">
<p>Applications</p>
</th><th style="text-align: left" valign="bottom">
<p>Machine Learning Type</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Financial </p>
</td><td style="text-align: left" valign="top">
<p>Credit risk scoring, fraud detection, and anti-money laundering</p>
</td><td style="text-align: left" valign="top">
<p>Supervised, unsupervised, graph models, time series, and stream learning</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Web</p>
</td><td style="text-align: left" valign="top">
<p>Online campaigns, health monitoring, and ad targeting </p>
</td><td style="text-align: left" valign="top">
<p>Supervised, unsupervised, semi-supervised</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Healthcare</p>
</td><td style="text-align: left" valign="top">
<p>Evidence-based medicine, epidemiological surveillance, drug events prediction, and claim fraud detection</p>
</td><td style="text-align: left" valign="top">
<p>Supervised, unsupervised, graph models, time series, and stream learning</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<span class="strong"><strong>Internet of things</strong></span> (<span class="strong"><strong>IoT</strong></span>)</p>
</td><td style="text-align: left" valign="top">
<p>Cyber <a id="id63" class="indexterm"/>security, smart roads, and sensor health monitoring</p>
</td><td style="text-align: left" valign="top">
<p>Supervised, unsupervised, semi-supervised, and stream learning</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Environment</p>
</td><td style="text-align: left" valign="top">
<p>Weather forecasting, pollution modeling, and water quality measurement</p>
</td><td style="text-align: left" valign="top">
<p>Time series, supervised, unsupervised, semi-supervised, and stream learning</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Retail</p>
</td><td style="text-align: left" valign="top">
<p>Inventory, customer management and recommendations, layout, and forecasting </p>
</td><td style="text-align: left" valign="top">
<p>Time series, supervised, unsupervised, semi-supervised, and stream learning</p>
</td></tr></tbody></table></div><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em> Applications of machine learning </em></span></p></blockquote></div></div>
<div class="section" title="Practical issues in machine learning"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec14"/>Practical issues in machine learning</h1></div></div></div><p>It is necessary <a id="id64" class="indexterm"/>to appreciate the nature of the constraints and potentially sub-optimal conditions one may face when dealing with problems requiring machine learning. An understanding of the nature of these issues, the impact of their presence, and the methods to deal with them will be addressed throughout the discussions in the coming chapters. Here, we present a brief introduction to the practical issues that confront us:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data quality and noise</strong></span>: Missing values, duplicate values, incorrect values due to human or instrument recording error, and incorrect formatting are some of the <a id="id65" class="indexterm"/>important issues to be considered while building machine learning models. Not addressing data quality can result in incorrect or incomplete models. In the next chapter, we will highlight some of these issues and some strategies to overcome them through data cleansing.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Imbalanced datasets</strong></span>: In many real-world datasets, there is an imbalance among labels in the training data. This imbalance in a dataset affects the choice of learning, the process of selecting algorithms, model evaluation and verification. If the right techniques are not employed, the models can suffer large biases, and the learning is not effective. Detailed in the next few chapters are various techniques that use meta-learning processes, such as cost-sensitive learning, ensemble learning, outlier detection, and so on, which can be employed in these situations.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data volume, velocity, and scalability</strong></span>: Often, a large volume of data exists in raw form or as real-time streaming data at high speed. Learning from the entire data becomes infeasible either due to constraints inherent to the algorithms or hardware limitations, or combinations thereof. In order to reduce the size of the dataset to fit the resources available, data sampling must be done. Sampling can be done in many ways, and each form of sampling introduces a bias. Validating the models against sample bias must be performed by employing various techniques, such as stratified sampling, varying sample sizes, and increasing the size of experiments on different sets. Using big data machine learning can also overcome the volume and sampling biases.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Overfitting</strong></span>: One of the core problems in predictive models is that the model is not generalized enough and is made to fit the given training data <span class="emphasis"><em>too well</em></span>. This results in poor performance of the model when applied to unseen data. There are various techniques described in later chapters to overcome these issues.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Curse of dimensionality</strong></span>: When dealing with high-dimensional data, that is, datasets with a large number of features, scalability of machine learning algorithms becomes a serious concern. One of the issues with adding more features to the data is that it introduces sparsity, that is, there are now fewer data points on average per unit volume of feature space unless an increase in the number of features is accompanied by an exponential increase in the number of training examples. This can hamper performance in many methods, such as distance-based algorithms. Adding more features can also deteriorate the predictive power of learners, as illustrated in the following figure. In such cases, a more suitable algorithm is needed, or the dimensionality of the data must <a id="id66" class="indexterm"/>be reduced.<div class="mediaobject"><img src="graphics/B05137_01_11.jpg" alt="Practical issues in machine learning"/><div class="caption"><p>Curse of dimensionality illustrated in classification learning, where adding more features deteriorates classifier performance.</p></div></div></li></ul></div></div>
<div class="section" title="Machine learning &#x2013; roles and process"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec15"/>Machine learning – roles and process</h1></div></div></div><p>Any <a id="id67" class="indexterm"/>effort to apply machine learning to a large-sized problem <a id="id68" class="indexterm"/>requires the collaborative effort of a number of roles, each abiding by a set of systematic processes designed for rigor, efficiency, and robustness. The following roles and processes ensure that the goals of the endeavor are clearly defined at the outset and the correct methodologies are employed in data analysis, data sampling, model selection, deployment, and performance evaluation—all as part of a comprehensive framework for conducting analytics consistently and with repeatability.</p><div class="section" title="Roles"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec05"/>Roles</h2></div></div></div><p>Participants <a id="id69" class="indexterm"/>play specific parts in each step. These responsibilities are captured in the following four roles:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Business domain expert</strong></span>: A subject <a id="id70" class="indexterm"/>matter expert with knowledge of the problem domain</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data engineer</strong></span>: Involved <a id="id71" class="indexterm"/>in the collecting, transformation, and cleaning of the data</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Project manager</strong></span>: Overseer <a id="id72" class="indexterm"/>of the smooth running of the process</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data scientist or machine learning expert</strong></span>: Responsible <a id="id73" class="indexterm"/>for applying descriptive or predictive analytic <a id="id74" class="indexterm"/>techniques</li></ul></div></div><div class="section" title="Process"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec06"/>Process</h2></div></div></div><p>
<span class="strong"><strong>CRISP</strong></span> (<span class="strong"><strong>Cross Industry Standard Process</strong></span>) is a well-known high-level process model for data <a id="id75" class="indexterm"/>mining that defines the analytics process. In <a id="id76" class="indexterm"/>this section, we have added some of our own extensions to the CRISP process that make it more comprehensive and better suited for analytics using machine learning. The entire iterative process is demonstrated in the following schematic figure. We will discuss each step of the process in detail in this section.</p><div class="mediaobject"><img src="graphics/B05137_01_12.jpg" alt="Process"/></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Identifying the business problem</strong></span>: Understanding the objectives and the end goals of the <a id="id77" class="indexterm"/>project or process is the first step. This is normally carried out by a business domain expert in conjunction with the project manager and machine learning expert. What are the end goals in terms of data availability, formats, specification, collection, ROI, business value, deliverables? All these questions are discussed in this phase of the process. Identifying the goals clearly, and <span class="emphasis"><em>in quantifiable terms</em></span> where possible, such as dollar amount saved, finding a pre-defined number of anomalies or clusters, or predicting no more than a certain number of false positives, and so on, is an important objective of this phase.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Machine learning mapping</strong></span>: The next step is mapping the business problem to one or <a id="id78" class="indexterm"/>more machine learning types discussed in the preceding section. This step is generally carried out by the machine learning expert. In it, we determine whether we should use just one form of learning (for example, supervised, unsupervised, semi-supervised) or if a hybrid of forms is more suitable for the project.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data collection</strong></span>: Obtaining <a id="id79" class="indexterm"/>the raw data in the agreed format and specification for processing follows next. This step is normally carried out by data engineers and may require handling some basic ETL steps.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data quality analysis</strong></span>: In this step, we perform analysis on the data for missing values, duplicates, and so on, conduct basic statistical analysis on the categorical and <a id="id80" class="indexterm"/>continuous types, and similar tasks to evaluate the quality of data. Data engineers and data scientists can perform the tasks together.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Data sampling and transformation</strong></span>: Determining whether data needs to be divided <a id="id81" class="indexterm"/>into samples and performing <a id="id82" class="indexterm"/>data sampling of various sizes for training, validation, or testing—these are the tasks performed in this step. It consists of employing different sampling techniques, such as oversampling and random sampling of the training datasets for effective learning by the algorithms, especially when the data is highly imbalanced in the labels. The data scientist is involved in this task.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Feature analysis and selection</strong></span>: This is an iterative process combined with modeling <a id="id83" class="indexterm"/>in many tasks to make <a id="id84" class="indexterm"/>sure the features are analyzed for either their discriminating values or their effectiveness. It can involve finding new features, transforming existing features, handling the data quality issues mentioned earlier, selecting a subset of features, and so on ahead of the modeling process. The data scientist is normally assigned this task.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Machine learning modeling</strong></span>: This is <a id="id85" class="indexterm"/>an iterative process working on different algorithms based on data characteristics and learning types. It involves different steps, such as generating hypotheses, selecting algorithms, tuning parameters, and getting results from evaluation to find models that meet the criteria. The data scientist carries out this task.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Model evaluation</strong></span>: While this step is related to all the preceding steps to some degree, it <a id="id86" class="indexterm"/>is more closely linked to the business understanding phase and machine learning mapping phase. The evaluation criteria must map in some way to the business problem or the goal. Each problem/project has its own goal, whether that be improving true positives, reducing false positives, finding anomalous clusters or behaviors, or analyzing data for different clusters. Different techniques that implicitly or explicitly measure these targets are used based on learning techniques. Data scientists and business domain experts normally take part in this step.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Model selection and deployment</strong></span>: Based on the evaluation criteria, one or more models—independent <a id="id87" class="indexterm"/>or as an ensemble—are selected. The deployment of models normally needs to address <a id="id88" class="indexterm"/>several issues: runtime scalability measures, execution specifications of the environment, and audit information, to name a few. Audit information that captures the key parameters based on learning is an essential part of the process. It ensures that model performance can be tracked and compared to check for the deterioration and aging of the models. Saving key information, such as training data volumes, dates, data quality analysis, and so on, is independent of learning types. Supervised learning might involve saving the confusion matrix, true positive ratios, false positive ratios, area under the ROC curve, precision, recall, error rates, and so on. Unsupervised learning might involve clustering or outlier evaluation results, cluster statistics, and so on. This is the domain of the data scientist, as well as the project manager.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Model performance monitoring</strong></span>: This task involves periodically tracking the model <a id="id89" class="indexterm"/>performance in terms of the criteria it was evaluated against, such as the true positive rate, false positive rate, performance speed, memory allocation, and so on. It is imperative to measure the deviations in these metrics with respect to the metrics between successive evaluations of the trained model's performance. The deviations and tolerance in the deviation will give insights into repeating the process or retuning the models as time progresses. The data scientist is responsible for this stage.</li></ul></div><p>As may be observed from the preceding diagram, the entire process is an iterative one. After a model or set of models has been deployed, business and environmental factors may change in ways that affect the performance of the solution, requiring a re-evaluation of business goals and success criteria. This takes us back through the cycle again.</p></div></div>
<div class="section" title="Machine learning &#x2013; tools and datasets"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec16"/>Machine learning – tools and datasets</h1></div></div></div><p>A sure <a id="id90" class="indexterm"/>way to master the techniques necessary to successfully <a id="id91" class="indexterm"/>complete a project of any size or complexity in machine learning is to familiarize yourself with the available tools and frameworks by performing experiments with widely-used datasets, as demonstrated in the chapters to follow. A short survey of the most popular Java frameworks is presented in the following list. Later chapters will include experiments that you will do using the following tools:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>RapidMiner</strong></span>: A leading <a id="id92" class="indexterm"/>analytics platform, RapidMiner has multiple offerings, including Studio, a visual design <a id="id93" class="indexterm"/>framework for processes, Server, a product to facilitate a collaborative environment by enabling sharing of data sources, processes, <a id="id94" class="indexterm"/>and practices, and Radoop, a system with translations to enable deployment and execution on the Hadoop ecosystem. RapidMiner Cloud provides a cloud-based repository and on-demand computing power.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: GPL (Community Edition) and Commercial (Enterprise Edition)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="https://rapidminer.com/">https://rapidminer.com/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Weka</strong></span>: This is a <a id="id95" class="indexterm"/>comprehensive open source Java <a id="id96" class="indexterm"/>toolset for data mining and building machine <a id="id97" class="indexterm"/>learning applications with its own collection of publicly available datasets.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: GPL</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://www.cs.waikato.ac.nz/ml/weka/">http://www.cs.waikato.ac.nz/ml/weka/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Knime</strong></span>: KNIME (we are urged to pronounce it with a silent k, as "naime") Analytics Platform <a id="id98" class="indexterm"/>is written in Java and offers <a id="id99" class="indexterm"/>an integrated toolset, a rich set of algorithms, and <a id="id100" class="indexterm"/>a visual workflow to do analytics without the need for standard programming languages, such as Java, Python, and R. However, one can write scripts in Java and other languages to implement functionality not available natively in KNIME.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: GNU GPL v3</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="https://www.knime.org/">https://www.knime.org/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Mallet</strong></span>: This is a <a id="id101" class="indexterm"/>Java library for NLP. It offers <a id="id102" class="indexterm"/>document classification, sequence tagging, topic <a id="id103" class="indexterm"/>modeling, and other text-based applications of machine learning, as well as an API for task pipelines.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Common Public License version 1.0 (CPL-1)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Elki</strong></span>: This <a id="id104" class="indexterm"/>is a research-oriented Java software <a id="id105" class="indexterm"/>primarily focused on data mining with unsupervised <a id="id106" class="indexterm"/>algorithms. It achieves high performance and scalability using data index structures that improve access performance of multi-dimensional data.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: AGPLv3</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://elki.dbs.ifi.lmu.de/">http://elki.dbs.ifi.lmu.de/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>JCLAL</strong></span>: This is a <a id="id107" class="indexterm"/>Java Class Library for Active Learning, and is an open source framework for developing Active <a id="id108" class="indexterm"/>Learning methods, one <a id="id109" class="indexterm"/>of the areas that deal with learning predictive models from a mix of labeled and unlabeled data (semi-supervised learning is another).<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: GNU General Public License version 3.0 (GPLv3)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="https://sourceforge.net/projects/jclal/">https://sourceforge.net/projects/jclal/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>KEEL</strong></span>: This is <a id="id110" class="indexterm"/>an open source software <a id="id111" class="indexterm"/>written in Java for designing experiments primarily <a id="id112" class="indexterm"/>suited to the implementation of evolutionary learning and soft computing based techniques for data mining problems.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: GPLv3</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://www.keel.es/">http://www.keel.es/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>DeepLearning4J</strong></span>: This <a id="id113" class="indexterm"/>is a distributed <a id="id114" class="indexterm"/>deep learning library for Java and Scala. DeepLearning4J is integrated with Spark and Hadoop. Anomaly detection <a id="id115" class="indexterm"/>and recommender systems are use cases that lend themselves well to the models generated via deep learning techniques.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License 2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://deeplearning4j.org/">http://deeplearning4j.org/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Spark-MLlib</strong></span>: (Included in Apache Spark distribution) MLlib is the machine learning library <a id="id116" class="indexterm"/>included in Spark mainly written in Scala and Java. Since the introduction of Data Frames in Spark, the <code class="literal">spark.ml</code> package, which is written on top of Data Frames, is recommended over the original <code class="literal">spark.mllib</code> package. MLlib includes <a id="id117" class="indexterm"/>support for all stages of the analytics process, including statistical methods, classification and regression algorithms, clustering, dimensionality reduction, feature extraction, model evaluation, and PMML support, among others. Another aspect of MLlib is the support for <a id="id118" class="indexterm"/>the use of pipelines or workflows. MLlib is accessible from R, Scala, and Python, in addition to Java.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License v2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://spark.apache.org/mllib/">http://spark.apache.org/mllib/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>H2O</strong></span>: H2O is a <a id="id119" class="indexterm"/>Java-based library with API support <a id="id120" class="indexterm"/>in R and Python, in addition to Java. H2O can also run on Spark as its own application called Sparkling Water. H2O Flow is a web-based interactive environment with executable cells and rich media in a single notebook-like <a id="id121" class="indexterm"/>document.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License v2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://www.h2o.ai/">http://www.h2o.ai/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>MOA/SAMOA</strong></span>: Aimed <a id="id122" class="indexterm"/>at machine <a id="id123" class="indexterm"/>learning <a id="id124" class="indexterm"/>from data streams <a id="id125" class="indexterm"/>with a pluggable interface for stream processing platforms, SAMOA, at the time of writing, is an Apache Incubator project.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License v2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="https://samoa.incubator.apache.org/">https://samoa.incubator.apache.org/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Neo4j</strong></span>: Neo4j is an <a id="id126" class="indexterm"/>open source NoSQL graphical <a id="id127" class="indexterm"/>database implemented in Java and Scala. As we will see in later chapters, graph analytics has a variety of use cases, including matchmaking, routing, social networks, network management, and so on. Neo4j supports <a id="id128" class="indexterm"/>fully ACID transactions.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Community <a id="id129" class="indexterm"/>Edition—GPLv3 and Enterprise Edition—multiple options, including Commercial and Educational (<a class="ulink" href="https://neo4j.com/licensing/">https://neo4j.com/licensing/</a>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="https://neo4j.com/">https://neo4j.com/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>GraphX</strong></span>: This is <a id="id130" class="indexterm"/>included in the Apache Spark <a id="id131" class="indexterm"/>distribution. GraphX is the graph library accompanying Spark. The API has extensive support for viewing and manipulating graph structures, as well as some graph algorithms, such as PageRank, Connected Components, and <a id="id132" class="indexterm"/>Triangle Counting.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License v2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://spark.apache.org/graphx/">http://spark.apache.org/graphx/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>OpenMarkov</strong></span>: OpenMarkov <a id="id133" class="indexterm"/>is a tool <a id="id134" class="indexterm"/>for editing <a id="id135" class="indexterm"/>and evaluating <span class="strong"><strong>probabilistic graphical models</strong></span> (<span class="strong"><strong>PGM</strong></span>). It <a id="id136" class="indexterm"/>includes a <a id="id137" class="indexterm"/>GUI for interactive learning.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: EUPLv1.1 (<a class="ulink" href="https://joinup.ec.europa.eu/community/eupl/og_page/eupl">https://joinup.ec.europa.eu/community/eupl/og_page/eupl</a>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://www.openmarkov.org/">http://www.openmarkov.org/</a></li></ul></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Smile</strong></span>: Smile is a <a id="id138" class="indexterm"/>machine learning platform <a id="id139" class="indexterm"/>for the JVM with an extensive library of algorithms. Its <a id="id140" class="indexterm"/>capabilities include NLP, manifold learning, association rules, genetic algorithms, and a versatile set of tools for visualization.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>License</strong></span>: Apache License 2.0</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Website</strong></span>: <a class="ulink" href="http://haifengl.github.io/smile/">http://haifengl.github.io/smile/</a></li></ul></div></li></ul></div><div class="section" title="Datasets"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec07"/>Datasets</h2></div></div></div><p>A number <a id="id141" class="indexterm"/>of publicly available datasets have aided research and learning in data science immensely. Several of those listed in the following section are well known and have been used by scores of researchers to benchmark their methods over the years. New datasets are constantly being made available to serve different communities of modelers and users. The majority are real-world datasets from different domains. The exercises in this volume will use several datasets from this list.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>UC Irvine (UCI) database</strong></span>: Maintained by the Center for Machine Learning and <a id="id142" class="indexterm"/>Intelligent Systems at <a id="id143" class="indexterm"/>UC Irvine, the UCI database is a catalog of some 350 datasets of varying sizes, from a dozen to more than forty million records and up to three million attributes, with a mix of <a id="id144" class="indexterm"/>multivariate text, time-series, and other data types. (<a class="ulink" href="https://archive.ics.uci.edu/ml/index.html">https://archive.ics.uci.edu/ml/index.html</a>)</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Tunedit</strong></span>: (<a class="ulink" href="http://tunedit.org/">http://tunedit.org/</a>) This offers <a id="id145" class="indexterm"/>Tunedit Challenges and tools to <a id="id146" class="indexterm"/>conduct <a id="id147" class="indexterm"/>repeatable data mining experiments. It also offers a platform for hosting data competitions.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Mldata.org</strong></span>: (<a class="ulink" href="http://mldata.org/">http://mldata.org/</a>) Supported by the PASCAL 2 organization <a id="id148" class="indexterm"/>that brings together <a id="id149" class="indexterm"/>researchers and students across Europe and <a id="id150" class="indexterm"/>the world, mldata.org is primarily a repository of user-contributed datasets that encourages data and solution sharing amongst groups of researchers to help with the goal of creating reproducible solutions.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>KDD Challenge Datasets</strong></span>: (<a class="ulink" href="http://www.kdnuggets.com/datasets/index.html">http://www.kdnuggets.com/datasets/index.html</a>) KDNuggets aggregates <a id="id151" class="indexterm"/>multiple <a id="id152" class="indexterm"/>dataset repositories across a wide <a id="id153" class="indexterm"/>variety of domains.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Kaggle</strong></span>: Billed as the <span class="emphasis"><em>Home of Data Science</em></span>, Kaggle is a leading platform for data science <a id="id154" class="indexterm"/>competitions and also a <a id="id155" class="indexterm"/>repository of datasets from past competitions and <a id="id156" class="indexterm"/>user-submitted datasets.</li></ul></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec17"/>Summary</h1></div></div></div><p>Machine learning has already demonstrated impressive successes despite being a relatively young field. With the ubiquity of Java resources, Java's platform independence, and the selection of ML frameworks in Java, superior skill in machine learning using Java is a highly desirable asset in the market today.</p><p>Machine learning has been around in some form—if only in the imagination of thinkers, in the beginning—for a long time. More recent developments, however, have had a radical impact in many spheres of our everyday lives. Machine learning has much in common with statistics, artificial intelligence, and several other related areas. Whereas some data management, business intelligence, and knowledge representation systems may also be related in the central role of data in each of them, they are not commonly associated with principles of learning from data as embodied in the field of machine learning.</p><p>Any discourse on machine learning would assume an understanding of what data is and what data types we are concerned with. Are they categorical, continuous, or ordinal? What are the data features? What is the target, and which ones are predictors? What kinds of sampling methods can be used—uniform random, stratified random, cluster, or systematic sampling? What is the model? We saw an example dataset for weather data that included categorical and continuous features in the ARFF format.</p><p>The types of machine learning include supervised learning, the most common when labeled data is available, unsupervised when it's not, and semi-supervised when we have a mix of both. The chapters that follow will go into detail on these, as well as graph mining, probabilistic graph modeling, deep learning, stream learning, and learning with Big Data.</p><p>Data comes in many forms: structured, unstructured, transactional, sequential, and graphs. We will use data of different structures in the exercises to follow later in this book.</p><p>The list of domains and the different kinds of machine learning applications keeps growing. This review presents the most active areas and applications.</p><p>Understanding and dealing effectively with practical issues, such as noisy data, skewed datasets, overfitting, data volumes, and the curse of dimensionality, is the key to successful projects—it's what makes each project unique in its challenges.</p><p>Analytics with machine learning is a collaborative endeavor with multiple roles and well-defined processes. For consistent and reproducible results, adopting the enhanced CRISP methodology outlined here is critical—from understanding the business problem to data quality analysis, modeling and model evaluation, and finally to model performance monitoring.</p><p>Practitioners of data science are blessed with a rich and growing catalog of datasets available to the public and an increasing set of ML frameworks and tools in Java as well as other languages. In the following chapters, you will be introduced to several datasets, APIs, and frameworks, along with advanced concepts and techniques to equip you with all you will need to attain mastery in machine learning.</p><p>Ready? Onward then!</p></div></body></html>