<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer183">
    <h1 class="chapterNumber">5</h1>
    <h1 class="chapterTitle" id="_idParaDest-112">Enhancing Customer Insight with Sentiment Analysis</h1>
    <p class="normal">In today’s digital age, understanding customer sentiment is key for shaping marketing strategies, refining brand messaging, and improving customer experience. Sentiment analysis, a subset<a id="_idIndexMarker386"/> of <strong class="keyWord">natural language processing</strong> (<strong class="keyWord">NLP</strong>), empowers marketers to sort through massive amounts of unstructured text data, such as customer feedback, social media conversations, and product reviews, to gauge public sentiment. This analytical approach not only helps in monitoring brand reputation but also in tailoring marketing messages according to customer preferences, which enhances the overall customer insight.</p>
    <p class="normal">This chapter explores the world of sentiment analysis for marketing. Using the power of Python, you will learn how to classify sentiments as positive, negative, or neutral, and identify the nuances embedded within customer feedback. We will also use hands-on examples, based on the “Twitter Airline Sentiment” dataset from Kaggle, to equip you with the skills to perform sentiment analysis, interpret the results, and apply these insights to craft more effective marketing strategies.</p>
    <p class="normal">Overall, this chapter will give you a comprehensive walkthrough of the fundamentals of sentiment analysis in marketing and then guide you through the practical aspects of data preparation, analysis, and results visualization. By the end of this chapter, you will gain proficiency in:</p>
    <ul>
      <li class="bulletList">Understanding the critical role of sentiment analysis in marketing</li>
      <li class="bulletList">Preprocessing text data to prepare it for analysis</li>
      <li class="bulletList">Applying Python libraries to perform sentiment analysis using traditional natural language processing and elements from generative AI</li>
      <li class="bulletList">Interpreting and visualizing the outcomes to derive actionable marketing insights</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-113">Introduction to sentiment analysis in marketing</h1>
    <p class="normal">In the fast-paced <a id="_idIndexMarker387"/>world of marketing, staying attuned to customer sentiments is not just beneficial; it’s a necessity. Sentiment analysis, or the process of detecting positive, negative, or neutral tones in text data, stands at the forefront of this effort, offering a lens through which marketers can view and understand the emotional undertones of customer interactions. This approach uses NLP, machine learning, and computational linguistics to systematically identify, extract, quantify, and study patterns within text. These patterns can range from the presence of certain keywords and phrases to the structure of sentences and the context in which terms are used.</p>
    <h2 class="heading-2" id="_idParaDest-114">The significance of sentiment analysis</h2>
    <p class="normal">The importance of<a id="_idIndexMarker388"/> sentiment analysis in marketing cannot be overstated. It acts as a compass, guiding brands through the vast and often turbulent sea of public opinion. By analyzing customer feedback, social media conversations, and product reviews, sentiment analysis helps marketers understand not just what people say but how they feel.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Further reading on sentiment analysis in marketing</strong></p>
      <p class="normal">For an overview of approaches to automated textual analysis in marketing, refer to the article “<em class="italic">Uniting the Tribes: Using Text for Marketing Insight</em>” (<a href="https://journals.sagepub.com/doi/full/10.1177/0022242919873106"><span class="url">https://journals.sagepub.com/doi/full/10.1177/0022242919873106</span></a>). </p>
    </div>
    <p class="normal">More specifically, the application of sentiment analysis in marketing opens an array of opportunities:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Brand monitoring</strong>: Sentimen<a id="_idIndexMarker389"/>t analysis enables real-time monitoring of brand perception across various digital platforms. By tracking shifts in sentiment, marketers can anticipate and mitigate potential PR crises. For example, during the United Airlines incident on April 9, 2017, where a passenger was forcibly removed from a flight due to overbooking, sentiment analysis could have helped United detect the rapidly escalating negative sentiment around the viral social media footage and respond more proactively.</li>
      <li class="bulletList"><strong class="keyWord">Campaign analysis</strong>: Understanding emotional responses to marketing campaigns allows for agile strategy adjustments. Sentiment analysis can reveal whether a campaign resonates positively with the target audience or if it misses the mark. For instance, Pepsi’s 2017 ad featuring Kendall Jenner received backlash for being perceived as trivializing social justice movements. Early sentiment analysis could have identified negative feedback and allowed for a timely campaign pivot.</li>
      <li class="bulletList"><strong class="keyWord">Product feedback</strong>: Detailed sentiment insights help pinpoint specific aspects of products or services that delight or disappoint customers. This feedback loop is invaluable for continuous improvement and innovation. Consider the case of Apple’s launch of the iPhone 6, where sentiment analysis of customer feedback highlighted the “Bendgate” issue, prompting Apple to address the problem quickly.</li>
      <li class="bulletList"><strong class="keyWord">Market research</strong>: Sentiment analysis offers a window into the broader market landscape, providing a competitive edge by uncovering trends, competitor standings, and gaps in the market. For example, Netflix uses sentiment <a id="_idIndexMarker390"/>analysis to understand viewer preferences and trends, which aids in content creation and recommendation algorithms.</li>
    </ul>
    <p class="normal">By harnessing the insights gained through sentiment analysis, marketers can not only monitor brand reputation but also tailor their communications to resonate more deeply with their audience, leading to more effective and impactful marketing strategies.</p>
    <h2 class="heading-2" id="_idParaDest-115">Advancements in AI and sentiment analysis</h2>
    <p class="normal">The emergence <a id="_idIndexMarker391"/>of <strong class="keyWord">large language models</strong> (<strong class="keyWord">LLMs</strong>) and <strong class="keyWord">Generative AI</strong> (<strong class="keyWord">GenAI</strong>) has<a id="_idIndexMarker392"/> transformed sentiment analysis, offering <a id="_idIndexMarker393"/>unprecedented <a id="_idIndexMarker394"/>depth and accuracy in understanding text data. LLMs are trained on vast datasets that encompass diverse linguistic patterns, enabling them to understand and generate human-like text. For example, LLMs can grasp context and nuance in ways that were previously unattainable, with state-of-the-art models that can distinguish between sarcasm and genuine dissatisfaction, or recognize the underlying positivity in a complaint that includes a suggestion for improvement.</p>
    <p class="normal">These advancements are particularly relevant for sentiment analysis, where the difference between a satisfied and dissatisfied customer can often be subtle and context-dependent. However, it is important to note that while LLMs offer these advantages, they also come with certain limitations. They can be computationally expensive and require significant processing power, which might not be accessible to all users or can come at a cost. Additionally, LLMs are not infallible, and they can sometimes produce biased or inaccurate results based on the data they were trained on.</p>
    <p class="normal">While a more in-depth discussion of GenAI models and their limitations will come in <em class="italic">Part IV</em> of the<a id="_idIndexMarker395"/> book, this<a id="_idIndexMarker396"/> chapter will touch upon the targeted application of GenAI for sentiment analysis.</p>
    <h1 class="heading-1" id="_idParaDest-116">Practical example: Twitter Airline Sentiment dataset</h1>
    <p class="normal">Our exploration of sentiment <a id="_idIndexMarker397"/>analysis will be based on the <code class="inlineCode">Twitter Airline Sentiment</code> dataset. This collection of tweets directed at various airlines provides a rich dataset for understanding how sentiment analysis can be applied to real-world marketing challenges. </p>
    <p class="normal">Here, sentiments are classified as positive, negative, or neutral via human annotation, reflecting a range of customer emotions from satisfaction to frustration.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Source code and data</strong>: <a href="https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb"><span class="url">https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/blob/main/ch.5/SentimentAnalysis.ipynb</span></a></p>
      <p class="normal"><strong class="keyWord">Data source</strong>: <a href="https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment"><span class="url">https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment</span></a></p>
    </div>
    <p class="normal">Conveniently, this dataset contains not only tweets and their sentiment classifications but also, in some cases, explanations for tweets with negative sentiment. These will provide useful benchmarks for us to evaluate the approaches we will develop in this chapter.</p>
    <p class="normal">Before diving into the data, below are some sample tweets, highlighting the sentiment classifications, the topics present, and the nature of the tweet content. As you can see, the first couple of rows of the dataset contain terms that are a result of real-world data entry errors, which will be addressed during the data preprocessing stage.</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_01.png"/></figure>
    <p class="packt_figref">Figure 5.1: Sample tweets from the Twitter Airline Sentiment dataset</p>
    <p class="normal">In the subsequent sections, we’ll tackle the data preparation, model building, analysis, and visualization stages, employing both conventional NLP techniques and a more modern approach using LLMs. Initially, we’ll apply NLP tools for data cleaning and structuring, laying the groundwork for traditional sentiment analysis. </p>
    <p class="normal">Recognizing the challenges of class <a id="_idIndexMarker398"/>imbalance, we’ll demonstrate how GenAI can be used as a tool to augment our dataset with additional examples, as necessary. We will then use the models we’ve built to derive actionable insights that can help guide marketing campaigns.</p>
    <h1 class="heading-1" id="_idParaDest-117">Preparing data for sentiment analysis</h1>
    <p class="normal">Before diving <a id="_idIndexMarker399"/>into sentiment analysis, it’s crucial to <a id="_idIndexMarker400"/>prepare your data effectively. Data preparation is a process that involves cleaning, structuring, and enhancing data to improve analysis outcomes. The goal of these steps is to ensure that the data is in a form that is directly usable for analysis and to remove any inaccuracies or irregularities.</p>
    <p class="normal">Let’s begin by loading the <code class="inlineCode">Twitter Airline Sentiment</code> dataset:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
df = pd.read_csv(<span class="hljs-string">'Tweets.csv'</span>)
df.head(<span class="hljs-number">5</span>)
</code></pre>
    <p class="normal">Using <code class="inlineCode">df.columns</code>, we can see a number of columns, such as <code class="inlineCode">text</code>, which contains the tweet itself, along with several valuable metadata and sentiment-related fields. The following is a summary of<a id="_idIndexMarker401"/> the <a id="_idIndexMarker402"/>columns, along with a short description of their meaning:</p>
    <table class="table-container" id="table001">
      <tbody>
        <tr>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Column</strong></p>
          </td>
          <td class="table-cell">
            <p class="normal"><strong class="keyWord">Description</strong></p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">tweet_id</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">ID of tweet</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">airline_sentiment</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Class label of tweets (positive, neutral, or negative)</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">airline_sentiment_confidence</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Confidence level in sentiment classification</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">negative_reason</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Reason for negative sentiment</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">airline</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Official name of the airline</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">airline_sentiment_gold</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Gold standard for airline sentiment classification</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">name</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Name of the user</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">negativereason_gold</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Gold standard for the rationale behind the negative reason</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">retweet_count</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Numerical value representing the number of retweets</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">text</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Text of the tweet as typed by the user</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">tweet_coord</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Latitude and longitude of the Twitter user</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">tweet_created</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Creation date of the tweet</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">tweet_location</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Location from which the tweet was sent</p>
          </td>
        </tr>
        <tr>
          <td class="table-cell">
            <p class="normal"><code class="inlineCode">user_timezone</code></p>
          </td>
          <td class="table-cell">
            <p class="normal">Timezone of the user</p>
          </td>
        </tr>
      </tbody>
    </table>
    <p class="packt_figref">Table 5.2: Columns and their description for the Twitter Airline Sentiment dataset</p>
    <h2 class="heading-2" id="_idParaDest-118">Traditional NLP techniques for data preparation</h2>
    <p class="normal">In traditional NLP<a id="_idIndexMarker403"/> techniques, careful text preparation—encompassing cleaning, tokenization, stop word removal, and lemmatization—is important to structure the input text for effective analysis. We’ll discuss these processes in detail in this section.</p>
    <p class="normal">In contrast, modern techniques such as word embeddings (e.g., Word2Vec and GloVe) and contextual embeddings (e.g., BERT and GPT-4) offer more advanced ways to represent and process text data. These modern techniques will also be explained in greater detail in <em class="italic">Part IV</em> of the book. Unlike traditional methods that rely on manual feature extraction, modern techniques automatically learn dense representations of words and context from their pre-training on other texts.</p>
    <p class="normal">For illustration, we will take a sample of five tweet texts and use them as examples to see the impact of traditional data preparation steps. We will also use the column width setting via <code class="inlineCode">pd.set_option</code> to show the full column width in our DataFrame, thus displaying the full tweet text:</p>
    <pre class="programlisting code"><code class="hljs-code">pd.set_option(<span class="hljs-string">"max_colwidth"</span>, <span class="hljs-literal">None</span>)
examples_idx = df.sample(<span class="hljs-number">5</span>).index <span class="hljs-comment"># [1106, 4860, 6977, 8884, 9108]</span>
df_sample = df.loc[examples_idx]
</code></pre>
    <h3 class="heading-" id="_idParaDest-119">Cleaning text data</h3>
    <p class="normal">Text cleaning <a id="_idIndexMarker404"/>enhances the quality of data analysis by removing noise and making the format of text uniform. The primary advantages include improved model accuracy and faster computation. However, it’s essential to approach cleaning carefully to avoid removing contextually important information. Cleaning is especially useful for the Twitter dataset, due to the informal and diverse nature of social media text. Tweets often contain URLs, mentions, emojis, and hashtags that can sometimes detract from the primary sentiment analysis. </p>
    <p class="normal">Our approach targets these specifics to preserve the core message while eliminating extraneous elements:</p>
    <pre class="programlisting code"><code class="hljs-code">!python -m space download en_core_web_sm
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> spacy
nlp = spacy.load(<span class="hljs-string">"en_core_web_sm"</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title">clean_text</span>(<span class="hljs-params">text</span>):
    text = re.sub(<span class="hljs-string">r'@\w+|#\w+|https?://\S+'</span>, <span class="hljs-string">''</span>, text)
    text = re.sub(<span class="hljs-string">r'[^\w\s]'</span>, <span class="hljs-string">''</span>, text)
    <span class="hljs-keyword">return</span> text.lower()
df_sample[<span class="hljs-string">'cleaned_text'</span>] = df_sample[<span class="hljs-string">'text'</span>].apply(clean_text)
df_sample[[<span class="hljs-string">"text"</span>, <span class="hljs-string">"cleaned_text"</span>]]
</code></pre>
    <p class="normal">This yields the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_02.png"/></figure>
    <p class="packt_figref">Figure 5.2: Examples of tweet text before and after cleaning</p>
    <p class="normal">Note that the removal of (<code class="inlineCode">@</code>) mentions from the text does little to detract from the context, as our<a id="_idIndexMarker405"/> dataset already has the subject of the tweet captured by the <code class="inlineCode">airline</code> column.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Additional packages for text preprocessing</strong></p>
      <p class="normal">Other useful Python tools for NLP and text preprocessing not used in this section include:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">NLTK</strong> (<a href="https://www.nltk.org/"><span class="url">https://www.nltk.org/</span></a>)</li>
        <li class="bulletList"><strong class="keyWord">TextBlob</strong> (<a href="https://textblob.readthedocs.io"><span class="url">https://textblob.readthedocs.io</span></a>)</li>
        <li class="bulletList"><strong class="keyWord">Gensim</strong> (<a href="https://radimrehurek.com/gensim/"><span class="url">https://radimrehurek.com/gensim/</span></a>)</li>
      </ul>
    </div>
    <h3 class="heading-" id="_idParaDest-120">Tokenization and stop word removal</h3>
    <p class="normal">Tokenization divides <a id="_idIndexMarker406"/>text into smaller units, such as words or phrases, making it easier for algorithms to understand language structure. Stop words are commonly used words like “is,” “and,” or “the,” and they are often removed because they add little semantic value, allowing models to focus on more meaningful content.</p>
    <p class="normal">In this implementation, we use spaCy’s model to apply both tokenization and stop word removal and show the results of each step of the process:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">tokenize_and_remove_stopwords</span>(<span class="hljs-params">row</span>):
    doc = nlp(row[<span class="hljs-string">'cleaned_text'</span>])
    all_tokens = [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc]
    tokens_without_stop = [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> token.is_stop]
    processed_text = <span class="hljs-string">'</span><span class="hljs-string"> '</span>.join(tokens_without_stop)
    row[<span class="hljs-string">'all_text_tokens'</span>] = all_tokens
    row[<span class="hljs-string">'without_stop_words_tokens'</span>] = tokens_without_stop
    row[<span class="hljs-string">'processed_text'</span>] = processed_text
    <span class="hljs-keyword">return</span> row
df_sample = df_sample.apply(tokenize_and_remove_stopwords, axis=<span class="hljs-number">1</span>)
df_sample[[<span class="hljs-string">'cleaned_text'</span>, <span class="hljs-string">'all_text_tokens'</span>, <span class="hljs-string">'without_stop_words_tokens'</span>, <span class="hljs-string">'processed_text'</span>]]
</code></pre>
    <p class="normal">This gives<a id="_idIndexMarker407"/> us the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_03.png"/></figure>
    <p class="packt_figref">Figure 5.3: Examples of tweet texts after tokenization and stop word removal</p>
    <h3 class="heading-" id="_idParaDest-121">Lemmatization</h3>
    <p class="normal">Lemmatization<a id="_idIndexMarker408"/> reduces words to their dictionary form, ensuring the outcome is a valid word. This process aims to consolidate different forms of a word to analyze them as a single item, enhancing the efficiency and accuracy of the downstream task. </p>
    <p class="normal">Looking at the last row of the below code, we see that the final lemmatized text standardizes <code class="inlineCode">wheels</code> to its singular form, <code class="inlineCode">wheel</code>, and converts <code class="inlineCode">thanks</code> to its base verb form, <code class="inlineCode">thank</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="hljs-title">lemmatize_text</span>(<span class="hljs-params">text</span>):
    doc = nlp(text)
    lemmatized = [token.lemma_ <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc]
    <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(lemmatized)
df_sample[<span class="hljs-string">'final_text'</span>] = df_sample[<span class="hljs-string">'processed_text'</span>].apply(lemmatize_text)
df_sample[[<span class="hljs-string">'processed_text'</span>, <span class="hljs-string">'final_text'</span>]]
</code></pre>
    <p class="normal">This gives us <a id="_idIndexMarker409"/>the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_04.png"/></figure>
    <p class="packt_figref">Figure 5.4: Examples of the tweet text after lemmatization</p>
    <h2 class="heading-2" id="_idParaDest-122">Class imbalance</h2>
    <p class="normal">We will now introduce<a id="_idIndexMarker410"/> why it is important to understand <a id="_idIndexMarker411"/>class balance through exploratory data analysis on our dataset. Class balance directly impacts a model’s ability to learn from data effectively. Unaddressed class imbalances can obscure insights and lead to models that do not perform as intended in real-world applications.</p>
    <p class="normal">In the following sections, we will not only quantify class imbalance but also discuss both simple and more advanced strategies to address it.</p>
    <h3 class="heading-" id="_idParaDest-123">Evaluating class balance</h3>
    <p class="normal">Identifying the <a id="_idIndexMarker412"/>overall sentiment distribution is crucial, as it helps us understand the general mood and opinions expressed in a dataset. This understanding is also essential for understanding any biases that may be present due to class imbalance.</p>
    <p class="normal">The following code groups tweets by airlines and sentiment, calculates the size of each group, and generates a bar plot to visualize the result:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
sentiment_by_airline = df.groupby([<span class="hljs-string">'airline'</span>, <span class="hljs-string">'airline_sentiment'</span>]).size().unstack().fillna(<span class="hljs-number">0</span>)
plt.figure(figsize=(<span class="hljs-number">14</span>, <span class="hljs-number">6</span>))
sentiment_by_airline.plot(kind=<span class="hljs-string">'bar'</span>, stacked=<span class="hljs-literal">True</span>, color=[<span class="hljs-string">'red'</span>, <span class="hljs-string">'yellow'</span>, <span class="hljs-string">'green'</span>])
plt.title(<span class="hljs-string">'Sentiment Distribution by Airline'</span>)
plt.xlabel(<span class="hljs-string">'Airline'</span>)
plt.ylabel(<span class="hljs-string">'Number of Tweets'</span>)
plt.xticks(rotation=<span class="hljs-number">45</span>)
plt.legend(title=<span class="hljs-string">'Sentiment'</span>)
plt.tight_layout()
plt.show()
</code></pre>
    <p class="normal">This code generates the following graph, illustrating how the airline tweets captured in this dataset are primarily <a id="_idIndexMarker413"/>negative in sentiment:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_05.png"/></figure>
    <p class="packt_figref">Figure 5.5: Distribution of tweets, grouped by airline and sentiment</p>
    <p class="normal">If we look at the class balance across the dataset, we can see there are 9,178 negative examples, 3,099 neutral examples, and 2,363 positive tweets. This can be shown via:</p>
    <pre class="programlisting code"><code class="hljs-code">df[<span class="hljs-string">'airline_sentiment'</span>].value_counts()
</code></pre>
    <p class="normal">Datasets with class imbalance are frequently encountered in real-world datasets, and therefore, we will retain this characteristic of the data throughout the chapter, allowing us to understand the<a id="_idIndexMarker414"/> impact that class imbalance can have on modeling results.</p>
    <h3 class="heading-" id="_idParaDest-124">Addressing class imbalance</h3>
    <p class="normal">The following <a id="_idIndexMarker415"/>traditional strategies can be employed to address class imbalance:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Undersampling</strong> reduces <a id="_idIndexMarker416"/>the size of the majority class to match the minority class. This helps balance the dataset but may result in the loss of valuable majority class examples.</li>
      <li class="bulletList"><strong class="keyWord">Oversampling</strong> increases the size of the minority class to match the majority class by duplicating existing examples. This improves balance but can lead to model overfitting on the repeated data examples.</li>
      <li class="bulletList"><strong class="keyWord">Synthetic Minority Over-sampling TEchnique</strong> (<strong class="keyWord">SMOTE</strong>) is similar to oversampling, except<a id="_idIndexMarker417"/> that it generates synthetic examples instead of simply duplicating existing ones. It does this by generating new instances based on examples that are similar in feature space.</li>
    </ul>
    <p class="normal">As an exercise, you can undersample the majority class (negative sentiment) to achieve a more balanced dataset. This can be achieved with the following code, where we first divide our training data into the negative, neutral, and positive classes and then downsample the negative class to match the number of examples in the minority (positive) class, resulting in a more balanced starting dataset:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.utils <span class="hljs-keyword">import</span> resample
negative = df[df.airline_sentiment == <span class="hljs-string">'negative'</span>]
neutral = df[df.airline_sentiment == <span class="hljs-string">'neutral'</span>]
positive = df[df.airline_sentiment == <span class="hljs-string">'positive'</span>]
negative_downsampled = resample(negative, n_samples=<span class="hljs-built_in">len</span>(positive))
df_downsampled = pd.concat([negative_downsampled, neutral, positive])
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Experimenting with undersampling</strong></p>
      <p class="normal">As an exercise, run the downsampling code given in the text and substitute <code class="inlineCode">df_downsampled</code> for <code class="inlineCode">df</code> in the<a id="_idIndexMarker418"/> remainder of the chapter to see how your results differ with a more balanced dataset.</p>
    </div>
    <h3 class="heading-" id="_idParaDest-125">GenAI for data augmentation</h3>
    <p class="normal">For this section, we<a id="_idIndexMarker419"/> will demonstrate a <a id="_idIndexMarker420"/>strategy to augment the underrepresented positive class by generating new examples, using a seed text via GenAI. This more novel approach complements traditional techniques to address class imbalance but with greater potential diversity in the new examples. However, using AI-generated data can introduce risks, such as overfitting to generated patterns or reflecting potential biases from the generative model itself. Ensuring a variety of seed texts can help mitigate these issues.</p>
    <p class="normal">We will utilize the <code class="inlineCode">distilgpt2</code> model from Hugging Face’s Transformers library to augment our dataset. This model, a simplified version of GPT-2, is tailored toward resource efficiency, thus making this example accessible to users with varying computational resources:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
generator = pipeline(<span class="hljs-string">'text-generation'</span>, model=<span class="hljs-string">'distilgpt2'</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title">augment_text</span>(<span class="hljs-params">text, augment_times=</span><span class="hljs-number">2</span>):
    augmented_texts = []
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(augment_times):
        generated = generator(text, max_length=<span class="hljs-number">60</span>, num_return_sequences=<span class="hljs-number">1</span>)
        new_text = generated[<span class="hljs-number">0</span>][<span class="hljs-string">'generated_text'</span>].strip()
        augmented_texts.append(new_text)
    <span class="hljs-keyword">return</span> augmented_texts
seed_text = <span class="hljs-string">"Fantastic airline service on this flight. My favorite part of the flight was"</span>
augmented_examples = augment_text(seed_text)
<span class="hljs-keyword">def</span> <span class="hljs-title">remove_extra_spaces</span>(<span class="hljs-params">text</span>):
    words = text.split()
    <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(words)
<span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> augmented_examples:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"------\n"</span>, remove_extra_spaces(example))
</code></pre>
    <p class="normal">Remember that GenAI’s probabilistic nature means that output may vary with each execution. By starting with a carefully chosen seed text of <code class="inlineCode">"</code><code class="inlineCode">Fantastic airline service on this flight. My favorite part of the flight was"</code> we are able to generate varied positive sentiments about airline services. When using this seed text in the <code class="inlineCode">text-generation</code> pipeline above, we generate outputs such as the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Fantastic airline service on this flight. My favorite part of the flight was</strong> <em class="italic">enjoying the fantastic view of all the flight attendants and the runway</em>.</li>
      <li class="bulletList"><strong class="keyWord">Fantastic airline service on this flight. My favorite part of the flight was</strong> <em class="italic">that it was the first time I ever flew in it, and it was worth it</em>.</li>
    </ul>
    <p class="normal">By default, most LLMs will produce language that’s reflective of what you’d expect to hear in everyday life. For example, try removing the end part of the seed statement “<code class="inlineCode">My favorite part of the flight was</code>" and see how much more difficult it is to have the LLM produce<a id="_idIndexMarker421"/> examples with positive<a id="_idIndexMarker422"/> sentiment.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Importance of GenAI model selection and prompt sensitivity</strong></p>
      <p class="normal">Exploring more sophisticated models available from Hugging Face, such as <code class="inlineCode">gpt-neo</code>, <code class="inlineCode">gpt-j</code>, and <code class="inlineCode">EleutherAI/gpt-neo-2.7B</code>, will yield more impressively nuanced and realistic augmentations.</p>
      <p class="normal">The choice of prompt also plays a crucial role in steering the generative model’s output. A subtle change in the seed text can lead to dramatically different results, underscoring the importance of prompt design in GenAI applications. This topic is explored in detail in <em class="chapterRef">Chapter 9</em> of this book.</p>
    </div>
    <p class="normal">While this augmentation step enhances the representation of positive sentiment tweets within our dataset, achieving true class balance would require more extensive data augmentation, as well as a variety of seed texts, to ensure that the model does not overfit on the beginning part of the tweet. We can increase the number of augmentation examples generated by changing the <code class="inlineCode">augment_times</code> parameter in the above <code class="inlineCode">augment_text()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code">augmented_data = pd.DataFrame({
    <span class="hljs-string">'text'</span>: augmented_examples,
    <span class="hljs-string">'airline_sentiment'</span>: [<span class="hljs-string">'positive'</span>] * <span class="hljs-built_in">len</span>(augmented_examples)
})
df_augmented = pd.concat([df, augmented_data], ignore_index=<span class="hljs-literal">True</span>)
</code></pre>
    <p class="normal">By carefully employing GenAI for data augmentation, we now have <code class="inlineCode">df_augmented</code> as a dataframe, with additional data that can be added to our existing dataset to mitigate class imbalance and enhance the dataset with varied expressions of positive sentiment. However, in order to illustrate the impact of the class imbalance in the original dataset on our results, we <a id="_idIndexMarker423"/>will refrain from adding these <a id="_idIndexMarker424"/>examples to our dataset.</p>
    <h1 class="heading-1" id="_idParaDest-126">Performing sentiment analysis</h1>
    <p class="normal">The power of sentiment<a id="_idIndexMarker425"/> analysis lies in its ability to uncover the emotions behind text data, providing invaluable insights into customer sentiments. While the focus of the Twitter Airline Sentiment dataset is on categorizing sentiments into positive, negative, and neutral classes, sentiment analysis can also extend beyond these basic categories. Depending on the application, sentiments can be analyzed to detect more nuanced emotional states or attitudes, such as happiness, anger, surprise, or disappointment.</p>
    <h2 class="heading-2" id="_idParaDest-127">Building your own ML model</h2>
    <p class="normal">A fundamental aspect of <a id="_idIndexMarker426"/>training sentiment analysis<a id="_idIndexMarker427"/> models, especially with traditional NLP techniques, is the necessity for pre-labeled data. These labels are typically derived from human annotations, a process that involves individuals assessing the sentiment of a piece of text and categorizing it accordingly. The sentiment scores in this Twitter dataset were collected with the help of volunteers, and some of the negative tweets were also broken down based on specific issues they highlighted, such as flight delays or poor service, providing a more nuanced view of customer dissatisfaction.</p>
    <p class="normal">Using <code class="inlineCode">scikit-learn</code>, we will construct sentiment analysis models that leverage this pre-labeled dataset. These models will utilize the text preprocessing demonstrated in the previous section to extract TF-IDF features from the text, which, in turn, serve as inputs for machine learning inferences that can predict the sentiment of unseen tweets.</p>
    <h3 class="heading-" id="_idParaDest-128">Feature engineering</h3>
    <p class="normal">Before training a <a id="_idIndexMarker428"/>model, we need to convert the text data into <a id="_idIndexMarker429"/>numerical features. One common approach is to use the <strong class="keyWord">TF-IDF</strong> (<strong class="keyWord">Term Frequency-Inverse Document Frequency</strong>) technique. TF-IDF is a statistical measure used to evaluate the<a id="_idIndexMarker430"/> importance of a word to a document in a collection or corpus. We will utilize the text preprocessing steps we performed earlier and apply the <code class="inlineCode">tfidf</code> vectorizer directly to the processed text, limiting the features to the top 1,000 terms <code class="inlineCode">(max_features=1000)</code>. This step is important because reducing dimensionality helps to simplify the model, making it faster to train and reducing the risk of overfitting. By focusing on the most relevant words, we ensure that the model captures the most significant patterns in the data while ignoring less important details:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer
df[<span class="hljs-string">'cleaned_text'</span>] = df[<span class="hljs-string">'text'</span>].apply(clean_text)
df = df.apply(tokenize_and_remove_stopwords, axis=<span class="hljs-number">1</span>)
df[<span class="hljs-string">'processed_text'</span>] = df[<span class="hljs-string">'cleaned_text'</span>].apply(tokenize_and_remove_stopwords)
df[<span class="hljs-string">'final_text'</span>] = df[<span class="hljs-string">'processed_text'</span>].apply(lemmatize_text)
tfidf_vectorizer = TfidfVectorizer(max_features=<span class="hljs-number">1000</span>)
X = tfidf_vectorizer.fit_transform(df[<span class="hljs-string">'final_text'</span>])
y = df[<span class="hljs-string">'airline_sentiment'</span>]
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Exploring feature engineering with TF-IDF</strong></p>
      <p class="normal">Another <a id="_idIndexMarker431"/>parameter to explore on<a id="_idIndexMarker432"/> your own during TF-IDF feature engineering is <code class="inlineCode">ngram_range</code>.</p>
      <p class="normal">N-grams allow you to go beyond individual words and consider pairs (bigrams) or triples (trigrams) of consecutive words as single features. This can capture more context and the relationship between words – for example, while “not” and “good” individually might not be very informative, the bigram “not good” carries a clear sentiment.</p>
    </div>
    <h3 class="heading-" id="_idParaDest-129">Model training</h3>
    <p class="normal">With our features<a id="_idIndexMarker433"/> ready, we can proceed to train a simple model using scikit-learn. Logistic regression is a simple yet powerful algorithm that works well with the dimensionality of the data contained in these short tweets. It models the probabilities for classification problems with two possible outcomes, but it can be extended to handle multiple classes, which is applicable in our case:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)
model = LogisticRegression(max_iter=<span class="hljs-number">1000</span>)
model.fit(X_train, y_train)
</code></pre>
    <p class="normal">With our logistic regression model trained, we can now interpret the model’s coefficients to obtain insight into how specific words influence sentiment classification. For each sentiment category, the coefficients represent the influence of these terms on the likelihood of a text being classified within that particular sentiment, and the magnitude represents the importance of each term in the model’s decision-making process. </p>
    <p class="normal">To accomplish this, we iterate over each class label to extract and display the most influential <a id="_idIndexMarker434"/>features, sorted by the absolute value of their coefficients:</p>
    <pre class="programlisting code"><code class="hljs-code">feature_names = tfidf_vectorizer.get_feature_names_out()
class_labels = model.classes_
<span class="hljs-keyword">for</span> index, class_label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(class_labels):
    coefficients = model.coef_[index]
    coefficients_df = pd.DataFrame({
        <span class="hljs-string">'Feature'</span>: feature_names,
        <span class="hljs-string">'Coefficient'</span>: coefficients
    })
    coefficients_df[<span class="hljs-string">'Absolute_Coefficient'</span>] = coefficients_df[<span class="hljs-string">'Coefficient'</span>].<span class="hljs-built_in">abs</span>()
    coefficients_df = coefficients_df.sort_values(by=<span class="hljs-string">'Absolute_Coefficient'</span>, ascending=<span class="hljs-literal">False</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Class: </span><span class="hljs-subst">{class_label}</span><span class="hljs-string">"</span>)
    <span class="hljs-built_in">print</span>(coefficients_df[[<span class="hljs-string">'Feature'</span>, <span class="hljs-string">'Coefficient'</span>]].head(<span class="hljs-number">10</span>))
</code></pre>
    <p class="normal">This yields the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_06.png"/></figure>
    <p class="packt_figref">Figure 5.6: Most influential features by sentiment class for the logistic regression model</p>
    <p class="normal">We can see from the <a id="_idIndexMarker435"/>above coefficients the influence of the following words on the three sentiment classes:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Negative sentiment</strong>: The word <code class="inlineCode">thank</code> <code class="inlineCode">(-3.88</code>) decreases the likelihood of a tweet being classified as negative, whereas words like <code class="inlineCode">hour</code> (<code class="inlineCode">3.61</code>), <code class="inlineCode">bad</code> (<code class="inlineCode">2.96</code>), <code class="inlineCode">delay</code> (<code class="inlineCode">2.84</code>), and <code class="inlineCode">cancel</code> (<code class="inlineCode">2.63</code>) increase this likelihood and are characteristic of complaints.</li>
      <li class="bulletList"><strong class="keyWord">Neutral sentiment</strong>: Words such as <code class="inlineCode">customer</code> (<code class="inlineCode">-2.24</code>), <code class="inlineCode">experience</code> (<code class="inlineCode">-1.91</code>), and <code class="inlineCode">fix</code> (<code class="inlineCode">-1.88</code>) decrease the likelihood of neutral classification, indicating that these terms are more often used in non-neutral contexts.</li>
      <li class="bulletList"><strong class="keyWord">Positive sentiment</strong>: Terms like <code class="inlineCode">thank</code> (<code class="inlineCode">4.36</code>), <code class="inlineCode">great</code> (<code class="inlineCode">3.54</code>), <code class="inlineCode">awesome</code> (<code class="inlineCode">3.18</code>), and <code class="inlineCode">amazing</code> (<code class="inlineCode">3.07</code>) significantly increase the likelihood of a tweet being classified as positive.</li>
    </ul>
    <h3 class="heading-" id="_idParaDest-130">Model evaluation</h3>
    <p class="normal">Evaluating our model’s<a id="_idIndexMarker436"/> performance is a critical step after training. Without proper evaluation, we risk deploying a model that may perform poorly in real-world scenarios, potentially leading to incorrect conclusions based on its predictions.</p>
    <h3 class="heading-" id="_idParaDest-131">Classification report</h3>
    <p class="normal">The classification report <a id="_idIndexMarker437"/>from scikit-learn gives us the precision, recall, and F1 score for each class. These metrics are crucial, as they tell us not just about the overall accuracy but also how well the model performs for each sentiment class:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, classification_report
y_pred = model.predict(X_test)
<span class="hljs-built_in">print</span>(classification_report(y_test, y_pred))
</code></pre>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_07.png"/></figure>
    <figure class="mediaobject">Figure 5.7: Classification report metrics evaluating logistic regression model performance</figure>
    <p class="normal">The macro average and weighted average scores give us an understanding of the model’s performance across all classes. The macro average treats all classes equally, while the weighted average takes the class imbalance into account. The differences between these scores highlight the impact of the class imbalance on the model’s performance.</p>
    <p class="normal">Let’s look more closely at the results for each class:</p>
    <ul>
      <li class="bulletList">The negative sentiment, as the majority class, has high precision (<code class="inlineCode">0.82</code>) and recall (<code class="inlineCode">0.92</code>), indicating that the model is particularly good at identifying negative tweets. This is an expected side effect of our class imbalance, since the model has more examples of this class to learn from, leading to a higher likelihood of predicting this class correctly.</li>
      <li class="bulletList">The neutral sentiment, being less represented than the negative but more than the positive, shows a significantly lower precision (<code class="inlineCode">0.61</code>) and recall (<code class="inlineCode">0.49</code>). The precision is reasonably good, meaning that when the model predicts a tweet as neutral, it’s correct a little over half the time.</li>
      <li class="bulletList">The positive sentiment, the least represented class, has a relatively high precision (<code class="inlineCode">0.79</code>) but lower recall (<code class="inlineCode">0.61</code>) than the negative class. High precision here indicates that most tweets predicted as positive are indeed positive, but the<a id="_idIndexMarker438"/> model fails to catch many positive sentiments (low recall).</li>
    </ul>
    <h4 class="heading-4">Confusion matrix</h4>
    <p class="normal">A confusion matrix is<a id="_idIndexMarker439"/> an excellent next <a id="_idIndexMarker440"/>step to further understanding a model’s performance. It shows a matrix with the actual classes on one axis and the predicted classes on the other. By analyzing the confusion matrix, we can see which classes are being confused with one another. For example, if many neutral tweets are misclassified as negative, this might suggest that the model is biased toward predicting negative and that the features for neutral tweets are not distinctive enough. We can calculate and visualize the confusion matrix using the following:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
cm = confusion_matrix(y_test, y_pred, labels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'neutral'</span>, <span class="hljs-string">'positive'</span>])
sns.heatmap(cm, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">'d'</span>, cmap=<span class="hljs-string">'Blues'</span>, xticklabels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'neutral'</span>, <span class="hljs-string">'positive'</span>], yticklabels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'neutral'</span>, <span class="hljs-string">'positive'</span>])
plt.ylabel(<span class="hljs-string">'Actual'</span>)
plt.xlabel(<span class="hljs-string">'Predicted'</span>)
plt.title(<span class="hljs-string">'Confusion Matrix'</span>)
plt.show()
</code></pre>
    <p class="normal">We can then see the following confusion matrix:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_08.png"/></figure>
    <p class="packt_figref">Figure 5.8: Confusion matrix of tweet sentiment classes for the logistic regression model</p>
    <p class="normal">Let’s break this down to understand it better:</p>
    <ul>
      <li class="bulletList">Consistent with our observations from the classification report, the model shows strong performance in correctly identifying negative tweets, as captured by the first row in the confusion matrix.</li>
      <li class="bulletList">When it comes to neutral sentiments, the second row indicates a tendency of the model to<a id="_idIndexMarker441"/> confuse <a id="_idIndexMarker442"/>neutral tweets with negative ones.</li>
      <li class="bulletList">Lastly, the third row corresponds to positive sentiments. While the model correctly identifies positive tweets more than half the time, there is still a considerable portion that is confused with negative or neutral sentiments.</li>
    </ul>
    <h4 class="heading-4">Understanding misclassifications</h4>
    <p class="normal">After assessing our <a id="_idIndexMarker443"/>model with various<a id="_idIndexMarker444"/> metrics, we can investigate examples when the model fails, giving insight into its limitations and opportunities for improvement.</p>
    <p class="normal">Let’s look at the instances where the model’s predictions clash with the trusted classifications provided by <code class="inlineCode">airline_sentiment_gold</code> data labels:</p>
    <pre class="programlisting code"><code class="hljs-code">gold_df = df[df[<span class="hljs-string">'airline_sentiment_gold'</span>].notnull()]
X_gold = tfidf_vectorizer.transform(gold_df[<span class="hljs-string">'final_text'</span>])
y_gold = gold_df[<span class="hljs-string">'airline_sentiment_gold'</span>]
y_gold_pred = model.predict(X_gold)
gold_df[<span class="hljs-string">'predicted_sentiment'</span>] = y_gold_pred
misclassified = gold_df[gold_df[<span class="hljs-string">'airline_sentiment_gold'</span>] != gold_df[<span class="hljs-string">'predicted_sentiment'</span>]]
misclassified[[<span class="hljs-string">'airline_sentiment_gold'</span>, <span class="hljs-string">'predicted_sentiment'</span>, <span class="hljs-string">'text'</span>, <span class="hljs-string">'final_text'</span>, <span class="hljs-string">'negativereason_gold'</span>]]
</code></pre>
    <p class="normal">We get the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_09.png"/></figure>
    <p class="packt_figref">Figure 5.9: Example tweets where the dataset labels disagree with model predictions from the logistic regression model</p>
    <p class="normal">An analysis of the <a id="_idIndexMarker445"/>misclassified examples <a id="_idIndexMarker446"/>demonstrates where our model’s <code class="inlineCode">predicted_sentiment</code> falls short of accurately capturing the context of the full tweet. For instance, the second misclassification example of a tweet expressing disappointment over a canceled flight, cloaked in a humorous tone, highlights the inherent challenge in detecting sarcasm and underscores the importance of model training that encompasses a wider spectrum of sentiment expressions. Then, for the last example, we have an encouraging tweet, acknowledging the opportunity for improvement from negative experiences, which is predicted to be negative. This illustrates the difficulty of TF-IDF features in a model to interpret nuanced positive sentiments, especially when intertwined with negative words. These mischaracterizations could benefit from more advanced NLP models that are capable of better discerning context and nuance, a topic we will explore in the next section on pre-trained LLMs.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Enhancing the performance of traditional sentiment models</strong></p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Address training data gaps</strong>: Ensure <a id="_idIndexMarker447"/>that your dataset includes a wide range of sentiment expressions such as sarcasm, humor, and conditional positivity. A model’s ability to accurately interpret sentiments is directly tied to the diversity of examples it has learned from. Sampling techniques, such as stratified sampling, can be used to ensure that all sentiment types are adequately represented in the training set.</li>
        <li class="bulletList"><strong class="keyWord">Understand feature representation limitations</strong>: Traditional feature representation methods like TF-IDF may not fully capture complex sentiment nuances, especially where overall sentiment is not the sum of its parts.</li>
        <li class="bulletList"><strong class="keyWord">Enhance models with contextual features</strong>: Enrich feature sets by incorporating contextual cues like n-grams or part-of-speech tagging. These additions help capture sentiment nuances by considering word order and grammatical structure.</li>
        <li class="bulletList"><strong class="keyWord">Explore more robust ML algorithms</strong>: Beyond simpler methods such as logistic regression and naive Bayes, ensemble methods like random forests and boosting algorithms (XGBoost) capture complex patterns better. Additionally, hyperparameter tuning on logistic regression (e.g., adjusting regularization strength) can significantly improve performance. Deep learning methods such as CNNs and RNNs often provide the best performance, provided there are enough training examples present.</li>
      </ul>
    </div>
    <p class="normal">Having explored various techniques to enhance traditional sentiment models, including addressing data gaps, feature<a id="_idIndexMarker448"/> representation, and<a id="_idIndexMarker449"/> appropriate algorithms, we now turn our attention to a more modern advancement in sentiment analysis, using pre-trained LLMs.</p>
    <h2 class="heading-2" id="_idParaDest-132">Using pre-trained LLMs</h2>
    <p class="normal">Before applying<a id="_idIndexMarker450"/> pre-trained LLMs for sentiment <a id="_idIndexMarker451"/>analysis, it is important to understand the concept of embeddings, which serve as the foundation for these advanced models. At their core, embeddings are dense vector representations of data, which could be anything, from words and entire documents to even images and relational data. These vectors are designed to capture the key features of data in a high-dimensional space.</p>
    <p class="normal">Early examples of NLP embeddings include Word2Vec and GloVe, which generate <strong class="keyWord">static embeddings</strong>. In <a id="_idIndexMarker452"/>Word2Vec, the embeddings are influenced by local context through techniques like skip-grams<a id="_idIndexMarker453"/> and <strong class="keyWord">continuous bag of words</strong> (<strong class="keyWord">CBOW</strong>), but once trained, the same word has the same vector representation regardless of the broader context. However, state-of-the-art LLMs like BERT and GPT introduced <a id="_idIndexMarker454"/>true <strong class="keyWord">contextual embeddings</strong>, where the representation of a word dynamically changes based on its contextual usage. The key attribute of an effective NLP embedding is that it preserves the original data’s semantic relationships in its vector space, meaning that similar vectors (words, phrases, or documents) are closer together than less similar data.</p>
    <p class="normal">Incorporating LLMs for sentiment analysis marks a significant advancement in the field of NLP, streamlining the process of understanding complex textual data. These models excel in capturing the subtleties of human language through extensive pre-training on diverse datasets, thus bypassing the need for elaborate text preprocessing, hyperparameter tuning – or even the need for pre-labeled data. For marketing professionals, this<a id="_idIndexMarker455"/> translates into a more efficient <a id="_idIndexMarker456"/>way to gauge customer sentiment across different platforms.</p>
    <h3 class="heading-" id="_idParaDest-133">Implementing pre-trained models</h3>
    <p class="normal">To demonstrate <a id="_idIndexMarker457"/>the efficacy of a pre-trained LLM, the <code class="inlineCode">sentiment-analysis</code> pipeline from the <code class="inlineCode">distilbert-base-uncased-finetuned-sst-2-english</code> model in the Transformers library will be used. DistilBERT is a smaller, faster version of BERT that retains 95% of its contextual embedding performance. This particular variant has been fine-tuned <a id="_idIndexMarker458"/>on the <strong class="keyWord">Stanford Sentiment Treebank</strong> (<strong class="keyWord">SST-2</strong>) dataset, a standard benchmark for sentiment analysis, consisting of movie reviews with human-annotated <code class="inlineCode">positive</code> or <code class="inlineCode">negative</code> sentiments.</p>
    <p class="normal">Given its binary classification nature, <code class="inlineCode">neutral</code> sentiments are excluded from our test set to align the model’s available predictions between <code class="inlineCode">positive</code> and <code class="inlineCode">negative</code>. For this example, we will also incorporate the <code class="inlineCode">time</code> and <code class="inlineCode">tqdm</code> modules into our code to track the execution time. After the model loads, inference on all of the test texts may take a few minutes to complete using the <code class="inlineCode">sentiment-analysis</code> pipeline:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> time
filtered_df = df[df[<span class="hljs-string">'airline_sentiment'</span>] != <span class="hljs-string">'neutral'</span>]
X = filtered_df[<span class="hljs-string">'text'</span>]
y = filtered_df[<span class="hljs-string">'airline_sentiment'</span>]
X_train_texts, X_test_texts, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)
sentiment_pipeline = pipeline(<span class="hljs-string">"sentiment-analysis"</span>, model=<span class="hljs-string">"distilbert-base-uncased-finetuned-sst-2-english"</span>)
start_time = time.time()
results = []
<span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> tqdm(X_test_texts, desc=<span class="hljs-string">"Analyzing sentiments"</span>):
    result = sentiment_pipeline(text)
    results.append(result[<span class="hljs-number">0</span>][<span class="hljs-string">'label'</span>].lower())
end_time = time.time()
total_time = end_time - start_time
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Total time for analyzing </span><span class="hljs-subst">{</span><span class="hljs-built_in">len</span><span class="hljs-subst">(X_test_texts)}</span><span class="hljs-string"> tweets: </span><span class="hljs-subst">{total_time:</span><span class="hljs-number">.2</span><span class="hljs-subst">f}</span><span class="hljs-string"> seconds"</span>)
</code></pre>
    <p class="normal">Utilizing the `<code class="inlineCode">sentiment-analysis</code>` pipeline for DistilBERT simplifies the sentiment analysis process by encapsulating several complex steps into one efficient process. Without this, the tokenization, text<a id="_idIndexMarker459"/> embeddings, inference, and post-processing would all need to be handled separately.</p>
    <h3 class="heading-" id="_idParaDest-134">Evaluating model performance</h3>
    <p class="normal">The classification <a id="_idIndexMarker460"/>report from the LLM inference can be obtained using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(classification_report(y_test, results))
</code></pre>
    <p class="normal">This yields the following results:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_10.png"/></figure>
    <p class="packt_figref">Figure 5.10: Classification report metrics evaluating LLM performance</p>
    <p class="normal">Next, let’s generate the confusion matrix:</p>
    <pre class="programlisting code"><code class="hljs-code">cm = confusion_matrix(y_test, results, labels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'positive'</span>])
sns.heatmap(cm, annot=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">'d'</span>, cmap=<span class="hljs-string">'Blues'</span>, xticklabels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'positive'</span>], yticklabels=[<span class="hljs-string">'negative'</span>, <span class="hljs-string">'positive'</span>])
plt.ylabel(<span class="hljs-string">'Actual'</span>)
plt.xlabel(<span class="hljs-string">'Predicted'</span>)
plt.title(<span class="hljs-string">'Confusion Matrix'</span>)
plt.show()
</code></pre>
    <p class="normal">This gives us the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_11.png"/></figure>
    <p class="packt_figref">Figure 5.11: Confusion matrix of tweet sentiment classes for the LLM</p>
    <p class="normal">When comparing the <a id="_idIndexMarker461"/>performances of the previous logistic regression model utilizing TF-IDF features and our pre-trained LLM, several observations emerge. The logistic regression model, while providing a strong baseline for sentiment analysis, has limitations in handling the nuances of natural language. While class imbalance likely played some role in the model’s performance issues, it is important to note that the LLM’s capabilities to understand language nuances, derived from its extensive pre-training and fine-tuning, likely played a larger role in its superior performance. Additionally, the logistic regression model only used unigrams for TF-IDF, which fails to capture context and contributes to mischaracterizations. For these reasons, it particularly struggles at classifying positive (and neutral) sentiments amid a dominant negative sentiment class.</p>
    <p class="normal">The LLM – keeping in mind we excluded the neutral class from its classification task to stay consistent with the nature of its fine-tuning procedure – demonstrates a more robust performance. </p>
    <p class="normal">This is showcased by its heightened accuracy in distinguishing between positive and negative sentiments. It is important to note that the logistic regression model started with imbalanced data to illustrate its impact on results, whereas the LLM did not undergo any task-specific training on the Twitter data and was trained only on the SST-2 movie reviews. The key takeaway here is that the LLM’s knowledge is generalized effectively, from movie reviews to Twitter data, highlighting its robust language understanding capabilities. With a precision of <code class="inlineCode">0.96</code> for negative sentiments and a recall rate of <code class="inlineCode">0.90</code>, the model underscores the potential of leveraging pre-trained neural networks for sentiment analysis. The improvement in positive sentiment detection, achieving a precision of <code class="inlineCode">0.68</code> and a recall of <code class="inlineCode">0.84</code>, further emphasizes the model’s predictive power.</p>
    <p class="normal">One drawback of using advanced machine-learning models like LLMs is their lack of explainability. Understanding what exactly creates negative sentiment can be challenging with these black-box models. Techniques<a id="_idIndexMarker462"/> such as <strong class="keyWord">LIME</strong> (<strong class="keyWord">local interpretable model-agnostic explanations</strong>) can be used to improve explainability. For a more detailed discussion on model transparency and techniques to elucidate LLM decisions, please refer to <em class="chapterRef">Chapter 13</em>.</p>
    <p class="normal">While the LLM performance is<a id="_idIndexMarker463"/> noteworthy, fine-tuning the LLM on the specific sentiment labels present in our airline tweets dataset would further improve its performance. Fine-tuning adapts a model more closely to a task’s unique context, allowing the model to leverage and understand the nuances of the classification task.</p>
    <p class="normal">In addition to fine-tuning, transfer learning and few-shot learning are powerful methodologies that further refine a model’s ability to classify sentiments with high accuracy. Transfer learning involves adapting a pre-trained model on a related task to perform well on the target task, even with minimal additional training data. Conversely, few-shot learning trains the model to make accurate predictions with only a few examples of the target task available.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Improving LLMs: transfer and few-shot learning</strong></p>
      <p class="normal">In <em class="italic">Part 4</em> of this book, we will explore these cutting-edge methodologies in more depth. We will explore how fine-tuning, transfer learning, and few-shot learning can be applied to pre-trained models, transforming them into highly specialized tools for domain-specific tasks like sentiment classification.</p>
    </div>
    <p class="normal">When we arrive at Part 4 of this book, we will delve deeper into related methodologies at the cutting edge of<a id="_idIndexMarker464"/> adapting pre-trained models for domain-specific tasks.</p>
    <h1 class="heading-1" id="_idParaDest-135">Translating sentiment into actionable insights</h1>
    <p class="normal">So far in this chapter, we <a id="_idIndexMarker465"/>have explored the tools and strategies needed to understand and apply sentiment analysis to your data, from the foundational techniques of data preparation and prediction using traditional NLP methods to the advanced capabilities of GenAI. In this final part of the chapter, we will discuss how these insights can be analyzed to generate actionable strategies that can guide a brand to success across all stages of a marketing campaign.</p>
    <h2 class="heading-2" id="_idParaDest-136">Creating your own dataset</h2>
    <p class="normal">Before applying <a id="_idIndexMarker466"/>this analysis to your use case, we <a id="_idIndexMarker467"/>need an approach to collecting the data that captures the underlying customer sentiment related to your brand. While this chapter utilizes the Twitter Airline dataset as an example, the techniques we’ve explored are applicable regardless of the industry or data source. This section will present the general steps you can take to curate your own proprietary dataset for analysis, whether it be from Twitter or another major data platform.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Ethics and governance in AI-enabled marketing</strong></p>
      <p class="normal">Ethics and governance<a id="_idIndexMarker468"/> in AI-enabled marketing is the topic of <em class="chapterRef">Chapter 13</em>, and it is crucial to adhere to ethical guidelines and governance frameworks that respect consumer privacy and data protection laws when collecting data. Ethical practices in marketing include obtaining consent for data collection, ensuring data anonymization to protect individual identities, and providing clear opt-out mechanisms. Companies should establish robust data governance policies that define data handling procedures and <a id="_idIndexMarker469"/>compliance with legal standards such<a id="_idIndexMarker470"/> as the EU’s <strong class="keyWord">General Data Protection Regulation</strong> (<strong class="keyWord">GDPR</strong>) or<a id="_idIndexMarker471"/> the <strong class="keyWord">California Consumer Privacy Act</strong> (<strong class="keyWord">CCPA</strong>).</p>
    </div>
    <h3 class="heading-" id="_idParaDest-137">Collecting twitter data</h3>
    <p class="normal">To start, ensure you<a id="_idIndexMarker472"/> have a Twitter<a id="_idIndexMarker473"/> Developer account and access to the Twitter (now rebranded as X) API. You can follow these steps:</p>
    <ol>
      <li class="numberedList" value="1">You’ll first need to create a project and obtain your API keys and tokens, and then, using the credentials from your Twitter Developer account (<a href="https://developer.twitter.com/en/portal/petition/essential/basic-info"><span class="url">https://developer.twitter.com/en/portal/petition/essential/basic-info</span></a>), authenticate your session to access the Twitter API. The following are general instructions to do this:
        <pre class="programlisting code"><code class="hljs-code">!pip install tweepy
<span class="hljs-keyword">import</span> tweepy
<span class="hljs-comment"># Replace these with your API keys and tokens</span>
consumer_key = <span class="hljs-string">'YOUR_CONSUMER_KEY'</span>
consumer_secret = <span class="hljs-string">'YOUR_CONSUMER_SECRET'</span>
access_token = <span class="hljs-string">'YOUR_ACCESS_TOKEN'</span>
access_token_secret = <span class="hljs-string">'YOUR_ACCESS_TOKEN_SECRET'</span>
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)
</code></pre>
      </li>
      <li class="numberedList">Now that we have access to the Twitter API, you can use the Twitter handle or relevant hashtags associated with your brand and combine this with the <code class="inlineCode">search_tweets</code> method to find relevant tweets. This example collects the latest 100 tweets mentioning <code class="inlineCode">"@YourBrandHandle"</code>:
        <pre class="programlisting code"><code class="hljs-code">query = <span class="hljs-string">"</span><span class="hljs-string">@YourBrandHandle -filter:retweets"</span>
tweets = api.search_tweets(q=query, lang=<span class="hljs-string">"en"</span>, count=<span class="hljs-number">100</span>)
</code></pre>
      </li>
    </ol>
    <div class="note">
      <p class="normal">Due to recent changes, the Twitter (X) API may have limited access, and certain endpoints may require elevated access levels. If you encounter a <code class="inlineCode">403</code> <code class="inlineCode">Forbidden</code> error, you may need to upgrade your access level or use alternative endpoints available in the API documentation. More details can be found on the Twitter developer portal (<a href="https://developer.twitter.com/en/portal/petition/essential/basic-info"><span class="url">https://developer.twitter.com/en/portal/petition/essential/basic-info</span></a>).</p>
    </div>
    <ol>
      <li class="numberedList" value="3">With the tweets collected, we can extract relevant information such as the tweet ID, text, creation time, and location. We can then structure this data into a <code class="inlineCode">pandas</code> DataFrame for easier analysis:
        <pre class="programlisting code"><code class="hljs-code">data = [{
    <span class="hljs-string">'tweet_id'</span>: tweet.<span class="hljs-built_in">id</span>,
    <span class="hljs-string">'text'</span>: tweet.text,
    <span class="hljs-string">'tweet_created'</span>: tweet.created_at,
    <span class="hljs-string">'tweet_location'</span>: tweet.user.location,
    } <span class="hljs-keyword">for</span> tweet <span class="hljs-keyword">in</span> tweets]
your_brand_df = pd.DataFrame(data)
</code></pre>
      </li>
    </ol>
    <p class="normal">There are many further metadata fields available in the API response documentation that are worth considering, including retweet count <code class="inlineCode">(tweet.retweet_count)</code>, hashtags <code class="inlineCode">(tweet.entities['hashtags'])</code>, and mentions <code class="inlineCode">(tweet.entities['user_mentions'])</code>. As discussed in the sections below, these fields can provide<a id="_idIndexMarker474"/> valuable insight into <a id="_idIndexMarker475"/>topics that are pivotal for understanding your brand’s sentiment narrative, including salient topics, tweet engagement, and virality.</p>
    <h3 class="heading-" id="_idParaDest-138">Collecting data from other platforms</h3>
    <p class="normal">Analyzing brand<a id="_idIndexMarker476"/> sentiment extends beyond Twitter, encompassing a variety of social media platforms including Facebook, Instagram, Google reviews, and more. Each platform presents unique challenges and opportunities to gather and analyze data. The approach to collecting data differs, based on each platform’s API capabilities and data availability. For platforms like Google reviews, APIs may allow you to directly access reviews and ratings. On platforms like Facebook and Instagram, you might rely on posts, comments, and hashtags to gauge sentiment.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Accessing developer APIs</strong></p>
      <p class="normal">To collect data from <a id="_idIndexMarker477"/>different social media platforms, you need to access their respective developer APIs. Here are some useful links to get you started:</p>
      <ul>
        <li class="bulletList"><strong class="keyWord">Facebook</strong>: <a href="https://developers.facebook.com/docs/graph-api "><span class="url">https://developers.facebook.com/docs/graph-api</span></a></li>
        <li class="bulletList"><strong class="keyWord">Instagram</strong>: <a href="https://developers.facebook.com/docs/instagram-api "><span class="url">https://developers.facebook.com/docs/instagram-api</span></a></li>
        <li class="bulletList"><strong class="keyWord">Reddit</strong>: <a href="https://www.reddit.com/dev/api/"><span class="url">https://www.reddit.com/dev/api/</span></a></li>
        <li class="bulletList"><strong class="keyWord">YouTube</strong>: <a href="https://developers.google.com/youtube/v3"><span class="url">https://developers.google.com/youtube/v3</span></a></li>
        <li class="bulletList"><strong class="keyWord">TikTok</strong><a href="https://developers.tiktok.com/products/research-api/"><span class="url">:https://developers.tiktok.com/products/research-api/</span></a></li>
      </ul>
    </div>
    <p class="normal">Once the data is obtained, a primary challenge can be accurately identifying mentions and discussions related to your brand. This is <a id="_idIndexMarker478"/>where <strong class="keyWord">named entity recognition </strong>(<strong class="keyWord">NER</strong>) and entity mapping techniques come into play. NER can help identify proper nouns, like brand names or <a id="_idIndexMarker479"/>products, within texts, while entity mapping can link these mentions to your brand across datasets.</p>
    <h3 class="heading-" id="_idParaDest-139">Performing NER on a dataset for a fictional retailer</h3>
    <p class="normal">For example, let’s <a id="_idIndexMarker480"/>consider <a id="_idIndexMarker481"/>a series of customer reviews from a fictional online retailer, Optimal Hiking Gear, which sells outdoor equipment. To extract mentions of the brand, we can use the built-in capabilities for NER in the spaCy language model and look for its <code class="inlineCode">ORG</code> tag to identify relevant mentions:</p>
    <pre class="programlisting code"><code class="hljs-code">nlp = spacy.load(<span class="hljs-string">"en_core_web_sm"</span>)
reviews = [
    <span class="hljs-string">"I recently purchased a sleeping bag from Optimal Hiking Gear and it exceeded my expectations."</span>,
    <span class="hljs-string">"The tent I bought from Optimal Hiking was damaged on arrival. Very disappointed."</span>,
    <span class="hljs-string">"The Optimal Hiking company makes a backpack that's the best. I've been using mine for years without any issues."</span>
]
<span class="hljs-keyword">for</span> review <span class="hljs-keyword">in</span> reviews:
    doc = nlp(review)
    <span class="hljs-keyword">for</span> ent <span class="hljs-keyword">in</span> doc.ents:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Entity: </span><span class="hljs-subst">{ent.text}</span><span class="hljs-string">, Label: </span><span class="hljs-subst">{ent.label_}</span><span class="hljs-string">"</span>)
</code></pre>
    <p class="normal">This yields the following result:</p>
    <pre class="programlisting con"><code class="hljs-con">Entity: Optimal Hiking Gear, Label: ORG
Entity: Optimal Hiking, Label: ORG
Entity: Optimal Hiking, Label: ORG
Entity: years, Label: DATE
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Enhancing NER with custom training</strong></p>
      <p class="normal">To tailor NER<a id="_idIndexMarker482"/> models more closely to your needs, consider training them with your data. This involves providing examples of texts with manually labeled entities that are specific to your brand or industry. By doing so, a model learns to recognize and categorize these custom entities more accurately. Tools like spaCy offer functionalities to train your NER models.</p>
    </div>
    <h2 class="heading-2" id="_idParaDest-140">Understanding topics and themes</h2>
    <p class="normal">This section delves<a id="_idIndexMarker483"/> into various tools to extract insights from your dataset to provide an overview of the key topics and themes present. Such insights are crucial for grasping the broader context of customer sentiment within your data. As a starting point, we can use, for reference, the number of different reasons for negative sentiment that were tagged by the annotators of this dataset:</p>
    <pre class="programlisting code"><code class="hljs-code">df.negativereason.value_counts()
</code></pre>
    <p class="normal">This gives us the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_12.png"/></figure>
    <p class="packt_figref">Figure 5.12: Counts of different negative sentiment tweets’ reasons given in the Twitter dataset</p>
    <h3 class="heading-" id="_idParaDest-141">Using word clouds</h3>
    <p class="normal"><strong class="keyWord">Word clouds</strong>, where<a id="_idIndexMarker484"/> the size of each word in a <a id="_idIndexMarker485"/>plot corresponds to its frequency of occurrence, are a valuable starting tool to visualize text data. In order to enrich our word clouds and ensure that visualizations reflect not only the most frequent terms but also those that are most indicative of unique sentiments and topics, we will incorporate TF-IDF analysis to produce our plot. By introducing the <code class="inlineCode">ngram_range=(1, 2)</code> argument into our <code class="inlineCode">tfidf_vectorizer</code>, we create both unigrams and bigrams. Leveraging the <code class="inlineCode">WordCloud</code> library, we can create word clouds via:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud
tfidf_vectorizer = TfidfVectorizer(max_features=<span class="hljs-number">1000</span>, ngram_range=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
tfidf_matrix = tfidf_vectorizer.fit_transform(df[<span class="hljs-string">'final_text'</span>])
tfidf_scores = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(tfidf_vectorizer.get_feature_names_out(), tfidf_matrix.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">0</span>).tolist()[<span class="hljs-number">0</span>]))
wordcloud_tfidf = WordCloud(width=<span class="hljs-number">800</span>, height=<span class="hljs-number">400</span>, background_color=<span class="hljs-string">'white'</span>).generate_from_frequencies(tfidf_scores)
plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))
plt.imshow(wordcloud_tfidf, interpolation=<span class="hljs-string">'bilinear'</span>)
plt.axis(<span class="hljs-string">'off'</span>)
plt.show()
</code></pre>
    <p class="normal">We’ll then see something similar to the following word cloud:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_13.png"/></figure>
    <p class="packt_figref">Figure 5.13: Word clouds showing the frequency of occurrence of different terms from TF-IDF analysis</p>
    <p class="normal">The analysis so far reveals pivotal themes through prevalent words such as <code class="inlineCode">delay</code>, <code class="inlineCode">cancel</code>, and <code class="inlineCode">help</code>. Through the inclusion of bigrams, key terms such as <code class="inlineCode">customer service</code> and <code class="inlineCode">cancel flight</code> can also be captured. In the context of Twitter data, hashtags offer a<a id="_idIndexMarker486"/> direct glimpse into the core topics and sentiments expressed. To dive deeper, we will proceed to extract hashtags from the tweets, creating a word cloud to visualize these key phrases differently. This approach aims to provide a different lens to view the themes within our dataset:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> nltk
<span class="hljs-keyword">def</span> <span class="hljs-title">extract_hashtags</span>(<span class="hljs-params">text</span>):
    <span class="hljs-keyword">return</span> re.findall(<span class="hljs-string">r"#(\w+)"</span>, text)
hashtags = <span class="hljs-built_in">sum</span>(df[<span class="hljs-string">'text'</span>].apply(extract_hashtags).tolist(), [])
hashtag_freq_dist = nltk.FreqDist(hashtags)
wordcloud_hashtags = WordCloud(width=<span class="hljs-number">800</span>, height=<span class="hljs-number">400</span>, background_color=<span class="hljs-string">'white'</span>).generate_from_frequencies(hashtag_freq_dist)
plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>))
plt.imshow(wordcloud_hashtags, interpolation=<span class="hljs-string">'bilinear'</span>)
plt.axis(<span class="hljs-string">'off'</span>)
plt.show()
</code></pre>
    <p class="normal">We then see <a id="_idIndexMarker487"/>the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_14.png"/></figure>
    <p class="packt_figref">Figure 5.14: Word clouds showing the frequency of occurrence of Twitter hashtags</p>
    <p class="normal">Excluding direct airline mentions, the word cloud distinctly highlights prevalent negative sentiments through hashtags like <code class="inlineCode">#Fail</code>, <code class="inlineCode">#Disappointed</code>, and <code class="inlineCode">#BadCustomerService</code>. In contrast to these, <code class="inlineCode">#DestinationDragons</code> emerges prominently as well, signifying a well-publicized tour<a id="_idIndexMarker488"/> by <a id="_idIndexMarker489"/>Southwest Airlines, showcasing the duality of customer feedback captured in our dataset.</p>
    <h3 class="heading-" id="_idParaDest-142">Discovering latent topics with LDA</h3>
    <p class="normal"><strong class="keyWord">Latent Dirichlet allocation</strong> (<strong class="keyWord">LDA</strong>) is an<a id="_idIndexMarker490"/> advanced<a id="_idIndexMarker491"/> technique that goes beyond simple frequency metrics, like those seen in word clouds, by identifying the underlying topics within a text corpus through unsupervised machine learning. Unlike word clouds, which only highlight the most frequent words, LDA discerns the hidden thematic structure by considering documents as mixtures of topics, where each topic is defined by a particular set of words. This process involves Bayesian inference, using the Dirichlet distribution to estimate not just the presence but also the proportion of topics within documents. For example, in a collection of hotel reviews, LDA might identify topics related to location, parking, bathroom cleanliness, and check-in experience. The sophistication of LDA lies in its ability to capture the context and co-occurrence of words across the corpus, providing a more nuanced understanding of the text’s thematic content without prior labeling. </p>
    <p class="normal">We can implement this approach via:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> LatentDirichletAllocation
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer
count_vect = CountVectorizer(max_df=<span class="hljs-number">0.95</span>, min_df=<span class="hljs-number">2</span>, stop_words=<span class="hljs-string">'english'</span>)
doc_term_matrix = count_vect.fit_transform(df[<span class="hljs-string">'final_text'</span>])
LDA = LatentDirichletAllocation(n_components=<span class="hljs-number">5</span>, random_state=<span class="hljs-number">42</span>)
LDA.fit(doc_term_matrix)
<span class="hljs-keyword">for</span> i, topic <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(LDA.components_):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Top words for topic #</span><span class="hljs-subst">{i}</span><span class="hljs-string">:"</span>)
    <span class="hljs-built_in">print</span>([count_vect.get_feature_names_out()[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> topic.argsort()[-<span class="hljs-number">10</span>:]])
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"\n"</span>)
</code></pre>
    <p class="normal">This gives us the<a id="_idIndexMarker492"/> following output:</p>
    <pre class="programlisting con"><code class="hljs-con">Top words for topic #0:
['fly', 'follow', 'send', 'dm', 'flight', 'hour', 'sit', 'gate', 'seat', 'plane']
Top words for topic #1:
['tomorrow', 'change', 'amp', 'time', 'late', 'delay', 'fly', 'flightle', 'cancel', 'flight']
Top words for topic #2:
['response', 'bad', 'good', 'time', 'flight', 'bag', 'great', 'customer', 'service', 'thank']
Top words for topic #3:
['wait', 'need', 'help', 'problem', 'delay', 'luggage', 'hour', 'miss', 'bag', 'flight']
Top words for topic #4:
['service', 'number', 'customer', 'minute', 'email', 'hour', 'help', 'try', 'phone', 'hold']
</code></pre>
    <p class="normal">Analyzing the clusters generated by LDA allows us to pinpoint important themes in the tweets, such as flight delays and customer service issues, represented in topics <code class="inlineCode">#1</code> and <code class="inlineCode">#2</code>, respectively. By changing the <code class="inlineCode">n_components</code> parameter, we can alter the algorithm’s assumption around the number of topics present, leading to more granular topics as the parameter increases in value.</p>
    <p class="normal">It’s important to recognize that not all topics identified by LDA will directly align with key sentiment expressions, and some may simply reflect common, non-specific language pervasive throughout the dataset, as seen in topic <code class="inlineCode">#0</code>. </p>
    <p class="normal">To extract meaningful insights, additional scrutiny is often required to discern which topics are most relevant for analysis. This process <a id="_idIndexMarker493"/>can be facilitated<a id="_idIndexMarker494"/> either through human review or by employing a carefully designed prompt for a language model, helping to summarize the word groupings according to their possible topics.</p>
    <h2 class="heading-2" id="_idParaDest-143">Temporal trends: tracking the brand narrative</h2>
    <p class="normal">In the dynamic realm <a id="_idIndexMarker495"/>of social media, the <a id="_idIndexMarker496"/>viral nature of tweets often acts as a barometer for the sentiments that are most impactful to a brand’s perception. This is especially true for negative sentiments, which carry a substantial risk to a brand’s image. By scrutinizing the Twitter activity around airlines, such as JetBlue, we can unearth insights into tweets that may significantly influence brand reputation.</p>
    <div class="note">
      <p class="normal">This paper presents a social media-based brand reputation tracker that monitors brand events in real time and connects them to specific drivers of brand reputation: <a href="https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f"><span class="url">https://ora.ox.ac.uk/objects/uuid:00e9fcb7-9bf1-486a-b4dd-3c1d086af24e/files/rz316q188f</span></a>.</p>
    </div>
    <p class="normal">This analysis involves sifting through tweets mentioning the <code class="inlineCode">@JetBlue</code> handle. The code below categorizes the sentiment of these tweets over time, where each data point’s bubble size corresponds<a id="_idIndexMarker497"/> to that day’s aggregate retweets, providing a visual scale of engagement:</p>
    <pre class="programlisting code"><code class="hljs-code">df[<span class="hljs-string">'tweet_created'</span>] = pd.to_datetime(df[<span class="hljs-string">'tweet_created'</span>]).dt.tz_convert(<span class="hljs-literal">None</span>)
df[<span class="hljs-string">'date'</span>] = df[<span class="hljs-string">'tweet_created'</span>].dt.date
airline_handle = <span class="hljs-string">"@JetBlue"</span>
airline_tweets = df[df.text.<span class="hljs-built_in">str</span>.contains(airline_handle)]
grouped = airline_tweets.groupby([<span class="hljs-string">'airline_sentiment'</span>, <span class="hljs-string">'date'</span>]).agg({<span class="hljs-string">'tweet_id'</span>:<span class="hljs-string">'count'</span>, <span class="hljs-string">'retweet_count'</span>:<span class="hljs-string">'</span><span class="hljs-string">sum'</span>}).reset_index()
positive_tweets = grouped[grouped[<span class="hljs-string">'airline_sentiment'</span>] == <span class="hljs-string">'positive'</span>]
neutral_tweets = grouped[grouped[<span class="hljs-string">'airline_sentiment'</span>] == <span class="hljs-string">'neutral'</span>]
negative_tweets = grouped[grouped[<span class="hljs-string">'airline_sentiment'</span>] == <span class="hljs-string">'negative'</span>]
plt.figure(figsize=(<span class="hljs-number">14</span>, <span class="hljs-number">7</span>))
scale_factor = <span class="hljs-number">3</span>
<span class="hljs-keyword">for</span> tweets, sentiment, color, linestyle <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(
    [positive_tweets, neutral_tweets, negative_tweets],
    [<span class="hljs-string">'Positive'</span>, <span class="hljs-string">'Neutral'</span>, <span class="hljs-string">'Negative'</span>],
    [<span class="hljs-string">'green'</span>, <span class="hljs-string">'orange'</span>, <span class="hljs-string">'red'</span>],
    [<span class="hljs-string">'-'</span>, <span class="hljs-string">'</span><span class="hljs-string">--'</span>, <span class="hljs-string">'-.'</span>]
):
    scaled_retweet_count = tweets[<span class="hljs-string">'retweet_count'</span>] * scale_factor
    plt.plot(tweets[<span class="hljs-string">'date'</span>], tweets[<span class="hljs-string">'tweet_id'</span>], linestyle=linestyle, label=sentiment, color=color)
    plt.scatter(tweets[<span class="hljs-string">'date'</span>], tweets[<span class="hljs-string">'tweet_id'</span>], scaled_retweet_count, color=color)
plt.title(<span class="hljs-string">f'Daily Sentiment Trend for </span><span class="hljs-subst">{airline_handle}</span><span class="hljs-string"> with Bubble Size Indicating Retweets'</span>)
plt.xlabel(<span class="hljs-string">'Date'</span>)
plt.ylabel(<span class="hljs-string">'</span><span class="hljs-string">Number of Tweets'</span>)
plt.legend()
plt.xticks(rotation=<span class="hljs-number">45</span>)
plt.tight_layout()
plt.show()
</code></pre>
    <p class="normal">This yields the<a id="_idIndexMarker498"/> following graph:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_15.png"/></figure>
    <p class="packt_figref">Figure 5.15: Sentiment of JetBlue tweets over time, where each data point’s bubble size corresponds to that day’s aggregate retweets</p>
    <p class="normal">Significant peaks in negative sentiment tweets are observed on February 22 and 23, with an unusual surge in retweets on the latter day indicating widespread engagement. Those focusing on brand reputation for JetBlue may find it valuable to delve into the specifics of these<a id="_idIndexMarker499"/> tweets. </p>
    <p class="normal">We can aggregate<a id="_idIndexMarker500"/> and rank the tweets in this date range, as well as the day before, according to those with the highest retweets, using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">dates_of_interest = [pd.to_datetime(<span class="hljs-string">'2015-02-22'</span>).date(), pd.to_datetime(<span class="hljs-string">'2015-02-23'</span>).date(), pd.to_datetime(<span class="hljs-string">'2015-02-24'</span>).date()]
filtered_df = airline_tweets[(airline_tweets[<span class="hljs-string">'date'</span>].isin(dates_of_interest)) &amp; (airline_tweets[<span class="hljs-string">'airline_sentiment'</span>] == <span class="hljs-string">'negative'</span>)]
top_tweets_per_date = filtered_df.groupby(<span class="hljs-string">'date'</span>).apply(<span class="hljs-keyword">lambda</span> x: x.nlargest(<span class="hljs-number">3</span>, <span class="hljs-string">'retweet_count'</span>))
top_tweets_per_date[[<span class="hljs-string">'text'</span>, <span class="hljs-string">'retweet_count'</span>, <span class="hljs-string">'negativereason'</span>]]
</code></pre>
    <p class="normal">This gives us the following result:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_16.png"/></figure>
    <p class="packt_figref">Figure 5.16: Analysis of peak negative sentiment tweets for JetBlue on February 22–24, 2015</p>
    <p class="normal">The first and last day of the result reveal typical grievances, like late flights and poor service, that are common in the airline industry. However, the backlash on February 23 highlights a controversy around a marketing campaign by JetBlue, encapsulated by the phrase “Our fleet’s on fleek.” As discussed in the introduction to this chapter, real-time monitoring of brand perception would have enabled them to track this shift in campaign sentiment early on, enabling them to anticipate and potentially mitigate the PR issues that ensued.</p>
    <p class="normal">The potential long-term repercussions of this negative publicity would necessitate further monitoring and analysis – using metrics such as the KPIs discussed in <em class="chapterRef">Chapter 2</em> – to assess the <a id="_idIndexMarker501"/>impact on brand <a id="_idIndexMarker502"/>reputation. Nonetheless, this analysis illustrates the importance of monitoring social media trends over time to preemptively address issues that could adversely affect brand perception.</p>
    <h2 class="heading-2" id="_idParaDest-144">Mapping sentiments using geospatial analysis</h2>
    <p class="normal">Geospatial analysis <a id="_idIndexMarker503"/>offers a <a id="_idIndexMarker504"/>powerful lens through which to view customer sentiment, enabling companies to identify areas of concern – from customer service issues to poorly designed marketing campaigns — potentially even before such issues become apparent to on-site staff. To illustrate how to generate such insights, let’s utilize the <code class="inlineCode">folium</code> package to create a heat map that pinpoints the origins of negative sentiments, based on tweet coordinates:</p>
    <pre class="programlisting code"><code class="hljs-code">!pip install folium
<span class="hljs-keyword">import</span> folium
<span class="hljs-keyword">from</span> folium.plugins <span class="hljs-keyword">import</span> HeatMap
filtered_df = df[(df[<span class="hljs-string">'text'</span>].<span class="hljs-built_in">str</span>.contains(<span class="hljs-string">'</span><span class="hljs-string">@JetBlue'</span>) &amp; (df[<span class="hljs-string">'airline_sentiment'</span>] == <span class="hljs-string">'negative'</span>))]
filtered_df = filtered_df.dropna(subset=[<span class="hljs-string">'tweet_coord'</span>])
valid_coords = []
<span class="hljs-keyword">for</span> coord <span class="hljs-keyword">in</span> filtered_df[<span class="hljs-string">'tweet_coord'</span>]:
    <span class="hljs-keyword">try</span>:
        lat, long = <span class="hljs-built_in">eval</span>(coord)
        valid_coords.append((lat, long))
    <span class="hljs-keyword">except</span> (TypeError, SyntaxError, NameError):
        <span class="hljs-keyword">continue</span>
<span class="hljs-keyword">if</span> valid_coords:
    map_center = [<span class="hljs-built_in">sum</span>(x)/<span class="hljs-built_in">len</span>(valid_coords) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*valid_coords)]
<span class="hljs-keyword">else</span>:
    map_center = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
tweet_map = folium.Map(location=map_center, zoom_start=<span class="hljs-number">4</span>)
HeatMap(valid_coords).add_to(tweet_map)
tweet_map
</code></pre>
    <p class="normal">This code <a id="_idIndexMarker505"/>yields the <a id="_idIndexMarker506"/>following map:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_05_17.png"/></figure>
    <p class="packt_figref">Figure 5.17: Heat map that pinpoints the origins of negative JetBlue sentiments, based on tweet coordinates</p>
    <p class="normal">The resulting heat map reveals concentrations of negative sentiment in regions where JetBlue predominantly operates – a correlation that is expected, given that a greater volume of flights naturally leads to more reports of negative experiences. However, by looking at the time evolution of these patterns, we can see that this method can serve as a real-time tool to spot unusual patterns of sentiment.</p>
    <p class="normal">For instance, a sudden influx of negative tweets from a new location could signal service issues and foreshadow potential PR challenges to follow. Conversely, identifying areas with a high number <a id="_idIndexMarker507"/>of positive <a id="_idIndexMarker508"/>tweets might highlight strengths within a company. Coupling geospatial analysis with the topic modeling approaches introduced earlier can also unlock further insights, revealing not only what is discussed but also where these conversations take place, providing a valuable trove of actionable marketing intelligence.</p>
    <h1 class="heading-1" id="_idParaDest-145">Summary</h1>
    <p class="normal">This chapter underscored the importance of sentiment analysis in modern marketing strategies. It introduced sentiment analysis as a key tool to interpret vast quantities of unstructured text data, such as social media conversations, to refine marketing strategies, brand messaging, or customer experience. By utilizing the Twitter Airline dataset, we covered the end-to-end process needed to classify sentiment as positive or negative, using both traditional NLP and more advanced GenAI methods involving pre-trained LLMs. We then covered an array of tools for the visualization and interpretation of these results to derive actionable marketing insights. This chapter should leave you equipped with the necessary skills to harness sentiment analysis effectively, for applications ranging from brand reputation monitoring to aligning marketing messages with customer preferences.</p>
    <p class="normal">Looking ahead to the next chapter, we will progress from understanding customer sentiment to actively shaping customer engagement using predictive analytics, with a focus on the empirical validation of marketing strategies through A/B testing. We will discuss identifying features to predict customer engagement, training machine learning models, model evaluation, and the implementation of A/B testing. The chapter is designed to advance your knowledge by providing skills in feature selection, building predictive models, optimizing model performance, conducting A/B tests, and integrating insights into effective marketing strategies. This next step will equip you with the ability to not only forecast customer behaviors but also empirically validate and refine marketing strategies for heightened effectiveness.</p>
    <h1 class="heading-1">Join our book’s Discord space</h1>
    <p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</p>
    <p class="normal"><a href="https://packt.link/genai"><span class="url">https://packt.link/genai</span></a></p>
    <p class="normal"><img alt="" src="../Images/QR_Code12856128601808671.png"/></p>
  </div>
</body></html>