- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is about machine learning, the functional approach to programming
    with Scala being the focus, and big data with Spark being the target. When I was
    offered to write the book about nine months ago, my first reaction was that, while
    each of the mentioned subjects have been thoroughly investigated and written about,
    I've definitely taken part in enough discussions to know that combining any pair
    of them presents challenges, not to mention combining all three of them in one
    book. The challenge piqued my interest, and the result is this book. Not every
    chapter is as smooth as I wished it to be, but in the world where technology makes
    huge strides every day, this is probably expected. I do have a real job and writing
    is only one way to express my ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with machine learning. Machine learning went through a head-spinning
    transformation; it was an offspring of AI and statistics somewhere in the 1990s
    and later gave birth to data science in or slightly before 2010\. There are many
    definitions of data science, but the most popular one is probably from Josh Wills,
    with whom I had the privilege to work at Cloudera, which is depicted in *Figure
    1*. While the details may be argued about, the truth is that data science is always
    on the intersection of a few disciplines, and a data scientist is not necessarily
    is an expert on any one of them. Arguably, the first data scientists worked at
    Facebook, according to Jeff Hammerbacher, who was also one of the Cloudera founders
    and an early Facebook employee. Facebook needed interdisciplinary skills to extract
    value from huge amounts of social data at the time. While I call myself a big
    data scientist, for the purposes of this book, I'd like to use the term machine
    learning or ML to keep the focus, as I am mixing too much already here.
  prefs: []
  type: TYPE_NORMAL
- en: One other aspect of ML that came about recently and is actively discussed is
    that the quantity of data beats the sophistication of the models. One can see
    this in this book in the example of some Spark MLlib implementations, and word2vec
    for NLP in particular. Speedier ML models that can respond to new environments
    faster also often beat the more complex models that take hours to build. Thus,
    ML and big data make a good match.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least is the emergence of microservices. I spent a great deal of
    time on the topic of machine and application communication in this book, and Scala
    with the Akka actors model comes very naturally here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Functional programming, at least for a good portion of practical programmers,
    is more about the style of programming than a programming language itself. While
    Java 8 started having lambda expressions and streams, which came out of functional
    programming, one can still write in a functional style without these mechanisms
    or even write a Java-style code in Scala. The two big ideas that brought Scala
    to prominence in the big data world are lazy evaluation, which greatly simplifies
    data processing in a multi-threaded or distributed world, and immutability. Scala
    has two different libraries for collections: one is mutable and another is immutable.
    While the distinction is subtle from the application user point of view, immutability
    greatly increases the options from a compiler perspective, and lazy evaluation
    cannot be a better match for big data, where REPL postpones most of the number
    crunching towards later stages of the pipeline, increasing interactivity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Preface](img/B04935_00_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: One of the possible definitions of a data scientist'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, big data. Big data has definitely occupied the headlines for a couple
    of years now, and a big reason for this is that the amount of data produced by
    machines today greatly surpasses anything that a human cannot even produce, but
    even comprehend, without using the computers. The social network companies, such
    as Facebook, Google, Twitter, and so on, have demonstrated that enough information
    can be extracted from these blobs of data to justify the tools specifically targeted
    towards processing big data, such as Hadoop, MapReduce, and Spark.
  prefs: []
  type: TYPE_NORMAL
- en: We will touch on what Hadoop does later in the book, but originally, it was
    a Band-Aid on top of commodity hardware to be able to deal with a vast amount
    of information, which the traditional relational DBs at the time were not equipped
    to handle (or were able, but at a prohibitive price). While big data is probably
    too big a subject for me to handle in this book, Spark is the focus and is another
    implementation of Hadoop MapReduce that removes a few inefficiencies of having
    to deal with persisting data on disk. Spark is a bit more expensive as it consumes
    more memory in general and the hardware has to be more reliable, but it is more
    interactive. Furthermore, Spark works on top of Scala—other languages such as
    Java and Python too—but Scala is the primary API language, and it found certain
    synergies in how it expresses data pipelines in Scala.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.xhtml "Chapter 1. Exploratory Data Analysis"), *Exploratory
    Data Analysis,* covers howevery data analyst begins with an exploratory data analysis.
    There is nothing new here, except that the new tools allow you to look into larger
    datasets—possibly spread across multiple computers, as easily as if they were
    just on a local machine. This, of course, does not prevent you from running the
    pipeline on a single machine, but even then, the laptop I am writing this on has
    four cores and about 1,377 threads running at the same time. Spark and Scala (parallel
    collections) allow you to transparently use this entire dowry, sometimes without
    explicitly specifying the parallelism. Modern servers may have up to 128 hyper-threads
    available to the OS. This chapter will show you how to start with the new tools,
    maybe by exploring your old datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.xhtml "Chapter 2. Data Pipelines and Modeling"), *Data Pipelines
    and Modeling*, explains that while data-driven processes existed long before Scala/Spark,
    the new age demonstrated the emergence of a fully data-driven enterprise where
    the business is optimized by the feedback from multiple data-generating machines.
    Big data requires new techniques and architectures to accommodate the new decision
    making process. Borrowing from a number of academic fields, this chapter proceeds
    to describe a generic architecture of a data-driven business, where most of the
    workers'' task is monitoring and tuning the data pipelines (or enjoying the enormous
    revenue per worker that these enterprises can command).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.xhtml "Chapter 3. Working with Spark and MLlib"), *Working
    with Spark and MLlib*, focuses on the internal architecture of Spark, which we
    mentioned earlier as a replacement for and/or complement to Hadoop MapReduce.
    We will specifically stop on a few ML algorithms, which are grouped under the
    MLlib tag. While this is still a developing topic and many of the algorithms are
    being moved using a different package now, we will provide a few examples of how
    to run standard ML algorithms in the `org.apache.spark.mllib` package. We will
    also explain the modes that Spark can be run under and touch on Spark performance
    tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ch04.xhtml "Chapter 4. Supervised and Unsupervised Learning"),
    *Supervised and Unsupervised Learning*, explains that while Spark MLlib may be
    a moving target, general ML principles have been solidly established. Supervised/unsupervised
    learning is a classical division of ML algorithms that work on row-oriented data—most
    of the data, really. This chapter is a classic part of any ML book, but we spiced
    it up a bit to make it more Scala/Spark-oriented.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](ch05.xhtml "Chapter 5. Regression and Classification"), *Regression
    and Classification*, introduces regression and classification, which is another
    classic subdivision of the ML algorithms, even if it has been shown that classification
    can be used to regress, and regression to classify, still these are the two classes
    that use different techniques, precision metrics, and ways to regularize the models.
    This chapter will take a practical approach while showing you practical examples
    of regression and classification analysis'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.xhtml "Chapter 6. Working with Unstructured Data"), *Working
    with Unstructured Data,* covers how one of the new features that social data brought
    with them and brought traditional DBs to their knees is nested and unstructured
    data. Working with unstructured data requires new techniques and formats, and
    this chapter is dedicated to the ways to present, store, and evolve these types
    of data. Scala becomes a big winner here, as it has a natural way to deal with
    complex data structures in the data pipelines.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.xhtml "Chapter 7. Working with Graph Algorithms"), *Working
    with Graph Algorithms*, explains how graphs present another challenge to the traditional
    row-oriented DBs. Lately, there has been a resurgence of graph DBs. We will cover
    two different libraries in this chapter: one is Scala-graph from Assembla, which
    is a convenient tool to represent and reason with graphs, and the other is Spark''s
    graph class with a few graph algorithms implemented on top of it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](ch08.xhtml "Chapter 8. Integrating Scala with R and Python"), *Integrating
    Scala with R and Python*, covers how even though Scala is cool, many people are
    just too cautious to leave their old libraries behind. In this chapter, I will
    show how to transparently refer to the legacy code written in R and Python, a
    request I hear too often. In short, there are too mechanisms: one is using Unix
    pipelines and another way is to launch R or Python in JVM.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 9](ch09.xhtml "Chapter 9. NLP in Scala"), *NLP in Scala*, focuses
    on how natural language processing has deal with human-computer interaction and
    computer''s understanding of our often-substandard ways to communicate. I will
    focus on a few tools that Scala specifically provide for NLP, topic association,
    and dealing with large amounts of textual information (Spark).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 10](ch10.xhtml "Chapter 10. Advanced Model Monitoring"), *Advanced
    Model Monitoring*, introduces how developing data pipelines usually means that
    someone is going to use and debug them. Monitoring is extremely important not
    only for the end user data pipeline, but also for the developer or designer who
    is looking for the ways to either optimize the execution or further the design.
    We cover the standard tools for monitoring systems and distributed clusters of
    machines as well as how to design a service that has enough hooks to look into
    its functioning without attaching a debugger. I will also touch on the new emerging
    field of statistical model monitoring.'
  prefs: []
  type: TYPE_NORMAL
- en: What you need for this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is based on open source software. First, it's Java. One can download
    Java from Oracle's Java Download page. You have to accept the license and choose
    an appropriate image for your platform. Don't use OpenJDK—it has a few problems
    with Hadoop/Spark.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, Scala. If you are using Mac, I recommend installing Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Multiple open source packages will also be available to you. To install Scala,
    run `brew install scala`. Installation on a Linux platform requires downloading
    an appropriate Debian or RPM package from the [http://www.scala-lang.org/download/](http://www.scala-lang.org/download/)
    site. We will use the latest version at the time, that is, 2.11.7.
  prefs: []
  type: TYPE_NORMAL
- en: Spark distributions can be downloaded from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
    We use pre-build for Hadoop 2.6 and later image. As it's Java, you need to just
    unzip the package and start using the scripts from the `bin` subdirectory.
  prefs: []
  type: TYPE_NORMAL
- en: R and Python packages are available at [http://cran.r-project.org/bin](http://cran.r-project.org/bin)
    and `http://python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tar.xz`
    sites respectively. The text has specific instruction on how to configure them.
    Although our use of the packages should be version agnostic, I used R version
    3.2.3 and Python version 2.7.11 in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Professional and emerging data scientists who want to sharpen their skills
    and see practical examples of working with big data: a data analyst who wants
    to effectively extract actionable information from large amounts of data and an
    aspiring statistician who is willing to get beyond the existing boundaries and
    become a data scientist.'
  prefs: []
  type: TYPE_NORMAL
- en: The book style is pretty much hands-on, I don't delve into mathematical proofs
    or validations, with a few exceptions, and there are more in-depth texts that
    I recommend throughout the book. However, I will try my best to provide code samples
    and tricks that you can start using for the standard techniques and libraries
    as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "We
    can include other contexts through the use of the `include` directive."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "Run all cells at once by navigating to **Cell** | **Run All**."'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings or important notes appear in a box like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Reader feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of.
  prefs: []
  type: TYPE_NORMAL
- en: To send us general feedback, simply e-mail `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book's title in the subject of your message.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  prefs: []
  type: TYPE_NORMAL
- en: Customer support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the example code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the code files by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in or register to our website using your e-mail address and password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Code Downloads & Errata**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the name of the book in the **Search** box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the book for which you're looking to download the code files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose from the drop-down menu where you purchased this book from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Code Download**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  prefs: []
  type: TYPE_NORMAL
- en: WinRAR / 7-Zip for Windows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipeg / iZip / UnRarX for Mac
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7-Zip / PeaZip for Linux
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning](https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning).
    We also have other code bundles from our rich catalog of books and videos available
    at. [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the color images of this book
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Errata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  prefs: []
  type: TYPE_NORMAL
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  prefs: []
  type: TYPE_NORMAL
- en: Piracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  prefs: []
  type: TYPE_NORMAL
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  prefs: []
  type: TYPE_NORMAL
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have a problem with any aspect of this book, you can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`,
    and we will do our best to address the problem.
  prefs: []
  type: TYPE_NORMAL
