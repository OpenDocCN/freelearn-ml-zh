- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: This book is about machine learning, the functional approach to programming
    with Scala being the focus, and big data with Spark being the target. When I was
    offered to write the book about nine months ago, my first reaction was that, while
    each of the mentioned subjects have been thoroughly investigated and written about,
    I've definitely taken part in enough discussions to know that combining any pair
    of them presents challenges, not to mention combining all three of them in one
    book. The challenge piqued my interest, and the result is this book. Not every
    chapter is as smooth as I wished it to be, but in the world where technology makes
    huge strides every day, this is probably expected. I do have a real job and writing
    is only one way to express my ideas.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是关于机器学习的，以Scala的函数式编程方法为重点，以Spark大数据处理为目标。大约九个月前，当我被邀请撰写这本书时，我的第一个反应是，虽然上述提到的每个主题都已经被彻底研究和撰写过，但我确实参与过足够的讨论，知道将任何两个主题结合起来都会面临挑战，更不用说将这三个主题全部结合在一本书中。这个挑战激起了我的兴趣，结果就是这本书。并非每一章都像我期望的那样流畅，但在每天技术都有巨大进步的世界里，这可能是在所难免的。我确实有一份真正的工作，写作只是表达我想法的一种方式。
- en: Let's start with machine learning. Machine learning went through a head-spinning
    transformation; it was an offspring of AI and statistics somewhere in the 1990s
    and later gave birth to data science in or slightly before 2010\. There are many
    definitions of data science, but the most popular one is probably from Josh Wills,
    with whom I had the privilege to work at Cloudera, which is depicted in *Figure
    1*. While the details may be argued about, the truth is that data science is always
    on the intersection of a few disciplines, and a data scientist is not necessarily
    is an expert on any one of them. Arguably, the first data scientists worked at
    Facebook, according to Jeff Hammerbacher, who was also one of the Cloudera founders
    and an early Facebook employee. Facebook needed interdisciplinary skills to extract
    value from huge amounts of social data at the time. While I call myself a big
    data scientist, for the purposes of this book, I'd like to use the term machine
    learning or ML to keep the focus, as I am mixing too much already here.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从机器学习开始。机器学习经历了一场令人眼花缭乱的变革；它在20世纪90年代左右是人工智能和统计学的产物，并在2010年或稍早的时候孕育了数据科学。关于数据科学的定义有很多，但最流行的一个可能是Josh
    Wills的定义，我在Cloudera与他共事过，这在*图1*中有描述。虽然细节可能会有争议，但事实是，数据科学始终处于几个学科的交汇点上，数据科学家不一定是其中任何一个学科的专家。据Jeff
    Hammerbacher所说，Facebook是第一个数据科学家工作的地方，他是Cloudera的创始人之一，也是Facebook的早期员工。当时Facebook需要跨学科技能来从大量社交数据中提取价值。虽然我称自己为大数据科学家，但为了这本书的目的，我愿意使用机器学习或ML这个术语来保持重点，因为我已经混合了太多的内容。
- en: One other aspect of ML that came about recently and is actively discussed is
    that the quantity of data beats the sophistication of the models. One can see
    this in this book in the example of some Spark MLlib implementations, and word2vec
    for NLP in particular. Speedier ML models that can respond to new environments
    faster also often beat the more complex models that take hours to build. Thus,
    ML and big data make a good match.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最近ML（机器学习）的一个方面是数据量超过了模型的复杂性。你可以在这本书中看到一些Spark MLlib实现的例子，特别是NLP中的word2vec。能够更快地响应新环境的ML模型也经常打败那些需要数小时才能构建的更复杂的模型。因此，ML和大数据是很好的匹配。
- en: Last but not least is the emergence of microservices. I spent a great deal of
    time on the topic of machine and application communication in this book, and Scala
    with the Akka actors model comes very naturally here.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是微服务的出现。我在这本书中花费了大量时间讨论机器和应用程序通信的话题，而Scala与Akka演员模型在这里非常自然地结合在一起。
- en: 'Functional programming, at least for a good portion of practical programmers,
    is more about the style of programming than a programming language itself. While
    Java 8 started having lambda expressions and streams, which came out of functional
    programming, one can still write in a functional style without these mechanisms
    or even write a Java-style code in Scala. The two big ideas that brought Scala
    to prominence in the big data world are lazy evaluation, which greatly simplifies
    data processing in a multi-threaded or distributed world, and immutability. Scala
    has two different libraries for collections: one is mutable and another is immutable.
    While the distinction is subtle from the application user point of view, immutability
    greatly increases the options from a compiler perspective, and lazy evaluation
    cannot be a better match for big data, where REPL postpones most of the number
    crunching towards later stages of the pipeline, increasing interactivity.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程，至少对于大部分实用程序员来说，更多的是关于编程风格，而不是编程语言本身。虽然Java 8开始引入了来自函数式编程的lambda表达式和流，但人们仍然可以在没有这些机制的情况下以函数式风格编写代码，甚至在Scala中编写Java风格的代码。将Scala在大数据世界中推向突出地位的两个主要思想是惰性评估，它极大地简化了多线程或分布式世界中的数据处理，以及不可变性。Scala有两个不同的集合库：一个是可变的，另一个是不可变的。虽然从应用程序用户的角度来看，这种区别很微妙，但不可变性从编译器的角度来看大大增加了选项，而惰性评估对于大数据来说是一个更好的匹配，因为REPL将大多数数值计算推迟到管道的后期阶段，从而增加了交互性。
- en: '![Preface](img/B04935_00_01.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![前言](img/B04935_00_01.jpg)'
- en: 'Figure 1: One of the possible definitions of a data scientist'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：数据科学家可能的定义之一
- en: Finally, big data. Big data has definitely occupied the headlines for a couple
    of years now, and a big reason for this is that the amount of data produced by
    machines today greatly surpasses anything that a human cannot even produce, but
    even comprehend, without using the computers. The social network companies, such
    as Facebook, Google, Twitter, and so on, have demonstrated that enough information
    can be extracted from these blobs of data to justify the tools specifically targeted
    towards processing big data, such as Hadoop, MapReduce, and Spark.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，大数据。大数据无疑已经占据了几年的头条新闻，其中一个重要原因是，今天机器产生的数据量远远超过了人类即使不使用计算机也无法生产，甚至无法理解的数据量。像Facebook、Google、Twitter等社交网络公司已经证明，可以从这些数据块中提取足够的信息，以证明专门针对处理大数据的工具（如Hadoop、MapReduce和Spark）的合理性。
- en: We will touch on what Hadoop does later in the book, but originally, it was
    a Band-Aid on top of commodity hardware to be able to deal with a vast amount
    of information, which the traditional relational DBs at the time were not equipped
    to handle (or were able, but at a prohibitive price). While big data is probably
    too big a subject for me to handle in this book, Spark is the focus and is another
    implementation of Hadoop MapReduce that removes a few inefficiencies of having
    to deal with persisting data on disk. Spark is a bit more expensive as it consumes
    more memory in general and the hardware has to be more reliable, but it is more
    interactive. Furthermore, Spark works on top of Scala—other languages such as
    Java and Python too—but Scala is the primary API language, and it found certain
    synergies in how it expresses data pipelines in Scala.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的后面部分介绍Hadoop的功能，但最初，它是在通用硬件上的一种临时解决方案，以便能够处理大量信息，而当时的传统关系型数据库无法处理这些信息（或者能够处理，但代价高昂）。虽然大数据可能是一个太大的主题，我无法在本书中处理，但Spark是重点，它是Hadoop
    MapReduce的另一种实现，它消除了处理磁盘上持久化数据的一些低效之处。Spark在总体上更昂贵，因为它消耗更多的内存，硬件也必须更可靠，但它更具有交互性。此外，Spark在Scala上运行——Java和Python等其他语言也可以——但Scala是主要的API语言，它在Scala中表达数据管道的方式找到了某些协同效应。
- en: What this book covers
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](ch01.xhtml "Chapter 1. Exploratory Data Analysis"), *Exploratory
    Data Analysis,* covers howevery data analyst begins with an exploratory data analysis.
    There is nothing new here, except that the new tools allow you to look into larger
    datasets—possibly spread across multiple computers, as easily as if they were
    just on a local machine. This, of course, does not prevent you from running the
    pipeline on a single machine, but even then, the laptop I am writing this on has
    four cores and about 1,377 threads running at the same time. Spark and Scala (parallel
    collections) allow you to transparently use this entire dowry, sometimes without
    explicitly specifying the parallelism. Modern servers may have up to 128 hyper-threads
    available to the OS. This chapter will show you how to start with the new tools,
    maybe by exploring your old datasets.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一章](ch01.xhtml "第一章 探索性数据分析"), *探索性数据分析*，讲述了每一位数据分析师都是从探索性数据分析开始的。这里没有新的内容，只是新的工具允许你轻松地查看更大的数据集——可能分布在不同计算机上，就像它们只是本地机器上的数据一样。当然，这并不妨碍你在单台机器上运行管道，但即使是那样，我写这篇文档的笔记本电脑也有四个核心和大约1,377个线程同时运行。Spark和Scala（并行集合）允许你透明地使用整个资源，有时甚至不需要明确指定并行性。现代服务器可能向操作系统提供多达128个超线程。本章将向你展示如何使用新工具开始，也许是通过探索你的旧数据集。'
- en: '[Chapter 2](ch02.xhtml "Chapter 2. Data Pipelines and Modeling"), *Data Pipelines
    and Modeling*, explains that while data-driven processes existed long before Scala/Spark,
    the new age demonstrated the emergence of a fully data-driven enterprise where
    the business is optimized by the feedback from multiple data-generating machines.
    Big data requires new techniques and architectures to accommodate the new decision
    making process. Borrowing from a number of academic fields, this chapter proceeds
    to describe a generic architecture of a data-driven business, where most of the
    workers'' task is monitoring and tuning the data pipelines (or enjoying the enormous
    revenue per worker that these enterprises can command).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](ch02.xhtml "第二章 数据管道和建模")，*数据管道和建模*，解释说尽管在Scala/Spark出现之前就已经存在数据驱动的过程，但新时代展示了完全数据驱动的企业的出现，其中业务通过多个数据生成机器的反馈进行优化。大数据需要新的技术和架构来适应新的决策过程。借鉴多个学术领域，本章继续描述一个数据驱动企业的通用架构，其中大多数工作人员的任务是监控和调整数据管道（或享受这些企业可以命令的每个工作人员的巨额收入）。'
- en: '[Chapter 3](ch03.xhtml "Chapter 3. Working with Spark and MLlib"), *Working
    with Spark and MLlib*, focuses on the internal architecture of Spark, which we
    mentioned earlier as a replacement for and/or complement to Hadoop MapReduce.
    We will specifically stop on a few ML algorithms, which are grouped under the
    MLlib tag. While this is still a developing topic and many of the algorithms are
    being moved using a different package now, we will provide a few examples of how
    to run standard ML algorithms in the `org.apache.spark.mllib` package. We will
    also explain the modes that Spark can be run under and touch on Spark performance
    tuning.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第三章](ch03.xhtml "第三章 使用Spark和MLlib")，*使用Spark和MLlib*，专注于Spark的内部架构，我们之前提到它是Hadoop
    MapReduce的替代品和/或补充。我们将特别关注几个ML算法，这些算法被归类在MLlib标签下。虽然这仍然是一个发展中的话题，许多算法现在正在使用不同的包进行迁移，但我们将提供一些如何在`org.apache.spark.mllib`包中运行标准ML算法的示例。我们还将解释Spark可以运行的模式，并简要介绍Spark性能调优。'
- en: '[Chapter 4](ch04.xhtml "Chapter 4. Supervised and Unsupervised Learning"),
    *Supervised and Unsupervised Learning*, explains that while Spark MLlib may be
    a moving target, general ML principles have been solidly established. Supervised/unsupervised
    learning is a classical division of ML algorithms that work on row-oriented data—most
    of the data, really. This chapter is a classic part of any ML book, but we spiced
    it up a bit to make it more Scala/Spark-oriented.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第四章](ch04.xhtml "第四章 监督学习和无监督学习")，*监督学习和无监督学习*，解释说虽然Spark MLlib可能是一个移动的目标，但一般的ML原则已经得到了稳固的建立。监督/无监督学习是ML算法的一个经典分类，这些算法处理行导向数据——实际上大部分数据。本章是任何ML书籍的经典部分，但我们增加了一些内容，使其更具Scala/Spark导向性。'
- en: '[Chapter 5](ch05.xhtml "Chapter 5. Regression and Classification"), *Regression
    and Classification*, introduces regression and classification, which is another
    classic subdivision of the ML algorithms, even if it has been shown that classification
    can be used to regress, and regression to classify, still these are the two classes
    that use different techniques, precision metrics, and ways to regularize the models.
    This chapter will take a practical approach while showing you practical examples
    of regression and classification analysis'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](ch05.xhtml "第5章. 回归与分类"), *回归与分类*，介绍了回归和分类，这是机器学习算法的另一个经典分支，尽管已经证明分类可以用于回归，回归也可以用于分类，但这两个类别仍然使用不同的技术、精确度指标和正则化模型的方法。本章将采用实践方法，同时展示回归和分类分析的实例。'
- en: '[Chapter 6](ch06.xhtml "Chapter 6. Working with Unstructured Data"), *Working
    with Unstructured Data,* covers how one of the new features that social data brought
    with them and brought traditional DBs to their knees is nested and unstructured
    data. Working with unstructured data requires new techniques and formats, and
    this chapter is dedicated to the ways to present, store, and evolve these types
    of data. Scala becomes a big winner here, as it has a natural way to deal with
    complex data structures in the data pipelines.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.xhtml "第6章. 处理非结构化数据"), *处理非结构化数据*，介绍了社交数据带来的新特性之一，即嵌套和非结构化数据，这一特性甚至让传统的数据库不堪重负。处理非结构化数据需要新的技术和格式，本章专门探讨了如何展示、存储和演进这些类型的数据。Scala在这里成为大赢家，因为它在数据处理管道中处理复杂数据结构有天然的方式。'
- en: '[Chapter 7](ch07.xhtml "Chapter 7. Working with Graph Algorithms"), *Working
    with Graph Algorithms*, explains how graphs present another challenge to the traditional
    row-oriented DBs. Lately, there has been a resurgence of graph DBs. We will cover
    two different libraries in this chapter: one is Scala-graph from Assembla, which
    is a convenient tool to represent and reason with graphs, and the other is Spark''s
    graph class with a few graph algorithms implemented on top of it.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.xhtml "第7章. 处理图算法"), *处理图算法*，解释了图如何给传统的基于行的数据库带来了另一个挑战。最近，图数据库出现了复兴。本章我们将介绍两个不同的库：一个是来自Assembla的Scala-graph，这是一个方便的工具，用于表示和推理图；另一个是Spark的图类，它在其之上实现了几个图算法。'
- en: '[Chapter 8](ch08.xhtml "Chapter 8. Integrating Scala with R and Python"), *Integrating
    Scala with R and Python*, covers how even though Scala is cool, many people are
    just too cautious to leave their old libraries behind. In this chapter, I will
    show how to transparently refer to the legacy code written in R and Python, a
    request I hear too often. In short, there are too mechanisms: one is using Unix
    pipelines and another way is to launch R or Python in JVM.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.xhtml "第8章. 将Scala与R和Python集成"), *将Scala与R和Python集成*，介绍了尽管Scala很酷，但许多人仍然过于谨慎，不愿放弃他们旧的库。在本章中，我将展示如何透明地引用用R和Python编写的旧代码，这是一个我经常听到的请求。简而言之，有两种机制：一种是通过Unix管道，另一种是在JVM中启动R或Python。'
- en: '[Chapter 9](ch09.xhtml "Chapter 9. NLP in Scala"), *NLP in Scala*, focuses
    on how natural language processing has deal with human-computer interaction and
    computer''s understanding of our often-substandard ways to communicate. I will
    focus on a few tools that Scala specifically provide for NLP, topic association,
    and dealing with large amounts of textual information (Spark).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.xhtml "第9章. Scala中的NLP"), *Scala中的NLP*，专注于自然语言处理如何处理人机交互以及计算机对我们常常不标准的交流方式的理解。我将专注于Scala为NLP、主题关联和处理大量文本信息（Spark）提供的几个工具。'
- en: '[Chapter 10](ch10.xhtml "Chapter 10. Advanced Model Monitoring"), *Advanced
    Model Monitoring*, introduces how developing data pipelines usually means that
    someone is going to use and debug them. Monitoring is extremely important not
    only for the end user data pipeline, but also for the developer or designer who
    is looking for the ways to either optimize the execution or further the design.
    We cover the standard tools for monitoring systems and distributed clusters of
    machines as well as how to design a service that has enough hooks to look into
    its functioning without attaching a debugger. I will also touch on the new emerging
    field of statistical model monitoring.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](ch10.xhtml "第10章. 高级模型监控")，*高级模型监控*，介绍了开发数据管道通常意味着有人将使用和调试它们。监控对于最终用户数据管道来说至关重要，对于寻找优化执行或进一步设计方法的开发人员或设计师来说也是如此。我们涵盖了监控系统和机器分布式集群的标准工具，以及如何设计一个具有足够钩子以查看其功能而不需要附加调试器的服务。我还会涉及到统计模型监控的新兴领域。'
- en: What you need for this book
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您需要这本书什么
- en: This book is based on open source software. First, it's Java. One can download
    Java from Oracle's Java Download page. You have to accept the license and choose
    an appropriate image for your platform. Don't use OpenJDK—it has a few problems
    with Hadoop/Spark.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本书基于开源软件。首先，是Java。您可以从Oracle的Java下载页面下载Java。您必须接受许可协议并选择适合您平台的适当镜像。不要使用OpenJDK——它与Hadoop/Spark存在一些问题。
- en: 'Second, Scala. If you are using Mac, I recommend installing Homebrew:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，Scala。如果您使用Mac，我建议安装Homebrew：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Multiple open source packages will also be available to you. To install Scala,
    run `brew install scala`. Installation on a Linux platform requires downloading
    an appropriate Debian or RPM package from the [http://www.scala-lang.org/download/](http://www.scala-lang.org/download/)
    site. We will use the latest version at the time, that is, 2.11.7.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您将也可以使用多个开源软件包。要安装Scala，请运行`brew install scala`。在Linux平台上安装需要从[http://www.scala-lang.org/download/](http://www.scala-lang.org/download/)网站下载适当的Debian或RPM软件包。我们将使用当时最新的版本，即2.11.7。
- en: Spark distributions can be downloaded from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
    We use pre-build for Hadoop 2.6 and later image. As it's Java, you need to just
    unzip the package and start using the scripts from the `bin` subdirectory.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Spark发行版可以从[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)下载。我们使用为Hadoop
    2.6及更高版本预构建的镜像。由于它是Java，您只需解压包并从`bin`子目录中的脚本开始使用即可。
- en: R and Python packages are available at [http://cran.r-project.org/bin](http://cran.r-project.org/bin)
    and `http://python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tar.xz`
    sites respectively. The text has specific instruction on how to configure them.
    Although our use of the packages should be version agnostic, I used R version
    3.2.3 and Python version 2.7.11 in this book.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: R和Python软件包分别可在[http://cran.r-project.org/bin](http://cran.r-project.org/bin)和`http://python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tar.xz`网站上找到。文本中具体说明了如何配置它们。尽管我们使用的软件包应该是版本无关的，但我在这本书中使用了R版本3.2.3和Python版本2.7.11。
- en: Who this book is for
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书面向谁
- en: 'Professional and emerging data scientists who want to sharpen their skills
    and see practical examples of working with big data: a data analyst who wants
    to effectively extract actionable information from large amounts of data and an
    aspiring statistician who is willing to get beyond the existing boundaries and
    become a data scientist.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想要提高技能并看到与大数据实际操作案例的专业和新兴数据科学家：一个希望从大量数据中有效提取可操作信息的分析师，以及愿意超越现有边界并成为数据科学家的有抱负的统计学家。
- en: The book style is pretty much hands-on, I don't delve into mathematical proofs
    or validations, with a few exceptions, and there are more in-depth texts that
    I recommend throughout the book. However, I will try my best to provide code samples
    and tricks that you can start using for the standard techniques and libraries
    as soon as possible.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本书风格相当实用，我不会深入数学证明或验证，尽管有一些例外，书中还有更多深入的内容推荐。然而，我会尽力提供代码示例和技巧，让您能够尽快开始使用标准技术和库。
- en: Conventions
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 惯例
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，您会发现许多文本样式，用于区分不同类型的信息。以下是一些这些样式的示例及其含义的解释。
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "We
    can include other contexts through the use of the `include` directive."'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称如下所示：“我们可以通过使用`include`指令来包含其他上下文。”
- en: 'A block of code is set as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都如下所示：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "Run all cells at once by navigating to **Cell** | **Run All**."'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要词汇**以粗体显示。您在屏幕上看到的单词，例如在菜单或对话框中，在文本中如下所示：“通过导航到**单元格** | **运行所有**”一次性运行所有单元格。”'
- en: Note
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要说明以如下所示的框中出现。
- en: Tip
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Tips and tricks appear like this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士和技巧看起来像这样。
- en: Reader feedback
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们欢迎读者的反馈。告诉我们您对这本书的看法——您喜欢或不喜欢什么。读者反馈对我们很重要，因为它帮助我们开发出您真正能从中获得最大价值的标题。
- en: To send us general feedback, simply e-mail `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book's title in the subject of your message.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要向我们发送一般反馈，请简单地发送电子邮件至`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在邮件的主题中提及书的标题。
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在某个主题上具有专业知识，并且您有兴趣撰写或为书籍做出贡献，请参阅我们的作者指南[www.packtpub.com/authors](http://www.packtpub.com/authors)。
- en: Customer support
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经是Packt图书的骄傲拥有者，我们有一些事情可以帮助您充分利用您的购买。
- en: Downloading the example code
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[http://www.packtpub.com](http://www.packtpub.com)的账户下载此书的示例代码文件。如果您在其他地方购买了此书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下步骤下载代码文件：
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的电子邮件地址和密码登录或注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**标签上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载与勘误表**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书的名称。
- en: Select the book for which you're looking to download the code files.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您想要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择您购买此书的来源。
- en: Click on **Code Download**.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载完成后，请确保使用最新版本解压缩或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip for Windows
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac上的Zipeg / iZip / UnRarX
- en: 7-Zip / PeaZip for Linux
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux上的7-Zip / PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning](https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning).
    We also have other code bundles from our rich catalog of books and videos available
    at. [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)
    Check them out!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此书的代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning](https://github.com/PacktPublishing/Mastering-Scala-Machine-Learning)。我们还有其他来自我们丰富图书和视频目录的代码包可供选择。[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)
    查看它们！
- en: Downloading the color images of this book
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载此书的彩色图片
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还为您提供了一个包含本书中使用的截图/图表的彩色图像的PDF文件。彩色图像将帮助您更好地理解输出的变化。您可以从[https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringScalaMachineLearning_ColorImages.pdf)下载此文件。
- en: Errata
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果您在我们的某本书中发现错误——可能是文本或代码中的错误——如果您能向我们报告这一点，我们将不胜感激。通过这样做，您可以避免其他读者感到沮丧，并帮助我们改进本书的后续版本。如果您发现任何勘误，请通过访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击**勘误提交表单**链接，并输入您的勘误详情来报告它们。一旦您的勘误得到验证，您的提交将被接受，勘误将被上传到我们的网站或添加到该标题的勘误部分下的现有勘误列表中。
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看之前提交的勘误，请访问[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)，并在搜索字段中输入书籍名称。所需信息将出现在**勘误**部分下。
- en: Piracy
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 海盗行为
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上对版权材料的盗版是一个跨所有媒体的持续问题。在Packt，我们非常重视保护我们的版权和许可证。如果您在互联网上发现任何形式的非法复制我们的作品，请立即提供位置地址或网站名称，以便我们可以寻求补救措施。
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 请通过`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并提供疑似盗版材料的链接。
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您在保护我们的作者和为您提供有价值内容的能力方面的帮助。
- en: Questions
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: If you have a problem with any aspect of this book, you can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`,
    and we will do our best to address the problem.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对本书的任何方面有问题，您可以通过`<[questions@packtpub.com](mailto:questions@packtpub.com)>`联系我们，我们将尽力解决问题。
