<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer272">
    <h1 class="chapterNumber">8</h1>
    <h1 class="chapterTitle" id="_idParaDest-181">Segmenting Customers with Machine Learning</h1>
    <p class="normal">With the rising availability of data on customer characteristics and behaviors, it has become more accessible to approach customers with more informed insights. From analyzing the drivers behind customer engagements that we discussed in <em class="chapterRef">Chapter 3</em> to understanding which specific products that individual customers may like, which we touched on in <em class="chapterRef">Chapter 7</em>, the assumptions behind these approaches were based on the fact that there are certain groups of similar customers that behave in similar fashions.</p>
    <p class="normal">Targeted marketing approaches are proven to work significantly better than mass marketing, due to <a id="_idIndexMarker671"/>which <strong class="keyWord">customer segmentation</strong> has been a frequently discussed topic in this domain. Also, with the upcoming cookieless world, first-party data is expected to play an even more critical role. Consequently, targeted strategies based on customer segments, such as geographic segments, demographic segments, or interest topic segments that will still be available without browser cookies, are going to be critical for success.</p>
    <p class="normal">In this chapter, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">One-time versus repeat customers</li>
      <li class="bulletList">Customer segmentation with K-means clustering and purchase behaviors</li>
      <li class="bulletList">Customer segmentation <a id="_idIndexMarker672"/>with <strong class="keyWord">large language models</strong> (<strong class="keyWord">LLMs</strong>) and product interests</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-182">One-time versus repeat customers</h1>
    <p class="normal">According<a id="_idIndexMarker673"/> to <em class="italic">BIA Advisory Services</em>, which provides some very clear<a id="_idIndexMarker674"/> metrics, repeat customers spend 67% more than new customers on average. Also, a survey conducted by <em class="italic">BIA Advisory Services</em> says that over half of the surveyed businesses’ revenue comes from repeat customers rather than new customers. This signifies the fact that retaining existing customers is as important as growing the customer base. However, businesses often sacrifice customer service to<a id="_idIndexMarker675"/> gain new customers.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">BIA Advisory Services report</strong></p>
      <p class="normal"><a href="https://www.bia.com/small-business-owners-shift-investment-from-customer-acquisition-to-customer-engagement-new-report-by-manta-and-biakelsey/"><span class="url">https://www.bia.com/small-business-owners-shift-investment-from-customer-acquisition-to-customer-engagement-new-report-by-manta-and-biakelsey/</span></a></p>
    </div>
    <h2 class="heading-2" id="_idParaDest-183">The need to retain customers</h2>
    <p class="normal">There are several benefits<a id="_idIndexMarker676"/> that indicate why retaining customers is so important to businesses:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Less investment</strong>: The first obvious reason is that new customers cost more. If you recall a typical customer life cycle from <em class="chapterRef">Chapter 2</em>, you need to spend capital and marketing resources to promote brand awareness among potential new customers, engage prospects with your business, and then finally convert them into paying customers.</li>
    </ul>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_01.png"/></figure>
    <p class="packt_figref">Figure 8.1: The customer life cycle</p>
    <p class="normal">For existing customers, you can skip these steps and focus your efforts on retaining them as repeat customers by providing great customer service and introducing products that interest them enough. Obtaining new customers often costs multiple times more than keeping existing customers.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Greater reliability</strong>: Repeat customers bring more reliable and recurring revenue to your business. As previously mentioned, repeat customers often contribute more than half of the revenue for businesses and spend more than new customers. As you provide products or services that existing customers like and as you provide better customer services, your customers may become loyal to your brand and continue to purchase products. </li>
    </ul>
    <p class="normal">For example, if you are selling pet products, such as pet food or pet toys, and they like your products, they may come back next month to purchase more or even subscribe to get monthly pet foods delivered to them. This results in a reliable and recurring revenue stream that is going to strengthen the cash flow of your business, which you can use to invest more into your products, which will bring in more revenue. This starts the positive cycle for your business.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Building brand loyalty</strong>: Repeat <a id="_idIndexMarker677"/>customers who are loyal to your business bring in more new customers. As you may recall from <em class="chapterRef">Chapter 2</em>, loyal customers act as your brand ambassadors and marketing agents, where they spread the word about your business and bring in new customers. Without having to spend more marketing dollars, these loyal customers promote your business and attract new customers.</li>
    </ul>
    <p class="normal">There are many more subtle benefits to having a strong repeat customer base, but these are the three most obvious benefits of having repeat customers, and demonstrate how they help businesses significantly.</p>
    <h2 class="heading-2" id="_idParaDest-184">Analyzing the impact of retaining customers</h2>
    <p class="normal">Let’s take a look at a<a id="_idIndexMarker678"/> practical example of the kinds of impacts these repeat customers have on the business compared to new customers:</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Source code and data</strong>: <a href="https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.8 "><span class="url">https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.8</span></a></p>
      <p class="normal"><strong class="keyWord">Data source</strong>: <a href="https://archive.ics.uci.edu/dataset/352/online+retail"><span class="url">https://archive.ics.uci.edu/dataset/352/online+retail</span></a></p>
    </div>
    <p class="normal">As always, we will start by importing the data into a <code class="inlineCode">pandas</code> DataFrame. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
df = pd.read_csv(<span class="hljs-string">"./data.csv"</span>)
df = df.dropna()
df = df.loc[
    df[<span class="hljs-string">"Quantity"</span>] &gt; <span class="hljs-number">0</span>
]
</code></pre>
    <p class="normal">Here, we load the<a id="_idIndexMarker679"/> data into a <code class="inlineCode">pandas</code> DataFrame, <code class="inlineCode">df</code>. As we are only interested in comparing new versus repeat customers, we are going to drop the rows with <code class="inlineCode">NaN</code> values using the <code class="inlineCode">dropna</code> function and only take the customers who have purchased at least one or more items by filtering with <code class="inlineCode">df["Quantity"] &gt; 0</code>.</p>
    <ol>
      <li class="numberedList" value="1">Then, we are going to create the following additional variables:<ul>
          <li class="bulletList"><strong class="keyWord">Sales amount</strong>: By simply multiplying the quantity that the customers have purchased by the individual price of the items, we can get the total sales amount for each order. In the following code, we create a new column named <code class="inlineCode">Sales</code>, which has the total sales amount for each order:
            <pre class="programlisting code"><code class="hljs-code">df[<span class="hljs-string">"Sales"</span>] = df[<span class="hljs-string">"Quantity"</span>] * df[<span class="hljs-string">"UnitPrice"</span>].
</code></pre>
          </li>
          <li class="bulletList"><strong class="keyWord">Month variable</strong>: In order to decide whether a given customer is a new customer or not, we need to consider the time horizon of the data. If a given customer has not purchased any items previously, then this customer will be considered new. On the other hand, if a given customer has purchased an item previously, then we will consider this customer a repeat customer. For this exercise, we are going to look at month-over-month data, which will require us to create a variable for what month the invoice was created. In the following code, we convert the column, <code class="inlineCode">InvoiceDate</code>, into the <code class="inlineCode">datetime</code> type and cast <code class="inlineCode">InvoiceDate</code> into each month. For example, the date <code class="inlineCode">2011-02-23</code> will be cast to <code class="inlineCode">2011-02-01</code>:
            <pre class="programlisting code"><code class="hljs-code">df[<span class="hljs-string">"InvoiceDate"</span>] = pd.to_datetime(df[<span class="hljs-string">"InvoiceDate"</span>])
df[<span class="hljs-string">"</span><span class="hljs-string">month"</span>] = df[<span class="hljs-string">"InvoiceDate"</span>].dt.strftime(<span class="hljs-string">"%Y-%m-01"</span>)
</code></pre>
          </li>
        </ul>
      </li>
      <li class="numberedList">With these <a id="_idIndexMarker680"/>two variables, we can now start dissecting whether the sales are from the new or repeat customers. Take a look at the following code:
        <pre class="programlisting code"><code class="hljs-code">monthly_data = []
<span class="hljs-keyword">for</span> each_month <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(df[<span class="hljs-string">"month"</span>].unique()):
    up_to_last_month_df = df.loc[
        df[<span class="hljs-string">"month"</span>] &lt; each_month
    ]
    this_month_df = df.loc[
        df[<span class="hljs-string">"month"</span>] == each_month
    ]
    curr_customers = <span class="hljs-built_in">set</span>(this_month_df[<span class="hljs-string">"CustomerID"</span>].unique())
    prev_customers = <span class="hljs-built_in">set</span>(up_to_last_month_df[<span class="hljs-string">"CustomerID"</span>].unique())
   
    repeat_customers = curr_customers.intersection(prev_customers)
    new_customers = curr_customers - prev_customers
   
    curr_sales = this_month_df[<span class="hljs-string">"Sales"</span>].<span class="hljs-built_in">sum</span>()
   
    sales_from_new_customers = this_month_df.loc[
        this_month_df[<span class="hljs-string">"CustomerID"</span>].isin(new_customers)
    ][<span class="hljs-string">"Sales"</span>].<span class="hljs-built_in">sum</span>()
    sales_from_repeat_customers = this_month_df.loc[
        this_month_df[<span class="hljs-string">"CustomerID"</span>].isin(repeat_customers)
    ][<span class="hljs-string">"Sales"</span>].<span class="hljs-built_in">sum</span>()
   
    avg_sales_from_new_customers = this_month_df.loc[
        this_month_df[<span class="hljs-string">"CustomerID"</span>].isin(new_customers)
    ][<span class="hljs-string">"Sales"</span>].mean()
    avg_sales_from_repeat_customers = this_month_df.loc[
        this_month_df[<span class="hljs-string">"CustomerID"</span>].isin(repeat_customers)
    ][<span class="hljs-string">"Sales"</span>].mean()
   
    monthly_data.append({
        <span class="hljs-string">"month"</span>: each_month,
       
        <span class="hljs-string">"num_customers"</span>: <span class="hljs-built_in">len</span>(curr_customers),
        <span class="hljs-string">"repeat_customers"</span>: <span class="hljs-built_in">len</span>(repeat_customers),
        <span class="hljs-string">"new_customers"</span>: <span class="hljs-built_in">len</span>(new_customers),
       
        <span class="hljs-string">"curr_sales"</span>: curr_sales,
        <span class="hljs-string">"sales_from_new_customers"</span>: sales_from_new_customers,
        <span class="hljs-string">"sales_from_repeat_customers"</span>: sales_from_repeat_customers,
        <span class="hljs-string">"avg_sales_from_new_customers"</span>: avg_sales_from_new_customers,
        <span class="hljs-string">"avg_sales_from_repeat_customers"</span>: avg_sales_from_repeat_customers,
    })
</code></pre>
      </li>
    </ol>
    <p class="normal">Let’s take a closer <a id="_idIndexMarker681"/>look at this code. We first iterate through each month in the <code class="inlineCode">month</code> variable. For each iteration, we find the unique customers in the given month and store them as a set into a variable, named <code class="inlineCode">curr_customers</code>. We do the same for the past customers by getting the unique customers up to the given month and storing them as a set in a variable named <code class="inlineCode">prev_customers</code>. Based on these two variables, we can identify the new customers from the repeat customers by using some set operations:</p>
    <ol>
      <li class="romanList" value="1">First, we find the intersection between <code class="inlineCode">curr_customers</code> and <code class="inlineCode">prev_customers</code>, which represent the repeat customers as we have seen these customers in our sales data already.</li>
      <li class="romanList">Next, we subtract the <code class="inlineCode">prev_customers</code> set from the <code class="inlineCode">curr_customers</code> set, which gives us the new customers as these are the customers that we have not seen before. From these operations, we have successfully identified new versus repeat customers.</li>
    </ol>
    <p class="normal">Based on these <code class="inlineCode">prev_customers</code> and <code class="inlineCode">curr_customers</code> sets, we can find the revenue from the new and repeat customers. Using the <code class="inlineCode">isin</code> function, we select the <code class="inlineCode">CustomerIDs</code> that match the IDs in the set of <code class="inlineCode">new_customers</code> and compute the total sales from the new customers by summing all the sales amounts from these customers and the average sales amount for the new customers by taking a mean of all the sales amounts from these customers. Similarly, using the <code class="inlineCode">isin</code> function, we select the <code class="inlineCode">CustomerIDs</code> that match the IDs in the set of <code class="inlineCode">repeat_customers</code> and compute the total sales from the repeat customers. We do this by summing all the sales amounts from these customers and the average sales amount for the repeat customers by taking a mean of all the sales amounts from these customers. We save this data into a variable, <code class="inlineCode">monthly_data</code>.</p>
    <ol>
      <li class="numberedList" value="3">We do one last <a id="_idIndexMarker682"/>set of computations as in the following and will be ready to look at the differences between the new and repeat customers:
        <pre class="programlisting code"><code class="hljs-code">monthly_data_df = pd.DataFrame(monthly_data).set_index(<span class="hljs-string">"month"</span>).iloc[<span class="hljs-number">1</span>:-<span class="hljs-number">1</span>]
monthly_data_df[<span class="hljs-string">"repeat_customer_percentage"</span>] = monthly_data_df[<span class="hljs-string">"repeat_customers"</span>]/monthly_data_df[<span class="hljs-string">"num_customers"</span>]
monthly_data_df[<span class="hljs-string">"repeat_sales_percentage"</span>] = monthly_data_df[<span class="hljs-string">"sales_from_repeat_customers"</span>]/monthly_data_df[<span class="hljs-string">"curr_sales"</span>]
</code></pre>
      </li>
    </ol>
    <p class="normal">This code simply converts the data into a <code class="inlineCode">pandas</code> DataFrame and computes what percentage of customers are actually repeat customers and what percentage of sales are from the repeat customers.</p>
    <p class="normal">Now that we’re done, let’s take a look at the monthly customer counts and the breakdowns between the new and repeat customers using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">ax = monthly_data_df[[
    <span class="hljs-string">"new_customers"</span>, <span class="hljs-string">"repeat_customers"</span>
]].plot(kind=<span class="hljs-string">"bar"</span>, grid=<span class="hljs-literal">True</span>, figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>))
(monthly_data_df[<span class="hljs-string">"repeat_customer_percentage"</span>]*<span class="hljs-number">100</span>).plot(
    ax=ax, secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"salmon"</span>, style=<span class="hljs-string">"-o"</span>
)
ax.right_ax.legend()
ax.right_ax.set_ylim([<span class="hljs-number">0</span>, <span class="hljs-number">100.0</span>])
ax.right_ax.set_ylabel(<span class="hljs-string">"repeat customer percentage (%)"</span>)
ax.set_ylabel(<span class="hljs-string">"number of customers"</span>)
ax.set_title(<span class="hljs-string">"number of new vs. repeat customers over time"</span>)
plt.show()
</code></pre>
    <p class="normal">This should produce the following chart:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_02.png"/></figure>
    <p class="packt_figref">Figure 8.2: The number of new versus repeat customers</p>
    <p class="normal">The bars on the left for <a id="_idIndexMarker683"/>each time period represent the number of new customers for each month and the bars on the right represent the number of repeat customers. As you can see, the composition of the repeat customers grows over time and there is some cycle in terms of the influx of the new customers. We see more new customers at the beginning and end of the year and dips during the summertime from June to August.</p>
    <p class="normal">The line chart shows what percentage of the customers in each month were repeat customers and as this chart suggests, it grew from around 40% in January 2011 to around 80% in November 2011.</p>
    <p class="normal">This indicates a very healthy business. It shows continuous demand and purchases from the customers who have made previous purchases from this business. The number of repeat customers continuously grows, which suggests that the products and services this business provides continuously attract customers who have once interacted with this business. For a business that lacks attractive products and/or good customer service, the number of repeat customers will typically decrease. One thing to note here though is that the rate of new customer influx is relatively steady and not growing. This, of course, is better than a decreasing new customer count over time, but this shows that there is a growth potential to capture more new customers. Given that there is a healthy repeat and recurring customer base, the marketers can focus on new customer acquisition more for this business.</p>
    <p class="normal">Similarly, let’s take a look at the sales amount from the new and repeat customers. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">ax = (monthly_data_df[[
    <span class="hljs-string">"sales_from_new_customers"</span>, <span class="hljs-string">"sales_from_repeat_customers"</span>
]]/<span class="hljs-number">1000</span>).plot(kind=<span class="hljs-string">"bar"</span>, grid=<span class="hljs-literal">True</span>, figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>))
(monthly_data_df[<span class="hljs-string">"repeat_sales_percentage"</span>]*<span class="hljs-number">100</span>).plot(
    ax=ax, secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"salmon"</span>, style=<span class="hljs-string">"-o"</span>
)
ax.set_ylabel(<span class="hljs-string">"sales (in thousands)"</span>)
ax.set_title(<span class="hljs-string">"sales from new vs. repeat customers over time"</span>)
ax.right_ax.legend()
ax.right_ax.set_ylim([<span class="hljs-number">0</span>, <span class="hljs-number">100.0</span>])
ax.right_ax.set_ylabel(<span class="hljs-string">"repeat customer percentage (%)"</span>)
plt.show()
</code></pre>
    <p class="normal">This code <a id="_idIndexMarker684"/>produces the following chart:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_03.png"/></figure>
    <p class="packt_figref">Figure 8.3: Sales from new versus repeat customers</p>
    <p class="normal">Similar to before, the bars on the left represent the sales amount from new customers and the bars on the right represent the sales amount from repeat customers. As was the case with a number of customer comparisons before, the sales amount from repeat customers outweighs the sales amount from new customers. This suggests that there is a strong continuous recurring revenue from repeat customers. The percentage of sales from the repeat customers reached above 80% in November 2011. This is somewhat expected as we have discussed previously how repeat customers often take up more than half of the revenue for the businesses. Another point discussed previously and reported by <em class="italic">BIA Advisory Services</em> was that repeat customers typically spend 67% more than new customers.</p>
    <p class="normal">Now let’s see what our data says about this business by comparing average monthly sales from new customers against repeat customers. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">monthly_data_df[<span class="hljs-string">"repeat_to_new_avg_sales_ratio"</span>] = (
    monthly_data_df[<span class="hljs-string">"avg_sales_from_repeat_customers"</span>]
    /
    monthly_data_df[<span class="hljs-string">"avg_sales_from_new_customers"</span>]
)
ax = monthly_data_df[[
    <span class="hljs-string">"avg_sales_from_new_customers"</span>, <span class="hljs-string">"avg_sales_from_repeat_customers"</span>
]].plot(kind=<span class="hljs-string">"bar"</span>, grid=<span class="hljs-literal">True</span>, figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">5</span>), rot=<span class="hljs-number">0</span>)
ax.set_ylabel(<span class="hljs-string">"average sales"</span>)
ax.set_title(<span class="hljs-string">"sales from new vs. repeat customers over time"</span>)
monthly_data_df[<span class="hljs-string">"repeat_to_new_avg_sales_ratio"</span>].plot(
    ax=ax, secondary_y=<span class="hljs-literal">True</span>, color=<span class="hljs-string">"salmon"</span>, style=<span class="hljs-string">"-o"</span>
)
ax.right_ax.set_ylim([<span class="hljs-number">0</span>, <span class="hljs-number">2.0</span>])
ax.right_ax.set_ylabel(<span class="hljs-string">"repeat to new customer avg sales ratio"</span>)
plt.show()
</code></pre>
    <p class="normal">This code <a id="_idIndexMarker685"/>should produce a chart like the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_04.png"/></figure>
    <figure class="mediaobject">Figure 8.4: Average sales from new versus repeat customers</figure>
    <p class="normal">Similarly, the bars on the left are the average sales from the new customers and the bars on the right are the average sales from the repeat customers for each month. The line plot shows the ratios between the average sales of the new customers versus those of the repeat customers. For example, if the ratio is <code class="inlineCode">1.5</code>, it means that the repeat customers spent <code class="inlineCode">1.5</code> times more than the new customers on average during that month. Based on this example dataset, we see that, on average, repeat customers spent more than the average customers for all months reported. In November 2011, the ratio was <code class="inlineCode">1:1.58</code>, which suggests that the repeat customers spent about 60% more than the new customers on average. This aligns with the <em class="italic">BIA Advisory Services</em> report that repeat customers spend significantly more than new customers on average.</p>
    <p class="normal">In this exercise, we have dissected the customer base into two simple segments: new versus repeat. As you may have noticed, this is a simple analytical exercise to conduct, but this produces powerful insights into the dynamics and health of the business and also tells the marketers which group of customers to focus on.</p>
    <p class="normal">If there is a strong recurring customer base with continuous recurring revenue, but it shows steadiness or a decreasing new customer base, it suggests that marketers should focus more on new customer acquisition.</p>
    <p class="normal">On the other hand, if there is a decline<a id="_idIndexMarker686"/> in repeat customers, it suggests that the products and services may not be attractive for customers to come back or that the customer service does not meet the customer expectations. In this case, the marketers should focus on improving the product marketing strategies, customer satisfaction strategies, or other marketing strategies to attract customers to come back for repeated purchases.</p>
    <h1 class="heading-1" id="_idParaDest-185">Customer segmentation with purchase behaviors</h1>
    <p class="normal">Segmenting customers based <a id="_idIndexMarker687"/>on new versus repeat customers is one of the basic and critical analyses to conduct. However, oftentimes, we would like to segment customers based on multiple factors, which can be demographic factors, such as age, geolocation, and occupation, or purchase history, such as how much they spent in the past year, how many items they have purchased, and how many returns they have requested. You can also segment based on customer web activities, such as number of logins in the past X number of days, how long they stay on your webpage, and what pages they look at.</p>
    <p class="normal">There are still challenges to segmenting customers based on these factors, as there are an infinite number of ways and values you can segment the customers by. For example, if you are segmenting your customers by age, some of the questions that may arise are “<code class="inlineCode">how many buckets should I create?</code>" or “<code class="inlineCode">what age cutoff thresholds should I choose?</code>". Similarly, if you want to segment your customers by past sales volume, you will still have to choose what thresholds to use to break down the customer base and how many segments you want to create.</p>
    <p class="normal">Furthermore, when you combine these segments across multiple factors, the number of segments grows exponentially. For example, if you have 2 segments based on the sales volume and combine it with the other 2 segments from purchase quantity, you will end up with 4 segments. If you had 3 segments for both factors, then you would end up with 9 segments in total. In summary, there are mainly three key questions to be answered in conducting customer segmentation:</p>
    <ol>
      <li class="numberedList" value="1">What factor(s) should be used for customer segmentation?</li>
      <li class="numberedList">How many segments should be created?</li>
      <li class="numberedList">What<a id="_idIndexMarker688"/> thresholds should be used to break down into segments?</li>
    </ol>
    <p class="normal">We are going to use the online retail dataset that we have used previously as an example and discuss how to answer these key questions with the K-means clustering algorithm and silhouette score for measuring the effectiveness of clusters.</p>
    <h2 class="heading-2" id="_idParaDest-186">K-means clustering</h2>
    <p class="normal">K-means clustering is<a id="_idIndexMarker689"/> one of the most frequently used machine learning algorithms for clustering and segmentation. It is a method to partition the data into <em class="italic">k</em> clusters. In short, the algorithm iteratively finds the centroids and groups the data points to the nearest centroids until the data points are closer to their centroids than to their neighboring centroids. As you can imagine, the data points in our case will be the factors of interest, such as sales amount, quantity, and refund, and the “<em class="italic">k</em>” in K-means clustering is how many clusters or customer segments we would like to create.</p>
    <p class="normal">In order to create customer segments based on the total sales amount, order quantity, and refunds, we need to do some prep work. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># Net Sales &amp; Quantity</span>
customer_net_df = df.groupby(<span class="hljs-string">'CustomerID'</span>)[[<span class="hljs-string">"Sales"</span>, <span class="hljs-string">"Quantity"</span>]].<span class="hljs-built_in">sum</span>()
customer_net_df.columns = [<span class="hljs-string">'NetSales'</span>, <span class="hljs-string">'NetQuantity'</span>]
<span class="hljs-comment"># Total Refunds</span>
customer_refund_df = df.loc[
    df[<span class="hljs-string">"</span><span class="hljs-string">Quantity"</span>] &lt; <span class="hljs-number">0</span>
].groupby(<span class="hljs-string">"CustomerID"</span>)[[<span class="hljs-string">"Sales"</span>, <span class="hljs-string">"Quantity"</span>]].<span class="hljs-built_in">sum</span>().<span class="hljs-built_in">abs</span>()
customer_refund_df.columns = [<span class="hljs-string">'TotalRefund'</span>, <span class="hljs-string">'TotalRefundQuantity'</span>]
customer_df = customer_net_df.merge(
    customer_refund_df, left_index=<span class="hljs-literal">True</span>, right_index=<span class="hljs-literal">True</span>, how=<span class="hljs-string">"left"</span>
).fillna(<span class="hljs-number">0</span>)
</code></pre>
    <p class="normal">Here, we first get the net <a id="_idIndexMarker690"/>sales and quantity for each customer. This will subtract any refunds and returned items as there are some records with negative <code class="inlineCode">Sales</code> and <code class="inlineCode">Quantity</code> values. Next, we get the information about the refunds. We assume any quantity that is negative is a refund. Thus, we get the total refund amount by summing all the sales with the negative quantity values and the total refund quantity by summing all the order quantities with the negative quantity values. Lastly, we merge these two DataFrames by the index, which is the customer ID. The resulting DataFrame should look like the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_05.png"/></figure>
    <p class="packt_figref">Figure 8.5: The resulting net sales, net quantity, refund amount, and refund quantity</p>
    <p class="normal">One thing to note here is that the data is highly skewed. Take a look at the following code, which we will be using to generate histograms:</p>
    <pre class="programlisting code"><code class="hljs-code">customer_df.hist(bins=<span class="hljs-number">50</span>, figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">10</span>))
plt.show()
</code></pre>
    <p class="normal">This gives us the following plots:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_06.png"/></figure>
    <p class="packt_figref">Figure 8.6: Data distribution</p>
    <p class="normal">As you can see from these <a id="_idIndexMarker691"/>histograms, the data is highly skewed to the right. This occurs often, especially when the data has monetary or quantity values. Skewness in data causes disproportionate clusters with suboptimal segmentation of data. One simple approach to overcome this skewness is to log transform the data, using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">log_customer_df = np.log(customer_df - customer_df.<span class="hljs-built_in">min</span>() + <span class="hljs-number">1</span>)
</code></pre>
    <p class="normal">We can generate the log-transformed data’s histograms using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">log_customer_df.hist(bins=<span class="hljs-number">50</span>, figsize=(<span class="hljs-number">15</span>,<span class="hljs-number">10</span>))
plt.show()
</code></pre>
    <p class="normal">The following are the histograms that are generated:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_07.png"/></figure>
    <p class="packt_figref">Figure 8.7: Log-transformed data distribution</p>
    <p class="normal">As expected, the<a id="_idIndexMarker692"/> log-transformed data is more centered around the mean and closer to a bell curve. We are going to examine clustering both with and without log transformation and see how it affects the clustering results.</p>
    <h3 class="heading-" id="_idParaDest-187">Without log transformation</h3>
    <p class="normal">Training a K-means clustering algorithm in <a id="_idIndexMarker693"/>Python is straightforward. Take a look at the following code, where we import the <code class="inlineCode">KMeans</code> module in the <code class="inlineCode">scikit-learn</code> package to build a K-means clustering algorithm:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
COLS = [<span class="hljs-string">'NetSales'</span>, <span class="hljs-string">'NetQuantity'</span>, <span class="hljs-string">'TotalRefundQuantity'</span>]
kmeans = KMeans(
    n_clusters=<span class="hljs-number">4</span>, n_init=<span class="hljs-string">"auto"</span>
).fit(
    customer_df[COLS]
)
</code></pre>
    <p class="normal">In this example, we are building customer segments based on the three columns, <code class="inlineCode">NetSales</code>, <code class="inlineCode">NetQuantity</code>, and <code class="inlineCode">TotalRefundQuantity</code>. Then, we are building four clusters by using the parameter <code class="inlineCode">n_clusters</code>. The <code class="inlineCode">labels_</code> attribute of the trained <code class="inlineCode">KMeans</code> model has the assigned labels (0 through 3) for each row or customer and the <code class="inlineCode">cluster_centers_</code> attribute shows the centroids of each cluster.</p>
    <div class="note">
      <p class="normal"><strong class="keyWord">Randomness in K-means clustering</strong></p>
      <p class="normal">As K-means<a id="_idIndexMarker694"/> clustering is an algorithm with iterative approaches to updating centroids from the original randomly selected centroids, there is a randomness in K-means clustering that results in slightly different results each time it is run. If you would like to get the same results each time, you would want to set the <code class="inlineCode">random_state</code> variable.</p>
      <p class="normal">The examples in this chapter do not use the <code class="inlineCode">random_state</code> variable, so your results may look slightly different from the charts you see here.</p>
    </div>
    <p class="normal">Now, let’s visualize the clusters so that we can visually inspect how the K-means clustering algorithm has segmented the customer base using the three factors we are interested in:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> matplotlib.colors <span class="hljs-keyword">as</span> mcolors
<span class="hljs-keyword">def</span> <span class="hljs-title">plot_clusters</span>(<span class="hljs-params">c_df, col1, col2</span>):    colors = <span class="hljs-built_in">list</span>(mcolors.TABLEAU_COLORS.values())
    clusters = <span class="hljs-built_in">sorted</span>(c_df[<span class="hljs-string">"cluster"</span>].unique())
    <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> clusters:
        plt.scatter(
            c_df.loc[c_df[<span class="hljs-string">'cluster'</span>] == c][col1],
            c_df.loc[c_df[<span class="hljs-string">'cluster'</span>] == c][col2],
            c=colors[c]
        )
    plt.title(<span class="hljs-string">f'</span><span class="hljs-subst">{col1}</span><span class="hljs-string"> vs. </span><span class="hljs-subst">{col2}</span><span class="hljs-string"> Clusters'</span>)
    plt.xlabel(col1)
    plt.ylabel(col2)
    plt.legend(clusters)
    plt.show()
cluster_df = customer_df[COLS].copy()
cluster_df[<span class="hljs-string">"cluster"</span>] = kmeans.labels_
plot_clusters(cluster_df, <span class="hljs-string">"NetSales"</span>, <span class="hljs-string">"NetQuantity"</span>)
plot_clusters(cluster_df, <span class="hljs-string">"NetSales"</span>, <span class="hljs-string">"TotalRefundQuantity"</span>)
plot_clusters(cluster_df, <span class="hljs-string">"NetQuantity"</span>, <span class="hljs-string">"TotalRefundQuantity"</span>)
</code></pre>
    <p class="normal">Here, we first define<a id="_idIndexMarker695"/> a function, <code class="inlineCode">plot_clusters</code>, to 2D plot each cluster, where it takes the DataFrame as an input with the two columns for x- and y-axes. Then, we create three plots: one to visualize the clusters based on <code class="inlineCode">NetSales</code> and <code class="inlineCode">NetQuantity</code>, another for <code class="inlineCode">NetSales</code> and <code class="inlineCode">TotalRefundQuantity</code>, and a third for <code class="inlineCode">NetQuantity</code> and <code class="inlineCode">TotalRefundQuantity</code>. The three resulting plots should look like the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_08.png"/></figure>
    <p class="packt_figref">Figure 8.8: Clusters based on NetSales versus NetQuantity</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_09.png"/></figure>
    <p class="packt_figref">Figure 8.9: Clusters based on NetSales versus TotalRefundQuantity</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_10.png"/></figure>
    <p class="packt_figref">Figure 8.10: Clusters based on NetQuantity versus TotalRefundQuantity</p>
    <p class="normal">In <em class="italic">Figures 8.8</em>, <em class="italic">8</em><em class="italic">.9</em>, and <em class="italic">8.10</em>, we can easily see how clusters are formed based on the pairs. For instance, cluster <code class="inlineCode">0</code> seems to be the customers who have low net sales, low net quantity, and low refunds, and <a id="_idIndexMarker696"/>cluster <code class="inlineCode">1</code> seems to be the customers who have low-mid net sales, low-mid net quantity, and low refunds. However, there are two things that stand out in this example:</p>
    <ul>
      <li class="bulletList">Some clusters have a wide range of points. Cluster <code class="inlineCode">0</code>, as an example, has a wide range of refund quantity that ranges from <code class="inlineCode">0</code> to <code class="inlineCode">80,000</code> if you look at <em class="italic">Figure 8.10</em>. This makes it difficult to describe what cluster <code class="inlineCode">0</code> actually signifies and how it is different from other clusters.</li>
      <li class="bulletList">Another thing to note here is that most of the data points are in cluster <code class="inlineCode">0</code> and very few are in other clusters. Cluster <code class="inlineCode">3</code> seems to contain only two data points. These large imbalances in cluster sizes make generalizations from these clusters less reliable as insights based on a few data points are not so trustable.</li>
    </ul>
    <p class="normal">You can take a look at the number of data points in each cluster using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">cluster_df.groupby(<span class="hljs-string">'cluster'</span>)[<span class="hljs-string">'NetSales'</span>].count()
</code></pre>
    <p class="normal">Here are the details of each cluster:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_11.png"/></figure>
    <p class="packt_figref">Figure 8.11: The number of data points in each cluster</p>
    <p class="normal">Data skewness <a id="_idIndexMarker697"/>often causes these problems as it makes the K-means clustering algorithm difficult to find or effectively cluster the data points. This is the reason why we need to normalize the data before applying clustering algorithms when there is a skewness in the data.</p>
    <h3 class="heading-" id="_idParaDest-188">With log transformation</h3>
    <p class="normal">Let’s see how log transformation <a id="_idIndexMarker698"/>may help customer segmentation using K-means clustering. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">COLS = [<span class="hljs-string">'NetSales'</span>, <span class="hljs-string">'NetQuantity'</span>, <span class="hljs-string">'TotalRefundQuantity'</span>]
kmeans = KMeans(
    n_clusters=<span class="hljs-number">4</span>, n_init=<span class="hljs-string">"auto"</span>
).fit(
    log_customer_df[COLS]
)
cluster_df = log_customer_df[COLS].copy()
cluster_df[<span class="hljs-string">"cluster"</span>] = kmeans.labels_
</code></pre>
    <p class="normal">Here, we use the previously defined variable, <code class="inlineCode">log_customer_df</code>, which is the log-transformed data, using the <code class="inlineCode">np.log</code> function. We then fit a K-means clustering model with four clusters. We can see what the cluster sizes look like now:</p>
    <pre class="programlisting code"><code class="hljs-code">cluster_df.groupby(<span class="hljs-string">'cluster'</span>)[<span class="hljs-string">'NetSales'</span>].count()
</code></pre>
    <p class="normal">This gives us the following output:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_12.png"/></figure>
    <p class="packt_figref">Figure 8.12: The number of data points in each cluster after log transformation</p>
    <p class="normal">Compared to earlier<a id="_idIndexMarker699"/> in the chapter, when we fit the clustering model without the log transformation, the clusters are more balanced, with each cluster having a significant number of customers. This is going to give better insights into how customers are segmented based on the three factors of our interest: net sales, net quantity, and total refunds. Let’s visualize the clusters with the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">plot_clusters(cluster_df, <span class="hljs-string">"NetSales"</span>, <span class="hljs-string">"NetQuantity"</span>)
plot_clusters(cluster_df, <span class="hljs-string">"NetSales"</span>, <span class="hljs-string">"TotalRefundQuantity"</span>)
plot_clusters(cluster_df, <span class="hljs-string">"NetQuantity"</span>, <span class="hljs-string">"TotalRefundQuantity"</span>)
</code></pre>
    <p class="normal">This code should create three charts similar to the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_13.png"/></figure>
    <p class="packt_figref">Figure 8.13: Clusters on NetSales versus NetQuantity after transformation</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_14.png"/></figure>
    <p class="packt_figref">Figure 8.14: Clusters on NetSales versus TotalRefundQuantityafter transformation</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_15.png"/></figure>
    <p class="packt_figref">Figure 8.15: Clusters on NetQuantity versus TotalRefundQuantity after transformation</p>
    <p class="normal">Let’s dive deeper<a id="_idIndexMarker700"/> into these cluster visualizations. There is no clear separation between clusters based on the net sales and net quantity if you look at <em class="italic">Figure 8.13</em>. Cluster <code class="inlineCode">3</code> seems more centered around the mean, while cluster <code class="inlineCode">1</code> tends more toward higher net sales and higher net quantity, and the clusters <code class="inlineCode">0</code> and <code class="inlineCode">2</code> more toward lower net sales and lower net quantity. Despite these subtle differences, all clusters seem to cluster around the means of net sales and net quantity.</p>
    <p class="normal">The distinctions between clusters are more clear in <em class="italic">Figures 8.14</em> and <em class="italic">8</em><em class="italic">.15</em>. Cluster <code class="inlineCode">1</code> seems to be the customer segment with high total refunds, with the cutoff threshold around <code class="inlineCode">4</code> in the log scale. You can convert this log-transformed value by reverting the transformation we have applied previously or by using the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">np.exp(X) + customer_df.<span class="hljs-built_in">min</span>()[COLUMN] - <span class="hljs-number">1</span>
</code></pre>
    <p class="normal">The <code class="inlineCode">X</code> in this code is the value in the log scale and <code class="inlineCode">COLUMN</code> in this code is the factor of interest. Let’s take a closer look at these clusters:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Cluster 0</strong>: This<a id="_idIndexMarker701"/> cluster seems to be the cluster with low total refunds and low net quantity. The thresholds for <code class="inlineCode">TotalRefundQuantity</code> in the log scale are around <code class="inlineCode">2</code> and <code class="inlineCode">6.7</code> for <code class="inlineCode">NetQuantity</code>. These numbers equate to <code class="inlineCode">6.4</code> in total refunds and <code class="inlineCode">811.4</code> in net quantity, using the preceding equation. This suggests that the customers in this cluster have less than <code class="inlineCode">6.4</code> total refunds and have a net quantity less than <code class="inlineCode">811.4</code>.</li>
      <li class="bulletList"><strong class="keyWord">Cluster 1</strong>: This cluster seems to be the group of customers who have got refunds the most frequently. The cutoff threshold for cluster <code class="inlineCode">1</code> seems to be around <code class="inlineCode">4</code> in the log scale of <code class="inlineCode">TotalRefundQuantity</code> and using the code above, this equates to <code class="inlineCode">54 (np.exp(4) + customer_df.min()["TotalRefundQuantity"] - 1)</code>. Thus, cluster <code class="inlineCode">1</code> is the segment of customers with above 54 total refunds.</li>
      <li class="bulletList"><strong class="keyWord">Cluster 2</strong>: This cluster seems to be the customer segment with mid-total refunds with a threshold of around <code class="inlineCode">2</code> in the log scale of <code class="inlineCode">TotalRefundQuantity</code>, which equates to about <code class="inlineCode">6</code> in actual total refunds. Thus, cluster <code class="inlineCode">2</code> is the segment of customers with total refunds between <code class="inlineCode">6</code> and <code class="inlineCode">54</code>.</li>
      <li class="bulletList"><strong class="keyWord">Cluster 3</strong>: The customers in cluster <code class="inlineCode">3</code> seem to be the ones with low total refunds but high net quantity. This customer segment may be the sweet spot for the business as it suggests that they buy frequently from the business but do not get as many refunds as other customers in different segments. Given that their cutoff thresholds for total refunds in the log scale are around <code class="inlineCode">2</code> and <code class="inlineCode">6.7</code> for net quantity, this group of customers are the ones with less than 6 in total refunds and more than <code class="inlineCode">811</code> in net quantity.</li>
    </ul>
    <p class="normal">As you can see in this exercise, the K-means clustering algorithm is helpful in segmenting the customers in an ML way without having to define the thresholds for each customer segment manually for yourselves. This programmatic approach helps you define customer segments more dynamically and in a more data-driven way. This way, you can better understand how different customer segments are grouped and what the separating factors are, which then can be used to strategize and prioritize for your future marketing efforts.</p>
    <h2 class="heading-2" id="_idParaDest-189">Silhouette score</h2>
    <p class="normal">We have seen how to build customer segments with the K-means clustering algorithm. One of the key arguments to build the clusters was the number of clusters. However, you may wonder how to decide or how you would know the right number of clusters before you build such clusters. In a practical setting, you would want to build multiple clusters with different numbers of clusters and decide which one works the best. This is where<a id="_idIndexMarker702"/> the <strong class="keyWord">silhouette score</strong> comes in. Simply put, the silhouette score is a metric that quantifies how well a given data point fits into its cluster and how distinguishable it is from other clusters. The formula for the silhouette score looks as follows:</p>
    <p class="center"><img alt="" src="../Images/B30999_08_001.png"/></p>
    <p class="normal">Here, <em class="italic">a</em><sub class="italic">i</sub> is the average distance of the <em class="italic">i</em><sup class="superscript">th</sup> data point to all other points in the same cluster and <em class="italic">b</em><sub class="italic">i</sub> is the minimum average distance of the <em class="italic">i</em><sup class="superscript">th</sup> data point to all other points in the other clusters.</p>
    <p class="normal">In order to get the silhouette scores for a clustering algorithm, you need to get the average of all individual silhouette scores for each data point. Silhouette scores range between <code class="inlineCode">-1</code> and <code class="inlineCode">1</code>. The closer the score is to <code class="inlineCode">1</code>, the better the data points are clustered together and the more distinct they are from adjacent clusters.</p>
    <p class="normal">Silhouette scores can easily be computed in Python. The <code class="inlineCode">scikit-learn</code> package in Python has a function, <code class="inlineCode">silhouette_score</code>, which computes the average silhouette score for the clusters:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> silhouette_score
silhouette_score(
    log_customer_df[COLS],
    kmeans.labels_
)
</code></pre>
    <p class="normal">As a higher silhouette score value suggests better clusters, we can utilize this to decide what the ideal number of clusters is. Take a look at the following code, where we are experimenting with clusters of sizes from <code class="inlineCode">4</code> to <code class="inlineCode">8</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">COLS = [<span class="hljs-string">'NetSales'</span>, <span class="hljs-string">'NetQuantity'</span>, <span class="hljs-string">'TotalRefundQuantity'</span>]
f, axes = plt.subplots(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, sharey=<span class="hljs-literal">False</span>, figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">7</span>))
<span class="hljs-keyword">for</span> i, n_cluster <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>([<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]):
    kmeans = KMeans(n_clusters=n_cluster, n_init=<span class="hljs-string">"auto"</span>).fit(
        log_customer_df[COLS]
    )
    silhouette_avg = silhouette_score(
        log_customer_df[COLS],
        kmeans.labels_
    )
   
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Silhouette Score for %i Clusters: %0.4f'</span> % (n_cluster, silhouette_avg))
   
    each_cluster_size = [
        (kmeans.labels_ == i).<span class="hljs-built_in">sum</span>()/<span class="hljs-built_in">len</span>(kmeans.labels_) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_cluster)
    ]
    ax = axes[i//<span class="hljs-number">3</span>][i%<span class="hljs-number">3</span>]
    pd.DataFrame(each_cluster_size).plot(ax=ax, kind=<span class="hljs-string">"barh"</span>, color=<span class="hljs-string">"orange"</span>)
    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> ax.patches:
        ax.annotate(<span class="hljs-string">f'</span><span class="hljs-subst">{p.get_width()*</span><span class="hljs-number">100</span><span class="hljs-subst">:</span><span class="hljs-number">.01</span><span class="hljs-subst">f}</span><span class="hljs-string">%'</span>, (p.get_width(), p.get_y()+<span class="hljs-number">0.2</span>))
    ax.axvline(x=(<span class="hljs-number">1</span>/n_cluster), color=<span class="hljs-string">"red"</span>, linestyle=<span class="hljs-string">"--"</span>)
    ax.set_xlabel(<span class="hljs-string">"Cluster Size"</span>, size=<span class="hljs-number">8</span>)
    ax.set_title(<span class="hljs-string">f"Cluster #</span><span class="hljs-subst">{n_cluster}</span><span class="hljs-string"> - Silhouette: </span><span class="hljs-subst">{silhouette_avg:</span><span class="hljs-number">.02</span><span class="hljs-subst">f}</span><span class="hljs-string">"</span>)
    ax.title.set_size(<span class="hljs-number">8</span>)
f.subplots_adjust(hspace=<span class="hljs-number">0.3</span>)
plt.show()
</code></pre>
    <p class="normal">For each cluster, we compute the <a id="_idIndexMarker703"/>silhouette scores and check what percentage of data points are in each cluster. Ideally, the best cluster is the one with the highest silhouette score and the highest number of data points evenly distributed among each cluster. This code should generate the output that follows:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_16.png"/></figure>
    <p class="packt_figref">Figure 8.16: The cluster size experimentation results</p>
    <p class="normal">This chart shows a couple of important decision factors when you are figuring out what the best cluster size should be:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Silhouette scores</strong>: First, we<a id="_idIndexMarker704"/> can see the silhouette scores for each cluster size, where it is <code class="inlineCode">0.4986</code> for the cluster of size <code class="inlineCode">4</code>, <code class="inlineCode">0.5391</code> for the cluster of size <code class="inlineCode">5</code>, and so forth. Here, the silhouette score for the cluster of size <code class="inlineCode">5</code> seems to be the highest with <code class="inlineCode">0.5391</code>.</li>
      <li class="bulletList"><strong class="keyWord">Cluster sizes and compositions</strong>: We should also evaluate if the data points in each cluster are somewhat evenly distributed, as large imbalances among the clusters may not be reliable enough to generate the best insights. The horizontal bar charts in <em class="italic">Figure 8.16</em> show the cluster compositions for each cluster size. The dotted vertical line shows where the bars should be if the composition is completely evenly distributed. As can be seen in these charts, clusters with high silhouette scores do not necessarily mean the best clusters. Cluster <code class="inlineCode">5</code>, for example, has the highest overall silhouette score, but has a large imbalance where the <em class="italic">0</em><sup class="superscript">th</sup> cluster has close to 70% of data points and the rest shares a small portion of the data. This is not an ideal cluster as too much of the data is in one cluster.</li>
    </ul>
    <p class="normal">In this example, a cluster of size <code class="inlineCode">4</code> may be the best choice as the data points are more evenly distributed across the clusters compared to others, even though the silhouette score is not the highest.</p>
    <h1 class="heading-1" id="_idParaDest-190">Customer segmentation with product interests</h1>
    <p class="normal">We <a id="_idIndexMarker705"/>have discussed how we can build customer segments based on their purchase history in the previous section and how this can inform marketers on which segment to prioritize and strategize for the next marketing effort. Not only can we segment customers based on their purchase history, or more specifically with numerical values, but we can also find customer segments based on their product interests.</p>
    <p class="normal">The items that customers purchase have hidden insights into what types of items each customer is interested in and what they are likely to purchase more of. There are multiple approaches to segmenting customers based on the products that they have purchased in the past, such as simply grouping by the product categories that they have purchased from. However, in this exercise, we are going to expand on the topic of the embedding vectors that we touched on in <em class="chapterRef">Chapter 5</em>.</p>
    <div class="note">
      <p class="normal">If you have not already, you may need to install Hugging Face’s <code class="inlineCode">transformers</code> using <code class="inlineCode">pip</code>:</p>
      <pre class="programlisting con"><code class="hljs-con">pip install transformers
</code></pre>
    </div>
    <p class="normal">As previously discussed in <em class="chapterRef">Chapter 5</em>, modern LLMs <a id="_idIndexMarker706"/>like <strong class="keyWord">BERT</strong> and <strong class="keyWord">GPT</strong> introduced contextual embeddings, where the words and <a id="_idIndexMarker707"/>sentences are transformed into numerical values or vectors that represent the contextual meanings. We will be using the pre-trained LLM <code class="inlineCode">all-MiniLM-L6-v2 </code>from Hugging Face to encode past product purchases for each customer in our example dataset and build customer segments using these embedding vectors. Take a look at the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> os
os.environ[<span class="hljs-string">"TOKENIZERS_PARALLELISM"</span>] = <span class="hljs-string">"false"</span>
<span class="hljs-keyword">from</span> sentence_transformers <span class="hljs-keyword">import</span> SentenceTransformer, util
customer_item_df = pd.DataFrame(
    df.groupby(<span class="hljs-string">"CustomerID"</span>)[<span class="hljs-string">"Description"</span>].apply(
        <span class="hljs-keyword">lambda</span> x: <span class="hljs-string">", "</span>.join(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(x)))
    )
)
embedding_model = SentenceTransformer(
    <span class="hljs-string">"sentence-transformers/all-MiniLM-L6-v2"</span>
)
encoded = embedding_model.encode(
    <span class="hljs-built_in">list</span>(customer_item_df[<span class="hljs-string">"Description"</span>]),
    show_progress_bar=<span class="hljs-literal">True</span>
)
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">'tmp.npy'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:
    np.save(f, encoded)
</code></pre>
    <p class="normal">Here, we<a id="_idIndexMarker708"/> first get all the product descriptions of products that the customers have bought and then create a comma-separated list for each of the customers, which gets stored in the variable <code class="inlineCode">customer_item_df</code>. Then, we load the pre-trained LLM, <code class="inlineCode">sentence-transformers/all-MiniLM-L6-v2</code>, and encode the list of product descriptions for each customer into numerical vectors by using the <code class="inlineCode">encode</code> function of the pre-trained LLM. This will result in a vector of 384 values for each customer. We then save this array into <code class="inlineCode">tmp.npy</code> for future usage.</p>
    <p class="normal">In high-dimensional space, the distances between data points become less meaningful as the volume increases due to larger dimensions making data too sparse. As the K-means clustering algorithm uses distance metrics to cluster data points together, this becomes an issue. In order to overcome this, we need to apply some dimensionality reduction techniques. In this exercise, we will simply apply <strong class="keyWord">principal component analysis</strong> (<strong class="keyWord">PCA</strong>) to reduce the<a id="_idIndexMarker709"/> dimensions of the embedding vectors while retrieving most of the variance within the data:</p>
    <ol>
      <li class="numberedList" value="1">Take a look at the following code:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA
<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">'tmp.npy'</span>, <span class="hljs-string">'rb'</span>) <span class="hljs-keyword">as</span> f:
    encoded = np.load(f)
pca = PCA(n_components=<span class="hljs-number">5</span>)
transforemd_encoded = pca.fit_transform(encoded)
</code></pre>
      </li>
    </ol>
    <p class="normal">Here, we import the <code class="inlineCode">PCA</code> module in the <code class="inlineCode">scikit-learn</code> package. We import the previously built embedding vectors from the temporary location, <code class="inlineCode">tmp.npy</code>, and fit and transform the vector by using the <code class="inlineCode">fit_transform</code> function. We have defined it to return 5 components, as you can see from the <code class="inlineCode">n_components</code> parameter. The resulting vector, <code class="inlineCode">transforemd_encoded</code>, should have a size of 5 vectors for each customer.</p>
    <div class="packt_tip">
      <p class="normal"><strong class="keyWord">Other dimensionality reduction approaches</strong></p>
      <p class="normal">There are numerous dimensionality reduction techniques other than PCA. In our exercise, we used PCA for its simplicity, but T-SNE and UMAP are two others that are frequently used when dealing with high-dimensional data. Be sure to check them out and see if they <a id="_idIndexMarker710"/>may be a better fit for this<a id="_idIndexMarker711"/> exercise!</p>
      <p class="normal"><strong class="keyWord">T-SNE</strong>: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"><span class="url">https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html</span></a></p>
      <p class="normal"><strong class="keyWord">UMAP</strong>: <a href="https://umap-learn.readthedocs.io/en/latest/"><span class="url">https://umap-learn.readthedocs.io/en/latest/</span></a></p>
    </div>
    <ol>
      <li class="numberedList" value="2">Now it’s <a id="_idIndexMarker712"/>finally the time to build customer segments or clusters based on these embedding vectors, which have contextual understandings of the products that each customer has bought. Take a look at the following code:
        <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">from</span> sklearn.cluster <span class="hljs-keyword">import</span> KMeans
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> silhouette_samples, silhouette_score
<span class="hljs-keyword">for</span> n_cluster <span class="hljs-keyword">in</span> [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]:
    kmeans = KMeans(n_clusters=n_cluster, n_init=<span class="hljs-string">"auto"</span>).fit(
        transforemd_encoded
    )
   
    silhouette_avg = silhouette_score(
        transforemd_encoded,
        kmeans.labels_
    )
   
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Silhouette Score for %i Clusters: %0.4f'</span> % (n_cluster, silhouette_avg))
</code></pre>
      </li>
    </ol>
    <p class="normal">This <a id="_idIndexMarker713"/>code should look familiar, as this is almost the exact same code as before when we built clusters using purchase history with the K-means clustering algorithm. The main difference here is instead of the sales metrics, we use the embedding vectors as the input to <code class="inlineCode">KMeans</code> to build clusters. The output of this code should look something like the following:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_17.png"/></figure>
    <p class="packt_figref">Figure 8.17: The silhouette scores for different cluster sizes</p>
    <p class="normal">The actual values may differ as there is some randomness in fitting a K-means clustering algorithm, but the trend should be similar.</p>
    <ol>
      <li class="numberedList" value="3">Based on this, we are going to build 7 clusters based on the embedding vectors, as in the following code:
        <pre class="programlisting code"><code class="hljs-code">n_cluster = <span class="hljs-number">7</span>
kmeans = KMeans(n_clusters=n_cluster, n_init=<span class="hljs-string">"</span><span class="hljs-string">auto"</span>).fit(
    transforemd_encoded
)
customer_item_df[<span class="hljs-string">"cluster"</span>] = kmeans.labels_
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter
n_items = <span class="hljs-number">5</span>
common_items = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_cluster):
    most_common_items = Counter(<span class="hljs-built_in">list</span>(df.set_index(<span class="hljs-string">"CustomerID"</span>).loc[
            customer_item_df.loc[
            customer_item_df[<span class="hljs-string">"cluster"</span>] == i
        ].index
    ][<span class="hljs-string">"Description"</span>])).most_common(n_items)
   
    common_items.append({
        <span class="hljs-string">f"item_</span><span class="hljs-subst">{j}</span><span class="hljs-string">"</span>: most_common_items[j][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_items)
    })
common_items_df = pd.DataFrame(common_items)
</code></pre>
      </li>
    </ol>
    <p class="normal">In this code, we build 7 clusters. Then, for each cluster, we get the top 5 most common items that customers in each cluster have purchased by using the <code class="inlineCode">collections</code> library in Python. We then store these top 5 most commonly bought items for each cluster in a DataFrame named <code class="inlineCode">common_items_df</code>. This DataFrame should give us insights into what types of products interest each customer segment the most.</p>
    <p class="normal">Let’s take a closer look at <a id="_idIndexMarker714"/>this DataFrame:</p>
    <figure class="mediaobject"><img alt="" src="../Images/B30999_08_18.png"/></figure>
    <p class="packt_figref">Figure 8.18: The top 5 common items for each cluster</p>
    <p class="normal">This gives us the following insights:</p>
    <ul>
      <li class="bulletList">The customers in the first cluster or the cluster indexed at 0 seem to have the most interest in some decoration items, such as ornaments and wooden frames.</li>
      <li class="bulletList">The customers in the second cluster or the cluster indexed at 1 seem to show interest in party-related items, such as baking sets, party bunting, and cards.</li>
      <li class="bulletList">The customers in the third cluster or the cluster indexed at 2 seem to be into teas or tea ceremonies, as they bought teacups and saucers.</li>
      <li class="bulletList">The fourth cluster’s customers seem to like purchasing bags.</li>
      <li class="bulletList">The fifth cluster’s customers seem to like water bottles, and so forth.</li>
    </ul>
    <p class="normal">As you can see, these customer clusters show what they are mostly interested in and how different customers can be grouped together by their product interests. These are going to be powerful insights as you build your next marketing strategies and campaigns. You may not want to promote tea sets to those who are interested in purchasing water bottles and vice versa. This misaligned targeting will result in wasteful marketing campaigns with low success rates in engagements and conversions. You would want to take these findings about different customer segments based on their product interests and<a id="_idIndexMarker715"/> build more targeted marketing campaigns for each segment with the product categories they are most interested in. </p>
    <p class="normal">This way, you are more likely to have successful marketing campaigns with more success in drawing customer engagements and conversions.</p>
    <h1 class="heading-1" id="_idParaDest-191">Summary</h1>
    <p class="normal">In this chapter, we discussed different ways to segment the customer base. We first looked at how new versus repeat customers contribute to revenue, as well as how monthly progressions of new and repeat customer numbers can tell us which segment or group of customers to focus on during the next marketing campaigns. Then, we discussed how the K-means clustering algorithm can be used to programmatically build and identify different customer segments. Using the sales amount, order quantity, and refunds, we experimented with how these factors can be used to build different customer segments. In lieu of doing it, we touched on silhouette scores as a criterion for finding the best number of clusters and how log transformation can be beneficial when dealing with highly skewed datasets. Lastly, we used word and sentence embedding vectors to convert the product descriptions into numerical vectors with contextual understanding and further built customer segments based on their product interests.</p>
    <p class="normal">In the following chapters, we are going to explore LLMs even further. From creating compelling content using pre-trained zero-shot models to more advanced few-shot and RAG approaches, we will touch more on LLMs and generative AI in the next chapter.</p>
    <h1 class="heading-1">Join our book’s Discord space</h1>
    <p class="normal">Join our Discord community to meet like-minded people and learn alongside more than 5000 members at:</p>
    <p class="normal"><a href="https://packt.link/genai"><span class="url">https://packt.link/genai</span></a></p>
    <p class="normal"><img alt="" src="../Images/QR_Code12856128601808671.png"/></p>
  </div>
</body></html>