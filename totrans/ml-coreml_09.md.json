["```py\nprotocol ImageProcessorDelegate : class{\n\n    func onImageProcessorFinishedProcessingFrame(\n        status:Int, processedFrames:Int, framesRemaining:Int)\n\n    func onImageProcessorFinishedComposition(\n        status:Int, image:CIImage?)\n}\n```", "```py\nclass ImageProcessor{\n\n    weak var delegate : ImageProcessorDelegate?\n\n    lazy var model : VNCoreMLModel = {\n        do{\n            let model = try VNCoreMLModel(\n                for: small_unet().model\n            )\n            return model\n        } catch{\n            fatalError(\"Failed to create VNCoreMLModel\")\n        }\n    }()    \n\n    var minMaskArea:CGFloat = 0.005\n    var targetSize = CGSize(width: 448, height: 448)\n    let lock = NSLock()\n    var frames = [CIImage]()\n    var processedImages = [CIImage]()\n    var processedMasks = [CIImage]()\n    private var _processingImage = false\n\n    init(){\n\n    }\n}\n```", "```py\nextension ImageProcessor{\n\n    var isProcessingImage : Bool{\n        get{\n            self.lock.lock()\n            defer {\n                self.lock.unlock()\n            }\n            return _processingImage\n        }\n        set(value){\n            self.lock.lock()\n            _processingImage = value\n            self.lock.unlock()\n        }\n    }\n\n    var isFrameAvailable : Bool{\n        get{\n            self.lock.lock()\n            let frameAvailable =\n                    self.frames.count > 0\n            self.lock.unlock()\n            return frameAvailable\n        }\n    }\n\n    public func addFrame(frame:CIImage){\n        self.lock.lock()\n        self.frames.append(frame)\n        self.lock.unlock()\n    }\n\n    public func getNextFrame() -> CIImage?{\n        self.lock.lock()\n        let frame = self.frames.removeFirst()\n        self.lock.unlock()\n        return frame\n    }\n\n    public func reset(){\n        self.lock.lock()\n        self.frames.removeAll()\n        self.processedImages.removeAll()\n        self.processedMasks.removeAll()\n        self.lock.unlock()\n    }\n}\n```", "```py\npublic func processFrames(){\n    if !self.isProcessingImage{\n        DispatchQueue.global(qos: .background).async {\n            self.processesingNextFrame()\n        }\n    }\n}\n```", "```py\nfunc getRequest() -> VNCoreMLRequest{\n    let request = VNCoreMLRequest(\n        model: self.model,\n        completionHandler: { [weak self] request, error in\n            self?.processRequest(for: request, error: error)\n    })\n    request.imageCropAndScaleOption = .centerCrop\n    return request\n}\n\nfunc processesingNextFrame(){\n    self.isProcessingImage = true\n\n    guard let nextFrame = self.getNextFrame() else{\n        self.isProcessingImage = false\n        return\n    }\n\n    var ox : CGFloat = 0\n    var oy : CGFloat = 0\n    let frameSize = min(nextFrame.extent.width, nextFrame.extent.height)\n    if nextFrame.extent.width > nextFrame.extent.height{\n        ox = (nextFrame.extent.width - nextFrame.extent.height)/2\n    } else if nextFrame.extent.width < nextFrame.extent.height{\n        oy = (nextFrame.extent.height - nextFrame.extent.width)/2\n    }\n    guard let frame = nextFrame\n        .crop(rect: CGRect(x: ox,\n                           y: oy,\n                           width: frameSize,\n                           height: frameSize))?\n        .resize(size: targetSize) else{\n            self.isProcessingImage = false\n            return\n    }\n\n    self.processedImages.append(frame)\n    let handler = VNImageRequestHandler(ciImage: frame)\n\n    do {\n        try handler.perform([self.getRequest()])\n    } catch {\n        print(\"Failed to perform classification.\\n\\(error.localizedDescription)\")\n        self.isProcessingImage = false\n        return\n    }\n}\n```", "```py\nfunc processRequest(for request:VNRequest, error: Error?){\n    self.lock.lock()\n    let framesReaminingCount = self.frames.count\n    let processedFramesCount = self.processedImages.count\n    self.lock.unlock()\n\n ...\n}\n```", "```py\n func processRequest(for request:VNRequest, error: Error?){\n ... \n\n    guard let results = request.results,\n        let pixelBufferObservations = results as? [VNPixelBufferObservation],\n        pixelBufferObservations.count > 0 else {\n            print(\"ImageProcessor\", #function, \"ERROR:\",\n                  String(describing: error?.localizedDescription))\n\n            self.isProcessingImage = false\n\n            DispatchQueue.main.async {\n                self.delegate?.onImageProcessorFinishedProcessingFrame(\n                    status: -1,\n                    processedFrames: processedFramesCount,\n                    framesRemaining: framesReaminingCount)\n            }\n            return\n    }\n\n ...\n}\n```", "```py\nfunc processRequest(for request:VNRequest, error: Error?){\n ...\n\n let options = [\n kCIImageColorSpace:CGColorSpaceCreateDeviceGray()\n ] as [String:Any]\n\n    let ciImage = CIImage(\n        cvPixelBuffer: pixelBufferObservations[0].pixelBuffer,\n        options: options)\n\n    self.processedMasks.append(ciImage)\n\n ...\n}\n```", "```py\nfunc processRequest(for request:VNRequest, error: Error?){\n ... \n\n    DispatchQueue.main.async {\n        self.delegate?.onImageProcessorFinishedProcessingFrame(\n            status: 1,\n            processedFrames: processedFramesCount,\n            framesRemaining: framesReaminingCount)\n    }\n\n    if self.isFrameAvailable{\n        self.processesingNextFrame()\n    } else{\n        self.isProcessingImage = false\n    }\n}\n```", "```py\nfunc compositeFrames(){\n\n    var selectedIndicies = self.getIndiciesOfBestFrames()\n    if selectedIndicies.count == 0{\n        DispatchQueue.main.async {\n            self.delegate?.onImageProcessorFinishedComposition(\n                status: -1,\n                image: self.processedImages.last!)\n        }\n        return\n    }\n\n    var finalImage = self.processedImages[selectedIndicies.last!]\n    selectedIndicies.removeLast() \n    // TODO Composite final image using segments from intermediate frames\n    DispatchQueue.main.async {\n        self.delegate?.onImageProcessorFinishedComposition(\n            status: 1,\n            image: finalImage)\n    }\n}\n\nfunc getIndiciesOfBestFrames() -> [Int]{\n // TODO; find best frames for the sequence i.e. avoid excessive overlapping\n return (0..<self.processedMasks.count).map({ (i) -> Int in\n return i\n })\n}\n\nfunc getDominantDirection() -> CGPoint{\n var dir = CGPoint(x: 0, y: 0)\n // TODO detected dominate direction\n return dir\n}\n```", "```py\nvar dir = CGPoint(x: 0, y: 0)\n\nvar startCenter : CGPoint?\nvar endCenter : CGPoint?\n\n// Find startCenter\nfor i in 0..<self.processedMasks.count{\n    let mask = self.processedMasks[i]\n\n    guard let maskBB = mask.getContentBoundingBox(),\n    (maskBB.width * maskBB.height) >=\n        (mask.extent.width * mask.extent.height) * self.minMaskArea\n    else {\n        continue\n    }\n\n    startCenter = maskBB.center\n    break\n}\n\n// Find endCenter\nfor i in (0..<self.processedMasks.count).reversed(){\n    let mask = self.processedMasks[i]\n\n    guard let maskBB = mask.getContentBoundingBox(),\n    (maskBB.width * maskBB.height) >=\n        (mask.extent.width * mask.extent.height) * self.minMaskArea\n    else {\n        continue\n    }\n\n    endCenter = maskBB.center\n    break\n}\n\nif let startCenter = startCenter, let endCenter = endCenter, startCenter != endCenter{\n    dir = (startCenter - endCenter).normalised\n}\n\nreturn dir\n```", "```py\nvar selectedIndicies = [Int]()\nvar previousBoundingBox : CGRect?\nlet dir = self.getDominateDirection()\n\nfor i in (0..<self.processedMasks.count).reversed(){\n    let mask = self.processedMasks[i]\n   guard let maskBB = mask.getContentBoundingBox(),\n        maskBB.width < mask.extent.width * 0.7,\n        maskBB.height < mask.extent.height * 0.7 else {\n        continue\n    }\n\n    if previousBoundingBox == nil{\n        previousBoundingBox = maskBB\n        selectedIndicies.append(i)\n    } else{\n        let distance = abs(dir.x) >= abs(dir.y)\n            ? abs(previousBoundingBox!.center.x - maskBB.center.x)\n            : abs(previousBoundingBox!.center.y - maskBB.center.y)\n        let bounds = abs(dir.x) >= abs(dir.y)\n            ? (previousBoundingBox!.width + maskBB.width) / 4.0\n            : (previousBoundingBox!.height + maskBB.height) / 4.0\n\n        if distance > bounds * 0.5{\n            previousBoundingBox = maskBB\n            selectedIndicies.append(i)\n        }\n    }\n\n}\n\nreturn selectedIndicies.reversed()\n```", "```py\nlet distance = abs(dir.x) >= abs(dir.y)\n    ? abs(previousBoundingBox!.center.x - maskBB.center.x)\n    : abs(previousBoundingBox!.center.y - maskBB.center.y) \n```", "```py\nlet bounds = abs(dir.x) >= abs(dir.y)\n    ? (previousBoundingBox!.width + maskBB.width) / 2.0\n    : (previousBoundingBox!.height + maskBB.height) / 2.0\n```", "```py\nif distance > bounds * 0.15{\n    previousBoundingBox = maskBB\n    selectedIndicies.append(i)\n}\n```", "```py\nlazy var compositeKernel : CIColorKernel? = {\n    let kernelString = \"\"\"\n        kernel vec4 compositeFilter(\n            __sample image,\n            __sample overlay,\n            __sample overlay_mask,\n            float alpha){\n            float overlayStrength = 0.0;\n\n            if(overlay_mask.r > 0.0){\n                overlayStrength = 1.0;\n            }\n\n            overlayStrength *= alpha;\n\n            return vec4(image.rgb * (1.0-overlayStrength), 1.0)\n                + vec4(overlay.rgb * (overlayStrength), 1.0);\n        }\n    \"\"\"\n    return CIColorKernel(source:kernelString)\n}()\n```", "```py\nlet alphaStep : CGFloat = 1.0 / CGFloat(selectedIndicies.count)\n\nfor i in selectedIndicies{\n    let image = self.processedImages[i]\n    let mask = self.processedMasks[i]\n\n    let extent = image.extent\n    let alpha = CGFloat(i + 1) * alphaStep\n    let arguments = [finalImage, image, mask, min(alpha, 1.0)] as [Any]\n    if let compositeFrame = self.compositeKernel?.apply(extent: extent, arguments: arguments){\n        finalImage = compositeFrame\n    }\n}\n```"]