["```py\n    import os\n    import boto3\n    ```", "```py\n    BUCKET_NAME = '<insert a unique bucket name>' \n    BUCKET_FOLDER = 'negative_movie_review_files/' \n    ```", "```py\n    LOCAL_PATH = os.getcwd() +'\\\\local_folder__negative_movie_review_files\\\\'\n    ```", "```py\n    text_files_list = [f for f in os.listdir(LOCAL_PATH) if f.endswith('.txt')]\n    ```", "```py\n    for filename in text_files_list:\n        s3.upload_file(LOCAL_PATH + filename, BUCKET_NAME, BUCKET_FOLDER + filename)\n    ```", "```py\n    import boto3\n    ```", "```py\n    import pandas as pd \n    ```", "```py\n    s3 = boto3.client('s3')\n    ```", "```py\n    bucket_name = '<insert a unique bucket name>' #  \n    ```", "```py\n    s3.create_bucket(Bucket=bucket_name)\n    ```", "```py\n    filenames_list = ['doc-topics.csv', 'topic-terms.csv']\n    ```", "```py\n    for filename in filenames_list:\n        s3.upload_file(filename, bucket_name, filename)\n    ```", "```py\n        if filename == 'doc-topics.csv':\n    ```", "```py\n    obj = s3.get_object(Bucket=bucket_name, Key=filename)\n    ```", "```py\n            doc_topics = pd.read_csv(obj['Body'])\n        else:\n            obj = s3.get_object(Bucket=bucket_name, Key=filename)\n            topic_terms = pd.read_csv(obj['Body'])\n    ```", "```py\n    merged_df = pd.merge(doc_topics, topic_terms, on='topic')\n    ```", "```py\n    print(merged_df) \n    ```", "```py\n    \"python local_csv_to_s3_for_analysis.py\"\n    ```", "```py\nI want a {size} {crust} crust {pizzaKind} pizza\n```", "```py\nI want a large thin crust cheese pizza\n```"]