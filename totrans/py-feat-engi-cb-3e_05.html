<html><head></head><body>
<div id="_idContainer093">
<h1 class="chapter-number" id="_idParaDest-144"><a id="_idTextAnchor662"/><span class="koboSpan" id="kobo.1.1" xmlns:="http://www.w3.org/1999/xhtml">5</span></h1>
<h1 id="_idParaDest-145"><a id="_idTextAnchor663"/><a id="_idTextAnchor664"/><span class="koboSpan" id="kobo.2.1" xmlns:="http://www.w3.org/1999/xhtml">Working with Outliers</span></h1>
<p><span class="koboSpan" id="kobo.3.1" xmlns:="http://www.w3.org/1999/xhtml">An outlier</span><a id="_idIndexMarker360"/><span class="koboSpan" id="kobo.4.1" xmlns:="http://www.w3.org/1999/xhtml"> is a data point that diverges notably from other values within a variable. </span><span class="koboSpan" id="kobo.4.2" xmlns:="http://www.w3.org/1999/xhtml">Outliers may stem from the inherent variability of the feature itself, manifesting as extreme values that occur infrequently within the distribution (typically found in the tails). </span><span class="koboSpan" id="kobo.4.3" xmlns:="http://www.w3.org/1999/xhtml">They can be the result of experimental errors or inaccuracies in data collection processes, or they can signal important events. </span><span class="koboSpan" id="kobo.4.4" xmlns:="http://www.w3.org/1999/xhtml">For instance, an unusually high expense in a card transaction may indicate fraudulent activity, warranting flagging and potentially blocking the card to safeguard customers. </span><span class="koboSpan" id="kobo.4.5" xmlns:="http://www.w3.org/1999/xhtml">Similarly, unusually distinct tumor morphologies can suggest malignancy, prompting </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1" xmlns:="http://www.w3.org/1999/xhtml">further examination.</span></span></p>
<p><span class="koboSpan" id="kobo.6.1" xmlns:="http://www.w3.org/1999/xhtml">Outliers can exert a disproportionately large impact on a statistical analysis. </span><span class="koboSpan" id="kobo.6.2" xmlns:="http://www.w3.org/1999/xhtml">For example, a small number of outliers can reverse the statistical significance of a test in either direction (think A/B testing) or directly influence the estimation of the parameters of the statistical model (think coefficients). </span><span class="koboSpan" id="kobo.6.3" xmlns:="http://www.w3.org/1999/xhtml">Some machine learning models are well known for being susceptible to outliers, such as linear regression. </span><span class="koboSpan" id="kobo.6.4" xmlns:="http://www.w3.org/1999/xhtml">Other models are known for being robust to outliers, such as decision-tree-based models. </span><span class="koboSpan" id="kobo.6.5" xmlns:="http://www.w3.org/1999/xhtml">AdaBoost is said to be sensitive to outliers in the target variable, and in principle, distance-based models, such as PCA and KNN, could also be affected by the presence </span><span class="No-Break"><span class="koboSpan" id="kobo.7.1" xmlns:="http://www.w3.org/1999/xhtml">of outliers.</span></span></p>
<p><span class="koboSpan" id="kobo.8.1" xmlns:="http://www.w3.org/1999/xhtml">There isn’t a strict mathematical definition for what qualifies as an outlier, and there is also no consensus on how to handle outliers in statistical or machine learning models. </span><span class="koboSpan" id="kobo.8.2" xmlns:="http://www.w3.org/1999/xhtml">If outliers stem from flawed data collection, discarding them seems like a safe option. </span><span class="koboSpan" id="kobo.8.3" xmlns:="http://www.w3.org/1999/xhtml">However, in many datasets, pinpointing the exact nature of outliers is challenging. </span><span class="koboSpan" id="kobo.8.4" xmlns:="http://www.w3.org/1999/xhtml">Ultimately, detecting and handling outliers remains a subjective exercise, reliant on domain knowledge and an understanding of their potential impact </span><span class="No-Break"><span class="koboSpan" id="kobo.9.1" xmlns:="http://www.w3.org/1999/xhtml">on models.</span></span></p>
<p><span class="koboSpan" id="kobo.10.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will begin by discussing methods to identify potential outliers, or more precisely, observations that significantly deviate from the rest. </span><span class="koboSpan" id="kobo.10.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we’ll proceed under the assumption that these observations are not relevant for the analysis, and show how to either remove them or reduce their impact on models </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1" xmlns:="http://www.w3.org/1999/xhtml">through truncation.</span></span></p>
<p><span class="koboSpan" id="kobo.12.1" xmlns:="http://www.w3.org/1999/xhtml">This chapter contains the </span><span class="No-Break"><span class="koboSpan" id="kobo.13.1" xmlns:="http://www.w3.org/1999/xhtml">following recipes:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.14.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule</span></span></li>
<li><span class="koboSpan" id="kobo.16.1" xmlns:="http://www.w3.org/1999/xhtml">Finding outliers using the mean and </span><span class="No-Break"><span class="koboSpan" id="kobo.17.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation</span></span></li>
<li><span class="koboSpan" id="kobo.18.1" xmlns:="http://www.w3.org/1999/xhtml">Using the median absolute deviation to </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1" xmlns:="http://www.w3.org/1999/xhtml">find outliers</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.20.1" xmlns:="http://www.w3.org/1999/xhtml">Removing outliers</span></span></li>
<li><span class="koboSpan" id="kobo.21.1" xmlns:="http://www.w3.org/1999/xhtml">Bringing outliers back within </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1" xmlns:="http://www.w3.org/1999/xhtml">acceptable limits</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.23.1" xmlns:="http://www.w3.org/1999/xhtml">Applying winsorization</span></span><a id="_idTextAnchor665"/><a id="_idTextAnchor666"/></li>
</ul>
<h1 id="_idParaDest-146"><a id="_idTextAnchor667"/><span class="koboSpan" id="kobo.24.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.25.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will use the Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.26.1" xmlns:="http://www.w3.org/1999/xhtml">numpy</span></strong><span class="koboSpan" id="kobo.27.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.28.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.29.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.30.1" xmlns:="http://www.w3.org/1999/xhtml">matplotlib</span></strong><span class="koboSpan" id="kobo.31.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.32.1" xmlns:="http://www.w3.org/1999/xhtml">seaborn</span></strong><span class="koboSpan" id="kobo.33.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.34.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.35.1" xmlns:="http://www.w3.org/1999/xhtml"> libraries.</span></span><a id="_idTextAnchor668"/><a id="_idTextAnchor669"/></p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor670"/><span class="koboSpan" id="kobo.36.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile proximity rule</span></h1>
<p><span class="koboSpan" id="kobo.37.1" xmlns:="http://www.w3.org/1999/xhtml">A </span><a id="_idIndexMarker361"/><span class="koboSpan" id="kobo.38.1" xmlns:="http://www.w3.org/1999/xhtml">common way to visualize outliers is by usin</span><a id="_idTextAnchor671"/><span class="koboSpan" id="kobo.39.1" xmlns:="http://www.w3.org/1999/xhtml">g boxplots. </span><span class="koboSpan" id="kobo.39.2" xmlns:="http://www.w3.org/1999/xhtml">Boxplots </span><a id="_idIndexMarker362"/><span class="koboSpan" id="kobo.40.1" xmlns:="http://www.w3.org/1999/xhtml">provide a standardized display of the variable’s distribution based on quartiles. </span><span class="koboSpan" id="kobo.40.2" xmlns:="http://www.w3.org/1999/xhtml">The box contains the observations within the first and third quartiles, known as the </span><strong class="bold"><span class="koboSpan" id="kobo.41.1" xmlns:="http://www.w3.org/1999/xhtml">Inter-Quartile Range</span></strong><strong class="bold"> </strong><span class="koboSpan" id="kobo.42.1" xmlns:="http://www.w3.org/1999/xhtml">(</span><strong class="bold"><span class="koboSpan" id="kobo.43.1" xmlns:="http://www.w3.org/1999/xhtml">IQR</span></strong><span class="koboSpan" id="kobo.44.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.44.2" xmlns:="http://www.w3.org/1999/xhtml">The</span><a id="_idIndexMarker363"/><span class="koboSpan" id="kobo.45.1" xmlns:="http://www.w3.org/1999/xhtml"> first quartile is the value below which 25% of the observations lie (equivalent to the 25th percentile), while the third quartile is the value below which 75% of the observations lie (equivalent to the 75th percentile). </span><span class="koboSpan" id="kobo.45.2" xmlns:="http://www.w3.org/1999/xhtml">The IQR is calculated </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1" xmlns:="http://www.w3.org/1999/xhtml">as follows:</span></span></p>
<p><span class="koboSpan" id="kobo.47.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mi&gt;Q&lt;/mml:mi&gt;&lt;mml:mi&gt;R&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mi&gt;s&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:mi&gt;q&lt;/mml:mi&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;mml:mi&gt;a&lt;/mml:mi&gt;&lt;mml:mi&gt;r&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;l&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;/mml:math&gt;" src="image/21.png" style="vertical-align:-0.252em;height:0.963em;width:13.330em"/></span></p>
<p><span class="koboSpan" id="kobo.48.1" xmlns:="http://www.w3.org/1999/xhtml">Boxplots also </span><a id="_idIndexMarker364"/><span class="koboSpan" id="kobo.49.1" xmlns:="http://www.w3.org/1999/xhtml">display whiskers, which are lines that protrude from each end of the box toward the minimum and maximum values and up to a limit. </span><span class="koboSpan" id="kobo.49.2" xmlns:="http://www.w3.org/1999/xhtml">These limits are given by the minimum or maximum value of the distribution or, in the presence of extreme values, by the </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1" xmlns:="http://www.w3.org/1999/xhtml">following equations:</span></span></p>
<p><span class="koboSpan" id="kobo.51.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mn&gt;1.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/22.png" style="vertical-align:-0.252em;height:0.963em;width:15.427em"/></span></p>
<p><span class="koboSpan" id="kobo.52.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;I&lt;/mi&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mn&gt;1.5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/23.png" style="vertical-align:-0.252em;height:0.963em;width:15.092em"/></span></p>
<p><span class="koboSpan" id="kobo.53.1" xmlns:="http://www.w3.org/1999/xhtml">According to the </span><strong class="bold"><span class="koboSpan" id="kobo.54.1" xmlns:="http://www.w3.org/1999/xhtml">IQR proximity rule</span></strong><span class="koboSpan" id="kobo.55.1" xmlns:="http://www.w3.org/1999/xhtml">, we</span><a id="_idIndexMarker365"/><span class="koboSpan" id="kobo.56.1" xmlns:="http://www.w3.org/1999/xhtml"> can consider a value an</span><a id="_idIndexMarker366"/><span class="koboSpan" id="kobo.57.1" xmlns:="http://www.w3.org/1999/xhtml"> outlier if it falls beyond the whisker limits determined by the previous equations. </span><span class="koboSpan" id="kobo.57.2" xmlns:="http://www.w3.org/1999/xhtml">In boxplots, outliers are indicated </span><span class="No-Break"><span class="koboSpan" id="kobo.58.1" xmlns:="http://www.w3.org/1999/xhtml">as dots.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.59.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.60.1" xmlns:="http://www.w3.org/1999/xhtml">If the variable has a normal distribution, about 99% of the observations will be located within the interval delimited by the whiskers. </span><span class="koboSpan" id="kobo.60.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, we can treat values beyond the whiskers as outliers. </span><span class="koboSpan" id="kobo.60.3" xmlns:="http://www.w3.org/1999/xhtml">Boxplots are, however, non-parametric, which is why we also use them to visualize outliers in </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1" xmlns:="http://www.w3.org/1999/xhtml">skewed variables.</span></span></p>
<p><span class="koboSpan" id="kobo.62.1" xmlns:="http://www.w3.org/1999/xhtml">In this </span><a id="_idIndexMarker367"/><span class="koboSpan" id="kobo.63.1" xmlns:="http://www.w3.org/1999/xhtml">recipe, we’ll begin by visualizing the variable distribution with boxplots, and then we’ll calculate the whisker’s limits manually to identify the points beyond which we could consider a value as </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1" xmlns:="http://www.w3.org/1999/xhtml">an o</span><a id="_idTextAnchor672"/><a id="_idTextAnchor673"/><span class="koboSpan" id="kobo.65.1" xmlns:="http://www.w3.org/1999/xhtml">utlier.</span></span></p>
<h2 id="_idParaDest-148"><a id="_idTextAnchor674"/><span class="koboSpan" id="kobo.66.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><a id="_idTextAnchor675"/><span class="koboSpan" id="kobo.67.1" xmlns:="http://www.w3.org/1999/xhtml">We will create boxplots utilizing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.68.1" xmlns:="http://www.w3.org/1999/xhtml">seaborn</span></strong><span class="koboSpan" id="kobo.69.1" xmlns:="http://www.w3.org/1999/xhtml"> library</span><a id="_idTextAnchor676"/><span class="koboSpan" id="kobo.70.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.70.2" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by importing the Python libraries and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.72.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the Python libraries and </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.74.1" xmlns:="http://www.w3.org/1999/xhtml">
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing</span></pre></li> <li><span class="koboSpan" id="kobo.75.1" xmlns:="http://www.w3.org/1999/xhtml">Modify the default background from </span><strong class="source-inline"><span class="koboSpan" id="kobo.76.1" xmlns:="http://www.w3.org/1999/xhtml">seaborn</span></strong><span class="koboSpan" id="kobo.77.1" xmlns:="http://www.w3.org/1999/xhtml"> (it makes prettier plots, but that’s subjective, </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1" xmlns:="http://www.w3.org/1999/xhtml">of course):</span></span><pre class="source-code"><span class="koboSpan" id="kobo.79.1" xmlns:="http://www.w3.org/1999/xhtml">
sns.set(style="darkgrid")</span></pre></li> <li><span class="koboSpan" id="kobo.80.1" xmlns:="http://www.w3.org/1999/xhtml">Load the California house prices dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.82.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)</span></pre></li> <li><span class="koboSpan" id="kobo.83.1" xmlns:="http://www.w3.org/1999/xhtml">Make a boxplot of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.84.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.85.1" xmlns:="http://www.w3.org/1999/xhtml"> variable to visualize </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1" xmlns:="http://www.w3.org/1999/xhtml">its distribution:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.87.1" xmlns:="http://www.w3.org/1999/xhtml">
plt.figure(figsize=(8, 3))
sns.boxplot(data=X["MedInc"], orient="y")
plt.title("Boxplot")
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.88.1" xmlns:="http://www.w3.org/1999/xhtml">In the following boxplot, we identify the box containing the observations within the IQR, that is, the observations between the first and third quartiles. </span><span class="koboSpan" id="kobo.88.2" xmlns:="http://www.w3.org/1999/xhtml">We also see the whiskers. </span><span class="koboSpan" id="kobo.88.3" xmlns:="http://www.w3.org/1999/xhtml">On</span><a id="_idIndexMarker368"/><span class="koboSpan" id="kobo.89.1" xmlns:="http://www.w3.org/1999/xhtml"> the left, the whisker extends to the minimum value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.91.1" xmlns:="http://www.w3.org/1999/xhtml">; on the right, the whisker goes up to the third quartile plus 1.5 times the IQR. </span><span class="koboSpan" id="kobo.91.2" xmlns:="http://www.w3.org/1999/xhtml">Values beyond the right whisker are represented as dots and could </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1" xmlns:="http://www.w3.org/1999/xhtml">constitute out</span><a id="_idTextAnchor677"/><span class="koboSpan" id="kobo.93.1" xmlns:="http://www.w3.org/1999/xhtml">liers:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer084">
<span class="koboSpan" id="kobo.94.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.1 – Boxplot of the MedInc variable highlighting potential outliers on the right tail of the distribution" src="image/B22396_05_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.95.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.1 – Boxplot of the MedInc variable highlighting potential outliers on the right tail of the distribution</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.96.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.97.1" xmlns:="http://www.w3.org/1999/xhtml">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.98.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.99.1" xmlns:="http://www.w3.org/1999/xhtml">.1</span></em><span class="koboSpan" id="kobo.100.1" xmlns:="http://www.w3.org/1999/xhtml">, the boxplot returns asymmetric boundaries denoted by the varying lengths of the left and right whiskers. </span><span class="koboSpan" id="kobo.100.2" xmlns:="http://www.w3.org/1999/xhtml">This makes boxplots a suitable method for identifying outliers in highly skewed distributions. </span><span class="koboSpan" id="kobo.100.3" xmlns:="http://www.w3.org/1999/xhtml">As we’ll see in the coming recipes, alternative methods to identify outliers create symmetric boundaries around the center of the distribution, which may not be the best option for </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1" xmlns:="http://www.w3.org/1999/xhtml">asymmetric distributions</span><a id="_idTextAnchor678"/><span class="koboSpan" id="kobo.102.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.103.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s now create a function to</span><a id="_idTextAnchor679"/><span class="koboSpan" id="kobo.104.1" xmlns:="http://www.w3.org/1999/xhtml"> plot a boxplot next to </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1" xmlns:="http://www.w3.org/1999/xhtml">a histogram:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.106.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_boxplot_and_hist(data, variable):
    f, (ax_box, ax_hist) = plt.subplots(
        2, sharex=True,
        gridspec_kw={"height_ratios": (0.50, 0.85)})
    sns.boxplot(x=data[variable], ax=ax_box)
    sns.histplot(data=data, x=variable, ax=ax_hist)
    plt.show(</span><a id="_idTextAnchor680"/><span class="koboSpan" id="kobo.107.1" xmlns:="http://www.w3.org/1999/xhtml">)</span></pre></li> <li><span class="koboSpan" id="kobo.108.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s use </span><a id="_idIndexMarker369"/><span class="koboSpan" id="kobo.109.1" xmlns:="http://www.w3.org/1999/xhtml">the previous </span><a id="_idTextAnchor681"/><span class="koboSpan" id="kobo.110.1" xmlns:="http://www.w3.org/1999/xhtml">function to create the plots for the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.111.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.112.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.113.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X, "MedInc")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.114.1" xmlns:="http://www.w3.org/1999/xhtml">In the following figure, we can see the relationship between the boxplot and the variable’s distribution shown in the histogram. </span><span class="koboSpan" id="kobo.114.2" xmlns:="http://www.w3.org/1999/xhtml">Note how most of </span><strong class="source-inline"><span class="koboSpan" id="kobo.115.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.116.1" xmlns:="http://www.w3.org/1999/xhtml">’s observations are located within the IQR box. </span><strong class="source-inline"><span class="koboSpan" id="kobo.117.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.118.1" xmlns:="http://www.w3.org/1999/xhtml">’s potential outliers lie on the right tail, corresponding to people with unusually </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1" xmlns:="http://www.w3.org/1999/xhtml">high-income sa</span><a id="_idTextAnchor682"/><span class="koboSpan" id="kobo.120.1" xmlns:="http://www.w3.org/1999/xhtml">laries:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer085">
<span class="koboSpan" id="kobo.121.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.2 – Boxplot and histogram – two ways of displaying a variable’s distribution" src="image/B22396_05_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.122.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.2 – Boxplot and histogram – two ways of displaying a variable’s distribution</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.123.1" xmlns:="http://www.w3.org/1999/xhtml">Now that </span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.124.1" xmlns:="http://www.w3.org/1999/xhtml">we’ve seen how we can visualize outliers, let’s see how to calculate the limits beyond which we find outliers at each side of </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1" xmlns:="http://www.w3.org/1999/xhtml">the distribution.</span></span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.126.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a function that returns the limits based on the IQR </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.128.1" xmlns:="http://www.w3.org/1999/xhtml">
def find_limits(df, variable, fold):
    q1 = df[variable].quantile(0.25)
    q3 = df[variable].quantile(0.75)
    IQR = q3 - q1
    lower_limit = q1 - (IQR * fold)
    upper_limit = q3 + (IQR * fold)
    return lower_limit, upper_limit</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.129.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.130.1" xmlns:="http://www.w3.org/1999/xhtml">Remember that the first and third quartiles are equivalent to the 25th and 75th percentiles. </span><span class="koboSpan" id="kobo.130.2" xmlns:="http://www.w3.org/1999/xhtml">That’s why we use pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.131.1" xmlns:="http://www.w3.org/1999/xhtml">quantile</span></strong><span class="koboSpan" id="kobo.132.1" xmlns:="http://www.w3.org/1999/xhtml"> to determine </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1" xmlns:="http://www.w3.org/1999/xhtml">those values.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.134.1" xmlns:="http://www.w3.org/1999/xhtml">With the function from </span><em class="italic"><span class="koboSpan" id="kobo.135.1" xmlns:="http://www.w3.org/1999/xhtml">step 7</span></em><span class="koboSpan" id="kobo.136.1" xmlns:="http://www.w3.org/1999/xhtml">, we’ll calculate the extreme limits </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1" xmlns:="http://www.w3.org/1999/xhtml">for </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.138.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.139.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.140.1" xmlns:="http://www.w3.org/1999/xhtml">
lower_limit, upper_limit = find_limits(
    X, "MedInc", 1.5)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.141.1" xmlns:="http://www.w3.org/1999/xhtml">If we now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.142.1" xmlns:="http://www.w3.org/1999/xhtml">lower_limit</span></strong><span class="koboSpan" id="kobo.143.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1" xmlns:="http://www.w3.org/1999/xhtml">upper_limit</span></strong><span class="koboSpan" id="kobo.145.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the values </span><strong class="source-inline"><span class="koboSpan" id="kobo.146.1" xmlns:="http://www.w3.org/1999/xhtml">-0.7063</span></strong><span class="koboSpan" id="kobo.147.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1" xmlns:="http://www.w3.org/1999/xhtml">8.013</span></strong><span class="koboSpan" id="kobo.149.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.149.2" xmlns:="http://www.w3.org/1999/xhtml">The lower limit is beyond </span><strong class="source-inline"><span class="koboSpan" id="kobo.150.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.151.1" xmlns:="http://www.w3.org/1999/xhtml">’s minimum value, hence in </span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.152.1" xmlns:="http://www.w3.org/1999/xhtml">the boxplot, the whisker only goes up to the minimum value. </span><span class="koboSpan" id="kobo.152.2" xmlns:="http://www.w3.org/1999/xhtml">The upper limit, on the other hand, coincides with the right </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1" xmlns:="http://www.w3.org/1999/xhtml">whisker’s limit.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.154.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.155.1" xmlns:="http://www.w3.org/1999/xhtml">Common values to multiply the IQR are </span><strong class="source-inline"><span class="koboSpan" id="kobo.156.1" xmlns:="http://www.w3.org/1999/xhtml">1.5</span></strong><span class="koboSpan" id="kobo.157.1" xmlns:="http://www.w3.org/1999/xhtml">, which is the default value in boxplots, or </span><strong class="source-inline"><span class="koboSpan" id="kobo.158.1" xmlns:="http://www.w3.org/1999/xhtml">3 </span></strong><span class="koboSpan" id="kobo.159.1" xmlns:="http://www.w3.org/1999/xhtml">if we want to be </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1" xmlns:="http://www.w3.org/1999/xhtml">more conservative.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.161.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s display the box plot and histogram for the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.162.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.163.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.164.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X, "HouseAge")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.165.1" xmlns:="http://www.w3.org/1999/xhtml">We can see that this variable does not seem to contain outliers, and hence the whiskers in the box plot extend to the minimum and </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1" xmlns:="http://www.w3.org/1999/xhtml">maximum values:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer086">
<span class="koboSpan" id="kobo.167.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.3 – Boxplot and histogram of the HouseAge variable" src="image/B22396_05_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.168.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.3 – Boxplot and histogram of the HouseAge variable</span></p>
<ol>
<li value="10"><span class="koboSpan" id="kobo.169.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s</span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.170.1" xmlns:="http://www.w3.org/1999/xhtml"> find the variable’s limits according to the IQR </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.172.1" xmlns:="http://www.w3.org/1999/xhtml">
lower_limit, upper_limit = find_limits(
    X, "HouseAge", 1.5)</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.173.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.174.1" xmlns:="http://www.w3.org/1999/xhtml">lower_limit</span></strong><span class="koboSpan" id="kobo.175.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1" xmlns:="http://www.w3.org/1999/xhtml">upper_limit</span></strong><span class="koboSpan" id="kobo.177.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the values </span><strong class="source-inline"><span class="koboSpan" id="kobo.178.1" xmlns:="http://www.w3.org/1999/xhtml">-10.5</span></strong><span class="koboSpan" id="kobo.179.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.180.1" xmlns:="http://www.w3.org/1999/xhtml">65.5</span></strong><span class="koboSpan" id="kobo.181.1" xmlns:="http://www.w3.org/1999/xhtml">, which are beyond the edges of the plots, and hence we don’t see </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1" xmlns:="http://www.w3.org/1999/xhtml">any </span><a id="_idTextAnchor683"/><a id="_idTextAnchor684"/><span class="koboSpan" id="kobo.183.1" xmlns:="http://www.w3.org/1999/xhtml">outliers.</span></span></p>
<h2 id="_idParaDest-149"><span class="koboSpan" id="kobo.184.1" xmlns:="http://www.w3.org/1999/xhtml">How it works</span><a id="_idTextAnchor685"/><span class="koboSpan" id="kobo.185.1" xmlns:="http://www.w3.org/1999/xhtml">…</span></h2>
<p><span class="koboSpan" id="kobo.186.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.187.1" xmlns:="http://www.w3.org/1999/xhtml">boxplot</span></strong><span class="koboSpan" id="kobo.188.1" xmlns:="http://www.w3.org/1999/xhtml"> method from Seaborn to create the boxplots and then we calculated the limits beyond which a value could be considered an outlier based on the IQR </span><span class="No-Break"><span class="koboSpan" id="kobo.189.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule.</span></span></p>
<p><span class="koboSpan" id="kobo.190.1" xmlns:="http://www.w3.org/1999/xhtml">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.191.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.192.1" xmlns:="http://www.w3.org/1999/xhtml">.2</span></em><span class="koboSpan" id="kobo.193.1" xmlns:="http://www.w3.org/1999/xhtml">, we saw that the box in the boxplot for </span><strong class="source-inline"><span class="koboSpan" id="kobo.194.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.195.1" xmlns:="http://www.w3.org/1999/xhtml"> extended from approximately 2 to 5, corresponding to the first and third quantiles (you can determine these values precisely by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.196.1" xmlns:="http://www.w3.org/1999/xhtml">X[</span></strong><span class="koboSpan" id="kobo.197.1" xmlns:="http://www.w3.org/1999/xhtml">“</span><strong class="source-inline"><span class="koboSpan" id="kobo.198.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.199.1" xmlns:="http://www.w3.org/1999/xhtml">”</span><strong class="source-inline"><span class="koboSpan" id="kobo.200.1" xmlns:="http://www.w3.org/1999/xhtml">].quantile(0.25)</span></strong><span class="koboSpan" id="kobo.201.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.202.1" xmlns:="http://www.w3.org/1999/xhtml">X[</span></strong><span class="koboSpan" id="kobo.203.1" xmlns:="http://www.w3.org/1999/xhtml">“</span><strong class="source-inline"><span class="koboSpan" id="kobo.204.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.205.1" xmlns:="http://www.w3.org/1999/xhtml">”</span><strong class="source-inline"><span class="koboSpan" id="kobo.206.1" xmlns:="http://www.w3.org/1999/xhtml">].quantile(0.75)</span></strong><span class="koboSpan" id="kobo.207.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.207.2" xmlns:="http://www.w3.org/1999/xhtml">We also saw that the whiskers start at </span><strong class="source-inline"><span class="koboSpan" id="kobo.208.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.209.1" xmlns:="http://www.w3.org/1999/xhtml">’s minimum on the left and extend up to </span><strong class="source-inline"><span class="koboSpan" id="kobo.210.1" xmlns:="http://www.w3.org/1999/xhtml">8.013</span></strong><span class="koboSpan" id="kobo.211.1" xmlns:="http://www.w3.org/1999/xhtml"> on the right (we know this value exactly because we calculated it in </span><em class="italic"><span class="koboSpan" id="kobo.212.1" xmlns:="http://www.w3.org/1999/xhtml">step 8</span></em><span class="koboSpan" id="kobo.213.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><strong class="source-inline"><span class="koboSpan" id="kobo.214.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.215.1" xmlns:="http://www.w3.org/1999/xhtml"> showed values greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.216.1" xmlns:="http://www.w3.org/1999/xhtml">8.013</span></strong><span class="koboSpan" id="kobo.217.1" xmlns:="http://www.w3.org/1999/xhtml">, which were displayed</span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.218.1" xmlns:="http://www.w3.org/1999/xhtml"> in the boxplot as dots. </span><span class="koboSpan" id="kobo.218.2" xmlns:="http://www.w3.org/1999/xhtml">Those are the values that could be </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1" xmlns:="http://www.w3.org/1999/xhtml">considered outliers.</span></span></p>
<p><span class="koboSpan" id="kobo.220.1" xmlns:="http://www.w3.org/1999/xhtml">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.221.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.222.1" xmlns:="http://www.w3.org/1999/xhtml">.3</span></em><span class="koboSpan" id="kobo.223.1" xmlns:="http://www.w3.org/1999/xhtml">, we displayed the boxplot for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.224.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.225.1" xmlns:="http://www.w3.org/1999/xhtml"> variable. </span><span class="koboSpan" id="kobo.225.2" xmlns:="http://www.w3.org/1999/xhtml">The box included values ranging from approximately 18 to 35 (you can determine the precise values by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.226.1" xmlns:="http://www.w3.org/1999/xhtml">X[</span></strong><span class="koboSpan" id="kobo.227.1" xmlns:="http://www.w3.org/1999/xhtml">“</span><strong class="source-inline"><span class="koboSpan" id="kobo.228.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.229.1" xmlns:="http://www.w3.org/1999/xhtml">”</span><strong class="source-inline"><span class="koboSpan" id="kobo.230.1" xmlns:="http://www.w3.org/1999/xhtml">].quantile(0.25)</span></strong><span class="koboSpan" id="kobo.231.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.232.1" xmlns:="http://www.w3.org/1999/xhtml">X[</span></strong><span class="koboSpan" id="kobo.233.1" xmlns:="http://www.w3.org/1999/xhtml">“</span><strong class="source-inline"><span class="koboSpan" id="kobo.234.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge</span></strong><span class="koboSpan" id="kobo.235.1" xmlns:="http://www.w3.org/1999/xhtml">”</span><strong class="source-inline"><span class="koboSpan" id="kobo.236.1" xmlns:="http://www.w3.org/1999/xhtml">].quantile(0.75)</span></strong><span class="koboSpan" id="kobo.237.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.237.2" xmlns:="http://www.w3.org/1999/xhtml">The whiskers extended to the minimum and maximum values of the distribution. </span><span class="koboSpan" id="kobo.237.3" xmlns:="http://www.w3.org/1999/xhtml">The limits of the whiskers in the plot did not coincide with those based on the IQR proximity rule (which we calculated in </span><em class="italic"><span class="koboSpan" id="kobo.238.1" xmlns:="http://www.w3.org/1999/xhtml">step 10</span></em><span class="koboSpan" id="kobo.239.1" xmlns:="http://www.w3.org/1999/xhtml">) because these limits were far beyond the value range observed for </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1" xmlns:="http://www.w3.org/1999/xhtml">this</span><a id="_idTextAnchor686"/><a id="_idTextAnchor687"/><span class="koboSpan" id="kobo.241.1" xmlns:="http://www.w3.org/1999/xhtml"> variable.</span></span></p>
<h1 id="_idParaDest-150"><a id="_idTextAnchor688"/><span class="koboSpan" id="kobo.242.1" xmlns:="http://www.w3.org/1999/xhtml">Finding outliers using the mean and standard deviation</span></h1>
<p><span class="koboSpan" id="kobo.243.1" xmlns:="http://www.w3.org/1999/xhtml">I</span><a id="_idTextAnchor689"/><span class="koboSpan" id="kobo.244.1" xmlns:="http://www.w3.org/1999/xhtml">n </span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.245.1" xmlns:="http://www.w3.org/1999/xhtml">normally distributed variables, around 99.8% of the observations lie within the interval comprising the mean plus and minus </span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.246.1" xmlns:="http://www.w3.org/1999/xhtml">thr</span><a id="_idTextAnchor690"/><span class="koboSpan" id="kobo.247.1" xmlns:="http://www.w3.org/1999/xhtml">ee times the standard devi</span><a id="_idTextAnchor691"/><span class="koboSpan" id="kobo.248.1" xmlns:="http://www.w3.org/1999/xhtml">ation. </span><span class="koboSpan" id="kobo.248.2" xmlns:="http://www.w3.org/1999/xhtml">Thus, values beyond those limits can be considered outliers; they </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1" xmlns:="http://www.w3.org/1999/xhtml">are rare.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.250.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.251.1" xmlns:="http://www.w3.org/1999/xhtml">Using the mean and standard deviation to detect outliers has some drawbacks. </span><span class="koboSpan" id="kobo.251.2" xmlns:="http://www.w3.org/1999/xhtml">Firstly, it assumes a normal distribution, including outliers. </span><span class="koboSpan" id="kobo.251.3" xmlns:="http://www.w3.org/1999/xhtml">Secondly, outliers strongly influence the mean and standard deviation. </span><span class="koboSpan" id="kobo.251.4" xmlns:="http://www.w3.org/1999/xhtml">Therefore, a recommended alternative is the </span><strong class="bold"><span class="koboSpan" id="kobo.252.1" xmlns:="http://www.w3.org/1999/xhtml">Median Absolute Deviation</span></strong><span class="koboSpan" id="kobo.253.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.254.1" xmlns:="http://www.w3.org/1999/xhtml">MAD</span></strong><span class="koboSpan" id="kobo.255.1" xmlns:="http://www.w3.org/1999/xhtml">), which</span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.256.1" xmlns:="http://www.w3.org/1999/xhtml"> we’ll discuss in the </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1" xmlns:="http://www.w3.org/1999/xhtml">next recipe.</span></span></p>
<p><span class="koboSpan" id="kobo.258.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will identify outliers as those observations that lie outside the interval delimited by the mean plus and minus three times the </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1" xmlns:="http://www.w3.org/1999/xhtml">standa</span><a id="_idTextAnchor692"/><a id="_idTextAnchor693"/><span class="koboSpan" id="kobo.260.1" xmlns:="http://www.w3.org/1999/xhtml">rd deviation.</span></span></p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor694"/><span class="koboSpan" id="kobo.261.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.262.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin the</span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.263.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe by importing the Python libraries and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.265.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1" xmlns:="http://www.w3.org/1999/xhtml">and dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.267.1" xmlns:="http://www.w3.org/1999/xhtml">
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer</span></pre></li> <li><span class="koboSpan" id="kobo.268.1" xmlns:="http://www.w3.org/1999/xhtml">Load the breast cancer dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.270.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = load_breast_cancer(
    return_X_y=True, as_frame=True)</span></pre></li> <li><span class="koboSpan" id="kobo.271.1" xmlns:="http://www.w3.org/1999/xhtml">Create </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.272.1" xmlns:="http://www.w3.org/1999/xhtml">a function to plot a </span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.273.1" xmlns:="http://www.w3.org/1999/xhtml">boxplot next to </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1" xmlns:="http://www.w3.org/1999/xhtml">a histogram:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.275.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_boxplot_and_hist(data, variable):
    f, (ax_box, ax_hist) = plt.subplots(
        2, sharex=True,
        gridspec_kw={"height_ratios": (0.50, 0.85)})
    sns.boxplot(x=data[variable], ax=ax_box)
    sns.histplot(data=data, x=variable, ax=ax_hist)
    plt.show()</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.276.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.277.1" xmlns:="http://www.w3.org/1999/xhtml">We discussed the function from </span><em class="italic"><span class="koboSpan" id="kobo.278.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.279.1" xmlns:="http://www.w3.org/1999/xhtml"> in the previous recipe, </span><em class="italic"><span class="koboSpan" id="kobo.280.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.281.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.282.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.283.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s plot the distribution of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1" xmlns:="http://www.w3.org/1999/xhtml">mean </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.285.1" xmlns:="http://www.w3.org/1999/xhtml">smoothness</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.286.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.287.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X, "mean smoothness")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.288.1" xmlns:="http://www.w3.org/1999/xhtml">In the</span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.289.1" xmlns:="http://www.w3.org/1999/xhtml"> following boxplot, we see that the variable’s values show a distribution like the</span><a id="_idIndexMarker381"/><span class="koboSpan" id="kobo.290.1" xmlns:="http://www.w3.org/1999/xhtml"> normal distribution, and it has six outliers – one on the left and five on the </span><span class="No-Break"><span class="koboSpan" id="kobo.291.1" xmlns:="http://www.w3.org/1999/xhtml">right tail:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer087">
<span class="koboSpan" id="kobo.292.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.4 – Boxplot and histogram of the variable mean smoothness" src="image/B22396_05_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.293.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.4 – Boxplot and histogram of the variable mean smoothness</span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.294.1" xmlns:="http://www.w3.org/1999/xhtml">Create a function that returns the mean plus and minus </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1" xmlns:="http://www.w3.org/1999/xhtml">fold</span></strong><span class="koboSpan" id="kobo.296.1" xmlns:="http://www.w3.org/1999/xhtml"> times the standard deviation, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.297.1" xmlns:="http://www.w3.org/1999/xhtml">fold</span></strong><span class="koboSpan" id="kobo.298.1" xmlns:="http://www.w3.org/1999/xhtml"> is a parameter to </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1" xmlns:="http://www.w3.org/1999/xhtml">the function:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.300.1" xmlns:="http://www.w3.org/1999/xhtml">
def find_limits(df, variable, fold):
    var_mean = df[variable].mean()
    var_std = df[variable].std()
    lower_limit = var_mean - fold * var_std
    upper_limit = var_mean + fold * var_std
    return lower_limit, upper_limit</span></pre></li> <li><span class="koboSpan" id="kobo.301.1" xmlns:="http://www.w3.org/1999/xhtml">Use the</span><a id="_idIndexMarker382"/><span class="koboSpan" id="kobo.302.1" xmlns:="http://www.w3.org/1999/xhtml"> function to identify the extreme limits of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1" xmlns:="http://www.w3.org/1999/xhtml">mean </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.304.1" xmlns:="http://www.w3.org/1999/xhtml">smoothness</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.305.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.306.1" xmlns:="http://www.w3.org/1999/xhtml">
lower_limit, upper_limit = find_limits(
    X, "mean smo</span><a id="_idTextAnchor695"/><span class="koboSpan" id="kobo.307.1" xmlns:="http://www.w3.org/1999/xhtml">othness", 3)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.308.1" xmlns:="http://www.w3.org/1999/xhtml">If we now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.309.1" xmlns:="http://www.w3.org/1999/xhtml">lower_limit</span></strong> <a id="_idTextAnchor696"/><span class="koboSpan" id="kobo.310.1" xmlns:="http://www.w3.org/1999/xhtml">or </span><strong class="source-inline"><span class="koboSpan" id="kobo.311.1" xmlns:="http://www.w3.org/1999/xhtml">upper_limit</span></strong><span class="koboSpan" id="kobo.312.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the values </span><strong class="source-inline"><span class="koboSpan" id="kobo.313.1" xmlns:="http://www.w3.org/1999/xhtml">0.0541</span></strong><span class="koboSpan" id="kobo.314.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.315.1" xmlns:="http://www.w3.org/1999/xhtml">0.13</span><a id="_idTextAnchor697"/><span class="koboSpan" id="kobo.316.1" xmlns:="http://www.w3.org/1999/xhtml">855</span></strong><span class="koboSpan" id="kobo.317.1" xmlns:="http://www.w3.org/1999/xhtml">, correspon</span><a id="_idTextAnchor698"/><span class="koboSpan" id="kobo.318.1" xmlns:="http://www.w3.org/1999/xhtml">ding to the limits beyond which we can consider a value </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1" xmlns:="http://www.w3.org/1999/xhtml">an outlier.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.320.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.321.1" xmlns:="http://www.w3.org/1999/xhtml">The interval between the mean plus and minus three times the standard deviation encloses 99.87% of the observations if the variable is normally distributed. </span><span class="koboSpan" id="kobo.321.2" xmlns:="http://www.w3.org/1999/xhtml">For less conservative limits, we could multiply the standard deviation by 2 or 2.5, which would produce intervals that enclose 95.4% and 97.6% of the </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1" xmlns:="http://www.w3.org/1999/xhtml">observations, respectively.</span></span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.323.1" xmlns:="http://www.w3.org/1999/xhtml">Create </span><a id="_idIndexMarker383"/><span class="koboSpan" id="kobo.324.1" xmlns:="http://www.w3.org/1999/xhtml">a Boolean vector that flags observations with values beyond the limits determined in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.325.1" xmlns:="http://www.w3.org/1999/xhtml">step 6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.326.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.327.1" xmlns:="http://www.w3.org/1999/xhtml">
outliers = np.where(
    (X[«mean smoothness»] &gt; upper_limit) |
    (X[«mean smoothness»] &lt; lower_limit),
    True,
    False
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.328.1" xmlns:="http://www.w3.org/1999/xhtml">If we now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.329.1" xmlns:="http://www.w3.org/1999/xhtml">outliers.sum()</span></strong><span class="koboSpan" id="kobo.330.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the value </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1" xmlns:="http://www.w3.org/1999/xhtml">5</span></strong><span class="koboSpan" id="kobo.332.1" xmlns:="http://www.w3.org/1999/xhtml">, indicating that there are five outliers or observations that are smaller or greater than the extreme values found with the mean and the standard deviation. </span><span class="koboSpan" id="kobo.332.2" xmlns:="http://www.w3.org/1999/xhtml">According to these limits, we’d identify one outlier less compared to the </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1" xmlns:="http://www.w3.org/1999/xhtml">IQR rule.</span></span></p></li> <li><span class="koboSpan" id="kobo.334.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s add red vertical lines to the histogram from </span><em class="italic"><span class="koboSpan" id="kobo.335.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.336.1" xmlns:="http://www.w3.org/1999/xhtml"> to highlight the limits determined</span><a id="_idIndexMarker384"/><span class="koboSpan" id="kobo.337.1" xmlns:="http://www.w3.org/1999/xhtml"> by using the mean and the </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.339.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_boxplot_and_hist(data, variable):
    f, (ax_box, ax_hist) = plt.subplots(
        2, sharex=True,
        gridspec_kw={"height_ratios": (0.50, 0.85)})
    sns.boxplot(x=data[variable], ax=ax_box)
    sns.histplot(data=data, x=variable, ax=ax_hist)
    plt.vlines(
        x=lower_limit, ymin=0, ymax=80, color='r')
    plt.vlines(
        x=upper_limit, ymin=0, ymax=80, color='r')
     plt.show()</span></pre></li> <li><span class="koboSpan" id="kobo.340.1" xmlns:="http://www.w3.org/1999/xhtml">And </span><a id="_idIndexMarker385"/><span class="koboSpan" id="kobo.341.1" xmlns:="http://www.w3.org/1999/xhtml">now let’s make </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1" xmlns:="http://www.w3.org/1999/xhtml">the plots:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.343.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X, "mean smoothness")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.344.1" xmlns:="http://www.w3.org/1999/xhtml">In the following plot, we see that the limits observed by the IQR proximity rule in the box plot are less conservative than those identified by the mean and the standard deviation. </span><span class="koboSpan" id="kobo.344.2" xmlns:="http://www.w3.org/1999/xhtml">Hence why we observe six potential outliers in the boxplot, but only five based on the mean and standard </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1" xmlns:="http://www.w3.org/1999/xhtml">deviation calculations:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer088">
<span class="koboSpan" id="kobo.346.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.5 – Comparison of the limits between the whiskers in the boxplot and those determined by using the mean and the standard deviation (vertical lines in the histogram)" src="image/B22396_05_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.347.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.5 – Comparison of the limits between the whiskers in the boxplot and those determined by using the mean and the standard deviation (vertical lines in the histogram)</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.348.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><a id="_idIndexMarker386"/><span class="koboSpan" id="kobo.349.1" xmlns:="http://www.w3.org/1999/xhtml">boundaries derived from the </span><a id="_idIndexMarker387"/><span class="koboSpan" id="kobo.350.1" xmlns:="http://www.w3.org/1999/xhtml">mean and standard deviation are symmetric. </span><span class="koboSpan" id="kobo.350.2" xmlns:="http://www.w3.org/1999/xhtml">They extend equidistantly from the center of the distribution toward both tails. </span><span class="koboSpan" id="kobo.350.3" xmlns:="http://www.w3.org/1999/xhtml">As previously mentioned, these boundaries are only suitable for normally</span><a id="_idTextAnchor699"/><a id="_idTextAnchor700"/> <span class="No-Break"><span class="koboSpan" id="kobo.351.1" xmlns:="http://www.w3.org/1999/xhtml">distributed variables.</span></span></p>
<h2 id="_idParaDest-152"><a id="_idTextAnchor701"/><span class="koboSpan" id="kobo.352.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.353.1" xmlns:="http://www.w3.org/1999/xhtml">With pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.354.1" xmlns:="http://www.w3.org/1999/xhtml">mean()</span></strong><span class="koboSpan" id="kobo.355.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.356.1" xmlns:="http://www.w3.org/1999/xhtml">std()</span></strong><span class="koboSpan" id="kobo.357.1" xmlns:="http://www.w3.org/1999/xhtml">, we captured the mean and standard deviation of the variable. </span><span class="koboSpan" id="kobo.357.2" xmlns:="http://www.w3.org/1999/xhtml">We determined the limits as the mean plus and minus three times the standard deviation. </span><span class="koboSpan" id="kobo.357.3" xmlns:="http://www.w3.org/1999/xhtml">To highlight the outliers, we used NumPy’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.358.1" xmlns:="http://www.w3.org/1999/xhtml">where()</span></strong><span class="koboSpan" id="kobo.359.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.359.2" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.360.1" xmlns:="http://www.w3.org/1999/xhtml">where()</span></strong><span class="koboSpan" id="kobo.361.1" xmlns:="http://www.w3.org/1999/xhtml"> function scanned the rows of the vari</span><a id="_idTextAnchor702"/><span class="koboSpan" id="kobo.362.1" xmlns:="http://www.w3.org/1999/xhtml">able, and if the value was </span><a id="_idTextAnchor703"/><span class="koboSpan" id="kobo.363.1" xmlns:="http://www.w3.org/1999/xhtml">greater than the upper limit or smaller than the lower limit, it was assigned </span><strong class="source-inline"><span class="koboSpan" id="kobo.364.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.365.1" xmlns:="http://www.w3.org/1999/xhtml">, and alternatively </span><strong class="source-inline"><span class="koboSpan" id="kobo.366.1" xmlns:="http://www.w3.org/1999/xhtml">False</span></strong><span class="koboSpan" id="kobo.367.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.367.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.368.1" xmlns:="http://www.w3.org/1999/xhtml">sum()</span></strong><span class="koboSpan" id="kobo.369.1" xmlns:="http://www.w3.org/1999/xhtml"> over this Boolean vector to calculate the total number </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1" xmlns:="http://www.w3.org/1999/xhtml">of outliers.</span></span></p>
<p><span class="koboSpan" id="kobo.371.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we compared the boundaries to determine outliers returned by the IQR proximity rule, which we discussed in the previous recipe, </span><em class="italic"><span class="koboSpan" id="kobo.372.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile proximity rule</span></em><span class="koboSpan" id="kobo.373.1" xmlns:="http://www.w3.org/1999/xhtml">, and the mean and the standard deviation. </span><span class="koboSpan" id="kobo.373.2" xmlns:="http://www.w3.org/1999/xhtml">We observed that the limits of the IQR rule are less conservative. </span><span class="koboSpan" id="kobo.373.3" xmlns:="http://www.w3.org/1999/xhtml">That means that with the IQR rule, we’d flag more outliers in this </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1" xmlns:="http://www.w3.org/1999/xhtml">particular variable.</span></span></p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor704"/><span class="koboSpan" id="kobo.375.1" xmlns:="http://www.w3.org/1999/xhtml">Using the median absolute deviation to find outliers</span></h1>
<p><span class="koboSpan" id="kobo.376.1" xmlns:="http://www.w3.org/1999/xhtml">The mean </span><a id="_idIndexMarker388"/><span class="koboSpan" id="kobo.377.1" xmlns:="http://www.w3.org/1999/xhtml">and the standard deviation are heavily impacted by outliers. </span><span class="koboSpan" id="kobo.377.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, using these parameters to identify outliers can defeat the purpose. </span><span class="koboSpan" id="kobo.377.3" xmlns:="http://www.w3.org/1999/xhtml">A better way to identify outliers is </span><a id="_idIndexMarker389"/><span class="koboSpan" id="kobo.378.1" xmlns:="http://www.w3.org/1999/xhtml">by using MAD. </span><span class="koboSpan" id="kobo.378.2" xmlns:="http://www.w3.org/1999/xhtml">MAD is the median of the absolute deviation between each observation and the median value of </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1" xmlns:="http://www.w3.org/1999/xhtml">the variable:</span></span></p>
<p><span class="koboSpan" id="kobo.380.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;×&lt;/mo&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mfenced&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/24.png" style="vertical-align:-0.254em;height:1.015em;width:15.728em"/></span></p>
<p><span class="koboSpan" id="kobo.381.1" xmlns:="http://www.w3.org/1999/xhtml">In the previous equation, </span><strong class="source-inline"><span class="koboSpan" id="kobo.382.1" xmlns:="http://www.w3.org/1999/xhtml">xi</span></strong><span class="koboSpan" id="kobo.383.1" xmlns:="http://www.w3.org/1999/xhtml"> is each observation in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1" xmlns:="http://www.w3.org/1999/xhtml">X</span></strong><span class="koboSpan" id="kobo.385.1" xmlns:="http://www.w3.org/1999/xhtml"> variable. </span><span class="koboSpan" id="kobo.385.2" xmlns:="http://www.w3.org/1999/xhtml">The beauty of MAD is that it uses the median instead of the mean, which is robust to outliers. </span><span class="koboSpan" id="kobo.385.3" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.386.1" xmlns:="http://www.w3.org/1999/xhtml">b</span></strong><span class="koboSpan" id="kobo.387.1" xmlns:="http://www.w3.org/1999/xhtml"> constant is used to estimate the standard deviation from MAD, and if we assume normality, then </span><strong class="source-inline"><span class="koboSpan" id="kobo.388.1" xmlns:="http://www.w3.org/1999/xhtml">b = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.389.1" xmlns:="http://www.w3.org/1999/xhtml">1.4826</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.390.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.391.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.392.1" xmlns:="http://www.w3.org/1999/xhtml">If the variable is assumed to have a different distribution, </span><strong class="source-inline"><span class="koboSpan" id="kobo.393.1" xmlns:="http://www.w3.org/1999/xhtml">b</span></strong><span class="koboSpan" id="kobo.394.1" xmlns:="http://www.w3.org/1999/xhtml"> is then calculated as 1 divided by the 75th percentile. </span><span class="koboSpan" id="kobo.394.2" xmlns:="http://www.w3.org/1999/xhtml">In the case of normality, 1/75th percentile = </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1" xmlns:="http://www.w3.org/1999/xhtml">1.4826.</span></span></p>
<p><span class="koboSpan" id="kobo.396.1" xmlns:="http://www.w3.org/1999/xhtml">After computing MAD, we use the median and MAD to establish distribution limits, designating values beyond these limits as outliers. </span><span class="koboSpan" id="kobo.396.2" xmlns:="http://www.w3.org/1999/xhtml">The limits are set as the median plus and minus a multiple of MAD, typically ranging from 2 to 3.5. </span><span class="koboSpan" id="kobo.396.3" xmlns:="http://www.w3.org/1999/xhtml">The multiplication factor we choose reflects how stringent we want to be (the higher, the more conservative). </span><span class="koboSpan" id="kobo.396.4" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will identify outliers </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1" xmlns:="http://www.w3.org/1999/xhtml">using MAD.</span></span></p>
<h2 id="_idParaDest-154"><a id="_idTextAnchor705"/><span class="koboSpan" id="kobo.398.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.399.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin the recipe by importing the Python libraries and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.401.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1" xmlns:="http://www.w3.org/1999/xhtml">and dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.403.1" xmlns:="http://www.w3.org/1999/xhtml">
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer</span></pre></li> <li><span class="koboSpan" id="kobo.404.1" xmlns:="http://www.w3.org/1999/xhtml">Load the </span><a id="_idIndexMarker390"/><span class="koboSpan" id="kobo.405.1" xmlns:="http://www.w3.org/1999/xhtml">breast cancer dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.407.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = load_breast_cancer(
    return_X_y=True, as_frame=True)</span></pre></li> <li><span class="koboSpan" id="kobo.408.1" xmlns:="http://www.w3.org/1999/xhtml">Create a </span><a id="_idIndexMarker391"/><span class="koboSpan" id="kobo.409.1" xmlns:="http://www.w3.org/1999/xhtml">function that returns the limits based </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1" xmlns:="http://www.w3.org/1999/xhtml">on MAD:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.411.1" xmlns:="http://www.w3.org/1999/xhtml">
def find_limits(df, variable, fold):
    median = df[variable].median()
    center = df[variable] - median
    MAD = center.abs().median() * 1.4826
    lower_limit = median - fold * MAD
    upper_limit = median + fold * MAD
    return lower_limit, upper_limit</span></pre></li> <li><span class="koboSpan" id="kobo.412.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s use the function to capture the extreme limits of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1" xmlns:="http://www.w3.org/1999/xhtml">mean </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.414.1" xmlns:="http://www.w3.org/1999/xhtml">smoothness</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.415.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.416.1" xmlns:="http://www.w3.org/1999/xhtml">
lower_limit, upper_limit = find_limits(
    X, "mean smoothness", 3)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.417.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1" xmlns:="http://www.w3.org/1999/xhtml">lower_limit</span></strong><span class="koboSpan" id="kobo.419.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.420.1" xmlns:="http://www.w3.org/1999/xhtml">upper_limit</span></strong><span class="koboSpan" id="kobo.421.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the values </span><strong class="source-inline"><span class="koboSpan" id="kobo.422.1" xmlns:="http://www.w3.org/1999/xhtml">0.0536</span></strong><span class="koboSpan" id="kobo.423.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.424.1" xmlns:="http://www.w3.org/1999/xhtml">0.13812</span></strong><span class="koboSpan" id="kobo.425.1" xmlns:="http://www.w3.org/1999/xhtml">, corresponding to the limits beyond which we can consider a value </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1" xmlns:="http://www.w3.org/1999/xhtml">an outlier.</span></span></p></li> <li><span class="koboSpan" id="kobo.427.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a Boolean vector that flags observations with values beyond </span><span class="No-Break"><span class="koboSpan" id="kobo.428.1" xmlns:="http://www.w3.org/1999/xhtml">the limits:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.429.1" xmlns:="http://www.w3.org/1999/xhtml">
outliers = np.where(
    (X[«mean smoothness»] &gt; upper_limit) |
    (X[«mean smoothness»] &lt; lower_limit),
    True,
    False
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.430.1" xmlns:="http://www.w3.org/1999/xhtml">If we </span><a id="_idIndexMarker392"/><span class="koboSpan" id="kobo.431.1" xmlns:="http://www.w3.org/1999/xhtml">now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1" xmlns:="http://www.w3.org/1999/xhtml">outliers.sum()</span></strong><span class="koboSpan" id="kobo.433.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the value </span><strong class="source-inline"><span class="koboSpan" id="kobo.434.1" xmlns:="http://www.w3.org/1999/xhtml">5</span></strong><span class="koboSpan" id="kobo.435.1" xmlns:="http://www.w3.org/1999/xhtml">, indicating that there are five outliers or observations that are smaller or greater than the extreme values found </span><span class="No-Break"><span class="koboSpan" id="kobo.436.1" xmlns:="http://www.w3.org/1999/xhtml">with MAD.</span></span></p></li> <li><span class="koboSpan" id="kobo.437.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker393"/><span class="koboSpan" id="kobo.438.1" xmlns:="http://www.w3.org/1999/xhtml">make a function to plot a boxplot next to a histogram of a variable, highlighting in the histogram the limits calculated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.439.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.440.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.441.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_boxplot_and_hist(data, variable):
    f, (ax_box, ax_hist) = plt.subplots(
        2, sharex=True,
        gridspec_kw={"height_ratios": (0.50, 0.85)})
    sns.boxplot(x=data[variable], ax=ax_box)
    sns.histplot(data=data, x=variable, ax=ax_hist)
    plt.vlines(
        x=lower_limit, ymin=0, ymax=80, color='r')
    plt.vlines(
        x=upper_limit, ymin=0, ymax=80, color='r')
    plt.show()</span></pre></li> <li><span class="koboSpan" id="kobo.442.1" xmlns:="http://www.w3.org/1999/xhtml">And now let’s make </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1" xmlns:="http://www.w3.org/1999/xhtml">the plots:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.444.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X, "mean smoothness")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.445.1" xmlns:="http://www.w3.org/1999/xhtml">In the following plot, we see that the limits observed by the IQR proximity rule in the box plot are less conservative than those identified by using MAD. </span><span class="koboSpan" id="kobo.445.2" xmlns:="http://www.w3.org/1999/xhtml">MAD returns </span><a id="_idIndexMarker394"/><span class="koboSpan" id="kobo.446.1" xmlns:="http://www.w3.org/1999/xhtml">symmetric boundaries, while the boxplot generates asymmetric boundaries, which are </span><a id="_idIndexMarker395"/><span class="koboSpan" id="kobo.447.1" xmlns:="http://www.w3.org/1999/xhtml">more suitable for highly </span><span class="No-Break"><span class="koboSpan" id="kobo.448.1" xmlns:="http://www.w3.org/1999/xhtml">skewed distributions:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer090">
<span class="koboSpan" id="kobo.449.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.6 – Comparison of the limits between the whiskers in the boxplot and those determined by using MAD" src="image/B22396_05_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.450.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.6 – Comparison of the limits between the whiskers in the boxplot and those determined by using MAD</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.451.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.452.1" xmlns:="http://www.w3.org/1999/xhtml">Detecting outliers with MAD requires that the variable has certain variability. </span><span class="koboSpan" id="kobo.452.2" xmlns:="http://www.w3.org/1999/xhtml">If more than 50% of the values in a variable are identical, the median coincides with the most frequent value, and MAD=0. </span><span class="koboSpan" id="kobo.452.3" xmlns:="http://www.w3.org/1999/xhtml">This means that all values different from the median will be flagged as outliers. </span><span class="koboSpan" id="kobo.452.4" xmlns:="http://www.w3.org/1999/xhtml">This constitutes another limitation of using MAD in </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1" xmlns:="http://www.w3.org/1999/xhtml">outlier detection.</span></span></p>
<p><span class="koboSpan" id="kobo.454.1" xmlns:="http://www.w3.org/1999/xhtml">That’s it! </span><span class="koboSpan" id="kobo.454.2" xmlns:="http://www.w3.org/1999/xhtml">You now know how to identify outliers using the median </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1" xmlns:="http://www.w3.org/1999/xhtml">and MAD.</span></span></p>
<h2 id="_idParaDest-155"><a id="_idTextAnchor706"/><span class="koboSpan" id="kobo.456.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.457.1" xmlns:="http://www.w3.org/1999/xhtml">We </span><a id="_idIndexMarker396"/><span class="koboSpan" id="kobo.458.1" xmlns:="http://www.w3.org/1999/xhtml">determined the median with pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1" xmlns:="http://www.w3.org/1999/xhtml">median()</span></strong><span class="koboSpan" id="kobo.460.1" xmlns:="http://www.w3.org/1999/xhtml"> and the absolute difference with pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.461.1" xmlns:="http://www.w3.org/1999/xhtml">abs()</span></strong><span class="koboSpan" id="kobo.462.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.462.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we used the NumPy </span><strong class="source-inline"><span class="koboSpan" id="kobo.463.1" xmlns:="http://www.w3.org/1999/xhtml">where()</span></strong><span class="koboSpan" id="kobo.464.1" xmlns:="http://www.w3.org/1999/xhtml"> function to create a Boolean vector with </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.466.1" xmlns:="http://www.w3.org/1999/xhtml"> if a value was greater than the upper limit or smaller than the lower limit, otherwise </span><strong class="source-inline"><span class="koboSpan" id="kobo.467.1" xmlns:="http://www.w3.org/1999/xhtml">False</span></strong><span class="koboSpan" id="kobo.468.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.468.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.469.1" xmlns:="http://www.w3.org/1999/xhtml">sum()</span></strong><span class="koboSpan" id="kobo.470.1" xmlns:="http://www.w3.org/1999/xhtml"> over this Boolean vector to calculate the total number </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1" xmlns:="http://www.w3.org/1999/xhtml">of outliers.</span></span></p>
<p><span class="koboSpan" id="kobo.472.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we </span><a id="_idIndexMarker397"/><span class="koboSpan" id="kobo.473.1" xmlns:="http://www.w3.org/1999/xhtml">compared the boundaries to determine outliers returned by the IQR proximity rule, which we discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.474.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile range proximity rule</span></em><span class="koboSpan" id="kobo.475.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe, and those returned by using MAD. </span><span class="koboSpan" id="kobo.475.2" xmlns:="http://www.w3.org/1999/xhtml">The limits returned by the IQR rule were less conservative. </span><span class="koboSpan" id="kobo.475.3" xmlns:="http://www.w3.org/1999/xhtml">This behavior can be changed by multiplying the IQR by 3 instead of 1.5, which is the default value in boxplots. </span><span class="koboSpan" id="kobo.475.4" xmlns:="http://www.w3.org/1999/xhtml">In addition, we noted that MAD returns symmetric boundaries, whereas the boxplot provided asymmetric limits, which could be better suited for </span><span class="No-Break"><span class="koboSpan" id="kobo.476.1" xmlns:="http://www.w3.org/1999/xhtml">asymmetric distributions.</span></span></p>
<h3><span class="koboSpan" id="kobo.477.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h3>
<p><span class="koboSpan" id="kobo.478.1" xmlns:="http://www.w3.org/1999/xhtml">For a thorough discussion of the advantages and limitations of the different methods to detect outliers, check out the </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1" xmlns:="http://www.w3.org/1999/xhtml">following resources:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.480.1" xmlns:="http://www.w3.org/1999/xhtml">Rousseeuw PJ, Croux C. </span><em class="italic"><span class="koboSpan" id="kobo.481.1" xmlns:="http://www.w3.org/1999/xhtml">Alternatives to the Median Absolute deviation</span></em><span class="koboSpan" id="kobo.482.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.482.2" xmlns:="http://www.w3.org/1999/xhtml">Journal of the American Statistical Association, </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1" xmlns:="http://www.w3.org/1999/xhtml">1993. </span></span><a href="https://www.jstor.org/stable/2291267"><span class="No-Break"><span class="koboSpan" id="kobo.484.1" xmlns:="http://www.w3.org/1999/xhtml">http://www.jstor.org/stable/2291267</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.485.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
<li><span class="koboSpan" id="kobo.486.1" xmlns:="http://www.w3.org/1999/xhtml">Leys C, et. </span><span class="koboSpan" id="kobo.486.2" xmlns:="http://www.w3.org/1999/xhtml">al. </span><em class="italic"><span class="koboSpan" id="kobo.487.1" xmlns:="http://www.w3.org/1999/xhtml">Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median</span></em><span class="koboSpan" id="kobo.488.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.488.2" xmlns:="http://www.w3.org/1999/xhtml">Journal of Experimental Social Psychology, </span><span class="No-Break"><span class="koboSpan" id="kobo.489.1" xmlns:="http://www.w3.org/1999/xhtml">2013. </span></span><span class="No-Break"><span class="koboSpan" id="kobo.490.1" xmlns:="http://www.w3.org/1999/xhtml">http://dx.doi.org/10.1016/j.jesp.2013.03.013</span></span><span class="No-Break"><span class="koboSpan" id="kobo.491.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
<li><span class="koboSpan" id="kobo.492.1" xmlns:="http://www.w3.org/1999/xhtml">Thériault R, et. </span><span class="koboSpan" id="kobo.492.2" xmlns:="http://www.w3.org/1999/xhtml">al. </span><em class="italic"><span class="koboSpan" id="kobo.493.1" xmlns:="http://www.w3.org/1999/xhtml">Check your outliers</span></em><em class="italic"><span class="koboSpan" id="kobo.494.1" xmlns:="http://www.w3.org/1999/xhtml">! </span><span class="koboSpan" id="kobo.494.2" xmlns:="http://www.w3.org/1999/xhtml">An introduction to identifying statistical outliers in R with easystats</span></em><span class="koboSpan" id="kobo.495.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.495.2" xmlns:="http://www.w3.org/1999/xhtml">Behavior Research Methods, </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1" xmlns:="http://www.w3.org/1999/xhtml">2024. </span></span><a href="https://link.springer.com/article/10.3758/s13428-024-02356-w"><span class="No-Break"><span class="koboSpan" id="kobo.497.1" xmlns:="http://www.w3.org/1999/xhtml">https://doi.</span><span id="_idTextAnchor707"/><span id="_idTextAnchor708"/><span id="_idTextAnchor709"/><span id="_idTextAnchor710"/><span id="_idTextAnchor711"/><span class="koboSpan" id="kobo.498.1" xmlns:="http://www.w3.org/1999/xhtml">org/10.3758/s13428-024-02356-w</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.499.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
</ul>
<h1 id="_idParaDest-156"><a id="_idTextAnchor712"/><span class="koboSpan" id="kobo.500.1" xmlns:="http://www.w3.org/1999/xhtml">Removing outliers</span></h1>
<p><span class="koboSpan" id="kobo.501.1" xmlns:="http://www.w3.org/1999/xhtml">Recent </span><a id="_idIndexMarker398"/><span class="koboSpan" id="kobo.502.1" xmlns:="http://www.w3.org/1999/xhtml">studies distinguish three types of outliers: error outliers, interesting outliers, and random outliers. </span><span class="koboSpan" id="kobo.502.2" xmlns:="http://www.w3.org/1999/xhtml">Error outliers are likely due to human or methodological errors and should be either corrected or removed from the data analysis. </span><span class="koboSpan" id="kobo.502.3" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we’ll assume outliers are errors (you don’t want to remove interesting or random outliers) a</span><a id="_idTextAnchor713"/><a id="_idTextAnchor714"/><span class="koboSpan" id="kobo.503.1" xmlns:="http://www.w3.org/1999/xhtml">nd remove them from </span><span class="No-Break"><span class="koboSpan" id="kobo.504.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset.</span></span></p>
<h2 id="_idParaDest-157"><a id="_idTextAnchor715"/><span class="koboSpan" id="kobo.505.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.506.1" xmlns:="http://www.w3.org/1999/xhtml">We’ll use the IQR proximity rule to find the outliers and then remove them from the data using pandas </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1" xmlns:="http://www.w3.org/1999/xhtml">and Feature-engine:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.508.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the Python libraries, functions, </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1" xmlns:="http://www.w3.org/1999/xhtml">and classes:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.510.1" xmlns:="http://www.w3.org/1999/xhtml">
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from feature_engine.out</span><a id="_idTextAnchor716"/><span class="koboSpan" id="kobo.511.1" xmlns:="http://www.w3.org/1999/xhtml">liers import OutlierTrimmer</span></pre></li> <li><span class="koboSpan" id="kobo.512.1" xmlns:="http://www.w3.org/1999/xhtml">Load the California housing dataset from scikit-learn and separate it into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.514.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.515.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a function to find the limits beyond which we’ll consider a data point an outlier using the IQR </span><span class="No-Break"><span class="koboSpan" id="kobo.516.1" xmlns:="http://www.w3.org/1999/xhtml">proximity rule:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.517.1" xmlns:="http://www.w3.org/1999/xhtml">
def find_limits(df, variable, fold):
    q1 = df[variable].quantile(0.25)
    q3 = df[variable].quantile(0.75)
    IQR = q3 - q1
    lower_limit = q1 - (IQR * fold)
    upper_limit = q3 + (IQR * fold)
    return lower_limit, upper_limit</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.518.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.519.1" xmlns:="http://www.w3.org/1999/xhtml">In </span><em class="italic"><span class="koboSpan" id="kobo.520.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.521.1" xmlns:="http://www.w3.org/1999/xhtml">, we use the IQR proximity rule to find the limits beyond which data points will be considered outliers, which we discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.522.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile proximity rule</span></em><span class="koboSpan" id="kobo.523.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe. </span><span class="koboSpan" id="kobo.523.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, you can identify outliers with the mean and the standard deviation or MAD, as we covered in the </span><em class="italic"><span class="koboSpan" id="kobo.524.1" xmlns:="http://www.w3.org/1999/xhtml">Finding outliers using the mean and standard deviation</span></em><span class="koboSpan" id="kobo.525.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.526.1" xmlns:="http://www.w3.org/1999/xhtml">Using the median absolute deviation to find </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.527.1" xmlns:="http://www.w3.org/1999/xhtml">outliers</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.528.1" xmlns:="http://www.w3.org/1999/xhtml"> recipes.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.529.1" xmlns:="http://www.w3.org/1999/xhtml">Using the</span><a id="_idIndexMarker399"/><span class="koboSpan" id="kobo.530.1" xmlns:="http://www.w3.org/1999/xhtml"> function from </span><em class="italic"><span class="koboSpan" id="kobo.531.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.532.1" xmlns:="http://www.w3.org/1999/xhtml"> , let’s determine the limits of the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.533.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.534.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.535.1" xmlns:="http://www.w3.org/1999/xhtml">
lower, upper = find_limits(X_train, "MedInc", 3)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.536.1" xmlns:="http://www.w3.org/1999/xhtml">If you execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.537.1" xmlns:="http://www.w3.org/1999/xhtml">print(lower_limit, upper_limit)</span></strong><span class="koboSpan" id="kobo.538.1" xmlns:="http://www.w3.org/1999/xhtml">, you’ll see the result of the previous command: </span><strong class="source-inline"><span class="koboSpan" id="kobo.539.1" xmlns:="http://www.w3.org/1999/xhtml">(-</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.540.1" xmlns:="http://www.w3.org/1999/xhtml">3.925900000000002, 11.232600000000001)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.541.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.542.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s retain the observations in the train and test sets whose values are greater than or equal to (</span><strong class="source-inline"><span class="koboSpan" id="kobo.543.1" xmlns:="http://www.w3.org/1999/xhtml">ge</span></strong><span class="koboSpan" id="kobo.544.1" xmlns:="http://www.w3.org/1999/xhtml">) the </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1" xmlns:="http://www.w3.org/1999/xhtml">lower limit:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.546.1" xmlns:="http://www.w3.org/1999/xhtml">
inliers = X_train["MedInc"].ge(lower)
train_t = X_train.loc[inliers]
inliers = X_test["MedInc"].ge(lower)
test_t = X_test.loc[inliers]</span></pre></li> <li><span class="koboSpan" id="kobo.547.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s retain the observations whose values are lower than or equal to (</span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1" xmlns:="http://www.w3.org/1999/xhtml">le</span></strong><span class="koboSpan" id="kobo.549.1" xmlns:="http://www.w3.org/1999/xhtml">) the </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1" xmlns:="http://www.w3.org/1999/xhtml">upper limit:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.551.1" xmlns:="http://www.w3.org/1999/xhtml">
inliers = X_train["MedInc"].le(upper)
train_t = X_train.loc[inliers]
inliers = X_test["MedInc"].le(upper)
test_t = X_test.loc[inliers]</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.552.1" xmlns:="http://www.w3.org/1999/xhtml">Go </span><a id="_idIndexMarker400"/><span class="koboSpan" id="kobo.553.1" xmlns:="http://www.w3.org/1999/xhtml">ahead and execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.554.1" xmlns:="http://www.w3.org/1999/xhtml">X_train.shape</span></strong><span class="koboSpan" id="kobo.555.1" xmlns:="http://www.w3.org/1999/xhtml"> followed by </span><strong class="source-inline"><span class="koboSpan" id="kobo.556.1" xmlns:="http://www.w3.org/1999/xhtml">train_t.shape</span></strong><span class="koboSpan" id="kobo.557.1" xmlns:="http://www.w3.org/1999/xhtml"> to corroborate that the transformed DataFrame contains fewer observations than the original one after removing </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1" xmlns:="http://www.w3.org/1999/xhtml">the outliers.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.559.1" xmlns:="http://www.w3.org/1999/xhtml">We can remove outliers across multiple variables simultaneously </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1" xmlns:="http://www.w3.org/1999/xhtml">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.561.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.562.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.563.1" xmlns:="http://www.w3.org/1999/xhtml">Set up a transformer to identify outliers in three variables by using the </span><span class="No-Break"><span class="koboSpan" id="kobo.564.1" xmlns:="http://www.w3.org/1999/xhtml">IQR rule:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.565.1" xmlns:="http://www.w3.org/1999/xhtml">
trimmer = OutlierTrimmer(
    variables = [«MedInc", "HouseAge", "Population"],
    capping_method="iqr",
    tail="both",
    fold=1.5,
)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.566.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.567.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer</span></strong><span class="koboSpan" id="kobo.568.1" xmlns:="http://www.w3.org/1999/xhtml"> can identify boundaries using the IQR, as we show in this recipe, as well as by using the mean and standard deviation, or MAD. </span><span class="koboSpan" id="kobo.568.2" xmlns:="http://www.w3.org/1999/xhtml">You need to change </span><strong class="source-inline"><span class="koboSpan" id="kobo.569.1" xmlns:="http://www.w3.org/1999/xhtml">capping_method</span></strong><span class="koboSpan" id="kobo.570.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1" xmlns:="http://www.w3.org/1999/xhtml">gaussian</span></strong><span class="koboSpan" id="kobo.572.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.573.1" xmlns:="http://www.w3.org/1999/xhtml">mad</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.574.1" xmlns:="http://www.w3.org/1999/xhtml">, respectively.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.575.1" xmlns:="http://www.w3.org/1999/xhtml">Fit the transformer to the training set so that it learns </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1" xmlns:="http://www.w3.org/1999/xhtml">those limits:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.577.1" xmlns:="http://www.w3.org/1999/xhtml">
trimmer.fit(X_train)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.578.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.579.1" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.580.1" xmlns:="http://www.w3.org/1999/xhtml">trimmer.left_tail_caps_</span></strong><span class="koboSpan" id="kobo.581.1" xmlns:="http://www.w3.org/1999/xhtml">, we can visualize the lower limits for the three variables: </span><strong class="source-inline"><span class="koboSpan" id="kobo.582.1" xmlns:="http://www.w3.org/1999/xhtml">{'MedInc': -0.6776500000000012, 'HouseAge': -10.5, 'Population': -626.0}</span></strong><span class="koboSpan" id="kobo.583.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.583.2" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.584.1" xmlns:="http://www.w3.org/1999/xhtml">trimmer.right_tail_caps_</span></strong><span class="koboSpan" id="kobo.585.1" xmlns:="http://www.w3.org/1999/xhtml">, we can see the variables’ upper limits: </span><strong class="source-inline"><span class="koboSpan" id="kobo.586.1" xmlns:="http://www.w3.org/1999/xhtml">{'MedInc': 7.984350000000001, 'HouseAge': 65.5, '</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.587.1" xmlns:="http://www.w3.org/1999/xhtml">Population': 3134.0}</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.588.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.589.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s remove outliers from the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.590.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.591.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_t = trimmer.transform(X_train)
X_test_t = t</span><a id="_idTextAnchor717"/><span class="koboSpan" id="kobo.592.1" xmlns:="http://www.w3.org/1999/xhtml">rimmer.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.593.1" xmlns:="http://www.w3.org/1999/xhtml">To finish with the recipe, let’s compare the distribution of a variable before and after </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1" xmlns:="http://www.w3.org/1999/xhtml">removing outliers.</span></span></p></li> <li><span class="koboSpan" id="kobo.595.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create</span><a id="_idIndexMarker401"/><span class="koboSpan" id="kobo.596.1" xmlns:="http://www.w3.org/1999/xhtml"> a function to display a boxplot on top of </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1" xmlns:="http://www.w3.org/1999/xhtml">a histogram:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.598.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_boxplot_and_hist(data, variable):
    f, (ax_box, ax_hist) = plt.subplots(
        2, sharex=True,
        gridspec_kw={"height_ratios": (0.50, 0.85)}
    )
    sns.boxplot(x=data[variable], ax=ax_box)
    sns.histplot(data=data, x=variable, ax=ax_hist)
    plt.show()</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.599.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.600.1" xmlns:="http://www.w3.org/1999/xhtml">We discussed the code in </span><em class="italic"><span class="koboSpan" id="kobo.601.1" xmlns:="http://www.w3.org/1999/xhtml">step 10</span></em><span class="koboSpan" id="kobo.602.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><em class="italic"><span class="koboSpan" id="kobo.603.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots</span></em><span class="koboSpan" id="kobo.604.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe earlier in </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1" xmlns:="http://www.w3.org/1999/xhtml">this chapter.</span></span></p>
<ol>
<li value="11"><span class="koboSpan" id="kobo.606.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s plot the distribution of </span><strong class="source-inline"><span class="koboSpan" id="kobo.607.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.608.1" xmlns:="http://www.w3.org/1999/xhtml"> before removing </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1" xmlns:="http://www.w3.org/1999/xhtml">the outliers:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.610.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(X_train, "MedInc")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.611.1" xmlns:="http://www.w3.org/1999/xhtml">In the following plot, we see that </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.613.1" xmlns:="http://www.w3.org/1999/xhtml"> is skewed and observations grea</span><a id="_idTextAnchor718"/><span class="koboSpan" id="kobo.614.1" xmlns:="http://www.w3.org/1999/xhtml">ter than 8 are marked </span><span class="No-Break"><span class="koboSpan" id="kobo.615.1" xmlns:="http://www.w3.org/1999/xhtml">as outliers:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer091">
<span class="koboSpan" id="kobo.616.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.7– Boxplot and the histogram of MedInc before removing outliers." src="image/B22396_05_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.617.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.7– Boxplot and the histogram of MedInc before removing outliers.</span></p>
<ol>
<li value="12"><span class="koboSpan" id="kobo.618.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s plot </span><a id="_idIndexMarker402"/><span class="koboSpan" id="kobo.619.1" xmlns:="http://www.w3.org/1999/xhtml">the distribution of </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.621.1" xmlns:="http://www.w3.org/1999/xhtml"> after removing </span><span class="No-Break"><span class="koboSpan" id="kobo.622.1" xmlns:="http://www.w3.org/1999/xhtml">the outliers:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.623.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_boxplot_and_hist(train_t, "MedInc")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.624.1" xmlns:="http://www.w3.org/1999/xhtml">After removing outliers, </span><strong class="source-inline"><span class="koboSpan" id="kobo.625.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><span class="koboSpan" id="kobo.626.1" xmlns:="http://www.w3.org/1999/xhtml"> seems less skewed and i</span><a id="_idTextAnchor719"/><span class="koboSpan" id="kobo.627.1" xmlns:="http://www.w3.org/1999/xhtml">ts values more </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1" xmlns:="http://www.w3.org/1999/xhtml">evenly distributed:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer092">
<span class="koboSpan" id="kobo.629.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 5.8 – Boxplot and the histogram of MedInc after removing outliers" src="image/B22396_05_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.630.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 5.8 – Boxplot and the histogram of MedInc after removing outliers</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.631.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.632.1" xmlns:="http://www.w3.org/1999/xhtml">Using the IQR rule over the transformed variable reveals new outliers. </span><span class="koboSpan" id="kobo.632.2" xmlns:="http://www.w3.org/1999/xhtml">This is not surprising; removing observations at the extremes of the distribution alters parameters such as the median and quartile values, which in turn determine the length of the whiskers, potentially identifying additional observations as outliers. </span><span class="koboSpan" id="kobo.632.3" xmlns:="http://www.w3.org/1999/xhtml">The tools that we use to identify outliers are just that: tools. </span><span class="koboSpan" id="kobo.632.4" xmlns:="http://www.w3.org/1999/xhtml">To unequivocally identify outliers, we need to support these tools with additional </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1" xmlns:="http://www.w3.org/1999/xhtml">data analysis.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.634.1" xmlns:="http://www.w3.org/1999/xhtml">If thinking</span><a id="_idIndexMarker403"/><span class="koboSpan" id="kobo.635.1" xmlns:="http://www.w3.org/1999/xhtml"> of removing error outliers from the dataset, make sure to compare and report the results with and without outliers, to see the ext</span><a id="_idTextAnchor720"/><a id="_idTextAnchor721"/><span class="koboSpan" id="kobo.636.1" xmlns:="http://www.w3.org/1999/xhtml">ent of their impact on </span><span class="No-Break"><span class="koboSpan" id="kobo.637.1" xmlns:="http://www.w3.org/1999/xhtml">the models.</span></span></p>
<h2 id="_idParaDest-158"><a id="_idTextAnchor722"/><span class="koboSpan" id="kobo.638.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.639.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.640.1" xmlns:="http://www.w3.org/1999/xhtml">ge()</span></strong><span class="koboSpan" id="kobo.641.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.642.1" xmlns:="http://www.w3.org/1999/xhtml">le()</span></strong><span class="koboSpan" id="kobo.643.1" xmlns:="http://www.w3.org/1999/xhtml"> methods </span><a id="_idIndexMarker404"/><span class="koboSpan" id="kobo.644.1" xmlns:="http://www.w3.org/1999/xhtml">from pandas created Boolean vectors identifying observations exceeding or falling below thresholds set by the IQR proximity rule. </span><span class="koboSpan" id="kobo.644.2" xmlns:="http://www.w3.org/1999/xhtml">We used these vectors with pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1" xmlns:="http://www.w3.org/1999/xhtml">loc</span></strong><span class="koboSpan" id="kobo.646.1" xmlns:="http://www.w3.org/1999/xhtml"> to retain observations within the interval defined by </span><span class="No-Break"><span class="koboSpan" id="kobo.647.1" xmlns:="http://www.w3.org/1999/xhtml">the IQR.</span></span></p>
<p><span class="koboSpan" id="kobo.648.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.650.1" xmlns:="http://www.w3.org/1999/xhtml"> library’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.651.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer()</span></strong><span class="koboSpan" id="kobo.652.1" xmlns:="http://www.w3.org/1999/xhtml"> automates the procedure of removing outliers for multiple variables. </span><strong class="source-inline"><span class="koboSpan" id="kobo.653.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer()</span></strong><span class="koboSpan" id="kobo.654.1" xmlns:="http://www.w3.org/1999/xhtml"> can identify outliers based on the mean and standard deviation, IQR proximity rule, MAD, or quantiles. </span><span class="koboSpan" id="kobo.654.2" xmlns:="http://www.w3.org/1999/xhtml">We can modify this behavior through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.655.1" xmlns:="http://www.w3.org/1999/xhtml">capping_method</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.656.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.657.1" xmlns:="http://www.w3.org/1999/xhtml">The methods to identify outliers can be made more or less conservative by changing the factor by which we multiply the IQR, the standard deviation, or MAD. </span><span class="koboSpan" id="kobo.657.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.658.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer()</span></strong><span class="koboSpan" id="kobo.659.1" xmlns:="http://www.w3.org/1999/xhtml">, we can control the strength of the methods through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.660.1" xmlns:="http://www.w3.org/1999/xhtml">fold</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.661.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.662.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.663.1" xmlns:="http://www.w3.org/1999/xhtml">tails</span></strong><span class="koboSpan" id="kobo.664.1" xmlns:="http://www.w3.org/1999/xhtml"> set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1" xmlns:="http://www.w3.org/1999/xhtml">"both"</span></strong><span class="koboSpan" id="kobo.666.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.667.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer()</span></strong><span class="koboSpan" id="kobo.668.1" xmlns:="http://www.w3.org/1999/xhtml"> found and removed outliers at both ends of the variables’ distribution. </span><span class="koboSpan" id="kobo.668.2" xmlns:="http://www.w3.org/1999/xhtml">To remove outliers just on one of the tails, we can pass </span><strong class="source-inline"><span class="koboSpan" id="kobo.669.1" xmlns:="http://www.w3.org/1999/xhtml">"left"</span></strong><span class="koboSpan" id="kobo.670.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1" xmlns:="http://www.w3.org/1999/xhtml">"right"</span></strong><span class="koboSpan" id="kobo.672.1" xmlns:="http://www.w3.org/1999/xhtml"> to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.673.1" xmlns:="http://www.w3.org/1999/xhtml">tails</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.674.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.675.1" xmlns:="http://www.w3.org/1999/xhtml">OutlierTrimmer()</span></strong><span class="koboSpan" id="kobo.676.1" xmlns:="http://www.w3.org/1999/xhtml"> adopts the scikit-learn functionality with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.677.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.678.1" xmlns:="http://www.w3.org/1999/xhtml"> method, to learn parameters, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.679.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.680.1" xmlns:="http://www.w3.org/1999/xhtml"> to modify the dataset. </span><span class="koboSpan" id="kobo.680.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.681.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.682.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer learned and stored the limits for each variable. </span><span class="koboSpan" id="kobo.682.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.683.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.684.1" xmlns:="http://www.w3.org/1999/xhtml">, it removed the outliers from the data, returning </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.685.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.686.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrames.</span></span></p>
<h2 id="_idParaDest-159"><a id="_idTextAnchor723"/><span class="koboSpan" id="kobo.687.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><span class="koboSpan" id="kobo.688.1" xmlns:="http://www.w3.org/1999/xhtml">This is the study that I mentioned earlier that classifies outliers into errors; it is interesting and random: Leys C, et.al. </span><span class="koboSpan" id="kobo.688.2" xmlns:="http://www.w3.org/1999/xhtml">2019. </span><em class="italic"><span class="koboSpan" id="kobo.689.1" xmlns:="http://www.w3.org/1999/xhtml">How to Classify, Detect, and Manage Univariate and Multivariate Outliers, with Emphasis on Pre-Registration</span></em><span class="koboSpan" id="kobo.690.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.690.2" xmlns:="http://www.w3.org/1999/xhtml">International Review of Social </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1" xmlns:="http://www.w3.org/1999/xhtml">Psycholo</span><a id="_idTextAnchor724"/><a id="_idTextAnchor725"/><span class="koboSpan" id="kobo.692.1" xmlns:="http://www.w3.org/1999/xhtml">gy. </span></span><a href="https://rips-irsp.com/articles/10.5334/irsp.289"><span class="No-Break"><span class="koboSpan" id="kobo.693.1" xmlns:="http://www.w3.org/1999/xhtml">https://doi.org/10.5334/irsp.289</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.694.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-160"><a id="_idTextAnchor726"/><span class="koboSpan" id="kobo.695.1" xmlns:="http://www.w3.org/1999/xhtml">Bringing outliers back within acceptable limits</span></h1>
<p><span class="koboSpan" id="kobo.696.1" xmlns:="http://www.w3.org/1999/xhtml">Removing </span><a id="_idIndexMarker405"/><span class="koboSpan" id="kobo.697.1" xmlns:="http://www.w3.org/1999/xhtml">error outliers can be a valid strategy. </span><span class="koboSpan" id="kobo.697.2" xmlns:="http://www.w3.org/1999/xhtml">However, this approach can reduce statistical power, in particular when there are outliers across many variables, because we end up removing big parts of the dataset. </span><span class="koboSpan" id="kobo.697.3" xmlns:="http://www.w3.org/1999/xhtml">An alternative way to handle error outliers is by bringing outliers back within acceptable limits. </span><span class="koboSpan" id="kobo.697.4" xmlns:="http://www.w3.org/1999/xhtml">In practice, what this means is replacing the value of the outliers with some thresholds identified with the IQR proximity rule, the mean and standard deviation, or MAD. </span><span class="koboSpan" id="kobo.697.5" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we’ll replace outlier va</span><a id="_idTextAnchor727"/><a id="_idTextAnchor728"/><span class="koboSpan" id="kobo.698.1" xmlns:="http://www.w3.org/1999/xhtml">lues using </span><strong class="source-inline"><span class="koboSpan" id="kobo.699.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.700.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.701.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.702.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-161"><a id="_idTextAnchor729"/><span class="koboSpan" id="kobo.703.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.704.1" xmlns:="http://www.w3.org/1999/xhtml">We’ll use </span><a id="_idIndexMarker406"/><span class="koboSpan" id="kobo.705.1" xmlns:="http://www.w3.org/1999/xhtml">the mean and standard deviation to find outliers and then replace their values u</span><a id="_idTextAnchor730"/><span class="koboSpan" id="kobo.706.1" xmlns:="http://www.w3.org/1999/xhtml">sing </span><strong class="source-inline"><span class="koboSpan" id="kobo.707.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.708.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.709.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.710.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.711.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.712.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.713.1" xmlns:="http://www.w3.org/1999/xhtml">
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from feature_engine.outliers import Winsorizer</span></pre></li> <li><span class="koboSpan" id="kobo.714.1" xmlns:="http://www.w3.org/1999/xhtml">Load the breast cancer dataset from scikit-learn and separate it into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.715.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.716.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = load_breast_cancer(
    return_X_y=True, as_frame=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.717.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a function to find outliers using the mean and </span><span class="No-Break"><span class="koboSpan" id="kobo.718.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.719.1" xmlns:="http://www.w3.org/1999/xhtml">
def find_limits(df, variable, fold):
    var_mean = df[variable].mean()
    var_std = df[variable].std()
    lower_limit = var_mean - fold * var_std
    upper_limit = var_mean + fold * var_std
    return lower_limit, upper_limit</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.720.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.721.1" xmlns:="http://www.w3.org/1999/xhtml">In </span><em class="italic"><span class="koboSpan" id="kobo.722.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.723.1" xmlns:="http://www.w3.org/1999/xhtml">, we use the mean and standard deviation to find the limits beyond which data points will be considered outliers, as discussed in the </span><em class="italic"><span class="koboSpan" id="kobo.724.1" xmlns:="http://www.w3.org/1999/xhtml">Finding outliers using the mean and standard deviation</span></em><span class="koboSpan" id="kobo.725.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe. </span><span class="koboSpan" id="kobo.725.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, you can identify outliers with the IQR rule or MAD, as we covered in the </span><em class="italic"><span class="koboSpan" id="kobo.726.1" xmlns:="http://www.w3.org/1999/xhtml">Visualizing outliers with boxplots and the inter-quartile proximity rule</span></em><span class="koboSpan" id="kobo.727.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.728.1" xmlns:="http://www.w3.org/1999/xhtml">Using the median absolute deviation to find </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.729.1" xmlns:="http://www.w3.org/1999/xhtml">outliers </span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.730.1" xmlns:="http://www.w3.org/1999/xhtml">recipes.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.731.1" xmlns:="http://www.w3.org/1999/xhtml">Using</span><a id="_idIndexMarker407"/><span class="koboSpan" id="kobo.732.1" xmlns:="http://www.w3.org/1999/xhtml"> the function from </span><em class="italic"><span class="koboSpan" id="kobo.733.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.734.1" xmlns:="http://www.w3.org/1999/xhtml">, let’s determine the limits of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.735.1" xmlns:="http://www.w3.org/1999/xhtml">mean smoothness</span></strong><span class="koboSpan" id="kobo.736.1" xmlns:="http://www.w3.org/1999/xhtml"> variable, which follows approximately a </span><span class="No-Break"><span class="koboSpan" id="kobo.737.1" xmlns:="http://www.w3.org/1999/xhtml">Gaussian distribution:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.738.1" xmlns:="http://www.w3.org/1999/xhtml">
var = "worst smoothness"
lower_limit, upper_limit = find_limits(
    X_train, var, 3)</span></pre></li> <li><span class="koboSpan" id="kobo.739.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a copy of the </span><span class="No-Break"><span class="koboSpan" id="kobo.740.1" xmlns:="http://www.w3.org/1999/xhtml">original datasets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.741.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = X_train.copy()
test_t = X_test.copy()</span></pre></li> <li><span class="koboSpan" id="kobo.742.1" xmlns:="http://www.w3.org/1999/xhtml">Now, replace outliers with the lower or upper limits from </span><em class="italic"><span class="koboSpan" id="kobo.743.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em><span class="koboSpan" id="kobo.744.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.745.1" xmlns:="http://www.w3.org/1999/xhtml">new DataFrames:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.746.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t[var] = train_t[var].clip(
    lower=lower_limit, upper=upper_limit)
test_t[var] = test_t[var].clip(
    lower=lower_limit, upper=upper_limit)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.747.1" xmlns:="http://www.w3.org/1999/xhtml">To corroborate that the outliers were replaced with the values determined in </span><em class="italic"><span class="koboSpan" id="kobo.748.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em><span class="koboSpan" id="kobo.749.1" xmlns:="http://www.w3.org/1999/xhtml">, execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.750.1" xmlns:="http://www.w3.org/1999/xhtml">train_t["worst smoothness"].agg(["min", "max"])</span></strong><span class="koboSpan" id="kobo.751.1" xmlns:="http://www.w3.org/1999/xhtml"> to obtain the new maximum and minimum values. </span><span class="koboSpan" id="kobo.751.2" xmlns:="http://www.w3.org/1999/xhtml">They should coincide with the minimum and maximum values of the variable, or the limits returned in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.752.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.753.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.754.1" xmlns:="http://www.w3.org/1999/xhtml">We can replace outliers in multiple variables simultaneously by </span><span class="No-Break"><span class="koboSpan" id="kobo.755.1" xmlns:="http://www.w3.org/1999/xhtml">utilizing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.756.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.757.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.758.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up a transformer to replace outliers in two variables, using limits determined </span><a id="_idIndexMarker408"/><span class="koboSpan" id="kobo.759.1" xmlns:="http://www.w3.org/1999/xhtml">with the mean and </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.761.1" xmlns:="http://www.w3.org/1999/xhtml">
capper = Winsorizer(
    variables=[«worst smoothness», «worst texture»],
    capping_method="gaussian",
    tail="both",
    fold=3,
)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.762.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.763.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer</span></strong><span class="koboSpan" id="kobo.764.1" xmlns:="http://www.w3.org/1999/xhtml"> can</span><a id="_idIndexMarker409"/><span class="koboSpan" id="kobo.765.1" xmlns:="http://www.w3.org/1999/xhtml"> identify boundaries using the mean and standard deviation, as we show in this recipe, as well as the IQR proximity rule and MAD. </span><span class="koboSpan" id="kobo.765.2" xmlns:="http://www.w3.org/1999/xhtml">You need to change </span><strong class="source-inline"><span class="koboSpan" id="kobo.766.1" xmlns:="http://www.w3.org/1999/xhtml">capping_meth</span><a id="_idTextAnchor731"/><span class="koboSpan" id="kobo.767.1" xmlns:="http://www.w3.org/1999/xhtml">od</span></strong><span class="koboSpan" id="kobo.768.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.769.1" xmlns:="http://www.w3.org/1999/xhtml">iqr</span></strong><span class="koboSpan" id="kobo.770.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.771.1" xmlns:="http://www.w3.org/1999/xhtml">mad</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.772.1" xmlns:="http://www.w3.org/1999/xhtml">, respectively.</span></span></p>
<ol>
<li value="8"><span class="koboSpan" id="kobo.773.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the transformer to the data so that it learns </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1" xmlns:="http://www.w3.org/1999/xhtml">those limits:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.775.1" xmlns:="http://www.w3.org/1999/xhtml">
capper.fit(X_train)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.776.1" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.777.1" xmlns:="http://www.w3.org/1999/xhtml">capper.left_tail</span><a id="_idTextAnchor732"/><span class="koboSpan" id="kobo.778.1" xmlns:="http://www.w3.org/1999/xhtml">_caps_</span></strong><span class="koboSpan" id="kobo.779.1" xmlns:="http://www.w3.org/1999/xhtml">, we can visualize the lower limits for the two variables: </span><strong class="source-inline"><span class="koboSpan" id="kobo.780.1" xmlns:="http://www.w3.org/1999/xhtml">{'worst smoothness': 0.06364743973736293, 'worst texture': 7.115307053129349}</span></strong><span class="koboSpan" id="kobo.781.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.781.2" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.782.1" xmlns:="http://www.w3.org/1999/xhtml">capper.right_tail_caps_</span></strong><span class="koboSpan" id="kobo.783.1" xmlns:="http://www.w3.org/1999/xhtml">, we can see the variables’ upper limits: </span><strong class="source-inline"><span class="koboSpan" id="kobo.784.1" xmlns:="http://www.w3.org/1999/xhtml">{'worst smoothness': 0.20149734880520967, 'worst </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.785.1" xmlns:="http://www.w3.org/1999/xhtml">texture': 43.97692158753917}</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.786.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p></li> <li><span class="koboSpan" id="kobo.787.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s replace the outliers with the limits from </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.788.1" xmlns:="http://www.w3.org/1999/xhtml">step 8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.789.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.790.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train = capper.transform(X_train)
X_test = capper.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.791.1" xmlns:="http://www.w3.org/1999/xhtml">If we now execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.792.1" xmlns:="http://www.w3.org/1999/xhtml">train_t[capper.variables_].agg(["min", "max"])</span></strong><span class="koboSpan" id="kobo.793.1" xmlns:="http://www.w3.org/1999/xhtml">, we’ll see that the maximum and minimum values of the transformed DataFrame coincide with either the maximum and minimum values of the variables or the identified limits, whatever </span><span class="No-Break"><span class="koboSpan" id="kobo.794.1" xmlns:="http://www.w3.org/1999/xhtml">comes first:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.795.1" xmlns:="http://www.w3.org/1999/xhtml">      worst smoothness  worst texture
min              0.071170        12.020000
max              0.201411        43.953738</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.796.1" xmlns:="http://www.w3.org/1999/xhtml">If you are</span><a id="_idIndexMarker410"/><span class="koboSpan" id="kobo.797.1" xmlns:="http://www.w3.org/1999/xhtml"> planning to cap variables, make sure you compare the performance of your models or the results of your ana</span><a id="_idTextAnchor733"/><a id="_idTextAnchor734"/><span class="koboSpan" id="kobo.798.1" xmlns:="http://www.w3.org/1999/xhtml">lysis before and after </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1" xmlns:="http://www.w3.org/1999/xhtml">replacing outliers.</span></span></p></li> </ol>
<h2 id="_idParaDest-162"><a id="_idTextAnchor735"/><span class="koboSpan" id="kobo.800.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.801.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.802.1" xmlns:="http://www.w3.org/1999/xhtml">clip()</span></strong><span class="koboSpan" id="kobo.803.1" xmlns:="http://www.w3.org/1999/xhtml"> function from</span><a id="_idIndexMarker411"/><span class="koboSpan" id="kobo.804.1" xmlns:="http://www.w3.org/1999/xhtml"> pandas is used to cap values at lower or upper specified limits. </span><span class="koboSpan" id="kobo.804.2" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we found those limits using the mean and standard deviation, and then clipped the variable so that all observations took values within those limits. </span><span class="koboSpan" id="kobo.804.3" xmlns:="http://www.w3.org/1999/xhtml">The minimum value of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1" xmlns:="http://www.w3.org/1999/xhtml">worst smoothness</span></strong><span class="koboSpan" id="kobo.806.1" xmlns:="http://www.w3.org/1999/xhtml"> variable was actually greater than the lower limit we found in </span><em class="italic"><span class="koboSpan" id="kobo.807.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em><span class="koboSpan" id="kobo.808.1" xmlns:="http://www.w3.org/1999/xhtml">, so no values were replaced at the left of its distribution. </span><span class="koboSpan" id="kobo.808.2" xmlns:="http://www.w3.org/1999/xhtml">However, there were values greater than the upper limit from </span><em class="italic"><span class="koboSpan" id="kobo.809.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em><span class="koboSpan" id="kobo.810.1" xmlns:="http://www.w3.org/1999/xhtml">, and those were replaced with the limit. </span><span class="koboSpan" id="kobo.810.2" xmlns:="http://www.w3.org/1999/xhtml">This means that the minimum value of the transformed variable and the original variable coincide, but the maximum values </span><span class="No-Break"><span class="koboSpan" id="kobo.811.1" xmlns:="http://www.w3.org/1999/xhtml">do not.</span></span></p>
<p><span class="koboSpan" id="kobo.812.1" xmlns:="http://www.w3.org/1999/xhtml">We used </span><strong class="source-inline"><span class="koboSpan" id="kobo.813.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.814.1" xmlns:="http://www.w3.org/1999/xhtml"> to replace outliers in multiple variables simultaneously. </span><strong class="source-inline"><span class="koboSpan" id="kobo.815.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer()</span></strong><span class="koboSpan" id="kobo.816.1" xmlns:="http://www.w3.org/1999/xhtml"> can identify outliers based on the mean and standard deviation, the IQR proximity rule, MAD, or by using percentiles. </span><span class="koboSpan" id="kobo.816.2" xmlns:="http://www.w3.org/1999/xhtml">We can modify this behavior through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.817.1" xmlns:="http://www.w3.org/1999/xhtml">capping_method</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.818.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.819.1" xmlns:="http://www.w3.org/1999/xhtml">The methods to identify outliers can be made more or less conservative by changing the factor by which we multiply the IQR, the standard deviation, or MAD. </span><span class="koboSpan" id="kobo.819.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.820.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer()</span></strong><span class="koboSpan" id="kobo.821.1" xmlns:="http://www.w3.org/1999/xhtml">, we can control the strength of the methods through the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.822.1" xmlns:="http://www.w3.org/1999/xhtml">fold</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.823.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.824.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.825.1" xmlns:="http://www.w3.org/1999/xhtml">tails</span></strong><span class="koboSpan" id="kobo.826.1" xmlns:="http://www.w3.org/1999/xhtml"> set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.827.1" xmlns:="http://www.w3.org/1999/xhtml">"both"</span></strong><span class="koboSpan" id="kobo.828.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.829.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer()</span></strong><span class="koboSpan" id="kobo.830.1" xmlns:="http://www.w3.org/1999/xhtml"> found and replaced outliers at both ends of the variables’ distribution. </span><span class="koboSpan" id="kobo.830.2" xmlns:="http://www.w3.org/1999/xhtml">To replace outliers at either end, we can pass </span><strong class="source-inline"><span class="koboSpan" id="kobo.831.1" xmlns:="http://www.w3.org/1999/xhtml">"left"</span></strong><span class="koboSpan" id="kobo.832.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.833.1" xmlns:="http://www.w3.org/1999/xhtml">"right"</span></strong><span class="koboSpan" id="kobo.834.1" xmlns:="http://www.w3.org/1999/xhtml"> to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.835.1" xmlns:="http://www.w3.org/1999/xhtml">tails</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.836.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.837.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer()</span></strong><span class="koboSpan" id="kobo.838.1" xmlns:="http://www.w3.org/1999/xhtml"> adopts the scikit-learn functionality with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.839.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.840.1" xmlns:="http://www.w3.org/1999/xhtml"> method, to learn parameters, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.841.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.842.1" xmlns:="http://www.w3.org/1999/xhtml"> to modify the dataset. </span><span class="koboSpan" id="kobo.842.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.843.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.844.1" xmlns:="http://www.w3.org/1999/xhtml">, the transformer learned and </span><a id="_idIndexMarker412"/><span class="koboSpan" id="kobo.845.1" xmlns:="http://www.w3.org/1999/xhtml">stored the limits for each variable. </span><span class="koboSpan" id="kobo.845.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.846.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.847.1" xmlns:="http://www.w3.org/1999/xhtml">, it replaced the values of the ou</span><a id="_idTextAnchor736"/><a id="_idTextAnchor737"/><span class="koboSpan" id="kobo.848.1" xmlns:="http://www.w3.org/1999/xhtml">tliers, returning </span><span class="No-Break"><span class="koboSpan" id="kobo.849.1" xmlns:="http://www.w3.org/1999/xhtml">pandas DataFrames.</span></span></p>
<h2 id="_idParaDest-163"><a id="_idTextAnchor738"/><span class="koboSpan" id="kobo.850.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.851.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.852.1" xmlns:="http://www.w3.org/1999/xhtml"> has </span><strong class="source-inline"><span class="koboSpan" id="kobo.853.1" xmlns:="http://www.w3.org/1999/xhtml">ArbitraryOutlierCapper()</span></strong><span class="koboSpan" id="kobo.854.1" xmlns:="http://www.w3.org/1999/xhtml">, which caps variables at arbitrary minimum and maximum </span><span class="No-Break"><span class="koboSpan" id="kobo.855.1" xmlns:="http://www.w3.org/1999/xhtml">values: </span></span><a href="https://feature-engine.readthedocs.io/en/latest/api_doc/outliers/ArbitraryOutlierCapper.html"><span class="No-Break"><span class="koboSpan" id="kobo.856.1" xmlns:="http://www.w3.org/1999/xhtml">https://feature-engine.readthedocs.io/en/latest/api_doc/outliers/ArbitraryOutlierCapper.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.857.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-164"><a id="_idTextAnchor739"/><span class="koboSpan" id="kobo.858.1" xmlns:="http://www.w3.org/1999/xhtml">Applying winsorization</span></h1>
<p><span class="koboSpan" id="kobo.859.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizing, or winsorization, consists</span><a id="_idIndexMarker413"/><span class="koboSpan" id="kobo.860.1" xmlns:="http://www.w3.org/1999/xhtml"> of replacing extreme, poorly known </span><a id="_idIndexMarker414"/><span class="koboSpan" id="kobo.861.1" xmlns:="http://www.w3.org/1999/xhtml">observations, that is, outliers, with the magnitude of the next largest (or smallest) observation. </span><span class="koboSpan" id="kobo.861.2" xmlns:="http://www.w3.org/1999/xhtml">It’s similar to the procedure described in the previous recipe, </span><em class="italic"><span class="koboSpan" id="kobo.862.1" xmlns:="http://www.w3.org/1999/xhtml">Bringing outliers back within acceptable limits</span></em><span class="koboSpan" id="kobo.863.1" xmlns:="http://www.w3.org/1999/xhtml">, but not exactly the same. </span><span class="koboSpan" id="kobo.863.2" xmlns:="http://www.w3.org/1999/xhtml">Winsorization involves replacing the </span><em class="italic"><span class="koboSpan" id="kobo.864.1" xmlns:="http://www.w3.org/1999/xhtml">same number of outliers</span></em><span class="koboSpan" id="kobo.865.1" xmlns:="http://www.w3.org/1999/xhtml"> at both ends of the distribution, which makes Winsorization a symmetric process. </span><span class="koboSpan" id="kobo.865.2" xmlns:="http://www.w3.org/1999/xhtml">This guarantees that the </span><strong class="bold"><span class="koboSpan" id="kobo.866.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorized mean</span></strong><span class="koboSpan" id="kobo.867.1" xmlns:="http://www.w3.org/1999/xhtml">, that is, the</span><a id="_idIndexMarker415"/><span class="koboSpan" id="kobo.868.1" xmlns:="http://www.w3.org/1999/xhtml"> mean estimated after replacing outliers, remains a robust estimator of the central tendency of </span><span class="No-Break"><span class="koboSpan" id="kobo.869.1" xmlns:="http://www.w3.org/1999/xhtml">the variable.</span></span></p>
<p><span class="koboSpan" id="kobo.870.1" xmlns:="http://www.w3.org/1999/xhtml">In practice, to</span><a id="_idIndexMarker416"/><span class="koboSpan" id="kobo.871.1" xmlns:="http://www.w3.org/1999/xhtml"> remove a similar number of observations at both tails, we’d use percentiles. </span><span class="koboSpan" id="kobo.871.2" xmlns:="http://www.w3.org/1999/xhtml">For example, the 5th percentile is the value below which 5% of the observations lie and the 95th percentile is the value beyond which 5% of the observations lie. </span><span class="koboSpan" id="kobo.871.3" xmlns:="http://www.w3.org/1999/xhtml">Using these values as replacements might result in replacing a similar number of observations on both tails, but it’s not guaranteed. </span><span class="koboSpan" id="kobo.871.4" xmlns:="http://www.w3.org/1999/xhtml">If the dataset contains repeated values, obtaining reliable percentiles is challenging and can lead to an uneven replacement of values at each tail. </span><span class="koboSpan" id="kobo.871.5" xmlns:="http://www.w3.org/1999/xhtml">If this happens, then the winsorized mean is not a good estimator of the central tenden</span><a id="_idTextAnchor740"/><a id="_idTextAnchor741"/><span class="koboSpan" id="kobo.872.1" xmlns:="http://www.w3.org/1999/xhtml">cy. </span><span class="koboSpan" id="kobo.872.2" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will </span><span class="No-Break"><span class="koboSpan" id="kobo.873.1" xmlns:="http://www.w3.org/1999/xhtml">apply winsorization.</span></span></p>
<h2 id="_idParaDest-165"><a id="_idTextAnchor742"/><span class="koboSpan" id="kobo.874.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.875.1" xmlns:="http://www.w3.org/1999/xhtml">We will cap all </span><a id="_idIndexMarker417"/><span class="koboSpan" id="kobo.876.1" xmlns:="http://www.w3.org/1999/xhtml">variables of the breast cancer dataset at their 5th and </span><span class="No-Break"><span class="koboSpan" id="kobo.877.1" xmlns:="http://www.w3.org/1999/xhtml">95th percentiles:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.878.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.879.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.880.1" xmlns:="http://www.w3.org/1999/xhtml">
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split</span></pre></li> <li><span class="koboSpan" id="kobo.881.1" xmlns:="http://www.w3.org/1999/xhtml">Load the breast cancer dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.882.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.883.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = load_breast_cancer(
    return_X_y=True, as_frame=True)</span></pre></li> <li><span class="koboSpan" id="kobo.884.1" xmlns:="http://www.w3.org/1999/xhtml">Separate</span><a id="_idIndexMarker418"/><span class="koboSpan" id="kobo.885.1" xmlns:="http://www.w3.org/1999/xhtml"> the data into a train and </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.887.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.3,
    random_state=0,
)</span></pre></li> <li><span class="koboSpan" id="kobo.888.1" xmlns:="http://www.w3.org/1999/xhtml">Capture the 5th and 95th percentiles of each variable </span><span class="No-Break"><span class="koboSpan" id="kobo.889.1" xmlns:="http://www.w3.org/1999/xhtml">in dictionaries:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.890.1" xmlns:="http://www.w3.org/1999/xhtml">
q05 = X_train.quantile(0.05).to_dict()
q95 = X_train.quantile(0.95).to_dict()</span></pre></li> <li><span class="koboSpan" id="kobo.891.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s now replace values beyond those percentiles with the respective percentiles for all variables </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1" xmlns:="http://www.w3.org/1999/xhtml">at once:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.893.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t = X_train.clip(lower=q05, upper=q95)
test_t = X_test.clip(lower=q05, upper=q95)</span></pre></li> <li><span class="koboSpan" id="kobo.894.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s display the minimum, maximum, and mean values of one variable </span><span class="No-Break"><span class="koboSpan" id="kobo.895.1" xmlns:="http://www.w3.org/1999/xhtml">before winsorization:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.896.1" xmlns:="http://www.w3.org/1999/xhtml">
var = 'worst smoothness'
X_train[var].agg(["min", "max", "mean"])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.897.1" xmlns:="http://www.w3.org/1999/xhtml">We can see the values in the </span><span class="No-Break"><span class="koboSpan" id="kobo.898.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.899.1" xmlns:="http://www.w3.org/1999/xhtml">min      0.071170</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.900.1" xmlns:="http://www.w3.org/1999/xhtml">max      0.222600</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.901.1" xmlns:="http://www.w3.org/1999/xhtml">mean     0.132529</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.902.1" xmlns:="http://www.w3.org/1999/xhtml">Name: worst smoothness, dtype: float64</span></strong></pre></li> <li><span class="koboSpan" id="kobo.903.1" xmlns:="http://www.w3.org/1999/xhtml">Display the</span><a id="_idIndexMarker419"/><span class="koboSpan" id="kobo.904.1" xmlns:="http://www.w3.org/1999/xhtml"> minimum, maximum, and mean values </span><a id="_idIndexMarker420"/><span class="koboSpan" id="kobo.905.1" xmlns:="http://www.w3.org/1999/xhtml">of the same variable </span><span class="No-Break"><span class="koboSpan" id="kobo.906.1" xmlns:="http://www.w3.org/1999/xhtml">after winsorization:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.907.1" xmlns:="http://www.w3.org/1999/xhtml">
train_t[var].agg([„min", „max"])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.908.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we can see that the minimum and maximum values correspond to the percentiles. </span><span class="koboSpan" id="kobo.908.2" xmlns:="http://www.w3.org/1999/xhtml">However, the mean is quite similar to the original mean of </span><span class="No-Break"><span class="koboSpan" id="kobo.909.1" xmlns:="http://www.w3.org/1999/xhtml">the variable:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.910.1" xmlns:="http://www.w3.org/1999/xhtml">min      0.096053</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.911.1" xmlns:="http://www.w3.org/1999/xhtml">max      0.173215</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.912.1" xmlns:="http://www.w3.org/1999/xhtml">mean     0.132063</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.913.1" xmlns:="http://www.w3.org/1999/xhtml">Name: worst smoothness, dtype: float64</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.914.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.915.1" xmlns:="http://www.w3.org/1999/xhtml">If you want to use winsorization as part of a scikit-learn pipeline, you can use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.916.1" xmlns:="http://www.w3.org/1999/xhtml">feature-engine</span></strong><span class="koboSpan" id="kobo.917.1" xmlns:="http://www.w3.org/1999/xhtml"> library’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.918.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer()</span></strong><span class="koboSpan" id="kobo.919.1" xmlns:="http://www.w3.org/1999/xhtml">, by setting it up </span><span class="No-Break"><span class="koboSpan" id="kobo.920.1" xmlns:="http://www.w3.org/1999/xhtml">as follows:</span></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.921.1" xmlns:="http://www.w3.org/1999/xhtml">capper = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.922.1" xmlns:="http://www.w3.org/1999/xhtml">Winsorizer(</span></strong></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.923.1" xmlns:="http://www.w3.org/1999/xhtml">     </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.924.1" xmlns:="http://www.w3.org/1999/xhtml">capping_method="quantiles",</span></strong></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.925.1" xmlns:="http://www.w3.org/1999/xhtml">     </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.926.1" xmlns:="http://www.w3.org/1999/xhtml">tail="both",</span></strong></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.927.1" xmlns:="http://www.w3.org/1999/xhtml">     </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.928.1" xmlns:="http://www.w3.org/1999/xhtml">fold=0.05,</span></strong></span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.929.1" xmlns:="http://www.w3.org/1999/xhtml">)</span></strong></p>
<p class="callout"><span class="koboSpan" id="kobo.930.1" xmlns:="http://www.w3.org/1999/xhtml">After this, proceed with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.931.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.932.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.933.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.934.1" xmlns:="http://www.w3.org/1999/xhtml"> methods as described in the </span><em class="italic"><span class="koboSpan" id="kobo.935.1" xmlns:="http://www.w3.org/1999/xhtml">Bringing outliers back within acceptable </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.936.1" xmlns:="http://www.w3.org/1999/xhtml">limits</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.937.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.938.1" xmlns:="http://www.w3.org/1999/xhtml">It’s </span><a id="_idIndexMarker421"/><span class="koboSpan" id="kobo.939.1" xmlns:="http://www.w3.org/1999/xhtml">worth </span><a id="_idIndexMarker422"/><span class="koboSpan" id="kobo.940.1" xmlns:="http://www.w3.org/1999/xhtml">noting that despite employing percentiles, the procedure didn’t precisely replace the same number of observations on both sides of the distribution. </span><span class="koboSpan" id="kobo.940.2" xmlns:="http://www.w3.org/1999/xhtml">If you intend to winsorize your variables, compare the out</span><a id="_idTextAnchor743"/><a id="_idTextAnchor744"/><span class="koboSpan" id="kobo.941.1" xmlns:="http://www.w3.org/1999/xhtml">comes of your analyses before and </span><span class="No-Break"><span class="koboSpan" id="kobo.942.1" xmlns:="http://www.w3.org/1999/xhtml">after winsorization.</span></span></p>
<h2 id="_idParaDest-166"><a id="_idTextAnchor745"/><span class="koboSpan" id="kobo.943.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.944.1" xmlns:="http://www.w3.org/1999/xhtml">We used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.945.1" xmlns:="http://www.w3.org/1999/xhtml">quantiles()</span></strong><span class="koboSpan" id="kobo.946.1" xmlns:="http://www.w3.org/1999/xhtml"> to obtain the 5th and 95th percentiles of all the variables in the dataset, and combined it with </span><strong class="source-inline"><span class="koboSpan" id="kobo.947.1" xmlns:="http://www.w3.org/1999/xhtml">to_dict()</span></strong><span class="koboSpan" id="kobo.948.1" xmlns:="http://www.w3.org/1999/xhtml"> to retain those percentiles in dictionaries, where the keys were the variables and the values were the percentiles. </span><span class="koboSpan" id="kobo.948.2" xmlns:="http://www.w3.org/1999/xhtml">We then passed these dictionaries to pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.949.1" xmlns:="http://www.w3.org/1999/xhtml">clip()</span></strong><span class="koboSpan" id="kobo.950.1" xmlns:="http://www.w3.org/1999/xhtml"> to replace values smaller or larger than those percentiles by the percentiles. </span><span class="koboSpan" id="kobo.950.2" xmlns:="http://www.w3.org/1999/xhtml">By using dictionaries, we capped multiple variables </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1" xmlns:="http://www.w3.org/1999/xhtml">at once.</span></span></p>
<h2 id="_idParaDest-167"><a id="_idTextAnchor746"/><span class="koboSpan" id="kobo.952.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><span class="koboSpan" id="kobo.953.1" xmlns:="http://www.w3.org/1999/xhtml">For more details about how winsorization affects the mean and standard deviation in symmetric and asymmetric replacements, check out the </span><span class="No-Break"><span class="koboSpan" id="kobo.954.1" xmlns:="http://www.w3.org/1999/xhtml">original article:</span></span></p>
<p><span class="koboSpan" id="kobo.955.1" xmlns:="http://www.w3.org/1999/xhtml">Dixon W. </span><em class="italic"><span class="koboSpan" id="kobo.956.1" xmlns:="http://www.w3.org/1999/xhtml">Simplified Estimation from Censored Normal Samples. </span><span class="koboSpan" id="kobo.956.2" xmlns:="http://www.w3.org/1999/xhtml">The Annals of Mathematica</span><a id="_idTextAnchor747"/><span class="koboSpan" id="kobo.957.1" xmlns:="http://www.w3.org/1999/xhtml">l Statistics</span></em><span class="koboSpan" id="kobo.958.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><span class="No-Break"><span class="koboSpan" id="kobo.959.1" xmlns:="http://www.w3.org/1999/xhtml">1960. </span></span><a href="https://www.jstor.org/stable/2237953"><span class="No-Break"><span class="koboSpan" id="kobo.960.1" xmlns:="http://www.w3.org/1999/xhtml">http://www.jstor.org/stable/2237953</span></span></a></p>
</div>
</body></html>