<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What's Next?</h1>
                </header>
            
            <article>
                
<p class="mce-root">The projects covered in this book can be considered bite-sized projects. They can be completed within a day or two. A real project will often take months. They require a combination of machine learning expertise, engineering expertise, and DevOps expertise. It would not quite be feasible to write about such projects without spanning multiple chapters while keeping the same level of detail. In fact, as can be witnessed by the progression of this book, as projects get more complex, the level of detail drops. In fact, the last two chapters are pretty thin.</p>
<p class="mce-root">All said and done, we've achieved quite a bit in this book. However, there is quite a bit we have not covered. This is owing to my own personal lack of expertise in some other fields in machine learning. In the introductory chapter, I noted that there are multiple classification schemes for machine learning systems and that we'd be choosing the common view that there are only unsupervised and supervised types of learning. Clearly, there are other classification schemes. Allow me to share another, one that has five classifications of machine learning systems:</p>
<ul>
<li class="mce-root">Connectionist</li>
<li class="mce-root">Evolutionary</li>
<li class="mce-root">Bayesian</li>
<li class="mce-root">Analogizer</li>
<li class="mce-root">Symbolist</li>
</ul>
<p class="mce-root">Here, I use the term machine learning. Others may use the term artificial intelligence to classify these systems. The difference is subtle. These five classes are technically schools of thought within artificial intelligence. And this sets a much larger stage for the topics at hand.</p>
<p class="mce-root">Except for two, we have, in this book, explored the different schools of thought in artificial intelligence. In the Connectionist school, we started with linear regression in <a href="12c81095-6fcf-4da9-b554-6367d45b34f8.xhtml" target="_blank"/><a href="12c81095-6fcf-4da9-b554-6367d45b34f8.xhtml" target="_blank">Chapter 2</a>, <em><span>Linear Regression – House Price Prediction</span></em>, and the various neural networks from <a href="26529196-995f-4689-91d7-0039b62337e9.xhtml" target="_blank">Chapters 8</a>, <em>Basic Facial Detection</em>, and <a href="3d4d68ef-7bd8-4e5d-9c3a-2d6a05d17842.xhtml" target="_blank">Chapter 10</a>, <em><span>What's Next?</span></em>. In the Bayesian school, we have Naive Bayes from <a href="d0447032-8c26-4198-a13c-b41ec20c02e8.xhtml" target="_blank"/><a href="d0447032-8c26-4198-a13c-b41ec20c02e8.xhtml" target="_blank">Chapter 3</a>, <em>Classification – Spam Email Detection</em>, as well as the DMMClust algorithm in <a href="d54b14d1-3403-4f2a-a98e-dd12adfe585a.xhtml" target="_blank">Chapter 6</a>, <em>Neural Networks – MNIST Handwriting Recognition</em>; we also have the various distance and clustering algorithms, which somewhat fall into the analogizer school of thought.</p>
<p class="mce-root">The two schools of thought on artificial intelligence that are not covered are the Evolutionary school and the Symbolist school. The former I only have theoretical experiences of. My understanding of the Evolutionary school of artificial intelligence is not great. I have much to learn from the likes of Martin Nowak. The latter, I am familiar with—I have been told that my introduction to Go betrays a lot of my experience with the Symbolist school of thought.</p>
<p class="mce-root">The main reason why I didn't write anything about the Symbolist school of thought is that as a subject matter it is too dense, and I am not a good enough writer to actually tackle the subject. It opens up hairy philosophical implications more immediately than the Connectionist school does. These implications are something I am not yet ready to deal with, though the reader might be.</p>
<p class="mce-root">Having said that, one of the most exhilarating times in my life was building DeepMind's AlphaGo algorithm in Go. You can find the code here: <a href="https://github.com/gorgonia/agogo" target="_blank">https://github.com/gorgonia/agogo</a>. It's a behemoth of a project, and successfully pulled off by a small team of four. It was an immensely rewarding experience. The AlphaGo algorithm merges Connectionist deep neural networks with Symbolist tree search. Despite pulling off such a feat, I still do not think I am ready to write about the symbolic approach to artificial intelligence.</p>
<p class="mce-root">All of this brings up the question: what's next?</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What should the reader focus on? </h1>
                </header>
            
            <article>
                
<p class="mce-root">This question has been asked of me every time I give a class on machine learning and artificial intelligence. I mentioned in the introductory chapter that one may want to be a machine learning practitioner or a machine learning researcher. My professional role straddles both. This allows me some experience to provide a bit of advice for readers interested in either field.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The practitioner </h1>
                </header>
            
            <article>
                
<p class="mce-root">To the practitioner, the most important skill is not in machine learning. The most important skill is in understanding the problem. Implicit in this statement is that the practitioner should also at least understand which machine learning algorithms would be suitable for the problem at hand. Obviously this entails understanding how the machine learning algorithm works.</p>
<p class="mce-root">New<span> people in the field</span><span> often ask me whether deep learning will solve all their problems. The answer is emphatically no. The solution must be tailored to the problem. Indeed, often, non-deep-learning solutions outperform deep learning solutions in terms of speed and accuracy. These are typically simple problems, so that's a good rule of thumb there: if the problem is non-compositional, you most likely do not need to use deep learning.</span></p>
<p class="mce-root">What do I mean by non-compositional? Recall from <a href="3d68e167-a44d-4195-a270-f8180ff8f85f.xhtml" target="_blank">Chapter 1</a>, <em>How to Solve All Machine Learning Problems</em>, when I introduced the types of problems, and how problems may be broken down into subproblems. If the subproblems are themselves composed of further subproblems, well, that means the problem is <em>composed</em> of subproblems. Problems that aren't compositional do not need deep learning.</p>
<p class="mce-root">Granted, this is a very gross overview of the issue. A finer understanding of the problem is always required.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The researcher </h1>
                </header>
            
            <article>
                
<p class="mce-root">To the researcher, the most important skill is understanding how a machine learning algorithm works at a high level. Following this, understanding data structures is the most important. From there, an actual algorithm may be written.</p>
<p class="mce-root">Of note would be the difference between data representation and data structure. Perhaps some day in the future—hopefully not too far from now—we will have programming languages where data representation does not matter. But now, data representation still matters. A good representation will yield an efficient algorithm. A poor representation yields poor algorithm performance.</p>
<p class="mce-root">For the most part, my advice is to start simple, by making things as understandable as possible as first. Then start subtracting the parts that are not necessary. A good example is shown in <a href="d0447032-8c26-4198-a13c-b41ec20c02e8.xhtml" target="_blank">Chapter 3</a><span>, </span><em>Classification – Spam Email Detection</em>, in Naive Bayes. A direct representation of the Bayesian function would be quite clunky. But in understanding the moving parts of the algorithm, we are able to make it efficient and small.</p>
<p class="mce-root">Sometimes, some complexity is unavoidable. Some complexities are unavoidable because the algorithm is fundamentally complex. Some complexities are tradeoffs that are required. An example of this is the use of Gorgonia. Deep learning is at its heart, just writing a long mathematical expression. To update the weights, backpropagation is used. Backpropagation is simply differentiation. But nobody wants to manually calculate the differentiation! We want to mechanically evaluate our calculus! Therefore some complexity is unavoidable.</p>
<p class="mce-root">Wisdom lies in knowing when these complexities are unavoidable. Wisdom comes from experience, so to the researcher, my advice is to do as much as possible. Doing things at different scales also brings out different experiences. For example, performing K-means at scale across multiple machines is a very different code from the one presented in the previous chapters.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The researcher, the practitioner, and their stakeholder</h1>
                </header>
            
            <article>
                
<p class="mce-root">A word on scale—there is a tendency to reach out to packages or external programs, such as Spark, to solve the problem. Often they do solve the problem. But it's been my experience that ultimately, when doing things at scale, there is no one-size-fits-all solution. Therefore, it's good to learn the basics, so that when necessary, you may refer to the basics and extrapolate them to your situation.</p>
<p class="mce-root">Again on the topic of scale—both researchers and practitioners would do well to learn to plan projects. This is one thing that I am exceedingly bad at. Even with the help of multiple project managers, machine learning projects have a tendency to spiral out of control. It does take quite a bit of discipline to manage these. This is both on the implementor's part and on the stakeholder's part.</p>
<p class="mce-root">Last, learn to manage the expectations of stakeholders. Many of my projects fail. That I can say the projects fail is itself a qualifying statement. For most projects I enter into, I have defined success and failure criteria. If it's a more traditional statistics-based project, then these are your simple null hypotheses. Failing to reject the null hypothesis would then be a failure. Likewise, more complicated projects would have multiple hypotheses—<span>t</span>hese come in form of F-scores and the like. Learn these tools well, and communicate them to your stakeholders. You must be aware that a large majority of machine learning projects fail on their first few attempts.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Where can I learn more?</h1>
                </header>
            
            <article>
                
<p class="mce-root">I strongly believe machine learning methods should not be tied to programming languages. If tomorrow a new language comes out that offers better performance than Go, while keeping the developer friendliness of Go, I'd move to that language in a heartbeat. I wouldn't have to be worried about having to relearn new machine learning methods. I already know them. I can simply rewrite them in that new language. As such, my recommendations would be language-agnostic.</p>
<p class="mce-root">If you want to learn more about machine learning algorithms, I recommend Christopher Bishop's, <em>Pattern Recognition and Machine Learning</em>. It's a slightly older book, but you'll be surprised at how many new developments in machine learning have their roots in that tome.</p>
<p class="mce-root">If you want to learn more about deep learning, I recommend Ian Goodfellow and Yoshua Bengio's, <em>Deep Learning</em>. It's a new book—it's extremely theoretical, with no code, but the insights gained will be priceless.</p>
<p class="mce-root">If you want to learn more about deep learning using Go and Gorgonia, there is an upcoming book by Darrell Chua and Gareth Seneque, published by Packt. It covers a wide range of deep-learning-related topics.</p>
<p class="mce-root">If you want to learn more about data science and machine learning in Go, I also recommend Daniel Whitenack's, <em>Machine Learning with Go</em>. It's one of the first books on machine learning in Go, and to this day, it still stands as an excellent resource.</p>
<p class="mce-root">If you want to learn more about Go, I highly recommend <em>The Go Programming Language</em>, by Alan Donovan and Brian Kernighan. <strong>Kernighan</strong> is the <strong>K</strong> in the famous <strong>K&amp;amp;R</strong> book on C. Here, he performs a similar feat.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Thank you</h1>
                </header>
            
            <article>
                
<p class="mce-root">Thank you for reading this book; I hope it has been useful to you.</p>


            </article>

            
        </section>
    </div>



  </body></html>