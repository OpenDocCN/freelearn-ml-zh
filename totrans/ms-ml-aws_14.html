<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Working with AWS Comprehend</h1>
                </header>
            
            <article>
                
<p class="mce-root">As a data scientist, knowing how machine learning algorithms work is very important. However, it may not be efficient to build your own machine learning models to perform certain tasks, as it takes a lot of effort and time to design an optimal algorithm. In <a href="b83ce0ca-e2d7-43f5-9e82-21edb54250c9.xhtml">Chapter 10</a>, <em>Working with AWS Comprehend</em>, <a href="b6601397-10a0-4a94-ba9f-32b5bfcdbb06.xhtml">Chapter 11</a>, <em>Using AWS Rekognition</em> and <a href="f9e097f0-ee26-456d-9360-7d0d3743e3a6.xhtml">Chapter 12</a>, <em>Building Conversational Interfaces Using AWS Lex</em>, we will look at the <strong>machine learning as a s</strong><strong>ervice</strong> (<strong>MLaaS</strong>) product that you can access in AWS. These products allow you to use models that are pre-trained in AWS using either the AWS dashboard or API calls. </p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Introducing <span>Amazon </span>Comprehend</li>
<li>Accessing Amazon Comprehend</li>
<li>Testing entity recognition using <span>Comprehend</span></li>
<li><span>Testing s</span>entiment analysis using <span>Comprehend</span></li>
<li>Implementing text classification using <span>Comprehend APIs</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing Amazon Comprehend</h1>
                </header>
            
            <article>
                
<p>Amazon Comprehend is a service available in AWS that offers <strong>natural language processing</strong> (<strong>NLP</strong>) algorithms. NLP is a field in machine learning that analyzes human (natural) languages and can identify various attributes of these languages. In most of our previous chapters, we looked at examples of structured data. The data had predefined features and was organized as rows of observations. However, a natural language dataset is more complicated to process. Such datasets are called <strong>unstructured datasets</strong>, as the structure of the features is not well-defined.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Hence, algorithms are needed to extract structure and information from a text document. For example, a natural language has words that are arranged using a grammatical structure. Natural-language sentences also have keywords, which contain more information regarding places, people, and other details. They also have a context, which is very hard to learn, and the same words may convey different meanings based on how they are arranged. </p>
<p>The field of NLP studies how to process these text documents and extract information from them. NLP not only involves clustering and classifying the documents, but also preprocessing the data to extract important keywords and entity information from the text. Based on the domain of the text documents, different preprocessing is required, as the styles of written documents change. For example, medical and legal texts are written with a lot of jargon and are well-structured. However, if you are using an NLP algorithm to process Twitter data, the text may be composed of poor grammar and hashtags. Hence, based on the domain of the data, you need a separate process to preprocess the data and how the models should be trained. Domain expertise is generally required when training NLP models. </p>
<p>AWS Comprehend provides tools to both train machine learning models and use pre-trained models to perform NLP tasks. It provides real-time dashboards to analyze text data and also provides tools to train machine learning algorithms using their UI.</p>
<p>In this chapter, we will explore four NLP tasks that can be accomplished using AWS Comprehend. We will also suggest when a data scientist should employ ready-to-use tools and when they should invest time in building their own machine learning algorithms. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accessing AmazonComprehend</h1>
                </header>
            
            <article>
                
<p><a href="https://aws.amazon.com/comprehend/"><span><span>Amazon </span></span>Comprehend</a> is available to use on the AWS Console. When you log into the AWS Management Console, search for Amazon Comprehend in the <span class="packt_screen">AWS Services</span> box. <span><span>Selecting</span></span> <span class="packt_screen">Amazon Comprehend</span><span><span> </span></span>will take you to the <span class="packt_screen">AWS Comprehend</span> start screen, as shown in the following screenshot: </p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-726 image-border" src="assets/f00d8f41-3c7c-4046-bfed-4f8cf06da30d.png" style="width:55.75em;height:18.00em;"/></p>
<p>Click on <span class="packt_screen">Launch Comprehend</span> when you get to this screen, which will take you to the AWS Comprehend dashboard. You should be able to access the algorithms used in the following sections from this page. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Named-entity recognition using Comprehend</h1>
                </header>
            
            <article>
                
<p><strong>Named-entity recognition</strong> (<strong>NER</strong>) is a field in NLP that tags mentions of named entities in unstructured text. Named entities are names of people, places, organizations, and so on. For example, consider the following sentence:</p>
<div class="packt_quote">Tim Cook traveled to New York for an Apple store opening.</div>
<p>In this sentence, there are three named entities. Tim Cook is the name of a person, New York is the name of a city (location), and Apple is the name of an organization. Hence, we need an NER model that can detect these entities. Note that Apple is an ambiguous noun, as it can be the name of a company or a fruit. The NER algorithm should understand the context in which the term is used and identify it accordingly. </p>
<p>AWS Comprehend offers a good NER tool that can be used to identify entities. This tool can be used in real-time via their dashboard or using their APIs. AWS Comprehend detects the following entities:</p>
<ul>
<li><strong>Commercial Item</strong>: Brand names</li>
<li><strong>Date</strong>: Dates in different formats</li>
<li><strong>Event</strong>: Names of concerts, festivals, elections, <span>and so on</span></li>
<li><strong>Location</strong>: Names of cities, countries, <span>and so on</span></li>
<li><strong>Organization</strong>: Names of companies and governmental organizations</li>
<li><strong>Person</strong>: Names of people</li>
<li><strong>Quantity</strong>: Commonly used units used to quantify a number</li>
<li><strong>Title</strong>: Names of movies, books, and so on</li>
</ul>
<p>To access the AWS dashboard for NER, go to the <span class="packt_screen">Real-time Analysis</span> tab in the menu. You can then add input text in the text box provided on the page. The following screenshot demonstrated how Amazon Comprehend performs the NER task:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-822 image-border" src="assets/b9c4ab81-b32e-4ca8-be65-168e7402f1b9.png" style="width:39.83em;height:25.17em;"/></p>
<p>You can see that the NER tool in Amazon Comprehend automatically labels the entities in the sentence. Along with labeling the categories of the entities, it also gives us a confidence score. This score can be used to determine whether we trust the results from the tool. </p>
<p>The NER tool in Amazon Comprehend can also be <span><span>accessed </span></span>using the API provided by AWS.</p>
<p>The following code shows how you can call the Comprehend tool to get the entity scores:</p>
<pre><span class="hljs-keyword">import</span><span> boto3<br/></span><span class="hljs-keyword">import</span><span> json<br/><br/>comprehend = boto3.client(service_name=</span><span class="hljs-string">'comprehend'</span><span>) <br/><br/>text = </span><span class="hljs-string">"<span>Tim Cook traveled to New York for an Apple store opening</span>"</span><span><br/><br/>print(json.dumps(comprehend.detect_entities(Text=text, LanguageCode=</span><span class="hljs-string">'en'</span><span>)</span><span>, sort_keys=</span><span class="hljs-keyword">True</span><span>, indent=</span><span class="hljs-number">4</span><span>)</span><span>) </span></pre>
<p>You use the <kbd>boto3</kbd> package, which is an AWS tool package for Python. We first initialize the Comprehend client and then pass our text to the client to get a JSON response with information about the named entities. <span>In the following code block we can see the response we receive from the client</span>:</p>
<pre>{<br/>  "Entities": [<br/>    {<br/>      "Score": 0.9999027252197266,<br/>      "Type": "PERSON",<br/>      "Text": "Tim Cook",<br/>      "BeginOffset": 0,<br/>      "EndOffset": 8<br/>    },<br/>    {<br/>      "Score": 0.992688775062561,<br/>      "Type": "LOCATION",<br/>      "Text": "New York",<br/>      "BeginOffset": 21,<br/>      "EndOffset": 29<br/>    },<br/>    {<br/>      "Score": 0.9699087738990784,<br/>      "Type": "ORGANIZATION",<br/>      "Text": "Apple",<br/>      "BeginOffset": 37,<br/>      "EndOffset": 42<br/>    }<br/>  ]<br/>}</pre>
<p>Thus, parsing the JSON can get us information regarding the entities in the text. </p>
<p>You can also train a custom NER algorithm in AWS Comprehend using the <span class="packt_screen">Customization</span> | <span class="packt_screen">Custom entity recognition</span> option in the left-hand side menu. You can add training sample documents and a list of annotations for entities. The algorithm automatically learns how to label these entities in the correct context and updates the existing models. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>NER algorithms are applied in various applications. One of their important applications is in the field of News Aggregation. You can automatically generate tags for a document so that users can search for documents based on the entities in them. NER is also useful in the field of recommendation algorithms, where NER is used to detect keywords and we can create a news-recommendation algorithm. We can build a collaborative filtering model that can recommend articles about entities that readers of a current article may also be interested in.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sentiment analysis using Comprehend</h1>
                </header>
            
            <article>
                
<p>Sentiment analysis algorithms analyze text and categorize it based on the sentiments or opinions in the text. Sentiment analysis detects subjective opinions that are expressed in text. For example, reviews on Amazon Marketplace give a good or a bad review of a product. Using sentiment analysis, we can detect whether a review is positive or negative. We can also recognize emotional nuances in a review, such as whether the reviewer was angry, excited, or neutral about a given product. In this age of social media, we have a large number of avenues to voice our opinions on products, movies, politics, and so on. Data scientists use sentiment analysis algorithms to analyze a large amount of data and extract opinions regarding a certain entity based on unstructured text data. </p>
<p>Amazon Comprehend makes the task of sentiment analysis easy by providing a real-time dashboard to analyze the sentiment in text. You can access the <span class="packt_screen">Sentiment Analysis</span> dashboard the same way you did for the NER algorithm. We'll provide two examples of how Comprehend can perform sentiment analysis on our data. I looked at two reviews on Amazon that were positive and negative and used Comprehend to perform sentiment analysis on them. Consider the first example, as seen in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-812 image-border" src="assets/a7961739-0c56-4aee-ac29-d97eff366f0d.png" style="width:97.92em;height:34.58em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In this example, the reviewer has used words such as disappointed. These terms have negative connotations. However, sentiment analysis algorithms can detect that the user also used a negative before this word and correctly predict that this text has a positive sentiment. Similarly, consider the following example:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-729 image-border" src="assets/fc145b08-2999-4f2d-b8d4-4a8c31ac9089.png" style="width:96.25em;height:41.83em;"/></p>
<p>You can see that the reviewer was initially happy regarding the product, but then had issues. Hence, the reviewer was not happy with the product. Hence, the sentiment analysis algorithm correctly predicts that the confidence of the review being negative is 70%. However, it also predicts that there are some mixed sentiments in this review and provides confidence of 22%. We use the soft-max methodology to pixel the sentiment with the highest confidence. </p>
<p>Sentiment analysis can also be accessed using the Amazon API. Here, we provide example code that shows how we can call the sentiment analysis API using the <kbd>boto3</kbd> Python package: </p>
<pre><span class="hljs-keyword">import</span><span> boto3<br/></span><span class="hljs-keyword">import</span><span> json<br/><br/>comprehend = boto3.client(service_name=</span><span class="hljs-string">'comprehend'</span><span>) <br/><br/>text = </span><span class="hljs-string">" It worked fine for the first 6 weeks, then I lost battery power I turned the phone off at night while charging, did not help. Then every else started to fail."</span><span><br/><br/>print(json.dumps(comprehend.detect_sentiment(Text=text, LanguageCode=</span><span class="hljs-string">'en'</span><span>), sort_keys=</span><span class="hljs-keyword">True</span><span>, indent=</span><span class="hljs-number">4</span><span>))</span></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root">This API call returns the following JSON with the data regarding the sentiment of the text:</p>
<pre>{<br/>    "Sentiment": {<br/>        "Sentiment": "NEGATIVE",<br/>        "SentimentScore": {<br/>            "Positive": 0.03148878738284111,<br/>            "Negative": 0.6730570793151855,<br/>            "Neutral": 0.047707948833703995,<br/>            "Mixed": 0.24774616956710815<br/>        }<br/>    }<br/>}</pre>
<p>You can use the API to classify a large number of reviews to detect what the overall sentiment is for a given product. </p>
<p>Sentiment analysis is a very powerful tool that companies use to analyze social media data to detect the overall sentiment regarding their products and also to determine why users are unhappy with their products. Movie review aggregators, such as Rotten Tomatoes, also use them to detect whether reviews are positive or negative so that they can classify them and generate aggregated scores. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Text classification using Comprehend</h1>
                </header>
            
            <article>
                
<p>Text classification is the process of classifying text documents into categories. Similar to the classification algorithms that we studied in <a href="9163133d-07bc-43a6-88e6-c79b2187e257.xhtml"/><a href="9163133d-07bc-43a6-88e6-c79b2187e257.xhtml"/><a href="9163133d-07bc-43a6-88e6-c79b2187e257.xhtml"/><a href="9163133d-07bc-43a6-88e6-c79b2187e257.xhtml">Chapter 2</a>,<span> </span><em><span class="cdp-organizer-chapter-title"><span class="cdp-organize-title-label">Classifying Twitter Feeds with Naive Bayes</span></span></em> to <a href="c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml">Chapter 6</a>, <em>Analyzing Visitor Patterns to Make Recommendations</em>, text classification algorithms also generate models based on labeled training observations. The classification model can then be applied to any observation to predict its class. Moreover, the same algorithms that we studied in the previous chapters, such as <a href="9163133d-07bc-43a6-88e6-c79b2187e257.xhtml">Chapter 2</a>, <span><em>Classifying Twitter Feeds with Naive Bayes</em>, <a href="eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml">Chapter 3</a>, <em>Predicting House Value with Regression Algorithms</em>, and <a href="af506fc8-f482-453e-8162-93a676b2e737.xhtml">Chapter 4</a>, <em>Predicting User Behavior with Tree-Based Methods,</em></span> can also be used for text classification. </p>
<p>Text data is unstructured data. Hence, we need to generate features from text documents so that those features can be used as input for our classification model. For text datasets, features are generally terms in the document. For example, consider the following sentence:</p>
<div class="packt_quote">Tim Cook traveled to New York for an Apple store opening.</div>
<p class="mce-root"/>
<p>Let's consider the class of this document as <kbd>Technology</kbd>. This sentence will be translated into structured data, as follows:</p>
<div>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><kbd>Tim Cook</kbd></td>
<td><kbd>traveled</kbd></td>
<td><kbd>to</kbd></td>
<td><kbd>New York</kbd></td>
<td><kbd>Apple</kbd></td>
<td><kbd>Store</kbd></td>
<td><kbd><span>Opening</span></kbd></td>
<td><kbd>Microsoft</kbd></td>
<td><kbd>Google</kbd></td>
<td><kbd>Class</kbd></td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>1</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>0</kbd></td>
<td class="CDPAlignCenter CDPAlign"><kbd>0</kbd></td>
<td><kbd>Technology</kbd></td>
</tr>
</tbody>
</table>
</div>
<p> </p>
<p> </p>
<p>Each term will be considered a feature in the dataset. Hence, for a large dataset with many documents, the feature set can be as large as the lexicon of that language. The value of the features is set to <kbd>0</kbd> or <kbd>1</kbd> based on whether that term exists in that document. As our example contains words such as <kbd>Tim Cook</kbd> and <kbd>New York</kbd>, the value of those features for this observation is set to <kbd>1</kbd>. As the terms Microsoft and Google are not present in the sentence, the value of those features is set to <kbd>0</kbd>. The <kbd>Class</kbd> variable is set to <kbd>Technology</kbd>. </p>
<p>In this section, we will show a step-by-step methodology on how to train custom classifiers on Comprehend. We'll use a popular text classification dataset called <strong>20 Newsgroups</strong> to generate a machine learning model that can mark a review as positive or negative. The dataset can be downloaded from <a href="https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups">https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups</a>.</p>
<p>The dataset can be downloaded as separate text files that are organized into 20 folders. Each folder name represents the category of documents in the folder. The dataset is a publicly available dataset. It contains news articles that are categorized into the following categories:</p>
<ul>
<li><kbd>alt.atheism</kbd></li>
<li><kbd>comp.graphics</kbd></li>
<li><kbd>comp.os.ms-windows.misc</kbd></li>
<li><kbd>comp.sys.ibm.pc.hardware</kbd></li>
<li><kbd>comp.sys.mac.hardware</kbd></li>
<li><kbd>comp.windows.x</kbd></li>
<li><kbd>misc.forsale</kbd></li>
<li><kbd>rec.autos</kbd></li>
<li><kbd>rec.motorcycles</kbd></li>
<li><kbd>rec.sport.baseball</kbd></li>
<li><kbd>rec.sport.hockey</kbd></li>
<li><kbd>sci.crypt</kbd></li>
<li><kbd>sci.electronics</kbd></li>
<li><kbd>sci.med</kbd></li>
<li><kbd>sci.space</kbd></li>
<li><kbd>soc.religion.christian</kbd></li>
<li><kbd>talk.politics.guns</kbd></li>
<li><kbd>talk.politics.mideast</kbd></li>
<li><kbd>talk.politics.misc</kbd></li>
<li><kbd>talk.religion.misc</kbd></li>
</ul>
<p>You can use the following steps to train the classifier:</p>
<ol>
<li>The first step is to download and preprocess the data into a format that is readable by the Comprehend tools. Comprehend requires the training data to be in the following format in CSV (comma-separated values):</li>
</ol>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign" style="width: 220.4px"><strong>Category</strong></td>
<td class="CDPAlignCenter CDPAlign" style="width: 254.8px"><strong>Document</strong></td>
</tr>
</tbody>
</table>
<p> </p>
<p style="padding-left: 60px">Hence, once you download the dataset, convert the data into the preceding format and upload it to your S3 bucket. </p>
<ol start="2">
<li>You can access the <span class="packt_screen">Custom Classification</span> tool on the <span class="packt_screen">Comprehend</span> dashboard, on the left-hand side under the <span class="packt_screen">Customization</span> tab. To train the model, you have to click on the <span class="packt_screen">Train Classifier</span> option. Note that Comprehend allows you to train your machine learning models and store them on this dashboard so that you can use them in the future. </li>
</ol>
<p style="padding-left: 60px">When you click on the <span class="packt_screen">Train Classifier</span> option, you will see the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-730 image-border" src="assets/787277e7-a142-425a-8ee4-0d946a21b8ab.png" style="width:57.42em;height:69.17em;"/></p>
<p class="mce-root"/>
<ol start="3">
<li>Name the classifier and select the language of the documents. Add your S3 location, where the training CSV document is stored. After you select the correct role, you can tag the classifier with relevant values, which can help you to search them in the future. Once you have added all the information, click on <span class="packt_screen">Train classifier</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-731 image-border" src="assets/4d8e2c52-835f-4526-a351-5064fe5b913f.png" style="width:57.58em;height:42.17em;"/></p>
<ol start="4">
<li>You will be taken back to the dashboard screen where you will see that the classifier training is in progress. Once the training is done, the status of the classifier will be marked as <span class="packt_screen">Trained</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-813 image-border" src="assets/d08fd414-7ac7-4685-97a9-1479bba25557.png" style="width:43.92em;height:9.67em;"/></p>
<ol start="5">
<li>You can then click on the classifier to see the evaluation metrics of the model. As you can see, our classification model has an accuracy of 90%:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-733 image-border" src="assets/cc1fe664-413f-46be-af89-870f0a42ce6a.png" style="width:47.25em;height:33.25em;"/></p>
<ol start="6">
<li>As we now have a classifier that is trained, you can get predictions for any document using this model. We create a <kbd>test.csv</kbd> file that contains 100 documents to get predictions from this model. We preprocess the data to create a CSV file with one document per line. To start the prediction process, click on the <span class="packt_screen">Create Job </span>option shown on the preceding screen.</li>
</ol>
<p style="padding-left: 90px">This will take you to another screen, where you can add details on which file you want to use for testing and where the output should be stored:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-811 image-border" src="assets/5b2840cf-efee-495c-8a5b-e612436a9d68.png" style="width:42.33em;height:51.42em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">On the <span class="packt_screen">Create analysis job</span> screen, add the details about the classifier to be used: where the input data is stored (on S3) and an <span class="packt_screen">S3 location</span> where the output is stored. You can either specify the input data as <span class="packt_screen">one document per line</span> or <span class="packt_screen">one document per file</span> and point the input data to the directory that contains all the files. In our example, since the <kbd>test.csv</kbd> file contains one document on each line, we use that format. </p>
<ol start="7">
<li>Once you click on <span class="packt_screen">Create Job</span>, it will automatically classify the documents and store the output in the output location. The output is stored in JSON format, where each line of the <kbd>output</kbd> file contains JSON that gives the analysis of that line.</li>
</ol>
<p style="padding-left: 60px">The following is an example of the output that was generated:</p>
<pre style="padding-left: 60px">{<br/>  "File": "test_2.csv",<br/>  "Line": "0",<br/>  "Classes": [<br/>    {<br/>      "Name": "alt.atheism",<br/>      "Score": 0.8642<br/>    },<br/>    {<br/>      "Name": "comp.graphics",<br/>      "Score": 0.0381<br/>    },<br/>    {<br/>      "Name": "comp.os.ms-windows.misc",<br/>      "Score": 0.0372<br/>    },<br/>    ...<br/>    {<br/>      "Name": "talk.religion.misc",<br/>      "Score": 0.0243<br/>    }<br/>  ]<br/>}</pre>
<p>Thus, you can see that our model labeled the first line in our input file as <kbd>"alt.atheism"</kbd> with a confidence score of 86.42%.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>You can also create a document classifier and prediction jobs using the Amazon Comprehend APIs: </p>
<pre><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'comprehend'</span><span class="p">)</span><span class="n"><br/>response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">create_document_classifier</span><span class="p">(</span>
    <span class="n">DocumentClassifierName</span><span class="o">=</span><span class="s1">'20NG-test'</span><span class="p">,</span>
    <span class="n">DataAccessRoleArn</span><span class="o">=</span><span class="s1">'</span><span class="s1">Data Access ARN value</span><span class="s1">'</span><span class="p">,<br/></span>     <span class="n">InputDataConfig</span><span class="o">=</span><span class="p">{<br/></span>         <span class="s1">'S3Uri'</span><span class="p">:</span> <span class="s1">'s3://masteringmlsagemaker/comprehend/train.csv'<br/></span>     <span class="p">},<br/></span>     <span class="n">OutputDataConfig</span><span class="o">=</span><span class="p">{<br/></span>         <span class="s1">'S3Uri'</span><span class="p">:</span> <span class="s1">'</span><span class="s1">s3://masteringmlsagemaker/comprehend/</span><span class="s1">'<br/>     </span><span class="p">},<br/>    </span><span class="n">LanguageCode</span><span class="o">=</span><span class="s1">'en'</span><span class="p">)</span></pre>
<p>Running this function will automatically generate the same classifier that we created in the previous steps. You can access your ARN value from the <span class="packt_screen">Roles</span> tab on the <span class="packt_screen">My Security Credentials</span> page. This is the ARN value of the same IAM role we created in step 3. The output data config location will automatically get a confusion metric of the evaluation of the classifier and the response string will be returned as follows:</p>
<pre><span class="p">{</span>
    <span class="s1">'DocumentClassifierArn'</span><span class="p">:</span> <span class="s1">'string'</span>
<span class="p">}</span></pre>
<p>The string will be the Amazon resource name that identifies the classifier. You can also run prediction jobs using the API. The following code can be used to generate the predictions for your input files:</p>
<pre><span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">client</span><span class="p">(</span><span class="s1">'comprehend'</span><span class="p">)<br/></span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">start_document_classification_job</span><span class="p">(</span> <span class="n">JobName</span><span class="o">=</span><span class="s1">'Testing Model'</span><span class="p">,</span> <span class="n">DocumentClassifierArn</span><span class="o">=</span><span class="s1">'&lt;ARN of classifier returned in the previous step&gt;'</span><span class="p">,</span> <span class="n">InputDataConfig</span><span class="o">=</span><span class="p">{</span> <span class="s1">'S3Uri'</span><span class="p">:</span> <span class="s1">'s3://masteringmlsagemaker/comprehend/test.csv'</span><span class="p">,</span> <span class="s1">'InputFormat'</span><span class="p">:</span> <span class="s1">'ONE_DOC_PER_LINE'</span> <span class="p">},</span> <span class="n">OutputDataConfig</span><span class="o">=</span><span class="p">{</span> <span class="s1">'S3Uri'</span><span class="p">:</span> <span class="s1">'s3://masteringmlsagemaker/comprehend/'</span><span class="p">,</span> <span class="p">},</span> <span class="n">DataAccessRoleArn</span><span class="o">=</span><span class="s1">'&lt;Data Access ARN value&gt;'</span><span class="p">)</span><span class="p"><br/></span></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The preceding code will start the exact same classification job that we created on the dashboard. Thus, you can control when you want to use a certain classifier and generate predictions on different datasets as required. The response of the function will be the status of the job. The job will also generate a job ID, that you can ping to check the status of the job using the <kbd><span>describe_document_classification_job()</span></kbd> function.</p>
<p>Thus, we have generated a custom document classifier using Comprehend tools on AWS. These tools will help you to create these classifiers quickly without having to worry about what classification algorithms to select, how to tune the parameters, and so on. Amazon automatically updates the algorithms used by Comprehend based on the expertise of their research teams. However, the main disadvantage is that Comprehend tools can be costly if you are running operations on large datasets, as they charge you per prediction. You can access the pricing information for AWS Comprehend at <a href="https://aws.amazon.com/comprehend/pricing/">https://aws.amazon.com/comprehend/pricing/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we studied how to use a built-in machine learning tool called Comprehend in AWS. We briefly discussed the field of NLP and provided an introduction to its sub-fields, such as NER and sentiment analysis. We also studied how to create a custom document classifier in Comprehend using the dashboard it provides. Moreover, we studied how to access Comprehend's APIs using the <kbd>boto3</kbd> package in Python. </p>
<p>These tools are fascinating as they will help you to create complex machine learning models quickly and start applying them in your applications. A data scientist who has cursory knowledge in the field of NLP can now train sophisticated machine learning models and use them to make optimal decisions. However, the question most data scientists face is whether the pricing provided by such tools is more economical than building algorithms in-house using Python packages. Note that Comprehend adds a layer of abstraction between data scientists and the machine learning models by making them worry about the underlying cluster configurations. In our experience, we use these tools during the rapid prototyping phases of our projects to evaluate a product. If we decide to move to production, it is easy to calculate the cost differences between using the AWS tools versus building algorithms in-house and maintaining them on our clusters. </p>
<p>We will introduce the Amazon Rekognition in the next chapter. This service is used for image recognition and is an out of the box solution for Object detection and similar applications</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exercise</h1>
                </header>
            
            <article>
                
<ol>
<li>Your task is to perform NER on a large dataset using APIs provided by Amazon Comprehend. Use the annotated NER dataset provided in the Kaggle competition to create a custom entity recognition in Comprehend (<a href="https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities">https://www.kaggle.com/abhinavwalia95/chemdner-iob-annotated-chemical-named-etities</a>).</li>
<li>Apply sentiment analysis on the Yelp dataset in Kaggle and then evaluate whether your predictions match the review score (<a href="https://www.kaggle.com/yelp-dataset/yelp-dataset">https://www.kaggle.com/yelp-dataset/yelp-dataset</a>).</li>
</ol>


            </article>

            
        </section>
    </body></html>