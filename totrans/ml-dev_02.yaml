- en: The Learning Process
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习过程
- en: In the first chapter, we saw a general overview of the mathematical concepts,
    history, and areas of the field of machine learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们看到了机器学习领域的数学概念、历史和领域的概述。
- en: As this book intends to provide a practical but formally correct way of learning,
    now it's time to explore the general thought process for any machine learning
    process. These concepts will be pervasive throughout the chapters and will help
    us to define a common framework of the best practices of the field.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书旨在提供一种既实用又形式正确的学习方法，现在是时候探索任何机器学习过程的一般思想过程了。这些概念将贯穿整个章节，并帮助我们定义该领域最佳实践的共同框架。
- en: 'The topics we will cover in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Understanding the problem and definitions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解问题和定义
- en: Dataset retrieval, preprocessing, and feature engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集检索、预处理和特征工程
- en: Model definition, training, and evaluation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型定义、训练和评估
- en: Understanding results and metrics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解结果和指标
- en: Every machine learning problem tends to have its own particularities. Nevertheless,
    as the discipline advances through time, there are emerging patterns of what kind
    of steps a machine learning process should include, and the best practices for
    them. The following sections will be a list of these steps, including code examples
    for the cases that apply.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个机器学习问题都有其特定的特点。然而，随着学科随着时间的推移而发展，出现了机器学习过程应包括哪些步骤以及最佳实践的模式。以下各节将列出这些步骤，包括适用于这些情况的代码示例。
- en: Understanding the problem
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解问题
- en: When solving machine learning problems, it's important to take time to analyze
    both the data and the possible amount of work beforehand. This preliminary step
    is flexible and less formal than all the subsequent ones on this list.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决机器学习问题时，花时间分析数据和可能的工作量是很重要的。这个初步步骤比列表中随后的所有步骤都要灵活和非正式。
- en: From the definition of machine learning, we know that our final goal is to make
    the computer learn or generalize a certain behavior or model from a sample set
    of data. So, the first thing we should do is understand the new capabilities we
    want to learn.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从机器学习的定义来看，我们知道我们的最终目标是让计算机从一组样本数据中学习或泛化某种行为或模型。因此，我们首先应该做的是理解我们想要学习的新能力。
- en: 'In the enterprise field, this is the time to have more practical discussions
    and brainstorms. The main questions we could ask ourselves during this phase could
    be as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业领域，现在是时候进行更多实际讨论和头脑风暴了。在这个阶段，我们可以提出的主要问题可能如下：
- en: What is the real problem we are trying to solve?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们真正试图解决的问题是什么？
- en: What is the current information pipeline?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前信息管道是什么？
- en: How can I streamline data acquisition?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何简化数据获取？
- en: Is the incoming data complete, or does it have gaps?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进来的数据是否完整，或者是否存在缺失？
- en: What additional data sources could we merge in order to have more variables
    to hand?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以合并哪些额外的数据源，以便有更多的变量可供使用？
- en: Is the data release periodical, or can it be acquired in real time?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据发布是否定期，或者能否实时获取？
- en: What should be the minimal representative unit of time for this particular problem?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于这个特定问题，最小的时间代表性单位应该是什么？
- en: Does the behavior I try to characterize change in nature, or are its fundamentals
    more or less stable through time?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我试图描述的行为在本质上是否发生变化，或者其基本原理在时间上是否相对稳定？
- en: Understanding the problem involves getting on the business knowledge side and
    looking at all the valuable sources of information that could influence the model.
    Once identified, the following task will generate an organized and structured
    set of values, which will be the input to our model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 理解问题需要从业务知识方面入手，审视所有可能影响模型的有价值的信息来源。一旦确定，接下来的任务将生成一组有组织和结构的值，这些值将成为我们模型的输入。
- en: Let's proceed to see an example of an initial problem definition, and the thought
    process of the initial analysis.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个初始问题定义的例子，以及初始分析的思想过程。
- en: Let's say firm A is a retail chain that wants to be able to predict a certain
    product's demand on certain dates. This could be a challenging task because it
    involves human behavior, which has some non-deterministic components.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 假设公司A是一家零售连锁店，希望能够预测特定日期某种产品的需求。这可能是一项具有挑战性的任务，因为它涉及到人类行为，其中包含一些非确定性因素。
- en: What kind of data input would be needed to build such a model? Of course, we
    would want the transaction listings for that kind of item. But what if the item
    is a commodity? If the item depends on the price of soybean or flour, the current
    and past harvest quantities could enrich the model. If the product is a medium-class
    item, current inflation and salary changes could also correlate with the current
    earnings.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 建立这样的模型需要什么样的数据输入？当然，我们希望得到该类商品的交易清单。但如果商品是商品呢？如果商品依赖于大豆或面粉的价格，当前和过去的收获量可以丰富模型。如果产品是中档商品，当前的通货膨胀和工资变化也可能与当前的收益相关。
- en: Understanding the problem involves some business knowledge and looking to gather
    all the valuable sources of information that could influence the model. In some
    sense, it is more of an art form, and this doesn't change its importance a little
    bit.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 理解问题需要一些业务知识，并寻找所有可能影响模型的有价值的信息来源。在某种程度上，这更像是一种艺术形式，但这并没有减少它的重要性。
- en: Let's then assume that the basics of the problem have been analyzed, and the
    behavior and characteristics of the incoming data and desired output are clearer.
    The following task will generate an organized and structured set of values that
    will be the input to our model. This group of data, after a process of cleaning
    and adapting, will be called our dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经分析了问题的基本要素，并且对输入数据和期望输出的行为和特征有了更清晰的了解。接下来的任务将生成一组有组织和结构化的值，这些值将成为我们模型的输入。经过清理和调整后，这组数据将被称为我们的数据集。
- en: Dataset definition and retrieval
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集定义和检索
- en: Once we have identified the data sources, the next task is to gather all the
    tuples or records as a homogeneous set. The format can be a tabular arrangement,
    a series of real values (such as audio or weather variables), and N-dimensional
    matrices (a set of images or cloud points), among other types.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了数据源，下一个任务就是收集所有元组或记录作为一个同质集合。格式可以是表格排列，一系列实值（如音频或天气变量），以及N维矩阵（一组图像或云点）等。
- en: The ETL process
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ETL过程
- en: The previous stages in the big data processing field evolved over several decades
    under the name of data mining, and then adopted the popular name of **big data**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据处理领域的前几个阶段在几十年的时间里以数据挖掘的名义发展，然后采用了流行的名称**大数据**。
- en: One of the best outcomes of these disciplines is the specification of the **Extraction**,
    **Transform**, **Load** (**ETL**) process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些学科中最好的成果之一是**提取**、**转换**、**加载**（**ETL**）过程的规范。
- en: This process starts with a mix of many data sources from business systems, then
    moves to a system that transforms the data into a readable state, and then finishes
    by generating a data mart with very structured and documented data types.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程从来自商业系统的多个数据源混合开始，然后过渡到一个将数据转换成可读状态的系统，最后通过生成具有非常结构化和文档化的数据类型的数据库结束。
- en: For the sake of applying this concept, we will mix the elements of this process
    with the final outcome of a structured dataset, which includes in its final form
    an additional label column (in the case of supervised learning problems).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应用这个概念，我们将这个过程的各种元素与结构化数据集的最终结果混合，其最终形式包括一个额外的标签列（在监督学习问题的情况下）。
- en: 'This process is depicted in the following diagram:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程在以下图中表示：
- en: '![](img/69cc866b-1119-49a8-b79c-930ee2bc7247.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/69cc866b-1119-49a8-b79c-930ee2bc7247.png)'
- en: Depiction of the ETL process, from raw data to a useful dataset
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从原始数据到有用数据集的ETL过程描述
- en: The diagram illustrates the first stages of the data pipeline, starting with
    all the organization's data, whether it is commercial transactions, IoT device
    raw values, or other valuable data sources' information elements, which are commonly
    in very different types and compositions. The ETL process is in charge of gathering
    the raw information from them using different software filters, applying the necessary
    transforms to arrange the data in a useful manner, and finally, presenting the
    data in tabular format (we can think of this as a single database table with a
    last feature or result column, or a big CSV file with consolidated data). The
    final result can be conveniently used by the following processes without practically
    thinking of the many quirks of data formatting, because they have been standardized
    into a very clear table structure.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图表说明了数据管道的第一阶段，从整个组织的所有数据开始，无论是商业交易、物联网设备原始值还是其他有价值的数据源的信息元素，这些元素通常具有非常不同类型和组成。ETL过程负责使用不同的软件过滤器从它们中收集原始信息，应用必要的转换以以有用的方式安排数据，最后以表格格式呈现数据（我们可以将其视为具有最后一个特征或结果列的单个数据库表，或者是一个包含合并数据的巨大CSV文件）。最终结果可以方便地被后续过程使用，而无需实际考虑数据格式的许多怪癖，因为它们已经被标准化为非常清晰的表格结构。
- en: Loading datasets and doing exploratory analysis with SciPy and pandas
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SciPy和pandas加载数据集并进行探索性分析
- en: In order to get a practical overview of some types of dataset formats, we will
    use the previously presented Python libraries (SciPy and pandas) for this example, given
    their almost universal use.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得一些数据集格式类型的实际概述，我们将使用之前介绍的Python库（SciPy和pandas）来演示这个例子，因为它们几乎被普遍使用。
- en: Let's begin by importing and performing a simple statistical analysis of several
    dataset input formats.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从导入并执行几个数据集输入格式的简单统计分析开始。
- en: The sample data files will be in the data directory inside each chapter's code
    directory.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 样本数据文件将位于每个章节代码目录中的data目录内。
- en: Working interactively with IPython
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用IPython进行交互式工作
- en: In this section, we will introduce **Python interactive console**, or **IPython**,
    a command-line shell that allows us to explore concepts and methods in an interactive
    way.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍**Python交互式控制台**，或**IPython**，这是一个命令行外壳，允许我们以交互式的方式探索概念和方法。
- en: 'To run IPython, you call it from the command line:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行IPython，你可以在命令行中调用它：
- en: '![](img/68caabb5-7103-4b92-a604-9deb5c1b1dc4.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/68caabb5-7103-4b92-a604-9deb5c1b1dc4.png)'
- en: Here we see IPython executing, and then the initial quick help. The most interesting
    part is the last line - it will allow you to import libraries and execute commands and
    will show the resulting objects. An additional and convenient feature of IPython
    is that you can redefine variables on the fly to see how the results differ with
    different inputs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到IPython正在执行，然后是初始的快速帮助。最有趣的部分是最后一行——它将允许你导入库并执行命令，并显示结果对象。IPython的一个额外且方便的特性是，你可以即时重新定义变量以查看不同输入下的结果差异。
- en: In the current examples, we are using the standard Python version for the most
    supported Linux distribution at the time of writing (Ubuntu 16.04). The examples
    should be equivalent for Python 3.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前示例中，我们使用的是撰写时的标准Python版本，这是当时最支持的Linux发行版（Ubuntu 16.04）。这些示例对于Python 3应该是等效的。
- en: 'First of all, let''s import pandas and load a sample `.csv` file (a very common
    format with one row per line, and registers). It contains a very famous dataset
    for classification problems with the dimensions of the attributes of 150 instances
    of iris plants, with a numerical column indicating the class (1, 2, or 3):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入pandas并加载一个样本`.csv`文件（一种非常常见的格式，每行一个记录）。它包含一个非常著名的用于分类问题的数据集，包含150个鸢尾花实例的属性维度，以及一个表示类别的数值列（1、2或3）：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this line, we import pandas in the usual way, making its method available
    for use with the `import` statement. The `as` modifier allows us to use a succinct
    name for all objects and methods in the library:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一行中，我们以通常的方式导入pandas，使其方法可以通过`import`语句使用。`as`修饰符允许我们使用简短的名字来引用库中的所有对象和方法：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this line, we use the `read_csv` method, allowing pandas to guess the possible
    item separator for the `.csv` file, and storing it in a `dataframe` object.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一行中，我们使用`read_csv`方法，允许pandas猜测`.csv`文件的可能的项分隔符，并将其存储在`dataframe`对象中。
- en: 'Let''s perform some simple exploration of the dataset:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对数据集进行一些简单的探索：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We are now able to see the column names of the dataset and explore the first
    *n* instances of it. Looking at the first registers, you can see the varying measures
    for the `setosa` iris class.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们能够看到数据集的列名并探索其前*n*个实例。查看前几个记录，您可以看到`setosa`鸢尾花类的不同度量。
- en: 'Now, let''s access a particular subset of columns and display the first three
    elements:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们访问特定列的子集并显示前三个元素：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Pandas includes many related methods for importing tabulated data formats, such
    as HDF5 (`read_hdf`), JSON (`read_json`), and Excel (`read_excel`). For a complete
    list of formats, visit [http://pandas.pydata.org/pandas-docs/stable/io.html](http://pandas.pydata.org/pandas-docs/stable/io.html)[.](http://pandas.pydata.org/pandas-docs/stable/io.html)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas包括许多用于导入表格数据格式的相关方法，例如HDF5（`read_hdf`）、JSON（`read_json`）和Excel（`read_excel`）。有关完整格式的列表，请访问[http://pandas.pydata.org/pandas-docs/stable/io.html](http://pandas.pydata.org/pandas-docs/stable/io.html)[.](http://pandas.pydata.org/pandas-docs/stable/io.html)
- en: 'In addition to these simple exploration methods, we will now use pandas to
    get all the descriptive statistics concepts we''ve seen in order to characterize
    the distribution of the `Sepal.Length` column:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些简单的探索方法之外，我们现在将使用pandas获取我们已看到的所有描述性统计概念，以便表征`Sepal.Length`列的分布：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And here are the main metrics of this distribution:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这个分布的主要指标：
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we will graphically evaluate the accuracy of these metrics by looking at
    the histogram of this distribution, this time using the built-in `plot.hist` method:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过查看该分布的直方图来图形化评估这些指标的准确性，这次使用内置的`plot.hist`方法：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](img/8a004d2f-7e5c-456d-bd00-e237fbd9a10d.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8a004d2f-7e5c-456d-bd00-e237fbd9a10d.png)'
- en: Histogram of the Iris Sepal Length
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 鸢尾花萼长度的直方图
- en: As the metrics show, the distribution is right skewed, because the skewness
    is positive, and it is of the plainly distributed type (has a spread much greater
    than 1), as the kurtosis metrics indicate.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如指标所示，分布是右偏斜的，因为偏度是正的，并且它是明显分布类型（具有比1大得多的分布范围），正如峰度指标所指示的。
- en: Working on 2D data
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理2D数据
- en: Let's stop here for tabular data, and go for 2D data structures. As images are
    the most commonly used type of data in popular machine learning problems, we will
    show you some useful methods included in the SciPy stack.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们停止表格数据的讨论，转向2D数据结构。由于图像是流行机器学习问题中最常用的数据类型，我们将向您展示SciPy堆栈中包含的一些有用方法。
- en: 'The following code is optimized to run on the Jupyter notebook with inline
    graphics. You will find the source code in the source file, `Dataset_IO.pynb`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码已优化，可在带有内联图形的Jupyter笔记本上运行。您可以在源文件`Dataset_IO.pynb`中找到源代码：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Importing a single image basically consists of importing the corresponding
    modules, using the `imread` method to read the indicated image into a matrix,
    and showing it using matplotlib. The `%` starting line corresponds to a parameter
    modification and indicates that the following `matplotlib` graphics should be
    shown inline on the notebook, with the following results (the axes correspond
    to pixel numbers):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 导入单个图像基本上包括导入相应的模块，使用`imread`方法将指定的图像读入矩阵，并使用matplotlib显示。以`%`开始的行对应于参数修改，表示以下`matplotlib`图形应在笔记本中内联显示，以下为结果（轴对应于像素数）：
- en: '![](img/860f0d8c-37b9-4c19-9172-aa151c1fe3b8.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/860f0d8c-37b9-4c19-9172-aa151c1fe3b8.png)'
- en: Initial RGB image loaded
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 初始RGB图像已加载
- en: 'The testing variable will contain a height * width * channel number array,
    with all the red, green, and blue values for each image pixel. Let''s get this
    information:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 测试变量将包含一个高度*宽度*通道数数组，包含每个图像像素的所有红色、绿色和蓝色值。让我们获取这些信息：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The interpreter will display the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 解释器将显示以下内容：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We could also try to separate the channels and represent them separately, with
    red, green, and blue scales, to get an idea of the color patterns in the image:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试将通道分离并分别用红色、绿色和蓝色尺度表示，以了解图像中的颜色模式：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the previous example, we create three subplots indicating the structure and
    position with a three-digit code. The first indicates the row number, the second
    indicates the column number, and the last, the plot position on that structure.
    The `cmap` parameter indicates the colormap assigned to each graphic.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们使用三位代码创建三个子图，以指示结构和位置。第一个表示行号，第二个表示列号，最后一个表示在该结构上的绘图位置。`cmap`参数表示分配给每个图形的颜色映射。
- en: 'The output will be as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![](img/f0630ea6-bf26-47b6-b7a0-cad85fc6193e.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f0630ea6-bf26-47b6-b7a0-cad85fc6193e.png)'
- en: Depiction of the separated channels of the sample image.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 样本图像分离通道的描述。
- en: Note that red and green channels share a similar pattern, while the blue tones
    are predominant in this bird figure. This channel separation could be an extremely
    rudimentary preliminary way to detect this kind of bird in its habitat.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，红色和绿色通道具有相似的图案，而蓝色调在这只鸟的图像中占主导地位。这种通道分离可能是检测这种鸟类在其栖息地中的极其基础的初步方法。
- en: This section is a simplified introduction to the different methods of loading
    datasets. In the following chapters, we will see different advanced ways to get
    the datasets, including  loading and training the different batches of sample
    sets.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本节是对加载数据集的不同方法的简化介绍。在接下来的章节中，我们将看到获取数据集的不同高级方法，包括加载和训练不同批次的样本集。
- en: Feature engineering
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程。
- en: Feature engineering is in some ways one of the most underrated parts of the
    machine learning process, even though it is considered the cornerstone of the
    learning process by many prominent figures of the community.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程在某种程度上是机器学习过程中最被低估的部分之一，尽管许多社区知名人士认为它是学习过程的基础。
- en: What's the purpose of this process? In short, it takes the raw data from databases,
    sensors, archives, and so on, and transforms it in a way that makes it easy for
    the model to generalize. This discipline takes criteria from many sources, including
    common sense. It's indeed more like an art than a rigid science. It is a manual
    process, even when some parts of it can be automatized via a group of techniques
    grouped in the feature extraction field.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的目的是什么？简而言之，它从数据库、传感器、档案等来源提取原始数据，并以一种使模型易于泛化的方式对其进行转换。这个学科从许多来源获取标准，包括常识。这确实更像是一门艺术，而不是一门僵化的科学。它是一个手动过程，即使其中的一些部分可以通过特征提取领域的某些技术实现自动化。
- en: As part of this process we also have many powerful mathematical tools and dimensionality
    reduction techniques, such as **Principal Component Analysis** (**PCA**) and **Autoencoders**,
    that allow data scientists to skip features that don't enrich the representation
    of the data in useful ways.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这个过程的一部分，我们还有许多强大的数学工具和降维技术，如**主成分分析**（**PCA**）和**自编码器**，这些工具允许数据科学家跳过那些不能以有用方式丰富数据表示的特征。
- en: Imputation of missing data
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失数据的插补。
- en: When dealing with not-so-perfect or incomplete datasets, a missing register
    may not add value to the model in itself, but all the other elements of the row
    could be useful to the model. This is especially true when the model has a high
    percentage of incomplete values, so no row can be discarded.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理不太完美或不完整的数据集时，缺失的记录本身可能不会为模型增加价值，但行中的其他元素可能对模型有用。这在模型有很高比例的不完整值时尤其如此，因此不能丢弃任何行。
- en: The main question in this process is *"how do you interpret a missing value?"*
    There are many ways, and they usually depend on the problem itself.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，主要问题是“你如何解释缺失值？”有很多方法，通常取决于问题本身。
- en: A very naive approach could be set the value to zero, supposing that the mean
    of the data distribution is 0\. An improved step could be to relate the missing
    data with the surrounding content, assigning the average of the whole column,
    or an interval of *n* elements of the same columns. Another option is to use the
    column's median or most frequent value.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一种非常简单的方法可能是将值设为零，假设数据分布的平均值为0。一个改进的步骤是将缺失数据与周围内容相关联，分配整个列的平均值，或者相同列的*n*个元素的平均值。另一个选择是使用列的中位数或最频繁的值。
- en: Additionally, there are more advanced techniques, such as robust methods and
    even k-nearest neighbors, that we won't cover in this book.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些更高级的技术，如鲁棒方法甚至k-最近邻，我们在这本书中不会涉及。
- en: One hot encoding
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单热编码。
- en: Numerical or categorical information can easily be normally represented by integers,
    one for each option or discrete result. But there are situations where `bins`
    indicating the current option are preferred. This form of data representation
    is called **one hot encoding**. This encoding simply transforms a certain input
    into a binary array containing only zeros, except for the value indicated by the
    value of a variable, which will be one.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 数值或分类信息可以很容易地用整数表示，每个选项或离散结果一个。但在某些情况下，`bins`表示当前选项更受欢迎。这种数据表示形式称为**单热编码**。这种编码简单地将某个输入转换为一个只包含零的二元数组，除了由变量的值指示的值，该值将为1。
- en: 'In the simple case of an integer, this will be the representation of the list
    [1, 3, 2, 4] in one hot encoding:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单的整数情况下，这将是列表[1, 3, 2, 4]在单热编码中的表示：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s perform a simple implementation of a one hot integer encoder for integer
    arrays, in order to better understand the concept:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现一个整数数组单热编码器的简单示例，以便更好地理解这个概念：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, we first define the `get_one_hot` function, which takes an
    array as input and returns an array.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们首先定义`get_one_hot`函数，它接受一个数组作为输入并返回一个数组。
- en: What we do is take the elements of the arrays one by one, and for each element
    in it, we generate a zero array with length equal to the maximum value of the
    array, in order to have space for all possible values. Then we insert `1` on the
    index position indicated by the current value (we subtract `1` because we go from
    1-based indexes to 0-based indexes).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做的是逐个取数组的元素，对于数组中的每个元素，我们生成一个长度等于数组最大值的零数组，以便为所有可能的值留出空间。然后我们在由当前值指示的索引位置插入`1`（我们减去`1`是因为我们从基于1的索引转换为基于0的索引）。
- en: 'Let''s try the function we just wrote:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试我们刚刚编写的函数：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Dataset preprocessing
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集预处理
- en: When we first dive into data science, a common mistake is expecting all the
    data to be very polished and with good characteristics from the very beginning.
    Alas, that is not the case for a very considerable percentage of cases, for many
    reasons such as null data, sensor errors that cause outliers and NAN, faulty registers,
    instrument-induced bias, and all kinds of defects that lead to poor model fitting
    and that must be eradicated.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次涉足数据科学时，一个常见的错误是期望所有数据从一开始就非常精致，具有良好的特征。唉，在许多情况下，这并不是事实，原因有很多，比如空数据、传感器错误导致异常值和NAN、故障寄存器、仪器引入的偏差以及所有导致模型拟合不良并必须根除的各种缺陷。
- en: 'The two key processes in this stage are data normalization and feature scaling. This
    process consists of applying simple transformations called **affine** that map
    the current unbalanced data into a more manageable shape, maintaining its integrity
    but providing better stochastic properties and improving the future applied model.
    The common goal of the standardization techniques is to bring the data distribution
    closer to a normal distribution, with the following techniques:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段两个关键的过程是数据归一化和特征缩放。这个过程包括应用简单的变换称为**仿射**，它将当前不平衡的数据映射到一个更易于管理的形状，保持其完整性但提供更好的随机属性，并改善未来应用的模型。标准化技术的共同目标是使数据分布更接近正态分布，以下技术：
- en: Normalization and feature scaling
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归一化和特征缩放
- en: One very important step in dataset preprocessing is normalization and feature
    scaling. Data normalization allows our optimization techniques, specially the
    iterative ones, to converge better, and makes the data more manageable.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集预处理中的一个非常重要的步骤是归一化和特征缩放。数据归一化允许我们的优化技术，特别是迭代技术，更好地收敛，并使数据更易于管理。
- en: Normalization or standardization
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归一化或标准化
- en: This technique aims to give the dataset the properties of a normal distribution,
    that is, a mean of 0 and a standard deviation of 1.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术旨在使数据集具有正态分布的性质，即均值为0，标准差为1。
- en: 'The way to obtain these properties is by calculating the so-called *z* scores,
    based on the dataset samples, with the following formula:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 获得这些性质的方法是计算所谓的*Z*分数，基于数据集样本，以下公式：
- en: '![](img/72fb7b7b-e99f-4fdc-98bb-f6c65f00ab3e.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/72fb7b7b-e99f-4fdc-98bb-f6c65f00ab3e.png)'
- en: 'Let''s visualize and practice this new concept with the help of scikit-learn,
    reading a file from the `MPG` dataset, which contains city-cycle fuel consumption
    in miles per gallon, based on the following features: `mpg`, `cylinders`, `displacement`, 
    `horsepower`, `weight`, `acceleration`, `model year`, `origin`, and `car name`.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们借助scikit-learn可视化并练习这个新概念，读取`MPG`数据集的一个文件，该数据集包含每加仑英里数（miles per gallon）的城市循环燃油消耗，基于以下特征：`mpg`、`cylinders`、`displacement`、`horsepower`、`weight`、`acceleration`、`model
    year`、`origin`和`car name`。
- en: '[PRE14]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following picture allows us to compare the non normalized and normalized
    data representations:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图片使我们能够比较非归一化和归一化的数据表示：
- en: '![](img/eb067f14-b133-4671-8471-8c49d0dd910c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eb067f14-b133-4671-8471-8c49d0dd910c.png)'
- en: Depiction of the original dataset, and its normalized counterpart.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集的描述和其归一化对应物的描述。
- en: It's very important to have an account of the denormalizing of the resulting
    data at the time of evaluation so that you do not lose the representative of the
    data, especially if the model is applied to regression, when the regressed data
    won't be useful if not scaled.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估时对结果数据进行去规范化非常重要，这样你才不会失去数据的代表性，尤其是如果模型应用于回归时，未缩放的数据将不再有用。
- en: Model definition
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型定义
- en: If we wanted to summarize the machine learning process using just one word,
    it would certainly be models. This is because what we build with machine learning
    are abstractions or models representing and simplifying reality, allowing us to
    solve real-life problems based on a model that we have trained on.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想用一个词来总结机器学习过程，那一定是模型。这是因为我们用机器学习构建的是抽象或模型，它们代表并简化现实，使我们能够根据我们在其上训练的模型解决现实生活中的问题。
- en: The task of choosing which model to use is becoming increasingly difficult,
    given the increasing number of models appearing almost every day, but you can
    make general approximations by grouping methods by the type of task you want to
    perform and also the type of input data, so that the problem is simplified to
    a smaller set of options.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 随着几乎每天都有新模型出现，选择使用哪个模型的任务变得越来越困难，但你可以通过按你想要执行的任务类型和输入数据的类型对方法进行分组，从而将问题简化为更小的一组选项。
- en: Asking ourselves the right questions
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提出正确的问题
- en: 'At the risk of generalizing too much, let''s try to summarize a sample decision
    problem for a model:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有过度概括的风险，让我们尝试总结一个用于模型的示例决策问题：
- en: Are we trying to characterize data by simply grouping information based on its
    characteristics, without any or a few previous hints? This is the domain of clustering
    techniques.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否试图通过仅根据其特征对信息进行分组来表征数据，而不需要任何或仅有少量先前的提示？这是聚类技术的领域。
- en: 'The first and most basic question: are we trying to predict the instant outcome
    of a variable, or to tag or classify data into groups? If the former, we are tackling
    a regression problem. If the latter, this is the realm of classification problems.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个也是最基本的问题：我们是在尝试预测变量的即时结果，还是将数据标记或分类到不同的组中？如果是前者，我们正在解决回归问题。如果是后者，这属于分类问题的领域。
- en: 'Having the former questions resolved, and opting for any of the options of
    point 2, we should ask ourselves: is the data sequential, or rather, should we
    take the sequence in account? Recurrent neural networks should be one of the first
    options.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解决前面的问题并选择第2点中的任何选项后，我们应该问自己：数据是否是序列的，或者我们是否应该考虑序列？循环神经网络应该是首选之一。
- en: 'Continuing with non-clustering techniques: is the data or pattern to discover
    spatially located? Convolutional neural networks are a common starting point for
    this kind of problem.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续探讨非聚类技术：我们要发现的数据或模式是否在空间上有位置？卷积神经网络是这类问题的一个常见起点。
- en: In the most common cases (data without a particular arrangement), if the function
    can be represented by a single univariate or multivariate function, we can apply
    linear, polynomial, or logistic regression, and if we want to upgrade the model,
    a multilayer neural network will provide support for more complex non-linear solutions.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在最常见的情况下（没有特定排列的数据），如果函数可以用一个单变量或多变量函数表示，我们可以应用线性、多项式或逻辑回归，如果我们想提升模型，多层神经网络将提供更复杂非线性解决方案的支持。
- en: How many dimensions and variables are we working on? Do we just want to extract
    the most useful features (and thus data dimensions), excluding the less interesting
    ones? This is the realm of dimensionality reduction techniques.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在处理多少维度和变量？我们只是想提取最有用的特征（以及数据维度），排除不那么有趣的那些吗？这是降维技术的领域。
- en: Do we want to learn a set of strategies with a finite set of steps aiming to
    reach a goal? This belongs to the field of reinforcement learning. If none of
    these classical methods are fit for our research, a very high number of niche
    techniques appear and should be subject to additional analysis.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否想要学习一组具有有限步骤的策略，以实现目标？这属于强化学习的领域。如果这些经典方法都不适合我们的研究，那么会出现大量利基技术，应该进行额外的分析。
- en: In the following chapters, you will find additional information about how to
    base your decision on stronger criteria, and finally apply a model to your data.
    Also, if you see your answers don't relate well with the simple criteria explained
    in this section, you can check *Chapter 8*, *Recent Models and Developments*,
    for more advanced models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将找到关于如何根据更严格的准则做出决策的更多信息，并最终将模型应用于你的数据。此外，如果你发现你的答案与这一节中解释的简单准则关系不大，你可以查看*第8章*，*最近模型和发展*，以了解更高级的模型。
- en: Loss function definition
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数定义
- en: This machine learning process step is also very important because it provides
    a distinctive measure of the quality of your model, and if wrongly chosen, it
    could either ruin the accuracy of the model or its efficiency in the speed of
    convergence.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个机器学习过程步骤也非常重要，因为它提供了衡量你模型质量的一个独特指标，如果选择不当，可能会破坏模型的准确性或其收敛速度的效率。
- en: Expressed in a simple way, the loss function is a function that measures the
    distance from the model's estimated value to the real expected value.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，损失函数是一个衡量模型估计值与真实期望值之间距离的函数。
- en: An important fact that we have to take into account is that the objective of
    almost all of the models is to minimize the error function, and for this, we need
    it to be differentiable, and the derivative of the error function should be as
    simple as possible.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须考虑的一个重要事实是，几乎所有模型的目的是最小化误差函数，为此，我们需要它可导，并且误差函数的导数应该尽可能简单。
- en: Another fact is that when the model gets increasingly complex, the derivative
    of the error will also get more complex, so we will need to approximate solutions
    for the derivatives with iterative methods, one of them being the well-known gradient
    descent.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个事实是，当模型变得越来越复杂时，误差的导数也会变得更加复杂，因此我们需要使用迭代方法来近似导数的解，其中之一就是众所周知的梯度下降法。
- en: Model fitting and evaluation
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型拟合和评估
- en: In this part of the machine learning process, we have the model and data ready,
    and we proceed to train and validate our model.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个机器学习过程的这部分，我们已经准备好了模型和数据，然后我们继续训练和验证我们的模型。
- en: Dataset partitioning
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集划分
- en: 'At the time of training the models, we usually partition all the provided data
    into three sets: the training set, which will actually be used to adjust the parameters
    of the models; the validation set, which will be used to compare alternative models
    applied to that data (it can be ignored if we have just one model and architecture
    in mind); and the test set, which will be used to measure the accuracy of the
    chosen model. The proportions of these partitions are normally 70/20/10.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，我们通常将提供的数据分成三组：训练集，它实际上将被用来调整模型的参数；验证集，它将被用来比较应用于该数据的替代模型（如果我们只有一个模型和架构在心中，则可以忽略）；以及测试集，它将被用来衡量所选模型的准确性。这些划分的比例通常是70/20/10。
- en: Common training terms –  iteration, batch, and epoch
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的训练术语 – 迭代、批次和epoch
- en: 'When training the model, there are some common terms that indicate the different
    parts of the iterative optimization:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，有一些常见的术语表示迭代优化的不同部分：
- en: An **iteration **defines one instance of calculating the error gradient and
    adjusting the model parameters. When the data is fed into groups of samples, each
    one of these groups is called a **batch**.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代**定义了一次计算误差梯度和调整模型参数的实例。当数据被分成样本组时，每个这样的组被称为**批次**。'
- en: Batches can include the whole dataset (traditional batching), or include just
    a tiny subset until the whole dataset is fed forward, called mini-batching. The
    number of samples per batch is called the **batch size**.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批次可以包括整个数据集（传统批次），或者只包括一个非常小的子集，直到整个数据集被前馈，这被称为小批量。每个批次中的样本数量称为**批次大小**。
- en: Each pass of the whole dataset is called an **epoch**.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个数据集的每次遍历称为一个**epoch**。
- en: Types of training – online and batch processing
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练类型 – 在线处理和批量处理
- en: The training process provides many ways of iterating over the datasets and adjusting
    the parameters of the models according to the input data and error minimization
    results.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程提供了许多遍历数据集和根据输入数据和误差最小化结果调整模型参数的方法。
- en: Of course, the dataset can and will be evaluated many times and in a variety
    of ways during the training phase.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在训练阶段，数据集将被多次以多种方式评估。
- en: Parameter initialization
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参数初始化
- en: In order to assure a good fitting start, the model weights have to be initialized
    to the most effective values. Neural networks, which normally have a *tanh* activation
    function, are mainly sensitive to the range [-1,1], or [0,1]; for this reason,
    it's important to have the data normalized, and the parameters should also be
    within that range.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保良好的拟合开始，模型权重必须初始化为最有效的值。通常具有*tanh*激活函数的神经网络对范围[-1,1]或[0,1]非常敏感；因此，对数据进行归一化以及参数也应处于该范围内非常重要。
- en: The model parameters should have useful initial values for the model to converge.
    One important decision at the start of training is the initialization values for
    the model parameters (commonly called **weights**). A canonical initial rule is
    not initializing variables at 0 because it prevents the models from optimizing,
    as they do not have a suitable function slope multiplier to adjust. A common sensible
    standard is to use a normal random distribution for all the values.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数应该有有用的初始值，以便模型收敛。训练开始时的重要决策之一是模型参数的初始化值（通常称为**权重**）。一个经典的初始规则不是将变量初始化为0，因为这会阻止模型优化，因为它们没有合适的函数斜率乘数来调整。一个常见的合理标准是使用正态随机分布来为所有值。
- en: 'Using NumPy, you would normally initialize a coefficient vector with the following
    code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy，你通常会使用以下代码初始化一个系数向量：
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: One particular source of problems at this stage is setting all of the model's
    parameters to zero. As many optimization techniques normally multiply the weights
    by a determinate coefficient to the approximate minimum, multiplying by zero will
    prevent any change in the model, excepting the bias terms.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，一个特定的问题来源是将模型的所有参数都设置为0。因为许多优化技术通常通过乘以一个确定的系数来近似最小值，乘以0将阻止模型发生任何变化，除了偏差项。
- en: Model implementation and results interpretation
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型实现和结果解释
- en: No model is practical if it can't be used outside the training and test sets.
    This is when the model is deployed into production.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型不能在训练和测试集之外使用，那么它就不实用。这就是模型部署到生产中的时候。
- en: In this stage, we normally load all the model's operation and trained weights,
    wait for new unknown data, and when it arrives, we feed it through all the chained
    functions of the model, informing the outcomes of the output layer or operation
    via a web service, printing to standard output, and so on.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们通常会加载所有模型的操作和训练好的权重，等待新的未知数据，当它到达时，我们通过模型的全部链式函数将其输入，通过Web服务通知输出层或操作的输出结果，打印到标准输出，等等。
- en: Then, we will have a final task - to interpret the results of the model in the
    real world to constantly check whether it works in the current conditions. In
    the case of generative models, the suitability of the predictions is easier to
    understand because the goal is normally the representation of a previously known
    entity.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将有一个最终任务——在现实世界中解释模型的输出结果，以不断检查它是否在当前条件下工作。在生成模型的情况下，预测的适用性更容易理解，因为目标通常是表示一个先前已知的实体。
- en: Regression metrics
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归指标
- en: For regression metrics, a number of indicators are calculated to give a succinct
    idea of the fitness of the regressed model. Here is a list of the main metrics.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归指标，计算了多个指标，以给出回归模型拟合度的简明概念。以下是主要指标列表。
- en: Mean absolute error
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方绝对误差
- en: The `mean_absolute_error` function computes mean absolute error, a risk metric
    corresponding to the expected value of the absolute error loss, or *l1-norm* loss.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`mean_absolute_error`函数计算平均绝对误差，这是一个与绝对误差损失期望值相对应的风险指标，或称为*l1-norm*损失。'
- en: 'If *ŷ[i]* is the predicted value of the *i*th sample, and *y[i]* is the corresponding
    true value, then the **mean absolute error** (**MAE**) estimated over *n* samples
    is defined as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*ŷ[i]*是第*i*个样本的预测值，而*y[i]*是对应的真实值，那么在*n*个样本上估计的**平均绝对误差**（**MAE**）定义如下：
- en: '![](img/addea822-7795-4645-8773-df4c2196e5b0.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/addea822-7795-4645-8773-df4c2196e5b0.png)'
- en: Median absolute error
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 中位数绝对误差
- en: The median absolute error is particularly interesting because it is robust to
    outliers. The loss is calculated by taking the median of all absolute differences
    between the target and the prediction.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数绝对误差特别有趣，因为它对异常值具有鲁棒性。损失是通过计算目标与预测之间的所有绝对差异的中位数来计算的。
- en: 'If *ŷ* is the predicted value of the *i*th sample and *y[i]* is the corresponding
    true value, then the median absolute error estimated over *n* samples is defined
    as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *ŷ* 是第 *i* 个样本的预测值，而 *y[i]* 是相应的真实值，那么在 *n* 个样本上估计的绝对误差中位数定义如下：
- en: '![](img/01cce5da-4454-43a3-88e3-30ae07e8d931.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/01cce5da-4454-43a3-88e3-30ae07e8d931.png)'
- en: Mean squared error
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差
- en: The **mean squared error** (**MSE**) is a risk metric equal to the expected
    value of the squared (quadratic) error loss.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**）是一个风险指标，等于平方（二次）误差损失的期望值。'
- en: 'If *ŷ[i]* is the predicted value of the *i*th sample and *y[i]* is the corresponding
    true value, then the MSE estimated over *n* samples is defined as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *ŷ[i]* 是第 *i* 个样本的预测值，而 *y[i]* 是相应的真实值，那么在 *n* 个样本上估计的 MSE 定义如下：
- en: '![](img/19b41214-110d-4bd7-87a0-6ca71a855c5c.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/19b41214-110d-4bd7-87a0-6ca71a855c5c.png)'
- en: Classification metrics
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类指标
- en: The task of classification implies different rules for the estimation of the
    error. The advantage we have is that the number of outputs is discrete, so it
    can be determined exactly whether a prediction has failed or not in a binary way.
    That leads us to the main indicators.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务意味着在估计误差时遵循不同的规则。我们所拥有的优势是输出的数量是离散的，因此可以以二进制方式精确地确定预测是否失败。这使我们转向主要指标。
- en: Accuracy
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确度
- en: The accuracy calculates either the fraction or the count of correct predictions
    for a model.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度计算模型正确预测的分数或计数。
- en: In multi-label classification, the function returns the subset's accuracy.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在多标签分类中，该函数返回子集的准确率。
- en: If the entire set of predicted labels for a sample strictly matches the true
    set of labels, then the subset's accuracy is *1.0*; otherwise, it is *0.0*.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个样本的所有预测标签严格匹配真实标签集，那么子集的准确率是 *1.0*；否则，它是 *0.0*。
- en: 'If *ŷ[i]* is the predicted value of the *i*th sample and *y[i]* is the corresponding
    true value, then the fraction of correct predictions over *n* samples is defined
    as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *ŷ[i]* 是第 *i* 个样本的预测值，而 *y[i]* 是相应的真实值，那么在 *n* 个样本中正确预测的比例定义如下：
- en: '![](img/d11bb0e9-44c1-4ed6-aa2e-2908f6076d06.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d11bb0e9-44c1-4ed6-aa2e-2908f6076d06.png)'
- en: Precision score, recall, and F-measure
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精确度得分、召回率和 F 度量
- en: '**Precision** score is as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**得分如下：'
- en: '![](img/d21665f9-726e-4904-bd22-7ff7a183d4ea.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d21665f9-726e-4904-bd22-7ff7a183d4ea.png)'
- en: Here, *t[p]* is the number of true positives and *f[p]* is the number of false
    positives. The precision is the ability of the classifier to not label as positive
    a sample that is negative. The best value is 1 and the worst value is *0*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*t[p]* 是真正例的数量，而 *f[p]* 是假正例的数量。精确度是分类器不将负样本标记为正样本的能力。最佳值是 1，最差值是 *0*。
- en: '**Recall** is as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**如下：'
- en: '![](img/320e3e5d-3413-4616-a921-375e4ca896cf.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/320e3e5d-3413-4616-a921-375e4ca896cf.png)'
- en: Here, *t[p]* is the number of true positives and *f[n]* is the number of false
    negatives. The recall can be described as the ability of the classifier to find
    all the positive samples. Its values range from 1 (optimum) to zero.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*t[p]* 是真正例的数量，而 *f[n]* 是假阴性数量。召回率可以描述为分类器找到所有正样本的能力。其值从 1（最佳）到 0。
- en: '**F measure** (*F[β]* and F[1] measures) can be interpreted as a special kind
    of mean (weighted harmonic mean) of the precision and recall. A  *F[β]* measure''s
    best value is 1 and its worst score is 0. With *β = 1*, *F[β]* and *F[1]* are
    equivalent, and the recall and the precision are equally important:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**F度量**（*F[β]* 和 F[1] 度量）可以解释为精确度和召回率的特殊类型的平均值（加权调和平均值）。*F[β]* 度量的最佳值是 1，其最差得分是
    0。当 *β = 1* 时，*F[β]* 和 *F[1]* 是等价的，召回率和精确度同等重要：'
- en: '![](img/ca5234a8-9e44-4d0e-a76a-230ae5b8c02b.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ca5234a8-9e44-4d0e-a76a-230ae5b8c02b.png)'
- en: Confusion matrix
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Every classification task aims to predict a label or tag for new unknown data.
    A very efficient way of showing the classification's accuracy is through a confusion
    matrix, where we show [classified sample, ground truth] pairs and a detailed view
    of how the predictions are doing.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分类任务都旨在为新未知数据预测一个标签或标记。展示分类准确率的一种非常有效的方式是通过混淆矩阵，其中我们展示了 [分类样本，真实值] 对，以及预测表现的具体视图。
- en: The expected output should be the main diagonal of the matrix with a 1.0 score;
    that is, all the expected values should match the real ones.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出应该是矩阵的主对角线，得分为 1.0；也就是说，所有预期值都应该与实际值相匹配。
- en: 'In the following code example, we will do a synthetic sample of predictions
    and real values, and generate a confusion matrix of the final data:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码示例中，我们将进行预测值和真实值的合成样本，并生成最终数据的混淆矩阵：
- en: '[PRE16]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The result will be the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是以下内容：
- en: '[PRE17]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'And the final confusion matrix graphic representation for these values will
    be as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值的最终混淆矩阵图形表示如下：
- en: '![](img/af7d43a7-d90f-4114-b495-f48a31597747.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/af7d43a7-d90f-4114-b495-f48a31597747.png)'
- en: Confusion matrix
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: In the image, we see the high accuracy value in the (*5,5*) diagonal value with
    three correct predictions, and the (*8,8*) value with two. As we can see, the
    distribution of the accuracy by value can be intuitively extracted just by analyzing
    the graph.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中，我们看到在(*5,5*)对角线上的高准确度值有三个正确预测，以及(*8,8*)值有两个。正如我们所看到的，通过分析图表可以直观地提取准确度的分布。
- en: Clustering quality measurements
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类质量测量
- en: Unsupervised learning techniques, understood as the labeling of data without
    a ground truth, makes it a bit difficult to implement significant metrics for
    the models. Nevertheless, there are a number of measures implemented for this
    kind of technique. In this section, we have a list of the most well-known ones.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习技术，理解为没有真实标签的数据标注，使得为模型实现显著的度量指标变得有些困难。尽管如此，为此类技术实现了一系列的度量。在本节中，我们列出了最著名的几种。
- en: Silhouette coefficient
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 轮廓系数
- en: The **silhouette** **coefficient** is a metric that doesn't need to know the
    labeling of the dataset. It gives an idea of the separation between clusters.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**轮廓系数**是一个不需要知道数据集标签的度量。它给出了簇之间分离的概念。'
- en: 'It is composed of two different elements:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 它由两个不同的元素组成：
- en: The mean distance between a sample and all other points in the same class (*a*)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本与其同一类中所有其他点的平均距离（*a*）
- en: The mean distance between a sample and all other points in the nearest cluster
    (*b*)
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本与其最近簇中所有其他点的平均距离（*b*）
- en: 'The formula for this coefficient *s* is defined as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 该系数*s*的公式定义如下：
- en: '![](img/fed0e65c-0325-4353-bcdb-012e59c3a141.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fed0e65c-0325-4353-bcdb-012e59c3a141.png)'
- en: The silhouette coefficient is only defined if the number of classes is at least
    two, and the coefficient for a whole sample set is the mean of the coefficient
    for all samples.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓系数仅在类别的数量至少为两个时才定义，整个样本集的系数是所有样本系数的平均值。
- en: Homogeneity, completeness, and V-measure
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纯度、完整性和V度量
- en: Homogeneity, completeness, and V-measure are three key related indicators of
    the quality of a clustering operation. In the following formulas, we will use
    *K* for the number of clusters, *C* for the number of classes, *N* for the total
    number of samples, and *a[ck]* for the number of elements of class *c* in cluster
    *k*.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 纯度、完整性和V度量是聚类操作质量的关键相关指标。在以下公式中，我们将使用*K*表示簇的数量，*C*表示类别的数量，*N*表示样本总数，*a[ck]*表示在簇*k*中类*c*的元素数量。
- en: '**Homogeneity** is a measure of the ratio of samples of a single class pertaining
    to a single cluster. The fewer different classes included in one cluster, the
    better. The lower bound should be 0.0 and the upper bound should be 1.0 (higher
    is better), and the formulation for it is expressed as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**纯度**是单个簇中属于单个类别的样本比率的度量。一个簇中包含的不同类别越少，越好。下限应为0.0，上限应为1.0（越高越好），其公式如下所示：'
- en: '![](img/631fb8c1-f23f-4fdd-90c6-9121e272c095.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/631fb8c1-f23f-4fdd-90c6-9121e272c095.png)'
- en: '**Completeness **measures the ratio of the member of a given class that is
    assigned to the same cluster:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**完整性**衡量的是分配到同一簇的给定类成员的比率：'
- en: '![](img/7398ef4a-b2d6-4845-a62f-bc7f07b530d8.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7398ef4a-b2d6-4845-a62f-bc7f07b530d8.png)'
- en: '**V-measure** is the harmonic mean of homogeneity and completeness, expressed
    by the following formula:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**V度量**是纯度和完整性的调和平均值，其公式如下：'
- en: '![](img/7598e979-d41d-4e76-ae8a-61ed1fc8c857.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7598e979-d41d-4e76-ae8a-61ed1fc8c857.png)'
- en: Summary
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed all the main steps involved in a machine learning
    process. We will be, indirectly, using them throughout the book, and we hope they
    help you structure your future work too.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了机器学习过程中涉及的所有主要步骤。我们将间接地在整本书中使用它们，并希望它们能帮助您构建未来的工作。
- en: In the next chapter, we will review the programming languages and frameworks
    that we will be using to solve all our machine learning problems and become proficient
    with them before starting with the projects.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回顾我们将使用来解决所有机器学习问题并熟练掌握它们的编程语言和框架。
- en: References
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Lichman, M. (2013). UCI Machine Learning Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)).
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lichman, M. (2013). UCI机器学习仓库 ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)).
    加利福尼亚州欧文，加州大学信息与计算机科学学院。
- en: Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In *Proceedings
    on the Tenth International Conference of Machine Learning*, 236-243, University
    of Massachusetts, Amherst. Morgan Kaufmann.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quinlan, R. (1993). 结合实例学习和基于模型的学习。在第十届国际机器学习会议论文集，236-243页，麻省大学阿默斯特分校。摩根考夫曼出版社。
- en: 'Townsend, James T. *Theoretical analysis of an alphabetic confusion matrix.*
    Attention, Perception, & Psychophysics 9.1 (1971): 40-50.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Townsend, James T. *字母混淆矩阵的理论分析*。注意，感知与心理学 9.1 (1971): 40-50。'
- en: 'Peter J. Rousseeuw (1987). *Silhouettes: a Graphical Aid to the Interpretation
    and Validation of Cluster Analysis*. Computational and Applied Mathematics 20:
    53-65.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Peter J. Rousseeuw (1987). *轮廓：聚类分析的图形辅助解释和验证*。计算与应用数学 20: 53-65。'
- en: 'Kent, Allen, et al, Machine literature searching VIII. *Operational criteria
    for designing information retrieval systems.* Journal of the Association for Information
    Science and Technology 6.2 (1955): 93-101.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kent, Allen等人，机器文献检索VIII. *设计信息检索系统的操作标准*。信息科学和技术协会杂志 6.2 (1955): 93-101。'
- en: 'Rosenberg, Andrew, and Julia Hirschberg, V-Measure: *A Conditional Entropy-Based
    External Cluster Evaluation Measure*. EMNLP-CoNLL. Vol. 7\. 2007.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenberg, Andrew和Julia Hirschberg，V-Measure：*基于条件熵的外部聚类评估度量*。EMNLP-CoNLL。第7卷。2007年。
