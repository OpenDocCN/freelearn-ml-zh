- en: '*Chapter 7*: Using the Many Models Solution Accelerator'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have experienced building regression, classification, and forecasting
    models with AutoML, it's time for you to learn how to deploy and utilize those
    models in actual business scenarios. Before you tackle this, however, we will
    first introduce you to a new, very powerful solution, that is, the **Many Models
    Solution Accelerator** (**MMSA**).
  prefs: []
  type: TYPE_NORMAL
- en: The MMSA lets you build hundreds to thousands of **machine learning** (**ML**)
    models at once and easily scales to hundreds of thousands of models. It's an advanced
    technology at the cutting edge of ML. Not only can you build hundreds of thousands
    of models, but you can also use the MMSA to easily deploy them into production.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will begin by installing the accelerator and understanding
    the various use cases to which it applies. You will then run the three sections
    of the accelerator notebook-by-notebook: prepping data, training models, and forecasting
    new data.'
  prefs: []
  type: TYPE_NORMAL
- en: In each section, you will use both sample data found within the accelerator
    as well as sample data that you generate with Python code. This will give you
    examples of using the MMSA with both file and tabular datasets. Finally, you will
    go over tips and tricks to maximize performance using the accelerator and you
    will be introduced to concepts such as **hierarchical forecasting**.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have mastered using the MMSA with AutoML.
    You will be able to bring your own data into the MMSA, get it into the right shape,
    and train thousands of models. This solution is ideal for scenarios in which you
    wish to train similar models over a large number of products or stores, for example,
    building a separate forecasting model for each combination of product and store.
    Large companies all over the USA use it, and, by the end of this chapter, you
    will be able to use it too.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the many models solution accelerator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepping data for many models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training many models simultaneously
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scoring new data for many models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving your many models results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within this chapter, you will log in to your **Azure Machine Learning studio**
    (**AMLS**), open up a Jupyter notebook on a compute instance, and install the
    MMSA from its location on GitHub. You will then run all three pieces of the MMSA
    sequentially, prepping the data, training the models remotely, and forecasting
    the data. As such, you need to have an Azure account, a compute instance for writing
    Python code, and a compute cluster for remote training. The full list of requirements
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Access to the internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web browser, preferably Google Chrome or Microsoft Edge Chromium.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Microsoft Azure account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should have created an AMLS workspace.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should have created a compute instance in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should have created the compute cluster in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should understand how to navigate to the Jupyter environment from an AMLS
    compute instance, as demonstrated in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter07](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter07).'
  prefs: []
  type: TYPE_NORMAL
- en: Installing the many models solution accelerator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MMSA was built by Microsoft in 2019 to address the needs of a growing number
    of customers who wanted to train hundreds of thousands of similar ML models simultaneously.
    This is particularly important for product demand forecasting, where you are trying
    to make forecasts for many different products at many different locations.
  prefs: []
  type: TYPE_NORMAL
- en: The impetus for the accelerator is **model accuracy**. While you could train
    a single model to predict product demand across all of your product lines and
    all of your stores, you will find that training individual models for each combination
    of product and store tends to yield superior performance. This is because a multitude
    of factors are dependent on both your algorithm and your data. It can be very
    difficult for some algorithms to find meaningful patterns when you're dealing
    with hundreds of thousands of different products distributed across the globe.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the same columns can have different or even opposite relationships
    with the target column you are trying to predict. Imagine weather and product
    sales. When it snows outside, it's very likely that certain products, such as
    winter hats, gloves, or boots, will experience a spike in sales. Other products,
    such as ice cream, will very likely experience a decline in sales. While some
    algorithms can handle these opposite relationships across product lines, many
    cannot, and using the MMSA to build a separate model for each product will often
    result in better metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Other common use cases besides forecasting product demand for the MMSA include
    predictive maintenance across thousands of devices and machines on factory plant
    floors, workforce optimization models across hundreds of stores, text analytics
    use cases and legal document search models per state in the United States, and
    many other similar scenarios. Still, forecasting is the most common use case.
    Chain stores, in particular, find the MMSA attractive.
  prefs: []
  type: TYPE_NORMAL
- en: Technically speaking, the key factor in determining whether to use the MMSA
    or not is the presence of one or more columns in your data, which you can use
    to split the data into multiple files. Columns such as store, product, and region
    are prime targets to split. If no such columns exist in your data, there's no
    reason to use the MMSA.
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, if you expect that patterns in your data should be relatively stable
    across columns such as product, group, and region, you should train a single ML
    model with AutoML as you would for any other problem.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will install the MMSA on your Jupyter environment. First,
    you will create a new Jupyter notebook used only for the installation. Then, you
    will install the MMSA on your Jupyter environment. This will create a series of
    files and folders. Lastly, you will be able to confirm that the MMSA has been
    successfully installed and identify the notebooks you will use for the remainder
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new notebook in your Jupyter environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to create a new Jupyter notebook on your compute
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: First, open up your AML studio instance by navigating to [http://ml.azure.com](http://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Compute**, start up a compute instance, and open a Jupyter environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook and name it `Accelerator_Installation`. If you
    need a refresher, please review [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With your notebook created, you are now ready to install the accelerator from
    GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the MMSA from GitHub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The MMSA is a publicly available solution developed by Microsoft hosted on
    a GitHub repository. Use the following code to install the MMSA on your Jupyter
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the MMSA repo into your Jupyter notebook filesystem using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: All of the files have now been loaded into a new folder named `solution-accelerator-many-models`.
    Click the Jupyter graphic at the top of your screen to navigate to your file directory,
    as shown in *Figure 7.1*:![Figure 7.1 – Navigating to your file directory ](img/Figure_7.1_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 7.1 – Navigating to your file directory
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Open the `solution-accelerator-many-models` folder by clicking it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upon opening the folder, you will find many files and folders. The first file
    you will use in the *Prepping data for many models* section is `01_Data_Preparation.ipynb`.
    If you wish to set up a new compute cluster for the MMSA, you should first run
    `00_Setup_AML_Workspace.ipynb`. Make a note of these.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Moving on, open the `Automated_ML` folder. This folder contains two subfolders,
    called `02_AutoML_Training_Pipeline` and `03_AutoML_Forecasting_Pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open each of the AutoML pipelines. Each one contains a Jupyter notebook with
    the same name as the folder. Make a note of these.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the rest of this chapter, these will be the only three Jupyter notebooks
    you will interact with, `01_Data_Preparation.ipynb`, `02_AutoML_Training_Pipeline`,
    and `03_AutoML_Forecasting_Pipeline`. In each case, first you will run the notebook
    as is, running with a default sample dataset. Then, you will make another notebook
    and use similar code to train a different dataset. This will teach you how to
    use both file and tabular datasets with the MMSA, and how to work with your own
    data. You will begin by prepping data.
  prefs: []
  type: TYPE_NORMAL
- en: Prepping data for many models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While training thousands of ML models simultaneously sounds complicated, the
    MMSA makes it easy. The example included in the notebooks uses the `OJ Sales`
    data you used in [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081), *Building
    an AutoML Forecasting Solution*. You will prepare the data simply by opening and
    running `01_Data_Preparation.ipynb`. By reading the instructions carefully step
    by step and working through the notebook slowly, you will be able to understand
    what each section is about.
  prefs: []
  type: TYPE_NORMAL
- en: Once you're able to understand what each section is doing and you have the `OJ
    Sales` data loaded, you will be able to load the new dataset into your Jupyter
    notebook. This way, by the end of this section, you will be able to load your
    own data into Azure, modify it for the MMSA, and master the ability to use this
    powerful solution.
  prefs: []
  type: TYPE_NORMAL
- en: Prepping the sample OJ dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how the first notebook works, follow these instructions in order:'
  prefs: []
  type: TYPE_NORMAL
- en: Open `01_Data_Preparation.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `1.0` of the notebook. These cells create
    a folder called `oj_sales_data` in your file directory and download the `OJ Sales`
    data there. After running `section` `1.0`, examine the files in your new folder;
    `oj_sales_data` will be located in the same directory level as `01_Data_Preparation.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the single cell in `section` `2.0` of the notebook. This cell splits the
    data into training data and inference data based on a date. It creates two folders
    in the `oj_sales_data` folder, one called `upload_train_data`, and another called
    `upload_inference_data`. Look inside each of these folders after you run the cell.
    You should see files with names such as `Store1000_dominicks.csv`. Click one of
    the files to see what the data looks like.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `3.0` of the notebook. These cells copy the
    data from your file directory on your compute instance to a file directory on
    your datastore. This copies the file structure and you end up with the `oj_sales_data`
    folder as well as your `upload_train_data` and `upload_inference data` subfolders
    on your datastore. If you'd like to, open up your Azure storage account and try
    to locate these folders. Remember that they will be in the container beginning
    with `azureml-blobstore`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the single cell in `section` `4.0` of the notebook. This cell creates two
    file datasets, one named `oj_data_small_train` and the other called `oj_data_small_inference`.
    These are the datasets you will use in `02_AutoML_Training_Pipeline` and `03_AutoML_Forecasting_Pipeline`,
    respectively.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `5.0` of the notebook to view your data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you run the notebook as is, you will train a small number of models using
    10 files. You can set `dataset_maxfiles` to `11793` to train a much larger number
    of models in `section` `1.0` of the notebook. In this case, your datasets will
    be called `oj_data_inference` and `oj_data_train`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You now have the `OJ Sales` data prepped for the accelerator. In order to bring
    your own data into the accelerator, there are a few important caveats you need
    to follow. Most importantly, the `OJ Sales` data comes presplit based on store
    and orange juice brand. You will need to mimic this structure using your own data
    in a new Jupyter notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Prepping a pandas dataframe
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Bringing your own data into the MMSA is unclear. `OJ Sales`, after all, is
    a file dataset consisting of 11,793 files. You are much more likely to use data
    that consists of a single file or comes from a single table within a database.
    Moreover, you are most likely to read it in via pandas, the most common Python
    package. To learn how to use pandas dataframes with the MMSA, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the `ManyModelsSampleData.csv` file from the *Automated-Machine-Learning-on-Microsoft-Azure*
    GitHub repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to your Jupyter environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `solution-accelerator-many-models` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the `ManyModelsSampleData.csv` file to your Jupyter environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook and open it. Rename it `01_Data_PreparationMy-Data.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To load in all of the libraries, you will require the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should recognize `pandas`, `numpy`, `Workspace`, `Dataset`, and `Datastore`
    from [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056), *Building an AutoML
    Regression Solution*. You've also used `os` in [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081),
    *Building an AutoML Forecasting Solution.*
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: New to this script is `split_data`, which is a `datetime`, which lets you convert
    string objects into proper Python datetime objects. This is a requirement since
    `split_data` requires datetime objects to function properly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Read the `ManyModelsSampleData.csv` file into a pandas dataframe with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Setting headers to `0` will use the first row of your CSV file for column names.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a folder called `MMSA_Sample_Folder` with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'View your dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will find that this dataset has three columns: `Date`, `Store`, and `Sales`.
    It''s about as simple a forecasting dataset as you can get. There are four stores
    and each store has a time series that extends from January 1, 2020 until March
    31, 2021\. You want to forecast sales into the future.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Convert your `Date` column into a `datetime` object with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code takes your `Date` column and applies a function to it using the `datetime`
    package to convert it from a string into a `datetime` object.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Split your pandas dataframe into four separate CSV files, one for each store,
    and place each of them in the MMSA sample folder with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Understand that `x` is an individual store within your `ManyModelsSample` dataframe
    and that `y` is a pandas dataframe with only values for that store. This code
    loops through all four stores and, one by one, creates a CSV file with headers
    inside `MMSA_Sample_Folder`. Each file will be the name of the store. In this
    case, the stores are named after the cities in which they are located: New York,
    Washington DC, San Francisco, and Seattle.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The time column that you use to split your data must absolutely be a datetime
    object, not a string. Leaving your time column as a string will result in failed
    forecasting runs later on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set variables for your time column as well as the cutoff for when you are training
    and scoring data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The MMSA documentation refers to scoring data as inference data. `split_date`,
    remember that the date you specify and every date after it will be used for scoring,
    while all dates prior to it will be used for training. Your `split_date` function
    must be in the format used here.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Split the data into training and inference files with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code uses your `split_data` helper function. Within the `MMSA_Sample_Folder`,
    two new folders will be created holding four sets each of training and scoring
    files.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are prompted to log in, do so by following the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your datastore to the default datastore that comes with your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code is slightly different than the one you used in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*. In the AzureML SDK, there are often
    functions with identical uses.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Upload your training data to your default datastore with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code will write your training files to a folder called `MMSA_Sample_Folder_train`
    on your default datastore.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Upload your scoring data to your default datastore with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code will write your training files to a folder called `MMSA_Sample_Folder_inference`
    on your default datastore.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create file datasets for your training and scoring data with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The MMSA requires file datasets to work. As such, you need to register the folders
    on your default datastore as file datasets. This will register the entire folder
    and all of its contents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create variables for the names for when you register the datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using this code will ensure that you register your datasets with the names `MMSA_Sample_train`
    and `MMSA_Sample_inference`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Register your file datasets with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should now have two additional datasets in your AML studio. Check by clicking
    **Datasets** on the left-hand panel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure you save your notebook, as this code will come in very handy in the
    future when you wish to use the MMSA with your own data. You have now prepped
    both the `OJ Sales` data as well the simple sample data and saved them as separate
    training and scoring file datasets. This is step number one in using the accelerator.
    Now that you have prepped your data, it's time for you to train a lot of models.
  prefs: []
  type: TYPE_NORMAL
- en: Training many models simultaneously
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like prepping data for many models, training many models is simply a matter
    of navigating to the correct notebook and running the cells. There's no custom
    code required, and you are simply required to change a few settings.
  prefs: []
  type: TYPE_NORMAL
- en: Like prepping data, you will first run the notebook step by step to carefully
    understand how it works. Once you have that understanding, you will then create
    a new notebook with code that uses the datasets you made from the sample data.
    This will benefit you tremendously, as you will understand exactly which parts
    of the code you need to change to facilitate your own projects.
  prefs: []
  type: TYPE_NORMAL
- en: Training the sample OJ dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To train many models using the OJ data and to understand the underlying process,
    follow these instructions step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: From the `solution-accelerator-many-models` folder, click on the `Automated_ML`
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the `Automated_ML` folder, click on the `02_AutoML_Training_Pipeline` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open `02_AutoML_Training_Pipeline.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `1.0`. This sets your datastore and your workspace
    and also assigns a name to your many models experiment. Notice that this code
    also outputs a nice table listing your AMLS workspace details along with the name
    of your datastore. You can add this table to all of your code if you wish or you
    can use the templates in this book for a more direct, spartan approach to coding.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you are having trouble loading any Azure libraries, update the Azure MLSDK
    by running the Update `AzureML SDK.ipynb` notebook foundhere: https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the single cell in `section` `2.0`. This retrieves your training dataset,
    `oj_data_small_train`. Notice that the dataset gets set twice here, first as a
    typical dataset, and then as **named input**. Named input is simply an Azure artifact
    that certain ML pipelines use to work with datasets. Underlying the MMSA is a
    **parallel run ML pipeline**. This ML pipeline lets you run different types of
    jobs in parallel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The MMSA often uses **AzureML contributor packages**. These are packages that
    are under development. You may have to uncomment out cells and install the packages
    in this section depending on your version of the AzureML SDK. Any packages you
    need to install will always be in the code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `3.0`. These cells create a compute cluster
    to train all of your models, set your AutoML forecasting settings, and set your
    many models `Store` and `Brand`. If your Azure subscription isn't able to use
    the `STANDARD_D16S_V3` `STANDARD_DS3_V2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The *node count* for your parallel run settings should be set to the number
    of nodes in your compute cluster. Your *process count per node* should not exceed
    the number of cores on each node. If you're using a `Standard_DS3_v2` VM, for
    example, the process count per node should not exceed `4`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run both cells in `section` `4.0`. These cells train all of your models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the cell in `section` `6.0` to get a list of your AutoML runs and the tags
    they were registered with. This is how you keep track of all of the different
    models you have registered. The MMSA automatically generates tags for your partition
    columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Publish your many models training pipeline by uncommenting the first cell and
    running it. Do not run the second cell, as this will schedule your pipeline to
    automatically run on a cadence. Although this feature is useful in a production
    setting, it does rack up costs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within 15 to 30 minutes, you should have all 10 models trained and registered.
    Unlike normal AutoML runs, the MMSA automatically registers the best model for
    each grouping (in this case, orange juice brand and store) you train. This feature
    scales exceptionally well and some Microsoft customers are using it to train and
    retrain hundreds of thousands of models on an ongoing basis.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the run in the portal by clicking the blue link, which will take
    you to the pipeline visualization seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – The MMSA in action ](img/Figure_7.2_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – The MMSA in action
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will create a new notebook and train many models with the sample data
    you loaded in as a pandas dataframe. You will substantially simplify the code
    in the second notebook to achieve an identical solution. This will help you easily
    adapt the MMSA to your own problems in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Training your sample dataset with the MMSA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as you modified the first notebook, you need to modify the second notebook
    to use your own code. All the steps will be the same, but the code will be less
    busy and easier to read. Begin with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `solution-accelerator-many-models` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Automated_ML` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `02_AutoML_Training_Pipeline` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook and open it. Rename it `02_AutoML_Training_Pipeline-My-Data.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load in all of the familiar libraries you will need with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should be familiar with most of these packages from the *Prepping data for
    many models* section. `ComputeTarget` is used to set a compute cluster for remote
    training and was covered in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load in the new libraries you will need to train your MMSA solution with the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`AzureMLPipelineBuilder` lets you build out your many models training runs
    and is a contributor package. Make sure you use pip to install it here if you
    haven''t already using the code that is commented out in the original MMSA training
    notebook. `Pipeline` lets you build ML pipelines, which are necessary for running
    the MMSA under the hood.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, `get_training_output` is another helper function that lets you retrieve
    information about the models you trained and `logging` enables more detailed logs
    to be collected regarding your training run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are prompted to log in, do so by following the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your datastore to the default datastore that comes with your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Be careful, as the datastore variable name is different from other Jupyter notebooks.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your experiment and give it a name using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Specify your training dataset with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It doesn't matter what name you give to your named input. The important thing
    is the underlying dataset. The MMSA will find the correct dataset regardless.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your compute cluster, which will be used for remote training, with the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you created a different compute cluster for many models training, use that
    one instead.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your partition column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can have as many partition columns as necessary for your business problem.
    `OJ Sales` has two. The sample data has one.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adjust your AutoML settings as needed. Specifically, set `label_column_name`
    to `Sales`. This is the column you are trying to predict. Change the name of `debug_log`
    to separate it from the training run with `OJ Sales`. Set `time_column_name` to
    `Date`. Set `grain_column_names` to `Store`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One confusing thing about the MMSA is that you should always pass in your partition
    columns to `grain_column_names` too. For more information about these settings,
    refer to [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081), *Building an AutoML
    Forecasting Solution*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The MMSA can be used for regression and classification of AutoML problems too.
    In that case, make sure you pass in the relevant settings specific to each problem
    type.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Pass in your MMSA configurations. Make sure you adjust `node_count` and `process_count_per_node`
    to match the number of nodes on your compute cluster and the number of cores on
    a single VM, respectively, with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Submit your MMSA training run with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get additional details about your MMSA training run with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Publish your MMSA pipeline with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code will publish your pipeline so you can schedule it later at your leisure.
    Setting `continue_on_step_failure` to `False` will prevent this code from publishing
    a pipeline that errors out.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you would like, you can copy code over from the original MMSA training notebook
    to schedule your MMSA pipeline to run on a cadence. You can also copy over code
    to look at the results of the overall run; this is very good for debugging errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You have now successfully trained many models using both the `OJ Sales` data
    and a sample file read in as a pandas dataframe. Instead of modifying the MMSA
    code from scratch, you also have a simplified notebook on hand that you can easily
    use to build your own solution with the MMSA. Next, you will learn how to score
    new data with models trained using the accelerator. This will complete your introduction
    to the MMSA using AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring new data for many models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scoring new data with the MMSA is a fairly straightforward task. Once you have
    your models trained, simply navigate to the correct notebook, change your variables
    to match your training notebook, and click the run button. As there are very few
    settings to alter compared to the training notebook, it's even easier to use with
    your own code.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, like the others, first you will run the out-of-the-box scoring
    notebook with `OJ Sales`. Then, you will create a new notebook to score the sample
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring OJ sales data with the MMSA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To score `OJ Sales` data with the multiple models you''ve trained, follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From the `solution-accelerator-many-models` folder, open the `Automated_ML`
    folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the `Automated_ML` folder, open the `03_AutoML_Forecasting_Pipeline` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open `03_AutoML_Forecasting_Pipeline.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run all of the cells in `section` `1.0`. These cells set up your AMLS workspace,
    compute cluster, datastore, and experiment. Like the training notebook before
    it, the forecasting notebook is also an ML pipeline. Information regarding your
    ML pipeline runs, like your training runs, is saved in experiment artifacts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Your *training experiment* that you ran to train many models is different from
    your *inferencing experiment* that you are running now. Make sure they have different
    names.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run the single cell in `section` `2.0`. This cell calls the inferencing dataset
    you created with the data preparation notebook; this is the data you will score
    with your trained model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In `section` `3.0`, set your training `02_AutoML_Training_Pipeline.ipynb` notebook
    you ran earlier or in the **Experiments** section of AMLS. Your pipeline run ID
    is the ID for the experiment that trained all of your models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the second cell in `section` `3.0`. This cell configures the settings for
    your many models scoring pipeline. Most importantly, this is passing in your partition
    columns, your target column that you're trying to predict, and your time column,
    which determines the cadence of your predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the two cells in `section` `4.0` to score new data. This is an ML pipeline
    run and your compute cluster will take some time to spin up. Once it spins up
    and the ML pipeline starts, however, scoring your data will be very fast.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the single cell in `section` `5.0` to view your results, as shown in the
    following screenshot:![Figure 7.3 – MMSA results ](img/Figure_7.3_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 7.3 – MMSA results
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you would like to publish your ML pipeline for later use, run the first cell
    in `section` `6.0`. Avoid running the second cell, as this creates an automated
    schedule for your pipeline that can become quite costly over time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You have now completed the MMSA `OJ Sales` notebooks from start to finish. You
    have prepped data and shaped it into the right format, splitting it into many
    files. Then, you trained 10 models in parallel and used those models to score
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: It's time to do the same and score your sample dataset with a simplified notebook
    and see the output. Keep in mind that the output should not be especially good,
    as the sales numbers were randomly generated. This will, however, provide you
    with a template for generating results with your own data.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring your sample dataset with many models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to score data from your sample dataset, observe the following instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `solution-accelerator-many-models` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `Automated_ML` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `03_AutoML_Forecasting_Pipeline` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Jupyter notebook and open it. Rename it `03_AutoML_Forecasting_Pipeline-My-Data.ipynb`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Load in all of the libraries you have already used in this chapter with the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you need a refresher on any of these, please refer to the *Training many
    models simultaneously* section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load in the libraries that are new to this section with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You have another helper function here, `get_forecasting_output`. This lets you
    easily retrieve the predictions generated by the MMSA without any hassle. Both
    `sys` and `shutil` are used by `get_forecasting_output`. While `shutil` lets you
    manipulate files and folders similar to `os`, `sys` lets you interact with the
    Python runtime environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect your Jupyter notebook to your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you are prompted to log in, do so by following the instructions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your datastore to the default datastore that comes with your AMLS workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This uses the same datastore variable name as the training notebook.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your experiment and give it a name with the help of the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Specify your training dataset with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It doesn't matter what name you give to your named input. The important thing
    is the underlying dataset. The MMSA will find the correct dataset regardless.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Set your compute cluster, which will be used for remote training, with the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve your experiment name and run ID from the ML pipeline you used to train
    the models. You can find the run ID in AML studio under **Experiments**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your partition column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass in your MMSA configurations. Make sure that you set `time_column_name`
    to `Date`, `target_column_name` that you are trying to predict to `Sales`, `node_count`
    to the maximum number of nodes on your compute cluster, and `process_count_per_node`
    to the number of cores on a single VM with the help of the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Submit your MMSA scoring run with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get additional details about your MMSA scoring run with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should only take a few minutes to run.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once your ML pipeline has finished, publish your ML pipeline with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Publishing your scoring pipeline will let you run it again very easily in the
    future. You will learn more about ML pipelines in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129),
    *Implementing a Batch Scoring Solution*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'View the first 10 rows of your results with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For this code to work, you need to manually enter the column names of your
    dataset. The last column will always be the predictions generated by your solution.
    Your results should resemble the following screenshot. Since the data was random,
    it shouldn''t be good:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Many model results on the sample data  ](img/Figure_7.4_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Many model results on the sample data
  prefs: []
  type: TYPE_NORMAL
- en: Success! You have reached the ultimate goal of creating a complete MMSA solution
    with sample data read in as a pandas dataframe. You are now in prime position
    to use the solution with your own data.
  prefs: []
  type: TYPE_NORMAL
- en: The first time you run the MMSA using only the `OJ Sales` data, it seems like
    it's really easy and there's nothing to it. Despite being easy, you will find
    that it produces superior results compared to the single model you trained in
    [*Chapter 6*](B16595_06_ePub.xhtml#_idTextAnchor081), *Building a Forecasting
    Solution*. By simply running a few notebooks in the correct order, you are able
    to produce a high performing model.
  prefs: []
  type: TYPE_NORMAL
- en: Experience has now taught you how you need to adjust the MMSA to work with your
    own data and that was pretty straightforward too. However, the first time you
    try to apply your own data to it, you may find it a bit tricky. Getting your data
    into just the right format can be frustrating. To help make your experience smooth,
    the final portion of this chapter covers tips and tricks to improve your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Improving your many models results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have adapted all three of the notebooks to run your own code, you
    should be feeling pretty confident in your ability to use the MMSA. Still, it's
    pretty easy to get stuck. Many models is a complicated framework and small errors
    in your data can lead to errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, sometimes it''s really hard to know what your data will look
    like when you are dealing with thousands of files you wish to train. Here is some
    good advice to follow in order to ensure you do not come to an impasse when using
    your own data with the MMSA:'
  prefs: []
  type: TYPE_NORMAL
- en: Before using the accelerator, always try creating a single model first with
    your entire dataset. Check the performance of your model. Only use the MMSA if
    the single model's performance is subpar compared to your expectations or in a
    situation where obtaining the best accuracy is mission-critical for your project.
    Sometimes, the trade-off between complexity and performance isn't worth it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spend a lot of time ensuring that your data is split correctly before using
    the accelerator. Each combination of partition columns needs to have its own file.
    Think carefully as to which columns you would like to use as your partitions.
    Alternatively, try out a few different combinations to see which gives the best
    performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When splitting data for forecasting using a date column, absolutely make sure
    that it is in a datetime format as opposed to a string format. Oftentimes, data
    scientists will make the mistake of splitting on a string column. Sometimes when
    this happens, the first two notebooks will run as is and you will be able to train
    models. However, when you get to the third notebook to forecast data, you will
    get an error and have to start from the beginning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the Data Preparation notebook, do not hardcode `split_date`. Instead, make
    it variable based on the current datetime, how much training data you expect to
    have, and how many hours, days, weeks, or months out you would like to forecast.
    This way, when you go to retrain the MMSA solution, you will get forecasts for
    the appropriate time periods. Keep in mind that this is only relevant for forecasting
    problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For all problems, carefully study your data before passing it into the solution.
    While AutoML will handle null values and many other errors, it does less with
    other problems, such as large gaps in your forecasting problem's time column.
    Clean your data as much as possible before passing it into the MMSA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the MMSA notebook was created using a forecasting example, it's quite
    easy to adapt the notebook for regression and classification problems. As these
    are inherently less complicated than forecasting, importing your own code for
    these problems is comparatively easier. You don't have to worry about dates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Become familiar with the log files. When you navigate them, make sure you first
    click on the pipeline step that failed. Then, click `logs` and expand it. Then,
    look for a folder called `user`. Within the `user` folder, you need to search
    for the `error` folder. The `error` folder contains numerous folders that are
    a series of numbers separated by periods such as `10.0.0.5`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These folders hold the most important files for debugging purposes. Each file
    starts with `process` and ends with `.txt`. Open up these files and use them to
    find any errors in your code.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do not be afraid to use very large compute clusters when training models with
    the MMSA. Although larger VMs cost more per hour to use, they also train much
    quicker than their cheaper counterparts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that when you are training models using the MMSA, the compute cluster
    running it will be at maximum capacity for a comparatively long time depending
    on how many models you are training. As such, it makes sense to make sure that
    the compute cluster you use to train many models isn't responsible for running
    other jobs at the same time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key problem that the MMSA solves is that, when you have multiple, high-dimensional
    categorical columns, many traditional ML algorithms underperform for mathematical
    reasons. As your business expands, your products expand, your locations expand,
    your workforce expands, and the MMSA becomes more and more appropriate for your
    business.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrain your models frequently on a schedule. It's very difficult to monitor
    hundreds of thousands of ML models to determine which ones need to be retrained.
    Instead, retrain all of them on a weekly or monthly basis to ensure high performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although you have received many tips and tricks that will help you build solutions
    using the MMSA, the best advice is simply to practice as much as possible. Explore
    the solution as much as possible and uncover as many caveats as you can.
  prefs: []
  type: TYPE_NORMAL
- en: More than anything, remember that the MMSA and AutoML perform best when you
    pass in clean data. This section concludes this chapter. You now have the expertise,
    knowledge, and practice to implement a truly game-changing solution in the world
    of automated ML.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced solutions like the MMSA are at the bleeding edge of ML and AI. It is
    a truly state-of-the-art technology and now it's another tool in your belt.
  prefs: []
  type: TYPE_NORMAL
- en: You've not only run all three notebooks on the `OJ Sales` data, but you have
    also converted the code to take in other datasets and understand how it works.
    Prepping data, training models, and forecasting the future using the MMSA are
    all things you have done and could do again. You may already have a use case to
    which you can apply it, or you may have to wait a few more years until your company
    is ready, but you are prepared.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16595_08_ePub.xhtml#_idTextAnchor112), *Choosing Real-Time versus
    Batch Scoring*, continues your journey at the forefront of the ML world. Once
    you build a model in AutoML, the next step is to deploy it, and there are two
    options: batch versus real-time scoring. You will learn when to use batch scoring,
    when to use real-time scoring, and the main differences between the two. Mastering
    these concepts is key to successfully applying your AutoML models to real-world
    business scenarios.'
  prefs: []
  type: TYPE_NORMAL
