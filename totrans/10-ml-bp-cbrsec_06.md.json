["```py\n# Data Processing\nimport numpy as np\nimport pandas as pd\nimport scipy.misc\nfrom sklearn.datasets import load_files\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Deep Learning Libraries\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\nfrom keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\nfrom keras_vggface.vggface import VGGFace\nfrom keras_vggface import utils\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\n```", "```py\ntraining_data_path = \"\"\ntest_data_path = \"\"\nbatch_size = 64\nprint(\"Loading Train…\")\ntraining_data = ImageDataGenerator(rescale = 1./255.) .flow_from_directory(\n    training_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='binary'\n)\nprint(\"Loading Test…\")\ntest_data = ImageDataGenerator(rescale = 1./255.)\n.flow_from_directory(\n    test_data_path,\n    target_size=(224, 224),\n    batch_size=batch_size,\n    class_mode='binary'\n)\n```", "```py\nLoading Train…\nFound 100000 images belonging to 2 classes.\nLoading Test…\nFound 20000 images belonging to 2 classes.\n```", "```py\ninput_shape = (224,224,3)\nepsilon=0.001\ndropout = 0.1\nmodel = Sequential()\n# Convolution and Pooling -- 1\nmodel.add(BatchNormalization(input_shape=input_shape))\nmodel.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization(epsilon=epsilon))\n# Convolution and Pooling -- 2\nmodel.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization(epsilon=epsilon))\nmodel.add(Dropout(dropout))\n#Convolution and Pooling -- 3\nmodel.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization(epsilon=epsilon))\nmodel.add(Dropout(dropout))\n# Aggregation\nmodel.add(GlobalAveragePooling2D())\n# Fully Connected Layer\nmodel.add(Dense(1, activation='sigmoid'))\n```", "```py\nmodel.summary()\n```", "```py\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(0.0001), metrics=['accuracy'])\ntraining_steps = 40000//batch_size\nnum_epochs = 10\nhistory = model.fit_generator(\n    training_data,\n    epochs=num_epochs,\n    steps_per_epoch = training_steps\n)\n```", "```py\ny_pred = model.predict(test_data)\ny_actual = test_data.classes\n```", "```py\n# Libraries for Machine Learning\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\n# Helper Libraries\nimport imageio\nimport cv2\nimport os\n```", "```py\ntrain_meta_file = '../deepfake-detection-challenge/train_sample_videos/metadata.json'\ntrain_sample_metadata = pd.read_json(train_meta_file).T\n```", "```py\ntrain_sample_metadata.head()\n```", "```py\ndef crop_image(frame):\n  # Read dimensions\n    y = frame.shape[0]\n    x = frame.shape[1]\n  # Calculate dimensions of cropped square\n    min_dimension = min(x, y)\n    start_x = (x/2) - (min_dimension/2)\n    start_y = (y/2) - (min_dimension/2)\n  # Pick only the part of the image to be retained\n    cropped = frame[start_y : start_y + min_dim,\n                    start_x : start_x + min_dim]\n    return cropped\n```", "```py\ndef parse_video_into_frames(video_file_path):\n    new_shape = (224, 224)\n    capture = cv2.VideoCapture(path)\n    frames = []\n    try:\n        while True:\n      # Read from the video stream\n            ret, frame = capture.read()\n            if not ret: # Have reached the end of frames\n                break\n      # Crop the frame and resize it\n            frame = crop_image(frame)\n            frame = cv2.resize(frame, new_shape)\n            frame = frame[:, :, [2, 1, 0]]\n       # Append it to a sequence\n            frames.append(frame)\n    finally:\n        capture.release()\n    return np.array(frames)\n```", "```py\ninception_model = keras.applications.InceptionV3(\n        weights=\"imagenet\",\n        include_top=False,\n        pooling=\"avg\",\n        input_shape=(224,224, 3),\n    )\npreprocess_input = keras.applications.inception_v3.preprocess_input\ninputs = keras.Input((224,224, 3))\npreprocessed = preprocess_input(inputs)\noutputs = inception_model(preprocessed)\nfeature_extractor = keras.Model(inputs, outputs, name=\"feature_extractor\")\n```", "```py\ndef prepare_data(df, data_dir):\n    MAX_SEQ_LENGTH = 20\n    NUM_FEATURES = 2048\n    num_samples = len(df)\n    video_paths = list(df.index)\n  # Binarize labels as 0/1\n    labels = df[\"label\"].values\n    labels = np.array(labels=='FAKE').astype(np.int)\n   # Placeholder arrays for frame masks and features\n    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n  # Parse through each video file\n    for idx, path in enumerate(video_paths):\n        # Gather all its frames and add a batch dimension.\n        frames = parse_video_into_frames(os.path.join(data_dir, path))\n        frames = frames[None, ...]\n        # Initialize placeholders to store the masks and features of the current video.\n        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n        temp_frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n        # Extract features from the frames of the current video.\n        for i, batch in enumerate(frames):\n            video_length = batch.shape[0]\n            length = min(MAX_SEQ_LENGTH, video_length)\n            for j in range(length):\n                temp_frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n        frame_features[idx,] = temp_frame_features.squeeze()\n        frame_masks[idx,] = temp_frame_mask.squeeze()\n    return (frame_features, frame_masks), labels\n```", "```py\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(train_sample_metadata,test_size=0.1,random_state=42,stratify=train_sample_metadata['label'])\ntrain_data, train_labels = prepare_data(train_set, \"train\")\ntest_data, test_labels = prepare_data(test_set, \"test\")\n```", "```py\nMAX_SEQ_LENGTH = 20\nNUM_FEATURES = 2048\nDROPOUT = 0.2\nframe_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\nmask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\nx = keras.layers.GRU(32, return_sequences=True)(frame_features_input, mask=mask_input)\nx = keras.layers.GRU(16)(x)\nx = keras.layers.GRU(8)(x)\nx = keras.layers.Dropout(DROPOUT)(x)\nx = keras.layers.Dense(8, activation=\"relu\")(x)\nx = keras.layers.Dense(8, activation=\"relu\")(x)\noutput = keras.layers.Dense(1, activation=\"sigmoid\")(x)\nmodel = keras.Model([frame_features_input, mask_input], output)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n```", "```py\nmodel.summary()\n```", "```py\nEPOCHS = 10\nmodel.fit(\n        [train_data[0], train_data[1]],\n        train_labels,\n        validation_data=([test_data[0], test_data[1]],test_labels),\n        epochs=EPOCHS,\n        batch_size=8\n    )\n```", "```py\npredicted_labels = []\nTHRESHOLD = 0.5\nfor idx in range(len(test_data[0])):\n  frame_features = test_data[0][idx]\n  frame_mask = test_data[1][idx]\n  output_prob = model.predict([frame_features, frame_mask])[0]\n  if (output_prob >= THRESHOLD):\n    predicted_labels.append(1)\n  else:\n    predicted_labels.append(0)\n```"]