<html><head></head><body>
        

                            
                    <h1 class="header-title">Learning More about Feature Detection in OpenCV</h1>
                
            
            
                
<p>In <a href="61bdd7aa-b605-4061-8bfe-71084c7c7104.xhtml">Chapter 4</a><em>, Controlling a Phone App with Your Suave Ges</em><em>tures</em>, we used the Good Features to Track algorithm to detect trackable features in images. OpenCV offers implementations of several more feature-detection algorithms. Two of the other algorithms, called minimum eigenvalue corners and Harris Corners, are precursors to Good Features to Track, which improves upon them. An official tutorial illustrates the use of eigenvalue corners and Harris Corners in a code sample at <a href="https://docs.opencv.org/master/d9/dbc/tutorial_generic_corner_detector.html">https://docs.opencv.org/master/d9/dbc/tutorial_generic_corner_detector.h</a><a href="https://docs.opencv.org/master/d9/dbc/tutorial_generic_corner_detector.html">tml</a>.</p>
<p>Some of the other, more-advanced feature-detection algorithms in OpenCV are named FAST, ORB, SIFT, SURF, and FREAK. Compared to Good Features to Track, these more-advanced alternatives evaluate a much larger set of potential features, at a much greater computational cost. They are overkill for a basic optical flow task such as ours. Once we have detected a face, we do not need many features in this region in order to distinguish between vertical motions (nodding) and horizontal motions (shaking). For our gesture-recognition task, running at a fast frame rate is far more important than running with a large number of features. On the other hand, some computer vision tasks require a large number of features. Image recognition is a good example. If we put red lipstick on a poster of the <em>Mona Lisa</em>, the resulting image is not the Mona Lisa (or at least not Leonardo's version of her). An image's details may be considered fundamental to its identity. However, a change in lighting or perspective does not change an image's identity, so the feature-detection and matching system still needs to be robust with respect to some changes.</p>
<p>For a project that covers image recognition and tracking, refer to <em>Chapters 4</em>, <em>Chapter 5</em>, and <em>Chapter 6</em> of <em>Android Application Programming with OpenCV 3</em>, by Packt Publishing.</p>
<p>For benchmarks of several feature detectors and matchers in OpenCV, refer to the series of articles on Ievgen Khvedchenia's blog, including <a href="http://computer-vision-talks.com/2011-07-13-comparison-of-the-opencv-feature-detection-algorithms/">http://computer-vision-talks.com/2011-07-13-comparison-of-the-opencv-feature-detection-algorithms/</a>. Also, you can find more up-to-date benchmarks in the <em>Example comparative performance tests of algorithms</em> section in <em>Chapter 9, </em><em>Finding the Best OpenCV Algorithm for the Job</em> in <em>Mastering OpenCV 4</em>, by Roy Shilkrot and David Millán Escrivá (Packt Publishing, 2018).</p>
<p>For tutorials on several algorithms and their OpenCV implementations, see the <em>Feature Detection and Description</em> section of the official OpenCV-Python Tutorials at <a href="http://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html">http://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html</a>.</p>


            

            
        
    </body></html>