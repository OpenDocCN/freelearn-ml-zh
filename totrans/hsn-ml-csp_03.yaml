- en: Bayes Intuition – Solving the Hit and Run Mystery and Performing Data Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯直觉 – 解决肇事逃逸之谜和进行数据分析
- en: '![](img/8e56062f-7bbb-4d3b-9bef-be0912cb3e70.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8e56062f-7bbb-4d3b-9bef-be0912cb3e70.png)'
- en: Notice how the start of this chapter was an in-your-face algorithm? I wanted
    to make sure that the first thing you see is this formula. This underscores just
    how important it will become in your machine learning career. Write it down, put
    it on a sticky note on your monitor, or commit it to memory!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到本章的开头是一个直接面对算法吗？我想确保你看到的第一件事就是这个公式。这强调了它在你机器学习生涯中的重要性。把它写下来，把它贴在你的显示器上的便利贴上，或者把它记在心里！
- en: 'In this chapter, we will:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将：
- en: Apply the famous Bayes' theorem to solve a very famous problem in computer science
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将著名的贝叶斯定理应用于解决计算机科学中一个非常著名的问题
- en: Show you how you can use Bayes' theorem and Naive Bayes to plot data, discover
    outliers from truth tables, and more
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示你如何使用贝叶斯定理和朴素贝叶斯来绘制数据，从真值表中发现异常，等等
- en: Overviewing Bayes' theorem
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述贝叶斯定理
- en: To be honest, there are as many interpretations of Bayes' theorem as there are
    books about it. The one shown previously is the main one that we will be discussing.
    I would also encourage you to refer to [https://brilliant.org/wiki/bayes-theorem/](https://brilliant.org/wiki/bayes-theorem/)
    for further reading.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，贝叶斯定理的解释和关于它的书籍一样多。前面展示的是我们将要讨论的主要解释。我也鼓励你参考[https://brilliant.org/wiki/bayes-theorem/](https://brilliant.org/wiki/bayes-theorem/)进行进一步阅读。
- en: To make this more concrete and formal, let's start off with a bit of intuition
    and formality; it will help us set the stage for what is to come.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个内容更具体和正式，让我们从一点直觉和正式性开始；这将帮助我们为即将到来的内容做好准备。
- en: 'When we use Bayes'' theorem, we are measuring the degree of belief of something,
    the likelihood that an event will occur. Let''s just keep it that simple for now:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用贝叶斯定理时，我们是在衡量某件事的信念程度，即事件发生的可能性。现在就让我们保持这个简单的理解：
- en: '![](img/ad43f1e3-6227-4a34-a79b-26c76628b873.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ad43f1e3-6227-4a34-a79b-26c76628b873.png)'
- en: The preceding formula means the probability of *A* given *B*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式表示在B的条件下A的概率。
- en: 'Probability is usually quantified as a number between 0 and 1, inclusive of
    both; 0 would indicate impossibility and 1 would indicate absolute certainty.
    The higher the probability, the more the certainty. The odds of a dice rolling
    a 6 and the odds of a coin flip coming up heads are two examples of probability
    that you are no doubt very familiar with. There''s also another example you are
    familiar with and encounter daily: spam.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 概率通常被量化为一个介于0和1之间的数，包括0和1；0表示不可能性，1表示绝对确定性。概率越高，确定性就越大。掷骰子得到6和抛硬币得到正面的概率是你无疑非常熟悉的概率例子。还有一个你熟悉且每天都会遇到的例子：垃圾邮件。
- en: All of us usually have our email open right beside us, all day long (some of
    us all night long too!). And with the messages that we are expecting also come
    the ones that we are not and do not care to receive. We all hate dealing with
    spam, that nasty email that has nothing to do with anything but Viagra; yet we
    somehow always seem to get it. What is the probability that any one of those emails
    I get each day is spam? What is the probability that I care about its content?
    How would we even know?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们中的大多数人通常都会全天（有些人甚至整夜）打开电子邮件，就放在我们身边！随着我们期待收到的邮件，也伴随着那些我们不期待且不希望收到的邮件。我们都讨厌处理垃圾邮件，那种与任何事物都无关，只与伟哥有关的讨厌的电子邮件；然而，我们似乎总是能收到它。我每天收到的那些邮件中，任何一封是垃圾邮件的概率是多少？我关心它的内容的概率是多少？我们如何才能知道呢？
- en: So let's talk a little bit about how a spam filter works because, you see, it's
    perhaps the best example of probability we can use! To be precise and more formal,
    we are dealing with **conditional probability**, which is the probability of event
    *A* given the occurrence of event *B*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们简单谈谈垃圾邮件过滤器是如何工作的，因为，你看，这可能是我们能用到的最好的概率例子！为了更精确和更正式，我们正在处理**条件概率**，即在事件B发生的情况下事件A的概率。
- en: 'The way most spam filters work, at least at the very basic level, is by defining
    a list of words that are used to indicate emails that we do not want or did not
    ask to receive. If the email contains those words, it''s considered spam and we
    deal with it accordingly. So, using Bayes'' theorem, we look for the probability
    that an email is spam given a list of words, which would look like this in a formulaic
    view:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数垃圾邮件过滤器的工作方式，至少在非常基本层面上，是通过定义一个单词列表，这些单词用来指示我们不希望或未请求收到的电子邮件。如果电子邮件包含这些单词，它就被认为是垃圾邮件，我们相应地处理它。因此，使用贝叶斯定理，我们寻找给定一组单词的电子邮件是垃圾邮件的概率，这在公式化视角下看起来是这样的：
- en: '![](img/b7eb54af-eab3-4059-8daa-8ddaf1db4f25.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7eb54af-eab3-4059-8daa-8ddaf1db4f25.png)'
- en: '**The probability that an email is spam, given a set of words**: User Qniemiec
    in Wikipedia has an incredible visual diagram that explains in full force every
    combination of a probabilistic view, which is represented by the superposition
    of two event trees. If you are a visual person like I am, here is a complete visualization
    of Bayes'' theorem represented by the superposition of two event tree diagrams:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**给定一组单词的电子邮件是垃圾邮件的概率**：维基百科的用户Qniemiec有一个令人难以置信的视觉图解，它全面解释了概率视角的每一种组合，这由两个事件树的叠加表示。如果你像我一样是一个视觉型的人，这里是对贝叶斯定理的完整可视化，由两个事件树图叠加表示：'
- en: '![](img/5f346d0c-ec5b-4ccd-afc3-5ef501fa9ddd.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f346d0c-ec5b-4ccd-afc3-5ef501fa9ddd.png)'
- en: Now, let's move on to a very famous problem. It is called by many names, but
    the basic problem is what is known as the **taxicab problem**. Here's our scenario,
    which we will attempt to solve using probability and Bayes' theorem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们转向一个非常著名的问题。它被许多人称为不同的名字，但基本问题就是众所周知的**出租车问题**。这是我们的场景，我们将尝试使用概率和贝叶斯定理来解决这个问题。
- en: 'An Uber driver was involved in a hit-and-run accident. The famous yellow taxi
    cabs and Uber drivers are the two companies that operate in the city and can be
    seen everywhere. We are given the following data:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一名优步司机卷入了一起肇事逃逸事故。著名的黄色出租车和优步司机是这座城市中运营的两家公司，随处可见。我们得到了以下数据：
- en: 85% of the cabs in the city are yellow and 15% are Uber.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这座城市中85%的出租车是黄色的，15%是优步。
- en: A witness identified the car involved in the hit and run and stated that it
    had an Uber sticker on it. That being said, we know how reliable witness testimony
    is, so the court decided to test the user and determine their reliability. Using
    the same set of circumstances that existed on the night of the accident, the court
    concluded that the witness correctly identified each one of the two vehicles 80%
    of the time, but failed 20% of the time. This is going to be important, so stay
    with me on this!
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一名目击者指认了肇事逃逸事故中涉及的车辆，并表示该车上有优步标志。话虽如此，我们知道目击者证词的可靠性，因此法院决定测试用户并确定其可靠性。使用事故当晚相同的情况，法院得出结论，目击者80%的时间正确地识别了这两辆车中的每一辆，但20%的时间失败了。这一点很重要，所以请跟我一起继续看下去！
- en: '**Our dilemma**: What is the probability that the car involved in the accident
    was an Uber driver versus a yellow cab?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们的困境**：事故中涉及的车辆是优步司机还是黄色出租车的概率是多少？'
- en: 'Mathematically, here''s how we get to the answer we need:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，我们是这样得到我们需要的答案的：
- en: 'The total number of Uber drivers identified correctly is:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确识别的优步司机总数为：
- en: '*15 * 0.8 = 12*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*15 * 0.8 = 12*'
- en: 'The witness is incorrect 20% of the time, so the total number of vehicles incorrectly
    identified is:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目击者20%的时间是错误的，所以错误识别的车辆总数为：
- en: '*85 * 0.2 = 17*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*85 * 0.2 = 17*'
- en: 'Therefore, the total vehicles identified by the witness is *12 + 17 = 29*.
    The probability that they identified the Uber driver correctly is hence:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，目击者总共识别的车辆数为 *12 + 17 = 29*。因此，他们正确识别优步司机的概率是：
- en: '*12/29 = @41.3%*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*12/29 = @41.3%*'
- en: 'Now, let''s see whether we can develop a simple program that can help us arrive
    at that number to prove our solution works and is viable. To accomplish this,
    we are going to dive into our first open source toolkit: **Encog**. Encog is designed
    to handle problems exactly like this.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们是否可以开发一个简单的程序来帮助我们得到这个数字，以证明我们的解决方案是可行的。为了完成这个任务，我们将深入我们的第一个开源工具包：**Encog**。Encog被设计来处理正好像这样的问题。
- en: The Encog framework is a full-fledged machine learning framework and was developed
    by Mr. Jeff Heaton. Mr. Heaton has also published several books on the Encog framework,
    as well as other subjects, and I encourage you to seek them out if you plan to
    use this framework extensively. I persoally own every one of them and I consider
    them seminal works.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Encog框架是一个完整的机器学习框架，由杰夫·希顿先生开发。希顿先生还出版了关于Encog框架以及其他主题的几本书，如果您计划广泛使用此框架，我鼓励您去寻找它们。我个人拥有它们的所有，并将它们视为开创性的作品。
- en: Let's look at the code it's going to take to solve our problem. As you'll notice,
    math, statistics, probability... it's all abstracted from you. Encog can allow
    you to focus on the business problem you are trying to solve.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看解决我们问题所需的代码。正如您将注意到的，数学、统计学、概率……这些都从您那里抽象出来。Encog可以使您专注于您试图解决的商业问题。
- en: The complete execution block looks like the following code. We'll begin to dissect
    it in a moment.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的执行块看起来像以下代码。我们将在稍后开始分析它。
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: OK, let's break this down into more digestible pieces. The first thing we are
    going to do is create a Bayesian network. This object will be at the center of
    solving our mystery. The `BayesianNetwork` object is a wrapper around a probability
    and classification engine.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们将其分解成更易于消化的部分。我们首先要做的是创建一个贝叶斯网络。这个对象将是解决我们谜题的中心。`BayesianNetwork`对象是一个概率和分类引擎的包装器。
- en: The Bayesian network is comprised of one or more `BayesianEvents`. An event
    will be one of three distinct types—`Evidence`, `Outcome`, or `Hidden`—and will
    usually correspond to a number in the training data. An `Event` is always discrete,
    but continuous values (if present and desired) can be mapped to a range of discrete
    values.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络由一个或多个`BayesianEvents`组成。一个事件将是三种不同类型之一——`Evidence`、`Outcome`或`Hidden`——并且通常对应于训练数据中的一个数字。`Event`总是离散的，但如果存在并且需要，连续值可以映射到一系列离散值。
- en: 'After creating the initial network object, we create an event for the Uber
    driver as well as for the witness who claimed they saw the driver involved in
    the hit and run. We will create a dependency between the Uber driver and the witness,
    and then finalize the structure of our network:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建初始网络对象之后，我们为声称看到司机卷入追尾逃逸事件的Uber司机以及目击者创建一个事件。我们将创建Uber司机和目击者之间的依赖关系，然后最终确定我们网络的结构：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we need to build the actual truth tables. A truth table is a listing
    of all possible values a function can have. There are one or more rows of increasing
    complexity, and the last row is the final function value. If you remember logic
    theory, there are basically three operations that you can have: `NOT`, `AND`,
    and `OR`. 0 usually represents `false`, and 1 usually represents `true`.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要构建实际的真值表。真值表是一个函数可以具有的所有可能值的列表。有一行或多行，其复杂性逐渐增加，最后一行是最终函数值。如果您记得逻辑理论，您基本上可以有三个操作：`NOT`、`AND`和`OR`。0通常代表`false`，而1通常代表`true`。
- en: 'If we look just a little bit deeper, we will see that we end up with the following
    rules:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再深入一点，我们会看到以下规则：
- en: '*If A = 0, -A = 1**If A = 1, -A = 0**A+B = 1, except when A and B = 0**A+B
    = 0 if A and B = 0**A*B = 0, except when A and B = 1**A*B = 1 if A and B = 1*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果A = 0，则-A = 1**；**如果A = 1，则-A = 0**；**A+B = 1，除非A和B = 0**；**如果A和B = 0，则A+B
    = 0**；**A*B = 0，除非A和B = 1**；**如果A和B = 1，则A*B = 1**'
- en: Now, back to our code.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到我们的代码。
- en: 'To build the truth table, we will need to know the probability and the result
    value. In the case of our problem, the probability that an Uber driver was involved
    in the accident is 85%. As for the witness, there is an 80% chance they are telling
    the truth and a 20% chance that they are mistaken. We will use the `AddLine` function
    of the truth table to add this information:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建真值表，我们需要知道概率和结果值。在我们的问题中，Uber司机卷入事故的概率是85%。至于目击者，有80%的可能性他们在说真话，有20%的可能性他们犯了错误。我们将使用真值表的`AddLine`函数来添加这些信息：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let's talk a bit more about truth tables. Here is an extended truth table showing
    all the possible truth functions of two variables, *P* and *Q*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再谈谈真值表。这里是一个扩展的真值表，显示了两个变量*P*和*Q*的所有可能的真值函数。
- en: '![](img/ac69c6d3-1f8e-4ceb-ab07-3fcf0976fafe.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ac69c6d3-1f8e-4ceb-ab07-3fcf0976fafe.png)'
- en: 'If we were to program our truth table more extensively, here is an example
    of how we could do so:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要更广泛地编程我们的真值表，以下是一个例子：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that our network and truth tables are built, it's time to define some events.
    As we mentioned earlier, events are any one of `Evidence`, `Hidden`, or `Outcome`.
    The `Hidden` event, which is neither `Evidence` nor `Outcome`, is still involved
    in the Bayesian graph itself. We will not be using `Hidden` but I wanted you to
    know that it does exist.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了网络和真值表，是时候定义一些事件了。正如我们之前提到的，事件可以是`证据`、`隐藏`或`结果`中的任何一个。`隐藏`事件，既不是`证据`也不是`结果`，但它仍然涉及到贝叶斯图本身。我们不会使用`隐藏`，但我希望你知道它确实存在。
- en: To solve our mystery, we must accumulate evidence. In our case, the evidence
    that we have is that the witness reported seeing an Uber driver involved in the
    hit and run. We will define an event type of `Evidence` and assign it to what
    the witness reported. The result, or outcome, is that it was an Uber driver, so
    we will assign an event type of outcome to that.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决我们的谜团，我们必须积累证据。在我们的例子中，我们有的证据是目击者报告说看到一名优步司机参与了追尾逃逸。我们将定义一个`证据`类型的事件并将其分配给目击者报告的内容。结果是，它是一名优步司机，因此我们将分配一个结果类型的事件。
- en: 'Finally, we must account for the fact that, at least some of the time, the
    witness''s report of seeing an Uber driver involved was incorrect. So we must
    create event values for both probabilities—that the witness did not see an Uber
    driver, and that an Uber driver was not involved:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须考虑到，至少在某些时候，目击者报告看到优步司机参与追尾逃逸是不正确的。因此，我们必须为两种概率创建事件值——目击者没有看到优步司机，以及优步司机没有参与：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notice that the query we are going to execute is an `EnumerationQuery`. This
    object allows probabilistic queries against a Bayesian network. This is done by
    calculating every combination of hidden nodes and using total probability to find
    the result. The performance can be weak if our Bayesian network is large, but
    fortunately for us, it is not.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将要执行的是一个`枚举查询`。这个对象允许对贝叶斯网络进行概率查询。这是通过计算隐藏节点的所有组合并使用总概率来找到结果来实现的。如果我们的贝叶斯网络很大，性能可能会较弱，但幸运的是，对我们来说，它并不大。
- en: 'Finally, we execute our query against our Bayesian network definition and print
    the results:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们对贝叶斯网络定义执行查询并打印结果：
- en: '![](img/326f782d-f4b1-4e77-9e13-4b3026ca3c2a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/326f782d-f4b1-4e77-9e13-4b3026ca3c2a.png)'
- en: The result, as we had hoped for, was 41%.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，正如我们所希望的，是41%。
- en: 'As an exercise for you, see whether you can now use Encog to solve another
    very famous example. In this example, we wake up in the morning and find out that
    the grass was wet. Did it rain, was the sprinkler on, or both? Here''s what our
    truth tables look like on pen and paper:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项练习，看看你现在是否可以使用Encog解决另一个非常著名的例子。在这个例子中，我们早上醒来发现草地是湿的。是下雨了，还是洒水器打开了，或者两者都有？这是我们用笔和纸上的真值表：
- en: '![](img/99ee0c33-fdf3-44c3-83a3-8ed9aaa5cc95.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/99ee0c33-fdf3-44c3-83a3-8ed9aaa5cc95.png)'
- en: 'The probability that it rained:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下雨的概率：
- en: '![](img/458aa8e9-2dee-4938-95bf-6feb70fd95d3.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/458aa8e9-2dee-4938-95bf-6feb70fd95d3.png)'
- en: 'The complete truth table:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的真值表：
- en: '![](img/3dafc76f-282d-468d-89c2-31f566fcad11.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3dafc76f-282d-468d-89c2-31f566fcad11.png)'
- en: Overviewing Naive Bayes and plotting data
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述朴素贝叶斯和绘制数据
- en: Although we discussed Bayes' theorem, we would be doing a great disservice to
    you if we did not discuss Naive Bayes. It's everywhere, and for good reasons.
    It almost always works well (hence the name, Naive), and you will most certainly
    be exposed to it during your machine learning career. It is a simplistic technique
    based upon a premise that the value of any one feature is completely independent
    from the value of any other. For example, an orange is round, the color is orange,
    the skin is not smooth, and it's 10-20 cm in diameter. A Naive Bayes classifier
    would then consider each feature described previously to contribute independently
    that this is an orange versus an apple, lemon, and so on, even if there is some
    data relationship amongst its features.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们讨论了贝叶斯定理，如果我们不讨论朴素贝叶斯，那将是对你极大的不公。朴素贝叶斯无处不在，并且有很好的理由。它几乎总是工作得很好（因此得名，朴素），你肯定会在你的机器学习生涯中接触到它。它是一种基于这样一个前提的简单技术：任何单个特征的价值完全独立于任何其他特征的价值。例如，一个橙子是圆的，颜色是橙色的，皮不是光滑的，直径在10-20厘米之间。朴素贝叶斯分类器将考虑之前描述的每个特征独立地贡献，认为这是一个橙子而不是苹果、柠檬等等，即使其特征之间有一些数据关系。
- en: As mentioned, Naïve Bayes is surprisingly efficient in resolving complex situations.
    Although there are scenarios where it can certainly be outperformed, it can be
    a great first-try algorithm to apply to your problem. We only need a very small
    amount of training data compared to many other models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，朴素贝叶斯在解决复杂情况时出奇地高效。尽管在某些情况下它可能无法超越其他算法，但它可以是一个很好的初次尝试算法，适用于你的问题。与许多其他模型相比，我们只需要非常少量的训练数据。
- en: Plotting data
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据绘图
- en: In our next application, we will be using the fantastic Accord.NET machine learning
    framework to provide you with a tool with which you can enter data, watch it being
    plotted, and learn about false positives and negatives. We will be able to enter
    data for objects that exist in our data space and categorize them as either being
    green or blue. We will be able to change that data and see how it is classified
    and, more importantly, visually represented. Our objective is to learn which set
    new cases fall into as they arrive; they are either green or blue. In addition,
    we want to track false positives and false negatives. Naive Bayes will do this
    for us based upon the data that exists within our data space. Remember, after
    we train our Naive Bayes classifier, the end goal is that it can recognize new
    objects from data it has previously never seen. If it cannot, then we need to
    circle back to the training stage.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个应用中，我们将使用出色的 Accord.NET 机器学习框架为你提供一个工具，你可以用它输入数据，观察数据被绘制，并了解假阳性和假阴性。我们将能够为存在于我们的数据空间中的对象输入数据，并将它们分类为绿色或蓝色。我们将能够更改这些数据，并看到它们是如何被分类的，更重要的是，如何被直观地表示。我们的目标是学习新案例属于哪个集合；它们要么是绿色，要么是蓝色。此外，我们还想跟踪假阳性和假阴性。朴素贝叶斯将根据我们数据空间中的数据为我们完成这项工作。记住，在我们训练朴素贝叶斯分类器之后，最终目标是它能从它以前从未见过的数据中识别出新对象。如果它不能，那么我们需要回到训练阶段。
- en: We briefly discussed truth tables, and now it's time to go back and put a bit
    more formality behind that definition. More concretely, let's talk in terms of
    a **confusion matrix**. In machine learning, a confusion matrix (error matrix
    or matching matrix) is a table layout that lets you visualize the performance
    of an algorithm. Each row represents predicted class instances, while each column
    represents actual class instances. It's called a confusion matrix because the
    visualization makes it easy to see whether you are confusing one with the other.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要地讨论了真值表，现在是我们回到并在这个定义上增加一些正式性的时候了。更具体地说，让我们用**混淆矩阵**来讨论。在机器学习中，混淆矩阵（错误矩阵或匹配矩阵）是一个表格布局，它让你能够可视化算法的性能。每一行代表预测的类实例，每一列代表实际的类实例。它被称为混淆矩阵，因为这种可视化使得很容易看出你是否混淆了这两个。
- en: 'An abstract view of a truth table would look something like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 真值表的抽象视图可能看起来像这样：
- en: '|  | **X present** | **X absent** |  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  | **X存在** | **X不存在** |  |'
- en: '| Test positive | True positive | False positive | Total positive |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 测试结果为正 | 真阳性 | 假阳性 | 总正数 |'
- en: '| Test negative | False negative | True negative | Total negative |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 测试结果为负 | 假阴性 | 真阴性 | 总负数 |'
- en: '|  | Total with X | Total without X | Grand total |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|  | 带有X的总数 | 没有X的总数 | 总计 |'
- en: 'A more visual view of the same truth table would look something like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于相同的真值表，一个更直观的视图可能看起来像这样：
- en: '![](img/fb4b97cd-5cfd-4804-aabf-2e0c0949798d.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb4b97cd-5cfd-4804-aabf-2e0c0949798d.png)'
- en: Visual view of the truth table
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 真值表的直观视图
- en: 'And finally, a more formal view of a true confusion matrix:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一个更正式的真混淆矩阵的视图：
- en: '![](img/d0a00c1f-f694-4660-9dc7-cf0648e81e89.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0a00c1f-f694-4660-9dc7-cf0648e81e89.png)'
- en: In the field of machine learning, the truth table/confusion matrix allows you
    to visually assess the performance of your algorithm. As you will see in our following
    application, every time you add or change data, you will be able to see whether
    any of these false or negative conditions occur.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的领域，真值表/混淆矩阵允许你直观地评估算法的性能。正如你将在我们接下来的应用中看到的那样，每次你添加或更改数据时，你都将能够看到是否发生了任何这些错误或负面的条件。
- en: Currently, the test data we will start out with is split evenly between green
    and blue objects, so there's no reasonable probability that any new case is more
    likely to be one versus the other. This reasonable probability, sometimes called
    a **belief**, is more formally known as the **prior probability** (there's that
    word again!). Prior probabilities are based upon prior experience with what we've
    seen with the data and, in many cases, this information is used to predict outcomes
    prior to them happening. Given a prior probability or belief, we will formulate
    a conclusion which then becomes our **posterior belief**.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将开始使用的测试数据在绿色和蓝色物体之间均匀分配，因此没有合理的概率表明任何新案例更有可能是其中之一而不是另一个。这种合理的概率，有时被称为
    **信念**，更正式地称为 **先验概率**（这个词又出现了！）。先验概率是基于我们对数据的先前经验，在许多情况下，这些信息被用来预测事件发生之前的结果。给定先验概率或信念，我们将制定一个结论，然后这成为我们的
    **后验信念**。
- en: 'In our case, we are looking at:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们正在查看：
- en: The prior probability of green objects being the total number of green objects/the
    total number of objects in our data space
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色物体的先验概率是绿色物体的总数/我们数据空间中物体的总数
- en: The prior probability of blue objects being the total number of blue objects/the
    total number of objects in our data space
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色物体的先验概率是蓝色物体的总数/我们数据空间中物体的总数
- en: Let's look a little bit further into what's happening.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步了解一下发生了什么。
- en: You can see what our data looks like in the following screenshot. The *X* and
    *Y* columns indicate coordinates in our data space along an *x* and *y* axis,
    and the *G* column is a label as to whether or not the object is green. Remember,
    supervised learning should give us the objective we are trying to arrive at, and
    Naive Bayes should make it easy to see whether that's true.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在下面的屏幕截图中看到我们的数据看起来是什么样子。*X* 和 *Y* 列表示数据空间中沿 *x* 和 *y* 轴的坐标，而 *G* 列表示物体是否为绿色的标签。记住，监督学习应该给我们我们试图达到的客观结果，朴素贝叶斯应该使我们能够轻松地看到这是否为真。
- en: '![](img/7914ccf9-d845-4e8b-b919-e90892751181.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7914ccf9-d845-4e8b-b919-e90892751181.png)'
- en: If we take the preceding data and create a scatter plot of it, it will look
    like the following screenshot. As you can see, all the points in our data space
    are plotted, and the ones with our *G* column having a value of 0 are plotted
    as blue, while those having a value of 1 are plotted as green.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取前面的数据并创建其散点图，它将看起来像下面的屏幕截图。正如你所看到的，我们数据空间中的所有点都被绘制出来，其中 *G* 列值为 0 的点被绘制为蓝色，而值为
    1 的点被绘制为绿色。
- en: 'Each data point is plotted against its *X*/*Y* location in our data space,
    represented by the *x*/*y* axis:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据点都绘制在我们数据空间中的 *X*/*Y* 位置上，由 *x*/*y* 轴表示：
- en: '![](img/828b307b-375c-40a0-8620-4babe7b20456.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/828b307b-375c-40a0-8620-4babe7b20456.png)'
- en: 'But what happens when we add new objects to our data space that the Naive Bayes
    classifier cannot correctly classify? We end up with what is known as false negatives
    and false positives, as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但当我们向数据空间添加朴素贝叶斯分类器无法正确分类的新物体时会发生什么？我们最终得到的是所谓的假阴性和假阳性，如下所示：
- en: '![](img/b6247b05-3d46-4daa-9079-23b34a5f0561.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6247b05-3d46-4daa-9079-23b34a5f0561.png)'
- en: As we have only two categories of data (green and blue), we need to determine
    how these new data objects will be correctly classified. As you can see, we have
    14 new data points, and the color coding shows where they align to the *x* and
    *y* axis.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有两种数据类别（绿色和蓝色），我们需要确定这些新数据对象将如何被正确分类。正如你所看到的，我们有 14 个新的数据点，着色显示它们与 *x*
    和 *y* 轴的对齐情况。
- en: 'Now let''s view our application in its full form. The following is a screenshot
    of our main screen. Under the Data Samples tab on the left-hand side of the screen,
    we can see that we have our data space loaded. On the right-hand side of the screen,
    we can see that we have a scatter plot visual diagram that helps us visualize
    that data space. As you can see, all the data points have been plotted and color-coded
    correctly:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们以完整的形式查看我们的应用程序。以下是我们主屏幕的屏幕截图。在屏幕左侧的“数据样本”选项卡下，我们可以看到我们已经加载了数据空间。在屏幕右侧，我们可以看到一个散点图视觉图，它帮助我们可视化数据空间。正如你所看到的，所有数据点都已正确绘制并着色：
- en: '![](img/56cebee2-9632-455e-b8ad-6740cffc1b11.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56cebee2-9632-455e-b8ad-6740cffc1b11.png)'
- en: 'If we take a look at how the probabilities are classified and plotted, you
    can see that the data presents itself almost in two enclosed but overlapping clusters:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看概率的分类和绘制方式，你可以看到数据几乎呈现为两个封闭但重叠的簇：
- en: '![](img/076e34d3-9c73-453a-b6be-a52ce3a3e5ad.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/076e34d3-9c73-453a-b6be-a52ce3a3e5ad.png)'
- en: When a data point in our space overlaps a different data point of a different
    color, that's where we need Naive Bayes to do its job for us.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们空间中的一个数据点与不同颜色的不同数据点重叠时，那就是我们需要朴素贝叶斯为我们做工作的地方。
- en: If we switch to our Model Testing tab, we can see the new data points we added.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们切换到我们的模型测试标签页，我们可以看到我们添加的新数据点。
- en: '![](img/b6247b05-3d46-4daa-9079-23b34a5f0561.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b6247b05-3d46-4daa-9079-23b34a5f0561.png)'
- en: Next, let's modify some of the data points that we have added in order to show
    how any one data point can become a false negative or a false positive. Note that
    we start this exercise with seven false negatives and seven false positives.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们修改一些我们添加的数据点，以展示任何一个数据点如何变成误报或漏报。请注意，我们从这个练习开始有七个误报和七个漏报。
- en: '![](img/041a0a99-8d46-4295-bc5e-f948f664b1fb.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/041a0a99-8d46-4295-bc5e-f948f664b1fb.png)'
- en: 'The data modifications we made previously result in the following plot. As
    you can see, we have additional false positives now:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前所做的数据修改导致以下图表。如您所见，我们现在有额外的误报：
- en: '![](img/79345884-955a-4004-a9f3-7970f160c9a8.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/79345884-955a-4004-a9f3-7970f160c9a8.png)'
- en: I will leave it up to you to experiment with the data and continue your Naive
    Bayes learning!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把实验数据并继续你的朴素贝叶斯学习留给你去尝试！
- en: Summary
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about probability theory, Bayes theorem, Naive Bayes,
    and how to apply it to real-world problems. We also learned how to develop a tool
    that will help us test out our classifier and see whether our data holds any false
    negatives or positives.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了概率论、贝叶斯定理、朴素贝叶斯，以及如何将其应用于现实世界的问题。我们还学习了如何开发一个工具，帮助我们测试我们的分类器，看看我们的数据是否包含任何误报或漏报。
- en: In our next chapter, we will dive deeper into the world of machine learning
    and talk about reinforcement learning.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨机器学习的世界，并讨论强化学习。
- en: References
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Creative Commons Attribution—ShareAlike License
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Creative Commons Attribution—ShareAlike License
- en: 'Heaton, J. (2015). *Encog: Library of Interchangeable Machine Learning Models
    for Java and C#*, *Journal of Machine Learning Research*, 16, 1243-1247'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Heaton, J. (2015). *Encog: Library of Interchangeable Machine Learning Models
    for Java and C#*, *Journal of Machine Learning Research*, 16, 1243-1247'
- en: Copyright 2008-2014, Heaton Research, Inc
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版权所有 2008-2014，Heaton Research，Inc
- en: Copyright (c) 2009-2017, Accord.NET authors authors@accord-framework.net
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版权所有（c）2009-2017，Accord.NET 作者 authors@accord-framework.net
- en: '*Case Study: The base rate fallacy reconsidered* (Koehler (1996))'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*案例研究：重新审视基础率谬误*（Koehler，1996）'
