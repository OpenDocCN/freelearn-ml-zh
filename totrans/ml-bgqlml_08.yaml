- en: '*Chapter 6*: Classifying Trees with Multiclass Logistic Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multiclass logistic regression is the **Machine Learning** (**ML**) algorithm
    used to classify events, entities, and behaviors into a fixed number of categories.
    It can be used across different industries and business scenarios when it's necessary
    to predict the classification of an entity into multiple groups. A typical classification
    use case is represented by the desire to segment the customer base of a company
    according to their profitability and preferences in order to target the right
    customers with the most effective marketing campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of technique is an extension of the binary logistic regression that
    allows us to overcome the limits of two possible labels and opens the applicability
    to other contexts where we can find multiple categories to identify.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll see all the stages necessary to implement, evaluate,
    and test a multiclass logistic regression model leveraging BigQuery ML.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll go through the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the business scenario
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering multiclass logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring and understanding the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training the multiclass logistic regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the multiclass logistic regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the multiclass logistic regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drawing business conclusions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires you to access a web browser and to have the possibility
    to leverage the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A GCP account to access the Google Cloud Console
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A GCP project to host the BigQuery datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we're ready with the technical requirements, let's dive into the analysis
    and development of our BigQuery ML logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/3h4w7xG](https://bit.ly/3h4w7xG)'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the business scenario
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this business scenario, we can imagine being a ML expert in New York City.
    Among all the activities that the city should perform, a census of the trees and
    verifying their condition is one of the most time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: The trees are spread across different areas of New York City and the process
    of collecting information about each tree is performed manually by volunteers
    or New York City employees. After the collection of the information, the data
    is stored in a database and made publicly available through a BigQuery public
    dataset for further analyses ([https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-tree-census](https://console.cloud.google.com/marketplace/details/city-of-new-york/nyc-tree-census)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we can see a picture from Central Park, one of the
    areas with more trees in New York City:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Trees in Central Park, New York City'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16722_06_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Trees in Central Park, New York City
  prefs: []
  type: TYPE_NORMAL
- en: In order to support and accelerate the job of the people in charge of classifying
    the trees and assessing their condition, one of your managers may ask you to build
    a ML model.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the ML model would be to automatically classify the trees into different
    species according to their characteristics, such as their position, size, and
    health status.
  prefs: []
  type: TYPE_NORMAL
- en: For this use case, we can focus our attention only on the five species of trees
    most present in the city.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've briefly explained and understood the business scenario, let's
    take a look at the ML technique that we can use to classify objects or events
    into multiple classes.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering multiclass logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll learn the basics of multiclass logistic regression and
    when this technique can be applied.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiclass logistic regression** is a classification technique that can be
    used to categorize events, objects, customers, or other entities into multiple
    classes. Different from binary logistic regression, this ML algorithm can be used
    to classify output values into more than two discrete classes.'
  prefs: []
  type: TYPE_NORMAL
- en: In order to predict one of the multiple labels, this ML algorithm calculates
    the probability of each outcome and selects the label with the highest probability.
  prefs: []
  type: TYPE_NORMAL
- en: Being a regression algorithm, the prediction of the label is based on a set
    of independent variables called features that are used to predict the dependent
    variable, called a label.
  prefs: []
  type: TYPE_NORMAL
- en: 'This ML technique can be used to answer business questions, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the comment of my customer *neutral*, *positive*, or *negative*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does my customer belong to the *Gold*, *Silver*, or *Bronze* level?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the probability of churn for a specific customer *high*, *medium*, or *low*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the image recognition algorithm identify a *cat*, a *dog*, a *mouse*, or
    a *cow*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our business scenario, since there are a limited number of species of trees
    and we'll focus only on five species, we can leverage multiclass logistic regression.
    Specifically, we're interested in classifying a tree into one of the five species
    according to its characteristics in terms of size, position, and health status.
  prefs: []
  type: TYPE_NORMAL
- en: Training a multiclass logistic regression model means trying to find the values
    of the coefficients that can be used in the equation between the input variables,
    called features, and the output variable, called a label.
  prefs: []
  type: TYPE_NORMAL
- en: After the training, we'll leverage a **Confusion Matrix** to evaluate the performances
    of our multiclass logistic regression model. In multiclass logistic regression,
    multiple rows and multiple columns compose the confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the performances of our ML model, we'll again use the **Area Under
    the Curve** (**AUC**) **Receiver Operating Characteristic** (**ROC**).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've learned the basics of multiclass logistic regression, it's time
    to take a look at the dataset that we'll use to build our ML model.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring and understanding the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've already done in the previous use cases, before diving into the development
    of the ML model, it's necessary to analyze the data that can be used to solve
    our use case.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start with the analysis of the table structure to have a clear understanding
    of the data that can be used for our business scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll look take a look at the data to understand its structure
    and how it can be used to build our ML model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start exploring the data, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the Google Cloud Console and access the **BigQuery** user interface
    from the navigation menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new dataset under the project that we created in [*Chapter 2*](B16722_02_Final_ASB_ePub.xhtml#_idTextAnchor039),
    *Setting Up Your GCP and BigQuery Environment*. For this use case, we'll create
    the dataset `06_nyc_trees` with the default options.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the GCP project `new_york_trees`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As we can see in the following screenshot, the BigQuery public dataset contains
    multiple tables to host the data collected every 10 years:![Figure 6.2 – The New
    York City Trees Public dataset contains the census
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: of the trees collected every 10 years
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.2 – The New York City Trees Public dataset contains the census of the
    trees collected every 10 years
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We''ll use the most recent one: `tree_census_2015`. This table contains all
    the information about the trees planted in New York City and registered in 2015.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's click on the table name `tree_census_2015` in the BigQuery navigation
    menu to access the schema of the table:![Figure 6.3 – The structure of the tree_census_2015
    table lists all the fields
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: that can be used as labels and features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.3 – The structure of the tree_census_2015 table lists all the fields
    that can be used as labels and features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Each field is well described in the **Description** column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The table contains the **spc_latin** column represented by a **STRING** that
    indicates the scientific name of the species of each tree. This field will be
    the label of our ML model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In order to classify each tree, we can leverage the information present in other
    fields. Some columns describe the size of the tree. For example, **tree_dbh**
    measures the diameter of the tree and **stump_diam** represents the diameter of
    the stump. We can also leverage information about the **health** of the tree.
    We can imagine that some species are more robust than others and more suited to
    the New York City weather.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Other fields are more related to the position of the tree in the city and to
    the context where it lives. In order to train our ML model, we can use the zip
    area where the tree resides: **zip_city**. Some other examples are the **boroname**
    column, which contains the name of the borough where the tree was planted, and
    **nta_name**, which represents the neighborhood the tree falls into.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can also assume that some species are more intrusive than others – the **sidewalk**
    field indicates whether a sidewalk adjacent to the tree was damaged, cracked,
    or lifted by the roots of the tree.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From a schema perspective, this table includes a lot of useful information that
    can be used to develop our classification model. Let's proceed with our analysis,
    diving more into the data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this section, we've analyzed the metadata of the **tree_census_2015** table,
    now it's time to look at the actual data and start querying it.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the data quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we''ve already understood from the previous use cases, the quality of data
    is fundamental to build effective ML models. In this section, we''ll apply some
    data quality checks in order to identify the right records to use:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we''ll check if the table `tree_census_2015` contains records
    with `spc_latin` equals to NULL. This is fundamental because the field `spc_latin`
    will be used as label of our machine learning model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The code block will COUNT all the records in the table ``bigquery-public-data.new_york_trees.tree_census_2015``
    where the field `spc_latin` is empty.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see the results of the query where we
    got a value higher than thirty one thousand:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.4 – The result of the query shows that some rows contain empty labels'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_004.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.4 – The result of the query shows that some rows contain empty labels
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For this reason, in the next queries we'll exclude the records where the field
    `spc_latin` is empty.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Focusing only on the rows where the field `spc_latin` is `NOT NULL`, we can
    check the presence of empty values on all the other fields that are potential
    features of our ML model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Also, in this case, the result of the query is not zero. In fact, we can easily
    identify three records that present `NULL` values in the `health` and `sidewalk`
    fields.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We'll filter these records in the following stages of the ML model life cycle.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that we've applied some quality checks to our dataset and we've understood
    which records should be filtered, let's focus on segmenting our dataset to focus
    the creation of our BigQuery ML model only on the five most frequent species of
    trees.
  prefs: []
  type: TYPE_NORMAL
- en: Segmenting the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we'll prepare the tables that we'll use to train, evaluate,
    and test our ML model.
  prefs: []
  type: TYPE_NORMAL
- en: 'For our purposes, we''ll extract the five most frequent species that appear
    in the dataset. After that, we''ll create the BigQuery tables that will be used
    to train, evaluate, and test our ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we''ll identify only the five most frequent species in the `tree_census_2015`
    table with the following query:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The SQL statement counts the number of occurrences of each species in the `tree_census_2015`
    table using the `GROUP BY spc_latin` clause and the `COUNT(*)` operator.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The query orders the records in descending mode according to the value of the
    field `total` field, which contains the result of the `COUNT`. Finally, the result
    set of the query is limited to the first five records of the result set with the
    `LIMIT 5` clause at the end of the query.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The SQL statement is based on the BigQuery public table `tree_census_2015` properly
    filtered with the data quality checks that we identified in the previous, *Checking
    the data quality* section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see the results of the query and the most
    common species of tree in our dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.5 – The result of the query shows the most common trees in New York
    City'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_005.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.5 – The result of the query shows the most common trees in New York
    City
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: From the query result, we can easily read the Latin name of the trees ordered
    from the most to the least common.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Since we''ll use this subset of five species in the next SQL queries, we can
    add a `CREATE TABLE` statement at the beginning of our `SELECT` statement in order
    to materialize the results in the `top5_species` table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By executing the query, we'll get the creation of a new table that contains
    only two fields and five records. `spc_latin` represents the species of the tree,
    while `total` counts the number of occurrences of each species in the original
    dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we can leverage the `top5_species` table to filter only the species on
    which we''re focusing and create the training table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The query creates a table with all the columns available in the original dataset
    through the `SELECT *` statement. It applies all the filters necessary to get
    not empty values for the `spc_latin` label and all the other potential features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With the usage of the `IN` clause, `training_table` will contain only the records
    related to the most five frequent species in the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The last line of the query, with the clause `MOD(tree_id,11)<=8`, allows us
    to only pick up 80% of the records from the entire set of records. `MOD` stands
    for modulo and returns the remainder of the division of `tree_id` by 11.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'With a similar approach, we can create the table that will be used for the
    evaluation of our ML model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For the `evaluation_table`, we will pick up only 10% of the records with the
    filter `MOD(tree_id,11)=9`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we''ll execute the following SQL statement in order to create the
    table that will be used to apply our multiclass classification model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`classification_table` is very similar to the previous segments of the dataset,
    but thanks to the `MOD` function will contain the remaining 10% percent of the
    dataset.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this section, we've analyzed the `new_york_trees` dataset, which contains
    information about the trees in New York City. We applied some data quality checks
    to exclude empty values. Then, we segmented the data, focusing on the five most
    common species that appear in the table. Now that we've completed the preparatory
    steps, it's time to move on and start the training of our BigQuery ML model.
  prefs: []
  type: TYPE_NORMAL
- en: Training the multiclass logistic regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''ve clearly understood the structure of the data and we''ve segmented
    it into multiple tables to support the different stages of the ML model life cycle,
    let''s focus on the training of our multiclass logistic regression model. We''ll
    execute the SQL queries to create our multiclass logistic regression models:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start creating the first version of our ML model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The query used to create the `classification_model_version_1` model is based
    only on two features: the zip area and the diameter of the tree.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The SQL statement starts with the keywords `CREATE OR REPLACE MODEL`, which
    are used to run the training, followed by the `OPTIONS` clause. Among the options,
    we can specify the model type equals `LOGISTIC_REG` and `auto_class_weights=TRUE`.
    This option can be particularly useful when we're in front of unbalanced training
    datasets with some labels that appear more frequently than others. In our case,
    the occurrences of the most common species are more than double the occurrences
    of the fifth one. For this reason, we've applied this kind of adjustment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The BigQuery ML syntax does not distinguish between binary logistic regression
    and multiclass logistic regression. In both cases, the BigQuery ML model type
    is `LOGISTIC_REG`. The difference is caused by the number of distinct values that
    appear in the column label of the training dataset. If the label presents only
    two values, BigQuery ML will train a binary logistic regression. If the label
    contains more than two distinct values, the model will be trained as a multiclass
    logistic regression.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After the execution of the training, we can access the information of our first
    ML model by clicking on **classification_model_version_1** from the navigation
    menu and selecting the **Evaluation** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot presents the key performance indicators of our first
    attempt:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.6 – The Evaluation tab shows the performance metrics related'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: to the selected BigQuery ML model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_006.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.6 – The Evaluation tab shows the performance metrics related to the
    selected BigQuery ML model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To have an idea of the effectiveness of our ML model, we can look at the **ROC
    AUC** value of **0.7383**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By scrolling down with the mouse in the **Evaluation** tab, we can take a look
    at the confusion matrix of our multiclass logistic regression model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the following figure, the confusion matrix shows the percentage of predicted
    and actual labels on the training dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.7 – The Evaluation tab shows the confusion matrix related to the
    selected BigQuery ML model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16722_06_007.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.7 – The Evaluation tab shows the confusion matrix related to the selected
    BigQuery ML model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Looking at the confusion matrix, we can visually notice that our ML model works
    quite well for some species but performs very poorly for others. For example,
    when the actual label is **Quercus palustris**, in 40% of the cases the ML model
    suggests a different species: **Platanus x acerifolia**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s try to improve our model by adding new features with the following BigQuery
    ML SQL statement:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In comparison with the first attempt, we've included additional features in
    the training of our model. In fact, we've added the name of the borough contained
    in the `boroname` field and `nta_name` to the list of features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After the execution of the SQL statement, let's access the **Evaluation** tab
    of the new model to see if we're improving its performance. Taking a look at the
    **ROC AUC** value of **0.7667**, we can see a slight increase in the performance
    of our model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As a last attempt, we''ll enrich our ML model with additional features. The
    new fields are related to the health of the tree and to the size of the roots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Compared to the previous ML model, in `classification_model_version_3` we've
    included the fields `health`, which describes the health status of our tree, and
    `sidewalk`, used to specify whether the roots of the tree are damaging the adjacent
    pavements.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Looking at the performance of our last ML model in the `0.7696`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Although the usage of more features can increase the ROC AUC value of a BigQuery
    ML classification model, we need to take into consideration the balance between
    the performance improvement and the resources spent to achieve it. In real-life
    scenarios, especially when the volumes are really high, we need to select only
    the features that can have the highest impact on the performance of our BigQuery
    ML model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this section, we''ve created different ML models trying to use different
    features in our dataset. In the next sections, we''ll use the model with the highest
    ROC AUC value: `classification_model_version_3`.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's evaluate the performance of our ML model leveraging the evaluation
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the multiclass logistic regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll execute queries to check the performance of the multiclass
    logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: For the evaluation phase of our BigQuery ML model, we'll use the `ML.EVALUATE`
    function and the `evaluation_table` table, expressly created to host the evaluation
    records.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the evaluation is performed on the same fields that were used
    during the training phase of the model but are extracted from the `evaluation_table`
    table that was created completely disjoint from the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The external `SELECT` statement extracts the `roc_auc` value returned by the
    `ML.EVALUATE` function. It also provides a meaningful description of the quality
    of the model that starts from `'POOR'` and goes up to the `'EXCELLENT'` grade,
    passing through some intermediate stages such as `'NEEDS IMPROVEMENTS'` and `'GOOD'`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s execute the following query to extract the key performance indicator
    of our ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'From the following screenshot, we can see the results of the query – the **roc_auc**
    value achieved more than 0.77\. The result of our BigQuery ML model can be considered
    **GOOD**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – The query extracts the ROC AUC value of the BigQuery ML model'
  prefs: []
  type: TYPE_NORMAL
- en: and a short description of the model quality
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16722_06_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.8 – The query extracts the ROC AUC value of the BigQuery ML model and
    a short description of the model quality
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've verified that the ML model maintains its performance on the disjoint
    evaluation dataset too, we can start using it to classify the trees in our `classification_table`
    table.
  prefs: []
  type: TYPE_NORMAL
- en: Using the multiclass logistic regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we'll test our ML model and analyze the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use our BigQuery ML model, we''ll use the `ML.PREDICT` function and the
    `classification_table` table, which hosts the records, to test our model, as seen
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The query statement is composed of the `SELECT` keyword, which extracts the
    `tree_id`, the actual value of the species in the field, `actual_label`, and the
    predicted fields `predicted_label_probs` and `predicted_label`.
  prefs: []
  type: TYPE_NORMAL
- en: The `ML.PREDICT` function is applied to the `SELECT` statement, which extracts
    the features and the actual species from the `classification_table`. The `actual_label`
    field will be used only as a benchmark for our predictions and not during the
    prediction phase.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see the structure of a record gotten from
    the execution of the previous query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – A record of the output dataset generated by the classification
    model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16722_06_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.9 – A record of the output dataset generated by the classification
    model
  prefs: []
  type: TYPE_NORMAL
- en: In this case, **tree_id** is equal to **857**, the tree is a **Quercus palustris**,
    and is correctly classified by the BigQuery ML model because **predicted_label**
    is exactly the same. **predicted_label_probs** indicates confidence of 45% for
    the highest classification label. All the other possible species are characterized
    by lower probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've applied our model, let's formulate some final considerations
    about our classification use case.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing business conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the results that we got from the previous section, *Using the multiclass
    logistic regression model*, we'll draw some conclusions about the effectiveness
    of our ML model.
  prefs: []
  type: TYPE_NORMAL
- en: Enriching the previous query with a parent `SELECT COUNT` statement, we can
    count how many predictions are right compared to the total number of records.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s execute the following query to calculate how often our BigQuery ML model
    is able to correctly classify the trees in the `classification_table` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The result of the `SELECT COUNT` query returns a value of 13,323 predictions
    with a correctly predicted label.
  prefs: []
  type: TYPE_NORMAL
- en: Considering that the total size of the `classification_table` table is 27,182,
    we can declare that in 49% of cases, our ML model is able to predict the right
    species of tree based on its characteristics and its position.
  prefs: []
  type: TYPE_NORMAL
- en: This could seem like a bad result, but we need to consider that multiclass logistic
    regression is more complex than a binary one because there are multiple options
    that could deceive the results of our model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've built our first multiclass classification model. After
    a brief introduction to the use case, we discovered what multiclass logistic regression
    is and how it can be used to classify events, behaviors, and objects according
    to their features into more than two categories.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into the development of the ML model, we analyzed the schema of
    the dataset related to the trees in New York City and applied some data quality
    checks necessary to build an effective ML model.
  prefs: []
  type: TYPE_NORMAL
- en: During the training stage, we trained three different ML models using different
    features to gradually improve the performance of the BigQuery ML model.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we chose the third ML model and we evaluated it against the evaluation
    dataset. In this phase, we noticed that the ML model was able to maintain its
    performance on new records also and was ready to pass to the next phase.
  prefs: []
  type: TYPE_NORMAL
- en: In the last step, we used our ML model to classify the trees in New York City
    into five different categories and leveraged their characteristics, such as size,
    health status, and position in the city.
  prefs: []
  type: TYPE_NORMAL
- en: We also calculated that our classification model is able to classify the right
    species of tree in 49% of cases.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll introduce unsupervised ML and the K-Means clustering
    technique.
  prefs: []
  type: TYPE_NORMAL
- en: Further resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**NYC Trees Census Public Dataset**: [https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census](https://console.cloud.google.com/marketplace/product/city-of-new-york/nyc-tree-census)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BigQuery ML Create Model**: [https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BigQuery ML Evaluate Model**: [https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BigQuery ML Predict**: [https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BigQuery ML Multiclass Logistic Example**: [https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction](https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
