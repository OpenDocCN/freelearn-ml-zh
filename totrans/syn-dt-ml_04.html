<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer032">
<h1 class="chapter-number" id="_idParaDest-62"><a id="_idTextAnchor065"/>4</h1>
<h1 id="_idParaDest-63"><a id="_idTextAnchor066"/>An Introduction to Synthetic Data</h1>
<p>In this chapter, we will define and introduce synthetic data. We will briefly explore the history and evolution of synthetic data. Then, we will introduce the main types of synthetic data and the basic data augmentation approaches <span class="No-Break">and techniques.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>What is <span class="No-Break">synthetic data?</span></li>
<li>History of <span class="No-Break">synthetic data</span></li>
<li>Synthetic <span class="No-Break">data types</span></li>
<li><span class="No-Break">Data augmentation</span></li>
</ul>
<h1 id="_idParaDest-64"><a id="_idTextAnchor067"/>Technical requirements</h1>
<p>The code used in this chapter will be available under the corresponding chapter folder in the book’s GitHub <span class="No-Break">repository: </span><a href="https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning"><span class="No-Break">https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-65"><a id="_idTextAnchor068"/>What is synthetic data?</h1>
<p><strong class="bold">Synthetic data</strong> is <a id="_idIndexMarker115"/>artificially generated data: the data is not captured, measured, or recorded from the real world. Instead, algorithms or software were used to create or generate this data. Synthetic data can be generated by simulating natural phenomena using mathematical models or by applying some approximations of real-world processes. There are many approaches to generating synthetic data, such as leveraging game engines, such as Unreal and Unity, or utilizing statistical models, such as GANs and diffusion models. As we know, ML models require large-scale training datasets for training and evaluation. Collecting and annotating these datasets is extremely time-consuming, error-prone, and subject to privacy issues. Please refer to <em class="italic">Chapters 2</em> and<em class="italic"> 3</em>. Synthetic data is a powerful solution to address these <span class="No-Break">previous limitations.</span></p>
<p>Synthetic data is useful for scenarios where collecting and annotating data is expensive, but its applications go beyond this particular use case, as we will see later. Synthetic data has been used in AI, ML, and data analytics, specifically <a id="_idIndexMarker116"/>for <strong class="bold">computer vision</strong> tasks, which usually require large and hard-to-annotate data for training. Thus, synthetic data has been widely utilized in this field and has shown <span class="No-Break">great progress.</span></p>
<p>Synthetic data <a id="_idIndexMarker117"/>can be generated to train or evaluate ML models under certain conditions that are usually hard to capture in the real world. For example, let us assume we would like to train a computer vision model to predict road traffic accidents based on some visual information such as RGB and LiDAR images. We would need to feed our training model with a sufficiently large dataset that includes thousands of road traffic accidents. Collecting this dataset from the real world may take us weeks, months, or years; it would require many engineers and annotators, and a huge budget to achieve our aim. At the same time, our dataset may not be valid in other countries or after a few years. If you collected your dataset in the UK, where people drive on the left, this dataset would not be applicable to China, where people drive on the right! In parallel to this, if you collected your dataset in 2005, your dataset may not be applicable for 2024 because of, for instance, new <span class="No-Break">car models.</span></p>
<p>On the other hand, if you generate<a id="_idIndexMarker118"/> your synthetic training data using a simulator such as <em class="italic">CARLA</em> (<a href="https://carla.org">https://carla.org</a>), you can simulate thousands of road traffic accidents. Additionally, you can control car models, scene attributes, weather conditions, and other attributes. This is just an example of the advantages of synthetic data for the training and evaluation of <span class="No-Break">ML models.</span></p>
<h2 id="_idParaDest-66"><a id="_idTextAnchor069"/>Synthetic and real data</h2>
<p>Assume<a id="_idIndexMarker119"/> that you want to train your ML model to predict the profit of<a id="_idIndexMarker120"/> selling a given product. The maximum profit that you can get is £10 and the maximum loss is £10 as well. In the real world, this specific financial problem can be modeled using a simple sinusoidal wave as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.1.</em> Thus, to get the maximum profit, you must sell the product on certain days approximately close to the second and eighth days from the production day (day 0). The blue line gives us the actual model of this problem in the real world. However, this model is hidden from us because if we know this model, then there is no need to use ML for the prediction. Assume that real data perfectly represents this model. Then, the synthetic data in this scenario is the black dots. In other words, synthetic data approximates the real data and real data is also an approximation of the actual process or phenomenon in the <span class="No-Break">real world.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer025">
<img alt="Figure 4.1 – Simple example of real and synthetic data" height="926" src="image/Figure_04_01_B18494.jpg" width="1294"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Simple example of real and synthetic data</p>
<p>At this point, we <a id="_idIndexMarker121"/>may ask, why do we need to use synthetic data if real data<a id="_idIndexMarker122"/> is available? Indeed, this is a sound question: if you have sufficient, annotated, and unbiased real data with no privacy issues, you should not use <span class="No-Break">synthetic data!</span></p>
<p>Unfortunately, in most real-world problems, such optimal datasets are unavailable, extremely expensive, and limited. Thus, synthetic data comes as a last resort to help ML models learn about the process or the task even when the real data is limited or absent. As you can see in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.1</em>, given only the scatter plot, we can still observe a clear pattern, that is, a <strong class="bold">sine wave</strong>, in this data. Thus, a<a id="_idIndexMarker123"/> suitable ML model will still be able to learn how to predict what is the best time to sell this product even if you train it using only <span class="No-Break">synthetic data.</span></p>
<h2 id="_idParaDest-67"><a id="_idTextAnchor070"/>Data-centric and architecture-centric approaches in ML</h2>
<p>In the field of ML, there are two primary approaches: a <a id="_idIndexMarker124"/>model-centric approach, which focuses<a id="_idIndexMarker125"/> on the ML model and its architecture, and a <a id="_idIndexMarker126"/>data-centric approach<a id="_idIndexMarker127"/>, which prioritizes the data as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer026">
<img alt="Figure 4.2 – Data-centric and model -centric ML" height="245" src="image/Figure_04_02_B18494.jpg" width="740"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Data-centric and model -centric ML</p>
<p>Next, let us discuss these two approaches in <span class="No-Break">more detail.</span></p>
<ul>
<li><strong class="bold">Model-centric ML</strong>: The <a id="_idIndexMarker128"/>model-centric <a id="_idIndexMarker129"/>paradigm has been the predominant approach in ML<a id="_idIndexMarker130"/> until recently. This approach assumes that the dataset is fixed and strives to come up with a better architecture, novel training procedures, and new ways to search and find optimal hyperparameters. Let us focus on these elements and discuss them in <span class="No-Break">more detail:</span><ul><li><strong class="bold">Code and architecture</strong>: Researchers <a id="_idIndexMarker131"/>continuously <a id="_idIndexMarker132"/>develop new architectures to better leverage and learn about the training data. For example, after the release of the well-known <em class="italic">ImageNet Large Scale Visual Recognition Challenge (ILSVRC) dataset</em> (<a href="https://www.image-net.org/challenges/LSVRC">https://www.image-net.org/challenges/LSVRC</a>), many architectures were proposed to improve the top-5 classification error, such as AlexNet, <em class="italic">ImageNet Classification with Deep Convolutional Neural Networks </em>(<a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf</a>), and ResNet, <em class="italic">Deep Residual Learning for Image Recognition</em> (<a href="https://arxiv.org/abs/1512.03385">https://arxiv.org/abs/1512.03385</a>). The improvements in the ML model can be in the number of layers, that is, the deep network; model parameters; learning filters; <span class="No-Break">and others.</span></li><li><strong class="bold">Training</strong>: Training is <a id="_idIndexMarker133"/>an interesting research area for ML researchers. Researchers try to find faster ways to train complex ML models and use less data. This addresses issues such as model parameter initialization techniques and their impact on the optimization process, proposes novel optimization techniques, better generalization, less overfitting, novel pretraining techniques, and better fine-tuning tricks for <span class="No-Break">ML models.</span></li><li><strong class="bold">Hyperparameters</strong>: Parameters <a id="_idIndexMarker134"/>such as the learning rate, batch size, and the number of layers highly impact the overall learning process and thus the model’s performance in the real world. Different approaches have been proposed to search for optimal hyperparameters efficiently to further improve <span class="No-Break">ML models.</span></li></ul></li>
<li><strong class="bold">Data-centric ML</strong>: This <a id="_idIndexMarker135"/>approach <a id="_idIndexMarker136"/>started to get more momentum just recently. It focuses <a id="_idIndexMarker137"/>on the data itself rather than the architecture and code. It assumes the ML model’s architecture is fixed and strives to improve performance by focusing only on the dataset. It gives more attention to the following <span class="No-Break">data-related concepts:</span><ul><li><span class="No-Break">Data quality</span></li><li><span class="No-Break">Ground-truth quality</span></li><li><span class="No-Break">Feature engineering</span></li><li><span class="No-Break">Domain knowledge</span></li></ul></li>
</ul>
<p>Let’s see how synthetic data <span class="No-Break">was developed.</span></p>
<h1 id="_idParaDest-68"><a id="_idTextAnchor071"/>History of synthetic data</h1>
<p>In this section, we<a id="_idIndexMarker138"/> will learn about the evolution of synthetic data. Basically, we can categorize the use of synthetic data into the following categories, which may not reflect the chronological order, as it is very hard to track the early uses of synthetic data for <span class="No-Break">each category.</span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor072"/>Random number generators</h2>
<p><strong class="bold">Random number generators</strong> are <a id="_idIndexMarker139"/>one of the <a id="_idIndexMarker140"/>simplest forms of synthetic data. Assume you are training an ML model to recognize faces. Let us say you have only a limited number of images. You can add, for example, random noise to the original images to create new synthetic ones. The implementation of random noise is possible through the utilization of random number generators. This will help the face recognizer ML model to learn how the person’s face changes under certain types of noise (see <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer027">
<img alt="Figure 4.3 – Utilizing random number generators to generate synthetic images" height="219" src="image/Figure_04_03_B18494.jpg" width="648"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Utilizing random number generators to generate synthetic images</p>
<p>Next, we’ll learn about GANs, which are another step in the development of <span class="No-Break">synthetic data.</span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor073"/>Generative Adversarial Networks (GANs)</h2>
<p>GANs <a id="_idIndexMarker141"/>were introduced in 2014 by the famous <strong class="bold">NeurIPS</strong> (formerly <strong class="bold">NIPS</strong>) paper titled <em class="italic">Generative Adversarial Nets</em> by Ian Goodfellow et al. (<a href="https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf</a>). Since then, GANs have been utilized in various applications, such as generating human faces, photo inpainting, 3D object generation, text-to-image translations, and many more <span class="No-Break">interesting applications.</span></p>
<p>A typical GAN is <a id="_idIndexMarker142"/>composed of two networks: a generator and a discriminator. The <strong class="bold">generator</strong> receives<a id="_idIndexMarker143"/> a noise random input vector and outputs a synthetic sample, for instance, say, a car image. The generator aims at making the synthetically generated data, for example, the car image, indistinguishable from the real data, real car images. The <strong class="bold">discriminator</strong>, on<a id="_idIndexMarker144"/> the other hand, strives to identify synthetic data from real data. The discriminator is fed with real or synthetic data and asked to predict the data source of the training sample. If the data sample was drawn from real data and the discriminator correctly identified the data source as real data, no error is backpropagated to the discriminator. On the other hand, the generator is penalized for predicting a sample that is distinguishable from the real dataset. Similarly, if the discriminator failed to identify the source of the image, the discriminator is penalized, and the generator is rewarded for generating indistinguishable synthetic samples close to the real dataset (see <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer028">
<img alt="Figure 4.4 – A typical GAN training process" height="288" src="image/Figure_04_04_B18494.jpg" width="1000"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – A typical GAN training process</p>
<p>We will discuss GANs in more detail in <a href="B18494_07.xhtml#_idTextAnchor120"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-71"><a id="_idTextAnchor074"/>Synthetic data for privacy issues</h2>
<p>As we<a id="_idIndexMarker145"/> discussed in <a href="B18494_03.xhtml#_idTextAnchor049"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, there are enormous privacy issues in real data, and current solutions are only partial solutions to the problem. Recently, synthetic data was proposed as a legitimate solution to these privacy issues. Usually, financial data is often associated with privacy issues as it is problematic to share customers’ data, such as personal details, transactions, assets, and income. This information usually is stored in tables. Surprisingly, it was shown that real data can be learned, and synthetic data can be generated. For example, the researchers who authored the paper titled <em class="italic">Modeling Tabular data using Conditional GAN</em> (<a href="https://arxiv.org/abs/1907.00503">https://arxiv.org/abs/1907.00503</a>) demonstrated that their <strong class="bold">Conditional Tabular GAN</strong> (<strong class="bold">CTGAN</strong>) can <a id="_idIndexMarker146"/>model the probability distribution of tabular real <a id="_idIndexMarker147"/>data with a complex distribution. Their code can be accessed from the paper’s GitHub repository <span class="No-Break">at </span><a href="https://github.com/sdv-dev/CTGAN"><span class="No-Break">https://github.com/sdv-dev/CTGAN</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-72"><a id="_idTextAnchor075"/>Synthetic data in computer vision</h2>
<p>Computer vision<a id="_idIndexMarker148"/> is one of the main fields in ML that requires<a id="_idIndexMarker149"/> large-scale training data. As we discussed earlier, collecting and annotating data for computer vision tasks is extremely expensive and the annotation process is error-prone. As a solution, researchers started to utilize various <a id="_idIndexMarker150"/>methods to generate synthetic data such as game engines, video games, GANs, and <strong class="bold">Variational Auto</strong><strong class="bold">e</strong><strong class="bold">ncoders</strong> (<strong class="bold">VAEs</strong>). The huge advancement in game<a id="_idIndexMarker151"/> engines such as <em class="italic">Unreal</em> (<a href="https://www.unrealengine.com">https://www.unrealengine.com</a>) and <em class="italic">Unity</em> (<a href="https://unity.com">https://unity.com</a>) facilitated the creation of <a id="_idIndexMarker152"/>photorealistic 3D virtual worlds and thus the generation of high-quality and large-scale synthetic data. At the same time, the availability of powerful and affordable <strong class="bold">Graphics Processing Units</strong> (<strong class="bold">GPUs</strong>) for <a id="_idIndexMarker153"/>small research groups further popularized such <span class="No-Break">game engines.</span></p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor076"/>Synthetic data and ethical considerations</h2>
<p>As synthetic data is <a id="_idIndexMarker154"/>gaining more attention and being utilized in various applications, in the last few months, many researchers, scientists, artists, and even the public started to question the copyright issues in texts and images generated using models, such <a id="_idIndexMarker155"/>as <em class="italic">Chat-GPT</em> (<a href="https://chat.openai.com/chat">https://chat.openai.com/chat</a>) and <em class="italic">Stable Diffusion</em> (<a href="https://stablediffusionweb.com">https://stablediffusionweb.com</a>). At <a id="_idIndexMarker156"/>the same time, other issues such as accountability and transparency are being brought to light by the ML community for further precautions and <span class="No-Break">more research.</span></p>
<p>Next, we will dive into the world of synthetic data and learn about its main types <span class="No-Break">in ML.</span></p>
<h1 id="_idParaDest-74"><a id="_idTextAnchor077"/>Synthetic data types</h1>
<p>There are <a id="_idIndexMarker157"/>various synthetic data types, such as textual, imagery, point cloud, and tabular. Based on the ML problem and task, different types of data are required. In this section, we will discuss the main types of synthetic data in <span class="No-Break">more detail.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer029">
<img alt="Figure 4.5 – A sample of synthetic data types" height="480" src="image/Figure_04_05_B18494.jpg" width="777"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – A sample of synthetic data types</p>
<ul>
<li><strong class="bold">Text</strong>: Wikipedia, digital books, lexicons, and text corpora are examples of textual data. ML <a id="_idIndexMarker158"/>models can be trained on large-scale textual datasets to learn the structure of the text that we generate or write as humans. Then, these models can be leveraged to answer questions, summarize texts, or translate from one language to another. These models, such as <em class="italic">ChatGPT</em>, <em class="italic">ChatSonic </em>(<a href="https://writesonic.com">https://writesonic.com</a>), and <em class="italic">Jasper Chat</em> (<a href="https://www.jasper.ai">https://www.jasper.ai</a>), work by generating synthetic texts based on making predictions on what word should <span class="No-Break">come next.</span></li>
<li><strong class="bold">Video, image, and audio</strong>: ML <a id="_idIndexMarker159"/>models can learn the patterns<a id="_idIndexMarker160"/> in a video, image, or audio, and then they can <a id="_idIndexMarker161"/>generate synthetic ones with some new conditions. Models such as <em class="italic">Stable Diffusion</em> (<a href="https://github.com/CompVis/stable-diffusion#stable-diffusion-v1">https://github.com/CompVis/stable-diffusion#stable-diffusion-v1</a>), <em class="italic">DALL·E 2</em> (<a href="https://openai.com/dall-e-2">https://openai.com/dall-e-2</a>), and <em class="italic">Imagen</em> (<a href="https://imagen.research.google">https://imagen.research.google</a>) can be leveraged to generate, theoretically, an unlimited number of synthetic images under <span class="No-Break">various conditions.</span></li>
<li><strong class="bold">Tabular</strong>: This<a id="_idIndexMarker162"/> refers to data that is usually organized in rows and columns using tables. Typically, rows are the observations and columns are the attributes. ML models can be used to predict missing values in tabular data, for example, <em class="italic">Diffusion models for missing value imputation in tabular </em><span class="No-Break"><em class="italic">data</em></span><span class="No-Break"> (</span><a href="https://arxiv.org/abs/2210.17128"><span class="No-Break">https://arxiv.org/abs/2210.17128</span></a><span class="No-Break">).</span></li>
<li><strong class="bold">Point cloud</strong>: This<a id="_idIndexMarker163"/> describes the data that captures the 3D coordinates of an object or a space. This data is often collected using photogrammetry or laser scanners. However, the process of capturing the data in the real world is noisy and problematic. Thus, synthetic datasets are seen as a promising solution in this area. As an example, the <strong class="source-inline">SynthCity</strong> dataset was proposed in this paper titled <em class="italic">SynthCity: A large scale synthetic point cloud</em> (<a href="https://arxiv.org/pdf/1907.04758.pdf">https://arxiv.org/pdf/1907.04758.pdf</a>), which provides more than 360 million synthetic <span class="No-Break">point clouds.</span></li>
</ul>
<p>In the next section, we delve into data augmentation techniques <span class="No-Break">in ML.</span></p>
<h1 id="_idParaDest-75"><a id="_idTextAnchor078"/>Data augmentation</h1>
<p>Data augmentation<a id="_idIndexMarker164"/> is a simple yet powerful tool to mitigate overfitting problems, particularly when limited real data is available. Data augmentation techniques aim to leverage domain knowledge to enrich the available training data. Thus, data augmentation is usually applied only to the training data and not to validation or test data. For example, assume you are training a face recognition algorithm and you have only 10 images per person. We can simply double the number of these training samples if we horizontally flip the images. Furthermore, we can enhance the diversity of our training data by applying various transformations, such as shifting, scaling, and rotating, using random variables. Instead of using fixed values for these transformations, we can leverage a random number generator to generate new values for <a id="_idIndexMarker165"/>each training epoch. Thus, the ML model will be exposed to new variations of our training data at each training epoch. This simple data augmentation technique will help the model in the training process. There are various data augmentation techniques for images, audio, and texts. Next, let us discuss some of these techniques. Please refer to <em class="italic">Image Data Augmentation for Deep Learning: A Survey</em> (<a href="https://arxiv.org/abs/2204.08610">https://arxiv.org/abs/2204.08610</a>) for more details and techniques for image <span class="No-Break">data augmentation.</span></p>
<h2 id="_idParaDest-76"><a id="_idTextAnchor079"/>Geometric transformations</h2>
<p>When limited<a id="_idIndexMarker166"/> training images are available <a id="_idIndexMarker167"/>and acquiring new ones is expensive, we can apply geometric transformations to the original images, such as translation, rotation, cropping, and flipping. However, it is important to take care that the semantic meaning of the image is preserved after these operations. For example, for cats-versus-dogs classification training images, flipping the image horizontally is acceptable, but a vertical flip is not. Similarly, horizontal and vertical flips may not be valid for traffic sign recognition tasks (see <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">).</span></p>
<div>
<div class="IMG---Figure" id="_idContainer030">
<img alt="Figure 4.6 – Sample of valid and invalid geometric transformations" height="467" src="image/Figure_04_06_B18494.jpg" width="940"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Sample of valid and invalid geometric transformations</p>
<p><strong class="bold">Translation</strong> is <a id="_idIndexMarker168"/>simply<a id="_idIndexMarker169"/> shifting an image horizontally or vertically by a fixed or random number of units to avoid object bias. For example, assume all cat images in your cats-dogs classification dataset are in the upper right of the image. Then, the ML model will develop a wrong <a id="_idIndexMarker170"/>association between the cat class and the upper right of the<a id="_idIndexMarker171"/> image. <strong class="bold">Rotation</strong> refers<a id="_idIndexMarker172"/> to rotating the image at a specific angle clockwise or anticlockwise. Like flipping, for some applications, a specific range may be valid but other ranges may change the semantic meaning of the training image. <strong class="bold">Cropping</strong> is <a id="_idIndexMarker173"/>cutting<a id="_idIndexMarker174"/> the image using a virtual cropping window. It is possible to use a fixed or dynamic cropping window size (height <span class="No-Break">and width).</span></p>
<h2 id="_idParaDest-77"><a id="_idTextAnchor080"/>Noise injection</h2>
<p>This<a id="_idIndexMarker175"/> technique <a id="_idIndexMarker176"/>can be applied to almost all data types and specifically to audio and images. Noise can be drawn from various probability distributions, such as normal (Gaussian), uniform, Poisson, and Bernoulli. As expected, training an ML model with carefully augmented data makes the model more robust against similar noise types. The injected noise can be utilized to simulate issues in a camera lens, microphone, transmission medium, and other sorts of distortions. When the ML model learns how to deal with similar scenarios in the training process, it will not struggle when these scenarios occur in the real world due to unpredictable factors, such as adverse weather conditions and hardware failures or <span class="No-Break">other issues.</span></p>
<h2 id="_idParaDest-78"><a id="_idTextAnchor081"/>Text replacement, deletion, and injection</h2>
<p>These <a id="_idIndexMarker177"/>techniques are widely used to increase the size of the textual datasets when training a <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>) model. It <a id="_idIndexMarker178"/>should be noted that like other data augmentation techniques for images, we should pay attention that augmenting the text does not change the meaning of the sentence. <strong class="bold">Text replacement</strong> is a <a id="_idIndexMarker179"/>simple technique that can be used to generate synthetic text to further enrich the diversity of the training data. A basic augmentation pipeline is shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.7</em>. Assume we have the sentence “<strong class="source-inline">Synthetic Data is essential in ML</strong>” and we want to apply a text augmentation technique to it. Given the sentence, we can randomly select a word, in this example, “<strong class="source-inline">essential</strong>,” and replace it with one of its synonyms selected at random, for example, “<strong class="source-inline">crucial</strong>.” The augmented synthetic sentence becomes “<strong class="source-inline">Synthetic Data is crucial </strong><span class="No-Break"><strong class="source-inline">in ML</strong></span><span class="No-Break">.”</span></p>
<div>
<div class="IMG---Figure" id="_idContainer031">
<img alt="Figure 4.7 – Text augmentation pipeline using synonyms" height="451" src="image/Figure_04_07_B18494.jpg" width="1101"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Text augmentation pipeline using synonyms</p>
<p>Similarly, <strong class="bold">text deletion</strong> and <strong class="bold">text injection</strong> can be<a id="_idIndexMarker180"/> utilized <a id="_idIndexMarker181"/>to generate <a id="_idIndexMarker182"/>synthetic text to improve the <a id="_idIndexMarker183"/>performance of <span class="No-Break">ML models.</span></p>
<h1 id="_idParaDest-79"><a id="_idTextAnchor082"/>Summary</h1>
<p>In this chapter, we explored synthetic data and its evolution. We learned about the main types of synthetic data. In this chapter, we also discussed the key data augmentation techniques to enrich a limited real dataset for images, audio, and <span class="No-Break">textual data.</span></p>
<p>In the next chapter, we will bring to light how synthetic data is being used as a solution for problems such as privacy and data scarcity. Additionally, we will learn why it is better in terms of cost and why it is a revolutionary solution for rare and limited <span class="No-Break">real data.</span></p>
</div>
</div></body></html>