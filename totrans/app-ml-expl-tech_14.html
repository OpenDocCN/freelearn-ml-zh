<html><head></head><body>
		<div id="_idContainer184">
			<h1 id="_idParaDest-211"><em class="italic"><a id="_idTextAnchor217"/>Chapter 11</em>: End User-Centered Artificial Intelligence</h1>
			<p>Over the last 10 chapters of this book, we have traveled over the entire landscape of <strong class="bold">Explainable AI</strong> (<strong class="bold">XAI</strong>), covering different types of explainability methods used in practice for<a id="_idIndexMarker748"/> different dimensions of explainability (<em class="italic">data</em>, <em class="italic">model</em>, <em class="italic">outcome</em>, and the <em class="italic">end users</em>). XAI is an active field of research that I think is yet to reach its full potential. But the field is growing rapidly, along with the broader domain of AI, and we will witness many new algorithms, approaches, and tools being developed in the future. Most likely, the new methods and tools of XAI will be better than the existing ones and will be able to tackle some of the <em class="italic">open challenges of XAI</em> discussed in <a href="B18216_10_ePub.xhtml#_idTextAnchor209"><em class="italic">Chapter 10</em></a>, <em class="italic">XAI Industry Best Practices</em>. Unfortunately, we cannot extend the scope of this book to cover all possible approaches to XAI. However, the goal of this book is to provide a blend of conceptual understanding of the field with the required practical skills so that it is a useful starting point for beginners, and even add to the knowledge of experts for an applied knowledge of XAI. </p>
			<p>In the previous chapter, we discussed the recommended practices for implementing an explainable <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) system <a id="_idIndexMarker749"/>from the industry perspective. We also discussed the existing challenges of XAI and some recommended ways to mitigate the challenges. Considering these existing challenges, in this chapter, we will focus on the ideology <a id="_idIndexMarker750"/>of <strong class="bold">End User-Centered Artificial Intelligence</strong> (<strong class="bold">ENDURANCE</strong>). This is a term that is often used to refer to sustainable and scalable AI solutions that are built, keeping the user in the center. It is recommended that you read the previous chapter before starting this chapter for a better understanding. ENDURANCE is neither a new algorithm nor a new, sophisticated tool for XAI. Instead, it is a practice; it is a methodical discipline to bridge the AI-end user gaps. </p>
			<p>This chapter will be particularly useful for researchers from the field of AI and <strong class="bold">Human-Computer Interaction</strong> (<strong class="bold">HCI</strong>) who <a id="_idIndexMarker751"/>view XAI from a <em class="italic">multidisciplinary perspective</em>. It is also useful for business leaders who want to drive problem solving using AI, considering a seamless <strong class="bold">User Experience</strong> (<strong class="bold">UX</strong>). For<a id="_idIndexMarker752"/> AI developers and thought leaders, this chapter will help you to design your AI solutions keeping the end user in the center and promoting AI adoption. </p>
			<p>This chapter focuses on the following main topi<a id="_idTextAnchor218"/>cs: </p>
			<ul>
				<li>User-centered XAI/ML systems</li>
				<li>Rapid XAI prototyping using EUCA</li>
				<li>Efforts toward increasing user acceptance of AI/ML systems using XAI</li>
				<li>Providing delightful UX</li>
				<li>What's next in XAI?</li>
			</ul>
			<p>Let's proceed with the first topic of discussion in the next section.</p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor219"/>User-centered XAI/ML systems</h1>
			<p>For most<a id="_idIndexMarker753"/> industrial problems, AI solutions are developed in isolation and users are only introduced in the final stages of the development process after a minimum viable solution is ready. With this conventional approach, it is often found that product leads or product managers tend to focus on projecting the solution from the development team's perspective to meet the goals of the users. Well, this approach is absolutely fine, and it might work really well for certain use cases that require the technical team to develop through abstraction. However, if the users are not involved in the early stages of the implementation process, it has been often found that the users are reluctant to adopt the solution. So, the ENDURANCE ideology is focused on developing solutions by involving final users right from the design phase of the solution. </p>
			<p>The ENDURANCE ideology<a id="_idIndexMarker754"/> focuses on the principles of HCI and emphasizes the importance of <em class="italic">distributed cognition</em> of the user. With this ideology, the entire solution comprising the <strong class="bold">User Interface</strong> (<strong class="bold">UI</strong>), <em class="italic">AI algorithms</em>, <em class="italic">underlying dataset</em>, <em class="italic">XAI component</em>, and <em class="italic">end user's experience</em> is considered collectively as a <em class="italic">system</em>, rather than considering the individual components in isolation. This ensures that explainability is baked into the system instead of being offered as an add-on service for the user. From what I have observed, most industrial AI solutions are developed in isolation as a separate component and then added to the main software system as an <em class="italic">add-on</em> or <em class="italic">premium feature</em>. Similarly, the XAI component is also considered an add-on feature after being developed in isolation. Consequently, the seamless UX can get hampered, and the main benefits<a id="_idIndexMarker755"/> of the AI solution and the XAI component may not be realized to their full potential. This is why we should focus on the design and development of the entire user-centric XAI/ML system.</p>
			<p>Next, let's discuss the various aspects of end user-centric XAI that we should consider while designing the solution.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor220"/>Different aspects of end user-centric XAI</h2>
			<p>In this section, we <a id="_idIndexMarker756"/>will discuss the different principles of human factors that should be integrated while designing the XAI system using the ENDURANCE ideology for bridging the AI and end user gap.</p>
			<h3>Goal relevance</h3>
			<p>The primary <a id="_idIndexMarker757"/>questions that the field of HCI tries to address are <em class="italic">Who are the users?</em> and <em class="italic">What are their needs?</em> Or in other words, it tries to understand the <em class="italic">goal relevance</em> of the solution for the user. If the solution provided is not effectively solving the problem by meeting the needs of the users without introducing other challenges, it is not relevant. Not considering the goal relevance is probably one of the main reasons why the majority of AI solutions are either scrapped or adopted with a lot of skepticism. </p>
			<p>The recommended approach to evaluate goal relevance is by checking whether the users can achieve their goals without the introduction of other challenges. Along with goal relevance, I often recommend assessing the impact of the solution. The impact of the solution can be qualitatively measured by taking the user's feedback when the solution is absent. </p>
			<h3>Connecting the user needs with the strengths of AI</h3>
			<p>As discussed<a id="_idIndexMarker758"/> before, in most industrial use cases, XAI is used in isolation to provide explainability without considering the user needs. Instead, using the ideology of ENDURANCE, XAI should connect the user needs with the strength of the AI algorithm. Once the user needs are identified, <em class="italic">translate the user needs into data needs and model needs</em>. If the underlying dataset is not sufficient to meet all the user needs, use <strong class="bold">data-centric XAI</strong> to <a id="_idIndexMarker759"/>communicate the limitations of the dataset to the user. If the model needs are identified, use XAI to interpret the working of the model, and tune accordingly to meet the needs of the user.</p>
			<p>But this process <a id="_idIndexMarker760"/>can be challenging as it involves identifying the existing <em class="italic">mental model</em> of the user. With the introduction of AI and XAI, the existing workflow should not get disrupted. </p>
			<p>Moreover, it is also recommended that using XAI, you try to explain whether the AI solution is adding any unique value. But design the explainability methods to justify the advantages and not the underlying technology used. For example, if the system conveys to the user that complex deep learning algorithms are used to predict the outcome, it does not increase the confidence of the user. Instead, if the system conveys that the intelligent solution helps the user to reach their goal five times faster than the conventional approach, the user will agree to adopt the solution. </p>
			<h3>User interface â€“ a medium to connect users with the AI solution</h3>
			<p>Considering the <a id="_idIndexMarker761"/>conventional approaches, most AI practitioners are focused only on developing accurate AI models giving much less focus to the user's interaction with the model. Generally, the user's interaction with the AI component is decided by the software engineering teams; unfortunately, in most organizations, the data science and AI teams work in silos. But it is the UI that controls the level of visibility, explainability, or interpretability of the AI models and plays a vital role in influencing the user's trust in the system. </p>
			<p>In <a href="B18216_10_ePub.xhtml#_idTextAnchor209"><em class="italic">Chapter 10</em></a>, <em class="italic">XAI Industry Best Practices</em>, while discussing <strong class="bold">Interactive Machine Learning</strong> (<strong class="bold">IML</strong>), we <a id="_idIndexMarker762"/>discussed how the user's interaction with the system through the UI gives more confidence to the user about the working of the AI/ML system. Hence, the UI should be in alignment with the AI model and its explainability methods to calibrate the user's trust. You can find out more about <a id="_idIndexMarker763"/>calibrating the user's trust using the UI in the People + AI Guidebook from Google PAIR: <a href="https://pair.withgoogle.com/chapter/explainability-trust/">https://pair.withgoogle.com/chapter/explainability-trust/</a>.</p>
			<h3>Involvement of the end user early in the development process of the solution</h3>
			<p>Unlike <a id="_idIndexMarker764"/>conventional approaches, the user-centric approach recommends involving the final user(s) early in the development process. The end user should in fact be involved from the design phase of the UI of the system, so that the needs of the user are correctly mapped into the interface. Similar to the design and development life cycle of the solution, explainability should also be evolved in an iterative process by taking continuous feedback from the user. </p>
			<p>As the ENDURANCE ideology views the XAI/ML system as one solution, the entire solution should have a <em class="italic">design phase</em>, <em class="italic">prototype phase</em>, <em class="italic">development phase</em>, and <em class="italic">evaluation phase</em>. These four phases would collectively form <em class="italic">one iteration of design and development</em>. Likewise, the entire solution should be matured in several iterations, keeping the user involved in every single phase of each iteration. This process is also in alignment with the <em class="italic">agile methodology</em> followed in software engineering. Involvement of the user in every phase ensures that useful feedback is collected for evaluating whether the user's needs are being met by the solution. Early involvement also ensures that the users are familiar with the design and working of the new system. Users' familiarity with the system increases the adoption rate of the system.</p>
			<h3>Connecting feedback with personalization</h3>
			<p>As <a id="_idIndexMarker765"/>discussed in the previous section, the importance of the user's feedback in every phase of the design and development of the solution is inevitable. But sometimes, a general framework of a solution doesn't fulfill all needs of the user. </p>
			<p>For example, when using counterfactual examples, it is technically possible to generate an example using all the features used for the prediction. But suppose the user is only interested in changing a specific set of actionable variables. In that case, the controlled counterfactuals should modify only the features that are interesting to the user. It has been found that a tailor-made personalized solution is often more useful to the end user than a generalized solution. So, using the feedback obtained from the user, try to provide a personalized solution meeting the specific pain points of the user.</p>
			<h3>Contextual and actionable AI</h3>
			<p>As we previously discussed in <a href="B18216_10_ePub.xhtml#_idTextAnchor209"><em class="italic">Chapter 10</em></a>, <em class="italic">XAI Industry Best Practices</em>, explanations should be contextual <a id="_idIndexMarker766"/>and actionable. The entire XAI/ML system should also be in alignment with the user's actions and should have context awareness. XAI plays a vital role in connecting AI to the user's action and modifying any AI<a id="_idIndexMarker767"/> solution into a contextual AI solution. </p>
			<p><em class="italic">Oliver Brdiczka</em>, in his article <em class="italic">Contextual AI: The Next Frontier of Artif<a id="_idTextAnchor221"/>icial Intelligence</em> (<a href="https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence">https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence</a>), defined<a id="_idIndexMarker768"/> the following<a id="_idIndexMarker769"/> four pillars of contextual AI:</p>
			<ul>
				<li><strong class="bold">Intelligible</strong>: Contextual AI <a id="_idIndexMarker770"/>systems should be able to explain its knowledge and working.</li>
				<li><strong class="bold">Adaptive</strong>: Contextual<a id="_idIndexMarker771"/> AI systems should be able to adapt to the different needs of the user in a different environment.</li>
				<li><strong class="bold">Customizable</strong>: The<a id="_idIndexMarker772"/> users should be able to control or modify the system to meet their needs.</li>
				<li><strong class="bold">Context-aware</strong>: The system<a id="_idIndexMarker773"/> should be able to perceive things at the same level as a human.</li>
			</ul>
			<p>The following figure shows the four different <a id="_idIndexMarker774"/>components of contextual AI:</p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="image/B18216_11_001.jpg" alt="Figure 11.1 â€“ Four components of contextual AI (inspired by https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence) &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.1 â€“ Four components of contextual AI (inspired by https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence) </p>
			<p>So, considering <a id="_idIndexMarker775"/>user-centric approaches, the <a id="_idIndexMarker776"/>XAI component of XAI/ML systems should provide actionable insights and it should be contextual to further bridge the gap between AI and end users. Now that we have discussed the user-centric approaches to bridge possible gaps between AI and end users, considering the open challenges of XAI discussed in <a href="B18216_10_ePub.xhtml#_idTextAnchor209"><em class="italic">Chapter 10</em></a>, <em class="italic">XAI Industry Best Practices</em>, let's discuss making rapid XAI prototypes <a id="_idIndexMarker777"/>using the <strong class="bold">End User-Centric Explainable Artificial Intelligence</strong> (<strong class="bold">EUCA</strong>) framework.</p>
			<h1 id="_idParaDest-214"><a id="_idTextAnchor222"/>Rapid XAI prototyping using EUCA</h1>
			<p>In the previous<a id="_idIndexMarker778"/> section, we discussed the key ingredients of a user-centered XAI/ML system. In this section, the importance of rapid prototyping<a id="_idIndexMarker779"/> in the ENDURANCE ideology will be emphasized. <em class="italic">Rapid prototyping</em> is a concept that is predominantly adopted in software engineering as software is probably the most malleable thing created by mankind. Building fast prototypes is an approach for collecting useful user feedback early in the development process of a software product. Hence, even for designing user-centered XAI/ML systems, rapid prototyping is very important.</p>
			<p><em class="italic">Jin et al.</em>, in their research work <em class="italic">EUCA: the End-User-Centered Explainable AI Framework</em> (<a href="https://arxiv.org/abs/2102.02437">https://arxiv.org/abs/2102.02437</a>), introduced a toolkit called EUCA. EUCA is a very <a id="_idIndexMarker780"/>interesting framework primarily designed by UX researchers, HCI researchers and designers, AI scientists, and developers for <a id="_idIndexMarker781"/>building rapid XAI prototypes<a id="_idIndexMarker782"/> for non-technical end users. The official GitHub repository for the EUCA framework is available at <a href="https://github.com/weinajin/end-user-xai">https://github.com/weinajin/end-user-xai</a>. It is strongly recommended to use EUCA to build low-fidelity prototypes and iteratively improve the prototype based on continuous user feedback for XAI/ML systems.</p>
			<p>The following important<a id="_idIndexMarker783"/> components are offered by this framework:</p>
			<ul>
				<li>12 explanatory forms for designing human-friendly explanations</li>
				<li>Corresponding XAI algorithms for integrating with functional prototypes</li>
				<li>Associated design templates and examples of their usage</li>
				<li>Suggested prototyping workflows</li>
				<li>Detailed strengths and weaknesses of various explanation methods obtained from their user study findings</li>
				<li>Scientific analysis of diverse explanation needs of end users (such as calibration of trust, detection of bias, and resolution of disagreements with AI)</li>
			</ul>
			<p>The following figure illustrates the different types <a id="_idIndexMarker784"/>of explanation methods currently supported by the EUCA framework:</p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="image/B18216_11_002.jpg" alt="Figure 11.2 â€“ Different types of explanation methods supported in EUCA &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.2 â€“ Different types of explanation methods supported in EUCA </p>
			<p>This <a id="_idIndexMarker785"/>framework is a great starting point and definitely recommended <a id="_idIndexMarker786"/>for building rapid XAI prototypes. Next, let's discuss some additional efforts that can be made to increase user acceptance of AI/ML systems. </p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor223"/>Efforts toward increasing user acceptance of AI/ML systems using XAI</h1>
			<p>In this section, we<a id="_idIndexMarker787"/> will discuss <a id="_idIndexMarker788"/>some recommended practices to increase the acceptance of AI/ML systems using XAI. In most software systems, the <strong class="bold">User Acceptance Testing </strong>(<strong class="bold">UAT</strong>) phase is used to determine the <em class="italic">go</em> or <em class="italic">no-go</em> for software. Similarly, before<a id="_idIndexMarker789"/> the final production phase, more and more organizations prefer doing a robust UAT process for AI/ML systems. But <em class="italic">how important is the explainability of AI algorithms, when doing UAT of AI/ML systems?</em> <em class="italic">Can explainability increase the user acceptance of AI?</em> The short answer is <em class="italic">yes</em>! Let's go<a id="_idIndexMarker790"/> through the following points to understand why:</p>
			<ul>
				<li><strong class="bold">User acceptance is a testimony of the user's trust</strong> â€“ Since XAI can increase the user's trust in AI, it increases the chance of the user's acceptance of the solution. Now, trust is something that cannot just be established during the UAT phase; rather, trust should be established from the beginning and maintained throughout the development process. The capabilities and limitations of the system should be communicated from the beginning to set a clear expectation of what is possible and what is not possible.Â Â </li>
				<li><strong class="bold">Risk tolerance estimation as UAT criteria</strong> â€“ It is quite obvious that AI systems cannot be 100% accurate every single time. It is not practically possible to achieve systems that have zero error or zero failure. But as a recommended practice, it is important to document the possible failure points for the system and the consequences of the potential failures of the system are termed <strong class="bold">risk</strong>. <strong class="bold">Risk tolerance</strong> is the <a id="_idIndexMarker791"/>maximum permissible error that the system can make without causing a huge impact. So, during the UAT phase, it is important to define the risks of the solution and have an estimation of the maximum risk tolerance of the user. The system's ability to perform within the risk tolerance should be considered a success criterion for the UAT process.</li>
				<li><strong class="bold">Perform as many user studies as possible before the UAT process</strong> â€“ User studies and qualitative and quantitative analysis of the user's feedback are certain ways by which the impact and trust of the system can be assessed. So, perform multiple <a id="_idIndexMarker792"/>user studies <a id="_idIndexMarker793"/>before the UAT process and ensure that the users are accepting the prototype solutions before directly moving the system into production.</li>
			</ul>
			<p>The preceding <a id="_idIndexMarker794"/>approaches are certain ways to increase user acceptance, but ultimately, user acceptance depends on the overall UX. In the next section, we will discuss further the importance of providing a delightful UX.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor224"/>Providing a delightful UX</h1>
			<p>In this section, we will focus on the importance of overall UX to promote the adoption of XAI/ML systems. <em class="italic">Aaron Walter</em>, in his book <em class="italic">Designing for Emotion</em> (<a href="https://abookapart.com/products/designing-for-emotion">https://abookapart.com/products/designing-for-emotion</a>), mentioned some of the foundational<a id="_idIndexMarker795"/> elements of user needs that must be met before higher motivation can influence the behavior of the user. According to his hierarchy of user needs, <em class="italic">pleasurable</em> or <em class="italic">delightful</em> UX is at the top of the pyramid. The following figure shows Aaron Walter's hierarchy of user needs:</p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="image/B18216_11_003.jpg" alt="Figure 11.3 â€“ Aaron Walter's hierarchy of user needs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 11.3 â€“ Aaron Walter's hierarchy of user needs</p>
			<p>This hierarchy of user needs defines the fundamental needs of the end user that should be fulfilled before any advanced needs of the user are addressed. So, if a system is only <em class="italic">functional</em>, <em class="italic">reliable</em>, and <em class="italic">usable</em>, it is not sufficient for adopting the system unless the overall UX is delightful and enjoyable! Hence, XAI/ML systems should also consider providing a seamless <a id="_idIndexMarker796"/>overall experience to truly bridge the AI-end user gap.Â Â </p>
			<p>This brings us to the end of the last chapter of this book. We will summarize the key topics of discussion in the next section.</p>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor225"/>Summary</h1>
			<p>In this chapter, we have primarily discussed using the ideology of ENDURANCE for the design and development of XAI/ML systems. We have discussed the importance of using XAI to steer us toward the main goals of the end user for building XAI/ML systems. Using some of the principles and recommended best practices presented in the chapter, we can bridge the gap between AI and the end user to a great extent! </p>
			<p>This also brings us to the end of this book! Congratulations on reaching the end! This book was carefully designed to include conceptual understanding of various XAI concepts and jargon, practical examples to use popular XAI frameworks for applied problem solving, real-life examples and experiences from an industrial perspective, and references to important research literature to further expand your knowledge. This book introduced you to the field of XAI from both the industrial perspective as well as an academic research perspective. The open challenges and the next phases of XAI research topics discussed in this book are important research problems that are being explored by the AI research community. </p>
			<p>Even though this book touched on almost every aspect of the field of XAI, clearly there are lots more to explore and unravel. My recommendation is not to restrict yourself to what was offered by this book. Instead, use this book as a reference starting point but explore and apply the knowledge gained from this book to practical use cases and step forward to contribute to the community! </p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor226"/>References</h1>
			<p>Please refer to the following resources to gain additional information:</p>
			<ul>
				<li><em class="italic">People + AI Guidebook from Google PAIR</em>: <a href="https://pair.withgoogle.com/chapter/explainability-trust/">https://pair.withgoogle.com/chapter/explainability-trust/</a></li>
				<li><em class="italic">Jin et al.</em>, <em class="italic">EUCA: the End-User-Centered Explainable AI Framework</em>: <a href="https://arxiv.org/abs/2102.02437">https://arxiv.org/abs/2102.02437</a></li>
				<li><em class="italic">EUCA: End-User-Centered Explainable AI Framework GitHub repository</em>: <a href="https://github.com/weinajin/end-user-xai">https://github.com/weinajin/end-user-xai</a></li>
				<li><em class="italic">Aaron Walter</em>, <em class="italic">Designing for Emotion</em>: <a href="https://abookapart.com/products/designing-for-emotion">https://abookapart.com/products/designing-for-emotion</a></li>
				<li><em class="italic">Oliver Brdiczka</em>, <em class="italic">Contextual AI: The Next Frontier of Artificial Intelligence</em>:<em class="italic">Â </em><a href="https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence">https://business.adobe.com/blog/perspectives/contextual-ai-the-next-frontier-of-artificial-intelligence</a></li>
			</ul>
		</div>
	</body></html>