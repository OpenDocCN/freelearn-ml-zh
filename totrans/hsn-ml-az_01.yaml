- en: AI Cloud Foundations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI云基础
- en: Today, every organization aspires to be a leader in adopting the latest technological advancements.
    The success of such adoption in recent years has been achieved by leveraging the
    data landscape surrounding businesses. In this chapter, we will talk about how
    AI can be leveraged using Microsoft's Azure platform to derive business value
    from that data landscape. Azure offers several hundred services, and choosing
    the right service is challenging. In this chapter, we will give a high-level overview
    of the choices a data scientist, developer, or data engineer has for building
    and deploying AI solutions for their organization. We will start with a decision
    tree that can guide technology choices so that you understand which ...
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，每个组织都渴望成为采用最新技术进步的领导者。近年来，这种采用的成功是通过利用企业周围的数据景观实现的。在本章中，我们将讨论如何利用微软的Azure平台从数据景观中提取业务价值。Azure提供数百项服务，选择正确的服务具有挑战性。在本章中，我们将提供一个高层次概述，介绍数据科学家、开发人员或数据工程师为构建和部署其组织的AI解决方案所面临的选项。我们将从一个决策树开始，它可以指导技术选择，以便您了解应该选择哪些... '
- en: The importance of artificial intelligence
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的重要性
- en: '**Artificial intelligence** (**AI**) is ever-increasingly being interwoven
    into the complex fabric of our technology-driven lives. Whether we realize it
    or not, AI is becoming an enabler for us to accomplish our day-to-day tasks more
    efficiently than we''ve ever done before. Personal assistants such as Siri, Cortana,
    and Alexa are some of the most visible AI tools that we come across frequently.
    Less obvious AI tools are ones such as those used by rideshare firms that suggest
    drivers move to a high-density area, and adjust prices dynamically based on demand.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）正日益融入我们技术驱动的复杂生活之中。无论我们是否意识到，人工智能正在成为我们更高效完成日常任务的推动者。个人助理如Siri、Cortana和Alexa是我们经常遇到的最为明显的AI工具。不那么明显的AI工具包括那些由共享出行公司使用的工具，它们建议司机移动到高密度区域，并根据需求动态调整价格。'
- en: Across the world, there are organizations at different stages of the AI journey.
    To some organizations, AI is the core of their business model. In other organizations,
    they see the potential of leveraging AI to compete and innovate their business.
    Successful organizations recognize that digital transformation through AI is key
    to their survival over the long term. Sometimes, this involves changing an organization's
    business model to incorporate AI through new technologies such as the **Internet
    of Things** (**IoT**). Across this spectrum of AI maturity, organizations face
    challenges implementing AI solutions. Challenges are typically related to scalability,
    algorithms, libraries, accuracy, retraining, pipelines, integration with other
    systems, and so on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在全球范围内，有各种处于AI旅程不同阶段的组织。对于某些组织来说，AI是其商业模式的核心。在其他组织中，他们看到了利用AI来竞争和创新业务的潜力。成功的组织认识到，通过AI实现的数字化转型是他们长期生存的关键。有时，这可能涉及通过新技术如**物联网**（**IoT**）改变组织的商业模式来融入AI。在这一AI成熟度的范围内，组织在实施AI解决方案时面临挑战。这些挑战通常与可扩展性、算法、库、准确性、再培训、管道、与其他系统的集成等相关。
- en: 'The field of AI has been around for several decades now, but it''s growth and
    adoption over the last decade has been tremendous. This can be attributed to three
    main drivers: large data, large compute, and enhanced algorithms. The growth in
    data stems mostly from entities that generate data, or from human interactions
    with those entities. The growth in compute can be attributed to improved chip
    design, as well as innovative compute technologies. Algorithms have improved partly
    due to the open source community and partly due to the availability of larger
    data and compute.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域已经存在了几十年，但过去十年其增长和采用率却非常显著。这主要归因于三个主要驱动力：大量数据、大量计算和改进的算法。数据增长主要来自产生数据的实体，或来自人类与这些实体的互动。计算能力的增长可以归因于芯片设计的改进，以及创新计算技术的应用。算法的改进部分得益于开源社区，部分得益于更大数据集和计算能力的可用性。
- en: The emergence of the cloud
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云的出现
- en: Developing AI solutions in the cloud helps organizations leapfrog their innovation,
    in addition to alleviating the challenges described here. One of the first steps
    is to bring all the data close together or in the same tool for easy retrieval.
    The cloud is the most optimal landing zone that meets this requirement. The cloud
    provides near-infinite storage, easy access to other data sources, and on-demand
    compute. Solutions that are built on the cloud are easier to maintain and update,
    due to there being a single pane of control. The availability of improved or customized
    hardware at the click of a button was unthinkable a few years back.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中开发人工智能解决方案有助于组织跨越其创新，同时缓解这里描述的挑战。第一步之一是将所有数据集中在一起或放在同一个工具中，以便于检索。云是最符合这一要求的最佳着陆区。云提供了几乎无限的存储、轻松访问其他数据源和按需计算。由于有一个统一的控制面板，建立在云上的解决方案更容易维护和更新。只需点击一下按钮即可获得改进或定制的硬件，这在几年前是想都不敢想的。
- en: Innovation in the cloud is so rapid that developers can build a large variety
    ...
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 云中的创新如此迅速，以至于开发者可以构建一个大型多样化...
- en: Essential cloud components for AI
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的云关键组件
- en: 'Any cloud AI solution will have different components, all modular, individually
    elastic, and integrated with each other. A broad framework for cloud AI is depicted
    in the following diagram. At the very base is **Storage**, which is separate from
    **Compute**. This separation of **Storage** and **Compute** is one of the key
    benefits of the cloud, which permits the user to scale one separate from the other.
    **Storage** itself may be tiered based on throughput, availability, and other
    features. Until a few years back, the **Compute** options were limited to the
    speed and generation of the underlying CPU chips. Now, we have options for GPU
    and **FPGA** (short- for **field-programmable gate array**) chips as well. Leveraging
    **Storage** and **Compute**, various services are built on the cloud fabric, which
    makes it easier to use ingest data, transform it, and build models. Services based
    on **Relational Databases**, **NoSQL**, **Hadoop**, **Spark**, and **Microservices**
    are some of the most frequent ones used to build AI solutions:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 任何云人工智能解决方案都将包含不同的组件，所有组件都是模块化的、各自弹性的，并且相互集成。以下图表展示了云人工智能的广泛框架。在最底层是**存储**，它与**计算**是分开的。这种**存储**和**计算**的分离是云的关键优势之一，它允许用户独立扩展。**存储**本身可以根据吞吐量、可用性和其他特性进行分层。直到几年前，**计算**选项仅限于底层CPU芯片的速度和代数。现在，我们还有GPU和**FPGA**（现场可编程门阵列）芯片的选项。利用**存储**和**计算**，各种服务建立在云基础设施上，这使得使用摄取数据、转换数据和构建模型变得更加容易。基于**关系数据库**、**NoSQL**、**Hadoop**、**Spark**和**微服务**的服务是一些最常用于构建人工智能解决方案的服务：
- en: '![](img/c5a2a935-adcf-4ff4-8826-5b49bf706d02.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c5a2a935-adcf-4ff4-8826-5b49bf706d02.png)'
- en: Essential building blocks of cloud AI
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 云人工智能的基本构建块
- en: At the highest level of complexity are the various AI-focused services that
    are available on the cloud. These services fall on a spectrum with fully customizable
    solutions at one end, and easy-to-build solutions at the other. **Custom AI**
    is typically a solution that allows the user to bring in their own libraries or
    use proprietary ones to build an end-to-end solution. This typically involves
    a lot of hands-on coding and gives the builder complete control over different
    parts of the solution. **Pre-Built AI** is typically in the form of APIs that
    expose some type of service that can be easily incorporated into your solution.
    Examples of these include custom vision, text, and language-based AI solutions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高复杂度级别上，云上提供了各种专注于人工智能的服务。这些服务覆盖了一个光谱，一端是完全可定制的解决方案，另一端是易于构建的解决方案。**定制人工智能**通常是一种允许用户引入自己的库或使用专有库来构建端到端解决方案的解决方案。这通常涉及大量的实际编码，并赋予构建者对解决方案不同部分的完全控制权。**预构建人工智能**通常以API的形式存在，这些API暴露了一些可以轻松集成到您解决方案中的服务。这些服务的例子包括定制视觉、文本和基于语言的AI解决方案。
- en: However complex the underlying AI may be, the goal of most applications is to
    make the end user experience as seamless as possible. This means that AI solutions
    need to integrate with general applications that reside in the organization solution
    stack. A lot of solutions use **Dashboards** or reports in the traditional BI
    space. These interfaces allow the user to explore the data generated by the AI
    solution. **Conversational Apps** are usually in the form of an intelligent interface
    (such as a bot) that interacts with the user in a conversational mode.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 无论底层AI多么复杂，大多数应用的目标都是尽可能使最终用户的使用体验无缝。这意味着AI解决方案需要与组织解决方案堆栈中的通用应用程序集成。许多解决方案使用**仪表板**或传统BI空间中的报告。这些界面允许用户探索AI解决方案生成数据。**对话式应用**通常以智能界面（如机器人）的形式出现，以对话模式与用户互动。
- en: The Microsoft cloud – Azure
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微软云 - Azure
- en: Microsoft's mission is been to empower every person and organization on Earth
    to achieve more. Microsoft Azure is a cloud platform designed to help customers
    achieve the intelligent cloud and the intelligent edge. Their vision is to help
    customers infuse AI into every application, both in the cloud and on compute devices
    of all form factors. With this in mind, Microsoft has developed a wide set of
    tools that can help its customer build AI into their applications with ease.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的使命是让地球上每个人和组织都能实现更多。Microsoft Azure是一个云平台，旨在帮助客户实现智能云和智能边缘。他们的愿景是帮助客户将AI融入每个应用程序，无论是在云中还是在各种形态的计算设备上。考虑到这一点，微软开发了一套广泛的工具，可以帮助客户轻松地将AI集成到他们的应用程序中。
- en: The following table shows the different tools that can be used to develop end-to-end
    AI solutions with Azure. The Azure Service column indicates those services that
    are owned and managed by Microsoft (first-party services). The Azure Marketplace
    ...
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了可用于使用Azure开发端到端AI解决方案的不同工具。Azure服务列指示由微软拥有和管理的服务（第一方服务）。Azure市场...
- en: Choosing AI tools on Azure
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure上选择AI工具
- en: In this book, we will assume that the you have knowledge and experience of AI
    in general. The goal here is not to touch on the basics of the various kinds of
    AI or to choose the correct algorithm; we assume you have a good understanding
    of what algorithms to choose in order to solve a given business need.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们假设您对AI有一般的知识和经验。这里的目的是不涉及各种AI类型的基础知识或选择正确的算法；我们假设您对解决特定商业需求时应选择哪种算法有很好的理解。
- en: 'The following diagram shows a decision tree that can help you choose the right
    Azure AI tools. It is not meant to be comprehensive; just a guide to the correct
    technology choices. There are a lot of options that cross over, and this was difficult
    to depict on this diagram. Also keep in mind that an efficient AI solution would
    leverage multiple tools in combination:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了一个决策树，可以帮助您选择正确的Azure AI工具。它并非旨在全面覆盖；仅作为正确技术选择的指南。有许多选项相互交叉，这在图表上难以完全展示。同时，请记住，一个高效的AI解决方案会结合使用多个工具：
- en: '![](img/7f0ac8d5-6588-44ad-a45a-6e3c8c4ed4fd.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7f0ac8d5-6588-44ad-a45a-6e3c8c4ed4fd.png)'
- en: Decision tree guide to choosing AI tools on Azure
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Azure上选择AI工具的决策树指南
- en: The preceding diagram shows a decision tree that helps users of **Microsoft's
    AI platform**. Starting from the top, the first question is whether you would
    like to **Build your own models or consume pre-trained models**. If you are building
    your own models, then it involves data scientists, data engineers, and developers
    at various stages of the process. In some use cases, developers prefer to just
    **consume pre-trained models**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上一图表展示了一个决策树，帮助**微软AI平台**的用户。从顶部开始，第一个问题是您是否希望**自己构建模型或使用预训练模型**。如果您正在构建自己的模型，那么它涉及到数据科学家、数据工程师和开发者在各个阶段的工作。在某些用例中，开发者更愿意只是**使用预训练模型**。
- en: Cognitive Services/bots
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认知服务/机器人
- en: Developers who would like to consume pre-trained AI models, typically use one
    of Microsoft's Cognitive Services. For those who are building conversational applications,
    a combination of Bot Framework and Cognitive Services is the recommended path.
    We will go into the details of Cognitive Services in [Chapter 3](89299379-0f5e-4602-ad78-9d3d46a0710e.xhtml), *Cognitive
    Services*, and [Chapter 4](08fa36ee-b325-4c6c-b5f5-f41c03d056c3.xhtml), *Bot Framework*,
    but it is important to understand when to choose Cognitive Services.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 想要使用预训练 AI 模型的开发者通常会使用微软的认知服务。对于正在构建对话应用的人来说，结合 Bot Framework 和认知服务是推荐的方法。我们将在第
    3 章“认知服务”和第 4 章“Bot Framework”中详细介绍认知服务，但了解何时选择认知服务是很重要的。
- en: Cognitive Services were built with the goal of giving developers the tools to
    rapidly build and deploy AI applications. Cognitive Services are pre-trained,
    customizable AI models that are exposed via APIs with accompanying SDKs and web
    services. They perform certain tasks, and are designed to ...
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 认知服务是为了给开发者提供快速构建和部署 AI 应用的工具而构建的。认知服务是预训练的、可定制的 AI 模型，通过 API、配套的 SDK 和网络服务进行暴露。它们执行某些任务，并设计为
    ...
- en: Azure Machine Learning Studio
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 机器学习工作室
- en: '**Azure Machine Learning** (**Azure ML**) Studio is the primary tool, purely
    a web-based GUI, to help build **machine learning** (**ML**) models. AzureML Studio
    is an almost code-free environment that allows the user to build end-to-end ML
    solutions. It has Microsoft Research''s proprietary algorithms built in, which
    can do most machine learning tasks with real simplicity. It can also embed Python
    or R code to enhance its functionality. One of the greatest features of Azure ML
    Studio is the ability to create a web service in a single click. The web service
    is exposed in the form of a REST endpoint that applications can send data to.
    In addition to the web service, an Excel spreadsheet is also created, which accesses
    the same web service and can be used to test the model''s functionality and share
    it easily with end users.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure 机器学习**（**Azure ML**）工作室是主要的工具，纯粹是基于网页的 GUI，用于帮助构建 **机器学习**（**ML**）模型。AzureML
    Studio 是一个几乎无需代码的环境，允许用户构建端到端的 ML 解决方案。它内置了微软研究部门的专有算法，可以以极大的简单性完成大多数机器学习任务。它还可以嵌入
    Python 或 R 代码以增强其功能。Azure ML Studio 的一个最伟大的功能是能够一键创建网络服务。该网络服务以 REST 端点形式暴露，应用程序可以向其发送数据。除了网络服务之外，还会创建一个
    Excel 电子表格，它访问相同的网络服务，可以用来测试模型的功能，并方便地与最终用户共享。'
- en: At time of writing, the primary limitation with Azure ML Studio is the 10 GB
    limit on an experiment container. This limit will be explained in detail in [Chapter
    6](f6d8b2f5-a038-41fe-892f-4720ef071fd9.xhtml), *Scalable Computing for Data Science*,
    but for now, it is sufficient to understand that Azure ML Studio is well-suited
    to training datasets that are in the 2 GB to 5 GB range. In addition, there are
    also limits to the amount of R and Python code that you can include in ML Studio,
    and its performance, which will be discussed in detail later.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Azure ML Studio 的主要限制是实验容器的大小限制为 10 GB。这个限制将在第 6 章“数据科学的可扩展计算”中详细解释，但就目前而言，了解
    Azure ML Studio 非常适合训练 2 GB 到 5 GB 范围内的数据集就足够了。此外，ML Studio 中可以包含的 R 和 Python
    代码的数量以及其性能也有限制，这些将在稍后详细讨论。
- en: ML Server
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML 服务器
- en: For a code-first experience, there are multiple tools available in the Microsoft
    portfolio. If organizations are looking to deploy on-premises (in addition to
    the cloud), the only option available is **Machine Learning Server** (**ML Server**).
    ML Server is an enterprise platform that supports both R and Python applications.
    It supports all the activities involved in the ML process end-to-end. ML Server
    was previously known as **R Server** and came about through Microsoft's acquisition
    of revolution analytics. Later, Python support was added to handle the variety
    of user preferences.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于希望以代码优先的体验，微软的套件中提供了多个工具。如果组织希望在本地上部署（除了云之外），唯一可用的选项是**机器学习服务器**（**ML Server**）。ML
    Server 是一个企业级平台，支持 R 和 Python 应用程序。它支持 ML 过程中的所有活动。ML Server 之前被称为 **R Server**，是通过微软收购
    Revolution Analytics 而产生的。后来，为了满足各种用户偏好，增加了对 Python 的支持。
- en: In ML Server, users can use any of the open source libraries as part of their
    solution. The challenge with a lot of the open source tooling is that it takes
    a ...
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ML Server 中，用户可以使用任何开源库作为他们解决方案的一部分。许多开源工具的挑战在于它们需要 ...
- en: Azure ML Services
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure ML 服务
- en: Azure ML Services is a relatively new service on Azure that enhances productivity
    in the process of building AI solutions. Azure ML Services has different components.
    On the user's end, Azure ML Workbench is a tool that allows users to pull in data,
    transform it, build models, and run them against various kinds of compute. Workbench
    is a tool that users run on their local machines and connect to Azure ML services.
    Azure ML Services itself runs on Azure and consists of experimentation and model
    management for ML. The experimentation service keeps track of model testing, performance,
    and any other metrics you would like to track while building a model. The model
    management service helps manage the deployment of models and manages the overall
    life cycle of multiple models built by individual users or large teams.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML 服务是 Azure 上相对较新的服务，它增强了构建 AI 解决方案过程中的生产力。Azure ML 服务具有不同的组件。在用户端，Azure
    ML Workbench 是一个工具，允许用户拉取数据，对其进行转换，构建模型，并在各种类型的计算上运行它们。Workbench 是用户在其本地机器上运行的工具，并连接到
    Azure ML 服务。Azure ML 服务本身运行在 Azure 上，包括实验和模型管理。实验服务跟踪模型测试、性能以及您在构建模型时希望跟踪的任何其他指标。模型管理服务帮助管理模型的部署，并管理由个人用户或大型团队构建的多个模型的整体生命周期。
- en: When leveraging Azure ML Services, there are multiple endpoints that can act
    as engines for the services. At the time of writing, only Python-based endpoints
    are supported. SQL Server, with the introduction of built-in Python services,
    can act as an endpoint. This is beneficial, especially if the user has most of
    the data in SQL tables and wants to minimize data movement.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当利用 Azure ML 服务时，有多个端点可以作为服务的引擎。在撰写本文时，仅支持基于 Python 的端点。随着内置 Python 服务的引入，SQL
    Server 可以作为端点。这特别有益，尤其是如果用户的大部分数据都在 SQL 表中，并且希望最小化数据移动。
- en: If you have leveraged Spark libraries for ML at scale on ML Services, then you
    can deploy to Spark-based solutions on Azure. Currently, these can be either Spark
    on HDInsight, or any other native implementation of Apache Spark (Cloudera, Hortonworks,
    and so on).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经在 ML 服务上利用了用于大规模机器学习的 Spark 库，则可以将它们部署到 Azure 上的基于 Spark 的解决方案。目前，这些可以是
    HDInsight 上的 Spark 或任何其他 Apache Spark 的原生实现（Cloudera、Hortonworks 等）。
- en: If the user has leveraged other Hadoop-based libraries to build ML Services,
    then those can be deployed to HDInsight or any of the Apache Hadoop implementations
    available on Azure.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户已经利用其他基于 Hadoop 的库来构建 ML 服务，则可以将这些库部署到 HDInsight 或 Azure 上可用的任何 Apache Hadoop
    实现。
- en: Azure Batch is a service that provides large-scale, on-demand compute for applications
    that require such resources on an ad hoc or scheduled basis. The typical workflow
    for this use case involves the creation of a VM cluster, followed by the submission
    of jobs to the cluster. After the job is completed, the cluster is destroyed,
    and users do not pay for any compute afterward.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Batch 是一种提供大规模、按需计算的服务，适用于那些需要临时或按计划使用此类资源的应用程序。此用例的典型工作流程包括创建一个虚拟机集群，然后向集群提交作业。作业完成后，集群将被销毁，用户之后不再为任何计算付费。
- en: The **Data Science Virtual Machine** (**DSVM**) is a highly customized VM template
    built on either Linux or Windows. It comes pre-installed with a huge variety of
    curated data science tools and libraries. All the tools and libraries are configured
    to work straight out of the box with minimal effort. The DSVM has multiple applications,
    which we will cover in [Chapter 7](b88febb4-e8e4-4a08-9f62-5495654f3842.xhtml),
    *Machine Learning Server*, including utilization as a base image VM for Azure
    Batch.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据科学虚拟机**（**DSVM**）是基于 Linux 或 Windows 的高度定制 VM 模板。它预装了大量的精选数据科学工具和库。所有工具和库都配置为无需额外努力即可直接使用。DSVM
    有多种应用，我们将在第 7 章“机器学习服务器”中介绍，包括作为 Azure Batch 的基础镜像 VM 的使用。'
- en: One of the most highly scalable targets for running models built by Azure ML
    Services is to leverage containers through Docker and orchestration via Kubernetes.
    This is made easier by leveraging **Azure Kubernetes Services** (**AKS**). Azure ML
    Services creates a Docker image that helps operationalize an ML model. The model
    itself is deployed as containerized Docker-based web services, while leveraging
    frameworks such as TensorFlow, and Spark. Applications can access this web service
    as a REST API. The web services can be scaled up and down by leveraging the scaling
    features of Kubernetes. More details on this topic will be covered in [Chapter
    10](3196eb4a-070f-4b7b-9e15-f8cdc23398f8.xhtml), *Building Deep Learning Solutions*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML服务构建的模型最具有高度可扩展性的目标之一是利用Docker容器化和通过Kubernetes进行编排。通过利用**Azure Kubernetes服务**（**AKS**）可以简化这一过程。Azure
    ML服务创建了一个Docker镜像，有助于将机器学习模型投入运营。该模型本身作为基于Docker的容器化Web服务进行部署，同时利用TensorFlow和Spark等框架。应用程序可以通过REST
    API访问这个Web服务。可以通过利用Kubernetes的扩展功能来增加或减少Web服务的规模。关于这个主题的更多细节将在[第10章](3196eb4a-070f-4b7b-9e15-f8cdc23398f8.xhtml)“构建深度学习解决方案”中介绍。
- en: The challenge with Azure ML Services is that it currently only supports Python.
    The platform itself has gone through some changes, and the heavy reliance on the
    command-line interface makes the interface not as user-friendly as some other
    tools.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML服务的挑战在于它目前仅支持Python。该平台本身经历了一些变化，对命令行界面的重度依赖使得界面不如一些其他工具用户友好。
- en: Azure Databricks
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Databricks
- en: Azure Databricks is one of the newest additions to the tools that can be used
    to build custom AI solutions on Azure. It is based on Apache Spark, but is optimized
    for use on the Azure platform. The Spark engine can be accessed by various APIs
    that can be based on Scala, Python, R, SQL, or Java. To leverage the scalability
    of Spark, users need to leverage Spark libraries when dealing with data objects
    and their transformations. Azure Databricks leverages these scalable libraries
    on top of highly elastic and scalable Spark clusters that are managed by the runtime.
    Databricks comes with enterprise-grade security, compliance, and collaboration
    features that distinguish it from Apache Spark. The ability to schedule and orchestrate
    ...
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Databricks是Azure上可以用来构建自定义AI解决方案的新增工具之一。它基于Apache Spark，但针对Azure平台进行了优化。Spark引擎可以通过基于Scala、Python、R、SQL或Java的各种API进行访问。为了利用Spark的可扩展性，用户在处理数据对象及其转换时需要利用Spark库。Azure
    Databricks在由运行时管理的弹性且可扩展的Spark集群之上利用了这些可扩展的库。Databricks提供了企业级的安全、合规性和协作功能，使其与Apache
    Spark区分开来。能够安排和编排...
- en: Summary
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In summary, this chapter has given a brief overview of all the different services
    that are available on Azure to build AI solutions. In the innovative cloud world,
    it is hard to find a single solution that encompasses all the desired outcomes
    for an AI project. The goal of this book is to guide users on picking the right
    tool for the right task. Mature organizations realize that being agile and flexible
    is key to innovating in the cloud.  In the next chapter, we will see TDSP stages
    and its tools.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章简要概述了Azure上可用于构建AI解决方案的所有不同服务。在创新的云世界中，很难找到一个包含AI项目所有期望结果的单一解决方案。本书的目标是指导用户选择适合特定任务的正确工具。成熟的组织意识到，在云中创新的关键在于敏捷性和灵活性。在下一章中，我们将看到TDSP阶段及其工具。
