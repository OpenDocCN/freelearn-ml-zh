- en: AI Cloud Foundations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, every organization aspires to be a leader in adopting the latest technological advancements.
    The success of such adoption in recent years has been achieved by leveraging the
    data landscape surrounding businesses. In this chapter, we will talk about how
    AI can be leveraged using Microsoft's Azure platform to derive business value
    from that data landscape. Azure offers several hundred services, and choosing
    the right service is challenging. In this chapter, we will give a high-level overview
    of the choices a data scientist, developer, or data engineer has for building
    and deploying AI solutions for their organization. We will start with a decision
    tree that can guide technology choices so that you understand which ...
  prefs: []
  type: TYPE_NORMAL
- en: The importance of artificial intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial intelligence** (**AI**) is ever-increasingly being interwoven
    into the complex fabric of our technology-driven lives. Whether we realize it
    or not, AI is becoming an enabler for us to accomplish our day-to-day tasks more
    efficiently than we''ve ever done before. Personal assistants such as Siri, Cortana,
    and Alexa are some of the most visible AI tools that we come across frequently.
    Less obvious AI tools are ones such as those used by rideshare firms that suggest
    drivers move to a high-density area, and adjust prices dynamically based on demand.'
  prefs: []
  type: TYPE_NORMAL
- en: Across the world, there are organizations at different stages of the AI journey.
    To some organizations, AI is the core of their business model. In other organizations,
    they see the potential of leveraging AI to compete and innovate their business.
    Successful organizations recognize that digital transformation through AI is key
    to their survival over the long term. Sometimes, this involves changing an organization's
    business model to incorporate AI through new technologies such as the **Internet
    of Things** (**IoT**). Across this spectrum of AI maturity, organizations face
    challenges implementing AI solutions. Challenges are typically related to scalability,
    algorithms, libraries, accuracy, retraining, pipelines, integration with other
    systems, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The field of AI has been around for several decades now, but it''s growth and
    adoption over the last decade has been tremendous. This can be attributed to three
    main drivers: large data, large compute, and enhanced algorithms. The growth in
    data stems mostly from entities that generate data, or from human interactions
    with those entities. The growth in compute can be attributed to improved chip
    design, as well as innovative compute technologies. Algorithms have improved partly
    due to the open source community and partly due to the availability of larger
    data and compute.'
  prefs: []
  type: TYPE_NORMAL
- en: The emergence of the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developing AI solutions in the cloud helps organizations leapfrog their innovation,
    in addition to alleviating the challenges described here. One of the first steps
    is to bring all the data close together or in the same tool for easy retrieval.
    The cloud is the most optimal landing zone that meets this requirement. The cloud
    provides near-infinite storage, easy access to other data sources, and on-demand
    compute. Solutions that are built on the cloud are easier to maintain and update,
    due to there being a single pane of control. The availability of improved or customized
    hardware at the click of a button was unthinkable a few years back.
  prefs: []
  type: TYPE_NORMAL
- en: Innovation in the cloud is so rapid that developers can build a large variety
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Essential cloud components for AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Any cloud AI solution will have different components, all modular, individually
    elastic, and integrated with each other. A broad framework for cloud AI is depicted
    in the following diagram. At the very base is **Storage**, which is separate from
    **Compute**. This separation of **Storage** and **Compute** is one of the key
    benefits of the cloud, which permits the user to scale one separate from the other.
    **Storage** itself may be tiered based on throughput, availability, and other
    features. Until a few years back, the **Compute** options were limited to the
    speed and generation of the underlying CPU chips. Now, we have options for GPU
    and **FPGA** (short- for **field-programmable gate array**) chips as well. Leveraging
    **Storage** and **Compute**, various services are built on the cloud fabric, which
    makes it easier to use ingest data, transform it, and build models. Services based
    on **Relational Databases**, **NoSQL**, **Hadoop**, **Spark**, and **Microservices**
    are some of the most frequent ones used to build AI solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5a2a935-adcf-4ff4-8826-5b49bf706d02.png)'
  prefs: []
  type: TYPE_IMG
- en: Essential building blocks of cloud AI
  prefs: []
  type: TYPE_NORMAL
- en: At the highest level of complexity are the various AI-focused services that
    are available on the cloud. These services fall on a spectrum with fully customizable
    solutions at one end, and easy-to-build solutions at the other. **Custom AI**
    is typically a solution that allows the user to bring in their own libraries or
    use proprietary ones to build an end-to-end solution. This typically involves
    a lot of hands-on coding and gives the builder complete control over different
    parts of the solution. **Pre-Built AI** is typically in the form of APIs that
    expose some type of service that can be easily incorporated into your solution.
    Examples of these include custom vision, text, and language-based AI solutions.
  prefs: []
  type: TYPE_NORMAL
- en: However complex the underlying AI may be, the goal of most applications is to
    make the end user experience as seamless as possible. This means that AI solutions
    need to integrate with general applications that reside in the organization solution
    stack. A lot of solutions use **Dashboards** or reports in the traditional BI
    space. These interfaces allow the user to explore the data generated by the AI
    solution. **Conversational Apps** are usually in the form of an intelligent interface
    (such as a bot) that interacts with the user in a conversational mode.
  prefs: []
  type: TYPE_NORMAL
- en: The Microsoft cloud – Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft's mission is been to empower every person and organization on Earth
    to achieve more. Microsoft Azure is a cloud platform designed to help customers
    achieve the intelligent cloud and the intelligent edge. Their vision is to help
    customers infuse AI into every application, both in the cloud and on compute devices
    of all form factors. With this in mind, Microsoft has developed a wide set of
    tools that can help its customer build AI into their applications with ease.
  prefs: []
  type: TYPE_NORMAL
- en: The following table shows the different tools that can be used to develop end-to-end
    AI solutions with Azure. The Azure Service column indicates those services that
    are owned and managed by Microsoft (first-party services). The Azure Marketplace
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Choosing AI tools on Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we will assume that the you have knowledge and experience of AI
    in general. The goal here is not to touch on the basics of the various kinds of
    AI or to choose the correct algorithm; we assume you have a good understanding
    of what algorithms to choose in order to solve a given business need.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a decision tree that can help you choose the right
    Azure AI tools. It is not meant to be comprehensive; just a guide to the correct
    technology choices. There are a lot of options that cross over, and this was difficult
    to depict on this diagram. Also keep in mind that an efficient AI solution would
    leverage multiple tools in combination:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f0ac8d5-6588-44ad-a45a-6e3c8c4ed4fd.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision tree guide to choosing AI tools on Azure
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram shows a decision tree that helps users of **Microsoft's
    AI platform**. Starting from the top, the first question is whether you would
    like to **Build your own models or consume pre-trained models**. If you are building
    your own models, then it involves data scientists, data engineers, and developers
    at various stages of the process. In some use cases, developers prefer to just
    **consume pre-trained models**.
  prefs: []
  type: TYPE_NORMAL
- en: Cognitive Services/bots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Developers who would like to consume pre-trained AI models, typically use one
    of Microsoft's Cognitive Services. For those who are building conversational applications,
    a combination of Bot Framework and Cognitive Services is the recommended path.
    We will go into the details of Cognitive Services in [Chapter 3](89299379-0f5e-4602-ad78-9d3d46a0710e.xhtml), *Cognitive
    Services*, and [Chapter 4](08fa36ee-b325-4c6c-b5f5-f41c03d056c3.xhtml), *Bot Framework*,
    but it is important to understand when to choose Cognitive Services.
  prefs: []
  type: TYPE_NORMAL
- en: Cognitive Services were built with the goal of giving developers the tools to
    rapidly build and deploy AI applications. Cognitive Services are pre-trained,
    customizable AI models that are exposed via APIs with accompanying SDKs and web
    services. They perform certain tasks, and are designed to ...
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Azure Machine Learning** (**Azure ML**) Studio is the primary tool, purely
    a web-based GUI, to help build **machine learning** (**ML**) models. AzureML Studio
    is an almost code-free environment that allows the user to build end-to-end ML
    solutions. It has Microsoft Research''s proprietary algorithms built in, which
    can do most machine learning tasks with real simplicity. It can also embed Python
    or R code to enhance its functionality. One of the greatest features of Azure ML
    Studio is the ability to create a web service in a single click. The web service
    is exposed in the form of a REST endpoint that applications can send data to.
    In addition to the web service, an Excel spreadsheet is also created, which accesses
    the same web service and can be used to test the model''s functionality and share
    it easily with end users.'
  prefs: []
  type: TYPE_NORMAL
- en: At time of writing, the primary limitation with Azure ML Studio is the 10 GB
    limit on an experiment container. This limit will be explained in detail in [Chapter
    6](f6d8b2f5-a038-41fe-892f-4720ef071fd9.xhtml), *Scalable Computing for Data Science*,
    but for now, it is sufficient to understand that Azure ML Studio is well-suited
    to training datasets that are in the 2 GB to 5 GB range. In addition, there are
    also limits to the amount of R and Python code that you can include in ML Studio,
    and its performance, which will be discussed in detail later.
  prefs: []
  type: TYPE_NORMAL
- en: ML Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a code-first experience, there are multiple tools available in the Microsoft
    portfolio. If organizations are looking to deploy on-premises (in addition to
    the cloud), the only option available is **Machine Learning Server** (**ML Server**).
    ML Server is an enterprise platform that supports both R and Python applications.
    It supports all the activities involved in the ML process end-to-end. ML Server
    was previously known as **R Server** and came about through Microsoft's acquisition
    of revolution analytics. Later, Python support was added to handle the variety
    of user preferences.
  prefs: []
  type: TYPE_NORMAL
- en: In ML Server, users can use any of the open source libraries as part of their
    solution. The challenge with a lot of the open source tooling is that it takes
    a ...
  prefs: []
  type: TYPE_NORMAL
- en: Azure ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure ML Services is a relatively new service on Azure that enhances productivity
    in the process of building AI solutions. Azure ML Services has different components.
    On the user's end, Azure ML Workbench is a tool that allows users to pull in data,
    transform it, build models, and run them against various kinds of compute. Workbench
    is a tool that users run on their local machines and connect to Azure ML services.
    Azure ML Services itself runs on Azure and consists of experimentation and model
    management for ML. The experimentation service keeps track of model testing, performance,
    and any other metrics you would like to track while building a model. The model
    management service helps manage the deployment of models and manages the overall
    life cycle of multiple models built by individual users or large teams.
  prefs: []
  type: TYPE_NORMAL
- en: When leveraging Azure ML Services, there are multiple endpoints that can act
    as engines for the services. At the time of writing, only Python-based endpoints
    are supported. SQL Server, with the introduction of built-in Python services,
    can act as an endpoint. This is beneficial, especially if the user has most of
    the data in SQL tables and wants to minimize data movement.
  prefs: []
  type: TYPE_NORMAL
- en: If you have leveraged Spark libraries for ML at scale on ML Services, then you
    can deploy to Spark-based solutions on Azure. Currently, these can be either Spark
    on HDInsight, or any other native implementation of Apache Spark (Cloudera, Hortonworks,
    and so on).
  prefs: []
  type: TYPE_NORMAL
- en: If the user has leveraged other Hadoop-based libraries to build ML Services,
    then those can be deployed to HDInsight or any of the Apache Hadoop implementations
    available on Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Batch is a service that provides large-scale, on-demand compute for applications
    that require such resources on an ad hoc or scheduled basis. The typical workflow
    for this use case involves the creation of a VM cluster, followed by the submission
    of jobs to the cluster. After the job is completed, the cluster is destroyed,
    and users do not pay for any compute afterward.
  prefs: []
  type: TYPE_NORMAL
- en: The **Data Science Virtual Machine** (**DSVM**) is a highly customized VM template
    built on either Linux or Windows. It comes pre-installed with a huge variety of
    curated data science tools and libraries. All the tools and libraries are configured
    to work straight out of the box with minimal effort. The DSVM has multiple applications,
    which we will cover in [Chapter 7](b88febb4-e8e4-4a08-9f62-5495654f3842.xhtml),
    *Machine Learning Server*, including utilization as a base image VM for Azure
    Batch.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most highly scalable targets for running models built by Azure ML
    Services is to leverage containers through Docker and orchestration via Kubernetes.
    This is made easier by leveraging **Azure Kubernetes Services** (**AKS**). Azure ML
    Services creates a Docker image that helps operationalize an ML model. The model
    itself is deployed as containerized Docker-based web services, while leveraging
    frameworks such as TensorFlow, and Spark. Applications can access this web service
    as a REST API. The web services can be scaled up and down by leveraging the scaling
    features of Kubernetes. More details on this topic will be covered in [Chapter
    10](3196eb4a-070f-4b7b-9e15-f8cdc23398f8.xhtml), *Building Deep Learning Solutions*.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge with Azure ML Services is that it currently only supports Python.
    The platform itself has gone through some changes, and the heavy reliance on the
    command-line interface makes the interface not as user-friendly as some other
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Databricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure Databricks is one of the newest additions to the tools that can be used
    to build custom AI solutions on Azure. It is based on Apache Spark, but is optimized
    for use on the Azure platform. The Spark engine can be accessed by various APIs
    that can be based on Scala, Python, R, SQL, or Java. To leverage the scalability
    of Spark, users need to leverage Spark libraries when dealing with data objects
    and their transformations. Azure Databricks leverages these scalable libraries
    on top of highly elastic and scalable Spark clusters that are managed by the runtime.
    Databricks comes with enterprise-grade security, compliance, and collaboration
    features that distinguish it from Apache Spark. The ability to schedule and orchestrate
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, this chapter has given a brief overview of all the different services
    that are available on Azure to build AI solutions. In the innovative cloud world,
    it is hard to find a single solution that encompasses all the desired outcomes
    for an AI project. The goal of this book is to guide users on picking the right
    tool for the right task. Mature organizations realize that being agile and flexible
    is key to innovating in the cloud.  In the next chapter, we will see TDSP stages
    and its tools.
  prefs: []
  type: TYPE_NORMAL
