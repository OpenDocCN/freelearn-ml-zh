["```py\n{\n    \"aggr_ip\": \"localhost\",\n    \"reg_socket\": \"8765\",\n    \"model_path\": \"./data/agents\",\n    \"local_model_file_name\": \"lms.binaryfile\",\n    \"global_model_file_name\": \"gms.binaryfile\",\n    \"state_file_name\": \"state\",\n    \"init_weights_flag\": 1,\n    \"polling\": 1\n}\n```", "```py\nimport asyncio, time, logging, sys, os\nfrom typing import Dict, Any\nfrom threading import Thread\nfrom fl_main.lib.util.communication_handler import \\\n     init_client_server, send, receive\nfrom fl_main.lib.util.helpers import read_config, \\\n     init_loop, save_model_file, load_model_file, \\\n     read_state, write_state, generate_id, \\\n     set_config_file, get_ip, compatible_data_dict_read, \\\n     generate_model_id, create_data_dict_from_models, \\\n     create_meta_data_dict\nfrom fl_main.lib.util.states import ClientState, \\\n     AggMsgType, ParticipateConfirmationMSGLocation, \\\n     GMDistributionMsgLocation, IDPrefix\nfrom fl_main.lib.util.messengers import \\\n     generate_lmodel_update_message, \\\n     generate_agent_participation_message, \\\n     generate_polling_message\n```", "```py\nclass Client:\n    \"\"\"\n    Client class instance with FL client-side functions\n    and libraries used in the agent's ML engine\n    \"\"\"\n```", "```py\ndef __init__(self):\n    self.agent_name = 'default_agent'\n    self.id = generate_id()\n    self.agent_ip = get_ip()\n    self.simulation_flag = False\n    if len(sys.argv) > 1:\n        self.simulation_flag = bool(int(sys.argv[1]))\n    config_file = set_config_file(\"agent\")\n    self.config = read_config(config_file)\n    self.aggr_ip = self.config['aggr_ip']\n    self.reg_socket = self.config['reg_socket']\n    self.msend_socket = 0\n    self.exch_socket = 0\n    if self.simulation_flag:\n        self.exch_socket = int(sys.argv[2])\n        self.agent_name = sys.argv[3]\n    self.model_path = f'{self.config[\"model_path\"]}\n                                        /{self.agent_name}'\n    if not os.path.exists(self.model_path):\n        os.makedirs(self.model_path)\n    self.lmfile = self.config['local_model_file_name']\n    self.gmfile = self.config['global_model_file_name']\n    self.statefile = self.config['state_file_name']\n    self.round = 0\n    self.init_weights_flag = \\\n                     bool(self.config['init_weights_flag'])\n    self.is_polling = bool(self.config['polling'])\n```", "```py\nasync def participate(self):\n    data_dict, performance_dict = \\\n       load_model_file(self.model_path, self.lmfile)\n    _, gene_time, models, model_id = \\\n       compatible_data_dict_read(data_dict)\n    msg = generate_agent_participation_message(\n         self.agent_name, self.id, model_id, models,\n         self.init_weights_flag, self.simulation_flag,\n         self.exch_socket, gene_time, performance_dict,\n         self.agent_ip)\n    resp = await send(msg, self.aggr_ip, self.reg_socket)\n    self.round = resp[ \\\n       int(ParticipateConfirmaMSGLocation.round)]\n    self.exch_socket = resp[ \\\n       int(ParticipateConfirmationMSGLocation.exch_socket)]\n    self.msend_socket = resp[ \\\n       int(ParticipateConfirmationMSGLocation.recv_socket)]\n    self.id = resp[ \\\n       int(ParticipateConfirmationMSGLocation.agent_id)]\n    self.save_model_from_message(resp, \\\n        ParticipateConfirmationMSGLocation)\n```", "```py\nAsync def model_exchange_routine(self):\n    while True:\n        await asyncio.sleep(5)\n        state = read_state(self.model_path, self.statefile)\n        if state == ClientState.sending:\n            await self.send_models()\n        elif state == ClientState.waiting_gm:\n            if self.is_polling == True:\n               await self.process_polling()\n            else: pass\n        elif state == ClientState.training: pass\n        elif state == ClientState.gm_ready: pass\n        else: pass\n```", "```py\nasync def wait_models(self, websocket, path):\n    gm_msg = await receive(websocket)\n    self.save_model_from_message( \\\n        gm_msg, GMDistributionMsgLocation)\n```", "```py\nasync def process_polling(self):\n    msg = generate_polling_message(self.round, self.id)\n    resp = await send(msg, self.aggr_ip, self.msend_socket)\n    if resp[int(PollingMSGLocation.msg_type)] \\\n                                      == AggMsgType.update:\n        self.save_model_from_message(resp, \\\n            GMDistributionMsgLocation)\n    else: pass\n```", "```py\ndef register_client(self):\n    asyncio.get_event_loop().run_until_complete( \\\n        self.participate())\n```", "```py\ndef start_wait_model_server(self):\n    th = Thread(target = init_client_server, \\\n        args=[self.wait_models, self.agent_ip, \\\n        self.exch_socket])\n    th.start()\n```", "```py\ndef start_model_exchange_server(self):\n    self.agent_running = True\n    th = Thread(target = init_loop, \\\n        args=[self.model_exchange_routine()])\n    th.start()\n```", "```py\ndef start_fl_client(self):\n    self.register_client()\n    if self.is_polling == False:\n        self.start_wait_model_server()\n    self.start_model_exchange_server()\n```", "```py\ndef save_model_from_message(self, msg, MSG_LOC):\n    data_dict = create_data_dict_from_models( \\\n        msg[int(MSG_LOC.model_id)],\n        msg[int(MSG_LOC.global_models)],\n        msg[int(MSG_LOC.aggregator_id)])\n    self.round = msg[int(MSG_LOC.round)]\n    save_model_file(data_dict, self.model_path, \\\n        self.gmfile)\n    self.tran_state(ClientState.gm_ready)\n```", "```py\ndef read_state(self) -> ClientState:\n    return read_state(self.model_path, self.statefile)\n```", "```py\ndef tran_state(self, state: ClientState):\n    write_state(self.model_path, self.statefile, state)\n```", "```py\nasync def send_models(self):\n    data_dict, performance_dict = \\\n        load_model_file(self.model_path, self.lmfile)\n    , _, models, model_id = \\\n        compatible_data_dict_read(data_dict)\n    msg = generate_lmodel_update_message( \\\n        self.id, model_id, models, performance_dict)\n    await send(msg, self.aggr_ip, self.msend_socket)\n    self.tran_state(ClientState.waiting_gm)\n```", "```py\ndef send_initial_model(self, initial_models, \\\n                             num_samples=1, perf_val=0.0):\n    self.setup_sending_models( \\\n        initial_models, num_samples, perf_val)\n```", "```py\ndef send_trained_model(self, models, \\\n                             num_samples, perf_value):\n    state = self.read_state()\n    if state == ClientState.gm_ready:\n        pass\n    else:\n        self.setup_sending_models( \\\n            models, num_samples, perf_value)\n```", "```py\ndef setup_sending_models(self, models, \\\n                               num_samples, perf_val):\n    model_id = generate_model_id( \\\n                   IDPrefix.agent, self.id, time.time())\n    data_dict = create_data_dict_from_models( \\\n                    model_id, models, self.id)\n    meta_data_dict = create_meta_data_dict( \\\n                         perf_val, num_samples)\n    save_model_file(data_dict, self.model_path, \\\n        self.lmfile, meta_data_dict)\n    self.tran_state(ClientState.sending)\n```", "```py\ndef wait_for_global_model(self):\n    while (self.read_state() != ClientState.gm_ready):\n        time.sleep(5)\n    data_dict, _ = load_model_file( \\\n                       self.model_path, self.gmfile)\n    global_models = data_dict['models']\n    self.tran_state(ClientState.training)\n    return global_models\n```", "```py\nimport numpy as np\nimport time, logging, sys\nfrom typing import Dict\nfrom fl_main.agent.client import Client\n```", "```py\ndef init_models() -> Dict[str,np.array]:\n    models = dict()\n    models['model1'] = np.array([[1, 2, 3], [4, 5, 6]])\n    models['model2'] = np.array([[1, 2], [3, 4]])\n    return models\n```", "```py\ndef training(models: Dict[str,np.array],\n           init_flag: bool = False) -> Dict[str,np.array]:\n    # return templates of models to tell the structure\n    # This model is not necessarily actually trained\n    if init_flag:\n        return init_models()\n    # ML Training. In this example, no actual training.\n    models = dict()\n    models['model1'] = np.array([[1, 2, 3], [4, 5, 6]])\n    models['model2'] = np.array([[1, 2], [3, 4]])\n    return models\n```", "```py\ndef compute_performance(models: Dict[str,np.array], \\\n                                      testdata) -> float:\n    # replace with actual performance computation logic\n    accuracy = 0.5\n    return\n```", "```py\ndef judge_termination(training_count: int = 0,\n              global_arrival_count: int = 0) -> bool:\n    # Depending on termination criteria, change the return bool value\n    # Call a performance tracker to check if the current models satisfy the required performance\n    return True\n```", "```py\ndef prep_test_data():\n    testdata = 0\n    return\n```", "```py\n# Step1: Create Client instance\ncl = Client()\n```", "```py\n# Step2: Create template models (to tell the shapes)\ninitial_models = training(dict(), init_flag=True)\n```", "```py\n# Step3: Send initial models\ncl.send_initial_model(initial_model)\n```", "```py\n# Step4: Start the FL client\ncl.start_fl_client()\n```", "```py\n# Step5: Run the local FL loop\ntraining_count, gm_arrival_count = 0, 0\nwhile judge_termination(training_count, gm_arrival_count):\n    global_models = cl.wait_for_global_model()\n    gm_arrival_count += 1\n    global_model_performance_data = \\\n       compute_performance(global_models, prep_test_data())\n    models = training(global_models)\n    training_count += 1\n    perf_value = compute_performance( \\\n                     models, prep_test_data())\n    cl.send_trained_model(models, 1, perf_value)\n```", "```py\nimport logging\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom typing import Dict\nfrom .cnn import Net\nfrom .conversion import Converter\nfrom .ic_training import DataManger, execute_ic_training\nfrom fl_main.agent.client import Client\n```", "```py\nclass TrainingMetaData:\n    # The number of training data used for each round\n    # This will be used for the weighted averaging\n    # Set to a natural number > 0\n    num_training_data = 8000\n```", "```py\ndef init_models() -> Dict[str,np.array]:\n    net = Net()\n    return Converter.cvtr().convert_nn_to_dict_nparray(net)\n```", "```py\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n```", "```py\ndef training(models: Dict[str,np.array], \\\n             init_flag: bool=False) -> Dict[str,np.array]:\n    if init_flag:\n        DataManger.dm( \\\n            int(TrainingMetaData.num_training_data / 4))\n        return init_models()\n    net = \\\n        Converter.cvtr().convert_dict_nparray_to_nn(models)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), \\\n                          lr=0.001, momentum=0.9)\n    trained_net = execute_ic_training(DataManger.dm(), \\\n                              net, criterion, optimizer)\n    models = Converter.cvtr(). \\\n                 convert_nn_to_dict_nparray(trained_net)\n    return models\n```", "```py\ndef compute_performance(models: Dict[str,np.array], \\\n                       testdata, is_local: bool) -> float:\n    # Convert np arrays to a CNN\n    net = \\\n       Converter.cvtr().convert_dict_nparray_to_nn(models)\n    correct, total = 0, 0\n    with torch.no_grad():\n        for data in DataManger.dm().testloader:\n            images, labels = data\n            _, predicted = torch.max(net(images).data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    acc = float(correct) / total\n    return acc\n```"]