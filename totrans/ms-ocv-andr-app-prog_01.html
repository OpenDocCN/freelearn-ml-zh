<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Applying Effects to Images"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Applying Effects to Images</h1></div></div></div><p>Generally, an image contains more information than required for any particular task. For this reason, we need to preprocess the images so that they contain only as much information as required for the application, thereby reducing the computing time needed.</p><p>In this chapter, we will learn about the different preprocessing operations, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Blurring</li><li class="listitem" style="list-style-type: disc">De-noising</li><li class="listitem" style="list-style-type: disc">Sharpening</li><li class="listitem" style="list-style-type: disc">Erosion and dilation</li><li class="listitem" style="list-style-type: disc">Thresholding and adaptive thresholding</li></ul></div><p>At the end of this chapter, we will see how you can integrate OpenCV into your existing Android applications.</p><p>Before we take a look at the various feature detection algorithms and their implementations, let's first build a basic Android application to which we will keep adding feature detection algorithms, as we go through this chapter.</p><div class="section" title="Getting started"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec08"/>Getting started</h1></div></div></div><p>When we see<a id="id0" class="indexterm"/> an image, we perceive it as colors and objects. However, a computer vision system sees it as a matrix of numbers (see the following image). These numbers are interpreted differently, depending on the color model used. The computer cannot directly detect patterns or objects in the image. The aim of computer vision systems is to interpret this matrix of numbers as an object of a particular type.</p><div class="mediaobject"><img src="graphics/B02052_01_01.jpg" alt="Getting started"/><div class="caption"><p>Representation of a binary image</p></div></div></div></div>
<div class="section" title="Setting up OpenCV"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec09"/>Setting up OpenCV</h1></div></div></div><p>OpenCV is<a id="id1" class="indexterm"/> the short <a id="id2" class="indexterm"/>form of Open Source Computer Vision library. It is the most widely used computer vision library. It is a collection of commonly used functions that perform operations related to computer vision. OpenCV has been natively written in C/C++, but has wrappers for Python, Java, and any JVM language, which is designed to create the Java byte code, such as Scala and Clojure. Since most of the Android app development is done in C++/Java, OpenCV has also been ported as an SDK that developers can use to implement it in their apps and make them vision enabled.</p><p>We will now take a look at how to get started with setting up OpenCV for the Android platform, and start our journey. We will use Android Studio as our IDE of choice, but any other IDE should work just as well with slight modifications. Follow these steps in order to get started:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download Android Studio from <a class="ulink" href="https://developer.android.com/sdk/">https://developer.android.com/sdk/</a> and <a id="id3" class="indexterm"/>OpenCV4Android SDK from <a class="ulink" href="http://sourceforge.net/projects/opencvlibrary/files/opencv-android/">http://sourceforge.net/projects/opencvlibrary/files/opencv-android/</a>.</li><li class="listitem">Extract<a id="id4" class="indexterm"/> the two files to a known location.</li><li class="listitem">Create a normal Android Project and name it <code class="literal">FirstOpenCVApp</code>. Navigate to <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Import</strong></span>.</li><li class="listitem">Select the <code class="literal">OpenCV_SDK_location/sdk/java/</code> directory.</li><li class="listitem">Navigate to <span class="strong"><strong>Build</strong></span> | <span class="strong"><strong>Rebuild Project</strong></span>.</li><li class="listitem">Navigate to<span class="strong"><strong> File</strong></span> | <span class="strong"><strong>Project Structure</strong></span>.</li><li class="listitem">Add the OpenCV module to your app by selecting the <span class="strong"><strong>app</strong></span> module in the left column. Click on the green in the dependencies tab, and finally, select the OpenCV module.</li><li class="listitem">You are now ready to use OpenCV in your Android project. It should look like this:</li></ol></div><div class="mediaobject"><img src="graphics/B02052_01_02.jpg" alt="Setting up OpenCV"/></div></div>
<div class="section" title="Storing images in OpenCV"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec10"/>Storing images in OpenCV</h1></div></div></div><p>OpenCV <a id="id5" class="indexterm"/>stores images as a custom object called <span class="strong"><strong>Mat</strong></span>. This <a id="id6" class="indexterm"/>object stores the information such as rows, columns, data, and so on that can be used to uniquely identify and recreate the image when required. Different images contain different amounts of data. For example, a colored image contains more data than a grayscale version of the same image. This is because a colored image is a 3-channel image when using the RGB model, and a grayscale image is a 1-channel image. The following figures show how 1-channel and <a id="id7" class="indexterm"/>multichannel (here, RGB) images are stored (these images are taken from <a class="ulink" href="http://docs.opencv.org">docs.opencv.org</a>).</p><p>A 1-channel representation of an image is shown as follows:</p><div class="mediaobject"><img src="graphics/B02052_01_03.jpg" alt="Storing images in OpenCV"/><div class="caption"><p>A grayscale (1-channel) image representation:</p></div></div><p>A more elaborate form of an image is the RGB representation, which is shown as follows:</p><div class="mediaobject"><img src="graphics/B02052_01_04.jpg" alt="Storing images in OpenCV"/><div class="caption"><p>A RGB (3-channel) image representation</p></div></div><p>In the grayscale image, the numbers represent the intensity of that particular color. They are represented on a scale of 0-255 when using integer representations, with 0 being pure black and 255 being pure white. If we use a floating point representation, the pixels are represented on a scale of 0-1, with 0 being pure black and 1 being pure white. In an RGB image in OpenCV, the first channel corresponds to blue color, second channel corresponds to <a id="id8" class="indexterm"/>green color, and the third channel corresponds to red color. Thus, each channel represents the intensity of any particular color. As we know that red, green, and blue are primary colors, they can be combined in different proportions to generate any color visible to the human eye. The following figure shows the different colors and their respective RGB equivalents in an integer format:</p><div class="mediaobject"><img src="graphics/B02052_01_05.jpg" alt="Storing images in OpenCV"/></div><div class="mediaobject"><img src="graphics/B02052_01_21.jpg" alt="Storing images in OpenCV"/></div><p>Now that we have seen how an image is represented in computing terms, we will see how we can modify the pixel values so that they need less computation time when using them for the actual task at hand.</p></div>
<div class="section" title="Linear filters in OpenCV"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec11"/>Linear filters in OpenCV</h1></div></div></div><p>We <a id="id9" class="indexterm"/>all like <a id="id10" class="indexterm"/>sharp images. Who doesn't, right? However, there is a trade-off that needs to be made. More information means that the image will require more computation time to complete the same task as compared to an image which has less information. So, to solve this problem, we apply blurring operations.</p><p>Many of the linear filtering algorithms make use of an array of numbers called a kernel. A kernel can be thought of as a sliding window that passes over each pixel and calculates the output value for that pixel. This can be understood more clearly by taking a look at the following figure (this image of <a id="id11" class="indexterm"/>linear filtering/convolution is taken from <a class="ulink" href="http://test.virtual-labs.ac.in/labs/cse19/neigh/convolution.jpg">http://test.virtual-labs.ac.in/labs/cse19/neigh/convolution.jpg</a>):</p><div class="mediaobject"><img src="graphics/B02052_01_06.jpg" alt="Linear filters in OpenCV"/></div><p>In the preceding <a id="id12" class="indexterm"/>figure, a 3 x 3 kernel is used on a 10 x 10 image.</p><p>One of the most general operations used for linear filtering is convolution. The values in a kernel are coefficients for multiplication of the corresponding pixels. The final result is stored in the anchor point, generally, the center of the kernel:</p><div class="mediaobject"><img src="graphics/B02052_01_22.jpg" alt="Linear filters in OpenCV"/></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note02"/>Note</h3><p>Linear filtering operations are generally not in-place operations, as for each pixel we use the values present in the original image, and not the modified values.</p></div></div><p>One of the most <a id="id13" class="indexterm"/>common uses of linear filtering is to remove the noise. Noise is the random variation in brightness or color information in images. We use blurring operations to reduce the noise in images.</p><div class="section" title="The mean blur method"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec08"/>The mean blur method</h2></div></div></div><p>A <a id="id14" class="indexterm"/>mean filter<a id="id15" class="indexterm"/> is the simplest form of blurring. It calculates the mean of all the pixels that the given kernel superimposes. The kernel that is used for this kind of operation is a simple Mat that has all its values as 1, that is, each neighboring pixel is given the same weightage.</p><p>For this chapter, we will pick an image from the gallery and apply the respective image transformations. For this, we will add basic code. We are assuming that OpenCV4Android SDK has been set up and is running.</p><p>We can use the first OpenCV app that we created at the start of the chapter for the purpose of this chapter. At the time of creating the project, the default names will be as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/B02052_01_07.jpg" alt="The mean blur method"/></div><p>Add a new <a id="id16" class="indexterm"/>activity by right-clicking on the Java folder and navigate to <span class="strong"><strong>New</strong></span> | <span class="strong"><strong>Activity</strong></span>. Then, select <span class="strong"><strong>Blank Activity</strong></span>. Name the activity <code class="literal">MainActivity.java</code> and the XML file <code class="literal">activity_main.xml</code>. Go to <code class="literal">res/menu/menu_main.xml</code>. Add an item as follows:</p><div class="informalexample"><pre class="programlisting">&lt;item android:id="@+id/action_load_image"
        android:title="@string/action_load_image"
        android:orderInCategory="1"
        android:showAsAction="ifRoom" /&gt;</pre></div><p>Since <code class="literal">MainActivity</code> is the activity that we will be using to perform our OpenCV specific tasks, we need to instantiate OpenCV. Add this as a global member of <code class="literal">MainActivity.java</code>:</p><div class="informalexample"><pre class="programlisting">private BaseLoaderCallback mOpenCVCallBack = new BaseLoaderCallback(this) {
        @Override
        public void onManagerConnected(int status) {
            switch (status) {
                case LoaderCallbackInterface.SUCCESS:
                    //DO YOUR WORK/STUFF HERE
                    break;
                default:
                    super.onManagerConnected(status);
                    break;
            }
        }
    };
@Override
    protected void onResume() {
        super.onResume();
        OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION_2_4_10, this,
                mOpenCVCallBack);
    }</pre></div><p>This is a <a id="id17" class="indexterm"/>callback, which <a id="id18" class="indexterm"/>checks whether the OpenCV manager is installed. We need the OpenCV manager app to be installed on the device because it has all of the OpenCV functions defined. If we do not wish to use the OpenCV manager, we can have the functions present natively, but the APK size then increases significantly. If the OpenCV manager is not present, the app redirects the user to the Play Store to download it. The function call in <code class="literal">onResume</code> loads OpenCV for use.</p><p>Next we will add a button to <code class="literal">activity_home.xml</code>:</p><div class="informalexample"><pre class="programlisting">&lt;Button
            android:id="@+id/bMean"
            android:layout_height="wrap_content"
            android:layout_width="wrap_content"
            android:text="Mean Blur" /&gt;</pre></div><p>Then, in <code class="literal">HomeActivity.java</code>, we will instantiate this button, and set an <code class="literal">onClickListener</code> to this button:</p><div class="informalexample"><pre class="programlisting">Button bMean = (Button)findViewById(R.id.bMean);
bMean.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                Intent i = new Intent(getApplicationContext(),MainActivity.class);
                i.putExtra("ACTION_MODE", MEAN_BLUR);
                startActivity(i);
            }
        });</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip02"/>Tip</h3><p>
<span class="strong"><strong>Downloading the example code</strong></span>
</p><p>You can download the example code files from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a> for all the Packt Publishing books you have purchased. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p></div></div><p>In the preceding code, <code class="literal">MEAN_BLUR</code> is a constant with value <code class="literal">1</code> that specifies the type of operation that we want to perform.</p><p>Here we <a id="id19" class="indexterm"/>have added<a id="id20" class="indexterm"/> extra to the activity bundle. This is to differentiate which operation we will be performing.</p><p>Open <code class="literal">activity_main.xml</code>. Replace everything with this code snippet. This snippet adds two <code class="literal">ImageView</code> items: one for the original image and one for the processed image:</p><div class="informalexample"><pre class="programlisting">&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;LinearLayout 
    android:orientation="vertical" 
    android:layout_width="match_parent"
    android:layout_height="match_parent"&gt;

    &lt;ImageView
        android:layout_width="match_parent"
        android:layout_height="match_parent"
        android:layout_weight="0.5"
        android:id="@+id/ivImage" /&gt;

    &lt;ImageView
        android:layout_width="match_parent"
        android:layout_height="match_parent"
        android:layout_weight="0.5"
        android:id="@+id/ivImageProcessed" /&gt;

&lt;/LinearLayout&gt;</pre></div><p>We need to programmatically link these <code class="literal">ImageView</code> items to the <code class="literal">ImageView</code> items in Java in our <code class="literal">MainActivity.java</code>:</p><div class="informalexample"><pre class="programlisting">    private final int SELECT_PHOTO = 1;
    private ImageView ivImage, ivImageProcessed;
    Mat src;
    static int ACTION_MODE = 0;
    
    @Override
    protected void onCreate(Bundle savedInstanceState) {
// Android specific code
ivImage = (ImageView)findViewById(R.id.ivImage);
        ivImageProcessed = (ImageView)findViewById(R.id.ivImageProcessed);
        Intent intent = getIntent();

        if(intent.hasExtra("ACTION_MODE")){
            ACTION_MODE = intent.getIntExtra("ACTION_MODE", 0);
}</pre></div><p>Here, the Mat <a id="id21" class="indexterm"/>and ImageViews have been made global to the class so that we can use them in other functions, without passing them as parameters. We will use the <code class="literal">ACTION_MODE</code> variable to identify the required operation to be performed.</p><p>Now we will <a id="id22" class="indexterm"/>add the code to load an image from the gallery. For this, we will use the menu button we created earlier. We will load the <code class="literal">menu_main.xml</code> file, when you click on the menu button:</p><div class="informalexample"><pre class="programlisting">@Override
    public boolean onCreateOptionsMenu(Menu menu) {
        getMenuInflater().inflate(R.menu.menu_main, menu);
        return true;
    }</pre></div><p>Then we will add the listener that will perform the desired action when an action item is selected. We will use <code class="literal">Intent.ACTION_PICK</code> to get an image from the gallery:</p><div class="informalexample"><pre class="programlisting">    @Override
    public boolean onOptionsItemSelected(MenuItem item) {
        int id = item.getItemId();
        if (id == R.id.action_load_image) {
            Intent photoPickerIntent = new Intent(Intent.ACTION_PICK);
            photoPickerIntent.setType("image/*");
            startActivityForResult(photoPickerIntent, SELECT_PHOTO);
            return true;
        }
        return super.onOptionsItemSelected(item);
    }</pre></div><p>As you can see, we have used <code class="literal">startActivityForResult()</code>. This will send the selected image to <code class="literal">onActivityResult()</code>. We will use this to get the Bitmap and convert it to an OpenCV Mat. Once the operation is complete, we want to get the image back from the other activity. For this, we make a new function <code class="literal">onActivityResult()</code> that gets called when the activity has completed its work, and is returned to the calling activity. Add the following code to <code class="literal">onActivityResult()</code>:</p><div class="informalexample"><pre class="programlisting">        switch(requestCode) {
            case SELECT_PHOTO:
                if(resultCode == RESULT_OK){
                    try {
                        //Code to load image into a Bitmap and convert it to a Mat for processing.
            final Uri imageUri = imageReturnedIntent.getData();
            final InputStream imageStream = getContentResolver().openInputStream(imageUri);
            final Bitmap selectedImage = BitmapFactory.decodeStream(imageStream);
                src = new Mat(selectedImage.getHeight(), selectedImage.getWidth(), CvType.CV_8UC4);
                        Utils.bitmapToMat(selectedImage, src);

                        switch (ACTION_MODE){
                            //Add different cases here depending on the required operation
                        }
                            //Code to convert Mat to Bitmap to load in an ImageView. Also load original image in imageView
    
                   } catch (FileNotFoundException e) {
                        e.printStackTrace();
                   }
    }
            break;
  }</pre></div><p>To apply <a id="id23" class="indexterm"/>mean blur to <a id="id24" class="indexterm"/>an image, we use the OpenCV provided function <code class="literal">blur()</code>. We have used a 3 x 3 kernel for this purpose:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.MEAN_BLUR:
Imgproc.blur(src, src, new Size(3,3));
      break;</pre></div><p>Now we will set this image in an ImageView to see the results of the operation:</p><div class="informalexample"><pre class="programlisting">Bitmap processedImage = Bitmap.createBitmap(src.cols(), src.rows(), Bitmap.Config.ARGB_8888);
Utils.matToBitmap(src, processedImage);
ivImage.setImageBitmap(selectedImage);
ivImageProcessed.setImageBitmap(processedImage);</pre></div><div class="mediaobject"><img src="graphics/B02052_01_08.jpg" alt="The mean blur method"/><div class="caption"><p>Original Image (Left) and Image after applying Mean Blur (Right)</p></div></div></div><div class="section" title="The Gaussian blur method"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec09"/>The Gaussian blur method</h2></div></div></div><p>The <a id="id25" class="indexterm"/>Gaussian blur<a id="id26" class="indexterm"/> is the most commonly used method of blurring. The Gaussian kernel <a id="id27" class="indexterm"/>is obtained using the Gaussian function given as follows:</p><div class="mediaobject"><img src="graphics/B02052_01_23.jpg" alt="The Gaussian blur method"/></div><div class="mediaobject"><img src="graphics/B02052_01_09.jpg" alt="The Gaussian blur method"/><div class="caption"><p>The Gaussian Function in one and two dimensions</p></div></div><p>The <a id="id28" class="indexterm"/>anchor pixel <a id="id29" class="indexterm"/>is considered to be at (0, 0). As we can see, the pixels closer to the anchor pixel are given a higher weightage than those further away from it. This is generally the ideal scenario, as the nearby pixels should influence the result of a particular pixel more than those further away. The <a id="id30" class="indexterm"/>Gaussian kernels <a id="id31" class="indexterm"/>of size 3, 5, and 7 are shown in the following figure (image of 'Gaussian kernels' taken from <a class="ulink" href="http://www1.adept.com/main/KE/DATA/ACE/AdeptSight_User/ImageProcessing_Operations.html">http://www1.adept.com/main/KE/DATA/ACE/AdeptSight_User/ImageProcessing_Operations.html</a>):</p><div class="mediaobject"><img src="graphics/B02052_01_10.jpg" alt="The Gaussian blur method"/><div class="caption"><p>These are the Gaussian kernels of size 3 x 3, 5 x 5 and 7 x 7.</p></div></div><p>To use the Gaussian blur in your application, OpenCV provides a built-in function called <a id="id32" class="indexterm"/>
<span class="strong"><strong>GaussianBlur</strong></span>. We will use this and get the following resulting image. We will add a new case to the same switch block we used earlier. For this code, declare a constant <code class="literal">GAUSSIAN_BLUR</code> with value 2:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.GAUSSIAN_BLUR:
    Imgproc.GaussianBlur(src, src, new Size(3,3), 0);
    break;</pre></div><div class="mediaobject"><img src="graphics/B02052_01_11.jpg" alt="The Gaussian blur method"/><div class="caption"><p>Image after applying Gaussian blur on the original image</p></div></div></div><div class="section" title="The median blur method"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec10"/>The median blur method</h2></div></div></div><p>One of the<a id="id33" class="indexterm"/> common<a id="id34" class="indexterm"/> types of noise present in images is called salt-and-pepper noise. In this kind of noise, sparsely occurring black and white pixels are distributed over the image. To remove this type of noise, we use median blur. In this kind of blur, we arrange the pixels covered by our kernel in ascending/descending order, and set the value of the middle element as the final value of the anchor pixel. The advantage of using this type of filtering is that salt-and-pepper noise is sparsely occurring, and so its influence is only over a small number of pixels when averaging their values. Thus, over a bigger area, the number of noise pixels is fewer than the number of pixels that are useful, as shown in the following image:</p><div class="mediaobject"><img src="graphics/B02052_01_12.jpg" alt="The median blur method"/><div class="caption"><p>Example of salt-and-pepper noise</p></div></div><p>To apply<a id="id35" class="indexterm"/> median blur<a id="id36" class="indexterm"/> in OpenCV, we use the built-in function <code class="literal">medianBlur</code>. As in the previous cases, we have to add a button and add the <code class="literal">OnClickListener</code> functions. We will add another case condition for this operation:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.MEDIAN_BLUR:
    Imgproc.medianBlur(src, src, 3);
    break;</pre></div><div class="mediaobject"><img src="graphics/B02052_01_13.jpg" alt="The median blur method"/><div class="caption"><p>Resulting image after applying median blur</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note03"/>Note</h3><p>Median blur does not use convolution.</p></div></div></div><div class="section" title="Creating custom kernels"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec11"/>Creating custom kernels</h2></div></div></div><p>We have<a id="id37" class="indexterm"/> seen <a id="id38" class="indexterm"/>how different types of kernels affect the image. What if we want to create our own kernels for different applications that aren't natively offered by OpenCV? In this section, we will see how we can achieve just that. We will try to form a sharper image from a given input.</p><p>Sharpening can be thought of as a linear filtering operation where the anchor pixel has a high weightage and the surrounding pixels have a low weightage. A kernel satisfying this constraint is shown in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>-1</p>
</td><td style="text-align: left" valign="top">
<p>0</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>-1</p>
</td><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>-1</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>-1</p>
</td><td style="text-align: left" valign="top">
<p>0</p>
</td></tr></tbody></table></div><p>We will use this kernel to perform the convolution on our image:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.SHARPEN:
    Mat kernel = new Mat(3,3,CvType.CV_16SC1); 
          kernel.put(0, 0, 0, -1, 0, -1, 5, -1, 0, -1, 0);</pre></div><p>Here we<a id="id39" class="indexterm"/> have given the image depth as <code class="literal">16SC1</code>. This means that each pixel in our image contains a 16-bit signed integer (16S) and the image has 1 channel (C1).</p><p>Now we <a id="id40" class="indexterm"/>will use the <code class="literal">filter2D()</code>function, which performs the actual convolution when given the input image and a kernel. We will show the image in an ImageView. We will add another case to the switch block created earlier:</p><div class="informalexample"><pre class="programlisting">    Imgproc.filter2D(src, src, src.depth(), kernel);</pre></div><div class="mediaobject"><img src="graphics/B02052_01_14.jpg" alt="Creating custom kernels"/><div class="caption"><p>Original image (left) and sharpened image (right)</p></div></div></div><div class="section" title="Morphological operations"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec12"/>Morphological operations</h2></div></div></div><p>Morphological operations <a id="id41" class="indexterm"/>are a set of operations that <a id="id42" class="indexterm"/>process an image based on the features of the image and a structuring element. These generally work on binary or grayscale images. We will take a look at some basic morphological operations before moving on to more advance ones.</p><div class="section" title="Dilation"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec01"/>Dilation</h3></div></div></div><p>Dilation <a id="id43" class="indexterm"/>is a method by which the bright regions <a id="id44" class="indexterm"/>of an image are expanded. To achieve this, we take a kernel of the desired size and replace the anchor pixel with the maximum value overlapped by the kernel. Dilation can be used to merge objects that might have been broken off.</p><div class="mediaobject"><img src="graphics/B02052_01_15.jpg" alt="Dilation"/><div class="caption"><p>A binary image (left) and the result after applying dilation (right)</p></div></div><p>To apply<a id="id45" class="indexterm"/> this operation, we use the <code class="literal">dilate()</code>function. We need to use a kernel to perform dilation. We use the <code class="literal">getStructuringElement()</code> OpenCV function to get the required kernel.</p><p>OpenCV provides <code class="literal">MORPH_RECT</code>, <code class="literal">MORPH_CROSS</code>, and <code class="literal">MORPH_ELLIPSE</code> as options to create our required kernels:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.DILATE:
    Mat kernelDilate = Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size(3, 3));
    Imgproc.dilate(src, src, kernelDilate);
    break;</pre></div><div class="mediaobject"><img src="graphics/B02052_01_16.jpg" alt="Dilation"/><div class="caption"><p>Original image (left) and dilated image (right)</p></div></div><p>If we <a id="id46" class="indexterm"/>use a <a id="id47" class="indexterm"/>rectangular structuring element, the image grows in the shape of a rectangle. Similarly, if we use an elliptical structuring element, the image grows in the shape of an ellipse.</p></div><div class="section" title="Erosion"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec02"/>Erosion</h3></div></div></div><p>Similarly, erosion <a id="id48" class="indexterm"/>is a<a id="id49" class="indexterm"/> method by which the dark regions of an image are expanded. To achieve this, we take a kernel of the desired size and replace the anchor pixel by the minimum value overlapped by the kernel. Erosion can be used to remove the noise from images.</p><div class="mediaobject"><img src="graphics/B02052_01_17.jpg" alt="Erosion"/><div class="caption"><p>A binary image (left) and the result after applying erosion (right)</p></div></div><p>To <a id="id50" class="indexterm"/>apply<a id="id51" class="indexterm"/> this operation, we use the <code class="literal">erode()</code> function:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.ERODE:
    Mat kernelErode = Imgproc.getStructuringElement(Imgproc.MORPH_ELLIPSE, new Size(5, 5));
    Imgproc.erode(src, src, kernelErode);
         break;</pre></div><div class="mediaobject"><img src="graphics/B02052_01_18.jpg" alt="Erosion"/><div class="caption"><p>Original image (left) and eroded image (right)</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note04"/>Note</h3><p>Erosion and dilation are not inverse operations.</p></div></div></div></div><div class="section" title="Thresholding"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec13"/>Thresholding</h2></div></div></div><p>Thresholding<a id="id52" class="indexterm"/> is the<a id="id53" class="indexterm"/> method of segmenting out sections of an image that we would like to analyze. The value of each pixel is compared to a predefined threshold value and based on this result, we modify the value of the pixel. OpenCV provides five types of thresholding operations.</p><p>To perform thresholding, we will use the following code as a template and change the parameters as per the kind of thresholding required. We need to replace <code class="literal">THRESH_CONSTANT</code> with the constant for the required method of thresholding:</p><div class="informalexample"><pre class="programlisting">case HomeActivity.THRESHOLD:
    Imgproc.threshold(src, src, 100, 255, Imgproc.THRESH_CONSTANT);
    break;</pre></div><p>Here, <code class="literal">100</code> is the<a id="id54" class="indexterm"/> threshold value and <code class="literal">255</code> is the maximum value (the value of pure white).</p><p>The <a id="id55" class="indexterm"/>constants are listed in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Thresholding Method Name</p>
</th><th style="text-align: left" valign="bottom">
<p>Thresholding Function</p>
</th><th style="text-align: left" valign="bottom">
<p>Constant</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Binary threshold</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B02052_01_24_a.jpg" alt="Thresholding"/></div>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">THRESH_BINARY</code>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Threshold to zero</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B02052_01_24_b.jpg" alt="Thresholding"/></div>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">THRESH_TOZERO</code>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Truncate</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B02052_01_24_c.jpg" alt="Thresholding"/></div>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">THRESH_TRUNC</code>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Binary threshold, inverted</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B02052_01_24_d.jpg" alt="Thresholding"/></div>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">THRESH_BINARY_INV</code>
</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Threshold to <a id="id56" class="indexterm"/>zero, inverted</p>
</td><td style="text-align: left" valign="top">
<div class="mediaobject"><img src="graphics/B02052_01_24_e.jpg" alt="Thresholding"/></div>
</td><td style="text-align: left" valign="top">
<p>
<code class="literal">THRESH_TOZERO_INV</code>
</p>
</td></tr></tbody></table></div><p>The following image for<a id="id57" class="indexterm"/> thresholding results is taken from <a class="ulink" href="http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html">http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html</a>:</p><div class="mediaobject"><img src="graphics/B02052_01_19.jpg" alt="Thresholding"/></div></div><div class="section" title="Adaptive thresholding"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec14"/>Adaptive thresholding</h2></div></div></div><p>Setting a<a id="id58" class="indexterm"/> global threshold <a id="id59" class="indexterm"/>value may not be the best option when performing segmentation. Lighting conditions affect the intensity of pixels. So, to overcome this limitation, we will try to calculate the threshold value for any pixel based on its neighboring pixels.</p><p>We will use three parameters to calculate the adaptive threshold of an image:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem"><span class="strong"><strong>Adaptive method</strong></span>: The following<a id="id60" class="indexterm"/> are the two methods we will use:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">ADAPTIVE_THRESH_MEAN_C</code>: The threshold value is the mean of the neighboring pixels</li><li class="listitem" style="list-style-type: disc"><code class="literal">ADAPTIVE_THRESH_GAUSSIAN_C</code>: The threshold value is the weighted sum of the neighboring pixel values, where weights are Gaussian kernels</li></ul></div></li><li class="listitem"><span class="strong"><strong>Block Size</strong></span>: This is <a id="id61" class="indexterm"/>the size of the neighborhood</li><li class="listitem"><span class="strong"><strong>C</strong></span>: This is the <a id="id62" class="indexterm"/>constant that has to be subtracted from the mean/weighted mean calculated for each pixel:<div class="informalexample"><pre class="programlisting">case HomeActivity.ADAPTIVE_THRESHOLD:
    Imgproc.cvtColor(src, src, Imgproc.COLOR_BGR2GRAY);
    Imgproc.adaptiveThreshold(src, src, 255, Imgproc.ADAPTIVE_THRESH_GAUSSIAN_C, Imgproc.THRESH_BINARY, 3, 0);
    break;</pre></div><div class="mediaobject"><img src="graphics/B02052_01_20.jpg" alt="Adaptive thresholding"/><div class="caption"><p>Original image (left) and image after applying Adaptive thresholding (right)</p></div></div></li></ol></div><p>Here, the<a id="id63" class="indexterm"/> resulting image has a lot of noise present. This can be avoided by applying a blurring operation before applying adaptive thresholding, so as to smooth the image.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec12"/>Summary</h1></div></div></div><p>In this chapter, we have learnt how to get started with using OpenCV in your Android project. Then we looked at different filters in image processing, especially linear filters, and how they can be implemented on an Android device. These filters will later form the basis of any computer vision application that you try to build. In the following chapters, we will look at more complex image filters, and also see how to extract information from the images in the form of edges, corners, and the like.</p></div></body></html>