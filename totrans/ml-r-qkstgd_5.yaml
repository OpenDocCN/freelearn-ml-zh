- en: Predicting Failures of Banks - Multivariate Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测银行失败 - 多元分析
- en: In this chapter, we are going to apply different algorithms with the aim of
    obtaining a good model using combinations of our predictors. The most common algorithm
    that's used in credit risk applications, such as credit scoring and rating, is
    logistic regression. In this chapter, we will see how other algorithms can be
    applied to solve some of the weaknesses of logistic regression.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将应用不同的算法，目的是通过我们的预测因子的组合来获得一个好的模型。在信用风险应用中，如信用评分和评级，最常用的算法是逻辑回归。在本章中，我们将看到其他算法如何应用于解决逻辑回归的一些弱点。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下主题：
- en: Logistic regression
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Regularized methods
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化方法
- en: Testing a random forest model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试随机森林模型
- en: Gradient boosting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Deep learning in neural networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络中的深度学习
- en: Support vector machines
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Ensembles
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成方法
- en: Automatic machine learning
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动机器学习
- en: Logistic regression
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Mathematically, a binary logistic model has a dependent variable with two categorical
    values. In our example, these values relate to whether or not a bank is solvent.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，二元逻辑模型有一个具有两个分类值的因变量。在我们的例子中，这些值与银行是否有偿付能力相关。
- en: 'In a logistic model, **log odds** refers to the logarithm of the odds for a
    class, which is a linear combination of one or more independent variables, as
    follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑模型中，**对数几率**指的是一个类别的对数几率，它是一个或多个独立变量的线性组合，如下所示：
- en: '![](img/d8748302-fdf3-43b2-adf6-f6774fcc2739.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d8748302-fdf3-43b2-adf6-f6774fcc2739.png)'
- en: The coefficients (beta values, *β*) of the logistic regression algorithm must
    be estimated using maximum likelihood estimation. Maximum likelihood estimation
    involves getting values for the regression coefficients that minimize the error
    in the probabilities that are predicted by the model and the real observed case.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归算法的系数（beta值，*β*）必须使用最大似然估计来估计。最大似然估计涉及获取回归系数的值，以最小化模型预测的概率与实际观察案例之间的误差。
- en: 'Logistic regression is very sensitive to the presence of outlier values, so
    high correlations in variables should be avoided. Logistic regression in R can
    be applied as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归对异常值的存在非常敏感，因此应避免变量之间的高相关性。在R中应用逻辑回归的方法如下：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code runs without problems, but a warning message appears. If the variables
    are highly correlated or collinearity exists, it is expected that the model parameters
    and the variance are inflated.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 代码运行没有问题，但出现了一个警告信息。如果变量高度相关或存在多重共线性，模型参数和方差膨胀是预期的。
- en: The high variance is not due to accurate or good predictors, but is instead
    due to a misspecified model with redundant predictors. Thus, the maximum likelihood
    is increased by simply adding more parameters, which results in overfitting.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 高方差不是由于准确的或好的预测因子，而是由于一个未指定且有冗余预测因子的模型。因此，通过简单地添加更多参数来增加最大似然，这会导致过拟合。
- en: 'We can observe the parameters of the model with the `summary()` function:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`summary()`函数观察模型的参数：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We can see that most of the variables in the last column of the preceding table
    are insignificant. In cases like this, the number of variables should be reduced
    in the regression, or another approach should be followed, such as a penalized
    or regularization method.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，前一个表的最后一列中的大多数变量都是不显著的。在这种情况下，应该减少回归中的变量数量，或者遵循另一种方法，例如惩罚或正则化方法。
- en: Regularized methods
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化方法
- en: 'There are three common approaches to using regularized methods:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则化方法有三种常见的方法：
- en: Lasso
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lasso
- en: Ridge
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岭回归
- en: Elastic net
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性网络
- en: In this section, we will see how these methods can be implemented in R. For
    these models, we will use the `h2o` package. This provides a predictive analysis
    platform to be used in machine learning that is open source, based on in-memory
    parameters, and distributed, fast, and scalable. It helps in creating models that
    are built on big data and is most suitable for enterprise applications as it enhances
    production quality.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到这些方法如何在R中实现。对于这些模型，我们将使用`h2o`包。这个包提供了一个开源的预测分析平台，用于机器学习，基于内存参数，分布式、快速且可扩展。它有助于创建基于大数据的模型，并且由于其提高了生产质量，因此最适合企业应用。
- en: For more information on the `h2o` package, please visit its documentation at
    [https://cran.r-project.org/web/packages/h2o/index.html](https://cran.r-project.org/web/packages/h2o/index.html).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`h2o`软件包的更多信息，请访问其文档[https://cran.r-project.org/web/packages/h2o/index.html](https://cran.r-project.org/web/packages/h2o/index.html)。
- en: This package is very useful because it summarizes several common machine learning
    algorithms in one package. Moreover, these algorithms can be executed in parallel
    on our own computer, as it is very fast. The package includes generalized linear
    naïve Bayes, distributed random forest, gradient boosting, and deep learning,
    among others.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此软件包非常有用，因为它在一个软件包中总结了几个常见的机器学习算法。此外，这些算法可以在我们的计算机上并行执行，因为它非常快。该软件包包括广义线性朴素贝叶斯、分布式随机森林、梯度提升和深度学习等。
- en: It is not necessary to have a high level of programming knowledge, because the
    package comes with a user interface.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要具备高级编程知识，因为该软件包自带用户界面。
- en: 'Let''s see how the package works. First, the package should be loaded:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个软件包是如何工作的。首先，应该加载软件包：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use the `h2o.init` method to initialize H2O. This method accepts other options
    that can be found in the package documentation:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`h2o.init`方法初始化H2O。此方法接受可在软件包文档中找到的其他选项：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The first step toward building our model involves placing our data in the H2O
    cluster/Java process. Before this step, we will ensure that our target is considered
    as a `factor` variable:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 建立我们的模型的第一步是将我们的数据放入H2O集群/Java进程。在此步骤之前，我们将确保我们的目标是作为`factor`变量考虑：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, let''s upload our data to the `h2o` cluster:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将我们的数据上传到`h2o`集群：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you close R and restart it later, you will need to upload the datasets again,
    as in the preceding code.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您关闭R并在稍后重新启动它，您将需要再次上传数据集，如前面的代码所示。
- en: 'We can check that the data has been uploaded correctly with the following command:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令检查数据是否已正确上传：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The package contains an easy interface that allows us to create different models
    when we run it in our browser. In general, the interface can be launched by writing
    the following address in our web browser, `http://localhost:54321/flow/index.html`.
    You will be faced with a page like the one that''s shown in the following screenshot.
    In the Model tab, we can see a list with all of the available models that are
    implemented in this package:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该软件包包含一个易于使用的界面，允许我们在浏览器中运行时创建不同的模型。通常，可以通过在网页浏览器中写入以下地址来启动界面，`http://localhost:54321/flow/index.html`。您将面对一个类似于以下截图的页面。在模型选项卡中，我们可以看到该软件包中实现的所有可用模型的列表：
- en: '![](img/4f048b93-f077-4cfa-a381-12ba40c141bf.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4f048b93-f077-4cfa-a381-12ba40c141bf.png)'
- en: 'First, we are going to develop regularization models. For that, Generalized
    Linear Modelling… must be selected. This module includes the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将开发正则化模型。为此，必须选择广义线性建模…。本模块包括以下内容：
- en: Gaussian regression
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯回归
- en: Poisson regression
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泊松回归
- en: Binomial regression (classification)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二项式回归（分类）
- en: Multinomial classification
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式分类
- en: Gamma regression
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伽马回归
- en: Ordinal regression
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序回归
- en: 'As shown in the following screenshot, we should fill in the necessary parameters
    to train our model:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，我们应该填写必要的参数来训练我们的模型：
- en: '![](img/cd371ff1-ed26-4cdd-9a97-a8398f634f8d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cd371ff1-ed26-4cdd-9a97-a8398f634f8d.png)'
- en: 'We will fill in the following fields:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将填写以下字段：
- en: 'model_id: Here, we can specify the name that can be used as a reference by
    the model.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: model_id：在这里，我们可以指定模型可以引用的名称。
- en: 'training_frame: The dataset that we wish to use to build and train the model
    can be mentioned here, as this will be our training dataset.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: training_frame：我们希望用于构建和训练模型的数据库可以在这里提及，因为这将是我们的训练数据集。
- en: 'validation_frame: Here, the dataset that will be used to check the accuracy
    of the model is mentioned.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: validation_frame：在这里，提到的数据集将用于检查模型的准确性。
- en: 'nfolds: For validation, we require a certain number of folds to be mentioned
    here. In our case, the nfolds value is `5`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nfolds：为了验证，我们需要在此处提及一定数量的折数。在我们的案例中，nfolds的值是`5`。
- en: 'seed: This specifies the seed that will be used by the algorithm. We will use
    a **Random Number Generator** (**RNG**) for the components in the algorithm that
    require random numbers.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: seed：这指定了算法将使用的种子。我们将使用**随机数生成器**（**RNG**）为算法中需要随机数的组件提供随机数。
- en: 'response_column: This is the column to use as the dependent variable. In our
    case, the column is named Default.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: response_column：这是用作因变量的列。在我们的案例中，该列命名为Default。
- en: 'ignored_columns: In this section, it is possible to ignore variables in the
    training process. In our case, all of the variables are considered relevant.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ignored_columns：在本节中，可以在训练过程中忽略变量。在我们的情况下，所有变量都被认为是相关的。
- en: 'ignore_const_cols: This is a flag that indicates that the package should avoid
    constant variables.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ignore_const_cols：这是一个标志，表示包应避免常数变量。
- en: 'family: This specifies the model type. In our case, we want to train a regression
    model, so the family should be fixed as binomial, because our target variable
    has two possible values.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: family：这指定了模型类型。在我们的情况下，我们想要训练一个回归模型，因此family应该固定为二项式，因为我们的目标变量有两个可能的值。
- en: 'solver: This specifies the solver to use. We don''t change this value because
    no significant differences have been observed regardless of whether one solver
    or another is chosen. Hence, we will keep it as the default value.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: solver：这指定了要使用的求解器。我们不会更改此值，因为无论选择哪个求解器，都没有观察到显著差异。因此，我们将保持默认值。
- en: 'alpha: Here, you have to choose values for the regularization distribution
    from L1 to L2\. If you select 1, it will be a Lasso regression. If you select
    0, it will be a Ridge regression. If any value in between 0 and 1 is selected,
    you will have a mixture of both Lasso and Ridge. In our case, we will select 1\.
    One of the main advantages of the Lasso model is in the reduction of the number
    of variables because the trained models makes the coefficient of non-relevant
    variables zero, resulting in models that are simple, but accurate at the same
    time.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: alpha：在这里，您必须从L1到L2选择正则化分布的值。如果您选择1，它将是一个Lasso回归。如果您选择0，它将是一个Ridge回归。如果您选择0和1之间的任何值，您将得到Lasso和Ridge的混合。在我们的情况下，我们将选择1。Lasso模型的主要优点之一是减少变量的数量，因为训练模型将非相关变量的系数设为零，从而产生简单但同时又准确的模型。
- en: 'lambda_search: This parameter starts a search of the regularization strength.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: lambda_search：此参数启动对正则化强度的搜索。
- en: 'standardize: If this flag is marked, it means that numeric columns will be
    transformed to have a zero mean and zero unit variance.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化：如果此标志被标记，则表示数值列将被转换，以具有零均值和零单位方差。
- en: 'Finally, the Build model button trains the model. Although other options can
    be selected, the preceding specifications are sufficient:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，构建模型按钮训练模型。尽管可以选择其他选项，但前面的规格已经足够：
- en: '![](img/d64f8f47-f7f4-4f04-aed7-de9bf5fb2b4f.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d64f8f47-f7f4-4f04-aed7-de9bf5fb2b4f.png)'
- en: 'We can see that the model has been trained quickly. The View button provides
    us with some interesting details about the model:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到模型训练得很快。查看按钮为我们提供了有关模型的一些有趣细节：
- en: Model parameters
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型参数
- en: Scoring history
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 得分历史
- en: The **Receiver Operating Characteristic** (**ROC**) curve for training and validation
    samples
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和验证样本的**接收者操作特征**（ROC）曲线
- en: Standardized coefficient magnitudes
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化系数幅度
- en: Gains/Lift table for cross-validation, training, and validation samples
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证、训练和验证样本的增益/提升表
- en: Cross-validation models
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证模型
- en: Metrics
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标
- en: Coefficients
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系数
- en: 'Let''s see some of the main results:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些主要结果：
- en: '![](img/508719aa-acca-45b9-a847-ee4f09b73369.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/508719aa-acca-45b9-a847-ee4f09b73369.png)'
- en: As we can see, our Lasso model is trained with 108 different variables, but
    only 56 result in a model that has a coefficient greater than zero.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的Lasso模型是用108个不同的变量训练的，但只有56个变量导致系数大于零的模型。
- en: 'The model provides an almost perfect classification. In the training sample,
    the **Area under the curve** (**AUC**) reaches 99.51%. This value is slightly
    lower in the validation sample, with a value of 98.65%. The standardized variables
    are also relevant:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型提供了几乎完美的分类。在训练样本中，**曲线下面积**（AUC）达到99.51%。在验证样本中，此值略低，为98.65%。标准化变量也相关：
- en: '![](img/95ade899-eea3-4f92-b42c-62fbaf23cd3a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95ade899-eea3-4f92-b42c-62fbaf23cd3a.png)'
- en: If a variable is shown in blue, this indicates that the coefficient is positive.
    If it is negative, the color is orange.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个变量以蓝色显示，这表示系数是正的。如果是负的，颜色是橙色。
- en: As we can see, UBPRE626 looks like an important variable. It shows us how many
    times the total loans and lease-financing receivables surpassed the actual total
    of the equity capital. A positive sign here means a higher ratio, which also implies
    a higher probability that a bank will fail in its operations.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，UBPRE626看起来是一个重要的变量。它显示总贷款和租赁融资应收账款超过实际股本总额的次数。这里的正号意味着更高的比率，这也意味着银行在其运营中失败的概率更高。
- en: 'The top five relevant variables according to this figure are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个图，前五个相关变量如下：
- en: 'UBPRE626: The number of times net loans and lease-financing receivables exceed
    the total equity capital'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: UBPRE626：净贷款和租赁融资应收账款超过总股本次数
- en: 'UBPRE545: The total of the due and non-accrual loans and leases, divided by
    the allowance for the loan and lease losses'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: UBPRE545：应计和未实现贷款及租赁总额，除以贷款和租赁损失准备金
- en: 'UBPRE170: The total equity capital'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: UBPRE170：总股本
- en: 'UBPRE394: Other construction and land development loans, divided by the average
    gross loans and leases'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: UBPRE394：其他建筑和土地开发贷款，除以平均总贷款和租赁
- en: 'UBPRE672: One quarter of the annualized realized gains (or losses) of the securities,
    divided by average assets'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: UBPRE672：证券年度化实现收益（或损失）的四分之一，除以平均资产
- en: When looking at credit risks, it is important to understand which variables
    are most significant and the economic relevance of these variables. For example,
    it would not make sense if the higher the non-performing loans or loans with problems,
    the higher the solvency of a bank. We aren't concerned about the economic sense
    of the variables in our model, but this is a key issue for some models that are
    developed in financial institutions. If the variables don't have the expected
    sign, they have to be removed from the model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估信用风险时，了解哪些变量最为重要以及这些变量的经济相关性非常重要。例如，如果非正常贷款或有问题贷款越多，银行的偿债能力就越高，那就没有意义了。我们并不关心模型中变量的经济意义，但这对于金融机构开发的一些模型来说是一个关键问题。如果变量没有预期的符号，它们必须从模型中移除。
- en: 'In some cases, is necessary to test different combinations of parameters until
    you obtain the best model. For example, in the recently trained regularized model,
    we could have tried different values of the alpha parameter. To test different
    parameters at the same time, you need to execute the algorithms using code. Let''s
    have a look at how to do this. We will train the regularized models again, but
    using some code this time. First, we remove all the objects, including the recently
    created model, from the `h2o` system:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，有必要测试不同的参数组合，直到获得最佳模型。例如，在最近训练的正则化模型中，我们可以尝试不同的 alpha 参数值。要同时测试不同的参数，需要使用代码执行算法。让我们看看如何做。这次我们将再次训练正则化模型，但这次使用一些代码。首先，我们从
    `h2o` 系统中删除所有对象，包括最近创建的模型：
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we upload our training and validation samples again:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们再次上传我们的训练和验证样本：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s code our model. A grid of empty parameters is created as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写我们的模型。创建一个空参数网格如下：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we assign different parameters to be tested in this grid:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在网格中分配不同的参数进行测试：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As we can see, the parameters are exactly the same as those we used to train
    the previous model. The only difference is that we now use different alpha values
    at the same time, which corresponds to a Ridge regression, with a Lasso and an
    elastic net. The model is trained using the following code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，参数与我们用来训练先前模型的参数完全相同。唯一的区别是我们现在同时使用不同的 alpha 值，这对应于岭回归、Lasso 和弹性网络。模型使用以下代码进行训练：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'According to the previous code, the different models in the grid should be
    ordered by the AUC metric. Thus, we are interested in the first model:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 根据之前的代码，网格中的不同模型应该按照 AUC 指标排序。因此，我们对第一个模型感兴趣：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s take a look at some details about this model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个模型的一些细节：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The model with the best performance is a Ridge model. The performance of the
    model can be obtained as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表现最好的模型是一个岭回归模型。模型的性能可以通过以下方式获得：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `AUC` and the `Gini` index, which are the main metrics of performance, are
    only slightly higher than in the Lasso that we trained initially—at least in the
    training sample.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`AUC` 和 `Gini` 指数，作为性能的主要指标，仅略高于我们最初训练的 Lasso 模型——至少在训练样本中是这样。'
- en: 'The performance of the model in the test sample is also high:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在测试样本中的性能也很高：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Again, the results do not differ significantly in comparison with the Lasso
    model. Nevertheless, the number of coefficients in the Lasso model is lower, which
    makes it easier to interpret and more parsimonious.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Lasso 模型相比，结果没有显著差异。尽管如此，Lasso 模型的系数数量较少，这使得它更容易解释且更简洁。
- en: 'The total number of coefficients in the Ridge regression is equal to the number
    of variables in the dataset and the intercept of the model:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归中的系数总数等于数据集中的变量数量和模型的截距：
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we will store the predictions of each model in a new data frame. We can
    combine the results of the different models to obtain an additional model. Initially,
    our data frame will contain only the ID of each bank and the target variable:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将每个模型的预测结果存储在一个新的数据框中。我们可以将不同模型的成果结合起来，得到一个额外的模型。最初，我们的数据框将只包含每个银行的ID和目标变量：
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s calculate the model predictions and store them in the summary data frame:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算模型预测并将它们存储在汇总数据框中：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'When we run the previous code to calculate the performance of the model, we
    also obtain a confusion matrix. For example, in the test sample, we obtain the
    following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行前面的代码来计算模型的性能时，我们还获得了一个混淆矩阵。例如，在测试样本中，我们得到以下结果：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This package classifies a bank as a failed bank if its probability of defaulting
    is higher than 0.5, and is a successful bank otherwise.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 此软件包将违约概率高于0.5的银行分类为失败银行，否则为成功银行。
- en: According to this assumption, `40` banks are misclassified (`28`+`12`). Nevertheless,
    the cutoff of 0.5 is not actually correct, because the proportion of failed versus
    non-failed banks in the sample is different.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个假设，`40`家银行被错误分类（`28`+`12`）。然而，0.5的截止点实际上并不正确，因为在样本中失败银行与非失败银行的比率是不同的。
- en: 'The proportion of failed banks is actually only 4.696%, as shown in the following
    code :'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 失败银行的比率实际上仅为4.696%，如下代码所示：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Hence, it is more appropriate to consider a bank as failed if the probability
    of a bank defaulting is higher than this proportion:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果一个银行的违约概率高于这个比例，将其视为失败银行更为合适：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Thus, the new confusion table for the test sample is as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，测试样本的新混淆表如下：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: According to this table, the model misclassifies 86 banks (`78`+`8`). Almost
    all of the failed banks have been correctly classified. It will be difficult to
    obtain a better algorithm than this.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这张表，模型错误分类了86家银行（`78`+`8`）。几乎所有失败银行都被正确分类。要获得比这个更好的算法将非常困难。
- en: 'The model can be saved locally using `h2o.saveModel`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以使用`h2o.saveModel`本地保存：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We remove the irrelevant objects in the workspace and save it as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从工作区中移除无关的对象，并按以下方式保存：
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Remember that if you close R and load this workspace again, you should convert
    your train and test samples into `h2o` format again:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，如果你关闭R并再次加载此工作区，你应该再次将你的训练和测试样本转换为`h2o`格式：
- en: '[PRE25]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Testing a random forest model
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试随机森林模型
- en: A random forest is an ensemble of decision trees. In a decision tree, the training
    sample, which is based on the independent variables, will be split into two or
    more homogeneous sets. This algorithm deals with both categorical and continuous
    variables. The best attribute is selected using a recursive selection method and
    is split to form the leaf nodes. This continues until a criterion that's meant
    to stop the loop is met. Every tree that's created by the expansion of leaf nodes
    is considered to be a weak learner. This weak learner is built on top of the rows
    and columns of the subsets. The higher the number of trees, the lower the variance.
    Both classification and regression random forests calculate the average prediction
    of all of the trees to make a final prediction.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一组决策树。在决策树中，基于独立变量的训练样本将被分割成两个或更多同质集合。此算法处理分类变量和连续变量。使用递归选择方法选择最佳属性，并将其分割成叶节点。这会一直持续到满足停止循环的准则。通过叶节点的扩展创建的每个树都被视为一个弱学习器。这个弱学习器建立在子集的行和列之上。树的数量越多，方差越低。分类和回归随机森林都会计算所有树的平均预测，以做出最终预测。
- en: When a random forest is trained, some different parameters can be set. Among
    the most common parameters are the number of trees, the maximum number of variables,
    the size of terminal nodes, and the depth in each tree. Several tests should be
    carried out to find a balance between performance and overfitting. For example,
    the higher the number and the depth of the trees, the better the accuracy on a
    training set, but this increases the risk of overfitting. To obtain this balance,
    several parameters and combinations of parameters should be tested on the validation
    set, and then they should be cross-validated during the training process.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练随机森林时，可以设置一些不同的参数。其中最常见的参数包括树的数量、最大变量数、终端节点的大小以及每棵树的深度。应该进行多次测试，以在性能和过拟合之间找到平衡。例如，树的数量和深度越高，训练集上的准确率越好，但这增加了过拟合的风险。为了获得这种平衡，应该在验证集上测试几个参数及其参数组合，然后在训练过程中进行交叉验证。
- en: 'Again, this algorithm is easy to implement in the `h2o` package using the visual
    guide in a browser. The grid of the parameters should be implemented by coding
    it. The code is almost the same as the one in the previous model. This time, however,
    the process is more time-consuming:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这个算法在 `h2o` 包中很容易实现，可以使用浏览器中的可视化指南。参数网格应该通过编码实现。代码几乎与先前的模型相同。然而，这次过程更耗时：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As we can see, the combinations in the number of trees (`ntrees`), the depth
    (`max_depth`), and the number of variables to be considered in each tree (`mtries`)
    are tested. The resulting models are ordered using the AUC metric.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，树的数量（`ntrees`）、深度（`max_depth`）和每棵树中要考虑的变量数量（`mtries`）的组合被测试。使用 AUC 指标对生成的模型进行排序。
- en: '`27` different models have been trained according to the preceding specifications.
    The first model, or the model that has the best accuracy, is selected:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 preceding 规范，已经训练了 `27` 个不同的模型。选择第一个模型，或者准确率最高的模型：
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The performance of this model is obtained for train and test samples:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在训练和测试样本上的性能如下：
- en: '[PRE28]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As you can see, the code is exactly the same as the previous model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，代码与先前的模型完全相同。
- en: 'Now, we find the performance of the test or validation sample using the following
    code:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用以下代码找到测试或验证样本的性能：
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The results are almost perfect in both samples. The importance of the variable
    can be obtained as well:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 两个样本的结果几乎完美。可以获取变量的重要性：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The preceding code generates the following output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/2105e9a6-9c14-4225-a3cc-fb03192e5ff4.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2105e9a6-9c14-4225-a3cc-fb03192e5ff4.png)'
- en: 'Just like Ridge regression, the probability of bankruptcy will be stored for
    both the train and validation samples:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 就像岭回归一样，破产的概率将存储在训练和验证样本中：
- en: '[PRE31]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, we can compute the confusion matrix. Remember that the cutoff to classify
    a bank regarding its probability of bankruptcy is determined based on the observed
    proportion of bad banks in the total sample:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以计算混淆矩阵。记住，根据观察到的坏银行在总样本中的比例，确定将银行分类为破产概率的截止值：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If the random forest and Ridge regression models are compared, we can see that
    random forest only misclassifies five failed banks, while there are 12 misclassified
    banks in the Ridge regression. Nevertheless, the random forest classifies more
    solvent banks as failed banks than Ridge regression, meaning that it has a high
    level of false positives.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将随机森林和岭回归模型进行比较，我们可以看到随机森林只错误分类了五家失败的银行，而岭回归中有 12 家银行被错误分类。尽管如此，随机森林将更多有偿付能力的银行错误分类为失败的银行，这意味着它有较高的假阳性率。
- en: 'The irrelevant objects are, again, removed from the workspace. Moreover, we
    save a backup of our workspace:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 无关对象再次从工作区中移除。此外，我们备份了我们的工作区：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Gradient boosting
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升
- en: '**Gradient boosting** means combining weak and average predictors to acquire
    one strong predictor. This ensures robustness. It is similar to a random forest,
    which is mainly based on decision trees. The difference is that the sample is
    not modified from one tree to another; only the weights of the different observations
    are modified.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**梯度提升**意味着将弱预测器和平均预测器结合以获得一个强预测器。这确保了鲁棒性。它与随机森林类似，主要基于决策树。区别在于样本在树之间没有修改；只有不同观察的权重被修改。'
- en: Boosting trains trees sequentially by using information from previously trained
    trees. For this, we first need to create decision trees using the training dataset.
    Then, we need to create another model that does nothing but rectify the errors
    that occurred in the training model. This process is repeated sequentially until
    the specified number of trees, or some other stopping rule, is reached.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 提升通过使用先前训练的树的信息按顺序训练树。为此，我们首先需要使用训练数据集创建决策树。然后，我们需要创建另一个模型，它除了纠正训练模型中发生的错误之外什么都不做。这个过程会按顺序重复，直到达到指定的树的数量或达到某个停止规则。
- en: More specific details about the algorithm can be found in the documentation
    of the `h2o` package. While training the algorithm, we will need to define parameters
    such as the number of trees that we will combine and the minimum observation in
    each node, just like we did for the random forests.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 关于该算法的更具体细节可以在`h2o`包的文档中找到。在训练算法时，我们需要定义诸如我们将要组合的树的数量和每个节点中的最小观察值等参数，就像我们在随机森林中做的那样。
- en: The shrinkage parameter, or the rate at which boosting learns, can alter the
    performance of the model. We will need to consider the results of many experiments
    to determine the optimal parameters to ensure a high accuracy.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩参数，或者说提升学习的学习速率，可以改变模型的性能。我们需要考虑许多实验的结果，以确定最佳参数，确保高精度。
- en: 'Our grid of parameters collects different combinations of the number of trees
    and the `max_depth` parameter:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的参数网格收集了树的数量和`max_depth`参数的不同组合：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Different models will be trained by executing the following code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下代码将训练不同的模型：
- en: '[PRE35]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The grids are ordered by `AUC`. The results are as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 网格是按照`AUC`排序的。结果如下：
- en: '[PRE36]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Most models obtain a perfect classification. This might be a sign of overfitting.
    Let''s take a look at the performance of the first model on the validation sample:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数模型获得了完美的分类。这可能是一个过拟合的迹象。让我们看看第一个模型在验证样本上的性能：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The results are very good, even in the test sample. The first model is selected
    and the predictions are stored, as in the previous models:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常好，甚至在测试样本中也是如此。选择了第一个模型，并将预测存储起来，就像之前的模型一样：
- en: '[PRE38]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Finally, the confusion table in the test sample is calculated:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，测试样本中的混淆表被计算出来：
- en: '[PRE39]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'A total of 14 failed banks and 25 non-failed banks are misclassified. Let''s
    save the results:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 总共有14家破产银行和25家非破产银行被错误分类。让我们保存结果：
- en: '[PRE40]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Deep learning in neural networks
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络中的深度学习
- en: For machine learning, we need systems that can process nonlinear and unrelated
    sets of data. This is very important so that we can make predictions for bankruptcy
    problems, since the relationship between the default and explanatory variables
    will rarely be linear. Therefore, using neural networks is the best possible solution.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习，我们需要能够处理非线性且无关数据集的系统。这对于我们预测破产问题非常重要，因为违约变量和解释变量之间的关系很少是线性的。因此，使用神经网络是最佳解决方案。
- en: '**Artificial neural networks** (**ANNs**) have long since been used to solve
    bankruptcy problems. An ANN is a computer system that has a number of interconnected
    processors. These processors provide outputs by processing information and by
    responding dynamically to the inputs that are provided. A prominent and basic
    example of ANN is the **multilayer perceptron** (**MLP**). An MLP can be represented
    as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工神经网络**（**ANNs**）长期以来一直被用来解决破产问题。ANN是一个具有多个相互连接处理器的计算机系统。这些处理器通过处理信息和动态响应提供的输入来提供输出。ANN的一个突出和基本示例是**多层感知器**（**MLP**）。MLP可以表示如下：'
- en: '![](img/06c35f9e-3a7d-40f6-8910-7f225859bd6b.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/06c35f9e-3a7d-40f6-8910-7f225859bd6b.png)'
- en: Except for the input nodes, each node is a neuron that uses a nonlinear activation
    function, which was sent in.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 除了输入节点外，每个节点都是一个使用非线性激活函数的神经元，该函数被发送进来。
- en: As is evident from its diagram, an MLP is nothing but a **feed-forward neural
    network**. This means that the input information that's provided will only move
    in a forward direction. This type of network usually consists of one input, one
    hidden layer, and one output layer. The input layer represents the input data
    of the model, or the variables. In our case, these are the financial variables.
    No calculations are made in this layer. Hidden layers are where intermediate processing
    or computation is done. They perform computation and then transfer the weights
    (the signals or information) from the input layer to the following layer. Finally,
    the output layer takes inputs from the hidden layer and calculates the outputs
    of the network. The input nodes use a nonlinear activation function to send information
    from one layer to the next. The purpose of the activation function is to transform
    the input signal into an output signal that models complex nonlinear patterns.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 从其图表中可以看出，多层感知器（MLP）不过是一个**前馈神经网络**。这意味着提供的输入信息将只向前移动。这种类型的网络通常由一个输入层、一个隐藏层和一个输出层组成。输入层代表模型的输入数据，或变量。在我们的案例中，这些是金融变量。在这个层中不进行任何计算。隐藏层是进行中间处理或计算的地方。它们执行计算，然后将权重（信号或信息）从输入层传递到下一层。最后，输出层从隐藏层接收输入并计算网络的输出。输入节点使用非线性激活函数将信息从一层传递到下一层。激活函数的目的是将输入信号转换为输出信号，以模拟复杂的非线性模式。
- en: Perceptrons networks learn by modifying the weights after every set of data
    is processed. These weights specify the number of errors that occur when processing
    the input, which is obtained by comparing the expected output.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器网络通过在处理完每一组数据后修改权重来学习。这些权重指定了处理输入时发生的错误数量，这是通过比较期望的输出获得的。
- en: Is deep learning different from MLP? MLP is just one type of deep learning algorithm.
    In many cases, deep learning is different from an MLP network, but only because
    of the complexity in the calculations and the number of hidden layers. Deep learning
    can be considered an MLP with two or more hidden layers. When two or more hidden
    layers are included, the learning process should be different as well, because
    the backpropagation learning rule that's used in MLP fails. The perceptron update
    rule is prone to vanishing and exploding gradients, making it difficult to train
    networks with more than one or two layers.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习与MLP有何不同？MLP只是深度学习算法的一种。在许多情况下，深度学习与MLP网络不同，但这仅仅是因为计算复杂性和隐藏层数量的不同。深度学习可以被视为具有两个或更多隐藏层的MLP。当包含两个或更多隐藏层时，学习过程也应该有所不同，因为MLP中使用的反向传播学习规则将失效。感知器更新规则容易产生消失和爆炸梯度，这使得训练多于一层或两层的网络变得困难。
- en: Designing a neural network
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计神经网络
- en: When designing a multilayer network, ensure that you determine the appropriate
    number of required layers for better accuracy and precision. Often, for many models,
    just one hidden layer is enough to solve the problem of classification. Nevertheless,
    the use of many hidden layers has demonstrated its usefulness in areas such as
    speech recognition or object detection, among others. Another thing to consider
    is the number of neurons in every hidden layer. This is a very important aspect.
    Mistakes in estimating these values can lead to problems such as overfitting,
    when too many neurons are added, and underfitting, when not enough neurons are
    added.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计多层网络时，确保你确定适当的层数以获得更好的准确性和精度。通常，对于许多模型来说，仅仅一个隐藏层就足以解决分类问题。然而，使用多个隐藏层已经在语音识别或物体检测等领域证明了其有用性。另一个需要考虑的是每个隐藏层中的神经元数量。这是一个非常重要的方面。估计这些值时的错误可能导致过度拟合（当添加太多神经元时）和欠拟合（当添加的神经元不足时）等问题。
- en: Training a neural network
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: 'The `h2o` package helps us train the neural networks. Deep learning models
    have many input parameters. In this exercise, the following parameters will be
    tested:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`h2o`包帮助我们训练神经网络。深度学习模型有许多输入参数。在这个练习中，以下参数将被测试：'
- en: '[PRE41]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here, we will test three structures: first, a network containing only a hidden
    layer with 25 neurons, then a network with three hidden layers with 32 neurons
    in each layer, and finally, a two hidden layer network with 64 neurons in each
    layer.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将测试三种结构：首先，一个只包含一个包含25个神经元的隐藏层的网络，然后是一个包含三个隐藏层，每个层有32个神经元的网络，最后是一个包含两个隐藏层，每个层有64个神经元的网络。
- en: A neural network learns, and neurons progressively specialize in values for
    specific variables. If neurons are too specialized in the training set, there
    is a high risk of overfitting. To avoid overfitting, the `input_dropout_ratio`
    command is included. The dropout technique is a regularization approach for neural
    network models to improve the generalization of neural networks.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络学习，神经元逐渐在特定变量的值上实现专业化。如果神经元在训练集中过于专业化，就有很高的过拟合风险。为了避免过拟合，包含了`input_dropout_ratio`命令。dropout技术是神经网络模型的一种正则化方法，用于提高神经网络的泛化能力。
- en: During training, the dropout approach randomly selects neurons and ignores them
    during training. In practice, at each training step, a different network is created
    because some of the random units are removed and trained using backpropagation,
    as usual. This forces the network to learn several independent representations
    of the patterns with identical input and output, improving the generalization.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，dropout方法会随机选择神经元并在训练中忽略它们。在实践中，在每一步训练中，都会创建一个不同的网络，因为一些随机单元被移除，并使用反向传播进行训练，就像通常一样。这迫使网络学习具有相同输入和输出的多个独立表示，从而提高泛化能力。
- en: To obtain more information related to the dropout approach, I recommend the
    original paper, *Dropout:* **A Sim*ple Way to Prevent Neural Networks from Overfitting*,
    by Nitish Srivastava et al. It is available at [https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取有关dropout方法的更多信息，我建议阅读原始论文，*Dropout:* **一种简单防止神经网络过拟合的方法*，作者为Nitish Srivastava等人。该论文可在[https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)找到。
- en: The suggested values for the input layer dropout ratio are 0.1 or 0.2\. Finally,
    with the `rate` command, we can specify the learning rate. Remember, if the learning
    rate is set too high, the model may become less stable, and if it is set too low,
    then the convergence will be very slow.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 建议的输入层dropout比值为0.1或0.2。最后，使用`rate`命令，我们可以指定学习率。记住，如果学习率设置得太高，模型可能变得不稳定；如果设置得太低，则收敛将非常缓慢。
- en: 'Let''s write some training code:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一些训练代码：
- en: '[PRE42]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The parameters in the preceding code can be described as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码中的参数可以描述如下：
- en: '`epochs`: The value that''s specified here determines the number of times the
    dataset has to be streamed while learning.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：这里指定的值决定了在学习过程中数据集需要流式传输的次数。'
- en: '`stopping_metric`: This specifies the metric to use for early stopping, which
    in our case is AUC.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stopping_metric`：这指定了用于早期停止的指标，在我们的案例中是AUC。'
- en: '`stopping_tolerance` and `stopping rounds`: These determine a tolerance value
    before the model stops learning, and a stopping value that prevents the model
    from learning when the `stopping_metric` doesn''t improve after the number of
    rounds specified, respectively. When cross-fold validation is specified (as in
    our case), this option will apply on all cross-validation models. In our case,
    we set the options of `stopping_tolerance=1e-2` and `stopping_rounds = 2`, which
    means that the model won''t be trained after 2 rounds of iterations or if there
    isn''t an improvement of at least 2% ( `1e-2`).'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stopping_tolerance`和`stopping_rounds`：这些参数分别确定在模型停止学习前的容忍值和停止值，当`stopping_metric`在指定轮次后没有改善时，防止模型继续学习。当指定交叉验证（如我们案例中所示）时，此选项将应用于所有交叉验证模型。在我们的案例中，我们设置了`stopping_tolerance=1e-2`和`stopping_rounds
    = 2`，这意味着模型将在2轮迭代后停止训练，或者如果没有至少2%（`1e-2`）的改善。'
- en: '`score_duty_cycle`: This indicates how much time to spend scoring versus training.
    The values are percentages ranging from 0 to 1\. Lower values indicate more training.
    The default value of this option is 0.1, which indicates that 10% of the time
    should be spent on scoring and the remaining 90% should be spent on training.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_duty_cycle`：这表示在评分和训练之间花费多少时间。这些值是介于0到1之间的百分比。较低的值表示更多的训练。此选项的默认值为0.1，表示应该花费10%的时间进行评分，剩余的90%用于训练。'
- en: '`l1` and `l2`: The value that''s added here is the regularization index, which
    ensures better generalization and stability.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l1`和`l2`：这里添加的值是正则化指数，它确保了更好的泛化能力和稳定性。'
- en: '`activation`: Activation functions such as `tanh`, `tanh with dropout`, `Maxout`,
    and others can be mentioned here.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation`：可以在此处提及如`tanh`、`tanh with dropout`、`Maxout`等激活函数。'
- en: '`nfolds`: This indicates the number of folds for cross-validation. The training
    process is very time-consuming because several configurations are tested. The
    performance of the different configurations can be obtained by running the following
    code:'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfolds`：这表示交叉验证的折数。由于要测试多个配置，因此训练过程非常耗时。可以通过运行以下代码来获得不同配置的性能：'
- en: '[PRE43]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The best model is obtained with three hidden layers of 32 units, a dropout ratio
    of `0.25`, and a learning rate of `0.02`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三个具有32个单位的隐藏层、`0.25`的dropout比率和`0.02`的学习率获得了最佳模型。
- en: 'The best model is selected as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择如下：
- en: '[PRE44]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The performance is obtained for the test sample:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 测试样本的性能如下：
- en: '[PRE45]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'As in the previous models, the predictions on the training and validation samples
    are stored:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前的模型一样，训练和验证样本的预测被存储：
- en: '[PRE46]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The confusion matrix is also obtained for the validation sample:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 验证样本的混淆矩阵也获得了：
- en: '[PRE47]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Support vector machines
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: 'The **support vector machine** (**SVM**) algorithm is a supervised learning
    technique. To understand this algorithm, take a look at the following diagram
    for the optimal hyperplane and maximum margin:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）算法是一种监督学习技术。为了理解这个算法，请查看以下图中关于最优超平面和最大边界的图示：'
- en: '![](img/c68909aa-0f0f-4048-be2f-80e8bc1047f3.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c68909aa-0f0f-4048-be2f-80e8bc1047f3.png)'
- en: In this classification problem, we only have two classes that exist for many
    possible solutions to a problem. As shown in the preceding diagram, the SVM classifies
    these objects by calculating an optimal hyperplane and maximizing the margins
    between the classes. Both of these things will differentiate the classes to the
    maximum extent. Samples that are placed closest to the margin are known as **support
    vectors**. The problem is then treated as an optimization problem and can be solved
    by optimization techniques, the most common one being the use of Lagrange multipliers.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个分类问题中，我们只有两个类别，它们对应于许多可能的解决方案。如图所示，支持向量机通过计算最优超平面并最大化类别间的边界来对这些对象进行分类。这两者都将最大限度地区分类别。位于边界最近的样本被称为**支持向量**。然后，问题被处理为一个优化问题，可以通过优化技术来解决，其中最常见的是使用拉格朗日乘数法。
- en: 'Even in a separable linear problem, as shown in the preceding diagram, sometimes,
    it is not always possible to obtain a perfect separation. In these cases, the
    SVM model is the one that maximizes the margin while minimizing the number of
    misclassifications. In the real world, the problems are too far apart to be linearly
    separated, at least without a previous treatment or transformation of data. In
    the following diagram, the difference between a linear separable problem and a
    nonlinear separable problem is shown:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在可分线性问题中，如图所示，有时也不总是能够获得完美的分离。在这些情况下，支持向量机模型是最大化边界同时最小化误分类数量的模型。在现实世界中，问题之间的距离太远，无法进行线性分离，至少在没有先前的数据预处理或转换的情况下。以下图中显示了线性可分问题和非线性可分问题之间的区别：
- en: '![](img/09d1a29f-4e7b-4185-8f50-0290a6af9fcd.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/09d1a29f-4e7b-4185-8f50-0290a6af9fcd.png)'
- en: To handle nonlinear problems, a kernel function maps the data to different spaces.
    This means that data is transformed to a higher-dimensional space. This technique
    is known as the **kernel trick**, because sometimes it is possible to perform
    a linear separation between classes, making transformations in the data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理非线性问题，核函数将数据映射到不同的空间。这意味着数据被转换到更高维的空间。这种技术被称为**核技巧**，因为有时可以在数据中执行类之间的线性分离，从而进行转换。
- en: 'The following are the advantages of the SVM algorithm:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机算法的优点如下：
- en: SVM is simple
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机很简单
- en: SVM is a combination of statistical and machine learning techniques
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机是统计和机器学习技术的结合
- en: SVM can be useful in solving financial problems like our problem statement
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机可以用于解决像我们问题陈述中的金融问题
- en: Selecting SVM parameters
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择支持向量机参数
- en: Let's discuss some parameters that we might need so that we can use SVM.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一些我们可能需要的参数，这样我们就可以使用支持向量机。
- en: The SVM kernel parameter
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机核参数
- en: 'One of the main difficulties of SVM is selecting the kernel that transforms
    the data. The following are the most commonly used transformations:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的主要困难之一是选择将数据转换的核函数。以下是最常用的转换：
- en: Linear
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性
- en: Polynomial
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式
- en: Radial basis
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 径向基
- en: Sigmoid
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sigmoid
- en: The cost parameter
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本参数
- en: The control on the liquidation and the transaction between the training error
    and the model complexity will be looked after by the cost parameter (`C`). If
    you have a relatively smaller number for `C`, there will be a higher number of
    training errors. If `C` is a bigger number, you could obtain a overfitted model,
    which means that your trained model has learned all of your training data but
    it is likely that the model does not work properly on any other sample. You can
    set the cost to any value between 1.001 and 100.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 控制清算和训练误差与模型复杂度之间的交易将由成本参数（`C`）负责。如果你为`C`设置一个相对较小的数值，就会有更多的训练误差。如果`C`是一个较大的数值，你可能会得到一个过拟合的模型，这意味着你的训练模型已经学会了所有的训练数据，但这个模型可能无法在任何一个其他样本上正常工作。你可以将成本设置为1.001到100之间的任何值。
- en: Gamma parameter
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gamma参数
- en: The gamma parameter is needed while using a Gaussian kernel. This parameter
    will calculate the level of influence that each training sample can accomplish.
    Here, you may consider the lower values to be *far* and the higher values to be
    *close*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用高斯核时需要gamma参数。此参数将计算每个训练样本可以产生的影响水平。在这里，你可能认为较低的值是*远的*，而较高的值是*近的*。
- en: Gamma is actually the opposite of the support vectors that we have seen. Therefore,
    in an SVM, different values of all three parameters should be tested.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Gamma实际上是与我们之前看到的支持向量相反。因此，在SVM中，应该测试所有三个参数的不同值。
- en: Training an SVM model
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练SVM模型
- en: 'The SVM algorithm is not available in the `h2o` package. To train the `SVM`
    classifier, we are going to use the `caret` package. Remember that our target
    value takes two different values:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`h2o`包中没有SVM算法。为了训练SVM分类器，我们将使用`caret`包。记住，我们的目标值有两个不同的值：'
- en: '[PRE48]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Although the different values of this variable (`0` and `1`) do not display
    problems in other algorithms, in this case, we need to make a little transformation
    here. The categories in the target variable can only take values like `X0` or
    `X1`, so we need to transform them. Let''s write some code for this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个变量的不同值（`0`和`1`）在其他算法中不会显示问题，但在这种情况下，我们需要在这里进行一点转换。目标变量的类别只能取`X0`或`X1`这样的值，因此我们需要对它们进行转换。让我们为这个任务编写一些代码：
- en: '[PRE49]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'These values are also transformed in the test sample:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值也在测试样本中进行了转换：
- en: '[PRE50]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We will create a grid with different values of the cost and gamma parameters
    in a similar way to the `h2o` package:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以与`h2o`包类似的方式创建一个网格，其中包含成本和gamma参数的不同值：
- en: '[PRE51]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, we will run the following code to train the different models:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将运行以下代码来训练不同的模型：
- en: '[PRE52]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: To train an `SVM` classifier, the `train()` method should be passed with the
    `method` parameter as `svmRadial`, which is our selected kernel. `TuneGrid` represents
    the different combinations of the cost and gamma parameters. The accuracy of models
    is measured using the `ROC` metric. 5-fold cross validation is used.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练一个`SVM`分类器，应该将`train()`方法与`method`参数作为`svmRadial`传递，这是我们选择的核。`TuneGrid`代表成本和gamma参数的不同组合。模型的准确性使用`ROC`指标来衡量。使用5折交叉验证。
- en: 'Once the model has been trained, we can view the results as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，我们可以如下查看结果：
- en: '[PRE53]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'In summary, the best parameters are the following ones:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，最佳参数如下：
- en: '[PRE54]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Furthermore, we can access the model with the best parameters as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以通过以下方式访问具有最佳参数的模型：
- en: '[PRE55]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The performance of the model is not directly obtained, as in the `h2o` package.
    This isn''t difficult to do, but we need to use the `ROCR` package:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的性能不是直接获得的，就像在`h2o`包中一样。这并不难做，但我们需要使用`ROCR`包：
- en: '[PRE56]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The preceding code generates the following graph:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下图表：
- en: '![](img/057e4d18-0ae2-43cd-9ea9-ebeecd282edd.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/057e4d18-0ae2-43cd-9ea9-ebeecd282edd.png)'
- en: 'The Gini index can be calculated as `2*ROC -1`. We can use the `Hmisc` package
    to calculate the ROC and then calculate the Gini index, as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Gini指数可以计算为`2*ROC -1`。我们可以使用`Hmisc`包来计算ROC，然后计算Gini指数，如下所示：
- en: '[PRE57]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Gini reaches 0.9766 in the test sample. As in the previous models, the confusion
    matrix is calculated using the validation or test sample. To do this, first, the
    probabilities are stored for both the train and test samples:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试样本中，Gini指数达到0.9766。与之前的模型一样，混淆矩阵是使用验证或测试样本计算的。为此，首先，存储训练和测试样本的概率：
- en: '[PRE58]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The confusion table is now calculated on the test sample:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在测试样本上计算混淆表：
- en: '[PRE59]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'SVM does a good job of classifying banks. Only 76 banks (`68`+`8`) are misclassified
    on the test sample. Now, a new backup of the workspace is created:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 在对银行进行分类方面做得很好。在测试样本中只有 76 家银行（`68`+`8`）被错误分类。现在，创建一个新的工作区备份：
- en: '[PRE60]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Ensembles
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成
- en: 'At this point, we have trained five different models. The predictions are stored
    in two data frames, one for training and the other for the validation samples:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经训练了五个不同的模型。预测结果存储在两个数据框中，一个用于训练样本，另一个用于验证样本：
- en: '[PRE61]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Let''s summarize the accuracy of the previously trained models. First, the
    predictive power of each classifier will be calculated using the Gini index. With
    the following code, the Gini index for the training and validation samples is
    calculated:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下先前训练的模型的准确性。首先，将使用基尼指数计算每个分类器的预测能力。以下代码计算了训练样本和验证样本的基尼指数：
- en: '[PRE62]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The results are stored in a data frame called `gini_models`. The variation
    in the predictive power between the train and test samples is also calculated:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 结果存储在一个名为 `gini_models` 的数据框中。训练样本和测试样本之间预测能力的差异也被计算：
- en: '[PRE63]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: There are not really many significant differences between the models. The SVM
    is the model with the highest predictive power in the test sample. On the other
    hand, the deep learning model obtains the worst results.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 模型之间并没有太多显著的差异。在测试样本中，SVM 是预测能力最高的模型。另一方面，深度学习模型获得了最差的结果。
- en: These results indicate that it is not very difficult to find banks that will
    fail in less than a year from the current financial statement, which is how we
    defined our target variable.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，从当前的财务报表中找到将在不到一年内失败的银行并不非常困难，这正是我们定义的目标变量。
- en: 'We can also see the predictive power of each model, depending on the number
    of banks that are correctly classified:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到每个模型的预测能力，这取决于正确分类的银行数量：
- en: '[PRE64]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now, let''s create new data frames where the banks are classified as solvent
    or non-solvent banks, depending on the predicted probabilities, as we have done
    for each model:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建新的数据框，其中银行根据预测概率被分类为清偿能力银行或非清偿能力银行，就像我们对每个模型所做的那样：
- en: '[PRE65]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now, a function that counts the number of banks as correctly and non-correctly
    classified is created:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建了一个函数，用于计算银行被正确和非正确分类的数量：
- en: '[PRE66]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'By running the preceding function, we will see a summary of the performance
    of each model. First, the function is applied on the training sample:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行前面的函数，我们将看到每个模型的性能摘要。首先，该函数应用于训练样本：
- en: '[PRE67]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then, we can see the results of the different models in our test sample:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以看到测试样本中不同模型的结果：
- en: '[PRE68]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: According to the table that was measured on the test sample, `RF` is the most
    accurate classifier of the failed banks, but this also misclassifies `138` solvent
    banks as failed, providing false alerts.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 根据在测试样本上测量的表格，`RF` 是最准确的失败银行分类器，但它也将 `138` 家清偿能力银行错误分类为失败，提供了错误的警报。
- en: 'The results of the different models are correlated:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型的结果是相关的：
- en: '[PRE69]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: It might be interesting to combine the results of the different models to obtain
    a better model. Here, the concept of ensembles comes in handy. **Ensemble** is
    a technique that's used to combine different algorithms to make a more robust
    model. This combined model incorporates the predictions from all the base learners.
    The resulting model will have a higher level of accuracy than the accuracy that
    would be attained if the models were run separately. In fact, some of the previous
    models that we've developed are ensemble models, for example; the random forest
    or **Gradient Boosting Machine** (**GBM**). There are many options when creating
    an ensemble. In this section, we will look at different alternatives, from the
    simplest to those that are more complex.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 将不同模型的结果结合起来以获得更好的模型可能很有趣。在这里，集成（Ensemble）的概念派上用场。**集成**是一种将不同的算法组合起来以创建更稳健模型的技巧。这个组合模型包含了所有基学习器的预测。结果模型将比单独运行模型时的准确性更高。实际上，我们之前开发的一些模型是集成模型，例如；随机森林或**梯度提升机**（**GBM**）。创建集成时有很多选项。在本节中，我们将探讨从最简单到更复杂的不同替代方案。
- en: Average model
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均模型
- en: 'This is simply defined as taking the average of the predictions from the models:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这简单定义为取模型预测的平均值：
- en: '[PRE70]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Thus, the final probability of the failure of a bank will be calculated as the
    simple average of the probabilities of failure of the previous five models.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，银行最终失败的概率将被计算为前五个模型失败概率的简单平均值。
- en: 'The predictive power of this simple ensemble is as follows:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单集成模型的预测能力如下：
- en: '[PRE71]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We can create a confusion matrix as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建以下混淆矩阵：
- en: '[PRE72]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: This combined model only misclassifies `7` failed banks and `62` non-failed
    banks. Apparently, this averaged model is better than the performance of all of
    the individual models.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组合模型只错误地将`7`家破产银行和`62`家非破产银行分类。显然，这个平均模型比所有单个模型的表现都要好。
- en: To add some degree of conservatism, we might think that a better approach would
    be to assign the highest probability of failure from the different models. Nevertheless,
    this approach is not likely to be successful, because we have observed before
    that random forest creates false alarms for some banks.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加一些保守性，我们可能会认为更好的方法是从不同的模型中分配最高的失败概率。然而，这种方法不太可能成功，因为我们之前观察到随机森林对某些银行产生了误报。
- en: Majority vote
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多数投票
- en: 'This is defined as taking the prediction with the maximum vote while predicting
    the outcome of a classification problem. First, we need to assign a vote for each
    model. This step is already done in the `decisions_test` data frame. A bank will
    be classified as non-solvent if three of the five models classify it as such.
    Let''s see the results of this approach:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这定义为在预测分类问题的结果时，选择具有最大投票的预测。首先，我们需要为每个模型分配一个投票。这一步已经在`decisions_test`数据框中完成。如果五个模型中有三个将银行分类为非清偿，则该银行将被分类为非清偿。让我们看看这种方法的结果：
- en: '[PRE73]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The results seem not to be as good as the individual models or the ensemble
    that considered the average probabilities:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 结果似乎不如单个模型或考虑平均概率的集成模型好：
- en: '[PRE74]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Model of models
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型模型
- en: This involves combining the individual output of the models (such as random
    forest or SVM) using another machine learning model (such as Lasso, GBM, or random
    forest). The top layer of the ensemble model can be any model, even if the same
    technique (such as random forest) is used in the bottom layer. The most complex
    algorithms (such as random forest, gradient boosting, SVM, and others) do not
    always show better performance than the simpler ones (such as trees or logistic
    regression).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到使用另一个机器学习模型（如Lasso、GBM或随机森林）结合模型的单个输出（如随机森林或SVM）。集成模型的顶层可以是任何模型，即使底层使用了相同的技巧（如随机森林）。最复杂的算法（如随机森林、梯度提升、SVM等）并不总是比简单的算法（如树或逻辑回归）表现更好。
- en: In this case, no additional examples and algorithms will be trained, as the
    previous results will be sufficient.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，不会训练额外的示例和算法，因为之前的结果已经足够。
- en: Automatic machine learning
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动机器学习
- en: Now that we have learned how to develop a powerful model to predict bank failures,
    we will test a final option to develop different models. Specifically, we will
    try out **automatic machine learning** (**autoML**), which is included in the
    `h2o` package. The process that we have carried out to build many models and find
    the best one without any prior knowledge is done automatically by the `autoML`
    function. This function trains different models by trying different grids of parameters.
    Moreover, stacked ensembles or models based on previously trained models are trained
    to find more accurate or predictive models.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何开发一个强大的模型来预测银行破产，我们将测试一个最终选项来开发不同的模型。具体来说，我们将尝试**自动机器学习**（**autoML**），它包含在`h2o`包中。我们执行的过程是自动完成的，无需任何先验知识，通过`autoML`函数构建许多模型并找到最佳模型。此函数通过尝试不同的参数网格来训练不同的模型。此外，堆叠集成或基于先前训练模型的模型也被训练，以找到更准确或更具预测性的模型。
- en: In my opinion, using this function before launching any model is highly recommended
    to get an initial idea of a reference starting point. Using an automatic approach,
    we can assess the most reliable algorithms, the most important potential variables
    to be used, or a reference of the accuracy we could obtain.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，在启动任何模型之前使用这个函数强烈推荐，以获得一个参考起点的基本概念。使用自动方法，我们可以评估最可靠的算法、最重要的潜在变量或我们可能获得的准确度参考。
- en: 'To test this function, we will load a previous workspace:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个函数，我们将加载一个先前的工作空间：
- en: '[PRE75]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '`Data12.RData` contains train and test samples before launching any model.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '`Data12.RData` 包含在启动任何模型之前的训练和测试样本。'
- en: 'We need to load the `h2o` package as well. Moreover, all of the objects that
    were created in the `h2o` space will be removed:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要加载`h2o`包。此外，在`h2o`空间中创建的所有对象都将被删除：
- en: '[PRE76]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Standardizing variables
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化变量
- en: In the previous models, we fixed a parameter that standardized the data. However,
    this option is not available in the `autoML` function. Thus, the variables will
    be standardized first. The columns will have zero mean and unit variance. We need
    to standardize the variables because otherwise the results will have dominating
    variables that seem to have a higher variance compared to other attributes as
    a consequence of their scale.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的模型中，我们固定了一个参数来标准化数据。然而，这个选项在`autoML`函数中不可用。因此，变量将首先进行标准化。列将具有零均值和单位方差。我们需要标准化变量，因为否则结果将会有主导变量，这些变量似乎比其他属性具有更高的方差，这是由于它们的规模造成的。
- en: 'Standardization is done using the `caret` package. First, we choose the name
    of numeric columns to standardize:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化使用`caret`包完成。首先，我们选择要标准化的数值列的名称：
- en: '[PRE77]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The variables are transformed with the `preProcess` function:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 变量使用`preProcess`函数进行转换：
- en: '[PRE78]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The previous function stores the parameters that are needed to make the standardization
    on any dataset. With the `predict` function, we can actually apply this transformation.
    Both the train and test samples must be transformed:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的功能存储了在任意数据集上进行标准化所需的参数。使用`predict`函数，我们可以实际应用这种转换。训练和测试样本都必须进行转换：
- en: '[PRE79]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Now, we are ready to create the different models. The train and test samples
    are converted into `h2o` tables:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备创建不同的模型。训练和测试样本被转换为`h2o`表：
- en: '[PRE80]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'We need the name of both the target and the predictors:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要目标和预测变量的名称：
- en: '[PRE81]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'After all of these basic preprocessing steps, it is time to create a model.
    The `h2o.automl` function implements the autoML method. The following parameters
    are needed:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些基本预处理步骤之后，是时候创建一个模型了。`h2o.automl`函数实现了autoML方法。以下参数是必需的：
- en: '`x`: The names of the predictors'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：预测变量的名称'
- en: '`y`: The target column name'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：目标列名称'
- en: '`training_frame`: The training dataset that is to be used for creating the
    model'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_frame`：用于创建模型的训练数据集'
- en: '`leaderboard_frame`: The validation dataset that''s used by `h2o` to ensure
    that the model doesn''t overfit the data'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaderboard_frame`：`h2o`用于确保模型不会过度拟合数据的验证数据集'
- en: There are more parameters, but the preceding list contains the minimum requirements.
    It is also possible to exclude some algorithms, for example. In our case, we will
    fix the maximum number of models to be trained and the AUC as the stopping metric
    criteria.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 有更多参数，但前面的列表包含了最小要求。也可以排除一些算法，例如。在我们的案例中，我们将固定要训练的模型的最大数量和AUC作为停止指标标准。
- en: 'Let''s train some models:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练一些模型：
- en: '[PRE82]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We can access the `Leaderboard` of the trained models as follows:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下访问训练模型的`Leaderboard`：
- en: '[PRE83]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'According to the `Leaderboard`, a gradient boosting model is the best if accuracy
    is to be considered. Let''s obtain the prediction of this boosting model:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 根据`Leaderboard`，如果考虑准确度，则梯度提升模型是最佳的。让我们获取这个提升模型的预测：
- en: '[PRE84]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'It is possible to print the complete details of the model with the following
    code (the results are not printed in this book because of their length):'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下代码打印出模型的完整细节（由于长度原因，这些结果没有打印在这本书中）：
- en: '[PRE85]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'It is possible to analyze the importance of individual models in a stacked
    model, as well. Let''s see the accuracy of the best model on the test sample:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，也可以分析堆叠模型中单个模型的重要性。让我们看看最佳模型在测试样本上的准确度：
- en: '[PRE86]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: It is important to remember that the predict column is the predicted category
    according to the model, but we need to take into consideration 50% as a threshold
    in the predicted probability of bankruptcy.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，预测列是根据模型预测的类别，但我们需要考虑破产预测概率中的50%作为阈值。
- en: 'Like in the previous algorithms, we should define the observed default rate
    in our sample:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前的算法一样，我们应该在我们的样本中定义观察到的违约率：
- en: '[PRE87]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Now, we will add the observed class, and then the accuracy table will be calculated:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加观察到的类别，然后计算准确度表：
- en: '[PRE88]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The automatic model obtains very good performance, but it''s a little worse
    than the SVM model. Like the previous models in the `h2o` package, the model can
    be saved for future use:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 自动模型获得了非常好的性能，但略逊于SVM模型。类似于`h2o`包中的先前模型，该模型可以保存以供将来使用：
- en: '[PRE89]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Summary
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we used different models and algorithms to try and optimize
    our model. All of the algorithms obtained good results. This would not have been
    the case in other problems. You can try using different algorithms in your problems
    and test the best combinations of parameters to solve your specific problem. A
    combination of different algorithms or ensembles might be a good option as well.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了不同的模型和算法来尝试优化我们的模型。所有算法都获得了良好的结果。在其他问题中可能不会是这样。你可以在你的问题中尝试使用不同的算法，并测试最佳参数组合以解决你的特定问题。结合不同的算法或集成也可能是一个不错的选择。
- en: In the next chapter, we will continue by looking at other real problems—specifically,
    data visualization of economic imbalances in European countries.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将继续探讨其他实际问题——特别是，欧洲国家经济失衡的数据可视化。
