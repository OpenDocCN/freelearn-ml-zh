- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Security and Privacy in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the digital world that we live in, preserving the privacy of users’ data
    and their personal information, as well as ensuring the security of their digital
    information and assets, are of great importance in technology development. This
    is not an exception for technologies built on top of machine learning models.
    We briefly talked about this topic in [*Chapter 3*](B16369_03.xhtml#_idTextAnchor119),
    *Debugging* *t**oward Responsible AI*. In this chapter, we will provide you with
    more details to help you start your journey in learning more about privacy preservation
    and ensuring security in developing machine learning models and technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Encryption techniques and their use in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Homomorphic encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differential privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Federated learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will understand the challenges in preserving
    privacy and ensuring security in machine learning settings, and learn a few techniques
    to tackle those challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following requirements are applicable to this chapter as they will help
    you better understand the concepts, be able to use them in your projects, and
    practice with the provided code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python library requirements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy` >= 1.22.4'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib` >= 3.7.1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tenseal` >= 0.3.14'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pycryptodome` = 3.18.0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pycryptodomex` = 3.18.0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are a Mac user and run into issues with `tenseal` installation, you can
    install it directly by cloning its repository, as explained at [https://github.com/OpenMined/TenSEAL/issues](https://github.com/OpenMined/TenSEAL/issues).
  prefs: []
  type: TYPE_NORMAL
- en: The code files for this chapter are available on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter16](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter16).
  prefs: []
  type: TYPE_NORMAL
- en: Encryption techniques and their use in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use different encryption techniques to encrypt raw data, processed data
    for model training and inference, model parameters, or other sensitive information
    that needs to be secured. There is a term called *key*, usually a string of numbers
    or letters, which is important in the majority of encryption techniques. The key
    gets processed by encryption algorithms for encoding and decoding data. There
    are several encryption techniques, some of which include the following (Bhanot
    et al., 2015; Dibas et al., 2021):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Advanced Encryption Standard** (**AES**): AES is one of the strongest encryption
    algorithms that protects data. AES accepts different key sizes: 128, 192, or 256
    bits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rivest-Shamir-Adleman (RSA) security**: RSA, which is one of the most secure
    encryption algorithms, is a public-key encryption algorithm that is widely used
    for secure data transmission.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Triple Data Encryption Standard (DES)**: Triple DES is an encryption method
    that uses a 56-bit key to encrypt data blocks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blowfish**: Blowfish is a symmetric-key encryption technique used as an alternative
    to the DES encryption algorithm. Blowfish is fast and highly effective for data
    encryption. It splits data, for example, strings and messages, into blocks of
    64 bits and encrypts them individually.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Twofish**: Twofish, which is Blowfish’s successor, is a symmetric encryption
    algorithm that deciphers 128-bit data blocks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we are going to use Python to practice the use of AES for data encryption,
    which is one of the most common encryption techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing AES encryption in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we want to practice with AES for data encryption in Python. The sole purpose
    of this practice is to help you better understand how you can benefit from Python
    for data encryption, how easy it is to encrypt and decrypt data in Python, and
    how you can benefit from it to preserve data privacy and ensure security in machine
    learning settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first import `Cryptodome.Cipher.AES()` for ciphering (encrypting) and deciphering
    (decrypting) and `Cryptodome.Random.get_random_bytes()` for key generation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use AES for encryption of text such as `My name is Ali` or other types
    of information. Here, we want to use it for encrypting what is called SMILES,
    which is a sequence representing a chemical compound. For example, `CC(=O)NC1=CC=C(C=C1)O`
    represents a famous drug called Acetaminophen (source: [https://pubchem.ncbi.nlm.nih.gov/compound/Acetaminophen](https://pubchem.ncbi.nlm.nih.gov/compound/Acetaminophen)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then decrypt and securely load the data back if we have the key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This regenerates the sequence we encrypted, `CC(=O)NC1=CC=C(C=C1)O`.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, AES helped us to encrypt information about drugs, which could
    be important for pharmaceutical and biotechnology companies in the process of
    developing a new drug. However, you can use AES via Python to encrypt other types
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we want to talk about another technique called homomorphic encryption.
  prefs: []
  type: TYPE_NORMAL
- en: Homomorphic encryption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another technique that lets us implement computations on encrypted data is called
    **homomorphic encryption**. This capability is helpful in machine learning settings,
    for example, in using a model for inference on encrypted data without the need
    for decryption. However, implementing fully homomorphic encryption can be complex,
    computationally expensive, and memory-inefficient (Armknecht et al., 2015; Gentry
    et al., 2009; Yousuf et al., 2020).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few Python libraries that can help us practice with homomorphic
    encryption schemes, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TenSEAL` ([https://github.com/OpenMined/TenSEAL](https://github.com/OpenMined/TenSEAL)),
    which can be integrated with PyTorch and NumPy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PySEAL` ([https://github.com/Huelse/PySEAL](https://github.com/Huelse/PySEAL))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HElib` (https://github.com/homenc/HElib)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s see a simple example of using homomorphic encryption using TenSEAL.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first import the `TenSEAL` library and generate a `context` object using
    `tenseal.context()`. The `context` object generates and stores the necessary keys
    required by an encrypted computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `poly_modulus_degree` parameter is used to determine the degree of the polynomial
    modulus, which is a polynomial with integer coefficients. The `plain_modulus`
    parameter is used to specify the modulus for encoding plaintext messages into
    polynomials that can be encrypted and processed homomorphically. If the `plain_modulus`
    parameter is too small, the messages may overflow and cause incorrect results,
    while if it is too large, the ciphertexts may become too large and slow down the
    homomorphic operations.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous code, we used the **Brakerski-Fan-Vercauteren** (**BFV**) scheme.
    BFV is a homomorphic encryption scheme that supports integer arithmetic. It consists
    of different polynomial-time algorithms for generating the public and secret keys,
    encrypting a plaintext message, decrypting a ciphertext message, adding and subtracting
    two ciphertexts, and multiplying two ciphertexts. The ciphertext is encrypted
    information that is unreadable by us or a computer without the proper cipher,
    or algorithm for performing encryption or decryption, to decrypt it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we define a list of three numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then implement decryption using the `context` object defined before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We then first implement an operation process as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The resulting `add_result` list would be `[51, 62, 73]`, which is an element-wise
    summation of the original list of values `[50, 60, 70]` and `[1,` `2, 3]`.
  prefs: []
  type: TYPE_NORMAL
- en: Although homomorphic encryption, or other encryption techniques, seems to be
    very secure, it still requires access to secret keys, for example, on the cloud
    server, which could lead to security concerns. There are solutions to reduce such
    risks, for example, by using key management services such as AWS KMS ([https://aws.amazon.com/kms/](https://aws.amazon.com/kms/))
    or **Multi-Factor** **Authentication** (**MFA**).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will briefly review **differential privacy** (**DP**) as a technique
    for preserving the privacy of individual data points.
  prefs: []
  type: TYPE_NORMAL
- en: Differential privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The objective of **differential privacy** is to ensure that the removal or addition
    of individual data points does not affect the outcome of the modeling. For example,
    by adding random noise to a normal distribution, it tries to make the features
    of individual data points obscure. The effect of noise in learning could be eliminated
    based on the *law of large numbers* (Dekking et al., 2005) if a large number of
    data points is accessible. To better understand this concept, we want to generate
    a random list of numbers and add noise to them from a normal distribution to help
    you better understand why this technique works. In this process, we will also
    define some widely used technical terminology.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first define a function called `gaussian_add_noise()` to add *Gaussian*
    noise to a query list of values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous function, we used `sensitivity` and `epsilon` as input arguments
    of the function, whose meaning we can simplify as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sensitivity`: The level of noise that is needed in the DP mechanism get determined
    by sensitivity parametrizes. Sensitivity tells us about the impact of a change
    on the result of the query. Larger `sensitivity` values result in better privacy
    but a less accurate response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epsilon (Privacy budget)`: The privacy budget is a parameter that limits the
    extent of the deviation between the noisy and query data. A smaller `epsilon`
    value will result in better privacy but a less accurate response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We then use a simple `for` loop to generate random values following a normal
    distribution as query values and then add noise to them using the defined `gaussian_mechanism()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The resulting noisy and query distributions are very similar, with an average
    of 0.78 and 0.82 and a standard deviation of 99.32 and 99.67, respectively. *Figure
    16**.1* shows the scatter plot of the two lists of values. You can change the
    distance between the query and noisy values by playing with the `sensitivity`
    and `epsilon` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1 – Comparison of the values of variables before and after noise
    addition](img/B16369_16_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – Comparison of the values of variables before and after noise addition
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also Python libraries that you can use to implement DP, such as the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Diffprivlib`) ([https://github.com/IBM/differential-privacy-library](https://github.com/IBM/differential-privacy-library))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PyDP` ([https://github.com/OpenMined/PyDP](https://github.com/OpenMined/PyDP))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Opacus` ([https://github.com/pytorch/opacus](https://github.com/pytorch/opacus))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last topic we want to introduce in this chapter is called **federated learning**,
    which helps us to go beyond privacy preservation for a central storage system.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Federated learning** (**FL**) relies on the idea of decentralizing learning,
    data analysis, and inference, therefore allowing the user data to be kept within
    individual devices or local databases (Kaissis et al., 2020; Yang et al., 2019).
    Through FL, we can benefit from the data of local devices and users, which cannot
    be stored in a centralized data storage system, to train and improve our machine
    learning models. As shown in *Figure 16**.2*, a local device or user can provide
    local data to update the global model and the model we are training and improve
    the central server. The global model then gets updated and improved and provides
    updated inferences to the local users and devices.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.2 – Schematic representation of updating a model using local data
    and feeding the global model back to the local devices and users](img/B16369_16_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.2 – Schematic representation of updating a model using local data
    and feeding the global model back to the local devices and users
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several Python libraries you can benefit from in implementing FL,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PySyft` (`https://github.com/OpenMined/PySyft`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow `Federated` ([https://www.tensorflow.org/federated](https://www.tensorflow.org/federated))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FedML` ([https://github.com/FedML-AI/FedML](https://github.com/FedML-AI/FedML))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Flower` ([https://github.com/adap/flower](https://github.com/adap/flower))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FATE` ([https://github.com/FederatedAI/FATE](https://github.com/FederatedAI/FATE))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the challenge of using FL in practice is beyond programming or infrastructure
    design. In spite of this great alternative to storing user data locally, there
    are still ethical, legal, and business challenges in benefitting from FL in different
    applications. Healthcare is a great example of a domain where FL can benefit the
    most but legal and ethical challenges still exist, slowing down its implementation
    in practice. Many institutes, hospitals, pharmaceutical companies, and government
    agencies still require the data used for modeling, even through FL, to go through
    the usual ethics, legal, and business approval processes that exist for full access
    to the data, without the need for FL. However, there is hope that as FL algorithms
    and the associated infrastructure get better, agencies, hospitals, and institutions
    will also come up with solutions to benefit from this technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to what we covered in this chapter on data privacy and security,
    you can review the important topics of attacks in machine learning settings in
    [*Chapter 3*](B16369_03.xhtml#_idTextAnchor119), *Debugging toward Responsible
    AI*. You can also check other resources such as the great article by Papernot
    et al., 2018 titled *Sok: Security and privacy in machine learning* to learn more
    about these important topics'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about some of the most important concepts and techniques
    that help you in preserving privacy and ensuring security including data encryption
    techniques, homomorphic encryption, differential privacy, and federated learning.
    You learned how homomorphic encryption provides the possibility of different types
    of operation and machine learning inference compared to traditional data encryption
    techniques. You also learned how we can ensure data privacy by adding noise to
    the data, in differential privacy, or work with decentralized data and omit the
    need to transfer raw data, as in federated learning. You also practiced some of
    them in Python. This knowledge could be a starting point for you to learn about
    these concepts further and benefit from them in your machine learning projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about the importance of integrating human
    feedback into machine learning modeling and the techniques that will help you
    on this topic.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Explain three encryption techniques that could help you in your machine learning
    projects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the benefit of homomorphic encryption in a machine learning setting?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is differential privacy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the non-technical challenges in the use of federated learning or differential
    privacy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shafahi, Ali, et al. “*Adversarial training for free!*.” *Advances in Neural
    Information Processing Systems* 32 (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaur, Shailendra Singh, Hemanpreet Singh Kalsi, and Shivani Gautam. “*A Comparative
    Study and Analysis of Cryptographic Algorithms: RSA, DES, AES, BLOWFISH, 3-DES,*
    *and TWOFISH*.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhanot, Rajdeep, and Rahul Hans. “*A review and comparative analysis of various
    encryption algorithms*.” *International Journal of Security and Its Applications*
    9.4 (2015): 289-306.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dibas, Hasan, and Khair Eddin Sabri. “*A comprehensive performance empirical
    study of the symmetric algorithms: AES, 3DES, Blowfish and Twofish*.” *International
    Conference on Information Technology (ICIT)*. IEEE (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Armknecht, Frederik, et al. “*A guide to fully homomorphic encryption*.” Cryptology
    ePrint Archive (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gentry, Craig. *A fully homomorphic encryption scheme*. Stanford University,
    2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yousuf, Hana, et al. “*Systematic review on fully homomorphic encryption scheme
    and its application*.” *Recent Advances in Intelligent Systems and Smart Applications*
    (2020): 537-551.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang, Qiang, et al. “*Federated machine learning: Concept and applications*.”
    *ACM Transactions on Intelligent Systems and Technology (TIST)* 10.2 (2019): 1-19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abadi, Martin, et al. “*Deep learning with differential privacy*.” *Proceedings
    of the 2016 ACM SIGSAC conference on computer and communications* *security* (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dekking, Frederik Michel, et al. *A Modern Introduction to Probability and
    Statistics: Understanding why and how*. Vol. 488\. London: Springer (2005).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kaissis, Georgios A., et al. “*Secure, privacy-preserving and federated machine
    learning in medical imaging*.” *Nature Machine Intelligence* 2.6 (2020): 305-311.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang, Qiang, et al. “*Federated machine learning: Concept and applications*.”
    *ACM Transactions on Intelligent Systems and Technology (TIST)* 10.2 (2019): 1-19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Papernot, Nicolas, et al. “*Sok: Security and privacy in machine learning*.”
    *IEEE European Symposium on Security and Privacy (EuroS&P)*. IEEE (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
