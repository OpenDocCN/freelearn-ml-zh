- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Explainable AI (XAI)** is an emerging field for bringing **artificial intelligence
    (AI)** closer to non-technical end-users. XAI promises to make **machine learning
    (ML)** models transparent, and trustworthy and promote AI adoption for industrial
    and research use-cases.'
  prefs: []
  type: TYPE_NORMAL
- en: This book is designed with a unique blend of industrial and academic research
    perspectives for gaining practical skills in XAI. ML/AI experts working with data
    science, ML, deep learning, and AI will be able to put their knowledge to work
    with this practical guide to XAI for bridging the gap between AI and the end-user.
    The book provides a hands-on approach for implementation and associated methodologies
    of XAI that will have you up-and-running, and productive in no time.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, you will get a conceptual understanding of XAI and why it's needed.
    Then, you will get the necessary practical experience of utilizing XAI in the
    AI/ML problem-solving process by making use of state-of-the-art methods and frameworks.
    Finally, you will get the necessary guidelines to take XAI to the next step and
    bridge the existing gaps between AI and end-users.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this book, you will be able to implement XAI methods and approaches
    using Python to solve industrial problems, address the key pain points encountered,
    and follow the best practices in the AI/ML life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book is designed for scientists, researchers, engineers, architects, and
    managers who are actively engaged in the field of ML and related areas. In general,
    anyone who is interested in problem-solving using AI would benefit from this book.
    You are recommended to have a foundational knowledge of Python, ML, deep learning,
    and data science. This book is ideal for readers who are working in the following
    roles:'
  prefs: []
  type: TYPE_NORMAL
- en: Data and AI scientists
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI/ML engineers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI/ML product managers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI product owners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI/ML researchers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User experience and HCI researchers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, any ML enthusiast with a foundational knowledge of Python will be
    able to read, understand and apply knowledge gained from this book.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B18216_01_ePub.xhtml#_idTextAnchor014), *Foundational Concepts
    of Explainability Techniques,* gives the necessary exposure to Explainable AI
    and help you understand it''s importance. This chapter covers various terminology
    and concepts related to explainability techniques, which is frequently used throughout
    this book. This chapter also covers the key criteria of human-friendly explainable
    ML systems and different approaches to evaluating the quality of the explainability
    techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18216_02_ePub.xhtml#_idTextAnchor033), *Model Explainability
    Methods,* discusses the various model explainability methods used for explaining
    black-box models. Some of these are model agnostic, some are model specific. Some
    of these methods provide global interpretability while others provide local interpretability.
    This chapter will introduce you to a variety of techniques that can be used for
    explaining ML models and provides recommendation for the right choice of explainability
    method.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18216_03_ePub.xhtml#_idTextAnchor053), *Data-Centric Approaches,*
    introduces the concept of data-centric XAI. This chapter covers various techniques
    to explain the working of ML systems in terms of the properties of the data, data
    volume, data consistency, data purity and actionable insights generated from the
    underlying training dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18216_04_ePub.xhtml#_idTextAnchor076), *LIME for Model Interpretability*,
    covers the application of one of the most popular XAI frameworks, called LIME.
    This chapter discusses about the intuition behind the working of the LIME algorithm
    and some important properties of the algorithm which makes the generated explanations
    human-friendly. Certain advantages and limitations of the LIME algorithm are also
    discussed in this chapter, along with a code tutorial for applying LIME for a
    classification problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18216_05_ePub.xhtml#_idTextAnchor088), *Practical Exposure to
    Using LIME in ML* is an extension of the previous chapter, but more focused towards
    the practical applications of the LIME Python framework on different types of
    datasets like images, texts along with structured tabular data. Practical code
    examples are also covered in this chapter for providing exposure to on-hand knowledge
    using Python LIME framework. This chapter also covers if LIME is a good fit for
    production-level ML systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18216_06_ePub.xhtml#_idTextAnchor107), *Model Interpretability
    Using SHAP* focuses on understanding the importance of the SHAP Python framework
    for model explainability. It covers the intuitive understanding of Shapley values
    and SHAP. This chapter also discusses how to use SHAP for model explainability
    through a variety of visualization and explainer methods. A code walkthrough for
    using SHAP to explain regression models is also covered in this chapter. Finally,
    we will discuss the key advantages and limitations of SHAP.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18216_07_ePub.xhtml#_idTextAnchor128), *Practical Exposure to
    Using SHAP in ML* provides the necessary practical exposure of using SHAP with
    tabular structured data as well unstructured data like images and texts. We have
    discussed about the different explainers available in SHAP for both model-specific
    and model agnostic explainability. We have applied SHAP for explaining linear
    models, tree ensemble models, convolution neural network models and even transformer
    models in this chapter. Necessary code tutorials are also covered in this chapter
    for providing exposure to hands-on knowledge using Python SHAP framework.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18216_08_ePub.xhtml#_idTextAnchor154), *Human-Friendly Explanations
    with TCAV* covers the concepts of TCAV, a framework developed by Google AI. This
    chapter provides both conceptual understanding of TCAV and practical exposure
    to applying the Python TCAV framework. The key advantages and limitations of TCAV
    are discussed along with interesting ideas about potential research problems that
    can be solved using concept-based explanations are discussed in the chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18216_09_ePub.xhtml#_idTextAnchor172), *Other Popular XAI Frameworks*
    covers about seven popular XAI frameworks available in Python â€“ DALEX, Explainerdashboard,
    InterpretML, ALIBI, DiCE, ELI5, and H2O AutoML explainers. We have discussed about
    the supported explanation methods for each of the framework, practical application,
    and the various pros and cons of each framework. This chapter also provides a
    quick comparison guide for helping you decide which framework you should go for
    considering your own use-case.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209), *XAI Industry Best Practices*
    focuses on the best practices for designing explainable AI systems for industrial
    problems. In this chapter, we have discussed about the open challenges of XAI
    and necessary design guidelines for explainable ML systems, considering the open
    challenges. We have also highlighted the importance of considering data-centric
    approaches of explainability, interactive machine learning and prescriptive insights
    for designing explainable AI/ML systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B18216_11_ePub.xhtml#_idTextAnchor217), *End User-Centered Artificial
    Intelligence* introduces the ideology of end user centered artificial intelligence
    (ENDURANCE) for the design and development of explainable AI/ML Systems. We have
    discussed about the importance of using XAI to steer towards the main goals of
    the end user for building explainable AI/ML systems. Using some of principles
    and recommended best practices presented in the chapter, we can bridge the gap
    between AI and the end user to a great extent!'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the code tutorials provided in this book, you will need a Jupyter environment
    with Python 3.6+. This can be achieved in either of the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Install one on your machine locally via **Anaconda Navigator** or from scratch
    with **pip**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a cloud-based environment such as **Google Colaboratory**, **Kaggle notebooks**,
    **Azure notebooks**, or **Amazon SageMaker**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can take a look at the supplementary information provided at the code repository
    if you are new to Jupyter notebooks: [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md).'
  prefs: []
  type: TYPE_NORMAL
- en: You can also take a look at [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md)
    and [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md)
    for getting the supplementary information about the Python packages and datasets
    used in the tutorial notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: For instructions on installing the Python packages used throughout the book,
    please refer the specific notebook provided in the code repository. For any additional
    help needed, please refer the original project repository of the specific package.
    You can use **PyPi** ([https://pypi.org/](https://pypi.org/)) and search for the
    specific package and navigate to the code repository of the project. It is expected
    that installation or execution instructions of these packages can change from
    time to time, given how often packages change. We also tested the code with specific
    versions detailed in the *Python package information README file* under the supplementary
    information provided at the code repository. So, if anything doesn't work as expected
    with the later versions, please install the specific version mentioned in the
    README instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book''s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting of code.**'
  prefs: []
  type: TYPE_NORMAL
- en: For beginners without any exposure to ML or data science, it is recommended
    to read the book sequentially as many important concepts are explained in sufficient
    detail in the earlier chapters. Seasoned ML or data science experts who are relatively
    new to the field of XAI can skim through the first three chapters to get clear
    conceptual understanding of various terminology used. For chapters four to nine,
    any order should be fine for seasoned experts. For all level of practitioners,
    it is recommended that you read chapter 10 and 11 only after covering all the
    nine chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the code provided, it is recommended that you either read each chapter
    and then run the corresponding code, or you can run the code simultaneously while
    reading the specific chapters. Sufficient theory is also added in the Jupyter
    notebooks to help you understand the overall flow of the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: When you are reading the book, it is recommended that you take notes of the
    important terminologies covered and try to think of ways in which you could apply
    the concept or the framework learned. After reading the book and going through
    all the Jupyter notebooks, hopefully, you will be inspired to apply the newly
    gained knowledge into action!
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques).
    If there's an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots and diagrams
    used in this book. You can download it here: [https://packt.link/DF7lG](https://packt.link/DF7lG).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: "For this example, we will use the `RegressionExplainer`
    and `ExplainerDashboard` submodules."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    "Due to these known drawbacks, the search for a robust **Explainable AI (XAI)**
    framework is still on."'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share Your Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you've read *Applied Machine Learning Explainability Techniques*, we'd
    love to hear your thoughts! Please click here to go straight to the Amazon review
    page for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we're delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
