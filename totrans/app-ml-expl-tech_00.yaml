- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '**Explainable AI (XAI)** is an emerging field for bringing **artificial intelligence
    (AI)** closer to non-technical end-users. XAI promises to make **machine learning
    (ML)** models transparent, and trustworthy and promote AI adoption for industrial
    and research use-cases.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释人工智能（XAI）**是一个新兴领域，旨在将**人工智能（AI）**更接近非技术终端用户。XAI承诺使**机器学习（ML）**模型透明、可信，并促进AI在工业和研究用例中的应用。'
- en: This book is designed with a unique blend of industrial and academic research
    perspectives for gaining practical skills in XAI. ML/AI experts working with data
    science, ML, deep learning, and AI will be able to put their knowledge to work
    with this practical guide to XAI for bridging the gap between AI and the end-user.
    The book provides a hands-on approach for implementation and associated methodologies
    of XAI that will have you up-and-running, and productive in no time.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书结合了工业和学术研究视角的独特混合，旨在获得XAI的实用技能。与数据科学、ML、深度学习和AI一起工作的ML/AI专家将能够利用这本XAI实用指南将他们的知识应用于实践，以弥合AI与终端用户之间的差距。本书提供了XAI的实施和相关方法的动手方法，让您能够迅速投入工作并变得高效。
- en: Initially, you will get a conceptual understanding of XAI and why it's needed.
    Then, you will get the necessary practical experience of utilizing XAI in the
    AI/ML problem-solving process by making use of state-of-the-art methods and frameworks.
    Finally, you will get the necessary guidelines to take XAI to the next step and
    bridge the existing gaps between AI and end-users.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您将获得对XAI及其必要性的概念理解。然后，您将通过利用最先进的方法和框架，获得在AI/ML问题解决过程中利用XAI的必要实践经验。最后，您将获得将XAI推进到下一步并弥合AI与终端用户之间现有差距的必要指南。
- en: By the end of this book, you will be able to implement XAI methods and approaches
    using Python to solve industrial problems, address the key pain points encountered,
    and follow the best practices in the AI/ML life cycle.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书结束时，您将能够使用Python实现XAI方法和方案来解决工业问题，解决遇到的关键痛点，并遵循AI/ML生命周期的最佳实践。
- en: Who this book is for
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的对象
- en: 'This book is designed for scientists, researchers, engineers, architects, and
    managers who are actively engaged in the field of ML and related areas. In general,
    anyone who is interested in problem-solving using AI would benefit from this book.
    You are recommended to have a foundational knowledge of Python, ML, deep learning,
    and data science. This book is ideal for readers who are working in the following
    roles:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是为那些积极从事机器学习及相关领域的科学家、研究人员、工程师、建筑师和管理人员设计的。一般来说，任何对使用AI进行问题解决感兴趣的人都能从这本书中受益。建议您具备Python、ML、深度学习和数据科学的基础知识。这本书非常适合以下角色的读者：
- en: Data and AI scientists
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据和AI科学家
- en: AI/ML engineers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI/ML工程师
- en: AI/ML product managers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI/ML产品经理
- en: AI product owners
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI产品负责人
- en: AI/ML researchers
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI/ML研究人员
- en: User experience and HCI researchers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户界面和人类计算机交互（HCI）研究人员
- en: In general, any ML enthusiast with a foundational knowledge of Python will be
    able to read, understand and apply knowledge gained from this book.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，任何具备Python基础知识的ML爱好者都将能够阅读、理解和应用从本书中获得的知识。
- en: What this book covers
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[*Chapter 1*](B18216_01_ePub.xhtml#_idTextAnchor014), *Foundational Concepts
    of Explainability Techniques,* gives the necessary exposure to Explainable AI
    and help you understand it''s importance. This chapter covers various terminology
    and concepts related to explainability techniques, which is frequently used throughout
    this book. This chapter also covers the key criteria of human-friendly explainable
    ML systems and different approaches to evaluating the quality of the explainability
    techniques.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B18216_01_ePub.xhtml#_idTextAnchor014)，*可解释性技术的基础概念*，提供了对可解释人工智能的必要了解，并帮助您理解其重要性。本章涵盖了与可解释性技术相关的各种术语和概念，这些术语和概念在本书中经常使用。本章还涵盖了人性化的可解释ML系统的关键标准以及评估可解释性技术质量的不同方法。'
- en: '[*Chapter 2*](B18216_02_ePub.xhtml#_idTextAnchor033), *Model Explainability
    Methods,* discusses the various model explainability methods used for explaining
    black-box models. Some of these are model agnostic, some are model specific. Some
    of these methods provide global interpretability while others provide local interpretability.
    This chapter will introduce you to a variety of techniques that can be used for
    explaining ML models and provides recommendation for the right choice of explainability
    method.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第二章*](B18216_02_ePub.xhtml#_idTextAnchor033)，*模型可解释性方法*讨论了用于解释黑盒模型的多种模型可解释性方法。其中一些方法是模型无关的，一些是模型特定的。一些方法提供全局可解释性，而其他方法提供局部可解释性。本章将向您介绍可用于解释机器学习模型的各种技术，并提供关于选择正确可解释性方法的建议。'
- en: '[*Chapter 3*](B18216_03_ePub.xhtml#_idTextAnchor053), *Data-Centric Approaches,*
    introduces the concept of data-centric XAI. This chapter covers various techniques
    to explain the working of ML systems in terms of the properties of the data, data
    volume, data consistency, data purity and actionable insights generated from the
    underlying training dataset.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第三章*](B18216_03_ePub.xhtml#_idTextAnchor053)，*数据为中心的方法*介绍了数据为中心的XAI概念。本章涵盖了各种技术，用于从数据属性、数据量、数据一致性、数据纯净度和从底层训练数据集中生成的可操作见解等方面解释机器学习系统的工作原理。'
- en: '[*Chapter 4*](B18216_04_ePub.xhtml#_idTextAnchor076), *LIME for Model Interpretability*,
    covers the application of one of the most popular XAI frameworks, called LIME.
    This chapter discusses about the intuition behind the working of the LIME algorithm
    and some important properties of the algorithm which makes the generated explanations
    human-friendly. Certain advantages and limitations of the LIME algorithm are also
    discussed in this chapter, along with a code tutorial for applying LIME for a
    classification problem.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第四章*](B18216_04_ePub.xhtml#_idTextAnchor076)，*LIME用于模型可解释性*涵盖了最受欢迎的XAI框架之一，即LIME的应用。本章讨论了LIME算法背后的直觉以及算法的一些重要特性，这些特性使得生成的解释对人类友好。本章还讨论了LIME算法的某些优势和局限性，并包含了一个关于如何将LIME应用于分类问题的代码教程。'
- en: '[*Chapter 5*](B18216_05_ePub.xhtml#_idTextAnchor088), *Practical Exposure to
    Using LIME in ML* is an extension of the previous chapter, but more focused towards
    the practical applications of the LIME Python framework on different types of
    datasets like images, texts along with structured tabular data. Practical code
    examples are also covered in this chapter for providing exposure to on-hand knowledge
    using Python LIME framework. This chapter also covers if LIME is a good fit for
    production-level ML systems.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B18216_05_ePub.xhtml#_idTextAnchor088)，*使用LIME在机器学习中的实际应用*是前一章的扩展，但更专注于LIME
    Python框架在不同类型的数据集上的实际应用，如图像、文本以及结构化表格数据。本章还涵盖了实际代码示例，以展示如何使用Python LIME框架获取手头知识。本章还讨论了LIME是否适合用于生产级别的机器学习系统。'
- en: '[*Chapter 6*](B18216_06_ePub.xhtml#_idTextAnchor107), *Model Interpretability
    Using SHAP* focuses on understanding the importance of the SHAP Python framework
    for model explainability. It covers the intuitive understanding of Shapley values
    and SHAP. This chapter also discusses how to use SHAP for model explainability
    through a variety of visualization and explainer methods. A code walkthrough for
    using SHAP to explain regression models is also covered in this chapter. Finally,
    we will discuss the key advantages and limitations of SHAP.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第六章*](B18216_06_ePub.xhtml#_idTextAnchor107)，*使用SHAP进行模型可解释性*着重于理解SHAP Python框架在模型可解释性方面的重要性。本章涵盖了Shapley值和SHAP的直观理解，并讨论了如何通过多种可视化和解释方法使用SHAP进行模型可解释性。本章还包含了一个使用SHAP解释回归模型的代码示例。最后，我们将讨论SHAP的关键优势和局限性。'
- en: '[*Chapter 7*](B18216_07_ePub.xhtml#_idTextAnchor128), *Practical Exposure to
    Using SHAP in ML* provides the necessary practical exposure of using SHAP with
    tabular structured data as well unstructured data like images and texts. We have
    discussed about the different explainers available in SHAP for both model-specific
    and model agnostic explainability. We have applied SHAP for explaining linear
    models, tree ensemble models, convolution neural network models and even transformer
    models in this chapter. Necessary code tutorials are also covered in this chapter
    for providing exposure to hands-on knowledge using Python SHAP framework.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B18216_07_ePub.xhtml#_idTextAnchor128)，*在机器学习中使用SHAP的实际应用*提供了使用SHAP与表格结构数据以及非结构化数据（如图像和文本）相结合的必要实践。我们讨论了SHAP中可用的不同解释器，用于模型特定和模型无关的解释性。在本章中，我们还应用了SHAP来解释线性模型、树集成模型、卷积神经网络模型甚至Transformer模型。本章还涵盖了必要的代码教程，以提供使用Python
    SHAP框架进行实际操作的体验。'
- en: '[*Chapter 8*](B18216_08_ePub.xhtml#_idTextAnchor154), *Human-Friendly Explanations
    with TCAV* covers the concepts of TCAV, a framework developed by Google AI. This
    chapter provides both conceptual understanding of TCAV and practical exposure
    to applying the Python TCAV framework. The key advantages and limitations of TCAV
    are discussed along with interesting ideas about potential research problems that
    can be solved using concept-based explanations are discussed in the chapter.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B18216_08_ePub.xhtml#_idTextAnchor154)，*使用TCAV进行人性化的解释*涵盖了由Google AI开发的TCAV框架的概念。本章提供了对TCAV的概念理解和应用Python
    TCAV框架的实际体验。本章讨论了TCAV的关键优势和局限性，并讨论了使用基于概念的解释解决潜在研究问题的有趣想法。'
- en: '[*Chapter 9*](B18216_09_ePub.xhtml#_idTextAnchor172), *Other Popular XAI Frameworks*
    covers about seven popular XAI frameworks available in Python – DALEX, Explainerdashboard,
    InterpretML, ALIBI, DiCE, ELI5, and H2O AutoML explainers. We have discussed about
    the supported explanation methods for each of the framework, practical application,
    and the various pros and cons of each framework. This chapter also provides a
    quick comparison guide for helping you decide which framework you should go for
    considering your own use-case.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B18216_09_ePub.xhtml#_idTextAnchor172)，*其他流行的XAI框架*介绍了在Python中可用的约七个流行XAI框架——DALEX、Explainerdashboard、InterpretML、ALIBI、DiCE、ELI5和H2O
    AutoML解释器。我们讨论了每个框架所支持的解释方法、实际应用以及每个框架的优缺点。本章还提供了一个快速比较指南，以帮助您根据您的用例决定应该选择哪个框架。'
- en: '[*Chapter 10*](B18216_10_ePub.xhtml#_idTextAnchor209), *XAI Industry Best Practices*
    focuses on the best practices for designing explainable AI systems for industrial
    problems. In this chapter, we have discussed about the open challenges of XAI
    and necessary design guidelines for explainable ML systems, considering the open
    challenges. We have also highlighted the importance of considering data-centric
    approaches of explainability, interactive machine learning and prescriptive insights
    for designing explainable AI/ML systems.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B18216_10_ePub.xhtml#_idTextAnchor209)，*XAI行业最佳实践*专注于为工业问题设计可解释AI系统的最佳实践。在本章中，我们讨论了XAI的开放挑战以及考虑开放挑战的必要设计指南，对于可解释ML系统。我们还强调了考虑以数据为中心的可解释性、交互式机器学习和面向设计的可解释AI/ML系统的规范性见解的重要性。'
- en: '[*Chapter 11*](B18216_11_ePub.xhtml#_idTextAnchor217), *End User-Centered Artificial
    Intelligence* introduces the ideology of end user centered artificial intelligence
    (ENDURANCE) for the design and development of explainable AI/ML Systems. We have
    discussed about the importance of using XAI to steer towards the main goals of
    the end user for building explainable AI/ML systems. Using some of principles
    and recommended best practices presented in the chapter, we can bridge the gap
    between AI and the end user to a great extent!'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B18216_11_ePub.xhtml#_idTextAnchor217)，*以最终用户为中心的人工智能*介绍了用于设计和开发可解释AI/ML系统的以最终用户为中心的人工智能（ENDURANCE）理念。我们讨论了使用XAI引导构建可解释AI/ML系统以实现最终用户主要目标的重要性。通过本章中提出的一些原则和推荐的最佳实践，我们可以极大地弥合AI与最终用户之间的差距！'
- en: To get the most out of this book
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用这本书
- en: 'To run the code tutorials provided in this book, you will need a Jupyter environment
    with Python 3.6+. This can be achieved in either of the following ways:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本书提供的代码教程，您需要一个具有Python 3.6+的Jupyter环境。这可以通过以下两种方式之一实现：
- en: Install one on your machine locally via **Anaconda Navigator** or from scratch
    with **pip**.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过**Anaconda Navigator**在您的机器上本地安装，或者从头开始使用**pip**安装。
- en: Use a cloud-based environment such as **Google Colaboratory**, **Kaggle notebooks**,
    **Azure notebooks**, or **Amazon SageMaker**.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于云的环境，例如**Google Colaboratory**、**Kaggle笔记本**、**Azure笔记本**或**Amazon SageMaker**。
- en: 'You can take a look at the supplementary information provided at the code repository
    if you are new to Jupyter notebooks: [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是Jupyter笔记本的新手，可以查看代码仓库中提供的补充信息：[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/CodeSetup.md)。
- en: You can also take a look at [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md)
    and [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md)
    for getting the supplementary information about the Python packages and datasets
    used in the tutorial notebooks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以查看[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/PythonPackageInfo.md)和[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/SupplementaryInfo/DatasetInfo.md)，以获取关于教程笔记本中使用的Python包和数据集的补充信息。
- en: For instructions on installing the Python packages used throughout the book,
    please refer the specific notebook provided in the code repository. For any additional
    help needed, please refer the original project repository of the specific package.
    You can use **PyPi** ([https://pypi.org/](https://pypi.org/)) and search for the
    specific package and navigate to the code repository of the project. It is expected
    that installation or execution instructions of these packages can change from
    time to time, given how often packages change. We also tested the code with specific
    versions detailed in the *Python package information README file* under the supplementary
    information provided at the code repository. So, if anything doesn't work as expected
    with the later versions, please install the specific version mentioned in the
    README instead.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于安装书中使用的Python包的说明，请参阅代码仓库中提供的特定笔记本。如需任何额外帮助，请参阅特定包的原始项目仓库。您可以使用**PyPi** ([https://pypi.org/](https://pypi.org/))搜索特定包并导航到项目的代码仓库。鉴于包经常更改，安装或执行说明可能会不时更改。我们还使用代码仓库提供的补充信息中的*Python包信息README文件*中详细说明的特定版本进行了代码测试。因此，如果后续版本有任何不符合预期的情况，请安装README中提到的特定版本。
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book''s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting of code.**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您正在使用这本书的数字版，我们建议您亲自输入代码或从书的GitHub仓库（下一节中有一个链接）获取代码。这样做将帮助您避免与代码复制粘贴相关的任何潜在错误。**'
- en: For beginners without any exposure to ML or data science, it is recommended
    to read the book sequentially as many important concepts are explained in sufficient
    detail in the earlier chapters. Seasoned ML or data science experts who are relatively
    new to the field of XAI can skim through the first three chapters to get clear
    conceptual understanding of various terminology used. For chapters four to nine,
    any order should be fine for seasoned experts. For all level of practitioners,
    it is recommended that you read chapter 10 and 11 only after covering all the
    nine chapters.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于没有任何机器学习或数据科学经验的初学者，建议按顺序阅读本书，因为许多重要概念在早期章节中都有充分的详细解释。对于相对新于XAI领域的经验丰富的机器学习或数据科学专家，可以快速浏览前三章，以获得对各种术语的清晰概念理解。对于第四到第九章，对于经验丰富的专家来说，任何顺序都行。对于所有级别的从业者，建议在覆盖完所有九章之后，再阅读第10章和第11章。
- en: Regarding the code provided, it is recommended that you either read each chapter
    and then run the corresponding code, or you can run the code simultaneously while
    reading the specific chapters. Sufficient theory is also added in the Jupyter
    notebooks to help you understand the overall flow of the notebook.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 关于提供的代码，建议你要么阅读每一章然后运行相应的代码，要么在阅读特定章节的同时运行代码。Jupyter笔记本中也添加了足够的理论，以帮助你理解笔记本的整体流程。
- en: When you are reading the book, it is recommended that you take notes of the
    important terminologies covered and try to think of ways in which you could apply
    the concept or the framework learned. After reading the book and going through
    all the Jupyter notebooks, hopefully, you will be inspired to apply the newly
    gained knowledge into action!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在阅读这本书时，建议你记录下涵盖的重要术语，并尝试思考如何应用所学的概念或框架。在阅读完这本书并浏览完所有Jupyter笔记本后，希望你能受到启发，将新获得的知识付诸实践！
- en: Download the example code files
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques).
    If there's an update to the code, it will be updated in the GitHub repository.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub下载这本书的示例代码文件[https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques](https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques)。如果代码有更新，它将在GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富的书籍和视频目录的代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。查看它们吧！
- en: Download the color images
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots and diagrams
    used in this book. You can download it here: [https://packt.link/DF7lG](https://packt.link/DF7lG).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份包含本书中使用的截图和图表的彩色图像的PDF文件。你可以从这里下载：[https://packt.link/DF7lG](https://packt.link/DF7lG)。
- en: Conventions used
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了多种文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: "For this example, we will use the `RegressionExplainer`
    and `ExplainerDashboard` submodules."'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“在这个例子中，我们将使用`RegressionExplainer`和`ExplainerDashboard`子模块。”'
- en: 'A block of code is set as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望将你的注意力引到代码块的一个特定部分时，相关的行或项目将以粗体显示：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For instance, words in menus or dialog boxes appear in **bold**. Here is an example:
    "Due to these known drawbacks, the search for a robust **Explainable AI (XAI)**
    framework is still on."'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要词汇或屏幕上看到的词汇。例如，菜单或对话框中的词汇以**粗体**显示。以下是一个示例：“由于这些已知的缺点，寻找一个稳健的**可解释人工智能（XAI）**框架仍在进行中。”'
- en: Tips or important notes
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士或重要注意事项
- en: Appear like this.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来像这样。
- en: Get in touch
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果你对这本书的任何方面有疑问，请通过电子邮件发送至[customercare@packtpub.com](mailto:customercare@packtpub.com)，并在邮件主题中提及书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误表**：尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果你在这本书中发现了错误，我们非常感谢你向我们报告。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)并填写表格。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**: 如果你在互联网上以任何形式遇到我们作品的非法副本，如果你能提供位置地址或网站名称，我们将不胜感激。请通过[mailto:copyright@packt.com](mailto:copyright@packt.com)与我们联系，并提供材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you've read *Applied Machine Learning Explainability Techniques*, we'd
    love to hear your thoughts! Please click here to go straight to the Amazon review
    page for this book and share your feedback.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您阅读了《应用机器学习可解释性技术》，我们很乐意听到您的想法！请点击此处直接进入此书的亚马逊评论页面并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we're delivering excellent quality content.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和科技社区都很重要，并将帮助我们确保我们提供高质量的内容。
