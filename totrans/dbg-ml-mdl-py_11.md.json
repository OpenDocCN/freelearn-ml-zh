["```py\nclass DataDriftMonitor:    def __init__(self, baseline_data: np.array,\n        threshold_mean: float = 0.1):\n            self.baseline = self.calculate_statistics(\n                baseline_data)\n            self.threshold_mean = threshold_mean\n    def calculate_statistics(self, data: np.array):\n        return np.mean(data, axis=0)\n    def assess_drift(self, current_data: np.array):\n        current_stats = self.calculate_statistics(\n            current_data)\n        drift_detected = False\n        for feature in range(0, len(current_stats)):\n            baseline_stat = self.baseline[feature]\n            current_stat = current_stats[feature]\n            if np.abs(current_stat - baseline_stat) > self.threshold_mean:\n                drift_detected = True\n                print('Feature id with drift:\n                    {}'.format(feature))\n                print('Mean of original distribution:\n                    {}'.format(baseline_stat))\n                print('Mean of new distribution:\n                    {}'.format(current_stat))\n                break\n        return drift_detected\n```", "```py\nnp.random.seed(23)# Generating a synthetic dataset, as the original data, with 100 datapoints and 5 features\n# from a normal distribution centered around 0 with std of 1\nbaseline_data = np.random.normal(loc=0, scale=1,\n    size=(100, 5))\n# Create a DataDriftMonitor instance\nmonitor = DataDriftMonitor(baseline_data,\n    threshold_mean=0.1)\n# Generating a synthetic dataset, as the original data, with 100 datapoints and 5 features from a normal distribution #centered around 0.2 with std of 1\ncurrent_data = np.random.normal(loc=0.15, scale=1,\n    size=(100, 5))\n# Assess data drift\ndrift_detected = monitor.assess_drift(current_data)\nif drift_detected:\n    print(\"Data drift detected.\")\nelse:\n    print(\"No data drift detected.\")\n```", "```py\nFeature id with drift: 1Mean of original distribution: -0.09990597519469419\nMean of new distribution: 0.09662442557421645\nData drift detected.\n```", "```py\nimport numpy as npimport pandas as pd\nimport lightgbm as lgb\nfrom alibi_detect.cd import KSDrift\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score as bacc\n# Generate synthetic data\nX, y = make_classification(n_samples=10000, n_features=10,\n    n_classes=2, random_state=42)\n```", "```py\n# Split into train and test setsX_train, X_test, y_train, y_test = train_test_split(X, y,\n    test_size=0.2, random_state=42)\n```", "```py\ntrain_data = lgb.Dataset(X_train, label=y_train)params = {\n    \"objective\": \"binary\",\n    \"metric\": \"binary_logloss\",\n    \"boosting_type\": \"gbdt\"\n}\nclf = lgb.train(train_set = train_data, params = params,\n    num_boost_round=100)\n```", "```py\n# Predict on the test sety_pred = clf.predict(X_test)\ny_pred = [1 if iter > 0.5 else 0 for iter in y_pred]\n# Calculate the balanced accuracy of the predictions\nbalanced_accuracy = bacc(y_test, y_pred)\nprint('Balanced accuracy on the synthetic test set:\n    {}'.format(balanced_accuracy))\n# Create a DataFrame from the test data and predictions\ndf = pd.DataFrame(X_test,\n    columns=[f\"feature_{i}\" for i in range(10)])\ndf[\"actual\"] = y_test\ndf[\"predicted\"] = y_pred\n```", "```py\n# Initialize the KSDrift detectordrift_detector = KSDrift(X_train)\n# Calculate the drift scores and p-values\ndrift_scores = drift_detector.predict(X_test)\np_values = drift_detector.predict(X_test,\n    return_p_val=True)\n# Print the drift scores and p-values\nprint(\"Drift scores:\")\nprint(drift_scores)\nprint(\"P-values:\")\nprint(p_values)\n```", "```py\nDrift scores:{'data': {'is_drift': 0, 'distance': array([0.02825 , 0.024625, 0.0225  , 0.01275 , 0.014   , 0.017125,0.01775 , 0.015125, 0.021375, 0.014625], dtype=float32), 'p_val': array([0.15258548, 0.28180763, 0.38703775, 0.95421314, 0.907967 ,0.72927415, 0.68762517, 0.8520056 , 0.45154762, 0.87837887],dtype=float32), 'threshold': 0.005}, 'meta': {'name': 'KSDrift', 'online': False, 'data_type': None, 'version': '0.11.1', 'detector_type': 'drift'}}\nP-values:\n{'data': {'is_drift': 0, 'distance': array([0.02825 , 0.024625, 0.0225  , 0.01275 , 0.014   , 0.017125,0.01775 , 0.015125, 0.021375, 0.014625], dtype=float32), 'p_val': array([0.15258548, 0.28180763, 0.38703775, 0.95421314, 0.907967 ,0.72927415, 0.68762517, 0.8520056 , 0.45154762, 0.87837887],dtype=float32), 'threshold': 0.005}, 'meta': {'name': 'KSDrift', 'online': False, 'data_type': None, 'version': '0.11.1', 'detector_type': 'drift'}}\n```", "```py\nimport pandas as pdimport numpy as np\nfrom sklearn import datasets\nfrom evidently.report import Report\nfrom evidently.metrics import DataDriftTable\nfrom evidently.metrics import DatasetDriftMetric\ndiabetes_data = datasets.fetch_openml(name='diabetes',\n    version=1, as_frame='auto')\ndiabetes = diabetes_data.frame\ndiabetes = diabetes.drop(['class', 'pres'], axis = 1)\n```", "```py\ndiabetes_reference = diabetes[diabetes.age <= 40]diabetes_current = diabetes[diabetes.age > 40]\ndata_drift_dataset_report = Report(metrics=[\n    DatasetDriftMetric(),\n    DataDriftTable(),\n])\ndata_drift_dataset_report.run(\n    reference_data=diabetes_reference,\n    current_data=diabetes_current)\nData_drift_dataset_report\n```"]