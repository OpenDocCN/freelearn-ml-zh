# 8

# 负责任AI

在人工智能（**AI**）领域最近出现的研究领域之一是使模型具有责任感和可问责性，从而产生准确的结果，而不是产生有偏见或不完整的结果。这是一个计算机科学的新领域，但也是数据科学领域许多人正在研究的内容。微软正集中精力在多个领域开展工作，包括**公平性**、**可靠性及安全性**、**隐私** **和** **安全性**、**包容性**、**透明度**和**问责性**。微软提供了一套工具箱，可用于处理数据集和模型以解决这些问题。在本章中，我们将探讨这些术语的含义以及如何利用微软的负责任AI工具箱来解决这些问题。

在本章中，我们将涵盖以下主题：

+   负责任AI原则

+   响应AI工具箱概述

+   负责任AI仪表板

+   错误分析

+   可解释性仪表板

+   公平性仪表板

# 负责任AI原则

如前所述，微软在其负责任AI工具箱中纳入了六个核心原则——**公平性**、**可靠性及安全性**、**隐私**和**安全性**、**包容性**、**透明度**和**问责性**。我们将简要解释如下：

+   在人工智能系统的**公平性**方面是一个社会技术挑战，科学家和开发者需要解决，以确保人们受到平等对待，并减少与我们构建模型的具体用例相关的公平性问题。在各个领域和用例中，人工智能系统可以用来提供资源和机会，通过检查公平性，我们可以确保我们不会强化现有的刻板印象。

例如，如果我们正在预测某个人口特定段落的民族群体及其食物偏好，并非所有城市或州的客户群体都具有相同的民族多样性。因此，当我们设计模型时，我们必须考虑所有民族群体，在数据中给予每个群体平等分布，将公平性融入模型。否则，模型可能会因为测试集中人口最多的民族群体而出现偏差。这也很难，因为所有城市和州民族群体的分布都是不均匀的。

+   **可靠性及安全性**：需要记住的一个重要事项是确保模型对他人来说是安全的，并且输出不会造成伤害。当模型做出预测时，确保这些预测对所有消费者来说都是安全且可靠的决策。理解到错误的预测在应用模型结果时可能会产生负面效应。花时间确保模型的结果对其设计和开发的目的来说是安全且可靠的。

+   **隐私和安全**：依赖于人类相关数据的用例，例如预测患者诊断或公司的流失分析，使用了大量个人数据。必须采取适当的预防措施来保护**个人可识别信息**（**PII**）和隐私。根据模型运行的位置，尽量将模型运行在数据存储附近，并确保不将其移动或复制，以保护隐私。同时，确保仅对需要访问数据的人员授予许可，而不是所有人。在某些情况下，如果可能，我们可以在构建模型之前对数据进行加密或将PII转换为不可识别的信息。还有关于为建模创建合成数据的讨论。根据用例，我们试图解决的商业问题必须驱动如何保护隐私和实施安全性的决策。

+   **包容性**是一个核心价值观，表明系统应该赋予所有人、用户和客户权力。AI系统与地球上每个不同的人都能协同工作的能力始终是目标。包容性与公平性非常相似。我们要问的问题是，我们如何包括所有不同的群体或包括所有少数民族社区在模型中，确保没有人被排除在外。我们的数据集应该代表所有社区，以便在构建我们的模型时，每个人都能得到适当的代表。

+   **系统的透明度**是确保系统能够被信任的关键。系统应该是透明的，使用户能够了解任何给定时间正在发生的事情。这提高了对系统的信任。我们可以讨论两种不同的透明度类别：

    +   **AI系统构建的透明度**：我们需要在AI系统的构建上保持透明，并提供关于我们构建的模型的过程和目的的适当文档。任何使用该模型的人都应该感到舒适并能够信任该模型。

    +   **模型陷阱的透明度**：使用可解释性来解释决策是如何做出的以及使用了哪些特征，这也是获得对即将使用的模型信任的重要方式。

+   **问责制**：鉴于模型构建具有一定的不确定性，我们必须对我们所构建的内容负责。必须建立适当的流程，以便我们能够对我们的模型建设承担问责制。我们应该确保我们所构建的内容考虑到隐私，并且我们接受对模型可信度的责任。例如，构建模型的科学家必须遵循所有这些原则来构建模型，并将对该模型承担问责。首先，每个组织都必须具备以下条件：

    +   负责任的AI策略

    +   一种负责任地开发AI/**机器学习**（**ML**）的方法

为了有一个负责任的人工智能策略，您需要制定与如何使用AI/ML来推动业务成果相关的业务指南，确定团队如何应用负责任的人工智能以及构建更好的模型结果，并决定需要哪些工具和技术来确保负责任的人工智能。这个策略应该是所有AI/ML模型开发的基础，并应用于任何其他系统。您还应该创建一个框架，用于报告和监控风险或泄露的AI/ML行为。

在本章的下一节中，我们将讨论如何利用**raiwidgets**（或**Responsible AI Toolkit SDK**）以及我们如何分析六个核心原则。并非所有这些原则都由SDK涵盖。例如，虽然公平性和透明度由SDK涵盖，但隐私和安全、可靠性和问责制将由其他编程机制来处理。

查阅以下URL以获取更多详细信息和新信息：[https://www.microsoft.com/en-us/ai/responsible-ai](https://www.microsoft.com/en-us/ai/responsible-ai)。

# 负责任的人工智能工具箱概述

我们在数据科学中面临的最大挑战之一是理解模型的作用。例如，如果我们使用的算法都是黑盒，那么了解决策是如何做出的并不那么容易。为了辨别我们的算法是如何做出决策的，我们可以利用负责任的人工智能。这将给我们机会解释模型的决策，找到对预测有贡献的特征，对数据集进行错误分析，并确保数据集的公平性。

微软最近开发了一个包含可解释性、公平性、反事实分析和因果决策的负责任人工智能工具箱，通过三个仪表板：一个**公平性仪表板**、一个**错误分析仪表板**和一个**可解释性仪表板**。

仪表板通过将所有工具箱输出集中在一个UI中简化了**用户界面**（**UI**）。在工具箱之前，这很困难，因为我们需要为每个仪表板下载一个单独的库并编写代码。现在，这非常简单，我将展示一些使用负责任的人工智能工具箱实现这一点的代码。

备注

工具箱处于公开预览阶段，并且正在开发新的功能。请确保您的库经常更新，以检查哪些新功能可供您使用。

工具箱可在以下位置获取：[https://github.com/microsoft/responsible-ai-toolbox](https://github.com/microsoft/responsible-ai-toolbox)。

# 负责任的人工智能仪表板

为了利用工具箱，我们将创建一个模型来应用工具箱。让我们看看创建和分析负责任的人工智能的过程。

让我们通过以下步骤在Azure ML服务中创建一个模型：

1.  前往Azure ML Studio UI。

1.  启动计算实例。

1.  在**作者**部分点击**笔记本**。

1.  使用Python 3.8创建一个新的笔记本，以Azure ML作为内核。

1.  将笔记本命名为`RAIDashboard.ipynb`。

1.  现在，我们需要安装或升级库。只有当它们尚未在您的系统上时才安装库。在撰写本文时，使用了Python 3.8和Azure ML内核，并且已经安装了`raiwidgets`。如果有旧版本，请使用以下升级命令升级到最新版本：

![图8.1 – 安装或升级责任AI工具箱](img/B18003_08_001.jpg)

图8.1 – 安装或升级责任AI工具箱

1.  现在，让我们升级依赖项：

![图8.2 – 升级pandas库到最新版本](img/B18003_08_002.jpg)

图8.2 – 升级pandas库到最新版本

1.  重新启动内核并清除所有输出。一旦安装了库，重新启动内核以反映已安装的库总是一个好习惯。一些包强制我们重新启动内核才能生效。

1.  我们现在将加载用于在笔记本中使用的库。责任AI仪表板用于生成一个漂亮的用户界面，以便与之交互并进行**假设分析**，以及其他类型的分析，包括**错误分析**、**特征排列**和**反事实分析**，针对创建的模型。

对于`RAIInsights`，这是我们进行所有计算以生成仪表板的地方。执行和分析模型并了解模型正在做什么通常需要时间。在责任AI仪表板上显示的所有内容都将由`RAIInsights`库计算得出。

![图8.3 – 导入责任AI库](img/B18003_08_003.jpg)

图8.3 – 导入责任AI库

1.  接下来，我们创建一个用于应用责任AI的样本回归模型。让我们导入`shap`和`sklearn`库来构建我们的模型。在这里，我们将加载机器学习库以及用于分割训练和测试数据的库。稍后，我们将数据集分成两部分：一部分用于训练，另一部分用于测试。通常，80%用于训练，20%用于测试。

![图8.4 – 导入模型的库](img/B18003_08_004.jpg)

图8.4 – 导入模型的库

1.  现在，让我们加载样本数据集并分割用于训练和测试的数据。同时，让我们指定用于目标特征的列，或者标记要预测的列。在这里，我们正在加载一个用于糖尿病的样本数据集。然后，我们将预测列指定为`'y'`。有时，它被称为`target_feature`。然后，我们使用剩余的列作为特征来训练模型。

![图8.5 – 加载样本数据集](img/B18003_08_005.jpg)

图8.5 – 加载样本数据集

1.  分割数据并将其分配给不同的数据框进行建模。通常，在建模时，训练数据被分割成两个数据集，一个用于训练，一个用于测试。接下来，预测列，也称为标签或目标，也被分割成训练和测试。以下截图显示了用于建模的特征。

![图8.6 – 分割数据以进行训练和测试](img/B18003_08_006.jpg)

图8.6 – 分割数据以进行训练和测试

现在我们已经构建了模型，我们需要运行它。在使用负责的人工智能工具箱分析模型的公平性、隐私、可靠性和偏差之前，这是必要的。偏差意味着我们希望我们使用的类别有相等的记录。例如，如果我们使用包含种族或性别特征的数据库，我们必须确保每个代表组的数据量相等，以避免偏差。

让我们现在按照以下步骤创建负责的人工智能代码：

1.  首先，在我们将模型传递给`RAIInsights`以计算公平性、偏差和其他错误分析之前，我们需要训练模型。

![图8.7 – 模型配置和训练](img/B18003_08_007.jpg)

图8.7 – 模型配置和训练

1.  模型已准备就绪。下一步是应用负责的人工智能。让我们配置`RAIInsights`的详细信息。

我们需要传递以下参数：`model`、`train_data`、`test_data`、`target_feature`、模型类型（例如，`regression`或`classification`）以及`categorical_features`。

因此，`RAIInsights`将生成以下内容：

+   错误分析仪表板

+   可解释性仪表板

+   公平性仪表板

+   负责的人工智能仪表板

![图8.8 – 调用RAIInsights](img/B18003_08_008.jpg)

图8.8 – 调用RAIInsights

1.  下一步是调用可解释性、错误分析和公平性，并构建仪表板：

    +   `IntepretML`用于理解列如何影响模型做出的预测。`IntepretML`是一个开源软件包。在这里，我们结合所有开源软件包的输出，使其无缝，并在`ResponsibleAIDashboard`中展示。

    +   为此使用`Error Analysis`软件包。

    +   `DiCE`是我们用来进行此分析的开源软件包。

    +   `EconML`开源软件包。此软件包允许我们更改条件并查看影响。例如，如果我们向客户细分市场引入新产品或向公司引入新策略，会有什么影响？

![图8.9 – 添加解释器、错误分析和反事实包](img/B18003_08_009.jpg)

图8.9 – 添加解释器、错误分析和反事实包

现在，让我们进行可解释性、错误和反事实分析：

1.  通常，进行所有计算需要一些时间。根据模型类型和数据集的大小，请做好在这里花费一些时间的准备。根据机器学习类型，使用`EconML`进行的因果分析也将用于假设分析。

![图 8.10 – 计算负责的 AI 计算洞察](img/B18003_08_010.jpg)

图 8.10 – 计算负责的 AI 计算洞察

1.  接下来，我们需要构建负责的 AI 仪表板。工具箱将所有输出汇总到仪表板中，并提供一个地方进行分析。请记住，并非所有原则都已实施，SDK 的研发仍在进行中。*图 8.11* 展示了负责的 AI 仪表板的创建。

![图 8.11 – 负责的 AI 仪表板](img/B18003_08_011.jpg)

图 8.11 – 负责的 AI 仪表板

1.  一旦构建了仪表板，请单击超链接以打开它。对于每种类型的分析，请参阅仪表板链接中的标题。

链接在此处可用：`responsible-ai-toolbox/tour.ipynb at main ·` `microsoft/responsible-ai-toolbox` ([https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tour.ipynb](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tour.ipynb))。

从前面的代码创建的仪表板将有一些选项来定制和与队列一起工作：

+   **仪表板导航**：允许我们过滤任何分析

+   **队列设置**：允许我们与队列一起工作

+   **切换全局队列**：允许我们在队列之间切换，并在弹出窗口中显示统计数据

+   **创建新队列**：允许我们根据需要创建新的队列

接下来，我们将深入探讨错误分析仪表板，以了解特征错误。

# 错误分析仪表板

错误分析使我们能够分析模型表现不佳的地方，并找到决策过程中的错误。

错误分析可以是树状图或热图。根据分析，红色代表错误。如果您点击其中一个洞察气泡，您将看到模型遍历的路径。

仪表板分析将基于我们选择的 ML 模型类型。有两种类型：分类和回归。在我们的例子中，我们选择了回归。以下是我们使用的两个准确性指标：

+   **均方误差**

+   **均绝对误差**

以下截图显示了由负责的 AI SDK 创建的错误分析仪表板 UI。

![图 8.12 – 错误分析仪表板](img/B18003_08_012.jpg)

图 8.12 – 错误分析仪表板

此仪表板提供选项保存错误分析以供进一步分析或与他人共享。如果我们需要与其他数据科学家或领域专家共享信息以了解模型性能，此功能非常有用。

以下截图显示了选择**热图**的错误分析屏幕：

![图 8.13 – 热图错误分析](img/B18003_08_013.jpg)

图 8.13 – 热图错误分析

在这个热图中，我们需要选择我们想要进行错误分析的特征。一旦我们选择了特征，系统将分析错误百分比。

提供了**分位数分箱**和**分箱阈值**的选项。

以下截图显示了**特征列表**。本节显示了哪些特征已被选择，以及每个特征对预测的重要性。

![图 8.14 – 特征列表](img/B18003_08_014.jpg)

图 8.14 – 特征列表

此功能说明了列或特征对预测的重要性。有选项可以更改由负责 AI 仪表板创建的决策树的最大深度和叶子数，以及分析一个叶子中样本的最小数量。

# 可解释性仪表板

现在，让我们看看仪表板的可解释性部分。这是分析每个特征并显示特征的重要性和影响的地方。顶级特征要么是聚合的，要么可以单独进行分析。

![图 8.15 – 聚合特征重要性](img/B18003_08_015.jpg)

图 8.15 – 聚合特征重要性

在前面的截图中，您可以查看聚合的特征重要性。

选择**单个特征重要性**以逐行分析数据。然后，选择要分析的数据行，如下所示：

![图 8.16 – 选择数据点进行特征重要性分析](img/B18003_08_016.jpg)

图 8.16 – 选择数据点进行特征重要性分析

一旦选择了特征数据点，向下滚动以查看图表。以下图表显示了特征重要性和其对所选行的影响。对于数据集中的每一行，您可以通过选择一行来分析数据集。

![图 8.17 – 单个特征重要性图](img/B18003_08_017.jpg)

图 8.17 – 单个特征重要性图

现在点击**个体条件期望（ICE）图**来更改图表。ICE 图将显示所选特征的所有行，并显示每一行对模型的影响程度。

在选择**个体条件期望（ICE）图**后，您应该看到*图 8.17*中所示的内容。*x* 轴应该是所选特征，而 *y* 轴是预测值。点击**特征**下拉菜单并选择特征以查看其影响。此外，还有设置最小和最大步数的选项。要获取更多信息，请点击**如何阅读****此图表**。

![图 8.18 – 个体条件期望（ICE）图](img/B18003_08_018.jpg)

图 8.18 – 个体条件期望（ICE）图

现在让我们看看模型统计信息。

模型统计信息使我们能够分析预测值分布、模型性能和模型指标。还有在队列和数据集之间切换的选项。选择 *y* 值以查看数据集中的错误、预测的 Y 值（模型预测的列的标签）以及真实的 Y 值（训练数据集中提供的列的标签）。这些选项使我们能够了解模型性能。

您还可以交换轴以在x轴上显示错误并在Y轴上显示预测值。此外，如果您点击**队列**，您可以选择数据集和要绘制的特征，并查看模型的性能。

![图8.19 – 模型统计](img/B18003_08_019.jpg)

图8.19 – 模型统计

接下来，我们将查看负责任AI仪表板上的**数据探索器**功能。

## 数据探索器

**数据探索器**是分析预测值、误差和特征的另一个可视化工具。您可以使用聚合或单个特征。它还允许您为假设分析选择预测特征和训练特征。

*图8.20* 展示了年龄如何分组或分箱成块的情况。*x* 轴是索引，*y* 轴是年龄组，可以是年龄数据点或年龄的箱。您可以选择选择**聚合图**或**单个数据点**来可视化聚合图和单个图之间的差异。箱形图清晰地显示了异常值的位置，并显示了绘图点的范围。

我们可以将*x*轴从索引更改为预测的*y*值或真实的*y*值以查看模式。还有更改箱数的选项。在以下示例中，我们选择了五个箱。此外，如果您点击**年龄**，您还可以更改特征以查看预测值的变化。

![图8.20 – 聚合图](img/B18003_08_020.jpg)

图8.20 – 聚合图

**数据探索器**允许我们选择预测值和原始值，并绘制聚合图或单个散点图以查看值如何对齐或相交。在下面的图表中，*y* 轴是年龄，*x* 轴是索引，预测结果是一个散点图。您可以选择不同的队列来查看不同的值。

![图8.21 – 单个值的散点图](img/B18003_08_021.jpg)

图8.21 – 单个值的散点图

上述图表提供了一种可视化模型预测值和误差值的方法。这使我们能够构建一个更准确、更现实的更好模型。

## 假设反事实

现在，我们可以更改数据点并点击**创建假设反事实**。假设分析允许我们选择预测因子并与特征进行比较，以查看对结果的影响。我们还可以更改索引和年龄，切换到查看预测的*y*值或真实的*y*值以及特征以查看反事实。然后，我们可以选择索引值并选择一个来查看图表如何变化。

在以下屏幕截图中，我们可以看到一个反事实图表，并通过更改特征来分析图表。

![图8.22 – 反事实](img/B18003_08_022.jpg)

图8.22 – 反事实

选择索引然后点击**创建假设反事实**以查看分布图中的特征百分比。您还可以保存图表。

![图8.23 – 假设反事实](img/B18003_08_023.jpg)

图8.23 – 假设反事实

在下一节中，我们将看到如何使用SDK分析公平性。

# 公平性

公平性是我们需要在涉及人的用例中调查的一个主题。应采取适当的预防措施来确定数据集是否公平。在Azure ML中，使用负责任的AI工具箱，我们可以创建一个公平性仪表板。为此，首先，我们需要知道哪些特征需要公平，例如性别和种族。一旦我们知道这一点，我们就可以创建一个仪表板，如图*图8**.24*所示。

在本节中，我们将使用样本数据集创建一个公平性仪表板：

1.  前往Azure ML Studio UI。

1.  启动计算实例。

1.  在**作者**部分点击**笔记本**。

1.  使用Python 3.8创建一个新的笔记本，以Azure ML作为内核。

1.  创建一个名为`FairnessDashboard`的新笔记本。

1.  导入所有必需的库：

![图8.24 – 公平性导入](img/B18003_08_024.jpg)

图8.24 – 公平性导入

1.  接下来，我们将加载样本数据集：

![图8.25 – 获取样本数据](img/B18003_08_025.jpg)

图8.25 – 获取样本数据

1.  然后，我们将指定敏感特征，然后使用分类列和标签编码器将字符串转换为数字：

![图8.26 – 特征工程](img/B18003_08_026.jpg)

图8.26 – 特征工程

1.  现在我们已经处理好了特征工程，下一步是将数据集分割为训练和测试。我们将数据集分割为80%用于训练和20%用于测试：

![图8.27 – 分割数据以进行训练和测试](img/B18003_08_027.jpg)

图8.27 – 分割数据以进行训练和测试

1.  接下来，配置训练：

![图8.28 – 训练](img/B18003_08_028.jpg)

图8.28 – 训练

使用数据集训练模型。在这里，我们使用逻辑回归进行建模。

1.  接下来，让我们创建一个公平性仪表板。一个公平性仪表板至少需要这三个参数：

    +   **敏感特征** – 包含敏感数据的列，例如性别或种族

    +   **原始** **标签值**

    +   **预测值** **进行分析**

点击由负责的AI SDK创建的URL。将打开一个新的网页。按照仪表板中的导航选择敏感列，查看数据如何分布在这些特征上。这里的主要目的是提供关于特征如何与敏感信息平衡的见解。例如，如果我们有包含男性和女性数据点的数据，我们想确保男性和女性在数据集中有相同数量的代表性。

![图8.29 – 创建公平性仪表板](img/B18003_08_029.jpg)

图8.29 – 创建公平性仪表板

这里是仪表板的主页：

![图8.30 – 公平性仪表板 – 简介页面](img/B18003_08_030.jpg)

图8.30 – 公平性仪表板 – 简介页面

1.  点击**开始**以查看分析公平性的选项。

1.  该过程的第一个步骤是选择敏感特征。在下面的屏幕截图中，我们有两个列，**性别**和**种族**。在**性别**列中，我们有两个类别，**男性**和**女性**。对于**种族**，我们有**白人**、**黑人**、**亚洲-太平洋岛民**、**其他**和**美洲印第安人-爱斯基摩人**。让我们首先选择**性别**来检查敏感特征，然后点击**下一步**。

![图 8.31 – 公平性仪表板 – 01 敏感特征](img/B18003_08_031.jpg)

图 8.31 – 公平性仪表板 – 01 敏感特征

1.  现在，让我们选择用于我们分析的性能指标。性能指标选项如下：

    +   **准确率**

    +   **平衡准确率**

    +   **F1 分数**

    +   **精确率**

    +   **回忆**

这些指标的定义在*图 8**.32*中提供。对于我们来说，我们将选择**准确率**作为指标，以**性别**作为我们分析的敏感列。点击**下一步**进入**公平性指标**。

![图 8.32 – 公平性仪表板 – 02 性能指标](img/B18003_08_032.jpg)

图 8.32 – 公平性仪表板 – 02 性能指标

1.  接下来是最重要的筛选之一。选择适合我们分析的正确公平性指标。在下面的屏幕截图中，你可以看到选择。在我们的例子中，我们选择**人口统计学差异**。然后点击**下一步**来查看分析图表。

![图 8.33 – 公平性仪表板 – 03 公平性指标](img/B18003_08_033.jpg)

图 8.33 – 公平性仪表板 – 03 公平性指标

1.  在下一个屏幕上，我们可以更改这些选择，查看公平性指标是如何计算的，并检查哪些敏感特征被选中以及它们的公平性如何。

![图 8.34 – 公平性结果](img/B18003_08_034.jpg)

图 8.34 – 公平性结果

前面的图表显示，模型中女性的代表性不足，这也表明模型可能对男性有偏见。因此，现在我们可以回过头来看看我们是否可以得到一个更平衡的数据集，以使我们的模型更加公平。尝试切换图表到假阳性和假阴性率，以深入查看假阳性和假阴性的比率。你还可以更改**性能指标**、**敏感特征**和**公平性指标**并分析公平性。随着这些选项的变化，图表将反映这些变化。这个工具提供了一个单一的地方来分析数据以查找偏差和公平性。

![图 8.35 – 公平性结果 – 假阳性率和假阴性率](img/B18003_08_035.jpg)

图 8.35 – 公平性结果 – 假阳性率和假阴性率

我们现在可以深入挖掘黑盒模型，看看模型是如何做出决策的，并分析数据集以查找任何偏差或错误，并确保公平性。

# 摘要

通过使用负责任的AI工具箱SDK，我们可以分析数据以评估公平性和错误，并深入挖掘决策树以理解模型是如何做出决策的。请注意，在这个领域还有工作要做。SDK仍在开发中，功能正在增加，所以请记住，功能将会改变，并将添加新功能。在撰写本文时，我们已使用LightGBM、XGBoost和PyTorch算法对公平性进行了测试。工具箱允许我们打开黑盒模型并查看决策是如何做出的，并且还能生成公平且无偏的输出。

在下一章中，我们将学习如何将机器学习模型投入生产。
