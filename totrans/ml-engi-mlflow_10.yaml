- en: '*Chapter 7*: Data and Feature Management'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will add a feature management data layer to the machine
    learning platform being built. We will leverage the features of the MLflow Projects
    module to structure our data pipeline.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will look at the following sections in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Structuring your data pipeline project
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acquiring stock data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking data quality
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing features
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will acquire relevant data to provide datasets for training.
    Our primary resource will be the Yahoo Finance Data for BTC dataset. Alongside
    that data, we will acquire the following extra datasets.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'Leveraging our productionization architecture introduced in [*Chapter 6*](B16783_06_Final_SB_epub.xhtml#_idTextAnchor106),
    *Introducing ML Systems Architecture*, represented in *Figure 7.1*, the feature
    and data component is responsible for acquiring data from sources and making the
    data available in a format consumable by the different components of the platform:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – High-level architecture with a data layer reference'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0013.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.1 – High-level architecture with a data layer reference
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Let's delve into this chapter and see how we will structure and populate the
    data layer with relevant data to be used for training models and generating features.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following prerequisites:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of Docker installed on your machine. If you don't already
    have it installed, please follow the instructions at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of docker-compose installed. Please follow the instructions
    at [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to Git on the command line and installed as described at [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a Bash terminal (Linux or Windows).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a browser.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.5+ installed.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of your machine learning installed locally as described in
    [*Chapter 3*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066), *Your Data Science
    Workbench*.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will describe the structure of our data pipeline, the
    data sources, and the different steps that we will execute to implement our practical
    example leveraging MLflow project features to package the project.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Copying and pasting directly from the code snippets might cause issues with
    your editor. Please refer to the GitHub repository of the chapter available at
    https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter07
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Structuring your data pipeline project
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At a high level, our data pipeline will run weekly, collecting data for the
    preceding 7 days and storing it in a way that can be run by machine learning jobs
    to generate models upstream. We will structure our data folders into three types
    of data:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '**Raw data**: A dataset generated by retrieving data from the Yahoo Finance
    API for the last 90 days. We will store the data in CSV format – the same format
    that it was received in from the API. We will log the run in MLflow and extract
    the number of rows collected.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原始数据**：通过从 Yahoo Finance API 获取过去 90 天的数据生成的数据集。我们将以 CSV 格式存储数据——与从 API 收到的格式相同。我们将在
    MLflow 中记录运行并提取收集到的行数。'
- en: '**Staged data**: Over the raw data, we will run quality checks, schema verification,
    and confirm that the data can be used in production. This information about data
    quality will be logged in MLflow Tracking.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**阶段数据**：在原始数据上，我们将运行质量检查、模式验证，并确认数据可用于生产。有关数据质量的信息将记录在 MLflow 跟踪中。'
- en: '**Training data**: The training data is the final product of the data pipeline.
    It must be executed over data that is deemed as clean and suitable to execute
    models. The data contains the data processed into features that can be consumed
    directly for the training process.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据**：训练数据是数据管道的最终产品。它必须在被认为是干净且适合执行模型的数据上执行。数据包含已处理成可以直接用于训练过程的功能数据。'
- en: 'This folder structure will be implemented initially on the filesystem and will
    be transposed to the relevant environment (examples: AWS S3, Kubernetes PersistentVolume,
    and so on) during deployment.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种文件夹结构最初将在文件系统中实现，并在部署期间转换为相关环境（例如：AWS S3、Kubernetes PersistentVolume 等）。
- en: 'In order to execute our data pipeline project, we will use the **MLflow Project**
    module to package the data pipeline in an execution environment-independent format.
    We will use the Docker format to package the **MLflow Project**. The Docker format
    provides us with different options to deploy our project in the cloud or on-premises
    depending on the available infrastructure to deploy our project:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行我们的数据管道项目，我们将使用 **MLflow 项目** 模块以与执行环境无关的格式打包数据管道。我们将使用 Docker 格式打包 **MLflow
    项目**。Docker 格式为我们提供了不同的选项，根据可用的基础设施，我们可以将项目部署在云端或本地：
- en: '![](img/image0024.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image0024.jpg)'
- en: Figure 7.2 – High-level architecture with a data layer reference
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 具有数据层引用的高级架构
- en: 'Our workflow will execute the following steps, as illustrated in *Figure 7.2*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作流程将执行以下步骤，如图 *图 7.2* 所示：
- en: '`data/raw/data.csv folder`.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data/raw/data.csv 文件夹`.'
- en: '`data/staged/data.csv file`.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data/staged/data.csv 文件`.'
- en: '`data/training/data.csv location`.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data/training/data.csv 位置`.'
- en: With these three distinct phases, we ensure the reproducibility of the training
    data generation process, visibility, and a clear separation of the different steps
    of the process.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这三个不同的阶段，我们确保了训练数据生成过程的可重复性、可见性和过程不同步骤的清晰分离。
- en: 'We will start by organizing our MLflow project into steps and creating placeholders
    for each of the components of the pipeline:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先将我们的 MLflow 项目组织成步骤，并为管道的每个组件创建占位符：
- en: Create a new folder on your local machine with the name `psytock-data-features`.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的本地机器上创建一个名为 `psytock-data-features` 的新文件夹。
- en: 'Add the `MLProject file`:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加 `MLProject 文件`：
- en: '[PRE0]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Add the following `conda.yaml` file:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加以下 `conda.yaml` 文件：
- en: '[PRE1]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can now add a sample `main.py` file to the folder to ensure that the basic
    structure of the project is working:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在可以向文件夹中添加一个示例 `main.py` 文件，以确保项目的基本结构正在工作：
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Test the basic structure by running the following command:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令测试基本结构：
- en: '[PRE3]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This command will build your project based on the environment created by your
    `conda.yaml` file and run the basic project that you just created. It should error
    out as we need to add the missing files. The *file not found* error will look
    like the following :'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令将根据您的 `conda.yaml` 文件创建的环境构建您的项目，并运行您刚刚创建的基本项目。它应该会出错，因为我们需要添加缺失的文件。*文件未找到*
    错误将如下所示：
- en: '[PRE4]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: At this stage, we have the basic blocks of the MLflow project of the data pipeline
    that we will be building in this chapter. We will next fill in the Python script
    to acquire the data in the next section.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们有了将在本章中构建的数据管道 MLflow 项目的基石。我们将在下一节中填写获取数据的 Python 脚本。
- en: Acquiring stock data
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取股票数据
- en: Our script to acquire the data will be based on the `pandas-datareader Python
    package`. It provides a simple abstraction to remote financial APIs we can leverage
    in the future in the pipeline. The abstraction is very simple. Given a data source
    such as Yahoo Finance, you provide the stock ticker/pair and date range, and the
    data is provided in a DataFrame.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取数据的脚本将基于`pandas-datareader Python包`。它提供了一个简单的抽象，我们可以利用它来在管道中利用远程金融API。这个抽象非常简单。给定一个数据源，例如Yahoo
    Finance，您提供股票代码/对和日期范围，数据将以DataFrame的形式提供。
- en: 'We will now create the `load_raw_data.py file`, which will be responsible for
    loading the data and saving it in the `raw` folder. You can look at the contents
    of the file in the repository at https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/load_raw_data.py.
    Execute the following steps to implement the file:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建`load_raw_data.py`文件，该文件将负责加载数据并将其保存到`raw`文件夹中。您可以在以下存储库中查看文件的详细内容：https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/load_raw_data.py。执行以下步骤以实现该文件：
- en: 'We will start by importing the relevant packages:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先导入相关包：
- en: '[PRE5]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, you should add a function to retrieve the data:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您应该添加一个函数来检索数据：
- en: '[PRE6]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that we've acquired the data, we need to apply the best practices we will
    address in the next section – an approach to check the data quality of the data
    acquired.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经获取了数据，我们需要应用下一节中将要讨论的最佳实践——检查获取的数据质量的方法。
- en: Checking data quality
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查数据质量
- en: Checking data quality as part of your machine learning system is extremely critical
    to ensure the integrity and correctness of your model training and inference.
    Principles of software testing and quality should be borrowed and used on the
    data layer of machine learning platforms.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据质量检查作为您机器学习系统的一部分，对于确保模型训练和推理的完整性和正确性至关重要。应借鉴并使用软件测试和质量原则于机器学习平台的数据层。
- en: 'From a data quality perspective, in a dataset there are a couple of critical
    dimensions with which to assess and profile our data, namely:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据质量的角度来看，在数据集中有几个关键的维度可以用来评估和配置我们的数据，即：
- en: '**Schema compliance**: Ensuring the data is from the expected types; making
    sure that numeric values don''t contain any other types of data'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式合规性**：确保数据来自预期的类型；确保数值不包含其他类型的数据'
- en: '**Valid data**: Assessing from a data perspective whether the data is valid
    from a business perspective'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效数据**：从数据角度评估数据是否从业务角度有效'
- en: '**Missing data**: Assessing whether all the data needed to run analytics and
    algorithms is available'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失数据**：评估是否所有运行分析和算法所需的数据都可用'
- en: For data validation, we will use the *Great Expectations* Python package (available
    at [https://github.com/great-expectations/great_expectations](https://github.com/great-expectations/great_expectations)).
    It allows making assertions on data with many data-compatible packages, such as
    pandas, Spark, and cloud environments. It provides a DSL in JSON with which to
    declare the rules that we want our data to be compliant with.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据验证，我们将使用*Great Expectations* Python包（可在[https://github.com/great-expectations/great_expectations](https://github.com/great-expectations/great_expectations)找到）。它允许使用许多数据兼容的包（如pandas、Spark和云环境）对数据进行断言。它提供了一个JSON
    DSL，我们可以用它来声明我们希望数据遵守的规则。
- en: 'For our current project, we want the following rules/constraints to be verifiable:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的当前项目，我们希望以下规则/约束是可验证的：
- en: Date values should be valid dates and cannot be missing.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期值应该是有效的日期，且不能缺失。
- en: Check numeric and long values are correctly typed.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数值和长值是否正确类型。
- en: All columns are present in the dataset.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中的所有列都存在。
- en: We will now create the `check_verify_data.py file`, which will be responsible
    for loading the data and saving it in the `staging` folder where all the data
    is valid and ready to be used for ML training. You can look at the contents of
    the file in the repository at https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/check_verify_data.py.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建`check_verify_data.py`文件，该文件将负责加载数据并将其保存到`staging`文件夹中，所有数据都有效且准备好用于机器学习训练。您可以在以下存储库中查看文件的详细内容：https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/check_verify_data.py。
- en: 'In order to convert the preceding rules so they can be relied on by our system,
    we will need to import the following dependencies:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使前面的规则能够被我们的系统依赖，我们需要导入以下依赖项：
- en: '[PRE7]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we will implement the script:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将实现脚本：
- en: '[PRE8]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we can progress to do a little bit of cleaning:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以进行一些清理工作：
- en: '[PRE9]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Having verified the quality of the data and staging to be used, it can now be
    utilized for feature generation with a high degree of confidence.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证了数据的质量和暂存用于后，现在可以以高度的信心用于特征生成。
- en: Generating a feature set and training data
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成特征集和训练数据
- en: We will refactor a bit of the code previously developed in our local environment
    to generate features for training to add to our MLflow project the data pipelineof
    our MLflow project .
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重构在本地环境中先前开发的代码，以生成用于训练的特征，并将我们的MLflow项目中的数据管道添加到我们的MLflow项目中。
- en: 'We will now create the `feature_set_generation.py file`, which will be responsible
    for generating our features and saving them in the `training` folder where all
    the data is valid and ready to be used for ML training. You can look at the contents
    in the file in the repository https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/feature_set_generation.py:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将创建`feature_set_generation.py`文件，该文件将负责生成我们的特征并将它们保存在`training`文件夹中，所有数据都是有效的，并且准备好用于机器学习训练。你可以在仓库https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter07/psystock-data-features-main/feature_set_generation.py中查看文件内容：
- en: 'We need to import the following dependencies:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要导入以下依赖项：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before delving into the main component of the code, we''ll now proceed to implement
    a critical function to generate the features by basically transforming the difference
    with each *n* preceding day in a feature that we will use to predict the next
    day, very similar to the approach that we used in previous chapters of the book
    for our running use case:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深入研究代码的主要组件之前，我们现在将实现一个关键函数，通过基本上将每个*n*个前一天的差异转换为特征，我们将使用这个特征来预测下一天，这与我们在本书的前几章中用于我们的运行用例的方法非常相似：
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we''ll proceed to read the staged file that is deemed as clean and ready
    to be used by upstream processes:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将继续读取被认为是清洁且准备好由上游流程使用的暂存文件：
- en: '[PRE12]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We generate the feature set and features. We are now able to run all of the
    end-to-end pipeline from data acquisition to feature generation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成特征集和特征。我们现在能够从数据采集到特征生成运行整个端到端管道。
- en: Running your end-to-end pipeline
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行你的端到端管道
- en: 'In this section, we will run the complete example, which you can retrieve from
    the following address for the book''s GitHub repository in the folder at `/Chapter07/psytock-data-features-main`.
    *Figure 7.3* illustrates the complete folder structure of the project that you
    can inspect in GitHub and compare with your local version:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将运行完整的示例，你可以从以下地址获取该示例，地址为书的GitHub仓库中的/Chapter07/psytock-data-features-main文件夹。*图7.3*展示了你可以在GitHub中检查的项目完整文件夹结构，并与你的本地版本进行比较：
- en: '![Figure 7.3 – Folder structure'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.3 – 文件夹结构'
- en: '](img/image0034.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0034.jpg)'
- en: Figure 7.3 – Folder structure
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 文件夹结构
- en: 'To run the pipeline end to end, you should execute the following command in
    the directory with the code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行端到端管道，你应该在包含代码的目录中执行以下命令：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It will basically execute the end-to-end pipeline and you can inspect it directly
    in the MLflow UI, running each of the steps of the pipeline in order:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 它将基本执行端到端管道，你可以在MLflow UI中直接检查它，按顺序运行管道的每个步骤：
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You can run and explore the tracking information in MLflow at [http://localhost:5000](http://localhost:5000).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在MLflow中运行和探索跟踪信息，网址为[http://localhost:5000](http://localhost:5000)。
- en: 'In *Figure 7.4*, you can see the different runs of the main project and subprojects
    of the stages of the pipeline in a nested workflow format that you can browse
    to inspect the details:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.4*中，你可以看到管道阶段的主项目和子项目的不同运行，以嵌套工作流程格式呈现，你可以浏览以检查细节：
- en: '![Figure 7.4 – High-level architecture with a data layer reference'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.4 – 带数据层引用的高级架构'
- en: '](img/image0044.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0044.jpg)'
- en: Figure 7.4 – High-level architecture with a data layer reference
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 带数据层引用的高级架构
- en: 'In *Figure 7.5*, you can see the reference to the `load_raw_data` phase of
    the data pipeline and check when it was started and stopped and the parameters
    used:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.5*中，你可以看到数据管道的`load_raw_data`阶段的引用，并检查它何时开始和停止以及使用的参数：
- en: '![Figure 7.5 – High-level architecture with a data layer reference'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.5 – 包含数据层引用的高级架构'
- en: '](img/image0054.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0054.jpg)'
- en: Figure 7.5 – High-level architecture with a data layer reference
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 包含数据层引用的高级架构
- en: 'In *Figure.7.6*, you can see the reference to the `check_verify_data` phase
    of the data pipeline where we logged some basic statistical information of the
    dataset obtained:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.6*中，您可以看到数据管道中`check_verify_data`阶段的引用，我们记录了数据集的一些基本统计信息：
- en: '![Figure 7.6 – High-level architecture with a data layer reference'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.6 – 包含数据层引用的高级架构'
- en: '](img/image0063.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0063.jpg)'
- en: Figure 7.6 – High-level architecture with a data layer reference
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 包含数据层引用的高级架构
- en: 'If any data quality issues are detected, the workflow will fail with a clear
    indication of which section failed, as represented in *Figure 7.7*:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测到任何数据质量问题，工作流将失败，并明确指出哪个部分失败了，如*图7.7*所示：
- en: '![Figure 7.7 – Checking errors'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.7 – 检查错误'
- en: '](img/image0073.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0073.jpg)'
- en: Figure 7.7 – Checking errors
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 检查错误
- en: With this section, we have concluded the description of the process of data
    management and feature generation in a data pipeline implemented with the `MLProjects`
    module in MLflow. We will now look at how to manage the data in a feature store.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本节，我们已完成了使用MLflow中的`MLProjects`模块实现的数据管道中数据管理和特征生成过程的描述。我们现在将探讨如何管理特征存储中的数据。
- en: Using a feature store
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用特征存储
- en: A feature store is a software layer on top of your data to abstract all the
    production and management processes for data by providing inference systems with
    an interface to retrieve a feature set that can be used for inference or training.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储是在您的数据之上的一层软件层，通过为推理系统提供一个接口来检索可用于推理或训练的特征集，从而抽象化所有数据的生成和管理过程。
- en: 'In this section, we will illustrate the concept of a feature store by using
    Feast (a feature store), an operational data system for managing and serving machine
    learning features to models in production:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过使用Feast（一个特征存储），一个用于管理和为生产中的模型提供机器学习特征的操作性数据系统，来阐述特征存储的概念：
- en: '![Figure 7.8 – Feast Architecture (retrieved from https://docs.feast.dev/)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.8 – Feast架构（来自https://docs.feast.dev/）'
- en: '](img/image0083.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0083.jpg)'
- en: Figure 7.8 – Feast Architecture (retrieved from https://docs.feast.dev/)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – Feast架构（来自https://docs.feast.dev/）
- en: 'In order to understand how Feast works and how it can fit into your data layer
    component (code available at https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter07/psystock_feature_store,
    execute the following steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解Feast是如何工作的以及它如何适合您的数据层组件（代码可在https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter07/psystock_feature_store找到，执行以下步骤：
- en: 'Install `feast`:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`feast`：
- en: '[PRE15]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Initialize a feature repository:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化特征存储库：
- en: '[PRE16]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create your feature definitions by replacing the `yaml` file generated automatically:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过替换自动生成的`yaml`文件来创建您的特征定义：
- en: '[PRE17]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will now proceed to import dependencies of the feature definition:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将导入特征定义的依赖项：
- en: '[PRE18]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can now load the feature files:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以加载特征文件：
- en: '[PRE19]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can now add a feature view:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以添加一个特征视图：
- en: '[PRE20]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To deploy the feature store with the configurations added so far, we need to
    run the following command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要部署带有迄今为止添加的配置的特征存储，我们需要运行以下命令：
- en: '[PRE21]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: At this stage, the feature store is deployed in your environment (locally in
    this case) and the feature store is available to be used from your MLflow job.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个阶段，特征存储已部署到您的环境中（在本例中为本地），并且特征存储可供您的MLflow作业使用。
- en: 'We can now do feature retrieval, now that all the features are stored in a
    feature store:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在所有特征都已存储在特征存储中，我们可以进行特征检索：
- en: '[PRE22]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can now integrate your feature store repository into your MLflow workloads.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以将您的特征存储库集成到您的MLflow工作负载中。
- en: With this section, we have concluded the description of the process of data
    management and feature generation in a data pipeline implemented with the `MLProjects
    module` in MLflow. We are now ready to deal with production environment deployments
    in subsequent chapters.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本节，我们已完成了使用MLflow中的`MLProjects模块`实现的数据管道中数据管理和特征生成过程的描述。我们现在准备好在后续章节中处理生产环境部署。
- en: Summary
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered MLflow and its integration with the feature management
    data layer of our reference architecture. We leveraged the features of the MLflow
    Projects module to structure our data pipeline.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了MLflow及其与参考架构中特征管理数据层的集成。我们利用MLflow项目模块的功能来构建我们的数据管道。
- en: The important layer of data and feature management was introduced, and the need
    for feature generation was made clear, as were the concepts of data quality, validation,
    and data preparation.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍了数据与特征管理的重要层级，并明确了特征生成的需求，同时阐述了数据质量、验证和数据准备的概念。
- en: We applied the different stages of producing a data pipeline to our own project.
    We then formalized data acquisition and quality checks. In the last section, we
    introduced the concept of a feature store and how to create and use one.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据管道生产的各个阶段应用于我们的项目。然后我们正式化了数据获取和质量检查。在最后一节，我们介绍了特征存储的概念以及如何创建和使用它。
- en: In the next chapters and following section of the book, we will focus on applying
    the data pipeline and features to the process of training and deploying the data
    pipeline in production.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一章节和后续部分，我们将专注于将数据管道和特征应用于生产环境中数据管道的训练和部署过程。
- en: Further reading
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'In order to further your knowledge, you can consult the documentation at the
    following link:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步扩展您的知识，您可以参考以下链接中的文档：
- en: '[https://github.com/mlflow/mlflow/blob/master/examples/multistep_workflow/MLproject](https://github.com/mlflow/mlflow/blob/master/examples/multistep_workflow/MLproject)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/mlflow/mlflow/blob/master/examples/multistep_workflow/MLproject](https://github.com/mlflow/mlflow/blob/master/examples/multistep_workflow/MLproject)'
