<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<meta charset="utf-8"/>
<meta content="pandoc" name="generator"/>
<title>ch020.xhtml</title>
<link href="../styles/stylesheet1.css" rel="stylesheet" type="text/css"/>
<!-- kobo-style -->
<style id="koboSpanStyle" type="text/css" xmlns="http://www.w3.org/1999/xhtml">.koboSpan { -webkit-text-combine: inherit; }</style>
</head>
<body epub:type="bodymatter">
<section class="level1 chapterHead" data-number="19" id="chapter-11-the-best-of-both-worlds-hybrid-architectures">
<h1 class="H1---Chapter chapterHead" data-number="19"><span class="titlemark"><span class="koboSpan" id="kobo.1.1" xmlns="http://www.w3.org/1999/xhtml">Chapter 11</span></span><br/>
<span id="x1-19500011"><span class="koboSpan" id="kobo.2.1" xmlns="http://www.w3.org/1999/xhtml">The Best of Both Worlds: Hybrid Architectures</span></span></h1>
<div class="flushright">
<p><em><span class="koboSpan" id="kobo.3.1" xmlns="http://www.w3.org/1999/xhtml">Unity makes strength.</span></em><br/><span class="koboSpan" id="kobo.4.1" xmlns="http://www.w3.org/1999/xhtml">
— English aphorism</span></p>
</div>
<p><span class="koboSpan" id="kobo.5.1" xmlns="http://www.w3.org/1999/xhtml">By now, we have a solid understanding of both classical and quantum neural networks. </span><span class="koboSpan" id="kobo.5.2" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we will leverage this knowledge to explore an interesting kind of model: hybrid architectures of quantum neural networks.</span></p>
<p><span class="koboSpan" id="kobo.6.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we will discuss what these models are and how they can be useful, and we will also learn how to implement and train them with PennyLane and Qiskit. </span><span class="koboSpan" id="kobo.6.2" xmlns="http://www.w3.org/1999/xhtml">The whole chapter is going to be very hands-on, and we will also take the time to fill in some gaps regarding the actual practice of training models in real-world scenarios. </span><span class="koboSpan" id="kobo.6.3" xmlns="http://www.w3.org/1999/xhtml">In addition to this — and just to spice things up a bit — we will go beyond our usual binary classifiers and also consider other kinds of problems.</span></p>
<p><span class="koboSpan" id="kobo.7.1" xmlns="http://www.w3.org/1999/xhtml">We’ll cover the following topics in this chapter:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.8.1" xmlns="http://www.w3.org/1999/xhtml">The what and why of hybrid architectures</span></p></li>
<li><p><span class="koboSpan" id="kobo.9.1" xmlns="http://www.w3.org/1999/xhtml">Hybrid architectures in PennyLane (with a brief overview of best practices for training models in real-world scenarios and an introduction to multi-class classification problems)</span></p></li>
<li><p><span class="koboSpan" id="kobo.10.1" xmlns="http://www.w3.org/1999/xhtml">Hybrid architectures in Qiskit (with an introduction to PyTorch)</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.11.1" xmlns="http://www.w3.org/1999/xhtml">This is going to be a very exciting chapter. </span><span class="koboSpan" id="kobo.11.2" xmlns="http://www.w3.org/1999/xhtml">Let’s begin by giving meaning to these hybrid architectures.</span></p>
<section class="level2 sectionHead" data-number="19.1" id="the-what-and-why-of-hybrid-architectures">
<h1 class="sectionHead" data-number="19.1"><span class="titlemark"><span class="koboSpan" id="kobo.12.1" xmlns="http://www.w3.org/1999/xhtml">11.1 </span></span> <span id="x1-19600011.1"><span class="koboSpan" id="kobo.13.1" xmlns="http://www.w3.org/1999/xhtml">The what and why of hybrid architectures</span></span></h1>
<p><span class="koboSpan" id="kobo.14.1" xmlns="http://www.w3.org/1999/xhtml">Up until now, we’ve used the adjective ”hybrid” to describe algorithms that rely on both classical and quantum processing; algorithms such as QAOA or VQE fit in this category, as well as the training of QSVMs and QNNs. </span><span class="koboSpan" id="kobo.14.2" xmlns="http://www.w3.org/1999/xhtml">When we talk about </span><strong><span class="koboSpan" id="kobo.15.1" xmlns="http://www.w3.org/1999/xhtml">hybrid architectures</span></strong><span class="koboSpan" id="kobo.16.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><strong><span class="koboSpan" id="kobo.17.1" xmlns="http://www.w3.org/1999/xhtml">hybrid models</span></strong><span class="koboSpan" id="kobo.18.1" xmlns="http://www.w3.org/1999/xhtml">, however, we refer to </span><span id="dx1-196001"/><span class="koboSpan" id="kobo.19.1" xmlns="http://www.w3.org/1999/xhtml">something more specific: we speak about models that combine classical </span><span id="dx1-196002"/><span class="koboSpan" id="kobo.20.1" xmlns="http://www.w3.org/1999/xhtml">models with other quantum-based models by joining them together and training them as a single unit. </span><span class="koboSpan" id="kobo.20.2" xmlns="http://www.w3.org/1999/xhtml">Of course, the training of hybrid models will itself be a hybrid algorithm. </span><span class="koboSpan" id="kobo.20.3" xmlns="http://www.w3.org/1999/xhtml">We know that the terminology might be confusing, but what can we do? </span><span class="koboSpan" id="kobo.20.4" xmlns="http://www.w3.org/1999/xhtml">Hybrid is too versatile a word to give it up.</span></p>
<p><span class="koboSpan" id="kobo.21.1" xmlns="http://www.w3.org/1999/xhtml">In particular, we will combine quantum neural networks with classical neural networks, for they are the two models that fit more naturally together. </span><span class="koboSpan" id="kobo.21.2" xmlns="http://www.w3.org/1999/xhtml">The way we will go about doing this will be by taking a usual classical neural network and plugging in a quantum neural network as one of its layers. </span><span class="koboSpan" id="kobo.21.3" xmlns="http://www.w3.org/1999/xhtml">In this way, the ”quantum layer” will take as input the outputs of the previous layer (or the inputs to the model, if there’s no layer before it) and will feed its output to the next layer (should there be any). </span><span class="koboSpan" id="kobo.21.4" xmlns="http://www.w3.org/1999/xhtml">The output of the quantum neural network will be a numerical array of length </span><span class="koboSpan" id="kobo.22.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.23.1" xmlns="http://www.w3.org/1999/xhtml">; thus, in the eyes of the next layer, the quantum layer will behave as if it were a classical layer with </span><span class="koboSpan" id="kobo.24.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.25.1" xmlns="http://www.w3.org/1999/xhtml"> neurons.</span></p>
<p><span class="koboSpan" id="kobo.26.1" xmlns="http://www.w3.org/1999/xhtml">These hybrid </span><span id="dx1-196003"/><span class="koboSpan" id="kobo.27.1" xmlns="http://www.w3.org/1999/xhtml">architectures combining classical and quantum neural networks are said to be, to the surprise of no one, </span><strong><span class="koboSpan" id="kobo.28.1" xmlns="http://www.w3.org/1999/xhtml">hybrid quantum neural</span></strong> <strong><span class="koboSpan" id="kobo.29.1" xmlns="http://www.w3.org/1999/xhtml">networks</span></strong><span class="koboSpan" id="kobo.30.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox important" id="tcolobox-193">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.31.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.32.1" xmlns="http://www.w3.org/1999/xhtml">In summary, a hybrid QNN is a classical neural network in which one or more of its layers have been replaced by quantum layers. </span><span class="koboSpan" id="kobo.32.2" xmlns="http://www.w3.org/1999/xhtml">These are quantum neural networks that get inputs from the outputs of the previous layer and feed their outputs to the next one. </span><span class="koboSpan" id="kobo.32.3" xmlns="http://www.w3.org/1999/xhtml">Of course, if there’s no next layer, the output of the quantum layer will be the output of the network. </span><span class="koboSpan" id="kobo.32.4" xmlns="http://www.w3.org/1999/xhtml">Analogously, if there’s no previous layer, the input to the quantum network will be the model’s input.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.33.1" xmlns="http://www.w3.org/1999/xhtml">As we’ve already hinted, a hybrid neural network is trained as a single unit: the training process involves the optimization of both the parameters of the classical layers and those of the quantum neural networks inside the quantum layers.</span></p>
<p><span class="koboSpan" id="kobo.34.1" xmlns="http://www.w3.org/1999/xhtml">To make the whole definition of hybrid QNNs more clear, let us consider a simple example of how one such </span><span id="dx1-196004"/><span class="koboSpan" id="kobo.35.1" xmlns="http://www.w3.org/1999/xhtml">network may be constructed:</span></p>
<ol>
<li><div id="x1-196006x1">
<p><span class="koboSpan" id="kobo.36.1" xmlns="http://www.w3.org/1999/xhtml">The hybrid QNN must begin taking some classical inputs. </span><span class="koboSpan" id="kobo.36.2" xmlns="http://www.w3.org/1999/xhtml">Let’s say it takes </span><span class="koboSpan" id="kobo.37.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.38.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-196008x2">
<p><span class="koboSpan" id="kobo.39.1" xmlns="http://www.w3.org/1999/xhtml">We may then feed the input into a usual classical layer with </span><span class="koboSpan" id="kobo.40.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.41.1" xmlns="http://www.w3.org/1999/xhtml"> neurons and use the sigmoid activation function.</span></p>
</div></li>
<li><div id="x1-196010x3">
<p><span class="koboSpan" id="kobo.42.1" xmlns="http://www.w3.org/1999/xhtml">Then, we will add a quantum layer. </span><span class="koboSpan" id="kobo.42.2" xmlns="http://www.w3.org/1999/xhtml">This quantum layer will have to accept </span><span class="koboSpan" id="kobo.43.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.44.1" xmlns="http://www.w3.org/1999/xhtml"> inputs from the previous layer. </span><span class="koboSpan" id="kobo.44.2" xmlns="http://www.w3.org/1999/xhtml">For example, we could use a QNN with three qubits using amplitude encoding. </span><span class="koboSpan" id="kobo.44.3" xmlns="http://www.w3.org/1999/xhtml">The output of this quantum layer could be, for instance, the expectation values of the first and second qubits, both measured on the computational basis. </span><span class="koboSpan" id="kobo.44.4" xmlns="http://www.w3.org/1999/xhtml">In this case, this quantum layer that we have added will return two numeric values.</span></p>
</div></li>
<li><div id="x1-196012x4">
<p><span class="koboSpan" id="kobo.45.1" xmlns="http://www.w3.org/1999/xhtml">Finally, we may add a classical layer with a single neuron that uses the sigmoid activation function. </span><span class="koboSpan" id="kobo.45.2" xmlns="http://www.w3.org/1999/xhtml">This layer will take inputs from the quantum layer, so it will accept two inputs. </span><span class="koboSpan" id="kobo.45.3" xmlns="http://www.w3.org/1999/xhtml">It will essentially treat the quantum layer as if it were a classical layer with two neurons.</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.46.1" xmlns="http://www.w3.org/1999/xhtml">And that’s how you can build yourself a simple hybrid QNN — at least in theory! </span><span class="koboSpan" id="kobo.46.2" xmlns="http://www.w3.org/1999/xhtml">But the question is... </span><span class="koboSpan" id="kobo.46.3" xmlns="http://www.w3.org/1999/xhtml">why would we want to do such a thing? </span><span class="koboSpan" id="kobo.46.4" xmlns="http://www.w3.org/1999/xhtml">What are these hybrid models good for? </span><span class="koboSpan" id="kobo.46.5" xmlns="http://www.w3.org/1999/xhtml">Let’s illustrate it with a typical example.</span></p>
<p><span class="koboSpan" id="kobo.47.1" xmlns="http://www.w3.org/1999/xhtml">In the previous chapter, we learned how to use a QNN to tackle a (binary) classification task. </span><span class="koboSpan" id="kobo.47.2" xmlns="http://www.w3.org/1999/xhtml">But, due to the </span><span id="dx1-196013"/><span class="koboSpan" id="kobo.48.1" xmlns="http://www.w3.org/1999/xhtml">limitations of current quantum hardware and simulators, we were forced to apply some dimensionality reduction techniques on our data before we could use it. </span><span class="koboSpan" id="kobo.48.2" xmlns="http://www.w3.org/1999/xhtml">That’s a situation where hybrid QNNs may prove useful: why not combine, in a single model, classical dimensionality reduction carried out by a classical neural network with classification performed by a quantum neural network?</span></p>
<p><span class="koboSpan" id="kobo.49.1" xmlns="http://www.w3.org/1999/xhtml">In this way, instead of first reducing the dimensionality of our data and then classifying it with a quantum neural network, we could consider a hybrid QNN with</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.50.1" xmlns="http://www.w3.org/1999/xhtml">a bunch of classical layers that would reduce the dimensionality of our data,</span></p></li>
<li><p><span class="koboSpan" id="kobo.51.1" xmlns="http://www.w3.org/1999/xhtml">joined to a quantum layer that would be in charge of making the classification.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.52.1" xmlns="http://www.w3.org/1999/xhtml">Of course, since the whole network would be trained as a single unit, there would be no way to truly tell whether the classical part of the network is only doing dimensionality reduction and the quantum part is only doing classification. </span><span class="koboSpan" id="kobo.52.2" xmlns="http://www.w3.org/1999/xhtml">Most likely, both parts will work on both tasks to some degree.</span></p>
<p><span class="koboSpan" id="kobo.53.1" xmlns="http://www.w3.org/1999/xhtml">Before proceeding any further, a few disclaimers are in order. </span><span class="koboSpan" id="kobo.53.2" xmlns="http://www.w3.org/1999/xhtml">First and foremost: quantum layers are not any sort of magical tool that will surely lead to great improvements in the performance of a classical neural network. </span><span class="koboSpan" id="kobo.53.3" xmlns="http://www.w3.org/1999/xhtml">Actually, if used unwisely, quantum layers could very easily have a negative impact on your model! </span><span class="koboSpan" id="kobo.53.4" xmlns="http://www.w3.org/1999/xhtml">The key takeaway is that you shouldn’t blindly use a quantum layer solely as a replacement for a classical layer in a network. </span><span class="koboSpan" id="kobo.53.5" xmlns="http://www.w3.org/1999/xhtml">Be intentional. </span><span class="koboSpan" id="kobo.53.6" xmlns="http://www.w3.org/1999/xhtml">If you are going to include a quantum layer in your model, think about the role it’s going to play in it.</span></p>
<p><span class="koboSpan" id="kobo.54.1" xmlns="http://www.w3.org/1999/xhtml">In addition, when working with hybrid QNNs, you should watch out for how you are joining classical and quantum layers together. </span><span class="koboSpan" id="kobo.54.2" xmlns="http://www.w3.org/1999/xhtml">For instance, if you have a quantum layer using a feature map that requires its inputs to be normalized, maybe using an ELU activation function in the previous layer isn’t the best of ideas, because it is in no way bounded. </span><span class="koboSpan" id="kobo.54.3" xmlns="http://www.w3.org/1999/xhtml">On the other hand, in that case, a sigmoid activation function could be a great fit for the previous layer.</span></p>
<p><span class="koboSpan" id="kobo.55.1" xmlns="http://www.w3.org/1999/xhtml">In the use case that we discussed a few paragraphs ago (combining classical data reduction with quantum classification), we can witness the ”intentionality” that we’ve just talked about. </span><span class="koboSpan" id="kobo.55.2" xmlns="http://www.w3.org/1999/xhtml">We do know that, in principle, a neural network can do a good job at reducing data dimensionality; in case you didn’t know, it’s a </span><span id="dx1-196014"/><span class="koboSpan" id="kobo.56.1" xmlns="http://www.w3.org/1999/xhtml">known fact that, using something called </span><strong><span class="koboSpan" id="kobo.57.1" xmlns="http://www.w3.org/1999/xhtml">autoencoders</span></strong> <span class="cite"><span class="koboSpan" id="kobo.58.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xhandsonml"><span class="koboSpan" id="kobo.59.1" xmlns="http://www.w3.org/1999/xhtml">104</span></a><span class="koboSpan" id="kobo.60.1" xmlns="http://www.w3.org/1999/xhtml">, Chapter 17]</span></span><span class="koboSpan" id="kobo.61.1" xmlns="http://www.w3.org/1999/xhtml">, one can train an </span><strong><span class="koboSpan" id="kobo.62.1" xmlns="http://www.w3.org/1999/xhtml">encoder</span></strong> <span id="dx1-196015"/><span class="koboSpan" id="kobo.63.1" xmlns="http://www.w3.org/1999/xhtml">network that can reduce the dimensionality of a dataset. </span><span class="koboSpan" id="kobo.63.2" xmlns="http://www.w3.org/1999/xhtml">And we know that a quantum neural network can do a good job at classifying data coming from a dimensionality reduction technique (just have a look at the previous chapter!). </span><span class="koboSpan" id="kobo.63.3" xmlns="http://www.w3.org/1999/xhtml">So there must be some choice of parameters such that the combined hybrid model will successfully accomplish both tasks. </span><span class="koboSpan" id="kobo.63.4" xmlns="http://www.w3.org/1999/xhtml">Hence, with the right training, our hybrid model should be able to perform at least as well as it would if a classical encoder and a quantum classifier were trained separately. </span><span class="koboSpan" id="kobo.63.5" xmlns="http://www.w3.org/1999/xhtml">And the important bit is the ”at least,” because when training the classical encoder and the quantum classifier together we can join their powers!</span></p>
<p><span class="koboSpan" id="kobo.64.1" xmlns="http://www.w3.org/1999/xhtml">And that’s the heuristic justification behind this interesting application of hybrid neural networks. </span><span class="koboSpan" id="kobo.64.2" xmlns="http://www.w3.org/1999/xhtml">Actually, this is the use case that we will devote this chapter to. </span><span class="koboSpan" id="kobo.64.3" xmlns="http://www.w3.org/1999/xhtml">However, this is by no means the only application of hybrid models!</span></p>
<div class="tcolorbox learnmore" id="tcolobox-194">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.65.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.66.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.67.1" xmlns="http://www.w3.org/1999/xhtml">Hybrid architectures can also be used in regression problems, as we will later see in an exercise. </span><span class="koboSpan" id="kobo.67.2" xmlns="http://www.w3.org/1999/xhtml">In fact, this is a very interesting application, for Skolit et al. </span><span class="cite"><span class="koboSpan" id="kobo.68.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xskolik2022quantum"><span class="koboSpan" id="kobo.69.1" xmlns="http://www.w3.org/1999/xhtml">91</span></a><span class="koboSpan" id="kobo.70.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.71.1" xmlns="http://www.w3.org/1999/xhtml"> have shown that adding a final layer with trainable parameters that transform the output of a quantum neural network can be very beneficial in certain reinforcement learning problems.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.72.1" xmlns="http://www.w3.org/1999/xhtml">Now we promised that this chapter would be very hands-on, and we are going to honor that. </span><span class="koboSpan" id="kobo.72.2" xmlns="http://www.w3.org/1999/xhtml">That should have been enough of a theoretical introduction, so let’s gear up! </span><span class="koboSpan" id="kobo.72.3" xmlns="http://www.w3.org/1999/xhtml">Get ready to train a bunch of hybrid QNNs to classify some data.</span></p>
</section>
<section class="level2 sectionHead" data-number="19.2" id="hybrid-architectures-in-pennylane">
<h1 class="sectionHead" data-number="19.2"><span class="titlemark"><span class="koboSpan" id="kobo.73.1" xmlns="http://www.w3.org/1999/xhtml">11.2 </span></span> <span id="x1-19700011.2"><span class="koboSpan" id="kobo.74.1" xmlns="http://www.w3.org/1999/xhtml">Hybrid architectures in PennyLane</span></span></h1>
<p><span class="koboSpan" id="kobo.75.1" xmlns="http://www.w3.org/1999/xhtml">In this section, we are going to use </span><span id="dx1-197001"/><span class="koboSpan" id="kobo.76.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane to implement and train a couple of hybrid QNNs in order to solve some classification problems. </span><span class="koboSpan" id="kobo.76.2" xmlns="http://www.w3.org/1999/xhtml">Firstly, we will tackle a binary classification problem, just to better understand how hybrid QNNs work in a familiar setting. </span><span class="koboSpan" id="kobo.76.3" xmlns="http://www.w3.org/1999/xhtml">Then, we will take one step further and do the same for a multi-class classification problem.</span></p>
<p><span class="koboSpan" id="kobo.77.1" xmlns="http://www.w3.org/1999/xhtml">Before we get to the problems, though, let us set things up.</span></p>
<section class="level3 subsectionHead" data-number="19.2.1" id="setting-things-up">
<h2 class="subsectionHead" data-number="19.2.1"><span class="titlemark"><span class="koboSpan" id="kobo.78.1" xmlns="http://www.w3.org/1999/xhtml">11.2.1 </span></span> <span id="x1-19800011.2.1"><span class="koboSpan" id="kobo.79.1" xmlns="http://www.w3.org/1999/xhtml">Setting things up</span></span></h2>
<p><span class="koboSpan" id="kobo.80.1" xmlns="http://www.w3.org/1999/xhtml">As on previous occasions, we shall begin by </span><span id="dx1-198001"/><span class="koboSpan" id="kobo.81.1" xmlns="http://www.w3.org/1999/xhtml">importing NumPy and TensorFlow and setting a seed for both packages — all to ensure the reproducibility of our results:</span></p>
<p><span id="x1-198002"/></p>
<pre class="lstlisting" id="listing-263"><span class="koboSpan" id="kobo.82.1" xmlns="http://www.w3.org/1999/xhtml">

import numpy as np 
 
import tensorflow as tf 
 
 
 
seed = 1234 
 
np.random.seed(seed) 
 
tf.random.set_seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.83.1" xmlns="http://www.w3.org/1999/xhtml">Now we can also import some useful functions from scikit-learn. </span><span class="koboSpan" id="kobo.83.2" xmlns="http://www.w3.org/1999/xhtml">We’ve already used them extensively — they need no introduction!</span></p>
<pre class="lstlisting" id="listing-264"><span class="koboSpan" id="kobo.84.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.metrics import accuracy_score 
 
from sklearn.model_selection import train_test_split
</span></pre>
<p><span class="koboSpan" id="kobo.85.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we will generate our own datasets to have more flexibility. </span><span class="koboSpan" id="kobo.85.2" xmlns="http://www.w3.org/1999/xhtml">In order to create them, we will rely on the </span><code><span class="koboSpan" id="kobo.86.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.87.1" xmlns="http://www.w3.org/1999/xhtml"> function in the scikit-learn package. </span><span class="koboSpan" id="kobo.87.2" xmlns="http://www.w3.org/1999/xhtml">Remember that we introduced it in </span><em><span class="koboSpan" id="kobo.88.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.89.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><span class="koboSpan" id="kobo.90.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.91.1" xmlns="http://www.w3.org/1999/xhtml">What Is</span></em> <em><span class="koboSpan" id="kobo.92.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Machine Learning?</span></em><span class="koboSpan" id="kobo.93.1" xmlns="http://www.w3.org/1999/xhtml">:</span></p>
<pre class="lstlisting" id="listing-265"><span class="koboSpan" id="kobo.94.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.datasets import make_classification
</span></pre>
<p><span class="koboSpan" id="kobo.95.1" xmlns="http://www.w3.org/1999/xhtml">Also, in this section, we will use the Lightning simulator with adjoint differentiation in order to get a good performance. </span><span class="koboSpan" id="kobo.95.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we need to change the default datatype used by Keras models:</span></p>
<pre class="lstlisting" id="listing-266"><span class="koboSpan" id="kobo.96.1" xmlns="http://www.w3.org/1999/xhtml">

tf.keras.backend.set_floatx(’float64’)
</span></pre>
<p><span class="koboSpan" id="kobo.97.1" xmlns="http://www.w3.org/1999/xhtml">We can now import PennyLane and define the </span><span id="dx1-198013"/><span class="koboSpan" id="kobo.98.1" xmlns="http://www.w3.org/1999/xhtml">hermitian matrix </span><span class="koboSpan" id="kobo.99.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.100.1" xmlns="http://www.w3.org/1999/xhtml"> that we used in the previous chapter. </span><span class="koboSpan" id="kobo.100.2" xmlns="http://www.w3.org/1999/xhtml">Recall that it corresponds to the observable that assigns the eigenvalue </span><span class="koboSpan" id="kobo.101.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.102.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><span class="koboSpan" id="kobo.103.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| 0 \right\rangle" class="math inline" src="../media/file6.png" style="vertical-align:middle" title="\left| 0 \right\rangle"/></span><span class="koboSpan" id="kobo.104.1" xmlns="http://www.w3.org/1999/xhtml"> and the eigenvalue </span><span class="koboSpan" id="kobo.105.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.106.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><span class="koboSpan" id="kobo.107.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| 1 \right\rangle" class="math inline" src="../media/file14.png" style="vertical-align:middle" title="\left| 1 \right\rangle"/></span><span class="koboSpan" id="kobo.108.1" xmlns="http://www.w3.org/1999/xhtml">; that is, </span><span class="koboSpan" id="kobo.109.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M = \left| 0 \right\rangle\left\langle 0 \right|" class="math inline" src="../media/file1388.png" style="vertical-align:middle" title="M = \left| 0 \right\rangle\left\langle 0 \right|"/></span><span class="koboSpan" id="kobo.110.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<pre class="lstlisting" id="listing-267"><span class="koboSpan" id="kobo.111.1" xmlns="http://www.w3.org/1999/xhtml">

import pennylane as qml 
 
 
 
state_0 = [[1], [0]] 
 
M = state_0 * np.conj(state_0).T
</span></pre>
<p><span class="koboSpan" id="kobo.112.1" xmlns="http://www.w3.org/1999/xhtml">Lastly, we may import Matplotlib and reuse the function that we defined in the previous chapter for plotting training and validation losses:</span></p>
<pre class="lstlisting" id="listing-268"><span class="koboSpan" id="kobo.113.1" xmlns="http://www.w3.org/1999/xhtml">

import matplotlib.pyplot as plt 
 
 
 
def plot_losses(history): 
 
    tr_loss = history.history["loss"] 
 
    val_loss = history.history["val_loss"] 
 
    epochs = np.array(range(len(tr_loss))) + 1 
 
    plt.plot(epochs, tr_loss, label = "Training loss") 
 
    plt.plot(epochs, val_loss, label = "Validation loss") 
 
    plt.xlabel("Epoch") 
 
    plt.legend() 
 
    plt.show()
</span></pre>
<p><span class="koboSpan" id="kobo.114.1" xmlns="http://www.w3.org/1999/xhtml">And that’s all we need to get started. </span><span class="koboSpan" id="kobo.114.2" xmlns="http://www.w3.org/1999/xhtml">Let’s go for our first problem.</span></p>
</section>
<section class="level3 subsectionHead" data-number="19.2.2" id="a-binary-classification-problem">
<h2 class="subsectionHead" data-number="19.2.2"><span class="titlemark"><span class="koboSpan" id="kobo.115.1" xmlns="http://www.w3.org/1999/xhtml">11.2.2 </span></span> <span id="x1-19900011.2.2"><span class="koboSpan" id="kobo.116.1" xmlns="http://www.w3.org/1999/xhtml">A binary classification problem</span></span></h2>
<p><span class="koboSpan" id="kobo.117.1" xmlns="http://www.w3.org/1999/xhtml">We are now ready to build our first </span><span id="dx1-199001"/><span class="koboSpan" id="kobo.118.1" xmlns="http://www.w3.org/1999/xhtml">hybrid QNN and train it to solve a binary classification task. </span><span class="koboSpan" id="kobo.118.2" xmlns="http://www.w3.org/1999/xhtml">Of course, the first thing we need is data and, as we discussed in the previous section, we shall generate it using the </span><code><span class="koboSpan" id="kobo.119.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.120.1" xmlns="http://www.w3.org/1999/xhtml"> function. </span><span class="koboSpan" id="kobo.120.2" xmlns="http://www.w3.org/1999/xhtml">Using a hybrid QNN that will ”combine classical encoding with quantum classification” can make sense if, for instance, we have a large number of variables (features) in our dataset, so we will generate a dataset with </span><span class="koboSpan" id="kobo.121.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="20" class="math inline" src="../media/file588.png" style="vertical-align:middle" title="20"/></span><span class="koboSpan" id="kobo.122.1" xmlns="http://www.w3.org/1999/xhtml"> variables — that might already be quite large for current quantum hardware! </span><span class="koboSpan" id="kobo.122.2" xmlns="http://www.w3.org/1999/xhtml">Just to make sure that we have enough data, we will generate </span><span class="koboSpan" id="kobo.123.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1000" class="math inline" src="../media/file790.png" style="vertical-align:middle" title="1000"/></span><span class="koboSpan" id="kobo.124.1" xmlns="http://www.w3.org/1999/xhtml"> samples. </span><span class="koboSpan" id="kobo.124.2" xmlns="http://www.w3.org/1999/xhtml">This is how we can do it:</span></p>
<pre class="lstlisting" id="listing-269"><span class="koboSpan" id="kobo.125.1" xmlns="http://www.w3.org/1999/xhtml">

x, y = make_classification(n_samples = 1000, n_features = 20)
</span></pre>
<p><span class="koboSpan" id="kobo.126.1" xmlns="http://www.w3.org/1999/xhtml">By default, the </span><code><span class="koboSpan" id="kobo.127.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.128.1" xmlns="http://www.w3.org/1999/xhtml"> functions generate datasets with two possible classes. </span><span class="koboSpan" id="kobo.128.2" xmlns="http://www.w3.org/1999/xhtml">Just what we wanted!</span></p>
<p><span class="koboSpan" id="kobo.129.1" xmlns="http://www.w3.org/1999/xhtml">As usual, we will have to split this dataset into some training, validation, and test datasets:</span></p>
<pre class="lstlisting" id="listing-270"><span class="koboSpan" id="kobo.130.1" xmlns="http://www.w3.org/1999/xhtml">

x_tr, x_test, y_tr, y_test = train_test_split( 
 
    x, y, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split( 
 
    x_test, y_test, train_size = 0.5)
</span></pre>
<p><span class="koboSpan" id="kobo.131.1" xmlns="http://www.w3.org/1999/xhtml">With our data ready, we need to think about the model that we will use. </span><span class="koboSpan" id="kobo.131.2" xmlns="http://www.w3.org/1999/xhtml">Let’s begin by constructing the quantum layer (the QNN) that we will include at the end of the network.</span></p>
<p><span class="koboSpan" id="kobo.132.1" xmlns="http://www.w3.org/1999/xhtml">For this problem, we will use the two-local variational form that we introduced in the previous chapter (see </span><em><span class="koboSpan" id="kobo.133.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="ch019.xhtml#Figure10.2"><em><span class="koboSpan" id="kobo.134.1" xmlns="http://www.w3.org/1999/xhtml">10.2</span></em></a><span class="koboSpan" id="kobo.135.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.135.2" xmlns="http://www.w3.org/1999/xhtml">As you surely remember, we can implement it in PennyLane as follows:</span></p>
<pre class="lstlisting" id="listing-271"><span class="koboSpan" id="kobo.136.1" xmlns="http://www.w3.org/1999/xhtml">

def TwoLocal(nqubits, theta, reps = 1): 
 
 
 
    for r in range(reps): 
 
        for i in range(nqubits): 
 
            qml.RY(theta[r * nqubits + i], wires = i) 
 
        for i in range(nqubits - 1): 
 
            qml.CNOT(wires = [i, i + 1]) 
 
 
 
    for i in range(nqubits): 
 
        qml.RY(theta[reps * nqubits + i], wires = i)
</span></pre>
<p><span class="koboSpan" id="kobo.137.1" xmlns="http://www.w3.org/1999/xhtml">We will take the </span><span id="dx1-199017"/><span class="koboSpan" id="kobo.138.1" xmlns="http://www.w3.org/1999/xhtml">quantum layer to be a simple QNN on four qubits using angle embedding as a feature map followed by the two-local variational form that we have just implemented. </span><span class="koboSpan" id="kobo.138.2" xmlns="http://www.w3.org/1999/xhtml">The measurement operation in the QNN will be the computation of the expectation value of </span><span class="koboSpan" id="kobo.139.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.140.1" xmlns="http://www.w3.org/1999/xhtml"> on the first qubit; that’s a sensible choice for binary classifiers in general, because it returns a value between </span><span class="koboSpan" id="kobo.141.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.142.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.143.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.144.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.144.2" xmlns="http://www.w3.org/1999/xhtml">The QNN can be defined as follows:</span></p>
<pre class="lstlisting" id="listing-272"><span class="koboSpan" id="kobo.145.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 4 
 
dev = qml.device("lightning.qubit", wires = nqubits) 
 
 
 
@qml.qnode(dev, interface="tf", diff_method = "adjoint") 
 
def qnn(inputs, theta): 
 
    qml.AngleEmbedding(inputs, range(nqubits)) 
 
    TwoLocal(nqubits, theta, reps = 2) 
 
    return qml.expval(qml.Hermitian(M, wires = [0])) 
 
 
 
weights = {"theta": 12}
</span></pre>
<p><span class="koboSpan" id="kobo.146.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have already declared the weights dictionary that we will have to send to the TensorFlow interface in order to create the quantum layer. </span><span class="koboSpan" id="kobo.146.2" xmlns="http://www.w3.org/1999/xhtml">In it, we’ve specified that our variational form uses </span><span class="koboSpan" id="kobo.147.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4 \cdot (2 + 1) = 12" class="math inline" src="../media/file1398.png" style="vertical-align:middle" title="4 \cdot (2 + 1) = 12"/></span><span class="koboSpan" id="kobo.148.1" xmlns="http://www.w3.org/1999/xhtml"> weights.</span></p>
<p><span class="koboSpan" id="kobo.149.1" xmlns="http://www.w3.org/1999/xhtml">We will define our hybrid QNN to have an input layer with </span><span class="koboSpan" id="kobo.150.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="20" class="math inline" src="../media/file588.png" style="vertical-align:middle" title="20"/></span><span class="koboSpan" id="kobo.151.1" xmlns="http://www.w3.org/1999/xhtml"> inputs in order to match the dimension of our data. </span><span class="koboSpan" id="kobo.151.2" xmlns="http://www.w3.org/1999/xhtml">This will be followed by a classical layer, which will be immediately followed by the quantum neural network (the quantum layer). </span><span class="koboSpan" id="kobo.151.3" xmlns="http://www.w3.org/1999/xhtml">Since our QNN accepts </span><span class="koboSpan" id="kobo.152.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.153.1" xmlns="http://www.w3.org/1999/xhtml"> inputs, the classical layer will have </span><span class="koboSpan" id="kobo.154.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.155.1" xmlns="http://www.w3.org/1999/xhtml"> neurons itself. </span><span class="koboSpan" id="kobo.155.2" xmlns="http://www.w3.org/1999/xhtml">Moreover, for the QNN to work optimally, we need the data to be normalized, so the classical layer will use a sigmoid activation function. </span><span class="koboSpan" id="kobo.155.3" xmlns="http://www.w3.org/1999/xhtml">We can define this </span><span id="dx1-199028"/><span class="koboSpan" id="kobo.156.1" xmlns="http://www.w3.org/1999/xhtml">model in Keras as follows:</span></p>
<pre class="lstlisting" id="listing-273"><span class="koboSpan" id="kobo.157.1" xmlns="http://www.w3.org/1999/xhtml">

model = tf.keras.models.Sequential([ 
 
    tf.keras.layers.Input(20), 
 
    tf.keras.layers.Dense(4, activation = "sigmoid"), 
 
    qml.qnn.KerasLayer(qnn, weights, output_dim=1) 
 
])
</span></pre>
<div class="tcolorbox learnmore" id="tcolobox-195">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.158.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.159.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.160.1" xmlns="http://www.w3.org/1999/xhtml">When defining the Keras model, you may be tempted to store the quantum layer in a variable and then use it in the model definition, as follows:</span></p>
<pre class="lstlisting" id="listing-274"><span class="koboSpan" id="kobo.161.1" xmlns="http://www.w3.org/1999/xhtml">

qlayer = qml.qnn.KerasLayer(qnn, weights, output_dim=1) 
 
model = tf.keras.models.Sequential([ 
 
    tf.keras.layers.Input(20), 
 
    tf.keras.layers.Dense(4, activation = "sigmoid"), 
 
    qlayer 
 
])
</span></pre>
<p><span class="koboSpan" id="kobo.162.1" xmlns="http://www.w3.org/1999/xhtml">This code will work and, a priori, there’s nothing wrong with it. </span><span class="koboSpan" id="kobo.162.2" xmlns="http://www.w3.org/1999/xhtml">However, if you decide to reset or modify your model, you will also have to rerun the first line, with the definition of </span><code><span class="koboSpan" id="kobo.163.1" xmlns="http://www.w3.org/1999/xhtml">qlayer</span></code><span class="koboSpan" id="kobo.164.1" xmlns="http://www.w3.org/1999/xhtml">, if you want to re-initialize the optimizable parameters (weights) in the quantum neural network!</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.165.1" xmlns="http://www.w3.org/1999/xhtml">Having the model ready, we can also define our usual early stopping callback:</span></p>
<pre class="lstlisting" id="listing-275"><span class="koboSpan" id="kobo.166.1" xmlns="http://www.w3.org/1999/xhtml">

earlystop = tf.keras.callbacks.EarlyStopping( 
 
    monitor="val_loss", patience=2, verbose=1, 
 
    restore_best_weights=True)
</span></pre>
<p><span class="koboSpan" id="kobo.167.1" xmlns="http://www.w3.org/1999/xhtml">We’ve set the patience to </span><span class="koboSpan" id="kobo.168.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.169.1" xmlns="http://www.w3.org/1999/xhtml"> epochs in order to speed up the training; having a higher patience may easily lead to better results!</span></p>
<p><span class="koboSpan" id="kobo.170.1" xmlns="http://www.w3.org/1999/xhtml">And now, all it takes for us to train our model is to — just as we’ve always done on TensorFlow — pick an optimizer, compile our model with the binary cross entropy loss function, and call the </span><code><span class="koboSpan" id="kobo.171.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.172.1" xmlns="http://www.w3.org/1999/xhtml"> method with the appropriate arguments:</span></p>
<pre class="lstlisting" id="listing-276"><span class="koboSpan" id="kobo.173.1" xmlns="http://www.w3.org/1999/xhtml">

opt = tf.keras.optimizers.Adam(learning_rate = 0.005) 
 
model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy()) 
 
 
 
history = model.fit(x_tr, y_tr, epochs = 50, shuffle = True, 
 
    validation_data = (x_val, y_val), 
 
    batch_size = 10, 
 
    callbacks = [earlystop])
</span></pre>
<p><span class="koboSpan" id="kobo.174.1" xmlns="http://www.w3.org/1999/xhtml">Et voilà! </span><span class="koboSpan" id="kobo.174.2" xmlns="http://www.w3.org/1999/xhtml">In just a matter of minutes, your flashy hybrid model will have finished training. </span><span class="koboSpan" id="kobo.174.3" xmlns="http://www.w3.org/1999/xhtml">Take a </span><span id="dx1-199050"/><span class="koboSpan" id="kobo.175.1" xmlns="http://www.w3.org/1999/xhtml">moment to reflect on how easy this was. </span><span class="koboSpan" id="kobo.175.2" xmlns="http://www.w3.org/1999/xhtml">You have been able to train a hybrid QNN with full ease, just as if it were a simple QNN. </span><span class="koboSpan" id="kobo.175.3" xmlns="http://www.w3.org/1999/xhtml">With PennyLane, quantum machine learning is a piece of cake.</span></p>
<p><span class="koboSpan" id="kobo.176.1" xmlns="http://www.w3.org/1999/xhtml">To check how well the training went, we can plot the training and validation losses with our custom function:</span></p>
<pre class="lstlisting" id="listing-277"><span class="koboSpan" id="kobo.177.1" xmlns="http://www.w3.org/1999/xhtml">

plot_losses(history)
</span></pre>
<p><span class="koboSpan" id="kobo.178.1" xmlns="http://www.w3.org/1999/xhtml">The generated plot can be found in </span><em><span class="koboSpan" id="kobo.179.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure11.1"><em><span class="koboSpan" id="kobo.180.1" xmlns="http://www.w3.org/1999/xhtml">11.1</span></em></a><span class="koboSpan" id="kobo.181.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.182.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 11.1: Evolution of the training and validation loss functions in the training of a hybrid QNN binary classifier " src="../media/file1399.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure11.1"><strong><span class="koboSpan" id="kobo.183.1" xmlns="http://www.w3.org/1999/xhtml">Figure 11.1</span></strong><span class="koboSpan" id="kobo.184.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.185.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the training and validation loss functions in the training of a hybrid QNN binary classifier </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.186.1" xmlns="http://www.w3.org/1999/xhtml">Those losses look really good; there don’t seem to be signs of overfitting and the model appears to be learning. </span><span class="koboSpan" id="kobo.186.2" xmlns="http://www.w3.org/1999/xhtml">In any case, let’s </span><span id="dx1-199054"/><span class="koboSpan" id="kobo.187.1" xmlns="http://www.w3.org/1999/xhtml">compute the test accuracy. </span><span class="koboSpan" id="kobo.187.2" xmlns="http://www.w3.org/1999/xhtml">We may also compute the training and validation accuracies, just for reference:</span></p>
<pre class="lstlisting" id="listing-278"><span class="koboSpan" id="kobo.188.1" xmlns="http://www.w3.org/1999/xhtml">

tr_acc = accuracy_score(model.predict(x_tr) &gt;= 0.5, y_tr) 
 
val_acc = accuracy_score(model.predict(x_val) &gt;= 0.5, y_val) 
 
test_acc = accuracy_score(model.predict(x_test) &gt;= 0.5, y_test) 
 
print("Train accuracy:", tr_acc) 
 
print("Validation accuracy:", val_acc) 
 
print("Test accuracy:", test_acc)
</span></pre>
<p><span class="koboSpan" id="kobo.189.1" xmlns="http://www.w3.org/1999/xhtml">When running the preceding code, we can see how our model has a training accuracy of </span><span class="koboSpan" id="kobo.190.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="95\%" class="math inline" src="../media/file1400.png" style="vertical-align:middle" title="95\%"/></span><span class="koboSpan" id="kobo.191.1" xmlns="http://www.w3.org/1999/xhtml">, a validation accuracy of </span><span class="koboSpan" id="kobo.192.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="90\%" class="math inline" src="../media/file1401.png" style="vertical-align:middle" title="90\%"/></span><span class="koboSpan" id="kobo.193.1" xmlns="http://www.w3.org/1999/xhtml">, and a test accuracy of </span><span class="koboSpan" id="kobo.194.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="96\%" class="math inline" src="../media/file1402.png" style="vertical-align:middle" title="96\%"/></span><span class="koboSpan" id="kobo.195.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.196.1" xmlns="http://www.w3.org/1999/xhtml">That’s a very satisfactory result. </span><span class="koboSpan" id="kobo.196.2" xmlns="http://www.w3.org/1999/xhtml">We have just trained our first hybrid QNN binary classifier, and we’ve seen how it can be effectively used to solve classification tasks.</span></p>
<div class="tcolorbox questionx" id="tcolobox-196">
<span id="x1-199062x11.2.2"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.197.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.1</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.198.1" xmlns="http://www.w3.org/1999/xhtml">Try to solve this problem using two additional (dense) classical layers, with </span><span class="koboSpan" id="kobo.199.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.200.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.201.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.202.1" xmlns="http://www.w3.org/1999/xhtml"> neurons each. </span><span class="koboSpan" id="kobo.202.2" xmlns="http://www.w3.org/1999/xhtml">Compare the results.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.203.1" xmlns="http://www.w3.org/1999/xhtml">Now, we said that this chapter was going to be hands-on and we truly meant it. </span><span class="koboSpan" id="kobo.203.2" xmlns="http://www.w3.org/1999/xhtml">So far, we have just </span><span id="dx1-199063"/><span class="koboSpan" id="kobo.204.1" xmlns="http://www.w3.org/1999/xhtml">trained models and gotten them right in one shot, but that’s something that rarely happens in practice. </span><span class="koboSpan" id="kobo.204.2" xmlns="http://www.w3.org/1999/xhtml">That’s why we’ve put together a small subsection on how to optimize models in real-world conditions.</span></p>
</section>
<section class="level3 subsectionHead" data-number="19.2.3" id="training-models-in-the-real-world">
<h2 class="subsectionHead" data-number="19.2.3"><span class="titlemark"><span class="koboSpan" id="kobo.205.1" xmlns="http://www.w3.org/1999/xhtml">11.2.3 </span></span> <span id="x1-20000011.2.3"><span class="koboSpan" id="kobo.206.1" xmlns="http://www.w3.org/1999/xhtml">Training models in the real world</span></span></h2>
<p><span class="koboSpan" id="kobo.207.1" xmlns="http://www.w3.org/1999/xhtml">Whether you believe it or not, we care for you, our dear reader. </span><span class="koboSpan" id="kobo.207.2" xmlns="http://www.w3.org/1999/xhtml">All this time, behind each and every </span><span id="dx1-200001"/><span class="koboSpan" id="kobo.208.1" xmlns="http://www.w3.org/1999/xhtml">model that we’ve trained, we’ve invested hours of meticulous parameter selection and model preparation — all to make sure that the results we give you are good enough, if not optimal.</span></p>
<p><span class="koboSpan" id="kobo.209.1" xmlns="http://www.w3.org/1999/xhtml">When you set out to train models on your own, you will soon find out that things don’t always work as well as you expected. </span><span class="koboSpan" id="kobo.209.2" xmlns="http://www.w3.org/1999/xhtml">For each well-performing model, there will be tens or even hundreds of discarded ones. </span><span class="koboSpan" id="kobo.209.3" xmlns="http://www.w3.org/1999/xhtml">And that’s something you need to prepare yourself for.</span></p>
<p><span class="koboSpan" id="kobo.210.1" xmlns="http://www.w3.org/1999/xhtml">At the early stages of a machine learning project in general — and a quantum machine learning project in particular — you should address two main following questions:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.211.1" xmlns="http://www.w3.org/1999/xhtml">How will you log all your results?</span></strong><span class="koboSpan" id="kobo.212.1" xmlns="http://www.w3.org/1999/xhtml"> When you train lots of models, you need to find a way to log their performances together with their architectures and the parameters used in their training. </span><span class="koboSpan" id="kobo.212.2" xmlns="http://www.w3.org/1999/xhtml">That way, you can easily identify what works and what doesn’t, and you can avoid repeating the same mistakes.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.213.1" xmlns="http://www.w3.org/1999/xhtml">How will you explore variations of your models?</span></strong><span class="koboSpan" id="kobo.214.1" xmlns="http://www.w3.org/1999/xhtml"> Keeping a separate script for every model can be manageable when you are not training many models, but this isn’t a solution for large-scale projects. </span><span class="koboSpan" id="kobo.214.2" xmlns="http://www.w3.org/1999/xhtml">Oftentimes, you want to try a wide range of configurations and see which one works best. </span><span class="koboSpan" id="kobo.214.3" xmlns="http://www.w3.org/1999/xhtml">And automation can truly make your life easier in this regard.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.215.1" xmlns="http://www.w3.org/1999/xhtml">We leave the first question to you. </span><span class="koboSpan" id="kobo.215.2" xmlns="http://www.w3.org/1999/xhtml">In truth, there’s no universal way to address it — it all depends on the problem at hand and on the training strategy that you take. </span><span class="koboSpan" id="kobo.215.3" xmlns="http://www.w3.org/1999/xhtml">However, in regard to the second question, we do have something to offer.</span></p>
<p><span class="koboSpan" id="kobo.216.1" xmlns="http://www.w3.org/1999/xhtml">When </span><span id="dx1-200002"/><span class="koboSpan" id="kobo.217.1" xmlns="http://www.w3.org/1999/xhtml">training a model, choosing good hyperparameters — such as a good batch size or learning rate — is not an easy task, but it is a crucial one. </span><span class="koboSpan" id="kobo.217.2" xmlns="http://www.w3.org/1999/xhtml">Should you use a smaller or a larger learning rate? </span><span class="koboSpan" id="kobo.217.3" xmlns="http://www.w3.org/1999/xhtml">How many layers should you use? </span><span class="koboSpan" id="kobo.217.4" xmlns="http://www.w3.org/1999/xhtml">Of what type? </span><span class="koboSpan" id="kobo.217.5" xmlns="http://www.w3.org/1999/xhtml">Decisions, decisions, decisions! </span><span class="koboSpan" id="kobo.217.6" xmlns="http://www.w3.org/1999/xhtml">The number of possibilities grows exponentially, so it is impossible to explore every one of them. </span><span class="koboSpan" id="kobo.217.7" xmlns="http://www.w3.org/1999/xhtml">But, in machine learning, finding a good configuration can be the difference between success and failure. </span><span class="koboSpan" id="kobo.217.8" xmlns="http://www.w3.org/1999/xhtml">How can we do this systematically and (kind of) effortlessly?</span></p>
<p><span class="koboSpan" id="kobo.218.1" xmlns="http://www.w3.org/1999/xhtml">There are quite a few packages and utilities out there that can help you automate the search for optimal training parameters. </span><span class="koboSpan" id="kobo.218.2" xmlns="http://www.w3.org/1999/xhtml">One of the most popular ones is the Optuna package, which we are about to demonstrate. </span><span class="koboSpan" id="kobo.218.3" xmlns="http://www.w3.org/1999/xhtml">Please refer to </span><em><span class="koboSpan" id="kobo.219.1" xmlns="http://www.w3.org/1999/xhtml">Appendix</span></em> <a href="ch027.xhtml#x1-240000D"><em><span class="koboSpan" id="kobo.220.1" xmlns="http://www.w3.org/1999/xhtml">D</span></em></a><span class="koboSpan" id="kobo.221.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.222.1" xmlns="http://www.w3.org/1999/xhtml">Installing the Tools</span></em><span class="koboSpan" id="kobo.223.1" xmlns="http://www.w3.org/1999/xhtml">, for installation instructions.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-197">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.224.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.225.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.226.1" xmlns="http://www.w3.org/1999/xhtml">The process of automatically searching for optimal training parameters in a machine learning problem fits into what is </span><span id="dx1-200003"/><span class="koboSpan" id="kobo.227.1" xmlns="http://www.w3.org/1999/xhtml">known as </span><strong><span class="koboSpan" id="kobo.228.1" xmlns="http://www.w3.org/1999/xhtml">automated machine learning</span></strong><span class="koboSpan" id="kobo.229.1" xmlns="http://www.w3.org/1999/xhtml">, usually abbreviated as </span><strong><span class="koboSpan" id="kobo.230.1" xmlns="http://www.w3.org/1999/xhtml">AutoML</span></strong><span class="koboSpan" id="kobo.231.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.231.2" xmlns="http://www.w3.org/1999/xhtml">This refers to the use of automation in order to solve machine learning problems. </span><span class="koboSpan" id="kobo.231.3" xmlns="http://www.w3.org/1999/xhtml">Having machines in charge of training other machines!</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.232.1" xmlns="http://www.w3.org/1999/xhtml">Once you’ve installed Optuna, you can import it as follows:</span></p>
<pre class="lstlisting" id="listing-279"><span class="koboSpan" id="kobo.233.1" xmlns="http://www.w3.org/1999/xhtml">

import optuna
</span></pre>
<p><span class="koboSpan" id="kobo.234.1" xmlns="http://www.w3.org/1999/xhtml">We are going to use Optuna to find the best possible learning rate between the values </span><span class="koboSpan" id="kobo.235.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.001" class="math inline" src="../media/file1165.png" style="vertical-align:middle" title="0.001"/></span><span class="koboSpan" id="kobo.236.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.237.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.1" class="math inline" src="../media/file1163.png" style="vertical-align:middle" title="0.1"/></span><span class="koboSpan" id="kobo.238.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.238.2" xmlns="http://www.w3.org/1999/xhtml">In order to do this, we need to define a function (which we shall call </span><code><span class="koboSpan" id="kobo.239.1" xmlns="http://www.w3.org/1999/xhtml">objective</span></code><span class="koboSpan" id="kobo.240.1" xmlns="http://www.w3.org/1999/xhtml">) with a single argument (</span><code><span class="koboSpan" id="kobo.241.1" xmlns="http://www.w3.org/1999/xhtml">trial</span></code><span class="koboSpan" id="kobo.242.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.242.2" xmlns="http://www.w3.org/1999/xhtml">The objective function should use the training parameters that we want to optimize — in a manner that we will soon make precise — and it should return whichever metric we want to optimize. </span><span class="koboSpan" id="kobo.242.3" xmlns="http://www.w3.org/1999/xhtml">For instance, in our case, we would like to maximize the validation accuracy, so the objective function should train a model and return the validation accuracy.</span></p>
<p><span class="koboSpan" id="kobo.243.1" xmlns="http://www.w3.org/1999/xhtml">The </span><code><span class="koboSpan" id="kobo.244.1" xmlns="http://www.w3.org/1999/xhtml">trial</span></code><span class="koboSpan" id="kobo.245.1" xmlns="http://www.w3.org/1999/xhtml"> argument of the </span><code><span class="koboSpan" id="kobo.246.1" xmlns="http://www.w3.org/1999/xhtml">objective</span></code><span class="koboSpan" id="kobo.247.1" xmlns="http://www.w3.org/1999/xhtml"> function is meant to represent an object of the </span><code><span class="koboSpan" id="kobo.248.1" xmlns="http://www.w3.org/1999/xhtml">Trial</span></code><span class="koboSpan" id="kobo.249.1" xmlns="http://www.w3.org/1999/xhtml"> class that can be found in the </span><code><span class="koboSpan" id="kobo.250.1" xmlns="http://www.w3.org/1999/xhtml">optuna</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.251.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.252.1" xmlns="http://www.w3.org/1999/xhtml">trial</span></code><span class="koboSpan" id="kobo.253.1" xmlns="http://www.w3.org/1999/xhtml"> module. </span><span class="koboSpan" id="kobo.253.2" xmlns="http://www.w3.org/1999/xhtml">We will use this object to define, within the objective function itself, the </span><span id="dx1-200005"/><span class="koboSpan" id="kobo.254.1" xmlns="http://www.w3.org/1999/xhtml">training parameters that we want to optimize, while also specifying their constraints: whether we want them to be integers or floats, the ranges within which we want our values to be, and so on.</span></p>
<p><span class="koboSpan" id="kobo.255.1" xmlns="http://www.w3.org/1999/xhtml">For our case, this is the objective function that we would have to define:</span></p>
<pre class="lstlisting" id="listing-280"><span class="koboSpan" id="kobo.256.1" xmlns="http://www.w3.org/1999/xhtml">

def objective(trial): 
 
    # Define the learning rate as an optimizable parameter. 
 
    </span><span class="koboSpan" id="kobo.256.2" xmlns="http://www.w3.org/1999/xhtml">lrate = trial.suggest_float("learning_rate", 0.001, 0.1) 
 
 
 
    # Define the optimizer with the learning rate. 
 
    </span><span class="koboSpan" id="kobo.256.3" xmlns="http://www.w3.org/1999/xhtml">opt = tf.keras.optimizers.Adam(learning_rate = lrate) 
 
 
 
    # Prepare and compile the model. 
 
    </span><span class="koboSpan" id="kobo.256.4" xmlns="http://www.w3.org/1999/xhtml">model = tf.keras.models.Sequential([ 
 
        tf.keras.layers.Input(20), 
 
        tf.keras.layers.Dense(4, activation = "sigmoid"), 
 
        qml.qnn.KerasLayer(qnn, weights, output_dim=1) 
 
    ]) 
 
    model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy()) 
 
 
 
    # Train it! 
 
    </span><span class="koboSpan" id="kobo.256.5" xmlns="http://www.w3.org/1999/xhtml">history = model.fit(x_tr, y_tr, epochs = 50, shuffle = True, 
 
        validation_data = (x_val, y_val), 
 
        batch_size = 10, 
 
        callbacks = [earlystop], 
 
        verbose = 0 # We want TensorFlow to be quiet. 
 
    </span><span class="koboSpan" id="kobo.256.6" xmlns="http://www.w3.org/1999/xhtml">) 
 
 
 
    # Return the validation accuracy. 
 
    </span><span class="koboSpan" id="kobo.256.7" xmlns="http://www.w3.org/1999/xhtml">return accuracy_score(model.predict(x_val) &gt;= 0.5, y_val)
</span></pre>
<p><span class="koboSpan" id="kobo.257.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have defined the </span><span id="dx1-200031"/><span class="koboSpan" id="kobo.258.1" xmlns="http://www.w3.org/1999/xhtml">learning rate as an optimizable parameter by calling the </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.259.1" xmlns="http://www.w3.org/1999/xhtml">trial</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.260.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.261.1" xmlns="http://www.w3.org/1999/xhtml">suggest_float</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.262.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.263.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.264.1" xmlns="http://www.w3.org/1999/xhtml">learning_rate</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.265.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.266.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.267.1" xmlns="http://www.w3.org/1999/xhtml">0.001,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.268.1" xmlns="http://www.w3.org/1999/xhtml">0.1)</span></code></span></span><span class="koboSpan" id="kobo.269.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.269.2" xmlns="http://www.w3.org/1999/xhtml">In general, if you want to optimize a parameter named </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.270.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.271.1" xmlns="http://www.w3.org/1999/xhtml">parameter</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.272.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.273.1" xmlns="http://www.w3.org/1999/xhtml">, the following applies:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.274.1" xmlns="http://www.w3.org/1999/xhtml">If the data type of the parameter is a float and the parameter is bounded between </span><code><span class="koboSpan" id="kobo.275.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code><span class="koboSpan" id="kobo.276.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.277.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code><span class="koboSpan" id="kobo.278.1" xmlns="http://www.w3.org/1999/xhtml">, you should call the </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.279.1" xmlns="http://www.w3.org/1999/xhtml">suggest_float</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.280.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.281.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.282.1" xmlns="http://www.w3.org/1999/xhtml">parameter</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.283.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.284.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.285.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.286.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.287.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.288.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code></span></span><span class="koboSpan" id="kobo.289.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.289.2" xmlns="http://www.w3.org/1999/xhtml">If you only want your parameter to take discrete values between </span><code><span class="koboSpan" id="kobo.290.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code><span class="koboSpan" id="kobo.291.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.292.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code><span class="koboSpan" id="kobo.293.1" xmlns="http://www.w3.org/1999/xhtml"> separated by a step </span><code><span class="koboSpan" id="kobo.294.1" xmlns="http://www.w3.org/1999/xhtml">s</span></code><span class="koboSpan" id="kobo.295.1" xmlns="http://www.w3.org/1999/xhtml">, you can send the optional argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.296.1" xmlns="http://www.w3.org/1999/xhtml">step</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.297.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.298.1" xmlns="http://www.w3.org/1999/xhtml">s</span></code></span></span><span class="koboSpan" id="kobo.299.1" xmlns="http://www.w3.org/1999/xhtml">, which defaults to </span><code><span class="koboSpan" id="kobo.300.1" xmlns="http://www.w3.org/1999/xhtml">None</span></code><span class="koboSpan" id="kobo.301.1" xmlns="http://www.w3.org/1999/xhtml"> (by default, the parameter will take continuous values).</span></p></li>
<li><p><span class="koboSpan" id="kobo.302.1" xmlns="http://www.w3.org/1999/xhtml">If the data type of the parameter is an integer bounded between </span><code><span class="koboSpan" id="kobo.303.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code><span class="koboSpan" id="kobo.304.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.305.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code><span class="koboSpan" id="kobo.306.1" xmlns="http://www.w3.org/1999/xhtml">, you should call </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.307.1" xmlns="http://www.w3.org/1999/xhtml">suggest_int</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.308.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.309.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.310.1" xmlns="http://www.w3.org/1999/xhtml">parameter</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.311.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.312.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.313.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.314.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.315.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.316.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code></span></span><span class="koboSpan" id="kobo.317.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.317.2" xmlns="http://www.w3.org/1999/xhtml">Also, if the values of the parameter should be separated by a step </span><code><span class="koboSpan" id="kobo.318.1" xmlns="http://www.w3.org/1999/xhtml">s</span></code><span class="koboSpan" id="kobo.319.1" xmlns="http://www.w3.org/1999/xhtml"> from </span><code><span class="koboSpan" id="kobo.320.1" xmlns="http://www.w3.org/1999/xhtml">m</span></code><span class="koboSpan" id="kobo.321.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><code><span class="koboSpan" id="kobo.322.1" xmlns="http://www.w3.org/1999/xhtml">M</span></code><span class="koboSpan" id="kobo.323.1" xmlns="http://www.w3.org/1999/xhtml">, you can send in </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.324.1" xmlns="http://www.w3.org/1999/xhtml">step</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.325.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.326.1" xmlns="http://www.w3.org/1999/xhtml">s</span></code></span></span><span class="koboSpan" id="kobo.327.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
<li><p><span class="koboSpan" id="kobo.328.1" xmlns="http://www.w3.org/1999/xhtml">If your parameter takes values out of a list </span><code><span class="koboSpan" id="kobo.329.1" xmlns="http://www.w3.org/1999/xhtml">values</span></code><span class="koboSpan" id="kobo.330.1" xmlns="http://www.w3.org/1999/xhtml"> of possible values, you should call </span><code><span class="koboSpan" id="kobo.331.1" xmlns="http://www.w3.org/1999/xhtml">suggest_categorical</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.332.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.333.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.334.1" xmlns="http://www.w3.org/1999/xhtml">parameter</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.335.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.336.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.337.1" xmlns="http://www.w3.org/1999/xhtml">values</span></code></span><code><span class="koboSpan" id="kobo.338.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code><span class="koboSpan" id="kobo.339.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.339.2" xmlns="http://www.w3.org/1999/xhtml">For instance, if we wanted to try out different activation functions on a layer of a neural network, we could use something like the following:</span></p>
<pre class="lstlisting" id="listing-281"><span class="koboSpan" id="kobo.340.1" xmlns="http://www.w3.org/1999/xhtml">

activation = trial.suggest_categorical( 
 
    "activation_function", ["sigmoid", "elu", "relu"]).
</span></pre></li>
</ul>
<p><span class="koboSpan" id="kobo.341.1" xmlns="http://www.w3.org/1999/xhtml">Of course, a single objective function can have as many optimizable parameters as desired. </span><span class="koboSpan" id="kobo.341.2" xmlns="http://www.w3.org/1999/xhtml">They would just be defined with separate invocations of the methods that we’ve just outlined.</span></p>
<p><span class="koboSpan" id="kobo.342.1" xmlns="http://www.w3.org/1999/xhtml">So that’s how you can create an objective function and specify the parameters that you want to optimize within it. </span><span class="koboSpan" id="kobo.342.2" xmlns="http://www.w3.org/1999/xhtml">Now, how do we optimize them? </span><span class="koboSpan" id="kobo.342.3" xmlns="http://www.w3.org/1999/xhtml">The first step is to create a </span><code><span class="koboSpan" id="kobo.343.1" xmlns="http://www.w3.org/1999/xhtml">Study</span></code><span class="koboSpan" id="kobo.344.1" xmlns="http://www.w3.org/1999/xhtml"> object with the </span><code><span class="koboSpan" id="kobo.345.1" xmlns="http://www.w3.org/1999/xhtml">create_study</span></code><span class="koboSpan" id="kobo.346.1" xmlns="http://www.w3.org/1999/xhtml"> function, just as follows:</span></p>
<pre class="lstlisting" id="listing-282"><span class="koboSpan" id="kobo.347.1" xmlns="http://www.w3.org/1999/xhtml">

from optuna.samplers import TPESampler 
 
 
 
study = optuna.create_study(direction=’maximize’, 
 
    sampler=TPESampler(seed = seed))
</span></pre>
<p><span class="koboSpan" id="kobo.348.1" xmlns="http://www.w3.org/1999/xhtml">Here we have specified that we want to create a study in order to maximize some objective function and using </span><code><span class="koboSpan" id="kobo.349.1" xmlns="http://www.w3.org/1999/xhtml">TPESampler</span></code><span class="koboSpan" id="kobo.350.1" xmlns="http://www.w3.org/1999/xhtml"> with a seed. </span><span class="koboSpan" id="kobo.350.2" xmlns="http://www.w3.org/1999/xhtml">By default, Optuna will try to minimize objective functions — that’s why we had to send in that argument. </span><span class="koboSpan" id="kobo.350.3" xmlns="http://www.w3.org/1999/xhtml">The sampler that we’ve passed is just the object that, during the </span><span id="dx1-200038"/><span class="koboSpan" id="kobo.351.1" xmlns="http://www.w3.org/1999/xhtml">optimization process, is going to look for values to try. </span><span class="koboSpan" id="kobo.351.2" xmlns="http://www.w3.org/1999/xhtml">The one we’ve selected is the default one, but we have passed it manually so that we could give it a seed and get reproducible results. </span><span class="koboSpan" id="kobo.351.3" xmlns="http://www.w3.org/1999/xhtml">There are many other samplers. </span><span class="koboSpan" id="kobo.351.4" xmlns="http://www.w3.org/1999/xhtml">Most notably, </span><code><span class="koboSpan" id="kobo.352.1" xmlns="http://www.w3.org/1999/xhtml">GridSampler</span></code><span class="koboSpan" id="kobo.353.1" xmlns="http://www.w3.org/1999/xhtml"> allows you to try all the combinations of parameters out of a pre-defined ”search space.” </span><span class="koboSpan" id="kobo.353.2" xmlns="http://www.w3.org/1999/xhtml">For instance, we could use the following sampler:</span></p>
<pre class="lstlisting" id="listing-283"><span class="koboSpan" id="kobo.354.1" xmlns="http://www.w3.org/1999/xhtml">

values = {"learning_rate": [0.001, 0.003, 0.005, 0.008, 0.01]} 
 
sampler = optuna.samplers.GridSampler(values)
</span></pre>
<p><span class="koboSpan" id="kobo.355.1" xmlns="http://www.w3.org/1999/xhtml">This would make Optuna try out the values </span><span class="koboSpan" id="kobo.356.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.001" class="math inline" src="../media/file1165.png" style="vertical-align:middle" title="0.001"/></span><span class="koboSpan" id="kobo.357.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.358.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.003" class="math inline" src="../media/file1403.png" style="vertical-align:middle" title="0.003"/></span><span class="koboSpan" id="kobo.359.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.360.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.005" class="math inline" src="../media/file1389.png" style="vertical-align:middle" title="0.005"/></span><span class="koboSpan" id="kobo.361.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.362.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.008" class="math inline" src="../media/file1404.png" style="vertical-align:middle" title="0.008"/></span><span class="koboSpan" id="kobo.363.1" xmlns="http://www.w3.org/1999/xhtml">, and </span><span class="koboSpan" id="kobo.364.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.01" class="math inline" src="../media/file1093.png" style="vertical-align:middle" title="0.01"/></span><span class="koboSpan" id="kobo.365.1" xmlns="http://www.w3.org/1999/xhtml"> — and no others.</span></p>
<p><span class="koboSpan" id="kobo.366.1" xmlns="http://www.w3.org/1999/xhtml">If you want to learn </span><span id="dx1-200041"/><span class="koboSpan" id="kobo.367.1" xmlns="http://www.w3.org/1999/xhtml">more about how these samplers work, you may have a look at their online documentation (</span><a class="url" href="https://optuna.readthedocs.io/en/stable/reference/samplers/index.html"><span class="koboSpan" id="kobo.368.1" xmlns="http://www.w3.org/1999/xhtml">https://optuna.readthedocs.io/en/stable/reference/samplers/index.html</span></a><span class="koboSpan" id="kobo.369.1" xmlns="http://www.w3.org/1999/xhtml">).</span></p>
<p><span class="koboSpan" id="kobo.370.1" xmlns="http://www.w3.org/1999/xhtml">With the </span><code><span class="koboSpan" id="kobo.371.1" xmlns="http://www.w3.org/1999/xhtml">Study</span></code><span class="koboSpan" id="kobo.372.1" xmlns="http://www.w3.org/1999/xhtml"> object ready, all we have to do is call the </span><code><span class="koboSpan" id="kobo.373.1" xmlns="http://www.w3.org/1999/xhtml">optimize</span></code><span class="koboSpan" id="kobo.374.1" xmlns="http://www.w3.org/1999/xhtml"> method specifying the objective function and the number of trials that we will let Optuna run:</span></p>
<pre class="lstlisting" id="listing-284"><span class="koboSpan" id="kobo.375.1" xmlns="http://www.w3.org/1999/xhtml">

study.optimize(objective, n_trials=6)
</span></pre>
<p><span class="koboSpan" id="kobo.376.1" xmlns="http://www.w3.org/1999/xhtml">Upon running this (it can take a while), you will get an output similar to the following:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.377.1" xmlns="http://www.w3.org/1999/xhtml">

 
Trial 0 finished with value: 0.9 and parameters: 
    {’learning_rate’: 0.01996042558751034}. 
    </span><span class="koboSpan" id="kobo.377.2" xmlns="http://www.w3.org/1999/xhtml">Best is trial 0 with value: 0.9. 
 
</span><span class="koboSpan" id="kobo.377.3" xmlns="http://www.w3.org/1999/xhtml">Trial 1 finished with value: 0.9 and parameters: 
    {’learning_rate’: 0.06258876833294336}. 
    </span><span class="koboSpan" id="kobo.377.4" xmlns="http://www.w3.org/1999/xhtml">Best is trial 0 with value: 0.9. 
 
</span><span class="koboSpan" id="kobo.377.5" xmlns="http://www.w3.org/1999/xhtml">Trial 2 finished with value: 0.9 and parameters: 
    {’learning_rate’: 0.04433504616170433}. 
    </span><span class="koboSpan" id="kobo.377.6" xmlns="http://www.w3.org/1999/xhtml">Best is trial 0 with value: 0.9. 
 
</span><span class="koboSpan" id="kobo.377.7" xmlns="http://www.w3.org/1999/xhtml">Trial 3 finished with value: 0.91 and parameters: 
    {’learning_rate’: 0.07875049978766316}. 
    </span><span class="koboSpan" id="kobo.377.8" xmlns="http://www.w3.org/1999/xhtml">Best is trial 3 with value: 0.91. 
 
</span><span class="koboSpan" id="kobo.377.9" xmlns="http://www.w3.org/1999/xhtml">Trial 4 finished with value: 0.92 and parameters: 
    {’learning_rate’: 0.07821760500376156}. 
    </span><span class="koboSpan" id="kobo.377.10" xmlns="http://www.w3.org/1999/xhtml">Best is trial 4 with value: 0.92. 
 
</span><span class="koboSpan" id="kobo.377.11" xmlns="http://www.w3.org/1999/xhtml">Trial 5 finished with value: 0.9 and parameters: 
    {’learning_rate’: 0.02798666792298152}. 
    </span><span class="koboSpan" id="kobo.377.12" xmlns="http://www.w3.org/1999/xhtml">Best is trial 4 with value: 0.92.
    
</span></pre>
<p><span class="koboSpan" id="kobo.378.1" xmlns="http://www.w3.org/1999/xhtml">With the </span><span id="dx1-200067"/><span class="koboSpan" id="kobo.379.1" xmlns="http://www.w3.org/1999/xhtml">parameter variations that we have considered, we haven’t seen any significant differences in performance. </span><span class="koboSpan" id="kobo.379.2" xmlns="http://www.w3.org/1999/xhtml">But, still, at least we’ve learned how to use Optuna!</span></p>
<div class="tcolorbox questionx" id="tcolobox-198">
<span id="x1-200069x11.2.3"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.380.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.2</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.381.1" xmlns="http://www.w3.org/1999/xhtml">Use Optuna to simultaneously optimize the learning rate and the batch size of the model.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.382.1" xmlns="http://www.w3.org/1999/xhtml">As a final remark, notice how, in the objective function, we have used the validation accuracy and not the test accuracy. </span><span class="koboSpan" id="kobo.382.2" xmlns="http://www.w3.org/1999/xhtml">The test dataset, remember, should only be used once we’ve already picked our best model. </span><span class="koboSpan" id="kobo.382.3" xmlns="http://www.w3.org/1999/xhtml">Otherwise, its independence is compromised. </span><span class="koboSpan" id="kobo.382.4" xmlns="http://www.w3.org/1999/xhtml">For instance, if we had saved the models following each Optuna trial, now it would make sense for us to compute the test accuracy on the trial 4 model in order to make sure that we have a low generalization error.</span></p>
<div class="tcolorbox questionx" id="tcolobox-199">
<span id="x1-200071x11.2.3"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.383.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.3</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.384.1" xmlns="http://www.w3.org/1999/xhtml">Optuna can be used on any framework, not just TensorFlow — it can be used to optimize any parameters that you want for any purpose! </span><span class="koboSpan" id="kobo.384.2" xmlns="http://www.w3.org/1999/xhtml">All you have to do is build a suitable objective function. </span><span class="koboSpan" id="kobo.384.3" xmlns="http://www.w3.org/1999/xhtml">To further illustrate this, use Optuna to find the minimum of the function </span><span class="koboSpan" id="kobo.385.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f(x) = {(x - 3)}^{2}" class="math inline" src="../media/file1405.png" style="vertical-align:middle" title="f(x) = {(x - 3)}^{2}"/></span><span class="koboSpan" id="kobo.386.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<div class="tcolorbox learnmore" id="tcolobox-200">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.387.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.388.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.389.1" xmlns="http://www.w3.org/1999/xhtml">In these few pages, we haven’t been able to cover all there is to know about Optuna. </span><span class="koboSpan" id="kobo.389.2" xmlns="http://www.w3.org/1999/xhtml">If you would like to learn more, you should have a look at its online documentation. </span><span class="koboSpan" id="kobo.389.3" xmlns="http://www.w3.org/1999/xhtml">You can find it at </span><a class="url" href="https://optuna.readthedocs.io/en/stable/index.html"><span class="koboSpan" id="kobo.390.1" xmlns="http://www.w3.org/1999/xhtml">https://optuna.readthedocs.io/en/stable/index.html</span></a><span class="koboSpan" id="kobo.391.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.392.1" xmlns="http://www.w3.org/1999/xhtml">That was a short </span><span id="dx1-200072"/><span class="koboSpan" id="kobo.393.1" xmlns="http://www.w3.org/1999/xhtml">overview of how to train (quantum) machine learning models in real-world scenarios. </span><span class="koboSpan" id="kobo.393.2" xmlns="http://www.w3.org/1999/xhtml">In the following subsection, we will leave our comfort zone and use PennyLane to solve a new problem for us: a multi-class classification task.</span></p>
</section>
<section class="level3 subsectionHead" data-number="19.2.4" id="a-multi-class-classification-problem">
<h2 class="subsectionHead" data-number="19.2.4"><span class="titlemark"><span class="koboSpan" id="kobo.394.1" xmlns="http://www.w3.org/1999/xhtml">11.2.4 </span></span> <span id="x1-20100011.2.4"><span class="koboSpan" id="kobo.395.1" xmlns="http://www.w3.org/1999/xhtml">A multi-class classification problem</span></span></h2>
<p><span class="koboSpan" id="kobo.396.1" xmlns="http://www.w3.org/1999/xhtml">This is going to be an </span><span id="dx1-201001"/><span class="koboSpan" id="kobo.397.1" xmlns="http://www.w3.org/1999/xhtml">exciting subsection, for we are about to consider a new kind of problem on which to apply our QML </span><span id="dx1-201002"/><span class="koboSpan" id="kobo.398.1" xmlns="http://www.w3.org/1999/xhtml">knowledge. </span><span class="koboSpan" id="kobo.398.2" xmlns="http://www.w3.org/1999/xhtml">Nonetheless, every long journey begins with a first step, and ours shall be to reset the seeds of NumPy and TensorFlow, just to make reproducibility easier:</span></p>
<pre class="lstlisting" id="listing-285"><span class="koboSpan" id="kobo.399.1" xmlns="http://www.w3.org/1999/xhtml">

np.random.seed(seed) 
 
tf.random.set_seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.400.1" xmlns="http://www.w3.org/1999/xhtml">We are about to consider a multi-class classification problem and, of course, the first thing we need is data. </span><span class="koboSpan" id="kobo.400.2" xmlns="http://www.w3.org/1999/xhtml">Our good old </span><code><span class="koboSpan" id="kobo.401.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.402.1" xmlns="http://www.w3.org/1999/xhtml"> function can help us here, for we can give it the optional argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.403.1" xmlns="http://www.w3.org/1999/xhtml">n_classes</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.404.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.405.1" xmlns="http://www.w3.org/1999/xhtml">3</span></code></span></span><span class="koboSpan" id="kobo.406.1" xmlns="http://www.w3.org/1999/xhtml"> in order for it to generate a dataset with </span><span class="koboSpan" id="kobo.407.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.408.1" xmlns="http://www.w3.org/1999/xhtml"> distinct classes, which will be labeled as </span><span class="koboSpan" id="kobo.409.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.410.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="koboSpan" id="kobo.411.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.412.1" xmlns="http://www.w3.org/1999/xhtml">, and </span><span class="koboSpan" id="kobo.413.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.414.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.414.2" xmlns="http://www.w3.org/1999/xhtml">However, there’s a catch. </span><span class="koboSpan" id="kobo.414.3" xmlns="http://www.w3.org/1999/xhtml">Increasing the number of classes means that, as per the function’s requirements, we will also have to tweak some of the </span><span id="dx1-201005"/><span class="koboSpan" id="kobo.415.1" xmlns="http://www.w3.org/1999/xhtml">default parameters; a valid configuration can be reached by setting the argument </span><code><span class="koboSpan" id="kobo.416.1" xmlns="http://www.w3.org/1999/xhtml">n_clusters_per_class</span></code><span class="koboSpan" id="kobo.417.1" xmlns="http://www.w3.org/1999/xhtml"> to </span><span class="koboSpan" id="kobo.418.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.419.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.419.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we can generate our dataset for ternary classification as follows:</span></p>
<pre class="lstlisting" id="listing-286"><span class="koboSpan" id="kobo.420.1" xmlns="http://www.w3.org/1999/xhtml">

x, y = make_classification(n_samples = 1000, n_features = 20, 
 
    n_classes = 3, n_clusters_per_class = 1)
</span></pre>
<p><span class="koboSpan" id="kobo.421.1" xmlns="http://www.w3.org/1999/xhtml">Now that we have data, it’s time for us to </span><span id="dx1-201008"/><span class="koboSpan" id="kobo.422.1" xmlns="http://www.w3.org/1999/xhtml">think about the model. </span><span class="koboSpan" id="kobo.422.2" xmlns="http://www.w3.org/1999/xhtml">We are approaching a new kind of problem, so we need to go back to the basics. </span><span class="koboSpan" id="kobo.422.3" xmlns="http://www.w3.org/1999/xhtml">For now, let’s forget about the hybrid component of the network, and let’s try to think about how we could design a QNN capable of solving a ternary classification problem.</span></p>
<section class="level5 subsubsectionHead" data-number="19.2.4.0.1" id="a-general-perspective-on-multi-class-classification-tasks">
<h4 class="subsubsectionHead" data-number="19.2.4.0.1"><span id="x1-20200011.2.4"/><span class="koboSpan" id="kobo.423.1" xmlns="http://www.w3.org/1999/xhtml">A general perspective on multi-class classification tasks</span></h4>
<p><span class="koboSpan" id="kobo.424.1" xmlns="http://www.w3.org/1999/xhtml">In this regard, it is useful to look at how this kind of </span><span id="dx1-202001"/><span class="koboSpan" id="kobo.425.1" xmlns="http://www.w3.org/1999/xhtml">problem is handled with classical neural networks. </span><span class="koboSpan" id="kobo.425.2" xmlns="http://www.w3.org/1999/xhtml">We know that, when solving binary classification problems, we consider neural networks having a single neuron in the final layer with a bounded activation function; in this way, we assign a label depending on whether the output is closer to </span><span class="koboSpan" id="kobo.426.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.427.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><span class="koboSpan" id="kobo.428.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.429.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.429.2" xmlns="http://www.w3.org/1999/xhtml">Such an approach might not be as effective, in general, when having multiple classes.</span></p>
<p><span class="koboSpan" id="kobo.430.1" xmlns="http://www.w3.org/1999/xhtml">When working with </span><span class="koboSpan" id="kobo.431.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.432.1" xmlns="http://www.w3.org/1999/xhtml">-class classification problems, neural networks are usually designed to have </span><span class="koboSpan" id="kobo.433.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.434.1" xmlns="http://www.w3.org/1999/xhtml"> neurons in their final layer — again, with bounded activation functions that make the values lie between </span><span class="koboSpan" id="kobo.435.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.436.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.437.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.438.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.438.2" xmlns="http://www.w3.org/1999/xhtml">And how is a label assigned from the output of these neurons? </span><span class="koboSpan" id="kobo.438.3" xmlns="http://www.w3.org/1999/xhtml">Easy. </span><span class="koboSpan" id="kobo.438.4" xmlns="http://www.w3.org/1999/xhtml">Each neuron is associated to a label, so we just assign the label of the neuron that has the highest output. </span><span class="koboSpan" id="kobo.438.5" xmlns="http://www.w3.org/1999/xhtml">Heuristically, you may think of each of these </span><span class="koboSpan" id="kobo.439.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.440.1" xmlns="http://www.w3.org/1999/xhtml"> neurons in the final layer as light bulbs — whose brightness is determined by their output — indicating how likely it is that the input will belong to a certain category. </span><span class="koboSpan" id="kobo.440.2" xmlns="http://www.w3.org/1999/xhtml">All we do in the end is assigning the category of the light bulb that shines the most!</span></p>
<p><span class="koboSpan" id="kobo.441.1" xmlns="http://www.w3.org/1999/xhtml">Porting this idea to quantum neural networks is easy. </span><span class="koboSpan" id="kobo.441.2" xmlns="http://www.w3.org/1999/xhtml">Instead of taking the expectation value of the observable </span><span class="koboSpan" id="kobo.442.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.443.1" xmlns="http://www.w3.org/1999/xhtml"> on the first qubit, we return an array of values with the expectation values of the </span><span class="koboSpan" id="kobo.444.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.445.1" xmlns="http://www.w3.org/1999/xhtml"> observable on the first </span><span class="koboSpan" id="kobo.446.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.447.1" xmlns="http://www.w3.org/1999/xhtml"> qubits — assigning to each qubit a label. </span><span class="koboSpan" id="kobo.447.2" xmlns="http://www.w3.org/1999/xhtml">It couldn’t be easier.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-201">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.448.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.449.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.450.1" xmlns="http://www.w3.org/1999/xhtml">There are other ways to build classifiers in problems with multiple classes. </span><span class="koboSpan" id="kobo.450.2" xmlns="http://www.w3.org/1999/xhtml">For instance, two popular </span><span id="dx1-202002"/><span class="koboSpan" id="kobo.451.1" xmlns="http://www.w3.org/1999/xhtml">approaches are the </span><strong><span class="koboSpan" id="kobo.452.1" xmlns="http://www.w3.org/1999/xhtml">one-versus-all</span></strong><span class="koboSpan" id="kobo.453.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><strong><span class="koboSpan" id="kobo.454.1" xmlns="http://www.w3.org/1999/xhtml">one-versus-one</span></strong> <span id="dx1-202003"/><span class="koboSpan" id="kobo.455.1" xmlns="http://www.w3.org/1999/xhtml">methods. </span><span class="koboSpan" id="kobo.455.2" xmlns="http://www.w3.org/1999/xhtml">They involve training multiple binary classifiers and combining their results. </span><span class="koboSpan" id="kobo.455.3" xmlns="http://www.w3.org/1999/xhtml">We invite you to have a look at chapter 3 of Geron’s book if you are curious </span><span class="cite"><span class="koboSpan" id="kobo.456.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xhandsonml"><span class="koboSpan" id="kobo.457.1" xmlns="http://www.w3.org/1999/xhtml">104</span></a><span class="koboSpan" id="kobo.458.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.459.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.460.1" xmlns="http://www.w3.org/1999/xhtml">That solves the </span><span id="dx1-202004"/><span class="koboSpan" id="kobo.461.1" xmlns="http://www.w3.org/1999/xhtml">problem of designing a QNN that can handle our task, but we still have an issue left: we don’t yet have a suitable loss function for this kind of problem. </span><span class="koboSpan" id="kobo.461.2" xmlns="http://www.w3.org/1999/xhtml">In binary classification, we could rely on the binary cross-entropy function, but it doesn’t work for problems with multiple categories. </span><span class="koboSpan" id="kobo.461.3" xmlns="http://www.w3.org/1999/xhtml">Luckily for us, there’s a loss function that generalizes the binary cross entropy. </span><span class="koboSpan" id="kobo.461.4" xmlns="http://www.w3.org/1999/xhtml">Please, let us </span><span id="dx1-202005"/><span class="koboSpan" id="kobo.462.1" xmlns="http://www.w3.org/1999/xhtml">introduce you to the </span><strong><span class="koboSpan" id="kobo.463.1" xmlns="http://www.w3.org/1999/xhtml">categorical cross-entropy</span></strong><span class="koboSpan" id="kobo.464.1" xmlns="http://www.w3.org/1999/xhtml"> loss.</span></p>
<p><span class="koboSpan" id="kobo.465.1" xmlns="http://www.w3.org/1999/xhtml">Let us consider an arbitrary neural network </span><span class="koboSpan" id="kobo.466.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="N" class="math inline" src="../media/file784.png" style="vertical-align:middle" title="N"/></span><span class="koboSpan" id="kobo.467.1" xmlns="http://www.w3.org/1999/xhtml"> that, for any choice of parameters </span><span class="koboSpan" id="kobo.468.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta" class="math inline" src="../media/file89.png" style="vertical-align:middle" title="\theta"/></span><span class="koboSpan" id="kobo.469.1" xmlns="http://www.w3.org/1999/xhtml"> and any input </span><span class="koboSpan" id="kobo.470.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.471.1" xmlns="http://www.w3.org/1999/xhtml">, returns an array </span><span class="koboSpan" id="kobo.472.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="N_{\theta}(x)" class="math inline" src="../media/file1406.png" style="vertical-align:middle" title="N_{\theta}(x)"/></span><span class="koboSpan" id="kobo.473.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.474.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.475.1" xmlns="http://www.w3.org/1999/xhtml"> entries, all of them between </span><span class="koboSpan" id="kobo.476.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.477.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.478.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.479.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.479.2" xmlns="http://www.w3.org/1999/xhtml">The categorical cross-entropy loss function depends on the parameters of the neural network </span><span class="koboSpan" id="kobo.480.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta" class="math inline" src="../media/file89.png" style="vertical-align:middle" title="\theta"/></span><span class="koboSpan" id="kobo.481.1" xmlns="http://www.w3.org/1999/xhtml">, the inputs </span><span class="koboSpan" id="kobo.482.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.483.1" xmlns="http://www.w3.org/1999/xhtml">, and the targets </span><span class="koboSpan" id="kobo.484.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y" class="math inline" src="../media/file270.png" style="vertical-align:middle" title="y"/></span><span class="koboSpan" id="kobo.485.1" xmlns="http://www.w3.org/1999/xhtml">, but there is an important subtlety: the loss function expects the targets </span><span class="koboSpan" id="kobo.486.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y" class="math inline" src="../media/file270.png" style="vertical-align:middle" title="y"/></span><span class="koboSpan" id="kobo.487.1" xmlns="http://www.w3.org/1999/xhtml"> to be in </span><strong><span class="koboSpan" id="kobo.488.1" xmlns="http://www.w3.org/1999/xhtml">one-hot</span></strong> <strong><span class="koboSpan" id="kobo.489.1" xmlns="http://www.w3.org/1999/xhtml">form</span></strong><span class="koboSpan" id="kobo.490.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.490.2" xmlns="http://www.w3.org/1999/xhtml">This </span><span id="dx1-202006"/><span class="koboSpan" id="kobo.491.1" xmlns="http://www.w3.org/1999/xhtml">means that </span><span class="koboSpan" id="kobo.492.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y" class="math inline" src="../media/file270.png" style="vertical-align:middle" title="y"/></span><span class="koboSpan" id="kobo.493.1" xmlns="http://www.w3.org/1999/xhtml"> shouldn’t be a number representing a label (</span><span class="koboSpan" id="kobo.494.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0,1,\ldots,k - 1" class="math inline" src="../media/file1407.png" style="vertical-align:middle" title="0,1,\ldots,k - 1"/></span><span class="koboSpan" id="kobo.495.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.495.2" xmlns="http://www.w3.org/1999/xhtml">Instead, it should be a vector (an array) with </span><span class="koboSpan" id="kobo.496.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.497.1" xmlns="http://www.w3.org/1999/xhtml"> entries that are all set to </span><span class="koboSpan" id="kobo.498.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.499.1" xmlns="http://www.w3.org/1999/xhtml"> except for the entry in the position of the label, which should be set to </span><span class="koboSpan" id="kobo.500.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.501.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.501.2" xmlns="http://www.w3.org/1999/xhtml">Thus, instead of having </span><span class="koboSpan" id="kobo.502.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y = 0" class="math inline" src="../media/file1408.png" style="vertical-align:middle" title="y = 0"/></span><span class="koboSpan" id="kobo.503.1" xmlns="http://www.w3.org/1999/xhtml">, we would have </span><span class="koboSpan" id="kobo.504.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y = (1,0,\ldots,0)" class="math inline" src="../media/file1409.png" style="vertical-align:middle" title="y = (1,0,\ldots,0)"/></span><span class="koboSpan" id="kobo.505.1" xmlns="http://www.w3.org/1999/xhtml">, or, instead of having </span><span class="koboSpan" id="kobo.506.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y = k - 1" class="math inline" src="../media/file1410.png" style="vertical-align:middle" title="y = k - 1"/></span><span class="koboSpan" id="kobo.507.1" xmlns="http://www.w3.org/1999/xhtml">, we would have </span><span class="koboSpan" id="kobo.508.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y = (0,\ldots,0,1)" class="math inline" src="../media/file1411.png" style="vertical-align:middle" title="y = (0,\ldots,0,1)"/></span><span class="koboSpan" id="kobo.509.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.509.2" xmlns="http://www.w3.org/1999/xhtml">Under these assumptions, the categorical cross-entropy is defined as follows:</span></p>
<p><span class="koboSpan" id="kobo.510.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j})." class="math display" src="../media/file1412.png" style="vertical-align:middle" title="H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j})."/></span></p>
<p><span class="koboSpan" id="kobo.511.1" xmlns="http://www.w3.org/1999/xhtml">Of course, we have used the subindex </span><span class="koboSpan" id="kobo.512.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.513.1" xmlns="http://www.w3.org/1999/xhtml"> in </span><span class="koboSpan" id="kobo.514.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y" class="math inline" src="../media/file270.png" style="vertical-align:middle" title="y"/></span><span class="koboSpan" id="kobo.515.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.516.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="N_{\theta}(x)" class="math inline" src="../media/file1406.png" style="vertical-align:middle" title="N_{\theta}(x)"/></span><span class="koboSpan" id="kobo.517.1" xmlns="http://www.w3.org/1999/xhtml"> to denote their </span><span class="koboSpan" id="kobo.518.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.519.1" xmlns="http://www.w3.org/1999/xhtml">-th entries. </span><span class="koboSpan" id="kobo.519.2" xmlns="http://www.w3.org/1999/xhtml">Notice how, in this definition, we have implicitly assumed that the first neuron in the final layer is associated to the label </span><span class="koboSpan" id="kobo.520.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.521.1" xmlns="http://www.w3.org/1999/xhtml">, the second neuron is associated to </span><span class="koboSpan" id="kobo.522.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.523.1" xmlns="http://www.w3.org/1999/xhtml">, and so on.</span></p>
<div class="tcolorbox questionx" id="tcolobox-202">
<span id="x1-202008x11.2.4"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.524.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.4</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.525.1" xmlns="http://www.w3.org/1999/xhtml">Prove that the binary cross-entropy loss is a particular case of the categorical cross-entropy loss for </span><span class="koboSpan" id="kobo.526.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k = 2" class="math inline" src="../media/file1413.png" style="vertical-align:middle" title="k = 2"/></span><span class="koboSpan" id="kobo.527.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.528.1" xmlns="http://www.w3.org/1999/xhtml">Of course, the categorical cross-entropy function is a reasonable loss function for multi-class classification, and it shares some nice properties with the binary cross-entropy loss function. </span><span class="koboSpan" id="kobo.528.2" xmlns="http://www.w3.org/1999/xhtml">For instance, it is zero if a classifier gets an output completely right (it assigns </span><span class="koboSpan" id="kobo.529.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.530.1" xmlns="http://www.w3.org/1999/xhtml"> to the correct output and </span><span class="koboSpan" id="kobo.531.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.532.1" xmlns="http://www.w3.org/1999/xhtml"> to the rest), but it diverges if a classifier assigns </span><span class="koboSpan" id="kobo.533.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.534.1" xmlns="http://www.w3.org/1999/xhtml"> to a wrong output and </span><span class="koboSpan" id="kobo.535.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.536.1" xmlns="http://www.w3.org/1999/xhtml"> to the rest.</span></p>
<p><span class="koboSpan" id="kobo.537.1" xmlns="http://www.w3.org/1999/xhtml">So far, we already know how to </span><span id="dx1-202009"/><span class="koboSpan" id="kobo.538.1" xmlns="http://www.w3.org/1999/xhtml">implement our QNN and we have a loss function, so we just have to finalize the details of our architecture. </span><span class="koboSpan" id="kobo.538.2" xmlns="http://www.w3.org/1999/xhtml">Regarding the quantum layer, we already know which observable we are going to use, so that’s not a problem. </span><span class="koboSpan" id="kobo.538.3" xmlns="http://www.w3.org/1999/xhtml">For the feature map, we will rely on angular encoding and, for the variational form, we shall use the two-local variational form. </span><span class="koboSpan" id="kobo.538.4" xmlns="http://www.w3.org/1999/xhtml">To keep things somewhat efficient, we will take our QNN to have four qubits, and we will leave the rest of the hybrid architecture just as it was in the previous subsection.</span></p>
<p><span class="koboSpan" id="kobo.539.1" xmlns="http://www.w3.org/1999/xhtml">That’s enough abstract thinking for now; let’s get to the code. </span><span class="koboSpan" id="kobo.539.2" xmlns="http://www.w3.org/1999/xhtml">And be prepared, because things are about to get hot.</span></p>
</section>
<section class="level5 subsubsectionHead" data-number="19.2.4.0.2" id="implementing-a-qnn-for-a-ternary-classification-problem">
<h4 class="subsubsectionHead" data-number="19.2.4.0.2"><span id="x1-20300011.2.4"/><span class="koboSpan" id="kobo.540.1" xmlns="http://www.w3.org/1999/xhtml">Implementing a QNN for a ternary classification problem</span></h4>
<p><span class="koboSpan" id="kobo.541.1" xmlns="http://www.w3.org/1999/xhtml">According to our plan, the first </span><span id="dx1-203001"/><span class="koboSpan" id="kobo.542.1" xmlns="http://www.w3.org/1999/xhtml">thing that we </span><span id="dx1-203002"/><span class="koboSpan" id="kobo.543.1" xmlns="http://www.w3.org/1999/xhtml">need to do is encode our array of targets </span><code><span class="koboSpan" id="kobo.544.1" xmlns="http://www.w3.org/1999/xhtml">y</span></code><span class="koboSpan" id="kobo.545.1" xmlns="http://www.w3.org/1999/xhtml"> in one-hot form.</span></p>
<div class="tcolorbox questionx" id="tcolobox-203">
<span id="x1-203005x11.2.4"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.546.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.5</span></p>
</div>
<div class="tcolorbox-content"><span class="koboSpan" id="kobo.547.1" xmlns="http://www.w3.org/1999/xhtml">
There is a variation of the categorical cross entropy loss that doesn’t require the targets to be in one-hot form. </span><span class="koboSpan" id="kobo.547.2" xmlns="http://www.w3.org/1999/xhtml">It is the </span><strong><span class="koboSpan" id="kobo.548.1" xmlns="http://www.w3.org/1999/xhtml">sparse</span></strong> <strong><span class="koboSpan" id="kobo.549.1" xmlns="http://www.w3.org/1999/xhtml">categorical cross entropy loss</span></strong><span class="koboSpan" id="kobo.550.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.550.2" xmlns="http://www.w3.org/1999/xhtml">Try to </span><span id="dx1-203004"/><span class="koboSpan" id="kobo.551.1" xmlns="http://www.w3.org/1999/xhtml">replicate what follows using this loss function and the unencoded targets. </span><span class="koboSpan" id="kobo.551.2" xmlns="http://www.w3.org/1999/xhtml">You may access it as </span><code><span class="koboSpan" id="kobo.552.1" xmlns="http://www.w3.org/1999/xhtml">tf</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.553.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.554.1" xmlns="http://www.w3.org/1999/xhtml">keras</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.555.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.556.1" xmlns="http://www.w3.org/1999/xhtml">losses</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.557.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span>
<code><span class="koboSpan" id="kobo.558.1" xmlns="http://www.w3.org/1999/xhtml">SparseCategoricalCrossentropy</span></code><span class="koboSpan" id="kobo.559.1" xmlns="http://www.w3.org/1999/xhtml">.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.560.1" xmlns="http://www.w3.org/1999/xhtml">We could implement our own one-hot encoder, but there’s no need to. </span><span class="koboSpan" id="kobo.560.2" xmlns="http://www.w3.org/1999/xhtml">The scikit-learn package — once again to our rescue! </span><span class="koboSpan" id="kobo.560.3" xmlns="http://www.w3.org/1999/xhtml">— already implements a </span><code><span class="koboSpan" id="kobo.561.1" xmlns="http://www.w3.org/1999/xhtml">OneHotEncoder</span></code><span class="koboSpan" id="kobo.562.1" xmlns="http://www.w3.org/1999/xhtml"> class, which you can import from </span><code><span class="koboSpan" id="kobo.563.1" xmlns="http://www.w3.org/1999/xhtml">sklearn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.564.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.565.1" xmlns="http://www.w3.org/1999/xhtml">preprocessing</span></code><span class="koboSpan" id="kobo.566.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.566.2" xmlns="http://www.w3.org/1999/xhtml">You can work with this class just as you would with other familiar scikit-learn classes, such as </span><code><span class="koboSpan" id="kobo.567.1" xmlns="http://www.w3.org/1999/xhtml">MaxAbsScaler</span></code><span class="koboSpan" id="kobo.568.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.569.1" xmlns="http://www.w3.org/1999/xhtml">In order to one-hot-encode an array of targets, you </span><span id="dx1-203006"/><span class="koboSpan" id="kobo.570.1" xmlns="http://www.w3.org/1999/xhtml">would need a </span><code><span class="koboSpan" id="kobo.571.1" xmlns="http://www.w3.org/1999/xhtml">OneHotEncoder</span></code><span class="koboSpan" id="kobo.572.1" xmlns="http://www.w3.org/1999/xhtml"> object and you would just have to pass the array to the </span><code><span class="koboSpan" id="kobo.573.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.574.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.574.2" xmlns="http://www.w3.org/1999/xhtml">But with a catch: the array should be a </span><span id="dx1-203007"/><span class="koboSpan" id="kobo.575.1" xmlns="http://www.w3.org/1999/xhtml">column vector! </span><span class="koboSpan" id="kobo.575.2" xmlns="http://www.w3.org/1999/xhtml">Our array of targets </span><code><span class="koboSpan" id="kobo.576.1" xmlns="http://www.w3.org/1999/xhtml">y</span></code><span class="koboSpan" id="kobo.577.1" xmlns="http://www.w3.org/1999/xhtml"> is one-dimensional, so we will have to reshape it before we can feed it to the </span><code><span class="koboSpan" id="kobo.578.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.579.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.579.2" xmlns="http://www.w3.org/1999/xhtml">Thus, this is how we can encode our array of targets in one-hot form:</span></p>
<pre class="lstlisting" id="listing-287"><span class="koboSpan" id="kobo.580.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.preprocessing import OneHotEncoder 
 
hot = OneHotEncoder(sparse = False) 
 
y_hot = hot.fit_transform(y.reshape(-1,1))
</span></pre>
<p><span class="koboSpan" id="kobo.581.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have added the argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.582.1" xmlns="http://www.w3.org/1999/xhtml">sparse</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.583.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.584.1" xmlns="http://www.w3.org/1999/xhtml">False</span></code></span></span><span class="koboSpan" id="kobo.585.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.585.2" xmlns="http://www.w3.org/1999/xhtml">This Boolean value, which defaults to </span><code><span class="koboSpan" id="kobo.586.1" xmlns="http://www.w3.org/1999/xhtml">True</span></code><span class="koboSpan" id="kobo.587.1" xmlns="http://www.w3.org/1999/xhtml">, determines whether or not the encoder should return sparse matrices. </span><span class="koboSpan" id="kobo.587.2" xmlns="http://www.w3.org/1999/xhtml">Sparse matrices are datatypes that can be very memory-efficient when storing matrices with lots of zeros, such as one-hot encoded arrays. </span><span class="koboSpan" id="kobo.587.3" xmlns="http://www.w3.org/1999/xhtml">Essentially, instead of logging the value of each entry</span><span id="dx1-203011"/><span class="koboSpan" id="kobo.588.1" xmlns="http://www.w3.org/1999/xhtml"> in a matrix, a sparse matrix only keeps track of the non-zero entries in it. </span><span class="koboSpan" id="kobo.588.2" xmlns="http://www.w3.org/1999/xhtml">When working with very large matrices, it can save a ton of memory, but, sadly, using sparse matrices would lead to problems in the training, so we need our one-hot encoder to give us an ordinary array.</span><span id="dx1-203012"/></p>
<div class="tcolorbox learnmore" id="tcolobox-204">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.589.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.590.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content"><span class="koboSpan" id="kobo.591.1" xmlns="http://www.w3.org/1999/xhtml">
The neat thing about the </span><code><span class="koboSpan" id="kobo.592.1" xmlns="http://www.w3.org/1999/xhtml">OneHotEncoder</span></code><span class="koboSpan" id="kobo.593.1" xmlns="http://www.w3.org/1999/xhtml"> class is that, once we have encoded an array of targets with representatives from each class using </span><code><span class="koboSpan" id="kobo.594.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.595.1" xmlns="http://www.w3.org/1999/xhtml">, we can use the </span><code><span class="koboSpan" id="kobo.596.1" xmlns="http://www.w3.org/1999/xhtml">transform</span></code><span class="koboSpan" id="kobo.597.1" xmlns="http://www.w3.org/1999/xhtml"> method on any array of targets. </span><span class="koboSpan" id="kobo.597.2" xmlns="http://www.w3.org/1999/xhtml">In our case, the </span><code><span class="koboSpan" id="kobo.598.1" xmlns="http://www.w3.org/1999/xhtml">hot</span></code><span class="koboSpan" id="kobo.599.1" xmlns="http://www.w3.org/1999/xhtml"> object will remember that there are </span><span class="koboSpan" id="kobo.600.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.601.1" xmlns="http://www.w3.org/1999/xhtml"> classes in our dataset, and hence </span><code><span class="koboSpan" id="kobo.602.1" xmlns="http://www.w3.org/1999/xhtml">hot</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.603.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span>
<code><span class="koboSpan" id="kobo.604.1" xmlns="http://www.w3.org/1999/xhtml">transform</span></code><span class="koboSpan" id="kobo.605.1" xmlns="http://www.w3.org/1999/xhtml"> will encode any targets correctly: even if it’s given an input with nothing other than zeros, it will still encode them as arrays of length </span><span class="koboSpan" id="kobo.606.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.607.1" xmlns="http://www.w3.org/1999/xhtml">.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.608.1" xmlns="http://www.w3.org/1999/xhtml">We have to do nothing more to our data, so we can now split it into some training, validation, and test datasets:</span></p>
<pre class="lstlisting" id="listing-288"><span class="koboSpan" id="kobo.609.1" xmlns="http://www.w3.org/1999/xhtml">

x_tr, x_test, y_tr, y_test = train_test_split( 
 
    x, y_hot, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split( 
 
    x_test, y_test, train_size = 0.5)
</span></pre>
<p><span class="koboSpan" id="kobo.610.1" xmlns="http://www.w3.org/1999/xhtml">And we can now </span><span id="dx1-203017"/><span class="koboSpan" id="kobo.611.1" xmlns="http://www.w3.org/1999/xhtml">implement the QNN that will constitute the quantum layer of our model. </span><span class="koboSpan" id="kobo.611.2" xmlns="http://www.w3.org/1999/xhtml">In truth, there’s nothing </span><span id="dx1-203018"/><span class="koboSpan" id="kobo.612.1" xmlns="http://www.w3.org/1999/xhtml">particularly special about this quantum neural network other than the fact that it will return an array of values rather than a single one. </span><span class="koboSpan" id="kobo.612.2" xmlns="http://www.w3.org/1999/xhtml">We can define it, according to our previous specification, as follows:</span></p>
<pre class="lstlisting" id="listing-289"><span class="koboSpan" id="kobo.613.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 4 
 
dev = qml.device("lightning.qubit", wires = nqubits) 
 
 
 
@qml.qnode(dev, interface="tf", diff_method = "adjoint") 
 
def qnn(inputs, theta): 
 
    qml.AngleEmbedding(inputs, range(nqubits)) 
 
    TwoLocal(nqubits, theta, reps = 2) 
 
    return [qml.expval(qml.Hermitian(M, wires = [0])), 
 
            qml.expval(qml.Hermitian(M, wires = [1])), 
 
            qml.expval(qml.Hermitian(M, wires = [2]))] 
 
 
 
weights = {"theta": 12}
</span></pre>
<p><span class="koboSpan" id="kobo.614.1" xmlns="http://www.w3.org/1999/xhtml">The code is pretty self-explanatory. </span><span class="koboSpan" id="kobo.614.2" xmlns="http://www.w3.org/1999/xhtml">Notice that, as usual, we have taken the chance to define the weights dictionary that we will use in the definition of the quantum Keras layer. </span><span class="koboSpan" id="kobo.614.3" xmlns="http://www.w3.org/1999/xhtml">In this case, we will be using </span><span class="koboSpan" id="kobo.615.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="12" class="math inline" src="../media/file601.png" style="vertical-align:middle" title="12"/></span><span class="koboSpan" id="kobo.616.1" xmlns="http://www.w3.org/1999/xhtml"> weights, exactly as in the case of our model in </span><em><span class="koboSpan" id="kobo.617.1" xmlns="http://www.w3.org/1999/xhtml">Subsection</span></em> <em/> <a href="#x1-19900011.2.2"><em><span class="koboSpan" id="kobo.618.1" xmlns="http://www.w3.org/1999/xhtml">11.2.2</span></em></a><span class="koboSpan" id="kobo.619.1" xmlns="http://www.w3.org/1999/xhtml">, because we are using the same variational form and the same number of qubits and repetitions.</span></p>
<p><span class="koboSpan" id="kobo.620.1" xmlns="http://www.w3.org/1999/xhtml">With our QNN ready, we can define the Keras model for our hybrid QNN. </span><span class="koboSpan" id="kobo.620.2" xmlns="http://www.w3.org/1999/xhtml">This is just analogous to what we did in the previous subsection, with a few important differences — don’t copy-paste so fast! </span><span class="koboSpan" id="kobo.620.3" xmlns="http://www.w3.org/1999/xhtml">First of all, in this case, we need to set the output dimension of the quantum layer to three, not one. </span><span class="koboSpan" id="kobo.620.4" xmlns="http://www.w3.org/1999/xhtml">And, much more importantly, we need to add an extra activation function on the QNN output.</span></p>
<p><span class="koboSpan" id="kobo.621.1" xmlns="http://www.w3.org/1999/xhtml">The categorical cross </span><span id="dx1-203031"/><span class="koboSpan" id="kobo.622.1" xmlns="http://www.w3.org/1999/xhtml">entropy loss function </span><span id="dx1-203032"/><span class="koboSpan" id="kobo.623.1" xmlns="http://www.w3.org/1999/xhtml">expects probability distributions. </span><span class="koboSpan" id="kobo.623.2" xmlns="http://www.w3.org/1999/xhtml">In principle, it assumes that the output of the </span><span class="koboSpan" id="kobo.624.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.625.1" xmlns="http://www.w3.org/1999/xhtml">-th neuron is the probability that the input belong to category </span><span class="koboSpan" id="kobo.626.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.627.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.627.2" xmlns="http://www.w3.org/1999/xhtml">Thus, the data that the model outputs should be normalized: it should add up to </span><span class="koboSpan" id="kobo.628.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.629.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.629.2" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, a priori,</span><span id="dx1-203033"/><span class="koboSpan" id="kobo.630.1" xmlns="http://www.w3.org/1999/xhtml"> there’s no way for us to guarantee that the QNN will return some normalized outputs with our current setup. </span><span class="koboSpan" id="kobo.630.2" xmlns="http://www.w3.org/1999/xhtml">In order to ensure this, we may use the </span><strong><span class="koboSpan" id="kobo.631.1" xmlns="http://www.w3.org/1999/xhtml">softmax</span></strong><span class="koboSpan" id="kobo.632.1" xmlns="http://www.w3.org/1999/xhtml"> activation function, which is </span><span id="dx1-203034"/><span class="koboSpan" id="kobo.633.1" xmlns="http://www.w3.org/1999/xhtml">defined as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.634.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}})." class="math display" src="../media/file1414.png" style="vertical-align:middle" title="\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}})."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.635.1" xmlns="http://www.w3.org/1999/xhtml">It’s easy to check that </span><span class="koboSpan" id="kobo.636.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\sigma" class="math inline" src="../media/file1415.png" style="vertical-align:middle" title="\sigma"/></span><span class="koboSpan" id="kobo.637.1" xmlns="http://www.w3.org/1999/xhtml"> is a vector with components bounded by </span><span class="koboSpan" id="kobo.638.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.639.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.640.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.641.1" xmlns="http://www.w3.org/1999/xhtml"> which add up to </span><span class="koboSpan" id="kobo.642.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.643.1" xmlns="http://www.w3.org/1999/xhtml"> and, hence, is a probability distribution.</span></p>
<p><span class="koboSpan" id="kobo.644.1" xmlns="http://www.w3.org/1999/xhtml">In addition to these modifications, we will add an extra classical layer with </span><span class="koboSpan" id="kobo.645.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.646.1" xmlns="http://www.w3.org/1999/xhtml"> neurons:</span></p>
<pre class="lstlisting" id="listing-290"><span class="koboSpan" id="kobo.647.1" xmlns="http://www.w3.org/1999/xhtml">

model = tf.keras.models.Sequential([ 
 
    tf.keras.layers.Input(20), 
 
    tf.keras.layers.Dense(8, activation = "elu"), 
 
    tf.keras.layers.Dense(4, activation = "sigmoid"), 
 
    qml.qnn.KerasLayer(qnn, weights, output_dim = 3), 
 
    tf.keras.layers.Activation(activation = "softmax") 
 
])
</span></pre>
<p><span class="koboSpan" id="kobo.648.1" xmlns="http://www.w3.org/1999/xhtml">And we can now compile our model with the Adam optimizer and the categorical cross-entropy loss before training it with the </span><code><span class="koboSpan" id="kobo.649.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.650.1" xmlns="http://www.w3.org/1999/xhtml"> method; nothing particularly exciting here. </span><span class="koboSpan" id="kobo.650.2" xmlns="http://www.w3.org/1999/xhtml">As a fun fact, if you were forgetful enough to tell TensorFlow to use the binary cross-entropy loss instead of the categorical cross-entropy one, it would still use the categorical cross-entropy loss (don’t look at us; we don’t say it from experience, right?). </span><span class="koboSpan" id="kobo.650.3" xmlns="http://www.w3.org/1999/xhtml">This is a rather nice and thoughtful feature from the guys behind TensorFlow.</span></p>
<pre class="lstlisting" id="listing-291"><span class="koboSpan" id="kobo.651.1" xmlns="http://www.w3.org/1999/xhtml">

opt = tf.keras.optimizers.Adam(learning_rate = 0.001) 
 
model.compile(opt, loss=tf.keras.losses.CategoricalCrossentropy()) 
 
 
 
history = model.fit(x_tr, y_tr, epochs = 50, shuffle = True, 
 
    validation_data = (x_val, y_val), 
 
    batch_size = 10, 
 
    callbacks = [earlystop])
</span></pre>
<p><span class="koboSpan" id="kobo.652.1" xmlns="http://www.w3.org/1999/xhtml">After a few </span><span id="dx1-203049"/><span class="koboSpan" id="kobo.653.1" xmlns="http://www.w3.org/1999/xhtml">minutes of training, we may get a plot of the evolution of the training and validation losses with the </span><span id="dx1-203050"/><span class="koboSpan" id="kobo.654.1" xmlns="http://www.w3.org/1999/xhtml">following instruction:</span></p>
<pre class="lstlisting" id="listing-292"><span class="koboSpan" id="kobo.655.1" xmlns="http://www.w3.org/1999/xhtml">

plot_losses(history)
</span></pre>
<p><span class="koboSpan" id="kobo.656.1" xmlns="http://www.w3.org/1999/xhtml">The resulting plot can be found in </span><em><span class="koboSpan" id="kobo.657.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure11.2"><em><span class="koboSpan" id="kobo.658.1" xmlns="http://www.w3.org/1999/xhtml">11.2</span></em></a><span class="koboSpan" id="kobo.659.1" xmlns="http://www.w3.org/1999/xhtml">, which shows the evolution of both losses.</span></p>
<figure>
<span class="koboSpan" id="kobo.660.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 11.2: Evolution of the training and validation loss functions in the training of a hybrid QNN multi-class classifier " src="../media/file1416.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure11.2"><strong><span class="koboSpan" id="kobo.661.1" xmlns="http://www.w3.org/1999/xhtml">Figure 11.2</span></strong><span class="koboSpan" id="kobo.662.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.663.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the training and validation loss functions in the training of a hybrid QNN multi-class classifier </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.664.1" xmlns="http://www.w3.org/1999/xhtml">We may now compute the training, validation, and test accuracies of our freshly-trained models, but, in order to do so, the </span><code><span class="koboSpan" id="kobo.665.1" xmlns="http://www.w3.org/1999/xhtml">accuracy_score</span></code><span class="koboSpan" id="kobo.666.1" xmlns="http://www.w3.org/1999/xhtml"> function needs the predicted and actual labels to be represented by numbers, not encoded in one-hot form as arrays. </span><span class="koboSpan" id="kobo.666.2" xmlns="http://www.w3.org/1999/xhtml">Hence, we need to undo the one-hot encoding. </span><span class="koboSpan" id="kobo.666.3" xmlns="http://www.w3.org/1999/xhtml">For this purpose, we can just use the </span><code><span class="koboSpan" id="kobo.667.1" xmlns="http://www.w3.org/1999/xhtml">argmax</span></code><span class="koboSpan" id="kobo.668.1" xmlns="http://www.w3.org/1999/xhtml"> method, which </span><span id="dx1-203054"/><span class="koboSpan" id="kobo.669.1" xmlns="http://www.w3.org/1999/xhtml">returns the entry of the </span><span id="dx1-203055"/><span class="koboSpan" id="kobo.670.1" xmlns="http://www.w3.org/1999/xhtml">maximum value in an array, and it can be given an optional </span><code><span class="koboSpan" id="kobo.671.1" xmlns="http://www.w3.org/1999/xhtml">axis</span></code><span class="koboSpan" id="kobo.672.1" xmlns="http://www.w3.org/1999/xhtml"> argument for it to be applied only in one axis. </span><span class="koboSpan" id="kobo.672.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we may compute the accuracy scores as follows:</span></p>
<pre class="lstlisting" id="listing-293"><span class="koboSpan" id="kobo.673.1" xmlns="http://www.w3.org/1999/xhtml">

tr_acc = accuracy_score( 
 
    model.predict(x_tr).argmax(axis = 1), 
 
    y_tr.argmax(axis = 1)) 
 
val_acc = accuracy_score( 
 
    model.predict(x_val).argmax(axis = 1), 
 
    y_val.argmax(axis = 1)) 
 
test_acc = accuracy_score( 
 
    model.predict(x_test).argmax(axis = 1), 
 
    y_test.argmax(axis = 1)) 
 
print("Train accuracy:", tr_acc) 
 
print("Validation accuracy:", val_acc) 
 
print("Test accuracy:", test_acc)
</span></pre>
<p><span class="koboSpan" id="kobo.674.1" xmlns="http://www.w3.org/1999/xhtml">This returns a training accuracy of </span><span class="koboSpan" id="kobo.675.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="67\%" class="math inline" src="../media/file1417.png" style="vertical-align:middle" title="67\%"/></span><span class="koboSpan" id="kobo.676.1" xmlns="http://www.w3.org/1999/xhtml">, a validation accuracy of </span><span class="koboSpan" id="kobo.677.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="53\%" class="math inline" src="../media/file1418.png" style="vertical-align:middle" title="53\%"/></span><span class="koboSpan" id="kobo.678.1" xmlns="http://www.w3.org/1999/xhtml">, and a test accuracy of </span><span class="koboSpan" id="kobo.679.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="60\%" class="math inline" src="../media/file1419.png" style="vertical-align:middle" title="60\%"/></span><span class="koboSpan" id="kobo.680.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.680.2" xmlns="http://www.w3.org/1999/xhtml">Notice that the low accuracy on the validation dataset — compared to that of the training dataset — seems to indicate an overfitting problem. </span><span class="koboSpan" id="kobo.680.3" xmlns="http://www.w3.org/1999/xhtml">This might be fixed, for example, by using a larger training dataset; of course, this would lead to longer training times.</span></p>
<div class="tcolorbox questionx" id="tcolobox-205">
<span id="x1-203069x11.2.4"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.681.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 11.6</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.682.1" xmlns="http://www.w3.org/1999/xhtml">Just to further leave our ”classifier comfort zone,” try to implement a hybrid model able to do regression. </span><span class="koboSpan" id="kobo.682.2" xmlns="http://www.w3.org/1999/xhtml">This model should be trained on some data with inputs </span><span class="koboSpan" id="kobo.683.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.684.1" xmlns="http://www.w3.org/1999/xhtml"> and target values </span><span class="koboSpan" id="kobo.685.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y" class="math inline" src="../media/file270.png" style="vertical-align:middle" title="y"/></span><span class="koboSpan" id="kobo.686.1" xmlns="http://www.w3.org/1999/xhtml"> for which there is a continuous function </span><span class="koboSpan" id="kobo.687.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f(x)" class="math inline" src="../media/file800.png" style="vertical-align:middle" title="f(x)"/></span><span class="koboSpan" id="kobo.688.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.689.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f(x) \simeq y" class="math inline" src="../media/file1420.png" style="vertical-align:middle" title="f(x) \simeq y"/></span><span class="koboSpan" id="kobo.690.1" xmlns="http://www.w3.org/1999/xhtml"> (you can create such a dataset, for instance, with the </span><code><span class="koboSpan" id="kobo.691.1" xmlns="http://www.w3.org/1999/xhtml">make_regression</span></code><span class="koboSpan" id="kobo.692.1" xmlns="http://www.w3.org/1999/xhtml"> method from scikit-learn). </span><span class="koboSpan" id="kobo.692.2" xmlns="http://www.w3.org/1999/xhtml">The model should try to learn the function </span><span class="koboSpan" id="kobo.693.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f" class="math inline" src="../media/file778.png" style="vertical-align:middle" title="f"/></span><span class="koboSpan" id="kobo.694.1" xmlns="http://www.w3.org/1999/xhtml"> for all the points in the dataset.</span></p>
<p><span class="koboSpan" id="kobo.695.1" xmlns="http://www.w3.org/1999/xhtml">You may design this model using some classical layers, followed by a quantum layer like the ones that we have considered, and a final classical layer with no activation functions and just one neuron. </span><span class="koboSpan" id="kobo.695.2" xmlns="http://www.w3.org/1999/xhtml">You should train it with the mean squared error loss.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.696.1" xmlns="http://www.w3.org/1999/xhtml">That </span><span id="dx1-203070"/><span class="koboSpan" id="kobo.697.1" xmlns="http://www.w3.org/1999/xhtml">concludes our study of hybrid </span><span id="dx1-203071"/><span class="koboSpan" id="kobo.698.1" xmlns="http://www.w3.org/1999/xhtml">architectures in PennyLane. </span><span class="koboSpan" id="kobo.698.2" xmlns="http://www.w3.org/1999/xhtml">It’s time for us to get to Qiskit, and that’s going to be a very different adventure!</span></p>
</section>
</section>
</section>
<section class="level2 sectionHead" data-number="19.3" id="hybrid-architectures-in-qiskit">
<h1 class="sectionHead" data-number="19.3"><span class="titlemark"><span class="koboSpan" id="kobo.699.1" xmlns="http://www.w3.org/1999/xhtml">11.3 </span></span> <span id="x1-20400011.3"><span class="koboSpan" id="kobo.700.1" xmlns="http://www.w3.org/1999/xhtml">Hybrid architectures in Qiskit</span></span></h1>
<p><span class="koboSpan" id="kobo.701.1" xmlns="http://www.w3.org/1999/xhtml">In the previous section, we </span><span id="dx1-204001"/><span class="koboSpan" id="kobo.702.1" xmlns="http://www.w3.org/1999/xhtml">discussed how hybrid QNNs could be implemented and trained using PennyLane in conjunction with TensorFlow, an ML framework that we already know how to use. </span><span class="koboSpan" id="kobo.702.2" xmlns="http://www.w3.org/1999/xhtml">We will devote this section to studying how to work with these hybrid architectures in Qiskit, and in this mission we will need to face a new challenge.</span></p>
<p><span class="koboSpan" id="kobo.703.1" xmlns="http://www.w3.org/1999/xhtml">For better or for worse, Qiskit doesn’t have a built-in TensorFlow interface at the time of writing. </span><span class="koboSpan" id="kobo.703.2" xmlns="http://www.w3.org/1999/xhtml">It only has native support for a different ML framework: PyTorch. </span><span class="koboSpan" id="kobo.703.3" xmlns="http://www.w3.org/1999/xhtml">So, if we want to get those hybrid NNs working on Qiskit, we better learn a thing or two about PyTorch. </span><span class="koboSpan" id="kobo.703.4" xmlns="http://www.w3.org/1999/xhtml">As daunting as this task may seem, it won’t be such a hassle and it will greatly pay off in the future — and, yes, the future is our next chapter on QGANs.</span></p>
<div class="tcolorbox important" id="tcolobox-206">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.704.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.705.1" xmlns="http://www.w3.org/1999/xhtml">We will be using </span><strong><span class="koboSpan" id="kobo.706.1" xmlns="http://www.w3.org/1999/xhtml">version 1.13</span></strong><span class="koboSpan" id="kobo.707.1" xmlns="http://www.w3.org/1999/xhtml"> of the PyTorch package. </span><span class="koboSpan" id="kobo.707.2" xmlns="http://www.w3.org/1999/xhtml">If you are using a different version, things may be slightly different!</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.708.1" xmlns="http://www.w3.org/1999/xhtml">What’s so special about PyTorch to be worth our time beyond this short section? </span><span class="koboSpan" id="kobo.708.2" xmlns="http://www.w3.org/1999/xhtml">Come and see.</span></p>
<section class="level3 subsectionHead" data-number="19.3.1" id="nice-to-meet-you-pytorch">
<h2 class="subsectionHead" data-number="19.3.1"><span class="titlemark"><span class="koboSpan" id="kobo.709.1" xmlns="http://www.w3.org/1999/xhtml">11.3.1 </span></span> <span id="x1-20500011.3.1"><span class="koboSpan" id="kobo.710.1" xmlns="http://www.w3.org/1999/xhtml">Nice to meet you, PyTorch!</span></span></h2>
<p><span class="koboSpan" id="kobo.711.1" xmlns="http://www.w3.org/1999/xhtml">So far, we have worked with TensorFlow. </span><span class="koboSpan" id="kobo.711.2" xmlns="http://www.w3.org/1999/xhtml">In our experience, this framework provides a very easy and streamlined experience for the implementation and training of all sorts of network-based models. </span><span class="koboSpan" id="kobo.711.3" xmlns="http://www.w3.org/1999/xhtml">However, there’s a small catch behind all that ease of use. </span><span class="koboSpan" id="kobo.711.4" xmlns="http://www.w3.org/1999/xhtml">In this book, we haven’t been using ”pure TensorFlow,” but we have been relying heavily on Keras. </span><span class="koboSpan" id="kobo.711.5" xmlns="http://www.w3.org/1999/xhtml">In spite of being fully integrated into TensorFlow, Keras is a component that creates some additional layers of abstraction in order to simplify the handling of neural-network models in TensorFlow. </span><span class="koboSpan" id="kobo.711.6" xmlns="http://www.w3.org/1999/xhtml">All this time, Keras has been taking care of lots of things for us behind the scenes.</span></p>
<p><span class="koboSpan" id="kobo.712.1" xmlns="http://www.w3.org/1999/xhtml">At the time of writing, there are two very popular ML frameworks out there: TensorFlow and PyTorch. </span><span class="koboSpan" id="kobo.712.2" xmlns="http://www.w3.org/1999/xhtml">The former we already know, the latter we soon will. </span><span class="koboSpan" id="kobo.712.3" xmlns="http://www.w3.org/1999/xhtml">PyTorch, unlike TensorFlow, doesn’t come with its own Keras (although there are some third-party packages that provide similar functionalities). </span><span class="koboSpan" id="kobo.712.4" xmlns="http://www.w3.org/1999/xhtml">In </span><span id="dx1-205001"/><span class="koboSpan" id="kobo.713.1" xmlns="http://www.w3.org/1999/xhtml">PyTorch, we will have to take care of many details ourselves. </span><span class="koboSpan" id="kobo.713.2" xmlns="http://www.w3.org/1999/xhtml">And that’s great. </span><span class="koboSpan" id="kobo.713.3" xmlns="http://www.w3.org/1999/xhtml">Granted, learning how to use PyTorch will require a tiny bit more effort on our part, but </span><span id="dx1-205002"/><span class="koboSpan" id="kobo.714.1" xmlns="http://www.w3.org/1999/xhtml">PyTorch will offer us a level of flexibility that TensorFlow’s Keras simply can’t. </span><span class="koboSpan" id="kobo.714.2" xmlns="http://www.w3.org/1999/xhtml">Let’s get started then.</span></p>
<p><span class="koboSpan" id="kobo.715.1" xmlns="http://www.w3.org/1999/xhtml">We will be </span><span id="dx1-205003"/><span class="koboSpan" id="kobo.716.1" xmlns="http://www.w3.org/1999/xhtml">using version 1.13 of the PyTorch package. </span><span class="koboSpan" id="kobo.716.2" xmlns="http://www.w3.org/1999/xhtml">Please refer to </span><em><span class="koboSpan" id="kobo.717.1" xmlns="http://www.w3.org/1999/xhtml">Appendix</span></em> <a href="ch027.xhtml#x1-240000D"><em><span class="koboSpan" id="kobo.718.1" xmlns="http://www.w3.org/1999/xhtml">D</span></em></a><span class="koboSpan" id="kobo.719.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.720.1" xmlns="http://www.w3.org/1999/xhtml">Installing the Tools</span></em><span class="koboSpan" id="kobo.721.1" xmlns="http://www.w3.org/1999/xhtml">, for instructions on how to install it.</span></p>
<p><span class="koboSpan" id="kobo.722.1" xmlns="http://www.w3.org/1999/xhtml">As usual, we shall begin by importing NumPy and a few utilities from scikit-learn. </span><span class="koboSpan" id="kobo.722.2" xmlns="http://www.w3.org/1999/xhtml">We will also set a seed for NumPy:</span></p>
<p><span id="x1-205004"/></p>
<pre class="lstlisting" id="listing-294"><span class="koboSpan" id="kobo.723.1" xmlns="http://www.w3.org/1999/xhtml">

import numpy as np 
 
from sklearn.metrics import accuracy_score 
 
from sklearn.model_selection import train_test_split 
 
from sklearn.datasets import make_classification 
 
 
 
seed = 1234 
 
np.random.seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.724.1" xmlns="http://www.w3.org/1999/xhtml">With those imports out of the way, we can get to our main dish. </span><span class="koboSpan" id="kobo.724.2" xmlns="http://www.w3.org/1999/xhtml">This is how you can import PyTorch and give it a seed to ensure reproducibility:</span></p>
<pre class="lstlisting" id="listing-295"><span class="koboSpan" id="kobo.725.1" xmlns="http://www.w3.org/1999/xhtml">

import torch 
 
torch.manual_seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.726.1" xmlns="http://www.w3.org/1999/xhtml">Most </span><span id="dx1-205014"/><span class="koboSpan" id="kobo.727.1" xmlns="http://www.w3.org/1999/xhtml">functionality related to the </span><span id="dx1-205015"/><span class="koboSpan" id="kobo.728.1" xmlns="http://www.w3.org/1999/xhtml">implementation of models is in the </span><code><span class="koboSpan" id="kobo.729.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.730.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.731.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code><span class="koboSpan" id="kobo.732.1" xmlns="http://www.w3.org/1999/xhtml"> module, and most activation functions can be found in the </span><code><span class="koboSpan" id="kobo.733.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.734.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.735.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.736.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.737.1" xmlns="http://www.w3.org/1999/xhtml">functional</span></code><span class="koboSpan" id="kobo.738.1" xmlns="http://www.w3.org/1999/xhtml"> module, so let’s import these as well:</span></p>
<pre class="lstlisting" id="listing-296"><span class="koboSpan" id="kobo.739.1" xmlns="http://www.w3.org/1999/xhtml">

import torch.nn as nn 
 
import torch.nn.functional as F
</span></pre>
<p><span class="koboSpan" id="kobo.740.1" xmlns="http://www.w3.org/1999/xhtml">Those are all the imports that we need for now.</span></p>
<section class="level4 subsubsectionHead" data-number="19.3.1.1" id="setting-up-a-model-in-pytorch">
<h3 class="subsubsectionHead" data-number="19.3.1.1"><span id="x1-20600011.3.1"><span class="koboSpan" id="kobo.741.1" xmlns="http://www.w3.org/1999/xhtml">Setting up a model in PyTorch</span></span></h3>
<p><span class="koboSpan" id="kobo.742.1" xmlns="http://www.w3.org/1999/xhtml">In order to understand how the </span><span id="dx1-206001"/><span class="koboSpan" id="kobo.743.1" xmlns="http://www.w3.org/1999/xhtml">PyTorch package works, we will implement and train a simple binary classifier as a (classical) neural network. </span><span class="koboSpan" id="kobo.743.2" xmlns="http://www.w3.org/1999/xhtml">This neural network will take </span><span class="koboSpan" id="kobo.744.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.745.1" xmlns="http://www.w3.org/1999/xhtml"> inputs and return a unique output between </span><span class="koboSpan" id="kobo.746.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.747.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.748.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.749.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.749.2" xmlns="http://www.w3.org/1999/xhtml">As usual, the two possible labels will be </span><span class="koboSpan" id="kobo.750.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.751.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.752.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.753.1" xmlns="http://www.w3.org/1999/xhtml"> and the output label will be decided based on whether the network output is closer to </span><span class="koboSpan" id="kobo.754.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.755.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><span class="koboSpan" id="kobo.756.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.757.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.758.1" xmlns="http://www.w3.org/1999/xhtml">Let’s see how we can implement this neural network classifier. </span><span class="koboSpan" id="kobo.758.2" xmlns="http://www.w3.org/1999/xhtml">In PyTorch, model architectures are defined as subclasses of the </span><code><span class="koboSpan" id="kobo.759.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.760.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.761.1" xmlns="http://www.w3.org/1999/xhtml">Module</span></code><span class="koboSpan" id="kobo.762.1" xmlns="http://www.w3.org/1999/xhtml"> class, and individual models are objects of these subclasses. </span><span class="koboSpan" id="kobo.762.2" xmlns="http://www.w3.org/1999/xhtml">When defining subclasses of </span><code><span class="koboSpan" id="kobo.763.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.764.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.765.1" xmlns="http://www.w3.org/1999/xhtml">Module</span></code><span class="koboSpan" id="kobo.766.1" xmlns="http://www.w3.org/1999/xhtml">, you should implement an initializer that first calls the parent’s initializer and then prepares all the variables of the model architecture; for instance, all the network layers should be initialized here. </span><span class="koboSpan" id="kobo.766.2" xmlns="http://www.w3.org/1999/xhtml">In addition, you need to provide a </span><code><span class="koboSpan" id="kobo.767.1" xmlns="http://www.w3.org/1999/xhtml">forward</span></code><span class="koboSpan" id="kobo.768.1" xmlns="http://www.w3.org/1999/xhtml"> method that defines the behavior of the network: this method should take any input to the network as an argument and return its output.</span></p>
<p><span class="koboSpan" id="kobo.769.1" xmlns="http://www.w3.org/1999/xhtml">Our desired neural network could be implemented as follows (don’t worry, we will discuss this piece of code right away):</span></p>
<pre class="lstlisting" id="listing-297"><span class="koboSpan" id="kobo.770.1" xmlns="http://www.w3.org/1999/xhtml">

class TorchClassifier(nn.Module): 
 
 
 
    def __init__(self): 
 
 
 
        # Initialize super class. 
 
        </span><span class="koboSpan" id="kobo.770.2" xmlns="http://www.w3.org/1999/xhtml">super(TorchClassifier, self).__init__() 
 
 
 
        # Declare the layers that we will use. 
 
        </span><span class="koboSpan" id="kobo.770.3" xmlns="http://www.w3.org/1999/xhtml">self.layer1 = nn.Linear(16, 8) 
 
        self.layer2 = nn.Linear(8, 4) 
 
        self.layer3 = nn.Linear(4, 2) 
 
        self.layer4 = nn.Linear(2, 1) 
 
 
 
    # Define the transformation of an input. 
 
    </span><span class="koboSpan" id="kobo.770.4" xmlns="http://www.w3.org/1999/xhtml">def forward(self, x): 
 
        x = F.elu(self.layer1(x)) 
 
        x = F.elu(self.layer2(x)) 
 
        x = F.elu(self.layer3(x)) 
 
        x = torch.sigmoid(self.layer4(x)) 
 
 
 
        return x
</span></pre>
<p><span class="koboSpan" id="kobo.771.1" xmlns="http://www.w3.org/1999/xhtml">There are a few things to </span><span id="dx1-206023"/><span class="koboSpan" id="kobo.772.1" xmlns="http://www.w3.org/1999/xhtml">digest in this implementation. </span><span class="koboSpan" id="kobo.772.2" xmlns="http://www.w3.org/1999/xhtml">Let us first look at the initializer. </span><span class="koboSpan" id="kobo.772.3" xmlns="http://www.w3.org/1999/xhtml">As expected, we are defining a subclass of </span><code><span class="koboSpan" id="kobo.773.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.774.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.775.1" xmlns="http://www.w3.org/1999/xhtml">Module</span></code><span class="koboSpan" id="kobo.776.1" xmlns="http://www.w3.org/1999/xhtml"> and we are first calling the parent’s initializer; so far, so good. </span><span class="koboSpan" id="kobo.776.2" xmlns="http://www.w3.org/1999/xhtml">Then we are defining what seem to be the layers of the neural network, and here is where some confusion may arise. </span><span class="koboSpan" id="kobo.776.3" xmlns="http://www.w3.org/1999/xhtml">Our first issue arises from terminology: ”linear layers” are PyTorch’s equivalent of Keras’ ”dense” layers — not a big deal. </span><span class="koboSpan" id="kobo.776.4" xmlns="http://www.w3.org/1999/xhtml">But then we have a deeper issue. </span><span class="koboSpan" id="kobo.776.5" xmlns="http://www.w3.org/1999/xhtml">Back in our Keras days, we defined the layers of a neural network by specifying the number of neurons they had and their activation function. </span><span class="koboSpan" id="kobo.776.6" xmlns="http://www.w3.org/1999/xhtml">But here there’s no trace of activation functions and the layers take what seem to be two-dimensional arguments. </span><span class="koboSpan" id="kobo.776.7" xmlns="http://www.w3.org/1999/xhtml">What’s going on?</span></p>
<p><span class="koboSpan" id="kobo.777.1" xmlns="http://www.w3.org/1999/xhtml">In a neural network, you have a bunch of neurons that are arranged into arrays, and these arrays are connected by some ”linear wiring” between them. </span><span class="koboSpan" id="kobo.777.2" xmlns="http://www.w3.org/1999/xhtml">In addition, each array of neurons has a (usually non-linear) activation function. </span><span class="koboSpan" id="kobo.777.3" xmlns="http://www.w3.org/1999/xhtml">In Keras, layers were associated to these arrays of </span><span id="dx1-206024"/><span class="koboSpan" id="kobo.778.1" xmlns="http://www.w3.org/1999/xhtml">neurons themselves (with their activation functions) and to the ”linear wiring” before them. </span><span class="koboSpan" id="kobo.778.2" xmlns="http://www.w3.org/1999/xhtml">In PyTorch, on the other hand, when we speak of layers, we only refer to the linear wiring between these arrays of neurons. </span><span class="koboSpan" id="kobo.778.3" xmlns="http://www.w3.org/1999/xhtml">Hence, </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.779.1" xmlns="http://www.w3.org/1999/xhtml">nn</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.780.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.781.1" xmlns="http://www.w3.org/1999/xhtml">Linear</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.782.1" xmlns="http://www.w3.org/1999/xhtml">(16,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.783.1" xmlns="http://www.w3.org/1999/xhtml">8)</span></code></span></span><span class="koboSpan" id="kobo.784.1" xmlns="http://www.w3.org/1999/xhtml"> is nothing more than the linear wiring — with its weights and biases — between an array of </span><span class="koboSpan" id="kobo.785.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.786.1" xmlns="http://www.w3.org/1999/xhtml"> neurons and an array of </span><span class="koboSpan" id="kobo.787.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.788.1" xmlns="http://www.w3.org/1999/xhtml"> neurons. </span><span class="koboSpan" id="kobo.788.2" xmlns="http://www.w3.org/1999/xhtml">This will make more sense when we look at the </span><code><span class="koboSpan" id="kobo.789.1" xmlns="http://www.w3.org/1999/xhtml">forward</span></code><span class="koboSpan" id="kobo.790.1" xmlns="http://www.w3.org/1999/xhtml"> method.</span></p>
<p><span class="koboSpan" id="kobo.791.1" xmlns="http://www.w3.org/1999/xhtml">The </span><code><span class="koboSpan" id="kobo.792.1" xmlns="http://www.w3.org/1999/xhtml">forward</span></code><span class="koboSpan" id="kobo.793.1" xmlns="http://www.w3.org/1999/xhtml"> method defines what happens to any input that gets into the network. </span><span class="koboSpan" id="kobo.793.2" xmlns="http://www.w3.org/1999/xhtml">In its implementation, we can see how any input, which will be a PyTorch tensor of length </span><span class="koboSpan" id="kobo.794.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.795.1" xmlns="http://www.w3.org/1999/xhtml">, goes through the first layer. </span><span class="koboSpan" id="kobo.795.2" xmlns="http://www.w3.org/1999/xhtml">This first layer is the ”linear wiring” between an array of </span><span class="koboSpan" id="kobo.796.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.797.1" xmlns="http://www.w3.org/1999/xhtml"> neurons and an array of </span><span class="koboSpan" id="kobo.798.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.799.1" xmlns="http://www.w3.org/1999/xhtml"> neurons; it has its own weights </span><span class="koboSpan" id="kobo.800.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="w_{jk}" class="math inline" src="../media/file1421.png" style="vertical-align:middle" title="w_{jk}"/></span><span class="koboSpan" id="kobo.801.1" xmlns="http://www.w3.org/1999/xhtml"> and biases </span><span class="koboSpan" id="kobo.802.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b_{k}" class="math inline" src="../media/file1422.png" style="vertical-align:middle" title="b_{k}"/></span><span class="koboSpan" id="kobo.803.1" xmlns="http://www.w3.org/1999/xhtml"> and, for any input </span><span class="koboSpan" id="kobo.804.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(x_{1},\ldots,x_{16})" class="math inline" src="../media/file1423.png" style="vertical-align:middle" title="(x_{1},\ldots,x_{16})"/></span><span class="koboSpan" id="kobo.805.1" xmlns="http://www.w3.org/1999/xhtml">, it returns a vector </span><span class="koboSpan" id="kobo.806.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="({\hat{x}}_{1},\ldots,{\hat{x}}_{8})" class="math inline" src="../media/file1424.png" style="vertical-align:middle" title="({\hat{x}}_{1},\ldots,{\hat{x}}_{8})"/></span><span class="koboSpan" id="kobo.807.1" xmlns="http://www.w3.org/1999/xhtml"> with</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.808.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}." class="math display" src="../media/file1425.png" style="vertical-align:middle" title="{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.809.1" xmlns="http://www.w3.org/1999/xhtml">Then, each entry in the resulting tensor goes through the ELU activation function. </span><span class="koboSpan" id="kobo.809.2" xmlns="http://www.w3.org/1999/xhtml">The rest of the code is self-explanatory and simply defines a neural network that matches our specifications.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-207">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.810.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.811.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.812.1" xmlns="http://www.w3.org/1999/xhtml">Layers in PyTorch define their own weights and biases. </span><span class="koboSpan" id="kobo.812.2" xmlns="http://www.w3.org/1999/xhtml">If you wish to remove the biases — setting them to zero for all eternity — you may do so by sending the optional argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.813.1" xmlns="http://www.w3.org/1999/xhtml">bias</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.814.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.815.1" xmlns="http://www.w3.org/1999/xhtml">False</span></code></span></span><span class="koboSpan" id="kobo.816.1" xmlns="http://www.w3.org/1999/xhtml"> when initializing a layer.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.817.1" xmlns="http://www.w3.org/1999/xhtml">Now that we have our model architecture defined, we can instantiate it into an individual model by initializing an object of the </span><code><span class="koboSpan" id="kobo.818.1" xmlns="http://www.w3.org/1999/xhtml">TorchClassifier</span></code><span class="koboSpan" id="kobo.819.1" xmlns="http://www.w3.org/1999/xhtml"> class. </span><span class="koboSpan" id="kobo.819.2" xmlns="http://www.w3.org/1999/xhtml">A nice thing about PyTorch models, by the way, is that they can be printed; their output gives you an overview of the different model components. </span><span class="koboSpan" id="kobo.819.3" xmlns="http://www.w3.org/1999/xhtml">Let’s create our model object and see this in action:</span></p>
<pre class="lstlisting" id="listing-298"><span class="koboSpan" id="kobo.820.1" xmlns="http://www.w3.org/1999/xhtml">

model = TorchClassifier() 
 
print(model)
</span></pre>
<p><span class="koboSpan" id="kobo.821.1" xmlns="http://www.w3.org/1999/xhtml">Upon running this, we get the </span><span id="dx1-206027"/><span class="koboSpan" id="kobo.822.1" xmlns="http://www.w3.org/1999/xhtml">following output from the print instruction:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.823.1" xmlns="http://www.w3.org/1999/xhtml">

 
TorchClassifier( 
  (layer1): Linear(in_features=16, out_features=8, bias=True) 
  (layer2): Linear(in_features=8, out_features=4, bias=True) 
  (layer3): Linear(in_features=4, out_features=2, bias=True) 
  (layer4): Linear(in_features=2, out_features=1, bias=True) 
)
    
</span></pre>
<p><span class="koboSpan" id="kobo.824.1" xmlns="http://www.w3.org/1999/xhtml">This is somewhat analogous to the model summaries that we could print in Keras.</span></p>
<p><span class="koboSpan" id="kobo.825.1" xmlns="http://www.w3.org/1999/xhtml">By default, the weights and biases of models are random, so our newly-created </span><code><span class="koboSpan" id="kobo.826.1" xmlns="http://www.w3.org/1999/xhtml">model</span></code><span class="koboSpan" id="kobo.827.1" xmlns="http://www.w3.org/1999/xhtml"> should already be ready to be used. </span><span class="koboSpan" id="kobo.827.2" xmlns="http://www.w3.org/1999/xhtml">Let’s try it out! </span><span class="koboSpan" id="kobo.827.3" xmlns="http://www.w3.org/1999/xhtml">The </span><code><span class="koboSpan" id="kobo.828.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.829.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.830.1" xmlns="http://www.w3.org/1999/xhtml">rand</span></code><span class="koboSpan" id="kobo.831.1" xmlns="http://www.w3.org/1999/xhtml"> function can create a random tensor of any specified size. </span><span class="koboSpan" id="kobo.831.2" xmlns="http://www.w3.org/1999/xhtml">We will use it to feed our model some random data and see if it works:</span></p>
<pre class="lstlisting" id="listing-299"><span class="koboSpan" id="kobo.832.1" xmlns="http://www.w3.org/1999/xhtml">

model(torch.rand(16))
</span></pre>
<p><span class="koboSpan" id="kobo.833.1" xmlns="http://www.w3.org/1999/xhtml">This is the output that we get:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.834.1" xmlns="http://www.w3.org/1999/xhtml">

 
tensor([0.4240], grad_fn=&lt;SigmoidBackward0&gt;)
    
</span></pre>
<p><span class="koboSpan" id="kobo.835.1" xmlns="http://www.w3.org/1999/xhtml">And there we have it! </span><span class="koboSpan" id="kobo.835.2" xmlns="http://www.w3.org/1999/xhtml">As expected, our model returns a value between </span><span class="koboSpan" id="kobo.836.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.837.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.838.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.839.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.839.2" xmlns="http://www.w3.org/1999/xhtml">By the way, notice one little thing in the output: right next to the tensor value, there is a </span><code><span class="koboSpan" id="kobo.840.1" xmlns="http://www.w3.org/1999/xhtml">grad_fn</span></code><span class="koboSpan" id="kobo.841.1" xmlns="http://www.w3.org/1999/xhtml"> value that somehow remembers that this output was last obtained from the application of a sigmoid function. </span><span class="koboSpan" id="kobo.841.2" xmlns="http://www.w3.org/1999/xhtml">Interesting, isn’t it? </span><span class="koboSpan" id="kobo.841.3" xmlns="http://www.w3.org/1999/xhtml">Well, you may remember that TensorFlow used its own tensor datatype, and PyTorch has its own tensors too. </span><span class="koboSpan" id="kobo.841.4" xmlns="http://www.w3.org/1999/xhtml">The cool thing about them is that every PyTorch tensor keeps track of how it was computed in order to enable gradient computation through backpropagation. </span><span class="koboSpan" id="kobo.841.5" xmlns="http://www.w3.org/1999/xhtml">We will further discuss this later on in this subsection.</span></p>
<p><span class="koboSpan" id="kobo.842.1" xmlns="http://www.w3.org/1999/xhtml">In any case, now that our network is all set up, let us generate some data and split it into some training, validation, and </span><span id="dx1-206038"/><span class="koboSpan" id="kobo.843.1" xmlns="http://www.w3.org/1999/xhtml">test datasets:</span></p>
<pre class="lstlisting" id="listing-300"><span class="koboSpan" id="kobo.844.1" xmlns="http://www.w3.org/1999/xhtml">

x, y = make_classification(n_samples = 1000, n_features = 16) 
 
 
 
x_tr, x_test, y_tr, y_test = train_test_split( 
 
    x, y, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split( 
 
    x_test, y_test, train_size = 0.5)
</span></pre>
</section>
<section class="level4 subsubsectionHead" data-number="19.3.1.2" id="training-a-model-in-pytorch">
<h3 class="subsubsectionHead" data-number="19.3.1.2"><span id="x1-20700011.3.1"><span class="koboSpan" id="kobo.845.1" xmlns="http://www.w3.org/1999/xhtml">Training a model in PyTorch</span></span></h3>
<p><span class="koboSpan" id="kobo.846.1" xmlns="http://www.w3.org/1999/xhtml">In principle, we could work with this raw data just as we did in TensorFlow — perhaps converting it to </span><span id="dx1-207001"/><span class="koboSpan" id="kobo.847.1" xmlns="http://www.w3.org/1999/xhtml">PyTorch tensors, but still. </span><span class="koboSpan" id="kobo.847.2" xmlns="http://www.w3.org/1999/xhtml">However, we know that PyTorch will require us to take care of many things ourselves; one of which will be splitting our data into batches should we want to. </span><span class="koboSpan" id="kobo.847.3" xmlns="http://www.w3.org/1999/xhtml">Doing that ourselves could be tedious to say the least. </span><span class="koboSpan" id="kobo.847.4" xmlns="http://www.w3.org/1999/xhtml">Thankfully, PyTorch comes with some tools that can assist us in the process, so we better give them a shot.</span></p>
<p><span class="koboSpan" id="kobo.848.1" xmlns="http://www.w3.org/1999/xhtml">The best way to deal with datasets in PyTorch is by storing data in subclasses of a </span><code><span class="koboSpan" id="kobo.849.1" xmlns="http://www.w3.org/1999/xhtml">Dataset</span></code><span class="koboSpan" id="kobo.850.1" xmlns="http://www.w3.org/1999/xhtml"> class, which can be found in the </span><code><span class="koboSpan" id="kobo.851.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.852.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.853.1" xmlns="http://www.w3.org/1999/xhtml">utils</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.854.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.855.1" xmlns="http://www.w3.org/1999/xhtml">data</span></code><span class="koboSpan" id="kobo.856.1" xmlns="http://www.w3.org/1999/xhtml"> module. </span><span class="koboSpan" id="kobo.856.2" xmlns="http://www.w3.org/1999/xhtml">Any subclasses of </span><code><span class="koboSpan" id="kobo.857.1" xmlns="http://www.w3.org/1999/xhtml">Dataset</span></code><span class="koboSpan" id="kobo.858.1" xmlns="http://www.w3.org/1999/xhtml"> should implement an initializer, a </span><code><span class="koboSpan" id="kobo.859.1" xmlns="http://www.w3.org/1999/xhtml">__getitem__</span></code><span class="koboSpan" id="kobo.860.1" xmlns="http://www.w3.org/1999/xhtml"> method (to access data items by indexing), and a </span><code><span class="koboSpan" id="kobo.861.1" xmlns="http://www.w3.org/1999/xhtml">__len__</span></code><span class="koboSpan" id="kobo.862.1" xmlns="http://www.w3.org/1999/xhtml"> method (returning the number of items in the dataset). </span><span class="koboSpan" id="kobo.862.2" xmlns="http://www.w3.org/1999/xhtml">For our purposes, we can create a subclass in order to create datasets from our NumPy arrays:</span></p>
<pre class="lstlisting" id="listing-301"><span class="koboSpan" id="kobo.863.1" xmlns="http://www.w3.org/1999/xhtml">

from torch.utils.data import Dataset 
 
 
 
class NumpyDataset(Dataset): 
 
    def __init__(self, x, y): 
 
 
 
        if (x.shape[0] != y.shape[0]): 
 
            raise Exception("Incompatible arrays") 
 
 
 
        y = y.reshape(-1,1) 
 
 
 
        self.x = torch.from_numpy(x).to(torch.float) 
 
        self.y = torch.from_numpy(y).to(torch.float) 
 
 
 
    def __getitem__(self, i): 
 
        return self.x[i], self.y[i] 
 
 
 
    def __len__(self): 
 
        return self.y.shape[0]
</span></pre>
<p><span class="koboSpan" id="kobo.864.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have added some size-checking to </span><span id="dx1-207020"/><span class="koboSpan" id="kobo.865.1" xmlns="http://www.w3.org/1999/xhtml">ensure that the data array and the labels vector have matching dimensions, and how we have reshaped the array of targets — that’s in order to avoid problems with the loss functions, which expect them to be column vectors. </span><span class="koboSpan" id="kobo.865.2" xmlns="http://www.w3.org/1999/xhtml">With this class set up, we may create dataset objects for the training, validation and test datasets as follows:</span></p>
<pre class="lstlisting" id="listing-302"><span class="koboSpan" id="kobo.866.1" xmlns="http://www.w3.org/1999/xhtml">

tr_data = NumpyDataset(x_tr, y_tr) 
 
val_data = NumpyDataset(x_val, y_val) 
 
test_data = NumpyDataset(x_test, y_test)
</span></pre>
<p><span class="koboSpan" id="kobo.867.1" xmlns="http://www.w3.org/1999/xhtml">Just to check whether our implementation was successful, let us try to access the first element in </span><code><span class="koboSpan" id="kobo.868.1" xmlns="http://www.w3.org/1999/xhtml">tr_data</span></code><span class="koboSpan" id="kobo.869.1" xmlns="http://www.w3.org/1999/xhtml"> and get the length of the training dataset:</span></p>
<pre class="lstlisting" id="listing-303"><span class="koboSpan" id="kobo.870.1" xmlns="http://www.w3.org/1999/xhtml">

print(tr_data[0]) 
 
print("Length:", len(tr_data))
</span></pre>
<p><span class="koboSpan" id="kobo.871.1" xmlns="http://www.w3.org/1999/xhtml">This is the output returned by these instructions:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.872.1" xmlns="http://www.w3.org/1999/xhtml">

 
(tensor([ 1.4791,  1.4646,  0.0430,  0.0409, -0.3792, -0.5357, 
          0.9736, -1.3697, -1.2596,  1.5159, -0.9276,  0.6868, 
          0.5138,  0.4751,  1.0193, -1.7873]), 
tensor([0.])) 
 
Length: 800
    
</span></pre>
<p><span class="koboSpan" id="kobo.873.1" xmlns="http://www.w3.org/1999/xhtml">We can see how, indeed, it gave us a tuple with a tensor of length </span><span class="koboSpan" id="kobo.874.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.875.1" xmlns="http://www.w3.org/1999/xhtml"> and its corresponding label. </span><span class="koboSpan" id="kobo.875.2" xmlns="http://www.w3.org/1999/xhtml">Also, a call to the </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.876.1" xmlns="http://www.w3.org/1999/xhtml">len</span></code></span></span><span class="koboSpan" id="kobo.877.1" xmlns="http://www.w3.org/1999/xhtml"> function did return the correct number of items in our dataset. </span><span class="koboSpan" id="kobo.877.2" xmlns="http://www.w3.org/1999/xhtml">Now, you may reasonably wonder why we should bother with all this mess of creating dataset classes. </span><span class="koboSpan" id="kobo.877.3" xmlns="http://www.w3.org/1999/xhtml">There are a </span><span id="dx1-207033"/><span class="koboSpan" id="kobo.878.1" xmlns="http://www.w3.org/1999/xhtml">couple of reasons. </span><span class="koboSpan" id="kobo.878.2" xmlns="http://www.w3.org/1999/xhtml">For one, this allows us to have our data organized and structured in a more orderly manner. </span><span class="koboSpan" id="kobo.878.3" xmlns="http://www.w3.org/1999/xhtml">What is more, using dataset objects, we can create data loaders. </span><span class="koboSpan" id="kobo.878.4" xmlns="http://www.w3.org/1999/xhtml">The </span><code><span class="koboSpan" id="kobo.879.1" xmlns="http://www.w3.org/1999/xhtml">DataLoader</span></code><span class="koboSpan" id="kobo.880.1" xmlns="http://www.w3.org/1999/xhtml"> class can be imported from </span><code><span class="koboSpan" id="kobo.881.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.882.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.883.1" xmlns="http://www.w3.org/1999/xhtml">utils</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.884.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.885.1" xmlns="http://www.w3.org/1999/xhtml">data</span></code><span class="koboSpan" id="kobo.886.1" xmlns="http://www.w3.org/1999/xhtml"> and its objects allow us to easily iterate through batches of data. </span><span class="koboSpan" id="kobo.886.2" xmlns="http://www.w3.org/1999/xhtml">An example may help clarify this.</span></p>
<p><span class="koboSpan" id="kobo.887.1" xmlns="http://www.w3.org/1999/xhtml">Let’s say that we want to iterate over the training dataset in batches of </span><span class="koboSpan" id="kobo.888.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.889.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.889.2" xmlns="http://www.w3.org/1999/xhtml">All we would have to do is to create a data loader with the </span><code><span class="koboSpan" id="kobo.890.1" xmlns="http://www.w3.org/1999/xhtml">tr_data</span></code><span class="koboSpan" id="kobo.891.1" xmlns="http://www.w3.org/1999/xhtml"> dataset specifying the batch size and the fact that we would like it to shuffle the data. </span><span class="koboSpan" id="kobo.891.2" xmlns="http://www.w3.org/1999/xhtml">Then, we could create an iterator object out of the data loader with the </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.892.1" xmlns="http://www.w3.org/1999/xhtml">iter</span></code></span></span><span class="koboSpan" id="kobo.893.1" xmlns="http://www.w3.org/1999/xhtml"> function and iterate over all the batches. </span><span class="koboSpan" id="kobo.893.2" xmlns="http://www.w3.org/1999/xhtml">This is shown in the following piece of code:</span></p>
<pre class="lstlisting" id="listing-304"><span class="koboSpan" id="kobo.894.1" xmlns="http://www.w3.org/1999/xhtml">

from torch.utils.data import DataLoader 
 
tr_loader = iter(DataLoader( 
 
    tr_data, batch_size = 2, shuffle = True)) 
 
print(next(tr_loader))
</span></pre>
<p><span class="koboSpan" id="kobo.895.1" xmlns="http://www.w3.org/1999/xhtml">You may recall from Python 101 that calling </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.896.1" xmlns="http://www.w3.org/1999/xhtml">next</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.897.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.898.1" xmlns="http://www.w3.org/1999/xhtml">tr_loader</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.899.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code></span></span><span class="koboSpan" id="kobo.900.1" xmlns="http://www.w3.org/1999/xhtml"> for the first time would be equivalent to running a </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.901.1" xmlns="http://www.w3.org/1999/xhtml">for</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.902.1" xmlns="http://www.w3.org/1999/xhtml">x</span></code></span><span style="color:#000000"> </span><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.903.1" xmlns="http://www.w3.org/1999/xhtml">in</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.904.1" xmlns="http://www.w3.org/1999/xhtml">tr_loader</span></code></span></span><span class="koboSpan" id="kobo.905.1" xmlns="http://www.w3.org/1999/xhtml"> loop and extracting the value of </span><code><span class="koboSpan" id="kobo.906.1" xmlns="http://www.w3.org/1999/xhtml">x</span></code><span class="koboSpan" id="kobo.907.1" xmlns="http://www.w3.org/1999/xhtml"> in the first iteration. </span><span class="koboSpan" id="kobo.907.2" xmlns="http://www.w3.org/1999/xhtml">This is the output that we get:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.908.1" xmlns="http://www.w3.org/1999/xhtml">

 
[tensor([[-1.2835, -0.4155,  0.4518,  0.6778, -1.3869, -0.4262, -0.1016, 
           1.4012, -0.9625,  1.0038,  0.3946,  0.1961, -0.7455,  0.4267, 
           -0.8352,  0.9295], 
          [-1.4578, -0.4947, -1.1755, -0.4800, -0.3247,  0.7821, -0.0078, 
           -0.5397, -1.0385, -1.3466,  0.4591,  0.5761,  0.2188, -0.1447, 
           0.3534,  0.5055]]), 
 tensor([[0.], 
         [0.]])]
    
</span></pre>
<p><span class="koboSpan" id="kobo.909.1" xmlns="http://www.w3.org/1999/xhtml">And there you have it! </span><span class="koboSpan" id="kobo.909.2" xmlns="http://www.w3.org/1999/xhtml">In each iteration of the data loader, we get an array with the training data in the batch and its </span><span id="dx1-207047"/><span class="koboSpan" id="kobo.910.1" xmlns="http://www.w3.org/1999/xhtml">corresponding array of targets. </span><span class="koboSpan" id="kobo.910.2" xmlns="http://www.w3.org/1999/xhtml">All is shuffled and taken care of by PyTorch automatically. </span><span class="koboSpan" id="kobo.910.3" xmlns="http://www.w3.org/1999/xhtml">Neat, isn’t it? </span><span class="koboSpan" id="kobo.910.4" xmlns="http://www.w3.org/1999/xhtml">That can and will save us a good deal of effort.</span></p>
<p><span class="koboSpan" id="kobo.911.1" xmlns="http://www.w3.org/1999/xhtml">We must say that, in truth, you could technically use data loaders without going through the whole process of defining datasets — just sending in the numpy arrays. </span><span class="koboSpan" id="kobo.911.2" xmlns="http://www.w3.org/1999/xhtml">But it wouldn’t be the most ”PyTorchy” of practices. </span><span class="koboSpan" id="kobo.911.3" xmlns="http://www.w3.org/1999/xhtml">Anyhow, this settles our preparation of datasets.</span></p>
<p><span class="koboSpan" id="kobo.912.1" xmlns="http://www.w3.org/1999/xhtml">In the training process, we will use, as always, the binary cross-entropy loss. </span><span class="koboSpan" id="kobo.912.2" xmlns="http://www.w3.org/1999/xhtml">We can save its function in a variable as follows:</span></p>
<pre class="lstlisting" id="listing-305"><span class="koboSpan" id="kobo.913.1" xmlns="http://www.w3.org/1999/xhtml">

get_loss = F.binary_cross_entropy
</span></pre>
<p><span class="koboSpan" id="kobo.914.1" xmlns="http://www.w3.org/1999/xhtml">Thus, the </span><code><span class="koboSpan" id="kobo.915.1" xmlns="http://www.w3.org/1999/xhtml">get_loss</span></code><span class="koboSpan" id="kobo.916.1" xmlns="http://www.w3.org/1999/xhtml"> function will take a tensor of values between </span><span class="koboSpan" id="kobo.917.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.918.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.919.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.920.1" xmlns="http://www.w3.org/1999/xhtml"> and a matching tensor of labels, and will use them to compute the binary cross entropy loss. </span><span class="koboSpan" id="kobo.920.2" xmlns="http://www.w3.org/1999/xhtml">To see if it works as expected, we may compute a simple loss:</span></p>
<pre class="lstlisting" id="listing-306"><span class="koboSpan" id="kobo.921.1" xmlns="http://www.w3.org/1999/xhtml">

print(get_loss(torch.tensor([1.]), torch.tensor([1.])))
</span></pre>
<p><span class="koboSpan" id="kobo.922.1" xmlns="http://www.w3.org/1999/xhtml">Since the only value in the tensor matches the expected value, we should get a loss of </span><span class="koboSpan" id="kobo.923.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.924.1" xmlns="http://www.w3.org/1999/xhtml"> and, indeed, this instruction returns </span><code><span class="koboSpan" id="kobo.925.1" xmlns="http://www.w3.org/1999/xhtml">tensor</span></code></p>
<p><code><span class="koboSpan" id="kobo.926.1" xmlns="http://www.w3.org/1999/xhtml">(0.)</span></code><span class="koboSpan" id="kobo.927.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.928.1" xmlns="http://www.w3.org/1999/xhtml">We are already preparing ourselves for the training. </span><span class="koboSpan" id="kobo.928.2" xmlns="http://www.w3.org/1999/xhtml">In our case, since our dataset has </span><span class="koboSpan" id="kobo.929.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1000" class="math inline" src="../media/file790.png" style="vertical-align:middle" title="1000"/></span><span class="koboSpan" id="kobo.930.1" xmlns="http://www.w3.org/1999/xhtml"> elements, it could make sense to use a batch size of </span><span class="koboSpan" id="kobo.931.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="100" class="math inline" src="../media/file389.png" style="vertical-align:middle" title="100"/></span><span class="koboSpan" id="kobo.932.1" xmlns="http://www.w3.org/1999/xhtml">, so let us prepare the training data loader to that effect:</span></p>
<pre class="lstlisting" id="listing-307"><span class="koboSpan" id="kobo.933.1" xmlns="http://www.w3.org/1999/xhtml">

tr_loader = DataLoader(tr_data, batch_size = 100, shuffle = True)
</span></pre>
<p><span class="koboSpan" id="kobo.934.1" xmlns="http://www.w3.org/1999/xhtml">As usual, we will rely on the Adam optimizer for the training. </span><span class="koboSpan" id="kobo.934.2" xmlns="http://www.w3.org/1999/xhtml">The optimizer is implemented as a class in the </span><code><span class="koboSpan" id="kobo.935.1" xmlns="http://www.w3.org/1999/xhtml">torch</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.936.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.937.1" xmlns="http://www.w3.org/1999/xhtml">optim</span></code><span class="koboSpan" id="kobo.938.1" xmlns="http://www.w3.org/1999/xhtml"> module, and, in order to use it, we need to specify which parameters it is going to optimize; in our case, that will be the parameters in our model, which we can retrieve with the </span><code><span class="koboSpan" id="kobo.939.1" xmlns="http://www.w3.org/1999/xhtml">parameters</span></code><span class="koboSpan" id="kobo.940.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.940.2" xmlns="http://www.w3.org/1999/xhtml">In addition, we can further configure the optimizer by passing optional arguments for the learning rate, among other adjustable parameters. </span><span class="koboSpan" id="kobo.940.3" xmlns="http://www.w3.org/1999/xhtml">We will use a learning rate of </span><span class="koboSpan" id="kobo.941.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.005" class="math inline" src="../media/file1389.png" style="vertical-align:middle" title="0.005"/></span><span class="koboSpan" id="kobo.942.1" xmlns="http://www.w3.org/1999/xhtml"> and trust the default values of the remaining parameters. </span><span class="koboSpan" id="kobo.942.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we can define our optimizer as follows:</span></p>
<pre class="lstlisting" id="listing-308"><span class="koboSpan" id="kobo.943.1" xmlns="http://www.w3.org/1999/xhtml">

opt = torch.optim.Adam(model.parameters(), lr = 0.005)
</span></pre>
<p><span class="koboSpan" id="kobo.944.1" xmlns="http://www.w3.org/1999/xhtml">Now we have all the </span><span id="dx1-207052"/><span class="koboSpan" id="kobo.945.1" xmlns="http://www.w3.org/1999/xhtml">ingredients ready and we can finally get to the training itself. </span><span class="koboSpan" id="kobo.945.2" xmlns="http://www.w3.org/1999/xhtml">In Keras, this would’ve been as easy as calling a method with a bunch of parameters, but here we have to work the training out ourselves! </span><span class="koboSpan" id="kobo.945.3" xmlns="http://www.w3.org/1999/xhtml">We will begin by defining a function that will perform one full training epoch. </span><span class="koboSpan" id="kobo.945.4" xmlns="http://www.w3.org/1999/xhtml">It will be the following:</span></p>
<pre class="lstlisting" id="listing-309"><span class="koboSpan" id="kobo.946.1" xmlns="http://www.w3.org/1999/xhtml">

def run_epoch(opt, tr_loader): 
 
    # Iterate through the batches. 
 
    </span><span class="koboSpan" id="kobo.946.2" xmlns="http://www.w3.org/1999/xhtml">for data in iter(tr_loader): 
 
        x, y = data # Get the data in the batch. 
 
        </span><span class="koboSpan" id="kobo.946.3" xmlns="http://www.w3.org/1999/xhtml">opt.zero_grad() # Reset the gradients. 
 
        </span><span class="koboSpan" id="kobo.946.4" xmlns="http://www.w3.org/1999/xhtml"># Compute gradients. 
 
        </span><span class="koboSpan" id="kobo.946.5" xmlns="http://www.w3.org/1999/xhtml">loss = get_loss(model(x), y) 
 
        loss.backward() 
 
        opt.step() # Update the weights. 
 
    </span><span class="koboSpan" id="kobo.946.6" xmlns="http://www.w3.org/1999/xhtml">return get_loss(model(tr_data.x), tr_data.y)
</span></pre>
<p><span class="koboSpan" id="kobo.947.1" xmlns="http://www.w3.org/1999/xhtml">The code is pretty much self-explanatory, but a few details deserve clarification. </span><span class="koboSpan" id="kobo.947.2" xmlns="http://www.w3.org/1999/xhtml">We have used two new methods: </span><code><span class="koboSpan" id="kobo.948.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code><span class="koboSpan" id="kobo.949.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.950.1" xmlns="http://www.w3.org/1999/xhtml">step</span></code><span class="koboSpan" id="kobo.951.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.951.2" xmlns="http://www.w3.org/1999/xhtml">Oversimplifying a bit, the </span><code><span class="koboSpan" id="kobo.952.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code><span class="koboSpan" id="kobo.953.1" xmlns="http://www.w3.org/1999/xhtml"> method on </span><code><span class="koboSpan" id="kobo.954.1" xmlns="http://www.w3.org/1999/xhtml">loss</span></code><span class="koboSpan" id="kobo.955.1" xmlns="http://www.w3.org/1999/xhtml"> computes the gradient of the loss by tracing back how it was computed and saving the partial derivatives in the optimizable parameters of the model on which the loss depends. </span><span class="koboSpan" id="kobo.955.2" xmlns="http://www.w3.org/1999/xhtml">This is the famous backpropagation technique that we talked about in </span><em><span class="koboSpan" id="kobo.956.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <em/> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.957.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><span class="koboSpan" id="kobo.958.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.959.1" xmlns="http://www.w3.org/1999/xhtml">What Is Quantum</span></em> <em><span class="koboSpan" id="kobo.960.1" xmlns="http://www.w3.org/1999/xhtml">Machine Learning?</span></em><span class="koboSpan" id="kobo.961.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.961.2" xmlns="http://www.w3.org/1999/xhtml">Then, </span><code><span class="koboSpan" id="kobo.962.1" xmlns="http://www.w3.org/1999/xhtml">opt</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.963.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.964.1" xmlns="http://www.w3.org/1999/xhtml">step</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.965.1" xmlns="http://www.w3.org/1999/xhtml">()</span></code><span class="koboSpan" id="kobo.966.1" xmlns="http://www.w3.org/1999/xhtml"> prompts the optimizer to update the optimizable parameters using the derivatives that </span><code><span class="koboSpan" id="kobo.967.1" xmlns="http://www.w3.org/1999/xhtml">loss</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.968.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.969.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code></span><code><span class="koboSpan" id="kobo.970.1" xmlns="http://www.w3.org/1999/xhtml">()</span></code><span class="koboSpan" id="kobo.971.1" xmlns="http://www.w3.org/1999/xhtml"> computed.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-208">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.972.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.973.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.974.1" xmlns="http://www.w3.org/1999/xhtml">If you are curious about how differentiation works with the </span><code><span class="koboSpan" id="kobo.975.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code><span class="koboSpan" id="kobo.976.1" xmlns="http://www.w3.org/1999/xhtml"> method on PyTorch tensors, we can run a quick example to illustrate. </span><span class="koboSpan" id="kobo.976.2" xmlns="http://www.w3.org/1999/xhtml">We may define two variables, </span><code><span class="koboSpan" id="kobo.977.1" xmlns="http://www.w3.org/1999/xhtml">a</span></code><span class="koboSpan" id="kobo.978.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.979.1" xmlns="http://www.w3.org/1999/xhtml">b</span></code><span class="koboSpan" id="kobo.980.1" xmlns="http://www.w3.org/1999/xhtml">, taking the values </span><span class="koboSpan" id="kobo.981.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.982.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.983.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.984.1" xmlns="http://www.w3.org/1999/xhtml"> respectively as follows:</span></p>
<pre class="lstlisting" id="listing-310"><span class="koboSpan" id="kobo.985.1" xmlns="http://www.w3.org/1999/xhtml">

a = torch.tensor([2.], requires_grad = True) 
 
b = torch.tensor([3.], requires_grad = True)
</span></pre>
<p><span class="koboSpan" id="kobo.986.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we set </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.987.1" xmlns="http://www.w3.org/1999/xhtml">requires_grad</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.988.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.989.1" xmlns="http://www.w3.org/1999/xhtml">True</span></code></span></span><span class="koboSpan" id="kobo.990.1" xmlns="http://www.w3.org/1999/xhtml"> to tell PyTorch that these are variables it should keep track of. </span><span class="koboSpan" id="kobo.990.2" xmlns="http://www.w3.org/1999/xhtml">We may then define the function </span><span class="koboSpan" id="kobo.991.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f(a,b) = a^{2} + b" class="math inline" src="../media/file1426.png" style="vertical-align:middle" title="f(a,b) = a^{2} + b"/></span><span class="koboSpan" id="kobo.992.1" xmlns="http://www.w3.org/1999/xhtml"> and compute its gradient as follows:</span></p>
<pre class="lstlisting" id="listing-311"><span class="koboSpan" id="kobo.993.1" xmlns="http://www.w3.org/1999/xhtml">

f = a**2 + b 
 
f.backward()
</span></pre><span class="koboSpan" id="kobo.994.1" xmlns="http://www.w3.org/1999/xhtml">
We know that </span><span class="koboSpan" id="kobo.995.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \partial f\slash\partial a = (\partial\slash\partial a)a^{2} + b = 2a \right." class="math inline" src="../media/file1427.png" style="vertical-align:middle" title="\left. \partial f\slash\partial a = (\partial\slash\partial a)a^{2} + b = 2a \right."/></span><span class="koboSpan" id="kobo.996.1" xmlns="http://www.w3.org/1999/xhtml">, which in our case is equal to </span><span class="koboSpan" id="kobo.997.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2a = 2 \cdot 2 = 4" class="math inline" src="../media/file1428.png" style="vertical-align:middle" title="2a = 2 \cdot 2 = 4"/></span><span class="koboSpan" id="kobo.998.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.998.2" xmlns="http://www.w3.org/1999/xhtml">When we run the </span><code><span class="koboSpan" id="kobo.999.1" xmlns="http://www.w3.org/1999/xhtml">backward</span></code><span class="koboSpan" id="kobo.1000.1" xmlns="http://www.w3.org/1999/xhtml"> method, PyTorch has already computed this partial derivative for us, and we can access it by calling </span><code><span class="koboSpan" id="kobo.1001.1" xmlns="http://www.w3.org/1999/xhtml">a</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1002.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1003.1" xmlns="http://www.w3.org/1999/xhtml">grad</span></code><span class="koboSpan" id="kobo.1004.1" xmlns="http://www.w3.org/1999/xhtml">, which, as expected, returns </span><code><span class="koboSpan" id="kobo.1005.1" xmlns="http://www.w3.org/1999/xhtml">tensor</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1006.1" xmlns="http://www.w3.org/1999/xhtml">([4.])</span></code><span class="koboSpan" id="kobo.1007.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1007.2" xmlns="http://www.w3.org/1999/xhtml">Analogously, </span><span class="koboSpan" id="kobo.1008.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \partial f\slash\partial b = 1 \right." class="math inline" src="../media/file1429.png" style="vertical-align:middle" title="\left. \partial f\slash\partial b = 1 \right."/></span><span class="koboSpan" id="kobo.1009.1" xmlns="http://www.w3.org/1999/xhtml">, and, as expected, </span><code><span class="koboSpan" id="kobo.1010.1" xmlns="http://www.w3.org/1999/xhtml">b</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1011.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1012.1" xmlns="http://www.w3.org/1999/xhtml">grad</span></code><span class="koboSpan" id="kobo.1013.1" xmlns="http://www.w3.org/1999/xhtml"> returns </span><code><span class="koboSpan" id="kobo.1014.1" xmlns="http://www.w3.org/1999/xhtml">tensor</span></code></span>
<code><span class="koboSpan" id="kobo.1015.1" xmlns="http://www.w3.org/1999/xhtml">([1.])</span></code><span class="koboSpan" id="kobo.1016.1" xmlns="http://www.w3.org/1999/xhtml">.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.1017.1" xmlns="http://www.w3.org/1999/xhtml">In principle, we could train our </span><span id="dx1-207067"/><span class="koboSpan" id="kobo.1018.1" xmlns="http://www.w3.org/1999/xhtml">model by calling </span><code><span class="koboSpan" id="kobo.1019.1" xmlns="http://www.w3.org/1999/xhtml">run_epoch</span></code><span class="koboSpan" id="kobo.1020.1" xmlns="http://www.w3.org/1999/xhtml"> manually as many times as we wanted, but why suffer like that when we can leave Python in charge?</span></p>
<p><span class="koboSpan" id="kobo.1021.1" xmlns="http://www.w3.org/1999/xhtml">Let us define a training loop in which, at each iteration, we will run an epoch and log the training and validation loss obtained over the whole dataset. </span><span class="koboSpan" id="kobo.1021.2" xmlns="http://www.w3.org/1999/xhtml">Instead of fixing a specific number of epochs, we will keep iterating until the validation loss increases — this will be our own version of the early stopping callback that we used in TensorFlow. </span><span class="koboSpan" id="kobo.1021.3" xmlns="http://www.w3.org/1999/xhtml">The following piece of code gets the job done:</span></p>
<pre class="lstlisting" id="listing-312"><span class="koboSpan" id="kobo.1022.1" xmlns="http://www.w3.org/1999/xhtml">

tr_losses = [] 
 
val_losses = [] 
 
while (len(val_losses) &lt; 2 or val_losses[-1] &lt; val_losses[-2]): 
 
    print("EPOCH", len(tr_losses) + 1, end = " ") 
 
    tr_losses.append(float(run_epoch(opt, tr_loader))) 
 
    # ^^ Remember that run_epoch returns the training loss. 
 
    </span><span class="koboSpan" id="kobo.1022.2" xmlns="http://www.w3.org/1999/xhtml">val_losses.append(float( 
 
        get_loss(model(val_data.x), val_data.y))) 
 
    print("| Train loss:", round(tr_losses[-1], 4), end = " ") 
 
    print("| Valid loss:", round(val_losses[-1], 4))
</span></pre>
<p><span class="koboSpan" id="kobo.1023.1" xmlns="http://www.w3.org/1999/xhtml">Notice how, when logging the losses in </span><code><span class="koboSpan" id="kobo.1024.1" xmlns="http://www.w3.org/1999/xhtml">tr_losses</span></code><span class="koboSpan" id="kobo.1025.1" xmlns="http://www.w3.org/1999/xhtml">, we have converted the </span><span id="dx1-207078"/><span class="koboSpan" id="kobo.1026.1" xmlns="http://www.w3.org/1999/xhtml">PyTorch tensors to floats. </span><span class="koboSpan" id="kobo.1026.2" xmlns="http://www.w3.org/1999/xhtml">This is the output that we get after executing this loop:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.1027.1" xmlns="http://www.w3.org/1999/xhtml">

 
EPOCH 1 | Train loss: 0.6727 | Valid loss: 0.6527 
EPOCH 2 | Train loss: 0.638 | Valid loss: 0.6315 
EPOCH 3 | Train loss: 0.5861 | Valid loss: 0.5929 
EPOCH 4 | Train loss: 0.5129 | Valid loss: 0.5277 
EPOCH 5 | Train loss: 0.4244 | Valid loss: 0.4428 
EPOCH 6 | Train loss: 0.3382 | Valid loss: 0.3633 
EPOCH 7 | Train loss: 0.2673 | Valid loss: 0.3024 
EPOCH 8 | Train loss: 0.2198 | Valid loss: 0.2734 
EPOCH 9 | Train loss: 0.1938 | Valid loss: 0.2622 
EPOCH 10 | Train loss: 0.1819 | Valid loss: 0.2616 
EPOCH 11 | Train loss: 0.1769 | Valid loss: 0.2687
    
</span></pre>
<p><span class="koboSpan" id="kobo.1028.1" xmlns="http://www.w3.org/1999/xhtml">An image is worth a thousand words, so, just to get a visual overview of the performance of our training, let us recycle the </span><code><span class="koboSpan" id="kobo.1029.1" xmlns="http://www.w3.org/1999/xhtml">plot_losses</span></code><span class="koboSpan" id="kobo.1030.1" xmlns="http://www.w3.org/1999/xhtml"> function that we had for TensorFlow and run it:</span></p>
<pre class="lstlisting" id="listing-313"><span class="koboSpan" id="kobo.1031.1" xmlns="http://www.w3.org/1999/xhtml">

import matplotlib.pyplot as plt 
 
def plot_losses(tr_loss, val_loss): 
 
    epochs = np.array(range(len(tr_loss))) + 1 
 
    plt.plot(epochs, tr_loss, label = "Training loss") 
 
    plt.plot(epochs, val_loss, label = "Validation loss") 
 
    plt.xlabel("Epoch") 
 
    plt.legend() 
 
    plt.show() 
 
 
 
plot_losses(tr_losses, val_losses)
</span></pre>
<p><span class="koboSpan" id="kobo.1032.1" xmlns="http://www.w3.org/1999/xhtml">The resulting plot can be found in </span><em><span class="koboSpan" id="kobo.1033.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure11.3"><em><span class="koboSpan" id="kobo.1034.1" xmlns="http://www.w3.org/1999/xhtml">11.3</span></em></a><span class="koboSpan" id="kobo.1035.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1035.2" xmlns="http://www.w3.org/1999/xhtml">The plot does show some signs of overfitting, but likely not </span><span id="dx1-207101"/><span class="koboSpan" id="kobo.1036.1" xmlns="http://www.w3.org/1999/xhtml">something to be concerned about; in any case, let’s wait until we get the accuracy over the test dataset.</span></p>
<figure>
<span class="koboSpan" id="kobo.1037.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 11.3: Evolution of the training and validation losses over the training of a classical binary classifier with PyTorch " src="../media/file1430.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure11.3"><strong><span class="koboSpan" id="kobo.1038.1" xmlns="http://www.w3.org/1999/xhtml">Figure 11.3</span></strong><span class="koboSpan" id="kobo.1039.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.1040.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the training and validation losses over the training of a classical binary classifier with PyTorch </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.1041.1" xmlns="http://www.w3.org/1999/xhtml">In order to get the accuracy of our classifier on the training, validation, and test datasets, we can run the following instructions:</span></p>
<pre class="lstlisting" id="listing-314"><span class="koboSpan" id="kobo.1042.1" xmlns="http://www.w3.org/1999/xhtml">

train_acc = accuracy_score( 
 
    (model(tr_data.x) &gt;= 0.5).to(float), tr_data.y) 
 
val_acc = accuracy_score( 
 
    (model(val_data.x) &gt;= 0.5).to(float), val_data.y) 
 
test_acc = accuracy_score( 
 
    (model(test_data.x) &gt;= 0.5).to(float), test_data.y) 
 
print("Training accuracy:", train_acc) 
 
print("Validation accuracy:", val_acc) 
 
print("Test accuracy:", test_acc)
</span></pre>
<p><span class="koboSpan" id="kobo.1043.1" xmlns="http://www.w3.org/1999/xhtml">This returns a </span><span id="dx1-207113"/><span class="koboSpan" id="kobo.1044.1" xmlns="http://www.w3.org/1999/xhtml">training accuracy of </span><span class="koboSpan" id="kobo.1045.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="94\%" class="math inline" src="../media/file1431.png" style="vertical-align:middle" title="94\%"/></span><span class="koboSpan" id="kobo.1046.1" xmlns="http://www.w3.org/1999/xhtml">, a validation accuracy of </span><span class="koboSpan" id="kobo.1047.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="92\%" class="math inline" src="../media/file1432.png" style="vertical-align:middle" title="92\%"/></span><span class="koboSpan" id="kobo.1048.1" xmlns="http://www.w3.org/1999/xhtml">, and a test accuracy of </span><span class="koboSpan" id="kobo.1049.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="96\%" class="math inline" src="../media/file1402.png" style="vertical-align:middle" title="96\%"/></span><span class="koboSpan" id="kobo.1050.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1051.1" xmlns="http://www.w3.org/1999/xhtml">We have just concluded our not-that-short introduction to PyTorch. </span><span class="koboSpan" id="kobo.1051.2" xmlns="http://www.w3.org/1999/xhtml">Let’s go quantum!</span></p>
</section>
</section>
<section class="level3 subsectionHead" data-number="19.3.2" id="building-a-hybrid-binary-classifier-with-qiskit">
<h2 class="subsectionHead" data-number="19.3.2"><span class="titlemark"><span class="koboSpan" id="kobo.1052.1" xmlns="http://www.w3.org/1999/xhtml">11.3.2 </span></span> <span id="x1-20800011.3.2"><span class="koboSpan" id="kobo.1053.1" xmlns="http://www.w3.org/1999/xhtml">Building a hybrid binary classifier with Qiskit</span></span></h2>
<p><span class="koboSpan" id="kobo.1054.1" xmlns="http://www.w3.org/1999/xhtml">In this subsection, we will </span><span id="dx1-208001"/><span class="koboSpan" id="kobo.1055.1" xmlns="http://www.w3.org/1999/xhtml">implement our first hybrid QNN with Qiskit. </span><span class="koboSpan" id="kobo.1055.2" xmlns="http://www.w3.org/1999/xhtml">The process will be fairly straightforward, and we will be able to rely on a good deal of the code that we already have. </span><span class="koboSpan" id="kobo.1055.3" xmlns="http://www.w3.org/1999/xhtml">To get started, let us import the Qiskit package and the ZZ feature map and two-local variational form that come bundled with it:</span></p>
<pre class="lstlisting" id="listing-315"><span class="koboSpan" id="kobo.1056.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit import * 
 
from qiskit.circuit.library import ZZFeatureMap, TwoLocal
</span></pre>
<p><span class="koboSpan" id="kobo.1057.1" xmlns="http://www.w3.org/1999/xhtml">With a QNN, it will be advisable to use smaller datasets in order for the training time to be reasonable on our simulators. </span><span class="koboSpan" id="kobo.1057.2" xmlns="http://www.w3.org/1999/xhtml">We can prepare them, along with the corresponding dataset and data loader objects, as follows:</span></p>
<pre class="lstlisting" id="listing-316"><span class="koboSpan" id="kobo.1058.1" xmlns="http://www.w3.org/1999/xhtml">

x, y = make_classification(n_samples = 500, n_features = 16) 
 
x_tr, x_test, y_tr, y_test = train_test_split(x, y, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, train_size = 0.5) 
 
 
 
tr_data = NumpyDataset(x_tr, y_tr) 
 
val_data = NumpyDataset(x_val, y_val) 
 
test_data = NumpyDataset(x_test, y_test) 
 
 
 
tr_loader = DataLoader(tr_data, batch_size = 20, shuffle = True)
</span></pre>
<p><span class="koboSpan" id="kobo.1059.1" xmlns="http://www.w3.org/1999/xhtml">Our quantum layer will be a simple </span><span class="koboSpan" id="kobo.1060.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.1061.1" xmlns="http://www.w3.org/1999/xhtml">-qubit QNN with one instance of the ZZ feature map and the two-local </span><span id="dx1-208013"/><span class="koboSpan" id="kobo.1062.1" xmlns="http://www.w3.org/1999/xhtml">variational form. </span><span class="koboSpan" id="kobo.1062.2" xmlns="http://www.w3.org/1999/xhtml">Thus, the components that we will use in our QNN circuit will be the following:</span></p>
<pre class="lstlisting" id="listing-317"><span class="koboSpan" id="kobo.1063.1" xmlns="http://www.w3.org/1999/xhtml">

zzfm = ZZFeatureMap(2) 
 
twolocal = TwoLocal(2, [’ry’,’rz’], ’cz’, ’linear’, reps = 1)
</span></pre>
<p><span class="koboSpan" id="kobo.1064.1" xmlns="http://www.w3.org/1999/xhtml">Here, we have instantiated the two-local form as in </span><em><span class="koboSpan" id="kobo.1065.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch019.xhtml#x1-18100010"><em><span class="koboSpan" id="kobo.1066.1" xmlns="http://www.w3.org/1999/xhtml">10</span></em></a><span class="koboSpan" id="kobo.1067.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1068.1" xmlns="http://www.w3.org/1999/xhtml">Quantum</span></em> <em><span class="koboSpan" id="kobo.1069.1" xmlns="http://www.w3.org/1999/xhtml">Neural Networks</span></em><span class="koboSpan" id="kobo.1070.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1071.1" xmlns="http://www.w3.org/1999/xhtml">Also, just as we did in the previous chapter, we could use the </span><code><span class="koboSpan" id="kobo.1072.1" xmlns="http://www.w3.org/1999/xhtml">TwoLayerQNN</span></code><span class="koboSpan" id="kobo.1073.1" xmlns="http://www.w3.org/1999/xhtml"> class in order to generate our quantum neural network according to our specifications. </span><span class="koboSpan" id="kobo.1073.2" xmlns="http://www.w3.org/1999/xhtml">We may import it as follows:</span></p>
<pre class="lstlisting" id="listing-318"><span class="koboSpan" id="kobo.1074.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.neural_networks import TwoLayerQNN
</span></pre>
<p><span class="koboSpan" id="kobo.1075.1" xmlns="http://www.w3.org/1999/xhtml">We are now ready to define our model architecture with PyTorch. </span><span class="koboSpan" id="kobo.1075.2" xmlns="http://www.w3.org/1999/xhtml">Its structure will be analogous to that of a classical architecture.</span><span id="dx1-208017"/><span class="koboSpan" id="kobo.1076.1" xmlns="http://www.w3.org/1999/xhtml"> The only difference is that we will have to define a quantum neural network object in the initializer, and we will have to rely on the </span><code><span class="koboSpan" id="kobo.1077.1" xmlns="http://www.w3.org/1999/xhtml">TorchConnector</span></code><span class="koboSpan" id="kobo.1078.1" xmlns="http://www.w3.org/1999/xhtml"> in order to use the QNN in the </span><code><span class="koboSpan" id="kobo.1079.1" xmlns="http://www.w3.org/1999/xhtml">forward</span></code><span class="koboSpan" id="kobo.1080.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.1080.2" xmlns="http://www.w3.org/1999/xhtml">This </span><code><span class="koboSpan" id="kobo.1081.1" xmlns="http://www.w3.org/1999/xhtml">TorchConnector</span></code><span class="koboSpan" id="kobo.1082.1" xmlns="http://www.w3.org/1999/xhtml"> is analogous to the </span><code><span class="koboSpan" id="kobo.1083.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1084.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1085.1" xmlns="http://www.w3.org/1999/xhtml">qnn</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1086.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1087.1" xmlns="http://www.w3.org/1999/xhtml">KerasLayer</span></code><span class="koboSpan" id="kobo.1088.1" xmlns="http://www.w3.org/1999/xhtml"> that we used in PennyLane — only that it’s for Qiskit and PyTorch! </span><span class="koboSpan" id="kobo.1088.2" xmlns="http://www.w3.org/1999/xhtml">This is how we may then define our hybrid network and instantiate a model:</span></p>
<pre class="lstlisting" id="listing-319"><span class="koboSpan" id="kobo.1089.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.connectors import TorchConnector 
 
from qiskit.providers.aer import AerSimulator 
 
 
 
class HybridQNN(nn.Module): 
 
 
 
    def __init__(self): 
 
 
 
        # Initialize super class. 
 
        </span><span class="koboSpan" id="kobo.1089.2" xmlns="http://www.w3.org/1999/xhtml">super(HybridQNN, self).__init__() 
 
 
 
        # Declare the layers that we will use. 
 
        </span><span class="koboSpan" id="kobo.1089.3" xmlns="http://www.w3.org/1999/xhtml">qnn = TwoLayerQNN(2, zzfm, twolocal, input_gradients = True, 
 
            quantum_instance = AerSimulator(method="statevector")) 
 
        self.layer1 = nn.Linear(16, 2) 
 
        self.qnn = TorchConnector(qnn) 
 
        self.final_layer = nn.Linear(1,1) 
 
 
 
    def forward(self, x): 
 
        x = torch.sigmoid(self.layer1(x)) 
 
        x = self.qnn(x) 
 
        x = torch.sigmoid(self.final_layer(x)) 
 
        return x 
 
 
 
model = HybridQNN()
</span></pre>
<p><span class="koboSpan" id="kobo.1090.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we’ve passed the optional argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.1091.1" xmlns="http://www.w3.org/1999/xhtml">input_gradients</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1092.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1093.1" xmlns="http://www.w3.org/1999/xhtml">True</span></code></span></span><span class="koboSpan" id="kobo.1094.1" xmlns="http://www.w3.org/1999/xhtml"> to the </span><code><span class="koboSpan" id="kobo.1095.1" xmlns="http://www.w3.org/1999/xhtml">TwoLayer</span></code><span class="koboSpan" id="kobo.1096.1" xmlns="http://www.w3.org/1999/xhtml"> initializer; that is required for the PyTorch interface to work properly. </span><span class="koboSpan" id="kobo.1096.2" xmlns="http://www.w3.org/1999/xhtml">Apart from that, the construction of the </span><span id="dx1-208042"/><span class="koboSpan" id="kobo.1097.1" xmlns="http://www.w3.org/1999/xhtml">quantum neural network was fully analogous to what we did in </span><em><span class="koboSpan" id="kobo.1098.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch019.xhtml#x1-18100010"><em><span class="koboSpan" id="kobo.1099.1" xmlns="http://www.w3.org/1999/xhtml">10</span></em></a><span class="koboSpan" id="kobo.1100.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1101.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Neural Networks</span></em><span class="koboSpan" id="kobo.1102.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1102.2" xmlns="http://www.w3.org/1999/xhtml">A detail that perhaps deserves an explanation is the reason why we have included a final classical layer after the quantum one. </span><span class="koboSpan" id="kobo.1102.3" xmlns="http://www.w3.org/1999/xhtml">This is because our QNN will return values between </span><span class="koboSpan" id="kobo.1103.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.1104.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1105.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1106.1" xmlns="http://www.w3.org/1999/xhtml">, not between </span><span class="koboSpan" id="kobo.1107.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.1108.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1109.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1110.1" xmlns="http://www.w3.org/1999/xhtml">; by including this final layer followed by the classical sigmoid activation function, we can ensure that the output of our network will be bounded between </span><span class="koboSpan" id="kobo.1111.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.1112.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1113.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1114.1" xmlns="http://www.w3.org/1999/xhtml">, as we expect.</span></p>
<p><span class="koboSpan" id="kobo.1115.1" xmlns="http://www.w3.org/1999/xhtml">Now all we have left to do before we can start the training is prepare the optimizer, and send the model parameters to it:</span></p>
<pre class="lstlisting" id="listing-320"><span class="koboSpan" id="kobo.1116.1" xmlns="http://www.w3.org/1999/xhtml">

opt = torch.optim.Adam(model.parameters(), lr = 0.005)
</span></pre>
<p><span class="koboSpan" id="kobo.1117.1" xmlns="http://www.w3.org/1999/xhtml">And we can simply reuse the </span><code><span class="koboSpan" id="kobo.1118.1" xmlns="http://www.w3.org/1999/xhtml">run_epoch</span></code><span class="koboSpan" id="kobo.1119.1" xmlns="http://www.w3.org/1999/xhtml"> function to complete the training, just as we did in the previous subsection:</span></p>
<pre class="lstlisting" id="listing-321"><span class="koboSpan" id="kobo.1120.1" xmlns="http://www.w3.org/1999/xhtml">

tr_losses = [] 
 
val_losses = [] 
 
 
 
while (len(val_losses) &lt; 2 or val_losses[-1] &lt; val_losses[-2]): 
 
    print("EPOCH", len(tr_losses) + 1, end = " ") 
 
    tr_losses.append(float(run_epoch(opt, tr_loader))) 
 
    val_losses.append(float(get_loss(model(val_data.x), val_data.y))) 
 
    print("| Train loss:", round(tr_losses[-1], 4), end = " ") 
 
    print("| Valid loss:", round(val_losses[-1], 4))
</span></pre>
<p><span class="koboSpan" id="kobo.1121.1" xmlns="http://www.w3.org/1999/xhtml">This is the </span><span id="dx1-208053"/><span class="koboSpan" id="kobo.1122.1" xmlns="http://www.w3.org/1999/xhtml">output that the execution will yield:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.1123.1" xmlns="http://www.w3.org/1999/xhtml">

 
EPOCH 1 | Train loss: 0.6908 | Valid loss: 0.696 
EPOCH 2 | Train loss: 0.6872 | Valid loss: 0.691 
EPOCH 3 | Train loss: 0.6756 | Valid loss: 0.6811 
EPOCH 4 | Train loss: 0.6388 | Valid loss: 0.6455 
EPOCH 5 | Train loss: 0.5661 | Valid loss: 0.5837 
EPOCH 6 | Train loss: 0.5099 | Valid loss: 0.5424 
EPOCH 7 | Train loss: 0.4692 | Valid loss: 0.5201 
EPOCH 8 | Train loss: 0.4425 | Valid loss: 0.5014 
EPOCH 9 | Train loss: 0.4204 | Valid loss: 0.4947 
EPOCH 10 | Train loss: 0.4019 | Valid loss: 0.4923 
EPOCH 11 | Train loss: 0.3862 | Valid loss: 0.4774 
EPOCH 12 | Train loss: 0.3716 | Valid loss: 0.4668 
EPOCH 13 | Train loss: 0.3575 | Valid loss: 0.451 
EPOCH 14 | Train loss: 0.3446 | Valid loss: 0.4349 
EPOCH 15 | Train loss: 0.3332 | Valid loss: 0.4323 
EPOCH 16 | Train loss: 0.3229 | Valid loss: 0.4259 
EPOCH 17 | Train loss: 0.3141 | Valid loss: 0.4253 
EPOCH 18 | Train loss: 0.3055 | Valid loss: 0.422 
EPOCH 19 | Train loss: 0.2997 | Valid loss: 0.4152 
EPOCH 20 | Train loss: 0.2954 | Valid loss: 0.4211
    
</span></pre>
<p><span class="koboSpan" id="kobo.1124.1" xmlns="http://www.w3.org/1999/xhtml">As before, we can get a plot of the loss evolution as follows:</span></p>
<pre class="lstlisting" id="listing-322"><span class="koboSpan" id="kobo.1125.1" xmlns="http://www.w3.org/1999/xhtml">

plot_losses(tr_losses, val_losses)
</span></pre>
<p><span class="koboSpan" id="kobo.1126.1" xmlns="http://www.w3.org/1999/xhtml">This </span><span id="dx1-208076"/><span class="koboSpan" id="kobo.1127.1" xmlns="http://www.w3.org/1999/xhtml">returns the plot shown in </span><em><span class="koboSpan" id="kobo.1128.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure11.4"><em><span class="koboSpan" id="kobo.1129.1" xmlns="http://www.w3.org/1999/xhtml">11.4</span></em></a><span class="koboSpan" id="kobo.1130.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1130.2" xmlns="http://www.w3.org/1999/xhtml">There does seem to be some overfitting, which could likely be fixed by giving more data to the classifier.</span></p>
<figure>
<span class="koboSpan" id="kobo.1131.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 11.4: Evolution of the training and validation losses over the training of a hybrid binary classifier with PyTorch " src="../media/file1433.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure11.4"><strong><span class="koboSpan" id="kobo.1132.1" xmlns="http://www.w3.org/1999/xhtml">Figure 11.4</span></strong><span class="koboSpan" id="kobo.1133.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.1134.1" xmlns="http://www.w3.org/1999/xhtml">Evolution of the training and validation losses over the training of a hybrid binary classifier with PyTorch </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.1135.1" xmlns="http://www.w3.org/1999/xhtml">In any case, let’s compute the training, validation, and test accuracies to get a better insight into the performance of the classifier. </span><span class="koboSpan" id="kobo.1135.2" xmlns="http://www.w3.org/1999/xhtml">We may do that by executing the following instructions:</span></p>
<pre class="lstlisting" id="listing-323"><span class="koboSpan" id="kobo.1136.1" xmlns="http://www.w3.org/1999/xhtml">

tr_acc = accuracy_score( 
 
    (model(tr_data.x) &gt;= 0.5).to(float), tr_data.y) 
 
val_acc = accuracy_score( 
 
    (model(val_data.x) &gt;= 0.5).to(float), val_data.y) 
 
test_acc = accuracy_score( 
 
    (model(test_data.x) &gt;= 0.5).to(float), test_data.y) 
 
print("Training accuracy:", tr_acc) 
 
print("Validation accuracy:", val_acc) 
 
print("Test accuracy:", test_acc)
</span></pre>
<p><span class="koboSpan" id="kobo.1137.1" xmlns="http://www.w3.org/1999/xhtml">Upon running this, we get a </span><span id="dx1-208088"/><span class="koboSpan" id="kobo.1138.1" xmlns="http://www.w3.org/1999/xhtml">training accuracy of </span><span class="koboSpan" id="kobo.1139.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="92\%" class="math inline" src="../media/file1432.png" style="vertical-align:middle" title="92\%"/></span><span class="koboSpan" id="kobo.1140.1" xmlns="http://www.w3.org/1999/xhtml">, a validation accuracy of </span><span class="koboSpan" id="kobo.1141.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="86\%" class="math inline" src="../media/file1434.png" style="vertical-align:middle" title="86\%"/></span><span class="koboSpan" id="kobo.1142.1" xmlns="http://www.w3.org/1999/xhtml">, and a test accuracy of </span><span class="koboSpan" id="kobo.1143.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="74\%" class="math inline" src="../media/file1435.png" style="vertical-align:middle" title="74\%"/></span><span class="koboSpan" id="kobo.1144.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1144.2" xmlns="http://www.w3.org/1999/xhtml">This confirms our suspicions regarding the existence of overfitting. </span><span class="koboSpan" id="kobo.1144.3" xmlns="http://www.w3.org/1999/xhtml">As in other cases, should we want to fix this, we could try training the model with additional data, for instance.</span></p>
<p><span class="koboSpan" id="kobo.1145.1" xmlns="http://www.w3.org/1999/xhtml">Of course, all that we’ve learned about how to train hybrid QNNs with PyTorch and Qiskit also works for ordinary QNNs. </span><span class="koboSpan" id="kobo.1145.2" xmlns="http://www.w3.org/1999/xhtml">If you want to train a simple Qiskit QNN using PyTorch, you’ve just learned how to do it; all it will take is defining a model with no classical layers.</span></p>
<p><span class="koboSpan" id="kobo.1146.1" xmlns="http://www.w3.org/1999/xhtml">This concludes our study of hybrid neural networks in Qiskit. </span><span class="koboSpan" id="kobo.1146.2" xmlns="http://www.w3.org/1999/xhtml">But we still have one thing left before bringing this section to an end.</span></p>
<p><span class="koboSpan" id="kobo.1147.1" xmlns="http://www.w3.org/1999/xhtml">One of the advantages of Qiskit is its tight integration with IBM’s quantum hardware. </span><span class="koboSpan" id="kobo.1147.2" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, as was the case in our study of quantum optimization, queueing times make the training of any QNN model on real hardware unfeasible through the usual interfaces to IBM’s hardware — that is, just using a real hardware backend, as we discussed in </span><em><span class="koboSpan" id="kobo.1148.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch009.xhtml#x1-400002"><em><span class="koboSpan" id="kobo.1149.1" xmlns="http://www.w3.org/1999/xhtml">2</span></em></a><span class="koboSpan" id="kobo.1150.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1151.1" xmlns="http://www.w3.org/1999/xhtml">The</span></em> <em><span class="koboSpan" id="kobo.1152.1" xmlns="http://www.w3.org/1999/xhtml">Tools of the Trade in Quantum Computing</span></em><span class="koboSpan" id="kobo.1153.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1153.2" xmlns="http://www.w3.org/1999/xhtml">Thankfully, there’s a better way.</span></p>
</section>
<section class="level3 subsectionHead" data-number="19.3.3" id="training-qiskit-qnns-with-runtime">
<h2 class="subsectionHead" data-number="19.3.3"><span class="titlemark"><span class="koboSpan" id="kobo.1154.1" xmlns="http://www.w3.org/1999/xhtml">11.3.3 </span></span> <span id="x1-20900011.3.3"><span class="koboSpan" id="kobo.1155.1" xmlns="http://www.w3.org/1999/xhtml">Training Qiskit QNNs with Runtime</span></span></h2>
<p><span class="koboSpan" id="kobo.1156.1" xmlns="http://www.w3.org/1999/xhtml">Using Qiskit’s </span><span id="dx1-209001"/><span class="koboSpan" id="kobo.1157.1" xmlns="http://www.w3.org/1999/xhtml">Runtime service, as we did in </span><em><span class="koboSpan" id="kobo.1158.1" xmlns="http://www.w3.org/1999/xhtml">Chapters</span></em> <a href="ch013.xhtml#x1-940005"><em><span class="koboSpan" id="kobo.1159.1" xmlns="http://www.w3.org/1999/xhtml">5</span></em></a><span class="koboSpan" id="kobo.1160.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.1161.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><span class="koboSpan" id="kobo.1162.1" xmlns="http://www.w3.org/1999/xhtml">, we can effectively train any QNN model defined in PyTorch through a Qiskit Torch connector on any of the devices and simulators provided by IBM Quantum. </span><span class="koboSpan" id="kobo.1162.2" xmlns="http://www.w3.org/1999/xhtml">All it takes is waiting on a single queue, and the whole training process is executed as a unit — with all the executions on quantum hardware included. </span><span class="koboSpan" id="kobo.1162.3" xmlns="http://www.w3.org/1999/xhtml">The folks at IBM refer to this use case of Qiskit Runtime as ”Torch Runtime.”</span></p>
<p><span class="koboSpan" id="kobo.1163.1" xmlns="http://www.w3.org/1999/xhtml">That is very convenient. </span><span class="koboSpan" id="kobo.1163.2" xmlns="http://www.w3.org/1999/xhtml">However, we must warn you that, at the time of writing, the queuing times to run these Torch Runtime programs can be somewhat long: around the order of a few hours. </span><span class="koboSpan" id="kobo.1163.3" xmlns="http://www.w3.org/1999/xhtml">Also, you should keep in mind that — again, at the time of writing — this service enables you to train QNNs defined on PyTorch, but not hybrid QNNs! </span><span class="koboSpan" id="kobo.1163.4" xmlns="http://www.w3.org/1999/xhtml">That is, your PyTorch model should not have any classical layers whatsoever.</span></p>
<p><span class="koboSpan" id="kobo.1164.1" xmlns="http://www.w3.org/1999/xhtml">We will train a </span><span id="dx1-209002"/><span class="koboSpan" id="kobo.1165.1" xmlns="http://www.w3.org/1999/xhtml">simple QNN model on a real device. </span><span class="koboSpan" id="kobo.1165.2" xmlns="http://www.w3.org/1999/xhtml">As usual, we should firstly load our IBMQ account and pick a device. </span><span class="koboSpan" id="kobo.1165.3" xmlns="http://www.w3.org/1999/xhtml">We will pick the least busy device among all the real devices with at least four qubits:</span></p>
<pre class="lstlisting" id="listing-324"><span class="koboSpan" id="kobo.1166.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.providers.ibmq import * 
 
 
 
provider = IBMQ.load_account() 
 
dev_list = provider.backends( 
 
    filters = lambda x: x.configuration().n_qubits &gt;= 4, 
 
                        simulator = False) 
 
 
 
dev = least_busy(dev_list)
</span></pre>
<p><span class="koboSpan" id="kobo.1167.1" xmlns="http://www.w3.org/1999/xhtml">We may define a simple QNN model with the PyTorch connector as follows:</span></p>
<pre class="lstlisting" id="listing-325"><span class="koboSpan" id="kobo.1168.1" xmlns="http://www.w3.org/1999/xhtml">

class QiskitQNN(nn.Module): 
 
 
 
    def __init__(self): 
 
 
 
        super(QiskitQNN, self).__init__() 
 
 
 
        qnn = TwoLayerQNN(2, zzfm, twolocal, input_gradients = True) 
 
        self.qnn = TorchConnector(qnn) 
 
 
 
    def forward(self, x): 
 
        x = self.qnn(x) 
 
        return x 
 
 
 
model = QiskitQNN()
</span></pre>
<p><span class="koboSpan" id="kobo.1169.1" xmlns="http://www.w3.org/1999/xhtml">Then, we may </span><span id="dx1-209025"/><span class="koboSpan" id="kobo.1170.1" xmlns="http://www.w3.org/1999/xhtml">generate some data on which to train this model using the </span><code><span class="koboSpan" id="kobo.1171.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.1172.1" xmlns="http://www.w3.org/1999/xhtml"> function:</span></p>
<pre class="lstlisting" id="listing-326"><span class="koboSpan" id="kobo.1173.1" xmlns="http://www.w3.org/1999/xhtml">

x, y = make_classification(n_samples = 100, n_features = 2, 
 
    n_clusters_per_class = 1, n_informative = 1, n_redundant = 1) 
 
x_tr, x_test, y_tr, y_test = train_test_split(x, y, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, 
 
    train_size = 0.5) 
 
tr_data = NumpyDataset(x_tr, y_tr) 
 
val_data = NumpyDataset(x_val, y_val) 
 
test_data = NumpyDataset(x_test, y_test)
</span></pre>
<p><span class="koboSpan" id="kobo.1174.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have adjusted some of the parameters of the </span><code><span class="koboSpan" id="kobo.1175.1" xmlns="http://www.w3.org/1999/xhtml">make_classification</span></code><span class="koboSpan" id="kobo.1176.1" xmlns="http://www.w3.org/1999/xhtml"> function in order to comply with its requirements (check its documentation at </span><a class="url" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"><span class="koboSpan" id="kobo.1177.1" xmlns="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html</span></a><span class="koboSpan" id="kobo.1178.1" xmlns="http://www.w3.org/1999/xhtml"> for more details).</span></p>
<p><span class="koboSpan" id="kobo.1179.1" xmlns="http://www.w3.org/1999/xhtml">Our model should return values between </span><span class="koboSpan" id="kobo.1180.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.1181.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1182.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1183.1" xmlns="http://www.w3.org/1999/xhtml">, but the observable that we have chosen for our circuit — the default one, the parity observable (check </span><em><span class="koboSpan" id="kobo.1184.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch019.xhtml#x1-18100010"><em><span class="koboSpan" id="kobo.1185.1" xmlns="http://www.w3.org/1999/xhtml">10</span></em></a><span class="koboSpan" id="kobo.1186.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1187.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Neural Networks</span></em><span class="koboSpan" id="kobo.1188.1" xmlns="http://www.w3.org/1999/xhtml">, for reference) — returns two possible values: </span><span class="koboSpan" id="kobo.1189.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1190.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><span class="koboSpan" id="kobo.1191.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.1192.1" xmlns="http://www.w3.org/1999/xhtml">, not </span><span class="koboSpan" id="kobo.1193.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.1194.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1195.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1196.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1196.2" xmlns="http://www.w3.org/1999/xhtml">Thus we need to update the targets mapping </span><span class="koboSpan" id="kobo.1197.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 0\mapsto - 1 \right." class="math inline" src="../media/file1436.png" style="vertical-align:middle" title="\left. 0\mapsto - 1 \right."/></span><span class="koboSpan" id="kobo.1198.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1199.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 1\mapsto 1 \right." class="math inline" src="../media/file1437.png" style="vertical-align:middle" title="\left. 1\mapsto 1 \right."/></span><span class="koboSpan" id="kobo.1200.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1200.2" xmlns="http://www.w3.org/1999/xhtml">This can be done with the following instructions:</span></p>
<pre class="lstlisting" id="listing-327"><span class="koboSpan" id="kobo.1201.1" xmlns="http://www.w3.org/1999/xhtml">

tr_data.y = 2 * (tr_data.y - 1/2) 
 
val_data.y = 2 * (val_data.y - 1/2) 
 
test_data.y = 2 * (test_data.y - 1/2)
</span></pre>
<p><span class="koboSpan" id="kobo.1202.1" xmlns="http://www.w3.org/1999/xhtml">Let us now set up some data loaders for the training, validation, and test data:</span></p>
<pre class="lstlisting" id="listing-328"><span class="koboSpan" id="kobo.1203.1" xmlns="http://www.w3.org/1999/xhtml">

tr_loader = DataLoader(tr_data, batch_size = 20, shuffle = True) 
 
val_loader = DataLoader(val_data) 
 
test_loader = DataLoader(test_data)
</span></pre>
<p><span class="koboSpan" id="kobo.1204.1" xmlns="http://www.w3.org/1999/xhtml">And the only </span><span id="dx1-209040"/><span class="koboSpan" id="kobo.1205.1" xmlns="http://www.w3.org/1999/xhtml">ingredients that we have left to define are the optimizer and the loss function. </span><span class="koboSpan" id="kobo.1205.2" xmlns="http://www.w3.org/1999/xhtml">We can still rely on Adam as an optimizer, but the binary cross entropy loss will no longer work since our labels are now </span><span class="koboSpan" id="kobo.1206.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.1207.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1208.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1209.1" xmlns="http://www.w3.org/1999/xhtml"> instead of </span><span class="koboSpan" id="kobo.1210.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.1211.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.1212.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1213.1" xmlns="http://www.w3.org/1999/xhtml">; thus, we will use the mean squared error loss instead:</span></p>
<pre class="lstlisting" id="listing-329"><span class="koboSpan" id="kobo.1214.1" xmlns="http://www.w3.org/1999/xhtml">

get_loss = F.mse_loss 
 
opt = torch.optim.Adam(model.parameters(), lr = 0.005)
</span></pre>
<p><span class="koboSpan" id="kobo.1215.1" xmlns="http://www.w3.org/1999/xhtml">In order to be able to use our model with Torch Runtime, we will have to define a Torch Runtime Client, </span><code><span class="koboSpan" id="kobo.1216.1" xmlns="http://www.w3.org/1999/xhtml">client</span></code><span class="koboSpan" id="kobo.1217.1" xmlns="http://www.w3.org/1999/xhtml">, specifying a few self-explanatory parameters. </span><span class="koboSpan" id="kobo.1217.2" xmlns="http://www.w3.org/1999/xhtml">This is done as follows:</span></p>
<pre class="lstlisting" id="listing-330"><span class="koboSpan" id="kobo.1218.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.runtime import TorchRuntimeClient 
 
 
 
client = TorchRuntimeClient(provider = provider, backend = dev, 
 
    model = model, optimizer = opt, loss_func = get_loss, 
 
    epochs = 5)
</span></pre>
<p><span class="koboSpan" id="kobo.1219.1" xmlns="http://www.w3.org/1999/xhtml">We have set the number of epochs to </span><span class="koboSpan" id="kobo.1220.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="5" class="math inline" src="../media/file296.png" style="vertical-align:middle" title="5"/></span><span class="koboSpan" id="kobo.1221.1" xmlns="http://www.w3.org/1999/xhtml"> in order to get some quick results, but feel free to increase it.</span></p>
<p><span class="koboSpan" id="kobo.1222.1" xmlns="http://www.w3.org/1999/xhtml">And now this is the instruction that we need to execute if we want to train our model:</span></p>
<pre class="lstlisting" id="listing-331"><span class="koboSpan" id="kobo.1223.1" xmlns="http://www.w3.org/1999/xhtml">

result = client.fit(train_loader = tr_loader, val_loader = val_loader)
</span></pre>
<p><span class="koboSpan" id="kobo.1224.1" xmlns="http://www.w3.org/1999/xhtml">This will likely take a while because of the queue time required to run a Torch Runtime program. </span><span class="koboSpan" id="kobo.1224.2" xmlns="http://www.w3.org/1999/xhtml">Sit back and relax. </span><span class="koboSpan" id="kobo.1224.3" xmlns="http://www.w3.org/1999/xhtml">Eventually, your model will be trained. </span><span class="koboSpan" id="kobo.1224.4" xmlns="http://www.w3.org/1999/xhtml">Once that happens, you can get information about the training from the </span><code><span class="koboSpan" id="kobo.1225.1" xmlns="http://www.w3.org/1999/xhtml">result</span></code><span class="koboSpan" id="kobo.1226.1" xmlns="http://www.w3.org/1999/xhtml"> object, whose type is </span><code><span class="koboSpan" id="kobo.1227.1" xmlns="http://www.w3.org/1999/xhtml">TorchRuntimeResult</span></code><span class="koboSpan" id="kobo.1228.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1228.2" xmlns="http://www.w3.org/1999/xhtml">In particular, the attributes </span><code><span class="koboSpan" id="kobo.1229.1" xmlns="http://www.w3.org/1999/xhtml">train_history</span></code><span class="koboSpan" id="kobo.1230.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1231.1" xmlns="http://www.w3.org/1999/xhtml">val_history</span></code><span class="koboSpan" id="kobo.1232.1" xmlns="http://www.w3.org/1999/xhtml"> will show you the evolution of the training and validation losses throughout the training process.</span></p>
<p><span class="koboSpan" id="kobo.1233.1" xmlns="http://www.w3.org/1999/xhtml">If you’d like to get the model’s prediction on some data — for instance, the test dataset — all you have to do is send a data loader object with the data to the </span><code><span class="koboSpan" id="kobo.1234.1" xmlns="http://www.w3.org/1999/xhtml">predict</span></code><span class="koboSpan" id="kobo.1235.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.1235.2" xmlns="http://www.w3.org/1999/xhtml">And this is how you can get your predictions:</span></p>
<pre class="lstlisting" id="listing-332"><span class="koboSpan" id="kobo.1236.1" xmlns="http://www.w3.org/1999/xhtml">

pred = client.predict(test_loader).prediction
</span></pre>
<p><span class="koboSpan" id="kobo.1237.1" xmlns="http://www.w3.org/1999/xhtml">Don’t expect to get great results! </span><span class="koboSpan" id="kobo.1237.2" xmlns="http://www.w3.org/1999/xhtml">The </span><span id="dx1-209050"/><span class="koboSpan" id="kobo.1238.1" xmlns="http://www.w3.org/1999/xhtml">model that we have defined is not very powerful and we only trained for a few epochs. </span><span class="koboSpan" id="kobo.1238.2" xmlns="http://www.w3.org/1999/xhtml">As if that were not enough, when you run on real hardware, there’s always the issue of having to deal with noise. </span><span class="koboSpan" id="kobo.1238.3" xmlns="http://www.w3.org/1999/xhtml">Of course, you could use error mitigation as we did back in </span><em><span class="koboSpan" id="kobo.1239.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.1240.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><span class="koboSpan" id="kobo.1241.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1242.1" xmlns="http://www.w3.org/1999/xhtml">VQE: Variational Quantum Eigensolver</span></em><span class="koboSpan" id="kobo.1243.1" xmlns="http://www.w3.org/1999/xhtml">, by setting </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.1244.1" xmlns="http://www.w3.org/1999/xhtml">measurement_error_mitigation</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1245.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1246.1" xmlns="http://www.w3.org/1999/xhtml">True</span></code></span></span><span class="koboSpan" id="kobo.1247.1" xmlns="http://www.w3.org/1999/xhtml"> in the </span><code><span class="koboSpan" id="kobo.1248.1" xmlns="http://www.w3.org/1999/xhtml">TorchRuntimeClient</span></code><span class="koboSpan" id="kobo.1249.1" xmlns="http://www.w3.org/1999/xhtml"> instantiation.</span></p>
</section>
<section class="level3 subsectionHead" data-number="19.3.4" id="a-glimpse-into-the-future">
<h2 class="subsectionHead" data-number="19.3.4"><span class="titlemark"><span class="koboSpan" id="kobo.1250.1" xmlns="http://www.w3.org/1999/xhtml">11.3.4 </span></span> <span id="x1-21000011.3.4"><span class="koboSpan" id="kobo.1251.1" xmlns="http://www.w3.org/1999/xhtml">A glimpse into the future</span></span></h2>
<p><span class="koboSpan" id="kobo.1252.1" xmlns="http://www.w3.org/1999/xhtml">The way in which we have </span><span id="dx1-210001"/><span class="koboSpan" id="kobo.1253.1" xmlns="http://www.w3.org/1999/xhtml">worked with Torch Runtime is supported by IBM at the time of writing, but change is the only constant in Qiskit land.</span></p>
<p><span class="koboSpan" id="kobo.1254.1" xmlns="http://www.w3.org/1999/xhtml">In the future, Torch Runtime will no longer be supported and, instead, it will be necessary to use a different interface in order to train quantum neural networks with Qiskit Runtime. </span><span class="koboSpan" id="kobo.1254.2" xmlns="http://www.w3.org/1999/xhtml">This interface — which, at the time of writing, is still in active development — will rely on the </span><code><span class="koboSpan" id="kobo.1255.1" xmlns="http://www.w3.org/1999/xhtml">Sampler</span></code><span class="koboSpan" id="kobo.1256.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1257.1" xmlns="http://www.w3.org/1999/xhtml">Estimator</span></code><span class="koboSpan" id="kobo.1258.1" xmlns="http://www.w3.org/1999/xhtml"> objects that we mentioned in </span><em><span class="koboSpan" id="kobo.1259.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <a href="ch015.xhtml#x1-1320007.3.7"><em><span class="koboSpan" id="kobo.1260.1" xmlns="http://www.w3.org/1999/xhtml">7.3.7</span></em></a><span class="koboSpan" id="kobo.1261.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1261.2" xmlns="http://www.w3.org/1999/xhtml">In this subsection, we will present to you a simple example that will showcase how to work with this new interface.</span></p>
<p><span class="koboSpan" id="kobo.1262.1" xmlns="http://www.w3.org/1999/xhtml">The following piece of code can be used to train a simple variational quantum classifier (a </span><code><span class="koboSpan" id="kobo.1263.1" xmlns="http://www.w3.org/1999/xhtml">VQC</span></code><span class="koboSpan" id="kobo.1264.1" xmlns="http://www.w3.org/1999/xhtml"> object) using the ”new” Qiskit Runtime on the </span><code><span class="koboSpan" id="kobo.1265.1" xmlns="http://www.w3.org/1999/xhtml">ibmq_lima</span></code><span class="koboSpan" id="kobo.1266.1" xmlns="http://www.w3.org/1999/xhtml"> device:</span></p>
<pre class="lstlisting" id="listing-333"><span class="koboSpan" id="kobo.1267.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_ibm_runtime import QiskitRuntimeService,Session,Sampler,Options 
 
from qiskit_machine_learning.algorithms.classifiers import VQC 
 
 
 
# channel = "ibmq_quantum" gives us access to IBM’s quantum computers. 
 
</span><span class="koboSpan" id="kobo.1267.2" xmlns="http://www.w3.org/1999/xhtml">service = QiskitRuntimeService(channel = "ibm_quantum", token = "TOKEN") 
 
 
 
with Session(service = service, backend = "ibmq_lima"): 
 
    sampler = Sampler() 
 
    vqc = VQC(sampler = sampler, num_qubits = 2) 
 
    vqc.fit(x_tr, y_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.1268.1" xmlns="http://www.w3.org/1999/xhtml">Please note that you need to install the </span><code><span class="koboSpan" id="kobo.1269.1" xmlns="http://www.w3.org/1999/xhtml">qiskit_ibm_runtime</span></code><span class="koboSpan" id="kobo.1270.1" xmlns="http://www.w3.org/1999/xhtml"> package (refer to </span><em><span class="koboSpan" id="kobo.1271.1" xmlns="http://www.w3.org/1999/xhtml">Appendix</span></em> <em/> <a href="ch027.xhtml#x1-240000D"><em><span class="koboSpan" id="kobo.1272.1" xmlns="http://www.w3.org/1999/xhtml">D</span></em></a><span class="koboSpan" id="kobo.1273.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1274.1" xmlns="http://www.w3.org/1999/xhtml">Installing the Tools</span></em><span class="koboSpan" id="kobo.1275.1" xmlns="http://www.w3.org/1999/xhtml">, for instructions) and replace </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1276.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1277.1" xmlns="http://www.w3.org/1999/xhtml">TOKEN</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1278.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1279.1" xmlns="http://www.w3.org/1999/xhtml"> with your actual IBM Quantum token.</span></p>
<p><span class="koboSpan" id="kobo.1280.1" xmlns="http://www.w3.org/1999/xhtml">As a matter of fact, when you send a </span><span id="dx1-210012"/><span class="koboSpan" id="kobo.1281.1" xmlns="http://www.w3.org/1999/xhtml">program through this new Qiskit Runtime interface, you will likely see a fairly big collection of jobs on your IBM Quantum dashboard. </span><span class="koboSpan" id="kobo.1281.2" xmlns="http://www.w3.org/1999/xhtml">Don’t worry, Runtime is working just fine. </span><span class="koboSpan" id="kobo.1281.3" xmlns="http://www.w3.org/1999/xhtml">All those jobs correspond to different calls to the quantum computer, but they are all executed without the need to wait in the queue after each and every job execution.</span></p>
<p><span class="koboSpan" id="kobo.1282.1" xmlns="http://www.w3.org/1999/xhtml">And that’s all we wanted to share with you about the Torch Runtime utility. </span><span class="koboSpan" id="kobo.1282.2" xmlns="http://www.w3.org/1999/xhtml">Let’s wrap up this chapter.</span></p>
</section>
</section>
<section class="level2 likesectionHead" data-number="19.4" id="summary-10">
<h1 class="likesectionHead" data-number="19.4"><span id="x1-21100011.3.4"><span class="koboSpan" id="kobo.1283.1" xmlns="http://www.w3.org/1999/xhtml">Summary</span></span></h1>
<p><span id="Q1-1-294"/></p>
<p><span class="koboSpan" id="kobo.1284.1" xmlns="http://www.w3.org/1999/xhtml">This has been a long and intense chapter. </span><span class="koboSpan" id="kobo.1284.2" xmlns="http://www.w3.org/1999/xhtml">We began by learning what hybrid neural networks actually are and in which use cases they can be useful. </span><span class="koboSpan" id="kobo.1284.3" xmlns="http://www.w3.org/1999/xhtml">We then explored how to implement and train these hybrid networks in PennyLane and, along the way, we discussed a few good practices that apply to any machine learning project. </span><span class="koboSpan" id="kobo.1284.4" xmlns="http://www.w3.org/1999/xhtml">In addition, we left our comfort zone and considered a new kind of QML problem: the training of multi-class classifiers.</span></p>
<p><span class="koboSpan" id="kobo.1285.1" xmlns="http://www.w3.org/1999/xhtml">Once we finished our study of PennyLane, we dived into Qiskit, and a big surprise was waiting for us there. </span><span class="koboSpan" id="kobo.1285.2" xmlns="http://www.w3.org/1999/xhtml">Since Qiskit relied on an interface with the PyTorch ML package for the implementation of hybrid QNNs, we invested a good deal of effort in learning how to use PyTorch. </span><span class="koboSpan" id="kobo.1285.3" xmlns="http://www.w3.org/1999/xhtml">In the process, we saw how PyTorch provided us with a level of flexibility that we simply couldn’t get using TensorFlow and Keras. </span><span class="koboSpan" id="kobo.1285.4" xmlns="http://www.w3.org/1999/xhtml">At the point where we had a solid understanding of the PyTorch package, we got to work with Qiskit and its PyTorch connector and we trained a hybrid QNN with them.</span></p>
<p><span class="koboSpan" id="kobo.1286.1" xmlns="http://www.w3.org/1999/xhtml">Lastly, we concluded the chapter by fulfilling a promise we made in </span><em><span class="koboSpan" id="kobo.1287.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch019.xhtml#x1-18100010"><em><span class="koboSpan" id="kobo.1288.1" xmlns="http://www.w3.org/1999/xhtml">10</span></em></a><span class="koboSpan" id="kobo.1289.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1290.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Neural Networks</span></em><span class="koboSpan" id="kobo.1291.1" xmlns="http://www.w3.org/1999/xhtml">, and we discussed how to train quantum neural networks on IBM’s quantum hardware using Torch Runtime.</span></p>
</section>
</section>
</body>
</html>
