- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Handling Imbalanced Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter delves into the intriguing world of imbalanced data and how conformal
    prediction can be a game-changer in handling such scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Imbalanced datasets are a common challenge in machine learning, often leading
    to biased predictions and underperforming models. This chapter will equip you
    with the knowledge and skills to tackle these issues head-on.
  prefs: []
  type: TYPE_NORMAL
- en: We will be introduced to imbalanced data and learn why it poses a significant
    challenge in machine learning applications. We will then explore various methods
    traditionally used to address imbalanced data problems.
  prefs: []
  type: TYPE_NORMAL
- en: The highlight of the chapter is the application of conformal prediction to imbalanced
    data problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will illustrate how conformal prediction can solve imbalanced
    data problems by covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing imbalanced data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why imbalanced data problems are complex to solve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methods for solving imbalanced data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How conformal prediction can be applied to help solve imbalanced data problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join us on this enlightening journey as we unravel the complexities of imbalanced
    data and discover innovative solutions through conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have a solid understanding of how conformal
    prediction can be effectively applied to handle imbalanced data, thereby improving
    the performance and reliability of your machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing imbalanced data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In machine learning, we often come across datasets that need to be more balanced.
    But what does it mean for a dataset to be imbalanced?
  prefs: []
  type: TYPE_NORMAL
- en: An imbalanced dataset is one where the distribution of samples across the different
    classes is not uniform. In other words, one type has significantly more samples
    than the other(s). This is a common scenario in many real-world applications.
    For instance, in a dataset for fraud detection, the number of non-fraudulent transactions
    (majority class) is typically much higher than the number of fraudulent ones (minority
    class).
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a medical dataset recording instances of a rare disease. Most patients
    will be disease-free, resulting in a large class of healthy records, while only
    a tiny fraction will be affected by the disease. This disproportion in the distribution
    of categories is what we call imbalanced data.
  prefs: []
  type: TYPE_NORMAL
- en: Imbalanced data can lead to a significant challenge in predictive modeling.
    By their very nature, machine learning algorithms are designed to minimize errors
    and maximize accuracy. When trained on imbalanced data, they tend to be biased
    toward the majority class, often at the expense of the minority class prediction
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: In our medical example, a naive model might predict that no one has the disease,
    achieving a high accuracy due to the sheer number of healthy records but failing
    to identify the few crucial cases that do. Such models, misled by the imbalance,
    could have dire real-world implications.
  prefs: []
  type: TYPE_NORMAL
- en: The nature of imbalanced data is pervasive across industries. From fraud detection
    in finance, where fraudulent transactions are rare but crucial to detect, to natural
    disaster predictions in meteorology, where the event of interest (e.g., a tornado
    or earthquake) is infrequent but significant, imbalances pose challenges that
    professionals must be equipped to handle.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing and understanding imbalanced data is the first step in effectively
    addressing their challenges. As we proceed, we’ll deep dive into why these problems
    are particularly tough to crack and explore methodologies to handle them, focusing
    on the potential of conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Why imbalanced data problems are complex to solve
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Addressing imbalanced data is no walk in the park, and here’s why. At the core
    of the challenge is the nature of conventional machine learning algorithms. These
    algorithms minimize overall error and are designed with the assumption of balanced
    class distributions. This becomes problematic when faced with imbalanced datasets,
    leading to a pronounced bias toward the majority class.
  prefs: []
  type: TYPE_NORMAL
- en: The gravity of this problem becomes evident when we realize that in many scenarios,
    it’s the minority class that carries more significance. Take fraud detection or
    medical diagnoses as cases in point. While fraudulent transactions or disease
    instances might be sparse, their correct identification is paramount. Yet, a model
    trained on skewed data might often lean toward predicting the majority class,
    achieving superficially high accuracy but failing its core objective.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add to the challenge, conventional metrics, such as accuracy, are only sometimes
    our friends here. A dataset with just 2% fraudulent transactions can trick us
    into complacency: a naive model predicting every transaction as legitimate will
    boast a 98% accuracy, masking its utter failure in detecting fraud.'
  prefs: []
  type: TYPE_NORMAL
- en: The maze of academic literature on this topic makes things even more difficult.
    With many methods and theories, determining which ones genuinely work is akin
    to finding a needle in a haystack. Methods such as **Synthetic Minority Oversampling
    Technique** (**SMOTE**), which is frequently discussed, require discerning analysis
    to gauge their actual effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: 'A word of advice for those just starting in data science: approach the realm
    of imbalanced classification with a discerning eye. Not all that glitters is gold.
    While searching for a magic solution is tempting, sometimes it’s about reframing
    the problem. By shifting our perspective and focusing on more relevant metrics,
    we can find a way through the maze, making informed and effective decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: We will now look into some common methods for dealing with imbalanced data.
  prefs: []
  type: TYPE_NORMAL
- en: Methods for solving imbalanced data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Where should we turn when confronted with the challenge of imbalanced class
    distribution? While a significant portion of resources in the field suggest using
    resampling methods, including undersampling, oversampling, and techniques such
    as SMOTE, it’s crucial to note that these recommendations often sidestep foundational
    theory and practical application.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into solutions for imbalanced classes, it’s essential first to
    understand their underlying nature. The issue might be better approached in specific
    scenarios such as anomaly detection rather than in a traditional classification
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: In specific scenarios, the class imbalance isn’t static. It can evolve or may
    be influenced by the need for adequate labels. For instance, consider a system
    monitoring network traffic for potential security threats. Initially, threats
    might be rare, leading to a class imbalance. However, as the system matures and
    more potential hazards are identified and labeled, the imbalance might shift,
    reducing or reversing the skew.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing such dynamic imbalances requires adaptive methods that can recalibrate
    as data characteristics change, ensuring the model remains effective throughout
    its life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: When these challenges are absent, it’s prudent to shift focus to the evaluation
    metrics. We’ve previously examined metrics such as log loss and Brier loss, which
    are instrumental in assessing model calibration. Notably, employing resampling
    techniques with these metrics might adversely impact the model’s calibration.
  prefs: []
  type: TYPE_NORMAL
- en: One frequently proposed remedy for imbalanced data is to modify the dataset
    through various resampling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Resampling methods are techniques used to balance the distribution of classes
    in an imbalanced dataset. These methods can be broadly categorized into two main
    types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Oversampling**: This involves increasing the number of instances in the minority
    class. Methods include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random oversampling**: This involves duplicating random records from the
    minority class.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SMOTE**: SMOTE creates synthetic samples for the minority class in a feature
    space by following a specific algorithm. It starts by randomly selecting a minority
    class instance and finding its k-nearest minority class neighbors. SMOTE randomly
    picks one from these neighbors and calculates the difference between its features
    and the selected instance’s features. It then multiplies this difference by a
    random number between 0 and 1, adding the result to the original instance’s features.
    This procedure generates a new, synthetic data point that lies somewhere on the
    line segment, connecting the actual instance with its chosen neighbor, effectively
    creating plausible new instances that contribute to a more balanced dataset for
    the classifier to learn from.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive synthetic (ADASYN) sampling**: Creating synthetic instances for
    the minority class by following their density distributions. Extra synthetic data
    is produced for minority samples that pose more significant learning challenges
    than those that are easier to learn.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Undersampling**: This involves reducing the number of instances in the majority
    class. Methods include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random undersampling**: This involves randomly eliminating majority class
    instances.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tomek links**: This identifies pairs of instances from nearest neighbor classes
    and removes the majority instance from the pair.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster centroids**: This method replaces a cluster of majority samples with
    the cluster centroid of a k-means algorithm.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neighborhood cleaning rule**: This combines undersampling and the **edited
    nearest neighbor** (**ENN**) method to remove majority class instances that are
    misclassified by the KNN classifier and the instances from the minority class
    that are misclassified.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combining oversampling and undersampling**: Techniques can be used to both
    oversample the minority class and undersample the majority class to achieve a
    balance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensemble resampling**: This involves creating multiple balanced subsets through
    resampling and building an ensemble of models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While resampling methods can help balance the class distribution, they may not
    always improve model performance, especially in terms of calibration. Evaluating
    models on a separate, untouched validation set and considering other strategies
    such as choosing appropriate evaluation metrics is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: While resampling methods such as SMOTE have been accepted for many years as
    potential solutions, there is no evidence that such methods work across a wide
    range of datasets. For example, in Kaggle competitions, SMOTE was never successfully
    used as part of winning solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Over the years, resampling methods, notably SMOTE, have been championed as
    potential solutions to the challenge of imbalanced datasets. However, a deeper
    dive into their effectiveness paints a more nuanced picture. Despite their widespread
    mention in literature and tutorials, there’s a conspicuous absence of empirical
    evidence supporting their efficacy across diverse datasets. A testament to this
    is the world of Kaggle competitions, where precision, innovation, and effectiveness
    are paramount. Notably, SMOTE and similar strategies have rarely, if ever, been
    components of winning solutions. This isn’t just a statistical anomaly or coincidence.
    It underscores a profound observation: while these methods might offer superficial
    relief in some contexts, they aren’t universally applicable or reliably effective.
    Any practitioner aiming for cutting-edge performance would do well to approach
    resampling methods with a healthy dose of skepticism and thorough validation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The study *The harm of class imbalance corrections for risk prediction models:
    illustration and simulation using logistic* *regression* by Ruben Van Den Goorbergh,
    Maarten van Smeden, Dirk Timmerman, Ben Van Calster, investigates the impact of
    class imbalance adjustments on the performance of logistic regression models.
    The research scrutinizes conventional and ridge-penalized versions of the model,
    assessing how these corrections influence their discrimination ability, calibration
    accuracy, and classification effectiveness.'
  prefs: []
  type: TYPE_NORMAL
- en: The paper analyzed techniques such as random undersampling and SMOTE, leveraging
    both Monte Carlo simulations and a real-world case study on ovarian cancer diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, while these corrective methods consistently resulted in miscalibrated
    models (with a pronounced overestimation of the likelihood of falling into the
    minority class), they didn’t necessarily enhance discrimination as measured by
    the area under the receiver operating characteristic curve. However, they did
    improve classification metrics such as sensitivity and specificity. Similar classification
    outcomes could be achieved simply by adjusting the probability threshold.
  prefs: []
  type: TYPE_NORMAL
- en: The paper argues that class imbalance correction techniques can harm the performance
    of prediction models, particularly in terms of calibration. The research determined
    that an imbalance in outcomes does not necessarily pose an issue and that attempts
    to correct this imbalance could degrade the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: The paper’s findings underscore that class imbalance, in isolation, isn’t inherently
    problematic and that efforts to rectify it might inadvertently degrade model performance.
  prefs: []
  type: TYPE_NORMAL
- en: In data science, distinguishing between prediction and classification is pivotal.
    Classification often mandates a premature decision, merging prediction with the
    decision-making process, potentially sidelining the actual decision-makers’ considerations.
    This is especially true when the cost of incorrect decisions shifts or data sampling
    criteria change. On the other hand, predictions remain neutral, serving as tools
    for any decision-maker.
  prefs: []
  type: TYPE_NORMAL
- en: In his article *Classification vs. Prediction* ([https://www.fharrell.com/post/classification/](https://www.fharrell.com/post/classification/)),
    Frank Harell argues that classification can lead to hasty decisions, and its application
    in machine learning is sometimes misguided. On the other hand, probability modeling
    quantifies underlying patterns, typically aligning more closely with the core
    objectives of a project.
  prefs: []
  type: TYPE_NORMAL
- en: Classification is most apt when outcomes are clear-cut, and predictors offer
    near-certain outcomes. However, many machine learning enthusiasts lean toward
    classifiers, neglecting the richness of probabilistic thinking, which is deeply
    rooted in statistics. An example of this is the frequent misclassification of
    logistic regression as a mere classification tool when, in essence, it offers
    rich probability estimates.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a misconception that binary decisions necessitate binary classifications.
    Often, the decision might be to gather more data or to take a phased approach.
    For instance, a physician might opt for progressive treatment based on evolving
    symptoms rather than making a binary decision upfront.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a high-clarity scenario such as optical character recognition. Here,
    the outcome is primarily deterministic, and machine learning classifiers excel.
    However, probability estimates become crucial when there’s inherent variability,
    such as in predicting disease outcomes. They inherently provide error margins,
    aiding decision-makers in understanding the associated risks.
  prefs: []
  type: TYPE_NORMAL
- en: There’s also a challenge with classifiers in imbalanced scenarios. For instance,
    in a dataset with an overwhelming majority of non-diseased patients, a naive classifier
    might label everyone as non-diseased, achieving high accuracy but failing in actual
    detection. Addressing this imbalance often involves practices such as subsampling,
    which can lead to more issues. Logistic regression, in contrast, can gracefully
    handle such situations by recalibrating for different datasets or prevalences.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of accuracy metrics is also fundamental. Opting for simplistic accuracy
    measures can lead to misleading models. The focus should instead be on more nuanced
    and statistically sound accuracy scoring rules.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, while classifiers might be suitable for deterministic scenarios
    with high-clarity outcomes, for most real-world situations with inherent variability
    and nuances, probability-based models, such as logistic regression, are more apt,
    versatile, and insightful.
  prefs: []
  type: TYPE_NORMAL
- en: The issue with resampling methods is that they destroy calibration, which is
    critical for decision-making; the resampling techniques do not add any new information.
    The general acceptance of the SMOTE paper that has received over 25K citations
    is very unfortunate, especially considering that the paper is 20 years old, used
    only a few datasets, and performed experiments using weak classifiers such as
    C4.5 (decision tree classifier), Ripper (rule-based algorithm), and a naïve Bayes
    classifier.
  prefs: []
  type: TYPE_NORMAL
- en: The paper also concentrated on inappropriate metrics, focusing solely on the
    **area under the curve** (**AUC**) and the ROC convex hull without considering
    metrics that measure classifier calibration. Consequently, the paper failed to
    report the adverse effects on calibration caused by SMOTE.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we’ll examine effective strategies to address the
    challenges of imbalanced datasets in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The methods for solving imbalanced data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Addressing the challenge of imbalanced data isn’t just about achieving a balanced
    class distribution; it’s about understanding the nuances of the problem and adopting
    a holistic approach that encompasses all facets of model performance. Let us go
    through the methods for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understanding the problem**: The first step is a deep understanding of the
    problem. It’s essential to discern why the data is imbalanced. Is it because of
    the nature of the data or perhaps due to some external factors or biases in data
    collection? Recognizing the root cause can offer insights into the most effective
    strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prioritizing calibration**: One critical aspect that’s often overlooked is
    calibration. A model’s ability to provide probability estimates that reflect true
    likelihoods is paramount, especially when decisions are based on these probabilities.
    Ensuring the model is well calibrated is often more crucial than mere class separation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metrics beyond ROC AUC**: While the **receiver operating characteristic area
    under the curve** (**ROC AUC**) is a popular metric, relying solely on it can
    be misleading, especially in imbalanced datasets. It’s pivotal to incorporate
    metrics that capture the essence of calibration. Metrics such as **expected calibration
    error** (**ECE**), log loss, and Brier score, which we’ve looked into in previous
    chapters, provide a more comprehensive understanding of a model’s performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resampling techniques**: While techniques such as oversampling, undersampling,
    and SMOTE have been propagated as potential solutions, it’s crucial to understand
    their implications. While they might balance class distributions, they may not
    always improve or even maintain a model’s calibration. Therefore, any resampling
    should be performed cautiously, and the resulting models should be rigorously
    evaluated on untouched validation sets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost-sensitive learning**: Another approach is to assign different costs
    to misclassifications of the minority and majority classes. By doing so, the algorithm
    inherently gives more weight to the minority class during training, aiming to
    reduce the more costly errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threshold tuning**: By adjusting the decision threshold away from the default
    (usually 0.5 for binary classification), one can perform better in the minority
    class. It’s about finding a balance between precision and recall, and this technique
    can be particularly effective when the real-world costs of false positives and
    false negatives are different.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ultimately, the goal is to build effective models differentiating classes and
    offering calibrated reliable probability estimates. A multifaceted approach emphasizing
    understanding, calibration, and the right metrics is the way to tackle the imbalanced
    data problem.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll explore how conformal prediction can be applied to help solve imbalanced
    data problem and offer insights into its potential to enhance data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Solving imbalanced data problems by applying conformal prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Conformal prediction is a technique that can be applied to handle imbalanced
    data problems. Here are a few ways it can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Graceful handling of imbalanced datasets**: conformal prediction can gracefully
    handle large imbalanced datasets. It strictly defines the level of similarity
    needed, removing any ambiguity. It can handle severely imbalanced datasets with
    ratios of 1:100 to 1:1000 without oversampling or undersampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local clustering conformal prediction** (**LCCP**): LCCP incorporates a dual-layer
    partitioning approach within the conformal prediction framework. Initially, it
    segments the imbalanced training dataset into subsets based on class taxonomy.
    Then, it further divides the examples from the majority class into subsets using
    clustering techniques. The goal of LCCP is to offer reliable confidence levels
    for its predictions while also enhancing the efficiency of the prediction process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mondrian conformal prediction** (**MCP**): This can deal with imbalanced
    datasets. It categorizes data based on their respective labels and assigns a distinct
    significance level to each class, ensuring that predictive validity is maintained
    across different classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-conformity scoring**: The core of conformal prediction is the non-conformity
    measure, which ranks new observations based on how “strange” they appear compared
    to the training data. This measure can be adapted for imbalanced datasets to give
    more weight to the minority class, ensuring that the model is more sensitive to
    the patterns associated with this class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calibration with validity**: conformal prediction guarantees that if we claim
    a prediction interval with a 95% confidence level, it will contain the actual
    outcome 95% of the time in the long run. This built-in calibration, maintained
    even for imbalanced datasets, ensures that the prediction intervals or sets genuinely
    reflect the model’s uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility with underlying models**: conformal prediction is not tied to
    a specific machine learning algorithm. This means that, even in the context of
    imbalanced data, practitioners can choose the best-performing base model (a tree-based
    method, neural network, or linear model) and then apply the conformal framework
    to obtain reliable predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transparency and interpretability**: The conformal prediction framework’s
    transparent nature allows straightforward interpretation. This transparency can
    be invaluable for imbalanced datasets, enabling stakeholders to understand why
    specific predictions are made and how certain the model is about them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adaptive to changing distributions**: One of the challenges with imbalanced
    data is that the distribution of the minority class can change over time. With
    its emphasis on ranking new observations based on their non-conformity, conformal
    prediction can adapt to these changes, ensuring that predictions remain calibrated
    even as the underlying data distribution evolves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: conformal prediction provides a framework that can be adapted to handle imbalanced
    datasets in various ways, offering potential solutions to this common problem
    in machine learning. While classification is now commonplace, the ultimate goal
    is enabling informed decisions, which requires reliable probability estimates
    even with skewed class data.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing imbalanced data with Venn-Abers predictors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the ever-evolving world of machine learning, addressing classification problems
    has become commonplace. From distinguishing between cats and dogs to more intricate
    challenges, the real aim of classification isn’t merely labeling; it’s also facilitating
    informed decision-making. For this purpose, more than just class labels are required.
    We need well-calibrated class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Most data scientists, especially those in the early stages of their journey,
    tend to evaluate classification models using standard metrics such as accuracy,
    precision, and recall. While these metrics are insightful for more straightforward
    tasks, they can be misleading for more intricate, real-world problems. The true
    essence of classification lies in calibration, an aspect often overlooked in introductory
    courses.
  prefs: []
  type: TYPE_NORMAL
- en: For professionals working on critical applications, from finance to healthcare,
    the calibration of classifiers is paramount. The heart of a classification problem
    is to make informed decisions. These decisions revolve around the probabilities
    of various scenarios, each with potential costs and benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Take the banking sector, for instance. If a model merely predicts that a potential
    customer won’t default on a loan, it needs to provide more depth for decision-making,
    especially when substantial amounts of money are at stake. What’s needed is a
    model that offers well-calibrated probabilities of various outcomes, allowing
    for a nuanced evaluation of risks and rewards.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, a significant challenge arises: many machine learning models don’t
    inherently produce class probabilities. Even if they do, these probabilities can
    often be miscalibrated, leading to erroneous decision-making. This is particularly
    concerning in critical sectors. For example, a self-driving car that misinterprets
    an obstacle due to miscalibrated probabilities could result in accidents.'
  prefs: []
  type: TYPE_NORMAL
- en: So, what can be done to achieve better calibration? Classic methods, such as
    Platt’s scaling ([https://en.wikipedia.org/wiki/Platt_scaling](https://en.wikipedia.org/wiki/Platt_scaling))
    and isotonic regression ([https://en.wikipedia.org/wiki/Isotonic_regression](https://en.wikipedia.org/wiki/Isotonic_regression)),
    were early solutions. However, these methods have limitations, often rooted in
    restrictive assumptions that hamper their efficacy across diverse datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Enter **Venn-Abers predictors**, a beacon of hope in classifier calibration.
    Venn-Abers predictors, a subset of the conformal prediction framework, promise
    a more robust approach to calibration. Unlike traditional methods, they don’t
    hinge on overly simplistic assumptions and offer a more versatile calibration
    tool apt for today’s complex datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, if you aim to harness the true potential of machine learning classifiers
    in 2022 and beyond, Venn-Abers and the broader conformal prediction framework
    are worth exploring. They might be the key to unlocking well-calibrated, reliable
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Venn-Abers predictors stand out in machine learning, offering probability-driven
    predictions for test data labels. What sets them apart is their built-in assurance
    of calibration. This assurance is grounded in the typical premise that data observations
    are independently sourced from a consistent distribution.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, the Venn-Abers approach is inspired by isotonic regression. It
    refines the probabilistic prediction calibration method pioneered by Zadrozny
    and Elkan. In contrast to techniques such as Platt’s scaler and isotonic regression,
    Venn-Abers predictors come equipped with inherent mathematical proofs, ensuring
    their unbiased validity.
  prefs: []
  type: TYPE_NORMAL
- en: 'An intriguing feature of Venn-Abers predictors is their ability to produce
    dual probability predictions for the *class 1* label. This dual output captures
    the range of prediction uncertainty. As a result, these predictors offer calibrated
    predictions and shed light on the inherent confidence associated with each prediction.
    This makes them invaluable tools for enhancing the calibration of probability-based
    predictions. Here’s how:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True-to-life probability intervals**: Venn-Abers predictors shine in delivering
    calibrated probability intervals. This ensures that the probabilities they produce
    genuinely represent the actual chances of an event, eliminating the pitfalls of
    overconfidence or underestimation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versatility across models**: The beauty of Venn-Abers calibration is its
    adaptability. Whether you’re working with decision trees, random forests, or even
    XGBoost models, Venn-Abers can recalibrate them, fine-tuning overambitious and
    cautious models to enhance their accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced decision support with valid intervals**: The predictors don’t just
    stop at labels. For every prediction, especially from typically complex models
    such as random forests and XGBoost, Venn-Abers offers a probability interval.
    The span of this interval serves as a barometer of the prediction’s reliability'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Venn-Abers predictors are a beacon for those navigating the choppy waters of
    imbalanced data issues. They refine the predictive accuracy of various machine
    learning models and arm users with credible probability intervals, making decision-making
    more informed and confident.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the various issues in imbalanced data problems, we will use the
    following notebook: `https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_11.ipynb`'
  prefs: []
  type: TYPE_NORMAL
- en: This notebook will look at various methods for handling an imbalanced class
    problem and apply conformal prediction to calibrate class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the Credit Card Fraud Detection dataset from Kaggle: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains data on credit card transactions in September 2013 by cardholders
    in Europe. The transactions occurred over two days, with 492 fraudulent transactions
    out of 284,807 transactions. The dataset is highly imbalanced, with the positive
    class (fraudulent transactions) accounting for 0.17% of all transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains numerical features that are the result of PCA transformation;
    the original features have been withheld due to confidentiality and privacy issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Features `V1`, `V2`, ... `V28` are the principal components obtained using
    PCA:'
  prefs: []
  type: TYPE_NORMAL
- en: The only original features are `Time` and `Amount`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feature `Time` contains the time (in seconds) for each transaction relative
    to the first transaction in the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The feature `Amount` is the transaction amount
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `label` Class is the dependent variable that needs to be predicted (fraudulent
    transactions labeled with 1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use various classifiers, including popular classifiers such as XGBoost,
    LightGBM, CatBoost, Random Forest, and logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: Key insights from the Credit Card Fraud Detection notebook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our exploration of the Credit Card Fraud Detection dataset, we unearthed
    several pivotal insights that can reshape our approach to imbalanced data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Embracing simplicity**: The most effective strategy is often to leave the
    data untouched. Contrary to the push for intricate resampling techniques, a minimalist
    approach can sometimes yield superior results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reframing imbalance**: Rather than viewing imbalanced data as a dilemma needing
    a direct fix, it’s crucial to understand that the imbalance isn’t always the root
    issue. The quest shouldn’t be to balance the scales but to derive meaningful insights
    from the data, irrespective of distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The power of robust metrics**: The choice of metrics can make or break your
    analysis. By employing a comprehensive set of metrics, you can accurately define
    the problem and pave the way for practical solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calibration’s central role**: Calibration is non-negotiable in real-world
    decision-making scenarios, especially in critical applications. Accurate probability
    estimations are vital, ensuring decisions are based on reliable data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The double-edged sword of resampling**: While resampling methods might seem
    promising, they often compromise the model’s calibration. Our analysis demonstrated
    that such techniques could deteriorate calibration metrics such as ECE, log loss,
    and Brier score.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**conformal prediction** **as a beacon**: Amid the challenges posed by imbalanced
    data and the potential pitfalls of resampling, conformal prediction emerges as
    a silver lining. It offers a reliable method to recalibrate probabilities, ensuring
    that even post-resampling, the data remains conducive for sound decision-making.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By internalizing these insights, we can approach imbalanced datasets with a
    refined perspective, prioritizing meaningful analysis over superficial fixes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The challenge of imbalanced datasets in machine learning often results in biased
    predictions and compromised model outcomes. This chapter delves deep into the
    complexities of such datasets and illuminates the path through conformal prediction,
    a groundbreaking approach to handling these scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional methods, such as resampling techniques, and metrics, such as ROC
    AUC, often fail to address the imbalances effectively. Furthermore, they can sometimes
    lead to even more skewed results. On the other hand, conformal prediction emerges
    as a robust solution, offering calibrated and reliable probability estimates.
  prefs: []
  type: TYPE_NORMAL
- en: The practical implications of these methods are illustrated using the Credit
    Card Fraud Detection dataset from Kaggle, an inherently imbalanced dataset. The
    exploration underscores the significance of understanding the data, using robust
    metrics, and the transformative potential of conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, while imbalanced data presents challenges, practitioners can navigate
    toward calibrated and insightful predictions with the right tools such as conformal
    prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter of this book, we will dive deep into the fascinating world
    of multi-class conformal prediction. This chapter will introduce you to various
    conformal prediction methods that can be effectively applied to multi-class classification
    problems.
  prefs: []
  type: TYPE_NORMAL
