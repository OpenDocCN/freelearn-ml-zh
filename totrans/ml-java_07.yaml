- en: Fraud and Anomaly Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 欺诈和异常检测
- en: Outlier detection is used to identify exceptions, rare events, and other anomalous
    situations. Such anomalies may be needles in a haystack, but their consequences
    can nonetheless be quite dramatic; for instance, credit card fraud detection,
    identifying network intrusions, faults in manufacturing processes, clinical trials,
    voting activities, and criminal activities in e-commerce. Therefore, anomalies
    represent a high value when they are found and high costs if they are not. Applying
    machine learning to outlier detection problems can bring new insights and better
    detection of outlier events. Machine learning can take into account many disparate
    sources of data, and can find correlations that are too obscure for human analysis
    to identify.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测用于识别异常、罕见事件和其他异常情况。这些异常可能像针尖上的麦芒，但它们的后果可能非常严重；例如，信用卡欺诈检测、识别网络入侵、制造过程中的故障、临床试验、投票活动以及电子商务中的犯罪活动。因此，当发现异常时，它们具有很高的价值；如果没有发现，则成本高昂。将机器学习应用于异常检测问题可以带来新的见解和更好的异常事件检测。机器学习可以考虑到许多不同的数据来源，并可以发现人类分析难以识别的相关性。
- en: Take the example of e-commerce fraud detection. With machine learning algorithms
    in place, the purchaser's online behavior, that is, website browsing history,
    becomes a part of the fraud detection algorithm, rather than simply the history
    of purchases made by the cardholder. This involves analyzing a variety of data
    sources, but it is also a far more robust approach to e-commerce fraud detection.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 以电子商务欺诈检测为例。在机器学习算法到位的情况下，购买者的在线行为，即网站浏览历史，成为欺诈检测算法的一部分，而不仅仅是持卡人购买历史的记录。这涉及到分析各种数据来源，但这也是一种更稳健的电子商务欺诈检测方法。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Problems and challenges
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题与挑战
- en: Suspicious pattern detection
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可疑模式检测
- en: Anomalous pattern detection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常模式检测
- en: Working with unbalanced datasets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与不平衡数据集合作
- en: Anomaly detection in time series
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列中的异常检测
- en: Suspicious and anomalous behavior detection
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可疑和异常行为检测
- en: The problem of learning patterns from sensor data arises in many applications,
    including e-commerce, smart environments, video surveillance, network analysis,
    human-robot interaction, ambient assisted living, and so on. We focus on detecting
    patterns that deviate from regular behaviors and might represent a security risk,
    health problem, or any other abnormal behavior contingency.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从传感器数据中学习模式的问题出现在许多应用中，包括电子商务、智能环境、视频监控、网络分析、人机交互、环境辅助生活等等。我们专注于检测偏离常规行为且可能代表安全风险、健康问题或任何其他异常行为的情况。
- en: In other words, deviant behavior is a data pattern that either does not conform
    to the expected behavior (anomalous behavior) or matches a previously defined
    unwanted behavior (suspicious behavior). Deviant behavior patterns are also referred
    to as outliers, exceptions, peculiarities, surprises, misuse, and so on. Such
    patterns occur relatively infrequently; however, when they do occur, their consequences
    can be quite dramatic, and often negatively so. Typical examples include credit
    card fraud, cyber intrusions, and industrial damage. In e-commerce, fraud is estimated
    to cost merchants more than $200 billion a year; in healthcare, fraud is estimated
    to cost taxpayers $60 billion a year; for banks, the cost is over $12 billion.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，偏差行为是一种数据模式，它要么不符合预期的行为（异常行为），要么与先前定义的不希望的行为相匹配（可疑行为）。偏差行为模式也被称为异常值、例外、特殊性、惊喜、滥用等等。这种模式相对较少发生；然而，当它们发生时，其后果可能非常严重，并且往往是负面的。典型的例子包括信用卡欺诈、网络入侵和工业损害。在电子商务中，欺诈估计每年使商家损失超过2000亿美元；在医疗保健中，欺诈估计每年使纳税人损失600亿美元；对于银行来说，成本超过120亿美元。
- en: Unknown unknowns
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未知之未知
- en: 'When Donald Rumsfeld, US Secretary of Defense, had a news briefing on February
    12, 2002, about the lack of evidence linking the government of Iraq to the supply
    of weapons of mass destruction to terrorist groups, it immediately became a subject
    of much commentary. Rumsfeld stated the following (*DoD News*, 2012):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当美国国防部长唐纳德·拉姆斯菲尔德于2002年2月12日举行新闻发布会，关于缺乏证据将伊拉克政府与向恐怖组织供应大规模杀伤性武器联系起来时，这立即成为许多评论的焦点。拉姆斯菲尔德陈述了以下内容（*DoD
    News*, 2012）：
- en: '"Reports that say that something hasn''t happened are always interesting to
    me, because as we know, there are known knowns; there are things we know we know.
    We also know there are known unknowns; that is to say we know there are some things
    we do not know. But there are also unknown unknowns-the ones we don''t know we
    don''t know. And if one looks throughout the history of our country and other
    free countries, it is the latter category that tend to be the difficult ones."'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “关于某些事情尚未发生的报告总是让我感到很有趣，因为我们知道，有已知已知；有我们已知我们知道的事情。我们也知道有已知未知；也就是说，我们知道有一些我们不知道的事情。但还有未知未知——那些我们不知道我们不知道的事情。如果我们回顾我国和其他自由国家的历史，往往是后者更难处理。”
- en: 'This statement might seem confusing at first, but the idea of unknown unknowns
    was well studied among scholars dealing with risk, NSA, and other intelligence
    agencies. What the statement basically implies is the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这句话一开始可能听起来有些令人困惑，但未知未知的概念在处理风险、国家安全局和其他情报机构的学者中得到了很好的研究。这个声明基本上意味着以下内容：
- en: '**Known knowns**: These are well-known problems or issues; we know how to recognize
    them and how deal with them'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已知已知**：这些是众所周知的问题或问题；我们知道如何识别它们以及如何处理它们'
- en: '**Known unknowns**: These are expected or foreseeable problems, which can be
    reasonably anticipated, but have not occurred before'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已知未知**：这些是预期或可预见的问题，可以合理预测，但之前尚未发生'
- en: '**Unknown unknowns**: These are unexpected and unforeseeable problems, which
    pose significant risk, as they cannot be anticipated, based on previous experience'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未知未知**：这些是意外和不可预见的问题，它们具有重大风险，因为基于以往的经验，它们无法被预测'
- en: 'In the following sections, we will look into two fundamental approaches dealing
    with the first two types of knowns and unknowns: suspicious pattern detection
    dealing with known knowns, and anomalous pattern detection targeting known unknowns.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将探讨两种处理前两种已知和未知类型的基本方法：可疑模式检测处理已知已知，以及针对已知未知的异常模式检测。
- en: Suspicious pattern detection
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可疑模式检测
- en: 'The first approach involves a behavior library that encodes negative patterns,
    shown as red minus signs in the following diagram, and recognizes that observed
    behavior corresponds to identifying a match in the library. If a new pattern can
    be matched against negative patterns, then it is considered suspicious:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法涉及一个行为库，该库编码负模式，在以下图中用红色减号表示，并识别观察到的行为是否与库中的匹配。如果一种新模式可以与负模式相匹配，那么它被认为是可疑的：
- en: '![](img/f8a12c37-d928-4b52-8fb9-f64f58b30ef8.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f8a12c37-d928-4b52-8fb9-f64f58b30ef8.png)'
- en: For example, when you visit a doctor, he/she inspects various health symptoms
    (body temperature, pain levels, affected areas, and so on) and matches the symptoms
    to a known disease. In machine learning terms, the doctor collects attributes
    and performs classifications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你去看医生时，他会检查各种健康症状（体温、疼痛程度、受影响区域等）并将症状与已知疾病相匹配。在机器学习的术语中，医生收集属性并执行分类。
- en: An advantage of this approach is that we immediately know what is wrong; for
    example, assuming that we know the disease, we can select an appropriate treatment
    procedure.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个优点是我们立即知道出了什么问题；例如，如果我们知道疾病，我们可以选择合适的治疗方案。
- en: A major disadvantage of this approach is that it can only detect suspicious
    patterns that are known in advance. If a pattern is not inserted into a negative
    pattern library, then we will not be able to recognize it. This approach is, therefore,
    appropriate for modeling known knowns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的重大缺点是它只能检测事先已知的可疑模式。如果一种模式没有被插入到负模式库中，那么我们就无法识别它。因此，这种方法适用于建模已知已知。
- en: Anomalous pattern detection
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常模式检测
- en: 'The second approach uses the pattern library in an inverse fashion, meaning
    that the library encodes only the positive patterns, which are marked with green
    plus signs in the following diagram. When an observed behavior (the blue circle)
    cannot be matched against the library, it is considered anomalous:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法以相反的方式使用模式库，这意味着库只编码正模式，在以下图中用绿色加号标记。当一个观察到的行为（蓝色圆圈）无法与库相匹配时，它被认为是异常的：
- en: '![](img/06313d61-ed0f-438c-be5b-41c210160dca.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/06313d61-ed0f-438c-be5b-41c210160dca.png)'
- en: This approach requires us to model only what we have seen in the past, that
    is, normal patterns. If we return to the doctor example, the main reason that
    we visited the doctor in the first place was because we did not feel well. Our
    perceived state of feelings (for example, a headache and sore skin) did not match
    our usual feelings, and therefore, we decided to seek a doctor. We don't know
    which disease caused this state, nor do we know the treatment, but we were able
    to observe that it doesn't match the usual state.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法要求我们仅对过去所见到的内容进行建模，即正常模式。如果我们回到医生这个例子，我们最初去看医生的主要原因是因为我们感觉不舒服。我们感知到的感觉状态（例如，头痛和皮肤疼痛）与我们通常的感觉不符，因此我们决定寻求医生的帮助。我们不知道是什么疾病导致了这种状态，也不知道治疗方法，但我们能够观察到它不符合通常的状态。
- en: A major advantage of this approach is that it does not require us to say anything
    about abnormal patterns; hence, it is appropriate for modeling known unknowns
    and unknown unknowns. On the other hand, it does not tell us exactly what is wrong.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的一个主要优点是它不需要我们说任何关于异常模式的内容；因此，它适合于建模已知未知和未知未知。另一方面，它并没有告诉我们具体是什么出了问题。
- en: Analysis types
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析类型
- en: 'Several approaches have been proposed to tackle this problem. We broadly classify
    anomalous and suspicious behavior detection in the following three categories:
    pattern analysis, transaction analysis, and plan recognition. In the following
    sections, we will quickly look at some real-life applications.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 已经提出了几种方法来解决这个问题。我们将异常和可疑行为检测大致分为以下三个类别：模式分析、事务分析和计划识别。在接下来的几节中，我们将快速查看一些实际应用。
- en: Pattern analysis
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模式分析
- en: An active area of anomalous and suspicious behavior detection from patterns
    is based on visual modalities, such as a camera. Zhang, et al. (2007) proposed
    a system for a visual human motion analysis from a video sequence, which recognizes
    unusual behavior based on walking trajectories; Lin, et al. (2009) described a
    video surveillance system based on color features, distance features, and a count
    feature, where evolutionary techniques are used to measure observation similarity.
    The system tracks each person and classifies their behavior by analyzing their
    trajectory patterns. The system extracts a set of visual low-level features in
    different parts of the image, and performs a classification with SVMs in order
    to detect aggressive, cheerful, intoxicated, nervous, neutral, and tired behavior.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于视觉模式（如摄像头）的异常和可疑行为检测是一个活跃的研究领域。Zhang等人（2007年）提出了一种从视频序列中分析人类运动的方法，它根据行走轨迹识别异常行为；Lin等人（2009年）描述了一个基于颜色特征、距离特征和计数特征的视频监控系统，其中使用了进化技术来测量观察相似性。该系统跟踪每个人，并通过分析他们的轨迹模式来对他们的行为进行分类。该系统从图像的不同部分提取一组视觉低级特征，并使用SVM进行分类，以检测攻击性、愉快、醉酒、紧张、中立和疲劳行为。
- en: Transaction analysis
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事务分析
- en: Transaction analysis assumes discrete states/transactions, in contrast to continuous
    observations. A major research area is **intrusion detection** (**ID**), which
    aims to detect attacks against information systems, in general. There are two
    types of ID systems, signature-based and anomaly-based, that broadly follow the
    suspicious and anomalous pattern detection that was described in the previous
    sections. A comprehensive review of ID approaches was published by Gyanchandani,
    et al. (2012).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与连续观察不同，事务分析假设离散状态/事务。一个主要的研究领域是**入侵检测**（**ID**），其目的是检测针对信息系统的一般攻击。有两种类型的ID系统，基于签名和基于异常，它们广泛遵循前几节中描述的可疑和异常模式检测。Gyanchandani等人（2012年）发表了对ID方法的综合评论。
- en: Furthermore, applications in ambient assisted living that are based on wearable
    sensors also fit to transaction analysis as sensing is typically event-based.
    Lymberopoulos, et al. (2008) proposed a system for automatic extraction of the
    user's spatio-temporal patterns, encoded as sensor activation from the sensor
    network deployed inside their home. The proposed method, based on location, time,
    and duration, was able to extract frequent patterns using the Apriori algorithm
    and encode the most frequent patterns in the form of a Markov chain. Another area
    of related work includes the **hidden Markov models** (**HMMs**) that are widely
    used in traditional activity recognition for modeling a sequence of actions, but
    these topics are already out of the scope of this book.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基于可穿戴传感器的环境辅助生活应用也适合于交易分析，因为传感通常是事件驱动的。Lymberopoulos等人（2008）提出了一种自动提取用户时空模式的方法，这些模式编码为传感器网络中的传感器激活，该传感器网络部署在他们家中。所提出的方法基于位置、时间和持续时间，能够使用Apriori算法提取频繁模式，并以马尔可夫链的形式编码最频繁的模式。相关工作的另一个领域包括广泛用于传统活动识别的**隐马尔可夫模型（HMMs**），但这些问题已经超出了本书的范围。
- en: Plan recognition
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划识别
- en: Plan recognition focuses on a mechanism for recognizing the unobservable state
    of an agent, given observations of its interaction with its environment (Avrahami-Zilberbrand,
    2009). Most existing investigations assume discrete observations in the form of
    activities. To perform anomalous and suspicious behavior detection, plan recognition
    algorithms may use a hybrid approach. A symbolic plan recognizer is used to filter
    consistent hypotheses and passes them to an evaluation engine, which focuses on
    ranking.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 计划识别关注于识别一个代理不可观察状态的机制，给定其与环境交互的观察结果（Avrahami-Zilberbrand，2009）。大多数现有研究假设以活动形式存在的离散观察。为了执行异常和可疑行为检测，计划识别算法可能使用混合方法。一个符号计划识别器用于过滤一致假设，并将它们传递给评估引擎，该引擎专注于排名。
- en: These were advanced approaches that were applied to various real-life scenarios,
    targeted at discovering anomalies. In the following sections, we'll dive into
    more basic approaches for suspicious and anomalous pattern detection.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是应用于各种现实场景的高级方法，旨在发现异常。在接下来的章节中，我们将深入了解用于可疑和异常模式检测的基本方法。
- en: Outlier detection using ELKI
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ELKI进行异常检测
- en: '**ELKI** stands for **Environment for Loping KDD applications Index** structures,
    where **KDD** stands for **Knowledge Discovery** **in Database**. It is an open
    source software used mainly for data mining, with an emphasis on unsupervised
    learning. It supports various algorithms for cluster analysis and outlier detection.
    The following are some outlier algorithms:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**ELKI**代表**用于KDD应用索引的环境**结构，其中**KDD**代表**数据库中的知识发现**。它是一个主要用于数据挖掘的开源软件，侧重于无监督学习。它支持各种聚类分析和异常检测算法。以下是一些异常检测算法：'
- en: '**Distance-based outlier detection**: This is used to specify two parameters.
    The object is flagged **outlier** if its fraction, p, for all the data objects
    that have a distance above d from c. There are many algorithms, such as `DBOutlierDetection`,
    `DBOutlierScore`, `KNNOutlier`, `KNNWeightOutlier`, `ParallelKNNOutlier`, `ParallelKNNWeightOutlier`,
    `ReferenceBasedOutlierDetection`, and so on.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于距离的异常检测**：这用于指定两个参数。如果一个对象与c的距离大于d，且其所有数据对象的分数p被标记为**异常**。有许多算法，如`DBOutlierDetection`、`DBOutlierScore`、`KNNOutlier`、`KNNWeightOutlier`、`ParallelKNNOutlier`、`ParallelKNNWeightOutlier`、`ReferenceBasedOutlierDetection`等。'
- en: '**LOF family methods**: This computes density-based local outlier factors on
    specific parameters. It includes algorithms such as `LOF`, `ParallelLOF`, `ALOCI`,
    `COF`, `LDF`, `LDOF`, and so on.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LOF系列方法**：这种方法在特定参数上计算基于密度的局部异常因子。它包括`LOF`、`ParallelLOF`、`ALOCI`、`COF`、`LDF`、`LDOF`等算法。'
- en: '**Angle-based outlier detection**: This uses the variance analysis of angles,
    using mostly high-dimensional datasets. Common algorithms include `ABOD`, `FastABOD`,
    and `LBABOD`.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于角度的异常检测**：这使用角度的方差分析，主要使用高维数据集。常见的算法包括`ABOD`、`FastABOD`和`LBABOD`。'
- en: '**Clustering-based outlier detection**: This uses EM clustering; if the object
    does not belong to a cluster, it is taken as an outlier. This includes algorithms
    such as `EMOutlier` and `KMeansOutlierDetection`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于聚类的异常检测**：这使用EM聚类；如果一个对象不属于任何聚类，则被视为异常。这包括`EMOutlier`和`KMeansOutlierDetection`等算法。'
- en: '**Subspace outlier detection**: This uses the outlier detection method for
    axis-parallel subspaces. It has algorithms such as `SOD`, `OutRankS1`, `OUTRES`,
    `AggrawalYuNaive`, and `AggrawalYuEvolutionary`.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子空间异常检测**：这使用的是轴平行子空间的异常检测方法。它包括`SOD`、`OutRankS1`、`OUTRES`、`AggrawalYuNaive`和`AggrawalYuEvolutionary`等算法。'
- en: '**Spatial outlier detection**: This has large datasets based on locations which
    are collected from different sources and the data point that is an extreme relative
    to neighbors. It has algorithms such as `CTLuGLSBackwardSearchAlgorithm`, `CTLuMeanMultipleAttributes`,
    `CTLuMedianAlgorithm`, `CTLuScatterplotOutlier`, and so on.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空间异常检测**：它基于从不同来源收集的基于位置的大量数据集，以及相对于邻居的极端数据点。它包括`CTLuGLSBackwardSearchAlgorithm`、`CTLuMeanMultipleAttributes`、`CTLuMedianAlgorithm`、`CTLuScatterplotOutlier`等算法。'
- en: An example using ELKI
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ELKI的一个示例
- en: 'In [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml), *Basic Algorithms –
    Classification, Regression, and Clustering*, you already saw how to get the required
    `.jar` file for ELKI. We will follow a similar process, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml)，“基本算法 – 分类、回归和聚类”中，你已经看到了如何为ELKI获取所需的`.jar`文件。我们将遵循类似的过程，如下所示：
- en: 'Open Command Prompt or Terminal, and execute the following command:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 打开命令提示符或终端，并执行以下命令：
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will provide the GUI interface, as shown in the following screenshot:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提供GUI界面，如下面的截图所示：
- en: '![](img/5e04484b-a85a-4193-b0d0-db8ea5a05187.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5e04484b-a85a-4193-b0d0-db8ea5a05187.png)'
- en: In the GUI, the dbc.in and algorithm parameters are highlighted and need to
    be set. We will use `pov.csv` file, as dbc.in. This CSV file can be downloaded
    from [https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv](https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在GUI中，`dbc.in`和算法参数被突出显示并需要设置。我们将使用`pov.csv`文件作为`dbc.in`。此CSV文件可以从[https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv](https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv)下载。
- en: 'For the algorithm, select outlier.clustering.EMOutlier, and in em.k, pass `3`
    as the value. The following screenshot shows all of the filled-in options:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法，选择`outlier.clustering.EMOutlier`，并在`em.k`中传递`3`作为值。以下截图显示了所有已填写的选项：
- en: '![](img/25c7747f-c7ec-41fb-8105-fff08d32f593.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/25c7747f-c7ec-41fb-8105-fff08d32f593.png)'
- en: 'Click on the Run Task button, and it will process and generate the following
    output:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“运行任务”按钮，它将处理并生成以下输出：
- en: '![](img/a54b3ac3-cc1d-4041-8111-a9bcd32b2818.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a54b3ac3-cc1d-4041-8111-a9bcd32b2818.png)'
- en: This shows clustering and the possible outliers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了聚类和可能的异常。
- en: Fraud detection in insurance claims
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保险索赔中的欺诈检测
- en: First, we'll take a look at suspicious behavior detection, where the goal is
    to learn about patterns of fraud, which corresponds to modeling known knowns.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将查看可疑行为检测，其目标是了解欺诈模式，这对应于已知已知建模。
- en: Dataset
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: We'll work with a dataset describing insurance transactions, which is publicly
    available in the Oracle database online documentation at [http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm](http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个描述保险交易的数据库集进行工作，该数据库集在Oracle数据库在线文档中公开可用，网址为[http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm](http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm)。
- en: 'The dataset describes insurance claims on vehicle incidents for an undisclosed
    insurance company. It contains 15,430 claims; each claim is comprised of 33 attributes,
    describing the following components:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集描述了一个未公开保险公司的车辆事故索赔。它包含15,430个索赔；每个索赔由33个属性组成，描述以下组件：
- en: Customer demographic details (Age, Sex, MartialStatus, and so on)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户人口统计详细信息（年龄、性别、婚姻状况等）
- en: Purchased policy (PolicyType, VehicleCategory, number of supplements, agent
    type, and so on)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 购买的政策（政策类型、车辆类别、补充数量、代理商类型等）
- en: Claim circumstances (day/month/week claimed, policy report filed, witness present,
    past days between incident-policy report, incident claim, and so on)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索赔情况（索赔的日/月/周、政策报告提交、目击者在场、事故与政策报告之间的过去天数、事故索赔等）
- en: Other customer data (number of cars, previous claims, DriverRating, and so on)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他客户数据（汽车数量、以前的索赔、驾驶员评分等）
- en: Fraud found (yes or no)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现欺诈（是或否）
- en: 'The sample of the database shown in the following screenshot depicts the data
    that''s been loaded into Weka:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了已加载到Weka中的数据库样本：
- en: '![](img/b856867d-d998-4e54-8ff0-0c66fd7f414b.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b856867d-d998-4e54-8ff0-0c66fd7f414b.png)'
- en: 'Now, the task is to create a model that will be able to identify suspicious
    claims in the future. The challenging thing about this task is the fact that only
    6% of the claims are suspicious. If we create a dummy classifier saying that no
    claim is suspicious, it will be accurate in 94% of cases. Therefore, in this task,
    we will use different accuracy measures: precision and recall.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，任务是创建一个能够识别未来可疑声明的模型。这个任务具有挑战性的地方在于只有 6% 的声明是可疑的。如果我们创建一个虚拟分类器，声称没有任何声明是可疑的，那么它在
    94% 的情况下将是准确的。因此，在这个任务中，我们将使用不同的准确度指标：精确度和召回率。
- en: 'Let''s recall the outcome table from [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*, where there are four possible outcomes,
    denoted as true positive, false positive, false negative, and true negative:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下[第 1 章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)《应用机器学习快速入门》中的结果表，其中包含四种可能的结果，分别表示真阳性、假阳性、假阴性和真阴性：
- en: '|  |  | **Classified as** |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '|  |  | **分类为** |'
- en: '| **Actual** |  | **Fraud** | **No fraud** |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| **实际** |  | **欺诈** | **无欺诈** |'
- en: '| **Fraud** | TP - true positive | FN - false negative |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| **欺诈** | TP - 真阳性 | FN - 假阴性 |'
- en: '| **No fraud** | FP - false positive | TN - true negative |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| **无欺诈** | FP - 假阳性 | TN - 真阴性 |'
- en: 'Precision and recall are defined as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度和召回率定义如下：
- en: '**Precision** is equal to the proportion of correctly raised alarms, as follows:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**等于正确发出警报的比例，如下所示：'
- en: '![](img/aaae16aa-e167-4849-99ed-8b994958e828.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aaae16aa-e167-4849-99ed-8b994958e828.png)'
- en: '**Recall** is equal to the proportion of deviant signatures, which are correctly
    identified as follows:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**等于正确识别的异常签名比例，如下所示：'
- en: '![](img/37de70de-abc6-4fa8-81fc-1065b24dcb12.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/37de70de-abc6-4fa8-81fc-1065b24dcb12.png)'
- en: 'With these measures–our dummy classifier scores–we find that *Pr = 0* and *Re
    = 0*, as it never marks any instance as fraud (*TP = 0*). In practice, we want
    to compare classifiers by both numbers; hence, we use *F - measure*. This is a
    de facto measure that calculates a harmonic mean between the precision and recall,
    as follows:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这些指标——我们的虚拟分类器得分——我们发现 *Pr = 0* 和 *Re = 0*，因为它从未将任何实例标记为欺诈 (*TP = 0*)。在实践中，我们希望通过数字比较分类器；因此，我们使用
    *F - measure*。这是一个事实上的指标，它计算精确度和召回率之间的调和平均值，如下所示：
- en: '![](img/05941bf8-3cd2-4fe7-8226-47141dd632ac.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05941bf8-3cd2-4fe7-8226-47141dd632ac.png)'
- en: Now, let's move on to designing a real classifier.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续设计一个真正的分类器。
- en: Modeling suspicious patterns
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立可疑模式模型
- en: 'To design a classifier, we can follow the standard supervised learning steps,
    as described in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml), *Applied
    Machine Learning Quick Start*. In this recipe, we will include some additional
    steps to handle unbalanced datasets and evaluate classifiers based on precision
    and recall. The plan is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设计一个分类器，我们可以遵循标准的有监督学习步骤，如[第 1 章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)《应用机器学习快速入门》中所述。在这个菜谱中，我们将包括一些额外的步骤来处理不平衡数据集并根据精确度和召回率评估分类器。计划如下：
- en: Load the data in the `.csv` format.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 `.csv` 格式加载数据。
- en: Assign the class attribute.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分配类属性。
- en: Convert all of the attributes from a numeric to nominal value to make sure that
    there are no incorrectly loaded numerical values.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有属性从数值转换为名义值，以确保没有错误加载的数值。
- en: '**Experiment 1**: Evaluating the models with k-fold cross-validation.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实验 1**：使用 k 折交叉验证评估模型。'
- en: '**Experiment 2**: Rebalancing the dataset to a more balanced class distribution,
    and manually perform cross-validation.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实验 2**：将数据集重新平衡到更平衡的类别分布，并手动执行交叉验证。'
- en: Compare the classifiers by recall, precision, and f-measure.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过召回率、精确度和 f-measure 比较分类器。
- en: 'First, let''s load the data using the `CSVLoader` class, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用 `CSVLoader` 类加载数据，如下所示：
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we need to make sure that all of the attributes are nominal. During the
    data import, Weka applies some heuristics to guess the most probable attribute
    type, that is, numeric, nominal, string, or date. As heuristics cannot always
    guess the correct type, we can set the types manually, as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要确保所有属性都是名义的。在数据导入过程中，Weka 应用一些启发式方法来猜测最可能的属性类型，即数值、名义、字符串或日期。由于启发式方法不能总是猜对类型，我们可以手动设置类型，如下所示：
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Before we continue, we need to specify the attribute that we will try to predict.
    We can achieve this by calling the `setClassIndex(int)` function:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们需要指定我们将尝试预测的属性。我们可以通过调用 `setClassIndex(int)` 函数来实现这一点：
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we need to remove an attribute describing the policy number, as it has
    no predictive value. We simply apply the `Remove` filter, as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要移除一个描述政策编号的属性，因为它没有预测价值。我们只需应用`Remove`过滤器，如下所示：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, we are ready to start modeling.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备开始建模。
- en: The vanilla approach
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本方法
- en: The vanilla approach is to directly apply the lesson, just like as it was demonstrated
    in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml), *Basic Algorithms
    - Classification, Regression, Clustering*, without any preprocessing, and not
    taking dataset specifics into account. To demonstrate the drawbacks of the vanilla
    approach, we will simply build a model with the default parameters and apply k-fold
    cross-validation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基本方法是将课程直接应用，就像在[第3章](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml)，“基本算法 - 分类、回归、聚类”中所展示的那样，没有任何预处理，也不考虑数据集的具体情况。为了展示基本方法的缺点，我们将简单地使用默认参数构建一个模型，并应用k折交叉验证。
- en: 'First, let''s define some classifiers that we want to test, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一些我们想要测试的分类器，如下所示：
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we need to create an `Evaluation` object and perform k-fold cross-validation
    by calling the `crossValidate(Classifier, Instances, int, Random, String[])` method,
    providing the `precision`, `recall`, and `fMeasure` as output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个`Evaluation`对象，并通过调用`crossValidate(Classifier, Instances, int, Random,
    String[])`方法执行k折交叉验证，提供`precision`、`recall`和`fMeasure`作为输出：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The evaluation provides the following scores as output:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 评估提供了以下分数作为输出：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can see that the results are not very promising. The recall, that is, the
    share of discovered frauds among all frauds, is only 1-3%, meaning that only 1-3/100
    frauds are detected. On the other hand, the precision, that is, the accuracy of
    alarms, is 91%, meaning that in 9/10 cases, when a claim is marked as fraud, the
    model is correct.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，结果并不十分令人鼓舞。召回率，即发现的欺诈在所有欺诈中的比例，仅为1-3%，这意味着只有1-3/100的欺诈被检测到。另一方面，精确度，即警报的准确性，为91%，这意味着在10个案例中有9个，当一个索赔被标记为欺诈时，模型是正确的。
- en: Dataset rebalancing
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集重平衡
- en: As the number of negative examples, that is, instances of fraud, is very small
    compared to positive examples, the learning algorithms struggle with induction.
    We can help them by giving them a dataset where the share of positive and negative
    examples is comparable. This can be achieved with dataset rebalancing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于负面示例（即欺诈实例）的数量与正面示例相比非常小，学习算法在归纳方面遇到了困难。我们可以通过提供一个正负示例比例相当的数据集来帮助他们。这可以通过数据集重平衡来实现。
- en: Weka has a built-in filter, `Resample`, which produces a random subsample of
    a dataset, using sampling either with replacement or without replacement. The
    filter can also bias the distribution toward a uniform class distribution.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Weka有一个内置的过滤器，`Resample`，它使用有放回或无放回的抽样方法生成数据集的随机子样本。该过滤器还可以使分布偏向均匀的类别分布。
- en: 'We will proceed by manually implementing k-fold cross-validation. First, we
    will split the dataset into *k* equal folds. Fold *k* will be used for testing,
    while the other folds will be used for learning. To split the dataset into folds,
    we''ll use the `StratifiedRemoveFolds` filter, which maintains the class distribution
    within the folds, as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将手动实现k折交叉验证。首先，我们将数据集分成*k*个相等的部分。第*k*部分将用于测试，而其他部分将用于学习。为了将数据集分成部分，我们将使用`StratifiedRemoveFolds`过滤器，该过滤器在部分内保持类别分布，如下所示：
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we can rebalance the training dataset, where the `-Z` parameter specifies
    the percentage of the dataset to be resampled, and `-B` biases the class distribution
    toward uniform distribution:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以重平衡训练数据集，其中`-Z`参数指定要重采样的数据集百分比，而`-B`参数使类别分布偏向均匀分布：
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we can build classifiers and perform evaluation:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以构建分类器并执行评估：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we calculate the average and provide the best model as output using
    the following lines of code:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用以下代码行计算平均值并提供最佳模型作为输出：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, the performance of the models has significantly improved, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型的性能显著提高，如下所示：
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can see that all of the models have scored significantly better; for instance,
    the best model, logistic regression, correctly discovers 76% of the fraud, while
    producing a reasonable amount of false alarms–only 13% of the claims marked as
    fraud are indeed fraudulent. If an undetected fraud is significantly more expensive
    than the investigation of false alarms, then it makes sense to deal with an increased
    number of false alarms.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，所有模型的表现都显著提高；例如，表现最好的模型——逻辑回归，正确地发现了76%的欺诈行为，同时产生合理数量的误报——只有13%被标记为欺诈的索赔实际上是欺诈的。如果未检测到的欺诈比误报的调查成本高得多，那么处理更多的误报是有意义的。
- en: The overall performance most likely still has some room for improvement; we
    could perform attribute selection and feature generation and apply more complex
    model learning, which we discussed in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml),
    *Basic Algorithms – Classification, Regression, Clustering*.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 总体性能很可能还有提升空间；我们可以进行属性选择和特征生成，并应用更复杂的模型学习，这些内容我们在[第3章](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml)，*基本算法
    – 分类、回归、聚类*中讨论过。
- en: Anomaly detection in website traffic
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网站流量中的异常检测
- en: In the second example, we'll focus on modeling the opposite of the previous
    example. Instead of discussing what typical fraudless cases are, we'll discuss
    the normal expected behavior of the system. If something cannot be matched against
    our expected model, it will be considered anomalous.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个示例中，我们将专注于建模前一个示例的相反情况。不是讨论典型的无欺诈案例，而是讨论系统的正常预期行为。如果某些东西无法与我们的预期模型匹配，它将被认为是异常的。
- en: Dataset
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: We'll work with a publicly available dataset that was released by Yahoo! Labs, which
    is useful for discussing how to detect anomalies in time series data. For Yahoo,
    the main use case is in detecting unusual traffic on Yahoo servers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个由Yahoo! Labs发布的公开数据集，这个数据集对于讨论如何检测时间序列数据中的异常非常有用。对于Yahoo来说，主要用例是在检测Yahoo服务器上的异常流量。
- en: Even though Yahoo has announced that their data is publicly available, you have
    to apply to use it, and it takes about 24 hours before the approval is granted.
    The dataset is available at [http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70](http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Yahoo已经宣布他们的数据是公开的，但你必须申请使用，并且批准通常需要大约24小时。数据集可在[http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70](http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70)获取。
- en: 'The dataset is comprised of real traffic for Yahoo services, along with some
    synthetic data. In total, the dataset contains 367 time series, each of which
    contains between 741 and 1,680 observations, which have been recorded at regular
    intervals. Each series is written in its own file, one observation per line. A
    series is accompanied by a second column indicator, with a one being used if the
    observation was an anomaly, and zero otherwise. The anomalies in real data were
    determined by human judgment, while those in the synthetic data were generated
    algorithmically. A snippet of the synthetic times series data is shown in the
    following table:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集由Yahoo服务的真实流量和一些合成数据组成。总共有367个时间序列，每个时间序列包含741到1,680个观测值，这些观测值以固定间隔记录。每个序列都写在它自己的文件中，每行一个观测值。每个序列还伴随一个第二列的指示符，如果观测值是异常，则使用1，否则使用0。真实数据中的异常是通过人工判断确定的，而合成数据中的异常是通过算法生成的。以下表格显示了合成时间序列数据的一个片段：
- en: '![](img/dba0f780-5990-40b0-a735-5374a17d729e.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/dba0f780-5990-40b0-a735-5374a17d729e.png)'
- en: In the following section, you'll learn how to transform time series data into
    an attribute presentation that allows us to apply machine learning algorithms.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何将时间序列数据转换成属性表示，这样我们就可以应用机器学习算法。
- en: Anomaly detection in time series data
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据中的异常检测
- en: Detecting anomalies in raw, streaming time series data requires some data transformation.
    The most obvious way to do this is to select a time window and sample a time series
    with a fixed length. In the next step, we want to compare a new time series to
    our previously collected set to detect whether something is out of the ordinary.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始的、流式的时间序列数据中检测异常需要一些数据转换。最明显的方法是选择一个时间窗口，并采样一个固定长度的时间序列。在下一步，我们希望将新的时间序列与之前收集的集合进行比较，以检测是否有异常情况发生。
- en: 'The comparison can be done with various techniques, as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 比较可以使用各种技术进行，如下所示：
- en: Forecasting the most probable following value, as well as the confidence intervals
    (for example, Holt-Winters exponential smoothing). If a new value is out of the
    forecasted confidence interval, it is considered anomalous.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测最可能的后继值以及置信区间（例如，Holt-Winters指数平滑）。如果一个新值超出了预测的置信区间，它被认为是异常的。
- en: Cross-correlation compares a new sample to a library of positive samples, and
    it looks for an exact match. If the match is not found, it is marked as anomalous.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互相关比较一个新样本与一组正样本库，并寻找精确匹配。如果没有找到匹配，它将被标记为异常。
- en: Dynamic time wrapping is similar to cross-correlation, but allows for signal
    distortion in comparison.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态时间卷绕与互相关类似，但允许信号在比较中发生扭曲。
- en: Discretizing signals to bands, where each band corresponds to a letter. For
    example, `A=[min, mean/3]`, `B=[mean/3, mean*2/3]`, and `C=[mean*2/3, max]` transforms
    the signal into a sequence of letters, such as `aAABAACAABBA....` This approach
    reduces the storage and allows us to apply the text mining algorithms that we
    will discuss in [Chapter 10](c3fd3723-2c46-4f0f-aaed-49329c3481ce.xhtml), *Text
    Mining with Mallet – Topic Modeling and Spam Detection*.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将信号离散化为频带，其中每个频带对应一个字母。例如，`A=[min, mean/3]`，`B=[mean/3, mean*2/3]`，和`C=[mean*2/3,
    max]`将信号转换为一系列字母，例如`aAABAACAABBA....`这种方法减少了存储空间，并允许我们应用第10章中将要讨论的文本挖掘算法，即*Mallet文本挖掘
    – 主题建模和垃圾邮件检测*。
- en: A distribution-based approach estimates the distribution of values in a specific
    time window. When we observe a new sample, we can compare whether the distribution
    matches the previously observed one.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于分布的方法估计特定时间窗口中值的分布。当我们观察到一个新的样本时，我们可以比较分布是否与之前观察到的分布相匹配。
- en: This list is by no means exhaustive. Different approaches are focused on detecting
    different anomalies (for example, in the value, frequency, and distribution).
    We will focus on a version of distribution-based approaches in this chapter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表绝对不是详尽的。不同的方法专注于检测不同的异常（例如，在值、频率和分布上）。在本章中，我们将关注基于分布的方法的一个版本。
- en: Using Encog for time series
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Encog进行时间序列分析
- en: 'We have to download the time series data from [https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt](https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt) and
    save the file in the `data` folder. In the `.java` file, we will specify the file
    path, and then we will indicate the format of the file using the following code
    block:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须从[https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt](https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt)下载时间序列数据，并将文件保存在`data`文件夹中。在`.java`文件中，我们将指定文件路径，然后我们将使用以下代码块指示文件的格式：
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, we will create the feedforward network with the window size `1`. When
    processing a time series, you should keep in mind that it should never be shuffled.
    We will hold some data back for validation. We will use the following lines of
    code to do so:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建窗口大小为`1`的前馈网络。在处理时间序列时，你应该记住它永远不应该被打乱。我们将保留一些数据用于验证。我们将使用以下代码行来完成：
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The next step is to run the training with five-fold cross-validation using
    the following line:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用以下行运行带有五折交叉验证的训练：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, it''s time to display the error and the final model. We will do that by
    using the following lines of code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候展示错误和最终模型了。我们将通过以下代码行来完成：
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will be similar to the following screenshot:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下截图：
- en: '![](img/59db7ca2-59d5-4895-8b20-e0493e2f63a1.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59db7ca2-59d5-4895-8b20-e0493e2f63a1.png)'
- en: 'Now, we will test the model using the following code block:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用以下代码块测试模型：
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output will be similar to the following screenshot:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下截图：
- en: '![](img/a6f7bd2b-0899-4495-b84a-9324fedeab78.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a6f7bd2b-0899-4495-b84a-9324fedeab78.png)'
- en: Histogram-based anomaly detection
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于直方图的异常检测
- en: In histogram-based anomaly detection, we split the signals by a selected time
    window, as shown in the following diagram.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于直方图的异常检测中，我们根据选定的时间窗口分割信号，如图所示。
- en: For each window, we calculate the histogram; that is, for a selected number
    of buckets, we count how many values fall into each bucket. The histogram captures
    the basic distribution of values in a selected time window, as shown in the center
    of the diagram.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个窗口，我们计算直方图；也就是说，对于选定的桶数，我们计算每个桶中有多少值。直方图捕捉了选定时间窗口中值的分布情况，如图中所示。
- en: Histograms can then be directly presented as instances, where each bin corresponds
    to an attribute. Furthermore, we can reduce the number of attributes by applying
    a dimensionality-reduction technique, such as **Principal Component Analysis**
    (**PCA**), which allows us to visualize the reduced-dimension histograms in a
    plot, as shown at the bottom-right of the diagram, where each dot corresponds
    to a histogram.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图可以随后直接作为实例展示，其中每个桶对应一个属性。此外，我们可以通过应用降维技术，如**主成分分析**（**PCA**），来减少属性的数量，这允许我们在图中可视化降维后的直方图，如图表右下角所示，其中每个点对应一个直方图。
- en: 'In our example, the idea is to observe website traffic for a couple of days,
    and then create histograms; for example, four-hour time windows, to build a library
    of positive behavior. If a new time window histogram cannot be matched against
    a positive library, we can mark it as an anomaly:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，想法是观察几天内的网站流量，然后创建直方图；例如，四小时的时间窗口，以建立一个积极行为的库。如果一个新时间窗口的直方图无法与积极库匹配，我们可以将其标记为异常：
- en: '![](img/29066236-a70f-48e7-b278-fcc60cd3e79d.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/29066236-a70f-48e7-b278-fcc60cd3e79d.png)'
- en: 'For comparing a new histogram to a set of existing histograms, we will use
    a density-based k-nearest neighbor algorithm, **Local Outlier Factor** (**LOF**)
    (Breunig, et al., 2000). The algorithm is able to handle clusters with different
    densities, as shown in the following diagram. For example, the upper-right cluster
    is large and widespread, compared to the bottom-left cluster, which is smaller
    and denser:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较一个新直方图与一组现有直方图，我们将使用基于密度的k近邻算法，**局部异常因子**（**LOF**）（Breunig等，2000）。该算法能够处理具有不同密度的簇，如下面的图所示。例如，右上角的簇较大且分布广泛，与左下角的簇相比，后者较小且密度更高：
- en: '![](img/619eb30f-21be-43a2-a7c6-e91a99d8d4ad.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/619eb30f-21be-43a2-a7c6-e91a99d8d4ad.png)'
- en: Let's get started!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Loading the data
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'In the first step, we''ll need to load the data from text files to a Java object.
    The files are stored in a folder, and each file contains one time series, with
    values per line. We''ll load them into a `Double` list, as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步，我们需要将数据从文本文件加载到Java对象中。这些文件存储在一个文件夹中，每个文件包含一个时间序列，每行一个值。我们将它们加载到一个`Double`列表中，如下所示：
- en: '[PRE18]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will need the `min` and `max` value for histogram normalization; so, let''s
    collect them in this data pass:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`min`和`max`值来进行直方图归一化；因此，让我们在这个数据传递中收集它们：
- en: '[PRE19]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The data has been loaded. Next, let's move on to histograms.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已经加载。接下来，让我们继续到直方图部分。
- en: Creating histograms
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建直方图
- en: We will create a histogram for a selected time window with the `WIN_SIZE` width.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`WIN_SIZE`宽度创建一个选定时间窗口的直方图。
- en: 'The histogram will hold the `HIST_BINS` value buckets. The histograms consisting
    of lists of doubles will be stored in an array list:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图将包含`HIST_BINS`值桶。由双列表组成的直方图将存储在数组列表中：
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The histograms are now completed. The last step is to transform them into Weka''s
    `Instance` objects. Each histogram value will correspond to one Weka attribute,
    as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图现在已经完成。最后一步是将它们转换为Weka的`Instance`对象。每个直方图值将对应一个Weka属性，如下所示：
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The dataset has been now loaded, and is ready to be plugged into an anomaly
    detection algorithm.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集现在已经加载，并准备好插入到异常检测算法中。
- en: Density-based k-nearest neighbors
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于密度的k近邻
- en: 'To demonstrate how LOF calculates scores, we''ll first split the dataset into
    training and testing sets by using the `testCV(int, int)` function. The first
    parameter specifies the number of folds, while the second parameter specifies
    which fold to return:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示LOF如何计算分数，我们将首先使用`testCV(int, int)`函数将数据集分为训练集和测试集。第一个参数指定了折数，而第二个参数指定了要返回的折：
- en: '[PRE22]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The LOF algorithm is not a part of the default Weka distribution, but it can
    be downloaded through Weka's package manager at [http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html](http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: LOF算法不是Weka默认分布的一部分，但可以通过Weka的包管理器在[http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html](http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html)下载。
- en: 'The LOF algorithm has two implemented interfaces: as an unsupervised filter
    that calculates LOF values (known unknowns), and as a supervised k-nearest neighbors
    classifier (known knowns). In our case, we want to calculate the outlierness factor,
    and therefore, we''ll use the unsupervised filter interface:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: LOF算法有两个实现接口：作为一个无监督过滤器，计算LOF值（已知未知），以及作为一个有监督的k最近邻分类器（已知已知）。在我们的情况下，我们想要计算异常因子，因此我们将使用无监督过滤器接口：
- en: '[PRE23]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The filter is initialized in the same way as a usual filter. We can specify `k`
    number of neighbors (for example, `k=3`) with the `-min` and `-max` parameters.
    `LOF` allows us to specify two different `k` parameters, which are used internally
    as the upper and lower bound, to find the minimum or maximum number of `lof` values:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤器初始化的方式与常规过滤器相同。我们可以使用`-min`和`-max`参数指定邻居的数量（例如，`k=3`）。`LOF`允许我们指定两个不同的`k`参数，这些参数在内部用作上限和下限，以找到最小或最大的`lof`值：
- en: '[PRE24]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we load the training instances into the filter that will serve as a positive
    example library. After we complete the loading, we will call the `batchFinished()` method
    to initialize the internal calculations:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将训练实例加载到作为正例库的过滤器中。加载完成后，我们将调用`batchFinished()`方法来初始化内部计算：
- en: '[PRE25]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, we can apply the filter to the test data. The `Filter()` function
    will process the instances and append an additional attribute at the end, containing
    the LOF score. We can simply provide the score as output in the console:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将过滤器应用于测试数据。`Filter()` 函数将处理实例并在末尾附加一个额外的属性，包含LOF分数。我们可以在控制台中简单地提供分数作为输出：
- en: '[PRE26]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The LOF score of the first couple of test instances is as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 前几个测试实例的LOF分数如下：
- en: '[PRE27]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: To understand the `LOF` values, we need some background on the LOF algorithm.
    It compares the density of an instance to the density of its nearest neighbors.
    The two scores are divided, producing the LOF score. An LOF score of around 1
    indicates that the density is approximately equal, while higher LOF values indicate
    that the density of the instance is substantially lower than the density of its
    neighbors. In such cases, the instance can be marked as anomalous.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解LOF值，我们需要了解LOF算法的一些背景知识。它比较实例的密度与其最近邻的密度。这两个分数相除，产生LOF分数。大约为1的LOF分数表示密度大致相等，而更高的LOF值表示实例的密度显著低于其邻居的密度。在这种情况下，实例可以被标记为异常。
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked into detecting anomalous and suspicious patterns.
    We discussed the two fundamental approaches, focusing on library encoding, either
    positive or negative patterns. Next, we got our hands on two real-life datasets,
    and we discussed how to deal with unbalanced class distributions and how to perform
    anomaly detection on time series data.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了检测异常和可疑模式。我们讨论了两种基本方法，重点关注库编码，即正模式或负模式。接下来，我们处理了两个真实数据集，并讨论了如何处理不平衡的类别分布以及如何在时间序列数据上执行异常检测。
- en: In the next chapter, we'll dive deeper into patterns and more advanced approaches
    to building pattern-based classifiers, and discuss how to assign labels to images
    using deep learning automatically.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨模式以及更高级的基于模式构建分类器的方法，并讨论如何使用深度学习自动为图像分配标签。
