- en: Fraud and Anomaly Detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outlier detection is used to identify exceptions, rare events, and other anomalous
    situations. Such anomalies may be needles in a haystack, but their consequences
    can nonetheless be quite dramatic; for instance, credit card fraud detection,
    identifying network intrusions, faults in manufacturing processes, clinical trials,
    voting activities, and criminal activities in e-commerce. Therefore, anomalies
    represent a high value when they are found and high costs if they are not. Applying
    machine learning to outlier detection problems can bring new insights and better
    detection of outlier events. Machine learning can take into account many disparate
    sources of data, and can find correlations that are too obscure for human analysis
    to identify.
  prefs: []
  type: TYPE_NORMAL
- en: Take the example of e-commerce fraud detection. With machine learning algorithms
    in place, the purchaser's online behavior, that is, website browsing history,
    becomes a part of the fraud detection algorithm, rather than simply the history
    of purchases made by the cardholder. This involves analyzing a variety of data
    sources, but it is also a far more robust approach to e-commerce fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Problems and challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suspicious pattern detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomalous pattern detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with unbalanced datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anomaly detection in time series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suspicious and anomalous behavior detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The problem of learning patterns from sensor data arises in many applications,
    including e-commerce, smart environments, video surveillance, network analysis,
    human-robot interaction, ambient assisted living, and so on. We focus on detecting
    patterns that deviate from regular behaviors and might represent a security risk,
    health problem, or any other abnormal behavior contingency.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, deviant behavior is a data pattern that either does not conform
    to the expected behavior (anomalous behavior) or matches a previously defined
    unwanted behavior (suspicious behavior). Deviant behavior patterns are also referred
    to as outliers, exceptions, peculiarities, surprises, misuse, and so on. Such
    patterns occur relatively infrequently; however, when they do occur, their consequences
    can be quite dramatic, and often negatively so. Typical examples include credit
    card fraud, cyber intrusions, and industrial damage. In e-commerce, fraud is estimated
    to cost merchants more than $200 billion a year; in healthcare, fraud is estimated
    to cost taxpayers $60 billion a year; for banks, the cost is over $12 billion.
  prefs: []
  type: TYPE_NORMAL
- en: Unknown unknowns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When Donald Rumsfeld, US Secretary of Defense, had a news briefing on February
    12, 2002, about the lack of evidence linking the government of Iraq to the supply
    of weapons of mass destruction to terrorist groups, it immediately became a subject
    of much commentary. Rumsfeld stated the following (*DoD News*, 2012):'
  prefs: []
  type: TYPE_NORMAL
- en: '"Reports that say that something hasn''t happened are always interesting to
    me, because as we know, there are known knowns; there are things we know we know.
    We also know there are known unknowns; that is to say we know there are some things
    we do not know. But there are also unknown unknowns-the ones we don''t know we
    don''t know. And if one looks throughout the history of our country and other
    free countries, it is the latter category that tend to be the difficult ones."'
  prefs: []
  type: TYPE_NORMAL
- en: 'This statement might seem confusing at first, but the idea of unknown unknowns
    was well studied among scholars dealing with risk, NSA, and other intelligence
    agencies. What the statement basically implies is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Known knowns**: These are well-known problems or issues; we know how to recognize
    them and how deal with them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Known unknowns**: These are expected or foreseeable problems, which can be
    reasonably anticipated, but have not occurred before'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unknown unknowns**: These are unexpected and unforeseeable problems, which
    pose significant risk, as they cannot be anticipated, based on previous experience'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following sections, we will look into two fundamental approaches dealing
    with the first two types of knowns and unknowns: suspicious pattern detection
    dealing with known knowns, and anomalous pattern detection targeting known unknowns.'
  prefs: []
  type: TYPE_NORMAL
- en: Suspicious pattern detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first approach involves a behavior library that encodes negative patterns,
    shown as red minus signs in the following diagram, and recognizes that observed
    behavior corresponds to identifying a match in the library. If a new pattern can
    be matched against negative patterns, then it is considered suspicious:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f8a12c37-d928-4b52-8fb9-f64f58b30ef8.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, when you visit a doctor, he/she inspects various health symptoms
    (body temperature, pain levels, affected areas, and so on) and matches the symptoms
    to a known disease. In machine learning terms, the doctor collects attributes
    and performs classifications.
  prefs: []
  type: TYPE_NORMAL
- en: An advantage of this approach is that we immediately know what is wrong; for
    example, assuming that we know the disease, we can select an appropriate treatment
    procedure.
  prefs: []
  type: TYPE_NORMAL
- en: A major disadvantage of this approach is that it can only detect suspicious
    patterns that are known in advance. If a pattern is not inserted into a negative
    pattern library, then we will not be able to recognize it. This approach is, therefore,
    appropriate for modeling known knowns.
  prefs: []
  type: TYPE_NORMAL
- en: Anomalous pattern detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The second approach uses the pattern library in an inverse fashion, meaning
    that the library encodes only the positive patterns, which are marked with green
    plus signs in the following diagram. When an observed behavior (the blue circle)
    cannot be matched against the library, it is considered anomalous:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06313d61-ed0f-438c-be5b-41c210160dca.png)'
  prefs: []
  type: TYPE_IMG
- en: This approach requires us to model only what we have seen in the past, that
    is, normal patterns. If we return to the doctor example, the main reason that
    we visited the doctor in the first place was because we did not feel well. Our
    perceived state of feelings (for example, a headache and sore skin) did not match
    our usual feelings, and therefore, we decided to seek a doctor. We don't know
    which disease caused this state, nor do we know the treatment, but we were able
    to observe that it doesn't match the usual state.
  prefs: []
  type: TYPE_NORMAL
- en: A major advantage of this approach is that it does not require us to say anything
    about abnormal patterns; hence, it is appropriate for modeling known unknowns
    and unknown unknowns. On the other hand, it does not tell us exactly what is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Several approaches have been proposed to tackle this problem. We broadly classify
    anomalous and suspicious behavior detection in the following three categories:
    pattern analysis, transaction analysis, and plan recognition. In the following
    sections, we will quickly look at some real-life applications.'
  prefs: []
  type: TYPE_NORMAL
- en: Pattern analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An active area of anomalous and suspicious behavior detection from patterns
    is based on visual modalities, such as a camera. Zhang, et al. (2007) proposed
    a system for a visual human motion analysis from a video sequence, which recognizes
    unusual behavior based on walking trajectories; Lin, et al. (2009) described a
    video surveillance system based on color features, distance features, and a count
    feature, where evolutionary techniques are used to measure observation similarity.
    The system tracks each person and classifies their behavior by analyzing their
    trajectory patterns. The system extracts a set of visual low-level features in
    different parts of the image, and performs a classification with SVMs in order
    to detect aggressive, cheerful, intoxicated, nervous, neutral, and tired behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Transaction analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Transaction analysis assumes discrete states/transactions, in contrast to continuous
    observations. A major research area is **intrusion detection** (**ID**), which
    aims to detect attacks against information systems, in general. There are two
    types of ID systems, signature-based and anomaly-based, that broadly follow the
    suspicious and anomalous pattern detection that was described in the previous
    sections. A comprehensive review of ID approaches was published by Gyanchandani,
    et al. (2012).
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, applications in ambient assisted living that are based on wearable
    sensors also fit to transaction analysis as sensing is typically event-based.
    Lymberopoulos, et al. (2008) proposed a system for automatic extraction of the
    user's spatio-temporal patterns, encoded as sensor activation from the sensor
    network deployed inside their home. The proposed method, based on location, time,
    and duration, was able to extract frequent patterns using the Apriori algorithm
    and encode the most frequent patterns in the form of a Markov chain. Another area
    of related work includes the **hidden Markov models** (**HMMs**) that are widely
    used in traditional activity recognition for modeling a sequence of actions, but
    these topics are already out of the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Plan recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Plan recognition focuses on a mechanism for recognizing the unobservable state
    of an agent, given observations of its interaction with its environment (Avrahami-Zilberbrand,
    2009). Most existing investigations assume discrete observations in the form of
    activities. To perform anomalous and suspicious behavior detection, plan recognition
    algorithms may use a hybrid approach. A symbolic plan recognizer is used to filter
    consistent hypotheses and passes them to an evaluation engine, which focuses on
    ranking.
  prefs: []
  type: TYPE_NORMAL
- en: These were advanced approaches that were applied to various real-life scenarios,
    targeted at discovering anomalies. In the following sections, we'll dive into
    more basic approaches for suspicious and anomalous pattern detection.
  prefs: []
  type: TYPE_NORMAL
- en: Outlier detection using ELKI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**ELKI** stands for **Environment for Loping KDD applications Index** structures,
    where **KDD** stands for **Knowledge Discovery** **in Database**. It is an open
    source software used mainly for data mining, with an emphasis on unsupervised
    learning. It supports various algorithms for cluster analysis and outlier detection.
    The following are some outlier algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distance-based outlier detection**: This is used to specify two parameters.
    The object is flagged **outlier** if its fraction, p, for all the data objects
    that have a distance above d from c. There are many algorithms, such as `DBOutlierDetection`,
    `DBOutlierScore`, `KNNOutlier`, `KNNWeightOutlier`, `ParallelKNNOutlier`, `ParallelKNNWeightOutlier`,
    `ReferenceBasedOutlierDetection`, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LOF family methods**: This computes density-based local outlier factors on
    specific parameters. It includes algorithms such as `LOF`, `ParallelLOF`, `ALOCI`,
    `COF`, `LDF`, `LDOF`, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Angle-based outlier detection**: This uses the variance analysis of angles,
    using mostly high-dimensional datasets. Common algorithms include `ABOD`, `FastABOD`,
    and `LBABOD`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering-based outlier detection**: This uses EM clustering; if the object
    does not belong to a cluster, it is taken as an outlier. This includes algorithms
    such as `EMOutlier` and `KMeansOutlierDetection`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subspace outlier detection**: This uses the outlier detection method for
    axis-parallel subspaces. It has algorithms such as `SOD`, `OutRankS1`, `OUTRES`,
    `AggrawalYuNaive`, and `AggrawalYuEvolutionary`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial outlier detection**: This has large datasets based on locations which
    are collected from different sources and the data point that is an extreme relative
    to neighbors. It has algorithms such as `CTLuGLSBackwardSearchAlgorithm`, `CTLuMeanMultipleAttributes`,
    `CTLuMedianAlgorithm`, `CTLuScatterplotOutlier`, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example using ELKI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml), *Basic Algorithms –
    Classification, Regression, and Clustering*, you already saw how to get the required
    `.jar` file for ELKI. We will follow a similar process, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Command Prompt or Terminal, and execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will provide the GUI interface, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e04484b-a85a-4193-b0d0-db8ea5a05187.png)'
  prefs: []
  type: TYPE_IMG
- en: In the GUI, the dbc.in and algorithm parameters are highlighted and need to
    be set. We will use `pov.csv` file, as dbc.in. This CSV file can be downloaded
    from [https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv](https://github.com/elki-project/elki/blob/master/data/synthetic/ABC-publication/pov.csv).
  prefs: []
  type: TYPE_NORMAL
- en: 'For the algorithm, select outlier.clustering.EMOutlier, and in em.k, pass `3`
    as the value. The following screenshot shows all of the filled-in options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/25c7747f-c7ec-41fb-8105-fff08d32f593.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the Run Task button, and it will process and generate the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a54b3ac3-cc1d-4041-8111-a9bcd32b2818.png)'
  prefs: []
  type: TYPE_IMG
- en: This shows clustering and the possible outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Fraud detection in insurance claims
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we'll take a look at suspicious behavior detection, where the goal is
    to learn about patterns of fraud, which corresponds to modeling known knowns.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll work with a dataset describing insurance transactions, which is publicly
    available in the Oracle database online documentation at [http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm](http://docs.oracle.com/cd/B28359_01/datamine.111/b28129/anomalies.htm).
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset describes insurance claims on vehicle incidents for an undisclosed
    insurance company. It contains 15,430 claims; each claim is comprised of 33 attributes,
    describing the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer demographic details (Age, Sex, MartialStatus, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Purchased policy (PolicyType, VehicleCategory, number of supplements, agent
    type, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Claim circumstances (day/month/week claimed, policy report filed, witness present,
    past days between incident-policy report, incident claim, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other customer data (number of cars, previous claims, DriverRating, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fraud found (yes or no)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The sample of the database shown in the following screenshot depicts the data
    that''s been loaded into Weka:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b856867d-d998-4e54-8ff0-0c66fd7f414b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, the task is to create a model that will be able to identify suspicious
    claims in the future. The challenging thing about this task is the fact that only
    6% of the claims are suspicious. If we create a dummy classifier saying that no
    claim is suspicious, it will be accurate in 94% of cases. Therefore, in this task,
    we will use different accuracy measures: precision and recall.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s recall the outcome table from [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*, where there are four possible outcomes,
    denoted as true positive, false positive, false negative, and true negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | **Classified as** |'
  prefs: []
  type: TYPE_TB
- en: '| **Actual** |  | **Fraud** | **No fraud** |'
  prefs: []
  type: TYPE_TB
- en: '| **Fraud** | TP - true positive | FN - false negative |'
  prefs: []
  type: TYPE_TB
- en: '| **No fraud** | FP - false positive | TN - true negative |'
  prefs: []
  type: TYPE_TB
- en: 'Precision and recall are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** is equal to the proportion of correctly raised alarms, as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/aaae16aa-e167-4849-99ed-8b994958e828.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Recall** is equal to the proportion of deviant signatures, which are correctly
    identified as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/37de70de-abc6-4fa8-81fc-1065b24dcb12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'With these measures–our dummy classifier scores–we find that *Pr = 0* and *Re
    = 0*, as it never marks any instance as fraud (*TP = 0*). In practice, we want
    to compare classifiers by both numbers; hence, we use *F - measure*. This is a
    de facto measure that calculates a harmonic mean between the precision and recall,
    as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/05941bf8-3cd2-4fe7-8226-47141dd632ac.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let's move on to designing a real classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling suspicious patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To design a classifier, we can follow the standard supervised learning steps,
    as described in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml), *Applied
    Machine Learning Quick Start*. In this recipe, we will include some additional
    steps to handle unbalanced datasets and evaluate classifiers based on precision
    and recall. The plan is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the data in the `.csv` format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the class attribute.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert all of the attributes from a numeric to nominal value to make sure that
    there are no incorrectly loaded numerical values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experiment 1**: Evaluating the models with k-fold cross-validation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experiment 2**: Rebalancing the dataset to a more balanced class distribution,
    and manually perform cross-validation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the classifiers by recall, precision, and f-measure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, let''s load the data using the `CSVLoader` class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to make sure that all of the attributes are nominal. During the
    data import, Weka applies some heuristics to guess the most probable attribute
    type, that is, numeric, nominal, string, or date. As heuristics cannot always
    guess the correct type, we can set the types manually, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we continue, we need to specify the attribute that we will try to predict.
    We can achieve this by calling the `setClassIndex(int)` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to remove an attribute describing the policy number, as it has
    no predictive value. We simply apply the `Remove` filter, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to start modeling.
  prefs: []
  type: TYPE_NORMAL
- en: The vanilla approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The vanilla approach is to directly apply the lesson, just like as it was demonstrated
    in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml), *Basic Algorithms
    - Classification, Regression, Clustering*, without any preprocessing, and not
    taking dataset specifics into account. To demonstrate the drawbacks of the vanilla
    approach, we will simply build a model with the default parameters and apply k-fold
    cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s define some classifiers that we want to test, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to create an `Evaluation` object and perform k-fold cross-validation
    by calling the `crossValidate(Classifier, Instances, int, Random, String[])` method,
    providing the `precision`, `recall`, and `fMeasure` as output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The evaluation provides the following scores as output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the results are not very promising. The recall, that is, the
    share of discovered frauds among all frauds, is only 1-3%, meaning that only 1-3/100
    frauds are detected. On the other hand, the precision, that is, the accuracy of
    alarms, is 91%, meaning that in 9/10 cases, when a claim is marked as fraud, the
    model is correct.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset rebalancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the number of negative examples, that is, instances of fraud, is very small
    compared to positive examples, the learning algorithms struggle with induction.
    We can help them by giving them a dataset where the share of positive and negative
    examples is comparable. This can be achieved with dataset rebalancing.
  prefs: []
  type: TYPE_NORMAL
- en: Weka has a built-in filter, `Resample`, which produces a random subsample of
    a dataset, using sampling either with replacement or without replacement. The
    filter can also bias the distribution toward a uniform class distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will proceed by manually implementing k-fold cross-validation. First, we
    will split the dataset into *k* equal folds. Fold *k* will be used for testing,
    while the other folds will be used for learning. To split the dataset into folds,
    we''ll use the `StratifiedRemoveFolds` filter, which maintains the class distribution
    within the folds, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can rebalance the training dataset, where the `-Z` parameter specifies
    the percentage of the dataset to be resampled, and `-B` biases the class distribution
    toward uniform distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can build classifiers and perform evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we calculate the average and provide the best model as output using
    the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the performance of the models has significantly improved, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We can see that all of the models have scored significantly better; for instance,
    the best model, logistic regression, correctly discovers 76% of the fraud, while
    producing a reasonable amount of false alarms–only 13% of the claims marked as
    fraud are indeed fraudulent. If an undetected fraud is significantly more expensive
    than the investigation of false alarms, then it makes sense to deal with an increased
    number of false alarms.
  prefs: []
  type: TYPE_NORMAL
- en: The overall performance most likely still has some room for improvement; we
    could perform attribute selection and feature generation and apply more complex
    model learning, which we discussed in [Chapter 3](e0c71e12-6bd7-4f63-b71d-78bb5a87b801.xhtml),
    *Basic Algorithms – Classification, Regression, Clustering*.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection in website traffic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the second example, we'll focus on modeling the opposite of the previous
    example. Instead of discussing what typical fraudless cases are, we'll discuss
    the normal expected behavior of the system. If something cannot be matched against
    our expected model, it will be considered anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll work with a publicly available dataset that was released by Yahoo! Labs, which
    is useful for discussing how to detect anomalies in time series data. For Yahoo,
    the main use case is in detecting unusual traffic on Yahoo servers.
  prefs: []
  type: TYPE_NORMAL
- en: Even though Yahoo has announced that their data is publicly available, you have
    to apply to use it, and it takes about 24 hours before the approval is granted.
    The dataset is available at [http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70](http://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70).
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset is comprised of real traffic for Yahoo services, along with some
    synthetic data. In total, the dataset contains 367 time series, each of which
    contains between 741 and 1,680 observations, which have been recorded at regular
    intervals. Each series is written in its own file, one observation per line. A
    series is accompanied by a second column indicator, with a one being used if the
    observation was an anomaly, and zero otherwise. The anomalies in real data were
    determined by human judgment, while those in the synthetic data were generated
    algorithmically. A snippet of the synthetic times series data is shown in the
    following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dba0f780-5990-40b0-a735-5374a17d729e.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following section, you'll learn how to transform time series data into
    an attribute presentation that allows us to apply machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection in time series data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Detecting anomalies in raw, streaming time series data requires some data transformation.
    The most obvious way to do this is to select a time window and sample a time series
    with a fixed length. In the next step, we want to compare a new time series to
    our previously collected set to detect whether something is out of the ordinary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The comparison can be done with various techniques, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting the most probable following value, as well as the confidence intervals
    (for example, Holt-Winters exponential smoothing). If a new value is out of the
    forecasted confidence interval, it is considered anomalous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-correlation compares a new sample to a library of positive samples, and
    it looks for an exact match. If the match is not found, it is marked as anomalous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic time wrapping is similar to cross-correlation, but allows for signal
    distortion in comparison.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discretizing signals to bands, where each band corresponds to a letter. For
    example, `A=[min, mean/3]`, `B=[mean/3, mean*2/3]`, and `C=[mean*2/3, max]` transforms
    the signal into a sequence of letters, such as `aAABAACAABBA....` This approach
    reduces the storage and allows us to apply the text mining algorithms that we
    will discuss in [Chapter 10](c3fd3723-2c46-4f0f-aaed-49329c3481ce.xhtml), *Text
    Mining with Mallet – Topic Modeling and Spam Detection*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A distribution-based approach estimates the distribution of values in a specific
    time window. When we observe a new sample, we can compare whether the distribution
    matches the previously observed one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list is by no means exhaustive. Different approaches are focused on detecting
    different anomalies (for example, in the value, frequency, and distribution).
    We will focus on a version of distribution-based approaches in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using Encog for time series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have to download the time series data from [https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt](https://solarscience.msfc.nasa.gov/greenwch/spot_num.txt) and
    save the file in the `data` folder. In the `.java` file, we will specify the file
    path, and then we will indicate the format of the file using the following code
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will create the feedforward network with the window size `1`. When
    processing a time series, you should keep in mind that it should never be shuffled.
    We will hold some data back for validation. We will use the following lines of
    code to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to run the training with five-fold cross-validation using
    the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it''s time to display the error and the final model. We will do that by
    using the following lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/59db7ca2-59d5-4895-8b20-e0493e2f63a1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will test the model using the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be similar to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a6f7bd2b-0899-4495-b84a-9324fedeab78.png)'
  prefs: []
  type: TYPE_IMG
- en: Histogram-based anomaly detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In histogram-based anomaly detection, we split the signals by a selected time
    window, as shown in the following diagram.
  prefs: []
  type: TYPE_NORMAL
- en: For each window, we calculate the histogram; that is, for a selected number
    of buckets, we count how many values fall into each bucket. The histogram captures
    the basic distribution of values in a selected time window, as shown in the center
    of the diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Histograms can then be directly presented as instances, where each bin corresponds
    to an attribute. Furthermore, we can reduce the number of attributes by applying
    a dimensionality-reduction technique, such as **Principal Component Analysis**
    (**PCA**), which allows us to visualize the reduced-dimension histograms in a
    plot, as shown at the bottom-right of the diagram, where each dot corresponds
    to a histogram.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, the idea is to observe website traffic for a couple of days,
    and then create histograms; for example, four-hour time windows, to build a library
    of positive behavior. If a new time window histogram cannot be matched against
    a positive library, we can mark it as an anomaly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29066236-a70f-48e7-b278-fcc60cd3e79d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For comparing a new histogram to a set of existing histograms, we will use
    a density-based k-nearest neighbor algorithm, **Local Outlier Factor** (**LOF**)
    (Breunig, et al., 2000). The algorithm is able to handle clusters with different
    densities, as shown in the following diagram. For example, the upper-right cluster
    is large and widespread, compared to the bottom-left cluster, which is smaller
    and denser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/619eb30f-21be-43a2-a7c6-e91a99d8d4ad.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Loading the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the first step, we''ll need to load the data from text files to a Java object.
    The files are stored in a folder, and each file contains one time series, with
    values per line. We''ll load them into a `Double` list, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need the `min` and `max` value for histogram normalization; so, let''s
    collect them in this data pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The data has been loaded. Next, let's move on to histograms.
  prefs: []
  type: TYPE_NORMAL
- en: Creating histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will create a histogram for a selected time window with the `WIN_SIZE` width.
  prefs: []
  type: TYPE_NORMAL
- en: 'The histogram will hold the `HIST_BINS` value buckets. The histograms consisting
    of lists of doubles will be stored in an array list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The histograms are now completed. The last step is to transform them into Weka''s
    `Instance` objects. Each histogram value will correspond to one Weka attribute,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The dataset has been now loaded, and is ready to be plugged into an anomaly
    detection algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Density-based k-nearest neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate how LOF calculates scores, we''ll first split the dataset into
    training and testing sets by using the `testCV(int, int)` function. The first
    parameter specifies the number of folds, while the second parameter specifies
    which fold to return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The LOF algorithm is not a part of the default Weka distribution, but it can
    be downloaded through Weka's package manager at [http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html](http://weka.sourceforge.net/packageMetaData/localOutlierFactor/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'The LOF algorithm has two implemented interfaces: as an unsupervised filter
    that calculates LOF values (known unknowns), and as a supervised k-nearest neighbors
    classifier (known knowns). In our case, we want to calculate the outlierness factor,
    and therefore, we''ll use the unsupervised filter interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The filter is initialized in the same way as a usual filter. We can specify `k`
    number of neighbors (for example, `k=3`) with the `-min` and `-max` parameters.
    `LOF` allows us to specify two different `k` parameters, which are used internally
    as the upper and lower bound, to find the minimum or maximum number of `lof` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we load the training instances into the filter that will serve as a positive
    example library. After we complete the loading, we will call the `batchFinished()` method
    to initialize the internal calculations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can apply the filter to the test data. The `Filter()` function
    will process the instances and append an additional attribute at the end, containing
    the LOF score. We can simply provide the score as output in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The LOF score of the first couple of test instances is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: To understand the `LOF` values, we need some background on the LOF algorithm.
    It compares the density of an instance to the density of its nearest neighbors.
    The two scores are divided, producing the LOF score. An LOF score of around 1
    indicates that the density is approximately equal, while higher LOF values indicate
    that the density of the instance is substantially lower than the density of its
    neighbors. In such cases, the instance can be marked as anomalous.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked into detecting anomalous and suspicious patterns.
    We discussed the two fundamental approaches, focusing on library encoding, either
    positive or negative patterns. Next, we got our hands on two real-life datasets,
    and we discussed how to deal with unbalanced class distributions and how to perform
    anomaly detection on time series data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll dive deeper into patterns and more advanced approaches
    to building pattern-based classifiers, and discuss how to assign labels to images
    using deep learning automatically.
  prefs: []
  type: TYPE_NORMAL
