- en: Resampling Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be introduced to the fundamental concept of sampling.
    We'll also learn about resampling and why it's important.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling is the process of selecting a subset of observations from the population
    with the purpose of estimating some parameters about the whole population. Resampling
    methods, on the other hand, are used to improve the estimates of the population
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k-fold and leave-one-out cross-validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrap sampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to sampling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sampling techniques can be broadly classified into non-probability sampling
    techniques and probability sampling techniques. Non-probability sampling techniques
    are based on the judgement of the user, whereas in probability sampling, the observations
    are selected by chance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Probability sampling most often includes **simple random sampling (SRS)**,
    stratified sampling, and systematic sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SRS**: In SRS, each observation in the population has an equal probability
    of being chosen for the sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stratified sampling**: In stratified sampling, the population data is divided
    into separate groups, called **strata**. A probability sample is then drawn from
    each group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Systematic sampling**: In this method, a sample is drawn from the population
    by choosing observations at regular intervals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the sample is too small or too large, it may lead to incorrect findings.
    For this reason, it's important that we've got the right sample size. A well-designed
    sample can help identify the biasing factors that can skew the accuracy and reliability
    of the expected outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Errors might be introduced to our samples for a variety of reasons. An error
    might occur due to random sampling, for example, which is known as a **sampling
    error**, or because the method of drawing observations causes the samples to be
    skewed, which is known as **sample bias**.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](2dbc8735-7eef-42ba-8b19-5644632c3197.xhtml), *Get Closer to your
    Data**,* we manipulated and prepared the data from the `HousePrices.csv` file
    and dealt with the missing values. In this example, we're going to use the final
    dataset to demonstrate these sampling and resampling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: You can get the prepared dataset from the GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll import the required libraries. We''ll read the data and take a look
    at the dimensions of our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s read our data. We''ll prefix the DataFrame name with `df_` to make it
    easier to understand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we'll look at how to use `train_test_split()` from `sklean.model_selection`
    to split our data into random training and testing subsets.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have read our dataset, let''s look at how to do the sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We check the dimensions of our DataFrame, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the dimension of our DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a52b784-69a5-4a03-a9cf-8b2c4bd9f643.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We then look to see if our DataFrame has any missing values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We notice that there are no missing values in `df_housingdata`
  prefs: []
  type: TYPE_NORMAL
- en: 'We separate the predictor and response variable into two different DataFrames, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We split both our predictor and our response datasets into training and testing
    subsets using `train_test_split()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can find the number of observations and columns in each subset as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that 70% of the data has been allocated to the training dataset
    and 30% has been allocated to the testing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/794a1517-b761-4d47-9a3c-0eee716977f7.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step 1* and *Step 2*, we looked at the dimensions of our DataFrame and found
    that our dataset had no missing values. In *Step 3*, we separated out the features
    and the response variable. In *Step 4*, we used the `train_test_split()` function
    from `sklearn.model_selection` to split our data and create the training and testing
    subsets. Notice that we passed two parameters, `train_size` and `test_size`, and
    set the values to `0.7` and `0.3`, respectively. `train_size` and `test_size`
    can take values between 0.0 and 1.0, which represent the proportion of the dataset
    allocated to each. If an integer value is provided, the number represents the
    absolute number of observations.
  prefs: []
  type: TYPE_NORMAL
- en: We can choose not to provide either of the two parameters, that is `train_size`
    or `test_size`. If we set the value of the `train_size` to `None` or if we do
    not provide it at all, the value is automatically set to complement the test size.
    Similarly, if `test_size` is unspecified or we set its value to `None`, the value
    is automatically set to complement the train size.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 5*, we looked at the shape of the subsets that were created by the
    `train_test_split()` function.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we''re going to use a dataset in which we measure a dichotomous
    categorical target variable. It''s important to understand that the distribution
    of both classes of our target variable is similar in both the training and testing
    subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by reading our dataset and looking at its dimensions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We have 30,000 observations with 25 variables. The last variable, the default
    payment next month, is our target variable, which has values that are either *0*
    or *1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We separate our data into a feature set and the response variable and split
    it into training and testing subsets using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note that, this time, we've used a parameter, `stratify`, in our `train_test_split()` function. The `stratify` parameter makes
    a split so that the proportion of values in the sample that's produced is equal
    to the proportion of values in the variable that's provided to it. Also note that
    we've assigned the response variable, `Y`, to the `stratify` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now see the distribution of our dichotomous class in our target variable
    for both the training and testing subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following output, we can see that the distributions of both the classes
    are the same in both subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/949d0716-b0f3-4781-bacb-b0188c5d69c6.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also pass another parameter, `shuffle`, to `train_test_split()`. This
    takes a Boolean value, `True` or `False`, to indicate whether or not to shuffle
    the data before splitting it. If `shuffle=False`, then `stratify` must be `None`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scikit-learn guide to `sklearn.model_selection`: [https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k-fold and leave-one-out cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning models often face the problem of generalization when they're
    applied to unseen data to make predictions. To avoid this problem, the model isn't
    trained using the complete dataset. Instead, the dataset is split into training
    and testing subsets. The model is trained on the training data and evaluated on
    the testing set, which it doesn't see during the training process. This is the
    fundamental idea behind cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest kind of cross-validation is the holdout method, which we saw in
    the previous recipe, *Introduction to sampling*. In the holdout method, when we
    split our data into training and testing subsets, there's a possibility that the
    testing set isn't that similar to the training set because of the high dimensionality
    of the data. This can lead to instability in the outcome. For this reason, it's
    very important that we sample our data efficiently. We can solve this problem
    using other cross-validation methods such as **leave-one-out cross-validation**
    (**LOOCV**) or **k-fold cross-validation** (**k-fold CV**).
  prefs: []
  type: TYPE_NORMAL
- en: 'k-fold CV is a widely used approach that''s used for estimating test errors. The
    original dataset with *N* observations is divided into *K* subsets and the holdout
    method is repeated *K* times. In each iteration, *K-1* subsets are used as the
    training set and the rest are used as the testing set. The error is calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35929789-baf8-4ee5-9649-8d5a4251c834.png)'
  prefs: []
  type: TYPE_IMG
- en: In LOOCV, the number of subsets *K* is equal to the number of observations in
    the dataset, *N*. LOOCV uses one observation from the original dataset as the
    validation set and the remaining *N-1* observations as the training set. This
    is iterated *N* times, so that each observation in the sample is used as the validation
    data in each iteration. This is the same as k-fold CV, in which *K* equals *N*,
    the number of data points in the set. LOOCV usually takes a lot of computational
    power because of the large number of iterations required.
  prefs: []
  type: TYPE_NORMAL
- en: In LOOCV, the estimates from each fold are highly correlated and their average
    can have a high level of variance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimating the test error is based on a single observation and is represented
    as *MSE =* ![](img/c3d1a06d-4629-40a7-8e98-9201740fd95e.png). We can compute the
    average of the MSEs for all the folds as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/247c3c78-5e6a-4fe0-a069-bb90cd6c73c7.png)'
  prefs: []
  type: TYPE_IMG
- en: This calculation is no different from the calculation involved in k-fold CV. We'll
    use scikit-learn libraries to see how techniques such as k-fold CV and LOOCV can
    be implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following code block, we can see how we can import the required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We read our data and split the features and the response variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The k-folds cross-validator provides us with the train and test indices to
    split the data into training and testing subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll split the dataset into *K* consecutive folds (without shuffling by default)
    with *K=10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can look at our coefficient of determination using `r2_score()` and the
    mean squared error using `mse()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of the preceding code are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/635b6459-6f3f-4046-8923-bf567ae9a1d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We plot the predicted values against the actual values of the response variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated by the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1d3bbb0c-ad84-4502-857a-ec195573f3db.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step 1*, the k-fold cross validator splits the dataset into *K* consecutive
    folds with *K*=10\. The k-fold cross-validator provides us with the train and
    test indices and then splits the data into training and testing subsets. In *Step*
    2, we looked at the coefficient of determination using `r2_score()` and the mean
    squared error using `mse()`. The coefficient of determination and the mean squared
    error are 79% and 12.85, respectively. In *Step 3*, we plotted the predicted values
    against the actual values of the response variable, `mpg`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll now do the same exercise with LOOCV by using `LeaveOneOut` from `sklearn.model_selection`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll read our data once again and split it into the features and response
    sets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We use LOOCV to build our models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can look at our coefficient of determination using `r2_score()` and the
    mean squared error using `mse()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can take a look at the coefficient of determination, and the mean squared
    error for the LOOCV results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bc1d360-d30b-4a3b-b22b-16fc5935b2ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can plot the predicted values against the actual values of the response
    variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot that is generated by the preceding code gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/969f0588-1f82-4dde-8732-f3a96c8f59a4.png)'
  prefs: []
  type: TYPE_IMG
- en: In LOOCV, there is no randomness in the splitting method, so it'll always provide
    you with the same result.
  prefs: []
  type: TYPE_NORMAL
- en: The stratified k-fold CV method is often used in classification problems. This is
    a variation of the k-fold CV method that returns stratified folds. Each set contains
    a similar percentage of samples of each target class as the original dataset.
    `startifiedShuffleSplit` is a variation of shuffle splits, which creates splits
    by maintaining the same percentage for every target class.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scikit-learn guide to other methods of cross-validation: [https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrapping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bootstrapping is based on the jackknife method, which was proposed by Quenouille
    in 1949, and then refined by Tukey in 1958\. The jackknife method is used for
    testing hypotheses and estimating confidence intervals. It's obtained by calculating
    the estimate after leaving out each observation and then computing the average
    of these calculations. With a sample of size *N*, the jackknife estimate can be
    found by aggregating the estimates of every *N-1* sized sub-sample. It's similar
    to bootstrap samples, but while the bootstrap method is sampling with replacement,
    the jackknife method samples the data without replacement.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping is a powerful, non-parametric resampling technique that's used
    to assess the uncertainty in the estimator. In bootstrapping, a large number of
    samples with the same size are drawn repeatedly from an original sample. This
    allows a given observation to be included in more than one sample, which is known
    as **sampling with replacement**. In the bootstrap method, *n* samples are created
    from the original data by sampling with replacement. Each sample is of identical
    size. The larger *n*, the closer the set of samples will be to the ideal bootstrap
    sample.
  prefs: []
  type: TYPE_NORMAL
- en: '"The essence of bootstrapping is the idea that in the absence of any other
    knowledge about a population, the distribution of values found in a random sample
    of size n from the population is the best guide to the distribution in the population.
    Therefore to approximate what would happen if the population was resampled, it''s
    sensible to resample the sample. In other words, the infinite population that
    consists of the n observed sample values, each with probability 1/n, is used to
    model the unknown real population."'
  prefs: []
  type: TYPE_NORMAL
- en: –Bryan F. J. Manly
  prefs: []
  type: TYPE_NORMAL
- en: 'A diagrammatic representation of a bootstrap sample would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46b71607-5c54-458b-a8f9-15f877441fdd.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see in the preceding diagram, some of the data points in the **S1**
    subset also appear in **S2** and **S4**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say that we have *n* bootstrap samples from our original sample. ![](img/f0c73234-b84a-449c-a947-9dd4a49c0086.png)
    denotes the estimates of the *n* bootstrap samples where *i=1,2,3...,n*. If ![](img/0a211672-b39b-48fd-9297-9052c060f949.png) denotes
    the estimate of the parameter for the original sample, the standard error for ![](img/f1a80abe-c907-4179-871f-e64341fd5190.png) is
    given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51c33b62-2975-455f-b6a0-220137c1667c.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png) is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8efea2c2-bddf-4d60-ace9-2ef3f4ac5708.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png) is the mean of the estimates
    across the *n* bootstrap samples.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to import the required libraries as usual. This time, we will use the `resample`
    class from `sklean.utils`, which we''ve not used previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We load our data and fill in the missing values with the median for the `horsepower`
    variable. We also drop the `carname` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have read our data, let''s see how we can perform bootstrap sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We write a custom function, `create_bootstrap_oob()`, which takes a DataFrame
    as a parameter and uses the `resample()` function from `sklearn.utils` to create
    a bootstrap sample with 100 observations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We loop through 50 iterations and call the custom function by passing the `df_autodata`
    DataFrame. We capture the mean of the `mpg` variable for each bootstrap sample,
    which we''ll measure against the mean of the `mpg` variable in our original DataFrame,
    which is `df_autodata`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We plot the mean of the `mpg` variable for each iteration, for which a separate
    bootstrap sample has been considered. We capture the mean of the `mpg` variable
    for each bootstrap sample in each iteration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We finally plot the mean of the `mpg` variable against each iteration, which
    can be seen in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/179ce760-d743-439f-8db3-2cb4d4d1bc97.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step 1*, we created a custom function, `create_bootstrap_oob( )`, and used
    the `resample()` function from `sklearn.utils` to create a bootstrap sample with
    100 observations. The `create_bootstrap_oob( )` custom function took a DataFrame
    as an input parameter and created both bootstrap and **Out-Of-the-Bag** (**OOB**)
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned that bootstrap sampling is sampling with replacement. This means
    that any given observation can appear more than once in a single sample.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 2*, we looped through the 50 iterations and called the `create_bootstrap_oob(
    )` custom function by passing `df_autoframe`. We captured the mean of the `mpg`
    variable for each bootstrap sample. In *Step 3*, we considered a separate bootstrap
    sample for each iteration. We captured the mean of the `mpg` variable against
    each iteration and then plotted the mean of the `mpg` variable for each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scikit-learn guide to `sklearn.cross_validation.Bootstrap`: [https://bit.ly/2RC5MYv](https://bit.ly/2RC5MYv)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
