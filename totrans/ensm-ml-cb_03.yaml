- en: Resampling Methods
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重抽样方法
- en: In this chapter, we will be introduced to the fundamental concept of sampling.
    We'll also learn about resampling and why it's important.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍抽样的基本概念。我们还将了解重抽样及其重要性。
- en: Sampling is the process of selecting a subset of observations from the population
    with the purpose of estimating some parameters about the whole population. Resampling
    methods, on the other hand, are used to improve the estimates of the population
    parameters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样是从总体中选择观测子集的过程，目的是估计关于整个总体的某些参数。另一方面，重抽样方法用于改进对总体参数的估计。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Introduction to sampling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽样简介
- en: k-fold and leave-one-out cross-validation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k折交叉验证和留一法交叉验证
- en: Bootstrap sampling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自举抽样
- en: Introduction to sampling
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抽样简介
- en: Sampling techniques can be broadly classified into non-probability sampling
    techniques and probability sampling techniques. Non-probability sampling techniques
    are based on the judgement of the user, whereas in probability sampling, the observations
    are selected by chance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样技术可以大致分为非概率抽样技术和概率抽样技术。非概率抽样技术基于用户的判断，而在概率抽样中，观测值是通过机会选择的。
- en: 'Probability sampling most often includes **simple random sampling (SRS)**,
    stratified sampling, and systematic sampling:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 概率抽样通常包括**简单随机抽样（SRS）**、分层抽样和系统抽样：
- en: '**SRS**: In SRS, each observation in the population has an equal probability
    of being chosen for the sample.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SRS**：在简单随机抽样（SRS）中，总体中的每个观测值都有同等的机会被选中作为样本。'
- en: '**Stratified sampling**: In stratified sampling, the population data is divided
    into separate groups, called **strata**. A probability sample is then drawn from
    each group.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层抽样**：在分层抽样中，总体数据被分为不同的组，称为**层**。然后从每个组中抽取概率样本。'
- en: '**Systematic sampling**: In this method, a sample is drawn from the population
    by choosing observations at regular intervals.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统抽样**：在此方法中，通过选择固定间隔的观测值从总体中抽取样本。'
- en: If the sample is too small or too large, it may lead to incorrect findings.
    For this reason, it's important that we've got the right sample size. A well-designed
    sample can help identify the biasing factors that can skew the accuracy and reliability
    of the expected outcome.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果样本太小或太大，可能会导致错误的发现。因此，确保我们有正确的样本大小非常重要。一个设计良好的样本可以帮助识别可能导致预期结果准确性和可靠性偏差的因素。
- en: Errors might be introduced to our samples for a variety of reasons. An error
    might occur due to random sampling, for example, which is known as a **sampling
    error**, or because the method of drawing observations causes the samples to be
    skewed, which is known as **sample bias**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于各种原因，我们的样本可能会引入错误。例如，由于随机抽样可能发生的错误，这被称为**抽样误差**，或者由于抽取观测值的方法导致样本偏斜，这被称为**样本偏差**。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In [Chapter 1](2dbc8735-7eef-42ba-8b19-5644632c3197.xhtml), *Get Closer to your
    Data**,* we manipulated and prepared the data from the `HousePrices.csv` file
    and dealt with the missing values. In this example, we're going to use the final
    dataset to demonstrate these sampling and resampling techniques.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](2dbc8735-7eef-42ba-8b19-5644632c3197.xhtml)“更接近你的数据”中，我们操作并准备了`HousePrices.csv`文件中的数据，并处理了缺失值。在这个例子中，我们将使用最终数据集来演示这些抽样和重抽样技术。
- en: You can get the prepared dataset from the GitHub.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub获取准备好的数据集。
- en: 'We''ll import the required libraries. We''ll read the data and take a look
    at the dimensions of our dataset:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入所需的库。我们将读取数据并查看数据集的维度：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s read our data. We''ll prefix the DataFrame name with `df_` to make it
    easier to understand:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们读取我们的数据。我们将DataFrame名称前缀为`df_`以使其更容易理解：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the next section, we'll look at how to use `train_test_split()` from `sklean.model_selection`
    to split our data into random training and testing subsets.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何使用`sklearn.model_selection`中的`train_test_split()`来将我们的数据分割成随机的训练和测试子集。
- en: How to do it...
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Now that we have read our dataset, let''s look at how to do the sampling:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经读取了我们的数据集，让我们看看如何进行抽样：
- en: 'We check the dimensions of our DataFrame, as follows:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查DataFrame的维度，如下所示：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can see the dimension of our DataFrame:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的DataFrame的维度：
- en: '![](img/2a52b784-69a5-4a03-a9cf-8b2c4bd9f643.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2a52b784-69a5-4a03-a9cf-8b2c4bd9f643.png)'
- en: 'We then look to see if our DataFrame has any missing values:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们检查我们的DataFrame是否有任何缺失值：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We notice that there are no missing values in `df_housingdata`
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到`df_housingdata`中没有缺失值。
- en: 'We separate the predictor and response variable into two different DataFrames, as
    follows:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将预测变量和响应变量分别放入两个不同的DataFrame中，如下所示：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We split both our predictor and our response datasets into training and testing
    subsets using `train_test_split()`:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`train_test_split()`将我们的预测变量和响应变量数据集分割成训练和测试子集：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can find the number of observations and columns in each subset as follows:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以按照以下方式找到每个子集中的观测值和列数：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see that 70% of the data has been allocated to the training dataset
    and 30% has been allocated to the testing dataset:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到70%的数据被分配到了训练数据集中，而30%被分配到了测试数据集中：
- en: '![](img/794a1517-b761-4d47-9a3c-0eee716977f7.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/794a1517-b761-4d47-9a3c-0eee716977f7.png)'
- en: How it works...
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1* and *Step 2*, we looked at the dimensions of our DataFrame and found
    that our dataset had no missing values. In *Step 3*, we separated out the features
    and the response variable. In *Step 4*, we used the `train_test_split()` function
    from `sklearn.model_selection` to split our data and create the training and testing
    subsets. Notice that we passed two parameters, `train_size` and `test_size`, and
    set the values to `0.7` and `0.3`, respectively. `train_size` and `test_size`
    can take values between 0.0 and 1.0, which represent the proportion of the dataset
    allocated to each. If an integer value is provided, the number represents the
    absolute number of observations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*和*步骤2*中，我们查看DataFrame的维度，发现我们的数据集没有缺失值。在*步骤3*中，我们将特征和响应变量分离出来。在*步骤4*中，我们使用`sklearn.model_selection`中的`train_test_split()`函数来分割我们的数据并创建训练和测试子集。注意，我们传递了两个参数`train_size`和`test_size`，并分别将它们的值设置为`0.7`和`0.3`。`train_size`和`test_size`可以取0.0到1.0之间的值，这些值代表分配给每个数据集的比例。如果提供了一个整数值，那么这个数字代表观测值的绝对数量。
- en: We can choose not to provide either of the two parameters, that is `train_size`
    or `test_size`. If we set the value of the `train_size` to `None` or if we do
    not provide it at all, the value is automatically set to complement the test size.
    Similarly, if `test_size` is unspecified or we set its value to `None`, the value
    is automatically set to complement the train size.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择不提供这两个参数中的任何一个，即`train_size`或`test_size`。如果我们把`train_size`的值设置为`None`或者根本不提供它，那么它的值会自动设置为与测试大小相补充。同样，如果`test_size`未指定或者我们将其值设置为`None`，它的值会自动设置为与训练大小相补充。
- en: In *Step 5*, we looked at the shape of the subsets that were created by the
    `train_test_split()` function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤5*中，我们查看了由`train_test_split()`函数创建的子集的形状。
- en: There's more...
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In this example, we''re going to use a dataset in which we measure a dichotomous
    categorical target variable. It''s important to understand that the distribution
    of both classes of our target variable is similar in both the training and testing
    subsets:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用一个数据集来衡量一个二分分类的目标变量。重要的是要理解，我们的目标变量的两个类别在训练和测试子集中分布是相似的：
- en: 'We start by reading our dataset and looking at its dimensions:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先读取我们的数据集并查看其维度：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We have 30,000 observations with 25 variables. The last variable, the default
    payment next month, is our target variable, which has values that are either *0*
    or *1*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有30,000个观测值和25个变量。最后一个变量，下个月默认付款，是我们的目标变量，其值要么是*0*要么是*1*。
- en: 'We separate our data into a feature set and the response variable and split
    it into training and testing subsets using the following code:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据分成特征集和响应变量，并使用以下代码将其分割成训练和测试子集：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that, this time, we've used a parameter, `stratify`, in our `train_test_split()` function. The `stratify` parameter makes
    a split so that the proportion of values in the sample that's produced is equal
    to the proportion of values in the variable that's provided to it. Also note that
    we've assigned the response variable, `Y`, to the `stratify` parameter.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这次我们在`train_test_split()`函数中使用了参数`stratify`。`stratify`参数使得分割后的样本中值的比例等于提供给它的变量的值的比例。此外，我们还把响应变量`Y`分配给了`stratify`参数。
- en: 'We can now see the distribution of our dichotomous class in our target variable
    for both the training and testing subsets:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到训练和测试子集中目标变量的二分类分布：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the following output, we can see that the distributions of both the classes
    are the same in both subsets:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的输出中，我们可以看到两个子集中类的分布是相同的：
- en: '![](img/949d0716-b0f3-4781-bacb-b0188c5d69c6.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/949d0716-b0f3-4781-bacb-b0188c5d69c6.png)'
- en: We can also pass another parameter, `shuffle`, to `train_test_split()`. This
    takes a Boolean value, `True` or `False`, to indicate whether or not to shuffle
    the data before splitting it. If `shuffle=False`, then `stratify` must be `None`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以传递另一个参数`shuffle`给`train_test_split()`。这个参数接受布尔值`True`或`False`，以指示在分割数据之前是否要打乱数据。如果`shuffle=False`，则`stratify`必须是`None`。
- en: See also
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: The scikit-learn guide to `sklearn.model_selection`: [https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn的`sklearn.model_selection`指南：[https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
- en: k-fold and leave-one-out cross-validation
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: k-fold和留一法交叉验证
- en: Machine learning models often face the problem of generalization when they're
    applied to unseen data to make predictions. To avoid this problem, the model isn't
    trained using the complete dataset. Instead, the dataset is split into training
    and testing subsets. The model is trained on the training data and evaluated on
    the testing set, which it doesn't see during the training process. This is the
    fundamental idea behind cross-validation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型在应用于未见数据以进行预测时，通常会面临泛化问题。为了避免这个问题，模型不是使用完整的数据集进行训练。相反，数据集被划分为训练集和测试集。模型在训练数据上训练，并在测试集上评估，而测试集在训练过程中并未看到。这是交叉验证的基本思想。
- en: The simplest kind of cross-validation is the holdout method, which we saw in
    the previous recipe, *Introduction to sampling*. In the holdout method, when we
    split our data into training and testing subsets, there's a possibility that the
    testing set isn't that similar to the training set because of the high dimensionality
    of the data. This can lead to instability in the outcome. For this reason, it's
    very important that we sample our data efficiently. We can solve this problem
    using other cross-validation methods such as **leave-one-out cross-validation**
    (**LOOCV**) or **k-fold cross-validation** (**k-fold CV**).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的交叉验证类型是保留方法，我们在之前的配方“采样介绍”中看到了它。在保留方法中，当我们把数据分成训练集和测试集时，由于数据的高维性，测试集可能并不那么类似于训练集。这可能导致结果的不稳定。因此，我们高效地采样数据非常重要。我们可以使用其他交叉验证方法来解决这个问题，例如**留一法交叉验证**（**LOOCV**）或**k-fold交叉验证**（**k-fold
    CV**）。
- en: 'k-fold CV is a widely used approach that''s used for estimating test errors. The
    original dataset with *N* observations is divided into *K* subsets and the holdout
    method is repeated *K* times. In each iteration, *K-1* subsets are used as the
    training set and the rest are used as the testing set. The error is calculated
    as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: k-fold CV是一种广泛使用的方法，用于估计测试误差。原始数据集包含*N*个观测值，被划分为*K*个子集，并且保留方法被重复*K*次。在每次迭代中，*K-1*个子集被用作训练集，其余的用作测试集。误差的计算如下：
- en: '![](img/35929789-baf8-4ee5-9649-8d5a4251c834.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/35929789-baf8-4ee5-9649-8d5a4251c834.png)'
- en: In LOOCV, the number of subsets *K* is equal to the number of observations in
    the dataset, *N*. LOOCV uses one observation from the original dataset as the
    validation set and the remaining *N-1* observations as the training set. This
    is iterated *N* times, so that each observation in the sample is used as the validation
    data in each iteration. This is the same as k-fold CV, in which *K* equals *N*,
    the number of data points in the set. LOOCV usually takes a lot of computational
    power because of the large number of iterations required.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在LOOCV中，子集的数量*K*等于数据集中观测值的数量*N*。LOOCV使用原始数据集中的一个观测值作为验证集，其余*N-1*个观测值作为训练集。这被迭代*N*次，以便样本中的每个观测值在每个迭代中都用作验证数据。这与k-fold
    CV相同，其中*K*等于*N*，即数据集中的数据点数量。由于需要大量的迭代，LOOCV通常需要大量的计算能力。
- en: In LOOCV, the estimates from each fold are highly correlated and their average
    can have a high level of variance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在LOOCV中，每个折叠的估计值高度相关，它们的平均值可能有很高的方差。
- en: 'Estimating the test error is based on a single observation and is represented
    as *MSE =* ![](img/c3d1a06d-4629-40a7-8e98-9201740fd95e.png). We can compute the
    average of the MSEs for all the folds as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 测试误差的估计基于单个观测值，表示为*MSE =* ![图片](img/c3d1a06d-4629-40a7-8e98-9201740fd95e.png)。我们可以计算所有折叠的MSE的平均值如下：
- en: '![](img/247c3c78-5e6a-4fe0-a069-bb90cd6c73c7.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/247c3c78-5e6a-4fe0-a069-bb90cd6c73c7.png)'
- en: This calculation is no different from the calculation involved in k-fold CV. We'll
    use scikit-learn libraries to see how techniques such as k-fold CV and LOOCV can
    be implemented.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种计算与k-fold CV中涉及的计算没有不同。我们将使用scikit-learn库来查看如何实现k-fold CV和LOOCV等技术。
- en: Getting ready
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In the following code block, we can see how we can import the required libraries:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们可以看到如何导入所需的库：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We read our data and split the features and the response variable:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取我们的数据，并将特征和响应变量分开：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How to do it...
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'The k-folds cross-validator provides us with the train and test indices to
    split the data into training and testing subsets:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: k 折交叉验证提供给我们训练和测试索引，以便将数据分为训练集和测试集：
- en: 'We''ll split the dataset into *K* consecutive folds (without shuffling by default)
    with *K=10*:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据集分成 *K* 个连续的折叠（默认情况下不进行洗牌），其中 *K=10*：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can look at our coefficient of determination using `r2_score()` and the
    mean squared error using `mse()`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `r2_score()` 来查看我们的决定系数，并使用 `mse()` 来查看我们的均方误差：
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The results of the preceding code are as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的结果如下：
- en: '![](img/635b6459-6f3f-4046-8923-bf567ae9a1d9.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/635b6459-6f3f-4046-8923-bf567ae9a1d9.png)'
- en: 'We plot the predicted values against the actual values of the response variable:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将预测值与响应变量的实际值进行绘图：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The plot generated by the preceding code is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成的图如下：
- en: '![](img/1d3bbb0c-ad84-4502-857a-ec195573f3db.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d3bbb0c-ad84-4502-857a-ec195573f3db.png)'
- en: How it works...
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, the k-fold cross validator splits the dataset into *K* consecutive
    folds with *K*=10\. The k-fold cross-validator provides us with the train and
    test indices and then splits the data into training and testing subsets. In *Step*
    2, we looked at the coefficient of determination using `r2_score()` and the mean
    squared error using `mse()`. The coefficient of determination and the mean squared
    error are 79% and 12.85, respectively. In *Step 3*, we plotted the predicted values
    against the actual values of the response variable, `mpg`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，k 折交叉验证将数据集分成 *K* 个连续的折叠，其中 *K*=10。k 折交叉验证提供给我们训练和测试索引，然后分割数据为训练集和测试集。在
    *步骤 2* 中，我们使用了 `r2_score()` 来查看决定系数，并使用 `mse()` 来查看均方误差。决定系数和均方误差分别是 79% 和 12.85。在
    *步骤 3* 中，我们绘制了预测值与响应变量 `mpg` 的实际值。
- en: There's more...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We''ll now do the same exercise with LOOCV by using `LeaveOneOut` from `sklearn.model_selection`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 `sklearn.model_selection` 中的 `LeaveOneOut` 来进行相同的 LOOCV 练习：
- en: 'We''ll read our data once again and split it into the features and response
    sets:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将再次读取我们的数据，并将其分为特征集和响应集：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We use LOOCV to build our models:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 LOOCV 来构建我们的模型：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can look at our coefficient of determination using `r2_score()` and the
    mean squared error using `mse()`:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `r2_score()` 来查看我们的决定系数，并使用 `mse()` 来查看我们的均方误差：
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can take a look at the coefficient of determination, and the mean squared
    error for the LOOCV results:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看 LOOCV 结果的决定系数和均方误差：
- en: '![](img/0bc1d360-d30b-4a3b-b22b-16fc5935b2ce.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bc1d360-d30b-4a3b-b22b-16fc5935b2ce.png)'
- en: 'We can plot the predicted values against the actual values of the response
    variable:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将预测值与响应变量的实际值进行绘图：
- en: '[PRE18]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The plot that is generated by the preceding code gives us the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成的图给出了以下输出：
- en: '![](img/969f0588-1f82-4dde-8732-f3a96c8f59a4.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/969f0588-1f82-4dde-8732-f3a96c8f59a4.png)'
- en: In LOOCV, there is no randomness in the splitting method, so it'll always provide
    you with the same result.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LOOCV 中，分割方法没有随机性，所以它总是会给你相同的结果。
- en: The stratified k-fold CV method is often used in classification problems. This is
    a variation of the k-fold CV method that returns stratified folds. Each set contains
    a similar percentage of samples of each target class as the original dataset.
    `startifiedShuffleSplit` is a variation of shuffle splits, which creates splits
    by maintaining the same percentage for every target class.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 分层 k 折交叉验证方法常用于分类问题。这是 k 折交叉验证方法的一种变体，它返回分层折叠。每个集合包含与原始数据集相似百分比的每个目标类的样本。`StratifiedShuffleSplit`
    是洗牌分割的变体，通过保持每个目标类的相同百分比来创建分割。
- en: See also
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The scikit-learn guide to other methods of cross-validation: [https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn 对其他交叉验证方法的指南：[https://bit.ly/2px08Ii](https://bit.ly/2px08Ii)
- en: Bootstrapping
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自举
- en: Bootstrapping is based on the jackknife method, which was proposed by Quenouille
    in 1949, and then refined by Tukey in 1958\. The jackknife method is used for
    testing hypotheses and estimating confidence intervals. It's obtained by calculating
    the estimate after leaving out each observation and then computing the average
    of these calculations. With a sample of size *N*, the jackknife estimate can be
    found by aggregating the estimates of every *N-1* sized sub-sample. It's similar
    to bootstrap samples, but while the bootstrap method is sampling with replacement,
    the jackknife method samples the data without replacement.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrapping基于1949年由Quenouille提出的jackknife方法，并在1958年由Tukey改进。jackknife方法用于检验假设和估计置信区间。它是通过在每次移除每个观测值后计算估计值，然后计算这些计算的平均值来获得的。对于大小为*N*的样本，可以通过聚合每个*N-1*大小的子样本的估计值来找到jackknife估计值。它与bootstrap样本类似，但while
    bootstrap方法是带替换的抽样，jackknife方法是不带替换地抽样数据。
- en: Bootstrapping is a powerful, non-parametric resampling technique that's used
    to assess the uncertainty in the estimator. In bootstrapping, a large number of
    samples with the same size are drawn repeatedly from an original sample. This
    allows a given observation to be included in more than one sample, which is known
    as **sampling with replacement**. In the bootstrap method, *n* samples are created
    from the original data by sampling with replacement. Each sample is of identical
    size. The larger *n*, the closer the set of samples will be to the ideal bootstrap
    sample.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrapping是一种强大的非参数重抽样技术，用于评估估计值的不确定性。在bootstrapping中，从原始样本中反复抽取具有相同大小的大量样本。这允许一个给定的观测值被包含在多个样本中，这被称为**带替换的抽样**。在bootstrap方法中，通过带替换抽样从原始数据中创建*n*个样本。每个样本的大小相同。*n*越大，样本集将越接近理想的bootstrap样本。
- en: '"The essence of bootstrapping is the idea that in the absence of any other
    knowledge about a population, the distribution of values found in a random sample
    of size n from the population is the best guide to the distribution in the population.
    Therefore to approximate what would happen if the population was resampled, it''s
    sensible to resample the sample. In other words, the infinite population that
    consists of the n observed sample values, each with probability 1/n, is used to
    model the unknown real population."'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: “Bootstrapping的本质是这样一个想法：在没有关于总体任何其他知识的情况下，从总体中随机抽取大小为n的样本中找到的值的分布是总体分布的最佳指南。因此，为了近似如果总体被重新抽样的情况，重新抽样样本是合理的。换句话说，由n个观测样本值组成的无限总体，每个值有1/n的概率，被用来模拟未知的真实总体。”
- en: –Bryan F. J. Manly
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: –Bryan F. J. Manly
- en: 'A diagrammatic representation of a bootstrap sample would look as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一个bootstrap样本的图示表示如下：
- en: '![](img/46b71607-5c54-458b-a8f9-15f877441fdd.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/46b71607-5c54-458b-a8f9-15f877441fdd.png)'
- en: As we can see in the preceding diagram, some of the data points in the **S1**
    subset also appear in **S2** and **S4**.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，**S1**子集中的部分数据点也出现在**S2**和**S4**中。
- en: 'Let''s say that we have *n* bootstrap samples from our original sample. ![](img/f0c73234-b84a-449c-a947-9dd4a49c0086.png)
    denotes the estimates of the *n* bootstrap samples where *i=1,2,3...,n*. If ![](img/0a211672-b39b-48fd-9297-9052c060f949.png) denotes
    the estimate of the parameter for the original sample, the standard error for ![](img/f1a80abe-c907-4179-871f-e64341fd5190.png) is
    given as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们从原始样本中获得了*n*个bootstrap样本。![图片](img/f0c73234-b84a-449c-a947-9dd4a49c0086.png)表示*n*个bootstrap样本的估计值，其中*i=1,2,3...,n*。如果![图片](img/0a211672-b39b-48fd-9297-9052c060f949.png)表示原始样本的参数估计值，那么![图片](img/f1a80abe-c907-4179-871f-e64341fd5190.png)的标准误差如下给出：
- en: '![](img/51c33b62-2975-455f-b6a0-220137c1667c.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/51c33b62-2975-455f-b6a0-220137c1667c.png)'
- en: '![](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png) is given as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png)如下给出：'
- en: '![](img/8efea2c2-bddf-4d60-ace9-2ef3f4ac5708.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8efea2c2-bddf-4d60-ace9-2ef3f4ac5708.png)'
- en: '![](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png) is the mean of the estimates
    across the *n* bootstrap samples.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/565f5de0-0f0c-45fa-828d-f9f32d366603.png)表示*n*个bootstrap样本的估计值的平均值。'
- en: Getting ready
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: 'We need to import the required libraries as usual. This time, we will use the `resample`
    class from `sklean.utils`, which we''ve not used previously:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要像往常一样导入所需的库。这次，我们将使用来自`sklean.utils`的`resample`类，这是我们之前没有使用过的：
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We load our data and fill in the missing values with the median for the `horsepower`
    variable. We also drop the `carname` variable:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们加载我们的数据，并用`horsepower`变量的中位数填充缺失值。我们还删除了`carname`变量：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How to do it...
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Now that we have read our data, let''s see how we can perform bootstrap sampling:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经读取了数据，让我们看看我们如何进行bootstrap采样：
- en: 'We write a custom function, `create_bootstrap_oob()`, which takes a DataFrame
    as a parameter and uses the `resample()` function from `sklearn.utils` to create
    a bootstrap sample with 100 observations:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们编写了一个自定义函数，`create_bootstrap_oob()`，它接受一个DataFrame作为参数，并使用`sklearn.utils`中的`resample()`函数创建了一个包含100个观察值的bootstrap样本：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We loop through 50 iterations and call the custom function by passing the `df_autodata`
    DataFrame. We capture the mean of the `mpg` variable for each bootstrap sample,
    which we''ll measure against the mean of the `mpg` variable in our original DataFrame,
    which is `df_autodata`:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们循环了50次迭代，并通过传递`df_autodata` DataFrame调用了自定义函数。我们记录了每个bootstrap样本中`mpg`变量的平均值，这些平均值将与我们原始DataFrame中`mpg`变量的平均值进行比较，即`df_autodata`：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We plot the mean of the `mpg` variable for each iteration, for which a separate
    bootstrap sample has been considered. We capture the mean of the `mpg` variable
    for each bootstrap sample in each iteration:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们绘制了每个迭代中`mpg`变量的平均值，其中考虑了单独的bootstrap样本。我们在每个迭代中记录了每个bootstrap样本中`mpg`变量的平均值：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We finally plot the mean of the `mpg` variable against each iteration, which
    can be seen in the following image:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终绘制了`mpg`变量的平均值与每个迭代的对比图，如下所示：
- en: '![](img/179ce760-d743-439f-8db3-2cb4d4d1bc97.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/179ce760-d743-439f-8db3-2cb4d4d1bc97.png)'
- en: How it works...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we created a custom function, `create_bootstrap_oob( )`, and used
    the `resample()` function from `sklearn.utils` to create a bootstrap sample with
    100 observations. The `create_bootstrap_oob( )` custom function took a DataFrame
    as an input parameter and created both bootstrap and **Out-Of-the-Bag** (**OOB**)
    samples.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 1**中，我们创建了一个自定义函数，`create_bootstrap_oob( )`，并使用`sklearn.utils`中的`resample()`函数创建了一个包含100个观察值的bootstrap样本。`create_bootstrap_oob(
    )`自定义函数接受一个DataFrame作为输入参数，并创建了bootstrap和**袋外样本**（**OOB**）。
- en: We mentioned that bootstrap sampling is sampling with replacement. This means
    that any given observation can appear more than once in a single sample.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到bootstrap采样是带有替换的采样。这意味着任何给定的观察值可以在单个样本中出现多次。
- en: In *Step 2*, we looped through the 50 iterations and called the `create_bootstrap_oob(
    )` custom function by passing `df_autoframe`. We captured the mean of the `mpg`
    variable for each bootstrap sample. In *Step 3*, we considered a separate bootstrap
    sample for each iteration. We captured the mean of the `mpg` variable against
    each iteration and then plotted the mean of the `mpg` variable for each iteration.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 2**中，我们循环了50次迭代，并通过传递`df_autoframe`调用了`create_bootstrap_oob( )`自定义函数。我们记录了每个bootstrap样本中`mpg`变量的平均值。在**步骤
    3**中，我们为每个迭代考虑了一个单独的bootstrap样本。我们记录了每个迭代中`mpg`变量的平均值，然后绘制了每个迭代中`mpg`变量的平均值。
- en: See also
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The scikit-learn guide to `sklearn.cross_validation.Bootstrap`: [https://bit.ly/2RC5MYv](https://bit.ly/2RC5MYv)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn指南中的`sklearn.cross_validation.Bootstrap`：[https://bit.ly/2RC5MYv](https://bit.ly/2RC5MYv)
