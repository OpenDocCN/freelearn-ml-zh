- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Future Trends and Developments
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Intelligence will drive the next generation of technologies, not big data. Big
    data systems have some issues, as discussed in [*Chapter 1*](B18369_01.xhtml#_idTextAnchor017),
    *Challenges in Big Data and Traditional AI*, and the world is gradually transitioning
    from the data-centric era to the intelligence-centric generation. **Federated
    learning** (**FL**) will play a core role in wisdom-driven technologies. Thus,
    the time is now to welcome the world of collective intelligence.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will talk about the direction of future AI technologies
    that are driven by the paradigm shift happening with FL. For many AI fields, such
    as privacy-sensitive areas and fields requiring scalability in **machine learning**
    (**ML**), the benefits and potential of FL are already significant, mainly because
    of the privacy-preserving and distributed learning aspects that FL naturally supports
    with its design. You will then learn about the different types of FL as well as
    the latest development efforts in that area, as seen in the split and swarm learning
    techniques, which can be considered as evolutional frameworks enhancing FL.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In addition, FL creates a new concept of an *Internet of Intelligence*, where
    people and computers exchange their wisdom instead of just data themselves. The
    Internet of Intelligence for everyone is further accelerated by blockchain technologies
    as well. This Internet of Intelligence can then form a newly defined concept of
    *collective intelligence* that drives another innovation, from *data-centric*
    approaches to *intelligence-centric* or *model-centric* approaches.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will share a collective vision in which FL plays a key role in collaboratively
    creating intelligence learned by many people and machines around the world.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Looking at future AI trends
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ongoing research and developments in FL
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Journeying on to collective intelligence
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at future AI trends
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The majority of industry leaders are now aware of the limitations of centralized
    ML as discussed in the next section.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The limitation of centralized ML
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When looking at the future of AI, it is important to first know the fact that
    many companies today are struggling to extract intelligence and obtain insight
    from the data they possess. More than half of the data that organizations and
    companies have collected is usually not used. Traditional approaches to machine
    learning and data science need data to be organized and consolidated into data
    lakes and stores in advance of analyzing and training ML models. You need to duplicate
    and move the data, which will result in delays in realizing and delivering the
    value of the intelligence extracted from the data, together with certain operational
    risks and complexities.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: In addition, most of the data generated by enterprise companies will be created
    and processed outside a traditional centralized data center or cloud. It is becoming
    increasingly unrealistic and inefficient to process data for generating insight
    in a centralized manner.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, based on some market reports out there, most of the largest global
    organizations and companies will explore FL at least once to create much more
    accurate, secure, and sustainable models environmentally.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: That being said, quite a few industries and markets are gradually becoming aware
    of the importance of a distributed and FL paradigm, because they are facing the
    unavoidable issues and limitations of the current centralized AI training with
    big data, as discussed in [*Chapter 1*](B18369_01.xhtml#_idTextAnchor017), *Challenges
    in Big Data and Traditional AI*. FL brings the model to the data where the training
    process resides instead of bringing the data to the model. Thus, FL is considered
    to be the future of data science and ML.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, let’s summarize the points of why FL is beneficial to those
    companies, especially enterprises that have been facing the aforementioned issues.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the benefits of FL
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will summarize the benefits of FL that have been introduced
    throughout this book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Increased model accuracy and generalizability
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: FL realizes collaborative and distributed learning that can improve the performance
    of ML models, by training on dispersed datasets locally to continuously incorporate
    the learning into a global model. This way, more accurate and generalized ML models
    can be produced.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Further privacy and security
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: FL provides privacy and security advantages because it won’t require private
    and raw data by its design and security mechanisms, as we discussed previously
    in [*Chapter 2*](B18369_02.xhtml#_idTextAnchor037), *What Is Federated Learning?*
    and [*Chapter 9*](B18369_09.xhtml#_idTextAnchor224), *Case Studies with Key Use
    Cases of Federated Learning Applications*. Thus, FL reduces the potential risk
    of data misuse, leakage, or exposure to sensitive information. FL is also compliant
    with many privacy regulations, such as **General Data Protection Regulation**
    (**GDPR**), **California Consumer Privacy Act** (**CCPA**), and **Health Insurance
    Portability and Accountability Act** (**HIPAA**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Improved speed and efficiency
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: FL is also known to realize high computation efficiency, which can accelerate
    the deployment and testing of ML models as well as decrease communication and
    computational latency. Due to the decentralized nature of FL, the delay for model
    delivery and update is minimized, which leads to a prediction by the global model
    in near real time. Real-time delivery and updates of intelligence are really valuable
    for time-sensitive ML applications.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: FL also helps reduce bandwidth and energy consumption by overcoming system heterogeneity
    and unbalanced data distribution, which leads to minimizing data storage and transfer
    costs that can also significantly contribute to reducing the environmental impact.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Toward distributed learning for further privacy and training efficiency
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Currently, AI is trained on huge computational servers, usually happening on
    big machines in big data companies.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the era of the supercomputer, which can process a huge amount of
    data and tasks within one machine or one cluster of machines, the evolutional
    process in technology starts from a central location and gradually transitions
    to distributed environments.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The same thing is exactly about to happen in AI. Now, the data lake concept
    is popular to organize and train ML models in one place, but ML already requires
    distributed learning frameworks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: FL is a great way to distribute a training process over multiple nodes. As shown
    in many research reports, most data is not fully used to extract insights into
    ML models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: There are some companies and projects that are trying to use FL as a powerful
    distributed learning technique, such as the platforms provided by Devron ([devron.ai](https://devron.ai)),
    FedML ([fedml.ai](https://fedml.ai)), and STADLE ([stadle.ai](https://stadle.ai)).
    These platforms are already resolving the issues discussed in *The limitation
    of centralized AI* section and have shown a drastic improvement in the ML process
    in various use cases, as stated in the *Revisiting the benefits of FL* section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Based on the AI trends that we have discussed, let’s look into the ongoing research
    and developments related to FL that cutting-edge companies are conducting now
    in the next section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing research and developments in FL
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now talk about the ongoing research and development projects that are being
    taken place both in academia and industries around the world. Let’s start with
    the different types and approaches of FL, and move on to ongoing efforts to further
    enhance the FL framework.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Exploring various FL types and approaches
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this book, we have visited the most basic algorithms and design concepts
    of an FL system. In the real world, we need to dig a bit deeper into what types
    of FL frameworks are available to extract the best performance out of those algorithms.
    Depending on the data scenario and use cases, we have several approaches in FL,
    as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal FL and vertical FL
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralized FL and decentralized FL
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-silo FL and cross-device FL
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s look at each type of FL in the following sections.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal FL and vertical FL
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Horizontal FL** uses datasets with the same feature space or schema across
    all distributed devices ([https://www.arxiv-vanity.com/papers/1902.04885/](https://www.arxiv-vanity.com/papers/1902.04885/)).
    This actually means that datasets share the same columns with different rows.
    Most existing FL projects are based on horizontal FL. Datasets and training processes
    with horizontal FL are straightforward because the datasets are formed identically,
    with different data distributions and inputs to be learned. Horizontal FL is also
    called homogeneous or sample-based FL.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**Vertical FL** is applied to the cases where different datasets share the
    same sample ID space but differ in feature space. You can check out this paper
    (https://arxiv.org/pdf/2202.04309) for further information about vertical FL.
    Relating these different databases through FL can be challenging, especially if
    the unique ID for the data is different. The key idea of vertical FL is to improve
    an ML model by using distributed datasets with a diverse set of attributes. Therefore,
    vertical FL can handle the partitioned data vertically with different attributes
    in the same sample space. Vertical FL is also called heterogeneous or feature-based
    FL.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Centralized FL and decentralized FL
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Centralized FL** is currently the most common approach and most of the platforms
    employ this framework. It uses a centralized server to collect and aggregate the
    different ML models, with distributed training across all local data sources.
    In this book, we focused on a centralized FL approach, with a scenario where local
    training agents communicate the learning results to a centralized FL server to
    create a global model.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**Decentralized FL**, on the other hand, does not use a centralized server
    to aggregate ML models. It requires individual ML models trained over local data
    sources to be communicated among themselves without a master node. In this case,
    model weights are transferred from each individual dataset to the others for further
    training. It could potentially be susceptible to model poisoning if an untrusted
    party could access the intelligence, and this is a common problem derived from
    peer-to-peer frameworks as well.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Cross-silo FL and cross-device FL
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Cross-silo FL** is the case where ML models are trained on data distributed
    across any functional, organizational, and regulatory barriers. In this case,
    big data is usually stored in a larger size of storage, with training computing
    capabilities such as cloud virtual machines. In the cross-silo FL case, the number
    of silos/training environments is relatively small, so not so many agents are
    needed in the FL process.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '**Cross-device FL** is the case where models need to be trained at scale, often
    within edge devices, such as mobile phones, **Internet of Things** (**IoT**) devices,
    Raspberry Pi-type environments, and so on. In this case, a huge number of devices
    are connected for the aggregation of ML models. In the cross-device FL case, the
    limitation basically lies in the low computing power of those edge devices. The
    framework also needs to handle a number of disconnected and inactive devices to
    conduct a consistent and continuous FL process. The training process and its data
    volume should be limited too.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: That concludes the different types of FL that can be applied to a variety of
    scenarios in ML applications. There are new techniques that try to enhance the
    FL framework to evolve into the next generation of AI technologies with FL. Let’s
    look into several advanced approaches in the next section.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Understanding enhanced distributed learning frameworks with FL
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are ongoing efforts to further enhance FL or distributed learning frameworks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Split learning
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Split learning**, developed in the MIT Media Lab, is an emerging distributed
    learning technique that enables partitioning ML models into multiple sections,
    trains those partitioned ML models at distributed clients, and aggregates them
    at the end. Split learning does not have to share the data either, so it is considered
    a privacy-preserving AI as well.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: The overall framework is similar to the FL. However, there is a difference in
    that the neural network is partitioned into multiple sections that will be trained
    on distributed clients. The trained weights of the section of the neural network
    are then transferred to the server and clients. The weights of those multiple
    sections are continuously trained in the next training sessions. Therefore, no
    raw and private data is shared among the distributed clients, and only the weights
    of each section are sent to the next client.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Especially, **SplitFed** ([https://arxiv.org/abs/2004.12088](https://arxiv.org/abs/2004.12088))
    is another advanced technique that combines split learning and FL. SplitFed splits
    the deep neural network architecture between the FL clients and servers to realize
    a higher level of privacy than FL. It offers better efficiency than split learning
    based on the parallel learning paradigm of FL.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Swarm learning
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Swarm learning** is a decentralized ML solution built on blockchain technology,
    particularly designed to enable enterprise industries to take advantage of the
    power of distributed data, which results in protecting data privacy and security.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: This can be achieved by individual nodes sharing parameters of ML models derived
    from the local data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Parameters shared from the distributed clients are merged into a global model.
    The difference from the normal FL is that the merge process is not performed by
    a central server. The distributed nodes and clients choose a temporary leader
    to perform the merge. That is why swarm learning is truly decentralized, also
    providing greater fault tolerance and resiliency. The distributed agents have
    the collective intelligence of a network without sharing local data into one node.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Swarm learning builds on top of blockchain. Blockchain provides the decentralized
    control, scalability, and fault-tolerance aspects to work beyond the restrictions
    of a single enterprise. At the same time, blockchain introduces a tamperproof
    cryptocurrency framework, and the participants can use the framework to monetize
    their contributions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: BAFFLE
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition, there is a framework called **BAFFLE** that stands for **Blockchain
    Based Aggregator Free Federated Learning** (https://arxiv.org/abs/1909.07452).
    BAFFLE is also an aggregator-free, blockchain-driven FL framework that is inherently
    decentralized. BAFFLE utilizes **Smart Contracts** (**SCs**) from the blockchain
    framework to coordinate round management, as well as model aggregation and updating
    tasks of FL. Using BAFFLE boosts computational performance. The global model is
    also decomposed into many sets of chunks, directly handled by the SC.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have learned about the latest research and developments in the FL
    field, in the next section, let’s look at a more visionary aspect of the AI, science,
    and technologies of collective intelligence.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Journeying on to collective intelligence
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big data has been a game changer for the AI movement. While the amount of data
    generated at the edge and by people will increase exponentially, intelligence
    derived from that data benefits society. Therefore, the big data era will gradually
    pass the baton to the collective intelligence era, empowered by FL, in which people
    will collaboratively create a wisdom-driven world.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by defining an intelligence-centric era where the concept of collective
    intelligence is realized based on FL.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Intelligence-centric era with collective intelligence
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Collective Intelligence** (**CI**) is the concept of a large group of single
    entities acting together in ways that seem intelligent. CI is an emergent phenomenon
    where groups of people process information to achieve insights that are not understandable
    by just individual members alone.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Recently, Thomas Malone, the head of the MIT Center for Collective Intelligence,
    and the person who initially coined the phrase *collective intelligence*, broadened
    the definition of CI: *“CI is something that can emerge from a group that includes
    people and computers. CI is a very general property, and superminds can arise
    in many kinds of systems, although the systems I’ve mostly talked about are those
    that involve people and computers”* (Reference: [https://www2.deloitte.com/xe/en/insights/focus/technology-and-the-future-of-work/human-and-machine-collaboration.html](https://www2.deloitte.com/xe/en/insights/focus/technology-and-the-future-of-work/human-and-machine-collaboration.html)).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，麻省理工学院集体智能中心负责人、最初提出“集体智能”一词的人托马斯·马龙，扩展了CI的定义：“CI是能够从包括人和计算机在内的群体中产生的东西。CI是一个非常普遍的特性，超级智能可以在许多类型的系统中出现，尽管我主要讨论的系统是涉及人和计算机的系统。”（参考：[https://www2.deloitte.com/xe/en/insights/focus/technology-and-the-future-of-work/human-and-machine-collaboration.html](https://www2.deloitte.com/xe/en/insights/focus/technology-and-the-future-of-work/human-and-machine-collaboration.html)）。
- en: We are now welcoming the new perspective of CI in technologies empowered by
    FL.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正迎来由FL（强化学习）赋能的技术中CI（集体智能）的新视角。
- en: Data, in the current world of technology, is a great source to extract intelligence.
    Dispersed datasets around the world can be converted into a collection of intelligence
    represented by AI technologies. The current trend, as mentioned, is big data,
    so big data companies are leading not only the technology industries but also
    the entire economy of the world as well. The future is moving in a CI direction.
    The vision of CI is even clearer with the emergence of sophisticated ML algorithms,
    including deep learning, as the intelligence represented by ML models can extract
    intelligence from people, computers, or any devices that generate meaningful data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的技术世界中，数据是提取智能的巨大来源。全球分散的数据集可以通过AI技术转化为智能集合。正如提到的，当前的趋势是大数据，因此大数据公司不仅领导着技术产业，也领导着整个世界经济。未来正朝着CI的方向发展。随着复杂ML算法（包括深度学习）的出现，CI的愿景变得更加清晰，因为ML模型所代表的智能可以从人、计算机或任何生成有意义数据的设备中提取智能。
- en: Why does FL promote the idea of CI? The nature of FL is to collect a set of
    distributed intelligence to be enhanced by an aggregating mechanism as discussed
    in this book. This itself enables a data-less platform that does not require collecting
    data from people or devices directly.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么FL会推崇CI的概念？FL的本质是收集一组分布式智能，通过书中讨论的聚合机制进行增强。这本身就能实现一个无需直接从人或设备收集数据的数据无平台。
- en: With the big data issues discussed throughout the book, we have steered clear
    of focusing on data-centric platform. However, it is also true that learning big
    data is very much critical and inevitable to really create systems and applications
    that are truly valuable and deliver real value in many domains of the world. That
    is why the big data field is still the most prosperous industry, even if it is
    facing significant challenges represented by privacy regulations, security, data
    silos, and so on.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管书中讨论了大数据问题，但我们并没有专注于以数据为中心的平台。然而，学习大数据对于真正创建真正有价值并能在世界许多领域创造实际价值的应用系统来说，是非常关键和不可避免的。这就是为什么即使面对隐私法规、安全、数据孤岛等重大挑战，大数据领域仍然是发展最繁荣的行业。
- en: Now is the time to further develop and disseminate the technologies such as
    FL that can accelerate the era of CI by fundamentally resolving the issues of
    big data. This way, we can realize a new era of technologies, truly driven by
    CI that has been backed up by an authentic mathematical basis.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是进一步发展和传播FL等技术的时机，这些技术可以通过从根本上解决大数据问题来加速CI时代的到来。这样，我们就能实现一个由真正的数学基础支持的CI驱动的新技术时代。
- en: As mentioned, *data-centric* platforms are the current trend. So many data and
    auto ML vendors can support and automate the processes of creating ML-based intelligence
    by organizing data and learning procedures to do so. An *intelligence-centric*
    or *model-centric* platform should be the next wave of technology in which people
    can share and enhance intelligence that they generate on their own. With FL, we
    can even realize crowd-sourced learning, where people can collaboratively and
    continuously enhance the quality and performance of ML models. Thus, FL is a critical
    and essential part of the intelligence-centric platform to truly achieve a wisdom-driven
    world.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Internet of Intelligence
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The IoT evolved into the **Internet of Everything**. However, what is the essential
    information that people want? Is it just big data? Or intelligence derived from
    data? With 5G technologies, a lot of data can be transferred over the Internet
    at a much higher speed, partially resolving the latency issues in many AI applications.
    FL can exchange less information than raw data but still needs to transfer ML
    models over the Internet.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: While lots of research projects are minimizing communications latency in FL,
    in the future, information related to intelligence will be another entity often
    exchanged over the web. There will be a model repository such as **Model Zoo**
    everywhere, and crowdsourced learning empowered by FL will be more common to create
    better intelligence over the Internet with people worldwide collaboratively.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: This paradigm shift is not just in the AI field itself but also in the wide
    range of information technologies. As we’ll discuss in the next sections, this
    **Internet of Intelligence** movement will be the basis of crowdsourced learning
    and CI, and will help make intelligence available to as many people as possible
    in the coming years.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Crowdsourced learning with FL
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *collection of intelligence* performed by FL naturally makes it a strong
    fit for moving toward CI. The same thing is applied to a scenario where people
    can collectively contribute a training process to global ML models.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: High-performing ML models in areas such as computer vision and natural language
    processing have been trained by certain big data companies, often spending a huge
    amount of money, including hundreds of millions of dollars.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Is there any way to collectively train an ML model that will probably be beneficial
    for a wide range of people in general? With the advanced framework of FL, that
    is possible.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: FL provides an authentic way to manage the aggregation of multiple trained models
    from various distributed agents. In this case, the distributed agents themselves
    may be people worldwide, where each individual user and trainer of the ML model
    has their own unique datasets that are not available to anybody else because of
    data privacy, silos, and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: This way of utilizing CI is often called *crowdsourced learning*. However, traditional
    crowdsourced learning is conducted in a much more limited way, just based on facilitating
    and recruiting data annotators at a large scale.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: With this new paradigm with FL, users on the CI platform can access and download
    ML models that they are interested in and retrain them if necessary to absorb
    learning in their own environments. Then, with the framework to share the trained
    ML models by those users, an advanced aggregation framework of FL could pick up
    the appropriate models to be federated and make the global model perform better,
    adopting diverse data that can be only accessible to the users.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: This way, intelligence by ML is becoming more available to many individuals
    in general, not just to specific companies that have a significant amount of data
    and budgets to train an authentic ML model. In other words, without an FL framework,
    collaborative learning is difficult and tricky and almost impossible to even automate.
    This openness of the ML models will move the entire technological world to the
    next level, and a lot more applications will become feasible, with truly powerful
    intelligence that is trained by enthusiasts to make the world better.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter of the book, we discussed fascinating future trends and
    developments in which FL is expected to play a crucial role in the coming decade.
    In the future, FL is a *must-to-have* technology from a *nice-to-have* framework
    for most enterprises and application providers, because of the inevitable privacy
    regulations and technology trends requiring scalability with so many users.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed, future technologies will be empowered by the concept of the
    Internet of Intelligence, by which people and computers mainly exchange their
    wisdom altogether to create a more intelligent society and world. Finally, the
    data-centric technologies will gradually evolve into intelligence-centric technologies
    because of the current collaborative learning trend with CI, which makes people
    pay significant attention to FL-related technologies, whose foundations are discussed
    throughout this book.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: This book was written at the dawn of a new age in advancements made possible
    by AI. There are many uncertainties and many more challenges ahead. We have made
    great strides in utilizing the big data playbook in the last couple of decades,
    and we have now outgrown those methods and must adopt new ways of doing things,
    new technologies, and new ideas to forge ahead. As long as we capture the current
    moment and invest in new technologies such as FL, we will have a bright future
    ahead of us.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are some sources if you wish to dive deeper into some concepts
    discussed in this chapter:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '*UNDERSTANDING THE TYPES OF FEDERATED LEARNING*, posted by OpenMinded: [https://blog.openmined.org/federated-learning-types](https://blog.openmined.org/federated-learning-types'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Thapa, Chandra, et al. *SplitFed: When Federated Learning Meets Split Learning*,
    Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36\. No. 8\.
    2022: [https://arxiv.org/pdf/2004.12088.pdf](https://arxiv.org/pdf/2004.12088.pdf'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '*SWARM LEARNING: TURN YOUR DISTRIBUTED DATA INTO COMPETITIVE EDGE,* technical
    white paper: [https://www.labs.hpe.com/pdf/Swarm_Learning.pdf](https://www.labs.hpe.com/pdf/Swarm_Learning.pdf'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'Paritosh Ramanan and Kiyoshi Nakayama. *BAFFLE: Blockchain based aggregator
    free federated learning*, 2020 IEEE International Conference on Blockchain (Blockchain).
    IEEE, 2020: [https://arxiv.org/pdf/1909.07452.pdf](https://arxiv.org/pdf/1909.07452.pdf)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Appendix: Exploring Internal Libraries'
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 4*](B18369_04.xhtml#_idTextAnchor085), *Federated Learning Server
    Implementation with Python*, and [*Chapter 5*](B18369_05.xhtml#_idTextAnchor130),
    *Federated Learning Client-Side Implementation*, both about the implementation
    of `fl_main/lib/util` directory of the provided `simple-fl` GitHub repository.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: In this appendix, we will provide an overview of the internal library and utilization
    classes and functions with code samples to achieve their functionalities.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the internal libraries for the FL system
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enumeration classes for implementing the FL system
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding communication handler functionalities
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the data structure handler class
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding helper and supporting libraries
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Messengers to generate communication payloads
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the library code files introduced in this chapter can be found in the `fl_main/lib/util`
    directory of the GitHub repository (https://github.com/tie-set/simple-fl).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: You can use the code files for personal or educational purposes. Please note
    that we will not support deployment for commercial use and will not be responsible
    for any errors, issues, or damages caused by using the code.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the internal libraries for the FL system
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Figure A.1* shows the Python code components for the internal libraries found
    in the `lib/util` folder of the `fl_main` directory, which is used in the database,
    aggregator, and agent of the FL system:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure A.1 – Python software components for the internal libraries used in
    the database, aggregator, and agent'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18369_A_01.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Figure A.1 – Python software components for the internal libraries used in the
    database, aggregator, and agent
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The following are brief descriptions of the Python files for the internal libraries
    found in the `lib/util` folder of the FL system.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: states.py
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `states.py` file in the `lib/util` folder defines a variety of enumeration
    classes to support implementing the FL system. Definitions of the classes include
    FL client states, types of ML models and messages, and locations of the information
    and values of various messages.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: communication_handler.py
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `communication_handler.py` file in the `lib/util` folder can provide communication
    functionalities among the database, FL server, and clients, mainly defining the
    `send` and `receive` functions between them. Also, it provides the functions to
    start the servers for the database, aggregator, and agent.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: data_struc.py
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `data_struc.py` file in the `lib/util` folder defines the class called `LimitedDict`
    to support an aggregation process of the FL cycle. It provides functions to convert
    ML models with a dictionary format into `LimitedDict` and vice versa.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: helpers.py
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `helpers.py` file in the `lib/util` folder has a collection of internal
    helper functions, such as reading configuration files, generating unique hash
    IDs, packaging ML models into a dictionary, loading and saving local ML models,
    getting the IP address of the machine, and manipulating the FL client state.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: messengers.py
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `messengers.py` file in the `lib/util` folder is for generating a variety
    of messages as communication payloads among FL systems to facilitate the implementation
    of communication protocols of the simple FL system discussed throughout the book.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have discussed an overview of the FL system’s internal libraries,
    next, let’s talk about the individual code files in more detail.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Enumeration classes for implementing the FL system
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enumeration classes are for assisting implemention of the FL system. They are
    defined in the `states.py` file found in the `lib/util` folder of the `fl_main`
    directory. Let us look into what libraries are imported to define the enumeration
    classes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries to define the enumeration classes
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this `states.py` code example, the file imports general libraries such as
    `Enum` and `IntEnum` from `enum`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we’ll explain the class that defines the prefixes of three components
    of the FL system.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: IDPrefix defining the FL system components
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is a list of classes to define the FL system components. `IDPrefix`
    is the prefix to indicate which FL component is referred to in the code, such
    as `agent`, `aggregator`, or `database`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, we’ll provide a list of the classes for the client state.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Client state classes
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is a list of enumeration classes related to the FL client states,
    including the state of waiting for global models (`waiting_gm`), the state of
    ML training (`training`), the state of sending local ML models (`sending`), and
    the state of receiving the global models (`gm_ready`). The client states defined
    in the agent specification are as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: List of classes defining the types of ML models and messages
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a list of classes defining the types of ML models and messages
    related to the FL system implementation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The ModelType class
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The types of ML models, including `local` models and `cluster` models (`global`
    models), are defined as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The DBMsgType class
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The message types are defined in the communication protocol between an aggregator
    and database, as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The AgentMsgType class
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The message types are defined in the communication protocol sent from an agent
    to an aggregator, as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The AggMsgType class
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The message types are defined in the communication protocol sent from an aggregator
    to an agent, as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: List of state classes defining message location
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a list of classes defining the message location related to
    communication between the FL systems.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: The ParticipateMSGLocation class
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator to read a participation message from an agent to the aggregator
    is as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The ParticipateConfirmationMSGLocation class
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator to read a participation confirmation message sent back
    from the aggregator is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The DBPushMsgLocation class
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator to read a `push` message from an aggregator to the database
    is as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The GMDistributionMsgLocation class
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator to read a global model distribution message from an aggregator
    to agents is as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The ModelUpMSGLocation class
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator to a message uploading local ML models from an agent to
    an aggregator is as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The PollingMSGLocation class
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The index indicator for a `polling` message from an agent to an aggregator
    is as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We have defined the enumeration classes that are utilized throughout the code
    of the FL system. In the next section, we will discuss the communication handler
    functionalities.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Understanding communication handler functionalities
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The communication handler functionalities are implemented in the `communication_handler.py`
    file, which can be found in the `lib/util` folder of the `fl_main` directory.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries for the communication handler
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this `communication_handler.py` code example, the handler imports general
    libraries such as `websockets`, `asyncio`, `pickle`, and `logging`:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, we’ll provide a list of functions of the communication handler.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Functions of the communication handler
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a list of the functions related to the communication hander.
    Although the **Secure Sockets Layer** (**SSL**) or **Transport Layer Security**
    (**TLS**) framework is not implemented in the communication handler code here
    for simplification, it is recommended to support them to secure communication
    among FL components all the time.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: The init_db_server function
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `init_db_server` function is for starting the database server on the FL
    server side. It takes a function, database IP address, and socket information
    as inputs and initiates the server functionality based on the WebSocket framework.
    You can use any other communication protocol, such as HTTP, as well. Here is the
    sample code to initiate the database server:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The init_fl_server function
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `init_fl_server` function is for starting the FL server on the aggregator
    side. As parameters, it takes three functions for agent registration, receiving
    messages from agents, and the model synthesis routine, as well as the aggregator’s
    IP address and registration and receiver sockets info (to receive messages from
    agents) to initiate the server functionality based on the WebSocket framework.
    Here is the sample code for initiating the FL server:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The init_client_server function
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `init_client_server` function is for starting the FL client-side server
    functionalities. It takes a function, the agent’s IP address, and the socket info
    to receive messages from an aggregator as inputs and initiate the functionality
    based on the WebSocket framework. Here is sample code for initiating the FL client-side
    server functionality:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The send function
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `send` function is for sending a message to the destination specified by
    the IP address and socket info taken as parameters together with a message to
    be sent. It returns a response message sent back from the destination node to
    the source node, if there is one:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The send_websocket function
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `send_websocket` function is for returning a message to the message source
    specified by the WebSocket information, taken as a parameter together with a message
    to be sent:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The receive function
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `receive` function is used to receive a message with the WebSocket taken
    as a parameter and returns a pickled message:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, we will talk about the data structure class that handles processing ML
    models.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data structure handler class
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data structure handler is implemented in the `data_struc.py` file, which
    can be found in the `lib/util` folder of the `fl_main` directory. The data structure
    class has the `LimitedDict` class to handle the aggregation of the ML models in
    a consistent manner.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries for the data structure handler
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this `data_struc.py` code example, the handler imports general libraries,
    such as `numpy` and `Dict`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Next, let’s move on to the `LimitedDict` class and its functions related to
    the data structure handler.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The LimitedDict class
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a definition of the `LimitedDict` class and its functions related
    to the data structure handler.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: The LimitedDict class and its functions
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The functions of the `LimitedDict` class are for converting a dictionary format
    into a class with keys and values. `LimitedDict` is used with the buffer in ML
    models to store local and cluster models in the memory space of the state manager
    of the aggregator:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The convert_LDict_to_Dict function
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `convert_LDict_to_Dict` function is used to convert the `LimitedDict` instance
    defined previously into a normal dictionary format:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the next section, we will talk about the helper and supporting libraries.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Understanding helper and supporting libraries
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The helper and supporting functions are implemented in the `helpers.py` file,
    which can be found in the `lib/util` folder of the `fl_main` directory.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries for helper libraries
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this `helpers.py` code example, the file imports general libraries such
    as `json` and `time`:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Next, let’s move on to the list of functions of the helper library.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Functions of the helper library
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a list of functions related to the helper library.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: The set_config_file function
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `set_config_file` function takes the type of the config file, such as `db`,
    `aggregator`, or `agent`, as a parameter and returns a string of the path to the
    configuration file:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The read_config function
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `read_config` function reads a JSON configuration file to set up the database,
    aggregator, or agent. It takes a config path as a parameter and returns config
    info in a dictionary format:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The generate_id function
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_id` function generates a system-wide unique ID based on the MAC
    address and instantiation time with a hash function (`sha256`) returning the hash
    value as an ID:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The generate_model_id function
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_model_id` function generates a system-wide unique ID for a set
    of models based on the following:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '**Component ID**: The ID of the FL system entity that created the models'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generation time**: The time the models were created'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The ID is generated by a hash function (sha256). It takes the following parameters:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '`component_type`: A string value with a prefix indicating the component type
    of `IDPrefix`'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`component_id`: A string value of the ID of the entity that created the models'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gene_time`: A float value of the time the models were created'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This function returns the hash value as a model ID:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The create_data_dict_from_models function
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `create_data_dict_from_models` function creates the data dictionary for
    ML models by taking the following parameters:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the model ID'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: The `np.array` about ML models'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`component_id`: The ID of the FL system such as aggregator ID and agent ID'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It returns a data dictionary containing the ML models:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The create_meta_data_dict function
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `create_meta_data_dict` function creates the metadata dictionary with the
    metadata of the ML models, taking the performance metrics (`perf_val`) and the
    number of samples (`num_samples`) as parameters, and returns `meta_data_dict`,
    containing the performance value and the number of samples:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The compatible_data_dict_read function
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `compatible_data_dict_read` function takes `data_dict`, which contains
    the information related to ML models, extracts the values if the corresponding
    key exists in the dictionary, and returns the component ID, the generation time
    of the ML models, the ML models themselves, and the model IDs:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The save_model_file function
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `save_model_file` function is for saving a given set of models into a local
    file. It takes the following parameters:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '`data_dict`: A dictionary containing the model ID and ML models with the `Dict[str,np.array]`
    format.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`path`: A string value of the path to the directory of the ML model storage.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: A string value of the model filename.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`performance_dict`: A dictionary containing performance data with the `Dict[str,float]`
    format. Each entry contains both the model ID and its performance information:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The load_model_file function
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`load_model_file` reads a local model file that takes the following parameters:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '`path`: A string value of the path to the directory to store ML models'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: A string value of the model filename'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It returns the unpickled ML models and performance data in the `Dict` format:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The read_state function
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `read_state` function reads a local state file that takes the following
    parameters:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '`path`: A string value of the path to the directory of the client state file'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: A string value of the model filename'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This function returns a client state, `ClientState` (for example, *training*
    or *sending*), the state indicated in the file, in an integer format. If the client
    state file is being written at the time of access, it will try to read the file
    again after 0.01 seconds:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The write_state function
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`write_state` changes the client state on the state file in the agent. It takes
    the following parameters:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '`path`: A string value of the path to the directory of the client state file'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: A string value of the model filename'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`state`: The value of `ClientState` (for example, *training* or *sending*)
    to set up a new client state:'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The get_ip function
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `get_ip` function obtains the IP address of the machine and returns the
    value of the IP address:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The init_loop function
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `init_loop` function is used to start a continuous loop function. It takes
    a function for running a loop function:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In the next section, let’s look at the messenger functions to create communication
    payloads.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Messengers to generate communication payloads
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The messenger functions are defined in the `messengers.py` file, which can be
    found in the `lib/util` folder of the `fl_main` directory.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Importing libraries for messengers
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this `messengers.py` code example, the file imports general libraries, such
    as `time` and `numpy`. It also imports `ModelType`, `DBMsgType`, `AgentMsgType`,
    and `AggMsgType`, which were defined in the *Enumeration classes for implementing
    the FL system* section in this chapter:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Next, let’s move on to the list of functions of the `messengers` library.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Functions of messengers
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following is a list of functions related to the `messengers` library.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: The generate_db_push_message function
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_db_push_message` function generates and returns a message for
    pushing the message containing ML models to the database. It takes the following
    parameters to package them as a payload message (in a `List` format with the message
    type defined as `push`) between the aggregator and database:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '`component_id`: A string value of the component ID, such as the aggregator
    ID'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`round`: FL round information in an integer format'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_type`: The type of ML model, such as `cluster` or `local` models'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: ML models with the `Dict[str, np.array]` format'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the unique ID of the ML models'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gene_time`: A float value of the time at which the ML models are generated'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`performance_dict`: Performance data with the `Dict[str, float]` format'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code provides the functionality of generating the preceding database
    push message:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The generate_lmodel_update_message function
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_lmodel_update_message` function generates and returns a message
    for sending the aggregator a message containing the local models created in an
    agent. It takes the following parameters to package them as a payload message
    (in `List` format with the message type defined as `update`) between the agent
    and aggregator:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '`agent_id`: A string value of the agent ID'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the unique ID of the ML models'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`local_models`: Local ML models with the `Dict[str, np.array]` format'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`performance_dict`: Performance data with the `Dict[str, float]` format'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the functionality of generating the preceding local
    model update message:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The generate_cluster_model_dist_message function
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_cluster_model_dist_message` function generates and returns a
    message in `List` format to send a message containing the global models created
    by an aggregator to the connected agents. It takes the following parameters to
    package them as a payload message (in `List` format with the message type defined
    as `update`) between the aggregator and agent:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '`aggregator_id`: A string value of the aggregator ID'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the unique ID of the ML models'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`round`: FL round information in an integer format'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: ML models with the `Dict[str, np.array]` format'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the functionality of generating the preceding cluster
    model distribution message:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The generate_agent_participation_message function
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_agent_participation_message` function generates and returns a
    message to send a participation request message containing the initial models
    created by an agent to the connected aggregator. It takes the following parameters
    to package them as a payload message (in `List` format with the message type defined
    as `participate`) between the agent and aggregator:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '`agent_name`: A string value of the agent name'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`agent_id`: A string value of the agent ID'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the unique ID of the ML models'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: ML models with the `Dict[str, np.array]` format'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`init_weights_flag`: A Boolean value to indicate whether the weights are initialized
    or not'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`simulation_flag`: A Boolean value to indicate whether the run is for a simulation
    or not'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exch_socket`: Socket information with a string value to send a message from
    an aggregator to this agent'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gene_time`: A float value of the time at which the ML models are generated'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`meta_dict`: Performance data with the `Dict[str, float]` format'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`agent_ip`: IP address of the agent itself'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the functionality of generating the preceding agent
    participation message:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The generate_agent_participation_confirm_message function
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_agent_participation_confirm_message` function generates and returns
    a message to send a participation confirmation message containing the global models
    back to the agent. It takes the following parameters to package them as a payload
    message (in `List` format with the message type defined as `welcome`) between
    the aggregator and agent:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '`aggregator_id`: A string value of the aggregator ID'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`: A string value of the unique ID of the ML models'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: ML models with the `Dict[str, np.array]` format'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`round`: FL round information in an integer format'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`agent_id`: A string value of the agent ID'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`exch_socket`: A port number to reach out to an agent from the aggregator'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recv_socket`: A port number to receive messages from the agent'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the functionality of generating the preceding agent
    participation confirmation message:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The generate_polling_message function
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_polling_message` function generates and returns a message to
    send a `polling` message containing the polling signal to the aggregator. It takes
    the following parameters to package them as a payload message (in `List` format
    with the message type defined as `polling`) between the agent and aggregator:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '`round`: FL round information in an integer format'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`agent_id`: A string value of the agent ID'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows the functionality of generating the preceding polling
    message:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The generate_ack_message function
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `generate_ack_message` function generates and returns a message to send
    an `ack` message containing the acknowledgment signal back to an agent. No parameter
    is required to create a payload message (in `List` format with the message type
    defined as `ack`) between the aggregator and agent:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Summary
  id: totrans-365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have explained the internal libraries in detail so that
    you can implement the entire FL system without further investigating what and
    how to code for basic functionalities such as communication and data structure
    conversion frameworks.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'There are mainly five aspects that the internal library covers: *enumeration
    classes*, defining the system states, such as FL client states; the *communication
    handler*, supporting send and receive functionalities; the *data structure*, to
    handle ML models when aggregation happens; *helper and support functions*, which
    cope with basic operations, such as saving data and producing randomized IDs;
    and *messenger functions*, to generate various payloads sent among the database,
    aggregator, and agents.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: With these functions, you will find the implementation of FL systems easy and
    smooth, but these libraries only support achieving some minimal functionality
    of the FL system; hence, it is up to you to further enhance the FL system to create
    a more authentic platform that can be used in real-life use cases and technologies.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
