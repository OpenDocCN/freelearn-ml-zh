["```py\nusing DataType = double;\nusing SampleType = dlib::matrix<DataType, 0, 1>;\nusing Samples = std::vector<SampleType>;\nusing Labels = std::vector<DataType>;\n```", "```py\nstd::pair<Samples, Labels> GenerateData(DataType start,\n                                        DataType end,\n                                        size_t n) {\n  Samples x;\n  x.resize(n);\n  Labels y;\n  y.resize(n);\n  auto step = (end - start) / (n - 1);\n  auto x_val = start;\n  size_t i = 0;\n  for (auto& x_item : x) {\n    x_item = SampleType({x_val});\n    auto y_val = std::cos(M_PI * x_val);\n    y[i] = y_val;\n    x_val += step;\n    ++i;\n  }\n  return {x, y};\n}\n```", "```py\nstd::pair<Samples, Labels> GenerateNoiseData(DataType start,\n                                             DataType end,\n                                             size_t n) {\n  Samples x;\n  x.resize(n);\n  Labels y;\n  y.resize(n);\n  std::mt19937 re(3467);\n  std::uniform_real_distribution<DataType> dist(start, end);\n  std::normal_distribution<DataType> noise_dist;\n  for (size_t i = 0; i < n; ++i) {\n    auto x_val = dist(re);\n    auto y_val =\n        std::cos(M_PI * x_val) + (noise_dist(re) * 0.3);\n    x[i] = SampleType({x_val});\n    y[i] = y_val;\n  }\n  return {x, y};\n}\n```", "```py\nauto [train_samples, train_lables] =\n  GenerateNoiseData(start, end, num_samples);\nauto [test_samples, test_lables] =\n  GenerateData(start, end, num_samples);\n```", "```py\n#include <dlib/random_forest.h>\n... \ndlib::random_forest_regression_trainer<\n  dlib::dense_feature_extractor> trainer;\nconstexpr size_t num_trees = 1000;\ntrainer.set_num_trees(num_trees);\nauto random_forest = trainer.train(train_samples, train_lables);\nfor (const auto& sample : test_samples) {\n  auto prediction = random_forest(sample);\n  …\n}\n```", "```py\narma::mat data;\nmlpack::data::DatasetInfo info;\ndata::Load(dataset_name, data, info, /*fail with error*/ true);\n```", "```py\n// extract the labels row\narma::Row<size_t> labels;\n labels = arma::conv_to<arma::Row<size_t>>::from( data.row(0));\n// remove the labels row\ndata.shed_row(0);\n```", "```py\n// split dataset into the train and test parts - make views\nsize_t train_num = 500;\narma::Row<size_t> train_labels = labels.head_cols( train_num); arma::mat test_input = data.tail_cols( num_samples - train_num); arma::Row<size_t> test_labels = \n  labels.tail_cols( num_samples - train_num);\n```", "```py\nusing namespace mlpack;\nRandomForest<> rf;\nrf.Train(train_input,\n         train_labels,\n         num_classes,\n         /*numTrees=*/100,\n         /*minimumLeafSize=*/10,\n         /*minimumGainSplit=*/1e-7,\n         /*maximumDepth=*/10);\n```", "```py\nAccuracy acc;\nauto acc_value = acc.Evaluate(rf, test_input, test_labels);\nstd::cout << \"Random Forest accuracy = \" << acc_value << std::endl;\n```", "```py\nusing namespace mlpack;\nPerceptron<> p;\nAdaBoost<Perceptron<>> ab;\n```", "```py\nab.Train(train_input,\n         train_labels,\n         num_classes,\n         p,\n         /*iterations*/ 1000,\n         /*tolerance*/ 1e-10);\n```", "```py\nAccuracy acc;\nauto acc_value = acc.Evaluate(ab, test_input, test_labels);\nstd::cout << \"AdaBoost accuracy = \" << acc_value << std::endl;\n```", "```py\nstruct KFoldDataSet {\n  KFoldDataSet(const arma::mat& train_input,\n               const arma::Row<size_ t>& train_labels,\n               size_t k);\n  std::tuple<arma::mat, arma::Row<size_t>, arma::mat,\n             arma::Row<size_t>>\n  get_fold(const size_t i);\n  size_t k{0};\n  size_t bin_size{0};\n  size_t last_bin_size{0};\n  arma::mat inputs;\n  arma::Row<size_t> labels;\n};\n```", "```py\nKFoldDataSet(const arma::mat& train_input,\n             const arma::Row<size_t>& train_labels, size_t k)\n  : k(k) {\n  fold_size = train_input.n_cols / k;\n  last_fold_size = train_input.n_cols - ((k - 1) * fold_size);\n  inputs = arma::join_rows(\n    train_input, train_input.cols(0, train_input.n_cols -\n                                   last_fold_size - 1));\n  labels = arma::join_rows(\n    train_labels,\n    train_labels.cols(\n      0, train_labels.n_cols - last_fold_size - 1));\n}\n```", "```py\nstd::tuple<arma::mat, arma::Row<size_t>, arma::mat,\n           arma::Row<size_t>>\nget_fold(const size_t i) {\n  const size_t subset_size =\n    (i != 0) ? last_fold_size + (k - 2) * fold_size\n             : (k - 1) * fold_size;\n  const size_t last_subset_size =\n    (i == k - 1) ? last_fold_size : fold_size;\n  // take k-1\n  auto input_fold =\n    arma::mat(inputs.colptr(fold_size * i), inputs.n_rows,\n              subset_size, false, true);\n  auto labels_fold = arma::Row<size_t>(\n    labels.colptr(fold_size * i), subset_size, false, true);\n  // take last k-th\n  auto last_input_fold =\n    arma::mat(inputs.colptr(fold_size * (i + k - 1)),\n              inputs.n_rows, last_subset_size, false, true);\n  auto last_labels_fold =\n    arma::Row<size_t>(labels.colptr(fold_size * (i + k - 1)),\n                      last_subset_size, false, true);\n  return {input_fold, labels_fold, last_input_fold,\n          last_labels_fold};\n}\n```", "```py\nvoid StackingClassification(\n  size_t num_classes,\n  const arma::mat& raw_train_input,\n  const arma::Row<size_t>& raw_train_labels,\n  const arma::mat& test_input,\n  const arma::Row<size_t>& test_labels);\n```", "```py\nusing namespace mlpack;\n// Shuffle data\narma::mat train_input;\narma::Row<size_t> train_labels;\nShuffleData(raw_train_input, raw_train_labels, train_input,\n            train_labels);\n// Normalize data\ndata::StandardScaler sample_scaler;\nsample_scaler.Fit(train_input);\narma::mat scaled_train_input(train_input.n_rows,\n                             train_input.n_cols);\nsample_scaler.Transform(train_input, scaled_train_input);\n```", "```py\nsize_t k = 30;\nKFoldDataSet meta_train(scaled_train_input, train_labels, k);\n```", "```py\nfor (size_t i = 0; i < k; ++i) {\n  auto [fold_train_inputs, fold_train_labels, fold_valid_inputs,\n        fold_valid_labels] = meta_train.get_fold(i);\n  arma::Row<size_t> predictions;\n  auto [fold_train_inputs, fold_train_labels, fold_valid_inputs,\n        fold_valid_labels] = meta_train.get_fold(i);\n  arma::Row<size_t> predictions;\n  arma::mat meta_feature;\n  LinearSVM<> local_weak0;\n  local_weak0.Train(fold_train_inputs, fold_train_labels,\n                    num_classes);\n  local_weak0.Classify(fold_valid_inputs, predictions);\n  meta_feature = arma::join_cols(\n      meta_feature,\n      arma::conv_to<arma::mat>::from(predictions));\n  SoftmaxRegression local_weak1(fold_train_inputs.n_cols,\n                                num_classes);\n  local_weak1.Train(fold_train_inputs, fold_train_labels,\n                    num_classes);\n  local_weak1.Classify(fold_valid_inputs, predictions);\n  meta_feature = arma::join_cols(\n      meta_feature,\n      arma::conv_to<arma::mat>::from(predictions));\n  DecisionTree<> local_weak2;\n  local_weak2.Train(fold_train_inputs, fold_train_labels,\n                    num_classes);\n  local_weak2.Classify(fold_valid_inputs, predictions);\n  meta_feature = arma::join_cols(\n      meta_feature,\n      arma::conv_to<arma::mat>::from(predictions));\n  meta_train_inputs =\n      arma::join_rows(meta_train_inputs, meta_feature);\n  meta_train_labels =\n      arma::join_rows(meta_train_labels, fold_valid_labels);\n}\n```", "```py\nDecisionTree<> meta_model;\nmeta_model.Train(meta_train_inputs,\n                 meta_train_labels,\n                 num_classes);\n```", "```py\nLinearSVM<> weak0;\nweak0.Train(scaled_train_input, train_labels, num_classes);\nSoftmaxRegression weak1(scaled_train_input.n_cols, num_classes);\nweak1.Train(scaled_train_input, train_labels, num_classes);\nDecisionTree<> weak2;\nweak2.Train(scaled_train_input, train_labels, num_classes);\n```", "```py\narma::mat scaled_test_input(test_input.n_rows,\n                            test_input.n_cols);\nsample_scaler.Transform(test_input, scaled_test_input);\n```", "```py\narma::mat meta_eval_inputs;\narma::Row<size_t> meta_eval_labes;\nThe next code snippet shows how we get the meta-features from the weak models:\nweak0.Classify(scaled_test_input, predictions);\nmeta_eval_inputs = arma::join_cols(meta_eval_inputs,\n      arma::conv_to<arma::mat>::from(predictions));\nweak1.Classify(scaled_test_input, predictions);\nmeta_eval_inputs = arma::join_cols(meta_eval_inputs,\n      arma::conv_to<arma::mat>::from(predictions));\nweak2.Classify(scaled_test_input, predictions);\nmeta_eval_inputs = arma::join_cols(meta_eval_inputs,\n      arma::conv_to<arma::mat>::from(predictions));\n```", "```py\nAccuracy acc;\nauto acc_value =\n      acc.Evaluate(meta_model, meta_eval_inputs, test_labels);\nstd::cout << \"Stacking ensemble accuracy = \" << acc_value << std::endl;\n```"]