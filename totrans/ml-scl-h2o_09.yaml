- en: '*Chapter 7*: Understanding ML Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第七章*: 理解机器学习模型'
- en: Now that we have built a few models using H2O software, the next step before
    production is to understand how the model is making decisions. This has been termed
    variously as **machine learning interpretability** (**MLI**), **explainable artificial
    intelligence** (**XAI**), model explainability, and so on. The gist of all these
    terms is that building a model that predicts well is not enough. There is an inherent
    risk in deploying any model before fully trusting it. In this chapter, we outline
    a set of capabilities within H2O for explaining ML models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用H2O软件构建了一些模型，下一步在生产之前是理解模型是如何做出决策的。这被称作机器学习可解释性（**MLI**）、可解释人工智能（**XAI**）、模型可解释性等等。所有这些术语的核心是，仅仅构建一个预测效果好的模型是不够的。在完全信任模型之前部署任何模型都存在固有的风险。在本章中，我们概述了H2O中用于解释机器学习模型的一组功能。
- en: 'By the end of this chapter, you will be able to do the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够做到以下几件事情：
- en: Select an appropriate model metric for evaluating your models.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个合适的模型度量标准来评估你的模型。
- en: Explain what Shapley values are and how they can be used.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释Shapley值是什么以及如何使用它们。
- en: Describe the differences between global and local explainability.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述全局和局部可解释性的区别。
- en: Use multiple diagnostics to build understanding and trust in a model.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多种诊断工具来建立对模型的了解和信任。
- en: Use global and local explanations along with model performance metrics to choose
    the best among a set of candidate models.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用全局和局部解释以及模型性能指标来从一组候选模型中选择最佳模型。
- en: Evaluate tradeoffs between model predictive performance, speed of scoring, and
    assumptions met in a single candidate model.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估单个候选模型在预测性能、评分速度和满足的假设之间的权衡。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Selecting model performance metrics
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择模型性能指标
- en: Explaining models built in H2O (both globally and locally)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释在H2O中构建的模型（全局和局部）
- en: Automated model documentation through H2O AutoDoc
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过H2O AutoDoc进行自动化的模型文档
- en: Selecting model performance metrics
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择模型性能指标
- en: The most relevant question about any model is, *How well does it predict?* Regardless
    of any other positive properties that a model may possess, models that don't predict
    well are just not very useful. How to best measure predictive performance depends
    both on the specific problem being solved and the choices available to the data
    scientist. H2O provides multiple options for measuring model performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 任何模型最相关的问题是，*它的预测效果如何？* 无论模型可能拥有的其他积极属性如何，预测效果不佳的模型只是不太有用。如何最好地衡量预测性能既取决于要解决的问题的具体情况，也取决于数据科学家可用的选择。H2O提供了多种测量模型性能的选项。
- en: For measuring predictive model performance in regression problems, H2O provides
    R2, **mean squared error** (**MSE**), **root mean squared error** (**RMSE**),
    **root mean squared logarithmic error** (**RMSLE**), and **mean absolute error**
    (**MAE**) as metrics. MSE and RMSE are good default options, with RMSE being our
    preference because the metric is expressed in the same units as the predictions
    (rather than squared units, as in the case of MSE). All metrics based on squared
    error are sensitive to outliers in general. If robustness to outliers is a requirement,
    then MAE is a better choice. Finally, RMSLE is useful in the special case where
    under-prediction is worse than over-prediction.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题中的预测模型性能测量，H2O提供了R2、**均方误差**（**MSE**）、**均方根误差**（**RMSE**）、**均方根对数误差**（**RMSLE**）和**平均绝对误差**（**MAE**）作为指标。MSE和RMSE是良好的默认选项，其中RMSE是我们的首选，因为该指标与预测的单位相同（而不是平方单位，如MSE的情况）。所有基于平方误差的指标通常对异常值敏感。如果需要鲁棒性以抵抗异常值，那么MAE是一个更好的选择。最后，RMSLE在预测不足比预测过度更糟糕的特殊情况下是有用的。
- en: For classification models, H2O adds the Gini coefficient, absolute **Matthews
    correlation coefficient** (**MCC**), F1, F0.5, F2, Accuracy, Logloss, **area under
    the ROC curve** (**AUC**), **area under the precision-recall curve** (**AUCPR**),
    and **Kolmogorov-Smirnov** (**KS**) metrics. In our experience, AUC is the most
    commonly used metric in business. Because communication with business partners
    and executives is so vital to data scientists, we recommend using well-known metrics
    when their use is appropriate for the job. In the case of AUC, it does a good
    job with binary classification models when data is relatively balanced. AUCPR
    is a better choice for imbalanced data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类模型，H2O添加了基尼系数、绝对**马修斯相关系数**（**MCC**）、F1、F0.5、F2、准确率、Logloss、**ROC曲线下面积**（**AUC**）、**精确率-召回率曲线下面积**（**AUCPR**）和**科尔莫哥洛夫-斯米尔诺夫**（**KS**）指标。根据我们的经验，AUC是商业中最常用的指标。由于与商业伙伴和高级管理人员的沟通对数据科学家至关重要，我们建议在适用的情况下使用公认的指标。在AUC的情况下，当数据相对平衡时，它对二分类模型做得很好。对于不平衡数据，AUCPR是更好的选择。
- en: TheLogloss metric, based on information theory, has some mathematical advantages.
    In particular, if you are interested in the predicted probabilities of class membership
    themselves and not just the predicted classifications, Logloss is a better choice
    of metric. Further documentation on these scoring options can be found at [https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Logloss指标基于信息理论，具有一些数学优势。特别是，如果你对类成员的预测概率本身感兴趣，而不仅仅是预测分类，那么Logloss是更好的指标选择。有关这些评分选项的更多文档可以在[https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html)找到。
- en: 'Leaderboards created in AutoML for a classification problem include AUC, Logloss,
    AUCPR, mean per-class error, RMSE, and MSE as performance metrics. The leaderboard
    for the `check` AutoML object created in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part 1,* is shown in *Figure 7.1* as an example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为分类问题创建的AutoML排行榜包括AUC、Logloss、AUCPR、每类平均误差、RMSE和MSE作为性能指标。在[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)，*高级模型构建
    – 第1部分*中创建的`check` AutoML对象的排行榜如图7.1所示：
- en: '![Figure 7.1 – An AutoML leaderboard for the check object'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 7.1 – An AutoML leaderboard for the check object]'
- en: '](img/B16721_07_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_01.jpg]'
- en: Figure 7.1 – An AutoML leaderboard for the check object
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 7.1 – An AutoML leaderboard for the check object]'
- en: In addition to predictive performance, additional metrics of model performance
    may be important in an enterprise setting. Two of these included by default in
    AutoML leaderboards are the amount of time required to fit a model (`training_time_ms`)
    and the amount of time required to predict a single row of the data (`predict_time_per_row_ms`).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了预测性能外，在企业环境中，模型性能的额外指标可能也很重要。在AutoML排行榜中默认包含的两个指标是拟合模型所需的时间（`training_time_ms`）和预测数据单行所需的时间（`predict_time_per_row_ms`）。
- en: In *Figure 7.1*, the best model according to both AUC and Logloss is a stacked
    ensemble of all models (the model in the top row). This model is also the slowest
    to score by an order of magnitude over any of the individual models. For streaming
    or real-time applications in particular, a model that cannot score quickly enough
    may automatically be disqualified as a candidate regardless of its predictive
    performance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.1*中，根据AUC和Logloss两个指标，最佳模型是所有模型的堆叠集成（顶部行中的模型）。这个模型在评分速度上比任何单个模型都要慢一个数量级。对于流式或实时应用来说，一个评分不够快的模型可能会自动被排除，无论其预测性能如何。
- en: We next address model explainability for understanding and evaluating our ML
    models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来讨论模型可解释性，以便理解和评估我们的机器学习模型。
- en: Explaining models built in H2O
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释H2O中构建的模型
- en: Model performance metrics measured on our test data can tell us how well a model
    predicts and how fast it predicts. As mentioned in the chapter introduction, knowing
    that a model predicts well is not a sufficient reason to put it into production.
    Performance metrics alone cannot provide any insight into *why* the model is predicting
    as it is. If we don't understand why the model is predicting well, we have little
    hope of being able to anticipate conditions that would make the model not work
    well. The ability to explain a model's reasoning is a critical step prior to promoting
    it into production. This process can be described as gaining trust in the model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试数据上测量的模型性能指标可以告诉我们模型预测得有多好以及预测有多快。如章节引言中提到的，知道模型预测得很好并不是将其投入生产的充分理由。仅凭性能指标本身无法提供任何关于“为什么”模型会这样预测的见解。如果我们不理解模型预测得好的原因，我们几乎没有希望预测出会使模型表现不佳的条件。解释模型推理的能力是在将其推广到生产之前的一个关键步骤。这个过程可以描述为对模型建立信任。
- en: Explainability is typically divided into global and local components. Global
    explainability describes how the model works for an entire population. Gaining
    trust in a model is primarily a function of determining how it works globally.
    Local explanations operate instead on individual rows. They address questions
    such as how an individual prediction came about. The `h2o.explain` and `h2o.explain_row`
    methods bundle a set of explainability functions and visualizations for global
    and local explanations, respectively.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性通常分为全局和局部两个部分。全局可解释性描述了模型对整个种群的工作方式。对模型建立信任主要取决于确定其全局工作方式。局部解释则作用于单个行。它们解决的问题是，例如，一个个体预测是如何产生的。《h2o.explain》和《h2o.explain_row》方法分别捆绑了一组用于全局和局部解释的可解释性函数和可视化。
- en: We start this section with a simple introduction to Shapley values, one of the
    bedrock methods in model explainability, which can be confusing when first encountered.
    We cover global explanations for single models using `h2o.explain` and local explainability
    with `h2o.explain_row`. We then address global explanations for AutoML using `h2o.explain`,
    which we use to demonstrate the role of explainability in model selection. We
    illustrate the output of these methods using two models developed in [*Chapter
    5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced Model Building
    – Part 1*. The first, `gbm`, is an individual baseline model built using default
    values with the H2O `check`. These models are chosen as examples only, acknowledging
    that the original baseline model was improved upon by multiple feature engineering
    and model optimization steps.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从沙普利值的简单介绍开始，这是模型可解释性中的基石方法之一，初次接触时可能会感到困惑。我们使用《h2o.explain》覆盖单个模型的全局解释，并使用《h2o.explain_row》进行局部可解释性。然后，我们使用《h2o.explain》处理AutoML的全局解释，我们用它来展示可解释性在模型选择中的作用。我们使用在[*第五章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)“高级模型构建
    – 第1部分”中开发的两个模型来说明这些方法的输出，*Advanced Model Building – Part 1*。第一个，`gbm`，是一个使用默认值和H2O
    `check`构建的个体基线模型。这些模型仅作为示例选择，承认原始基线模型通过多个特征工程和模型优化步骤得到了改进。
- en: A simple introduction to Shapley values
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 沙普利值的简单介绍
- en: 'Shapley values have become an important part of ML explainability as a means
    for attributing the contribution of each feature to either overall or individual
    predictions. Shapley values are mathematically elegant and well-suited for the
    task of attribution. In this section, we provide a description of Shapley values:
    their origin, calculation, and how to use them for interpretation.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 沙普利值已成为机器学习可解释性中的一个重要部分，作为将每个特征的贡献归因于整体或个体预测的手段。沙普利值在数学上优雅，非常适合归因任务。在本节中，我们提供了沙普利值的描述：它们的起源、计算以及如何用于解释。
- en: Lloyd Shapley (1923-2016), a 2012 Nobel Prize winner in Economics, derived Shapley
    values in 1953 as the solution to a specific problem in game theory. Suppose a
    group of players working together receives a prize. How should that award be equitably
    divided amongst the players?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 洛伊德·沙普利（1923-2016），2012年诺贝尔经济学奖获得者，于1953年推导出沙普利值，作为博弈论中特定问题的解决方案。假设一组玩家共同获得一项奖金。应该如何在玩家之间公平地分配这笔奖金？
- en: 'Shapley started with mathematical axioms defining fairness: **symmetry** (players
    who contribute the same amount get the same payout), **dummy** (players who contribute
    nothing receive nothing), and **additivity** (if the game can be separated into
    additive parts, then you can decompose the payouts). The Shapley value is the
    unique mathematical solution that satisfies these axioms. In short, the Shapley
    value approach pays players in proportion to their marginal contributions.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley从定义公平性的数学公理开始：**对称性**（贡献相同数量的玩家获得相同的支付），**虚拟玩家**（没有贡献的玩家什么也得不到），和**可加性**（如果游戏可以分解为可加的部分，那么可以分解支付）。Shapley值是满足这些公理的唯一数学解。简而言之，Shapley值方法按玩家的边际贡献比例支付玩家。
- en: We next demonstrate the calculation of Shapley values for a couple of simple
    scenarios.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来演示几个简单场景的Shapley值的计算。
- en: Shapley calculations illustrated – Two players
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Shapley计算示例 – 两位玩家
- en: To illustrate the calculation of a Shapley value, consider the following simple
    example. Two musicians, John and Paul, performing on their own can earn £4 and
    £3, respectively. John and Paul playing together earn £10\. How should they divide
    the £10?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明Shapley值的计算，考虑以下简单的例子。两位音乐家约翰和保罗，各自单独表演可以赚得£4和£3，分别。约翰和保罗一起表演可以赚得£10。他们应该如何分配这£10？
- en: 'To calculate their marginal contributions, consider the number of ways these
    players can be sequenced. For two players, there are only two unique orderings:
    John is playing and is then joined by Paul, or Paul is playing and is then joined
    by John. This is illustrated in *Figure 7.2*:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算他们的边际贡献，考虑这些玩家可以按何种方式排序。对于两位玩家，只有两种独特的排序：约翰先演奏，然后保罗加入，或者保罗先演奏，然后约翰加入。这已在*图7.2*中展示：
- en: '![Figure 7.2 – Unique player sequences for John and Paul'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2 – 约翰和保罗的独特玩家序列'
- en: '](img/B16721_07_02.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_07_02.jpg)'
- en: Figure 7.2 – Unique player sequences for John and Paul
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 约翰和保罗的独特玩家序列
- en: 'The formulation as unique player sequences allows us to calculate Shapley values
    for each player. We illustrate the calculation of the Shapley value for John in
    *Figure 7.3*:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将其表示为独特玩家序列使我们能够计算每个玩家的Shapley值。我们在*图7.3*中展示了约翰的Shapley值的计算：
- en: '![Figure 7.3 – Sequence values for John'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.3 – 约翰的序列值'
- en: '](img/B16721_07_03.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_07_03.jpg)'
- en: Figure 7.3 – Sequence values for John
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 约翰的序列值
- en: 'John is the first player present in sequence 1, thus the Shapley contribution
    is just the marginal value *v(J) = 4*. In the second sequence, John joins after
    Paul. The marginal value for John is the joint value of John and Paul, *v(JP)*,
    minus the marginal value of Paul, *v(P)*. In other words, *10 – 3 = 7*. The Shapley
    value for John is the average of the values for each sequence: *S(J) = 11/2 =
    5.5*. Therefore, John should receive £5.50 of the £10 payment.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列1中，约翰是第一个出现的玩家，因此Shapley贡献只是边际价值*v(J) = 4*。在第二个序列中，约翰在保罗之后加入。约翰的边际价值是约翰和保罗的联合价值*v(JP)*减去保罗的边际价值*v(P)*。换句话说，*10
    – 3 = 7*。约翰的Shapley值是每个序列值的平均值：*S(J) = 11/2 = 5.5*。因此，约翰应该从£10的支付中获得£5.50。
- en: 'The Shapley value for Paul is calculated in a similar fashion (obviously, it
    could also be calculated by subtraction). The sequence calculations are shown
    in *Figure 7.4*:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 保罗的Shapley值以类似的方式计算（显然，也可以通过减法计算）。序列计算在*图7.4*中展示：
- en: '![Figure 7.4 – Sequence values for Paul'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.4 – 保罗的序列值'
- en: '](img/B16721_07_04.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_07_04.jpg)'
- en: Figure 7.4 – Sequence values for Paul
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 保罗的序列值
- en: 'In the first sequence in *Figure 7.4*, Paul joins after John, so the sequence
    value is the joint, *v(JP) = 10*, minus the marginal for John, *v(J) = 4*. The
    second sequence is just the marginal value of Paul: *v(P)=3*. The Shapley value
    for Paul is *S(P) = 9/2 = 4.5*.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.4*的第一个序列中，保罗在约翰之后加入，因此序列值是联合的*v(JP) = 10*减去约翰的边际价值*v(J) = 4*。第二个序列只是保罗的边际价值：*v(P)=3*。保罗的Shapley值是*S(P)
    = 9/2 = 4.5*。
- en: These calculations are easy and make sense with two players. Let's see what
    happens when we add a third player.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些计算简单且合理，适用于两位玩家。让我们看看当我们添加第三位玩家时会发生什么。
- en: Shapley calculations illustrated – Three players
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Shapley计算示例 – 三位玩家
- en: 'Suppose a third musician, George, joins John and Paul. George earns £2 on his
    own, £7 performing with John, £9 performing with Paul, and £20 when all three
    play together. For clarity, we summarize the earnings in *Figure 7.5*:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设第三位音乐家乔治加入约翰和保罗。乔治自己赚得£2，与约翰合作表演赚得£7，与保罗合作表演赚得£9，当三人一起表演时赚得£20。为了清晰起见，我们在*图7.5*中总结了收入：
- en: '![Figure 7.5 – Earnings for John, Paul, and George'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.5 – 约翰、保罗和乔治的收益'
- en: '](img/B16721_07_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_05.jpg)'
- en: Figure 7.5 – Earnings for John, Paul, and George
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 约翰、保罗和乔治的收益
- en: 'Because there are three players, there are 3! = 6 unique sequences in which
    John, Paul, and George can arrive. The calculations for the Shapley value for
    John in this three-player scenario are summarized in *Figure 7.6*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因为有三个玩家，所以约翰、保罗和乔治可以到达的6个独特的序列中，有3! = 6个。在这个三玩家场景中，计算约翰Shapley值的计算总结在*图7.6*中：
- en: '![Figure 7.6 – Arrival sequences and values for calculating the Shapley value
    for John'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.6 – 计算约翰Shapley值的到达序列和值'
- en: '](img/B16721_07_06.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_06.jpg)'
- en: Figure 7.6 – Arrival sequences and values for calculating the Shapley value
    for John
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 计算约翰Shapley值的到达序列和值
- en: 'In *Figure 7.6*, sequences 1 and 2 are straightforward: John is the first player,
    so the *v(J)* value is all that is needed. In sequences 3 and 5, John is the second
    player. The sequence values are calculated by taking the joint value of John and
    the first player and then subtracting the marginal value of that player. Sequences
    4 and 6 are identical: John is the last player. His marginal contribution is calculated
    by taking the three-way interaction, *v(JPG)*, and subtracting the joint value
    of Paul and George, *v(PG)*. The Shapley value is *S(J) = 42/6 = 7*.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.6*中，序列1和2很简单：约翰是第一个玩家，所以只需要*v(J)*值。在序列3和5中，约翰是第二个玩家。序列值是通过计算约翰和第一个玩家的联合值，然后减去该玩家的边际值来计算的。序列4和6是相同的：约翰是最后一个玩家。他的边际贡献是通过计算三方交互*v(JPG)*，然后减去保罗和乔治的联合值*v(PG)*来计算的。Shapley值为*S(J)
    = 42/6 = 7*。
- en: We could continue and find the Shapley values for Paul and George in the same
    manner.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续以同样的方式找到保罗和乔治的Shapley值。
- en: Calculating Shapley values for N players
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算N个玩家的Shapley值
- en: As you can see, Shapley value calculations can quickly become overwhelming as
    the number of players, *N*, increases. The Shapley sequence calculations depend
    on knowing the values for the main effects and all the interactions from two-way
    to *N*-way, as in *Figure 7.5*. In addition, there are *N!* sequences to be solved.
    The computational task increases dramatically as the number of players increases.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，随着玩家数量N的增加，Shapley值计算可以迅速变得令人难以承受。Shapley序列计算依赖于知道主要效应和从双向到N向的所有交互的值，如图7.5所示。此外，还有*N!*个序列需要解决。随着玩家数量的增加，计算任务显著增加。
- en: In the context of a predictive model, each feature is a player and the prediction
    is the shared prize. We can use Shapley values to attribute the impact of each
    feature on the final prediction. With some models having dozens or hundreds or
    possibly, even more, features, computing Shapley values in the real world is non-trivial.
    Fortunately, a combination of modern computing and mathematical shortcuts for
    computing Shapley values for certain families of models makes Shapley calculations
    tenable.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测模型的背景下，每个特征都是一个玩家，预测是共享的奖品。我们可以使用Shapley值来分配每个特征对最终预测的影响。一些模型可能有数十个、数百个甚至更多的特征，因此在现实世界中计算Shapley值并非易事。幸运的是，现代计算和计算某些模型族Shapley值的数学捷径的组合使得Shapley计算可行。
- en: Whether in simple examples as we have shown or in large complex ML models, the
    interpretation of Shapley values is the same.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 不论是我们在示例中展示的简单例子，还是大型复杂的机器学习模型，Shapley值的解释都是相同的。
- en: We next turn our attention to global explanations for single models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来关注单个模型的全球解释。
- en: Global explanations for single models
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单个模型的全球解释
- en: We illustrate single model explanations using the baseline GBM model built in
    [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced Model
    Building – Part 1*. We labeled this model `gbm` and documented its performance
    in *Figure 5.5* through to *Figure 5.10*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用第5章中构建的基线GBM模型来说明单个模型解释，该模型在*第5章*（B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082）中介绍，*高级模型构建
    – 第1部分*。我们将其标记为`gbm`，并在*图5.5*至*图5.10*中记录了其性能。
- en: 'The basic command for global explanations is as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 全局解释的基本命令如下：
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, `test` is the holdout test dataset used in model evaluation. Additional
    optional parameters include the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`test` 是用于模型评估的保留测试数据集。其他可选参数包括以下内容：
- en: '`top_n_features`: An integer indicating how many columns to use in column-based
    methods such as `5`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_n_features`：一个整数，表示在基于列的方法（如`5`）中要使用多少列。'
- en: '`columns`: A vector of column names to use in column-based methods as an alternative
    to `top_n_features`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`columns`：一个列名向量，用于基于列的方法，作为 `top_n_features` 的替代。'
- en: '`include_explanations` or `exclude_explanations`: Respectively, `include` or
    `exclude` methods such as `confusion_matrix`, `varimp`, `shap_summary`, or `pdp`.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`include_explanations` 或 `exclude_explanations`：分别表示包含或排除如 `confusion_matrix`、`varimp`、`shap_summary`
    或 `pdp` 等方法。'
- en: For a single classification model such as `gbm`, this command will display the
    confusion matrix, variable importance plot, SHAP summary plot, and partial dependence
    plots for the top five variables in order of importance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个分类模型如 `gbm`，此命令将显示混淆矩阵、变量重要性图、SHAP 概述图和部分依赖图，按重要性顺序显示前五个变量。
- en: We demonstrate this using our `gbm` model with the `gbm.explain(test)` command
    and discuss each display in turn.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `gbm` 模型和 `gbm.explain(test)` 命令来演示这一点，并依次讨论每个显示结果。
- en: The confusion matrix
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'The first output result is the confusion matrix, shown in *Figure 7.7*:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输出结果是混淆矩阵，如图 7.7 所示：
- en: '![Figure 7.7 – Confusion matrix for the GBM baseline model'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7 – GBM 基线模型的混淆矩阵'
- en: '](img/B16721_07_07.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_07.jpg)'
- en: Figure 7.7 – Confusion matrix for the GBM baseline model
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – GBM 基线模型的混淆矩阵
- en: 'A nice feature of the `explain` method is that simple summary descriptions
    are provided for each display: `gbm` shows true negatives (17,616), false positives
    (2,087), false negatives (1,716), and true positives (2,057), along with a false
    positive rate (10.59%) and a false negative rate (45.48%).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain` 方法的优点之一是每个显示都提供了简单的总结描述：`gbm` 显示真实负例（17,616），假阳性（2,087），假阴性（1,716），和真实正例（2,057），以及假阳性率（10.59%）和假阴性率（45.48%）。'
- en: The variable importance plot
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变量重要性图
- en: 'The second visualization from the `explain` method is the variable importance
    plot, shown in *Figure 7.8*:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain` 方法的第二个可视化结果是变量重要性图，如图 7.8 所示：'
- en: '![Figure 7.8 – Variable importance plot for the GBM baseline model'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.8 – GBM 基线模型的变量重要性图'
- en: '](img/B16721_07_08.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_08.jpg)'
- en: Figure 7.8 – Variable importance plot for the GBM baseline model
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 – GBM 基线模型的变量重要性图
- en: Note that the variable importance plot in *Figure 7.8* is identical to the plot
    displayed in *Figure 5.10* that we created manually using the `varimp_plot` command.
    Its inclusion here is one of the benefits of using the `explain` method.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，图 7.8 中的变量重要性图与我们在图 5.10 中手动使用 `varimp_plot` 命令创建的图表相同。它的包含是使用 `explain`
    方法的一个好处。
- en: The SHAP summary plot
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SHAP 概述图
- en: 'The third visualization output by `explain` is a SHAP summary plot. **SHAP**,
    based on Shapley values, provides an informative view into black-box models. The
    SHAP summary plot for the GBM baseline model is shown in *Figure 7.9*:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain` 方法输出的第三个可视化结果是 SHAP 概述图。**SHAP**，基于 Shapley 值，为黑盒模型提供了一个信息丰富的视角。GBM
    基线模型的 SHAP 概述图如图 7.9 所示：'
- en: '![Figure 7.9 – SHAP summary plot for the GBM baseline model'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.9 – GBM 基线模型的 SHAP 概述图'
- en: '](img/B16721_07_09.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_09.jpg)'
- en: Figure 7.9 – SHAP summary plot for the GBM baseline model
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 – GBM 基线模型的 SHAP 概述图
- en: 'Let''s explain in a little more detail the SHAP summary plot in *Figure 7.9*.
    There is a lot going on in this informative plot:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释图 7.9 中的 SHAP 概述图。在这个信息丰富的图表中有很多内容：
- en: On the left-hand side, we have features (data columns) listed in order of decreasing
    feature importance based on Shapley values. (Note that Shapley feature importance
    rankings are not necessarily identical to the feature importance in *Figure 7.8*.)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在左侧，我们按 Shapley 值递减的顺序列出了特征（数据列）。(注意，Shapley 特征重要性排名不一定与图 7.8 中的特征重要性相同。)
- en: 'On the right-hand side, we have a normalized feature value scale going from
    **0.0** to **1.0** (blue to red as output by H2O). In other words, for each feature,
    we code the original data values by color: low original values as blue transitioning
    through purple for middling values, and ending with high original values as red
    (they show as varying shades of gray in this figure).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在右侧，我们有一个从 **0.0** 到 **1.0**（蓝色到红色，由 H2O 输出）的归一化特征值刻度。换句话说，对于每个特征，我们通过颜色编码原始数据值：低原始值用蓝色表示，过渡到紫色表示中等值，最后用红色表示高原始值（在本图中它们显示为不同灰度的阴影）。
- en: The horizontal location of each observation is determined by its SHAP value.
    SHAP values measure the contribution of each feature to the prediction. Lower
    SHAP values are associated with lower predictions and higher values are associated
    with higher predictions.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个观察值的水平位置由其SHAP值决定。SHAP值衡量每个特征对预测的贡献。较低的SHAP值与较低的预测相关联，而较高的值与较高的预测相关联。
- en: 'With that initial understanding, we can make the following observations:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了这个初步理解之后，我们可以做出以下观察：
- en: Features that have red values to the right and blue values to the left are positively
    correlated with the response. Since we are modeling the probability of a bad loan,
    features such as longer term (`term`) or higher revolving utilization (`revol_util`)
    are positively correlated with loan default. (Revolving credit utilization is
    essentially how large a customer's credit card balances are month-to-month.)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有右侧红色值和左侧蓝色值的特征与响应呈正相关。由于我们正在建模不良贷款的概率，因此像较长期限（`term`）或较高循环利用率（`revol_util`）这样的特征与贷款违约呈正相关。（循环信用利用率基本上是客户每月信用卡余额的大小。）
- en: Features with red values to the left and blue values to the right are negatively
    correlated with the response. So, for example, higher annual income (`annual_inc`)
    is negatively correlated with a loan going into default.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左侧红色值和右侧蓝色值的特征与响应呈负相关。因此，例如，更高的年收入（`annual_inc`）与贷款违约呈负相关。
- en: These model observations from the SHAP summary plot make intuitive sense. You
    might expect someone who carries a larger credit card balance or makes a lower
    annual income to have an increased probability of defaulting on a loan.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些来自SHAP摘要图模型的观察结果具有直观的意义。你可能会预期，持有更大信用卡余额或年收入较低的人有更高的贷款违约概率。
- en: Note that we can get the same plot using the `gbm.shap_summary_plot(test)` command.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以使用`gbm.shap_summary_plot(test)`命令得到相同的图。
- en: Partial dependence plots
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部分依赖性图
- en: 'The fourth visualization output by `explain` is a set of partial dependence
    plots. The specific plots shown depend on the `top_n_features` or `columns` optional
    parameters. By default, the top five features are shown in order of decreasing
    variable importance. *Figure 7.10* displays the partial dependence plots for the
    address state:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain`输出的第四个可视化结果是部分依赖性图的一组。具体显示的图取决于`top_n_features`或`columns`可选参数。默认情况下，按变量重要性递减的顺序显示前五个特征。*图7.10*显示了地址状态的部分依赖性图：'
- en: '![Figure 7.10 – Partial dependence plot for address state'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.10 – 地址状态的部分依赖性图]'
- en: '](img/B16721_07_10.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_10.jpg]'
- en: Figure 7.10 – Partial dependence plot for address state
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 – 地址状态的部分依赖性图
- en: '*Figure 7.11* displays the partial dependence plot for the revolving utilization
    variable:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.11*显示了循环利用率变量的部分依赖性图：'
- en: '![Figure 7.11 – Partial dependence plot for revolving utilization'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.11 – 循环利用率的部分依赖性图]'
- en: '](img/B16721_07_11.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_11.jpg]'
- en: Figure 7.11 – Partial dependence plot for revolving utilization
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11 – 循环利用率的部分依赖性图
- en: The partial dependence plots output by `explain` include a representation of
    sample size (the shaded area starting from the bottom of the graph) overlayed
    by the mean response and its variability (the line surrounded by a shaded region).
    In the case of categorical variables, the mean response is a dot with bars indicating
    variability, as in *Figure 7.10*. In the case of numeric variables, the mean response
    is a dark line with lighter shading indicating variability, as in *Figure 7.11*.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain`生成的部分依赖性图包括样本大小（从图表底部开始的阴影区域）的表示，以及均值响应及其变异性（被阴影区域包围的线）。在分类变量的情况下，均值响应是一个带有表示变异性的条形图的点，如图*7.10*所示。在数值变量的情况下，均值响应是一条深色线，较浅的阴影表示变异性，如图*7.11*所示。'
- en: 'Note that we can create a partial dependence plot for any individual column
    using the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以使用以下方法为任何单个列创建部分依赖性图：
- en: '[PRE1]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The global individual conditional expectation (ICE) plot
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全局个体条件期望（ICE）图
- en: 'ICE plots will be introduced later in the *Local explanations for single models*
    section. However, for completeness, we include a global version of the ICE plot
    here. Note that this plot is not output by `explain`. The `gbm.ice_plot(test,
    column=''revol_util'')` command returns a global ICE plot as shown in *Figure
    7.12*:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ICE图将在“单个模型的局部解释”部分后面介绍。然而，为了完整性，我们在此包括一个全局版本的ICE图。请注意，此图不是由`explain`生成的。`gbm.ice_plot(test,
    column='revol_util')`命令返回一个全局ICE图，如图*7.12*所示：
- en: '![Figure 7.12 – Global ICE plot for revolving utilization'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.12 – 全球 ICE 利用率图'
- en: '](img/B16721_07_12.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_12.jpg)'
- en: Figure 7.12 – Global ICE plot for revolving utilization
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – 全球 ICE 利用率图
- en: The global ICE plot for a variable is an expansion of the partial dependence
    plot for that variable. The partial dependence plot displays how the mean response
    is related to the values of a specific variable. Shading, as shown in *Figure
    7.11*, indicates the variability of the partial dependence line. The global ICE
    plot amplifies this by using multiple lines to represent the population. (In the
    case of categorical variables, the lines are replaced by points and the shading
    by bars.)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 变量的全局 ICE 图是该变量的部分依赖图的扩展。部分依赖图显示均值响应与特定变量的值之间的关系。阴影，如 *图 7.11* 所示，表示部分依赖线的可变性。全局
    ICE 图通过使用多条线来表示总体来放大这一点。（在分类变量的情况下，线被点替换，阴影被条形图替换。）
- en: 'As shown in *Figure 7.12*, the global ICE plot includes lines for the minimum
    (0th percentile), the deciles (10th percentile through 90th percentile by 10s),
    the maximum (100th percentile), and the partial dependence itself. This visually
    portrays the population much more accurately than partial dependence alone. Percentiles
    that parallel the partial dependence line correspond to segments of the population
    for which the partial dependence is a good representation. As is often the case,
    the behavior of the minimum and maximum of a population may be quite different
    than the mean behavior described by the partial dependence line. In *Figure 7.12*,
    there are three lines that are different from the others: the minimum, the maximum,
    and the 10th percentile.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 7.12* 所示，全局 ICE 图包括最小值（0 百分位）、十分位数（10 百分位至 90 百分位，每 10 个百分位一个），最大值（100
    百分位）以及部分依赖本身。这比单独的部分依赖图更准确地描绘了总体。与部分依赖线平行的百分位数对应于部分依赖是良好代表的总体部分。通常情况下，总体最小值和最大值的行为可能与部分依赖线描述的均值行为大不相同。在
    *图 7.12* 中，有三条与其他不同的线：最小值、最大值和 10 百分位。
- en: We next turn our attention to local explanations for single models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来关注单个模型的局部解释。
- en: Local explanations for single models
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单个模型的局部解释
- en: The `h2o.explain_row` method allows a data scientist to investigate local explanations
    of a model. While global explanations are used for understanding how the model
    represents the overall population, local explanations give us the ability to interrogate
    a model on a per-row basis. This can be especially important in business when
    rows represent customers, as is the case in our Lending Club analysis.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`h2o.explain_row` 方法允许数据科学家调查模型的局部解释。虽然全局解释用于理解模型如何代表总体，但局部解释使我们能够逐行询问模型。这在业务中尤为重要，因为行代表客户，正如我们在
    Lending Club 分析中所做的那样。'
- en: When predictive models are used to make decisions that impact customers directly
    (for instance, not approving a loan application or raising a customer's insurance
    rates), global explanations are not sufficient to satisfy business, legal, or
    regulatory requirements. This is where local explanations are critical.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测模型被用来做出直接影响客户决策（例如，不批准贷款申请或提高客户的保险费率）时，全局解释不足以满足业务、法律或监管要求。这正是局部解释至关重要的地方。
- en: The `explain_row` method returns these local explanations for a specified `row_index`
    value. The `gbm.explain_row(test, row_index=10)` command provides a SHAP explanation
    plot and multiple ICE plots for columns based on variable importance. As with
    partial dependence plots, the `top_n_features` or `columns` parameters can optionally
    be provided.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain_row` 方法返回指定 `row_index` 值的这些局部解释。`gbm.explain_row(test, row_index=10)`
    命令提供了一个基于变量重要性的 SHAP 解释图和多个 ICE 图。与部分依赖图一样，可以提供可选的 `top_n_features` 或 `columns`
    参数。'
- en: 'The resulting SHAP explanation plot is shown in *Figure 7.13*:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的 SHAP 解释图显示在 *图 7.13* 中：
- en: '![Figure 7.13 – SHAP explanation for index = 10'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.13 – 指数 = 10 的 SHAP 解释'
- en: '](img/B16721_07_13.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_13.jpg)'
- en: Figure 7.13 – SHAP explanation for index = 10
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – 指数 = 10 的 SHAP 解释
- en: SHAP explanations show the contributions of each variable to the overall prediction
    based on Shapley values. For the customer displayed in *Figure 7.13*, the positive
    SHAP values can be thought of as increasing the probability of loan default, while
    the negative SHAP values are those decreasing the probability of default. For
    this customer, the revolving utilization rate of 78.5% is the largest positive
    contributor to the predicted probability. The largest negative contributor is
    the annual income of 90,000, which decreases the probability of loan default more
    than any other variable. SHAP explanations can be used to provide **reason codes**
    that can help explain the model. Reason codes can also be used as the basis for
    sharing information directly with the customer, for instance, in adverse action
    codes that apply to some financial and insurance-related regulatory models.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 解释显示了每个变量对基于 Shapley 值的整体预测的贡献。对于 *图 7.13* 中显示的客户，正的 SHAP 值可以被认为是增加了贷款违约的概率，而负的
    SHAP 值是那些降低违约概率的值。对于这位客户，78.5% 的循环利用率是预测概率的最大正贡献者。最大的负贡献者是年收入 90,000，它比其他任何变量都更能降低贷款违约的概率。SHAP
    解释可以用来提供 **原因代码**，这有助于解释模型。原因代码还可以作为与客户直接分享信息的基础，例如，在适用于某些金融和保险相关监管模型的负面行动代码中。
- en: We next visit some of the ICE plots output from the `explain_row` method.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来查看 `explain_row` 方法输出的某些 ICE 图。
- en: ICE plots for local explanations
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ICE 图的局部解释
- en: 'ICE plots are individual or per-row counterparts of partial dependence plots.
    Just as partial dependence plots for a feature display the mean response of the
    target variable while varying the feature value, the ICE plot measures the target
    variable response while varying the feature value for a single row. Consider the
    ICE plot for the address state displayed in *Figure 7.14* as a result of the `gbm.explain_row`
    call:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ICE 图是部分依赖图的个体或每行对应图。就像特征的部分依赖图显示目标变量的平均响应，同时改变特征值一样，ICE 图在改变单行特征值的同时测量目标变量的响应。以
    *图 7.14* 中显示的地址状态的 ICE 图为例，这是 `gbm.explain_row` 调用的结果：
- en: '![Figure 7.14 – ICE plot for address state'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14 – 地址状态的 ICE 图'
- en: '](img/B16721_07_14.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_14.jpg)'
- en: Figure 7.14 – ICE plot for address state
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 地址状态的 ICE 图
- en: The vertical dark dashed line in *Figure 7.14* represents the actual response
    for the row in question. In this case, the state is **NJ** (New Jersey) with a
    response of approximately 0.10\. Had the state for this row been **VA** (Virginia),
    the response would have been lower (about 0.07). Had the state for this row instead
    been **NV** (Nevada), the response would have been higher, around 0.16.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.14* 中的垂直暗虚线代表所讨论行的实际响应。在这种情况下，状态是 **NJ**（新泽西州）响应约为 0.10。如果这一行的状态是 **VA**（弗吉尼亚州），响应会较低（大约
    0.07）。如果这一行的状态是 **NV**（内华达州），响应会更高，大约 0.16。'
- en: 'Consider next *Figure 7.15*, the ICE plot for the term of the loan:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑下一个 *图 7.15*，贷款期限的 ICE 图：
- en: '![Figure 7.15 – ICE plot for the loan term'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.15 – 贷款期限的 ICE 图'
- en: '](img/B16721_07_15.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_16.jpg)'
- en: Figure 7.15 – ICE plot for the loan term
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – 贷款期限的 ICE 图
- en: The SHAP explanation value in *Figure 7.13* for a term of 36 months was the
    second-largest negative factor (it reduced the probability of loan default the
    most after annual income, which was the largest). According to *Figure 7.15*,
    a loan term of 60 months would have resulted in a default probability of slightly
    more than 0.35, significantly higher than the approximate 0.10 probability of
    default with a term of 36 months. While SHAP explanations and ICE plots are measuring
    two different things, their interpretations can be used jointly to understand
    the behavior of a particular prediction.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.13* 中对于 36 个月期限的 SHAP 解释值是第二大负因素（它在年收入之后，年收入是最大的，它降低了贷款违约的概率）。根据 *图 7.15*，60
    个月的贷款期限会导致略高于 0.35 的违约概率，这比 36 个月期限的大约 0.10 的违约概率显著更高。虽然 SHAP 解释和 ICE 图测量的是两件不同的事情，但它们的解释可以联合使用来理解特定预测的行为。'
- en: 'The last ICE plot we consider is for revolving utilization, a numerical rather
    than categorical feature. This plot is shown in *Figure 7.16*:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑的最后一张 ICE 图是关于旋转利用率的，这是一个数值特征而不是分类特征。这张图显示在 *图 7.16* 中：
- en: '![Figure 7.16 – ICE plot for revolving utilization'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.16 – 旋转利用率 ICE 图](img/B16721_07_15.jpg)'
- en: '](img/B16721_07_16.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_14.jpg)'
- en: Figure 7.16 – ICE plot for revolving utilization
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 旋转利用率的 ICE 图
- en: Revolving utilization was the most significant positive factor (increasing the
    probability of loan default) according to the SHAP explanations in *Figure 7.13*.
    The ICE plot in *Figure 7.16* shows the relationship between response and the
    value of revolving utilization. Had `revol_util` been 50%, the probability of
    loan default would have been reduced to approximately 0.08\. At 20%, the probability
    of default would be approximately 0.05\. If this customer were denied a loan,
    the high value of revolving utilization would be a defensible reason. Results
    of the corresponding ICE plot can be used to inform the customer of steps they
    could take to qualify for the loan.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图7.13中的SHAP解释，循环利用率是影响最大的积极因素（增加贷款违约的概率）。图7.16中的ICE图显示了响应与循环利用率值之间的关系。如果`revol_util`为50%，贷款违约的概率将降低到大约0.08。如果为20%，违约概率将约为0.05。如果这位客户被拒绝贷款，循环利用率的高值将是一个可辩护的理由。相应的ICE图的结果可以用来告知客户他们可以采取哪些步骤来获得贷款资格。
- en: Global explanations for multiple models
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个模型的全球解释
- en: In determining which model to promote into production, for instance, from an
    AutoML run, the data scientist could rely purely on predictive model metrics.
    This could mean simply promoting the model with the best AUC value. However, there
    is a lot of information that could be used to help in this decision, with predictive
    power being only one of multiple criteria.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定要将哪个模型推广到生产中时，例如从AutoML运行中，数据科学家可以完全依赖预测模型指标。这可能意味着简单地推广AUC值最好的模型。然而，有很多信息可以帮助做出这个决定，其中预测能力只是多个标准中的一个。
- en: The global and local explain features of H2O provide additional information
    that is useful for evaluating models in conjunction with predictive attributes.
    We demonstrate it using the `check` AutoML object from [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082),
    *Advanced Model Building – Part 1*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: H2O的全局和局部解释特征提供了额外的信息，这些信息对于与预测属性一起评估模型非常有用。我们使用来自[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)，“高级模型构建
    – 第1部分”的`check` AutoML对象来演示它。
- en: 'The code to launch global explanations for multiple models is simply as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 启动多个模型的全球解释的代码非常简单，如下所示：
- en: '[PRE2]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This results in a variable importance heatmap, model correlation heatmap, and
    multiple-model partial dependence plots. We will review each of these in order.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生变量重要性热图、模型相关性热图和多个模型的局部依赖性图。我们将依次回顾这些内容。
- en: Variable importance heatmap
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变量重要性热图
- en: 'The variable importance heatmap visually combines the variable importance plots
    for multiple models by adding color as a dimension to be viewed along with variables
    (as rows) and models (as columns). The variable importance heatmap produced by
    `check.explain` is shown in *Figure 7.17*:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 变量重要性热图通过添加颜色作为维度，将多个模型的变量重要性图进行视觉组合，以便与变量（作为行）和模型（作为列）一起查看。`check.explain`生成的变量重要性热图如图7.17所示：
- en: '![Figure 7.17 – Variable importance heatmap for an AutoML object'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 7.17 – AutoML对象的变量重要性热图'
- en: '](img/B16721_07_17.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_17.jpg](img/B16721_07_17.jpg)'
- en: Figure 7.17 – Variable importance heatmap for an AutoML object
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 7.17 – AutoML对象的变量重要性热图
- en: Variable importance values are coded as a color continuum from blue (cold) for
    low values to red (hot) for high values. The resulting figure is visually meaningful.
    In *Figure 7.17*, vertical bands correspond to each model and horizontal bands
    correspond to individual features. Vertical bands that are similar indicate a
    high level of correspondence between how models use their features. For instance,
    the `XGBoost_1` and `XGBoost_2` models (the last two columns) display similar
    patterns.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 变量重要性值被编码为从蓝色（冷色）到红色（暖色）的颜色连续体，代表低值到高值。生成的图形具有视觉意义。在图7.17中，垂直带对应于每个模型，水平带对应于单个特征。相似的垂直带表明模型使用其特征的方式之间存在高度相关性。例如，`XGBoost_1`和`XGBoost_2`模型（最后两列）显示出相似的图案。
- en: 'You also see horizontal bands of similar color for variables such as `delinq_2yrs`,
    `verification_status`, or to a lesser extent, `annual_inc`. This indicates that
    all the candidate models treat these variables with comparable importance. The
    `term` variable in the last row is the most visually striking, being heterogeneous
    across models. These models don''t agree on its absolute importance. However,
    you must be careful not to read too much into this. Notice that for `term`, the
    *relative* importance is the same for six of the ten models (all but the blue
    squares: `DRF_1`, `GBM_4`, `XGBoost_2`, and `XGBoost_1`). For these six models,
    `term` is the most important feature although its exact value varies widely.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以看到类似颜色的水平带，例如`delinq_2yrs`、`verification_status`或在一定程度上，`annual_inc`。这表明所有候选模型都对这些变量给予了相当的重要性。最后一行的`term`变量在视觉上最为突出，因为其在不同模型中是异质的。这些模型对其绝对重要性的看法并不一致。然而，你必须小心不要过度解读这一点。注意，对于`term`，六个模型中的十个模型（除了蓝色方块：`DRF_1`、`GBM_4`、`XGBoost_2`和`XGBoost_1`）的相对重要性是相同的。对于这六个模型，`term`是最重要的特征，尽管其确切值变化很大。
- en: 'The code to create this display directly is as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 创建此显示的直接代码如下：
- en: '[PRE3]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's next consider the model correlation heatmap.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们考虑模型相关性热图。
- en: Model correlation heatmap
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型相关性热图
- en: 'The variable importance heatmap allows us to compare multiple models in terms
    of how they view and use their component variables. The model correlation heatmap
    addresses a different question: *How correlated are the predictions from these
    different models?* To answer this, we turn to the model correlation heatmap in
    *Figure 7.18*:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 变量重要性热图使我们能够比较多个模型在如何查看和使用其组件变量方面的差异。模型相关性热图则回答了不同的问题：*这些不同模型的预测结果之间有多少相关性？*
    为了回答这个问题，我们转向*图7.18*中的模型相关性热图：
- en: '![Figure 7.18 – Model correlation heatmap for an AutoML object'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.18 – AutoML对象的模型相关性热图'
- en: '](img/B16721_07_18.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_07_18.jpg)'
- en: Figure 7.18 – Model correlation heatmap for an AutoML object
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.18 – AutoML对象的模型相关性热图
- en: The darkest blocks along the diagonal of *Figure 7.18* show a perfect correlation
    between a model and itself. Sequentially lighter shading describes decreasing
    correlation between models. How might you use this display to determine which
    model to promote to production?
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.18*对角线上的最深色块显示了一个模型与其自身之间的完美相关性。依次变浅的阴影描述了模型之间的相关性逐渐降低。你如何使用这种显示来确定哪个模型可以提升到生产环境？'
- en: This is where business or regulatory constraints can come into play. In our
    example, `StackedEnsemble_AllModels` had the best model performance in terms of
    AUC. Suppose that we are not allowed to promote an ensemble model into production,
    for whatever reason. The single models that are most highly correlated with our
    best model include `XGBoost_3`, `GBM_5`, and `GLM_1`. These could then become
    candidates to promote into production, with a final decision based on additional
    criteria (perhaps the AUC value on the test set).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是商业或监管约束可能发挥作用的地方。在我们的例子中，`StackedEnsemble_AllModels`在AUC方面表现最佳。假设我们因任何原因不允许将集成模型提升到生产环境。与我们最佳模型高度相关的单个模型包括`XGBoost_3`、`GBM_5`和`GLM_1`。这些可以成为提升到生产环境的候选者，最终决定基于额外的标准（可能是测试集上的AUC值）。
- en: If one of those additional criteria is native interpretability, then `GLM_1`
    for this AutoML object is the only choice. Note that interpretable models are
    indicated with a red-colored font in the model correlation heatmap.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些额外标准之一是原生可解释性，那么对于这个AutoML对象，`GLM_1`是唯一的选择。请注意，在模型相关性热图中，可解释的模型用红色字体表示。
- en: 'We can create this display directly using the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接使用以下代码创建此显示：
- en: '[PRE4]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let's move on to introduce partial dependence plots for multiple models in the
    next subsection.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续介绍下一小节中多个模型的部分依赖图。
- en: Multiple-model partial dependence plots
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多模型部分依赖图
- en: 'The third output from the `explain` method for multiple models is an extension
    of the partial dependence plot. For categorical variables, plot symbols and colors
    corresponding to different models are displayed on an individual plot. *Figure
    7.19* is an example using the `term` variable:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 多模型`explain`方法的第三个输出是部分依赖图的扩展。对于分类变量，每个图上显示与不同模型对应的符号和颜色。*图7.19*是使用`term`变量的一个示例：
- en: '![Figure 7.19 – Multiple model partial dependence plot for a loan term'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.19 – 贷款期限的多模型部分依赖图'
- en: '](img/B16721_07_19.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_07_19.jpg)'
- en: Figure 7.19 – Multiple model partial dependence plot for a loan term
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19 – 贷款期限的多模型部分依赖图
- en: 'For numeric variables, multiple models are represented by different colored
    lines on the same partial dependence plot. *Figure 7.20* is an example of this
    using the `revol_util` variable:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值变量，多个模型在同一部分依赖图上用不同颜色的线条表示。*图7.20*是使用`revol_util`变量示例：
- en: '![Figure 7.20 – Multiple model partial dependence plot for revolving utilization'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.20 – 旋转利用率的多模型部分依赖图]'
- en: '](img/B16721_07_20.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_20.jpg]'
- en: Figure 7.20 – Multiple model partial dependence plot for revolving utilization
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20 – 多模型旋转利用率的部分依赖图
- en: 'In *Figure 7.19* and *Figure 7.20*, the competing models yield very similar
    results. This is not always the case. For example, *Figure 7.21* shows the multiple
    model partial dependence plot for annual income:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.19*和*图7.20*中，竞争模型产生了非常相似的结果。这并不总是如此。例如，*图7.21*显示了年收入的多模型部分依赖图：
- en: '![Figure 7.21 – Multiple model partial dependence plot for annual income'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.21 – 年收入的多模型部分依赖图]'
- en: '](img/B16721_07_21.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_07_21.jpg]'
- en: Figure 7.21 – Multiple model partial dependence plot for annual income
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.21 – 多模型年收入的部分依赖图
- en: Although most of the models in *Figure 7.21* are similar for lower incomes,
    they diverge rather drastically as incomes increase. This is partially due to
    the very small sample sizes in the tails of the annual income distribution. The
    data scientist may also decide to disqualify certain models based on unrealistic
    or unreasonable tail behavior. For example, based on our experience, it does not
    make sense for loan default risk to increase as annual income increases. At worst,
    we would expect no relationship between income and default beyond a certain point.
    We are more likely to expect a monotonic decrease in loan default as income increases.
    Based on this reasoning, we would remove the models for the top two lines (`DRF_1`
    and `GBM_1`) from consideration.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*图7.21*中的大多数模型在低收入时相似，但随着收入的增加，它们差异很大。这部分是由于年收入分布尾部的样本量非常小。数据科学家也可能基于不切实际或不合理的尾部行为决定取消某些模型的资格。例如，根据我们的经验，随着年收入增加，贷款违约风险增加是没有意义的。最坏的情况是，我们预计收入和违约之间在某个点之后没有关系。我们更有可能预计随着收入的增加，贷款违约将单调递减。基于这个推理，我们会从考虑中移除顶部两条线（`DRF_1`和`GBM_1`）的模型。
- en: 'As with other `explain` methods, we can create this plot directly using the
    following command:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他`explain`方法一样，我们可以直接使用以下命令创建此图：
- en: '[PRE5]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We next visit model documentation.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来访问模型文档。
- en: Automated model documentation (H2O AutoDoc)
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化模型文档（H2O AutoDoc）
- en: One of the important roles a data science team performs in an enterprise setting
    is documenting the history, attributes, and performance of models that are put
    into production. At a minimum, model documentation should be part of a data science
    team's best practices. More commonly in an enterprise setting, thorough model
    documentation or whitepapers are mandated to satisfy internal and external controls
    as well as regulatory or compliance requirements.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业环境中，数据科学团队的一个重要角色是记录投入生产的模型的历史、属性和性能。至少，模型文档应该是数据科学团队最佳实践的一部分。在企业环境中，通常需要详尽的模型文档或白皮书，以满足内部和外部控制以及监管或合规要求。
- en: As a rule, model documentation should be comprehensive enough to allow for the
    recreation of the model being documented. This entails identifying all data sources,
    including training and test data characteristics, specifying hardware system components,
    noting software versions, modeling code, software settings and seeds, modeling
    assumptions adopted, alternative models considered, performance metrics and appropriate
    diagnostics, and anything else necessary based on business or regulatory conditions.
    This process, while vital, is time-consuming and can be tedious.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型文档应该足够全面，以便能够重新创建所记录的模型。这包括识别所有数据源，包括训练和测试数据特征，指定硬件系统组件，记录软件版本，建模代码，软件设置和种子，采用的建模假设，考虑的替代模型，性能指标和适当的诊断，以及基于业务或监管条件所需的其他任何内容。虽然这个过程至关重要，但耗时且可能繁琐。
- en: '**H2O AutoDoc** is a commercial software product that automatically creates
    comprehensive documentation for models built in H2O-3 and scikit-learn. A similar
    capability has existed in H2O.ai''s **Driverless AI**, a commercial product that
    combines automatic feature engineering with enhanced AutoML to build and deploy
    supervised learning models. AutoDoc has been successfully used for documenting
    models now in production. We present a brief introduction to automatic document
    creation using AutoDoc here:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**H2O AutoDoc** 是一款商业软件产品，可以自动为在H2O-3和scikit-learn中构建的模型创建全面的文档。在H2O.ai的**Driverless
    AI**中，也存在类似的功能，这是一款结合了自动特征工程和增强AutoML的商业产品，用于构建和部署监督学习模型。AutoDoc已被成功用于记录现在投入生产的模型。在此，我们简要介绍了使用AutoDoc自动创建文档的方法：'
- en: 'After a model object has been created, we import the `Config` and `render_autodoc`
    modules into Python:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建模型对象之后，我们将`Config`和`render_autodoc`模块导入Python：
- en: '[PRE6]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we will specify the output file path:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将指定输出文件路径：
- en: '[PRE7]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we will render the report by passing the configuration information and
    model object:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将通过传递配置信息和模型对象来渲染报告：
- en: '[PRE8]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once the report is created, the location of the report can be indicated using
    the following:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 报告创建后，可以使用以下方式指示报告的位置：
- en: '[PRE9]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Figure 7.22* shows the table of contents for a 44-page report created by H2O
    AutoDoc in Microsoft Word:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.22* 展示了由H2O AutoDoc在Microsoft Word中创建的44页报告的目录：'
- en: '![Figure 7.22 – Table of contents for model documentation created by H2O AutoDoc'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.22 – 由H2O AutoDoc创建的模型文档目录'
- en: '](img/B16721_07_22.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_07_22.jpg)'
- en: Figure 7.22 – Table of contents for model documentation created by H2O AutoDoc
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.22 – 由H2O AutoDoc创建的模型文档目录
- en: 'The advantages of thorough documentation produced in a consistent manner with
    a minimal amount of manual effort are self-evident. Output as either a Microsoft
    Word document or in markdown format, the reports can be individually edited and
    further customized. Report templates are also easily edited, allowing a data science
    team to have a different report structure for different uses: internal whitepaper
    or report for regulatory review, for example. The AutoDoc capability is consistently
    one of the best-loved features for H2O software for the enterprise.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以最少的手动努力以一致的方式生成的详尽文档的优势是显而易见的。输出可以是Microsoft Word文档或Markdown格式，报告可以单独编辑和进一步定制。报告模板也易于编辑，允许数据科学团队根据不同的用途拥有不同的报告结构：例如，内部白皮书或用于监管审查的报告。AutoDoc功能一直是H2O企业软件最受欢迎的功能之一。
- en: Summary
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed multiple model performance metrics and learned
    how to choose one for evaluating a model's predictive performance. We introduced
    Shapley values through some simple examples to further understand their purpose
    and use in predictive model evaluation. Within H2O, we used the `explain` and
    `explain_row` commands to create global and local explanations for a single model.
    We learned how to interpret the resulting diagnostics and visualizations to gain
    trust in a model. For AutoML objects and other lists of models, we generated global
    and local explanations and saw how to use them alongside model performance metrics
    to weed out inappropriate candidate models. Putting it all together, we can now
    evaluate tradeoffs between model performance, scoring speed, and explanations
    in determining which model to put into production. Finally, we discussed the importance
    of model documentation and showed how H2O AutoDoc can automatically generate detailed
    documentation for any model built in H2O (or scikit-learn).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了多个模型性能指标，并学习了如何选择一个用于评估模型预测性能的指标。我们通过一些简单的例子介绍了Shapley值，以进一步了解它们在预测模型评估中的目的和使用。在H2O中，我们使用了`explain`和`explain_row`命令为单个模型创建全局和局部解释。我们学习了如何解释生成的诊断和可视化结果，以增强对模型的信任。对于AutoML对象和其他模型列表，我们生成了全局和局部解释，并展示了如何将它们与模型性能指标一起使用，以筛选掉不合适的候选模型。综合以上内容，我们现在可以评估模型性能、评分速度和解释之间的权衡，以确定哪个模型可以投入生产。最后，我们讨论了模型文档的重要性，并展示了H2O
    AutoDoc如何自动为在H2O（或scikit-learn）中构建的任何模型生成详细的文档。
- en: In the next chapter, we will put everything we have learned about building and
    evaluating models in H2O together to create a deployment-ready model for predicting
    bad loans in the Lending Club data.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把我们在H2O中构建和评估模型所学的所有内容结合起来，为Lending Club数据预测不良贷款创建一个部署就绪的模型。
