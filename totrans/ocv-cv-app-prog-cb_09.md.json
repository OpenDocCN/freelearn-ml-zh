["```py\n  // Define keypoints vector\n  std::vector<cv::KeyPoint> keypoints1;\n  std::vector<cv::KeyPoint> keypoints2;\n  // Define feature detector\n  cv::FastFeatureDetector fastDet(80);\n  // Keypoint detection\n  fastDet.detect(image1,keypoints1);\n  fastDet.detect(image2,keypoints2);\n```", "```py\n  // Define a square neighborhood\n  const int nsize(11); // size of the neighborhood\n  cv::Rect neighborhood(0, 0, nsize, nsize); // 11x11\n  cv::Mat patch1;\n  cv::Mat patch2;\n```", "```py\n// For all keypoints in first image\n// find best match in second image\ncv::Mat result;\nstd::vector<cv::DMatch> matches;\n\n//for all keypoints in image 1\nfor (int i=0; i<keypoints1.size(); i++) {\n\n  // define image patch\n  neighborhood.x = keypoints1[i].pt.x-nsize/2;\n  neighborhood.y = keypoints1[i].pt.y-nsize/2;\n\n  // if neighborhood of points outside image, \n  // then continue with next point\n  if (neighborhood.x<0 || neighborhood.y<0 ||\n      neighborhood.x+nsize >= image1.cols || \n          neighborhood.y+nsize >= image1.rows)\n      continue;\n\n  //patch in image 1\n  patch1 = image1(neighborhood);\n\n  // reset best correlation value;\n  cv::DMatch bestMatch;\n\n  //for all keypoints in image 2\n  for (int j=0; j<keypoints2.size(); j++) {\n\n      // define image patch\n      neighborhood.x = keypoints2[j].pt.x-nsize/2;\n      neighborhood.y = keypoints2[j].pt.y-nsize/2;\n\n      // if neighborhood of points outside image, \n      // then continue with next point\n      if (neighborhood.x<0 || neighborhood.y<0 ||\n        neighborhood.x + nsize >= image2.cols ||\n             neighborhood.y + nsize >= image2.rows)\n          continue;\n\n      // patch in image 2\n      patch2 = image2(neighborhood);\n\n      // match the two patches                  \n         cv::matchTemplate(patch1,patch2,result,\n                           CV_TM_SQDIFF_NORMED);\n\n      // check if it is a best match\n      if (result.at<float>(0,0) < bestMatch.distance) {\n\n        bestMatch.distance= result.at<float>(0,0);\n        bestMatch.queryIdx= i;\n        bestMatch.trainIdx= j;\n      }\n    }\n\n    // add the best match\n    matches.push_back(bestMatch);\n}\n```", "```py\n  // extract the 25 best matches\n  std::nth_element(matches.begin(),\n                    matches.begin()+25,matches.end());\n  matches.erase(matches.begin()+25,matches.end());\n```", "```py\n  // Draw the matching results\n  cv::Mat matchImage;\n  cv::drawMatches(image1,keypoints1,          // first image\n                   image2,keypoints2,         // second image\n                   matches,                   // vector of matches\n                   cv::Scalar(255,255,255),   // color of lines\n                   cv::Scalar(255,255,255));  // color of points\n```", "```py\n// define search region\ncv::Mat roi(image2, \n  // here top half of the image\n  cv::Rect(0,0,image2.cols,image2.rows/2)); \n\n// perform template matching\ncv::matchTemplate(\n  roi,    // search region\n  target, // template\n  result, // result\n  CV_TM_SQDIFF); // similarity measure\n\n// find most similar location\ndouble minVal, maxVal;\ncv::Point minPt, maxPt;\ncv::minMaxLoc(result, &minVal, &maxVal, &minPt, &maxPt);\n\n// draw rectangle at most similar location\n// at minPt in this case\ncv::rectangle(roi, \n   cv::Rect(minPt.x, minPt.y, target.cols , target.rows), \n   255);\n```", "```py\n  // Define feature detector\n  // Construct the SURF feature detector object\n  cv::Ptr<cv::FeatureDetector> detector = new cv::SURF(1500.);\n\n  // Keypoint detection\n  // Detect the SURF features\n  detector->detect(image1,keypoints1);\n  detector->detect(image2,keypoints2);\n\n  // SURF includes both the detector and descriptor extractor\n  cv::Ptr<cv::DescriptorExtractor> descriptor = detector;\n\n  // Extract the descriptor\n   cv::Mat descriptors1;\n   cv::Mat descriptors2;\n   descriptor->compute(image1,keypoints1,descriptors1);\n   descriptor->compute(image2,keypoints2,descriptors2);\n```", "```py\n   // Construction of the matcher \n   cv::BFMatcher matcher(cv::NORM_L2);\n   // Match the two image descriptors\n   std::vector<cv::DMatch> matches;\n   matcher.match(descriptors1,descriptors2, matches);\n```", "```py\n   // Construction of the matcher with cross-check \n   cv::BFMatcher matcher2(cv::NORM_L2, // distance measure\n                         true);       // cross-check flag\n```", "```py\n  // find the best two matches of each keypoint\n    std::vector<std::vector<cv::DMatch>> matches2;\n    matcher.knnMatch(descriptors1,descriptors2, matches2, \n                 2); // find the k best matches\n```", "```py\n// perform ratio test\ndouble ratio= 0.85;\nstd::vector<std::vector<cv::DMatch>>::iterator it;\nfor (it= matches2.begin(); it!= matches2.end(); ++it) {\n\n  //   first best match/second best match\n  if ((*it)[0].distance/(*it)[1].distance < ratio) {\n    // it is an acceptable match\n    matches.push_back((*it)[0]);\n  }\n}\n// matches is the new match set\n```", "```py\n// radius match\nfloat maxDist= 0.4;\nstd::vector<std::vector<cv::DMatch>> matches2;\nmatcher.radiusMatch(descriptors1, descriptors2, matches2, \n                  maxDist); // maximum acceptable distance\n                             // between the 2 descriptors\n```", "```py\n// Define keypoints vector\nstd::vector<cv::KeyPoint> keypoints1, keypoints2;\n// Construct the ORB feature detector object\ncv::Ptr<cv::FeatureDetector> detector = \n  new cv::ORB(100); // detect approx 100 ORB points  \n// Detect the ORB features\ndetector->detect(image1,keypoints1);\ndetector->detect(image2,keypoints2);\n// ORB includes both the detector and descriptor extractor\ncv::Ptr<cv::DescriptorExtractor> descriptor = detector;\n// Extract the descriptor\ncv::Mat descriptors1, descriptors2;\ndescriptor->compute(image1,keypoints1,descriptors1);\ndescriptor->compute(image2,keypoints2,descriptors2);\n// Construction of the matcher \ncv::BFMatcher matcher(\n     cv::NORM_HAMMING); // always use hamming norm\n                        // for binary descriptors\n// Match the two image descriptors\nstd::vector<cv::DMatch> matches;\nmatcher.match(descriptors1,descriptors2, matches);\n```", "```py\ncv::Ptr<cv::DescriptorExtractor> descriptor =\n   new cv::FREAK(); // to describe with FREAK  \n```"]