- en: Chapter 10. Ensembling Survival Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The primary biliary cirrhosis data was introduced in first two chapters using
    the jackknife method. Observations in clinical trials are usually subject to censoring,
    and the jackknife method helps to complete incomplete observations through the
    idea of pseudo values. Since pseudo values are likely to be dependent on each
    other, the generalized estimating equation framework made it possible to estimate
    the impact of twelve covariates at the time of interest. The idea of pseudo values
    and the generalized estimating equation framework makes it easy for practitioners
    to interpret the results. However, this method might not be useful if the number
    of censored observations is exceptionally high. Furthermore, it is also preferable
    to have statistical methods that preserve the incompleteness of the observations
    and yet make good use of them. The general (linear) regression framework with
    time as the dependent variable and the error term following appropriate lifetime
    distribution can be set up in the usual regression framework. However, it turns
    out to be unreliable, and in many cases, it is known to be unstable, or the convergence
    simply does not take place. In *Regression Models and Life-Tables* ([http://www.stat.cmu.edu/~ryantibs/journalclub/cox_1972.pdf](http://www.stat.cmu.edu/~ryantibs/journalclub/cox_1972.pdf)),
    Cox (1972) achieved a breakthrough in the regression modeling of the survival
    data when he proposed the proportional hazards model. So, what is a hazards model?
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will open with core survival analysis concepts such as hazard rate,
    cumulative hazard function, and survival function. A few parametric lifetime models
    are also discussed and visualized through R programs. For the given data, we will
    then study how to carry out inference for the lifetime distribution through nonparametric
    methods. An estimation of the survival function and cumulative hazard function
    is then illustrated for the time to event of interest for the `pbc` dataset. Hypothesis
    testing through the use of the logrank test is demonstrated for different segments
    of the `pbc` data. Regression models will begin with a simple illustration of
    the parametric regression model, using exponential distribution as an example.
    It is known that the parametric models are not very useful for clinical trials
    data. This leads to an important variant in the Cox proportional hazards regression
    model, which is a **semiparametric** model in the sense that the baseline hazard
    rate is left completely unspecified and the impact of covariates is modeled through
    an exponential linear term on the hazard rate.
  prefs: []
  type: TYPE_NORMAL
- en: Survival trees are an important variant of the decision tree applicable to the
    survival data. The split criteria are based on the **logrank** test. Naturally,
    we will be interested in ensemble methods for the survival data, and hence we
    develop the survival random forests in the concluding section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Essential concepts of survival analysis, such as hazard rate, cumulative hazard
    function, and survival function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Nelson-Aalen and Kaplan Meier estimators as respective estimators of the
    cumulative hazard function and the survival function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logrank tests for the comparison of survival curves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parametric and semiparametric methods analyzing the impact of independent covariates
    on the hazard rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Survival tree based on logrank test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random forests as ensemble methods for the survival data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Core concepts of survival analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Survival analysis deals with censored data, and it is very common that parametric
    models are unsuitable for explaining the lifetimes observed in clinical trials.
  prefs: []
  type: TYPE_NORMAL
- en: Let *T* denote the survival time, or the time to the event of interest, and
    we will naturally have ![Core concepts of survival analysis](img/00399.jpeg),
    which is a continuous random variable. Suppose that the lifetime cumulative distribution
    is *F* and the associated density function is *f*. We define important concepts
    as required for further analysis. We will explore the concept of *survival function*
    next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that *T* is the continuous random variable of a lifetime and that the
    associated cumulative distribution function is *F*. The survival function at time
    *t* is the probability the observation is still alive at the time, and it is defined
    by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00400.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The survival function can take different forms. Let's go through some examples
    for each of the distributions to get a clearer picture of the difference in survival
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exponential Distribution**: Suppose that the lifetime distribution of an
    electronic component follows exponential distribution with rate ![Core concepts
    of survival analysis](img/00401.jpeg). Then, its density function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00402.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The cumulative distribution function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00403.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The mean and variance of the exponential distribution are, respectively, ![Core
    concepts of survival analysis](img/00404.jpeg) and ![Core concepts of survival
    analysis](img/00405.jpeg). The survival function of the exponential distribution
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00406.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The mean of exponential distribution is ![Core concepts of survival analysis](img/00407.jpeg).
    The exponential distribution is driven by a single parameter and it also enjoys
    an elegant property, which is known as a memoryless property (see Chapter 6, Tattar,
    et al. (2016)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Gamma Distribution**: We say that the lifetime random variable follows a
    gamma distribution with rate ![Core concepts of survival analysis](img/00408.jpeg)
    and shape ![Core concepts of survival analysis](img/00409.jpeg), if its probability
    density function `f` is of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00410.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The mean and variance of gamma distribution are, respectively, ![Core concepts
    of survival analysis](img/00411.jpeg) and ![Core concepts of survival analysis](img/00412.jpeg).
    A closed form of the cumulative distribution functions, and hence the survival
    function, does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: '**Weibull Distribution**: A lifetime random variable is said to follow a Weibull
    distribution with rate ![Core concepts of survival analysis](img/00413.jpeg) and
    shape ![Core concepts of survival analysis](img/00414.jpeg), if its probability
    density function `f` is of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00415.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The cumulative distribution function of the Weibull distribution is demonstrated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00416.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The survival function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00417.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Next, we will define the concept of hazard rate, which is also known as the
    instantaneous failure rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *T* denote the lifetime random variable and *F* denote the associated cumulative
    distribution function, then the hazard rate at time `t` is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00418.jpeg)![Core concepts of survival
    analysis](img/00419.jpeg)![Core concepts of survival analysis](img/00420.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The problem of estimating the hazard rate is as difficult as that of the density
    function, and hence the cumulative function concept will be useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *T* denote the lifetime random variable and ![Core concepts of survival
    analysis](img/00421.jpeg) be the associated hazard rate, then the cumulative hazard
    function is defined using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00422.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following relationship exists between these three quantities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00423.jpeg)![Core concepts of survival
    analysis](img/00424.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The expected value is related to the survival function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00425.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the next R program, we will visualize the three survival quantities for
    the three probability distributions. First, we will set up a graphical device
    for nine plots with the par and `mfrow` functions. The program is explained for
    the exponential distribution. Consider the time period 0-100 and create a numeric
    object `Time` in the program. We will begin with the computation of the values
    of the density functions using the `dexp` function for the Time object. This means
    that `dexp(Time)` will calculate the value of the density function *f(t)* for
    each point between 0–100\. Since the survival function is related to the cumulative
    distribution by ![Core concepts of survival analysis](img/00426.jpeg) and `pexp`
    gives us the values of *F* at the time point *t*, the survival function for the
    exponential distribution is computed as *1-pexp()*. The hazard rate, density function,
    and survival function are related by ![Core concepts of survival analysis](img/00427.jpeg)
    and can be easily obtained. The cumulative hazard function is obtained by using
    the values of the survival function and the relationship as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00428.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The program is then repeated for the gamma and Weibull distribution with changes
    in the appropriate specification of the parameters, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Core concepts of survival analysis](img/00429.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Hazard rate, Cumulative hazard function, and Survival function for
    Exponential, Gamma, and Weibull distributions'
  prefs: []
  type: TYPE_NORMAL
- en: Repeat the preceding program for different parameter values and prepare a summary
    of your observations for the change in the hazard function, cumulative hazard
    function, and the survival function. Summarize your observations separately for
    the three distributions of exponential, gamma, and Weibull.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to see how well the model fits to the `pbc` dataset. Here, we
    will fit the exponential, gamma, and Weibull distributions to the lifetimes of
    interest in the `pbc` dataset. Note that, since we have censored data, the incomplete
    observations can''t simply be thrown away, as 257 out of 418 are incomplete observations.
    Though we can''t go into the mathematics of the maximum likelihood estimation
    for survival data, it is important to note here that the contribution of a complete
    observation to the likelihood is *f(t)* and if it is incomplete/censored, it is
    *S(t)*. Consequently, it is important for the software to know which observation
    is complete and which is incomplete. Here we will use the `Surv` function from
    the `survival` package to specify this, and then use the `flexsurvreg` function
    from the `flexsurv` package to fit an appropriate lifetime distribution. The option
    of `dist` helps set up the appropriate distributions, as can be seen in the following
    program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting diagram is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Core concepts of survival analysis](img/00430.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Fitting exponential, gamma, and Weibull distributions for censored
    data'
  prefs: []
  type: TYPE_NORMAL
- en: The AIC value for the fitted exponential model is 3065.187, for the fitted gamma
    model it is 3066.147, and for Weibull it is 3066.035\. The lower the criteria,
    the better. Consequently, the exponential is the best fit according to the AIC
    criteria. This is then followed by the Weibull and gamma distributions. The exponential
    distribution with a single parameter is a better fit here than the more complex
    models of gamma and Weibull.
  prefs: []
  type: TYPE_NORMAL
- en: Some explanation of the R program is in order now. The `pbc` dataset is loaded
    with `survival::pbc` since the R package `randomForestSRC` also has a dataset
    with the same name and it is a slightly different version. Consequently, the `survival::pbc`
    code ensures that we continue to load the `pbc` dataset as we did in earlier instances.
    The event of interest for us is indicated by `status==2` and `Surv(pbc$time,pbc$status==2)`,
    which creates a survival object that has complete observations mentioned in the
    numeric object. If the `status` is anything other than `2`, the observation is
    censored and this is indicated by the number followed by the `+` sign. The `Surv(time,status==2)~1`
    code creates the necessary formula, which is useful for applying survival functions.
    The `dist="exponential"` option ensures that exponential distribution is fitted
    on the survival data. When the fitted model `pbc_exp` is run on the console, we
    get a summary of the fitted model and it returns the estimates of the parameters
    of the model, the 95% confidence interval, and the standard error of the parameter's
    estimate. We also get the count of complete and censored observations, the total
    time at risk for all patients, the likelihood function value, and the AIC. Note
    how the degrees of freedom vary across the three fitted distributions.
  prefs: []
  type: TYPE_NORMAL
- en: The parametric models detailed here give an idea of the survival concepts. When
    we don't have enough evidence to construct a parametric model, we resort to nonparametric
    and semiparametric models for carrying out the statistical inference. In the following
    section, we will continue our analysis of the `pbc` data.
  prefs: []
  type: TYPE_NORMAL
- en: Nonparametric inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Survival data is subject to censoring and we need to introduce a new quantity
    to capture this information. Suppose that we have a *n* IID random sample of lifetime
    random variables in ![Nonparametric inference](img/00431.jpeg), and we know that
    the event of interest might have occurred or that it will occur sometime in the
    future. The additional information is captured by the Kronecker indicator variable,
    ![Nonparametric inference](img/00432.jpeg):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonparametric inference](img/00433.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Thus, we have n pairs of random observations in the *Ts* and ![Nonparametric
    inference](img/00434.jpeg)s, ![Nonparametric inference](img/00435.jpeg). To obtain
    the estimates of the cumulative hazard function and the survival function, we
    will need an additional notation. Let ![Nonparametric inference](img/00436.jpeg)
    denote the unique times of Ts at which the event of interest is observed. Next,
    we denote ![Nonparametric inference](img/00437.jpeg) to represent the number of
    observations that are at risk just before times ![Nonparametric inference](img/00438.jpeg)
    and ![Nonparametric inference](img/00439.jpeg) the number of events that occur
    at that time. Using these quantities, we now propose to estimate the cumulative
    hazard function using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonparametric inference](img/00440.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The estimator ![Nonparametric inference](img/00441.jpeg) is the famous Nelson-Aalen
    estimator. The Nelson-Aalen estimator enjoys statistical properties including
    the fact that (i) it is the nonparametric maximum likelihood estimator for the
    cumulative hazard function, and (ii) it follows an asymptotically normal distribution.
    An estimator of the survival function is given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonparametric inference](img/00442.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The estimator ![Nonparametric inference](img/00443.jpeg) is the well-known Kaplan-Meier
    estimator. The properties of the Nelson-Aalen estimator get carried over to the
    Kaplan-Meier estimator by an application of the functional-delta theorem. It should
    be noted that the Kaplan-Meier estimator is again the nonparametric maximum likelihood
    estimator and asymptotically, it follows the normal distribution. We will now
    look at how to obtain the estimates for a given dataset using R software.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have already created the survival object using the `Surv(pbc$time, pbc$status==2)`
    code. Now, applying the `survfit` function on the survival object, we set up the
    Kaplan-Meier estimator in the `pbc_sf survfit` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output shows that we have `418` observations. Out of these, `161` experience
    the event of interest. We would like to obtain the survival function at different
    time points of interest. The median survival time is shown as `3395` and the confidence
    interval for this point estimate is `3090` and `3853`. However, if you find the
    median of the overall times, the median time for complete observations, and for
    censored observations, none of that will come closer to the displayed value of
    `3395`. A quick code reveals the results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You may ask yourself, Why is there so much of a difference between the estimated
    median survival time and these medians? The answer will become clear soon enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `summary` function will be used to obtain that answer. For the ten deciles
    of the observed time, inclusive of censored times, we will obtain the Kaplan-Meier
    estimates and the associated 95% confidence interval, which is based on the variance
    estimate, which in turn is based on Greenwood''s formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We have now obtained the Kaplan-Meier estimates at each of the decile time
    points, the standard error, and the confidence interval at each of the points.
    Using the `plot` function, we will now visualize the fitted Kaplan-Meier estimator
    for the `pbc` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Nonparametric inference](img/00444.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Kaplan-Meier estimator for the PBC dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Now, if you look at the time at which the survival time becomes nearly 0.5,
    the earlier answer of median survival time being 3395 becomes clear enough. Next,
    we look at the cumulative hazard function.
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain the cumulative hazard function, we will apply the `coxph` function
    on the survival object and use the `basehaz` function to get the baseline cumulative
    hazard function, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use the following code to create a visual display of the Nelson-Aalen
    estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following graph illustrates the Nelson-Aalen estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonparametric inference](img/00445.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The Nelson-Aalen estimator for the cumulative hazard function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that one might be tempted to use the ![Nonparametric inference](img/00446.jpeg)
    relationship to obtain the Kaplan-Meier estimator, or vice versa. Let us check
    it out using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything seems to be right here, so let''s check it in its entirety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: After a certain length of time, the estimates will differ vastly, and hence
    we compute these two quantities separately. Next, we will look at how to carry
    out statistical tests to compare the equality of survival curves.
  prefs: []
  type: TYPE_NORMAL
- en: As noted previously, we are feeding a formula to the `survfit` function. It
    appeared as an extra specification `'~1'` in the `Surv` formula. As the formula
    is essential for further analysis of survival data, we can now make good use of
    this framework. If we replace 1 with a categorical variable such as sex, then
    we will then obtain survival curves for each level of the categorical variable.
    For the `pbc` data, we will plot the survival curves. The Kaplan-Meier estimates
    for males and females separately.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![Nonparametric inference](img/00447.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Gender-wise comparison of the survival curves for the PBC data'
  prefs: []
  type: TYPE_NORMAL
- en: 'The survival curves (indicated by the blue and red continuous lines) clearly
    show differences and we need to evaluate whether the observed difference is statistically
    significant. To that end, we apply the `survdiff` function and check if the difference
    is significant, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The p-value is `0.0845`, and hence if the chosen significance is 95%, we conclude
    that the difference is insignificant.
  prefs: []
  type: TYPE_NORMAL
- en: 'A note to the reader: the significance level is pre-determined. If you have
    fixed it at 95% before carrying out the analysis and then look at the p-value
    and find that it is between 0.05 and 0.10, don''t change the level. Stick to what
    was agreed on earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: In the analysis thus far, we have looked at parametric and nonparametric methods,
    and now we need to develop a larger framework. The impact of covariates needs
    to be evaluated clearly, and we will explore this topic in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Regression models – parametric and Cox proportional hazards models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may recall that the survival data consists of complete as well as censored
    observations, and we saw that the lifetimes look like 400, 4500+, 1012, 1925,
    1504+, … for the `pbc` dataset. Although the lifetimes are continuous random variables,
    a regression model of the form ![Regression models – parametric and Cox proportional
    hazards models](img/00448.jpeg) will not be appropriate here. In fact, there were
    many attempts to correct and improvise on models of this form in the 1970s, and
    most often the results were detrimental. We will define a generic **hazards regression
    model** as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression models – parametric and Cox proportional hazards models](img/00449.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *t* is the lifetime, ![Regression models – parametric and Cox proportional
    hazards models](img/00450.jpeg) is the lifetime indicator, ![Regression models
    – parametric and Cox proportional hazards models](img/00451.jpeg) is the covariate
    vector, ![Regression models – parametric and Cox proportional hazards models](img/00452.jpeg)
    is the vector of regression coefficients, and ![Regression models – parametric
    and Cox proportional hazards models](img/00453.jpeg) is the baseline hazard rate.
    A relative risks model that is of specific interest is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression models – parametric and Cox proportional hazards models](img/00454.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will focus solely on this class of model. First, the parametric hazards
    regression is considered. This means that we will specify the hazard rate ![Regression
    models – parametric and Cox proportional hazards models](img/00455.jpeg) through
    a parametric model, for example, through exponential distribution. But what does
    this mean? It means that the baseline hazard function is of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression models – parametric and Cox proportional hazards models](img/00456.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Consequently, the hazards regression model is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression models – parametric and Cox proportional hazards models](img/00457.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The estimation problem is then to find ![Regression models – parametric and
    Cox proportional hazards models](img/00458.jpeg) and ![Regression models – parametric
    and Cox proportional hazards models](img/00459.jpeg). The R function `survreg`
    from the `flexsurv` package will be useful to fit the parametric hazards regression
    model. It is demonstrated as continuity on the `pbc` dataset. The `survival` formula
    will be extended to include all the covariates in the model, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the convergence occurs after five iterations. The p-value is nearly equal
    to zero, which implies that the fitted model is significant. However, not all
    the p-values associated with the covariates indicate significance. We will use
    the following code to find it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The AIC value is also very high, and we try to see if this can be improved
    on. Hence, we slap the `step` function on the fitted exponential hazards regression
    model and eliminate the covariates that are insignificant, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We see here that all the covariates in the current model are significant, except
    the `trig` and `platelet` variables. The AIC value has also decreased drastically.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parametric models are often not acceptable in life sciences. A flexible framework
    for ![Regression models – parametric and Cox proportional hazards models](img/00460.jpeg)
    is the famous Cox proportional hazards model. It is a semi-parametric regression
    model in that the baseline hazard function ![Regression models – parametric and
    Cox proportional hazards models](img/00461.jpeg) is completely unspecified. Cox
    (1972) proposed this model, which is one of the most important models in statistics.
    The only requirement of the baseline hazard function ![Regression models – parametric
    and Cox proportional hazards models](img/00462.jpeg) is that it must be non-negative
    and the associated probability distribution with it must be a *proper* probability
    distribution. In this model, the regression coefficient vector ![Regression models
    – parametric and Cox proportional hazards models](img/00463.jpeg) is estimated
    by treating the baseline hazard function as a nuisance factor. Its inference is
    based on the important notion of partial likelihood function; see Cox (1975) for
    complete details. Here, we will only specify the form of the Cox proportional
    hazards model and refer the interested reader to Kalbfleisch and Prentice (2002):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression models – parametric and Cox proportional hazards models](img/00464.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We will use the `coxph` function from the `survival` package to fit the proportional
    hazards regression model. For some technical reason, we will have to omit all
    rows from the `pbc` dataset which have missing values, and the remaining steps
    parallel the fitting of the exponential hazards regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we find that a lot of variables are insignificant, we will attempt to
    improve on it by using the `step` function and then calculating the improved AIC
    value, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We can now see that almost all the variables in the `pbc_coxph_eff` model are
    significant. The AIC value has also decreased from its earlier value.
  prefs: []
  type: TYPE_NORMAL
- en: In most survival data analyses, the purpose is to find the effective covariates
    and their impact on the hazard rate. Accuracy measures, such as AUC with classification
    problems, do not exist in the context of survival data. On similar (though important)
    lines, the prediction of the lifetime for a given choice of covariates might not
    again be of importance. In [Chapter 2](part0018_split_000.html#H5A41-2006c10fab20488594398dc4871637ee
    "Chapter 2. Bootstrapping"), *Bootstrapping*, we looked at the application of
    pseudo values and the jackknife methods that provided ease of interpretation.
    We will look at a different approach in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Survival tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The parametric hazards regression model is sometimes seen as a restrictive class
    of models by practitioners, and the Cox proportional hazards regression is sometimes
    preferred over its parametric counterpart. Compared with the parametric models,
    the interpretation is sometimes lost, and the regular practitioner finds it difficult
    to connect with the hazards regression model. Of course, an alternative is to
    build a survival tree over the pseudo observations. Such an attempt can be seen
    in Tattar's (2016) unpublished paper. Gordon and Olshen (1985) made the first
    attempt to build a survival tree and many scientists have continued constructing
    it. LeBlanc and Crowley (1992) are among the most important contributors to set
    up a survival tree. Zhang and Singer (2010) have also given a systematic development
    of related methods, and chapters 7-10 of their book deal with survival trees.
    The basic premise remains the same, and we need good splitting criteria in order
    to create the survival tree.
  prefs: []
  type: TYPE_NORMAL
- en: LeBlanc and Crowley proposed the splitting criteria based on the node deviance
    measure between a saturated model log-likelihood and the maximum log-likelihood,
    and then the unknown full likelihood is approximated by replacing the baseline
    cumulative hazard function as estimated by the Nelson-Aalen estimator. As suggested
    by Hamad et al. (2011), note that the advantage of this method is that any software
    that can carry out the implementation of Poisson trees would be able to create
    the survival tree. This approach has been exploited in the `rpart` R package created
    by Therneau and Atkinson (2017). The terminal nodes of the survival tree can be
    summarized by the Kaplan-Meier survival function for the observations belonging
    in the node.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now set up the survival tree for the `pbc` dataset using the `rpart`
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: A text display of the survival tree is displayed by running `pbc_stree` at the
    console. The asterisk (`*`) at the end of the `yval` for a node indicates censorship.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look at the `cptable` and variable importance associated with the
    survival tree, as shown in the following program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The variable importance shows that the `bili` variable is the most important,
    followed by `protime` and `age`. We conclude this section with a visual depiction
    of the survival tree, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![Survival tree](img/00465.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Survival tree for the PBC dataset'
  prefs: []
  type: TYPE_NORMAL
- en: As with the problem of overfitting with a single tree, we need to look at an
    important alternative method of ensembles of survival trees.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble survival models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The random forest package `randomForestSRC` will continue to be useful for
    creating the random forests associated with the survival data. In fact, the `S`
    of `SRC` in the package name stands for survival! The usage of the `rfsrc` function
    remains the same as in previous chapters, and we will now give it a `Surv` object,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will find some of the basic settings that have gone into setting up this
    random forest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Thus, the splitting criteria is based on the log-rank test, the minimum number
    of observations in a terminal node is six, and the number of variables considered
    at random for each split is five.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will find the variable importance for both events and apply the function
    `var.select` as we have done in earlier chapters. We will then show a part of
    the iteration run using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, the error rate plot as the number of trees increases will be depicted
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![Ensemble survival models](img/00466.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Random forest error rates for the two events'
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, we have now seen the construction and setup of random forests
    for the survival data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Survival data is different to typical regression data, and the incomplete observations
    pose a challenge. Since the data structure is completely different, we need specialized
    techniques to handle the incomplete observations and to that end, we introduced
    core survival concepts, such as hazard rate and survival function. We then introduced
    parametric lifetime models, which gives us a brief peek at how the lifetime distribution
    should look. We even fitted these lifetime distributions into the pbc dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned that the parametric setup might be very restrictive, and hence
    considered the nonparametric methods of the estimation of survival quantities.
    We also demonstrated the utility of the Nelson-Aalen estimator, the Kaplan-Meier
    survival function, and the log-rank test. The parametric hazards regression model
    was backed with the Cox proportional hazards regression model and applied to the
    pbc dataset. The logrank test can also help in the splitting criteria, and it
    has also been seen as the criteria for the random forest. Survival trees were
    demonstrated in the earlier section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will look at another kind of data structure: time series
    data. The reader does not need to be familiar with time series analysis in order
    to follow the ensemble methods applied in it.'
  prefs: []
  type: TYPE_NORMAL
