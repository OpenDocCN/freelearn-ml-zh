- en: Clean Up Your Personal Twitter Timeline by Clustering Tweets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here''s a little bit of gossip for you: The original project for this title
    had to do with detecting foreign influence on US elections in social media. At
    about the same time, I was also applying for a visa to the United States, to give
    a series of talks. It later transpired that I hadn''t needed the visa after all;
    ESTA covered all the things I had wanted to do in the United States. But as I
    was preparing for the visa, an attorney gave me a very stern talking-to about
    writing a book on the politics of the United States. The general advice is this—if
    I don''t want trouble with US Customs and Border Patrol, I should not write or
    say anything on social media about American politics, and especially not write
    a chapter of a book on it. So, I had to hastily rewrite this chapter. The majority
    of methods used in this chapter can be used for the original purpose, but the
    content is a lot milder.'
  prefs: []
  type: TYPE_NORMAL
- en: I use Twitter a lot. I mainly tweet and read Twitter in my downtime. I follow
    many people who share similar interests, among other things, machine learning,
    artificial intelligence, Go, linguistics, and programming languages. These people
    not only share interests with me; they also share interests with one another.
    As such, sometimes, multiple people may be tweeting about the same topic.
  prefs: []
  type: TYPE_NORMAL
- en: As may be obvious from the fact that I use Twitter a lot, I am a novelty junkie.
    I like new things. Multiple people tweeting about the same topic is nice if I
    am interested in the differing viewpoints, but I don't use Twitter like that.
    I use Twitter as a sort of summary of interesting topics. Events X, Y, and Z happened.
    It's good enough that I know they happened. For most topics, there is no benefit
    for me to go deep and learn what the finer points are, and 140 characters is not
    a lot of characters for nuance anyway. Therefore, a shallow overview is enough
    to keep my general knowledge abreast with the rest of the population.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, when multiple people tweet about the same topic, that's repetition in
    my newsfeed. That's annoying. What if, instead of that, my feed could just be
    one instance of each topic?
  prefs: []
  type: TYPE_NORMAL
- en: I think of my Twitter-reading habit as happening in sessions. Each session is
    typically five minutes. I really only read about 100 tweets each session. If out
    of 100 tweets I read, 30% of the people I follow overlap on topics, then I really
    only have read 30 tweets of real content. That's not efficient at all! Efficiency
    means being able to cover more topics per session.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do you increase efficiency in reading tweets? Well, remove the tweets
    that cover the same topic of course! There is the secondary matter of choosing
    the best tweet that summarizes the topic, but that's a subject for another day.
  prefs: []
  type: TYPE_NORMAL
- en: The project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What we're going to do is to cluster tweets on Twitter. We will be using two
    different clustering techniques, K-means and DBSCAN. For this chapter, we're going
    to rely on some skills we built up in [Chapter 2](12c81095-6fcf-4da9-b554-6367d45b34f8.xhtml),
    *Linear Regression – House Price Prediction*. We will also be using the same libraries
    used in Chapter 2, *Linear Regression – House Price Prediction*. On top of that,
    we will also be using the clusters library by mpraski.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the project, we will be able to clean up any collection of tweets
    from Twitter, and cluster them into groups. The main body of code that fulfills
    the objective is very simple, it's only about 150 lines of code in total. The
    rest of the code is for fetching and preprocessing data.
  prefs: []
  type: TYPE_NORMAL
- en: K-means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**K-means** is a method of clustering data. The problem is posed as this—given
    a dataset of N items, we wish to partition the data into K groups. How do you
    do so?'
  prefs: []
  type: TYPE_NORMAL
- en: Allow me to take a side bar and explore the wonderful world of coordinates.
    No, no, don't run! It's very visual.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b3bd494-5b0d-41b0-a81e-0401099e2b92.png)'
  prefs: []
  type: TYPE_IMG
- en: Which line is longer? How do you know?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7b12adde-1086-432d-bbcc-5ad5ccd91311.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You know which line is longer because you can measure each line from points
    a, b, c, and d. Now, let''s try something different:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c45dafa-dfaa-4e0b-b663-7766b5ef57ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Which dot is closest to X? How do you know?
  prefs: []
  type: TYPE_NORMAL
- en: 'You know because again, you can measure the distance between the dots. And
    now, for our final exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6035e6fc-1038-4cbe-9bfa-15c56ba47388.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Consider the distance between the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A** and **X**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** and **Y**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** and **Z**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B** and **X**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B** and **Y**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B** and **Z**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C** and **X**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C** and **Y**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C** and **Z**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the average distance between **A** and **X**, **B** and **X**, and **C**
    and **X**? What is the average distance between **A** and **Y**, **B** and **Y**
    and **C** and **Y**? What is the average distance between **A** and **Z**, **B**
    and **Z**, and **C** and **Z**?
  prefs: []
  type: TYPE_NORMAL
- en: If you had to choose one point between **X**, **Y**, and **Z** to represent
    the **A**, **B**, and **C**, which would you choose?
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You just did a very simple and abbreviated version of K-means
    clustering. Specifically, you did a variant where *k = 1*. If you had to pick
    two points between **X**, **Y**, and **Z**, then that's *k = 2*. A cluster is
    therefore the set of points that make it such that the average distance of the
    group is minimal.
  prefs: []
  type: TYPE_NORMAL
- en: That's a mouthful, but think back to what you just did. Now, instead of just
    three points, **A**, **B**, and **C**, you have many points. And you aren't given
    **X**, **Y**, or **Z**; you'd have to generate your own **X**, **Y**, and **Z**
    points. Then, you have to find the groups that minimize the distance to each possible
    points of **X**, **Y**, and **Z**.
  prefs: []
  type: TYPE_NORMAL
- en: That is, in a nutshell, K-means. It's easy to understand, but hard to implement
    it well. It turns out K-means is NP-hard; it may not be solved in polynomial time.
  prefs: []
  type: TYPE_NORMAL
- en: DBSCAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**DBSCAN** inherits the idea that data can be represented as multidimensional
    points. Again, sticking with a two-dimensional example, this is in rough steps
    how DBSCAN works:'
  prefs: []
  type: TYPE_NORMAL
- en: Pick a point that has not been visited before.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a circle with the point as the center. The radius of the circle is epsilon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Count how many other points fall into the circle. If there are more than a specified
    threshold, we mark all the points as being part of the same cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recursively do the same for each point in this cluster. Doing so expands the
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat these steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I highly encourage you to do this on dotted paper and try to draw this out yourself.
    Start by plotting random points, and use pencils to draw circles on paper. This
    will give you an intuition of how DBSCAN works. The picture shows my working that
    enhanced my intuition about how DBSCAN works. I found this intuition to be very
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: Data acquisition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the earlier exercises, I asked you to look at the dots and figure out the
    distance. This gives a hint as to how we need to think of our data. We need to
    think of our data as coordinates in some imaginary coordinate space. Now, our
    data won't be just two-dimensional, because it's textual. Instead, it'll be multidimensional.
    This gives us hints as to how our data will look—slices of numbers representing
    a coordinate in some arbitrarily large N-dimensional space.
  prefs: []
  type: TYPE_NORMAL
- en: But, first, we'll need to get the data.
  prefs: []
  type: TYPE_NORMAL
- en: To acquire the tweets from the feed, we'll be using Aditya Mukherjee's excellent
    Anaconda library. To install it, simply run `go get -u github.com/ChimeraCoder/Anaconda`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, one can''t just grab data from Twitter willy-nilly. We will need
    to acquire data via the Twitter API. The documentation of Twitter''s API is the
    best source to get started: [https://developer.twitter.com/en/docs/basics/getting-started](https://developer.twitter.com/en/docs/basics/getting-started).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to first apply for a Twitter developer account (if you don''t
    already have it): [https://developer.twitter.com/en/apply/user](https://developer.twitter.com/en/apply/user).
    The process is rather lengthy and requires human approval for a developer account.
    Despite this, you don''t need developer access to develop this project. I thought
    I had access to Twitter''s API when I started, but it turns out I didn''t. The
    good news is, the Twitter API documentation page does provide enough examples
    to get started with developing the necessary data structures.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The specific end point that we''re interested in is this: [https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-home_timeline.html](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-home_timeline.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at the `JSON` acquired from the Twitter API endpoint. A single
    tweet looks something like this (from the Twitter API documentation example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will be representing each individual tweet in a data structure that looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we embed `anaconda.Tweet`, which is given as such in the Anaconda
    package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the interest of building the program, we''ll use the example tweets supplied
    by Twitter. I saved the example responses into a file called `example.json` and
    then a `mock` function is created to mock calling the API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The utility function `dieIfErr` is defined as usual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note that in `mock`, no API calls to Twitter were made. In the future, we will
    be creating a function with a similar API so we can just replace the mock version
    of this function with the real one, which acquires the timeline from the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, we can test that this works by the following program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the output I got:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Data massage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we tested that the data structure made sense, we printed the `FullText`
    field. We wish to cluster based on the content of the tweet. What matters to us
    is that content. This can be found in the `FullText` field of the struct. Later
    on in the chapter, we will see how we may use the metadata of the tweets, such
    as location, to help cluster the tweets better.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in the previous sections, each individual tweet needs to be represented
    as a coordinate in some higher-dimensional space. Thus, our goal is to take all
    the tweets in a timeline and preprocess them in such a way that we can get this
    output table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Each row in the table represents a tweet, indexed by the tweet ID. The columns
    that follow are words that exist in the tweet, indexed by its header. So, in the
    first row, `test` appears in the tweet, while `twitter`, `right`, and `wrong`
    do not. The slice of numbers `[0 1 0 0]` in the first row is the input we require
    for the clustering algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, binary numbers indicating the presence of a word in a tweet isn't
    the best. It'd be more interesting if the relative importance of the word is used
    instead. Again, we turn to the familiar TF-IDF, first introduced in [Chapter 2](12c81095-6fcf-4da9-b554-6367d45b34f8.xhtml),
    *Linear Regression – House Price Prediction*, for this. More advanced techniques
    such as using word embeddings exist. But you'd be surprised how well something
    as simple as TF-IDF can perform.
  prefs: []
  type: TYPE_NORMAL
- en: By now, the process should be familiar—we want to represent the text as a slice
    of numbers, not as a slice of bytes. In order to do so, we would have to require
    some sort of dictionary to convert the words in the text into IDs. From there,
    we can built the table.
  prefs: []
  type: TYPE_NORMAL
- en: Again, like in [Chapter 2](https://cdp.packtpub.com/go_machine_learning_projects/wp-admin/post.php?post=28&action=edit#post_46), *Linear
    Regression – House Price* Prediction, we shall approach this with a simple tokenization
    strategy. More advanced tokenizers are nice, but not necessary for our purpose.
    Instead, we'll rely on good old `strings.Field`.
  prefs: []
  type: TYPE_NORMAL
- en: The processor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Having laid out our requirements, we can combine them into a single data structure
    that contains the things we need. Here''s how the processor data structure looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For now, ignore the `locations` field. We shall look into how metadata might
    be useful in clustering.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a new `processor`, the following function is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we see some interesting decisions. The corpus is constructed with a number
    of special strings—`mention`, `hashtag`, `retweet`, and `url.` These are defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Some of the designs of this is for historical reasons. A long time ago, before
    Twitter supported retweets as an action, people manually retweeted tweets by prepending
    `RT` on to tweets. If we are to analyze data far into the past (which we won't
    for this chapter), then we'd have to be aware of the historical designs of Twitter
    as well. So, you must design for that.
  prefs: []
  type: TYPE_NORMAL
- en: But having constructed a corpus with special keywords implies something. It
    implies that when converting the text of a tweet into a bunch of IDs and numbers,
    mentions, hashtags, retweets, and URLs are all treated as the same. It implies
    we don't really want to care what the URL is, or who is mentioned. However, when
    it comes to hashtags, that's the interesting case.
  prefs: []
  type: TYPE_NORMAL
- en: A hashtag is typically used to denote the topic of the tweet. Think `#MeToo` or
    `#TimesUp`. A hashtag contains information. Compressing all hashtags into one
    single ID may not be useful. This is a point to note when we experiment later
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having said all that, here''s how a list of `*processedTweet` is processed.
    We will be revisiting and revising the function as the chapter goes on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Let's go through this function line by line.
  prefs: []
  type: TYPE_NORMAL
- en: We start by ranging over all the `*processedTweets`. `a` is `[]*processedTweet`
    for a good reason—we want to modify the structure as we go along. If `a` were
    `[]processedTweet`, then we would have to either allocate a lot more, or have
    complicated modification schemes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each tweet is comprised of its `FullText`. We want to extract each word from
    the text, and then give each word its own ID. To do that, this is the loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Preprocessing a single word
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `p.single` processes a single word. It returns the ID of the word, and
    whether to add it to the list of words that make up the tweet. It is defined as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We start by making the word lowercase. This makes words such as `café` and `Café`
    equivalent.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking of `café`, what would happen if there are two tweets mentioning a `café`,
    but one user writes `café` and the other writes cafe? Assume, of course, they
    both refer to the same thing. We'd need some form of normalization to tell us
    that they're the same.
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing a string
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, the word is to be normalized into `NFKC` form. In [Chapter 2](https://cdp.packtpub.com/go_machine_learning_projects/wp-admin/post.php?post=28&action=edit#post_46), *Linear
    Regression–House Price Prediction*, this was introduced, but I then mentioned
    that LingSpam basically provides normalized datasets. In real-world data, which
    Twitter is, data is often dirty. Hence, we need to be able to compare them on
    an apples-to-apples basis.
  prefs: []
  type: TYPE_NORMAL
- en: 'To show this, let''s write a side program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first thing to note is that there are at least three ways of writing the
    word `café`, which for the purposes of this demonstration means coffee shop. It's
    clear from the first two comparisons that the words are not the same. But since
    they mean the same thing, a comparison should return `true`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do that, we will need to transform all the text to one form, and then comapare
    it. To do so, we would need to define a transformer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This transformer is a chain of text transformers, applied one after another.
  prefs: []
  type: TYPE_NORMAL
- en: First, we convert all the text to its decomposing form, NFD. This would turn
    `café` into `cafe\u0301`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we remove any non-spacing mark. This turns `cafe\u0301` into `cafe`.
    This removal function is done with the `isMn` function, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, convert everything to NKFC form for maximum compatibility and space
    saving. All three strings are now equal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that this type of comparison is done with one single assumption that belies
    it all: there is one language that we''re doing our comparisons in—English. **Café**
    in French means **coffee** as well as **coffee shop**. This kind of normalization,
    where we remove diacritical marks, works so long as removing a diacritic mark
    does not change the meaning of the word. We''d have to be more careful around
    normalization when dealing with multiple languages. But for this project, this
    is a good enough assumption.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this new knowledge, we will need to update our `processor` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The first line of our `p.single` function would have to change too, from this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'It will change to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If you're feeling extra hard-working, try making `strings.ToLower` a `transform.Transformer`.
    It is harder than you might expect, but not as hard as it appears.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing stopwords
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enough about normalization. We now turn our focus to `stopwords`.
  prefs: []
  type: TYPE_NORMAL
- en: Recall from [Chapter 2](https://cdp.packtpub.com/go_machine_learning_projects/wp-admin/post.php?post=28&action=edit#post_46), *Linear
    Regression–House Price Prediction*, that `stopwords` are words such as **the**,
    **there**, **from**, and so on. They're connective words, useful in understanding
    the specific context of sentences, but for a naive statistical analysis, they
    often add nothing more than noise. So, we have to remove them.
  prefs: []
  type: TYPE_NORMAL
- en: 'A check for `stopwords` is simple. If a word matches a `stopwords`, we''ll
    return `false` for whether to add the word ID into the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Where does the list of `stopwords` come from? It''s simple enough that I just
    wrote this in `stopwords.go`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: And that's it! A tweet with content that looks like this—*an apple a day keeps
    the doctor away* would have the IDs for *apple*, *day*, *doctor*, and *away*.
  prefs: []
  type: TYPE_NORMAL
- en: The list of stopwords is adapted from the list that is used in the `lingo` package.
    The list of stopwords in the `lingo` package is meant to be used on lemmatized
    words. Because we're not lemmatizing, some words were manually added. It's not
    perfect but works well enough for our purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing Twitter entities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After we''ve removed the stopwords, it''s time to process the special Twitter
    entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: These are straightforwards enough.
  prefs: []
  type: TYPE_NORMAL
- en: If a word begins with `"#"`, then it's a hashtag. We might want to come back
    to this later, so it's good to keep this in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Any word that begins with a `"@"` is a mention. This is a little tricky. Sometimes,
    people tweet things such as `I am @PlaceName`, indicating a location, as opposed
    to mentioning a user (indeed, one may find `@PlaceName` does not exist). Or, alternatively,
    people may tweet something such as `I am @ PlaceName`. In this case, the solo `"@"` would
    still be treated as a mention. I found that for the former (`@PlaceName`), it
    doesn't really matter if the word is treated as a mention. Twitter's API does
    indeed return a list of mentions that you may check against. But for my personal
    timeline, this was extra work that isn't necessary. So, think of this as an extra
    credit project—check against the list of mentions from the API.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we shan't be as lazy as to leave everything to extra credit; simple
    checks can be made—if `@` is solo, then we shouldn't treat it as a mention. It
    should be treated as `at`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we check for URLs. The line `if strings.HasPrefix(word, "http://")`checks
    for a `http://` prefix. This isn't good. This doesn't account for URLs with a
    `https` scheme.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we know how to modify this section of the code. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, a final line of code is added to handle historical tweets before retweets
    were supported by Twitter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Processing a single tweet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Consider the following snippet of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: What it says is after we've preprocessed every single word, we simply add that
    word to the TFIDF.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of this project is to clean up the amount of tweets that I have
    to read. If there is a reading budget of 100 tweets, I don't want to be reading
    50 tweets on the same topic; they may well represent different viewpoints, but
    in general for skimming purposes, are not relevant to my interests. Clustering
    provides a good solution to this problem.
  prefs: []
  type: TYPE_NORMAL
- en: First, if the tweets are clustered, the 50 tweets on the same topic will be
    grouped in the same cluster. This allows me to dig in deeper if I wish. Otherwise,
    I can just skip those tweets and move on.
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we wish to use K-means. To do so, we'll use Marcin Praski's
    `clusters` library. To install it, simply run `go get -u github.com/mpraski/clusters`.
    It's a good library, and it comes built in with multiple clustering algorithms.
    I introduced K-means before, but we're also going to be using DBSCAN.
  prefs: []
  type: TYPE_NORMAL
- en: Last, we're going to be using the DMMClust algorithm to compare against. The
    DMMClust algorithm is in a different library. To install it, simply run `go get
    -u github.com/go-nlp/dmmclust`. The purpose of DMMClust is to cluster small texts
    using an innovative process.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering with K-means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As a recap, here''s what we did so far—we processed each tweet in a list of
    tweets from the home timeline to be a slice of `float64`. These represent the
    coordinates in the higher-dimensional space. Now, all we need to do is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a clusterer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `[][]float64` representing all the tweets from the timeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the clusterer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predict which tweet belongs in which cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Surprised? Let's break it down.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first few lines are for processing `tweets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We then create a clusterer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Here, we say we want a K-means clusterer. We'll train on the data 10,000 times,
    and we want it to find 25 clusters, using the `EuclideanDistance` method to calculate
    distances. The Euclidean distance is your bog standard distance calculation, the
    same one you'd use to calculate the distance between two points in the exercises
    in the K-means section before. There are other methods of calculating distances,
    which are more suited for textual data. Later in this chapter, I'll show you how
    to create a distance function, the Jacard distance, which is much better than
    Euclidean distance when used on text.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we''ve created a clusterer, we need to convert our list of `tweets` into
    a matrix. We then train the clusterer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'And, finally, we display the `clusters`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Clustering with DBSCAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Clustering with DBSCAN using Marcin''s package is equally simple. In fact,
    you would just need to change one single line of code from this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'You would change it to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Now, of course, the question is what values should `eps` and `minPts` be?
  prefs: []
  type: TYPE_NORMAL
- en: '`eps` represents the minimum distance required for two points to be considered
    a neighbor. `minPts` is the minimum number of points to form a dense cluster.
    Let''s address `eps` first.'
  prefs: []
  type: TYPE_NORMAL
- en: How do we know what the best distance is? A good way to figure this out is usually
    to visualize the data. In fact, this is what the original inventors of the DBSCAN
    algorithm suggests. But what exactly are we to visualize?
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to visualize the distance between the tweets. Given a dataset, we can
    compute a distance matrix that looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To do so, we write the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This function takes a matrix of floats; each row represents a tweet, and finds
    the top k-nearest neighbors. Let's walk through the algorithm. As we walk though
    the algorithm, bear in mind that each row is a tweet; you can think of each row
    therefore as a very complicated coordinate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we want to do is to find the distance between a tweet and another
    tweet, hence the following block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Of particular note are the two expressions `for _, row := range a` and `for
    _, row2 := range a`. In a normal KNN function, you'd have two matrices, `a` and
    `b`, and you'd find the distance between a tweet in `a` and a tweet in `b`. But
    for the purposes of drawing this chart, we are going to compare tweets within
    the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we acquired all the distances, we want to find the closest neighbors,
    so we sort the list and then put them in the distance matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: This, in a very quick way, is how to do K-nearest neighbors. Of course, it's
    not the most efficient. The algorithm I've shown here is *O(n^2)*. There are better
    ways of doing things, but for the purpose of this project, this suffices.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, we grab the last column of the matrix and sort the last column.
    This is what we wish to plot. The plotting code is not unlike that seen in previous
    chapters. I shall provide it here with no further elaboration on how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'When I plot the real Twitter data to figure out the ideal `eps`, I get the
    following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee722fa9-fd28-45b5-9f84-2f49e9dc4954.png)'
  prefs: []
  type: TYPE_IMG
- en: What you want to find is an `elbow` or `knee` in the picture. Unfortunately,
    as you can tell, there are many of them. This is going to make clustering with
    the DBSCAN algorithm difficult. What this means is that the data is rather noisy.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things that is of particular importance is the distance function
    used. I will go into this a little further in following sections on tweaking the
    program.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering with DMMClust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having been somewhat discouraged by the distance plot of my Twitter home feed,
    I looked into another way of clustering tweets. To that end, I used the `dmmclust`
    library (of which I am the primary author). The purpose of the DMMClust algorithm
    is that it is able to handle small texts quite well. Indeed, it was written to
    handle the problem of having small text.
  prefs: []
  type: TYPE_NORMAL
- en: What exactly is a small text? Most text clustering research out there is done
    on texts with large amounts of words. Twitter, up to very recently, only supported
    140 characters. As you may imagine, the amount of information that 140 characters
    to be transmitted as human language is not very much.
  prefs: []
  type: TYPE_NORMAL
- en: The DMMClust algorithm works very much like students joining high school social
    clubs. Imagine the tweets as a bunch of students. Each student randomly joins
    a social club. Within each social club, they may like their fellow members of
    the club, or they may not. If they do not like the people in the group, they are
    allowed to change social clubs. This happens until all the clubs have people who
    like each other the most, or until the amount of iterations runs out.
  prefs: []
  type: TYPE_NORMAL
- en: This, in a nutshell, is how the DMMClust algorithm works.
  prefs: []
  type: TYPE_NORMAL
- en: Real data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to this point, we've been working on an example `JSON` that the Twitter documentation
    provides. I assume by now you have your Twitter API access. So, let's get real
    Twitter data!
  prefs: []
  type: TYPE_NORMAL
- en: 'To get your API keys from the developer portal, click on the Get Started link.
    You will come to a page such as this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba823fed-8ca0-4c68-94b9-4dceb42f62da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select Create an app. You will be brought to a page that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bfe0179-c124-46df-b8f7-421c22ec9fea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'I had previously created a Twitter app a long time ago (it had very similar
    features to the one we''re creating in this project); hence, I have an app there
    already. Click on the blue Create an app button at the top right. You will be
    brought to the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/241b3ba0-075d-4278-91d6-9cc220c5d281.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fill in the form then click submit. It might take a few days before you receive
    an email saying the app has been approved for development. Be sure to be truthful
    in the description. Lastly, you should then be able to click into your app, and
    get the following page, which shows your API key and secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/02da6d9d-162e-4652-a314-42b97726412e.png)'
  prefs: []
  type: TYPE_IMG
- en: Click Create to create your access token and access token secret. You'll be
    needing them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our API access key, this is how you''d access Twitter using
    the Anaconda package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'At first glance, this snippet of code is a little weird. Let''s go through
    the code line by line. The first six lines deal with the access tokens and keys.
    Obviously, they should not be hardcoded in. A good way to handle secrets like
    these is to put them in environment variables. I''ll leave that as an exercise
    to the reader. We''ll move on to the rest of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'These two lines uses the Anaconda library to get the tweets found in the Home
    timeline. The `nil` being passed in may be of interest. Why would one do this?
    The `GetHomeTimeline` method takes a map of `url.Values`. The package can be found
    in the standard library as `net/url`. Values is defined thus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'But what do the values represent? It turns out that you may pass some parameters
    to the Twitter API. The parameters and what they do are enumerated here: [https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-home_timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-home_timeline).
    I don''t wish to limit anything, so passing in `nil` is acceptable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is `[]anaconda.Tweet`, all neatly packaged up for us to use. The
    following few lines are therefore quite odd:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Why would I want to save this as a `JSON` file? The answer is simple—when using
    machine learning algorithms, you may need to tune the algorithm. Saving the request
    as a `JSON` file serves two purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: It allows for consistency. Under active development, you would expect to tweak
    the algorithm a lot. If the JSON file keeps changing, how do you know if it's
    the tweaks that are making the improvements, and not because the JSON has changed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being a good citizen. Twitter's API is rate limited. This means you cannot request
    the same thing over and over again too many times. While testing and tuning machine
    learning algorithms, you are likely to have to repeatedly process your data over
    and over again. Instead of hammering the Twitter servers, you should be a good
    citizen and use a locally cached copy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We defined `load` earlier. Again, we shall see its usefulness in the context
    of tweaking the algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we''ve done that, we may move the previous `main()` into a different function,
    leaving ourselves with a blank canvas for `main()` again. We''re now ready for
    the meat of the program. This is a skeleton program. You''re encouraged to actually
    actively change the program while writing this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'There are some utility functions that I have yet to show you. Now it''s time
    to define them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: These are some of the utility functions that may be found in `utils.go`. They
    mainly help with tweaking the program. Now run the program by typing `go run *.go`.
  prefs: []
  type: TYPE_NORMAL
- en: Tweaking the program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have been following up to this point, you may get very poor results from
    all the clustering algorithms. I'd like to remind you that the stated objective
    of this book in general is to impart an understanding of what it's like to do
    data science in Go. For the most part, I have advocated a method that can be described
    as think hard about the problem, then write the answers down. But the reality
    is that often trial and error are required.
  prefs: []
  type: TYPE_NORMAL
- en: The solution that works for me on my Twitter home timeline may not work for
    you. For example, this code works well on a friend's Twitter feed. Why is this?
    He follows a lot of similar people who talk about similar things at the same time.
    It's a little harder to cluster tweets in my Twitter home feed. I follow a diverse
    array of people. The people I follow don't have set schedules of tweeting and
    do not generally interact with other Twitter users. Therefore, the tweets are
    generally quite diverse already.
  prefs: []
  type: TYPE_NORMAL
- en: It is with this in mind that I encourage you to experiment and tweak your program.
    In the subsections that follow, I shall outline what worked for me. It may not
    work for you.
  prefs: []
  type: TYPE_NORMAL
- en: Tweaking distances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up to this point, we had been using Euclidean distance as provided by the `Marcin`
    library. The Euclidean distance is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `EuclideanDistance` is a good metric to use when it comes to coordinates
    in a Cartesian space. Indeed, earlier I had drawn up an analogy of thinking of
    a tweet as a bunch of coordinates in space, to explain K-means and DBSCAN. The
    reality is that text documents aren't really in Cartesian space. You may think
    of them as being in Cartesian space, but they are not strictly so.
  prefs: []
  type: TYPE_NORMAL
- en: So, allow me to introduce another type of distance, one that is more suited
    to dealing with textual elements in a bag-of-words-style setting that we're currently
    doing, the Jaccard distance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jaccard distance is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `$A$` and `$B$` are sets of words in each tweet. The implementation of
    the Jaccard distance in Go is rudimentary, but it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Tweaking the preprocessing step
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One thing you may note is that the preprocessing of tweets is very minimal,
    and some of the rules are odd. For example, all hashtags are treated as one, as
    are all links and mentions. When this project started, it seemed like a good reason.
    There is no other justification than it seemed like a good reason; one always
    needs a springboard from which to jump off in any project. A flimsy excuse at
    that point is as good as any other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Nonetheless, I have tweaked my preprocessing steps. These are the functions
    that I finally settled on. Do observe the difference between this and the original, listed
    in previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The most notable thing that I have changed is that I now consider a hashtag
    a word. Mentions are removed. As for URLs, in one of the attempts at clustering,
    I realized that the clustering algorithms were clustering all the tweets with
    a URL into the same cluster. That realization made me remove hashtags, mentions,
    and URLs. Hashtags have the `#` removed and are treated as if they were normal
    words.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, you may note that I added some quick and dirty ways to `clean`
    certain things:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Here, I used regular expressions to replace multiple newlines with just one,
    and to replace all HTML-encoded text with nothing. Lastly, I removed all punctuation.
  prefs: []
  type: TYPE_NORMAL
- en: In a more formal setting, I would use a proper lexer to handle my text. The
    lexer I'd use would come from Lingo (`github.com/chewxy/lingo`). But given that
    Twitter is a low value environment, there wasn't much point in doing so. A proper
    lexer like the one in lingo flags text as multiple things, allowing for easy removal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another thing you might notice is that I changed the definition of what a tweet
    is mid-flight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This block of code says if a tweet is indeed a retweeted status, replace the
    tweet with the retweeted tweet. This works for me. But it may not work for you.
    I personally consider any retweet to be the same as repeating a tweet. So, I do
    not see why they should be separate. Additionally, Twitter allows for users to
    comment on a retweet. If you want to include that, you'd have to change the logic
    a little bit more. Either way, the way I got to this was by manually inspecting
    the `JSON` file I had saved.
  prefs: []
  type: TYPE_NORMAL
- en: It's asking these questions and then making a judgment call what is important
    in doing data science, either in Go or any other language. It's not about blindly
    applying algorithms. Rather, it's always driven by what the data tells you.
  prefs: []
  type: TYPE_NORMAL
- en: 'One last thing that you may note is this curious block of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Here, I only consider English tweets. I follow many people who tweet in a variety
    of languages. At any given time, my home timeline would have about 15% of tweets
    in French, Chinese, Japanese, or German. Clustering tweets in a different language
    is a whole different ballgame, so I chose to omit them.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to cluster tweets using a variety of clustering
    methods. Though frequently touted as one of the most robust algorithms, we've
    shown that DBSCAN has problems with clustering tweets due to the nature of tweets
    being noisy. Instead, we see that older, more traditional methods, as well as
    a new method of clustering, would yield better results.
  prefs: []
  type: TYPE_NORMAL
- en: This points to a lesson—there is no one machine-learning algorithm to rule them
    all; there is no ultimate algorithm. Instead, we need to try more than one thing.
    In the chapters that follow, this theme will be more apparent, and we shall approach
    these with more rigor. In the next chapter, we will learn about basics of neural
    networks and apply them on handwriting to recognize digits.
  prefs: []
  type: TYPE_NORMAL
