["```py\n$ bin/spark-shell \nWelcome to\n ____              __\n / __/__  ___ _____/ /__\n _\\ \\/ _ \\/ _ `/ __/  ''_/\n /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.1\n /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_40)\nType in expressions to have them evaluated.\nType :help for more information.\nSpark context available as sc.\nSQL context available as sqlContext.\n\nscala> val leotolstoy = sc.textFile(\"leotolstoy\").cache\nleotolstoy: org.apache.spark.rdd.RDD[String] = leotolstoy MapPartitionsRDD[1] at textFile at <console>:27\n\nscala> leotolstoy.flatMap(_.split(\"\\\\W+\")).count\nres1: Long = 1318234 \n\nscala> val shakespeare = sc.textFile(\"shakespeare\").cache\nshakespeare: org.apache.spark.rdd.RDD[String] = shakespeare MapPartitionsRDD[7] at textFile at <console>:27\n\nscala> shakespeare.flatMap(_.split(\"\\\\W+\")).count\nres2: Long = 1051958\n\n```", "```py\nscala> :silent\n\nscala> val shakespeareBag = shakespeare.flatMap(_.split(\"\\\\W+\")).map(_.toLowerCase).distinct\n\nscala> val leotolstoyBag = leotolstoy.flatMap(_.split(\"\\\\W+\")).map(_.toLowerCase).distinct\nleotolstoyBag: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[27] at map at <console>:29\n\nscala> println(\"The bags intersection is \" + leotolstoyBag.intersection(shakespeareBag).count)\nThe bags intersection is 11552\n\n```", "```py\n$ (mkdir bible; cd bible; wget http://www.gutenberg.org/cache/epub/10/pg10.txt)\n\nscala> val bible = sc.textFile(\"bible\").cache\n\nscala> val bibleBag = bible.flatMap(_.split(\"\\\\W+\")).map(_.toLowerCase).distinct\n\nscala>:silent\n\nscala> bibleBag.intersection(shakespeareBag).count\nres5: Long = 7250\n\nscala> bibleBag.intersection(leotolstoyBag).count\nres24: Long = 6611\n\n```", "```py\n$ (mkdir chekhov; cd chekhov;\n wget http://www.gutenberg.org/cache/epub/7986/pg7986.txt\n wget http://www.gutenberg.org/cache/epub/1756/pg1756.txt\n wget http://www.gutenberg.org/cache/epub/1754/1754.txt\n wget http://www.gutenberg.org/cache/epub/13415/pg13415.txt)\n\nscala> val chekhov = sc.textFile(\"chekhov\").cache\nchekhov: org.apache.spark.rdd.RDD[String] = chekhov MapPartitionsRDD[61] at textFile at <console>:27\n\nscala> val chekhovBag = chekhov.flatMap(_.split(\"\\\\W+\")).map(_.toLowerCase).distinct\nchekhovBag: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[66] at distinct at <console>:29\n\nscala> chekhovBag.intersection(leotolstoyBag).count\nres8: Long = 8263\n\nscala> chekhovBag.intersection(shakespeareBag).count\nres9: Long = 6457 \n\n```", "```py\ndef main(args: Array[String]) {\n\n    val stemmer = new Stemmer\n\n    val conf = new SparkConf().\n      setAppName(\"Stemmer\").\n      setMaster(args(0))\n\n    val sc = new SparkContext(conf)\n\n    val stopwords = scala.collection.immutable.TreeSet(\n      \"\", \"i\", \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"from\", \"had\", \"has\", \"he\", \"her\", \"him\", \"his\", \"in\", \"is\", \"it\", \"its\", \"my\", \"not\", \"of\", \"on\", \"she\", \"that\", \"the\", \"to\", \"was\", \"were\", \"will\", \"with\", \"you\"\n    ) map { stemmer.stem(_) }\n\n    val bags = for (name <- args.slice(1, args.length)) yield {\n      val rdd = sc.textFile(name).map(_.toLowerCase)\n      if (name == \"nytimes\" || name == \"nips\" || name == \"enron\")\n        rdd.filter(!_.startsWith(\"zzz_\")).flatMap(_.split(\"_\")).map(stemmer.stem(_)).distinct.filter(!stopwords.contains(_)).cache\n      else {\n        val withCounts = rdd.flatMap(_.split(\"\\\\W+\")).map(stemmer.stem(_)).filter(!stopwords.contains(_)).map((_, 1)).reduceByKey(_+_)\n        val minCount = scala.math.max(1L, 0.0001 * withCounts.count.toLong)\n        withCounts.filter(_._2 > minCount).map(_._1).cache\n      }\n    }\n\n    val cntRoots = (0 until { args.length - 1 }).map(i => Math.sqrt(bags(i).count.toDouble))\n\n    for(l <- 0 until { args.length - 1 }; r <- l until { args.length - 1 }) {\n      val cnt = bags(l).intersection(bags(r)).count\n      println(\"The intersect \" + args(l+1) + \" x \" + args(r+1) + \" is: \" + cnt + \" (\" + (cnt.toDouble / cntRoots(l) / cntRoots(r)) + \")\")\n    }\n\n    sc.stop\n    }\n}\n```", "```py\n$ sbt \"run-main org.akozlov.examples.Stemmer local[2] shakespeare leotolstoy chekhov nytimes nips enron bible\"\n[info] Loading project definition from /Users/akozlov/Src/Book/ml-in-scala/chapter09/project\n[info] Set current project to NLP in Scala (in build file:/Users/akozlov/Src/Book/ml-in-scala/chapter09/)\n[info] Running org.akozlov.examples.Stemmer local[2] shakespeare leotolstoy chekhov nytimes nips enron bible\nThe intersect shakespeare x shakespeare is: 10533 (1.0)\nThe intersect shakespeare x leotolstoy is: 5834 (0.5293670391596142)\nThe intersect shakespeare x chekhov is: 3295 (0.4715281914492153)\nThe intersect shakespeare x nytimes is: 7207 (0.4163369701270161)\nThe intersect shakespeare x nips is: 2726 (0.27457329089479504)\nThe intersect shakespeare x enron is: 5217 (0.34431535832271265)\nThe intersect shakespeare x bible is: 3826 (0.45171392986714726)\nThe intersect leotolstoy x leotolstoy is: 11531 (0.9999999999999999)\nThe intersect leotolstoy x chekhov is: 4099 (0.5606253333241973)\nThe intersect leotolstoy x nytimes is: 8657 (0.47796976891152176)\nThe intersect leotolstoy x nips is: 3231 (0.3110369262979765)\nThe intersect leotolstoy x enron is: 6076 (0.38326210407266764)\nThe intersect leotolstoy x bible is: 3455 (0.3898604013063757)\nThe intersect chekhov x chekhov is: 4636 (1.0)\nThe intersect chekhov x nytimes is: 3843 (0.33463022711780555)\nThe intersect chekhov x nips is: 1889 (0.28679311682962116)\nThe intersect chekhov x enron is: 3213 (0.31963226496874225)\nThe intersect chekhov x bible is: 2282 (0.40610513998395287)\nThe intersect nytimes x nytimes is: 28449 (1.0)\nThe intersect nytimes x nips is: 4954 (0.30362042173997206)\nThe intersect nytimes x enron is: 11273 (0.45270741164576034)\nThe intersect nytimes x bible is: 3655 (0.2625720159205085)\nThe intersect nips x nips is: 9358 (1.0000000000000002)\nThe intersect nips x enron is: 4888 (0.3422561629856124)\nThe intersect nips x bible is: 1615 (0.20229053645165143)\nThe intersect enron x enron is: 21796 (1.0)\nThe intersect enron x bible is: 2895 (0.23760453654690084)\nThe intersect bible x bible is: 6811 (1.0)\n[success] Total time: 12 s, completed May 17, 2016 11:00:38 PM\n\n```", "```py\nscala> val bags = for (name <- List(\"shakespeare\", \"leotolstoy\", \"chekhov\", \"nytimes\", \"enron\", \"bible\")) yield {\n |     sc textFile(name) flatMap { _.split(\"\\\\W+\") } map { _.toLowerCase } map { stemmer.stem(_) } filter { ! stopwords.contains(_) } cache()\n | }\nbags: List[org.apache.spark.rdd.RDD[String]] = List(MapPartitionsRDD[93] at filter at <console>:36, MapPartitionsRDD[98] at filter at <console>:36, MapPartitionsRDD[103] at filter at <console>:36, MapPartitionsRDD[108] at filter at <console>:36, MapPartitionsRDD[113] at filter at <console>:36, MapPartitionsRDD[118] at filter at <console>:36)\n\nscala> bags reduceLeft { (a, b) => a.union(b) } map { (_, 1) } reduceByKey { _+_ } collect() sortBy(- _._2) map { x => scala.math.log(x._2) }\nres18: Array[Double] = Array(10.27759958298627, 10.1152465449837, 10.058652004037477, 10.046635061754612, 9.999615579630348, 9.855399641729074, 9.834405391348684, 9.801233318497372, 9.792667717430884, 9.76347807952779, 9.742496866444002, 9.655474810542554, 9.630365631415676, 9.623244409181346, 9.593355351246755, 9.517604459155686, 9.515837804297965, 9.47231994707559, 9.45930760329985, 9.441531454869693, 9.435561763085358, 9.426257878198653, 9.378985497953893, 9.355997944398545, 9.34862295977619, 9.300820725104558, 9.25569607369698, 9.25320827220336, 9.229162126216771, 9.20391980417326, 9.19917830726999, 9.167224080902555, 9.153875834995056, 9.137877200242468, 9.129889247578555, 9.090430075303626, 9.090091799380007, 9.083075020930307, 9.077722847361343, 9.070273383079064, 9.0542711863262...\n...\n\n```", "```py\nscala> import org.apache.spark.mllib.feature.HashingTF\nimport org.apache.spark.mllib.feature.HashingTF\n\nscala> import org.apache.spark.mllib.linalg.Vector\nimport org.apache.spark.mllib.linalg.Vector\n\nscala> val hashingTF = new HashingTF\nhashingTF: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@61b975f7\n\nscala> val documents: RDD[Seq[String]] = sc.textFile(\"shakepeare\").map(_.split(\"\\\\W+\").toSeq)\ndocuments: org.apache.spark.rdd.RDD[Seq[String]] = MapPartitionsRDD[263] at map at <console>:34\n\nscala> val tf = hashingTF transform documents\ntf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[264] at map at HashingTF.scala:76\n\n```", "```py\nscala> tf.cache\nres26: tf.type = MapPartitionsRDD[268] at map at HashingTF.scala:76\n\nscala> import org.apache.spark.mllib.feature.IDF\nimport org.apache.spark.mllib.feature.IDF\n\nscala> val idf = new IDF(minDocFreq = 2) fit tf\nidf: org.apache.spark.mllib.feature.IDFModel = org.apache.spark.mllib.feature.IDFModel@514bda2d\n\nscala> val tfidf = idf transform tf\ntfidf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[272] at mapPartitions at IDF.scala:178\n\nscala> tfidf take(10) foreach println\n(1048576,[3159,3543,84049,582393,787662,838279,928610,961626,1021219,1021273],[3.9626355004005083,4.556357737874695,8.380602528651274,8.157736974683708,11.513471982269106,9.316247404932888,10.666174121881904,11.513471982269106,8.07948477778396,11.002646358503116])\n(1048576,[267794,1021219],[8.783442874448122,8.07948477778396])\n(1048576,[0],[0.5688129477150906])\n(1048576,[3123,3370,3521,3543,96727,101577,114801,116103,497275,504006,508606,843002,962509,980206],[4.207164322003765,2.9674322162952897,4.125144122691999,2.2781788689373474,2.132236195047438,3.2951341639027754,1.9204575904855747,6.318664992090735,11.002646358503116,3.1043838099579815,5.451238364272918,11.002646358503116,8.43769700104158,10.30949917794317])\n(1048576,[0,3371,3521,3555,27409,89087,104545,107877,552624,735790,910062,943655,962421],[0.5688129477150906,3.442878442319589,4.125144122691999,4.462482535201062,5.023254392629403,5.160262034409286,5.646060083831103,4.712188947797486,11.002646358503116,7.006282204641219,6.216822672821767,11.513471982269106,8.898512204232908])\n(1048576,[3371,3543,82108,114801,149895,279256,582393,597025,838279,915181],[3.442878442319589,2.2781788689373474,6.017670811187438,3.8409151809711495,7.893585399642122,6.625632265652778,8.157736974683708,10.414859693600997,9.316247404932888,11.513471982269106])\n(1048576,[3123,3555,413342,504006,690950,702035,980206],[4.207164322003765,4.462482535201062,3.4399651117812313,3.1043838099579815,11.513471982269106,11.002646358503116,10.30949917794317])\n(1048576,[0],[0.5688129477150906])\n(1048576,[97,1344,3370,100898,105489,508606,582393,736902,838279,1026302],[2.533299776544098,23.026943964538212,2.9674322162952897,0.0,11.225789909817326,5.451238364272918,8.157736974683708,10.30949917794317,9.316247404932888,11.513471982269106])\n(1048576,[0,1344,3365,114801,327690,357319,413342,692611,867249,965170],[4.550503581720725,23.026943964538212,2.7455719545259836,1.9204575904855747,8.268278849083533,9.521041817578901,3.4399651117812313,0.0,6.661441718349489,0.0])\n\n```", "```py\n$ mkdir enron\n$ cat /dev/null > enron/all.txt\n$ for f in $(find maildir -name \\*\\. -print); do cat $f | sed '1,/^$/d;/^$/d' | tr \"\\n\\r\" \"  \" >> enron/all.txt; echo \"\" >> enron/all.txt; done\n$\n\n```", "```py\n$ spark-shell --driver-memory 8g --executor-memory 8g --packages com.github.fommil.netlib:all:1.1.2\nIvy Default Cache set to: /home/alex/.ivy2/cache\nThe jars for the packages stored in: /home/alex/.ivy2/jars\n:: loading settings :: url = jar:file:/opt/cloudera/parcels/CDH-5.5.2-1.cdh5.5.2.p0.4/jars/spark-assembly-1.5.0-cdh5.5.2-hadoop2.6.0-cdh5.5.2.jar!/org/apache/ivy/core/settings/ivysettings.xml\ncom.github.fommil.netlib#all added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0\n confs: [default]\n found com.github.fommil.netlib#all;1.1.2 in central\n found net.sourceforge.f2j#arpack_combined_all;0.1 in central\n found com.github.fommil.netlib#core;1.1.2 in central\n found com.github.fommil.netlib#netlib-native_ref-osx-x86_64;1.1 in central\n found com.github.fommil.netlib#native_ref-java;1.1 in central\n found com.github.fommil#jniloader;1.1 in central\n found com.github.fommil.netlib#netlib-native_ref-linux-x86_64;1.1 in central\n found com.github.fommil.netlib#netlib-native_ref-linux-i686;1.1 in central\n found com.github.fommil.netlib#netlib-native_ref-win-x86_64;1.1 in central\n found com.github.fommil.netlib#netlib-native_ref-win-i686;1.1 in central\n found com.github.fommil.netlib#netlib-native_ref-linux-armhf;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-osx-x86_64;1.1 in central\n found com.github.fommil.netlib#native_system-java;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-linux-x86_64;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-linux-i686;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-linux-armhf;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-win-x86_64;1.1 in central\n found com.github.fommil.netlib#netlib-native_system-win-i686;1.1 in central\ndownloading https://repo1.maven.org/maven2/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1-javadoc.jar ...\n [SUCCESSFUL ] net.sourceforge.f2j#arpack_combined_all;0.1!arpack_combined_all.jar (513ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#core;1.1.2!core.jar (18ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-osx-x86_64/1.1/netlib-native_ref-osx-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-osx-x86_64;1.1!netlib-native_ref-osx-x86_64.jar (167ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-linux-x86_64/1.1/netlib-native_ref-linux-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-linux-x86_64;1.1!netlib-native_ref-linux-x86_64.jar (159ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-linux-i686/1.1/netlib-native_ref-linux-i686-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-linux-i686;1.1!netlib-native_ref-linux-i686.jar (131ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-win-x86_64/1.1/netlib-native_ref-win-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-win-x86_64;1.1!netlib-native_ref-win-x86_64.jar (210ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-win-i686/1.1/netlib-native_ref-win-i686-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-win-i686;1.1!netlib-native_ref-win-i686.jar (167ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_ref-linux-armhf/1.1/netlib-native_ref-linux-armhf-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_ref-linux-armhf;1.1!netlib-native_ref-linux-armhf.jar (110ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-osx-x86_64/1.1/netlib-native_system-osx-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-osx-x86_64;1.1!netlib-native_system-osx-x86_64.jar (54ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-linux-x86_64/1.1/netlib-native_system-linux-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-linux-x86_64;1.1!netlib-native_system-linux-x86_64.jar (47ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-linux-i686/1.1/netlib-native_system-linux-i686-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-linux-i686;1.1!netlib-native_system-linux-i686.jar (44ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-linux-armhf/1.1/netlib-native_system-linux-armhf-1.1-natives.jar ...\n[SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-linux-armhf;1.1!netlib-native_system-linux-armhf.jar (35ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-win-x86_64/1.1/netlib-native_system-win-x86_64-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-win-x86_64;1.1!netlib-native_system-win-x86_64.jar (62ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/netlib-native_system-win-i686/1.1/netlib-native_system-win-i686-1.1-natives.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#netlib-native_system-win-i686;1.1!netlib-native_system-win-i686.jar (55ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/native_ref-java/1.1/native_ref-java-1.1.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#native_ref-java;1.1!native_ref-java.jar (24ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/jniloader/1.1/jniloader-1.1.jar ...\n [SUCCESSFUL ] com.github.fommil#jniloader;1.1!jniloader.jar (3ms)\ndownloading https://repo1.maven.org/maven2/com/github/fommil/netlib/native_system-java/1.1/native_system-java-1.1.jar ...\n [SUCCESSFUL ] com.github.fommil.netlib#native_system-java;1.1!native_system-java.jar (7ms)\n:: resolution report :: resolve 3366ms :: artifacts dl 1821ms\n :: modules in use:\n com.github.fommil#jniloader;1.1 from central in [default]\n com.github.fommil.netlib#all;1.1.2 from central in [default]\n com.github.fommil.netlib#core;1.1.2 from central in [default]\n com.github.fommil.netlib#native_ref-java;1.1 from central in [default]\n com.github.fommil.netlib#native_system-java;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-linux-armhf;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-linux-i686;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-linux-x86_64;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-osx-x86_64;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-win-i686;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_ref-win-x86_64;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-linux-armhf;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-linux-i686;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-linux-x86_64;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-osx-x86_64;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-win-i686;1.1 from central in [default]\n com.github.fommil.netlib#netlib-native_system-win-x86_64;1.1 from central in [default]\n net.sourceforge.f2j#arpack_combined_all;0.1 from central in [default]\n :: evicted modules:\n com.github.fommil.netlib#core;1.1 by [com.github.fommil.netlib#core;1.1.2] in [default]\n --------------------------------------------------------------------\n |                  |            modules            ||   artifacts   |\n |       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n ---------------------------------------------------------------------\n |      default     |   19  |   18  |   18  |   1   ||   17  |   17  |\n ---------------------------------------------------------------------\n...\nscala> val enron = sc textFile(\"enron\")\nenron: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[1] at textFile at <console>:21\n\nscala> enron.flatMap(_.split(\"\\\\W+\")).map(_.toLowerCase).distinct.count\nres0: Long = 529199 \n\nscala> val stopwords = scala.collection.immutable.TreeSet (\"\", \"i\", \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"from\", \"had\", \"has\", \"he\", \"her\", \"him\", \"his\", \"in\", \"is\", \"it\", \"its\", \"not\", \"of\", \"on\", \"she\", \"that\", \"the\", \"to\", \"was\", \"were\", \"will\", \"with\", \"you\")\nstopwords: scala.collection.immutable.TreeSet[String] = TreeSet(, a, an, and, are, as, at, be, but, by, for, from, had, has, he, her, him, his, i, in, is, it, its, not, of, on, she, that, the, to, was, were, will, with, you)\nscala> \n\nscala> val terms = enron.flatMap(x => if (x.length < 8192) x.toLowerCase.split(\"\\\\W+\") else Nil).filterNot(stopwords).map(_,1).reduceByKey(_+_).collect.sortBy(- _._2).slice(0, 1000).map(_._1)\nterms: Array[String] = Array(enron, ect, com, this, hou, we, s, have, subject, or, 2001, if, your, pm, am, please, cc, 2000, e, any, me, 00, message, 1, corp, would, can, 10, our, all, sent, 2, mail, 11, re, thanks, original, know, 12, 713, http, may, t, do, 3, time, 01, ees, m, new, my, they, no, up, information, energy, us, gas, so, get, 5, about, there, need, what, call, out, 4, let, power, should, na, which, one, 02, also, been, www, other, 30, email, more, john, like, these, 03, mark, 04, attached, d, enron_development, their, see, 05, j, forwarded, market, some, agreement, 09, day, questions, meeting, 08, when, houston, doc, contact, company, 6, just, jeff, only, who, 8, fax, how, deal, could, 20, business, use, them, date, price, 06, week, here, net, 15, 9, 07, group, california,...\nscala> def getBagCounts(bag: Seq[String]) = { for(term <- terms) yield { bag.count(_==term) } }\ngetBagCounts: (bag: Seq[String])Array[Int]\n\nscala> import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.linalg.Vectors\n\nscala> val corpus = enron.map(x => { if (x.length < 8192) Some(x.toLowerCase.split(\"\\\\W+\").toSeq) else None } ).map(x => { Vectors.dense(getBagCounts(x.getOrElse(Nil)).map(_.toDouble).toArray) }).zipWithIndex.map(_.swap).cache\ncorpus: org.apache.spark.rdd.RDD[(Long, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[14] at map at <console>:30\n\nscala> import org.apache.spark.mllib.clustering.{LDA, DistributedLDAModel}\nimport org.apache.spark.mllib.clustering.{LDA, DistributedLDAModel}\n\nscala> import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.linalg.Vectors\n\nscala> val ldaModel = new LDA().setK(10).run(corpus)\n...\nscala> ldaModel.topicsMatrix.transpose\nres2: org.apache.spark.mllib.linalg.Matrix = \n207683.78495933366  79745.88417942637   92118.63972404732   ... (1000 total)\n35853.48027575886   4725.178508682296   111214.8860582083   ...\n135755.75666585402  54736.471356209106  93289.65563593085   ...\n39445.796099155996  6272.534431534215   34764.02707696523   ...\n329786.21570967307  602782.9591026317   42212.22143362559   ...\n62235.09960154089   12191.826543794878  59343.24100019015   ...\n210049.59592560542  160538.9650732507   40034.69756641789   ...\n53818.14660186875   6351.853448001488   125354.26708575874  ...\n44133.150537842856  4342.697652158682   154382.95646078113  ...\n90072.97362336674   21132.629704311104  93683.40795807641   ...\n\n```", "```py\nscala> ldaModel.describeTopics foreach { x : (Array[Int], Array[Double]) => { print(x._1.slice(0,10).map(terms(_)).mkString(\":\")); print(\"-> \"); print(x._2.slice(0,10).map(_.toFloat).mkString(\":\")); println } }\ncom:this:ect:or:if:s:hou:2001:00:we->0.054606363:0.024220783:0.02096761:0.013669214:0.0132700335:0.012969772:0.012623918:0.011363528:0.010114557:0.009587474\ns:this:hou:your:2001:or:please:am:com:new->0.029883621:0.027119286:0.013396418:0.012856948:0.01218803:0.01124849:0.010425644:0.009812181:0.008742722:0.0070441025\ncom:this:s:ect:hou:or:2001:if:your:am->0.035424445:0.024343235:0.015182628:0.014283071:0.013619815:0.012251413:0.012221165:0.011411696:0.010284024:0.009559739\nwould:pm:cc:3:thanks:e:my:all:there:11->0.047611523:0.034175437:0.022914853:0.019933242:0.017208714:0.015393614:0.015366959:0.01393391:0.012577525:0.011743208\nect:com:we:can:they:03:if:also:00:this->0.13815293:0.0755843:0.065043546:0.015290086:0.0121941045:0.011561104:0.011326733:0.010967959:0.010653805:0.009674695\ncom:this:s:hou:or:2001:pm:your:if:cc->0.016605735:0.015834121:0.01289918:0.012708308:0.0125788655:0.011726159:0.011477625:0.010578845:0.010555539:0.009609056\ncom:ect:we:if:they:hou:s:00:2001:or->0.05537054:0.04231919:0.023271963:0.012856676:0.012689817:0.012186356:0.011350313:0.010887237:0.010778923:0.010662295\nthis:s:hou:com:your:2001:or:please:am:if->0.030830953:0.016557815:0.014236835:0.013236604:0.013107091:0.0126846135:0.012257128:0.010862533:0.01027849:0.008893094\nthis:s:or:pm:com:your:please:new:hou:2001->0.03981197:0.013273305:0.012872894:0.011672661:0.011380969:0.010689667:0.009650983:0.009605533:0.009535899:0.009165275\nthis:com:hou:s:or:2001:if:your:am:please->0.024562683:0.02361607:0.013770585:0.013601272:0.01269994:0.012360005:0.011348433:0.010228578:0.009619628:0.009347991\n\n```", "```py\nscala> ldaModel.save(sc, \"ldamodel\")\n\nscala> val sameModel = DistributedLDAModel.load(sc, \"ldamode2l\")\n\nscala> sameModel.topDocumentsPerTopic(10) foreach { x : (Array[Long], Array[Double]) => { print(x._1.mkString(\":\")); print(\"-> \"); print(x._2.map(_.toFloat).mkString(\":\")); println } }\n59784:50745:52479:60441:58399:49202:64836:52490:67936:67938-> 0.97146696:0.9713364:0.9661418:0.9661132:0.95249915:0.9519995:0.94945914:0.94944507:0.8977366:0.8791358\n233009:233844:233007:235307:233842:235306:235302:235293:233020:233857-> 0.9962034:0.9962034:0.9962034:0.9962034:0.9962034:0.99620336:0.9954057:0.9954057:0.9954057:0.9954057\n14909:115602:14776:39025:115522:288507:4499:38955:15754:200876-> 0.83963907:0.83415157:0.8319566:0.8303818:0.8291597:0.8281472:0.82739806:0.8272517:0.82579833:0.8243338\n237004:71818:124587:278308:278764:278950:233672:234490:126637:123664-> 0.99929106:0.9968135:0.9964454:0.99644524:0.996445:0.99644494:0.99644476:0.9964447:0.99644464:0.99644417\n156466:82237:82252:82242:341376:82501:341367:340197:82212:82243-> 0.99716955:0.94635135:0.9431836:0.94241136:0.9421047:0.9410431:0.94075173:0.9406304:0.9402021:0.94014835\n335708:336413:334075:419613:417327:418484:334157:335795:337573:334160-> 0.987011:0.98687994:0.9865438:0.96953565:0.96953565:0.96953565:0.9588571:0.95852506:0.95832515:0.9581657\n243971:244119:228538:226696:224833:207609:144009:209548:143066:195299-> 0.7546907:0.7546907:0.59146744:0.59095955:0.59090924:0.45532238:0.45064417:0.44945204:0.4487876:0.44833568\n242260:214359:126325:234126:123362:233304:235006:124195:107996:334829-> 0.89615464:0.8961442:0.8106028:0.8106027:0.8106023:0.8106023:0.8106021:0.8106019:0.76834095:0.7570231\n209751:195546:201477:191758:211002:202325:197542:193691:199705:329052-> 0.913124:0.9130985:0.9130918:0.9130672:0.5525752:0.5524637:0.5524494:0.552405:0.55240136:0.5026157\n153326:407544:407682:408098:157881:351230:343651:127848:98884:129351-> 0.97206575:0.97206575:0.97206575:0.97206575:0.97206575:0.9689198:0.968068:0.9659192:0.9657442:0.96553063\n\n```", "```py\n$ git clone https://github.com/factorie/factorie.git\n...\n$ cd factorie\n$ git checkout factorie_2.11-1.2\n...\n$ mvn package -Pnlp-jar-with-dependencies\n\n```", "```py\n$ $ bin/fac nlp --wsj-forward-pos --conll-chain-ner\njava -Xmx6g -ea -Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -classpath ./src/main/resources:./target/classes:./target/factorie_2.11-1.2-nlp-jar-with-dependencies.jar\nfound model\n18232\nListening on port 3228\n...\n\n```", "```py\n$ telnet localhost 3228\nTrying ::1...\nConnected to localhost.\nEscape character is '^]'.\nBut I warn you, if you don't tell me that this means war, if you still try to defend the infamies and horrors perpetrated by that Antichrist--I really believe he is Antichrist--I will have nothing more to do with you and you are no longer my friend, no longer my 'faithful slave,' as you call yourself! But how do you do? I see I have frightened you--sit down and tell me all the news.\n\n1  1  But  CC  O\n2  2  I    PRP  O\n3  3  warn    VBP  O\n4  4  you    PRP  O\n5  5  ,      O\n6  6  if    IN  O\n7  7  you    PRP  O\n8  8  do    VBP  O\n9  9  n't    RB  O\n10  10  tell    VB  O\n11  11  me    PRP  O\n12  12  that    IN  O\n13  13  this    DT  O\n14  14  means    VBZ  O\n15  15  war    NN  O\n16  16  ,    ,  O\n17  17  if    IN  O\n18  18  you  PRP  O\n19  19  still    RB  O\n20  20  try    VBP  O\n21  21  to    TO  O\n22  22  defend    VB  O\n23  23  the    DT  O\n24  24  infamies    NNS  O\n25  25  and    CC  O\n26  26  horrors    NNS  O\n27  27  perpetrated    VBN  O\n28  28  by    IN  O\n29  29  that    DT  O\n30  30  Antichrist    NNP  O\n31  31  --    :  O\n32  1  I  PRP  O\n33  2  really    RB  O\n34  3  believe    VBP  O\n35  4  he    PRP  O\n36  5  is    VBZ  O\n37  6  Antichrist    NNP  U-MISC\n38  7  --    :  O\n39  1  I    PRP  O\n40  2  will    MD  O\n41  3  have    VB  O\n42  4  nothing    NN  O\n43  5  more    JJR  O\n44  6  to    TO  O\n45  7  do    VB  O\n46  8  with    IN  O\n47  9  you    PRP  O\n48  10  and    CC  O\n49  11  you    PRP  O\n50  12  are    VBP  O\n51  13  no    RB  O\n52  14  longer    RBR  O\n53  15  my    PRP$  O\n54  16  friend    NN  O\n55  17  ,    ,  O\n56  18  no    RB  O\n57  19  longer    RB  O\n58  20  my  PRP$  O\n59  21  '    POS  O\n60  22  faithful    NN  O\n61  23  slave    NN  O\n62  24  ,    ,  O\n63  25  '    ''  O\n64  26  as    IN  O\n65  27  you    PRP  O\n66  28  call    VBP  O\n67  29  yourself    PRP  O\n68  30  !    .  O\n69  1  But    CC  O\n70  2  how    WRB  O\n71  3  do    VBP  O\n72  4  you    PRP  O\n73  5  do    VB  O\n74  6  ?    .  O\n75  1  I    PRP  O\n76  2  see    VBP  O\n77  3  I    PRP  O\n78  4  have    VBP  O\n79  5  frightened    VBN  O\n80  6  you    PRP  O\n81  7  --    :  O\n82  8  sit    VB  O\n83  9  down    RB  O\n84  10  and    CC  O\n85  11  tell    VB  O\n86  12  me    PRP  O\n87  13  all    DT  O\n88  14  the    DT  O\n89  15  news    NN  O\n90  16  .    .  O\n\n```", "```py\nscala> val word2vec = new Word2Vec\nword2vec: org.apache.spark.mllib.feature.Word2Vec = org.apache.spark.mllib.feature.Word2Vec@58bb4dd\n\nscala> val model = word2vec.fit(sc.textFile(\"warandpeace\").map(_.split(\"\\\\W+\").toSeq)\nmodel: org.apache.spark.mllib.feature.Word2VecModel = org.apache.spark.mllib.feature.Word2VecModel@6f61b9d7\n\nscala> val synonyms = model.findSynonyms(\"life\", 10)\nsynonyms: Array[(String, Double)] = Array((freedom,1.704344822168997), (universal,1.682276637692245), (conception,1.6776193389148586), (relation,1.6760497906519414), (humanity,1.67601036253831), (consists,1.6637604144872544), (recognition,1.6526169382380496), (subjection,1.6496559771230317), (activity,1.646671198014248), (astronomy,1.6444424059160712))\n\nscala> synonyms foreach println\n(freedom,1.704344822168997)\n(universal,1.682276637692245)\n(conception,1.6776193389148586)\n(relation,1.6760497906519414)\n(humanity,1.67601036253831)\n(consists,1.6637604144872544)\n(recognition,1.6526169382380496)\n(subjection,1.6496559771230317)\n(activity,1.646671198014248)\n(astronomy,1.6444424059160712)\n\n```", "```py\nscala> val a = model.getVectors.filter(_._1 == \"monarchs\").map(_._2).head\na: Array[Float] = Array(-0.0044642715, -0.0013227836, -0.011506443, 0.03691717, 0.020431392, 0.013427449, -0.0036369907, -0.013460356, -3.8938568E-4, 0.02432113, 0.014533845, 0.004130258, 0.00671316, -0.009344602, 0.006229065, -0.005442078, -0.0045390734, -0.0038824948, -6.5973646E-4, 0.021729799, -0.011289608, -0.0030690092, -0.011423801, 0.009100784, 0.011765533, 0.0069619063, 0.017540144, 0.011198071, 0.026103685, -0.017285397, 0.0045515243, -0.0044477824, -0.0074411617, -0.023975836, 0.011371289, -0.022625357, -2.6478301E-5, -0.010510282, 0.010622139, -0.009597833, 0.014937023, -0.01298345, 0.0016747514, 0.01172987, -0.001512275, 0.022340108, -0.009758578, -0.014942565, 0.0040697413, 0.0015349758, 0.010246878, 0.0021413323, 0.008739062, 0.007845526, 0.006857361, 0.01160148, 0.008595...\nscala> val b = model.getVectors.filter(_._1 == \"princess\").map(_._2).head\nb: Array[Float] = Array(0.13265875, -0.04882792, -0.08409957, -0.04067986, 0.009084379, 0.121674284, -0.11963971, 0.06699862, -0.20277102, 0.26296946, -0.058114383, 0.076021515, 0.06751665, -0.17419271, -0.089830205, 0.2463593, 0.062816426, -0.10538805, 0.062085453, -0.2483566, 0.03468293, 0.20642486, 0.3129267, -0.12418643, -0.12557726, 0.06725172, -0.03703333, -0.10810595, 0.06692443, -0.046484336, 0.2433963, -0.12762263, -0.18473054, -0.084376186, 0.0037174677, -0.0040220995, -0.3419341, -0.25928706, -0.054454487, 0.09521076, -0.041567303, -0.13727514, -0.04826158, 0.13326299, 0.16228828, 0.08495835, -0.18073058, -0.018380836, -0.15691829, 0.056539804, 0.13673553, -0.027935665, 0.081865616, 0.07029694, -0.041142456, 0.041359138, -0.2304657, -0.17088272, -0.14424285, -0.0030700471, -0...\nscala> val c = model.getVectors.filter(_._1 == \"individual\").map(_._2).head\nc: Array[Float] = Array(-0.0013353615, -0.01820516, 0.007949033, 0.05430816, -0.029520465, -0.030641818, -6.607431E-4, 0.026548808, 0.04784935, -0.006470232, 0.041406438, 0.06599842, 0.0074243015, 0.041538745, 0.0030222891, -0.003932073, -0.03154199, -0.028486902, 0.022139633, 0.05738223, -0.03890591, -0.06761177, 0.0055152955, -0.02480924, -0.053222697, -0.028698998, -0.005315235, 0.0582403, -0.0024816995, 0.031634405, -0.027884213, 6.0290704E-4, 1.9750209E-4, -0.05563172, 0.023785716, -0.037577976, 0.04134448, 0.0026664822, -0.019832063, -0.0011898747, 0.03160933, 0.031184288, 0.0025268437, -0.02718441, -0.07729341, -0.009460656, 0.005344515, -0.05110715, 0.018468754, 0.008984449, -0.0053139487, 0.0053904117, -0.01322933, -0.015247412, 0.009819351, 0.038043085, 0.044905875, 0.00402788...\nscala> model.findSynonyms(new DenseVector((for(i <- 0 until 100) yield (a(i) - b(i) + c(i)).toDouble).toArray), 10) foreach println\n(achievement,0.9432423663884002)\n(uncertainty,0.9187759184842362)\n(leader,0.9163721499105207)\n(individual,0.9048367510621271)\n(instead,0.8992079672038455)\n(cannon,0.8947818781378154)\n(arguments,0.8883634101905679)\n(aims,0.8725107984356915)\n(ants,0.8593842583047755)\n(War,0.8530727227924755)\n\n```", "```py\n  def step1(s: String) = {\n    b = s\n    // step 1a\n    processSubList(List((\"sses\", \"ss\"), (\"ies\",\"i\"),(\"ss\",\"ss\"), (\"s\", \"\")), _>=0)\n    // step 1b\n    if (!(replacer(\"eed\", \"ee\", _>0)))\n    {\n      if ((vowelInStem(\"ed\") && replacer(\"ed\", \"\", _>=0)) || (vowelInStem(\"ing\") && replacer(\"ing\", \"\", _>=0)))\n      {\n        if (!processSubList(List((\"at\", \"ate\"), (\"bl\",\"ble\"), (\"iz\",\"ize\")), _>=0 ) )\n        {\n          // if this isn't done, then it gets more confusing.\n          if (doublec() && b.last != 'l' && b.last != 's' && b.last != 'z') { b = b.substring(0, b.length - 1) }\n          else\n            if (calcM(b.length) == 1 && cvc(\"\")) { b = b + \"e\" }\n        }\n      }\n    }\n    // step 1c\n    (vowelInStem(\"y\") && replacer(\"y\", \"i\", _>=0))\n    this\n  }\n```"]