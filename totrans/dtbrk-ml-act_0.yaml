- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will discover what makes the Databricks Data Intelligence
    Platform the go-to choice for top-tier machine learning solutions. *Databricks
    ML in Action* presents cloud-agnostic, end-to-end examples with hands-on illustrations
    of executing data science, machine learning, and generative AI projects on the
    Databricks Platform. You’ll develop expertise in Databricks’ managed MLflow, Vector
    Search, AutoML, Unity Catalog, and Model Serving as you learn to apply them practically
    in everyday workflows. This Databricks book not only offers detailed code explanations
    but also facilitates seamless code importation for practical use. You’ll discover
    how to leverage the open source Databricks platform to enhance your learning,
    boost your skills, and elevate your productivity with supplemental resources.
    By the end of this book, you’ll have mastered the use of Databricks for data science,
    machine learning, and generative AI, enabling you to deliver outstanding data
    products.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for machine learning engineers, data scientists, and technical
    managers seeking hands-on expertise in implementing and leveraging the Databricks
    Data Intelligence Platform and its lakehouse architecture to create data products.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B16865_01.xhtml#_idTextAnchor016), *Getting Started with This
    Book and Lakehouse Concepts*, covers the different techniques and methods for
    data engineering and machine learning. The goal is not to unveil insights into
    data never seen before. If that were the case, this would be an academic paper.
    Instead, the goal of this chapter is to use open and free data to demonstrate
    advanced technology and best practices. You will list and describe each dataset
    present in the book.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B16865_02.xhtml#_idTextAnchor073), *Designing Databricks: Day
    One*, covers workspace design, model life cycle practices, naming conventions,
    what not to put in DBFS, and other preparatory topics. The Databricks platform
    is simple to use. However, there are many options available to cater to the different
    needs of different organizations. During my years as a contractor and my time
    at Databricks, I have seen teams succeed and fail. I will share with you the successful
    dynamics as well as any configurations that accompany those insights in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B16865_03.xhtml#_idTextAnchor123), *Building Out Our Bronze Layer*,
    begins your data journey in the Databricks DI Platform by exploring the fundamentals
    of the Bronze layer of the Medallion architecture. The Bronze layer is the first
    step in transforming your data for downstream projects, and this chapter will
    focus on the Databricks features and techniques you have available for the necessary
    transformations. We will start by introducing you to Auto Loader, a tool to automate
    data ingestion, which you can implement with or without **Delta Live Tables**
    (**DLT**) to insert and transform your data.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B16865_04.xhtml#_idTextAnchor180), *Getting to Know Your Data*,
    explores the features within the Databricks DI Platform that help improve and
    monitor data quality and facilitate data exploration. There are numerous approaches
    to getting to know your data better with Databricks. First, we cover how to oversee
    data quality with DLT to catch quality issues early and prevent the contamination
    of entire pipelines. We will take our first close look at Lakehouse Monitoring,
    which helps us analyze data changes over time and can alert us to changes that
    concern us.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B16865_05.xhtml#_idTextAnchor244), *Feature Engineering on Databricks*,
    progresses from [*Chapter 4*](B16865_04.xhtml#_idTextAnchor180), where we harnessed
    the power of Databricks to explore and refine our datasets, to delve into the
    components of Databricks that enable the next step – feature engineering. We will
    start by covering **Databricks Feature Engineering** (**DFE**) in Unity Catalog
    to show you how you can efficiently manage engineered features using Unity Catalog.
    Understanding how to leverage DFE in UC is crucial for creating reusable and consistent
    features across training and inference. Then, you will learn how to leverage Structured
    Streaming to calculate features on a stream, which allows you to create stateful
    features needed for models to make quick decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B16865_06.xhtml#_idTextAnchor297), *Searching for a Signal*,
    examines how to use data science to search for a signal hidden in the noise of
    data. We will leverage the features we created within the Databricks platform
    during the previous chapter. We will start by using AutoML in a basic modeling
    approach, providing auto-generated code and quickly enabling data scientists to
    establish a baseline model to beat. When searching for a signal, we experiment
    with different features, hyperparameters, and models. Historically, tracking these
    configurations and their corresponding evaluation metrics is a time-consuming
    project in and of itself. A low-overhead tracking mechanism, such as the tracking
    provided by MLflow, an open source platform for managing data science projects
    and supporting MLOps, will reduce the burden of manually capturing configurations.
    More specifically, we’ll introduce MLflow Tracking, an MLflow component that significantly
    improves tracking each permutation’s many outputs. However, that is only the beginning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B16865_07.xhtml#_idTextAnchor325), *Productionizing ML on Databricks*,
    explores productionizing a machine learning model using Databricks products, which
    makes the journey more straightforward and cohesive by incorporating functionality
    such as the Unity Catalog Registry, Databricks Workflows, Databricks Asset Bundles,
    and Model Serving capabilities. This chapter will cover the tools and practices
    to take your models from development to production.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16865_08.xhtml#_idTextAnchor384), *Monitoring, Evaluating, and
    More*, covers how to create visualizations for dashboards in both the new Lakeview
    dashboards and the standard DBSQL dashboards. Deployed models can be shared via
    a web application. Therefore, we will not only introduce Hugging Face Spaces but
    also deploy the RAG chatbot using a Gradio app to apply what we have learned.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Databricks | Windows, macOS, or Linux |'
  prefs: []
  type: TYPE_TB
- en: '| Python and its associated libraries | Windows, macOS, or Linux |'
  prefs: []
  type: TYPE_TB
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book’s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting** **of code.**'
  prefs: []
  type: TYPE_NORMAL
- en: This book contains a few long screenshots which have been captured to show the
    overview of workflows and also the UI. Due to this, the content in this images
    may appear small at 100% zoom. Please check out the PDF copy provided with the
    book to zoom in for clearer images.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Databricks-ML-In-Action](https://github.com/PacktPublishing/Databricks-ML-In-Action).
    If there’s an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “ For example, you could select the `ml_in_action.favorita_forecasting.train_set`
    table.”'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    screen. For instance, words in menus or dialog boxes appear in **bold**. Here
    is an example: “ Once you have a dataset, return to the **Canvas** tab.”'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packtpub.com](mailto:copyright@packtpub.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share Your Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Databricks ML in Action*, we’d love to hear your thoughts!
    Please [click here to go straight to the Amazon review page](https://packt.link/r/1-800-56489-9)
    for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B16865_QR_Free_PDF.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/978-1-80056-489-3](https://packt.link/free-ebook/978-1-80056-489-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Part 1: Overview of the Databricks Unified Lakehouse Platform'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this part is not to unveil insights into data never seen before.
    If that were the case, this would be an academic paper. Instead, the goal is to
    use open and free data to demonstrate advanced technology and best practices.
    This part will list and describe each dataset present in the book. It also introduces
    you to the successful dynamics as well as any configurations that accompany the
    insights in this part. This part covers workspace design, model life cycle practices,
    naming conventions, what not to put in DBFS, and other preparatory topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B16865_01.xhtml#_idTextAnchor016), *Getting Started with This
    Book and Lakehouse Concepts*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B16865_02.xhtml#_idTextAnchor073), *Designing Databricks: Day
    One*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B16865_03.xhtml#_idTextAnchor123), *Building Out Our Bronze Layer*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
