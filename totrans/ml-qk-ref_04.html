<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Training Neural Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root">When you hear the term <strong>neural networks</strong>, it gives you a sense that its a form of biological terminology pertaining to brains. And I have to tell you candidly that it's a no brainer to guess that and, in fact, we are treading along the right path by doing so. We will see how it is connected to that.</p>
<p class="mce-root">Neural networks have brought in a revolution in the data science world. Until 2011, due to not having enough computation power, the people rooting for neural networks were not able to propagate it to the extent that they wanted. But, with the advent of cheaper computation solutions and more research in the area of neural networks, they have taken the data science and artificial world by storm. Neural networks are an algorithm that can be applied in both supervised and unsupervised learning. With deeper networks, they are able to provide solutions to unstructured data, such as images and text.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Neural networks</li>
<li>Network initialization</li>
<li>Overfitting</li>
<li>Dropouts</li>
<li>Stochastic gradient descent</li>
<li>Recurrent neural networks</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural networks</h1>
                </header>
            
            <article>
                
<p>Let me explain first of all what neurons are and how they are structured. The following labelled diagram shows a typical neuron:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5c407659-7770-4b8f-84ab-cc64be72d799.png" style="width:30.83em;height:13.75em;"/></p>
<p>We define neuron as an electrically excitable cell that receives, processes, and transmits information through electric and chemical signals. A dendrite is a part of it that receives signals from other neurons. One thing that we need to pay attention to is that just a single neuron can't do anything and there are billions of neurons connected to each other, which enables the electro-chemical signal flow and, in turn, the information to flow through it. The information passes through an axon and a synapse, before being transmitted.</p>
<p>When it comes to a neural network, the structure doesn't change much. Let's have a look at it. In the middle, we have a neuron and this neuron gets signals from three other neurons, X1, X2, and X3. All three neurons are connected by arrows that act like a synapse. These neurons, X1, X2, and X3, are called <strong>input layer neurons</strong>. After passing through the neuron, we get the output value. It's interesting to see that the human brain gets an input signal through all the sensors such as eyes, ear, touch, and nose and that all the synapses let these electro-chemical signals go, and output comes as vision, voice, sense of touch, and smell. A similar process is followed in the case of a neural network.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How a neural network works</h1>
                </header>
            
            <article>
                
<p>Let's say we have one set of input and output as follows:</p>
<table border="1" style="border-collapse: collapse;width: 48.6933%">
<tbody>
<tr>
<td style="width: 34%"><strong>Input (X)</strong></td>
<td style="width: 61.2857%"><strong>Output (Y)</strong></td>
</tr>
<tr>
<td style="width: 34%">2</td>
<td class="CDPAlignLeft CDPAlign" style="width: 61.2857%">4</td>
</tr>
<tr>
<td style="width: 34%">3</td>
<td class="CDPAlignLeft CDPAlign" style="width: 61.2857%">6</td>
</tr>
<tr>
<td style="width: 34%">4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 61.2857%">8</td>
</tr>
<tr>
<td style="width: 34%">5</td>
<td class="CDPAlignLeft CDPAlign" style="width: 61.2857%">10</td>
</tr>
<tr>
<td style="width: 34%">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 61.2857%">12</td>
</tr>
</tbody>
</table>
<p> </p>
<p>In the preceding table, input and output might look to have a linear relationship; however, that is not always the case. In addition, every time the model needs to initialize. Let's understand the meaning of initialization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model initialization</h1>
                </header>
            
            <article>
                
<p>Going by the preceding table, the network is trying to find a relationship between input and output. For example, let's assume the relationship that comes through is the following:</p>
<p class="CDPAlignCenter CDPAlign"><em>Y = W. X</em></p>
<p>In the preceding equation, <em>Y</em> and <em>X</em> are known, and based on that <em>W</em> has to be found out. But, finding out the value of <em>W</em> in one iteration is rare. It has to be initialized first. Let's say <em>W</em> is initialized with the value of <em>3</em>. And the equation turns out to be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>Y= 3X</em></p>
<table border="1" style="border-collapse: collapse;width: 56.5337%">
<tbody>
<tr>
<td style="width: 28%"><strong>Input (X)</strong></td>
<td style="width: 136.612%"><strong>Actual Output (Y)</strong></td>
</tr>
<tr>
<td style="width: 28%">2</td>
<td style="width: 136.612%">6</td>
</tr>
<tr>
<td style="width: 28%">3</td>
<td style="width: 136.612%">9</td>
</tr>
<tr>
<td style="width: 28%">4</td>
<td style="width: 136.612%">12</td>
</tr>
<tr>
<td style="width: 28%">5</td>
<td style="width: 136.612%">15</td>
</tr>
<tr>
<td style="width: 28%">6</td>
<td style="width: 136.612%">18</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now we have to assess the output and whether it is close to the desired output. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loss function</h1>
                </header>
            
            <article>
                
<p>So far, the model has been randomly initialized and with this we have been able to get an output. In order to assess if the actual output is close to the desired output, <strong>loss function</strong> is introduced. It enables the generalization of the model, and figures out how well the model is able to reach the desired output.</p>
<p class="mce-root"/>
<p>We can have a look at the new table, which has got actual output as well as desired output:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 22%"><strong>Input (X)</strong></td>
<td style="width: 26%"><strong>Actual Output (Y<sub>a</sub>)</strong></td>
<td style="width: 21.5222%"><strong>Desired Output (Y)</strong></td>
</tr>
<tr>
<td style="width: 22%">2</td>
<td style="width: 26%">6</td>
<td style="width: 21.5222%">4</td>
</tr>
<tr>
<td style="width: 22%">3</td>
<td style="width: 26%">9</td>
<td style="width: 21.5222%">6</td>
</tr>
<tr>
<td style="width: 22%">4</td>
<td style="width: 26%">12</td>
<td style="width: 21.5222%">8</td>
</tr>
<tr>
<td style="width: 22%">5</td>
<td style="width: 26%">15</td>
<td style="width: 21.5222%">10</td>
</tr>
<tr>
<td style="width: 22%">6</td>
<td style="width: 26%">18</td>
<td style="width: 21.5222%">12</td>
</tr>
</tbody>
</table>
<p> </p>
<p>If we have to put the loss function down, it has to be as follows:</p>
<p class="CDPAlignCenter CDPAlign"><em>Loss Function = Desired Output-Actual Output</em></p>
<p>However, putting loss function this way would invite both kinds of values: negative and positive. In the case of a negative value for the loss function, it would mean that the network is overshooting as <em>Desired Output &lt; Actual Output</em> and in the reverse scenario (<em>Desired Output &gt; Actual Output</em>), the network would undershoot. In order to get rid of this kind of thing, we will go for having an absolute loss:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr style="height: 40px">
<td style="width: 10%;height: 40px"><strong>Input(X)</strong></td>
<td style="width: 16%;height: 40px"><strong>Actual Output (Y<sub>a</sub>)</strong></td>
<td style="width: 16%;height: 40px"><strong>Desired Output (Y)</strong></td>
<td style="width: 10%;height: 40px"><strong>Loss=Y-Y<sub>a</sub></strong></td>
<td style="width: 13.8966%;height: 40px"><strong>Absolute Loss</strong></td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">2</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-2</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">2</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">3</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">9</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-3</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">3</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">12</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">8</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">4</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">5</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">15</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">10</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-5</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">5</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">18</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">12</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">6</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Total Absolute Loss = 20</p>
<p>Having this approach of absolute loss will do no good to the model, as if we try to see the preceding table gingerly, the smallest loss is of 2 units and the maximum coming through is 6 units. One might get a feeling that the difference between maximum and minimum loss is not much (here, 4 units), but it can be huge for the model. Hence, a different route is taken altogether. Rather than taking absolute loss, we would go for the square of losses:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr style="height: 40px">
<td style="width: 10%;height: 40px"><strong>Input(X)</strong></td>
<td style="width: 16%;height: 40px"><strong>Actual output (Y<sub>a</sub>)</strong></td>
<td style="width: 16%;height: 40px"><strong>Desired output (Y)</strong></td>
<td style="width: 10%;height: 40px"><strong>Loss=Y-Y<sub>a</sub></strong></td>
<td style="width: 13.8966%;height: 40px"><strong>Square of Loss</strong></td>
</tr>
<tr style="height: 38.7188px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 38.7188px">2</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 38.7188px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 38.7188px">4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 38.7188px">-2</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 38.7188px">4</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">3</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">9</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-3</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">9</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">12</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">8</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-4</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">16</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">5</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">15</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">10</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-5</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">25</td>
</tr>
<tr style="height: 32px">
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">18</td>
<td class="CDPAlignLeft CDPAlign" style="width: 16%;height: 32px">12</td>
<td class="CDPAlignLeft CDPAlign" style="width: 10%;height: 32px">-6</td>
<td class="CDPAlignLeft CDPAlign" style="width: 13.8966%;height: 32px">36</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now, the more the loss, the more the penalization. It can easily make things evident where we have more losses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Optimization</h1>
                </header>
            
            <article>
                
<p>We have to figure out a way to minimize the total loss function and it can be achieved by changing the weight. It can be done by using a crude method like modifying the parameter <em>W</em> over a range of -500 to 500 with a step 0.001. It will help us to find a point where the sum of squares of error becomes 0 or minimum.</p>
<p>But this approach will work out in this scenario because we don't have too many parameters here and computation won't be too challenging. However, when we have a number of parameters, the computation would take a hit. </p>
<p>Here, mathematics comes to our rescue in the form of differentiation (maxima and minima approach) in order to optimize the weights. The derivative of a function at a certain point gives the rate at which this function is changing its values. Here, we would take the derivative of loss function. What it will do is to assess an impact on total error by making a slight adjustment or change in weight. For example, if we try to make a change in weight which is <em>δW, W= W+ </em><span><em>δW</em>, we can find out how it is influencing loss function. Our end goal is to minimize the loss function through this.</span></p>
<p>We know that the minima will be arrived at <em>w=2</em>; hence, we are exploring different scenarios here:</p>
<ul>
<li><em>w&lt;2</em> implies a positive loss function, negative derivative, meaning that an increase of weight will decrease the loss function</li>
<li><em>w&gt;2</em> implies positive loss function, but the derivative is positive, meaning that any more increase in the weight will increase the losses</li>
<li>At <em>w=2</em>, loss=0 and the derivative is 0; minima is achieved:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/18242011-6eff-469d-8dde-610e9b8146b6.png" style="width:21.25em;height:15.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Computation in neural networks</h1>
                </header>
            
            <article>
                
<p>Now, let's look at a simple and shallow network:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1011 image-border" src="assets/74496ea6-7e1a-45ce-9483-1b594efecada.png" style="width:28.33em;height:19.42em;"/></p>
<p>Where:</p>
<ul>
<li><strong>I1</strong>: Input neuron 1</li>
<li><strong>I2</strong>: Input neuron 2</li>
<li><strong>B1</strong>: Bias 1</li>
<li><strong>H1</strong>: Neuron 1 in hidden layer</li>
<li><strong>H2</strong>: Neuron 2 in hidden layer</li>
<li><strong>B2</strong>: Bias 2</li>
<li><strong>O1</strong>: Neuron at output layer</li>
</ul>
<p>The final value comes at the output neuron <strong>O1</strong>. <strong>O1</strong> gets the input from <strong>H1</strong>, <strong>H2</strong>, and <strong>B2</strong>. Since <strong>B2</strong> is a bias neuron, the activation for it is always 1. However, we need to calculate the activation for <strong>H1</strong> and <strong>H2</strong>. In order to calculate activation of <strong>H1</strong> and <strong>H2</strong>, activation for <strong>I1</strong>, <strong>I2</strong>, and <strong>B1</strong> would be required. It may look like <strong>H1</strong> and <strong>H2</strong> will have the same activation, since they have got the same input. But this is not the case here as weights of <strong>H1</strong> and <strong>H2</strong> are different. The connectors between two neurons represent weights.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Calculation of activation for H1</h1>
                </header>
            
            <article>
                
<p>Let's have a look at the part of network involving just <strong>H1</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-980 image-border" src="assets/a119d44b-03e2-48ea-aea5-a71f3ca56d56.png" style="width:21.17em;height:24.17em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The hidden layer comes out as in the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/d64d4cf1-b2c9-492f-b3d9-80f867ea7193.png" style="width:10.83em;height:3.83em;"/></p>
<p>Where:</p>
<ul>
<li><em>A</em>: Activation function</li>
<li><em>x<sub>i</sub></em>: Input values</li>
<li><em>w<sub>i</sub></em>: Weight values</li>
</ul>
<p>In our scenario, there are three input values, <em>n=3</em>:</p>
<ul>
<li><em>x<sub>1</sub></em> = <em>I1</em> = Input value 1 from first neuron</li>
<li><em>x<sub>2 </sub></em>= <em>I2</em>= Input value 2 from second neuron</li>
<li><em>x<sub>3 </sub></em>= <em>B1</em> = <em>1</em></li>
<li><em>w1 </em>= Weight from <em>I1</em> to <em>H1</em></li>
<li><em>w2 </em>= Weight from <em>I2</em> to <em>H1</em></li>
<li><em>w3 </em>= Weight from <em>B1</em> to <em>H1</em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backward propagation</h1>
                </header>
            
            <article>
                
<p>In this step, we calculate the gradients of the loss function <em>f(y, y_hat)</em> with respect to <em>A</em>, <em>W</em>, and <em>b</em> called <em>dA</em>, <em>dW,</em> and <em>db</em>. Using these gradients, we update the values of the parameters from the last layer to the first.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activation function</h1>
                </header>
            
            <article>
                
<p>Activation function is typically introduced in the neural network in order to induce non-linearity. Without non-linearity, a neural network will have little chance to learn non-linearity. But you might question as to why why we need non-linearity in the first place. If we deem every relationship as a linear one, then the model won't be able to do justice to the actual relationship because having a linear relationship is a rarity. If applied linearity, the model's output won't be a generalized one. </p>
<p>Also, the main purpose of an activation function is to convert an input signal into an output. Let's say if we try to do away with an activation function, it will output a linear result. Linear function is a polynomial of the first degree and it's easy to solve but, again, it's not able to capture complex mapping between various features, which is very much required in the case of unstructured data.</p>
<p><span>Non-linear functions are those that have a degree more than one. Now we need a neural network model to learn and represent almost anything and any arbitrary complex function that maps inputs to outputs. Neural networks are also called </span><strong>universal function approximators</strong><span>. </span>It means that they can compute and learn any function<span>. Hence, activation function is an integral part of a neural network to make it learn complex functions.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Types of activation functions</h1>
                </header>
            
            <article>
                
<ol>
<li><strong>Sigmoid</strong>: This type of activation function comes along as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/8bcb8153-74b3-4a24-b927-2967314bbf01.png" style="width:10.58em;height:1.58em;"/></p>
<p style="padding-left: 60px">The value of this function ranges between <em>0</em> and <em>1</em>. It comes with a lot of issues:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li>Vanishing gradient</li>
</ul>
<ul>
<li>Its output is not zero-centered</li>
<li>It has slow convergence</li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>Hyperbolic tangent function (tanh)</strong>: The mathematical formula to represent it is this:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/76547790-6185-4522-bddc-1e58280a80f8.png" style="width:16.08em;height:1.67em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The value of this function ranges between -1 and +1. However, it still faces the vanishing gradient problem:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9e924e24-2a35-4a8f-9072-4c49f9d7f9ad.png" style="width:19.42em;height:13.83em;"/></p>
<ol start="3">
<li><strong>Rectified Linear Units (ReLU)</strong>: Mathematically, we represent it in the following manner:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/141499a5-01e1-4e4a-97d7-21fa7000f8df.png" style="width:9.00em;height:1.42em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ce1a9375-30b1-4e09-9822-66bf365ed966.png" style="width:24.67em;height:12.42em;"/></p>
<p class="graf graf--p graf-after--h3" style="padding-left: 60px">Going by the preceding diagram, ReLU is linear for all positive values, and zero for all negative values. This means that the following are true:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li class="graf graf--li graf-after--p">It's cheap to compute as there is no complicated math. The model can therefore take less time to train.</li>
<li class="graf graf--li graf-after--li">It converges faster. Linearity means that the slope doesn't hit the plateau when<span> </span><em>x</em><span> </span>gets large. It doesn't have the vanishing gradient problem suffered by other activation functions <span>such as</span> sigmoid or tanh.</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network initialization</h1>
                </header>
            
            <article>
                
<p>So far, we have seen that there are a number of stages in a neural network model. We already know that weight exists between two nodes (of two different layers). The weights undergo a linear transformation and, along with values from input nodes, it crosses through nonlinear activation function in order to yield the value of the next layer. It gets repeated for the next and subsequent layers and later on, with the help of backpropagation, optimal values of weights are found out.</p>
<p>For a long time, weights used to get randomly initialized. Later on, it was realized that the way we initialize the network has a massive impact on the model. Let's see how we initialize the model:</p>
<ul>
<li><strong>Zero initialization</strong>: In this kind of initialization, all the initial weights are set to zero. Due to this, all the neurons of all the layers perform the same calculation, which results in producing the same output. It will make the whole deep network futile. Predictions coming out of this network would be as good as random. Intuitively speaking, it doesn't perform symmetry breaking. Normally, during forward propagation of a neural network, each hidden node gets a signal and this signal is nothing but the following:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7ed004a1-bbc9-4521-b36d-17faa6d57a86.png" style="width:7.08em;height:3.67em;"/></p>
<p style="padding-left: 60px">If a network is initialized with zero, then all the hidden nodes will get zero signal because all the inputs will be multiplied by zero. Hence, no matter what the input value is, if all weights are the same, all units in the hidden layer will be the same too. This is called <strong>symmetry</strong>, and it has to be broken in order to have more information capturing a good model. Hence, the weights are supposed to be randomly initialized or with different values:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/f0640572-0929-4ab6-8727-a72292178280.png" style="width:24.50em;height:1.50em;"/></p>
<ul>
<li><strong>Random initialization</strong>: This kind of initialization helps in symmetry breaking. <span>In this method, the weights are randomly initialized very close to zero. Every neuron doesn't perform the same computation as the weight is not equal to zero:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5d537d8c-7360-4499-a735-08e3745db251.png" style="width:33.92em;height:1.58em;"/></p>
<ul>
<li><strong>He-et-al initialization</strong>: This initialization depends on the size of the previous layer. It<span class="markup--quote markup--p-quote is-other"> helps in attaining a global minimum of the cost function. </span><span>The weights are random but differ in range depending on the size of the previous layer of neurons:</span></li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4ea122bf-7683-472f-b158-b3ffef64ec96.png" style="width:44.92em;height:1.50em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backpropagation</h1>
                </header>
            
            <article>
                
<p>Backpropagation takes place once feed forward is completed. It stands for <strong>backward propagation of errors</strong>. In the case of neural networks, this step begins to compute the gradient of error function (loss function) with respect to the weights. One can wonder why the term <strong>back</strong> is associated with it. It's due to gradient computation that starts backwards through the network. In this, the gradient of the final layer of weights gets calculated first and the the weights of the first layer are calculated last.</p>
<p>Backpropagation needs three elements:</p>
<ul>
<li><strong>Dataset</strong>: A dataset that consists of pairs of input-output <img class="fm-editor-equation" src="assets/4547391a-da1a-4ad7-b3dd-a8fc87618733.png" style="width:2.67em;height:1.25em;"/> where <img class="fm-editor-equation" src="assets/413b860f-3d7a-4eb6-b627-8ba6547d1c7a.png" style="width:1.00em;height:1.33em;"/> is the input and <img class="fm-editor-equation" src="assets/516eb17d-0d03-4582-8e5a-b81806b6e626.png" style="width:1.00em;height:1.42em;"/> is the output that we are expecting. Hence, a set of such input-outputs of size <em>N</em> is taken and denoted as <img class="fm-editor-equation" src="assets/69a7749c-d852-4e99-bff9-f07109e362a8.png" style="width:14.75em;height:1.67em;"/>.</li>
<li><strong>Feed-forward network</strong>: In this, the<span> parameters are denoted as <em>θ</em></span><span>.</span> <span>The parameters,<img class="fm-editor-equation" src="assets/ca7375da-5da5-4a0b-a055-11c63e0c870b.png" style="width:1.50em;height:1.67em;"/></span><span>, the weight between node <em>j</em></span><span> in layer <em>l<sub>k</sub> </em></span><span>and node <em>i</em> </span><span>in layer <em>l<sub>k-1</sub></em></span>, <span>and </span><span>the bias <img class="fm-editor-equation" src="assets/b91ce0ca-b2ff-4a9a-bc69-9b4193a865eb.png" style="width:1.08em;height:1.58em;"/> for node <em>i</em></span><span> in layer <em>l<sub>k-1</sub></em></span><span>.</span> <span>There are no connections between nodes in the same layer and layers are fully connected.</span></li>
<li><strong>Loss function</strong>: <em>L(X,θ)</em>.</li>
</ul>
<p>Training a neural network with gradient descent requires the calculation of the gradient of the loss/error function <em>E(X,θ)</em><span> </span>with respect to the weights<span> <img class="fm-editor-equation" src="assets/dadeb00b-55a2-421c-8bab-946c28b37d4d.png" style="width:1.25em;height:1.42em;"/> </span>and biases <img class="fm-editor-equation" src="assets/1455e031-42d4-4c52-bf4f-5626cbc06bc2.png" style="width:0.92em;height:1.33em;"/>. Then, according to the learning rate<span> <em>α</em></span>, each iteration of gradient descent updates the weights and biases<span> </span>collectively, denoted<span> </span>according to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/1c456d7b-2549-43ba-8427-cdeefb863b33.png" style="width:15.50em;height:1.67em;"/></p>
<p><span>Here <img class="fm-editor-equation" src="assets/64229546-bef0-4e41-8c0c-4f7ad5c38557.png" style="width:0.67em;height:1.25em;"/> </span>denotes the parameters of the neural network at iteration<span> </span>in gradient descent.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overfitting</h1>
                </header>
            
            <article>
                
<p>We have already discussed overfitting in detail. However, let's have a recap of what we learned and what overfitting is in a neural network scenario.</p>
<p>By now, we are cognizant of the fact that, when a large number of parameters (in deep learning) are available at our disposal to map and explain an event, more often than not, the model built using these parameters will tend to have a good fit and try to showcase that it has the ability to describe the event properly. However, the real test of any model is always on unseen data, and we were able to assess how the model fares on such unseen data points. We expect our model to have an attribute of generalization and it will enable the model to score on test data (unseen) in alignment with the trained one. But, a number of times our model fails to generalize when it comes to the unseen data, as the model has not learned the insights and causal relationship of the event. In this scenario, one might be able to see the huge gulf of variance in training accuracy and test accuracy and, needless to say, it is not what we are seeking out of the model. This phenomenon is called <strong>overfitting</strong>.</p>
<p>In deep learning, there are millions of parameters you may encounter and in all likelihood, you might fall into the trap of overfitting. As we had defined overfitting in the first chapter, it<span> happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prevention of overfitting in NNs</h1>
                </header>
            
            <article>
                
<p>As we already discussed in the earlier chapters, overfitting is a major issue that needs to be considered while building models as our work doesn't get over only at training phase. The litmus test for any model takes place on unseen data. Let's explore the techniques of handling overfitting issues in neural networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Vanishing gradient </h1>
                </header>
            
            <article>
                
<p>Neural networks have been a revelation in extracting complex features out of the data. Be it images or texts, they are able to find the combinations that result in better predictions. The deeper the network, the higher the chances of picking those complex features. If we keep on adding more hidden layers, the learning speed of the added hidden layers get faster.</p>
<p class="mce-root"/>
<p>However, when we get down to backpropagation, which is moving backwards in the network to find out gradients of the loss with respect to weights, the gradient tends to get smaller and smaller as we head towards the first layer. It that initial layers of the deep network become slower learners and later layers tend to learn faster. This is called the <strong>vanishing gradient problem</strong>.</p>
<p><strong><span>Initial layers </span></strong><span>in the network are important because they are responsible to </span><em>learn and detect the simple patterns</em><span> and are actually the </span><strong>building blocks</strong><span> of our network. Obviously, if they give improper and </span><strong>inaccurate</strong><span> results, then how can we expect the next layers and the complete network to perform effectively and produce accurate results? The following diagram shows the figure of a ball that rolls on a steeper slope:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a3ae1b6c-f32c-4cd9-887a-e201c1590813.png" style="width:37.58em;height:15.83em;"/></p>
<p>Just to make it a little simpler for us all, let's say that there are two slopes: one being steeper and the other being less steep. Both slopes have got balls rolling down them and it is a no brainer that the ball will roll down the steeper slope faster than the one that is not as steep. Similar to that, if the gradient is large, the learning and training gets faster; otherwise, training gets too slow if the gradient is less steep.</p>
<p>From backpropagation intuition, we are aware of the fact that the optimization algorithms such as gradient descent<span> slowly seeko attain the local optima by regulating weights such that the cost function's output is decreased. The gradient descent algorithm updates the weights by the negative of the gradient multiplied by the learning rate (<em>α</em>) (which is small):</span></p>
<p class="CDPAlignLeft CDPAlign" style="padding-left: 120px">      <img src="assets/440170ea-fc59-46bc-817e-dec702406d97.png" style="width:20.25em;height:8.67em;"/></p>
<p>It says that we have to repeat until it attains convergence. However, there are two scenarios here. The first is that, if there are fewer iterations, then the accuracy of the result will take a hit; the second is that more iterations result in training taking too much time. This happens because weight does not change enough at each iteration as the gradient is small (and we know <em>α</em> is already very small). Hence, weight does not move to the lowest point in the assigned iterations.</p>
<p>Let's talk about that activation function, which might have an impact on the vanishing gradient problem. Here, we talk about the sigmoid function, which is typically used as an activation function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/7657cf67-19e2-45f3-81b7-4084792ceb64.png" style="width:7.42em;height:2.42em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2857f1c6-3632-4d5a-acda-04b0ef32219a.png" style="width:19.25em;height:15.75em;"/></p>
<p>It translates all input values into a range of values between <em>(0,1)</em>. If we have to find out the derivative of the sigmoid function then:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/b5d457b0-01e6-4904-baa1-f1e0674a4969.png" style="width:11.17em;height:2.67em;"/></p>
<p>Let's plot it now:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/df11e32f-2167-467a-bd05-36ce684c8313.png"/></p>
<p>It is quite evident that the derivative has got the maximum value as 0.25. Hence, the range of values under which it would lie is <em>(0,1/4)</em>.</p>
<p>A typical neural network looks like the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/1acf1c62-c478-4e81-9699-0e7c6f511a05.png" style="width:41.17em;height:7.17em;"/></p>
<p>Once the weight parameters are initialized, the input gets multiplied by weights and gets passed on through an activation function and, finally, we get a cost function (<strong>J</strong>). Subsequently, backpropagation takes place to modify the weights through gradient descent in order to minimize <strong>J</strong>.</p>
<p>In order to calculate the derivative with respect to first weight, we are using the chain rule. It will turn out to be like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3a106879-37e1-4614-a153-6ee334fb3b73.png" style="width:27.92em;height:2.75em;"/></p>
<p>If we just try to study the derivatives in the middle of the preceding expression, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4ff036d1-3594-41c1-ae0e-7cf946652c0a.png" style="width:12.00em;height:2.75em;"/></p>
<p><span>Part 1—from the output to hidden2.</span></p>
<p><span>Since the output is the activation of the 2nd hidden unit, the expression turns out to be like the following:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/3941e87a-2dd0-453c-bfd3-e9799e41ebce.png" style="width:9.08em;height:1.17em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5ecc45d9-810a-4fc3-b0d4-eb19564c6eea.png" style="width:15.17em;height:2.75em;"/></p>
<p>Similarly for part 2, from hidden 2 to hidden 1, <span>the expression turns out to be like the following:</span></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/adc5ddd6-823d-42ba-b0fe-361a56202f8e.png" style="width:10.42em;height:1.33em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/773e3435-985d-4240-bb66-935d38d4f466.png" style="width:16.08em;height:2.92em;"/></p>
<p>On putting everything together, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/98f8ca56-7833-4e7e-b0e2-a145aa45817b.png" style="width:31.67em;height:2.92em;"/></p>
<p>We know that the maximum value of the derivative of the sigmoid function is 1/4 and the weights can <span>typically</span> take the values between -1 and 1 if weights have been initialized with standard deviation 1 and mean 0. It will lead to the whole expression being smaller. If there is a deep network to be trained, then this expression will keep on getting even smaller and, as a result of that, the training time will become slow-paced.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overcoming vanishing gradient</h1>
                </header>
            
            <article>
                
<p>From the preceding explanation of vanishing gradient, it comes out that the root cause of this problem is the sigmoid function being picked as an activation function. The similar problem has been detected when <em>tanh</em> is chosen as an activation function.</p>
<p>In order to counter such a scenario, the ReLU function comes to the rescue:</p>
<p class="CDPAlignCenter CDPAlign"><em>ReLU(x)= max(0,x)</em></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a7bd50b5-43f3-4021-96d0-4f8bad02d742.png" style="width:27.25em;height:22.17em;"/></p>
<p>If the input is negative or less than zero, the function outputs as zero. In the second scenario, if the input is greater than zero, then the output will be equal to input.</p>
<p>Let's take the derivative of this function and see what happens:</p>
<p><strong>Case 1</strong>: <em>x&lt;0</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/a8afc1d4-1539-4c14-a667-536914439103.png" style="width:3.58em;height:2.42em;"/></p>
<p><strong>Case 2</strong>: <em>x&gt;0</em>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/18ee3326-b6a5-42a1-8b59-34b0438ffd82.png" style="width:3.83em;height:2.58em;"/></p>
<p>If we have to plot it, we get the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7c495aa3-2edc-4e29-b2c3-469228c57c88.png" style="width:41.67em;height:19.17em;"/></p>
<p>So, the derivative of ReLU is either 0 or 1. The plot comes out to be like a step function. Now, we can see that we won't face the vanishing gradient problem as the value of the derivative doesn't lie between 0 and 1.</p>
<p>However, it's still not true. We might still face this problem when the input value happens to be negative and we know that derivative turns out to be zero in this scenario. Typically, it doesn't happen that the weighted sum ends up negative, and we can indeed initialize weights to be only positive and/or normalize input between 0 and 1, if we are concerned about the chance of an issue like this occurring.</p>
<p>There is still a workaround for this kind of scenario. We have got another function called <strong>Leaky ReLU</strong>, which appears as the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><em>RELU (x) = max (εx, x)</em></p>
<p>Here, the value of ε is typically 0.2–0.3. We could plot it, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bad4eb21-876b-4479-a23a-eece3cf8b89b.png" style="width:14.75em;height:11.92em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recurrent neural networks</h1>
                </header>
            
            <article>
                
<p>Our thought process always has a sequence. We always understand things in an order. For example, if we watch a movie, we understand the next sequence by connecting it with the previous one. We retain the memory of the last sequence and get an understanding of the whole movie. We don't always go back to the first sequence in order to get it.</p>
<p>Can a neural network act like this? Traditional ones typically cannot operate in this manner and that is a major shortcoming. This is where recurrent neural networks make a difference. It comes with a loop that allows information to flow:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/bbf8d6b1-9c18-4882-aa18-6151eafb603f.png" style="width:7.25em;height:8.92em;"/></p>
<p>Here, a neural network takes an input as <strong>X<sub>t</sub> </strong>and throws an output in the form of <strong>h<sub>t </sub></strong>. A recurrent neural network is made up of multiple copies of the same network that pass on the message to the successor.</p>
<p>If we were to go and unroll the preceding network, it would look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/29ac117d-d864-4bff-a992-4a6ede2b024e.png" style="width:38.17em;height:12.33em;"/></p>
<p><span>This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They are the natural architecture of neural networks to use for such data. Since the network has got an internal memory, RNNs are able to remember the input they received which, in turn, enables them to come up with accurate and precise results and predictions.</span></p>
<p class="mce-root">So far, we have been talking about sequential data. But we need to have a proper understanding of this term, sequential data. This form of data is an order data where there exists a relationship between data at time <em>t</em> and the data at time <em>t-1</em>. An example of that kind of data can be financial data, time-series data, video, and so on. RNNs allow us to operate over sequences of vectors. For example, look at the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f5836407-530c-42b7-95b3-db16dfd08cb4.png"/></p>
<p><span>Each rectangle is represented as a vector, and arrows stand for functions. Input vectors are in red, output vectors are in blue, and green vectors hold the RNN's state:</span></p>
<ul class="postList">
<li class="graf graf--li graf-after--p">Vanilla mode of processing can be done without including RNN, from a fixed-sized input to output</li>
<li class="graf graf--li graf-after--li">Sequencing the output in a proper format</li>
<li class="graf graf--li graf-after--li">Sequencing the input </li>
<li class="graf graf--li graf-after--li">Sequencing the input and output (<span>for example,</span> machine translation: an RNN which reads a sentence in English and then outputs a sentence in some other language, like German).</li>
<li class="graf graf--li graf-after--li">Syncing the sequenced input and output (for <span>example,</span> video classification where label each frame of the video)</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Limitations of RNNs</h1>
                </header>
            
            <article>
                
<p>Recurrent neural networks function just right when it comes to short-term dependencies. What this means is that, if there is just a single statement to be dealt with, a neural network operates fine. For example, if there is a sentence, <em>India's capital is __</em>, in this scenario we would <span>invariably </span>get the correct result as this is a universal statement and there is nothing like a context here. This statement has no dependency on the previous sentence and here, there is no previous sentence either.</p>
<p class="mce-root"/>
<p>Hence, the prediction would be <em>India's capital is New Delhi</em>.</p>
<p>Afterall, the vanilla RNN's does not understand the context behind an input. We will understand with an example:</p>
<p><em>Staying in India meant that I gravitated towards cricket. But, after 10 years, I moved to the US for work.</em></p>
<p><em>The popular game in India is ___</em>.</p>
<p>One can see that there is a context in the first sentence and then it changes in the second one. However, prediction has to be done by the network on the basis of the first one. It is highly likely that the popular game in India is cricket, but context plays a role here and it has to be understood by the network. Simple RNN is a failure here.</p>
<p>That is where <strong>Long Short-Term Memory</strong> (<strong>LSTM</strong>) comes into the picture.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case</h1>
                </header>
            
            <article>
                
<p>Let's work on a use case that will help us in understanding the network.</p>
<p>We will work on a time series problem. We have got the Google stock price dataset. One being training and the other being test. We will now look at a use case to forecast the stock prices of Google:</p>
<ol>
<li>Let's start by importing the libraries:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</pre>
<ol start="2">
<li>Next, import the training set:</li>
</ol>
<pre style="padding-left: 60px">dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')<br/>training_set = dataset_train.iloc[:, 1:2].values</pre>
<ol start="3">
<li> Feature scaling is done in the next step:</li>
</ol>
<pre style="padding-left: 60px">from sklearn.preprocessing import MinMaxScaler<br/>sc = MinMaxScaler(feature_range = (0, 1))<br/>training_set_scaled = sc.fit_transform(training_set)</pre>
<ol start="4">
<li>Let's create a data structure with 60 time steps and 1 output:</li>
</ol>
<pre style="padding-left: 60px">X_train = []<br/>y_train = []<br/>for i in range(60, 1258):<br/> X_train.append(training_set_scaled[i-60:i, 0])<br/> y_train.append(training_set_scaled[i, 0])<br/>X_train, y_train = np.array(X_train), np.array(y_train)</pre>
<ol start="5">
<li>Next, reshape the data:</li>
</ol>
<pre style="padding-left: 60px">X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))</pre>
<ol start="6">
<li>Now, import the Keras libraries and packages:</li>
</ol>
<pre style="padding-left: 60px">from keras.models import Sequential<br/>from keras.layers import Dense<br/>from keras.layers import LSTM<br/>from keras.layers import Dropout</pre>
<ol start="7">
<li class="mce-root"> We will initialize the RNN with the regressor function:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor = Sequential()</pre>
<ol start="8">
<li class="mce-root">Now, add the first LSTM layer and some dropout regularization:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))<br/>regressor.add(Dropout(0.2))</pre>
<ol start="9">
<li class="mce-root"> Now, add the second LSTM layer and some dropout regularization:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.add(LSTM(units = 50, return_sequences = True))<br/>regressor.add(Dropout(0.2))</pre>
<ol start="10">
<li class="mce-root">Add the third LSTM layer and some dropout regularization:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.add(LSTM(units = 50, return_sequences = True))<br/>regressor.add(Dropout(0.2))</pre>
<ol start="11">
<li class="mce-root">Add a fourth LSTM layer and some dropout regularization:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.add(LSTM(units = 50))<br/>regressor.add(Dropout(0.2))</pre>
<ol start="12">
<li class="mce-root">Finally, add the output layer:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.add(Dense(units = 1))</pre>
<ol start="13">
<li class="mce-root"> Next, we will compile the RNN:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')</pre>
<ol start="14">
<li class="mce-root"> We will fit the RNN to the training set:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)</pre>
<ol start="15">
<li class="mce-root"> We get the real stock price of 2017 as shown:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')<br/>real_stock_price = dataset_test.iloc[:, 1:2].values</pre>
<ol start="16">
<li class="mce-root">We get the predicted stock price of 2017 as shown:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)<br/>inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values<br/>inputs = inputs.reshape(-1,1)<br/>inputs = sc.transform(inputs)<br/>X_test = []<br/>for i in range(60, 80):<br/> X_test.append(inputs[i-60:i, 0])<br/>X_test = np.array(X_test)<br/>X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))<br/>predicted_stock_price = regressor.predict(X_test)<br/>predicted_stock_price = sc.inverse_transform(predicted_stock_price)</pre>
<ol start="17">
<li class="mce-root"> Finally, we will visualize the results as shown:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')<br/>plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')<br/>plt.title('Google Stock Price Prediction')<br/>plt.xlabel('Time')<br/>plt.ylabel('Google Stock Price')<br/>plt.legend()<br/>plt.show()</pre>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned about neural networks along with their working, and were introduced to backward propagation and the activation function. We studied network initialization and how can we initialize the different types of models. We learned about overfitting and dropouts <span>in the neural network scenario. </span></p>
<p>We introduced the concept of RNN, and studied a use case regarding the <span>Google stock price dataset</span>. In the next chapter, we will study time series analysis.</p>


            </article>

            
        </section>
    </body></html>