- en: When in Doubt, Use Random Forests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to random forests
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a random forest for predicting credit card defaults using scikit-learn
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a random forest for predicting credit card defaults using H2O
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to random forests
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A random forest is a supervised machine learning algorithm based on ensemble
    learning. It is used for both regression and classification problems. The general
    idea behind random forests is to build multiple decision trees and aggregate them
    to get an accurate result. A decision tree is a deterministic algorithm, which
    means if the same data is given to it, the same tree will be produced each time.
    They have a tendency to overfit, because they build the best tree possible with
    the given data, but may fail to generalize when unseen data is provided. All the
    decision trees that make up a random forest are different because we build each
    tree on a different random subset of our data. A random forest tends to be more
    accurate than a single decision tree because it minimizes overfitting.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram demonstrates bootstrap sampling being done from the source
    sample. Models are built on each of the samples and then the predictions are combined
    to arrive at a final result:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7a368ae-ce16-47db-96c7-5ab98ab0b289.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
- en: 'Each tree in a random forest is built using the following steps where A represents
    the entire forest, a represents a single tree, for *a = 1* to *A*:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Create a bootstrap sample with replacement, *D* training from *x*, *y* label
    these *X[a]*[, ]*Y[a]*
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the tree *f[a]* on *X[a]*, *Y[a]*
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Average the predictions or take the majority vote to arrive at a final prediction
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a regression problem, predictions for the test instances are made by taking
    the mean of the predictions made by all trees. This can be represented as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b058aa6d-f242-48e0-ab2c-e20bca7feca3.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: Here, *N* is the total number of trees in the random forest. *a=1* represents
    the first tree in a forest, while the last tree in the forest is *A*. ![](img/b6820836-5f23-4996-b72c-86e17bcfbed3.png)(![](img/d7f322ac-15d3-4190-bea7-6b3f7250eba4.png))
    represents the prediction from a single tree.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: If we have a classification problem, majority voting or the most common answer
    is used.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a random forest for predicting credit card defaults using scikit-learn
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The scikit-learn library implements random forests by providing two estimators:
    `RandomForestClassifier`and `RandomForestRegressor`. They take various parameters,
    some of which are explained as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '` n_estimators`:This parameter is the number of trees the algorithm builds
    before taking a maximum vote or the average prediction. In general, the higher
    the number of trees the better the performance and the accuracy of the predictions,
    but it also costs more in terms of computation.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_features`: This parameter is the maximum number of features that the random
    forest is allowed to try in an individual tree.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_sample_leaf`:This parameter determines the minimum number of leaves that
    are required to split an internal node.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_jobs`: This hyperparameter tells the engine how many jobs to run in parallel
    for both fitting the model and predicting new instances. If it has a value of
    `None` or `1`, it runs only one job. A value of `-1` means it will use all the
    processors.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_state`:This parameter will always produce the same results when it
    has a definite value of `random_state` and if it has been given the same hyperparameters
    and the same training data.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`oob_score`: This parameter is also known as **out-of-the-bag ****sampling**,
    and is a random forest cross-validation method. In this sampling method, about
    one-third of the data is not used to train the model and can be used to evaluate
    its performance. These samples are called the **out-of-the-bag** **samples**.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this example, we use a dataset from the UCI ML repository on credit card
    defaults. This dataset contains the following information:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Default payments
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demographic factors
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Credit data
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: History of payments
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bill statements of credit card clients
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data and the data descriptions are provided in the GitHub folder:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by loading the required libraries and reading our dataset:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We set our working folder as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s now read our data. We will prefix the DataFrame name with `df_` so that
    we can understand it easily:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We check the shape of the dataset:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We check the datatypes:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We drop the `ID` column, as this is not required:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can explore our data in various ways. Let''s take a look at a couple of
    different methods:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that we have used a semicolon in the last line in the preceding code block.
    The semicolon helps to hide the verbose information produced by Matplotlib. `xlabelsize`
    and `ylabelsize` are used to adjust the font size in the x-axis and the y-axis.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows the distribution of the numeric variables:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9ea0dcfd-9bd1-47c3-9207-8d476ce78ee0.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
- en: 'We will now explore the payment defaults by age group. We bucket the `age`
    variable and store the binned values in a new variable, `age_group`, in `df_creditcarddata`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then use our new `age_group` variable to plot the number of defaults per
    age group:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following screenshot shows the amount of defaults per age:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a01f25a0-5db7-469d-b4b7-e1638ac2ed03.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: 'We can drop the `age_group` variable from `df_creditcarddata` since we do not
    need it anymore:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will now look at the payment defaults according to the credit limits of
    the account holders:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code gives us the following plot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8ca04a04-c2dc-4bac-bbf1-55319d9dee18.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: We can also assign labels to some of our variables to make the interpretations
    better. We assign labels for the `Gender`, `Marriage`, and `Education` variables.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'We also change the datatype of the `pay` variables to the string:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There are more explorations available in the code bundle provided with this
    book. We now move on to training our random forest model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now look at how to use a random forest to train our model:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by splitting our target and feature variables:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We separate the numerical and non-numerical variables in our feature set:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We dummy code the categorical variables:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We concatenate the dummy code variables to our DataFrame:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We split our dataset into training and testing subsets:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We scale the features with `StandardScaler()`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We might notice that the column names have been changed to numbers. We assign
    the columns names and index values back to the scaled DataFrame:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We import `RandomForestClassifier()` from `sklearn.ensemble`. We will then
    build our random forest classifier model:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After that, we calculate the accuracy of our training model:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We get the **f****alse positive rate** (**FPR**) and **t****rue positive rate** (**TPR**)
    by passing `y_test` and `y_pred_proba` to `roc_curve()`. We also get the `auc `value
    using `roc_auc_score()`. Using the FPR, TPR, and the AUC value, we plot the ROC
    curve with the AUC value annotated on the plot:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following graph shows the ROC curve with the AUC value annotated on it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43c5f4c5-d916-4f76-a3b4-8bf301a6926f.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
- en: 'We can also evaluate other scores, as shown here:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code produces the following evaluation scores:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dac2941b-1804-4d74-977b-f9878a69d72a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'We can also evaluate a few statistics based on the class of the target variable,
    which in this case is `0` or `1`:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`classification_report` from `sklearn.metrics` gives us the following scores
    based on each class of the target variable:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb489a75-2234-4f49-86ce-191e94fd501c.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: 'We can plot the top 10 variables by feature importance to see which variables
    are important for the model:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot shows the top 10 variables with their relative importance:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/152d22d8-51d0-4861-9e34-66ac936652a2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: We can change the hyperparameters to see how the model can perform better. We
    can also perform a grid search over combinations of hyperparameter values to fine-tune
    our model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Step 1*, we split our target and feature variables. In *Step 2*, in our
    feature set, we separated the numeric and non-numeric variables. In *Step 3* and
    *Step 4*, we converted the non-numeric variables to dummy coded variables and
    added them back to the DataFrame. In *Step 5*, we split our dataset into training
    and testing subsets, and in *Step 6*, we imported `StandardScaler()` from `sklearn.preprocessing`
    and applied the same scale to our features.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: After executing the commands in *Step 6*, we noticed that the column names had
    changed to sequential numbers. For this reason, in *Step 7*, we assigned the column
    names and the index values back to the scaled DataFrame. In *Step 8*, we imported `RandomForestClassifier()`
    from `sklearn.ensemble` and built our first random forest classifier model. After
    that, in *Step 9* and *Step 10*, we used our model to calculate the accuracy of
    our training model and plotted the ROC curve respectively. We also annotated the
    ROC Curve with the AUC value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 执行**步骤6**中的命令后，我们注意到列名已更改为顺序号。因此，在**步骤7**中，我们将列名和索引值重新分配给缩放后的DataFrame。在**步骤8**中，我们从`sklearn.ensemble`中导入`RandomForestClassifier()`并构建了我们第一个随机森林分类器模型。之后，在**步骤9**和**步骤10**中，我们使用我们的模型计算训练模型的准确度并绘制ROC曲线。我们还用AUC值标注了ROC曲线。
- en: In *Step 11*, we evaluated other scores, including the kappa value, the precision,
    the recall, and the accuracy.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤11**中，我们评估了其他分数，包括kappa值、精确度、召回率和准确度。
- en: In *Step 12*, we also evaluated these scores based on each class of the target
    variable, which in this case is `0` or `1`, using `classification_report` from
    `sklearn.metrics`. There, `classification_report()` provides us with metrics such
    as precision, recall, and f1-score by each class, as well as the average of each
    of the metrics.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤12**中，我们也根据目标变量的每个类别（在这种情况下是`0`或`1`）使用`sklearn.metrics`中的`classification_report`对这些分数进行了评估。在那里，`classification_report()`为我们提供了每个类别的精确度、召回率和f1分数等指标，以及每个指标的均值。
- en: '`classification_report()` reports averages, including averaging the total true
    positives, false negatives and false positives, averaging the unweighted mean
    per label, and averaging the support-weighted mean per label. It also reports
    sample averages for multi-label classification.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`classification_report()`报告平均值，包括平均总真实阳性、假阴性、假阳性，平均每个标签的无权均值，以及平均每个标签的支持加权均值。它还报告多标签分类的样本平均值。'
- en: Finally, in *Step 13*, we looked at the relative variable importance of the
    top 10 features. This can help in feature selection to build the models with the
    right features.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在**步骤13**中，我们研究了前10个特征的相对变量重要性。这有助于在特征选择中构建具有正确特征的模型。
- en: There are various feature selection methods available, such as averaged variable,
    importance, Boruta, recursive feature selection, and variable selection using
    RF.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种特征选择方法可用，例如平均变量重要性、Boruta、递归特征选择以及使用RF进行变量选择。
- en: There's more...
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Isolation forest is another algorithm that is built on the basis of decision
    trees, and it's used for anomaly and outlier detection. This algorithm is based
    on the assumption that the outlier data points are rare.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离森林是另一种基于决策树的算法，用于异常值和异常检测。该算法基于异常数据点稀少的假设。
- en: The algorithm works a bit differently to the random forest. It creates a bunch
    of decision trees, then it calculates the path length necessary to isolate an
    observation in the tree. The idea is that isolated observations, or anomalies,
    are easier to separate because there are fewer conditions necessary to distinguish
    them from normal cases. Thus, the anomalies will have shorter paths than normal
    observations and will, therefore, reside closer to the root of the tree. When
    several decision trees are created, the scores are averaged, which gives us a
    good idea about which observations are truly anomalies. As a result, isolation
    forests are used for outliers and anomaly detection.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的工作方式与随机森林略有不同。它创建了一组决策树，然后计算在树中隔离一个观察所需的路径长度。其想法是孤立观察值或异常值更容易分离，因为区分它们与正常情况所需的条件较少。因此，异常值将比正常观察值有更短的路径，并且因此将更靠近树的根部。当创建了多个决策树时，分数会被平均，这让我们对哪些观察值真正是异常值有一个很好的了解。因此，隔离森林被用于异常值和异常检测。
- en: Also, an isolation forest does not utilize any distance or density measures
    to detect an anomaly. This reduces the computational cost significantly compared
    to the distance-based and density-based methods.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，隔离森林不利用任何距离或密度度量来检测异常。与基于距离和密度的方法相比，这显著降低了计算成本。
- en: In scikit-learn, `sklearn.ensemble.IsolationForest` provides an implementation
    of the isolation forest algorithm.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-learn中，`sklearn.ensemble.IsolationForest`提供了隔离森林算法的实现。
- en: See also
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The scikit-learn implementation of the isolation forest algorithm can be found
    here: [https://bit.ly/2DCjGGF](https://bit.ly/2DCjGGF)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离森林算法的scikit-learn实现可以在这里找到：[https://bit.ly/2DCjGGF](https://bit.ly/2DCjGGF)
- en: Implementing random forest for predicting credit card defaults using H2O
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O 实现预测信用卡违约的随机森林
- en: H2O is an open source and distributed machine learning platform that allows
    you to build machine learning models on large datasets. H2O supports both supervised
    and unsupervised algorithms and is extremely fast, scalable, and easy to implement. H2O's
    REST API allows us to access all its functionalities from external programs such
    as R and Python. H2O in Python is designed to be very similar to scikit-learn. At
    the time of writing this book, the latest version of H2O is H2O v3.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 是一个开源的分布式机器学习平台，允许您在大型数据集上构建机器学习模型。H2O 支持监督和非监督算法，并且非常快速、可扩展且易于实现。H2O 的
    REST API 允许我们从外部程序（如 R 和 Python）访问其所有功能。在编写本书时，H2O 的最新版本是 H2O v3。
- en: 'The reason why H2O brought lightning-fast machine learning to enterprises is
    given by the following explanation:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 将闪电般的机器学习带给企业的原因如下所述：
- en: '"H2O''s core code is written in Java. Inside H2O, a distributed key/value store
    is used to access and reference data, models, objects, and so on, across all nodes
    and machines. The algorithms are implemented on top of H2O''s distributed Map/Reduce
    framework and utilize the Java fork/join framework for multi-threading. The data
    is read in parallel and is distributed across the cluster and stored in memory
    in a columnar format in a compressed way. H2O''s data parser has built-in intelligence
    to guess the schema of the incoming dataset and supports data ingest from multiple
    sources in various formats"'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '"H2O 的核心代码是用 Java 编写的。在 H2O 中，使用分布式键/值存储来访问和引用数据、模型、对象等，跨越所有节点和机器。算法是在 H2O
    的分布式 Map/Reduce 框架上实现的，并利用 Java fork/join 框架进行多线程处理。数据并行读取并分布在整个集群中，以压缩的列格式存储在内存中。H2O
    的数据解析器具有内置的智能来猜测传入数据集的模式，并支持从多种格式的多个来源进行数据摄取"'
- en: '- from h2o.ai'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '- 来自 h2o.ai'
- en: H2O provides us with distributed random forests, which are a powerful tool used
    for classification and regression tasks. This generates multiple trees, rather
    than single trees. In a distributed random forest, we use the average predictions
    of both the classification and regression models to reach a final result.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 为我们提供了分布式随机森林，这是一种用于分类和回归任务的有力工具。它生成多个树，而不是单个树。在分布式随机森林中，我们使用分类和回归模型的平均预测来得出最终结果。
- en: Getting ready
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Java is an absolute must for H2O to run. Make sure you have Java installed
    with the following command in Jupyter:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Java 对于 H2O 运行是绝对必要的。请确保您已安装 Java，并在 Jupyter 中使用以下命令：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You will now need to install H2O. To install this from Jupyter, use the following
    command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要安装 H2O。要从 Jupyter 安装，请使用以下命令：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Import the required libraries:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To use H2O, we need to initialize an instance and connect to it. We can do
    that as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 H2O，我们需要初始化一个实例并将其连接。我们可以这样做：
- en: '[PRE28]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'By default, the preceding command tries to connect to an instance. If it fails
    to do so, it will attempt to start an instance and then connect to it. Once connected
    to an instance, we will see the details of that instance, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，前面的命令会尝试连接到一个实例。如果它无法这样做，它将尝试启动一个实例然后连接到它。一旦连接到实例，我们将看到该实例的详细信息，如下所示：
- en: '![](img/845d5994-fe6f-4d56-abfe-db1c235d5142.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/845d5994-fe6f-4d56-abfe-db1c235d5142.png)'
- en: 'We read our data into a `pandas` DataFrame:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据读入一个 `pandas` DataFrame：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We change our `pandas` DataFrame to an H2O DataFrame using `h2o.H2OFrame()`.
    We name the `df_creditcarddata` H2O DataFrame:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `h2o.H2OFrame()` 将我们的 `pandas` DataFrame 转换为 H2O DataFrame。我们将 `df_creditcarddata`
    H2O DataFrame 命名：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Check whether the data in the H2O DataFrame is properly loaded as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 H2O DataFrame 中的数据是否已正确加载，如下所示：
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can see the summary statistics with the `describe()` method:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `describe()` 方法查看摘要统计信息：
- en: '[PRE32]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We drop the ID column, as this will not be required for our model building
    exercise:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除 ID 列，因为这对于我们的模型构建练习不是必需的：
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We will now move on to explore our data and build our model.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进入探索数据和构建模型的过程。
- en: How to do it...
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We have performed various explorations on our data in the previous section.
    There is no limit to the ways in which we can explore our data. In this section,
    we are going to look at a few more techniques:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们对数据进行了各种探索。我们可以探索数据的方式没有限制。在本节中，我们将探讨一些更多技术：
- en: 'We check the correlation of each of our feature variables with the target variable:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查每个特征变量与目标变量的相关性：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following plot shows how each of the features is correlated with the target
    variable:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fac4a15a-c60d-4fca-9ae4-01edb2638f15.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
- en: 'We check the datatypes in the H2O DataFrame. Note that for the `pandas` DataFrame, we
    used `dtypes`. For the H2O DataFrame, we use types:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We notice that they are all of the integer datatype. We will convert them to
    factor type, which is categorical in nature:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We can check the datatypes with `hf_creditcarddata.types` to see that the datatype
    conversion has taken place.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'We will encode the binary target variable as a factor type variable:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We select the features and the `target` variable:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We now split the H2O DataFrame into training and testing subsets. We use 70%
    of our data for training the model and the remaining 30% for validation:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We build our random forest model with the default settings. You can check the
    model performance on the test data with the following commands:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This gives us the following performance metrics:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b237e8e-a899-4125-8590-a66ef4baa7a0.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
- en: How it works...
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Getting ready* section, we installed JRE and H2O. We initialized and
    connected to an H2O instance with `h2o.init()`. We then read our data using `pandas`
    and converted it to an H2O DataFrame. We used the `head()` and `describe()` methods
    on the H2O DataFrame, just like we used them on a `pandas` DataFrame. We then
    dropped the `ID` column from the H2O DataFrame.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: After we did these data explorations in the *Getting ready* section, we moved
    on to the next steps. In *Step 1,* we checked the correlation of each of the features
    with the `target` variable. In *Step 2*, we used the `h2o` DataFrame and checked
    the datatypes.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Note that for the `pandas` DataFrame we used `dtypes`, whereas we used `types`
    with the `h2o `DataFrame.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 3*, we used `asfactor()` to convert the numeric variables to the categorical
    type. We performed this on variables that were supposed to be of a categorical
    type but were appearing as numeric.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: In previous examples, we used the `astype()` method on a `pandas` DataFrame.
    With an H2O DataFrame, we used the `asfactor()` method.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 4*, we used `asfactor()` on our `target` variable to convert it to
    a categorical variable.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 5*, we separated our features and the `target` variable. In *Step*
    6, we split the H2O DataFrame into training and testing subsets using `split_frame()`
    on our H2O DataFrame. We used the `ratios` parameter and set it to `ratios=[0.7]`
    for `split_frame()` to allocate 70% of the data to the training set and 30% of
    the data to the testing set.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 7*, we imported `H2ORandomForestEstimator` from `h2o.estimators.random_forest`.
    We passed `model_id` and then referred to it to call the `train()` function and
    pass the predictor and the `target` variables. We then looked at the performance
    metrics by passing the test subset to `model_performance()`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our preceding example, we have an AUC of `0.76` and a log loss of `0.44`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'We can apply cross-validation by passing `nfolds` as a parameter to `H2ORandomForestEstimator()`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过将`nfolds`作为参数传递给`H2ORandomForestEstimator()`来应用交叉验证：
- en: '[PRE41]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We notice that the AUC has slightly improved to `0.77` and that the log loss
    has dropped to `0.43`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到AUC略有提高至`0.77`，而log损失降至`0.43`：
- en: '![](img/ee005306-9054-40e0-b54f-eb0931b04b2d.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ee005306-9054-40e0-b54f-eb0931b04b2d.png)'
- en: 'We can also apply a grid search to extract the best model from the given options.
    We set our options as follows:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以应用网格搜索来从给定选项中提取最佳模型。我们设置选项如下：
- en: '[PRE42]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We build the model with the preceding search parameters:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面的搜索参数构建模型：
- en: '[PRE43]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We now sort all models by AUC in a descending manner and then pick the first
    model, which has the highest AUC:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在按AUC降序对所有模型进行排序，然后选择第一个具有最高AUC的模型：
- en: '[PRE44]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We apply the best model for our test data:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应用最佳模型来测试我们的数据：
- en: '[PRE45]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can plot the variable importance from the best model that we have achieved
    so far:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以绘制到目前为止我们达到的最佳模型的变量重要性：
- en: '[PRE46]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This gives us the following plot:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下图表：
- en: '![](img/1014ef94-8e46-46df-af56-802e3ba9589f.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1014ef94-8e46-46df-af56-802e3ba9589f.png)'
- en: See also
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: You may want to look into extremely randomized trees, which have a slightly
    different implementation but can sometimes perform better than random forests.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想了解一下极随机树，它们的实现方式略有不同，但有时可能比随机森林表现得更好。
- en: In ensemble methods, each model learns differently in terms of the subset of
    the dataset and the subset of the feature vector used for training. These subsets
    are taken randomly. Extremely randomized trees possess a high randomness factor
    in the way they compute the splits and the subset of the features selected. Unlike
    random forests, in which the splitting threshold is chosen randomly, in extremely
    randomized trees, a discriminative threshold is used as the splitting rule. Due
    to this, the overall variance of the ensemble decreases and the overall performance
    may be better.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成方法中，每个模型在数据集的子集和用于训练的特征向量子集方面以不同的方式学习。这些子集是随机选取的。极随机树在计算分裂和选择特征子集的方式上具有很高的随机性因素。与随机森林不同，在随机森林中分裂阈值是随机选择的，而在极随机树中，使用判别阈值作为分裂规则。因此，集成整体的方差降低，整体性能可能更好。
- en: The scikit-learn implementation of extremely randomized trees can be found at
    the following link: [https://bit.ly/2zWsNNS](https://bit.ly/2zWsNNS)[. H2O also
    supports extremely randomized trees. ](https://bit.ly/2zWsNNS)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接中可以找到scikit-learn对极随机树的实现：[https://bit.ly/2zWsNNS](https://bit.ly/2zWsNNS)[.
    H2O也支持极随机树。](https://bit.ly/2zWsNNS)
