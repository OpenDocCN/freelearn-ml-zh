- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Diversity Issues in Synthetic Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduces you to a well-known issue in the field of synthetic
    data, which is generating diverse synthetic datasets. It discusses different approaches
    to ensure high diversity in large-scale datasets. Then, it highlights some issues
    and challenges in achieving diversity for synthetic data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The need for diverse data in ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating diverse synthetic datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diversity issues in the synthetic data realm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for diverse data in ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have discussed and seen in previous chapters, diverse training data improves
    the generalizability of ML models to new domains and contexts. In fact, diversity
    helps your ML-based solution to be more accurate and better applicable to real-world
    scenarios. Additionally, it makes it more robust to noise and anomalies, which
    are usually unavoidable in practice. For more information, please refer to *Diversity
    in Machine Learning* ([https://arxiv.org/abs/1807.01477](https://arxiv.org/abs/1807.01477))
    and *Performance of Machine Learning Algorithms and Diversity in* *Data* ([https://doi.org/10.1051/MATECCONF%2F201821004019](https://doi.org/10.1051/MATECCONF%2F201821004019)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s highlight some of the main advantages of using diverse training
    data in ML. In general, training and validating your ML model on diverse datasets
    improve the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Transferability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problem modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The process of debugging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robustness to anomalies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creativity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer satisfaction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s delve into each of these elements in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Transferability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you train your ML model on diverse data covering a variety of scenarios,
    contexts, and environments, you boost the transferability of your ML solution
    to other applications and domains. The reason for this is that when the model
    learns how to deal with more diverse situations in the training stage, it becomes
    more capable of adapting to new, unseen contexts. For more information, please
    refer to *Can Data Diversity Enhance Learning* *Generalization?* ([https://aclanthology.org/2022.coling-1.437](https://aclanthology.org/2022.coling-1.437)).
  prefs: []
  type: TYPE_NORMAL
- en: Better problem modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Diverse training data enables the ML model to look at the problem from different
    perspectives. For example, let’s consider that our ML model is learning a semantic
    segmentation task. Training the model under adverse weather conditions and with
    objects of various colors, textures, and shapes will help the model to better
    learn the mapping from the RGB images to the semantic segmentation ones. Thus,
    it will significantly enhance the performance as the model has already learned
    how to capture a wider range of patterns under various variations. These patterns
    and associations between input features and output labels may not be easily identified
    given a less diverse training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Research has recently shown that training your ML model on diverse training
    data can improve the robustness of your model to adversarial attacks. Thus, your
    model becomes even more reliable and secure with diverse training data. For example,
    training your ML model on a diverse set of adversarial training samples significantly
    boosts your ML model’s robustness to adversarial attacks. These attacks primarily
    involve manipulating images with noise to fool the ML model while still making
    them recognizable to the human eye. For instance, a slight change in some pixels’
    intensity such as the color of a traffic sign may cause ML models to wrongly classify
    it under a different class with a high confidence. For more information, please
    refer to *Diversity Adversarial Training against Adversarial Attack on Deep Neural
    Networks* ([http://www.mdpi.com/2073-8994/13/3/428](http://www.mdpi.com/2073-8994/13/3/428))
    and *Adversarial Attacks on Traffic Sign Recognition: A* *Survey* ([https://arxiv.org/pdf/2307.08278.pdf](https://arxiv.org/pdf/2307.08278.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: Process of debugging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Leveraging diverse data in the validation and evaluation stages helps ML practitioners
    identify the weaknesses and limitations of their ML models and algorithms. Thus,
    they can avoid costly failures under challenging scenarios. Furthermore, they
    can iterate on their solutions and mitigate any potential issues and problems.
    For instance, suppose we are proposing a new person identification ML model. To
    clearly understand the limitations of our model, we need to evaluate the model
    on diverse datasets that cover various illumination conditions, camera viewpoints,
    indoor and outdoor scenes, and other relevant attributes. This will help us to
    spot the weaknesses of our approach. By returning to our example, we may see that
    our model is struggling to identify people at nighttime or when the camera is
    very close to the person. This sort of observation is essential for improving
    the model and preventing costly failures, which cannot be achieved without using
    appropriate diverse validation or evaluation datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Robustness to anomalies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training your ML model on diverse training data that includes anomalies helps
    the model learn how to deal with similar situations. Thus, it makes your ML-based
    solution more robust against outliers and unexpected situations. For instance,
    let’s suppose you trained your ML model for depth estimation on standard data
    collected by an industry-standard sensor under normal conditions. Your model may
    fail if the camera sensor was partially damaged, or some dust or raindrops accumulated
    on the camera lens. Therefore, training your ML model on similar scenarios improves
    the robustness and reliability of your ML system. Please refer to *A Novel Cross-Perturbation
    for Single Domain Generalization* ([https://arxiv.org/pdf/2308.00918.pdf](https://arxiv.org/pdf/2308.00918.pdf))
    for more in-depth details.
  prefs: []
  type: TYPE_NORMAL
- en: Creativity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In problems where creativity is a key requirement, training generative models
    on diverse training data is necessary to fuel this need. For instance, an LLM
    or image generator will significantly benefit from being trained on textual or
    visual data collected from different sources. This will help these generative
    models to be exposed to various topics, styles, ideas, and opinions, which will
    provide sufficient knowledge and urge the model to be more creative at various
    tasks and applications. For some interesting examples, please refer to *Deep Dream
    Generator* ([https://deepdreamgenerator.com](https://deepdreamgenerator.com)),
    *AutoDraw* ([https://www.autodraw.com](https://www.autodraw.com)), *Stablecog*
    ([https://stablecog.com](https://stablecog.com)), and *DALL-E* *2* ([https://openai.com/dall-e-2](https://openai.com/dall-e-2)).
  prefs: []
  type: TYPE_NORMAL
- en: Inclusivity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying diverse training data that appropriately represents the real world
    helps customers to feel that your ML-based solution is inclusive and does not
    discriminate against any characteristics of the population worldwide. Therefore,
    it is essential to ensure that your ML model works as intended for all customers
    regardless of their age, race, gender, geography, language, and religion. If customers
    feel that they are disadvantaged because of any of the previous factors, they
    will develop a negative impression of your business, not just the application
    itself. Additionally, it may cause legal issues and unwanted consequences to organizations.
    On the other hand, it helps decision-makers to make more appropriate decisions
    that take into careful consideration the unique needs of each demographic group
    of the target audience.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the importance of training our ML models on diverse training
    data, let’s examine how to generate diverse synthetic data.
  prefs: []
  type: TYPE_NORMAL
- en: Generating diverse synthetic datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will learn different methods of generating diverse synthetic
    datasets. We will discuss the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Latent space variations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensemble synthetic data generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diversity regularization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporating external knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Progressive training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Procedural content generation with game engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latent space variations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Latent space usually refers to a high-dimensional space where the training data
    is represented in a more abstract or compact way. Deep learning with many layers
    is designed to make the features in the latent space capture more semantic and
    conceptual information. For more details, please refer to [*Chapter 1*](B18494_01.xhtml#_idTextAnchor014).
    Thus, these features, in that space, convey encoded information about the problem
    through the ML model during the training stage. We may not be able to directly
    link the changes in the latent space to the changes that will happen on the generated
    images in models such as GANs. However, it was shown in *Interpreting the Latent
    Space of GANs for Semantic Face Editing* ([https://arxiv.org/abs/1907.10786](https://arxiv.org/abs/1907.10786))
    and *Closed-Form Factorization of Latent Semantics in GANs* ([https://arxiv.org/abs/2007.06600](https://arxiv.org/abs/2007.06600))
    that changing certain attributes in the latent space can generate unique and diverse
    synthetic samples. For instance, if you carefully change certain features in the
    latent space, you may generate new samples with different poses, backgrounds,
    lighting, and weather conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble synthetic data generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the approaches that is usually deployed to improve the diversity of the
    generated synthetic data is using multiple generative models to ensure that they
    capture the intended data distribution. This is especially applicable if the distribution
    is complex and cannot be modeled using a single generative model. For more information,
    please refer to *Ensembles of GANs for Synthetic Training Data Generation* ([https://arxiv.org/pdf/2104.11797.pdf](https://arxiv.org/pdf/2104.11797.pdf)).
    In this work, multiple GANs were used to improve the generated synthetic data
    diversity. The researchers focused specifically on the effectiveness of this approach
    for synthesizing digital pathology patches. GANs were trained independently and
    in isolation from each other on the training dataset. This work shows that the
    stochasticity of the optimization process is fundamental to better represent the
    training data distribution and enrich the generated data diversity for GANs.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity regularization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another approach to encourage generative models to generate diverse synthetic
    samples is to utilize a regularization term in the training objective or loss.
    In other words, you can penalize the generative model for generating similar synthetic
    samples. Thus, your model will tend to generate more diverse samples to minimize
    the training loss. For example, this approach was utilized in *Mode Seeking Generative
    Adversarial Networks for Diverse Image Synthesis* ([https://arxiv.org/pdf/1903.05628.pdf](https://arxiv.org/pdf/1903.05628.pdf))
    to address the mode collapse issue in GANs and improve the diversity of the generated
    synthetic images. For more details about the mode collapse issue in GANs, please
    refer to [*Chapter 7*](B18494_07.xhtml#_idTextAnchor120). This approach does not
    require any modification to the architecture of the GAN. It simply changes the
    loss to encourage the generator to generate dissimilar images. Thus, the generator
    is urged to better cover the training data distribution and consequently generate
    more diverse synthetic images. For a survey of the regularization approaches in
    GANs, please refer to *A Systematic Survey of Regularization and Normalization
    in* *GANs* ([https://arxiv.org/abs/2008.08930](https://arxiv.org/abs/2008.08930)).
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating external knowledge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can also condition the generation process to encourage the generative models
    to generate synthetic data with certain attributes and under specific scenarios.
    For example, if your data has fewer training samples taken in rainy conditions,
    you can explicitly condition the GAN model to generate more examples under this
    weather condition. Additionally, you may prevent generative models from generating
    examples that are not relevant to your problem. For example, if you are generating
    cat images in an indoor environment, you may prevent your GAN from generating
    examples under adverse weather conditions as they are not valid in this particular
    environment. This can be achieved through various means, such as modifying the
    loss function to impose penalties on these irrelevant or unwanted predictions.
    In this scenario, the discriminator would need to make at least two distinct predictions:
    one for assessing whether the sample is real or fake and another for determining
    its relevance.'
  prefs: []
  type: TYPE_NORMAL
- en: Progressive training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another interesting approach to increase the diversity of the generated synthetic
    samples is to gradually introduce more complex patterns, add more layers to the
    generator and discriminator throughout the training process, and penalize for
    less diverse examples during the training stage. This encourages the synthetic
    data generation model to generate more diverse and variant data. For example,
    researchers in *Progressive Growing of GANs for Improved Quality, Stability, and
    Variation* ([https://arxiv.org/pdf/1710.10196.pdf](https://arxiv.org/pdf/1710.10196.pdf))
    showed that growing the generator and discriminator by adding new layers and training
    on more detailed and higher-resolution images as the training progresses significantly
    improves the stability of the training process of the GAN and the diversity of
    the generated synthetic images.
  prefs: []
  type: TYPE_NORMAL
- en: Procedural content generation with game engines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Procedural Content Generation** (**PCG**) is a widely used approach in video
    games to make the virtual world diverse and rich, resulting in a better player
    experience. The same concept can be utilized in game engines and simulators to
    create diverse 3D virtual worlds and thus generate diverse synthetic data. PCG
    can be utilized to generate textures, objects, maps, animations, and other scene
    elements. For a specific example, please refer to *ProcSy: Procedural Synthetic
    Dataset Generation Towards Influence Factor Studies Of Semantic Segmentation*
    *Networks* ([https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy](https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy)).'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have learned the main approaches usually utilized to improve the
    diversity of the generated synthetic data. Next, let’s learn the main issues and
    limitations of these approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity issues in the synthetic data realm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we have seen, diversity helps us to build robust, accurate, and general-purpose
    ML models. Additionally, we learned many approaches to improve synthetic data
    diversity in practice. In this section, we will examine three main issues we usually
    encounter when we try to generate diverse synthetic data:'
  prefs: []
  type: TYPE_NORMAL
- en: Balancing diversity and realism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Privacy and confidentiality concerns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validation and evaluation challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balancing diversity and realism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is usually a trade-off between diversity and realism. Generating diverse
    synthetic examples without considering the realism of these generated samples
    may introduce or increase the domain gap between synthetic and real domains. For
    more details, please refer to *Chapters 13* and *14*. For example, let’s suppose
    that we want to generate images with sports cars for a particular computer vision
    task or application. While it is crucial to generate diverse sports cars that
    cover most of the available real sports car samples in the real world, we do not
    want to generate sports cars that are unlikely to be observed in our problem context.
    Thus, our aim should always be to generate synthetic data that accurately represents
    the distribution in the real world. It should be diverse but also realistic to
    be useful for training and testing ML models in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy and confidentiality concerns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When generating synthetic data for applications that have restrictions on the
    real data because of privacy or confidentiality concerns, it becomes rather hard
    to generate diverse synthetic data. The reason behind this is the limited understanding
    of the attributes, patterns, and correlations of the real data, which cannot be
    learned by generative models given a small-scale training dataset. Thus, it becomes
    extremely hard for generative models to generate diverse synthetic data for such
    applications. Please refer to [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049)
    for an in-depth discussion about privacy issues with large-scale real datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Validation and evaluation challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the main issues in this area is assessing the diversity of the generated
    synthetic data, and thus the usability of this data in practice. Developing a
    robust, reliable, and universal diversity evaluation metric would be highly beneficial
    in practice. State-of-the-art metrics are usually problem dependent and experimental
    and lack the appropriate theoretical framework. For more information, please refer
    to *Reliable Fidelity and Diversity Metrics for Generative* *Models* ([https://arxiv.org/abs/2002.09797](https://arxiv.org/abs/2002.09797)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have discussed the main reasons why the diversity of data
    is crucial for ML-based solutions. We also examined the key approaches to generating
    diverse synthetic data. Then, we highlighted the main issues and challenges. In
    the next chapter, we will focus on another relevant and interesting issue in synthetic
    data, which is photorealism.
  prefs: []
  type: TYPE_NORMAL
