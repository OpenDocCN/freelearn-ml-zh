<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Encyclopedias and Neurons – Traveling Salesman Problem</h1>
                </header>
            
            <article>
                
<p>In this chapter we are going to solve one of the most famous of all problems for machine learners. We will also dive into the world of graph theory (just a bit) as well as neural network neurons. Let's start off by explaining the traveling salesman problem, shall we?</p>
<p>In this chapter we will cover:</p>
<ul>
<li>Traveling salesman problem</li>
<li>Learning rate parameter</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Traveling salesman problem</h1>
                </header>
            
            <article>
                
<p>We have a salesman who must travel between <em>n</em> cities. He doesn't care about which order this happens in, nor which city he visits first or last. His only concern is that he visits each city only once and finishes at home, where he started.</p>
<div class="packt_infobox">Each city is a node, and each node is connected to other close nodes by an edge (think of it like a road, plane, train, car, and so on).</div>
<p>Now, each of those connections has one or more weights associated with it, which we will call the <strong>cost</strong>.</p>
<div class="packt_infobox">The cost describes the difficulty of travel along that connection, such as the cost of the plane ticket, the amount of gas the car needs, and so on.</div>
<p>Our salesman has a boss as we met in <a href="7a1f2cca-1be5-426a-8e8a-6a4a3828cd76.xhtml" target="_blank">Chapter 1</a>, <em>Machine Learning Basics</em>, so his marching orders are to keep the cost and distance he travels as low as possible.</p>
<p><em>How does this apply to me in real life?</em> you may ask. This problem actually has several applications in real life such as</p>
<ul>
<li>The design and creation of circuit boards for your computer. With millions of transistors, the circuit board needs to be drilled and created precisely.</li>
<li>It also appears as a subproblem in DNA sequencing, which has become a big part of machine learning for many people.</li>
</ul>
<p>For those that have taken up or are familiar with graph theory, you hopefully remember the undirected weighted graph. That is exactly what we are dealing with here. The cities are vertices, the paths are edges, and the path distance is the edge weight. Never thought you'd use that knowledge again, did you? In essence, we have a minimization problem of starting and finishing at a specific vertex after having visited every other vertex just once. We may, in fact, end up with a complete graph when we are done, where each pair of vertices is connected by an edge.</p>
<p>Next, we must talk about asymmetry and symmetry, because this problem may end up being either. What do we mean exactly? Well, we have either an asymmetric traveling salesman problem or a symmetric traveling salesman problem. It all depends upon the distance between two cities. If the distances are the same in each direction, we have a symmetric traveling salesman problem, and the symmetry helps us have the possible solutions. If the paths do not exist in both directions, or if the distances are different, we have a directed graph. Here is a diagram showing the preceding description:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-599 image-border" src="assets/7ea1158d-5dd6-46d9-927a-3243696efbf9.png" style=""/></div>
<p>The traveling salesman problem can be symmetric or asymmetric. In this chapter, we are going to take you through the wonderful land of genetic algorithms. Let's start with an incredibly oversimplistic description of what's going to happen.</p>
<p>In the biology world, when we want to create a new genotype, we take a little bit from parent <strong>A</strong> and the rest from parent <strong>B</strong>. This is called crossover mutation, if you are updating your buzzword-compliant checklist! After this happens, these genotypes are perturbed, or altered, ever so slightly. This is called <strong>mutation</strong> (update that buzzword compliant list again), and this is how genetic material is created.</p>
<p>Next, we delete the original generation, replaced by the new one, and each genotype is tested. The newer genotypes, being the better part of their previous components, will now be skewed towards higher fitness; on an average, this generation should score higher than its predecessor.</p>
<p>This process continues for many generations, and over time, the average fitness of the population will evolve and increase. This doesn't always work, as in real life, but generally speaking, it does.</p>
<p>With a seminar of genetic algorithmic programming behind us, let's dive into our application.</p>
<p>Here's what our sample application looks like. It is based on the Accord.NET framework. After we've defined the number of houses we need to visit, we simply click on the <span class="packt_screen">Generate</span> button:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-600 image-border" src="assets/5852916c-ce94-4bba-adb9-ff2010210271.png" style=""/></div>
<p>In our test application, we can change the number of houses that we want to visit very easily, as shown in the highlighted area.</p>
<p>We could have a very simple problem space or a more complicated one. Here is an example of a very simple problem space:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-601 image-border" src="assets/11f8c269-cfe9-4e8c-8c1a-30b2f450db74.png" style=""/></div>
<p>And here is an example of a more complicated problem space:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-602 image-border" src="assets/f22d22ab-aa44-4951-82b8-13f4631562b3.png" style=""/></div>
<p>We also have three different types of selection methods for our algorithm to work with, namely <span class="packt_screen">Elite</span>, <span class="packt_screen">Rank</span>, and <span class="packt_screen">Roulette</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-603 image-border" src="assets/ab140719-461c-4cf3-b830-d2be1935a592.png" style=""/></div>
<ul>
<li><span class="packt_screen">Elite</span>: Specifies the number of best chromosomes to work within the next generation.</li>
<li><span class="packt_screen">Roulette</span>: Selects chromosomes based on their rank (fitness value).</li>
<li><span class="packt_screen">Rank</span>: Selects chromosomes based on their rank (fitness value). This differs from the <span class="packt_screen">Roulette</span> selection method in that the wheel and sector sizes are different within the calculation.</li>
</ul>
<p>Finally, we choose the total number of iterations we want our algorithm to use. We select the <span class="packt_screen">Calculate Route</span> button, and, assuming all goes well, we'll end up with our map looking similar to this:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-604 image-border" src="assets/b913e5cd-325a-4d20-a531-77f68c56c7de.png" style=""/></div>
<p>Let's take a look at what happens when we select the number of cities we want and then click on the <span class="packt_screen">Generate</span> button:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">        private void GenerateMap( )<br/>         {<br/>             Random rand = new Random( (int) DateTime.Now.Ticks );<br/> <br/>             // create coordinates array<br/>             map = new double[citiesCount, 2];<br/> <br/>             for ( int i = 0; i &lt; citiesCount; i++ )<br/>             {<br/>                 map[i, 0] = rand.Next( 1001 );<br/>                 map[i, 1] = rand.Next( 1001 );<br/>             }<br/> <br/>             // set the map<br/>             mapControl.UpdateDataSeries( "map", map );<br/>             // erase path if it is<br/>             mapControl.UpdateDataSeries( "path", null );<br/>         }</pre>
<p>The first thing that we do is initialize our random number generator and seed it. Next, we get the total number of cities that the user specified, and then create a new array from that. Finally, we plot each point and update our map. The map is a chart control from Accord.NET that will take care of a lot of visual plotting for us.</p>
<p>With that done, we are ready to calculate our route and (hopefully) solve our problem.</p>
<p>Next, let's see what our main search solution looks like:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">            Neuron.RandRange = new Range( 0, 1000 );<br/>             DistanceNetwork network = new DistanceNetwork( 2, neurons );<br/>             ElasticNetworkLearning    trainer = new ElasticNetworkLearning(<br/> network );<br/>             double    fixedLearningRate = learningRate / 20;<br/>             double    driftingLearningRate = fixedLearningRate * 19;<br/>             double[,] path = new double[neurons + 1, 2];<br/>             double[] input = new double[2];<br/>             int i = 0;<br/> <br/>             while ( !needToStop )<br/>             {<br/>                 trainer.LearningRate = driftingLearningRate * ( iterations - i ) / iterations + fixedLearningRate;<br/>                 trainer.LearningRadius = learningRadius * ( iterations - i ) / iterations;<br/> <br/>                 int currentCity = rand.Next( citiesCount );<br/>                 input[0] = map[currentCity, 0];<br/>                 input[1] = map[currentCity, 1];<br/> <br/>                 trainer.Run( input );<br/> <br/>                 for ( int j = 0; j &lt; neurons; j++ )<br/>                 {<br/>                     path[j, 0] = network.Layers[0].Neurons[j].Weights[0];<br/>                     path[j, 1] = network.Layers[0].Neurons[j].Weights[1];<br/>                 }<br/>                 path[neurons, 0] = network.Layers[0].Neurons[0].Weights[0];<br/>                 path[neurons, 1] = network.Layers[0].Neurons[0].Weights[1];<br/> <br/>                 chart?.UpdateDataSeries( "path", path );<br/>                 i++;<br/> <br/>                 SetText( currentIterationBox, i.ToString( ) );<br/> <br/>                 if ( i &gt;= iterations )<br/>                     break;<br/>            }</pre>
<p>Let's try and break all that down into more usable chunks for you. The first thing we do is determine the selection method that we'll use to rank our chromosomes:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">// create fitness function<br/> TSPFitnessFunction fitnessFunction = new TSPFitnessFunction( map );<br/> // create population<br/> Population population = new Population( populationSize,<br/>     ( greedyCrossover ) ? new TSPChromosome( map ) : new PermutationChromosome( citiesCount ),<br/>     fitnessFunction,<br/>     ( selectionMethod == 0 ) ? (ISelectionMethod) new EliteSelection( ) :<br/>     ( selectionMethod == 1 ) ? (ISelectionMethod) new RankSelection( ) :<br/>     (ISelectionMethod) new RouletteWheelSelection( ));</pre>
<p>I want to take this opportunity to point out the <kbd>TSPChromosome</kbd> you see here. This object is based on a short-array chromosome (one that is an array of unsigned short values ranging from 2 to 65,536. There are two specific features:</p>
<ul>
<li>All genes are unique within the chromosome, meaning there are no two genes with the same value</li>
<li>The maximum value of each gene is equal to the chromosome length minus 1</li>
</ul>
<p>Next, we must create the path variable for us to fill in with our data points:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">double[,] path = new double[citiesCount + 1, 2];</pre>
<p>After this is complete, we can enter our <kbd>while</kbd> loop and begin our processing. To do that, we will process a single generation by running a single epoch. You can think of an epoch as an iteration:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">                // run one epoch of genetic algorithm<br/>                 RILogManager.Default?.SendDebug("Running Epoch " + i);<br/>                 population.RunEpoch( );</pre>
<p>We then get the best values from that effort:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">ushort[] bestValue = ((PermutationChromosome) population.BestChromosome).Value;</pre>
<p>We update and create our path between each city:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">for ( int j = 0; j &lt; citiesCount; j++ )<br/>                 {<br/>                     path[j, 0] = map[bestValue[j], 0];<br/>                     path[j, 1] = map[bestValue[j], 1];<br/>                 }<br/>                 path[citiesCount, 0] = map[bestValue[0], 0];<br/>                 path[citiesCount, 1] = map[bestValue[0], 1];</pre>
<p>And we supply that value to our chart control:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">mapControl.UpdateDataSeries( "path", path );</pre>
<p>Let's see some examples of what our route might look like based on the selection method that we choose.</p>
<p>The <span class="packt_screen">Elite</span> selection:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-605 image-border" src="assets/97c489e9-78a5-4c48-b6c3-a16089603056.png" style=""/></div>
<p>The <span class="packt_screen">Rank</span> selection:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-606 image-border" src="assets/3f3947c7-7cce-46f5-b247-12539e267f3c.png" style=""/></div>
<p>The difference between this and the <span class="packt_screen">Roulette</span> selection method is in the wheel and its sector size calculation methods. The size of the wheel equals <em>size * (size +1) / 2</em>, where <em>size</em> is the size of the current population. The worst chromosome has its sector size equal to 1, the next has a size of 2, and so on.</p>
<p><span class="packt_screen">The Roulette</span> selection:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-608 image-border" src="assets/9f9e0630-f82a-4842-a908-bf94bb5fbcb1.png" style=""/></div>
<p>This algorithm selects chromosomes of the new generation according to their fitness values. The higher the value, the greater the chances of it becoming a member of the new generation.</p>
<p>What you will notice as you generate your routes is that the <span class="packt_screen">Elite</span> method finds its solution right away. The <span class="packt_screen">Rank</span> method continues refining its route throughout the iterations, and the <span class="packt_screen">Roulette</span> method refines its routes even more.</p>
<p>To illustrate what I mean, define a huge load for your salesman today. Let's say he has 200 houses to visit, as we need to sell a lot of encyclopedias today. This is where the beauty of our algorithm shines. It's easy to create the optimal map and route if we are dealing with five houses. But if we are dealing with 200 houses, not so much!</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-609 image-border" src="assets/67bf4408-40f4-424e-824c-84f4a98aca18.png" style=""/></div>
<p>Now that we've solved our problem, let's see if we can apply what we learned from our earlier chapter about <strong>self-organizing maps</strong> (<strong>SOM</strong>) here to approach this problem from a different angle. If you recall, back in <a href="01438011-1511-48a3-af59-1d6451a3128e.xhtml" target="_blank">Chapter 6</a>, <em>Color Blending – Self-Organizing Maps and Elastic Neural Networks</em>, we discussed SOM in general. So we'll preclude the academia from happening here! We're going to use a technique called Elastic Network Training, which is a great unsupervised approach to such a problem as we have here.</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-610 image-border" src="assets/d7c46099-1bea-474c-ba05-f411d6e93957.png" style=""/></div>
<p>Let's first talk briefly about what an <strong>Elastic Map</strong> is. Elastic Maps provide a tool for creating nonlinear dimensionality reduction. They are a system of elastic springs in our data space that approximate a low-dimensional manifold. With this capability, we can go from completely unstructured clustering (no elasticity) to a closer linear principal components analysis manifold for high bending/low stretching of the springs. You'll see when using our sample application that the lines are not necessarily as rigid as they were in our previous solution. And in many cases, they may not even get into the center of the city we are visiting (the line generates off the center) but approach only the outskirts of the city limits, as in the preceding example!</p>
<p>Once again, we'll be dealing with neurons, one of my favorite objects of all. This time we'll have a bit more control though, by being able to specify our learning rate and radius. As with our previous example, we'll be able to specify the total number of cities our salesman must visit today. Let's go easier on him this time though!</p>
<p>To start, we'll visit 50 cities and use a learning rate of <kbd>0.3</kbd> and radius of <kbd>0.75</kbd>. Finally, we will run for 50,000 iterations (don't worry; this will go fast). Our output will look like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/41121417-820a-4800-87e1-686bd0f6d353.png" style=""/></div>
<p> </p>
<p> </p>
<p>Now, what happens if we change our radius to a different value, say, <span class="packt_screen">0.25</span>? Note how our angles between some cities become more pronounced:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-612 image-border" src="assets/0b891719-fb9b-43b8-8b1d-fbe52275dafe.png" style=""/></div>
<p>Next, let's change our learning rate from <span class="packt_screen">0.3</span> to <span class="packt_screen">0.75</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-614 image-border" src="assets/35e19e73-4025-40fc-8e21-82c8d0c333af.png" style=""/></div>
<p>Even though our route looks very similar in the end, there is one important difference. In the previous example, the route path for our salesman was not drawn until all the iterations were complete. By raising the learning rate, the route gets drawn several times before the perfect route is complete. Here are some images showing the progression:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-616 image-border" src="assets/785cc6e2-d233-47ce-9176-2a1edf306085.png" style=""/></div>
<p class="mce-root CDPAlignLeft CDPAlign">Here we are at iteration <span class="packt_screen">5777</span> of our solution:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-620 image-border" src="assets/08874e3a-19a4-4bdc-b944-43b3bfc5abc9.png" style=""/></div>
<p class="mce-root CDPAlignLeft CDPAlign">This shows how our solution looks at iteration <span class="packt_screen">44636</span>:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-622 image-border" src="assets/09a4e84c-51e5-479f-b3dc-7289dd36ce4f.png" style=""/></div>
<p class="mce-root CDPAlignLeft CDPAlign">This one shows how our solution looks at iteration <span class="packt_screen">34299</span>:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-624 image-border" src="assets/7dc9b79e-c1b5-48a1-b58f-3b9da4438abb.png" style=""/></div>
<p class="mce-root">Now, let's look into a small bit of code to see how our search solution differs this time:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">            // create fitness function<br/>             TSPFitnessFunction fitnessFunction = new TSPFitnessFunction( map );<br/>             // create population<br/>             Population population = new Population( populationSize,<br/>                 ( greedyCrossover ) ? new TSPChromosome( map ) : new PermutationChromosome( citiesCount ),<br/>                 fitnessFunction, ( selectionMethod == 0 ) ? new EliteSelection( )<br/>                 : ( selectionMethod == 1 ) ? new RankSelection( ) :<br/>                 (ISelectionMethod) new RouletteWheelSelection( ));<br/>             // iterations<br/>             int i = 1;<br/> <br/>             // path<br/>             double[,] path = new double[citiesCount + 1, 2];<br/> <br/>             // loop<br/>             while ( !needToStop )<br/>             {<br/>                 // run one epoch of genetic algorithm<br/>                 RILogManager.Default?.SendDebug("Running Epoch " + i);<br/>                 population.RunEpoch( );<br/> <br/>                 // display current path<br/>                 ushort[] bestValue = ((PermutationChromosome) population.BestChromosome).Value;<br/> <br/>                 for ( int j = 0; j &lt; citiesCount; j++ )<br/>                 {<br/>                     path[j, 0] = map[bestValue[j], 0];<br/>                     path[j, 1] = map[bestValue[j], 1];<br/>                 }<br/>                 path[citiesCount, 0] = map[bestValue[0], 0];<br/>                 path[citiesCount, 1] = map[bestValue[0], 1];<br/> <br/>                 mapControl.UpdateDataSeries( "path", path );<br/> </pre>
<pre class="mce-root CDPAlignLeft CDPAlign">                 // set current iteration's info<br/>                 SetText( currentIterationBox, i.ToString( ) );<br/>                 SetText( pathLengthBox, fitnessFunction.PathLength( population.BestChromosome ).ToString( ) );<br/> <br/>                 // increase current iteration<br/>                 i++;<br/> <br/>                 //<br/>                 if ( ( iterations != 0 ) &amp;&amp; ( i &gt; iterations ) )<br/>                     break;<br/>             }</pre>
<p>The first thing you see that we've done is creating a <kbd>DistanceNetwork</kbd> object. This object contains only a single <kbd>DistanceLayer</kbd>, which is a single layer of distance neurons. A distance neuron computes its output as the distance between its weights and inputs—the sum of absolute differences between the weight values and input values. All of this together makes up our SOM and, more importantly, our Elastic Network.</p>
<p>Next, we have to initialize our network with some random weights. We will do this by creating a <strong>uniform continuous distribution</strong> for each neuron. A uniform continuous distribution, or rectangular distribution, is a symmetric probability distribution such that, for each member of the family, all intervals of the same length on the distribution's support have the same probability. You will usually see this written out as U(<em>a</em>, <em>b</em>), with parameters <em>a</em> and <em>b</em> being the minimum and maximum values respectively.</p>
<pre class="mce-root">foreach (var neuron in network.Layers.SelectMany(layer =&gt; layer?.Neurons).Where(neuron =&gt; neuron != null))<br/> {<br/>                 neuron.RandGenerator = new UniformContinuousDistribution(new Range(0, 1000));<br/> }</pre>
<p class="mce-root">Next, we create our elastic learner object, which allows us to train our distance network:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">            ElasticNetworkLearning trainer = new ElasticNetworkLearning(network);</pre>
<p>Here's what the <kbd>ElasticNetworkLearning</kbd> constructor looks like internally:</p>
<div class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-630 image-border" src="assets/945ba172-7ba3-4692-8100-e0f4148b24b7.png" style=""/></div>
<p>Now we calculate our learning rate and radius:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">            double fixedLearningRate = learningRate / 20;<br/>             double driftingLearningRate = fixedLearningRate * 19;</pre>
<p>Finally, we are in our central processing loop, where we will remain until told to stop:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">while (!needToStop)<br/>             {<br/>                 // update learning speed &amp; radius<br/>                 trainer.LearningRate = driftingLearningRate * (iterations - i) / iterations + fixedLearningRate;<br/>                 trainer.LearningRadius = learningRadius * (iterations - i) / iterations;<br/> <br/>                 // set network input<br/>                 int currentCity = rand.Next(citiesCount);<br/>                 input[0] = map[currentCity, 0];<br/>                 input[1] = map[currentCity, 1];<br/> <br/>                 // run one training iteration<br/>                 trainer.Run(input);<br/> <br/>                 // show current path<br/>                 for (int j = 0; j &lt; neurons; j++)<br/>                 {<br/>                     path[j, 0] = network.Layers[0].Neurons[j].Weights[0];<br/>                     path[j, 1] = network.Layers[0].Neurons[j].Weights[1];<br/>                 }<br/>                 path[neurons, 0] = network.Layers[0].Neurons[0].Weights[0];<br/>                 path[neurons, 1] = network.Layers[0].Neurons[0].Weights[1];<br/> <br/>                 chart.UpdateDataSeries("path", path);<br/> <br/>                 i++;<br/> <br/>                 SetText(currentIterationBox, i.ToString());<br/> <br/>                 if (i &gt;= iterations)<br/>                     break;<br/>             }</pre>
<p>In the preceding loop, the trainer is running one epoch (iteration) per loop increment. Here's what the <kbd>trainer.Run</kbd> function looks like, so you can see what's happening. Basically, the method finds the winning neuron (the one that has the weights with values closest to the specified input vector). It then updates its weights as well as the weights of the neighboring neurons:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">public double Run( double[] input )<br/>         {<br/>             double error = 0.0;<br/> <br/>             // compute the network<br/>             network.Compute( input );<br/>             int winner = network.GetWinner( );<br/> <br/>             // get layer of the network<br/>             Layer layer = network.Layers[0];<br/> <br/>             // walk through all neurons of the layer<br/>             for ( int j = 0; j &lt; layer.Neurons.Length; j++ )<br/>             {<br/>                 Neuron neuron = layer.Neurons[j];<br/> <br/>                 // update factor<br/>                 double factor = Math.Exp( -distance[Math.Abs( j - winner )] / squaredRadius2 );<br/> <br/>                 // update weights of the neuron<br/>                 for ( int i = 0; i &lt; neuron.Weights.Length; i++ )<br/>                 {<br/>                     // calculate the error<br/>                     double e = ( input[i] - neuron.Weights[i] ) * factor;<br/>                     error += Math.Abs( e );<br/>                     // update weight<br/>                     neuron.Weights[i] += e * learningRate;<br/>                 }<br/>             }<br/>             return error;<br/>         }</pre>
<p>The two main functions of this method that we will look deeper into are computing the network and obtaining the winner (highlighted items).</p>
<p>How do we compute the network? Basically, we work ourselves down through the distance layer and into each neuron in order to update the weights correctly, similar to what you see here:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">public virtual double[] Compute( double[] input )<br/>         {<br/>             // local variable to avoid mutlithread conflicts<br/>             double[] output = input;<br/> <br/>             // compute each layer<br/>             for ( int i = 0; i &lt; layers.Length; i++ )<br/>             {<br/>                 output = layers[i].Compute( output );<br/>             }<br/> <br/>             // assign output property as well (works correctly for single threaded usage)<br/>             this.output = output;<br/> <br/>             return output;<br/>         }</pre>
<p>Finally, we need to compute the winner, the neuron with the minimum weight and therefore the minimum distance:</p>
<pre class="mce-root CDPAlignLeft CDPAlign">public int GetWinner( )<br/>         {<br/>             // find the MIN value<br/>             double min = output[0];<br/>             int    minIndex = 0;<br/> <br/>             for ( int i = 1; i &lt; output.Length; i++ )<br/>             {<br/>                 if ( output[i] &lt; min )<br/>                 {<br/>                     // found new MIN value<br/>                     min = output[i];<br/>                     minIndex = i;<br/>                 }<br/>             }<br/> <br/>             return minIndex;<br/>         }</pre>
<p>Let's talk briefly about the parameters you can enter on the screen.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning rate parameter</h1>
                </header>
            
            <article>
                
<p>The learning rate is a parameter that determines the speed of learning. More formally, it determines <span class="markup--quote markup--p-quote is-other">how much we are adjusting the weights of our network with respect to the loss gradient</span>. If it is too low, we travel <span>slower </span>down our slope. Even though we desire to have a low learning rate, it could mean that we'll be taking a long time to reach convergence. The learning rate also affects how quickly our model can converge tolocal minima (best accuracy).</p>
<p>When dealing with neurons, it determines the acquisition time (the amount of time it takes for a response to a new experience to be learned) for neurons with weights being used for training.</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0dd70be0-c08f-44a6-8af2-60d03935a5d8.png" style=""/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">Effect of various learning rates on convergence (image credit: <a href="http://cs231n.github.io/neural-networks-3/" target="_blank">cs231n</a>)</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Learning radius</h1>
                </header>
            
            <article>
                
<p>The learning radius determines the number of neurons to be updated around the winning neuron. Any neuron that is in the circle of the radius will be updated during the learning process. The closer the neuron, the more updates that are happening. The farther away, the fewer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned about neurons, which is an incredibly fascinating branch of research, focused on heavily for several years. We also learned about the famous traveling salesman problem, what it is, and how we can solve it with a computer. This little example has wide-reaching applications in the real world. In our next chapter, we are going to put all this neural knowledge we have gained and apply it to <strong>Restricted Boltzmann Machines</strong> (<strong>RBM</strong>) with a <strong>Deep Belief Network</strong> (<strong>DBN</strong>). This chapter will be sure to add a lot of terminology to your buzzword-compliant checklist! In the next chapter, we will answer the question that we all, as developers, face: <em>Should I take the job?</em></p>


            </article>

            
        </section>
    </body></html>