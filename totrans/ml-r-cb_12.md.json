["```py\n    $ yum install R R-core R-core-devel R-devel\n\n    ```", "```py\n    $ sudo R\n\n    ```", "```py\n    > install.packages(c(\"codetools\", \"Rcpp\", \"RJSONIO\", \"bitops\", \"digest\", \"functional\", \"stringr\", \"plyr\", \"reshape2\", \"rJava\", \"caTools\"))\n\n    ```", "```py\n    > q()\n\n    ```", "```py\n    $ wget --no-check-certificate https://raw.githubusercontent.com/RevolutionAnalytics/rmr2/3.3.0/build/rmr2_3.3.0.tar.gz\n\n    ```", "```py\n    $ sudo R CMD INSTALL rmr2_3.3.0.tar.gz\n\n    ```", "```py\n    $ R\n    > library(rmr2)\n\n    ```", "```py\n    $wget --no-check-certificate https://raw.github.com/RevolutionAnalytics/rhdfs/master/build/rhdfs_1.0.8.tar.gz\n\n    ```", "```py\n    $ sudo HADOOP_CMD=/usr/bin/hadoop  R CMD INSTALL rhdfs_1.0.8.tar.gz\n\n    ```", "```py\n    $ sudo JAVA_HOME=/usr/java/jdk1.7.0_67-cloudera R CMD javareconf\n\n    ```", "```py\n    $ R\n    > Sys.setenv(HADOOP_CMD=\"/usr/bin/hadoop\")\n    > Sys.setenv(HADOOP_STREAMING=\"/usr/lib/hadoop-mapreduce/hadoop-\n    streaming-2.5.0-cdh5.2.0.jar\")\n    > library(rhdfs)\n    > hdfs.init()\n\n    ```", "```py\n    $ sudo updatedb\n    $ locate streaming | grep jar | more\n\n    ```", "```py\n    > Sys.setenv(HADOOP_CMD=\"/usr/bin/hadoop\")\n    > Sys.setenv(HADOOP_STREAMING=\"/usr/lib/hadoop-mapreduce/hadoop-streaming-2.5.0-cdh5.2.0.jar\")\n    > library(rhdfs)\n    > hdfs.init ()\n\n    ```", "```py\n        > hdfs.put('word.txt', './')\n\n        ```", "```py\n        > hdfs.ls('./')\n\n        ```", "```py\n        > hdfs.copy('word.txt', 'wordcnt.txt')\n\n        ```", "```py\n        > hdfs.move('wordcnt.txt', './data/wordcnt.txt')\n\n        ```", "```py\n        > hdfs.delete('./data/')\n\n        ```", "```py\n        > hdfs.rm('./data/')\n\n        ```", "```py\n        > hdfs.get(word.txt', '/home/cloudera/word.txt')\n\n        ```", "```py\n        hdfs.rename('./test/q1.txt','./test/test.txt')\n\n        ```", "```py\n        > hdfs.chmod('test', permissions= '777')\n\n        ```", "```py\n        > hdfs.file.info('./')\n\n        ```", "```py\n    > f = hdfs.file(\"iris.txt\",\"w\")\n    > data(iris)\n    > hdfs.write(iris,f)\n    > hdfs.close(f)\n\n    ```", "```py\n    > f = hdfs.file(\"iris.txt\", \"r\")\n    > dfserialized = hdfs.read(f)\n    > df = unserialize(dfserialized)\n    > df\n    > hdfs.close(f)\n\n    ```", "```py\n    > Sys.setenv(HADOOP_CMD=\"/usr/bin/hadoop\")\n    > Sys.setenv(HADOOP_STREAMING=\"/usr/lib/hadoop-mapreduce/hadoop-streaming-2.5.0-cdh5.2.0.jar \")\n    > library(rmr2)\n    > library(rhdfs)\n    > hdfs.init()\n\n    ```", "```py\n    > hdfs.mkdir(\"/user/cloudera/wordcount/data\")\n    > hdfs.put(\"wc_input.txt\", \"/user/cloudera/wordcount/data\")\n\n    ```", "```py\n    > map = function(.,lines) { keyval(\n    +   unlist(\n    +     strsplit(\n    +       x = lines, \n    +       split = \" +\")),\n    +   1)}\n\n    ```", "```py\n    > reduce = function(word, counts) { \n    +   keyval(word, sum(counts)) \n    + }\n\n    ```", "```py\n    > hdfs.root = 'wordcount' > hdfs.data = file.path(hdfs.root, 'data')\n    > hdfs.out = file.path(hdfs.root, 'out')\n    > wordcount = function (input, output=NULL) { \n    +  mapreduce(input=input, output=output, input.format=\"text\", map=map, \n    +  reduce=reduce) \n    + } \n    > out = wordcount(hdfs.data, hdfs.out)\n\n    ```", "```py\n    > results = from.dfs(out) \n    > results$key[order(results$val, decreasing = TRUE)][1:10]\n\n    ```", "```py\n    > a.time = proc.time() \n    > small.ints2=1:100000 \n    > result.normal = sapply(small.ints2, function(x) x^2) \n    > proc.time() - a.time\n\n    ```", "```py\n    > b.time = proc.time() \n    > small.ints= to.dfs(1:100000) \n    > result = mapreduce(input = small.ints, map = function(k,v)       cbind(v,v^2)) \n    > proc.time() - b.time\n\n    ```", "```py\n    $ hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-test.jar mrbench -numRuns 50\n\n    ```", "```py\n    > rmr.options(backend = 'local')\n\n    ```", "```py\n    > b.time = proc.time() \n    > small.ints= to.dfs(1:100000) \n    > result = mapreduce(input = small.ints, map = function(k,v)       cbind(v,v^2)) \n    > proc.time() - b.time\n\n    ```", "```py\n    > out = mapreduce(to.dfs(1), map = function(k, v) rmr.str(v))\n    Dotted pair list of 14\n     $ : language mapreduce(to.dfs(1), map = function(k, v) rmr.str(v))\n     $ : language mr(map = map, reduce = reduce, combine = combine, vectorized.reduce, in.folder = if (is.list(input)) {     lapply(input, to.dfs.path) ...\n     $ : language c.keyval(do.call(c, lapply(in.folder, function(fname) {     kv = get.data(fname) ...\n     $ : language do.call(c, lapply(in.folder, function(fname) {     kv = get.data(fname) ...\n     $ : language lapply(in.folder, function(fname) {     kv = get.data(fname) ...\n     $ : language FUN(\"/tmp/Rtmp813BFJ/file25af6e85cfde\"[[1L]], ...)\n     $ : language unname(tapply(1:lkv, ceiling((1:lkv)/(lkv/(object.size(kv)/10^6))), function(r) {     kvr = slice.keyval(kv, r) ...\n     $ : language tapply(1:lkv, ceiling((1:lkv)/(lkv/(object.size(kv)/10^6))), function(r) {     kvr = slice.keyval(kv, r) ...\n     $ : language lapply(X = split(X, group), FUN = FUN, ...)\n     $ : language FUN(X[[1L]], ...)\n     $ : language as.keyval(map(keys(kvr), values(kvr)))\n     $ : language is.keyval(x)\n     $ : language map(keys(kvr), values(kvr))\n     $ :length 2 rmr.str(v)\n     ..- attr(*, \"srcref\")=Class 'srcref'  atomic [1:8] 1 34 1 58 34 58 1 1\n     .. .. ..- attr(*, \"srcfile\")=Classes 'srcfilecopy', 'srcfile' <environment: 0x3f984f0> \n    v\n     num 1\n\n    ```", "```py\n    > help(rmr.options)\n\n    ```", "```py\n    $ yum install libxml2-devel\n    $ sudo yum install curl-devel\n\n    ```", "```py\n    $ sudo R\n    > Install.packages(c(\" Rcurl\", \"httr\"),  dependencies = TRUE\n    > Install.packages(\"devtools\", dependencies = TRUE)\n    > library(devtools)\n    > install_github(\"pryr\", \"hadley\")\n    > install.packages(c(\" R.methodsS3\", \"hydroPSO\"),  dependencies = TRUE)\n    > q()\n\n    ```", "```py\n    $ wget -no-check-certificate https://raw.github.com/RevolutionAnalytics/plyrmr/master/build/plyrmr_0.5.0.tar.gz\n    $ sudo R CMD INSTALL plyrmr_0.5.0.tar.gz\n\n    ```", "```py\n    $ R\n    > library(plyrmr)\n\n    ```", "```py\n    > help(package=plyrmr) \n\n    ```", "```py\n    > library(rmr2)\n    > library(plyrmr)\n\n    ```", "```py\n    > plyrmr.options(backend=\"local\")\n\n    ```", "```py\n    > data(Titanic)\n    > titanic = data.frame(Titanic)\n\n    ```", "```py\n    > where(\n    +    Titanic, \n    + Freq >=100)\n\n    ```", "```py\n    > titanic %|% where(Freq >=100)\n\n    ```", "```py\n    > tidata = to.dfs(data.frame(Titanic), output = '/tmp/titanic')\n    > tidata\n\n    ```", "```py\n    > input(tidata) %|% transmute(sum(Freq))\n\n    ```", "```py\n    > input(tidata) %|% group(Sex) %|% transmute(sum(Freq))\n\n    ```", "```py\n    > sample(input(tidata), n=10)\n\n    ```", "```py\n    > convert_tb = data.frame(Label=c(\"No\",\"Yes\"), Symbol=c(0,1))\n    ctb = to.dfs(convert_tb, output = 'convert')\n    > as.data.frame(plyrmr::merge(input(tidata), input(ctb), by.x=\"Survived\", by.y=\"Label\"))\n    > file.remove('convert')\n\n    ```", "```py\n    > library(MASS)\n    > data(cats)\n    > X = matrix(cats$Bwt)\n    > y = matrix(cats$Hwt)\n\n    ```", "```py\n    > model = lm(y~X)\n    > summary(model)\n\n    Call:\n    lm(formula = y ~ X)\n\n    Residuals:\n     Min      1Q  Median      3Q     Max \n    -3.5694 -0.9634 -0.0921  1.0426  5.1238 \n\n    Coefficients:\n     Estimate Std. Error t value Pr(>|t|) \n    (Intercept)  -0.3567     0.6923  -0.515    0.607 \n    X             4.0341     0.2503  16.119   <2e-16 ***\n    ---\n    Signif. codes: \n    0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    Residual standard error: 1.452 on 142 degrees of freedom\n    Multiple R-squared:  0.6466,  Adjusted R-squared:  0.6441 \n    F-statistic: 259.8 on 1 and 142 DF,  p-value: < 2.2e-16\n\n    ```", "```py\n    > plot(y~X)\n    > abline(model, col=\"red\")\n\n    ```", "```py\n    > Sys.setenv(HADOOP_CMD=\"/usr/bin/hadoop\")\n    > Sys.setenv(HADOOP_STREAMING=\"/usr/lib/hadoop-mapreduce/hadoop-> streaming-2.5.0-cdh5.2.0.jar\")\n    > library(rmr2)\n    > rmr.options(backend=\"local\")\n\n    ```", "```py\n    > X = matrix(cats$Bwt)\n    > X.index = to.dfs(cbind(1:nrow(X), X))\n    > y = as.matrix(cats$Hwt)\n\n    ```", "```py\n    > Sum = \n    +   function(., YY) \n    +     keyval(1, list(Reduce('+', YY)))\n\n    ```", "```py\n    > XtX = \n    +    values(\n    +      from.dfs(\n    +        mapreduce(\n    +          input = X.index,\n    +          map = \n    +            function(., Xi) {\n    +              Xi = Xi[,-1]\n    +              keyval(1, list(t(Xi) %*% Xi))},\n    +          reduce = Sum,\n    +          combine = TRUE)))[[1]]\n\n    ```", "```py\n    Xty = \n    +    values(\n    +      from.dfs(\n    +        mapreduce(\n    +          input = X.index,\n    +          map = function(., Xi) {\n    +            yi = y[Xi[,1],]\n    +            Xi = Xi[,-1]\n    +            keyval(1, list(t(Xi) %*% yi))},\n    +          reduce = Sum,\n    +          combine = TRUE)))[[1]]\n\n    ```", "```py\n    > solve(XtX, Xty)\n     [,1]\n    [1,] 3.907113\n\n    ```", "```py\n    echo 'install.packages(c(\"codetools\", \"Rcpp\", \"RJSONIO\", \"bitops\", \"digest\", \"functional\", \"stringr\", \"plyr\", \"reshape2\", \"rJava\", \"caTools\"), repos=\"http://cran.us.r-project.org\")' > /home/hadoop/installPackage.R\n    sudo Rscript /home/hadoop/installPackage.R\n    wget --no-check-certificate https://raw.githubusercontent.com/RevolutionAnalytics/rmr2/master/build/rmr2_3.3.0.tar.gz\n    sudo R CMD INSTALL rmr2_3.3.0.tar.gz\n    wget --no-check-certificate https://raw.github.com/RevolutionAnalytics/rhdfs/master/build/rhdfs_1.0.8.tar.gz\n    sudo HADOOP_CMD=/home/hadoop/bin/hadoop R CMD INSTALL rhdfs_1.0.8.tar.gz\n    ```"]