<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Foreign Exchange Rate Forecast</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we are going to start building regression models in C#. Up until now, we have built <strong class="calibre4">machine learning</strong> (<strong class="calibre4">ML</strong>) models with the goal of classifying data into binary or multiple buckets using logistic regression, Naive Bayes, and random forest learning algorithms. However, we are now going to switch gears and start building models that predict continuous outcomes. In this chapter, we will explore a financial dataset, more specifically a Foreign Exchange Rate market dataset. We will be using historical data of daily currency exchange rates between Euros (EUR) and U.S. Dollars (USD) to build a regression model that forecasts future exchange rates. We are going to start with the problem definition and then move on to data preparation and data analysis. During the data preparation and analysis steps, we are going to explore how we can manage the time series data and analyze the distributions of daily returns. Then, we are going to start building features that can forecast<span class="calibre5"> </span>currency exchange rates in the feature engineering step. We are going to discuss a few commonly used technical indicators in the financial market, such as moving averages, Bollinger Bands, and lagging variables. Using those technical indicators, we will be building regression ML models using linear regression and <strong class="calibre4">Support Vector Machine</strong> (<strong class="calibre4">SVM</strong>) learning algorithms. While building such models, we will also explore some of the ways we can fine-tune hyperparameters for the SVM model. Lastly, we will discuss a few validation metrics and methods for evaluating our regression models. We will discuss how we can use <strong class="calibre4">root mean square error</strong> (<strong class="calibre4">RMSE</strong>), R<sup class="calibre64">2</sup>, and an observed versus fitted values plot to evaluate the performances of our models. By the end of this chapter, you will have working regression models for forecasting daily EUR/USD exchange rates.</p>
<p class="calibre2">In this chapter, we will cover the following steps:</p>
<ul class="calibre10">
<li class="calibre11">Problem definition for the Foreign Exchange Rate (EUR versus USD) forecast project</li>
<li class="calibre11">Data preparation using time-series functionalities in the Deedle framework</li>
<li class="calibre11">Time series data analysis</li>
<li class="calibre11">Feature engineering using various technical indicators in Forex</li>
<li class="calibre11">Linear regression versus SVM</li>
<li class="calibre11">Model validations using RMSE, R<sup class="calibre64">2</sup>, and the actual versus predicted plot</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Problem definition</h1>
                
            
            <article>
                
<p class="calibre2">Let's start this chapter by defining what we are trying to solve in this project. You might have heard the terms <em class="calibre13">Algorithmic Trading</em> or <em class="calibre13">Quantitative Finance/Trading</em>. This is one of the well-known fields in the finance industry where data science and ML meet finance. Algorithmic Trading or Quantitative Finance refers to a strategy where you use statistical learning models that were built from a large amount of historical data to forecast future financial market movements. Such strategies and techniques are used widely by various traders and investors forecast future prices for various financial assets. The foreign exchange market is one of the largest and most liquid financial markets, and a large pool of traders and investors take part in it. It is a unique market that is open 24 hours a day and five days a week and traders from all over the world come in to buy and sell certain currency pairs. Due to this advantage and uniqueness, the foreign exchange market is also an attractive financial market for algorithmic and quantitative traders to build ML models to forecast future exchange rates and automate their trades to take advantage of the fast decisions and executions that computers can make.</p>
<p class="calibre2">To get a feel for how we can apply our ML knowledge to financial markets and regression models, we are going to use historical data of daily EUR/USD rates from January 1, 1999 to December 31st, 2017. We are going to use a publicly available dataset, which can be downloaded from this link: <a href="http://www.global-view.com/forex-trading-tools/forex-history/index.html" target="_blank" class="calibre9">http://www.global-view.com/forex-trading-tools/forex-history/index.html</a>. With this data, we are going to build features by using commonly used technical indicators, such as moving averages, Bollinger Bands, and lagging variables. Then, we are going to build regression models using linear regression and SVM learning algorithms that forecast future daily exchange rates for EUR/USD currency pairs. Once we have built these models, we are going to use RMSE, R<sup class="calibre64"><sub class="calibre65">2</sub></sup>, and a plot of observed values against predicted values to evaluate our models.</p>
<p class="calibre2">To summarize our problem definition for the foreign exchange rate forecasting project:</p>
<ul class="calibre10">
<li class="calibre11">What is the problem? We need a regression model that forecasts future foreign exchange rates between Euros and U.S. Dollars; more specifically, we want to build a ML model that forecasts daily changes in EUR/USD exchange rates.</li>
<li class="calibre11">Why is it a problem? Due to the fast-paced and volatile environments in the foreign exchange market, it is advantageous to have a ML model that can forecast and make autonomous decisions on when to buy and when to sell certain currency pairs.</li>
<li class="calibre11">What are some of the approaches to solving this problem? We are going to use historical data of daily exchange rates between EUR and USD. With this dataset, we are going to build financial features using often used technical indicators, such as moving averages, Bollinger Bands, and lagging variables. We will explore linear regression and SVM learning algorithms as our candidates for the regression model. Then, we will look at RMSE, R<sup class="calibre64">2</sup>, and use an observed versus predicted plot to evaluate the performances of the models that we built.</li>
<li class="calibre11">What are the success criteria? We want low RMSE, as we want our predictions to be as close to the actual values as possible. We want high R<sup class="calibre64">2</sup>, as it indicates the goodness of fit for our models. Lastly, we would like to see data points lined up closely to a diagonal line in the observed versus predicted plot.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Data preparation</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Now that we know what kind of problem we are trying to solve in this chapter, let's start looking into the data. Unlike the two previous chapters, where we precompiled and prelabeled data, we are going to start with raw EUR/USD exchange rate data. Follow this link: <a href="http://www.global-view.com/forex-trading-tools/forex-history/index.html" class="calibre9">http://www.global-view.com/forex-trading-tools/forex-history/index.html</a> and select <strong class="calibre4">EUR/USD Close</strong>, <strong class="calibre4">EUR/USD High</strong>, and <strong class="calibre4">EUR/USD Low</strong>. You can also select different currency pairs, if you'd like to explore different datasets. Once you have selected the data points you want, you can then select the start and end dates and you can also choose whether you want to download daily, weekly, or monthly data. For this chapter, we choose <strong class="calibre4">01/01/1999</strong> as the <strong class="calibre4">Start Date</strong> and <strong class="calibre4">12/31/2017</strong> as the <strong class="calibre4">Stop Date</strong> and we download the daily dataset that contains close, high, and low prices for the EUR/USD currency pair.</span></p>
<p class="calibre2">Once you have downloaded the data, there are a few tasks we need to do to get it ready for our future data analysis, feature engineering, and ML modeling. First, we need to define target variables. As discussed in our problem definition step, our target variable is going to be the daily change in EUR/USD exchange rates. To compute daily returns, we need to subtract the previous day's close price from today's close price and then divide it by previous day's close price. The formula for calculating daily returns is as follows:</p>
<div class="mce-root"><img class="fm-editor-equation" src="../images/00051.jpeg"/></div>
<p class="calibre2">We can use the <kbd class="calibre12">Diff</kbd> method in Deedle's data frame to calculate the difference between the previous price and the current price. You can actually use the <kbd class="calibre12">Diff</kbd> method to calculate the difference between a data point at any arbitrary point in time and the current data point. For example, the following code shows how you can calculate the differences between the current data point and the data points at one step ahead, three steps ahead, and five steps ahead:</p>
<pre class="calibre19">rawDF["DailyReturn"].Diff(1)<br class="title-page-name"/>rawDF["DailyReturn"].Diff(3)<br class="title-page-name"/>rawDF["DailyReturn"].Diff(5)</pre>
<p class="calibre2">The output of the preceding code is as follows:</p>
<div class="mce-root"><img class="alignnone8" src="../images/00052.gif"/></div>
<p class="calibre2">Using this <kbd class="calibre12">Diff</kbd> method, the following code is how we can calculate the daily returns of EUR/USD exchange rates:</p>
<pre class="calibre19">// Compute Daily Returns<br class="title-page-name"/>rawDF.AddColumn(<br class="title-page-name"/>    "DailyReturn", <br class="title-page-name"/>    rawDF["Close"].Diff(1) / rawDF["Close"] * 100.0<br class="title-page-name"/>);</pre>
<p class="calibre2">In this code, we are taking the difference in close prices between the previous day and the current day and then dividing them by the previous close price. By multiplying them by <kbd class="calibre12">100</kbd>, we can get the daily returns in a percentage. Finally, we add this daily return series back to the original data frame with a column name, <kbd class="calibre12">DailyReturn</kbd>, by using the <kbd class="calibre12">AddColumn</kbd> method in Deedle's data frame.</p>
<p class="calibre2">However, we are not quite done yet with building the target variables. Since we are building a forecasting model, we need to take the next day return as the target variable. We can use the <kbd class="calibre12">Shift</kbd> method in Deedle's data frame to associate each record with the next day return. Similar to the <kbd class="calibre12">Diff</kbd> method, you can use the <kbd class="calibre12">Shift</kbd> method to move a series back and forth to any arbitrary point in time. The following code shows how you can move the <kbd class="calibre12">DailyReturn</kbd> column by <kbd class="calibre12">1</kbd>, <kbd class="calibre12">3</kbd>, and <kbd class="calibre12">5</kbd> steps:</p>
<pre class="calibre19">rawDF["DailyReturn"].Shift(1)<br class="title-page-name"/>rawDF["DailyReturn"].Shift(3)<br class="title-page-name"/>rawDF["DailyReturn"].Shift(5)</pre>
<p class="calibre2">The output of the preceding code is as follows:</p>
<div class="mce-root"><img class="alignnone9" src="../images/00053.gif"/></div>
<p class="calibre2">As you can see from this example, the <kbd class="calibre12">DailyReturn</kbd> column or series has been moved forward by <kbd class="calibre12">1</kbd>, <kbd class="calibre12">3</kbd>, and <kbd class="calibre12">5</kbd> steps, depending on the parameters you fed into the <kbd class="calibre12">Shift</kbd> method. Using this <kbd class="calibre12">Shift</kbd> method, we are going to move daily returns back one step, so that each record has the next day's return as a target variable. The following code is how we created a target variable column, <kbd class="calibre12">Target</kbd>:</p>
<pre class="calibre19">// Encode Target Variable - Predict Next Daily Return<br class="title-page-name"/>rawDF.AddColumn(<br class="title-page-name"/>    "Target",<br class="title-page-name"/>    rawDF["DailyReturn"].Shift(-1)<br class="title-page-name"/>);</pre>
<p class="calibre2">Now that we have encoded target variables, there is one more step we need to take to get our data prepared for future tasks. When you are working with financial data, you will often hear the terms <em class="calibre13">OHLC chart</em> or <em class="calibre13">OHLC prices</em>. OHLC stands for Open, High, Low, and Close and it is often used to show price movements over time. If you look at the data that we downloaded, you will notice that open prices are missing in the dataset. However, we are going to need open prices for our future feature engineering step. We are going to assume that the open price for a given day is the close price of the previous day, given that the foreign exchange market is run 24 hours a day and is very liquid with high trading volume. In order to take previous close prices as open prices, we are going to use the <kbd class="calibre12">Shift</kbd> method. The following code shows how we created and added open prices into our data frame:</p>
<pre class="calibre19">// Assume Open prices are previous Close prices<br class="title-page-name"/>rawDF.AddColumn(<br class="title-page-name"/>    "Open",<br class="title-page-name"/>    rawDF["Close"].Shift(1)<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">The following code is the full code that we used for the data preparation step:</span></p>
<pre class="calibre19">using Deedle;<br class="title-page-name"/>using System;<br class="title-page-name"/>using System.Collections.Generic;<br class="title-page-name"/>using System.IO;<br class="title-page-name"/>using System.Linq;<br class="title-page-name"/>using System.Text;<br class="title-page-name"/>using System.Threading.Tasks;<br class="title-page-name"/><br class="title-page-name"/>namespace DataPrep<br class="title-page-name"/>{<br class="title-page-name"/>    class Program<br class="title-page-name"/>    {<br class="title-page-name"/>        static void Main(string[] args)<br class="title-page-name"/>        {<br class="title-page-name"/>            Console.SetWindowSize(100, 50);<br class="title-page-name"/><br class="title-page-name"/>            // Read in the raw dataset<br class="title-page-name"/>            // TODO: change the path to point to your data directory<br class="title-page-name"/>            string dataDirPath = @"\\Mac\Home\Documents\c-sharp-machine-<br class="title-page-name"/>learning\ch.4\input-data";<br class="title-page-name"/><br class="title-page-name"/>            // Load the data into a data frame<br class="title-page-name"/>            string rawDataPath = Path.Combine(dataDirPath, "eurusd-daily.csv");<br class="title-page-name"/>            Console.WriteLine("Loading {0}\n", rawDataPath);<br class="title-page-name"/>            var rawDF = Frame.ReadCsv(<br class="title-page-name"/>                rawDataPath,<br class="title-page-name"/>                hasHeaders: true,<br class="title-page-name"/>                schema: "Date,float,float,float",<br class="title-page-name"/>                inferTypes: false<br class="title-page-name"/>            );<br class="title-page-name"/><br class="title-page-name"/>            // Rename &amp; Simplify Column Names<br class="title-page-name"/>            rawDF.RenameColumns(c =&gt; c.Contains("EUR/USD ") ? c.Replace("EUR/USD ", "") : c);<br class="title-page-name"/><br class="title-page-name"/>            // Assume Open prices are previous Close prices<br class="title-page-name"/>            rawDF.AddColumn(<br class="title-page-name"/>                "Open",<br class="title-page-name"/>                rawDF["Close"].Shift(1)<br class="title-page-name"/>            );<br class="title-page-name"/><br class="title-page-name"/>            // Compute Daily Returns<br class="title-page-name"/>            rawDF.AddColumn(<br class="title-page-name"/>                "DailyReturn", <br class="title-page-name"/>                rawDF["Close"].Diff(1) / rawDF["Close"] * 100.0<br class="title-page-name"/>            );<br class="title-page-name"/><br class="title-page-name"/>            // Encode Target Variable - Predict Next Daily Return<br class="title-page-name"/>            rawDF.AddColumn(<br class="title-page-name"/>                "Target",<br class="title-page-name"/>                rawDF["DailyReturn"].Shift(-1)<br class="title-page-name"/>            );<br class="title-page-name"/><br class="title-page-name"/>            rawDF.Print();<br class="title-page-name"/><br class="title-page-name"/>            // Save OHLC data<br class="title-page-name"/>            string ohlcDataPath = Path.Combine(dataDirPath, "eurusd-daily-ohlc.csv");<br class="title-page-name"/>            Console.WriteLine("\nSaving OHLC data to {0}\n", rawDataPath);<br class="title-page-name"/>            rawDF.SaveCsv(ohlcDataPath);<br class="title-page-name"/><br class="title-page-name"/>            Console.WriteLine("DONE!!");<br class="title-page-name"/>            Console.ReadKey();<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/>}</pre>
<p class="calibre2">When you run this code, it is going to output the results into a file named <kbd class="calibre12">eurusd-daily-ohlc.csv</kbd>, which contains the OHLC prices, daily returns, and target variables. We are going to use this file for the future data analysis and feature engineering steps.</p>
<p class="calibre2">This code can also be found in the following repository: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/DataPrep.cs" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/DataPrep.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Time series data analysis</h1>
                
            
            <article>
                
<p class="calibre2">Let's start looking into the data. We are going to take the output from the previous data preparation step and start looking at the distributions of daily returns. Unlike previous chapters, where we primarily worked with categorical variables, we are dealing with continuous and time series variables. We will look at this data in a few different ways. First, let's look at the time series close prices chart. The following code shows how to build a line chart using the Accord.NET framework:</p>
<pre class="calibre19">// Time-series line chart of close prices<br class="title-page-name"/>DataSeriesBox.Show(<br class="title-page-name"/>    ohlcDF.RowKeys.Select(x =&gt; (double)x),<br class="title-page-name"/>    ohlcDF.GetColumn&lt;double&gt;("Close").ValuesAll<br class="title-page-name"/>);</pre>
<p class="calibre2">Refer to the Accord.NET documentation the <kbd class="calibre12">DataSeriesBox.Show</kbd> method for various other ways to display a line chart. In this example, we built a line chart with the integer indexes of our data frame as the <em class="calibre13">x</em> axis values and the close prices as the <em class="calibre13">y</em> axis values. The following is the time series line chart that you will see when you run the code:</p>
<div class="mce-root"><img src="../images/00054.jpeg" class="calibre66"/></div>
<p class="calibre2">This chart shows us the overall movements of EUR/USD exchange rates over time from 1999 to 2017. It started from around 1.18 and went below 1.0 in 2000 and 2001. Then, it went as high as 1.6 in 2008 and then ended 2017 at around 1.20. Let's now look at the historical daily returns. The following code shows you how to build a line chart of historical daily returns:</p>
<pre class="calibre19">// Time-series line chart of daily returns<br class="title-page-name"/>DataSeriesBox.Show(<br class="title-page-name"/>    ohlcDF.RowKeys.Select(x =&gt; (double)x),<br class="title-page-name"/>    ohlcDF.FillMissing(0.0)["DailyReturn"].ValuesAll<br class="title-page-name"/>);</pre>
<p class="calibre2">One thing to note here is the usage of the <kbd class="calibre12">FillMissing</kbd> method. If you remember from the previous data preparation step, the <kbd class="calibre12">DailyReturn</kbd> series was built by taking the difference between the previous period and the current period. As a result, we have a missing value for the very first data point, since there is no previous period data point for the first record. The <kbd class="calibre12">FillMissing</kbd> method helps you encode missing values with custom values. Depending on your dataset and assumptions, you can encode missing values with different values, and the <kbd class="calibre12">FillMissing</kbd> method in Deedle's data frame will come in handy.</p>
<p class="calibre2">When you run the previous code, it will display a chart as follows:</p>
<div class="mce-root"><img src="../images/00055.jpeg" class="calibre67"/></div>
<p class="calibre2">As you can see from this chart, daily returns oscillate around <strong class="calibre4">0</strong>, mostly between -2.0% and +2.0%. Let's look at the distribution of daily returns more closely. We are going to look at the minimum, maximum, mean, and standard deviation values. Then, we are going to look at the quartiles of daily returns, which we will discuss in more detail after looking at the code. The code to compute those numbers is as follows:</p>
<pre class="calibre19">// Check the distribution of daily returns<br class="title-page-name"/>double returnMax = ohlcDF["DailyReturn"].Max();<br class="title-page-name"/>double returnMean = ohlcDF["DailyReturn"].Mean();<br class="title-page-name"/>double returnMedian = ohlcDF["DailyReturn"].Median();<br class="title-page-name"/>double returnMin = ohlcDF["DailyReturn"].Min();<br class="title-page-name"/>double returnStdDev = ohlcDF["DailyReturn"].StdDev();<br class="title-page-name"/><br class="title-page-name"/>double[] quantiles = Accord.Statistics.Measures.Quantiles(<br class="title-page-name"/>    ohlcDF.FillMissing(0.0)["DailyReturn"].ValuesAll.ToArray(),<br class="title-page-name"/>    new double[] {0.25, 0.5, 0.75}<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("-- DailyReturn Distribution-- ");<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("Mean: \t\t\t{0:0.00}\nStdDev: \t\t{1:0.00}\n", returnMean, returnStdDev);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine(<br class="title-page-name"/>    "Min: \t\t\t{0:0.00}\nQ1 (25% Percentile): \t{1:0.00}\nQ2 (Median): \t\t{2:0.00}\nQ3 (75% Percentile): \t{3:0.00}\nMax: \t\t\t{4:0.00}", <br class="title-page-name"/>    returnMin, quantiles[0], quantiles[1], quantiles[2], returnMax<br class="title-page-name"/>);</pre>
<p class="calibre2">As you can see from this code, the Deedle framework has numerous built-in methods for computing basic statistics. As shown in the first six lines of the code, you can use the <kbd class="calibre12">Max</kbd>, <kbd class="calibre12">Mean</kbd>, <kbd class="calibre12">Median</kbd>, <kbd class="calibre12">Min</kbd>, and <kbd class="calibre12">StdDev</kbd> methods in the Deedle framework in order to get corresponding statistics for daily returns. </p>
<p class="calibre2">In order to get quartiles, we need to use the <kbd class="calibre12">Quantiles</kbd> method in the <kbd class="calibre12">Accord.Statistics.Measures</kbd> module of the Accord.NET Framework. Quantiles are the points that divide an ordered distribution into equal-length intervals. For example, ten-quantiles break an ordered distribution into ten subsets of equal sizes, so that the first subset represents the bottom 10% of the distribution and the last subset represents the top 10% of the distribution. Similarly, four-quantiles break an ordered distribution into four subsets of equal sizes, where the first subset represents the bottom 25% of the distribution and the last subset represents the top 25% of the distribution. Four-quantiles are often called <strong class="calibre4">quartiles</strong>, ten-quantiles are called <strong class="calibre4">deciles</strong>, and 100-quantiles are called <strong class="calibre4">percentiles</strong>. As you can deduce from these definitions, the 1<sup class="calibre64">st </sup>quartile is the same as the 0.25<sup class="calibre64">th </sup>decile and the 25<sup class="calibre64">th </sup>percentile. Similarly, the 2<sup class="calibre64">nd </sup>and 3<sup class="calibre64">rd </sup>quartiles are the same as the 0.<span class="calibre5">50<sup class="calibre64">th </sup>and 0.75<sup class="calibre64">th </sup>deciles</span><span class="calibre5"> and</span> the 50<sup class="calibre64">th </sup>and 75<sup class="calibre64">th </sup><span class="calibre5">percentiles.</span> As we are interested in the quartiles, we used 25%, 50%, and 75% as the inputs for the <kbd class="calibre12">percentiles</kbd> parameter in the <kbd class="calibre12">Quantiles</kbd> method. The following shows the output when you run this code:</p>
<div class="mce-root"><img class="alignnone10" src="../images/00056.gif"/></div>
<p class="calibre2">Similar to what we have noticed from the daily return time series line chart, mean, and median are about 0, suggesting the daily returns oscillate around 0%. From 1999 to 2017, the largest negative daily return in history is -2.86% and the largest positive daily return is 3.61%. The first quartile, which is the middle number between the minimum and median, is at -0.36% and the third quartile, which is the middle number between the median and the maximum, is at 0.35%. From these summary statistics, we can see that the daily returns are spread almost symmetrically from 0%. To show this more visually, let's now look at the histogram of daily returns. The code to plot a histogram of daily returns is as follows:</p>
<pre class="calibre19">var dailyReturnHistogram = HistogramBox<br class="title-page-name"/>.Show(<br class="title-page-name"/>    ohlcDF.FillMissing(0.0)["DailyReturn"].ValuesAll.ToArray()<br class="title-page-name"/>)<br class="title-page-name"/>.SetNumberOfBins(20);</pre>
<p class="calibre2">We used <kbd class="calibre12">HistogramBox</kbd> in the Accord.NET framework to build a histogram chart of daily returns. Here, we set the number of bins as <kbd class="calibre12">20</kbd>. You can increase or decrease the number of bins to show more or less granular buckets. When you run this code, the following chart is what you will see:</p>
<div class="mce-root"><img class="alignnone11" src="../images/00057.jpeg"/></div>
<p class="calibre2">Similar to what we have observed in the summary statistics, daily returns are spread almost symmetrically from 0%. This histogram of daily returns shows a clear bell curve, which suggests that daily returns follow a normal distribution.</p>
<p class="calibre2">The full code that we ran for this data analysis step can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/DataAnalyzer.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/DataAnalyzer.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature engineering</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">Now that we have a better understanding of the distribution of daily returns, let's start building features for our ML modeling. In this step, we are going to discuss a couple of frequently used technical indicators that traders in the foreign exchange market use and how we can build features for our ML models using those technical indicators.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Moving average</h1>
                
            
            <article>
                
<p class="calibre2">The first set of features we are going to build moving averages. A moving average is a rolling average for a pre-defined number of periods and is an often used technical indicator. A moving average helps smooth out volatile price movements and shows the overall trends of price actions. An in-depth discussion about how moving averages are used in trading financial assets is beyond the scope of this book, but in short, looking at multiple moving averages with different timeframes helps traders to identify trends and support and resistance levels for trading. In this chapter, we are going to use four moving averages, where the look-back periods are 10 days, 20 days, 50 days, and 200 days. The following code shows how we can compute moving averages using the <kbd class="calibre12">Window</kbd> method:</p>
<pre class="calibre19">// 1. Moving Averages<br class="title-page-name"/>ohlcDF.AddColumn("10_MA", ohlcDF.Window(10).Select(x =&gt; x.Value["Close"].Mean()));<br class="title-page-name"/>ohlcDF.AddColumn("20_MA", ohlcDF.Window(20).Select(x =&gt; x.Value["Close"].Mean()));<br class="title-page-name"/>ohlcDF.AddColumn("50_MA", ohlcDF.Window(50).Select(x =&gt; x.Value["Close"].Mean()));<br class="title-page-name"/>ohlcDF.AddColumn("200_MA", ohlcDF.Window(200).Select(x =&gt; x.Value["Close"].Mean()));</pre>
<p class="calibre2">The <kbd class="calibre12">Window</kbd> method in the Deedle framework helps us easily compute moving averages. The <kbd class="calibre12">Window</kbd> method takes a data frame and builds a series of data frames where each data frame contains a pre-defined number of records. For example, if your input to the <kbd class="calibre12">Window</kbd> method is <kbd class="calibre12">10</kbd>, then it is going to build a series of data frames, where the first data frame contains records from the 0th index to the 9<sup class="calibre64">th</sup> index, the second data frame contains records from the 1<sup class="calibre64">st</sup> index to the 11<sup class="calibre64">th</sup> index, and so forth. Using this method, we can easily compute moving averages for different time windows, as shown in the code. Now, let's plot a time series close price chart with these moving averages:</p>
<div class="mce-root"><img src="../images/00058.jpeg" class="calibre68"/></div>
<p class="calibre2">As you can see from this chart, moving averages smooth out volatile price movements. The red line shows moving averages of 10 days, the green line shows moving averages of 20 days, the black line for 50 days, and the pink line for 200 days. As you can see from this chart, the shorter the time window the closer it follows price actions and the less smooth the chart is. The code we used to generate this chart is as follows:</p>
<pre class="calibre19">// Time-series line chart of close prices &amp; moving averages<br class="title-page-name"/>var maLineChart = DataSeriesBox.Show(<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).RowKeys.Select(x =&gt; (double)x),<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("Close").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("10_MA").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("20_MA").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("50_MA").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("200_MA").ValuesAll<br class="title-page-name"/>);</pre>
<p class="calibre2">With these moving averages we just calculated, the actual features that we are going to use for our model are the distances between the close price and the moving averages. As briefly mentioned, moving averages often work as support and resistance levels and by looking at how far each price point is from each of the moving averages, we can figure out whether we are approaching the support and resistance lines. The code to calculate the distances between the close price and the moving averages is as follows:</p>
<pre class="calibre19">// Distance from moving averages<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_10_MA", ohlcDF["Close"] - ohlcDF["10_MA"]);<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA", ohlcDF["Close"] - ohlcDF["20_MA"]);<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA", ohlcDF["Close"] - ohlcDF["50_MA"]);<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA", ohlcDF["Close"] - ohlcDF["200_MA"]);</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Bollinger Bands</h1>
                
            
            <article>
                
<p class="calibre2">The second technical indicator that we are going to look at is Bollinger Bands. <span class="calibre5">Bollinger Bands</span> comprise a moving average and the moving standard deviation of the same time window as the moving average that it is using. Then, Bollinger Bands are plotted two standard deviations <span class="calibre5">above and below the moving average on the price time series chart. </span>We will use a 20-day time window for computing <span class="calibre5">Bollinger Bands</span>. The code to compute <span class="calibre5">Bollinger Bands is as follows:</span></p>
<pre class="calibre19">// 2. Bollinger Band<br class="title-page-name"/>ohlcDF.AddColumn("20_day_std", ohlcDF.Window(20).Select(x =&gt; x.Value["Close"].StdDev()));<br class="title-page-name"/>ohlcDF.AddColumn("BollingerUpperBound", ohlcDF["20_MA"] + ohlcDF["20_day_std"] * 2);<br class="title-page-name"/>ohlcDF.AddColumn("BollingerLowerBound", ohlcDF["20_MA"] - ohlcDF["20_day_std"] * 2);</pre>
<p class="calibre2">As you can see from this code, we are using the <kbd class="calibre12">Window</kbd> and <kbd class="calibre12">StdDev</kbd> methods to calculate moving standard deviations. Then, we calculate the upper and lower boundaries of <span class="calibre5">Bollinger Bands by adding and subtracting two standard deviations from 20-day moving averages. When you plot Bollinger Bands with price series, the result looks as follows:</span></p>
<div class="mce-root"><img src="../images/00059.jpeg" class="calibre69"/></div>
<p class="calibre2">The blue line shows the price movements, the green line shows 20-day moving averages, the red line shows the upper boundary of Bollinger Bands, which is two standard deviations above the moving averages, and the black line shows the lower boundary of Bollinger Bands, which<span class="calibre5"> is two standard deviations below the moving averages</span>. As you can see from this chart, Bollinger Bands form bands around the price movements. The code to display this chart is as follows:</p>
<pre class="calibre19">// Time-series line chart of close prices &amp; bollinger bands<br class="title-page-name"/>var bbLineChart = DataSeriesBox.Show(<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).RowKeys.Select(x =&gt; (double)x),<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("Close").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("BollingerUpperBound").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("20_MA").ValuesAll,<br class="title-page-name"/>    ohlcDF.Where(x =&gt; x.Key &gt; 4400 &amp;&amp; x.Key &lt; 4900).GetColumn&lt;double&gt;("BollingerLowerBound").ValuesAll<br class="title-page-name"/>);</pre>
<p class="calibre2">Similar to the previous case of moving averages, we are going to use the distances between the close price and Bollinger Bands. Since most of the trades are made between the upper and lower bands, the distances between the price and the bands can be features for our ML models. The code to calculate the distances is as follows:</p>
<pre class="calibre19">// Distance from Bollinger Bands<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerUpperBound", ohlcDF["Close"] - ohlcDF["BollingerUpperBound"]);<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerLowerBound", ohlcDF["Close"] - ohlcDF["BollingerLowerBound"]);</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Lagged variables</h1>
                
            
            <article>
                
<p class="calibre2">Finally, the last set of features we are going to use is lagged variables. Lagged variables contain information about previous periods. For example, if we use the daily return value of a previous day as a feature for our model, then it is a lagged variable that lagged one period. We can also use the daily return of two days prior to the current date as a feature for our model. These types of variable are called <strong class="calibre4">lagged variables</strong> and are often used in time series modeling. We are going to use daily returns and previously built features as lagged variables. In this project, we look back as far as five periods, but you can experiment with longer or shorter look-back periods. The code to create lagged variables for daily returns is as follows:</p>
<pre class="calibre19">// 3. Lagging Variables<br class="title-page-name"/>ohlcDF.AddColumn("DailyReturn_T-1", ohlcDF["DailyReturn"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("DailyReturn_T-2", ohlcDF["DailyReturn"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("DailyReturn_T-3", ohlcDF["DailyReturn"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("DailyReturn_T-4", ohlcDF["DailyReturn"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("DailyReturn_T-5", ohlcDF["DailyReturn"].Shift(5));</pre>
<p class="calibre2">Similarly, we can create lagged variables for the differences between moving averages and the close prices, using the following code:</p>
<pre class="calibre19">ohlcDF.AddColumn("Close_minus_10_MA_T-1", ohlcDF["Close_minus_10_MA"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_10_MA_T-2", ohlcDF["Close_minus_10_MA"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_10_MA_T-3", ohlcDF["Close_minus_10_MA"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_10_MA_T-4", ohlcDF["Close_minus_10_MA"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_10_MA_T-5", ohlcDF["Close_minus_10_MA"].Shift(5));<br class="title-page-name"/><br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA_T-1", ohlcDF["Close_minus_20_MA"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA_T-2", ohlcDF["Close_minus_20_MA"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA_T-3", ohlcDF["Close_minus_20_MA"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA_T-4", ohlcDF["Close_minus_20_MA"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_20_MA_T-5", ohlcDF["Close_minus_20_MA"].Shift(5));<br class="title-page-name"/><br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA_T-1", ohlcDF["Close_minus_50_MA"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA_T-2", ohlcDF["Close_minus_50_MA"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA_T-3", ohlcDF["Close_minus_50_MA"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA_T-4", ohlcDF["Close_minus_50_MA"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_50_MA_T-5", ohlcDF["Close_minus_50_MA"].Shift(5));<br class="title-page-name"/><br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA_T-1", ohlcDF["Close_minus_200_MA"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA_T-2", ohlcDF["Close_minus_200_MA"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA_T-3", ohlcDF["Close_minus_200_MA"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA_T-4", ohlcDF["Close_minus_200_MA"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_200_MA_T-5", ohlcDF["Close_minus_200_MA"].Shift(5));</pre>
<p class="calibre2">Lastly, we can create lagged variables for Bollinger Band indicators, using the following code:</p>
<pre class="calibre19">ohlcDF.AddColumn("Close_minus_BollingerUpperBound_T-1", ohlcDF["Close_minus_BollingerUpperBound"].Shift(1));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerUpperBound_T-2", ohlcDF["Close_minus_BollingerUpperBound"].Shift(2));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerUpperBound_T-3", ohlcDF["Close_minus_BollingerUpperBound"].Shift(3));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerUpperBound_T-4", ohlcDF["Close_minus_BollingerUpperBound"].Shift(4));<br class="title-page-name"/>ohlcDF.AddColumn("Close_minus_BollingerUpperBound_T-5", ohlcDF["Close_minus_BollingerUpperBound"].Shift(5));</pre>
<p class="calibre2">As you can see from these code snippets, it is very simple and straightforward to create such lagged variables. We can simply use the <kbd class="calibre12">Shift</kbd> method in the Deedle framework and change the input to the method according to the look-back period.</p>
<p class="calibre2">One last thing we are going to do in this section is drop the missing values. Because we were building many time series features, we created a lot of missing values. For example, when we calculate 200-day moving averages, the first 199 records will have no moving averages, and as a result will have missing values. When you happen to have missing values in your dataset, there are two ways you can handle them—you can either encode them with certain values, or drop the missing values from the dataset. Since we have enough data, we are going to drop all the records with missing values. The code for dropping missing values from our data frame is as follows:</p>
<pre class="calibre19">Console.WriteLine("\n\nDF Shape BEFORE Dropping Missing Values: ({0}, {1})", ohlcDF.RowCount, ohlcDF.ColumnCount);<br class="title-page-name"/>ohlcDF = ohlcDF.DropSparseRows();<br class="title-page-name"/>Console.WriteLine("\nDF Shape AFTER Dropping Missing Values: ({0}, {1})\n\n", ohlcDF.RowCount, ohlcDF.ColumnCount);</pre>
<p class="calibre2">As you can see from this code, the Deedle framework has a handy function that we can use to drop missing values. We can use the <kbd class="calibre12">DropSparseRows</kbd> method to drop all the missing values. When you run this code, your output will look as follows:</p>
<div class="mce-root"><img class="alignnone12" src="../images/00060.gif"/></div>
<p class="calibre2">As you can see from this output, it dropped 250 records for having missing values. The full code to run the data analysis step from end to end can be found at this link: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/FeatureEngineer.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/FeatureEngineer.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Linear regression versus SVM</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this section, we are going to build models that are completely different from previous chapters. We are going to build models that predict continuous variables and provide a daily return of EUR/USD exchange rates, and we are going to use two new learning algorithms, linear regression and SVM. Linear regression models try to find linear relationships between the target variables and the features, whereas SVM models try to build hyperplanes that maximize the distances between different classes. For this foreign exchange rate forecasting project, we are going to discuss how to build linear regression and SVM models for regression problems in C# using the Accord.NET Framework.</span></p>
<p class="calibre2">Before we build models, we will have to split our sample set into two subsets—one for training and another for testing. In the previous chapter, we<span class="calibre5"> used </span><kbd class="calibre12">SplitSetValidation</kbd><em class="calibre13"> </em><span class="calibre5">in the Accord.NET Framework to randomly split a sample set into train and test sets at a pre-defined proportion. However, we cannot apply the same approach in this chapter. </span>Since we are dealing with time series data, we cannot randomly select and split records into train and test sets. If we do randomly split the sample set, then we are going to have cases where we train our ML models with future events and test our models on past events. So, we want to split our sample set at a certain point in time and take the records up to that point into a train set and the records after that point into a test set. The following code shows how we split our sample set into train and test sets:</p>
<pre class="calibre19">// Read in the file we created in the previous step<br class="title-page-name"/>// TODO: change the path to point to your data directory<br class="title-page-name"/>string dataDirPath = @"&lt;path-to-data-dir&gt;";<br class="title-page-name"/><br class="title-page-name"/>// Load the data into a data frame<br class="title-page-name"/>Console.WriteLine("Loading data...");<br class="title-page-name"/>var featuresDF = Frame.ReadCsv(<br class="title-page-name"/>    Path.Combine(dataDirPath, "eurusd-features.csv"),<br class="title-page-name"/>    hasHeaders: true,<br class="title-page-name"/>    inferTypes: true<br class="title-page-name"/>);<br class="title-page-name"/><br class="title-page-name"/>// Split the sample set into train and test sets<br class="title-page-name"/>double trainProportion = 0.9;<br class="title-page-name"/><br class="title-page-name"/>int trainSetIndexMax = (int)(featuresDF.RowCount * trainProportion);<br class="title-page-name"/><br class="title-page-name"/>var trainSet = featuresDF.Where(x =&gt; x.Key &lt; trainSetIndexMax);<br class="title-page-name"/>var testSet = featuresDF.Where(x =&gt; x.Key &gt;= trainSetIndexMax);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\nTrain Set Shape: ({0}, {1})", trainSet.RowCount, trainSet.ColumnCount);<br class="title-page-name"/>Console.WriteLine("Test Set Shape: ({0}, {1})", testSet.RowCount, testSet.ColumnCount);</pre>
<p class="calibre2">As you can see from this code snippet, we take the first 90% of the sample set for training and the remaining 10% for testing, using the <kbd class="calibre12">Where</kbd> method to filter records in the sample set by index. The next thing we need to do before training our ML models is select the features that we want to train our models with. Since we are only interested in using lagged variables and the distances between the prices and moving averages or Bollinger Bands, we do not want to include raw moving average or Bollinger Band numbers into our feature space. The following code snippet shows how we define the feature set for our models:</p>
<pre class="calibre19">string[] features = new string[] {<br class="title-page-name"/>    "DailyReturn", <br class="title-page-name"/>    "Close_minus_10_MA", "Close_minus_20_MA", "Close_minus_50_MA",<br class="title-page-name"/>    "Close_minus_200_MA", "20_day_std", <br class="title-page-name"/>    "Close_minus_BollingerUpperBound", "Close_minus_BollingerLowerBound",<br class="title-page-name"/>    "DailyReturn_T-1", "DailyReturn_T-2",<br class="title-page-name"/>    "DailyReturn_T-3", "DailyReturn_T-4", "DailyReturn_T-5",<br class="title-page-name"/>    "Close_minus_10_MA_T-1", "Close_minus_10_MA_T-2", <br class="title-page-name"/>    "Close_minus_10_MA_T-3", "Close_minus_10_MA_T-4",<br class="title-page-name"/>    "Close_minus_10_MA_T-5", <br class="title-page-name"/>    "Close_minus_20_MA_T-1", "Close_minus_20_MA_T-2",<br class="title-page-name"/>    "Close_minus_20_MA_T-3", "Close_minus_20_MA_T-4", "Close_minus_20_MA_T-5",<br class="title-page-name"/>    "Close_minus_50_MA_T-1", "Close_minus_50_MA_T-2", "Close_minus_50_MA_T-3",<br class="title-page-name"/>    "Close_minus_50_MA_T-4", "Close_minus_50_MA_T-5", <br class="title-page-name"/>    "Close_minus_200_MA_T-1", "Close_minus_200_MA_T-2", <br class="title-page-name"/>    "Close_minus_200_MA_T-3", "Close_minus_200_MA_T-4",<br class="title-page-name"/>    "Close_minus_200_MA_T-5",<br class="title-page-name"/>    "Close_minus_BollingerUpperBound_T-1",<br class="title-page-name"/>    "Close_minus_BollingerUpperBound_T-2", "Close_minus_BollingerUpperBound_T-3",<br class="title-page-name"/>    "Close_minus_BollingerUpperBound_T-4", "Close_minus_BollingerUpperBound_T-5"<br class="title-page-name"/>};</pre>
<p class="calibre2">Now we are ready to start building model objects and training our ML models. Let's first look at how to instantiate a linear regression model. The code we used to train a linear regression model is as follows:</p>
<pre class="calibre19">Console.WriteLine("\n**** Linear Regression Model ****");<br class="title-page-name"/><br class="title-page-name"/>// OLS learning algorithm<br class="title-page-name"/>var ols = new OrdinaryLeastSquares()<br class="title-page-name"/>{<br class="title-page-name"/>    UseIntercept = true<br class="title-page-name"/>};<br class="title-page-name"/><br class="title-page-name"/>// Fit a linear regression model<br class="title-page-name"/>MultipleLinearRegression regFit = ols.Learn(trainX, trainY);<br class="title-page-name"/><br class="title-page-name"/>// in-sample predictions<br class="title-page-name"/>double[] regInSamplePreds = regFit.Transform(trainX);<br class="title-page-name"/><br class="title-page-name"/>// out-of-sample predictions<br class="title-page-name"/>double[] regOutSamplePreds = regFit.Transform(testX);</pre>
<p class="calibre2">As you can see from this code snippet, we are using <kbd class="calibre12">OrdinaryLeastSquares</kbd> as a learning algorithm and <kbd class="calibre12">MultipleLinearRegression</kbd> as a model. <strong class="calibre4">Ordinary Least Squares</strong> (<strong class="calibre4">OLS</strong>) is a way of training a linear regression model by minimizing and optimizing on the sum of squares of errors. A multiple linear regression model is a model where the number of input features is larger than 1. Lastly, in order to make predictions on data, we are using the <kbd class="calibre12">Transform</kbd> method of the <kbd class="calibre12">MultipleLinearRegression</kbd> object. We will be making predictions on both the train and test sets for our model validations in the following section.</p>
<p class="calibre2">Let's now look at another learning algorithm and model that we are going to use in this chapter. The following code shows how to build and train a SVM model for regression problems:</p>
<pre class="calibre19">Console.WriteLine("\n**** Linear Support Vector Machine ****");<br class="title-page-name"/>// Linear SVM Learning Algorithm<br class="title-page-name"/>var teacher = new LinearRegressionNewtonMethod()<br class="title-page-name"/>{<br class="title-page-name"/>    Epsilon = 2.1,<br class="title-page-name"/>    Tolerance = 1e-5,<br class="title-page-name"/>    UseComplexityHeuristic = true<br class="title-page-name"/>};<br class="title-page-name"/><br class="title-page-name"/>// Train SVM<br class="title-page-name"/>var svm = teacher.Learn(trainX, trainY);<br class="title-page-name"/><br class="title-page-name"/>// in-sample predictions<br class="title-page-name"/>double[] linSVMInSamplePreds = svm.Score(trainX);<br class="title-page-name"/><br class="title-page-name"/>// out-of-sample predictions<br class="title-page-name"/>double[] linSVMOutSamplePreds = svm.Score(testX);</pre>
<p class="calibre2">As you can see from this code, we are using <kbd class="calibre12">LinearRegressionNewtonMethod</kbd> as a learning algorithm to train a SVM model. <kbd class="calibre12">LinearRegressionNewtonMethod</kbd><em class="calibre13"> </em>is a learning algorithm for SVM using linear kernel. Simply put, a kernel is a way of projecting data points onto another space where the data points are more separable than in the original space. Other kernels, such as polynomial and Gaussian kernels, are also often used when training SVM models. We will experiment with and further discuss these other kernels in the next chapter, but you can certainly experiment with the model performances on other kernels for this project. When making predictions with a trained SVM model, you can use the <kbd class="calibre12">Score</kbd> method, as shown in the code snippet.</p>
<p class="calibre2">The full code that we used to train and validate linear regression and SVM models can be found here: <a href="https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/Modeling.cs" target="_blank" class="calibre9">https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.4/Modeling.cs</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Model validations </h1>
                
            
            <article>
                
<p class="calibre2">Now that you have built and trained regression models for this chapter's foreign exchange rate forecast project, let's start looking into how our models performed. In this section, we are going to discuss two commonly used basic metrics, RMSE, and R<sup class="calibre64">2</sup>, and a diagnostic plot, actual or observed values versus predicted values. Before we delve into those metrics and a diagnostic plot, let's first briefly discuss how to extract coefficient and intercept values from the linear regression model.</p>
<p class="calibre2">The following code snippet shows you how to extract coefficients and the intercept from the <kbd class="calibre12">MultipleLinearRegression</kbd><em class="calibre13"> </em>object:</p>
<pre class="calibre19">Console.WriteLine("\n* Linear Regression Coefficients:");<br class="title-page-name"/><br class="title-page-name"/>for (int i = 0; i &lt; features.Length; i++)<br class="title-page-name"/>{<br class="title-page-name"/>    Console.WriteLine("\t{0}: {1:0.0000}", features[i], regFit.Weights[i]);<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("\tIntercept: {0:0.0000}", regFit.Intercept);</pre>
<p class="calibre2">When you run this code, you will see an output like the following:</p>
<div class="mce-root"><img class="alignnone13" src="../images/00061.gif"/></div>
<p class="calibre2">Looking at the coefficients and intercept of the fitted linear regression model helps us understand the model and gain some insights into how each feature affects the prediction results. The fact that we can understand and visualize exactly how the relationships between the features and the target variable are formed and how they interact with each other makes linear regression models still attractive, even though other black-box models, such as random forest models or support vector machines, often outperform linear regression models. As you can see from this output, you can easily tell which features affect daily return predictions negatively or positively and the magnitudes of their impacts.</p>
<p class="calibre2">Let's now look at the first metrics that we are using for regression model validation in this chapter. You might already be familiar with RMSE, which measures the square root of the errors between the predicted values and the actual values. The lower RMSE values are, the better the model fit is. The following code shows how you can compute the RMSE of the model fit:</p>
<pre class="calibre19">// RMSE for in-sample <br class="title-page-name"/>double regInSampleRMSE = Math.Sqrt(new SquareLoss(trainX).Loss(regInSamplePreds));<br class="title-page-name"/><br class="title-page-name"/>// RMSE for out-sample <br class="title-page-name"/>double regOutSampleRMSE = Math.Sqrt(new SquareLoss(testX).Loss(regOutSamplePreds));<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("RMSE: {0:0.0000} (Train) vs. {1:0.0000} (Test)", regInSampleRMSE, regOutSampleRMSE);</pre>
<p class="calibre2">As you can see from this code, we are using the <kbd class="calibre12">SquareLoss</kbd> class in the Accord.NET framework, which computes the squared values of the differences between the predicted and the actual values. In order to get the RMSE, we need to take a square root of this value.</p>
<p class="calibre2">The next metric that we are going to look at is R<sup class="calibre64">2</sup>. R<sup class="calibre64"><em class="calibre20">2</em></sup> is frequently used as an indicator of the goodness of fit. The closer the value is to 1, the better the model fit. The following code shows how we can compute R<sup class="calibre64">2</sup> values:</p>
<pre class="calibre19">// R^2 for in-sample <br class="title-page-name"/>double regInSampleR2 = new RSquaredLoss(trainX[0].Length, trainX).Loss(regInSamplePreds);<br class="title-page-name"/><br class="title-page-name"/>// R^2 for out-sample <br class="title-page-name"/>double regOutSampleR2 = new RSquaredLoss(testX[0].Length, testX).Loss(regOutSamplePreds);<br class="title-page-name"/><br class="title-page-name"/>Console.WriteLine("R^2: {0:0.0000} (Train) vs. {1:0.0000} (Test)", regInSampleR2, regOutSampleR2);</pre>
<p class="calibre2">As you can see from this code, we are using the <kbd class="calibre12">RSquaredLoss</kbd> class in the Accord.NET framework. We are computing once for in-sample predictions (predictions on the train set) and once for out-of-sample predictions (predictions on the test set). The closer the two values are, the less overfitting the models.</p>
<p class="calibre2">When you run this code for RMSE and R<sup class="calibre64">2</sup> for the linear regression model, the following is an output you will get:</p>
<div class="mce-root"><img class="alignnone14" src="../images/00062.gif"/></div>
<p class="calibre2">And for the SVM model, the output you will see is as follows:</p>
<div class="mce-root"><img class="alignnone15" src="../images/00063.gif"/></div>
<p class="calibre2">From these outputs, we can see that the SVM model outperforms the linear regression model by a large amount. The SVM model has a much lower RMSE compared to the linear regression model. Also, the SVM model has a much higher R<sup class="calibre64">2</sup> value than the linear regression model. Note the R<sup class="calibre64">2</sup> value for the linear regression model. This happens when the fit of the model is worse than a simple horizontal line, and this suggests that our linear regression model fit is not good. On the other hand, the R<sup class="calibre64">2</sup> for the SVM model is about 0.26, which suggests that 26% of the target variable variance can be explained by this model.</p>
<p class="calibre2">Lastly, we are going to look at a diagnostic plot; actual values versus predicted values. This diagnostic plot is a good way to visually see the goodness of the model fit. Ideally, we would want all the points to be on a diagonal line. For example, if the actual value is 1.0, then we would want to have predicted value close to 1.0. The closer the points are to the diagonal line, the better the model fit is. You can use the following code to plot actual values against predicted values:</p>
<pre class="calibre19">// Scatter Plot of expected and actual<br class="title-page-name"/>ScatterplotBox.Show(<br class="title-page-name"/>    String.Format("Actual vs. Prediction ({0})", modelName), testY, regOutSamplePreds<br class="title-page-name"/>);</pre>
<p class="calibre2"><span class="calibre5">We are using the <kbd class="calibre12">ScatterplotBox</kbd> class in the Accord.NET framework to build a scatter plot of actual values against predicted values. When you run this code for linear regression model results, you will see the following diagnostic plot:</span></p>
<div class="mce-root"><img src="../images/00064.jpeg" class="calibre70"/></div>
<p class="calibre2"><span class="calibre5">When you run the same code for the SVM model results, the diagnostic plot appears as follows:</span></p>
<div class="mce-root"><img src="../images/00065.jpeg" class="calibre71"/></div>
<p class="calibre2">As you can see from these plots, predictions from the linear regression model are more clogged around 0, while those from the SVM model are more spread out across a wider range. Although both plots for the linear regression and SVM model results do now show a perfect diagonal line, the plot for the SVM model shows better results and is aligned with the results we have seen from the RMSE and R<sup class="calibre64">2</sup> metrics.</p>
<p class="calibre2">The method we wrote and used to run validations for the models is as follows:</p>
<pre class="calibre19">private static void ValidateModelResults(string modelName, double[] regInSamplePreds, double[] regOutSamplePreds, double[][] trainX, double[] trainY, double[][] testX, double[] testY)<br class="title-page-name"/>{<br class="title-page-name"/>    // RMSE for in-sample <br class="title-page-name"/>    double regInSampleRMSE = Math.Sqrt(new SquareLoss(trainX).Loss(regInSamplePreds));<br class="title-page-name"/><br class="title-page-name"/>    // RMSE for in-sample <br class="title-page-name"/>    double regOutSampleRMSE = Math.Sqrt(new SquareLoss(testX).Loss(regOutSamplePreds));<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("RMSE: {0:0.0000} (Train) vs. {1:0.0000} (Test)", regInSampleRMSE, regOutSampleRMSE);<br class="title-page-name"/><br class="title-page-name"/>    // R^2 for in-sample <br class="title-page-name"/>    double regInSampleR2 = new RSquaredLoss(trainX[0].Length, trainX).Loss(regInSamplePreds);<br class="title-page-name"/><br class="title-page-name"/>    // R^2 for in-sample <br class="title-page-name"/>    double regOutSampleR2 = new RSquaredLoss(testX[0].Length, testX).Loss(regOutSamplePreds);<br class="title-page-name"/><br class="title-page-name"/>    Console.WriteLine("R^2: {0:0.0000} (Train) vs. {1:0.0000} (Test)", regInSampleR2, regOutSampleR2);<br class="title-page-name"/><br class="title-page-name"/>    // Scatter Plot of expected and actual<br class="title-page-name"/>    ScatterplotBox.Show(<br class="title-page-name"/>        String.Format("Actual vs. Prediction ({0})", modelName), testY, regOutSamplePreds<br class="title-page-name"/>    );<br class="title-page-name"/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2"><span class="calibre5">In this chapter, we built and trained our first regression models. We used a time series dataset that contains historical daily exchange rates between Euros and U.S. Dollars from 1999 to 2017. We first discussed how to create a target variable from an unlabeled raw dataset and how to apply the</span> <kbd class="calibre12">Shift</kbd> and <kbd class="calibre12">Diff</kbd> m<span class="calibre5">ethods in the Deedle framework in order to compute daily returns and create the target variable, which is the daily return for one period ahead. We further looked at the distributions of daily returns in a few different ways, such as a time series line chart, summary statistics using mean, standard deviation, and quantiles. We also looked at the histogram of daily returns and saw a well-drawn bell curve that follows a normal distribution. Then, we covered a few frequently used technical indicators in the foreign exchange market and how to apply them to our feature building processes. Using technical indicators, such as moving averages, Bollinger Bands, and lagged variables, we built various features that help our learning algorithms to learn how to predict future daily returns. With these features that we built in the feature engineering step, we built linear regression and SVM models to forecaste EUR/USD rates. We learned how to extract coefficients and the intercept from the </span><kbd class="calibre12">MultipleLinearRegression</kbd><em class="calibre13"> </em><span class="calibre5">object to gain insights into, and a better understanding, of how each feature affects the outcome of predictions. We briefly discussed the usage of kernels in building SVM models. Lastly, we went over two frequently used metrics for regression models, RMSE and R<sup class="calibre64">2</sup>, and a diagnostic plot of actual values versus predicted values. From this model validation step, we observed how the SVM model outperformed the linear regression model by a large amount. We also discussed the comparative benefits of explainability we can gain from using the linear regression model, compared to other black-box models such as random forest and SVM models.</span></p>
<p class="calibre2">In the next chapter, we are going to extend our knowledge and experience by building regression models in C# using the Accord.NET framework. We will use a house price dataset that contains both continuous and categorical variables and learn how to build regression models for such a complex dataset. We will also discuss various other kernels we can use for SVMs and how they affect the performance of our SVM models.</p>


            </article>

            
        </section>
    </body></html>