["```py\n<properties>\n     <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n     <jdk.version>1.8</jdk.version>\n     <spark.version>2.2.0</spark.version>\n     <nd4j.version>1.0.0-alpha</nd4j.version>\n     <dl4j.version>1.0.0-alpha</dl4j.version>\n     <datavec.version>1.0.0-alpha</datavec.version>\n     <arbiter.version>1.0.0-alpha</arbiter.version>\n     <logback.version>1.2.3</logback.version>\n</properties>\n```", "```py\n****************************************************************\n WARNING: COULD NOT LOAD NATIVE SYSTEM BLAS\n ND4J performance WILL be reduced\n ****************************************************************\n```", "```py\nval data = spark.read.option(\"maxColumns\", 25000).format(\"com.databricks.spark.csv\")\n      .option(\"header\", \"true\") // Use first line of all files as header\n      .option(\"inferSchema\", \"true\") // Automatically infer data types\n      .load(\"TCGA-PANCAN/TCGA-PANCAN-HiSeq-801x20531/data.csv\");// set this path accordingly\n```", "```py\nval numFeatures = data.columns.length\nval numSamples = data.count()\nprintln(\"Number of features: \" + numFeatures)\nprintln(\"Number of samples: \" + numSamples)\n```", "```py\nNumber of features: 20532\nNumber of samples: 801\n```", "```py\nval numericDF = data.drop(\"id\") // now 20531 features left\n```", "```py\nval labels = spark.read.format(\"com.databricks.spark.csv\")\n      .option(\"header\", \"true\") \n      .option(\"inferSchema\", \"true\") \n      .load(\"TCGA-PANCAN/TCGA-PANCAN-HiSeq-801x20531/labels.csv\") \nlabels.show(10)\n```", "```py\nval indexer = new StringIndexer().setInputCol(\"Class\")\n              .setOutputCol(\"label\")\n              .setHandleInvalid(\"skip\"); // skip null/invalid values    \n```", "```py\nval indexedDF = indexer.fit(labels).transform(labels)\n                       .select(col(\"label\")\n                       .cast(DataTypes.IntegerType)); // casting data types to integer\n```", "```py\nindexedDF.show()\n```", "```py\nval combinedDF = numericDF.join(indexedDF)\n```", "```py\nval splits = combinedDF.randomSplit(Array(0.7, 0.3), 12345L) //70% for training, 30% for testing\nval trainingDF = splits(0)\nval testDF = splits(1)\n```", "```py\nprintln(trainingDF.count())// number of samples in training set\nprintln(testDF.count())// number of samples in test set\n```", "```py\ntrainingDF.coalesce(1).write\n      .format(\"com.databricks.spark.csv\")\n      .option(\"header\", \"false\")\n      .option(\"delimiter\", \",\")\n      .save(\"output/TCGA_train.csv\")\n\ntestDF.coalesce(1).write\n      .format(\"com.databricks.spark.csv\")\n      .option(\"header\", \"false\")\n      .option(\"delimiter\", \",\")\n      .save(\"output/TCGA_test.csv\")\n```", "```py\n// Show data paths\nval trainPath = \"TCGA-PANCAN/TCGA_train.csv\"\nval testPath = \"TCGA-PANCAN/TCGA_test.csv\"\n```", "```py\n// Preparing training and test set.\nval labelIndex = 20531\nval numClasses = 5\nval batchSize = 128\n```", "```py\nval trainingDataIt: DataSetIterator = readCSVDataset(trainPath, batchSize, labelIndex, numClasses)\n```", "```py\nval testDataIt: DataSetIterator = readCSVDataset(testPath, batchSize, labelIndex, numClasses)\n```", "```py\n// Network hyperparameters\nval numInputs = labelIndex\nval numOutputs = numClasses\nval numHiddenNodes = 5000\n```", "```py\n//First LSTM layer\nval layer_0 = new LSTM.Builder()\n      .nIn(numInputs)\n      .nOut(numHiddenNodes)\n      .activation(Activation.RELU)\n      .build()\n\n//Second LSTM layer\nval layer_1 = new LSTM.Builder()\n      .nIn(numHiddenNodes)\n      .nOut(numHiddenNodes)\n      .activation(Activation.RELU)\n      .build()\n\n//Third LSTM layer\nval layer_2 = new LSTM.Builder()\n      .nIn(numHiddenNodes)\n      .nOut(numHiddenNodes)\n      .activation(Activation.RELU)\n      .build()\n\n//RNN output layer\nval layer_3 = new RnnOutputLayer.Builder()\n      .activation(Activation.SOFTMAX)\n      .lossFunction(LossFunction.MCXENT)\n      .nIn(numHiddenNodes)\n      .nOut(numOutputs)\n      .build()\n```", "```py\n//Create network configuration and conduct network training\nval LSTMconf: MultiLayerConfiguration = new NeuralNetConfiguration.Builder()\n      .seed(seed) //Random number generator seed for improved repeatability. Optional.\n      .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n      .weightInit(WeightInit.XAVIER)\n      .updater(new Adam(5e-3))\n      .l2(1e-5)\n      .list()\n          .layer(0, layer_0)\n          .layer(1, layer_1)\n          .layer(2, layer_2)\n          .layer(3, layer_3)\n      .pretrain(false).backprop(true).build()\n```", "```py\nval model: MultiLayerNetwork = new MultiLayerNetwork(LSTMconf)\nmodel.init()\n```", "```py\n//print the score with every 1 iteration\nmodel.setListeners(new ScoreIterationListener(1))\n\n//Print the number of parameters in the network (and for each layer)\nval layers = model.getLayers()\nvar totalNumParams = 0\nvar i = 0\n\nfor (i <- 0 to layers.length-1) {\n      val nParams = layers(i).numParams()\n      println(\"Number of parameters in layer \" + i + \": \" + nParams)\n      totalNumParams = totalNumParams + nParams\n}\nprintln(\"Total number of network parameters: \" + totalNumParams)\n```", "```py\nNumber of parameters in layer 0: 510640000\nNumber of parameters in layer 1: 200020000\nNumber of parameters in layer 2: 200020000\nNumber of parameters in layer 3: 25005\nTotal number of network parameters: 910705005\n```", "```py\nvar j = 0\nprintln(\"Train model....\")\nfor (j <- 0 to numEpochs-1) {\n   model.fit(trainingDataIt)\n```", "```py\nprintln(\"Evaluate model....\")\nval eval: Evaluation = new Evaluation(5) //create an evaluation object with 5 possible classes    \nwhile (testDataIt.hasNext()) {\n      val next:DataSet = testDataIt.next()\n      val output:INDArray  = model.output(next.getFeatureMatrix()) //get the networks prediction\n      eval.eval(next.getLabels(), output) //check the prediction against the true class\n    }\nprintln(eval.stats())\nprintln(\"****************Example finished********************\")\n  }\n```", "```py\n==========================Scores========================================\n # of classes:    5\n Accuracy:        0.9900\n Precision:       0.9952\n Recall:          0.9824\n F1 Score:        0.9886\n Precision, recall & F1: macro-averaged (equally weighted avg. of 5 classes)\n ========================================================================\n ****************Example finished******************\n```", "```py\nActual label 0 predicted by the model as 0: 82 times\nActual label 1 predicted by the model as 0: 1 times\nActual label 1 predicted by the model as 1: 17 times\nActual label 2 predicted by the model as 2: 35 times\nActual label 3 predicted by the model as 0: 1 times\nActual label 3 predicted by the model as 3: 30 times \n```"]