<html><head></head><body>
		<div id="_idContainer073">
			<h1 id="_idParaDest-106" class="chapter-number"><a id="_idTextAnchor019"/>7</h1>
			<h1 id="_idParaDest-107">Attributing Authorship and How to Evade It</h1>
			<p>The internet has provided the impetus to the fundamental right of freedom of expression by providing a public platform for individuals to voice their opinions, thoughts, findings, and concerns. Any person can express their views through an article, a blog post, or a video and post it online, free of charge in some cases (such as on Blogspot, Facebook, or YouTube). However, this has also led to malicious actors being able to generate misinformation, slander, libel, and abusive content freely. Authorship attribution is a task where we identify the author of a text based on the contents. Attributing authorship can help law enforcement authorities trace hate speech and threats to the perpetrator, or help social media companies detect coordinated attacks and <span class="No-Break">Sybil accounts.</span></p>
			<p>On the other hand, individuals may wish to remain anonymous as authors. They may want to protect their identity to avoid scrutiny or public interest. This is where authorship obfuscation comes into play. Authorship obfuscation is the task of modifying the text so that the author cannot be identified with <span class="No-Break">attribution techniques.</span></p>
			<p>In this chapter, we will cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Authorship attribution <span class="No-Break">and obfuscation</span></li>
				<li>Techniques for <span class="No-Break">authorship attribution</span></li>
				<li>Techniques for <span class="No-Break">authorship obfuscation</span></li>
			</ul>
			<p>By the end of this chapter, you will have an understanding of authorship attribution, the socio-technical aspects behind it, and methods to <span class="No-Break">evade it.</span></p>
			<h1 id="_idParaDest-108">Technical requirements</h1>
			<p>You can find the code files for this chapter on GitHub <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%207"><span class="No-Break">https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/tree/main/Chapter%207</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-109">Authorship attribution and obfuscation</h1>
			<p>In this section, we will discuss exactly what authorship attribution is and the incentives for designing attribution systems. While there are some very good reasons for doing so, there are some nefarious ones as well; we will therefore also discuss the importance of obfuscation to protect against attacks by <span class="No-Break">nefarious attackers.</span></p>
			<h2 id="_idParaDest-110">What is authorship attribution?</h2>
			<p><strong class="bold">Authorship attribution</strong> is the task of<a id="_idIndexMarker527"/> identifying the author of a given text. The fundamental idea behind attribution is that different authors have different styles of writing that will reflect in the vocabulary, grammar, structure, and overall organization of the text. Attribution can be based on heuristic methods (such as similarity, common word analysis, or manual expert analysis). Recent advances in <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) have also<a id="_idIndexMarker528"/> made it possible to build classifiers that can learn to detect the author of a <span class="No-Break">given text.</span></p>
			<p>Authorship attribution is not a new problem—the study of this field goes back to 1964. A series of papers known as <em class="italic">The Federalist Papers</em> had been published, which contained over 140 political essays. While the work was jointly authored by 3 people, 12 of those essays were claimed by 2 authors. The study by Mosteller and Wallace involving Bayesian modeling and statistical analysis using <em class="italic">n</em>-grams, which produced statistically significant differences between the authors, is known to be the first actual work in <span class="No-Break">authorship attribution.</span></p>
			<p>Authorship attribution is important for several reasons, as <span class="No-Break">outlined here:</span></p>
			<ul>
				<li><strong class="bold">Historical significance</strong>: Scientists and researchers rely on historical documents and texts for evidence <a id="_idIndexMarker529"/>of certain events. At times, these may have immense political and cultural significance, and knowing the author would help place them in the proper context and determine their credibility. For example, if an account describing certain historical periods and projecting dictators or known malicious actors in a positive light were to be found, it would be important to ascertain who the author is, as that could change the credibility of the text. Authorship attribution would help in determining whether the text could be accepted as an authoritative source <span class="No-Break">or not.</span></li>
				<li><strong class="bold">Intellectual property</strong>: As with <em class="italic">The Federalist Papers</em>, there is often contention on who the owner of certain creative or academic works is. This happens when multiple people claim ownership over the same book, article, or research paper. At other<a id="_idIndexMarker530"/> times, one individual may be accused of plagiarizing the work of another. In such cases, it is extremely important to trace who the author of a particular text is. Authorship attribution can help identify the author, match similarity in style and tone, and resolve issues of contended <span class="No-Break">intellectual property.</span></li>
				<li><strong class="bold">Criminal investigation</strong>: Criminals often use text as a means of communicating with victims and law enforcement. This can be in the form of a ransom note or threats. If there is a significant amount of text, it may be possible that it reflects some of the stylistic habits of the author. Law enforcement officers use authorship attribution methods to determine whether the messages received fit the style of any <span class="No-Break">known criminal.</span></li>
				<li><strong class="bold">Abuse detection</strong>: Sybil accounts are a growing challenge on the internet and social media. These are a group of accounts controlled by the same entity but masquerading as different people. Sybil accounts have nefarious purposes such as multiple Facebook accounts generating fake engagement, or multiple Amazon accounts to write fake product reviews. As they are controlled by the same entity, the content produced (posts, tweets, reviews) is generally similar. Authorship attribution can be used to identify groups of accounts that post content written by the <span class="No-Break">same author.</span></li>
			</ul>
			<p>With the prevalence of the internet and social media platforms, cybercrime has been on the rise, and malicious actors are preying on unknowing victims. Authorship attribution, therefore, is also a cybersecurity problem. The next section will describe authorship obfuscation, a task that counters <span class="No-Break">authorship attribution.</span></p>
			<h2 id="_idParaDest-111">What is authorship obfuscation?</h2>
			<p>In the previous section, we <a id="_idIndexMarker531"/>discussed authorship attribution, which is the task of identifying the author of a given text. Authorship obfuscation is a task that works exactly toward <span class="No-Break">the opposite.</span></p>
			<p>Given a text, authorship obfuscation aims to manipulate and modify the text in such a way that the end result <span class="No-Break">is this:</span></p>
			<ul>
				<li>The meaning and key points in the text are <span class="No-Break">left intact</span></li>
				<li>The style, structure, and vocabulary are suitably modified so that the text cannot be attributed to the original author (that is, authorship attribution techniques will <span class="No-Break">be evaded)</span></li>
			</ul>
			<p>Individuals may use obfuscation techniques to hide their identity. Consider the sentence <em class="italic">“We have observed great corruption at the highest levels of government in this country.”</em> If this is re-written as <em class="italic">“Analysis has shown tremendous corrupt happenings in the uppermost echelons of this nation’s administration,”</em> the meaning is left intact. However, the style is clearly different and does not bear much resemblance to the original author. This is effective obfuscation. An analyst examining the text will not be easily able to map it to the <span class="No-Break">same author.</span></p>
			<p>Note that both of the objectives in obfuscation (that is, retaining the original meaning and stripping off the style markers) are equally important and there is a trade-off between them. We can obtain high obfuscation by making extreme changes to the text, but at that point, the text may have lost its original meaning and intent. On the other hand, we can retain the meaning with extremely minor tweaks—but this may not lead to <span class="No-Break">effective obfuscation.</span></p>
			<p>Authorship obfuscation has both positive and negative use cases. Malicious actors can use obfuscation techniques in order to counter the attribution purposes discussed previously and avoid detection. For example, a criminal who wants to stay undetected and yet send ransom notes and emails may obfuscate their text by choosing a different vocabulary, grammatical structure, and organization. However, obfuscation has several important use cases in civil and human rights, as <span class="No-Break">detailed here:</span></p>
			<ul>
				<li><strong class="bold">Oppressive governments</strong>: As discussed before, the internet has greatly facilitated the human right to freely express oneself. However, some governments may try to curtail these rights by targeting individuals who speak up against them. For <a id="_idIndexMarker532"/>example, an autocratic government may want to prohibit reporting on content that speaks against its agenda or expose corruption and malicious schemes. At such times, journalists and individuals may want to remain anonymous—their identity being detected could lead to them being captured. Obfuscation techniques will alter the text they write so that the matter they want to convey will be retained, but the writing style will be significantly different than their <span class="No-Break">usual one.</span></li>
				<li><strong class="bold">Sensitive issues</strong>: Even if the government is not oppressive by nature, certain issues may be sensitive to discuss and controversial. Examples of such issues include religion, racial discrimination, reports of sexual violence, homosexuality, and reproductive healthcare. Individuals who write about such issues may offend the public or certain other groups or sects. Authorship obfuscation allows such individuals to publish such content and yet remain anonymous (or, at least, makes it harder to discern the author of <span class="No-Break">the text).</span></li>
				<li><strong class="bold">Privacy and anonymity</strong>: Many believe that privacy is a fundamental human right. Therefore, even if an issue is not sensitive or the government is not corrupt, users have the right to protect their identity if they want to. Every individual should be free to post what they want and hide their identity. Authorship obfuscation allows users to maintain their privacy while <span class="No-Break">expressing themselves.</span></li>
			</ul>
			<p>Now that you have a good understanding of authorship attribution and obfuscation and why it is actually needed, let us go into implementing it <span class="No-Break">with Python.</span></p>
			<h1 id="_idParaDest-112">Techniques for authorship attribution</h1>
			<p>The previous section <a id="_idIndexMarker533"/>described the importance of authorship <a id="_idIndexMarker534"/>attribution and obfuscation. This section will focus on the attribution aspect—how we can design and build models to pinpoint the author of a <span class="No-Break">given text.</span></p>
			<h2 id="_idParaDest-113">Dataset</h2>
			<p>There has been prior research in the <a id="_idIndexMarker535"/>field of authorship attribution and obfuscation. The standard dataset for benchmarking on this task is the <em class="italic">Brennan-Greenstadt Corpus</em>. This dataset was collected through a survey at a university in the United States. 12 authors were recruited, and each author was required to submit a pre-written text that comprised at least <span class="No-Break">5,000 words.</span></p>
			<p>A modified and improved version of this data—called the <em class="italic">Extended Brennan-Greenstadt Corpus</em>—was released later by the same authors. To generate this dataset, the authors conducted a large-scale survey by recruiting participants from Amazon <strong class="bold">Mechanical Turk</strong> (<strong class="bold">MTurk</strong>). MTurk is a <a id="_idIndexMarker536"/>platform that allows researchers and scientists to conduct human-subjects research. Users sign up for MTurk and fill out detailed questionnaires, which makes it easier for researchers to survey the segment or<a id="_idIndexMarker537"/> demographic (by gender, age, nationality) they want. Participants get paid for every <strong class="bold">human interaction task</strong> (<strong class="bold">HIT</strong>) <span class="No-Break">they complete.</span></p>
			<p>To create the extended corpus, MTurk was used so that the submissions would be diverse and varied and not limited to university students. Each piece of writing was scientific or scholarly (such as an essay, a research paper, or an opinion paper). The submission only contained text and no other information (such as references, citations, URLs, images, footnotes, endnotes, and section breaks). Quotations were to be kept to a minimum as most of the text was supposed to be author generated. Each sample had at least <span class="No-Break">500 words.</span></p>
			<p>Both the <em class="italic">Brennan-Greenstadt Corpus</em> and the <em class="italic">Extended Brennan-Greenstadt Corpus</em> are available online to the public for free. For simplicity, we will run our experiments with the <em class="italic">Brennan-Greenstadt Corpus</em> (which contains writing samples from university students). However, readers are encouraged to reproduce the results on the extended corpus, and tune models as required. The process and code would remain the same—you would have to just change the <span class="No-Break">underlying dataset.</span></p>
			<p>For convenience, we have provided the dataset we're using (<a href="https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/blob/main/Chapter%207/Chapter_7.ipynb">https://github.com/PacktPublishing/10-Machine-Learning-Blueprints-You-Should-Know-for-Cybersecurity/blob/main/Chapter%207/Chapter_7.ipynb</a>). The dataset consists of a root folder that has one subfolder for every author. Each subfolder contains writing samples for the author. You will need to unzip the data and place it into the folder you want (and change <strong class="source-inline">data_root_dir</strong> in the following <span class="No-Break">code accordingly).</span></p>
			<p>Recall that for our experiments, we need to read the dataset such that the input (features) is in an array and the labels are in a separate array. The following code snippet parses the folder <a id="_idIndexMarker538"/>structure and produces data in <span class="No-Break">this format:</span></p>
			<pre class="source-code">
def read_dataset(num_authors = 99):
  X = []
  y = []
  data_root_dir = "../data/corpora/amt/"
  authors_to_ignore = []
  authorCount = 0
  for author_name in os.listdir(data_root_dir):
      # Check if the maximum number of authors has been parsed
      if authorCount &gt; self.numAuthors:
         break
      if author_name not in authors_to_ignore:
         label = author_name
         documents_path = data_root_dir + author_name + "/"
         authorCount += 1
         for doc in os.listdir(documents_path):
            if validate_file(doc):
              text = open(docPath + doc, errors = "ignore").read()
              X.append(text)
              y.append(label)
  return X, y</pre>
			<p>The dataset also contains some housekeeping files as well as some files that indicate the training, test, and validation data. We need a function to filter out these so that this information is not<a id="_idIndexMarker539"/> read in the data. Here’s what <span class="No-Break">we’ll use:</span></p>
			<pre class="source-code">
def validate_file(file_name):
    filterWords = ["imitation", "demographics", "obfuscation", "verification"]
    for fw in filterWords:
        if fw in file_name:
            return False
    return True</pre>
			<p>Our dataset has been read, and we can now extract features from it. For authorship attribution, most features are stylometric and hand-crafted. In the next section, we will explore some features that have shown success in <span class="No-Break">prior work.</span></p>
			<h2 id="_idParaDest-114">Feature extraction</h2>
			<p>We will now implement a <a id="_idIndexMarker540"/>series of functions, each of which extracts a particular feature from our data. Each function will take in the input text as a parameter, process it, and return the feature <span class="No-Break">as output.</span></p>
			<p>We begin as usual by importing the <span class="No-Break">required libraries:</span></p>
			<pre class="source-code">
import os
import nltk
import re
import spacy
from sortedcontainers import SortedDict
from keras.preprocessing import text
import numpy as np</pre>
			<p>As a first feature, we will use the number of characters in <span class="No-Break">the input:</span></p>
			<pre class="source-code">
def CountChars(input):
    num_chars = len(input)
    return num_chars</pre>
			<p>Next, we will design a feature that measures the average word length (number of characters per word). For this, we first split the text into an array of words and clean it up by removing any<a id="_idIndexMarker541"/> special characters such as braces, symbols, and punctuation. Then, we calculate the number of characters and the number of words separately. Their ratio is our <span class="No-Break">desired feature:</span></p>
			<pre class="source-code">
def averageCharacterPerWord(input):
    text_array = text.text_to_word_sequence(input,
                                            filters=' !#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_{|}~\t\n"',
                                            lower=False, split=" ")
    num_words = len(text_array)
    text_without_spaces = input.replace(" ", "")
    num_chars = len(text_without_spaces)
    avgCharPerWord = 1.0 * num_chars / num_words
    return avgCharPerWord</pre>
			<p>Now, we calculate the frequency of alphabets. We will first create a 26-element array where each element counts the number of times that alphabet appears in the text. The first element corresponds to A, the next to B, and so on. Note that as we are counting alphabets, we need to convert the text to lowercase. However, if this were our feature, it would depend heavily<a id="_idIndexMarker542"/> on the length of the text. Therefore, we normalize this by the total number of characters. Each element of the array, therefore, depicts the percentage of that particular alphabet in <span class="No-Break">the text:</span></p>
			<pre class="source-code">
def frequencyOfLetters(input):
    input = input.lower()  # because its case sensitive
    input = input.lower().replace(" ", "")
    num_chars = len(input)
    characters = "abcdefghijklmnopqrstuvwxyz".split()
    frequencies = []
    for each_char in characters:
      char_count = input.count(each_char)
      if char_count &lt; 0:
        frequencies.append(0)
      else:
        frequencies.append(char_count/num_chars)
    return frequencies</pre>
			<p>Next, we will calculate the frequency of common bigrams. Prior research in linguistics and phonetics has indicated which bigrams are common in English writing. We will first compile a list of such bigrams. Then, we will parse through the list and calculate the frequency of each bigram and compute a vector. Finally, we normalize this vector, and the result represents <span class="No-Break">our feature:</span></p>
			<pre class="source-code">
def CommonLetterBigramFrequency(input):
    common_bigrams = ['th','he','in','er','an','re','nd',
                      'at','on','nt','ha','es','st','en',
                      'ed','to','it','ou','ea','hi','is',
                      'or','ti','as','te','et','ng','of',
                      'al','de','se','le','sa','si','ar',
                      've','ra','ld','ur']
    bigramCounter = []
    input = input.lower().replace(" ", "")
    for bigram in common_bigrams:
      bigram_count = input.count(bigram)
      if bigram_count == -1:
        bigramCounter.append(0)
      else:
        bigramCounter.append(bigram_count)
    total_bigram_count = np.sum(bigramCounter)
    bigramCounterNormalized = []
    for bigram_count in bigramCounter:
      bigramCounterNormalized.append(bigram_count / total_bigram_count)
    return bigramCounterNormalized</pre>
			<p>Just as with the common bigrams, we also compute the frequency of common trigrams (sequences of three alphabets). The final feature represents a normalized vector, similar to what we had <span class="No-Break">for</span><span class="No-Break"><a id="_idIndexMarker543"/></span><span class="No-Break"> bigrams:</span></p>
			<pre class="source-code">
def CommonLetterTrigramFrequency(input):
    common_trigrams = ["the", "and", "ing", "her", "hat",
                       "his", "tha", "ere", "for", "ent",
                       "ion", "ter", "was", "you", "ith",
                       "ver", "all", "wit", "thi", "tio"]
    trigramCounter = []
    input = input.lower().replace(" ", "")
    for trigram in common_trigrams:
      trigram_count = input.count(trigram)
      if trigram_count == -1:
        trigramCounter.append(0)
      else:
        trigramCounter.append(trigram_count)
    total_trigram_count = np.sum(trigramCounter)
    trigramCounterNormalized = []
    for trigram_count in trigramCounter:
      trigramCounterNormalized.append(trigram_count / total_trigram_count)
    return trigramCounterNormalized</pre>
			<p>The next feature is the percentage of characters that are digits. First, we calculate the total number of characters in the text. Then, we parse through the text character by character and check whether each character is numeric. We count all such occurrences and divide them by the total number we computed earlier—this gives us <span class="No-Break">our feature:</span></p>
			<pre class="source-code">
def digitsPercentage(input):
    num_chars = len(input)
    num_digits = 0
    for each_char in input:
      if each_char.isnumeric():
        num_digits = num_digits + 1
    digit_percent = num_digits / num_chars
    return digit_percent</pre>
			<p>Similarly, the next feature is the percentage of characters that are alphabets. We will first need to convert the<a id="_idIndexMarker544"/> text to lowercase. Just as with the previous feature, we parse character by character, now checking whether each character we encounter is in the <span class="No-Break">range </span><span class="No-Break"><strong class="source-inline">[a-z]</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
def charactersPercentage(input):
    input = input.lower().replace(" ", "")
    characters = "abcdefghijklmnopqrstuvwxyz"
    total_chars = len(input)
    char_count = 0
    for each_char in input:
      if each_char in characters:
        char_count = char_count + 1
    char_percent = char_count / total_chars
    return char_percent</pre>
			<p>Previously, we calculated <a id="_idIndexMarker545"/>the frequency of alphabets. On similar lines, we calculate the frequency of each digit from <strong class="source-inline">0</strong> to <strong class="source-inline">9</strong> and normalize it. The normalized vector is used as <span class="No-Break">our feature:</span></p>
			<pre class="source-code">
def frequencyOfDigits(input):
    input = input.lower().replace(" ", "")
    num_chars = len(input)
    digits = "0123456789".split()
    frequencies = []
    for each_digit in digits:
      digit_count = input.count(each_digit)
      if digit_count &lt; 0:
        frequencies.append(0)
      else:
        frequencies.append(digit_count/num_chars)
    return frequencies</pre>
			<p>We will now calculate the percentage of characters that are uppercase. We follow a similar procedure as we did <a id="_idIndexMarker546"/>for counting the characters, but now we count for capital letters instead. The result is normalized, and the normalized value forms <span class="No-Break">our feature:</span></p>
			<pre class="source-code">
def upperCaseCharactersPercentage(input):
    input = input.replace(" ", "")
    upper_characters = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    num_chars = len(input)
    upper_count = 0
    for each_char in upper_characters:
      char_count = input.count(each_char)
      if char_count &gt; 0:
        upper_count = upper_count + char_count
    upper_percent = upper_count / num_chars
    return upper_percent</pre>
			<p>Now, we will calculate the frequency of special characters in our text. We first compile a list of special characters of interest in a file. We parse the file and count the frequency of each character and form a vector. Finally, we normalize this vector by the total number of characters. Note that the following function uses a static file where the list of characters is stored—you will need to change this line of code to reflect the path where the file is stored on <span class="No-Break">your system:</span></p>
			<pre class="source-code">
def frequencyOfSpecialCharacters(input):
    SPECIAL_CHARS_FILE = "static_files/writeprints_special_chars.txt"
    num_chars = len(input)
    special_counts = []
    special_characters = open(SPECIAL_CHARS_FILE , "r").readlines()
    for each_char in special_characters:
      special = each_char.strip().rstrip()
      special_count = input.count(special)
      if special_count &lt; 0:
        special_counts.append(0)
      else:
        special_counts.append(special_count / num_chars)
    return special_counts</pre>
			<p>Next, we will count the number of short words in the text. We define a short word as one with fewer than or at<a id="_idIndexMarker547"/> most three characters. This is a rather heuristic definition; there is no globally accepted standard for a word being short. You can play around with different values here and see whether it affects <span class="No-Break">the results:</span></p>
			<pre class="source-code">
def CountShortWords(input):
    words = text.text_to_word_sequence(input, filters=",.?!\"'`;:-()&amp;$", lower=True, split=" ")
    short_word_count = 0
    for word in words:
        if len(word) &lt;= 3:
            short_word_count = short_word_count + 1
    return short_word_count</pre>
			<p>As a very simple feature, we compute the total number of words in the input. This involves splitting the text into an array of words (cleaning up special characters) and counting the length of <span class="No-Break">the array:</span></p>
			<pre class="source-code">
def CountWords(input):
    words = text.text_to_word_sequence(input, filters=",.?!\"'`;:-()&amp;$", lower=True, split=" ")
    return len(words)</pre>
			<p>Now, we calculate the <a id="_idIndexMarker548"/>average word length. We simply calculate the length of each word in the text and use the mean of all such length values as <span class="No-Break">the feature:</span></p>
			<pre class="source-code">
def averageWordLength(input):
    words = text.text_to_word_sequence(inputText, filters=",.?!\"'`;:-()&amp;$", lower=True, split=" ")
    lengths = []
    for word in words:
        lengths.append(len(word))
    return np.mean(lengths)</pre>
			<p>We now have all of the functions to compute features in place. Each function will take in the text as a parameter and process it to produce the feature we designed. Now, we will write a wrapper function to put it all together. This function, on being passed the text, will run it through all of our feature extraction functions and compute each feature. Each feature will be appended to a vector. This forms our final <span class="No-Break">feature vector:</span></p>
			<pre class="source-code">
def calculate_features(input):
  features = []
  features.extend([CountWords(input)])
  features.extend([averageWordLength(input)])
  features.extend([CountShortWords(input)])
  features.extend([CountChars(input)])
  features.extend([averageCharacterPerWord(input)])
  features.extend([frequencyOfLetters(input)])
  features.extend([CommonLetterBigramFrequency(input)])
  features.extend([CommonLetterTrigramFrequency(input)])
  features.extend([digitsPercentage(input)])
  features.extend([charactersPercentage(input)])
  features.extend([frequencyOfDigits(input)])
  features.extend([upperCaseCharactersPercentage(input)])
  features.extend([frequencyOfSpecialCharacters(input)])
  features.extend([frequencyOfPunctuationCharacters(input)])
  features.extend([posTagFrequency(input)])</pre>
			<p>Now, all that is to<a id="_idIndexMarker549"/> be done is to apply this function to <span class="No-Break">our dataset:</span></p>
			<pre class="source-code">
X_original, Y = read_dataset(num_authors = 6)
X_Features = []
for x in X_original:
  x_features = calculate_features(x)
  X.append(x_features)</pre>
			<p>After this is executed, <strong class="source-inline">X</strong> will be an array containing features that we designed, and <strong class="source-inline">Y</strong> will contain the<a id="_idIndexMarker550"/> corresponding labels. The hard part is done! Next, we will turn to the <span class="No-Break">modeling phase.</span></p>
			<h2 id="_idParaDest-115">Training the attributor</h2>
			<p>In the previous <a id="_idIndexMarker551"/>section, we processed our dataset, hand-crafted several features, and now have one feature vector per text and the ground-truth label corresponding to it. At this point, this is essentially a <strong class="bold">supervised learning</strong> (<strong class="bold">SL</strong>) problem; we <a id="_idIndexMarker552"/>have the features and labels and want to learn the association between them. We will approach this as we did with all other supervised problems we have seen <span class="No-Break">so far.</span></p>
			<p>To recap, here are the steps <span class="No-Break">we’ll take:</span></p>
			<ol>
				<li>Split the data into training and <span class="No-Break">testing sets.</span></li>
				<li>Train a supervised classifier on the <span class="No-Break">training set.</span></li>
				<li>Evaluate the performance of the trained model on the <span class="No-Break">testing set.</span></li>
			</ol>
			<p>First, we split the data as follows. Note that we have a mix of authors, therefore we have multiple labels. We must ensure that the distribution of labels in the training and test sets is roughly similar; otherwise, our model will be biased toward specific authors. If a particular author does not appear in the training set, the model will not be able to detect them <span class="No-Break">at all.</span></p>
			<p>Then, we train our classification model (logistic regression, decision tree, random forest, <strong class="bold">deep neural network</strong> (<strong class="bold">DNN</strong>)) on the<a id="_idIndexMarker553"/> training set. We use this model to make predictions for the data in the test set and compare the predictions with the ground truth. As this procedure has been covered in preceding chapters, we will not go into detailed <span class="No-Break">explanations here.</span></p>
			<p>A sample code snippet that performs the previous steps with a random forest is shown next. Readers should repeat it with other models <span class="No-Break">as well:</span></p>
			<pre class="source-code">
# Import Packages
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from matplotlib import pyplot as plt
import seaborn as sns
# Training and Test Datasets
X_train, X_test, Y_train, Y_test = train_test_split(X_Features, Y)
# Train the model
model = RandomForestClassifier(n_estimators = 100)
model.fit(X_train, Y_train)
# Plot the confusion matrix
Y_predicted = model.predict(X_test)
confusion = confusion_matrix(Y_test, Y_predicted)
plt.figure(figsize = (10,8))
sns.heatmap(confusion, annot = True,
            fmt = 'd', cmap="YlGnBu")</pre>
			<p>As you run this, you will notice that the confusion matrix now looks different. Whereas previously we <a id="_idIndexMarker554"/>had a 2x2 matrix, now we get a 6x6 matrix. This is because our dataset now contains six different labels (one for every author). Therefore, for every data point with a given class, there are six possible classes to <span class="No-Break">be predicted.</span></p>
			<p>Calculating accuracy is still the same; we need to find the fraction of examples that were predicted correctly. Here is a function that <span class="No-Break">does this:</span></p>
			<pre class="source-code">
def calculate_accuracy(actual, predicted):
  total_examples = len(actual)
  correct_examples = 0
  for idx in range(total_examples):
    if actual[i] == predicted[i]:
      correct_examples = correct_examples + 1
  accuracy = correct_examples / total_examples
  return accuracy</pre>
			<p>In multi-class problems, the <a id="_idIndexMarker555"/>definitions of precision and recall are no longer as simple as computing false positives and negatives. Rather, these metrics are calculated per class. For example, if there are six labels (1-6), then for class 2, we say <span class="No-Break">the following:</span></p>
			<ul>
				<li>True positives are those where the actual and predicted classes are <span class="No-Break">both 2</span></li>
				<li>False positives are the ones where the predicted class is 2, but the actual class is anything other <span class="No-Break">than 2</span></li>
				<li>True negatives are those where both the actual and predicted classes are anything other <span class="No-Break">than 2</span></li>
				<li>False negatives are those where the predicted class is anything other than 2, but the actual class <span class="No-Break">is 2</span></li>
			</ul>
			<p>Using these definitions and the usual expressions for calculating metrics, we can calculate per-class metrics. The per-class precision and recall may be averaged to compute the overall precision, recall, and <span class="No-Break">F1 scores.</span></p>
			<p>Fortunately, we do not need to manually implement this per-class metric calculation. <strong class="source-inline">scikit-learn</strong> has an inbuilt classification report that will compute and produce these metrics for you. This can be used <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
from sklearn.metrics import classification_report
classification_report(Y_test, Y_predicted)</pre>
			<p>This completes our implementation and analysis of authorship attribution. Next, we will suggest some experiments<a id="_idIndexMarker556"/> that readers can pursue to explore the <span class="No-Break">topic more.</span></p>
			<h2 id="_idParaDest-116">Improving authorship attribution</h2>
			<p>We have presented <a id="_idIndexMarker557"/>vanilla models and techniques for authorship attribution. However, there is a large scope for improvement here. As data scientists, we must be willing to explore new ideas and techniques and continuously improve our models. Here are a few suggestions that readers should try out to see whether they can obtain a <span class="No-Break">better performance.</span></p>
			<h3>Additional features</h3>
			<p>We have used the feature set<a id="_idIndexMarker558"/> that is known as the Writeprints set of features. This has shown success in prior research. However, this is not an exhaustive list of features. Readers can explore more hand-crafted and automatic features to evaluate whether performance is improved. Examples of some features are set <span class="No-Break">out here:</span></p>
			<ul>
				<li><span class="No-Break">Text sentiment</span></li>
				<li><span class="No-Break">Text polarity</span></li>
				<li>Number and <a id="_idIndexMarker559"/>fraction of <span class="No-Break">function words</span></li>
				<li><strong class="bold">Term Frequency – Inverse Document Frequency</strong> (<span class="No-Break"><strong class="bold">TF-IDF</strong></span><span class="No-Break">) features</span></li>
				<li>Word embeddings derived <span class="No-Break">from Word2vec</span></li>
				<li>Contextual word embeddings derived from <strong class="bold">Bidirectional Encoder Representations from </strong><span class="No-Break"><strong class="bold">Transformers</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">BERT</strong></span><span class="No-Break">)</span></li>
			</ul>
			<h3>Data configurations</h3>
			<p>The experiment we ran was on a <a id="_idIndexMarker560"/>subset of six authors from the dataset. In the real world, the problem is much more open-ended and there may be several more authors. It is worth exploring how the model performance varies as the number of authors changes. In particular, readers should explore <span class="No-Break">the following:</span></p>
			<ul>
				<li>What are the performance measures if we choose only 3 authors? What about if we <span class="No-Break">choose 12?</span></li>
				<li>How does the performance change if we model this problem as binary classification? Instead of predicting the author, we predict whether a particular text was written by a<a id="_idIndexMarker561"/> particular author or not. This would involve training a separate classifier per author. Does this show better predictive power and practical application than the <span class="No-Break">multi-class approach?</span></li>
			</ul>
			<h3>Model improvements</h3>
			<p>For brevity and to avoid repetition, we<a id="_idIndexMarker562"/> showed only the example of a random forest. However, readers should experiment with more models, including<a id="_idIndexMarker563"/> but not limited to <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Support vector </strong><span class="No-Break"><strong class="bold">machines</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SVMs</strong></span><span class="No-Break">)</span></li>
				<li><span class="No-Break">Naïve-Bayes classifier</span></li>
				<li><span class="No-Break">Logistic regression</span></li>
				<li><span class="No-Break">Decision tree</span></li>
				<li><span class="No-Break">DNN</span></li>
			</ul>
			<p>The <strong class="bold">neural network</strong> (<strong class="bold">NN</strong>) algorithms will<a id="_idIndexMarker564"/> be particularly useful as the number of features increases. When the embeddings and TF-IDF scores are added, the features will not be easily interpretable anymore—NNs excel in such situations where they can discover <span class="No-Break">high-dimensional features.</span></p>
			<p>This completes our discussion of authorship attribution. In the next section, we will discuss a problem that is the opposite of the <span class="No-Break">attribution task.</span></p>
			<h1 id="_idParaDest-117">Techniques for authorship obfuscation</h1>
			<p>So far, we have seen how <a id="_idIndexMarker565"/>authorship can be attributed to the writer and how to build models to detect the author. In this section, we will turn to the authorship obfuscation problem. Authorship obfuscation, as discussed in the initial section of this chapter, is the art of purposefully manipulating the text to strip it of any stylistic features that might give away <span class="No-Break">the author.</span></p>
			<p>The code is inspired by an implementation that is freely available online (<a href="https://github.com/asad1996172/Obfuscation-Systems">https://github.com/asad1996172/Obfuscation-Systems</a>) with a few <span class="No-Break">minor tweaks.</span></p>
			<p>First, we will import the<a id="_idIndexMarker566"/> required libraries. The most important library here is the <strong class="bold">Natural Language Toolkit</strong> (<strong class="bold">NLTK</strong>) library (<a href="https://www.nltk.org/">https://www.nltk.org/</a>) developed<a id="_idIndexMarker567"/> by Stanford. This library contains standard off-the-shelf implementations for several <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) tasks such as <a id="_idIndexMarker568"/>tokenization, <strong class="bold">part-of-speech</strong> (<strong class="bold">POS</strong>) tagging, <strong class="bold">named entity recognition</strong> (<strong class="bold">NER</strong>), and so on. It has a powerful set of functionalities that greatly <a id="_idIndexMarker569"/>simplify feature extraction in text <a id="_idIndexMarker570"/>data. You are encouraged to explore the library in detail. The <strong class="bold">word-sense disambiguation</strong> (<strong class="bold">WSD</strong>) implementation (<a href="https://github.com/asad1996172/Obfuscation-Systems/blob/master/Document%20Simplification%20PAN17/WSD_with_UKB.py">https://github.com/asad1996172/Obfuscation-Systems/blob/master/Document%20Simplification%20PAN17/WSD_with_UKB.py</a>) can be found online and should be downloaded locally. </p>
			<p>The code to import the libraries is <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
import nltk
import re
import random
import pickle
from nltk.wsd import lesk
from nltk.corpus import wordnet as wn
import WSD_with_UKB as wsd
from nltk.tokenize import sent_tokenize
from nltk.tokenize import RegexpTokenizer</pre>
			<p>First, we will implement a function for the expansion and contraction replacement. We begin by reading the extraction-contraction list from the <strong class="source-inline">pickle</strong> file (you will have to change the path to it accordingly). The result is a dictionary where the keys are contractions and values associated are corresponding expansions. We parse through the sentence and count the expansions and contractions occurring. If there are mostly contractions, we replace them with expansions, and if there are mostly expansions, we replace them with <a id="_idIndexMarker571"/>contractions. If both are the same, we do nothing <span class="No-Break">at all:</span></p>
			<pre class="source-code">
def contraction_replacement(sentence):
    # Read Contractions
    CONTRACTION_FILE = 'contraction_extraction.pickle'
    with open(CONTRACTION_FILE, 'rb') as contraction_file:
        contractions = pickle.load(contraction_file)
    # Calculate contraction counts
    all_contractions = contractions.keys()
    contractions_count = 0
    for contraction in all_contractions:
        if contraction.lower() in sentence.lower():
            contractions_count += 1
    # Calculate expansion counts
    all_expansions = contractions.values()
    expansions_count = 0
    for expansion in all_expansions:
        if expansion.lower() in sentence.lower():
            expansions_count += 1
    if contractions_count &gt; expansions_count:
        # There are more contractions than expansions
        # So we should replace all contractions with their expansions
        temp_contractions = dict((k.lower(), v) for k, v in contractions.items())
        for contraction in all_contractions:
            if contraction.lower() in sentence.lower():
                case_insensitive = re.compile(re.escape(contraction.lower()), re.IGNORECASE)
                sentence = case_insensitive.sub(temp_contractions[contraction.lower()], sentence)
        contractions_applied = True
    elif expansions_count &gt; contractions_count:
        # There are more expansions than contractions
        # So we should replace expansions by contractions
        inv_map = {v: k for k, v in contractions.items()}
        temp_contractions = dict((k.lower(), v) for k, v in inv_map.items())
        for expansion in all_expansions:
            if expansion.lower() in sentence.lower():
                case_insensitive = re.compile(re.escape(expansion.lower()), re.IGNORECASE)
                sentence = case_insensitive.sub(temp_contractions[expansion.lower()], sentence)
        contractions_applied = True
    else:
        # Both expansions and contractions are equal
        # So do nothing
        contractions_applied = False
    return sentence, contractions_applied</pre>
			<p>Next, we will remove <a id="_idIndexMarker572"/>any parentheses occurring in the text. This means that we have to search for characters associated with brackets—<strong class="source-inline">(, ), [, ], {, }</strong>—and remove them from <span class="No-Break">the text:</span></p>
			<pre class="source-code">
def remove_parenthesis(sentence):
    parantheses = ['(', ')', '{', '}', '[', ']']
    for paranthesis in parantheses:
      sentence = sentence.replace(paranthesis, "")
    return sentence</pre>
			<p>We will implement a function to purge discourse markers from the text. We will first read a list of discourse markers (you will need to change the filename and path, depending on how you have saved it locally). We then iterate through the list and remove each item from the text, <span class="No-Break">if found:</span></p>
			<pre class="source-code">
def remove_discourse_markers(sentence):
    # Read Discourse Markers
    DISCOURSE_FILE = 'discourse_markers.pkl'
    with open(DISCOURSE_FILE , 'rb') as discourse_file:
        discourse_markers = pickle.load(discourse_file)
    sent_tokens = sentence.lower().split()
    for marker in discourse_markers:
        if marker.lower() in sent_tokens:
            case_insensitive = re.compile(re.escape(marker.lower()), re.IGNORECASE)
            sentence = case_insensitive.sub('', sentence)
    return sentence</pre>
			<p>Next, we will implement a<a id="_idIndexMarker573"/> function to remove appositions from<a id="_idIndexMarker574"/> the text. We will use <strong class="bold">regular expression</strong> (<strong class="bold">regex</strong>) matching <span class="No-Break">for this:</span></p>
			<pre class="source-code">
def remove_appositions(sentence):
    sentence = re.sub(r" ?\,[^)]+\,", "", sentence)
    return sentence</pre>
			<p>We will now implement a function to change expressions of possession. We will first use regex matching to find expressions of the form “X of Y.” We will then replace this with “Y’s X.” For example, “book of Jacob” will become “Jacob’s book.” Note that we are not making this replacement deterministically. We will randomly choose whether to replace or not (biased with the probability of replacement <span class="No-Break">being 2/3):</span></p>
			<pre class="source-code">
def apply_possessive_transformation(text):
    if re.match(r"(\w+) of (\w+)", text):
        rnd = random.choice([False, True, False])
        if rnd:
            return re.sub(r"(\w+) of (\w+)" , r"\2's \1", text)
    return text</pre>
			<p>Next, we will apply equation transformation where we will replace mathematical expressions with their textual representations. We will define a dictionary where common symbols and their text representations are defined (such as “+” translating to “plus” and "*" translating<a id="_idIndexMarker575"/> to “multiplied by”). Then, we will find occurrences of each symbol in the text and make the <span class="No-Break">necessary replacements:</span></p>
			<pre class="source-code">
def apply_equation_transformation(text):
    words = RegexpTokenizer(r'\w+').tokenize(text)
    symbol_to_text =   {
                '+': ' plus ',
                '-': ' minus ',
                '*': ' multiplied by ',
                '/': ' divided by ',
                '=': ' equals ',
                '&gt;': ' greater than ',
                '&lt;': ' less than ',
                '&lt;=': ' less than or equal to ',
                '&gt;=': ' greater than or equal to ',
            }
    for n,w in enumerate(words):
        for symbol in symbol_to_text:
            if symbol in w:
                words[n] = words[n].replace(symbol, symbol_to_text[sym])
    sentence = ''
    for word in words:
      sentence = sentence + word + " "
    return sentence</pre>
			<p>The next step is synonym replacement. However, as a helper function for synonym replacement, we need a <a id="_idIndexMarker576"/>function for <em class="italic">untokenization</em>. This is the exact opposite of tokenization and can be done with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
def untokenize(words):
    text = ' '.join(words)
    step1 = text.replace("`` ", '"').replace(" ''", '"').replace('. . .', '...')
    step2 = step1.replace(" ( ", " (").replace(" ) ", ") ")
    step3 = re.sub(r' ([.,:;?!%]+)([ \'"`])', r"\1\2", step2)
    step4 = re.sub(r' ([.,:;?!%]+)$', r"\1", step3)
    step5 = step4.replace(" '", "'").replace(" n't", "n't").replace(
        "can not", "cannot")
    step6 = step5.replace(" ` ", " '")
    return step6.strip()</pre>
			<p>Now, we will implement <a id="_idIndexMarker577"/>the actual <span class="No-Break">synonym substitution:</span></p>
			<pre class="source-code">
def synonym_substitution(sentence, all_words):
    new_tokens = []
    output = wsd.process_text(sentence)
    for token, synset in output:
        if synset != None:
            try:
                # Get the synset name
                synset = synset.split('-')
                offset = int(synset[0])
                pos = synset[1]
                synset_name = wn.synset_from_pos_and_offset(pos, offset)
                # List of Synonyms
                synonyms = synset_name.lemma_names()
                for synonym in synonyms:
                    if synonym.lower() not in all_words:
                        token = synonym
                        break
            except Exception as e:
                # Some error in the synset naming....
                continue
        new_tokens.append(token)
    final = untokenize(new_tokens)
    final = final.capitalize()
    return final</pre>
			<p>Finally, we will put all of this together in a wrapper function. This function will take in the text and apply all of <a id="_idIndexMarker578"/>our transformations (contraction-expansion replacement, parenthesis removal, discourse and apposition removal, synonym replacement, equation transformation, and possessive transformation) to each sentence of the text, and then join the sentences back to form the <span class="No-Break">obfuscated </span><span class="No-Break"><a id="_idIndexMarker579"/></span><span class="No-Break">text:</span></p>
			<pre class="source-code">
def obfuscate_text(input_text):
    obfuscated_text = []
    sentences = sent_tokenize(input_text)
    tokens = set(nltk.word_tokenize(input_text.lower()))
    for sentence in sentences:
        # 1. Apply Contractions
        sentence, contractions_applied = contraction_replacement(sentence, contractions)
        # 2. Remove Parantheses
        sentence = remove_parenthesis(sentence)
        # 3. Remove Discourse Markers
        sentence = remove_discourse_markers(sentence, discourse_markers)
        # 4. Remove Appositions
        sentence = remove_appositions(sentence)
        # 5. Synonym Substitution
        sentence = synonym_substitution(sentence, tokens)
        # 6. Apply possessive transformation
        sentence = apply_possessive_transformation(sentence)
        # 7. Apply equation transformation
        sentence = apply_equation_transformation(sentence)
        obfuscated_text.append(sentence)
    obfuscated_text = " ".join(obfuscated_text)
    return obfuscated_text</pre>
			<p>We now will test how effective this obfuscation is. We will train a vanilla model and then test it on the <a id="_idIndexMarker580"/>obfuscated data. This mirrors exactly the threat model that would occur in the real world; at the time of training, we would not have access to the obfuscated data. Here is the process we will follow in order to evaluate <span class="No-Break">the model:</span></p>
			<ol>
				<li>Split the data into training and <span class="No-Break">test sets.</span></li>
				<li>Extract features from the <span class="No-Break">training data.</span></li>
				<li>Train an authorship attribution ML model based on <span class="No-Break">these features.</span></li>
				<li>Apply the obfuscator on the test data to transform the raw text into <span class="No-Break">obfuscated text.</span></li>
				<li>Extract features from the obfuscated text and use them to run inference on the previously <span class="No-Break">trained model.</span></li>
			</ol>
			<p>We load the data and split it <span class="No-Break">as before:</span></p>
			<pre class="source-code">
from sklearn.model_selection import train_test_split
# Read Data
X, Y = read_dataset(num_authors = 6)
# Split it into train and test
X_train, X_test, Y_train, Y_test = train_test_split(X, Y)</pre>
			<p>Then, we extract features and train a model. Note that we extract features only from the training data, not the<a id="_idIndexMarker581"/> test data (which we need <span class="No-Break">to obfuscate):</span></p>
			<pre class="source-code">
# Extract features from training data
X_train_features = []
for x in X_train:
  x_features = calculate_features(x)
  X_train_features.append(x_features)
# Train the model
model = RandomForestClassifier(n_estimators = 100)
model.fit(X_train_features, Y_train)</pre>
			<p>Now, we will obfuscate the test data using the functions we defined earlier, and then extract features from the obfuscated version of <span class="No-Break">the data:</span></p>
			<pre class="source-code">
X_test_obfuscated = []
for x in X_test:
  # Obfuscate
  x_obfuscated = obfuscate_text(x)
  # Extract features
  x_obfuscated_features = calculate_features(x_obfuscated)
  X_test_obfuscated.append(x_obfuscated_features)</pre>
			<p>Finally, we can run inference on the trained model using the newly generated (<span class="No-Break">obfuscated) data:</span></p>
			<pre class="source-code">
# Calculate accuracy on original
Y_pred_original = model.predict(X_test)
accuracy_orig = calculate_accuracy(Y_test, Y_pred_original)
# Calculate accuracy on obfuscated
Y_pred_obfuscated = model.predict(X_test_obfuscated)
accuracy_obf = calculate_accuracy(Y_test, Y_pred_obfuscated)</pre>
			<p>Comparing the two values of accuracy should give you the performance degradation caused due to the obfuscation. The first calculated value represents the accuracy of the original data, and the second one represents the accuracy of the model when our obfuscation tactics are applied. When the second value is lower than the first, our obfuscation has <span class="No-Break">been successful.</span></p>
			<p>Next, we will provide an <a id="_idIndexMarker582"/>overview of some strategies to improve the performance of <span class="No-Break">our obfuscators.</span></p>
			<h2 id="_idParaDest-118">Improving obfuscation techniques</h2>
			<p>Here, we describe<a id="_idIndexMarker583"/> potential changes and improvements that can help us achieve a better performance of our obfuscator. Readers are highly encouraged to experiment with these to examine which ones show the <span class="No-Break">best performance.</span></p>
			<h3>Advanced manipulations</h3>
			<p>In our example obfuscator, we implemented<a id="_idIndexMarker584"/> basic obfuscation tactics such as the replacement of synonyms, changing of contractions, removing parentheses, and so on. There is a vast arena of features that can be manipulated here. A few possibilities are <span class="No-Break">given next:</span></p>
			<ul>
				<li><strong class="bold">Antonym replacement</strong>: Replacing words with the negation of their antonyms. For example, <em class="italic">good</em> is replaced by <span class="No-Break"><em class="italic">not bad</em></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Function word manipulation</strong>: Adding extra helper words at the beginning of sentences, or removing existing words that add no value. For example, <em class="italic">“Thus, we have shown that the plan works”</em> becomes <em class="italic">“We have shown that the </em><span class="No-Break"><em class="italic">plan works.”</em></span></li>
				<li><strong class="bold">Punctuation manipulation</strong>: Adding punctuation symbols (two question marks, two exclamation marks, trailing periods) or removing existing ones. This may affect the grammar and structure of the sentence, which may or may not be acceptable depending <a id="_idIndexMarker585"/>on your <span class="No-Break">use case.</span></li>
			</ul>
			<h3>Language models</h3>
			<p>Recent advances such as<a id="_idIndexMarker586"/> transformers and the attention mechanism have led to the development of several improved language models, which have excellent text-generation capabilities. Such models can be used to generate obfuscated text. An example is using a transformer-based document summarizer as an obfuscator. The summarizer aims to reproduce the text in the original document in a short and concise manner. The hope is that in doing so, it will strip off the stylistic features from the text. Readers are encouraged to experiment with various summarization models and compare the accuracy before and after obfuscation. Note that it is also important to check the similarity of the text against the original in terms <span class="No-Break">of meaning.</span></p>
			<p>This completes our discussion of authorship <span class="No-Break">obfuscation models!</span></p>
			<h1 id="_idParaDest-119">Summary</h1>
			<p>This chapter focused on two important problems in security and privacy. We began by discussing authorship attribution, a task of identifying who wrote a particular piece of text. We designed a series of linguistic and text-based features and trained ML models for authorship attribution. Then, we turned to authorship obfuscation, a task that aims to evade the attribution models by making changes to the text such that author-identifying characteristics and style markers are removed. We looked at a series of obfuscation methods for this. For both tasks, we looked at the improvements that could be made to <span class="No-Break">the performance.</span></p>
			<p>Both authorship attribution and obfuscation have important applications in cybersecurity. Attribution can be used to detect Sybil accounts, trace cybercriminals, and protect intellectual property rights. Similarly, obfuscation can help preserve the anonymity of individuals and provide privacy guarantees. This chapter enables ML practitioners in cybersecurity and privacy to effectively tackle these <span class="No-Break">two tasks.</span></p>
			<p>In the next one, we will change tracks slightly and look at how fake news can be detected using <span class="No-Break">graph ML.</span></p>
		</div>
	</body></html>