["```py\nimport pandas as pd\nimport os\nFILENAME = \"./loan_dataset.csv\"\nDATA_URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n```", "```py\nif not os.path.exists(FILENAME):\n    data = (\n        pd.read_excel(io=DATA_URL, header=1)\n        .drop(columns=[\"ID\"])\n        .rename(\n            columns={\"PAY_0\": \"PAY_1\", \"default payment next month\": \"default\"}\n        )\n    )\n    data.to_csv(FILENAME, sep=\",\", encoding=\"utf-8\", index=False)\n```", "```py\ndataset = pd.read_csv(FILENAME, sep=\",\", encoding=\"utf-8\")\ndataset.shape\n(30000, 24)\n```", "```py\ncat_colums = ['EDUCATION', 'MARRIAGE']\nfor col in cat_colums:\n    dataset[col] = dataset[col].astype(\"category\")\ndataset['SEX'] = dataset['SEX'].map({1: 1, 2:0})\n```", "```py\nY, A = dataset.loc[:, \"default\"], dataset.loc[:, \"SEX\"]\nX = pd.get_dummies(dataset.drop(columns=[\"default\",\"SEX\"]))\nX[\"SEX\"] = A.copy()\nA_str = A.map({1: \"male\", 0: \"female\"})\n```", "```py\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.combine import SMOTEENN, SMOTETomek\nfrom sklearn.ensemble import IsolationForest\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn.under_sampling import AllKNN, InstanceHardnessThreshold, RepeatedEditedNearestNeighbours, TomekLinks, EditedNearestNeighbours\nfrom sklearn.metrics import balanced_accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.pipeline import Pipeline\nfrom fairlearn.metrics import MetricFrame, equalized_odds_difference, demographic_parity_ratio\nimport numpy as np\nimport shap\n```", "```py\nX_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X,\n                 Y,\n                 A_str,\n                 test_size=0.2,\n                 stratify=Y,\n                 random_state=42)\n```", "```py\nd_tree_params = {\n    \"min_samples_leaf\": 10,\n    \"random_state\": 42\n}\nestimator = Pipeline(steps=[\n    (\"classifier\", DecisionTreeClassifier(**d_tree_params))\n])\nestimator.fit(X_train, y_train)\n```", "```py\ny_pred_proba = estimator.predict_proba(X_test)[:, 1]\ny_pred = estimator.predict(X_test)\nprint(f\"Roc score is : {roc_auc_score(y_test, y_pred_proba)}\")\ncm = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=estimator.classes_)\ncm.plot()\nRoc score is : 0.6875636482794665\n```", "```py\ndef false_positive_rate(y_true, y_pred):\n    \"\"\"Compute the standard error for the false positive rate estimate.\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    return fp/(fp+tn)\ndef false_negative_rate(y_true, y_pred):\n    \"\"\"Compute the standard error for the false positive rate estimate.\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    return fn/(tp+fn)\nfairness_metrics = {\n    \"balanced_accuracy\": balanced_accuracy_score,\n    \"false_positive_rate\": false_positive_rate,\n    \"false_negative_rate\": false_negative_rate,\n}\nmetrics_to_report = list(fairness_metrics.keys())\n```", "```py\ndef calculate_fairness_metrics(y_test, y_pred, A_test, metrics=fairness_metrics):\n    \"\"\"Function to calculate fairness metrics\"\"\"\n    metricframe = MetricFrame(\n        metrics=fairness_metrics,\n        y_true=y_test,\n        y_pred=y_pred,\n        sensitive_features=A_test,\n    )\n    print(metricframe.by_group[metrics_to_report])\n    print(\"\\n *diff*\")\n    print(metricframe.difference()[metrics_to_report])\n    print(\"\\n *final_metrics*\")\n    print(metricframe.overall[metrics_to_report])\n    equalized_odds = equalized_odds_difference(\n        y_test, y_pred, sensitive_features=A_test\n    )\n    print(\"\\n *equalized_odds*\")\n    print(equalized_odds)\n    dpr= demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)\n    print(\"\\n *demographic_parity_ratio*\")\n    print(dpr)\n```", "```py\ncalculate_fairness_metrics_unmitigated = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nfor val in dataset.SEX.unique():\n    print(f\"{('male' if val == 1 else 'female')} default rate is: \")\n    print(dataset[dataset.SEX == val]['default'].mean())\n    print()\nfemale default rate is:\n0.20776280918727916\nmale default rate is: 0.2416722745625841\n```", "```py\nnp.random.seed(42)\nX.loc[:, 'Interest_rate'] = np.random.normal(loc=2*Y, scale=A.map({1:2, 0:1}))\nprint(\"Maximum interest rate for men who defaulted vs women who defaulted\")\nprint(X[(X.SEX == 1) & (Y == 1)][\"Interest_rate\"].max(), X[(X.SEX == 0) & (Y == 1)][\"Interest_rate\"].max())\nprint()\nprint(\"Maximum interest rate for men who did not default vs women that did not default\")\nprint(X[(X.SEX == 1) & (Y == 0)][\"Interest_rate\"].max(), X[(X.SEX == 0) & (Y == 0)][\"Interest_rate\"].max())\nMaximum interest rate for men who defaulted vs women who defaulted\n9.852475412872653 6.479084251025757\nMaximum interest rate for men who did not default vs women that did not default\n6.857820956016427 3.852731490654721\n```", "```py\ny_pred_proba = estimator.predict_proba(X_test)[:, 1]\ny_pred = estimator.predict(X_test)\nroc_auc_score(y_test, y_pred_proba)\n0.8465698909107798\n```", "```py\ncalculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nestimator.fit(X_train.drop(['SEX'], axis=1), y_train)\nPipeline(steps=[('classifier',\n                 DecisionTreeClassifier(min_samples_leaf=10, random_state=42))])\n```", "```py\nestimator.fit(X_train.drop(['SEX'], axis=1), y_train)\ny_pred_proba = estimator.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]\ny_pred = estimator.predict(X_test.drop(['SEX'], axis=1))\nroc_auc_score(y_test, y_pred_proba)\n0.8392395442658211\n```", "```py\ncalculate_fairness_metrics_mitigated_v1 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nscaler = StandardScaler()\nsampler_method = AllKNN(n_jobs=-1)\n```", "```py\nsampler_pipeline = make_pipeline(\n    scaler,\n    sampler_method,\n    estimator)\n```", "```py\ncv_results = cross_validate(sampler_pipeline,\n                            X_train.drop(['SEX'], axis=1),\n                            y_train, scoring=['roc_auc','balanced_accuracy'],\n                            return_estimator=True)\n```", "```py\nprint(f\"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}\")\nprint(f\"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}\")\nValidation roc auc : 0.853 +/- 0.006\nValidation balanced acc : 0.802 +/- 0.005\n```", "```py\nmodel = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'],axis=1))\nroc_auc_score(y_test, y_pred_proba)\n0.8537904984477683\n```", "```py\ncalculate_fairness_metrics_mitigated_v2 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nd_tree_params = {\n    \"min_samples_leaf\": 10,\n    \"random_state\": 42\n}\nd_tree = DecisionTreeClassifier(**d_tree_params)\nsampler_method = InstanceHardnessThreshold(\n    estimator=d_tree,\n    sampling_strategy='auto',\n    random_state=42,\n    n_jobs=-1,\n    cv=3)\nestimator = Pipeline(steps=[\n    (\"classifier\", DecisionTreeClassifier(**d_tree_params))\n])\nsampler_pipeline = make_pipeline(\n    scaler,\n    sampler_method,\n    estimator)\ncv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)\n```", "```py\nprint(f\"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}\")\nprint(f\"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}\")\nValidation roc auc : 0.853 +/- 0.005\nValidation balanced acc : 0.807 +/- 0.007\n```", "```py\nmodel = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'],axis=1))\nroc_auc_score(y_test, y_pred_proba)\n0.8549627959428299\n```", "```py\ncalculate_fairness_metrics_mitigated_v3 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nestimator = Pipeline(steps=[\n    (\"classifier\", DecisionTreeClassifier(**d_tree_params))\n])\nsampler_method = SMOTE(random_state=42)\nsampler_pipeline = make_pipeline(\n    scaler,\n    sampler_method,\n    estimator)\ncv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)\nprint(f\"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}\")\nprint(f\"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}\")\nmodel = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'],axis=1))\nroc_auc_score(y_test, y_pred_proba)\nValidation roc auc : 0.829 +/- 0.009\nValidation balanced acc : 0.758 +/- 0.012\n0.8393191272926885\n```", "```py\ncalculate_fairness_metrics_mitigated_v4 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nsampler_method = ADASYN(random_state=42)\nsampler_pipeline = make_pipeline(\n    scaler,\n    sampler_method,\n    estimator)\ncv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)\nprint(f\"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}\")\nprint(f\"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}\")\nmodel = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'],axis=1))\nroc_auc_score(y_test, y_pred_proba)\nValidation roc auc : 0.823 +/- 0.004\nValidation balanced acc : 0.757 +/- 0.006\n0.816654655300673\n```", "```py\ncalculate_fairness_metrics_mitigated_v5 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nsampler_method = ADASYN(random_state=42)\nsampler_pipeline = make_pipeline(\n    scaler,\n    sampler_method,\n    estimator)\ncv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)\nmodel = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)\n```", "```py\nX_train_males = X_train[X_train.SEX == 1].copy()\nX_train_males[\"predictions\"] = model.predict(X_train_males.drop(['SEX'], axis=1))\nX_train_males['y_true'] = y_train.filter(X_train_males.index)\n```", "```py\nX_train_male_false_negatives = X_train_males[(X_train_males.y_true == 1) & (X_train_males.predictions == 0)]\n```", "```py\nX_train_sample = X_train_male_false_negatives[X_train.columns].sample(frac=0.1, replace=True, random_state=42, axis=0)\ny_train_sample = X_train_male_false_negatives['y_true'].sample(frac=0.1, replace=True, random_state=42, axis=0)\n```", "```py\nX_train_with_male_samples = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)\ny_train_with_male_samples = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)\n```", "```py\ncv_results = cross_validate(sampler_pipeline, X_train_with_male_samples.drop(['SEX'], axis=1), y_train_with_male_samples, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)\nprint(f\"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}\")\nprint(f\"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}\")\nmodel = sampler_pipeline.fit(X_train_with_male_samples.drop(['SEX'], axis=1), y_train_with_male_samples)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'],axis=1))\nroc_auc_score(y_test, y_pred_proba)\nValidation roc auc : 0.824 +/- 0.005\nValidation balanced acc : 0.754 +/- 0.005\n0.8201623558253082\n```", "```py\ncalculate_fairness_metrics_mitigated_v6 = calculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nmethods = {\n    \"all_knn\": AllKNN(n_jobs=-1),\n    \"renn\": RepeatedEditedNearestNeighbours(n_jobs=-1),\n    \"iht\": InstanceHardnessThreshold(\n        estimator=DecisionTreeClassifier(**d_tree_params),\n        random_state=42,\n        n_jobs=-1,\n        cv=3),\n    \"tomek\": TomekLinks(n_jobs=-1),\n    \"adasyn\" : ADASYN(random_state=42),\n    \"smote\" : SMOTE(random_state=42),\n    \"smoteenn\": SMOTEENN(random_state=42,\n                         smote=SMOTE(random_state=42),\n                         enn=EditedNearestNeighbours(n_jobs=-1)\n                        ),\n    \"smotetomek\": SMOTETomek(random_state=42,\n                             smote=SMOTE(random_state=42),\n                             tomek=TomekLinks(n_jobs=-1)\n                            )\n          }\n```", "```py\ndef sample_false_positives(X_train, y_train, estimator, perc=0.1, subset_col=\"SEX\", subset_col_value=1, with_replace=True):\n    \"\"\"Function to sample false positives\"\"\"\n    X_train = X_train.copy()\n    y_train = y_train.copy()\n    X_train_subset = X_train[X_train[subset_col] == subset_col_value].copy()\n    y_train_subset = y_train.filter(X_train_subset.index).copy()\n    X_train_subset[\"predictions\"] = estimator.predict(X_train_subset.drop([subset_col], axis=1))\n    X_train_subset['y_true'] = y_train_subset.values\n    X_train_subset_false_positives = X_train_subset[(X_train_subset.y_true == 0) & (X_train_subset.predictions == 1)]\n    X_train_sample = X_train_subset_false_positives[X_train.columns].sample(frac=perc, replace=with_replace, random_state=42, axis=0)\n    y_train_sample = X_train_subset_false_positives['y_true'].sample(frac=perc, replace=with_replace, random_state=42, axis=0)\n    X_train_sample = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)\n    y_train_sample = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)\n    return X_train_sample, y_train_sample\n```", "```py\ndef sample_false_negatives(X_train, y_train, estimator, perc=0.1, subset_col=\"SEX\", subset_col_value=1, with_replace=True):\n    \"\"\"Function to sample false positives\"\"\"\n    X_train = X_train.copy()\n    y_train = y_train.copy()\n    X_train_subset = X_train[X_train[subset_col] == subset_col_value].copy()\n    y_train_subset = y_train.filter(X_train_subset.index).copy()\n    X_train_subset[\"predictions\"] = estimator.predict(X_train_subset.drop([subset_col], axis=1))\n    X_train_subset['y_true'] = y_train_subset.values\n    X_train_subset_false_negatives = X_train_subset[(X_train_subset.y_true == 1) & (X_train_subset.predictions == 0)]\n    X_train_sample = X_train_subset_false_negatives[X_train.columns].sample(frac=perc, replace=with_replace, random_state=42, axis=0)\n    y_train_sample = X_train_subset_false_negatives['y_true'].sample(frac=perc, replace=with_replace, random_state=42, axis=0)\n    X_train_sample = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)\n    y_train_sample = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)\n    return X_train_sample, y_train_sample\n```", "```py\ndef calculate_metrics(estimator, X_test, y_test, A_test):\n    \"\"\"Function to calculate metrics\"\"\"\n    y_pred_proba = estimator.predict_proba(X_test)[:, 1]\n    y_pred = model.predict(X_test)\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\n    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n    equalized_odds = equalized_odds_difference(\n        y_test, y_pred, sensitive_features=A_test\n    )\n    dpr = demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)\n    return roc_auc, balanced_accuracy, equalized_odds, dpr\n```", "```py\ndf = pd.DataFrame(data=results,\n                  columns=[\"method\", \"sample\",\n                           \"test_roc_auc\", \"test_balanced_accuracy\",\n                           \"equalized_odds\",\n                           \"demographic_parity_ratio\",\n                           \"validation_roc_auc\",\n                           \"validation_balanced_accuracy\"]\n                 )\n```", "```py\ndf.sort_values(by=\"equalized_odds\")\n```", "```py\nX_train_scaled = pd.DataFrame()\nscaler = StandardScaler()\nsampler = SMOTETomek(random_state=42,\n                     smote=SMOTE(random_state=42),\n                     tomek=TomekLinks(n_jobs=-1)\n                    )\n```", "```py\ncolumns = X_train.drop(['SEX'], axis=1).columns\nX_train_scaled[columns] = scaler.fit_transform(X_train.drop(['SEX'], axis=1))\nX_train_resample, y_train_resample = sampler.fit_resample(X_train_scaled, y_train)\nX_train_resample[columns] = scaler.inverse_transform(X_train_resample)\n```", "```py\nanomaly_model = IsolationForest(contamination=float(.1), random_state=42, n_jobs=-1)\nanomaly_model.fit(X_train_resample)\nX_train_resample['IF_anomaly'] = anomaly_model.predict(X_train_resample)\nX_train_resample['default'] = y_train_resample\nX_train_additional_samples = X_train_resample[X_train_resample.IF_anomaly == -1]\nX_train_additional_samples.drop(['IF_anomaly'], axis=1, inplace=True)\n```", "```py\nX_train_clean = X_train_resample[X_train_resample.IF_anomaly != -1]\ny_train_clean = X_train_clean.default\nestimator.fit(X_train_clean.drop(['IF_anomaly', 'default'], axis=1), y_train_clean)\ny_pred_proba = estimator.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]\ny_pred = estimator.predict(X_test.drop(['SEX'], axis=1))\nroc_auc_score(y_test, y_pred_proba)\n0.8248481592937735\n```", "```py\nmodel = DecisionTreeClassifier(**d_tree_params)\nmodel.fit(X_train, y_train)\nDecisionTreeClassifier(min_samples_leaf=10, random_state=42)\n```", "```py\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)\n```", "```py\nshap_values[0][0]\n```", "```py\nshap.summary_plot(shap_values[0], X_train)\n```", "```py\nshap.summary_plot(shap_values[1], X_train)\n```", "```py\nmodel = DecisionTreeClassifier(**d_tree_params)\nX_train_samples = X_train.drop(['SEX'], axis=1).copy()\ny_train_samples = y_train.copy()\nmodel.fit(X_train_samples, y_train_samples)\n```", "```py\nexplainer = shap.Explainer(model)\nshap_values = explainer.shap_values(X_train_samples)\n```", "```py\nY_pred = model.predict(X_train_samples)\n```", "```py\nprint(f\"Shapley value for first value in the dataset for class 0 : {sum(shap_values[0][0])}\")\nprint(f\"Shapley value for first value in the dataset for class 1 : {sum(shap_values[1][0])}\")\nprint(f\"Prediction of first value is {Y_pred[0]}\")\nprint(f\"Actual prediction is {y_train_samples[0]}\")\nShapley value for first value in the dataset for class 0 : -0.07290931372549389\nShapley value for first value in the dataset for class 1 : 0.07290931372548978\nPrediction of first value is 0\nActual prediction is 1\n```", "```py\ndata = [(index, pred, actual, sum(s0), sum(s1)) for\n        index, (pred, actual, s0, s1) in\n        enumerate(zip(Y_pred, y_train_samples, shap_values[0], shap_values[1]))\n        if pred != actual]\ndf = pd.DataFrame(data=data, columns=[\"index\", \"predictions\",\"actuals\", \"shap_class_0\", \"shap_class_1\"])\ndf.sample(5, random_state=42)\n```", "```py\nshap.force_plot(explainer.expected_value[0], shap_values[0][4255,:], X_train_samples.iloc[4255, :], matplotlib=True)\n```", "```py\nshap.force_plot(explainer.expected_value[1], shap_values[1][4255,:], X_train_samples.iloc[4255, :], matplotlib=True)\n```", "```py\nindex = 422\nshap_impact = abs(df['shap_class_0'][index])\nprint(shap_impact)\n0.4787916666666662\n```", "```py\ndef get_shapley_impact(shap_value, threshold=0.2):\n    \"\"\"Calculate Shapley impact\"\"\"\n    shap_value_impacts = np.abs(shap_value)\n    if np.max(shap_value_impacts) >= threshold:\n        return np.abs(np.sum(shap_value))\n```", "```py\nX_train_sample, X_val, y_train_sample, y_val, A_train_sample, A_val = train_test_split(X_train,\n                   y_train,\n                   A_train,\n                   test_size=0.2,\n                   stratify=y_train,\n                   random_state=42)\n```", "```py\nmodel = DecisionTreeClassifier(**d_tree_params)\nscaler = StandardScaler()\nsampler = SMOTETomek(random_state=42,\n                     smote=SMOTE(random_state=42),\n                     tomek=TomekLinks(n_jobs=-1)\n                    )\ncolumns = X_train_sample.columns\nX_train_scaled = pd.DataFrame()\nX_train_scaled[columns] = scaler.fit_transform(X_train_sample[columns])\nX_train_resampled, y_train_resampled = sampler_method.fit_resample(X_train_scaled, y_train_sample)\nX_train_resampled[columns] = scaler.inverse_transform(X_train_resampled)\nA_train_resampled = X_train_resampled['SEX'].copy()\nmodel.fit(X_train_resampled.drop(['SEX'], axis=1), y_train_resampled)\nY_pred = model.predict(X_train_resampled.drop(['SEX'], axis=1))\ny_val_pred = model.predict_proba(X_val.drop(['SEX'], axis=1))[: ,1]\nval_roc = roc_auc_score(y_val, y_val_pred)\nprint(f\"Validation roc auc : {val_roc}\")\nValidation roc auc : 0.8275769341994823\n```", "```py\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'], axis=1))\nprint(f\"Roc: {roc_auc_score(y_test, y_pred_proba)}\")\nRoc: 0.8258396009334518\n```", "```py\ncalculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nexplainer = shap.Explainer(model)\ncolumns = X_train_resampled.drop(['SEX'], axis=1).columns\nshap_values = explainer.shap_values(X_train_resampled[columns])\n```", "```py\nshapley_impact_false_negative = [(i, get_shapley_impact(s), y, p, a)\n                                for s, i, y, p, a\n                                in zip(shap_values[1], X_train_resampled.index, y_train_resampled, Y_pred, A_train_resampled)\n                                 if y == 1 and p == 0 and a == 1]\n```", "```py\nshapley_impact_true_negative = [(i, get_shapley_impact(s), y, p, a)\n                                for s, i, y, p, a\n                                in zip(shap_values[0], X_train_resampled.index, y_train_resampled, Y_pred, A_train_resampled)\n                                 if y == 0 and p == 0 and a == 1]\n```", "```py\nshapley_impact_false_negative_sorted = sorted([i for i in shapley_impact_false_negative if i[1] is not None], key=lambda x: x[1], reverse=True)\n```", "```py\nshapley_impact_true_negative_sorted =  sorted([i for i in shapley_impact_true_negative if i[1] is not None], key=lambda x: x[1], reverse=True)\n```", "```py\ndata_points_to_eliminate = [i[0] for i in shapley_impact_false_negative_sorted[0:100]]\ndata_points_to_add = [i[0] for i in shapley_impact_true_negative_sorted[0:100]]\nX_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\ny_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\nX_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)\ny_train_reduced = y_train_resampled.drop(data_points_to_eliminate)\nX_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)\ny_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)\n```", "```py\nestimator = DecisionTreeClassifier(**d_tree_params)\nmodel = estimator.fit(X_train_final, y_train_final)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'], axis=1))\nprint(f\"Roc: {roc_auc_score(y_test, y_pred_proba)}\")\nRoc: 0.8262453372973797\n```", "```py\ncalculate_fairness_metrics(y_test, y_pred, A_test)\n```", "```py\nperc_points_to_eliminate = np.linspace(0.05,0.5,10)\nperc_points_to_eliminate\narray([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ])\n```", "```py\nfn_examples = len(shapley_impact_false_negative)\ntn_examples = len(shapley_impact_true_negative)\nmodel = DecisionTreeClassifier(**d_tree_params)\ndata = []\nfor fnp in perc_points_to_eliminate:\n    data_points_to_eliminate = [idx[0] for idx in shapley_impact_false_negative_sorted[0:(round(fn_examples*fnp))]]\n    for tnp in perc_points_to_eliminate:\n        data_points_to_add = [idx[0] for idx in shapley_impact_true_negative_sorted[0:(round(tn_examples*tnp))]]\n        X_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\n        y_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\n        X_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)\n        y_train_reduced = y_train_resampled.drop(data_points_to_eliminate)\n        X_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)\n        y_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)\n        model.fit(X_train_final, y_train_final)\n        y_pred = model.predict(X_test.drop(['SEX'], axis=1))\n        fpr = false_positive_rate(y_test, y_pred)\n        fnr = false_negative_rate(y_test, y_pred)\n        equalized_odds_mitigated = equalized_odds_difference(\n            y_test, y_pred, sensitive_features=A_test\n        )\n        demographic_parity_ratio_mitigated = demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)\n        data.append((fnp,\n                     tnp,\n                     fpr,\n                     fnr,\n                     equalized_odds_mitigated,\n                     demographic_parity_ratio_mitigated\n                    ))\n```", "```py\ncolumns = [\"perc_false_negative_removed\",\n          \"perc_true_negative_added\",\n          \"false_positive_rate\",\n          \"false_negative_rate\",\n          \"equalized_odds_mitigated\",\n          \"demographic_parity_ratio_mitigated\"]\ndf_shapley = pd.DataFrame(data=data, columns=columns)\ndf_shapley.sort_values(by=\"equalized_odds_mitigated\")\n```", "```py\ntop_values = df_shapley.sort_values(by=\"equalized_odds_mitigated\").values[0]\nperc_false_negative_removed = top_values[0]\nperc_true_negative_added = top_values[1]\ncolumns = X_train_resampled.drop(['SEX'], axis=1).columns\ndata_points_to_eliminate = [i[0] for i in shapley_impact_false_negative_sorted[0:(round(fn_examples*perc_false_negative_removed))]]\ndata_points_to_add = [i[0] for i in shapley_impact_true_negative_sorted[0:(round(tn_examples*perc_true_negative_added))]]\nX_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\ny_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)\nX_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)\ny_train_reduced = y_train_resampled.drop(data_points_to_eliminate)\nX_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)\ny_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)\n```", "```py\nestimator = DecisionTreeClassifier(**d_tree_params)\nmodel = estimator.fit(X_train_final, y_train_final)\ny_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]\ny_pred = model.predict(X_test.drop(['SEX'], axis=1))\nprint(f\"Roc: {roc_auc_score(y_test, y_pred_proba)}\")\nRoc: 0.820911097453972\n```", "```py\ncalculate_fairness_metrics(y_test, y_pred, A_test)\n```"]