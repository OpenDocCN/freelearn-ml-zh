["```py\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nX, y = make_classification(n_samples=300, n_features=50,\n                           n_informative=10,\n                           n_redundant=25, n_repeated=15,\n                           n_clusters_per_class=5,\n                           flip_y=0.05, class_sep=0.5,\n                           random_state=0) \n```", "```py\nfrom sklearn import svm\nsvc = svm.SVC()\nsvc = svm.SVC(probability=True, random_state=1)\nfrom sklearn import model_selection\nsearch_grid = [\n               {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n               {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n               'kernel': ['rbf']}\n               ]\n\nscorer = 'accuracy' \n```", "```py\nsearch_func = model_selection.GridSearchCV(estimator=svc, \n                                           param_grid=search_grid,\n                                           scoring=scorer, \n                                           n_jobs=-1,\n                                           cv=5)\nsearch_func.fit(X, y)\nprint (search_func.best_params_)\nprint (search_func.best_score_) \n```", "```py\nimport scipy.stats as stats\nfrom sklearn.utils.fixes import loguniform\nsearch_dict = {'kernel': ['linear', 'rbf'], \n               'C': loguniform(1, 1000),\n               'gamma': loguniform(0.0001, 0.1)\n               }\nscorer = 'accuracy'\nsearch_func = model_selection.RandomizedSearchCV\n              (estimator=svc,param_distributions=search_dict, n_iter=6,\n              scoring=scorer, n_jobs=-1, cv=5)\nsearch_func.fit(X, y)\nprint (search_func.best_params_)\nprint (search_func.best_score_) \n```", "```py\nfrom sklearn.experimental import enable_halving_search_cv\nfrom sklearn.model_selection import HalvingRandomSearchCV\nsearch_func = HalvingRandomSearchCV(estimator=svc,\n                                    param_distributions=search_dict,\n                                    resource='n_samples',\n                                    max_resources=100,\n                                    aggressive_elimination=True,\n                                    scoring=scorer,\n                                    n_jobs=-1,\n                                    cv=5,\n                                    random_state=0)\nsearch_func.fit(X, y)\nprint (search_func.best_params_)\nprint (search_func.best_score_) \n```", "```py\n# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial\n# Suppressing warnings because of skopt verbosity\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Classifiers\nimport lightgbm as lgb\n# Model selection\nfrom sklearn.model_selection import KFold\n# Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer\n# Skopt functions\nfrom skopt import BayesSearchCV\nfrom skopt.callbacks import DeadlineStopper, DeltaYStopper\nfrom skopt.space import Real, Categorical, Integer \n```", "```py\n# Loading data \nX = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\nX_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n# Preparing data as a tabular matrix\ny = X.target\nX = X.set_index('id').drop('target', axis='columns')\nX_test = X_test.set_index('id')\n# Dealing with categorical data\ncategoricals = [item for item in X.columns if 'cat' in item]\ncat_values = np.unique(X[categoricals].values)\ncat_dict = dict(zip(cat_values, range(len(cat_values))))\nX[categoricals] = X[categoricals].replace(cat_dict).astype('category')\nX_test[categoricals] = X_test[categoricals].replace(cat_dict).astype('category') \n```", "```py\n# Reporting util for different optimizers\ndef report_perf(optimizer, X, y, title=\"model\", callbacks=None):\n    \"\"\"\n    A wrapper for measuring time and performance of optimizers\n    optimizer = a sklearn or a skopt optimizer\n    X = the training set \n    y = our target\n    title = a string label for the experiment\n    \"\"\"\n    start = time()\n\n    if callbacks is not None:\n        optimizer.fit(X, y, callback=callbacks)\n    else:\n        optimizer.fit(X, y)\n\n    d=pd.DataFrame(optimizer.cv_results_)\n    best_score = optimizer.best_score_\n    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n    best_params = optimizer.best_params_\n\n    print((title + \" took %.2f seconds, candidates checked: %d, best CV            score: %.3f\" + u\" \\u00B1\"+\" %.3f\") % \n                             (time() - start,\n                             len(optimizer.cv_results_['params']),\n                             best_score, \n                             best_score_std))\n    print('Best parameters:')\n    pprint.pprint(best_params)\n    print()\n    return best_params \n```", "```py\n# Setting the scoring function\nscoring = make_scorer(partial(mean_squared_error, squared=False),\n                      greater_is_better=False)\n# Setting the validation strategy\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\n# Setting the basic regressor\nreg = lgb.LGBMRegressor(boosting_type='gbdt',\n                        metric='rmse',\n                        objective='regression',\n                        n_jobs=1, \n                        verbose=-1,\n                        random_state=0) \n```", "```py\n# Setting the search space\nsearch_spaces = {\n\n     # Boosting learning rate\n    'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n\n     # Number of boosted trees to fit\n    'n_estimators': Integer(30, 5000),\n\n     # Maximum tree leaves for base learners\n    'num_leaves': Integer(2, 512),\n\n     # Maximum tree depth for base learners\n    'max_depth': Integer(-1, 256),\n     # Minimal number of data in one leaf\n    'min_child_samples': Integer(1, 256),\n     # Max number of bins buckets\n    'max_bin': Integer(100, 1000),\n     # Subsample ratio of the training instance \n    'subsample': Real(0.01, 1.0, 'uniform'),\n     # Frequency of subsample \n    'subsample_freq': Integer(0, 10),\n\n     # Subsample ratio of columns\n    'colsample_bytree': Real(0.01, 1.0, 'uniform'), \n\n     # Minimum sum of instance weight\n    'min_child_weight': Real(0.01, 10.0, 'uniform'),\n\n     # L2 regularization\n    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),\n\n     # L1 regularization\n    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),\n   } \n```", "```py\n# Wrapping everything up into the Bayesian optimizer\nopt = BayesSearchCV(estimator=reg,\n                    search_spaces=search_spaces,\n                    scoring=scoring,\n                    cv=kf,\n                    n_iter=60,           # max number of trials\n                    n_jobs=-1,           # number of jobs\n                    iid=False,         \n                    # if not iid it optimizes on the cv score\n                    return_train_score=False,\n                    refit=False,  \n                    # Gaussian Processes (GP) \n                    optimizer_kwargs={'base_estimator': 'GP'},\n                    # random state for replicability\n                    random_state=0) \n```", "```py\n# Running the optimizer\noverdone_control = DeltaYStopper(delta=0.0001)\n# We stop if the gain of the optimization becomes too small\ntime_limit_control = DeadlineStopper(total_time=60 * 60 * 6)\n# We impose a time limit (6 hours)\nbest_params = report_perf(opt, X, y,'LightGBM_regression', \n                          callbacks=[overdone_control, time_limit_control]) \n```", "```py\n# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial\n# Suppressing warnings because of skopt verbosity\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Classifier/Regressor\nfrom xgboost import XGBRegressor\n# Model selection\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n# Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer\n# Skopt functions\nfrom skopt import BayesSearchCV\nfrom skopt.callbacks import DeadlineStopper, DeltaYStopper\nfrom skopt.space import Real, Categorical, Integer\nfrom skopt import gp_minimize, forest_minimize\nfrom skopt import gbrt_minimize, dummy_minimize\n# Decorator to convert a list of parameters to named arguments\nfrom skopt.utils import use_named_args \n# Data processing\nfrom sklearn.preprocessing import OrdinalEncoder \n```", "```py\n# Loading data \nX_train = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\nX_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n# Preparing data as a tabular matrix\ny_train = X_train.target\nX_train = X_train.set_index('id').drop('target', axis='columns')\nX_test = X_test.set_index('id')\n# Pointing out categorical features\ncategoricals = [item for item in X_train.columns if 'cat' in item]\n# Dealing with categorical data using OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nX_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])\nX_test[categoricals] = ordinal_encoder.transform(X_test[categoricals]) \n```", "```py\n# Setting the scoring function\nscoring = partial(mean_squared_error, squared=False)\n# Setting the cv strategy\nkf = KFold(n_splits=5, shuffle=True, random_state=0)\n# Setting the search space\nspace = [Real(0.01, 1.0, 'uniform', name='learning_rate'),\n         Integer(1, 8, name='max_depth'),\n         Real(0.1, 1.0, 'uniform', name='subsample'),\n         # Subsample ratio of columns by tree\n         Real(0.1, 1.0, 'uniform', name='colsample_bytree'),  \n         # L2 regularization\n         Real(0, 100., 'uniform', name='reg_lambda'),\n         # L1 regularization\n         Real(0, 100., 'uniform', name='reg_alpha'),\n         # minimum sum of instance weight (hessian)  \n         Real(1, 30, 'uniform', name='min_child_weight')\n         ]\nmodel = XGBRegressor(n_estimators=10_000, \n                     booster='gbtree', random_state=0) \n```", "```py\n# The objective function to be minimized\ndef make_objective(model, X, y, space, cv, scoring, validation=0.2):\n    # This decorator converts your objective function \n    # with named arguments into one that accepts a list as argument,\n    # while doing the conversion automatically.\n    @use_named_args(space) \n    def objective(**params):\n        model.set_params(**params)\n        print(\"\\nTesting: \", params)\n        validation_scores = list()\n        for k, (train_index, test_index) in enumerate(kf.split(X, y)):\n            val_index = list()\n            train_examples = int(train_examples * (1 - validation))\n            train_index, val_index = (train_index[:train_examples], \n                                      train_index[train_examples:])\n\n            start_time = time()\n            model.fit(X.iloc[train_index,:], y[train_index],\n                      early_stopping_rounds=50,\n                      eval_set=[(X.iloc[val_index,:], y[val_index])], \n                      verbose=0\n                    )\n            end_time = time()\n\n            rounds = model.best_iteration\n\n            test_preds = model.predict(X.iloc[test_index,:])\n            test_score = scoring(y[test_index], test_preds)\n            print(f\"CV Fold {k+1} rmse:{test_score:0.5f}-{rounds} \n                  rounds - it took {end_time-start_time:0.0f} secs\")\n            validation_scores.append(test_score) \n```", "```py\n if len(history[k]) >= 10:\n                threshold = np.percentile(history[k], q=25)\n                if test_score > threshold:\n                    print(f\"Early stopping for under-performing fold: \n                          threshold is {threshold:0.5f}\")\n                    return np.mean(validation_scores)\n\n            history[k].append(test_score)\n        return np.mean(validation_scores)\n    return objective \n```", "```py\nobjective = make_objective(model,\n                           X_train, y_train,\n                           space=space,\n                           cv=kf,\n                           scoring=scoring) \n```", "```py\ndef onstep(res):\n    global counter\n    x0 = res.x_iters   # List of input points\n    y0 = res.func_vals # Evaluation of input points\n    print('Last eval: ', x0[-1], \n          ' - Score ', y0[-1])\n    print('Current iter: ', counter, \n          ' - Best Score ', res.fun, \n          ' - Best Args: ', res.x)\n    # Saving a checkpoint to disk\n    joblib.dump((x0, y0), 'checkpoint.pkl') \n    counter += 1 \n```", "```py\ncounter = 0\nhistory = {i:list() for i in range(5)}\nused_time = 0\ngp_round = dummy_minimize(func=objective,\n                          dimensions=space,\n                          n_calls=30,\n                          callback=[onstep],\n                          random_state=0) \n```", "```py\nx0, y0 = joblib.load('checkpoint.pkl')\nprint(len(x0)) \n```", "```py\nx0, y0 = joblib.load('checkpoint.pkl')\ngp_round = gp_minimize(func=objective,\n                       x0=x0,    # already examined values for x\n                       y0=y0,    # observed values for x0\n                       dimensions=space,\n                       acq_func='gp_hedge',\n                       n_calls=30,\n                       n_initial_points=0,\n                       callback=[onstep],\n                       random_state=0) \n```", "```py\nx0, y0 = joblib.load('checkpoint.pkl')\nprint(f\"Best score: {gp_round.fun:0.5f}\")\nprint(\"Best hyperparameters:\")\nfor sp, x in zip(gp_round.space, gp_round.x):\n    print(f\"{sp.name:25} : {x}\") \n```", "```py\nimport tensorflow as tf \n```", "```py\ndef df_to_dataset(dataframe, shuffle=True, batch_size=32):\n    dataframe = dataframe.copy()\n    labels = dataframe.pop('target')\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe),   \n                                             labels))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dataframe))\n    ds = ds.batch(batch_size)\n    return ds\ntf.keras.utils.get_custom_objects().update({'leaky-relu': tf.keras.layers.Activation(tf.keras.layers.LeakyReLU(alpha=0.2))}) \n```", "```py\ndef create_model(cat0_dim, cat1_dim, cat2_dim,\n                 cat3_dim, cat4_dim, cat5_dim, \n                 cat6_dim, cat7_dim, cat8_dim, cat9_dim,\n                 layers, layer_1, layer_2, layer_3, layer_4, layer_5, \n                 activation, dropout, batch_normalization, learning_rate, \n                 **others):\n\n    dims = {'cat0': cat0_dim, 'cat1': cat1_dim, 'cat2': cat2_dim, \n            'cat3': cat3_dim, 'cat4': cat4_dim, 'cat5': cat5_dim,\n            'cat6': cat6_dim, 'cat7': cat7_dim, 'cat8': cat8_dim, \n            'cat9': cat9_dim}\n\n    vocab = {h:X_train['cat4'].unique().astype(int) \n             for h in ['cat0', 'cat1', 'cat2', 'cat3', \n                       'cat4', 'cat5', 'cat6', 'cat7', \n                       'cat8', 'cat9']}\n\n    layers = [layer_1, layer_2, layer_3, layer_4, layer_5][:layers]\n\n    feature_columns = list()\n    for header in ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', \n                   'cont6','cont7', 'cont8', 'cont9', 'cont10',\n                   'cont11', 'cont12', 'cont13']:\n\n        feature_columns.append(tf.feature_column.numeric_column(header))\n    for header in ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', \n                   'cat6', 'cat7', 'cat8', 'cat9']:\n        feature_columns.append(\n            tf.feature_column.embedding_column(\n            tf.feature_column.categorical_column_with_vocabulary_list(\n            header, vocabulary_list=vocab[header]),  \n            dimension=dims[header]))\n    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n    network_struct = [feature_layer]\n    for nodes in layers:\n        network_struct.append(\n                 tf.keras.layers.Dense(nodes, activation=activation))\n        if batch_normalization is True:\n                   network_struct.append(\n                   tf.keras.layers.BatchNormalization())\n        if dropout > 0:\n            network_struct.append(tf.keras.layers.Dropout(dropout))\n    model = tf.keras.Sequential(network_struct + \n                                [tf.keras.layers.Dense(1)])\n    model.compile(optimizer=tf.keras.optimizers.Adam(\n                          learning_rate=learning_rate),\n                  loss= tf.keras.losses.MeanSquaredError(),\n                  metrics=['mean_squared_error'])\n\n    return model \n```", "```py\n# Setting the search space\n\nspace = [Integer(1, 2, name='cat0_dim'),\n         Integer(1, 2, name='cat1_dim'),\n         Integer(1, 2, name='cat2_dim'),\n         Integer(1, 3, name='cat3_dim'),\n         Integer(1, 3, name='cat4_dim'),\n         Integer(1, 3, name='cat5_dim'),\n         Integer(1, 4, name='cat6_dim'),\n         Integer(1, 4, name='cat7_dim'),\n         Integer(1, 6, name='cat8_dim'),\n         Integer(1, 8, name='cat9_dim'),\n         Integer(1, 5, name='layers'),\n         Integer(2, 256, name='layer_1'),\n         Integer(2, 256, name='layer_2'),\n         Integer(2, 256, name='layer_3'),\n         Integer(2, 256, name='layer_4'),\n         Integer(2, 256, name='layer_5'),\n         Categorical(['relu', 'leaky-relu'], name='activation'),\n         Real(0.0, 0.5, 'uniform', name='dropout'),\n         Categorical([True, False], name='batch_normalization'),\n         Categorical([0.01, 0.005, 0.002, 0.001], name='learning_rate'),\n         Integer(256, 1024, name='batch_size')\n        ] \n```", "```py\ndef make_objective(model_fn, X, space, cv, scoring, validation=0.2):\n    # This decorator converts your objective function with named arguments\n    # into one that accepts a list as argument, while doing the conversion\n    # automatically.\n    @use_named_args(space) \n    def objective(**params):\n\n        print(\"\\nTesting: \", params)\n        validation_scores = list()\n\n        for k, (train_index, test_index) in enumerate(kf.split(X)):\n            val_index = list()\n            train_examples = len(train_index)\n            train_examples = int(train_examples * (1 - validation))\n            train_index, val_index = (train_index[:train_examples], \n                                      train_index[train_examples:])\n\n            start_time = time()\n\n            model = model_fn(**params)\n            measure_to_monitor = 'val_mean_squared_error'\n            modality='min'\n            early_stopping = tf.keras.callbacks.EarlyStopping(\n                                 monitor=measure_to_monitor,\n                                 mode=modality,\n                                 patience=5, \n                                 verbose=0)\n            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n                                   'best.model',\n                                   monitor=measure_to_monitor, \n                                   mode=modality, \n                                   save_best_only=True, \n                                   verbose=0)\n            run = model.fit(df_to_dataset(\n                                X_train.iloc[train_index, :], \n                                batch_size=params['batch_size']),\n                            validation_data=df_to_dataset(\n                                X_train.iloc[val_index, :], \n                                batch_size=1024),\n                            epochs=1_000,\n                            callbacks=[model_checkpoint, \n                                       early_stopping],\n                            verbose=0)\n\n            end_time = time()\n\n            rounds = np.argmin(\n                     run.history['val_mean_squared_error']) + 1\n\n            model = tf.keras.models.load_model('best.model')\n            shutil.rmtree('best.model')\n\n            test_preds = model.predict(df_to_dataset(\n                            X.iloc[test_index, :], shuffle=False, \n                            batch_size=1024)).flatten()\n                            test_score = scoring(\n                            X.iloc[test_index, :]['target'], \n                            test_preds)\n            print(f\"CV Fold {k+1} rmse:{test_score:0.5f} - {rounds} \n                  rounds - it took {end_time-start_time:0.0f} secs\")\n            validation_scores.append(test_score)\n\n            if len(history[k]) >= 10:\n                threshold = np.percentile(history[k], q=25)\n                if test_score > threshold:\n                    print(f\"Early stopping for under-performing fold: \n                          threshold is {threshold:0.5f}\")\n                    return np.mean(validation_scores)\n\n            history[k].append(test_score)\n        return np.mean(validation_scores)\n    return objective \n```", "```py\ncounter = 0\nhistory = {i:list() for i in range(5)}\nused_time = 0\ngp_round = dummy_minimize(func=objective,\n                          dimensions=space,\n                          n_calls=10,\n                          callback=[onstep],\n                          random_state=0)\ngc.collect()\nx0, y0 = joblib.load('checkpoint.pkl')\ngp_round = gp_minimize(func=objective,\n                           x0=x0,  # already examined values for x\n                           y0=y0,  # observed values for x0\n                           dimensions=space,\n                           n_calls=30,\n                           n_initial_points=0,\n                           callback=[onstep],\n                           random_state=0)\ngc.collect() \n```", "```py\n!pip install -U keras-tuner\n!pip install -U tensorflow-addons \n```", "```py\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\npad_sequences = keras.preprocessing.sequence.pad_sequences\nimdb = keras.datasets.imdb(train_data, train_labels),\n(test_data, test_labels) = imdb.load_data(num_words=10000)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.30,\n                 shuffle=True, random_state=0) \n```", "```py\n# A dictionary mapping words to an integer index\nword_index = imdb.get_word_index()\n# The first indices are reserved\nword_index = {k:(v+3) for k,v in word_index.items()} \nword_index[\"<PAD>\"] = 0\nword_index[\"<START>\"] = 1\nword_index[\"<UNK>\"] = 2  # unknown\nword_index[\"<UNUSED>\"] = 3\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text]) \n```", "```py\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Flatten, RepeatVector, dot, multiply, Permute, Lambda\nK = keras.backend\ndef attention(layer):\n    # --- Attention is all you need --- #\n    _,_,units = layer.shape.as_list()\n    attention = Dense(1, activation='tanh')(layer)\n    attention = Flatten()(attention)\n    attention = Activation('softmax')(attention)\n    attention = RepeatVector(units)(attention)\n    attention = Permute([2, 1])(attention)\n    representation = multiply([layer, attention])\n    representation = Lambda(lambda x: K.sum(x, axis=-2), \n                            output_shape=(units,))(representation)\n    # ---------------------------------- #\n    return representation \n```", "```py\ndef get_optimizer(option=0, learning_rate=0.001):\n    if option==0:\n        return tf.keras.optimizers.Adam(learning_rate)\n    elif option==1:\n        return tf.keras.optimizers.SGD(learning_rate, \n                                       momentum=0.9, nesterov=True)\n    elif option==2:\n        return tfa.optimizers.RectifiedAdam(learning_rate)\n    elif option==3:\n        return tfa.optimizers.Lookahead(\n                   tf.optimizers.Adam(learning_rate), sync_period=3)\n    elif option==4:\n        return tfa.optimizers.SWA(tf.optimizers.Adam(learning_rate))\n    elif option==5:\n        return tfa.optimizers.SWA(\n                   tf.keras.optimizers.SGD(learning_rate, \n                                       momentum=0.9, nesterov=True))\n    else:\n        return tf.keras.optimizers.Adam(learning_rate) \n```", "```py\nlayers = keras.layers\nmodels = keras.models\n\ndef create_tunable_model(hp, vocab_size=10000, pad_length=256):\n    # Instantiate model params\n    embedding_size = hp.Int('embedding_size', min_value=8, \n                            max_value=512, step=8)\n    spatial_dropout = hp.Float('spatial_dropout', min_value=0, \n                               max_value=0.5, step=0.05)\n    conv_layers = hp.Int('conv_layers', min_value=1,\n                         max_value=5, step=1)\n    rnn_layers = hp.Int('rnn_layers', min_value=1,\n                        max_value=5, step=1)\n    dense_layers = hp.Int('dense_layers', min_value=1,\n                          max_value=3, step=1)\n    conv_filters = hp.Int('conv_filters', min_value=32, \n                          max_value=512, step=32)\n    conv_kernel = hp.Int('conv_kernel', min_value=1,\n                         max_value=8, step=1)\n    concat_dropout = hp.Float('concat_dropout', min_value=0, \n                              max_value=0.5, step=0.05)\n    dense_dropout = hp.Float('dense_dropout', min_value=0, \n                             max_value=0.5, step=0.05) \n```", "```py\n inputs = layers.Input(name='inputs',shape=[pad_length])\n    layer  = layers.Embedding(vocab_size, embedding_size, \n                              input_length=pad_length)(inputs)\n    layer  = layers.SpatialDropout1D(spatial_dropout)(layer)\n    for l in range(conv_layers):\n        if l==0:\n            conv = layers.Conv1D(filters=conv_filters, \n                       kernel_size=conv_kernel, padding='valid',\n                       kernel_initializer='he_uniform')(layer)\n        else:\n            conv = layers.Conv1D(filters=conv_filters,  \n                       kernel_size=conv_kernel, padding='valid', \n                       kernel_initializer='he_uniform')(conv) \n    avg_pool_conv = layers.GlobalAveragePooling1D()(conv)\n    max_pool_conv = layers.GlobalMaxPooling1D()(conv)\n    representations = list()\n    for l in range(rnn_layers):\n\n        use_bidirectional = hp.Choice(f'use_bidirectional_{l}',\n                                      values=[0, 1])\n        use_lstm = hp.Choice(f'use_lstm_{l}', values=[0, 1])\n        units = hp.Int(f'units_{l}', min_value=8, max_value=512, step=8)\n        if use_lstm == 1:\n            rnl = layers.LSTM\n        else:\n            rnl = layers.GRU\n        if use_bidirectional==1:\n            layer = layers.Bidirectional(rnl(units, \n                              return_sequences=True))(layer)\n        else:\n            layer = rnl(units, return_sequences=True)(layer)\n        representations.append(attention(layer))\n    layer = layers.concatenate(representations + [avg_pool_conv, \n                                                  max_pool_conv])\n    layer = layers.Dropout(concat_dropout)(layer)\n    for l in range(dense_layers):\n        dense_units = hp.Int(f'dense_units_{l}', min_value=8, \n                             max_value=512, step=8)\n        layer = layers.Dense(dense_units)(layer)\n        layer = layers.LeakyReLU()(layer)\n        layer = layers.Dropout(dense_dropout)(layer)\n    layer = layers.Dense(1, name='out_layer')(layer)\n    outputs = layers.Activation('sigmoid')(layer)\n    model = models.Model(inputs=inputs, outputs=outputs) \n```", "```py\n hp_learning_rate = hp.Choice('learning_rate', \n                                 values=[0.002, 0.001, 0.0005])\n    optimizer_type = hp.Choice('optimizer', values=list(range(6)))\n    optimizer = get_optimizer(option=optimizer_type,  \n                              learning_rate=hp_learning_rate)\n\n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy',\n                  metrics=['acc'])\n\n    return model \n```", "```py\nimport keras_tuner as kt\ntuner = kt.BayesianOptimization(hypermodel=create_tunable_model,\n                                objective='val_acc',\n                                max_trials=100,\n                                num_initial_points=3,\n                                directory='storage',\n                                project_name='imdb',\n                                seed=42)\ntuner.search(train_data, train_labels, \n             epochs=30,\n             batch_size=64, \n             validation_data=(val_data, val_labels),\n             shuffle=True,\n             verbose=2,\n             callbacks = [EarlyStopping('val_acc',\n                                        patience=3,\n                                        restore_best_weights=True)]\n             ) \n```", "```py\nbest_hps = tuner.get_best_hyperparameters()[0]\nmodel = tuner.hypermodel.build(best_hps)\nprint(best_hps.values)\nmodel.summary()\nmodel.save(\"best_model.h5\") \n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom xgboost import XGBRegressor\nimport optuna\nfrom optuna.integration import XGBoostPruningCallback\n# Loading data \nX_train = pd.read_csv(\"../input/30-days-of-ml/train.csv\").iloc[:100_000, :]\nX_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n# Preparing data as a tabular matrix\ny_train = X_train.target\nX_train = X_train.set_index('id').drop('target', axis='columns')\nX_test = X_test.set_index('id')\n# Pointing out categorical features\ncategoricals = [item for item in X_train.columns if 'cat' in item]\n# Dealing with categorical data using OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nX_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])\nX_test[categoricals] = ordinal_encoder.transform(X_test[categoricals]) \n```", "```py\ndef objective(trial):\n\n    params = {\n            'learning_rate': trial.suggest_float(\"learning_rate\", \n                                                 0.01, 1.0, log=True),\n            'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", \n                                                   1e-9, 100.0),\n            'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", \n                                                  1e-9, 100.0),\n            'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n            'colsample_bytree': trial.suggest_float(\n                                      \"colsample_bytree\", 0.1, 1.0),\n            'max_depth': trial.suggest_int(\"max_depth\", 1, 7),\n            'min_child_weight': trial.suggest_int(\"min_child_weight\", \n                                                  1, 7),\n            'gamma': trial.suggest_float(\"gamma\", 0.1, 1.0, step=0.1)\n    }\n    model = XGBRegressor(\n        random_state=0,\n        tree_method=\"gpu_hist\",\n        predictor=\"gpu_predictor\",\n        n_estimators=10_000,\n        **params\n    )\n\n    model.fit(x, y, early_stopping_rounds=300, \n              eval_set=[(x_val, y_val)], verbose=1000,\n              callbacks=[XGBoostPruningCallback(trial, 'validation_0-rmse')])\n    preds = model.predict(x_test)\n    rmse = mean_squared_error(y_test, preds, squared=False)\n    return rmse \n```", "```py\nx, x_val, y, y_val = train_test_split(X_train, y_train, random_state=0,\n                                      test_size=0.2)\nx, x_test, y, y_test = train_test_split(x, y, random_state=0, test_size=0.25)\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective, n_trials=100) \n```", "```py\nprint(study.best_value)\nprint(study.best_params) \n```"]