["```py\n    carla.Transform(carla.Location(x=1.6, z=1.7), \t  carla.Rotation(pitch=-15))\n    ```", "```py\n    save_img(image_rgb, '_out/rgb/rgb_%08d.png' % \t  image_rgb.frame)\n    save_img(image_semseg, '_out/seg_raw/seg_raw_%08d.png' % \t  image_rgb.frame)\n    ```", "```py\n    save_img(image_semseg, '_out/seg/seg_%08d.png' % \t  image_rgb.frame)\n    ```", "```py\n    def save_img(image, path):\n        array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n        array = np.reshape(array, (image.height, image.width, 4))\n        array = array[:, :, :3]\n        img = cv2.resize(array, (160, 160), \t interpolation=cv2.INTER_NEAREST)\n        cv2.imwrite(path, img)\n    ```", "```py\nlayer = BatchNormalization()(layer)\nlayer = ReLU()(layer)\nlayer = Conv2D(num_filters, kernel_size, padding=\"same\",   kernel_initializer='he_uniform')(layer)\n```", "```py\n    def dn_conv(layer, num_filters, kernel_size, dropout=0.0):\n        layer = BatchNormalization()(layer)\n        layer = ReLU()(layer)\n        layer = Conv2D(num_filters, kernel_size, padding=\"same\", kernel_initializer='he_uniform')(layer)\n         if dropout > 0.0:\n            layer = Dropout(dropout)(layer)\n         return layer\n    ```", "```py\n    def dn_dense(layer, growth_rate, num_layers, add_bottleneck_layer, dropout=0.0):\n      block_layers = []\n      for i in range(num_layers):\n        new_layer = dn_conv(layer, 4 * growth_rate, (1, 1),       dropout) if add_bottleneck_layer else layer\n        new_layer = dn_conv(new_layer, growth_rate, (3, 3), dropout)\n        block_layers.append(new_layer)\n        layer = Concatenate()([layer, new_layer])\n      return layer, Concatenate()(block_layers)\n    ```", "```py\ndef dn_transition_down(layer, compression_factor=1.0, dropout=0.0):\n  num_filters_compressed = int(layer.shape[-1] *     compression_factor)\n  layer = dn_conv(layer, num_filters_compressed, (1, 1), dropout)\n\n  return AveragePooling2D(2, 2, padding='same')(layer)\n```", "```py\ndef dn_transition_up(skip_connection, layer):  num_filters = int(layer.shape[-1])  layer = Conv2DTranspose(num_filters, kernel_size=3, strides=2,    padding='same',                            kernel_initializer='he_uniform')(layer)  return Concatenate()([layer, skip_connection])\n```", "```py\ninput = Input(input_shape)layer = Conv2D(36, 7, padding='same')(input)\n```", "```py\nskip_connections = []for idx in range(groups):  (layer, _) = dn_dense(layer, growth_rate, 4,     add_bottleneck_layer, dropout)  skip_connections.append(layer)  layer = dn_transition_down(layer, transition_compression_factor,      dropout)\n```", "```py\nskip_connections.reverse()\n(layer, block_layers) = dn_dense(layer, growth_rate, 4,   add_bottleneck_layer, dropout)\n\nfor idx in range(groups):\n  layer = dn_transition_up(skip_connections[idx], block_layers)\n  (layer, block_layers) = dn_dense(layer, growth_rate, 4,     add_bottleneck_layer, dropout)\n```", "```py\nlayer = Conv2D(num_classes, kernel_size=1, padding='same',   kernel_initializer='he_uniform')(layer)output = Activation('softmax')(layer)model = Model(input, output)\n```", "```py\ndef generator(ids, fn_image, fn_label, augment, batch_size):\n    num_samples = len(ids)\n    while 1:  # Loop forever so the generator never terminates\n        samples_ids = shuffle(ids)  # New epoch\n\n        for offset in range(0, num_samples, batch_size):\n            batch_samples_ids = samples_ids[offset:offset + batch_size]\n            batch_samples = np.array([fn_image(x, augment, offset + idx) for idx, x in enumerate(batch_samples_ids)])\n            batch_labels = np.array([fn_label(x, augment, offset + idx) for idx, x in enumerate(batch_samples_ids)])\n\n            yield batch_samples, batch_labels\n```", "```py\ndef extract_image(file_name, augment, idx):\n  img = cv2.resize(cv2.imread(file_name), size_cv,     interpolation=cv2.INTER_NEAREST)\n\n  if augment and (idx % 2 == 0):\n    img = cv2.flip(img, 1)\n\n  return img\n```", "```py\ndef extract_label(file_name, augment, idx):\n  img = cv2.resize(cv2.imread(file_name.replace(\"rgb\", \"seg_raw\",        2)), size_cv, interpolation=cv2.INTER_NEAREST)\n\n  if augment and (idx % 2 == 0):\n    img = cv2.flip(img, 1)\n\n  return convert_to_segmentation_label(img, num_classes)\n```", "```py\ndef convert_to_segmentation_label(image, num_classes):\n  img_label = np.ndarray((image.shape[0], image.shape[1],     num_classes), dtype=np.uint8)\n\n  one_hot_encoding = []\n\n  for i in range(num_classes):\n    one_hot_encoding.append(to_categorical(i, num_classes))\n\n  for i in range(image.shape[0]):\n    for j in range(image.shape[1]):\n      img_label[i, j] = one_hot_encoding[image[i, j, 2]]\n\n  return img_label\n```", "```py\nMin Loss: 0.19355240797595402\nMin Validation Loss: 0.14731630682945251\nMax Accuracy: 0.9389197\nMax Validation Accuracy: 0.9090136885643005\n```", "```py\npalette = [] # in rgb\n\npalette.append([0, 0, 0])  # 0: None\npalette.append([70, 70, 70])  # 1: Buildings\npalette.append([190, 153, 153])  # 2: Fences\npalette.append([192, 192, 192])  # 3: Other  (?)\npalette.append([220, 20, 60])  # 4: Pedestrians\npalette.append([153,153, 153])  # 5: Poles\npalette.append([0, 255, 0])  # 6: RoadLines  ?\npalette.append([128, 64, 128])  # 7: Roads\npalette.append([244, 35,232])  # 8: Sidewalks\npalette.append([107, 142, 35])  # 9: Vegetation\npalette.append([0, 0, 142])  # 10: Vehicles\npalette.append([102,102,156])  # 11: Walls\npalette.append([220, 220, 0])  # 11: Traffic signs\n```", "```py\ndef convert_from_segmentation_label(label):\n    raw = np.zeros((label.shape[0], label.shape[1], 3), dtype=np.uint8)\n    color = np.zeros((label.shape[0], label.shape[1], 3), dtype=np.uint8)\n\n    for i in range(label.shape[0]):\n        for j in range(label.shape[1]):\n            color_label = int(np.argmax(label[i,j]))\n            raw[i, j][2] = color_label\n            # palette from rgb to bgr\n            color[i, j][0] = palette[color_label][2]\n            color[i, j][1] = palette[color_label][1]\n            color[i, j][2] = palette[color_label][0]\n\n    return (raw, color)\n```", "```py\nmedian = cv2.medianBlur(color, 3)\n```"]