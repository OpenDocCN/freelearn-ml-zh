# 第8章

什么是量子机器学习？

*告诉我，我会忘记。教我，我会记住。参与其中，我会学习。*

—— 本杰明·富兰克林

现在我们开始我们的量子机器学习（**QML**）之旅。在本章中，我们将为本部分书籍的其余部分奠定基础。我们将首先回顾一些经典机器学习的一般概念，然后我们将介绍支撑整个QML的基本思想。

在本章中，我们将涵盖以下主题：

+   机器学习的基本原理

+   你想训练一个模型吗？

+   量子-经典模型

在本章中，你将学习通用机器学习背后的基本原理，并了解如何使用行业标准框架和工具构建、训练和评估一些简单的经典模型。我们还将展示量子机器学习（QML）世界的总体图景。

# 8.1 机器学习的基本原理

在讨论量子机器学习之前，回顾一些机器学习（ML）的基本概念可能是个好主意。如果你熟悉这个主题，请随意跳过这一部分。请记住，机器学习的世界非常广阔；如此之大，有时很难做出公正的概括，以体现这个领域的压倒性多样性。因此，我们将强调对我们更有相关性的元素，而其他机器学习的方面——虽然它们本身也很重要——将只做简要介绍。

除了这个，请记住，这将是一个非常浓缩且实用的机器学习入门介绍。如果您想更深入地了解这个领域，我们可以推荐一些非常好的书籍，例如阿布-莫斯塔法、马格东-伊斯拉姆和林所著的书籍[[1](ch030.xhtml#Xabu2012learning)]，或者奥雷利安·热隆所著的书籍[[104](ch030.xhtml#Xhandsonml)]。

尽管机器学习可能看起来很神秘，但其背后的思想相当简单。从广义上讲，我们可以将机器学习的目的定义为设计算法，使“计算系统”能够意识到数据中的模式。这些模式可以是真正的一切。也许你想设计一个能够区分猫和兔子的图片的系统。也许你希望提出一个能够转录带有爱尔兰口音的英语口语的计算模型。也许你想创建一个能够生成不存在但与真实情况难以区分的人脸图片的模型。正如你肯定知道的，可能性是无限的！所有这些算法的共同之处在于，它们不会明确编程来解决这些任务；相反，它们将从数据中“学习”如何去做……这就是“机器学习”这个名字的由来！

猫与兔子的例子是某种有趣类型模型的一个特例：**分类器**。正如其名所示，分类器是任何将标签分配给每个输入的系统，这些标签来自有限的可能集合。在许多情况下，只有两个这样的标签，它们通常表示为![0](img/file12.png "0" "正")（读作**正**）和![1](img/file13.png "1" "负"）；例如，在物理学应用中，这些标签通常分别读作**信号**和**背景**。在这种情况下，我们说分类器是**二元的**。请记住这一点，因为我们将在接下来的几个例子中使用这个术语！

因此，既然我们已经知道了我们的目标，我们需要回答一个基本问题：我们如何使机器学习成为现实？

## 8.1.1 机器学习的要素

在大多数机器学习设置中，有三个基本要素：

+   首先，我们需要某种“足够强大”的计算模型来处理我们的问题。通过这种方式，我们通常意味着一个可以配置来解决当前任务——至少达到一定准确度的算法。

+   然后，如果我们想让我们的模型捕捉到模式，我们需要给它一些数据，这样它才能做到这一点。因此，我们需要数据，最好是大量的数据。这种数据的性质将取决于我们采取的方法，但在大多数情况下，我们需要将其转换为数值形式。大多数模型期望数据以实数向量的形式表示，称为**属性**，所以我们通常假设我们拥有这些。

+   最后，我们需要一个**训练过程**，这将允许我们优化模型的配置，使其解决问题（或者至少接近解决问题！）在机器学习术语中，我们可以说我们需要找到一种方法让我们的模型**学习**，以便识别隐藏在我们问题数据背后的模式。

这是一个相当稳固——但有些过于简化的——愿望清单。让我们看看我们如何使这个清单更有意义。

**模型** 让我们先分析一下我们之前提到的计算模型。我们说它必须“足够强大”，这意味着应该有一种方式来配置模型，使其按我们的意图行事。

乍一看，这个要求可能看起来有些可疑：我们怎么可能确信存在这样的配置呢？在大多数现实生活中的问题中，我们永远不能完全确定……但我们可以在一定程度上确信！这种确定性可能来自经验，或者更理想的是，也来自一些证明它的理论结果。例如，你可能听说过**神经网络**。我们将在稍后讨论它们，但就目前而言，你应该知道它们是已被证明为**通用函数逼近器**的模型。也就是说，任何函数都可以通过足够大的神经网络逼近到任何给定的精度，无论其复杂性如何。这使得神经网络成为许多问题的自然选择。

我们将在后面详细讨论神经网络——以及许多其他有趣的模型，但首先，我们可以考虑一个简化的版本，实际上这个版本可以被认为是神经网络的老祖宗：**感知器**。

感知器是一个计算模型，它接受![N](img/file784.png "N")个数值输入，并返回一个单比特输出。这个模型依赖于一组权重![w_{i}](img/file1095.png "w_{i}")，其中![i = 1,\ldots,N](img/file1096.png "i = 1,\ldots,N")，以及一个偏置![b](img/file17.png "b")，并且它的工作方式如下：对于任何输入![x_{1},\ldots,x_{N}](img/file1097.png "x_{1},\ldots,x_{N}"),如果

| ![sum_{i=1}^{N}x_{i}w_{i} + b \geq 0,](img/file1098.png "sum_{i=1}^{N}x_{i}w_{i} + b \geq 0,") |
| --- |

然后，模型返回![1](img/file13.png "1")，否则返回![0](img/file12.png "0")。

这是一个非常简单的计算模型，但我们可以通过寻找适当的权重和偏置值来设置一个基本的二元分类器。也就是说，给定一组我们希望输出为![1](img/file13.png "1")的点，以及另一组我们希望输出为![0](img/file12.png "0")的点，我们可以尝试寻找![w_{i}](img/file1095.png "w_{i}")和![b](img/file17.png "b")系数的某些值，使得感知器返回期望的输出。实际上，在机器学习时代的黎明时期，已经证明存在一个简单的学习算法，在问题数据可以线性分离的条件下，可以找到能够有效分类数据的系数。

这就是你的第一个婴儿机器学习模型！不用说，感知器——至少就其本身而言——不是一个特别强大的模型，但至少是一个有希望的起点！

练习8.1

我们都可以同意，感知器是可爱的模型。但为了了解它们的局限性，证明它们不能实现XOR门。也就是说，如果你给出输入 ![\{(0,1),(1,0)\}](img/file1099.png "\{(0,1),(1,0)\}")，期望输出![1](img/file13.png "1")，以及输入 ![\{(0,0),(1,1)\}](img/file1100.png "\{(0,0),(1,1)\}")，期望输出![0](img/file12.png "0")，那么在这种情况下没有感知器权重和偏置的组合能够工作。

**训练过程** 好吧，假设我们有一个模型，我们相信它足够强大来接近我们的问题（但也不太强大……关于这一点稍后还会讨论！）。我们将限制自己假设我们的模型配置依赖于一些数值参数 ![\theta](img/file89.png "\theta")；这意味着我们将会寻找那些参数的某个选择 ![\theta_{0}](img/file1045.png "\theta_{0}")，这将使我们的模型尽可能好地工作。那么，我们如何找到这些参数呢？

要了解更多…

我们将只讨论那些行为可以通过调整和定义一些数值参数来调整和定义的模型，就像感知器的情况一样。然而，也存在**非参数**模型，它们的行为不是这样。一个流行的例子是 ![k](img/file317.png "k")-最近邻算法；你可以在参考文献 [[104](ch030.xhtml#Xhandsonml), 第1章] 中找到一些信息。

为了说明所有这些，我们将讨论如何训练一个参数模型来实现二元分类器。也就是说，我们旨在在某个领域 ![D](img/file1101.png "D") 上构建一个二元分类器，该领域有一些元素 ![x](img/file269.png "x")，它们应该被分类为特定的 ![y](img/file270.png "y")（其中 ![y](img/file270.png "y") 可以是 ![0](img/file12.png "0") 或 ![1](img/file13.png "1")）。为此，我们将使用一个模型 ![M](img/file704.png "M")，它依赖于一些参数，对于这些参数的任何选择 ![\theta](img/file89.png "\theta")，它为数据集中的每个元素 ![x \in D](img/file1103.png "x \in D") 返回一个标签 ![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)")。

在这个场景中，我们的目标是寻找一组参数 ![\theta](img/file89.png "\theta")，它可以最小化任何随机输入 ![x](img/file269.png "x") 被错误分类的概率。用稍微正式一点的话来说，如果 ![y](img/file270.png "y") 是应该分配给输入 ![x](img/file269.png "x") 的正确标签，我们希望最小化 ![P(M_{\theta}(x) \neq y)](img/file1104.png "P(M_{\theta}(x) \neq y)"), 即将错误标签分配给 ![x](img/file269.png "x") 的概率。这样，我们就将训练模型的问题简化为寻找一些参数 ![\theta](img/file89.png "\theta")，以最小化 ![P(M_{\theta}(x) \neq y)](img/file1104.png "P(M_{\theta}(x) \neq y)"), 这被称为**泛化误差**或**真实**误差。

现在，如果我们能够访问我们领域 ![D](img/file1101.png "D") 中所有可能的输入，并且我们知道它们的预期输出，我们只需最小化真实误差……我们就完成了！然而，这既不是一个有趣的情况，也不是一个常见的情况。

如果我们有一个问题，我们已经知道所有可能的输入和它们的输出……我们为什么要费心去做所有这些机器学习的事情？我们可以直接实现一个老式的算法！确实，"学习"的全部意义在于能够预测未见数据的正确输出。因此，当我们求助于机器学习时，我们之所以这样做，是因为我们没有完全访问我们领域中的所有可能的输入和输出——要么因为这是不可行的，要么因为这样的领域可能是无限的！

现在我们面临一个问题。我们有一个（可能是无限的）数据域，我们必须最小化真实误差，但我们只能访问它的一小部分。但是……我们究竟如何计算真实误差以使其最小化呢？答案是，在一般情况下，我们无法做到，因为我们需要有关所有数据和问题标签分布的完整信息，而这通常是我们没有的。尽管如此，我们仍然可以访问一个——可能很大的——数据子集。我们能利用它吗？是的，我们当然可以！通常的策略是将我们拥有的数据集分成两个独立的集合：一个**训练数据集**和一个**测试数据集**。训练集通常比测试集大得多，将用于调整我们模型的参数，以尝试最小化真实误差，而测试集将用于估计真实误差本身。

因此，我们能做的就是取我们正在使用的任意训练数据集![T](img/file74.png "T")，而不是最小化我们根本无法访问的真实误差，我们可以尝试最小化**经验误差**：在训练数据集中错误分类一个元素的概率。这个经验误差将被计算为![T](img/file74.png "T")中错误分类元素的比例：

| ![R_{\text{emp}}(\theta) = \frac{1}{&#124;T&#124;}\sum\limits_{(x,y) \in T}1 - \delta(M_{\theta}(x),y),](img/file1105.png "R_{\text{emp}}(\theta) = \frac{1}{&#124;T&#124;}\sum\limits_{(x,y) \in T}1 - \delta(M_{\theta}(x),y),") |
| --- |

其中 ![|T|](img/file1106.png "|T|") 是训练数据集的大小，![\delta(a,b)](img/file1107.png "\delta(a,b)") 如果 ![a = b](img/file1108.png "a = b") 则为 ![1](img/file13.png "1")，否则为 ![0](img/file12.png "0")（这个![\delta](img/file1109.png "\delta")函数被称为克罗内克δ）。我们当然会做所有这些，希望真实误差会与经验误差相似。自然地，这种希望将需要得到证实，并基于一些证据，我们很快就会看到测试数据集如何帮助我们做到这一点。无论如何，如果我们想让所有这些设置都起作用，我们需要使用足够大的数据集。

因此，我们的目标是最小化真实误差，到目前为止，我们唯一的策略是通过最小化经验误差来实现它。然而，在实践中，我们并不经常直接处理这些量。相反，我们采取一种更“通用”的方法：我们寻求最小化**损失函数**的期望值，该函数为每个参数选择![\theta](img/file89.png "\theta")和每个可能的输入![x](img/file269.png "x")及其期望输出![y](img/file270.png "y")定义。例如，我们可以定义0-1损失函数为

| ![L_{01}(\theta;x,y) = 1 - \delta(M_{\theta}(x),y).](img/file1110.png "L_{01}(\theta;x,y) = 1 - \delta(M_{\theta}(x),y).") |
| --- |

根据这个定义，可以很容易地看出，在整个域上取![L_{01}](img/file1111.png "L_{01}")的期望值正好是真实误差；这个期望值被称为**真实风险**。同样，这个损失函数在训练样本上的期望值是实证误差。

重要提示

请记住，在有限数据集上的损失函数的期望值只是它的平均值。

因此，在实践中，我们最小化真实误差的策略将是最小化在训练数据集上适合的损失函数的期望值。我们将把这个期望值称为**经验风险**。由于我们将在后面讨论的原因，我们通常会考虑与![L_{01}](img/file1111.png "L_{01}")不同的损失函数。

**评估训练好的模型**我们现在必须解决一个重要问题。我们如何确保——一旦我们训练了一个模型——它将在训练数据集之外的数据上表现良好？为此，我们不能仅仅依赖于![R_{\text{emp}}(\theta)](img/file1112.png "R_{\text{emp}}(\theta)")，因为那个平均损失是在分类器已经看到的数据上计算的。这就像只对一个学生进行老师已经在课堂上解决的问题的测试一样！

幸运的是，有一种东西可以拯救这一天。你还记得我们之前提到的测试数据集吗？现在是它大放异彩的时候了！事实上，我们已经把这个测试集保存在保险箱里，以确保其示例从未在训练过程中使用过。我们可以把它们看作是完全新的问题，学生从未见过，因此我们可以用它们来评估他们对主题的理解。因此，我们可以计算![M_{\theta}](img/file1113.png "M_{\theta}")在测试集示例上的平均损失——这有时被称为**测试误差**。只要它们代表整个分类问题，并且示例数量足够多，我们就可以相当有信心地说，测试误差将接近模型的真实误差。这仅仅是应用一些统计学中的**中心**定理的例子！

现在，如果测试误差与经验风险相似（并且如果它们足够低），我们就完成了！这就是全部！我们已经成功训练了一个模型。然而，正如你可以想象的那样，事情也可能出错。非常糟糕的错误。

如果测试误差远大于在训练集上计算的实证误差，这会类似于有一个学生知道如何重复老师已经解决的问题的解决方案，但却无法解决新问题。在我们的情况下，这意味着有一个在训练数据集上工作得很好但在其之外的任何输入上犯很多错误的分类器。

这种情况被称为**过拟合**，它是机器学习中最大的风险之一（无意中开玩笑）。它发生在我们的模型以某种方式学习了它所看到的数据的特定细节，但没有学习到一般模式；也就是说，它对训练数据拟合得太好了，因此得名“过拟合”。这个问题通常发生在训练数据集太小或模型太强大时。在前一种情况下，没有足够的信息来提取一般模式。这就是为什么在本章中，我们一直强调数据越多越好。但第二种情况呢？为什么一个非常强大的模型最终会变成一件坏事？

这里有一个例子可以非常说明问题。假设我们想使用机器学习来近似一些未知的真实函数。我们还没有讨论这种设置将如何工作，但核心思想将与我们所看到的类似（我们会寻求最小化损失函数的期望值，等等）。如果我们有一个平面上的![1000](img/file790.png "1000")个点的样本，我们总能找到一个![999](img/file1114.png "999")次的多项式来完美地拟合数据，就像我们总能将一条线拟合到两个点一样。然而，如果这些点只是![f(x) = x](img/file1115.png "f(x) = x")加上一些噪声（这可能是由于一些经验采样错误或其他原因），我们的多项式会不遗余力地拟合这些点，并迅速偏离它应该学习的线性形状。以这种方式，能够拟合过多信息有时会与学习数据的一般模式的目标相悖。这如图*8.1*所示。在这张图中，“拟合”多项式的次数非常大，可以完美地拟合训练数据，包括其噪声，但它错过了隐含的线性模式，在测试数据上的表现非常糟糕。

![图8.1：使用过于强大的模型导致的过拟合简单示例](img/file1116.png)

**图8.1**：使用过于强大的模型导致的过拟合简单示例。

重要提示

有时，机器学习模型可能仅在训练数据集上正常工作。这种现象被称为**过拟合**。它通常发生在训练数据集太小或模型太强大时。

如果你发现自己处于模型过度拟合数据的情境中，你可以尝试获取更多数据——这并不总是可能的——或者以某种方式降低你模型的力量。例如，在我们将在本章后面研究的神经网络中，你可以尝试减小它们的大小。

了解更多…

另一种避免过拟合的流行技术是使用**正则化**。简而言之，正则化限制了模型某些参数可以取的值，有效地使其变得更弱，并且不太可能拟合训练数据的每一个细节。

要了解更多关于正则化技术及其在机器学习中的应用，我们强烈推荐阅读Aurélien Géron所著的书籍[[104](ch030.xhtml#Xhandsonml)]。

你可能还想知道，你的模型可能会表现出一种与过拟合相反的问题，这被恰当地命名为**欠拟合**。如果你的模型表达能力不足，你可能会在训练集和测试集上发现高误差率。例如，如果你使用线性函数来尝试拟合来自二次多项式的点，这些点遵循抛物线形状，你肯定会遇到某种形式的欠拟合。为了解决这个问题，使用更强大的模型——或者如果你恰好在使用正则化，减少正则化的强度。

总结到目前为止我们所讨论的内容，请记住，我们希望获得一个具有低泛化误差的模型；也就是说，一个即使在未训练过的数据上也能表现良好的模型。为了实现这一点，我们考虑一个参数化模型，并寻找那些在训练集上最小化误差的模型参数，因为我们无法轻易计算真实误差。并且为了确保模型在面对新数据时表现良好，我们计算测试数据集上的误差，作为评估经验风险对未见过数据的误差代表性的方法。

然而，使用这种策略，我们仍然可能面临另一个问题。如果我们训练了大量的不同模型，那么仅仅通过纯粹的偶然性，其中一个模型可能在测试数据集上有很好的表现，但在其他领域则不行。事实上，训练的模型越多，这种风险就越高。想象一下，一千名学生参加一个有10个问题、每个问题有两个可能答案的考试。即使他们没有为考试学习，并且完全随机回答，至少有一个人答对的可能性非常高。因此，你不应该使用测试数据集来选择模型，而应该用它来评估模型的行为是否与训练期间的行为相似。

这确实是一个问题，因为我们通常希望训练许多不同的模型，并选择我们认为最好的一个。更重要的是，许多模型都有所谓的**超参数**。这些参数固定了模型的某些属性，例如神经网络的大小和层数（稍后会有更多介绍），这些参数在训练过程中无法优化。通常，我们会用不同超参数值训练许多不同的模型，然后从这些模型中选出最佳模型。

这就是第三种数据集进入等式的地方：**验证数据集**。当我们分割全局数据集时，我们可以构建这样一个额外的数据集；当然，它应该完全独立于训练集和测试集。

我们想要验证集做什么呢？一旦我们用不同的超参数和配置训练了我们的模型，我们就可以在验证集上计算经验风险，并可能选择最好的一个或几个。然后，我们可以在训练集和验证集的并集上再次训练这些模型——以便更好地从我们的数据中提取所有信息——然后计算模型在测试集上的误差，我们一直保留到这个时刻，以便它仍然是一个很好的泛化误差估计器。这样，我们可以在保持测试集原始状态以用于最终评估过程中选择最佳的超参数或模型。

了解更多...

你可能还想知道，使用固定的验证集，选择超参数的一种流行方式是使用![k](img/file317.png "k")**-折交叉验证**。使用这种技术，训练数据集被分成![k](img/file317.png "k")个子集或**折**，大小相等。模型的训练重复![k](img/file317.png "k")次，每次使用不同的子集作为验证数据集，其余的作为训练数据集。性能在每一个验证集上计算，并在![k](img/file317.png "k")次重复中平均。当然，使用交叉验证获得的结果估计比使用固定的验证集更好，但计算成本要高得多——实际上高![k](img/file317.png "k")倍！像scikit-learn这样的软件库——我们将在本章下一节中使用——提供了用于超参数选择的交叉验证实现。如果你想看到这种技术的具体实现，请查看[GridSearchCV的文档](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)——其中CV代表交叉验证。

此外，有时训练过程是迭代的。在这些情况下，**验证损失**（验证数据集上的平均损失）可以在每个迭代的末尾计算，并与训练损失进行比较，以便了解训练的进展情况——并且如果模型开始过拟合，可以提前停止！使用测试集来达到这个目的不是好的做法：测试集应该只在所有训练完成后使用，我们只是想确保我们的结果的有效性。

了解更多...

我们在这里考虑的所有非正式概念都可以使用概率理论的语言精确地表达。如果你想了解机器学习背后的正式机制，你应该看看《从数据中学习》[[1](ch030.xhtml#Xabu2012learning)]或《理解机器学习》[[105](ch030.xhtml#Xunderml)]这本书。

通过所有这些，我们现在对机器学习所需的所有元素都有了很好的理解。在下一节中，我们将通过研究在训练机器学习模型时采取的一些最常见方法，来尝试使所有这些内容更加精确。

## 8.1.2 机器学习的类型

大多数，如果不是所有，机器学习技术都可以归入三个主要类别：**监督学习**、**无监督学习**和**强化学习**。在这本书中，我们将主要使用监督学习，但也会考虑一些无监督学习技术。让我们更详细地解释一下每个机器学习分支的内容。

**监督学习** 监督学习的主要目标是学习预测输入数据上函数的值。这些值可以是来自有限集（我们在这章的大部分时间里一直在讨论的分类问题）的选择，或者可以是连续值，例如一个人的体重或一个月后某些债券的价值。当我们想要预测的值是连续的，我们说我们在解决一个**回归**问题。

当我们使用监督学习来训练模型时，我们需要处理一个数据集，这个数据集既有足够多的有效输入，也有模型对这些输入应该返回的所有预期输出。这被称为拥有一个**标记**的数据集。

例如，如果我们想要使用监督学习训练一个猫-兔图片分类器，我们需要有一个包含兔子和大猫图片的（足够大的）数据集，并且我们还需要知道，对于这些图片中的每一张，它们是兔子的图片还是猫的图片。

使用我们的标记数据集，我们会定义一个依赖于输入和模型参数的损失函数——这样我们就可以计算相应的输出——以及预期的（正确）输出。而且，正如我们之前讨论的那样，然后我们只需应用一个优化算法来找到一个模型配置，该配置可以在训练数据集上最小化损失函数——同时确保没有过拟合。

我们仍然需要讨论那个优化算法将如何工作，但这留待以后再说！

**无监督学习** 当我们使用无监督学习时，我们可以访问**未标记**的数据集，其中没有预期的输出。我们让算法通过尝试识别某些模式来自行学习。例如，我们可能想要将相似的数据点分组在一起（这被称为**聚类**），或者我们可能想要了解数据是如何分布的。

在后一种情况下，我们的目标将是训练一个**生成模型**，我们可以用它来创建新的数据样本。一个令人印象深刻的应用实例是使用**生成对抗网络**，由Ian Goodfellow及其合作者在具有高度影响力的论文[[46](ch030.xhtml#Xgoodfellow2014generative)]中提出，以创建与训练阶段使用的图像相似——但完全不同的图像。这正是我们将在*第* *[*12*](ch021.xhtml#x1-21200012)，* *量子生成对抗网络* *中工作的模型……当然是以量子形式！*

**强化学习** 在强化学习中，模型——在这个设置中通常被称为**智能体**——与**环境**交互，试图完成某些任务。这个智能体观察环境的**状态**并采取一些**行动**，这些行动反过来又影响它所观察到的状态。根据其表现，它会收到“奖励”和“惩罚”……当然，它希望最大化奖励同时最小化惩罚。为了做到这一点，它试图学习一个**策略**，该策略决定了在给定环境状态时采取什么行动。

例如，智能体可能是一个机器人，环境是一个它需要导航的迷宫。状态可以包括它在迷宫中的位置和它可以跟随的开放路径，它的行动可以是旋转到某个方向并向前移动。目标可能是找到迷宫的出口，在预定的某个时间内完成，这样机器人将获得正面的奖励。

这种学习已被广泛用于训练旨在玩游戏的设计模型——AlphaGo，这个计算机程序在2016年以五场比赛击败了围棋（人类）大师李世石，是一个突出的例子！要了解更多关于强化学习的信息，一个很好的来源是Sutton和Barto合著的书籍[[93](ch030.xhtml#Xsutton2018reinforcement)]。

虽然人们对在强化学习中使用量子技术表现出一些兴趣（例如，参见[[91](ch030.xhtml#Xskolik2022quantum)]），但这可能是目前量子算法发展较慢的机器学习分支。因此，我们不会在本书中涵盖这种学习。希望几年后会有更多关于量子强化学习的内容！现在，让我们通过使用监督学习来实现一个非常简单的分类器来使一切具体化。为此，我们将使用TensorFlow。

# 8.2 你想训练一个模型吗？

TensorFlow是Google开发的一个机器学习框架，它被广泛使用。你应该参考*附录* [*D*](ch027.xhtml#x1-240000D)，*安装工具*，以获取安装说明。请记住，我们将使用2.9.1版本。我们将在我们的量子机器学习模型中使用TensorFlow，因此尽早熟悉它是明智的。

为了保持事情简单，我们将解决一个人工问题。我们将准备一个包含属于两种可能类别之一的元素的数据库，并尝试使用机器学习来构建一个分类器，以区分任何给定输入属于哪个类别。

在我们做任何事情之前，让我们快速导入NumPy并设置一个种子：

[PRE0]

我们稍后将与TensorFlow使用相同的种子。现在，让我们生成数据！

我们不会手动生成数据库，而是将使用Python **scikit-learn** 包（`sklearn`）提供的函数。这个包是机器学习的一个非常有价值的资源：它不仅包括大量用于日常机器学习相关任务的有用工具，而且还允许你训练和执行大量有趣的模型！我们将使用`sklearn`的1.0.2版本，并且，像往常一样，你应该参考*附录* *[*D*](ch027.xhtml#x1-240000D)，*安装工具*，以获取安装说明。

*为了生成我们的数据库，我们将使用`sklearn.datasets`中的`make_classification`函数。我们将要求它生成![2500](img/file1117.png "2500")个具有两个特征（变量）的数据库样本。我们还将要求两个特征都是**信息性**的，而不是冗余的；例如，如果其中一个变量只是另一个变量的倍数，则这些变量将是冗余的。最后，我们还将要求数据库中两个类别的比例是![20\,\%](img/file1118.png "20\,\%")到![80\,\%](img/file1119.png "80\,\%")。我们可以这样做：

[PRE1]

`class_sep`参数指定了我们希望两个类别有多大的可区分性：此参数的值越高，区分它们就越容易。请注意，我们还使用了之前设置的种子，以确保结果可重复。

你现在可能想知道，为什么我们指定了数据库中的两个类别比例应该是![20\,\%](img/file1118.png "20\,\%")到![80\,\%](img/file1119.png "80\,\%")，当两个类别平衡会更为自然。确实，在数据库中两个类别拥有相同数量的代表是理想的……但是生活是艰难的，在许多实际场景中，这种情况并不总是可能的！所以，就让我们把我们的这个选择看作是我们自己接近现实生活的小小方式吧。

实际上，`make_classification`函数返回了一个包含整个数据集（包括两个类别中所有正负元素）的数组`data`，以及一个数组`labels`，使得`data[i]`的标签将是`labels[i]`（其中![0](img/file12.png "0")对应正类，![1](img/file13.png "1")对应负类）。

为了让我们对所创建的数据集有一个直观的感觉，我们可以绘制一个简单的直方图，显示我们数据集中两个特征的分布：

[PRE2]

运行此操作后，我们得到了*图*[*8.2*](#Figure8.2)中所示的图表。

![图8.2：表示我们数据集两个特征的分布的直方图。](img/file1120.png)

**图8.2**：表示我们数据集两个特征的分布的直方图。

练习8.2

通过图表可视化你所处理的数据可以帮助你深入了解如何解决你手头的难题。我们已经使用直方图绘制了我们的数据，这通常是一个不错的选择。我们还可以使用哪些其他表示方法？

我们现在的目标是使用机器学习来构建一个可以解决我们创建的分类问题的系统。这样做的第一步将是选择一个好的模型来处理我们的问题！

## 8.2.1 选择一个模型

不久前，我们介绍了感知器，并展示了它**单独使用**时并不是最强大的模型。现在，我们将解释为什么我们强调了“单独使用”，因为我们即将介绍一个非常有趣的模型，这个模型可以被认为是通过将感知器连接在一起来构建的。让我们深入探讨**神经网络**吧！

你可能还记得，感知器如何接受![N](img/file784.png "N")个数值输入![x_{i}](img/file714.png "x_{i}")，使用一组![N](img/file784.png "N")个权重![w_{i}](img/file1095.png "w_{i}")和一个偏置![b](img/file17.png "b")，并返回一个依赖于

| ![求和符号\sum\limits_{i = 1}^{N}w_{i}x_{i} + b.](img/file1121.png "\sum\limits_{i = 1}^{N}w_{i}x_{i} + b.") |
| --- |

好吧，这样我们就可以将神经网络看作是一组感知器——从现在起，我们将它们称为**神经元**——按照以下方式组织：

+   所有神经元都排列成层，一个层的神经元的输出是下一层神经元的输入。

+   此外，每个神经元的“原始”线性输出将通过我们选择的（很可能非线性的）**激活函数**。

这就是一般思路，但现在让我们使其更精确。

一个有![N_{0}](img/file1122.png "N_{0}")个输入的神经网络由以下元素定义：

+   一个有序的**层**序列([l = 1,\ldots,L](img/file1123.png "l = 1,\ldots,L"))，每层有固定数量的**神经元**![N_{l}](img/file1124.png "N_{l}")。

+   每个层的每个神经元![n](img/file244.png "n")都有一个**激活函数**![h_{ln}](img/file1125.png "h_{ln}")。

+   每个神经元都有一个**偏差** ![b_{ln}](img/file1126.png "b_{ln}") 的集合，对于每一层 ![l](img/file514.png "l") 中的神经元 ![n](img/file244.png "n")，都有一个 ![N_{l - 1}](img/file1127.png "N_{l - 1}") **权重** ![w_{kln}](img/file1128.png "w_{kln}") 的集合，其中 ![k = 1,\ldots,N_{l - 1}](img/file1129.png "k = 1,\ldots,N_{l - 1}")。这些偏差和权重是我们需要调整以使模型按我们希望的方式运行的调整参数。

在 *图* *[*8.3*](#Figure8.3) 中，我们可以看到一个简单神经网络的图形表示。

*![图8.3：一个简单的具有两层且接收三个输入 (a_{0n}) 的神经网络。我们标记了一些权重，但没有标记任何偏差或激活函数 ](img/file1131.jpg)

**图8.3**：一个简单的具有两层且接收三个输入 ![a_{0n})](img/file1130.png "a_{0n})") 的神经网络。我们标记了一些权重，但没有标记任何偏差或激活函数

这些就是我们设置神经网络所需的成分。那么，它是如何工作的呢？很简单！对于任何选择的激活函数 ![h_{ln}](img/file1125.png "h_{ln}")、偏差 ![b_{ln}](img/file1126.png "b_{ln}") 和权重 ![w_{kln}](img/file1128.png "w_{kln}")，神经网络接收一些数值输入 ![a_{0n}](img/file1132.png "a_{0n}")，然后，从那里开始，这些输入以以下方式通过神经网络的层传播：所有层 ![l](img/file514.png "l") 中神经元 ![n](img/file244.png "n") 的值 ![a_{ln}](img/file1133.png "a_{ln}") 根据归纳公式确定

| ![a_{ln}: - h_{ln}\left( {b_{ln} + \sum\limits_{k = 1}^{N_{l - 1}}w_{kln}a_{l - 1,k}} \right).](img/file1134.png "a_{ln}: - h_{ln}\left( {b_{ln} + \sum\limits_{k = 1}^{N_{l - 1}}w_{kln}a_{l - 1,k}} \right).") |
| --- |

通过这个程序，我们可以为网络中的每个神经元分配一个值。最后一层中神经元的值是模型的输出。

严格来说，我们刚才描述的是所谓的**人工** **前馈密集神经网络**。神经网络还有其他可能的架构，但这是本书大部分内容将使用的架构。

这就是如何定义一个神经网络，但在定义中有一个元素我们没有给予太多关注：激活函数。我们之前提到过，这可以是我们选择的任何函数，我们也看到了它在神经网络行为中扮演的角色，但这个函数有哪些合理的选项呢？让我们来探索最常见的几种：

+   我们可能从一个简单的激活函数开始，实际上，这就是我们在定义感知器时隐含考虑的同一个函数。这是一个**阶梯函数**，由以下给出

    | ![h(x) = \left\{ \begin{array}{ll} {1,\quad} & {x \geq 0} \\ {0,\quad} & {x < 0.} \\ \end{array} \right.](img/file1135.png "h(x) = \left\{ \begin{array}{ll} {1,\quad} & {x \geq 0} \\ {0,\quad} & {x < 0.} \\ \end{array} \right.") |
    | --- |

    我们在技术上可以在神经网络中使用这个函数，但……实际上……这并不是一个非常明智的选择。它既不可导，甚至不连续。而且，正如我们很快就会看到的，这通常使任何函数成为神经网络内部激活函数的糟糕候选者。无论如何，它是一个具有历史重要性的例子。

+   让我们考虑一个稍微复杂且有趣的例子：**sigmoid**激活函数。这个函数是平滑且连续的，其输出值在![0](img/file12.png "0")和![1](img/file13.png "1")之间。这使得它成为例如分类器最终层的激活函数的理想候选者。它被定义为

    | ![S(x) = \frac{e^{x}}{e^{x} + 1}.](img/file1136.png "S(x) = \frac{e^{x}}{e^{x} + 1}.") |
    | --- |

    我们已在*图* [*8.4a*](#Figure8.4a)中绘制了它。

+   尽管它看起来可能很美，但当用于内部层时，sigmoid函数很容易在训练过程中导致问题（有关更多内容，请参阅Aurelien的书籍 [[104](ch030.xhtml#Xhandsonml)]）。一般来说，内部层更好的选择是**指数线性单元**或**ELU**激活函数，其定义为

    | ![E(x) = \left\{ \begin{array}{ll} {x,\quad} & {x \geq 0} \\ {e^{x} - 1,\quad} & {x < 0.} \\ \end{array} \right.](img/file1137.png "E(x) = \left\{ \begin{array}{ll} {x,\quad} & {x \geq 0} \\ {e^{x} - 1,\quad} & {x < 0.} \\ \end{array} \right.") |
    | --- |

    你可以在*图* [*8.4b*](#Figure8.4b)中找到它的图像。

+   我们还将讨论最后一个激活函数：**线性整流单元**或**ReLU**函数。一般来说，它的结果比ELU函数差，但它更容易计算，因此其使用可以加快训练速度。它被定义为

    | ![R(x) = \max\{ 0,x\}.](img/file1138.png "R(x) = \max\{ 0,x\}.") |
    | --- |

    该图可以在*图* [*8.4c*](#Figure8.4c)中找到。

练习8.3

检查sigmoid函数![S](img/file73.png "S")的图像是否为![（0,1）](img/file305.png "(0,1)")。证明ELU函数![E](img/file327.png "E")是平滑的，并且其图像为![（-1,∞）](img/file1139.png "( - 1,\infty)")。ReLU函数的图像是什么？它是平滑的吗？

![（a）Sigmoid函数](img/file1140.jpg)

**（a）** Sigmoid函数

![（b）ELU函数](img/file1141.jpg)

**（b）** ELU函数

![（c）ReLU函数](img/file1142.jpg)

**（c）** ReLU函数

**图8.4**：神经网络中的一些常见激活函数

如我们在本章开头提到的，已经证明神经网络是通用的函数逼近器 [[107](ch030.xhtml#Xnn-universal)]，因此它们是任何涉及监督机器学习问题的有趣模型。因此，它们将成为我们构建分类器所使用的模型。我们将考虑一个具有两个输入和一些层的神经网络——我们稍后将会决定它们的具体数量以及每个层将有多少个神经元。最后一层当然将只有一个神经元，它将是输出。在整个网络中，我们将使用ELU激活函数，除了最后一层；在那里，我们将使用sigmoid激活函数以获得归一化的结果。这样，我们将得到一个介于 ![0](img/file12.png "0") 和 ![1](img/file13.png "1") 之间的连续值，并且按照惯例，我们将定义一个阈值 ![\left. 1\slash 2 \right.](img/file136.png "\left. 1\slash 2 \right.") 来分配正 (![\left. \geq 1\slash 2 \right.](img/file1143.png "\left. \geq 1\slash 2 \right.")) 或负 (![\left. < 1\slash 2 \right.](img/file1144.png "\left. < 1\slash 2 \right.")) 给任何给定的输出。

现在我们已经准备好了模型，接下来等待我们的挑战是找到一个合适的损失函数。

## 8.2.2 理解损失函数

当涉及到为依赖于某些连续参数的监督机器学习模型定义损失函数时，我们希望寻找对模型的可训练参数连续且可微的损失函数。这个原因与为什么我们希望激活函数可微的原因相同，这将在稍后变得清晰。

正如我们之前讨论的，最自然的损失函数——我们真正想要最小化的期望值——将是0-1损失函数，但这个函数不会对模型的参数有连续的依赖：它会随着分类器行为的改变而出现“离散跳跃”。因此，我们需要寻找其他损失函数，这些函数确实是连续且可微的，同时在分类问题中测量损失的方式既合理又自然。

另一个相对简单但更好的选择是将**均方误差**作为我们的损失函数。对于我们的问题，我们知道神经网络返回一个介于![0](img/file12.png "0")和![1](img/file13.png "1")之间的连续值，而且我们知道——理想情况下——这个值越接近![0](img/file12.png "0")或![1](img/file13.png "1")，它就越可能分别对应于负或正输入。为了进行分类，我们设置一个阈值为![\left. 1\slash 2 \right.](img/file136.png "\left. 1\slash 2 \right.")并得到一个离散标签，但是，为了计算损失函数，我们实际上应该查看那个连续输出！这样，如果我们让![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)")是模型对于给定输入![x](img/file269.png "x")返回的![\lbrack 0,1\rbrack](img/file1145.png "\lbrack 0,1\rbrack")中的连续值，并且我们让![y \in \{ 0,1\}](img/file1146.png "y \in \{ 0,1\}")是其对应的标签，我们可以将我们的损失函数取为

| ![L(\theta;x,y) = \left( {M_{\theta}(x) - y} \right)^{2},](img/file1147.png "L(\theta;x,y) = \left( {M_{\theta}(x) - y} \right)^{2},") |
| --- |

在这里，我们将所有依赖于我们的神经网络![M](img/file704.png "M")的参数（权重和偏差）分组在![\theta](img/file89.png "\theta")中。

当然，为了计算训练损失（在训练数据集上的期望值），我们只需在训练数据集上取平均值，对于验证损失也是如此。这通常被称为**均方误差**（**MSE**），因为，嗯，它是误差平方的平均值。

均方误差是一个好的损失函数，但当涉及到二元分类器时，实际上有一个更好的候选者：**二元交叉熵**。它是这样计算的

| ![H(\theta;x,y) = - y\log\left( {M_{\theta}(x)} \right) - (1 - y)\log\left( {1 - M_{\theta}(x)} \right).](img/file1148.png "H(\theta;x,y) = - y\log\left( {M_{\theta}(x)} \right) - (1 - y)\log\left( {1 - M_{\theta}(x)} \right).") |
| --- |

现在，这个表达式可能看起来非常复杂，但实际上它是一个非常优雅且强大的损失函数！首先，如果模型的输出相对于其可训练参数是可微的和连续的，那么损失也是（这很容易检查，只需回到微积分101即可）。而且不仅如此。以下练习可能有助于你意识到为什么二元交叉熵函数是二元分类器的优秀选择函数。

练习8.4

证明二元交叉熵损失函数 ![H(\theta;x,y)](img/file1149.png "H(\theta;x,y)") 的输出在 ![M_{\theta}(x) = y](img/file1150.png "M_{\theta}(x) = y") 时为 ![0](img/file12.png "0")，并且当 ![M_{\theta}(x)](img/file1102.png "M_{\theta}(x)") 接近 ![y](img/file270.png "y") 的相反标签时发散到 ![\infty](img/file1151.png "\infty")（这意味着，如果 ![y_{i} = 0](img/file1153.png "y_{i} = 0")，则 ![left. M_{\theta}(x)\rightarrow 1 \right.](img/file1152.png "\left. M_{\theta}(x)\rightarrow 1 \right.")；如果 ![y = 1](img/file769.png "y = 1")，则 ![left. M(x)\rightarrow 0 \right.](img/file1154.png "\left. M(x)\rightarrow 0 \right."））。

因此，我们这个闪亮的新损失函数已经准备好使用。然而，我们还有一个最后的元素需要处理，这是我们迄今为止忽视和忽略的。是的，在接下来的章节中，我们将给予优化算法它们应得的关注和照顾！

## 8.2.3 梯度下降

你现在可能正在家中、大学图书馆或办公室舒适地阅读这本书。但是生活以最意想不到的方式改变，也许在几周后，你会发现自己在山顶上，蒙着眼睛（不要问我们为什么），被赋予了到达附近山谷底部的任务。如果这种情况发生了，你会怎么做？

你不需要成为生存专家就能完成这个任务。诚然——由于未公开的原因——你被蒙上了眼睛，所以你看不见山谷在哪里，但，嘿，你仍然可以四处移动，不是吗？所以，你可以朝着你认为能让你向下移动的最高斜率的方向迈出一些小步。你可以重复这个过程几次，最终你会到达山谷的底部。

当然，在你下降的过程中，你必须小心你的步子有多大。步子太大，你可能会从一个山峰跳到另一个山峰的顶端，中间的所有山谷都跳过了（一些医生建议这可能从解剖学上是不可能的，但，嗯，你明白我们的意思）。另一方面，如果你的步子太小，你可能永远也到不了山谷。所以，你必须找到一个合适的平衡点！

不管怎样，这个看似疯狂的思维实验如何与机器学习相关呢？让我们看看。

**梯度下降算法** 我们现在有一个足够强大的模型，它依赖于一些参数。此外，由于我们做出了明智的生活选择，我们还拥有一个损失函数 ![L](img/file1012.png "L")，它连续依赖于这些参数，并且对这些参数是可微的（这是因为我们选择了一些平滑的激活函数和二元交叉熵）。

通过这样做，我们实际上已经将我们的机器学习问题简化为最小化损失函数的问题，这是一个在某些变量（可训练参数）上的可微函数。我们如何做到这一点？使用力量……抱歉，我们走远了。我们的意思是：使用微积分！

我们之前讨论的“到达山谷”问题——正如你现在可能已经非常准确地猜到的——是一个简单的类比，将帮助我们说明**梯度下降法**。这种方法只是一个算法，将允许我们最小化一个可微函数，我们可以将其视为在山上最陡峭的下坡方向上迈出小步的数学等价。我们应该提醒你，本小节剩余的内容可能有些密集。请，不要让技术细节压倒你。如果这是一首歌，那么不了解歌词是完全正常的；重要的是你要熟悉它的节奏！

如同你从那些美好的本科微积分时光中记得的那样，每当有一个可微函数 ![\left. f:R^{N}\rightarrow R \right.](img/file1155.png "\left. f:R^{N}\rightarrow R \right.")（对于那些不太熟悉数学符号的你们，这是一种说法，意思是 ![f](img/file778.png "f") 有 ![N](img/file784.png "N") 个实数输入并返回一个单一的实数输出），它在点 ![x](img/file269.png "x") 上下降得更陡峭的方向由 ![- \nabla f(x)](img/file1156.png "- \nabla f(x)") 给出，其中 ![\nabla f(x)](img/file1157.png "\nabla f(x)") 是 ![x](img/file269.png "x") 处的**梯度** **向量**，其计算方式为

| ![\nabla f(x) = \left( {\left. \frac{\partial f}{\partial x_{1}} \right&#124;_{x},\ldots,\left. \frac{\partial f}{\partial x_{n}} \right&#124;_{x}} \right),](img/file1158.png "\nabla f(x) = \left( {\left. \frac{\partial f}{\partial x_{1}} \right&#124;_{x},\ldots,\left. \frac{\partial f}{\partial x_{n}} \right&#124;_{x}} \right),") |
| --- |

其中 ![\left. \partial\slash\partial x_{i} \right.](img/file1159.png "\left. \partial\slash\partial x_{i} \right.") 表示关于变量 ![x_{i}](img/file714.png "x_{i}") 的偏导数算子。因此，如果我们想要在某个点上移动到最小值，我们就必须朝着 ![- \nabla f(x)](img/file1156.png "- \nabla f(x)") 的方向移动，但移动多少呢？

步长的大小在数学上对应一个参数 ![\tau](img/file1160.png "\tau")，称为**学习率**。并且，以这种方式，给定一个学习率 ![\tau](img/file1160.png "\tau") 和我们模型参数的初始配置 ![\theta_{0}](img/file1045.png "\theta_{0}")，我们可以通过迭代计算，根据以下规则尝试找到最小化损失函数 ![L](img/file1012.png "L") 的参数：

| ![θ_{k + 1} = θ_{k} - τ∇L(θ_{k}).](img/file1161.png "θ_{k + 1} = θ_{k} - τ∇L(θ_{k}).") |
| --- |

有些算法会随着优化过程的进行动态调整这个步长大小，从初始学习率开始。其中一种算法是**Adam**（即**自适应矩估计器**），这是目前最好的梯度下降算法之一；它实际上将成为我们的首选选择。

重要提示

智能地选择学习率非常重要。如果它太小，训练将会非常缓慢。如果太大，你可能会发现自己迈出巨大的步伐，跳过整个山谷，训练可能永远不会成功。

当然，为了让梯度下降算法能够工作，你需要能够计算损失函数的梯度。有几种方法可以做到这一点；例如，你总是可以数值估计梯度。但是，当处理某些模型，如神经网络时，你可以采用一种称为**反向传播**的技术，它能够高效地计算精确梯度。你可以在Gerón的杰出著作中了解更多关于技术细节[[104](ch030.xhtml#Xhandsonml)，第10章]]。

要了解更多...

反向传播的方法一直是导致我们今天所经历的深度学习巨大成功的关键发展之一。尽管这种技术在20世纪60年代就已经为人所知，但它是由Geoffrey Hinton及其合作者推广用于训练神经网络的。Hinton与Yoshua Bengio、Demis Hassabis和Yann LeCun一起，因在神经网络领域的杰出工作而获得了2022年阿斯图里亚斯公主技术科学奖。通过阅读优秀的《智能建筑师》，你可以了解反向传播的起源以及神经网络研究的历史，这本书中Martin Ford采访了Bengio、Hassabis、Hinton、LeCun以及其他许多人工智能领域的杰出人物[[40](ch030.xhtml#Xford2018architects)]。顺便说一句，Demis Hassabis在很大程度上是AlphaGo成功的原因之一，这是我们本章前面提到的强化学习的一个例子。

**小批量梯度下降** 当训练集很大时，计算损失函数的梯度——作为模型可优化参数的函数——可能会显著减慢训练速度。为了加快训练速度，您可以求助于 **小批量梯度下降** 这种技术。在这种优化方法中，训练集被分成固定大小的 **批量**。然后对每个这些批量计算损失函数的梯度，并使用这些结果来近似全局损失函数的梯度：也就是说，整个训练集上的损失函数。当我们使用这种技术时，我们需要注意我们使用的批量大小：太小，训练将非常不稳定；太大，训练将太慢。就像学习率一样，这都是一个寻找平衡的问题！然而，在某些情况下，速度至关重要，我们会采取极端措施，使用仅包含一个输入的批量。这被称为 **随机梯度下降**。另一方面，当批量包含数据集中的所有元素时，我们说我们在使用 **批量梯度** **下降**。

现在我们已经拥有了训练第一个模型所需的一切。我们有一个数据集，我们知道我们的模型应该是什么样子，我们选择了一个损失函数，并且知道如何优化它。所以，让我们让它工作起来！为此，我们将使用 TensorFlow 和 scikit-learn。

## 8.2.4 进入（Tensor）Flow

我们已经准备好了数据集，并且可以手动将其分割成训练集、验证集和测试集，但已经有了一些高质量的机器学习包，它们提供了帮助您完成这一任务的函数。其中之一是 `sklearn`，它实现了 `train_test_split` 函数。该函数将数据集分割成训练集和测试集（它不返回验证集，但我们可以通过其他方式解决这个问题）。它是通过将数据集和标签数组作为参数来实现的；此外，它还有一些可选参数，用于指定数据集是否应该打乱顺序以及数据集应该分割的比例。为了得到比例分别为 ![0.8](img/file1162.png "0.8")、![0.1](img/file1163.png "0.1") 和 ![0.1](img/file1163.png "0.1") 的训练集、验证集和测试集，我们只需要使用这个函数两次：一次用于获取一个训练集（大小为 ![0.8](img/file1162.png "0.8")）和一个测试集（大小为 ![0.2](img/file1091.png "0.2")），然后再次将测试集分成两半，得到一个大小为 ![0.1](img/file1163.png "0.1") 的验证集和一个测试集。

按照惯例，我们将数据集表示为变量 `x`，将标签表示为变量 `y`。这样，我们可以运行以下操作：

[PRE3]

注意，在下面的函数中，它按以下顺序返回四个数组：训练数据集的数据、测试数据集的数据、训练数据集的标签和测试数据集的标签。关于`train_test_split`函数的一个重要特点是它可以使用**分层**。如果我们还提供了`stratify` `=` `labels`和`stratify` `=` `y_test`的参数，这意味着在将数据分割成训练和测试样本时，它会保持原始数据中正负类的确切比例（或者至少尽可能接近）。这很重要，尤其是在我们处理不平衡数据集时，其中一个类别比另一个类别多得多。如果我们不小心，我们可能会得到一个少数类几乎不存在的数据集。

现在数据已经准备得完美无缺，是我们关注模型的时候了。对于我们的问题，我们将使用具有以下组件的神经网络：

+   一个包含两个输入的输入层

+   三个中间层（也称为**隐藏层**）使用ELU激活函数，并且分别有![8](img/file506.png "8")、![16](img/file619.png "16")和![8](img/file506.png "8")个神经元

+   一个输出层，包含一个使用sigmoid激活函数的单个神经元

让我们现在尝试稍微消化一下这个规范。由于问题的性质，我们知道我们的模型需要两个输入和一个输出，因此输入层和输出层的大小。更重要的是，我们希望输出在![0](img/file12.png "0")和![1](img/file13.png "1")之间归一化，所以在输出层使用sigmoid激活函数是有意义的。现在，我们需要找到一种方法，从第一层的![2](img/file302.png "2")个神经元到输出层的![1](img/file13.png "1")个神经元。我们可以使用![2](img/file302.png "2")或![1](img/file13.png "1")个隐藏层……但这不会产生一个非常强大的神经网络。因此，我们逐步扩大了神经网络的大小：首先从![2](img/file302.png "2")增加到![8](img/file506.png "8")，然后从![8](img/file506.png "8")增加到![16](img/file619.png "16")，然后从![16](img/file619.png "16")减少到![8](img/file506.png "8")，最终达到包含1个神经元的输出层。

我们如何在TensorFlow中定义这样的模型呢？嗯，在完成必要的导入和设置种子（记住，如果想要结果可复现，这是一个重要的步骤！）之后，只需要定义一个被称为**Keras** **顺序模型**的内容。

代码相当直观：

[PRE4]

正是这样，我们可以创建我们的模型，并将其存储为`Sequential`类的一个对象。

要了解更多…

一旦你定义了一个 Keras `model`，比如我们刚刚考虑的顺序模型，你可以通过运行指令 `print(model.summary())` 来打印它的可视摘要。这个摘要列出了模型的全部层及其形状，并显示了所有模型参数的数量。

在我们能够训练这个模型之前，我们需要**编译**它，将其与一个优化算法和损失函数关联起来。这是通过调用 `compile` 方法并传递 `optimizer` 和 `loss` 参数来完成的。在我们的例子中，我们希望使用 Adam 优化器（仅使用其默认参数）和二元交叉熵损失函数。因此，我们可以按如下方式编译我们的模型：

[PRE5]

当我们实例化 Adam 优化器而不提供任何参数时，默认情况下，学习率被设置为 ![10^{- 3}](img/file1164.png "10^{- 3}")。我们可以通过为可选参数 `learning_rate` 设置一个值来改变这个值——我们经常会这样做！

## 8.2.5 训练模型

现在我们已经准备好训练我们的模型了。这将通过调用 `fit` 方法来完成。但在我们这样做之前，让我们详细探讨一下我们必须传递给这个方法的最重要参数：

+   `fit` 函数接受的第一个参数是数据集 `x`。它应该是一个包含需要传递给模型以进行训练的输入的数组。在我们的例子中，那将是 `x_tr`。

+   我们可以发送的第二个参数是标签数组 `y`。当然，`x` 和 `y` 的维度需要匹配。在我们的例子中，我们将 `y` 设置为 `y_tr`。

+   如果你使用的是依赖于梯度下降的优化器，你可能想使用小批量梯度下降。为此，你可以给 `batch_size` 参数提供一个整数值，默认值为 ![32](img/file771.png "32")（因此，默认情况下使用小批量梯度下降）。如果你不想使用小批量梯度下降，你应该将 `batch_size` 设置为 `None`；这就是我们将要做的。

+   当我们讨论梯度下降时，我们看到了这些梯度下降算法是如何**迭代**的：它们通过计算一系列点来工作，这些点在原则上应该收敛到一个（局部）最小值。但这引发了一个问题：算法应该进行多少次优化周期——序列中应该计算多少个这样的点。你可以固定你希望优化算法执行的步数，也称为**周期**，这是通过为 `epochs` 参数设置一个值来完成的，默认值为 ![1](img/file13.png "1")。在我们的例子中，我们将使用 ![8](img/file506.png "8") 个周期。

+   如果我们想使用一些验证数据，正如我们的情况一样，我们可以通过 `validation_data` 参数传递它。这个参数的值应该是一个元组，其中第一个条目是验证数据集，第二个条目是对应的标签。因此，在我们的例子中，我们将 `validation_data` 设置为 `(``x_val``,` `y_val` `)`。

+   你可能已经注意到，提取训练、验证和测试数据集的整个过程可能有些繁琐。好吧，结果是TensorFlow可以在这里提供帮助。原则上，我们只需给TensorFlow提供一个包含训练和验证数据的数据集，并告诉它在`validation_split`参数中应该按什么比例分割。这个值必须是一个介于![0](img/file12.png "0")和![1](img/file13.png "1")之间的浮点数，表示用于验证的训练数据集的比例。

    通过这样做，我们可以节省一个“split”，但我们仍然需要自己提取一个测试数据集。

要了解更多...

我们只涵盖了TensorFlow提供的一些可能性——那些我们将最常使用的。如果你对我们迄今为止所看到的内容感到足够舒适，并想深入探索TensorFlow，你应该查看文档([https://www.tensorflow.org/api_docs/python/tf](https://www.tensorflow.org/api_docs/python/tf))。

我们接下来训练模型的方式将是以下：

[PRE6]

然后，在交互式壳中执行此指令，我们将得到以下输出：

[PRE7]

当看到这个时，我们首先应该做的事情是对比训练损失和验证损失——只是为了避免过拟合！在我们的情况下，我们看到这两个足够接近，并且在训练过程中遵循了类似的下降趋势。这确实是一个好兆头！

你可能已经注意到，我们将`fit`方法的输出保存在我们称之为`history`的对象中，TensorFlow将在其中存储有关训练的信息。例如，每个epoch结束时的训练和验证损失被记录在一个我们可以通过`history``.``history`访问的字典中。

练习8.5

在单个图表上绘制训练和验证损失随epoch演变的趋势，依赖于`history`对象中包含的信息。

在这种情况下，我们手动设置了epoch的数量为![8](img/file506.png "8")，但这并不总是最佳策略。理想情况下，我们希望设置一个合理的最大epoch数量，但我们希望训练一旦损失不再改善就停止。这被称为**早期停止**，并且可以在TensorFlow中轻松使用。

为了在TensorFlow中使用早期停止，我们首先需要创建一个`EarlyStopping`对象，在其中我们指定我们希望早期停止如何行为。假设我们想训练我们的模型，直到连续三个epoch后，验证损失在每个epoch后没有下降超过![0.001](img/file1165.png "0.001")。为此，我们必须调用以下对象：

[PRE8]

然后，在调用`fit`方法时，我们只需传递可选参数`callbacks` `=` `[``early_stp``]`。就这么简单！

在任何情况下，我们现在已经训练了我们的模型。如果我们想让我们的模型处理任何输入，我们可以使用`predict`方法，传递一个包含任意数量有效输入的数组。例如，在我们的情况下，如果我们想得到模型在测试数据集上的输出，我们可以检索`model``.``predict``(``x_test```)。然而，这将给我们模型返回的连续值（范围从![0](img/file12.png "0")到![1](img/file13.png "1")），而不是标签！为了得到离散标签 (![0](img/file12.png "0") 或 ![1](img/file13.png "1"))，我们需要设置一个阈值。自然地，我们会将其设置为![0.5](img/file1166.png "0.5")。因此，如果我们想得到模型会预测的标签，我们必须运行以下代码：

[PRE9]

当然，现在我们必须决定这次训练是否成功，因此我们应该评估我们的模型在测试数据集上的性能。为了做到这一点，我们可能简单地计算模型在测试数据集上的**准确率**，即我们可能计算模型正确分类的测试数据集输入的比例。

为了做到这一点，我们可以使用来自`sklearn``.``metrics`的`accuracy_score`函数：

[PRE10]

在我们的情况下，我们得到了![89.2\%](img/file1167.png "89.2\%")的准确率。这似乎是一个相当不错的值，但我们应该始终在问题的背景下考虑准确率值。对于某些任务，![89.2\%](img/file1167.png "89.2\%")确实可以是非常好的，但对于其他任务，它可能只是令人失望的。想象一下，例如，你有一个问题，其中![99\%](img/file1168.png "99\%")的例子属于一个类别。那么，获得至少![99\%](img/file1168.png "99\%")的准确率是微不足道的！你只需要将所有输入分类为多数类别即可。在接下来的几页中，我们将介绍工具来考虑这种情况，并更好地量化分类性能。

练习 8.6

在以下条件下重新训练模型，并计算所得模型的准确率：

+   将学习率降低到![10^{- 6}](img/file1169.png "10^{- 6}")

+   将学习率降低到![10^{- 6}](img/file1169.png "10^{- 6}")并增加迭代次数到![1,000](img/file1170.png "1,000")

+   将训练数据集的大小减少到![20](img/file588.png "20")

在哪些情况下所得模型的准确率较低？为什么？

在这些场景中是否发生了过拟合？你如何识别它？

到目前为止，我们只是通过设置![0.5](img/file1166.png "0.5")的阈值来衡量模型正确分类的元素比例，从而评估了模型的准确率。然而，二分类器的性能还有其他指标。我们将在下一小节中研究它们！

## 8.2.6 二分类器性能

在任何二分类器中，任何输出都可以属于以下表格中描述的四个类别之一：

|  | 被分类为阳性 | 被分类为阴性 |
| --- | --- | --- |
| 实际正类别 | 真正例 | 假负例 |
| 实际负类别 | 假正例 | 真负例 |

简写TP、FN、FP和TN也用来表示分类器在给定数据集上产生的真正例、假负例、假正例和真负例（分别）的数量。这些数量被非常频繁地使用。事实上，评估分类器性能的一种常见方法是通过查看其**混淆矩阵**（通常是测试数据集上的），这实际上不过是以下矩阵

| ![矩阵 \begin{pmatrix} \text{TP} & \text{FN} \\ \text{FP} & \text{TN} \\ \end{pmatrix}.](img/file1171.png "\begin{pmatrix} \text{TP} & \text{FN} \\ \text{FP} & \text{TN} \\ \end{pmatrix}.") |
| --- |

要开始，我们现在可以计算在测试数据集上训练的二分类器的混淆矩阵。为此，我们可以使用来自`sklearn.metrics`的`confusion_matrix`函数，该函数需要两个参数：预测标签的数组以及真实标签的数组：

[PRE11]

执行这段代码后，我们得到了以下混淆矩阵：

| ![矩阵 \begin{pmatrix} {24} & {20} \\ 7 & {199} \\ \end{pmatrix}.](img/file1172.png "\begin{pmatrix} {24} & {20} \\ 7 & {199} \\ \end{pmatrix}.") |
| --- |

这个矩阵显示，与真负例的数量相比，假正例非常少，但假负例的数量几乎与真正例一样多。这意味着我们的分类器在识别负类别方面做得非常好，但在识别正类别方面并不那么出色。稍后，我们将讨论如何更精确地量化这一点。

要了解更多...

虽然我们只关注二分类器，但混淆矩阵也可以用于有![n](img/file244.png "n")个类别的分类问题。它们有![n](img/file244.png "n")行和![n](img/file244.png "n")列，行![k](img/file317.png "k")列![l](img/file514.png "l")的条目表示实际上属于类别![k](img/file317.png "k")但被系统标记为类别![l](img/file514.png "l")的元素数量。

此外，如果你将其中一个![n](img/file244.png "n")类别定义为正类别，并将其余类别视为负类别，你可以为该特定类别获得TP、FP、TN和FN。

混淆矩阵非常有信息量，其中的数量可以帮助我们定义二分类器性能的几个指标。例如，通常的准确率指标可以定义为

| ![准确率 = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}.](img/file1173.png "\text{Acc} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}.") |
| --- |

其他有趣的指标是**阳性预测值**和**灵敏度**，它们分别定义为

| ![P = \frac{\text{TP}}{\text{TP} + \text{FP}},\qquad S = \frac{\text{TP}}{\text{TP} + \text{FN}}.](img/file1174.png "P = \frac{\text{TP}}{\text{TP} + \text{FP}},\qquad S = \frac{\text{TP}}{\text{TP} + \text{FN}}.") |
| --- |

正预测值也被称为分类器的**精确度**，而灵敏度也被称为**召回率**。

在 ![P](img/file1.png "P") 和 ![S](img/file73.png "S") 之间存在权衡。获得完美的召回率很简单：你只需将每个输入分类为正类即可。但这样，你的精确度会很低。同样，获得非常高的精确度也很容易：只有在你非常确定一个例子是正类时才将其分类为正类。但这样召回率会非常低。

因此，一个有趣的指标是 ![F_{1}](img/file1175.png "F_{1}") 分数，定义为 ![P](img/file1.png "P") 和 ![S](img/file73.png "S") 的调和平均：

| ![F_{1} = \frac{2}{\frac{1}{P} + \frac{1}{S}} = \frac{2PS}{P + S}.](img/file1176.png "F_{1} = \frac{2}{\frac{1}{P} + \frac{1}{S}} = \frac{2PS}{P + S}.") |
| --- |

很容易看出这个分数可以从 ![0](img/file12.png "0")（最坏可能的分类器的分数）到 ![1](img/file13.png "1")（完美分类器的分数）变化。此外，一个高的 ![F_{1}](img/file1175.png "F_{1}") 分数意味着我们既没有偏向召回率，也没有偏向精确度。

如果你具有数学背景，你可能已经意识到我们的 ![F_{1}](img/file1175.png "F_{1}") 表达式实际上在 ![P = S = 0](img/file1177.png "P = S = 0") 时是未定义的，但我们可以通过连续性简单地扩展它，使其在该处取值 ![F_{1} = 0](img/file1178.png "F_{1} = 0")。

为了计算这些指标，我们可以使用 `sklearn.metrics` 中的 `classification_report` 函数。在我们的案例中，我们可以运行以下代码：

[PRE12]

这会产生以下输出：

[PRE13]

在这个表格中，我们可以看到我们提到的所有指标。你可以看到，对于 ![0](img/file12.png "0") 是正类的情况以及当 ![1](img/file13.png "1") 是正类的情况（在我们的案例中，我们认为 ![0](img/file12.png "0") 是正类，所以我们查看第一行）。顺便说一下，一个类的**支持度**表示在数据集中可以找到的该类元素的数量。此外，每个指标的**宏平均**就是将每个类作为正类获得的指标值的简单平均。加权平均类似于宏平均，但根据数据集中每个类的元素比例进行加权。

假设我们有一个二元分类器，它在通过阈值分配标签之前返回一个介于![0](img/file12.png "0")和![1](img/file13.png "1")之间的连续输出。如我们之前所见，我们可以通过使用一系列指标来衡量我们分类器的性能。但如果我们想更全面地了解我们的分类器对于任何阈值可能的表现，我们可以采取另一种方法。

使用数据集上的混淆矩阵的条目，我们可以定义**真正例率**为比例

| ![TPR = TP / (TP + FN),](img/file1179.png "TPR = TP / (TP + FN),") |
| --- |

即，实际被分类为正类的正类样本的比例。另一方面，我们可以类似地定义**假正例率**为商

| ![FPR = FP / (FP + TN),](img/file1180.png "FPR = FP / (FP + TN).") |
| --- |

**接收者操作特征曲线**或**ROC曲线**是针对返回连续值的分类器，通过在给定数据集上绘制，对于每个可能的阈值选择，一个点由相应的TPR给出![Y](img/file11.png "Y")坐标，以及![X](img/file9.png "X")坐标对应于该阈值下的FPR。随着阈值从![0](img/file12.png "0")增加到![1](img/file13.png "1")，这将产生一系列有限点。曲线是通过直线连接这些点得到的。请注意，我们通过不同水平的“需求”来评估分类器对输入进行正类分类的性能。当阈值较高时，将某物分类为正类会更困难；FPR会很低——很好！——但TPR可能也会很低。另一方面，对于较低的阈值，输入被分类为正类的可能性会更高：TPR会很高——太好了！——但这也可能导致假阳性增加。

听起来熟悉吗？这是我们之前在定义精确率和召回率时讨论过的相同类型的权衡。区别在于，在这种情况下，我们考虑了分类器对于每个可能的阈值选择的行为，从而给出了一个全面的评估。绘制ROC曲线可以非常有信息量，因为它还可以帮助我们选择更适合我们问题的分类阈值。例如，如果你试图检测某个患者是否患有某种严重的疾病，可能值得以非常低的假阴性率为代价，接受一些假阳性——可能需要接受额外医疗测试的人。ROC曲线可以通过识别TPR高且FPR可接受的点来帮助你做到这一点。

为了绘制ROC曲线，我们可以使用来自`sklearn.metrics`的`roc_curve`函数。它将返回曲线点的![X](img/file9.png "X")和![Y](img/file11.png "Y")坐标。在我们的特定情况下，我们可能运行以下代码段：

[PRE14]

注意我们如何省略了`roc_curve`函数的部分输出；特别是我们忽略的返回对象产生了一个包含分类器准确率变化的阈值数组的数组（你可以参考[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)上的文档以获取更多信息）。我们得到的输出可以在*图* [*8.5*](#Figure8.5)中找到。注意我们手动在![(0,0)](img/file613.png "(0,0)")和![(1,1)](img/file1181.png "(1,1)")之间画了一条虚线。这表示由随机分类器生成的ROC曲线，该分类器将输入分配给一个类别的概率与该类别的规模成比例，并且这是一个重要的视觉辅助工具。这是因为任何高于该虚线的曲线都是具有一些实际分类能力的分类器的ROC曲线。

![图8.5：我们训练的分类器的ROC曲线（实线）](img/file1182.png)

**图8.5**：我们训练的分类器的ROC曲线（实线）。

在这个ROC曲线中有一些有趣的特征，让我们稍微讨论一下。首先，注意点![(0,0)](img/file613.png "(0,0)")和![(1,1)](img/file1181.png "(1,1)")总是属于任何分类器的ROC曲线，因为它们分别对应于最高和最低的阈值。在前一种情况下，没有输入被分配给正类，因此我们既没有TPs也没有FPs。在后一种情况下，所有输入都被分配给正类，因此我们既没有FNs也没有TNs。

此外，我们可以在我们的图表中观察到，从 ![(0,0)](img/file613.png "(0,0)"), ROC曲线开始水平移动，增加FPR而不增加TPR。这意味着测试数据集中有一些例子，模型非常自信地将它们分类为正类，但实际上它们是负类。这当然是不理想的。我们希望ROC曲线向上——增加TPR——而不向右移动。这正是第一次中断之后发生的事情。我们观察到一段很长的TPR增加而没有FPR增加的段。如果我们需要我们的分类器具有高精度，我们可以选择达到大约 ![0.71](img/file1183.png "0.71") 的TPR和只有大约 ![0.02](img/file1184.png "0.02") 的FPR的阈值。另一方面，如果我们需要高召回率，我们可以在曲线上选择TPR已经达到 ![1](img/file13.png "1") 而FPR大约为 ![0.5](img/file1166.png "0.5") 的点。对于更平衡的分类器，请注意，ROC曲线上有一个TPR大约为 ![0.91](img/file1185.png "0.91") 且FPR低于 ![0.21](img/file1186.png "0.21") 的点。

当然，理想的分类器应该有一个从 ![(0,0)](img/file613.png "(0,0)") 到 ![(1,0)](img/file1187.png "(1,0)") 的ROC曲线。这意味着存在一个阈值，所有正例都被分类为正类，而没有任何负例被分配到正类。这简直就是完美！从那里，ROC曲线将直接到达 ![(1,1)](img/file1181.png "(1,1)"): 我们已经找到了所有正例，所以TPR不能再增加，但通过降低阈值，我们最终会将FPR从 ![0](img/file12.png "0") 增加到 ![1](img/file13.png "1")。

显然，这种完美的ROC曲线只有在极其简单的分类问题中才能实现。然而，我们仍然可以通过计算**ROC曲线下的面积**，通常简称为**AUC**，来将我们的实际模型与理想分类器进行比较。对于完美的分类器，ROC曲线的面积等于1，因此我们可以认为，一个分类器的AUC越接近1，其整体性能就越好。同样，一个随机分类器的ROC曲线将是一条从 ![(0,0)](img/file613.png "(0,0)") 到 ![(1,1)](img/file1181.png "(1,1)") 的直线，因此其AUC为 ![0.5](img/file1166.png "0.5")。因此，AUC高于 ![0.5](img/file1166.png "0.5") 的分类器具有一些实际的分类能力，而不仅仅是随机猜测。

一旦有了定义ROC曲线的点的坐标，我们就可以很容易地使用`sklearn.metrics`中的`auc`函数来获取AUC分数。

[PRE15]

在我们的情况下，我们得到大约![0.9271](img/file1188.png "0.9271")的AUC分数。再次强调，这看起来是一个很好的值，但让我们再次强调，这一切都取决于问题的难度——而我们一直在考虑的问题并不特别困难。此外，请记住，AUC是一个全局性能指标，它考虑了分类器可能的所有阈值。最终，你需要承诺一个阈值值，如果你的特定阈值选择准确性、精确度和召回率不是那么好，那么高AUC可能并不意味太多。

那是很多信息！无论如何，对于大多数实际用途，你所需要知道的所有内容都总结在以下注意事项中。

重要注意事项

给定一个具有连续输出的二元分类器，我们可以在数据集上计算其接收者操作特征曲线（也称为ROC曲线）。该曲线下的面积越大，分类器的分类能力就越强。

我们将分类器ROC曲线下的面积称为其AUC（简称“曲线下面积”）：

+   AUC（曲线下面积）为![1](img/file13.png "1")对应于完美的分类器

+   AUC（曲线下面积）为![0.5](img/file1166.png "0.5")将匹配随机分类器的

+   AUC（曲线下面积）为![0](img/file12.png "0")对应于总是返回错误输出的分类器

到现在为止，我们应该对（经典）机器学习有一个相当的了解，你可能想知道“量子”部分从哪里开始？它现在开始了。

# 8.3 量子-经典模型

从广义上讲，量子机器学习指的是应用机器学习技术——只是在这个过程中涉及到量子计算。也许你会在你希望训练的模型的部分使用量子计算机。也许你希望使用某些量子过程生成数据。也许你使用量子计算机来处理量子生成数据。正如你可以想象的那样，量子机器学习的主题作为一个整体，足够广泛，可以容纳各种想法和应用。

为了尝试对其进行分类，我们可以遵循Schuld和Petruccione在他们的书中展示的有用分类[[106](ch030.xhtml#Xschuld)]，并根据所使用的数据和处理的设备的经典或量子性质，将量子机器学习分为四种不同的风味，如图*8.6*所示：

+   我们可以将量子机器学习的一部分视为所有受量子启发的经典机器学习技术；也就是说，所有从量子计算中汲取灵感的经典机器学习方法。在这种情况下，数据和计算机都是经典的，但在过程中涉及一些量子风味。这在图表中用CC表示。由于这种方法中没有实际使用量子计算机，我们不会研究这类方法。

+   此外，我们还可以考虑任何依赖量子数据的经典机器学习算法作为量子机器学习的一部分；就我们的目的而言，我们可以将其视为由量子过程生成的数据，或者将经典机器学习应用于量子计算。这是图表中的QC块。在这种方法中，机器学习是一个工具而不是目的，因此我们不会涉及这些技术。

+   我们在这本书中将要关注的机器学习类型是图表中CQ标签所代表的类型：依赖于经典数据并在模型或训练中使用量子计算的机器学习。

+   最后，还有一个非常有趣的QQ类别。这些技术在模型本身或训练过程中使用量子计算处理量子数据。请注意——与CQ量子机器学习相反——在这种情况下，量子数据不必来自测量：量子状态可以直接输入到量子模型中，例如。这是一个充满希望的区域（例如，参见黄等人最近发表的论文[54](ch030.xhtml#Xhuang2022quantum)]），但所需的技术仍然不成熟，因此我们不会详细讨论这种方法。

![图8.6：根据所使用的模型和数据性质分类的量子机器学习的四大类](img/file1189.jpg)

**图8.6**：根据所使用的模型和数据性质分类的量子机器学习的四大类

因此，我们的计划是专注于CQ量子机器学习：在经典数据上依赖量子计算的机器学习。现在，在这个类别中，仍然有相当广泛的可能性。我们可以在模型和优化过程中使用量子计算。已经有许多有趣的提议表明量子计算如何加速传统的机器学习模型，但通常这些方法不能用于我们当前的量子硬件。因此，我们不会在本书中讨论这些方法——但如果您想了解更多关于它们的信息，我们可以推荐Biamonte等人出色的论文[108](ch030.xhtml#Xbiamonte-qml)]。

相反，我们将全心全意地投入到研究可以在NISQ设备上运行的完全量子导向模型。这些模型将在经典数据上训练，并且通常我们将使用纯经典优化技术。

在接下来的章节中，我们将研究以下模型：

+   **量子支持向量机**。我们将很快探讨支持向量机是什么以及如何使用经典机器学习进行训练。我们还将看到它们的量子版本只是通用支持向量机的一个特例，其中我们使用量子计算机将数据映射到量子状态空间。

+   **量子神经网络**。接下来，我们将探讨一个纯量子模型：量子神经网络。这个模型完全在量子计算机上运行，其行为灵感来源于经典神经网络。

+   **混合网络**。在下一章中，我们将学习如何将量子神经网络与其他经典模型（最常见的是神经网络）相结合。我们将把这些模型称为混合网络。

+   **量子生成对抗网络**。最后，我们将研究生成对抗网络，并介绍这些模型组件如何被量子电路所取代。

正如本书的其余部分一样，我们的方法将非常实用和动手。如果您希望扩展您在量子机器学习方面的理论知识，您也可以查阅Maria Schuld和Francesco Petruccione合著的书籍[[106](ch030.xhtml#Xschuld)]。

# 摘要

在本章中，我们探讨了机器学习基础的一些基本概念和思想。我们不仅从理论角度探讨了它们，还看到了它们是如何付诸实践的。

我们已经了解了机器学习是什么，我们也讨论了一些最常用的方法来实现它。特别是，我们了解到许多机器学习问题可以通过在合适模型上的某些优化算法来最小化损失函数来简化。

我们还深入研究了一些经典神经网络，并使用行业标准机器学习框架（TensorFlow）对其进行训练。

最后，我们通过介绍量子机器学习是什么以及提前浏览本书本部分的其余章节来结束本章。***
