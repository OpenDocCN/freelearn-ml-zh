<html><head></head><body>
<div id="_idContainer066">
<h1 class="chapter-number" id="_idParaDest-121"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-122"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.2.1">Deep Learning and Convolutional Neural Networks</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.3.1">Deep learning</span></strong><span class="koboSpan" id="kobo.4.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.5.1">DL</span></strong><span class="koboSpan" id="kobo.6.1">) is a </span><strong class="bold"><span class="koboSpan" id="kobo.7.1">machine learning</span></strong><span class="koboSpan" id="kobo.8.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.9.1">ML</span></strong><span class="koboSpan" id="kobo.10.1">) technology</span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.11.1"> based on </span><a id="_idIndexMarker626"/><span class="koboSpan" id="kobo.12.1">multilayer </span><strong class="bold"><span class="koboSpan" id="kobo.13.1">artificial neural networks</span></strong><span class="koboSpan" id="kobo.14.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.15.1">ANNs</span></strong><span class="koboSpan" id="kobo.16.1">) that </span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.17.1">has allowed many applications to reach a high degree of accuracy. </span><strong class="bold"><span class="koboSpan" id="kobo.18.1">Deep NNs</span></strong><span class="koboSpan" id="kobo.19.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.20.1">DNNs</span></strong><span class="koboSpan" id="kobo.21.1">) are </span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.22.1">capable of modeling and have the ability to capture intricate connections between input and output information. </span><span class="koboSpan" id="kobo.22.2">Among the highly effective </span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.23.1">uses, </span><strong class="bold"><span class="koboSpan" id="kobo.24.1">computer vision</span></strong><span class="koboSpan" id="kobo.25.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.26.1">CV</span></strong><span class="koboSpan" id="kobo.27.1">) stands out, encompassing activities such as categorization, image regression, and the identification of objects. </span><span class="koboSpan" id="kobo.27.2">As an illustration, an advanced NN can produce a stratified portrayal of entities, wherein each entity is recognized by a collection of features taking the shape of visual basics, such as specific contours, directed lines, surface details, and repetitive designs. </span><strong class="bold"><span class="koboSpan" id="kobo.28.1">Convolutional</span></strong> <strong class="bold"><span class="koboSpan" id="kobo.29.1">networks</span></strong><span class="koboSpan" id="kobo.30.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.31.1">CNNs</span></strong><span class="koboSpan" id="kobo.32.1">) are </span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.33.1">characterized by convolutional layers, which use filters to analyze data in a local region and produce an activation map. </span><span class="koboSpan" id="kobo.33.2">These activation maps are then processed by pooling layers, which aggregate the low-resolution data to reduce the dimensionality of the representation and make processing more computationally efficient. </span><span class="koboSpan" id="kobo.33.3">The convolutional and pooling layers are then alternated several times until the image is represented by a low-resolution activation map. </span><span class="koboSpan" id="kobo.33.4">In this chapter, we will learn the basic concepts of DL and discover how to implement an algorithm based on CNNs in the </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">MATLAB environment.</span></span></p>
<p><span class="koboSpan" id="kobo.35.1">In this chapter, we’re going to cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.37.1">Understanding DL </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">basic concepts</span></span></li>
<li><span class="koboSpan" id="kobo.39.1">Exploring </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">DL models</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.41.1">Approaching </span></span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">CNNs</span></span></li>
<li><span class="koboSpan" id="kobo.43.1">Building a CNN </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">in MATLAB</span></span></li>
<li><span class="koboSpan" id="kobo.45.1">Exploring the </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">model’s results</span></span></li>
<li><span class="koboSpan" id="kobo.47.1">Discovering </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">DL architectures</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.49.1">As always, I thank the technical reviewers for their helpful advice on improving my chapter. </span><span class="koboSpan" id="kobo.49.2">I will try to apply them as they were proposed </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">to me.</span></span></p>
<h1 id="_idParaDest-123"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.51.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.52.1">In this chapter, we will introduce ML basic concepts. </span><span class="koboSpan" id="kobo.52.2">To understand these topics, a basic knowledge of algebra and mathematical modeling is needed. </span><span class="koboSpan" id="kobo.52.3">A working knowledge of the MATLAB environment is </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">also required.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">To work with the MATLAB code in this chapter, you need the following files (available on GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">at </span></span><a href="https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition"><span class="No-Break"><span class="koboSpan" id="kobo.56.1">https://github.com/PacktPublishing/MATLAB-for-Machine-Learning-second-edition</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.57.1">):</span></span></p>
<ul>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.58.1">CNNPistachioClassification.m</span></strong></span></li>
<li><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.59.1">PistachioShort.zip</span></strong></span></li>
</ul>
<h1 id="_idParaDest-124"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.60.1">Understanding DL basic concepts</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.61.1">DL</span></strong><span class="koboSpan" id="kobo.62.1"> is a branch of </span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.63.1">ML based on using algorithms to model high-level abstractions about data. </span><span class="koboSpan" id="kobo.63.2">This discipline is part of a range of approaches that aim to learn methods for representing data. </span><span class="koboSpan" id="kobo.63.3">For example, an observation such as an image can be described in different ways: as a vector of intensity values for each pixel, or more abstractly as a set of edges or regions that have shapes or significant features. </span><span class="koboSpan" id="kobo.63.4">Some of these possible representations may prove more effective than others in facilitating the process of training another </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">ML system.</span></span></p>
<p><span class="koboSpan" id="kobo.65.1">For automatically identifying and extracting relevant features from raw data, we can use automated feature extraction to eliminate the </span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.66.1">need for manual </span><strong class="bold"><span class="koboSpan" id="kobo.67.1">feature engineering</span></strong><span class="koboSpan" id="kobo.68.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.69.1">FE</span></strong><span class="koboSpan" id="kobo.70.1">). </span><span class="koboSpan" id="kobo.70.2">This process streamlines ML tasks and improves </span><span class="No-Break"><span class="koboSpan" id="kobo.71.1">model performance.</span></span></p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.72.1">Automated feature extraction</span></h2>
<p><span class="koboSpan" id="kobo.73.1">In this</span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.74.1"> context, one of the central aspects of DL is the development of learning algorithms that specialize in automatically extracting significant features from a dataset, which can then be used to train ML systems. </span><span class="koboSpan" id="kobo.74.2">This is a significant contribution, considering that without such techniques, these features would have to be manually generated and vetted prior to training. </span><span class="koboSpan" id="kobo.74.3">The basic concept of DL is to successively subject the input data to different levels of processing, the result of which is the emergence of features. </span><span class="koboSpan" id="kobo.74.4">Consider an image of a cat. </span><span class="koboSpan" id="kobo.74.5">Automated feature extraction can identify features such as the cat’s eyes, ears, </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">and whiskers.</span></span></p>
<p><span class="koboSpan" id="kobo.76.1">In the field of NNs, the concept of DL was introduced with the creation of so-called </span><strong class="bold"><span class="koboSpan" id="kobo.77.1">DNNs</span></strong><span class="koboSpan" id="kobo.78.1">. </span><span class="koboSpan" id="kobo.78.2">The</span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.79.1"> operating principle is like that of traditional NNs but with one obvious difference: the significant increase in the number of intermediate layers of hidden neurons. </span><span class="koboSpan" id="kobo.79.2">As with classical NNs, DNNs are capable of modeling complex relationships between input and </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">output data.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">One of the most successful areas of application is CV, which includes tasks such as classification, image regression, and object detection. </span><span class="koboSpan" id="kobo.81.2">In the latter task, a DNN can build a layered representation of objects, in which each object is identified by a set of features that appear in the form of primitive visual elements, such as specific edges, oriented lines, textures, and recurring patterns. </span><span class="koboSpan" id="kobo.81.3">This modeling ability is rooted in a large number of hidden layers </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">of neurons.</span></span></p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.83.1">Training a DNN</span></h2>
<p><span class="koboSpan" id="kobo.84.1">As far as</span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.85.1"> the training phase is concerned, it is still possible to use the </span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.86.1">well-established backpropagation algorithm. </span><span class="koboSpan" id="kobo.86.2">As with traditional NNs, DNNs can suffer from the age-old problem of overfitting. </span><span class="koboSpan" id="kobo.86.3">To mitigate this </span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.87.1">situation, </span><strong class="bold"><span class="koboSpan" id="kobo.88.1">regularization techniques</span></strong><span class="koboSpan" id="kobo.89.1"> are usually employed, which intervene in the optimization process during the training phase. </span><span class="koboSpan" id="kobo.89.2">Among the most frequently employed methods are </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.91.1">L2 regularization</span></strong><span class="koboSpan" id="kobo.92.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.93.1">weight decay</span></strong><span class="koboSpan" id="kobo.94.1">), which influences the optimizer’s operation </span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.95.1">by adding the </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">L2 norm</span></strong><span class="koboSpan" id="kobo.97.1"> of </span><a id="_idIndexMarker639"/><span class="koboSpan" id="kobo.98.1">the</span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.99.1"> network weights, multiplied by a specific constant, to the loss function. </span><span class="koboSpan" id="kobo.99.2">The L2 norm, also known as the Euclidean norm, is a mathematical function that measures the length of a vector. </span><span class="koboSpan" id="kobo.99.3">It is defined as the square root of the sum of the squares of the vector’s components. </span><span class="koboSpan" id="kobo.99.4">The L2 norm is often used</span><a id="_idIndexMarker641"/><span class="koboSpan" id="kobo.100.1"> in ML and statistics to measure the distance between </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">two vectors.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.102.1">The formula for the L2 norm of a vector </span><em class="italic"><span class="koboSpan" id="kobo.103.1">x</span></em><span class="koboSpan" id="kobo.104.1"> is </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">as follows:</span></span></p><p class="list-inset"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.106.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.107.1">|</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.108.1">x</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.109.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.110.1">|</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.111.1">2</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.112.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.113.1">s</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.114.1">q</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.115.1">r</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.116.1">t</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.117.1">(</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.118.1">∑</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.119.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.120.1">x</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.121.1">_</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.122.1">i</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.123.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.124.1">^</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.125.1">2</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.126.1">)</span></span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.127.1">Please refer here </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">as follows:</span></span></p><ul><li><em class="italic"><span class="koboSpan" id="kobo.129.1">||x||_2</span></em><span class="koboSpan" id="kobo.130.1"> is the L2 norm </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">of </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.132.1">x</span></em></span></li><li><em class="italic"><span class="koboSpan" id="kobo.133.1">x_i</span></em><span class="koboSpan" id="kobo.134.1"> is the i-th component </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">of </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.136.1">x</span></em></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.137.1">L1 regularization</span></strong><span class="koboSpan" id="kobo.138.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.139.1">sparsity</span></strong><span class="koboSpan" id="kobo.140.1">), functioning</span><a id="_idIndexMarker642"/><span class="koboSpan" id="kobo.141.1"> similarly</span><a id="_idIndexMarker643"/><span class="koboSpan" id="kobo.142.1"> to the former but using the </span><strong class="bold"><span class="koboSpan" id="kobo.143.1">L1 norm</span></strong><span class="koboSpan" id="kobo.144.1">. </span><span class="koboSpan" id="kobo.144.2">The L1 norm </span><a id="_idIndexMarker644"/><span class="koboSpan" id="kobo.145.1">is often used in ML and statistics to measure the distance between </span><a id="_idIndexMarker645"/><span class="koboSpan" id="kobo.146.1">two vectors. </span><span class="koboSpan" id="kobo.146.2">It is also known as the Manhattan norm or the Taxicab norm because it corresponds to the distance traveled by a taxicab moving along city streets. </span><span class="koboSpan" id="kobo.146.3">The formula for the L1 norm of a vector </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.147.1">x</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.148.1"> is:</span></span><p class="list-inset"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.149.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.150.1">|</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.151.1">x</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.152.1">|</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.153.1">|</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.154.1">1</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.155.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.156.1">∑</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.157.1">|</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.158.1">x</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.159.1">_</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.160.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.161.1">|</span></span></span></p><p class="list-inset"><span class="No-Break"><span class="koboSpan" id="kobo.162.1">Here:</span></span></p><ul><li><em class="italic"><span class="koboSpan" id="kobo.163.1">||x||_1</span></em><span class="koboSpan" id="kobo.164.1"> is the L1 norm </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">of </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.166.1">x</span></em></span></li><li><em class="italic"><span class="koboSpan" id="kobo.167.1">x_i</span></em><span class="koboSpan" id="kobo.168.1"> is the i-th component </span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">of </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.170.1">x</span></em></span></li></ul></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.171.1">Dropout</span></strong><span class="koboSpan" id="kobo.172.1">, where, during</span><a id="_idIndexMarker646"/><span class="koboSpan" id="kobo.173.1"> each training step, a set </span><a id="_idIndexMarker647"/><span class="koboSpan" id="kobo.174.1">number of randomly chosen neurons within the hidden layers are turned off, preventing their outputs from affecting </span><span class="No-Break"><span class="koboSpan" id="kobo.175.1">subsequent neurons.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.176.1">All these techniques serve to lessen the interdependencies between the network and the training data samples, effectively curbing overfitting. </span><span class="koboSpan" id="kobo.176.2">Although backpropagation training provides a solid solution due to its simplicity and tendency to converge toward better local minima compared to other methods, it can pose considerable challenges in deep networks concerning actual computation. </span><span class="koboSpan" id="kobo.176.3">Indeed, an </span><a id="_idIndexMarker648"/><span class="koboSpan" id="kobo.177.1">array of </span><strong class="bold"><span class="koboSpan" id="kobo.178.1">hyperparameters</span></strong><span class="koboSpan" id="kobo.179.1"> must be considered in DNNs, encompassing factors such as dimensions (in terms of layer count and units per layer), learning rate, initial weights, and the optimization of these parameters—a process that can become unwieldy in terms of time and </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">computational resources.</span></span></p>
<p><span class="koboSpan" id="kobo.181.1">Various solutions </span><a id="_idIndexMarker649"/><span class="koboSpan" id="kobo.182.1">have been suggested in this context, including the utilization of mini-batches of data to expedite training. </span><span class="koboSpan" id="kobo.182.2">However, a substantial breakthrough has been the advancement of GPUs with increasingly powerful computational capabilities in recent years. </span><span class="koboSpan" id="kobo.182.3">In network operations, the primary computational tasks involve matrix and vector operations, which align well with parallel implementation on </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">GPU hardware.</span></span></p>
<p><span class="koboSpan" id="kobo.184.1">Another issue stemming from gradient descent-based techniques, accentuated by the intricate structure of deep networks, is </span><a id="_idIndexMarker650"/><span class="koboSpan" id="kobo.185.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.186.1">vanishing gradient problem</span></strong><span class="koboSpan" id="kobo.187.1">. </span><span class="koboSpan" id="kobo.187.2">This challenge originates from gradient computation within the chain and the network’s substantial number of layers. </span><span class="koboSpan" id="kobo.187.3">Typically used activation functions tend to generate gradients with minute values, typically within the range of [-1, 1]. </span><span class="koboSpan" id="kobo.187.4">Due to the chain computation, this results in the multiplication of many small values when calculating the gradient in the initial layers of an </span><em class="italic"><span class="koboSpan" id="kobo.188.1">n</span></em><span class="koboSpan" id="kobo.189.1">-level network. </span><span class="koboSpan" id="kobo.189.2">Consequently, the gradient decreases exponentially with </span><em class="italic"><span class="koboSpan" id="kobo.190.1">n</span></em><span class="koboSpan" id="kobo.191.1">, causing the initial layers to learn at a </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">sluggish pace.</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">Another solution provides the preliminary training in an unsupervised way of one level of the network at a time, to then carry out a final complete training by means of backpropagation. </span><span class="koboSpan" id="kobo.193.2">Another way around the problem, encouraged by the development of GPUs in recent times, is the use of faster hardware to counteract what is the main symptom of the problem—namely, the slowness of the training process. </span><span class="koboSpan" id="kobo.193.3">Another point against DNNs, in the </span><a id="_idIndexMarker651"/><span class="koboSpan" id="kobo.194.1">case of </span><strong class="bold"><span class="koboSpan" id="kobo.195.1">supervised learning</span></strong><span class="koboSpan" id="kobo.196.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.197.1">SL</span></strong><span class="koboSpan" id="kobo.198.1">), is represented by the very large amount of sample data (including the desired output) necessary for the network to reach the required results at the end of the training. </span><span class="koboSpan" id="kobo.198.2">This represents a significant obstacle since, for certain tasks, the production of the expected outputs for each example is an operation that can take a very </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">long time.</span></span></p>
<p><span class="koboSpan" id="kobo.200.1">After introducing DL, let’s now see the different types of </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">DL available.</span></span></p>
<h1 id="_idParaDest-127"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.202.1">Exploring DL models</span></h1>
<p><span class="koboSpan" id="kobo.203.1">Various types</span><a id="_idIndexMarker652"/><span class="koboSpan" id="kobo.204.1"> of DL architectures and techniques have been developed to tackle different tasks and challenges. </span><span class="koboSpan" id="kobo.204.2">Here are </span><span class="No-Break"><span class="koboSpan" id="kobo.205.1">some examples:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.206.1">CNNs</span></strong><span class="koboSpan" id="kobo.207.1">: Mainly </span><a id="_idIndexMarker653"/><span class="koboSpan" id="kobo.208.1">used for image and video analysis, CNNs are designed</span><a id="_idIndexMarker654"/><span class="koboSpan" id="kobo.209.1"> to learn spatial hierarchies of features automatically and adaptively from input data. </span><span class="koboSpan" id="kobo.209.2">They have been highly successful in tasks such as image classification, object detection, and </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">image segmentation.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.211.1">Recurrent NNs</span></strong><span class="koboSpan" id="kobo.212.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.213.1">RNNs</span></strong><span class="koboSpan" id="kobo.214.1">): RNNs are </span><a id="_idIndexMarker655"/><span class="koboSpan" id="kobo.215.1">well suited for tasks involving sequences, such as </span><strong class="bold"><span class="koboSpan" id="kobo.216.1">natural language processing</span></strong><span class="koboSpan" id="kobo.217.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.218.1">NLP</span></strong><span class="koboSpan" id="kobo.219.1">) and </span><a id="_idIndexMarker656"/><span class="koboSpan" id="kobo.220.1">speech recognition. </span><span class="koboSpan" id="kobo.220.2">They have an internal</span><a id="_idIndexMarker657"/><span class="koboSpan" id="kobo.221.1"> memory that allows them to maintain information about previous inputs, making them effective for handling </span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">sequential data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.223.1">Long short-term memory</span></strong><span class="koboSpan" id="kobo.224.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.225.1">LSTM</span></strong><span class="koboSpan" id="kobo.226.1">) </span><strong class="bold"><span class="koboSpan" id="kobo.227.1">networks</span></strong><span class="koboSpan" id="kobo.228.1">: A type of RNN, LSTMs are designed to </span><a id="_idIndexMarker658"/><span class="koboSpan" id="kobo.229.1">overcome the</span><a id="_idIndexMarker659"/><span class="koboSpan" id="kobo.230.1"> vanishing gradient problem in training deep networks. </span><span class="koboSpan" id="kobo.230.2">They are particularly useful for capturing long-range dependencies in sequential data, making them popular for tasks such as language modeling and </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">machine translation.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.232.1">Generative adversarial networks</span></strong><span class="koboSpan" id="kobo.233.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.234.1">GANs</span></strong><span class="koboSpan" id="kobo.235.1">): GANs consist of two NNs—the generator and</span><a id="_idIndexMarker660"/><span class="koboSpan" id="kobo.236.1"> the discriminator—engaged</span><a id="_idIndexMarker661"/><span class="koboSpan" id="kobo.237.1"> in a game-like setting. </span><span class="koboSpan" id="kobo.237.2">GANs are used for generating new data samples that are like a given dataset. </span><span class="koboSpan" id="kobo.237.3">They have been used for image generation, style transfer, and </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">data augmentation.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.239.1">Autoencoders</span></strong><span class="koboSpan" id="kobo.240.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.241.1">AEs</span></strong><span class="koboSpan" id="kobo.242.1">): AEs </span><a id="_idIndexMarker662"/><span class="koboSpan" id="kobo.243.1">are used for </span><strong class="bold"><span class="koboSpan" id="kobo.244.1">unsupervised learning</span></strong><span class="koboSpan" id="kobo.245.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.246.1">UL</span></strong><span class="koboSpan" id="kobo.247.1">) and data compression. </span><span class="koboSpan" id="kobo.247.2">They consist of an encoder that</span><a id="_idIndexMarker663"/><span class="koboSpan" id="kobo.248.1"> maps the input data to a latent space and a </span><a id="_idIndexMarker664"/><span class="koboSpan" id="kobo.249.1">decoder that reconstructs the input from the latent representation. </span><span class="koboSpan" id="kobo.249.2">AEs find applications in dimensionality reduction, denoising, and </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">anomaly detection.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.251.1">Transformer networks</span></strong><span class="koboSpan" id="kobo.252.1">: Transformers</span><a id="_idIndexMarker665"/><span class="koboSpan" id="kobo.253.1"> have gained</span><a id="_idIndexMarker666"/><span class="koboSpan" id="kobo.254.1"> popularity in NLP tasks. </span><span class="koboSpan" id="kobo.254.2">They utilize self-attention mechanisms to process input data in parallel, making them efficient for handling long-range dependencies in</span><a id="_idIndexMarker667"/><span class="koboSpan" id="kobo.255.1"> sequences. </span><span class="koboSpan" id="kobo.255.2">The </span><strong class="bold"><span class="koboSpan" id="kobo.256.1">Bidirectional Encoder Representations from Transformers</span></strong><span class="koboSpan" id="kobo.257.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.258.1">BERT</span></strong><span class="koboSpan" id="kobo.259.1">) model is a </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">prominent example.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.261.1">Capsule networks</span></strong><span class="koboSpan" id="kobo.262.1">: Capsule networks</span><a id="_idIndexMarker668"/><span class="koboSpan" id="kobo.263.1"> aim to improve the</span><a id="_idIndexMarker669"/><span class="koboSpan" id="kobo.264.1"> robustness of NNs to variations in object poses and viewpoints. </span><span class="koboSpan" id="kobo.264.2">They use </span><em class="italic"><span class="koboSpan" id="kobo.265.1">capsules</span></em><span class="koboSpan" id="kobo.266.1"> to represent different aspects of an object, allowing them to capture hierarchical relationships </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">between features.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.268.1">Neural Turing machines</span></strong><span class="koboSpan" id="kobo.269.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.270.1">NTMs</span></strong><span class="koboSpan" id="kobo.271.1">): These architectures combine NNs with external </span><a id="_idIndexMarker670"/><span class="koboSpan" id="kobo.272.1">memory, enabling them to </span><a id="_idIndexMarker671"/><span class="koboSpan" id="kobo.273.1">perform algorithmic tasks. </span><span class="koboSpan" id="kobo.273.2">They are designed to learn algorithmic procedures and have been used for tasks such as sorting and </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">associative recall.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.275.1">Graph NNs</span></strong><span class="koboSpan" id="kobo.276.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.277.1">GNNs</span></strong><span class="koboSpan" id="kobo.278.1">): GNNs </span><a id="_idIndexMarker672"/><span class="koboSpan" id="kobo.279.1">operate on graph-structured data, making them suitable for tasks such as node classification, link </span><a id="_idIndexMarker673"/><span class="koboSpan" id="kobo.280.1">prediction, and graph-level classification. </span><span class="koboSpan" id="kobo.280.2">They have applications in social network analysis, molecular chemistry, and </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">recommendation systems.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.282.1">These are just a few examples of the diverse range of DL architectures and techniques available, each tailored to specific tasks and data types. </span><span class="koboSpan" id="kobo.282.2">For example, CNNs are designed for image and spatial data analysis using convolutional layers to automatically learn hierarchical features and patterns from images. </span><span class="koboSpan" id="kobo.282.3">Characteristic claims are image classification, object detection, and image segmentation. </span><span class="koboSpan" id="kobo.282.4">RNNs are suited for sequential and temporal data analysis, maintaining the memory of previous inputs through recurrent connections and enabling them to capture sequential patterns. </span><span class="koboSpan" id="kobo.282.5">Typical applications are NLP, speech recognition, and time-series prediction. </span><span class="koboSpan" id="kobo.282.6">LSTM networks are an improved version of RNNs to address the vanishing gradient problem, incorporating memory cells to selectively retain and update information over long sequences. </span><span class="koboSpan" id="kobo.282.7">Applications of these technologies provide language modeling, machine translation, and </span><strong class="bold"><span class="koboSpan" id="kobo.283.1">sentiment analysis</span></strong><span class="koboSpan" id="kobo.284.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.285.1">SA</span></strong><span class="koboSpan" id="kobo.286.1">). </span><span class="koboSpan" id="kobo.286.2">GANs </span><a id="_idIndexMarker674"/><span class="koboSpan" id="kobo.287.1">are used to generate new data samples that resemble a given dataset using a generator and a discriminator network that compete in a minimax game. </span><span class="koboSpan" id="kobo.287.2">This type of DL is particularly suitable for image generation, style transfer, and data augmentation. </span><span class="koboSpan" id="kobo.287.3">Finally, AEs as UL for data compression and feature extraction comprise an encoder to map input data to a lower-dimensional latent space and a decoder to reconstruct input data. </span><span class="koboSpan" id="kobo.287.4">Dimensionality reduction, denoising, and anomaly detection are representative applications for </span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">these algorithms.</span></span></p>
<p><span class="koboSpan" id="kobo.289.1">The field of DL continues to evolve, with new architectures and approaches emerging to address various challenges across </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">different domains.</span></span></p>
<p><span class="koboSpan" id="kobo.291.1">At this point, we can delve into the main technology of </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">DL—namely, CNNs.</span></span></p>
<h1 id="_idParaDest-128"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.293.1">Approaching CNNs</span></h1>
<p><span class="koboSpan" id="kobo.294.1">As outlined in </span><a href="B21156_05.xhtml#_idTextAnchor105"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.295.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.296.1">, </span><em class="italic"><span class="koboSpan" id="kobo.297.1">Introducing Artificial Neural Networks Modeling,</span></em><span class="koboSpan" id="kobo.298.1"> ANNs draw their inspiration from biological NNs. </span><span class="koboSpan" id="kobo.298.2">These ANNs aim to replicate human cognitive</span><a id="_idIndexMarker675"/><span class="koboSpan" id="kobo.299.1"> processes by emulating the mechanisms observed in natural NNs. </span><span class="koboSpan" id="kobo.299.2">They serve the purpose of estimating or approximating functions that might rely on numerous inputs, many of which could be unfamiliar. </span><span class="koboSpan" id="kobo.299.3">ANNs are typically conceptualized as networks of interconnected neurons, facilitating the exchange of messages. </span><span class="koboSpan" id="kobo.299.4">Each connection possesses an associated weight, the value of which can be adjusted through learning from experience. </span><span class="koboSpan" id="kobo.299.5">This adaptive characteristic empowers NNs to accommodate diverse input types and facilitates their capacity to learn (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.300.1">Figure 6</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.301.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.302.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<span class="koboSpan" id="kobo.303.1"><img alt="Figure 6.1 – ANN architecture with hidden layers" src="image/B21156_06_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.304.1">Figure 6.1 – ANN architecture with hidden layers</span></p>
<p><span class="koboSpan" id="kobo.305.1">ANNs</span><a id="_idIndexMarker676"/><span class="koboSpan" id="kobo.306.1"> define a neuron as the </span><strong class="bold"><span class="koboSpan" id="kobo.307.1">central processing unit</span></strong><span class="koboSpan" id="kobo.308.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.309.1">CPU</span></strong><span class="koboSpan" id="kobo.310.1">) that executes a mathematical operation to produce a single output from a set of input values. </span><span class="koboSpan" id="kobo.310.2">The neuron’s output is determined by the weighted sum of inputs and an added bias. </span><span class="koboSpan" id="kobo.310.3">Each neuron undertakes a straightforward task: activation occurs if the cumulative signal surpasses a specified activation threshold. </span><span class="koboSpan" id="kobo.310.4">The previous diagram illustrates a basic ANN structure, which essentially embodies CNNs. </span><span class="koboSpan" id="kobo.310.5">Indeed, like the latter, CNNs consist of interconnected neurons linked by weighted branches (weights); the networks’ training parameters remain the weights </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">and biases.</span></span></p>
<p><span class="koboSpan" id="kobo.312.1">Within CNNs, the </span><a id="_idIndexMarker677"/><span class="koboSpan" id="kobo.313.1">inter-neuron connectivity pattern takes inspiration from the arrangement observed in the animal world’s visual cortex. </span><span class="koboSpan" id="kobo.313.2">Neurons within this section of the brain (visual cortex) react to specific stimuli within limited observation zones referred to as receptive fields. </span><span class="koboSpan" id="kobo.313.3">These fields partially overlap to encompass the entire field of vision. </span><span class="koboSpan" id="kobo.313.4">The response of an individual neuron to stimuli within its receptive field can be approximated mathematically through a </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">convolution operation.</span></span></p>
<p><span class="koboSpan" id="kobo.315.1">All aspects pertaining to NN training, encompassing forward/backward propagation and weight updates, hold true in this context. </span><span class="koboSpan" id="kobo.315.2">Additionally, an entire CNN utilizes a singular differentiable cost function. </span><span class="koboSpan" id="kobo.315.3">However, CNNs are based on a particular assumption: their input possesses a specific data structure, such as an image. </span><span class="koboSpan" id="kobo.315.4">This characteristic empowers them to incorporate tailored architectural elements for enhanced processing of </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">such data.</span></span></p>
<p><span class="koboSpan" id="kobo.317.1">CNNs</span><a id="_idIndexMarker678"/><span class="koboSpan" id="kobo.318.1"> adopt a </span><strong class="bold"><span class="koboSpan" id="kobo.319.1">fully connected</span></strong><span class="koboSpan" id="kobo.320.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.321.1">FC</span></strong><span class="koboSpan" id="kobo.322.1">) </span><strong class="bold"><span class="koboSpan" id="kobo.323.1">architecture</span></strong><span class="koboSpan" id="kobo.324.1">, where each neuron in each layer connects to all neurons in the preceding</span><a id="_idIndexMarker679"/><span class="koboSpan" id="kobo.325.1"> layer (excluding bias neurons). </span><span class="koboSpan" id="kobo.325.2">Generally, these architectures do not scale effectively when confronted with expanding input </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">data sizes.</span></span></p>
<p><span class="koboSpan" id="kobo.327.1">The most common layers in a </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">CNN are:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.329.1">Convolutional layer</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.330.1">Pooling layer</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.331.1">Rectified linear </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.332.1">units</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.333.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.334.1">ReLUs</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">)</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.336.1">FC layer</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.337.1">The function of each layer is addressed in detail in the </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">following subsections.</span></span></p>
<p><span class="koboSpan" id="kobo.339.1">Usually, a CNN is composed of multiple sequential levels of convolution and subsampling (pooling), which are subsequently succeeded by one or more FC final levels, especially in the context of </span><span class="No-Break"><span class="koboSpan" id="kobo.340.1">classification tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.341.1">For addressing real-world challenges, these procedures can be merged and repeated as required. </span><span class="koboSpan" id="kobo.341.2">For instance, you can incorporate two, three, or even multiple layers of convolution. </span><span class="koboSpan" id="kobo.341.3">Additionally, you have the flexibility to apply pooling operations repeatedly to downsize the data dimensions. </span><span class="koboSpan" id="kobo.341.4">As mentioned earlier, a variety of levels are typically employed within a CNN. </span><span class="koboSpan" id="kobo.341.5">Certain layers encompass adjustable training parameters (weight and bias), whereas others are designed to execute </span><span class="No-Break"><span class="koboSpan" id="kobo.342.1">predefined functions.</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor132"/><span class="koboSpan" id="kobo.343.1">Convolutional layer</span></h2>
<p><span class="koboSpan" id="kobo.344.1">In a CNN, the </span><a id="_idIndexMarker680"/><span class="koboSpan" id="kobo.345.1">primary layer type is the </span><strong class="bold"><span class="koboSpan" id="kobo.346.1">convolutional layer</span></strong><span class="koboSpan" id="kobo.347.1">, and</span><a id="_idIndexMarker681"/><span class="koboSpan" id="kobo.348.1"> including one or more of these layers within a CNN is indispensable. </span><span class="koboSpan" id="kobo.348.2">In practical terms, the parameters of a convolutional layer are tied to a collection of adaptable filters. </span><span class="koboSpan" id="kobo.348.3">In contrast to CNNs, convolutional layers are structured in three dimensions, encompassing width, height, </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">and depth.</span></span></p>
<p><span class="koboSpan" id="kobo.350.1">Every filter occupies</span><a id="_idIndexMarker682"/><span class="koboSpan" id="kobo.351.1"> a small spatial area (along width and height dimensions) while spanning the complete depth of the input volume it is applied to. </span><span class="koboSpan" id="kobo.351.2">In forward propagation, each filter is shifted—or, more precisely, convolved—across the input volume’s width and height, generating a two-dimensional activation map (also known as a feature map) specific to that filter. </span><span class="koboSpan" id="kobo.351.3">While the filter traverses the input region, a scalar product operation takes place between the filter values and those of the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">input section.</span></span></p>
<p><span class="koboSpan" id="kobo.353.1">Conceptually, the</span><a id="_idIndexMarker683"/><span class="koboSpan" id="kobo.354.1"> network’s objective is to learn activated filters that detect specific functionalities within distinct spatial regions of the input. </span><span class="koboSpan" id="kobo.354.2">Combining all these feature maps (for every filter) along the depth dimension forms the output volume of a convolutional layer. </span><span class="koboSpan" id="kobo.354.3">Each element within this volume can be interpreted as the output of a neuron observing a confined input area, and it shares its parameters with other neurons within the same feature map. </span><span class="koboSpan" id="kobo.354.4">This sharing stems from their common origin—the application of the </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">same filter.</span></span></p>
<p><span class="koboSpan" id="kobo.356.1">The mathematical steps for filtering are </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.358.1">Align the filter and the </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">image patch.</span></span></li>
<li><span class="koboSpan" id="kobo.360.1">Multiply each image pixel by the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">feature pixel.</span></span></li>
<li><span class="koboSpan" id="kobo.362.1">Sum </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">the products.</span></span></li>
<li><span class="koboSpan" id="kobo.364.1">Divide each sum by the total number of pixels in </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">the feature.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.366.1">Here is the formula for the output of a </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">convolutional layer:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.368.1">O</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.369.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.370.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.371.1">p</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.372.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.373.1">t</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.374.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.375.1">∑</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.376.1">F</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.377.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.378.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.379.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.380.1">l</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.381.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Symbol_v-normal"><span class="koboSpan" id="kobo.382.1">*</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.383.1">I</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.384.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.385.1">i</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.386.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.387.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.388.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.389.1">j</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.390.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.391.1">l</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.392.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.393.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.394.1">/</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.395.1">S</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.396.1">(</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.397.1">k</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.398.1">,</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.399.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.400.1">)</span></span></span></p>
<p><span class="No-Break"><span class="koboSpan" id="kobo.401.1">Here:</span></span></p>
<ul>
<li><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.402.1">F</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.403.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.404.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.405.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.406.1">l</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.407.1">)</span></span><span class="koboSpan" id="kobo.408.1"> is the feature map element in </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.409.1">(</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.410.1">k</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.411.1">,</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.412.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.413.1">)</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.414.1">p</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.415.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.416.1">s</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.417.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.418.1">t</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.419.1">i</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.420.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.421.1">n</span></span></span></li>
<li><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.422.1">I</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.423.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.424.1">i</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.425.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.426.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.427.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.428.1">j</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.429.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.430.1">l</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.431.1">)</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.432.1">)</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.433.1">)</span></span><span class="koboSpan" id="kobo.434.1"> is the image element in</span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.435.1">(</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.436.1">i</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.437.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.438.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.439.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.440.1">j</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.441.1">+</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.442.1">l</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.443.1">)</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">position</span></span></li>
<li><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.445.1">S</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.446.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.447.1">k</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.448.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.449.1">l</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.450.1">)</span></span><span class="koboSpan" id="kobo.451.1"> is the sum of the </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">feature pixel</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.453.1">In summary, key points to </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">emphasize include:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.455.1">Local receptive field</span></strong><span class="koboSpan" id="kobo.456.1">: Neurons in a layer are connected to a small segment of the input, known as a local receptive field. </span><span class="koboSpan" id="kobo.456.2">Each connection learns </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1">a weight.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.458.1">Shared weights</span></strong><span class="koboSpan" id="kobo.459.1">: Since significant features (such as edges or blobs) can appear anywhere in an image, neurons within the same layer share weights. </span><span class="koboSpan" id="kobo.459.2">This implies that identical features are recognized by all neurons in the layer, even if they’re positioned at different </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">input points.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.461.1">Convolution</span></strong><span class="koboSpan" id="kobo.462.1">: Identical weight patterns are employed at various positions. </span><span class="koboSpan" id="kobo.462.2">The outcome of convolution is</span><a id="_idIndexMarker684"/><span class="koboSpan" id="kobo.463.1"> termed a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.464.1">feature map</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.466.1">Each filter</span><a id="_idIndexMarker685"/><span class="koboSpan" id="kobo.467.1"> captures</span><a id="_idIndexMarker686"/><span class="koboSpan" id="kobo.468.1"> a specific feature from the preceding layer. </span><span class="koboSpan" id="kobo.468.2">Therefore, training multiple convolutional filters is necessary to extract diverse features. </span><span class="koboSpan" id="kobo.468.3">Each filter produces a feature map highlighting </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">distinct characteristics.</span></span></p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor133"/><span class="koboSpan" id="kobo.470.1">Pooling layer</span></h2>
<p><span class="koboSpan" id="kobo.471.1">These </span><a id="_idIndexMarker687"/><span class="koboSpan" id="kobo.472.1">layers are </span><a id="_idIndexMarker688"/><span class="koboSpan" id="kobo.473.1">systematically integrated into a network to periodically diminish the spatial dimensions (width and height) of ongoing representations and volumes within a specific stage of the network. </span><span class="koboSpan" id="kobo.473.2">This serves a dual purpose of minimizing the number of parameters, reducing computational time, and keeping a check on overfitting. </span><span class="koboSpan" id="kobo.473.3">The role of a </span><strong class="bold"><span class="koboSpan" id="kobo.474.1">pooling layer</span></strong><span class="koboSpan" id="kobo.475.1"> is to operate on each depth slice of the input volume independently to resize </span><span class="No-Break"><span class="koboSpan" id="kobo.476.1">it spatially.</span></span></p>
<p><span class="koboSpan" id="kobo.477.1">For each feature obtained during the convolutional process, a matrix is constructed, and the maximum value within each selected matrix is identified to compress the entire input. </span><span class="koboSpan" id="kobo.477.2">The steps are </span><span class="No-Break"><span class="koboSpan" id="kobo.478.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.479.1">Choose a window size (typically </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1">2</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.481.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">).</span></span></li>
<li><span class="koboSpan" id="kobo.484.1">Select a stride distance for pixel movement (usually 2). </span><span class="koboSpan" id="kobo.484.2">In a CNN, the stride distance in a pooling layer determines how much the pooling operation slides across the input feature map. </span><span class="koboSpan" id="kobo.484.3">A higher stride distance means that the pooling operation will skip over more pixels, resulting in a smaller output feature map. </span><span class="koboSpan" id="kobo.484.4">A lower stride distance means that the pooling operation will slide more carefully across the input feature map, resulting in a larger output </span><span class="No-Break"><span class="koboSpan" id="kobo.485.1">feature map.</span></span></li>
<li><span class="koboSpan" id="kobo.486.1">Slide the window across the </span><span class="No-Break"><span class="koboSpan" id="kobo.487.1">filtered images.</span></span></li>
<li><span class="koboSpan" id="kobo.488.1">For each window, determine the </span><span class="No-Break"><span class="koboSpan" id="kobo.489.1">maximum value.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.490.1">Illustratively, this</span><a id="_idIndexMarker689"/><span class="koboSpan" id="kobo.491.1"> method partitions an input image into groups of squares, and for each resulting segment, the highest value is extracted as the output. </span><span class="koboSpan" id="kobo.491.2">CNNs additionally incorporate pooling layers, strategically placed right after the convolutional layers. </span><span class="koboSpan" id="kobo.491.3">A pooling layer dissects the input into sections and chooses a representative value, employing methods such as max pooling or average pooling. </span><span class="koboSpan" id="kobo.491.4">The </span><strong class="bold"><span class="koboSpan" id="kobo.492.1">max pooling</span></strong><span class="koboSpan" id="kobo.493.1"> layer </span><a id="_idIndexMarker690"/><span class="koboSpan" id="kobo.494.1">captures the </span><a id="_idIndexMarker691"/><span class="koboSpan" id="kobo.495.1">highest features detected by preceding convolutional layers. </span><span class="koboSpan" id="kobo.495.2">The output layer assesses the presence of a potential feature within a region of the previous layers, albeit without exact spatial coordinates. </span><span class="koboSpan" id="kobo.495.3">The objective is to enable subsequent layers to process larger data sections. </span><span class="koboSpan" id="kobo.495.4">Max pooling expedites convergence rates, thereby enabling the selection of highly invariant features that enhance </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">generalization performance.</span></span></p>
<p><span class="koboSpan" id="kobo.497.1">The integration</span><a id="_idIndexMarker692"/><span class="koboSpan" id="kobo.498.1"> of a pooling layer offers the </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">following benefits:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.500.1">Reduces subsequent </span><span class="No-Break"><span class="koboSpan" id="kobo.501.1">layer computations</span></span></li>
<li><span class="koboSpan" id="kobo.502.1">Enhances feature robustness concerning </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">spatial positioning</span></span></li>
<li><span class="koboSpan" id="kobo.504.1">Operates under the premise that after identifying a particular feature, its precise location within the input becomes less significant than its general position relative to </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">other features</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.506.1">Average pooling serves as a downsampling operation that consolidates the representation of features within patches of the feature map. </span><span class="koboSpan" id="kobo.506.2">Typically, it is implemented in 2x2 patches of the feature map with a stride of (2, 2). </span><span class="koboSpan" id="kobo.506.3">The process entails computing the average for each patch of the feature map, indicating that every 2x2 square in the feature map is downsampled to its average value. </span><span class="koboSpan" id="kobo.506.4">To illustrate, consider the 6x6 feature map resulting from the line detector convolutional filter discussed in the preceding section. </span><span class="koboSpan" id="kobo.506.5">We can manually explore the application of the average pooling operation to the initial line of that </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">feature map.</span></span></p>
<p><span class="koboSpan" id="kobo.508.1">In a typical CNN architecture, convolution layers and pooling layers are interleaved in a </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">recurring pattern.</span></span></p>
<h2 id="_idParaDest-131"><a id="_idTextAnchor134"/><span class="koboSpan" id="kobo.510.1">ReLUs</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.511.1">ReLUs</span></strong><span class="koboSpan" id="kobo.512.1"> serve </span><a id="_idIndexMarker693"/><span class="koboSpan" id="kobo.513.1">as crucial activation functions within NNs. </span><span class="koboSpan" id="kobo.513.2">Their frequent utilization occurs multiple times within a single network, often following each convolutional layer. </span><span class="koboSpan" id="kobo.513.3">A ReLU layer is composed of neurons that execute the function </span><em class="italic"><span class="koboSpan" id="kobo.514.1">f(x) = max(0, x)</span></em><span class="koboSpan" id="kobo.515.1">. </span><span class="koboSpan" id="kobo.515.2">Incorporating these layers enhances the network’s non-linearity while maintaining the convolutional levels’ receptive </span><span class="No-Break"><span class="koboSpan" id="kobo.516.1">fields unchanged.</span></span></p>
<p><span class="koboSpan" id="kobo.517.1">ReLUs are </span><a id="_idIndexMarker694"/><span class="koboSpan" id="kobo.518.1">favored over alternative functions such as hyperbolic tangent or sigmoid, primarily due to their capacity to accelerate the training process significantly without substantially compromising generalization accuracy. </span><span class="koboSpan" id="kobo.518.2">By employing ReLU layers, network training becomes remarkably swifter, all while preserving </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1">comparable performance.</span></span></p>
<p><span class="koboSpan" id="kobo.520.1">These layer types lack adjustable parameters, thus executing a fixed function. </span><span class="koboSpan" id="kobo.520.2">Furthermore, they don’t possess any adaptable parameters either. </span><span class="koboSpan" id="kobo.520.3">Layers devoid of tunable parameters simplify the backward propagation process: errors computed up to that point, stemming from the subsequent layer, are propagated backward to the </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">preceding layer.</span></span></p>
<h2 id="_idParaDest-132"><a id="_idTextAnchor135"/><span class="koboSpan" id="kobo.522.1">FC layer</span></h2>
<p><span class="koboSpan" id="kobo.523.1">This </span><a id="_idIndexMarker695"/><span class="koboSpan" id="kobo.524.1">layer type mirrors the structure of any layer </span><a id="_idIndexMarker696"/><span class="koboSpan" id="kobo.525.1">found in a traditional ANN featuring an FC architecture. </span><span class="koboSpan" id="kobo.525.2">In an </span><strong class="bold"><span class="koboSpan" id="kobo.526.1">FC layer</span></strong><span class="koboSpan" id="kobo.527.1">, each neuron establishes connections with all neurons from the preceding layer, specifically interacting with </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">their activations.</span></span></p>
<p><span class="koboSpan" id="kobo.529.1">Unlike what has been observed thus far in CNNs, this layer type does not adhere to the principle of local connectivity. </span><span class="koboSpan" id="kobo.529.2">An FC layer establishes connections spanning the entire input volume, which naturally results in a multitude of connections. </span><span class="koboSpan" id="kobo.529.3">The sole adjustable parameter in this layer type is the number of neurons, </span><em class="italic"><span class="koboSpan" id="kobo.530.1">K</span></em><span class="koboSpan" id="kobo.531.1">, that constitute it. </span><span class="koboSpan" id="kobo.531.2">The fundamental characteristic of an FC layer can be summarized as follows: linking its K neurons with the entire input volume and calculating the activation for each of these </span><span class="No-Break"><span class="koboSpan" id="kobo.532.1">K neurons.</span></span></p>
<p><span class="koboSpan" id="kobo.533.1">In practice, the outcome will be a singular 1 x 1 x K vector, encapsulating the computed activations. </span><span class="koboSpan" id="kobo.533.2">The transition from an input volume, organized in three dimensions, to a singular output </span><a id="_idIndexMarker697"/><span class="koboSpan" id="kobo.534.1">vector in one dimension (1 x 1 x K) after implementing an FC layer signifies that the utilization of additional convoluted layers becomes infeasible. </span><span class="koboSpan" id="kobo.534.2">In the realm of CNNs, FC layers </span><a id="_idIndexMarker698"/><span class="koboSpan" id="kobo.535.1">primarily serve the purpose of consolidating information amassed up to that point, presenting it as a singular value (the activation of one of its neurons). </span><span class="koboSpan" id="kobo.535.2">This singular value subsequently forms the basis for subsequent computations in the final </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">classification process.</span></span></p>
<p><span class="koboSpan" id="kobo.537.1">Having thoroughly examined each element of a CNN, it is now fitting to delve into the overarching structure of a </span><span class="No-Break"><span class="koboSpan" id="kobo.538.1">complete CNN.</span></span></p>
<h1 id="_idParaDest-133"><a id="_idTextAnchor136"/><span class="koboSpan" id="kobo.539.1">Building a CNN in MATLAB</span></h1>
<p><span class="koboSpan" id="kobo.540.1">In this </span><a id="_idIndexMarker699"/><span class="koboSpan" id="kobo.541.1">section, we will see how to train a CNN for image classification, starting from the images as input layers. </span><span class="koboSpan" id="kobo.541.2">The overall architecture of a CNN typically comprises a sequence of convolutional layers, interspersed with </span><a id="_idIndexMarker700"/><span class="koboSpan" id="kobo.542.1">ReLU layers and, when appropriate, standardization and pooling layers. </span><span class="koboSpan" id="kobo.542.2">Ultimately, the network concludes with a series of FC layers leading to the </span><span class="No-Break"><span class="koboSpan" id="kobo.543.1">output layer.</span></span></p>
<p><span class="koboSpan" id="kobo.544.1">CNNs consist of two primary types </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1">of neurons:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.546.1">Processing neurons</span></strong><span class="koboSpan" id="kobo.547.1">: These</span><a id="_idIndexMarker701"/><span class="koboSpan" id="kobo.548.1"> neurons undertake the responsibility of processing specific sections of the input image through convolution functions. </span><span class="koboSpan" id="kobo.548.2">Their primary role involves extracting distinctive features from the </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">input data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.550.1">Aggregation or pooling neurons</span></strong><span class="koboSpan" id="kobo.551.1">: These neurons aggregate the input data and reduce its </span><a id="_idIndexMarker702"/><span class="koboSpan" id="kobo.552.1">dimensions through subsampling, enhancing efficiency for subsequent </span><span class="No-Break"><span class="koboSpan" id="kobo.553.1">layers’ processing.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.554.1">By assembling the output values from a given layer, it becomes possible to reconstruct an intermediate image that serves as a foundation for subsequent </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">layers’ operations:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<span class="koboSpan" id="kobo.556.1"><img alt="Figure 6.2 – CNN architecture" src="image/B21156_06_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.557.1">Figure 6.2 – CNN architecture</span></p>
<p><span class="koboSpan" id="kobo.558.1">The</span><a id="_idIndexMarker703"/><span class="koboSpan" id="kobo.559.1"> fundamental concept involves commencing with a sizable image and progressively condensing the data through incremental steps until a singular outcome is achieved. </span><span class="koboSpan" id="kobo.559.2">As the number of convolutional </span><a id="_idIndexMarker704"/><span class="koboSpan" id="kobo.560.1">passages increases, the NN’s capacity to comprehend and handle intricate </span><span class="No-Break"><span class="koboSpan" id="kobo.561.1">functions amplifies.</span></span></p>
<p><span class="koboSpan" id="kobo.562.1">The configuration of a basic CNN can be succinctly described through the </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">following components:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.564.1">An input layer tasked with acquiring input elements, such </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">as images</span></span></li>
<li><span class="koboSpan" id="kobo.566.1">A sequence of convolutional layers, occasionally punctuated by a ReLU layer and, when deemed appropriate, </span><span class="No-Break"><span class="koboSpan" id="kobo.567.1">pooling layers</span></span></li>
<li><span class="koboSpan" id="kobo.568.1">A series of </span><span class="No-Break"><span class="koboSpan" id="kobo.569.1">FC layers</span></span></li>
<li><span class="koboSpan" id="kobo.570.1">An output layer that furnishes the </span><span class="No-Break"><span class="koboSpan" id="kobo.571.1">final results</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.572.1">Recent research has indicated that the significance of FC layers might be less substantial. </span><span class="koboSpan" id="kobo.572.2">Nevertheless, for the present context, the outlined structure represents the typical architecture of </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">a CNN.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.574.1">Object recognition</span></strong><span class="koboSpan" id="kobo.575.1"> refers </span><a id="_idIndexMarker705"/><span class="koboSpan" id="kobo.576.1">to the capacity to locate a specific object within a series of images or videos. </span><span class="koboSpan" id="kobo.576.2">Humans effortlessly identify diverse objects in images, even when those objects appear differently. </span><span class="koboSpan" id="kobo.576.3">Moreover, objects can be distinguished even when only parts of them are visible. </span><span class="koboSpan" id="kobo.576.4">However, this remains a challenging task for the broader field </span><span class="No-Break"><span class="koboSpan" id="kobo.577.1">of CV.</span></span></p>
<p><span class="koboSpan" id="kobo.578.1">In each image, every object boasts numerous intriguing features that can be extracted to craft a depiction of it. </span><span class="koboSpan" id="kobo.578.2">This portrayal subsequently serves to distinguish the object when attempting to spot it amid multiple objects in a test image. </span><span class="koboSpan" id="kobo.578.3">Ensuring the features taken from the reference image are unaffected by differences in image scale, disturbances, lighting variations, and distortions is crucial for establishing </span><span class="No-Break"><span class="koboSpan" id="kobo.579.1">dependable recognition.</span></span></p>
<p><span class="koboSpan" id="kobo.580.1">CNNs are</span><a id="_idIndexMarker706"/><span class="koboSpan" id="kobo.581.1"> particularly well suited for this endeavor, providing algorithms that excel in the identification of objects with remarkable accuracy. </span><span class="koboSpan" id="kobo.581.2">This is because they are able to learn features from images that are invariant to translation, scale, and rotation. </span><span class="koboSpan" id="kobo.581.3">This is due to the use of convolutional layers, which</span><a id="_idIndexMarker707"/><span class="koboSpan" id="kobo.582.1"> apply a filter to a small region of the input image and then slide the filter across the image. </span><span class="koboSpan" id="kobo.582.2">This allows the network to learn features that are specific to different parts of the image, regardless of where they are located. </span><span class="koboSpan" id="kobo.582.3">Additionally, pooling layers are used to reduce the dimensionality of the feature maps, which makes the network more efficient to train </span><span class="No-Break"><span class="koboSpan" id="kobo.583.1">and run.</span></span></p>
<p><span class="koboSpan" id="kobo.584.1">For CNN training, we will use Pistachio image dataset. </span><span class="koboSpan" id="kobo.584.2">The dataset offers data for analyzing the species of pistachio using a large collection </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">of photos.</span></span></p>
<p><span class="koboSpan" id="kobo.586.1">It encompasses a total of 2,148 images categorized into 2 classes—</span><strong class="source-inline"><span class="koboSpan" id="kobo.587.1">Kirmizi</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.588.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.589.1">Siirt</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.590.1">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.591.1">To start, we must load the dataset in the MATLAB workspace. </span><span class="koboSpan" id="kobo.591.2">The dataset is available in ZIP format on the site linked in the </span><em class="italic"><span class="koboSpan" id="kobo.592.1">Technical requirements</span></em><span class="koboSpan" id="kobo.593.1"> section. </span><span class="koboSpan" id="kobo.593.2">To facilitate the reader’s work, the images have been divided according to class into folders named according to the category and resized to reduce the weight of the data. </span><span class="koboSpan" id="kobo.593.3">These folders are available for download on the book’s GitHub site. </span><span class="koboSpan" id="kobo.593.4">Once the file has been downloaded and the contents extracted, it will be enough to define the path of the root folder. </span><span class="koboSpan" id="kobo.593.5">At this point, it will be possible to upload the data to the MATLAB </span><a id="_idTextAnchor137"/><span class="koboSpan" id="kobo.594.1">workspace </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">as follows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.596.1">
Data = imageDatastore('C:\MatlabScript\PistachioShort', 'IncludeSubfolders',true,'LabelSource','foldernames');</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.597.1">To load the data, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.598.1">imageDatastore()</span></strong><span class="koboSpan" id="kobo.599.1"> function, which employs an </span><strong class="source-inline"><span class="koboSpan" id="kobo.600.1">ImageDatastore</span></strong><span class="koboSpan" id="kobo.601.1"> entity to oversee a compilation of image files, with each singular image fitting within memory, although the complete image collection might not. </span><span class="koboSpan" id="kobo.601.2">Constructing an </span><strong class="source-inline"><span class="koboSpan" id="kobo.602.1">ImageDatastore</span></strong><span class="koboSpan" id="kobo.603.1"> entity involves utilizing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1">imageDatastore</span></strong><span class="koboSpan" id="kobo.605.1"> function, where you can define its attributes. </span><span class="koboSpan" id="kobo.605.2">Subsequently, you can import and manipulate the data using the functions associated with the entity. </span><span class="koboSpan" id="kobo.605.3">Three parameters were used, </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1">as follows:</span></span></p><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.607.1">Location= 'C:\MatlabScript\PistachioShort'</span></strong><span class="koboSpan" id="kobo.608.1">: This is the location of the dataset. </span><span class="koboSpan" id="kobo.608.2">To replicate the example, the reader has to simply substitute the path of the folder in which the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.609.1">was stored.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.610.1">IncludeSubfolders</span></strong><span class="koboSpan" id="kobo.611.1">: The inclusion of subfolders can be controlled using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1">IncludeSubfolders</span></strong><span class="koboSpan" id="kobo.613.1"> name-value argument, which accepts either </span><strong class="source-inline"><span class="koboSpan" id="kobo.614.1">true</span></strong><span class="koboSpan" id="kobo.615.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.616.1">false</span></strong><span class="koboSpan" id="kobo.617.1">. </span><span class="koboSpan" id="kobo.617.2">Opt for </span><strong class="source-inline"><span class="koboSpan" id="kobo.618.1">true</span></strong><span class="koboSpan" id="kobo.619.1"> to encompass all files and subfolders within each main folder, or select </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1">false</span></strong><span class="koboSpan" id="kobo.621.1"> to solely encompass files within each main folder. </span><span class="koboSpan" id="kobo.621.2">When </span><strong class="source-inline"><span class="koboSpan" id="kobo.622.1">IncludeSubfolders</span></strong><span class="koboSpan" id="kobo.623.1"> is not explicitly specified, the default value </span><span class="No-Break"><span class="koboSpan" id="kobo.624.1">is </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.625.1">false</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.626.1">.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.627.1">LabelSource</span></strong><span class="koboSpan" id="kobo.628.1">: The origin of label data is determined through the </span><strong class="source-inline"><span class="koboSpan" id="kobo.629.1">LabelSource</span></strong><span class="koboSpan" id="kobo.630.1"> name-value argument, which accepts either </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">none</span></strong><span class="koboSpan" id="kobo.632.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">foldernames</span></strong><span class="koboSpan" id="kobo.634.1">. </span><span class="koboSpan" id="kobo.634.2">By specifying </span><strong class="source-inline"><span class="koboSpan" id="kobo.635.1">none</span></strong><span class="koboSpan" id="kobo.636.1">, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.637.1">Labels</span></strong><span class="koboSpan" id="kobo.638.1"> property remains devoid of labels. </span><span class="koboSpan" id="kobo.638.2">On the other hand, designating </span><strong class="source-inline"><span class="koboSpan" id="kobo.639.1">foldernames</span></strong><span class="koboSpan" id="kobo.640.1"> results in the assignment of labels based on the folder names, which are then stored within the </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1">Labels</span></strong><span class="koboSpan" id="kobo.642.1"> property. </span><span class="koboSpan" id="kobo.642.2">Subsequent adjustments to the labels can be made by directly accessing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.643.1">Labels</span></strong><span class="koboSpan" id="kobo.644.1"> property. </span><span class="koboSpan" id="kobo.644.2">It’s important to note that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.645.1">LabelSource</span></strong><span class="koboSpan" id="kobo.646.1"> name-value argument cannot be utilized when a </span><strong class="source-inline"><span class="koboSpan" id="kobo.647.1">FileSet</span></strong><span class="koboSpan" id="kobo.648.1"> object serves as the file or </span><span class="No-Break"><span class="koboSpan" id="kobo.649.1">folder location.</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.650.1">We can </span><a id="_idIndexMarker708"/><span class="koboSpan" id="kobo.651.1">now view some of the</span><a id="_idIndexMarker709"/><span class="koboSpan" id="kobo.652.1"> images loaded through a </span><span class="No-Break"><span class="koboSpan" id="kobo.653.1">random process:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.654.1">figure;
RandId = randperm(2148,9);
for i = 1:9
    subplot(3,3,i);
    imshow(Data.Files{RandId(i)});
end</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.655.1">In this piece of code, we have used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.656.1">randperm()</span></strong><span class="koboSpan" id="kobo.657.1"> function, which generates a row vector comprising </span><strong class="source-inline"><span class="koboSpan" id="kobo.658.1">9</span></strong><span class="koboSpan" id="kobo.659.1"> distinct random integers chosen from the range of </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1">1</span></strong><span class="koboSpan" id="kobo.661.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.662.1">2148</span></strong><span class="koboSpan" id="kobo.663.1">. </span><span class="koboSpan" id="kobo.663.2">Each number generated was used as an index to identify an image file path </span><a id="_idIndexMarker710"/><span class="koboSpan" id="kobo.664.1">stored in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">Data.Files</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.666.1"> property.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.667.1">The </span><a id="_idIndexMarker711"/><span class="koboSpan" id="kobo.668.1">following output </span><span class="No-Break"><span class="koboSpan" id="kobo.669.1">was returned:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer061">
<span class="koboSpan" id="kobo.670.1"><img alt="Figure 6.3 – Image samples from PistachioShort dataset" src="image/B21156_06_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.671.1">Figure 6.3 – Image samples from PistachioShort dataset</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.672.1">We are now able to determine the image count in each category. </span><span class="koboSpan" id="kobo.672.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.673.1">ClassItemsNumber</span></strong><span class="koboSpan" id="kobo.674.1"> variable represents a table containing the labels and the corresponding number of images associated with each </span><span class="No-Break"><span class="koboSpan" id="kobo.675.1">of them:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.676.1">
ClassItemsNumber = countEachLabel(Data)</span></pre> <p class="list-inset"><span class="koboSpan" id="kobo.677.1">We </span><a id="_idIndexMarker712"/><span class="koboSpan" id="kobo.678.1">used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.679.1">countEachLabel()</span></strong><span class="koboSpan" id="kobo.680.1"> function that produces a summary table indicating the labels within the </span><strong class="source-inline"><span class="koboSpan" id="kobo.681.1">Data</span></strong><span class="koboSpan" id="kobo.682.1"> dataset and the respective count of associated</span><a id="_idIndexMarker713"/><span class="koboSpan" id="kobo.683.1"> files for </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">each label.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.685.1">The following table </span><span class="No-Break"><span class="koboSpan" id="kobo.686.1">was printed:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.687.1">
ClassItemsNumber =
  2×2 table
     Label     Count
    _______    _____
    Kirmizi    1232
    Siirt       916</span></pre> <p class="list-inset"><span class="koboSpan" id="kobo.688.1">As we can see, there are two categories, and there are enough images in </span><span class="No-Break"><span class="koboSpan" id="kobo.689.1">each category.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.690.1">To start, it is necessary to divide the data at our disposal into two subsets; the first will be used for training, and the second for algorithm validation. </span><span class="koboSpan" id="kobo.690.2">Data splitting is a crucial step in ML and data analysis whereby a dataset is divided into two or more subsets for the purpose of training, validation, and testing of a model. </span><span class="koboSpan" id="kobo.690.3">We have </span><strong class="source-inline"><span class="koboSpan" id="kobo.691.1">2148</span></strong><span class="koboSpan" id="kobo.692.1"> samples divided into </span><strong class="source-inline"><span class="koboSpan" id="kobo.693.1">1232</span></strong><span class="koboSpan" id="kobo.694.1"> Kirmizi species and </span><strong class="source-inline"><span class="koboSpan" id="kobo.695.1">916</span></strong><span class="koboSpan" id="kobo.696.1">  Siirt species. </span><span class="koboSpan" id="kobo.696.2">Usually, the data would be split into 80% for the training and 20% for validation. </span><span class="koboSpan" id="kobo.696.3">For this purpose, we decide to use 700 samples for the training and the remainder </span><span class="No-Break"><span class="koboSpan" id="kobo.697.1">for validation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.698.1">
TrainSamples = 0.8;
[DataTrain,DataValidation] = splitEachLabel(Data,TrainSamples,'randomize');</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.699.1">To do this, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.700.1">splitEachLabel()</span></strong><span class="koboSpan" id="kobo.701.1"> function was used: this function divides the image files in the Data dataset into two distinct datastores—namely, </span><strong class="source-inline"><span class="koboSpan" id="kobo.702.1">DataTrain</span></strong><span class="koboSpan" id="kobo.703.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.704.1">DataValidation</span></strong><span class="koboSpan" id="kobo.705.1">. </span><span class="koboSpan" id="kobo.705.2">The freshly created </span><strong class="source-inline"><span class="koboSpan" id="kobo.706.1">DataTrain</span></strong><span class="koboSpan" id="kobo.707.1"> datastore encompasses the initial </span><strong class="source-inline"><span class="koboSpan" id="kobo.708.1">TrainSamples</span></strong><span class="koboSpan" id="kobo.709.1"> value from every category, while the </span><strong class="source-inline"><span class="koboSpan" id="kobo.710.1">DataValidation</span></strong><span class="koboSpan" id="kobo.711.1"> datastore holds the remaining files from each category. </span><strong class="source-inline"><span class="koboSpan" id="kobo.712.1">TrainSamples</span></strong><span class="koboSpan" id="kobo.713.1"> can either be a fractional value between </span><strong class="source-inline"><span class="koboSpan" id="kobo.714.1">0</span></strong><span class="koboSpan" id="kobo.715.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.716.1">1</span></strong><span class="koboSpan" id="kobo.717.1">, denoting the proportion of files to allocate to </span><strong class="source-inline"><span class="koboSpan" id="kobo.718.1">DataTrain</span></strong><span class="koboSpan" id="kobo.719.1">, or an integer representing </span><a id="_idIndexMarker714"/><span class="koboSpan" id="kobo.720.1">the exact count of files to be placed in </span><strong class="source-inline"><span class="koboSpan" id="kobo.721.1">DataTrain</span></strong><span class="koboSpan" id="kobo.722.1"> for </span><span class="No-Break"><span class="koboSpan" id="kobo.723.1">each category.</span></span></p></li> <li><span class="koboSpan" id="kobo.724.1">Now, we</span><a id="_idIndexMarker715"/><span class="koboSpan" id="kobo.725.1"> can start building our CNN. </span><span class="koboSpan" id="kobo.725.2">As anticipated, a CNN is formed by a series of layers connected to each other. </span><span class="koboSpan" id="kobo.725.3">To get started, you need to use a layer to import your </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">input data:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.727.1">
layers = [
    imageInputLayer([64, 64, 3])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.728.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.729.1">layers</span></strong><span class="koboSpan" id="kobo.730.1"> variable is an array containing a list of layers of the CNN and defines the architecture of NNs for DL. </span><span class="koboSpan" id="kobo.730.2">As a first layer, we set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.731.1">imageInputLayer</span></strong><span class="koboSpan" id="kobo.732.1"> layer: this layer serves as an image input, feeding 2D images into a NN while also implementing data normalization. </span><span class="koboSpan" id="kobo.732.2">This layer provides an image input layer and defines the unchangeable </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.733.1">InputSize</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.734.1"> attribute.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.735.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.736.1">InputSize</span></strong><span class="koboSpan" id="kobo.737.1"> attribute is a depiction of the input data’’ dimensions, represented as a 1D array of integers </span><strong class="source-inline"><span class="koboSpan" id="kobo.738.1">[h w c]</span></strong><span class="koboSpan" id="kobo.739.1">, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.740.1">h</span></strong><span class="koboSpan" id="kobo.741.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.742.1">w</span></strong><span class="koboSpan" id="kobo.743.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.744.1">c</span></strong><span class="koboSpan" id="kobo.745.1"> denote the height, width, and number of channels respectively. </span><span class="koboSpan" id="kobo.745.2">In this case, we have an RGB image with height = 64 and width = </span><span class="No-Break"><span class="koboSpan" id="kobo.746.1">64.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.747.1">After the input layer, we set the first block of three layers </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">in sequence:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.749.1">    convolution2dLayer(3,8,'Padding','same')
    batchNormalizationLayer
    reluLayer</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.750.1">Filter size </span><em class="italic"><span class="koboSpan" id="kobo.751.1">3x3</span></em><span class="koboSpan" id="kobo.752.1">, number of filters = 8, and padding = </span><strong class="source-inline"><span class="koboSpan" id="kobo.753.1">'same'</span></strong><span class="koboSpan" id="kobo.754.1"> indicate the convolution </span><a id="_idIndexMarker716"/><span class="koboSpan" id="kobo.755.1">process would yield the same size of input </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">image (</span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.757.1">64x64x3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.758.1">).</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.759.1">In this block, </span><span class="No-Break"><span class="koboSpan" id="kobo.760.1">we have:</span></span></p><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.761.1">convolution2dLayer</span></strong><span class="koboSpan" id="kobo.762.1">: A 2D convolutional layer utilizes sliding convolutional filters on 2D input data. </span><span class="koboSpan" id="kobo.762.2">This layer performs convolution by shifting the filters across the input data in both vertical and horizontal directions. </span><span class="koboSpan" id="kobo.762.3">It calculates the dot product between the filter weights and the input at each position and subsequently incorporates a </span><span class="No-Break"><span class="koboSpan" id="kobo.763.1">bias term.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.764.1">batchNormalizationLayer</span></strong><span class="koboSpan" id="kobo.765.1">: A layer for batch normalization standardizes a mini-batch of data independently across all observations for each</span><a id="_idIndexMarker717"/><span class="koboSpan" id="kobo.766.1"> channel. </span><span class="koboSpan" id="kobo.766.2">To accelerate the training process of a CNN and decrease vulnerability to network initialization, incorporate batch normalization layers between convolutional layers and non-linear functions such as </span><span class="No-Break"><span class="koboSpan" id="kobo.767.1">ReLU layers.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.768.1">reluLayer</span></strong><span class="koboSpan" id="kobo.769.1">: A ReLU layer applies a thresholding operation to each input element, nullifying any value that is less than zero and setting it </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">to zero.</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.771.1">After this first block, we have to apply a pooling layer </span><span class="No-Break"><span class="koboSpan" id="kobo.772.1">as follows:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.773.1">    maxPooling2dLayer(2,'Stride',2)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.774.1">Downsampling at a 2:1 ratio and stride = 2 indicate a shift by 2 columns and 2 rows in the pooling operation. </span><span class="koboSpan" id="kobo.774.2">A 2D max pooling layer conducts downsampling by partitioning the input into rectangular pooling regions and subsequently determining the maximum value within </span><span class="No-Break"><span class="koboSpan" id="kobo.775.1">each region.</span></span></p></li> <li><span class="koboSpan" id="kobo.776.1">Now, we will apply a second block of layers like the first, changing </span><span class="No-Break"><span class="koboSpan" id="kobo.777.1">the parameters:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.778.1">
    convolution2dLayer(3,16,'Padding','same')
    batchNormalizationLayer
    reluLayer</span></pre></li> <li><span class="koboSpan" id="kobo.779.1">After that, a new pooling layer </span><span class="No-Break"><span class="koboSpan" id="kobo.780.1">is applied:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.781.1">
    maxPooling2dLayer(2,'Stride',2)</span></pre></li> <li><span class="koboSpan" id="kobo.782.1">And finally, a third block </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">of layers:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.784.1">
    convolution2dLayer(3,32,'Padding','same')
    batchNormalizationLayer
    reluLayer</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.785.1">Now, we need an </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">FC layer:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.787.1">    fullyConnectedLayer(2)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.788.1">In an FC layer, the</span><a id="_idIndexMarker718"/><span class="koboSpan" id="kobo.789.1"> input is </span><a id="_idIndexMarker719"/><span class="koboSpan" id="kobo.790.1">multiplied by a weight matrix and then augmented with a bias vector. </span><span class="koboSpan" id="kobo.790.2">A bias vector is a set of values added to the weighted input of a neuron before applying the activation function. </span><span class="koboSpan" id="kobo.790.3">It plays a crucial role in adjusting neuron activation thresholds and enabling the network to represent complex relationships in data. </span><span class="koboSpan" id="kobo.790.4">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.791.1">Size</span></strong><span class="koboSpan" id="kobo.792.1"> parameter output specifies the output size; we are classifying a two-species pistachio, so the size is </span><strong class="source-inline"><span class="koboSpan" id="kobo.793.1">2</span></strong><span class="koboSpan" id="kobo.794.1">. </span><span class="koboSpan" id="kobo.794.2">This layer category replicates the configuration of layers typically present in a conventional ANN that employs an FC design. </span><span class="koboSpan" id="kobo.794.3">Within an FC layer, each neuron establishes connections with every neuron from the previous layer, engaging directly with their </span><span class="No-Break"><span class="koboSpan" id="kobo.795.1">respective activations.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.796.1">Then, we need a </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">softmax layer:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.798.1">softmaxLayer</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.799.1">softmaxLayer</span></strong><span class="koboSpan" id="kobo.800.1"> is a type of layer used in NNs, specifically designed to apply the </span><strong class="source-inline"><span class="koboSpan" id="kobo.801.1">softmax</span></strong><span class="koboSpan" id="kobo.802.1"> function to the input. </span><span class="koboSpan" id="kobo.802.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.803.1">softmax</span></strong><span class="koboSpan" id="kobo.804.1"> function is often used in classification tasks to convert raw scores or logits into a probability distribution over multiple classes. </span><span class="koboSpan" id="kobo.804.2">This layer is commonly utilized as the final layer in a NN for multi-class classification, where the output values are transformed into probabilities that sum up to </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1">1</span></strong><span class="koboSpan" id="kobo.806.1">, making it easier to interpret the </span><span class="No-Break"><span class="koboSpan" id="kobo.807.1">model’s predictions.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.808.1">Finally, to close the network, a classification layer </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">was applied:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.810.1">classificationLayer];</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.811.1">The classification</span><a id="_idIndexMarker720"/><span class="koboSpan" id="kobo.812.1"> layer computes cross-entropy loss for both standard and weighted classification tasks involving mutually exclusive classes. </span><span class="koboSpan" id="kobo.812.2">The layer automatically </span><a id="_idIndexMarker721"/><span class="koboSpan" id="kobo.813.1">determines the number of classes based on the dimension of the output from the </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">preceding layer.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.815.1">Right now, we have to set the option of </span><span class="No-Break"><span class="koboSpan" id="kobo.816.1">the CNN:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.817.1">options = trainingOptions('sgdm', ...
</span><span class="koboSpan" id="kobo.817.2">    'InitialLearnRate',0.01, ...
</span><span class="koboSpan" id="kobo.817.3">    'MaxEpochs',50, ...
</span><span class="koboSpan" id="kobo.817.4">    'Shuffle','every-epoch', ...
</span><span class="koboSpan" id="kobo.817.5">    'ValidationData',imdsValidation, ...
</span><span class="koboSpan" id="kobo.817.6">    'ValidationFrequency',30, ...
</span><span class="koboSpan" id="kobo.817.7">    'Verbose',false, ...
</span><span class="koboSpan" id="kobo.817.8">    'Plots','training-progress');</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.818.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.819.1">trainingOptions()</span></strong><span class="koboSpan" id="kobo.820.1"> function was used to set several options relevant to the training of the network. </span><span class="koboSpan" id="kobo.820.2">The following options </span><span class="No-Break"><span class="koboSpan" id="kobo.821.1">were set:</span></span></p><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.822.1">sdm</span></strong><span class="koboSpan" id="kobo.823.1">: Solver for</span><a id="_idIndexMarker722"/><span class="koboSpan" id="kobo.824.1"> training the NN; we have used the </span><strong class="bold"><span class="koboSpan" id="kobo.825.1">stochastic gradient descent with momentum</span></strong><span class="koboSpan" id="kobo.826.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.827.1">SGDM</span></strong><span class="koboSpan" id="kobo.828.1">) optimizer. </span><span class="koboSpan" id="kobo.828.2">The momentum optimizer is a modified version of the gradient descent algorithm. </span><span class="koboSpan" id="kobo.828.3">It is designed to accelerate the optimization process by incorporating momentum into the </span><span class="No-Break"><span class="koboSpan" id="kobo.829.1">weight updates.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.830.1">InitialLearnRate</span></strong><span class="koboSpan" id="kobo.831.1">: The initial learning rate employed in training is a positive numerical value. </span><span class="koboSpan" id="kobo.831.2">When the learning rate is excessively low, the training process might become prolonged. </span><span class="koboSpan" id="kobo.831.3">Conversely, if the learning rate is excessively high, the training could yield suboptimal results </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1">or diverge.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.833.1">MaxEpochs</span></strong><span class="koboSpan" id="kobo.834.1">: The maximum number of training epochs is defined as a positive integer. </span><span class="koboSpan" id="kobo.834.2">In the context of gradient descent optimization using mini-batches, an iteration signifies a single step aimed at minimizing the loss function. </span><span class="koboSpan" id="kobo.834.3">An epoch refers to the full iteration of the training algorithm across the entire </span><span class="No-Break"><span class="koboSpan" id="kobo.835.1">training dataset.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.836.1">Shuffle</span></strong><span class="koboSpan" id="kobo.837.1">: Option for data shuffling. </span><span class="koboSpan" id="kobo.837.2">For this, we employed the practice of shuffling the training data before every training epoch, and similarly, shuffling the validation data before each validation of </span><span class="No-Break"><span class="koboSpan" id="kobo.838.1">the NN.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.839.1">ValidationData</span></strong><span class="koboSpan" id="kobo.840.1">: The validation data to be utilized during training is defined as either a datastore, a table, or an array of cells containing the predictors and </span><span class="No-Break"><span class="koboSpan" id="kobo.841.1">validation responses.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.842.1">ValidationFrequency</span></strong><span class="koboSpan" id="kobo.843.1">: The NN’s validation rate is expressed as a positive integer, representing the count of interactions. </span><strong class="source-inline"><span class="koboSpan" id="kobo.844.1">ValidationFrequency</span></strong><span class="koboSpan" id="kobo.845.1"> signifies the interval, in terms of iterations, at which validation metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.846.1">are assessed.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.847.1">Verbose</span></strong><span class="koboSpan" id="kobo.848.1">: For displaying training </span><span class="No-Break"><span class="koboSpan" id="kobo.849.1">progress information.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.850.1">Plots</span></strong><span class="koboSpan" id="kobo.851.1">: Upon configuring the </span><strong class="source-inline"><span class="koboSpan" id="kobo.852.1">training-progress</span></strong><span class="koboSpan" id="kobo.853.1"> training option in </span><strong class="source-inline"><span class="koboSpan" id="kobo.854.1">trainingOptions</span></strong><span class="koboSpan" id="kobo.855.1"> and initiating the network training using </span><strong class="source-inline"><span class="koboSpan" id="kobo.856.1">trainNetwork()</span></strong><span class="koboSpan" id="kobo.857.1">, a plot is generated. </span><span class="koboSpan" id="kobo.857.2">This plot showcases training metrics for each iteration. </span><span class="koboSpan" id="kobo.857.3">Each iteration involves an estimation of the gradient and an adjustment of the network parameters. </span><span class="koboSpan" id="kobo.857.4">If you provide validation data within </span><strong class="source-inline"><span class="koboSpan" id="kobo.858.1">trainingOptions</span></strong><span class="koboSpan" id="kobo.859.1">, the plot will additionally present validation metrics whenever the network undergoes validation by the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.860.1">trainNetwork</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.861.1"> process.</span></span></li></ul></li> <li><span class="koboSpan" id="kobo.862.1">Finally, we have to train </span><span class="No-Break"><span class="koboSpan" id="kobo.863.1">the network:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.864.1">
Cnnet = trainNetwork(DataTrain,layers,options);</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.865.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.866.1">trainNetwork()</span></strong><span class="koboSpan" id="kobo.867.1"> function facilitates the training of DNNs. </span><span class="koboSpan" id="kobo.867.2">This training can be executed on either a CPU or a GPU. </span><span class="koboSpan" id="kobo.867.3">For tasks such as image classification and image regression, it’s possible to train a single NN concurrently using multiple GPUs or a local/remote parallel pool. </span><span class="koboSpan" id="kobo.867.4">However, the employment of GPUs or parallel processing necessitates the presence of Parallel Computing Toolbox. </span><span class="koboSpan" id="kobo.867.5">Additionally, utilizing a GPU for DL mandates the availability of a compatible </span><span class="No-Break"><span class="koboSpan" id="kobo.868.1">GPU device.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.869.1">The following plot was returned to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.870.1">trainNetwork()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.871.1"> function:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer062">
<span class="koboSpan" id="kobo.872.1"><img alt="Figure 6.4 – Training process" src="image/B21156_06_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.873.1">Figure 6.4 – Training process</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.874.1">The plot in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.875.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.876.1">.4</span></em><span class="koboSpan" id="kobo.877.1"> will be progressively updated throughout the training process. </span><span class="koboSpan" id="kobo.877.2">In this way, it will be possible to check how the algorithm manages to adjust the weights to reach convergence. </span><span class="koboSpan" id="kobo.877.3">The plot in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.878.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.879.1">.4</span></em><span class="koboSpan" id="kobo.880.1"> consists of </span><span class="No-Break"><span class="koboSpan" id="kobo.881.1">three curves:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.882.1">Training error</span></strong><span class="koboSpan" id="kobo.883.1">: This curve shows the average error of the network on the training data as a function of the number of training epochs. </span><span class="koboSpan" id="kobo.883.2">Epochs are the number of times the network is trained on the entire training dataset. </span><span class="koboSpan" id="kobo.883.3">A low training error indicates that the network is learning well from the </span><span class="No-Break"><span class="koboSpan" id="kobo.884.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.885.1">Validation error</span></strong><span class="koboSpan" id="kobo.886.1">: This curve shows the average error of the network on the validation data as a function of the number of training epochs. </span><span class="koboSpan" id="kobo.886.2">Validation data is data that the network was not trained on, and it is used to evaluate how well the network generalizes to unseen data. </span><span class="koboSpan" id="kobo.886.3">A low validation error indicates that the network is learning to generalize well to </span><span class="No-Break"><span class="koboSpan" id="kobo.887.1">new data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.888.1">Network weights</span></strong><span class="koboSpan" id="kobo.889.1">: This curve shows the magnitude of the weights of the network as a function of the number of training epochs. </span><span class="koboSpan" id="kobo.889.2">The weights are the parameters that the network learns from the training data. </span><span class="koboSpan" id="kobo.889.3">A stable weight curve indicates that the network is not overfitting to the </span><span class="No-Break"><span class="koboSpan" id="kobo.890.1">training data.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.891.1">After seeing how to train a CNN in MATLAB, we now need to learn how to interpret the results and use the validation </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1">metrics correctly.</span></span></p>
<h1 id="_idParaDest-134"><a id="_idTextAnchor138"/><span class="koboSpan" id="kobo.893.1">Exploring the model’s results</span></h1>
<p><span class="koboSpan" id="kobo.894.1">Evaluating results is an essential part of any CNN implementation process. </span><span class="koboSpan" id="kobo.894.2">This, of course, is true for any algorithm based on ML. </span><span class="koboSpan" id="kobo.894.3">Evaluation metrics are quantitative measures used to assess the performance and quality of a model, algorithm, or system in various tasks, such as ML, data analysis, and optimization. </span><span class="koboSpan" id="kobo.894.4">These metrics provide a way to objectively quantify how well a model is performing and to compare different models </span><span class="No-Break"><span class="koboSpan" id="kobo.895.1">or approaches.</span></span></p>
<p><span class="koboSpan" id="kobo.896.1">The type of metric to adopt obviously depends on the type of algorithm we are implementing; in the previous section, we implemented a CNN for the classification of the pistachio species. </span><span class="koboSpan" id="kobo.896.2">So, let’s take a look at the metrics available for this type </span><span class="No-Break"><span class="koboSpan" id="kobo.897.1">of algorithm.</span></span></p>
<p><span class="koboSpan" id="kobo.898.1">For a classification task, we can use the </span><span class="No-Break"><span class="koboSpan" id="kobo.899.1">following metrics:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.900.1">Accuracy</span></strong><span class="koboSpan" id="kobo.901.1">: The proportion of correctly classified instances out of the </span><span class="No-Break"><span class="koboSpan" id="kobo.902.1">total instances</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.903.1">Precision</span></strong><span class="koboSpan" id="kobo.904.1">: The ratio of true positive predictions to the total number of positive predictions, indicating the accuracy of </span><span class="No-Break"><span class="koboSpan" id="kobo.905.1">positive predictions</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.906.1">Recall (Sensitivity)</span></strong><span class="koboSpan" id="kobo.907.1">: The ratio of true positive predictions to the total number of actual positives, indicating the model’s ability to identify </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">positive cases</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.909.1">F1-score</span></strong><span class="koboSpan" id="kobo.910.1">: The harmonic mean of precision and recall, providing a balance </span><span class="No-Break"><span class="koboSpan" id="kobo.911.1">between them</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.912.1">Receiver Operating Characteristic (ROC) curve</span></strong><span class="koboSpan" id="kobo.913.1">: A graph showing the trade-off between true positive rate and false positive rate at </span><span class="No-Break"><span class="koboSpan" id="kobo.914.1">various thresholds</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.915.1">Area Under the ROC Curve (AUC-ROC)</span></strong><span class="koboSpan" id="kobo.916.1">: A metric that quantifies the overall performance of a binary </span><span class="No-Break"><span class="koboSpan" id="kobo.917.1">classification model</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.918.1">Let us try to deepen the concept of accuracy. </span><span class="koboSpan" id="kobo.918.2">Accuracy is a fundamental evaluation metric used in classification tasks to measure the proportion of correctly predicted instances out of the total instances in a dataset. </span><span class="koboSpan" id="kobo.918.3">It provides an overall view of how well a classification model is performing. </span><span class="koboSpan" id="kobo.918.4">The accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.919.1">formula is:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.920.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.921.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.922.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.923.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.924.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.925.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.926.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.927.1">y</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.928.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.929.1"> </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.930.1">N</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.931.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.932.1">m</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.933.1">b</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.934.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.935.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.936.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.937.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.938.1">C</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.939.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.940.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.941.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.942.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.943.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.944.1">t</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.945.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.946.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.947.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.948.1">d</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.949.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.950.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.951.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.952.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.953.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.954.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.955.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.956.1">  </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.957.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.958.1">_____________________</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.959.1">  </span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.960.1">T</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.961.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.962.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.963.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.964.1">l</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.965.1">N</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.966.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.967.1">m</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.968.1">b</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.969.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.970.1">r</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.971.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.972.1">f</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.973.1">P</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.974.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.975.1">e</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.976.1">d</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.977.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.978.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.979.1">t</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.980.1">i</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.981.1">o</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.982.1">n</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.983.1">s</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.984.1"> </span></span></p>
<p><span class="koboSpan" id="kobo.985.1">For example, if you have a binary classification problem with 100 instances, and your model correctly predicts 90 of them, the accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.986.1">would be:</span></span></p>
<p><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.987.1">A</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.988.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.989.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.990.1">u</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.991.1">r</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.992.1">a</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.993.1">c</span></span><span class="_-----MathTools-_Math_Variable_v-normal"><span class="koboSpan" id="kobo.994.1">y</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.995.1">=</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.996.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.997.1">90</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.998.1"> </span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.999.1">_</span></span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1000.1"> </span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1001.1">100</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1002.1"> </span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1003.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1004.1">0.90</span></span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1005.1">,</span></span><span class="_-----MathTools-_Math_Space"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1006.1">o</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1007.1">r</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Space"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1008.1">90</span></span></span><span class="No-Break"><span class="_-----MathTools-_Math_Symbol"><span class="koboSpan" id="kobo.1009.1">%</span></span></span></p>
<p><span class="koboSpan" id="kobo.1010.1">While accuracy is a simple and intuitive metric, it might not be suitable in cases of imbalanced classes, where one class significantly outnumbers the other. </span><span class="koboSpan" id="kobo.1010.2">In such situations, a high accuracy could be misleading if the model is performing well on the dominant class but poorly on the minority class. </span><span class="koboSpan" id="kobo.1010.3">In these cases, precision, recall, F1-score, and other metrics might provide a more accurate representation of the model’s performance. </span><span class="koboSpan" id="kobo.1010.4">Also, in this case, it is important to point out that when the dataset is not sufficiently balanced between the classes, the classification result may not be applied to all </span><span class="No-Break"><span class="koboSpan" id="kobo.1011.1">the classes.</span></span></p>
<p><span class="koboSpan" id="kobo.1012.1">So, let’s try to apply this metric to the case study analyzed in the previous section for the classification of the pistachio species. </span><span class="koboSpan" id="kobo.1012.2">We have already trained the network, and at this point, we can use it to make classifications using data never seen before by </span><span class="No-Break"><span class="koboSpan" id="kobo.1013.1">the algorithm:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1014.1">To carry out the validation, we start by classifying the collected images in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1015.1">DataValidation</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1016.1"> subset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1017.1">
CNNPredLabel = classify(CNnet,DataValidation);</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1018.1">This function employs a trained DNN to classify data. </span><span class="koboSpan" id="kobo.1018.2">Predictions can be generated using the trained network on either a CPU or GPU. </span><span class="koboSpan" id="kobo.1018.3">Utilizing a GPU necessitates both a </span><em class="italic"><span class="koboSpan" id="kobo.1019.1">Parallel Computing Toolbox™ license</span></em><span class="koboSpan" id="kobo.1020.1"> and a compatible GPU device. </span><span class="koboSpan" id="kobo.1020.2">Two parameters are passed: the CNN trained (</span><strong class="source-inline"><span class="koboSpan" id="kobo.1021.1">CNnet</span></strong><span class="koboSpan" id="kobo.1022.1">) and the input </span><span class="No-Break"><span class="koboSpan" id="kobo.1023.1">dataset (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1024.1">DataValidation</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1025.1">).</span></span></p></li> <li><span class="koboSpan" id="kobo.1026.1">After that, we must extract the label of the input data; this information is contained in the image datastore. </span><span class="koboSpan" id="kobo.1026.2">We have only to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1027.1">labels</span></strong><span class="koboSpan" id="kobo.1028.1"> parameter, </span><span class="No-Break"><span class="koboSpan" id="kobo.1029.1">as follows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1030.1">
DataValLabel = DataValidation.Labels;</span></pre></li> <li><span class="koboSpan" id="kobo.1031.1">Let’s calculate the accuracy using the formula </span><span class="No-Break"><span class="koboSpan" id="kobo.1032.1">previously introduced:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1033.1">
ACC = sum(CNNPredLabel == DataValLabel)/numel(DataValLabel)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1034.1">The following result </span><span class="No-Break"><span class="koboSpan" id="kobo.1035.1">is returned:</span></span></p><pre class="source-code"><span class="koboSpan" id="kobo.1036.1">ACC =
    0.8695</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1037.1">An accuracy of 86.95% was obtained; this tells us that the CNN-based algorithm can correctly classify 86.95% of the pistachio images we passed it. </span><span class="koboSpan" id="kobo.1037.2">We also recall that these images had never been used by the network </span><span class="No-Break"><span class="koboSpan" id="kobo.1038.1">training algorithm.</span></span></p></li> <li><span class="koboSpan" id="kobo.1039.1">To better understand the performance of the model, we can draw a confusion matrix. </span><span class="koboSpan" id="kobo.1039.2">A confusion matrix is a tabular representation used in the field of ML and statistics to evaluate the performance of a classification model. </span><span class="koboSpan" id="kobo.1039.3">It provides a comprehensive view of how well the model’s predictions align with the actual classes in </span><span class="No-Break"><span class="koboSpan" id="kobo.1040.1">a dataset.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.1041.1">A confusion matrix is organized into </span><span class="No-Break"><span class="koboSpan" id="kobo.1042.1">four categories:</span></span></p><ul><li><strong class="bold"><span class="koboSpan" id="kobo.1043.1">True Positives</span></strong><span class="koboSpan" id="kobo.1044.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1045.1">TP</span></strong><span class="koboSpan" id="kobo.1046.1">): Instances that are correctly predicted </span><span class="No-Break"><span class="koboSpan" id="kobo.1047.1">as positive</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1048.1">True Negatives</span></strong><span class="koboSpan" id="kobo.1049.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1050.1">TN</span></strong><span class="koboSpan" id="kobo.1051.1">): Instances that are correctly predicted </span><span class="No-Break"><span class="koboSpan" id="kobo.1052.1">as negative</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1053.1">False Positives</span></strong><span class="koboSpan" id="kobo.1054.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1055.1">FP</span></strong><span class="koboSpan" id="kobo.1056.1">): Instances that are incorrectly predicted as positive when they are actually negative (</span><strong class="bold"><span class="koboSpan" id="kobo.1057.1">Type </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1058.1">I error</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1059.1">)</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.1060.1">False Negatives</span></strong><span class="koboSpan" id="kobo.1061.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1062.1">FN</span></strong><span class="koboSpan" id="kobo.1063.1">): Instances that are incorrectly predicted as negative when they are actually positive (</span><strong class="bold"><span class="koboSpan" id="kobo.1064.1">Type </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1065.1">II error</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1066.1">)</span></span></li></ul><p class="list-inset"><span class="koboSpan" id="kobo.1067.1">The matrix format looks </span><span class="No-Break"><span class="koboSpan" id="kobo.1068.1">like this:</span></span></p><table class="T---Table _idGenTablePara-1" id="table001-1"><colgroup><col/><col/><col/></colgroup><tbody><tr class="T---Table"><td class="T---Table T---Body T---Body"/><td class="T---Table T---Body T---Body"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1069.1">Predicted Positive</span></strong></span></p></td><td class="T---Table T---Body T---Body"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1070.1">Predicted Negative</span></strong></span></p></td></tr><tr class="T---Table"><td class="T---Table T---Body T---Body"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1071.1">Actual Positive</span></strong></span></p></td><td class="T---Table T---Body T---Body"><p><span class="No-Break"><span class="koboSpan" id="kobo.1072.1">True Positives</span></span></p></td><td class="T---Table T---Body T---Body"><p><span class="No-Break"><span class="koboSpan" id="kobo.1073.1">False Negatives</span></span></p></td></tr><tr class="T---Table"><td class="T---Table T---Body T---Body"><p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1074.1">Actual Negative</span></strong></span></p></td><td class="T---Table T---Body T---Body"><p><span class="No-Break"><span class="koboSpan" id="kobo.1075.1">False Positives</span></span></p></td><td class="T---Table T---Body T---Body"><p><span class="No-Break"><span class="koboSpan" id="kobo.1076.1">True Negatives</span></span></p></td></tr></tbody></table></li>
</ol>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1077.1">Figure 6.5 – Confusion matrix terms’ meaning</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1078.1">In MATLAB, we can use the </span><span class="No-Break"><span class="koboSpan" id="kobo.1079.1">following command:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1080.1">
ConfMatrix=confusionchart((DataValLabel,CNNPredLabel))</span></pre> <p class="list-inset"><span class="koboSpan" id="kobo.1081.1">This function generates a confusion matrix chart using true labels stored in </span><strong class="source-inline"><span class="koboSpan" id="kobo.1082.1">DataValLabel</span></strong><span class="koboSpan" id="kobo.1083.1"> and predicted labels stored in </span><strong class="source-inline"><span class="koboSpan" id="kobo.1084.1">CNNPredLabel</span></strong><span class="koboSpan" id="kobo.1085.1">. </span><span class="koboSpan" id="kobo.1085.2">It then returns a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1086.1">ConfusionMatrixChart</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1087.1"> object.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1088.1">The following results </span><span class="No-Break"><span class="koboSpan" id="kobo.1089.1">are printed:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1090.1">
ConfMatrix =
  ConfusionMatrixChart with properties:
    NormalizedValues: [2×2 double]
         ClassLabels: [2×1 categorical]</span></pre> <p class="list-inset"><span class="koboSpan" id="kobo.1091.1">The following output </span><span class="No-Break"><span class="koboSpan" id="kobo.1092.1">was returned:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<span class="koboSpan" id="kobo.1093.1"><img alt="Figure 6.6 – Confusion matrix" src="image/B21156_06_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1094.1">Figure 6.6 – Confusion matrix</span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1095.1">In that matrix, rows correspond to the true classes, and columns correspond to the predicted classes. </span><span class="koboSpan" id="kobo.1095.2">Cells along the diagonal represent correctly classified instances, while off-diagonal cells represent instances that were </span><span class="No-Break"><span class="koboSpan" id="kobo.1096.1">classified incorrectly.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1097.1">We can also show the accuracy calculation from the confusion matrix table </span><span class="No-Break"><span class="koboSpan" id="kobo.1098.1">as this:</span></span></p>
<p class="list-inset"><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1099.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1100.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1101.1">P</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1102.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1103.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1104.1">N</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1105.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1106.1">/</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1107.1">(</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1108.1">T</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1109.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1110.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1111.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1112.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1113.1">v</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1114.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1115.1">l</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1116.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1117.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1118.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1119.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1120.1">i</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1121.1">o</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1122.1">n</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1123.1">d</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1124.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1125.1">t</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1126.1">a</span></span><span class="_-----MathTools-_Math_Variable"><span class="koboSpan" id="kobo.1127.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1128.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"><span class="koboSpan" id="kobo.1129.1">(</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1130.1">204</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1131.1">+</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1132.1">169</span></span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1133.1">)</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1134.1">/</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1135.1">916</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator"><span class="koboSpan" id="kobo.1136.1">=</span></span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number"><span class="koboSpan" id="kobo.1137.1">0.8695</span></span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.1138.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1139.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1140.1">.6</span></em><span class="koboSpan" id="kobo.1141.1">, we can notice that false negatives are greater than false positives. </span><span class="koboSpan" id="kobo.1141.2">In some applications, false negatives are more serious than false positives. </span><span class="koboSpan" id="kobo.1141.3">For example, in the context of medical diagnosis, it is generally more important to avoid missing a disease than to incorrectly flag a healthy person as having a disease. </span><span class="koboSpan" id="kobo.1141.4">However, in other applications, false positives may be more serious. </span><span class="koboSpan" id="kobo.1141.5">For example, in the context of fraud detection, it is generally more important to avoid incorrectly accusing an innocent person of fraud than to miss a </span><span class="No-Break"><span class="koboSpan" id="kobo.1142.1">fraudulent transaction.</span></span></p>
<p><span class="koboSpan" id="kobo.1143.1">After seeing how to implement a CNN and correctly interpret the results, we can now explore some of the many DL </span><span class="No-Break"><span class="koboSpan" id="kobo.1144.1">architectures available.</span></span></p>
<h1 id="_idParaDest-135"><a id="_idTextAnchor139"/><span class="koboSpan" id="kobo.1145.1">Discovering DL architectures</span></h1>
<p><span class="koboSpan" id="kobo.1146.1">DL models are </span><a id="_idIndexMarker723"/><span class="koboSpan" id="kobo.1147.1">essentially multi-layered NNs, which refers to NNs that comprise multiple hidden layers (at least two) structured hierarchically. </span><span class="koboSpan" id="kobo.1147.2">This hierarchical arrangement facilitates the sharing and reuse of information. </span><span class="koboSpan" id="kobo.1147.3">Across this hierarchy, one can pinpoint features while disregarding unnecessary intricacies, thereby enhancing invariance. </span><span class="koboSpan" id="kobo.1147.4">Within the realm of multi-level ML, deeper tiers acquire inputs from the outputs of prior layers and execute more complex transformations and abstractions. </span><span class="koboSpan" id="kobo.1147.5">This layering approach to learning draws inspiration from the information processing and learning methods of mammalian brains, enabling them to react to </span><span class="No-Break"><span class="koboSpan" id="kobo.1148.1">external stimuli.</span></span></p>
<p><span class="koboSpan" id="kobo.1149.1">DL architectures </span><a id="_idIndexMarker724"/><span class="koboSpan" id="kobo.1150.1">are the fundamental blueprints that underlie the construction of DNNs, enabling them to effectively learn and represent complex patterns and features from data. </span><span class="koboSpan" id="kobo.1150.2">These architectures define the layout, connections, and flow of information within the network, determining how data is transformed and features are extracted at various layers. </span><span class="koboSpan" id="kobo.1150.3">Several notable DL architectures have been developed over the years, each designed to tackle specific types of tasks and data. </span><span class="koboSpan" id="kobo.1150.4">In the following sections, we will address the </span><span class="No-Break"><span class="koboSpan" id="kobo.1151.1">most used.</span></span></p>
<h2 id="_idParaDest-136"><a id="_idTextAnchor140"/><span class="koboSpan" id="kobo.1152.1">Understanding RNNs</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.1153.1">Feedforward NNs</span></strong><span class="koboSpan" id="kobo.1154.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1155.1">FNNs</span></strong><span class="koboSpan" id="kobo.1156.1">) operate </span><a id="_idIndexMarker725"/><span class="koboSpan" id="kobo.1157.1">by providing input data to the </span><a id="_idIndexMarker726"/><span class="koboSpan" id="kobo.1158.1">network that is then transformed into output. </span><span class="koboSpan" id="kobo.1158.2">In SL scenarios, the output typically represents a label that corresponds to the input. </span><span class="koboSpan" id="kobo.1158.3">These algorithms essentially link raw data with specific categories by recognizing underlying patterns. </span><span class="koboSpan" id="kobo.1158.4">In contrast, recurrent networks incorporate not only the current input data being fed into the network but also information they have accumulated </span><span class="No-Break"><span class="koboSpan" id="kobo.1159.1">over time.</span></span></p>
<p><span class="koboSpan" id="kobo.1160.1">An RNN embodies</span><a id="_idIndexMarker727"/><span class="koboSpan" id="kobo.1161.1"> a neural model with bidirectional information flow. </span><span class="koboSpan" id="kobo.1161.2">Unlike feedforward networks where signal propagation only moves unidirectionally from inputs to outputs, RNNs exhibit a different behavior. </span><span class="koboSpan" id="kobo.1161.3">In RNNs, signal propagation can traverse between neural layers, from a prior layer to a subsequent one, among neurons within the same layer, or even from a neuron to itself. </span><span class="koboSpan" id="kobo.1161.4">A decision made by an RNN at a given moment influences its subsequent decisions. </span><span class="koboSpan" id="kobo.1161.5">Consequently, RNNs possess two sources of input—the present and the recent past—combining to determine responses to new data, mirroring how people make decisions in </span><span class="No-Break"><span class="koboSpan" id="kobo.1162.1">everyday life.</span></span></p>
<p><span class="koboSpan" id="kobo.1163.1">The key distinction between recurrent and feedforward networks lies in the </span><strong class="bold"><span class="koboSpan" id="kobo.1164.1">feedback loop</span></strong><span class="koboSpan" id="kobo.1165.1"> that </span><a id="_idIndexMarker728"/><span class="koboSpan" id="kobo.1166.1">connects RNNs to their past decisions, momentarily utilizing their output as input. </span><span class="koboSpan" id="kobo.1166.2">This aspect underscores the memory aspect of RNNs. </span><span class="koboSpan" id="kobo.1166.3">The inclusion of memory in NNs serves a purpose: there is intrinsic information in the sequence itself, and RNNs leverage this information to perform tasks that feedforward networks are unable </span><span class="No-Break"><span class="koboSpan" id="kobo.1167.1">to accomplish.</span></span></p>
<p><span class="koboSpan" id="kobo.1168.1">Access to this memory occurs based on content rather than specific addresses or locations. </span><span class="koboSpan" id="kobo.1168.2">One approach entails considering memory content as the activation patterns on nodes within an </span><a id="_idIndexMarker729"/><span class="koboSpan" id="kobo.1169.1">RNN. </span><span class="koboSpan" id="kobo.1169.2">The concept involves initiating the network with an activation pattern that partially or noisily represents the desired memory content, allowing the network to </span><a id="_idIndexMarker730"/><span class="koboSpan" id="kobo.1170.1">stabilize around the required content. </span><span class="koboSpan" id="kobo.1170.2">An RNN belongs to the category of NNs where there exists at least one feedback connection between neurons, forming a directed cycle within the </span><span class="No-Break"><span class="koboSpan" id="kobo.1171.1">network’s structure.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1172.1">Figure 6</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1173.1">.7</span></em><span class="koboSpan" id="kobo.1174.1"> illustrates a standard RNN with connections linking the hidden layer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.1175.1">output layer:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer064">
<span class="koboSpan" id="kobo.1176.1"><img alt="Figure 6.7 – RNN architecture" src="image/B21156_06_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1177.1">Figure 6.7 – RNN architecture</span></p>
<p><span class="koboSpan" id="kobo.1178.1">In the preceding</span><a id="_idIndexMarker731"/><span class="koboSpan" id="kobo.1179.1"> diagram depicting a recurrent network, the hidden layer’s weights are defined using both the input and output layers. </span><span class="koboSpan" id="kobo.1179.2">Essentially, we can view RNNs as a variation of ANNs, with differences in the number of hidden layers and the flow of data patterns. </span><span class="koboSpan" id="kobo.1179.3">RNNs exhibit distinct data flow patterns due to the cyclic connections between neurons. </span><span class="koboSpan" id="kobo.1179.4">Unlike feedforward networks, RNNs can leverage internal memory during their computations. </span><span class="koboSpan" id="kobo.1179.5">RNNs belong to the class of ANNs that incorporate connections between hidden layers, which are carried forward across time to facilitate the learning </span><span class="No-Break"><span class="koboSpan" id="kobo.1180.1">of sequences.</span></span></p>
<p><span class="koboSpan" id="kobo.1181.1">RNNs derive their strength and effectiveness from their unique mechanism of storing and flowing data across varying time intervals. </span><span class="koboSpan" id="kobo.1181.2">These networks are adept at identifying patterns in data sequences, making them valuable tools for prediction and forecasting. </span><span class="koboSpan" id="kobo.1181.3">Their versatility spans multiple domains, encompassing text, images, speech, and time series data. </span><span class="koboSpan" id="kobo.1181.4">Positioned</span><a id="_idIndexMarker732"/><span class="koboSpan" id="kobo.1182.1"> among the potent members of the ANN family, RNNs embody the intricacies of the biological brain, encompassing both memory and </span><span class="No-Break"><span class="koboSpan" id="kobo.1183.1">computational capabilities.</span></span></p>
<h2 id="_idParaDest-137"><a id="_idTextAnchor141"/><span class="koboSpan" id="kobo.1184.1">Analyzing LSTM networks</span></h2>
<p><span class="koboSpan" id="kobo.1185.1">A specific </span><a id="_idIndexMarker733"/><span class="koboSpan" id="kobo.1186.1">form of RNN is the LSTM network, originally conceptualized by Hochreiter and Schmidhuber in 1997. </span><span class="koboSpan" id="kobo.1186.2">This architecture has garnered renewed attention within the realm of DL due to its immunity to the vanishing gradient problem and its proven excellence in practical results </span><span class="No-Break"><span class="koboSpan" id="kobo.1187.1">and performance.</span></span></p>
<p><span class="koboSpan" id="kobo.1188.1">The vanishing gradient problem poses challenges in training ANNs through gradient-based learning techniques. </span><span class="koboSpan" id="kobo.1188.2">Methods such as backpropagation adjust weights based on error gradients. </span><span class="koboSpan" id="kobo.1188.3">However, these gradients can diminish exponentially as they propagate deeper into the network, sometimes rendering them exceedingly small and preventing weight adjustments. </span><span class="koboSpan" id="kobo.1188.4">In extreme cases, this can halt network </span><span class="No-Break"><span class="koboSpan" id="kobo.1189.1">training altogether.</span></span></p>
<p><span class="koboSpan" id="kobo.1190.1">LSTM networks offer an ideal solution for predicting and classifying sequential data, outperforming numerous traditional </span><a id="_idIndexMarker734"/><span class="koboSpan" id="kobo.1191.1">ML methodologies. </span><span class="koboSpan" id="kobo.1191.2">A significant example is Google’s transition in 2012 from </span><strong class="bold"><span class="koboSpan" id="kobo.1192.1">hidden Markov models</span></strong><span class="koboSpan" id="kobo.1193.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1194.1">HMMs</span></strong><span class="koboSpan" id="kobo.1195.1">) to DNNs for voice recognition. </span><span class="koboSpan" id="kobo.1195.2">By 2015, Google had adopted LSTM-based RNNs </span><a id="_idIndexMarker735"/><span class="koboSpan" id="kobo.1196.1">combined with </span><strong class="bold"><span class="koboSpan" id="kobo.1197.1">Connectionist Temporal Classification</span></strong><span class="koboSpan" id="kobo.1198.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1199.1">CTC</span></strong><span class="koboSpan" id="kobo.1200.1">) for improved </span><span class="No-Break"><span class="koboSpan" id="kobo.1201.1">voice recognition.</span></span></p>
<p><span class="koboSpan" id="kobo.1202.1">CTC serves as an output and scoring function for training RNNs. </span><span class="koboSpan" id="kobo.1202.2">An LSTM network’s strength lies in its ability to capture long-term dependencies among data, enhancing its utility in contexts such as speech recognition where understanding sentence context </span><span class="No-Break"><span class="koboSpan" id="kobo.1203.1">is crucial.</span></span></p>
<p><span class="koboSpan" id="kobo.1204.1">An LSTM network comprises interconnected LSTM cells, each featuring input, output, and </span><strong class="bold"><span class="koboSpan" id="kobo.1205.1">forget gates</span></strong><span class="koboSpan" id="kobo.1206.1">. </span><span class="koboSpan" id="kobo.1206.2">These</span><a id="_idIndexMarker736"/><span class="koboSpan" id="kobo.1207.1"> gates facilitate writing, reading, and resetting functions on the cell memory. </span><span class="koboSpan" id="kobo.1207.2">Rather than binary, the gates are analogical, typically managed by sigmoid activation functions that map values to a range (0, 1). </span><span class="koboSpan" id="kobo.1207.3">This multiplicative nature empowers the cells to retain information over extended periods. </span><span class="koboSpan" id="kobo.1207.4">The input gate controls whether the current state is combined with incoming input, while the forget gate resets the cell’s state when its value drops to zero. </span><span class="koboSpan" id="kobo.1207.5">The output gate determines whether the cell’s content is retrieved or not, influencing the network’s </span><span class="No-Break"><span class="koboSpan" id="kobo.1208.1">overall output.</span></span></p>
<p><span class="koboSpan" id="kobo.1209.1">The following diagram explains an </span><span class="No-Break"><span class="koboSpan" id="kobo.1210.1">LSTM unit:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer065">
<span class="koboSpan" id="kobo.1211.1"><img alt="Figure 6.8 – LSTM architecture" src="image/B21156_06_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1212.1">Figure 6.8 – LSTM architecture</span></p>
<p><span class="koboSpan" id="kobo.1213.1">NN-based</span><a id="_idIndexMarker737"/><span class="koboSpan" id="kobo.1214.1"> approaches possess significant potency, enabling the extraction of inherent data characteristics and relationships. </span><span class="koboSpan" id="kobo.1214.2">Notably, LSTM networks have demonstrated impressive real-world efficacy, boasting remarkable recognition rates. </span><span class="koboSpan" id="kobo.1214.3">However, one drawback is that NNs function</span><a id="_idIndexMarker738"/><span class="koboSpan" id="kobo.1215.1"> as </span><strong class="bold"><span class="koboSpan" id="kobo.1216.1">black-box models</span></strong><span class="koboSpan" id="kobo.1217.1">. </span><span class="koboSpan" id="kobo.1217.2">This means their behavior lacks predictability, and it’s impossible to decipher the underlying logic by which they </span><span class="No-Break"><span class="koboSpan" id="kobo.1218.1">process data.</span></span></p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor142"/><span class="koboSpan" id="kobo.1219.1">Introducing transformer models</span></h2>
<p><strong class="bold"><span class="koboSpan" id="kobo.1220.1">Transformer models</span></strong><span class="koboSpan" id="kobo.1221.1"> are a</span><a id="_idIndexMarker739"/><span class="koboSpan" id="kobo.1222.1"> revolutionary architecture in the</span><a id="_idIndexMarker740"/><span class="koboSpan" id="kobo.1223.1"> field of NLP and beyond. </span><span class="koboSpan" id="kobo.1223.2">Introduced in 2017, transformers have since become a foundational framework for a wide range of tasks, from language translation to image generation. </span><span class="koboSpan" id="kobo.1223.3">The key innovation in transformer models is the self-attention mechanism. </span><span class="koboSpan" id="kobo.1223.4">Traditional models process sequences in a linear manner, which limits their ability to capture long-range dependencies. </span><span class="koboSpan" id="kobo.1223.5">In contrast, transformers employ self-attention to weigh the importance of different words in a sequence with respect to each other, enabling them to consider global context </span><span class="No-Break"><span class="koboSpan" id="kobo.1224.1">and dependencies.</span></span></p>
<p><span class="koboSpan" id="kobo.1225.1">The transformer </span><a id="_idIndexMarker741"/><span class="koboSpan" id="kobo.1226.1">architecture consists of an encoder and a decoder, each comprising multiple layers. </span><span class="koboSpan" id="kobo.1226.2">The encoder processes the input data, while the decoder generates the </span><a id="_idIndexMarker742"/><span class="koboSpan" id="kobo.1227.1">output. </span><strong class="bold"><span class="koboSpan" id="kobo.1228.1">Attention mechanisms</span></strong><span class="koboSpan" id="kobo.1229.1"> within these layers allow the model to focus on relevant parts of the input or </span><span class="No-Break"><span class="koboSpan" id="kobo.1230.1">output sequence.</span></span></p>
<p><span class="koboSpan" id="kobo.1231.1">Transformers can be </span><a id="_idIndexMarker743"/><span class="koboSpan" id="kobo.1232.1">applied with success in </span><span class="No-Break"><span class="koboSpan" id="kobo.1233.1">various applications:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1234.1">Machine translation</span></strong><span class="koboSpan" id="kobo.1235.1">: Models such as </span><em class="italic"><span class="koboSpan" id="kobo.1236.1">transformers</span></em><span class="koboSpan" id="kobo.1237.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.1238.1">BERT</span></em><span class="koboSpan" id="kobo.1239.1"> have set new benchmarks in machine translation, allowing for more accurate and contextually </span><span class="No-Break"><span class="koboSpan" id="kobo.1240.1">meaningful translations</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1241.1">Language understanding</span></strong><span class="koboSpan" id="kobo.1242.1">: BERT captures bidirectional context, significantly improving language </span><span class="No-Break"><span class="koboSpan" id="kobo.1243.1">understanding tasks</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1244.1">Text generation</span></strong><span class="koboSpan" id="kobo.1245.1">: </span><strong class="bold"><span class="koboSpan" id="kobo.1246.1">Generative Pre-trained Transformer</span></strong><span class="koboSpan" id="kobo.1247.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1248.1">GPT</span></strong><span class="koboSpan" id="kobo.1249.1">) models generate coherent and contextually relevant text, finding applications in chatbots, content generation, </span><span class="No-Break"><span class="koboSpan" id="kobo.1250.1">and more</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1251.1">Image generation</span></strong><span class="koboSpan" id="kobo.1252.1">: </span><strong class="bold"><span class="koboSpan" id="kobo.1253.1">Vision Transformer</span></strong><span class="koboSpan" id="kobo.1254.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1255.1">ViT</span></strong><span class="koboSpan" id="kobo.1256.1">) extends transformers to images, achieving competitive performance in image classification and </span><span class="No-Break"><span class="koboSpan" id="kobo.1257.1">generation tasks</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1258.1">One of</span><a id="_idIndexMarker744"/><span class="koboSpan" id="kobo.1259.1"> the reasons behind transformers’ success is their parallelizable structure, which speeds up training. </span><span class="koboSpan" id="kobo.1259.2">Additionally, the attention mechanism enables capturing relationships without explicitly defining </span><span class="No-Break"><span class="koboSpan" id="kobo.1260.1">sequence lengths.</span></span></p>
<p><span class="koboSpan" id="kobo.1261.1">Despite their immense capabilities, transformers have their own challenges, such as a high computational cost for large models and the potential for generating biased or inappropriate content. </span><span class="koboSpan" id="kobo.1261.2">Researchers continue to refine and adapt the transformer architecture to address these issues and push the boundaries of </span><span class="No-Break"><span class="koboSpan" id="kobo.1262.1">AI capabilities.</span></span></p>
<h1 id="_idParaDest-139"><a id="_idTextAnchor143"/><span class="koboSpan" id="kobo.1263.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1264.1">In this chapter, we learned the basic concepts of DL and discovered how to implement a CNN algorithm in the MATLAB environment. </span><span class="koboSpan" id="kobo.1264.2">First, we looked at how DL enables automated feature extraction, then we looked at how to train a deep network, and then we got a taste of the most popular </span><span class="No-Break"><span class="koboSpan" id="kobo.1265.1">DL architectures.</span></span></p>
<p><span class="koboSpan" id="kobo.1266.1">We then focused on CNN to analyze it in detail. </span><span class="koboSpan" id="kobo.1266.2">We learned about the different layers that make up this network and what functions these layers perform. </span><span class="koboSpan" id="kobo.1266.3">We then saw in practice how to implement a CNN in the MATLAB environment for image classification of pistachio nuts. </span><span class="koboSpan" id="kobo.1266.4">We learned how to correctly import the image database, how to draw the architecture of the network with the different layers one after the other, and how to set the network parameters. </span><span class="koboSpan" id="kobo.1266.5">Finally, we saw how to use evaluation metrics for the correct interpretation of </span><span class="No-Break"><span class="koboSpan" id="kobo.1267.1">the results.</span></span></p>
<p><span class="koboSpan" id="kobo.1268.1">In the last section, we introduced some of the most used networks, which will be the subject of more detailed study and application in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1269.1">following chapters.</span></span></p>
<p><span class="koboSpan" id="kobo.1270.1">In the next chapter, we will understand the basic concepts of NLP, how to use corpora and word and sentence tokenization, and how to build a model to label sentences, and finally, we will implement gradient boosting techniques </span><span class="No-Break"><span class="koboSpan" id="kobo.1271.1">using MATLAB.</span></span></p>
</div>


<div class="Content" id="_idContainer067">
<h1 id="_idParaDest-140" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor144"/><span class="koboSpan" id="kobo.1.1">Part 3: Machine Learning in Practice</span></h1>
<p><span class="koboSpan" id="kobo.2.1">In this part, we will take a journey into the specialized domains of MATLAB application, where we will reveal the immense potential of the software in various fields. </span></p>
<p><span class="koboSpan" id="kobo.3.1">Explore the enchanting world of natural language processing using MATLAB, where language intricacies are deciphered, enabling machines to comprehend and respond to human communication. </span><span class="koboSpan" id="kobo.3.2">Transitioning into the visual realm, </span><a href="B21156_08.xhtml#_idTextAnchor167"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.5.1"> opens doors to the manipulation and understanding of visual data, bringing pixels to life through sophisticated algorithms. </span><span class="koboSpan" id="kobo.5.2">Delve into the intricate patterns of </span><a href="B21156_09.xhtml#_idTextAnchor184"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.6.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.7.1">, where historical data paves the way for informed predictions and strategic decision-making. </span><span class="koboSpan" id="kobo.7.2">Then, witness the power of </span><a href="B21156_10.xhtml#_idTextAnchor202"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.8.1">Chapter 10</span></em></span></a><span class="koboSpan" id="kobo.9.1">, where personalized suggestions and recommendations emerge from intricate algorithms, enhancing user experiences. </span><span class="koboSpan" id="kobo.9.2">Concluding our exploration, immerse yourself in the realm of </span><a href="B21156_11.xhtml#_idTextAnchor223"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.10.1">Chapter 11</span></em></span></a><span class="koboSpan" id="kobo.11.1">, where subtle deviations in data patterns are unveiled, providing a critical edge in identifying outliers and potential threats. </span><span class="koboSpan" id="kobo.11.2">Join us as we navigate through these diverse applications, unlocking the capabilities of MATLAB in shaping the future of data analysis and </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">decision support.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1">This part has the </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">following chapters:</span></span></p>
<ul>
<li><a href="B21156_07.xhtml#_idTextAnchor145"><em class="italic"><span class="koboSpan" id="kobo.15.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.16.1">, </span><em class="italic"><span class="koboSpan" id="kobo.17.1">Natural Language Processing Using MATLAB</span></em></li>
<li><a href="B21156_08.xhtml#_idTextAnchor167"><em class="italic"><span class="koboSpan" id="kobo.18.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.19.1">, </span><em class="italic"><span class="koboSpan" id="kobo.20.1">MATLAB for Image Processing and Computer Vision</span></em></li>
<li><a href="B21156_09.xhtml#_idTextAnchor184"><em class="italic"><span class="koboSpan" id="kobo.21.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.22.1">, </span><em class="italic"><span class="koboSpan" id="kobo.23.1">Time Series Analysis and Forecasting with MATLAB</span></em></li>
<li><a href="B21156_10.xhtml#_idTextAnchor202"><em class="italic"><span class="koboSpan" id="kobo.24.1">Chapter 10</span></em></a><span class="koboSpan" id="kobo.25.1">, </span><em class="italic"><span class="koboSpan" id="kobo.26.1">MATLAB Tools for Recommender Systems</span></em></li>
<li><a href="B21156_11.xhtml#_idTextAnchor223"><em class="italic"><span class="koboSpan" id="kobo.27.1">Chapter 11</span></em></a><span class="koboSpan" id="kobo.28.1">, </span><em class="italic"><span class="koboSpan" id="kobo.29.1">Anomaly Detection in MATLAB</span></em></li>
</ul>
</div>
<div>
<div id="_idContainer068">
</div>
</div>
<div>
<div class="Basic-Graphics-Frame" id="_idContainer069">
</div>
</div>
</body></html>