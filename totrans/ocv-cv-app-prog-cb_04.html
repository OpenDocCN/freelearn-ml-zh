<html><head></head><body>
<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04" class="calibre1"/>Chapter 4. Counting the Pixels with Histograms</h1></div></div></div><p class="calibre8">In this chapter, we will cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem">Computing the image histogram</li><li class="listitem">Applying look-up tables to modify the image appearance</li><li class="listitem">Equalizing the image histogram</li><li class="listitem">Backprojecting a histogram to detect the specific image content</li><li class="listitem">Using the mean shift algorithm to find an object</li><li class="listitem">Retrieving similar images using the histogram comparison</li><li class="listitem">Counting pixels with integral images</li></ul></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch04lvl1sec26" class="calibre1"/>Introduction</h1></div></div></div><p class="calibre8">An image is composed of pixels of different values (colors). The distribution of pixel values across an image constitutes an important characteristic of that image. This chapter introduces the concept of image histograms. You will learn how to compute a histogram and how to use it to modify an image's appearance. Histograms can also be used to characterize an image's content and detect specific objects or textures in an image. Some of these techniques will be presented in this chapter.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec27" class="calibre1"/>Computing the image histogram</h1></div></div></div><p class="calibre8">An image <a id="id258" class="calibre1"/>is made of pixels, and each of them have different values. For example, in a 1-channel gray-level image, each pixel has a value between 0 (black) and 255 (white). Depending on the picture content, you will find different amounts of each gray shade laid out inside the image.</p><p class="calibre8">A <strong class="calibre2">histogram</strong><a id="id259" class="calibre1"/> is a simple table that gives you the number of pixels that have a given value in an image (or sometimes, a set of images). The histogram of a gray-level image will, therefore, have <a id="id260" class="calibre1"/>256 entries (or <strong class="calibre2">bins</strong>). Bin 0 gives you the number of pixels that have the value 0, bin 1 gives<a id="id261" class="calibre1"/> you the number of pixels that have the value 1, and so on. Obviously, if you sum all of the entries of a histogram, you should get the total number of pixels. Histograms can also be normalized such that the sum of the bins equals 1. In this case, each bin gives you the percentage of pixels that have this specific value in the image.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec73" class="calibre1"/>Getting started</h2></div></div></div><p class="calibre8">The first three recipes of this chapter will use the following image:</p><div><img src="img/00029.jpeg" alt="Getting started" class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec74" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">Computing a <a id="id262" class="calibre1"/>histogram with OpenCV can be easily done by using the<a id="id263" class="calibre1"/> <code class="email">cv::calcHist</code> function. This is a general function that can compute the histogram of multiple channel images of any pixel value type and range. Here, we will make this simpler to use by specializing a class for the case of 1-channel gray-level images. For other types of images, you can always directly use the <code class="email">cv::calcHist</code> function, which offers you all the flexibility required. The next section will explain each of its parameters.</p><p class="calibre8">For now, our specialized class looks as follows:</p><div><pre class="programlisting">// To create histograms of gray-level images
class Histogram1D {

  private:

    int histSize[1];         // number of bins in histogram
    float hranges[2];        // range of values
    const float* ranges[1];  // pointer to the value ranges
    int channels[1];         // channel number to be examined

  public:

  Histogram1D() {

    // Prepare default arguments for 1D histogram
    histSize[0]= 256;   // 256 bins
    hranges[0]= 0.0;    // from 0 (inclusive)
    hranges[1]= 256.0;  // to 256 (exclusive)
    ranges[0]= hranges; 
    channels[0]= 0;     // we look at channel 0
  }</pre></div><p class="calibre8">With the defined <a id="id264" class="calibre1"/>member variables, computing a gray-level histogram<a id="id265" class="calibre1"/> can then be accomplished using the following method:</p><div><pre class="programlisting">  // Computes the 1D histogram.
  cv::Mat getHistogram(const cv::Mat &amp;image) {

    cv::Mat hist;

    // Compute histogram
    cv::calcHist(&amp;image, 
      1,         // histogram of 1 image only
      channels,  // the channel used
      cv::Mat(), // no mask is used
      hist,      // the resulting histogram
      1,         // it is a 1D histogram
      histSize,  // number of bins
      ranges     // pixel value range
    );

    return hist;
  }</pre></div><p class="calibre8">Now, your program simply needs to open an image, create a <code class="email">Histogram1D</code> instance, and call the <code class="email">getHistogram</code> method:</p><div><pre class="programlisting">   // Read input image
   cv::Mat image= cv::imread("group.jpg",
                             0); // open in b&amp;w

   // The histogram object
   Histogram1D h;

   // Compute the histogram
   cv::Mat histo= h.getHistogram(image);</pre></div><p class="calibre8">The <code class="email">histo</code> object <a id="id266" class="calibre1"/>here is a simple one-dimensional array with <code class="email">256</code> entries. Therefore, you can read each bin by simply looping over this array:</p><div><pre class="programlisting">   // Loop over each bin
   for (int i=0; i&lt;256; i++) 
      cout &lt;&lt; "Value " &lt;&lt; i &lt;&lt; " = " &lt;&lt; 
                   histo.at&lt;float&gt;(i) &lt;&lt; endl;  </pre></div><p class="calibre8">With the image shown at the start of this chapter, some of the displayed values would read as follows:</p><div><pre class="programlisting">...
Value 7 = 159
Value 8 = 208
Value 9 = 271
Value 10 = 288
Value 11 = 340
Value 12 = 418
Value 13 = 432
Value 14 = 472
Value 15 = 525
...</pre></div><p class="calibre8">It is obviously difficult to extract any intuitive meaning from this sequence of values. For this reason, it is often convenient to display a histogram as a function, for example, using bar graphs. The following methods create such a graph:</p><div><pre class="programlisting">// Computes the 1D histogram and returns an image of it.
cv::Mat getHistogramImage(const cv::Mat &amp;image, 
                             int zoom=1){

  // Compute histogram first
  cv::Mat hist= getHistogram(image);
  // Creates image
  return getImageOfHistogram(hist, zoom);
}

// Create an image representing a histogram (static method)
static cv::Mat getImageOfHistogram
                  (const cv::Mat &amp;hist, int zoom) {
  // Get min and max bin values
  double maxVal = 0;
  double minVal = 0;
  cv::minMaxLoc(hist, &amp;minVal, &amp;maxVal, 0, 0);

  // get histogram size
  int histSize = hist.rows;

  // Square image on which to display histogram
  cv::Mat histImg(histSize*zoom, 
                   histSize*zoom, CV_8U, cv::Scalar(255));

  // set highest point at 90% of nbins (i.e. image height)
  int hpt = static_cast&lt;int&gt;(0.9*histSize);

  // Draw vertical line for each bin 
  for (int h = 0; h &lt; histSize; h++) {

    float binVal = hist.at&lt;float&gt;(h);
    if (binVal&gt;0) {
      int intensity = static_cast&lt;int&gt;(binVal*hpt / maxVal);
      cv::line(histImg, cv::Point(h*zoom, histSize*zoom),
        cv::Point(h*zoom, (histSize - intensity)*zoom), 
             cv::Scalar(0), zoom);
    }
  }

  return histImg;
}</pre></div><p class="calibre8">Using <a id="id267" class="calibre1"/>the<a id="id268" class="calibre1"/> <code class="email">getImageOfHistogram</code> method, you can obtain an image of the histogram function in the form of a bar graph that is drawn using lines:</p><div><pre class="programlisting">   // Display a histogram as an image
   cv::namedWindow("Histogram");
   cv::imshow("Histogram",
               h.getHistogramImage(image));</pre></div><p class="calibre8">The result is the following image:</p><div><img src="img/00030.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">From the preceding histogram, it can be seen that the image exhibits a large peak of mid-gray level <a id="id269" class="calibre1"/>values and a good quantity of darker pixels. Coincidentally, these two groups mostly correspond to, respectively, the background and foreground of the image. This can be verified by thresholding the image at the transition between these two groups. A convenient OpenCV function can be used for this, namely the <code class="email">cv::threshold</code> function that was introduced in the previous chapter. Here, to create our binary image, we threshold the image at the minimum value just before it increases toward the high peak of the histogram (gray value <code class="email">60</code>):</p><div><pre class="programlisting">cv::Mat thresholded; // output binary image
cv::threshold(image,thresholded,
            60,    // threshold value
            255,   // value assigned to 
                   // pixels over threshold value
          cv::THRESH_BINARY); // thresholding type</pre></div><p class="calibre8">The resulting binary image clearly shows you the background/foreground segmentation:</p><div><img src="img/00031.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec75" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">The <code class="email">cv::calcHist</code> function <a id="id270" class="calibre1"/>has many parameters to permit its use in many contexts, which are as follows:</p><div><pre class="programlisting">void calcHist(const Mat* images, int nimages, 
  const int* channels, InputArray mask, OutputArray hist, 
  int dims, const int* histSize, const float** ranges, 
  bool uniform=true, bool accumulate=false )</pre></div><p class="calibre8">Most of the time, your <a id="id271" class="calibre1"/>histogram will be one of a single 1-channel or 3-channel image. However, the function allows you to specify a multiple-channel image distributed over several images. This is why an array of images is input into this function. The sixth parameter, <code class="email">dims</code>, specifies the dimensionality of the histogram, for example, 1 for a 1D histogram. Even if you are analyzing a multichannel image, you do not have to use all its channels in the computation of the histogram. The channels to be considered are listed in the <code class="email">channel</code> array that has the specified dimensionality. In our class implementation, this single channel is the channel 0 by default. The histogram itself is described by the number of bins in each dimension (this is the <code class="email">histSize</code> array of integers) and by the minimum (inclusive) and maximum (exclusive) values in each dimension (given by the <code class="email">ranges</code> array of 2-element arrays). It is also possible to define a non-uniform histogram; in which case, you need to specify the limits of each bin.</p><p class="calibre8">As with many <a id="id272" class="calibre1"/>OpenCV functions, a mask can be specified, indicating which pixels you want to include in the count (all pixels for which the mask value is 0 are then ignored). Two additional optional parameters can be specified, both of which are Boolean values. The first one indicates whether the histogram is uniform or not (uniform is the default). The second allows you to accumulate the result of several histogram computations. If this last parameter is true, then the pixel count of the image will be added to the current values found in the input histogram. This is useful when you want to compute the histogram of a group of images.</p><p class="calibre8">The resulting histogram is stored in a <code class="email">cv::Mat</code> instance. Indeed, the <code class="email">cv::Mat</code> class can be used to manipulate general N-dimensional matrices. Recall from <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <em class="calibre9">Manipulating Pixels</em>, that this class has defined the <code class="email">at</code> method for matrices of dimension 1, 2, and 3. This is why we were able to write the following code when accessing each bin of the 1D histogram in the <code class="email">getHistogramImage</code> method:</p><div><pre class="programlisting">         float binVal = hist.at&lt;float&gt;(h);</pre></div><p class="calibre8">Note that the values in the histogram are stored as <code class="email">float</code> values.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch04lvl2sec76" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">The <code class="email">Histogram1D</code> class<a id="id273" class="calibre1"/> presented in this recipe has simplified the <code class="email">cv::calcHist</code> function by restricting it to a 1D histogram. This is useful for gray-level images, but what about color images?</p><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec21" class="calibre1"/>Computing histograms of color images</h3></div></div></div><p class="calibre8">Using <a id="id274" class="calibre1"/>the same <code class="email">cv::calcHist</code> function, we can compute histograms of multichannel images. For example, a class that computes histograms of color BGR images can be defined as follows:</p><div><pre class="programlisting">class ColorHistogram {

  private:

    int histSize[3];        // size of each dimension
    float hranges[2];       // range of values
    const float* ranges[3]; // ranges for each dimension
    int channels[3];        // channel to be considered

  public:

  ColorHistogram() {

    // Prepare default arguments for a color histogram
    // each dimension has equal size and range
    histSize[0]= histSize[1]= histSize[2]= 256;
    hranges[0]= 0.0;    // BRG range from 0 to 256
    hranges[1]= 256.0;
    ranges[0]= hranges; // in this class,  
    ranges[1]= hranges; // all channels have the same range
    ranges[2]= hranges; 
    channels[0]= 0;    // the three channels 
    channels[1]= 1; 
    channels[2]= 2; 
  }</pre></div><p class="calibre8">In this case, the <a id="id275" class="calibre1"/>histogram will be three-dimensional. Therefore, we need to specify a range for each of the three dimensions. In the case of our BGR image, the three channels have the same <code class="email">[0,255]</code> range. With the arguments thus prepared, the color histogram is computed by the following method:</p><div><pre class="programlisting">  // Computes the histogram.
  cv::Mat getHistogram(const cv::Mat &amp;image) {

    cv::Mat hist;

    // BGR color histogram
    hranges[0]= 0.0;    // BRG range
    hranges[1]= 256.0;
    channels[0]= 0;    // the three channels 
    channels[1]= 1; 
    channels[2]= 2; 

    // Compute histogram
    cv::calcHist(&amp;image, 
      1,          // histogram of 1 image only
      channels,   // the channel used
      cv::Mat(),  // no mask is used
      hist,       // the resulting histogram
      3,          // it is a 3D histogram
      histSize,   // number of bins
      ranges      // pixel value range
    );

    return hist;
  }</pre></div><p class="calibre8">A three-dimensional <code class="email">cv::Mat</code> instance is returned. When a histogram of <code class="email">256</code> bins is selected, this matrix has <code class="email">(256)^3</code> elements, which represents more than 16 million entries. In many applications, it would be better to reduce the number of bins in the computation of the <a id="id276" class="calibre1"/>histogram. It is also possible to use the <code class="email">cv::SparseMat</code> data structure that is designed to represent large sparse matrices (that is, matrices with very few nonzero elements) without consuming too much memory. The <code class="email">cv::calcHist</code> function has a version that returns one such matrix. It is, therefore, simple to modify the previous method in order to use <code class="email">cv::SparseMatrix</code>:</p><div><pre class="programlisting">  // Computes the histogram.
  cv::SparseMat getSparseHistogram(const cv::Mat &amp;image) {

    cv::SparseMat hist(3,        // number of dimensions
                      histSize, // size of each dimension
                   CV_32F);

    // BGR color histogram
    hranges[0]= 0.0;    // BRG range
    hranges[1]= 256.0;
    channels[0]= 0;     // the three channels 
    channels[1]= 1; 
    channels[2]= 2; 

    // Compute histogram
    cv::calcHist(&amp;image, 
      1,         // histogram of 1 image only
      channels,  // the channel used
      cv::Mat(), // no mask is used
      hist,      // the resulting histogram
      3,         // it is a 3D histogram
      histSize,  // number of bins
      ranges     // pixel value range
    );

    return hist;
  }</pre></div><p class="calibre8">Obviously, it is also possible to illustrate the color distribution in an image by showing the individual R, G, and B histograms.</p></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_5"><a id="ch04lvl2sec77" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The <em class="calibre9">Backprojecting a histogram to detect specific image content</em> recipe later in this chapter makes use of color histograms in order to detect specific image content</li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec28" class="calibre1"/>Applying look-up tables to modify the image appearance</h1></div></div></div><p class="calibre8">Image histograms <a id="id277" class="calibre1"/>capture the way a scene is rendered using the available pixel intensity values. By analyzing the distribution of the pixel values over an image, it is possible to use this information to modify and possibly improve an image. This recipe explains how we can use a simple mapping function, represented by a look-up table, to modify the pixel values of an image. As we will see, look-up tables are often defined from histogram distributions.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec78" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">A <strong class="calibre2">look-up table</strong><a id="id278" class="calibre1"/> is a simple one-to-one (or many-to-one) function that defines how pixel values are transformed into new values. It is a 1D array with, in the case of regular gray-level images, 256 entries. Entry <code class="email">i</code> of the table gives you the new intensity value of the corresponding gray level, which is as follows:</p><div><pre class="programlisting">         newIntensity= lookup[oldIntensity];</pre></div><p class="calibre8">The <code class="email">cv::LUT</code> function<a id="id279" class="calibre1"/> in OpenCV applies a look-up table to an image in order to produce a new image. We can add this function to our <code class="email">Histogram1D</code> class:</p><div><pre class="programlisting">   static cv::Mat applyLookUp(
    const cv::Mat&amp; image,     // input image
    const cv::Mat&amp; lookup) {  // 1x256 uchars

      // the output image
      cv::Mat result;

      // apply lookup table
      cv::LUT(image,lookup,result);

      return result;
   }</pre></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec79" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">When a look-up table is applied on an image, it results in a new image where the pixel intensity values have been modified as prescribed by the look-up table. A simple transformation could be the following:</p><div><pre class="programlisting">   // Create an image inversion table
   int dim(256);
   cv::Mat lut(1, // 1 dimension
      &amp;dim,       // 256 entries
      CV_8U);     // uchar

   for (int i=0; i&lt;256; i++) {
      
      lut.at&lt;uchar&gt;(i)= 255-i;
   }</pre></div><p class="calibre8">This transformation <a id="id280" class="calibre1"/>simply inverts the pixel intensities, that is, intensity <code class="email">0</code> becomes <code class="email">255</code>, <code class="email">1</code> becomes <code class="email">254</code>, and so on. Applying such a look-up table on an image will produce the negative of the original image. On the image of the previous recipe, the result is seen here:</p><div><img src="img/00032.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec80" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">Look-up tables are useful for any application in which all pixel intensities are given a new intensity value. The transformation, however, has to be global, that is, all pixels of each intensity value must undergo the same transformation.</p><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec22" class="calibre1"/>Stretching a histogram to improve the image contrast</h3></div></div></div><p class="calibre8">It is possible to improve an image's contrast <a id="id281" class="calibre1"/>by defining a look-up table that modifies the original image's histogram. For example, if you observe the histogram of the previous image shown in the first recipe, it is easy to notice that the full range of possible intensity values is not used (in particular, for this image, the brighter intensity values have not been used). We can, therefore, stretch the histogram in order to produce an <a id="id282" class="calibre1"/>image with an expanded contrast. To do so, the procedure uses a percentile threshold that defines the percentage of pixels that should be black and white in the stretched image.</p><p class="calibre8">We must, therefore, find the lowest (<code class="email">imin</code>) and the highest (<code class="email">imax</code>) intensity values such that we have the required minimum number of pixels below or above the specified percentile. The intensity values can then be remapped such that the <code class="email">imin</code> value is repositioned at intensity <code class="email">0</code> and the <code class="email">imax</code> value is assigned the value of <code class="email">255</code>. The in-between <code class="email">i</code> intensities are simply linearly remapped as follows:</p><div><pre class="programlisting">255.0*(i-imin)/(imax-imin);</pre></div><p class="calibre8">Consequently, the complete image stretch method would look as follows:</p><div><pre class="programlisting">   cv::Mat stretch(const cv::Mat &amp;image, int minValue=0) {

      // Compute histogram first
      cv::Mat hist= getHistogram(image);

      // find left extremity of the histogram
      int imin= 0;
      for( ; imin &lt; histSize[0]; imin++ ) {
         // ignore bins with less than minValue entries
         if (hist.at&lt;float&gt;(imin) &gt; minValue)
            break;
      }
      
      // find right extremity of the histogram
      int imax= histSize[0]-1;
      for( ; imax &gt;= 0; imax-- ) {

         // ignore bins with less than minValue entries
         if (hist.at&lt;float&gt;(imax) &gt; minValue)
            break;
      }
   
      // Create lookup table
      int dim(256);
      cv::Mat lookup(1,  // 1 dimension
            &amp;dim,        // 256 entries
            CV_8U);      // uchar

      // Build lookup table
      for (int i=0; i&lt;256; i++) {
      
         // stretch between imin and imax
         if (i &lt; imin) lookup.at&lt;uchar&gt;(i)= 0;
         else if (i &gt; imax) lookup.at&lt;uchar&gt;(i)= 255;
         // linear mapping
      else lookup.at&lt;uchar&gt;(i)= 
        cvRound(255.0*(i-imin)/(imax-imin));
      }

      // Apply lookup table
      cv::Mat result;
      result= applyLookUp(image,lookup);

      return result;
   }</pre></div><p class="calibre8">Note the call to <a id="id283" class="calibre1"/>our <code class="email">applyLookUp</code> method once this method has been computed. Also, in practice, it could be advantageous to not only ignore bins with the <code class="email">0</code> value, but also entries with negligible count, for example, less than a given value (defined here as <code class="email">minValue</code>). The method is called as follows:</p><div><pre class="programlisting">  // setting 1% of pixels at black and 1% at white
  cv::Mat streteched = h.stretch(image,0.01f);</pre></div><p class="calibre8">The resulting stretched image is as follows:</p><div><img src="img/00033.jpeg" alt="Stretching a histogram to improve the image contrast" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The expanded histogram then looks as follows:</p><div><img src="img/00034.jpeg" alt="Stretching a histogram to improve the image contrast" class="calibre10"/></div><p class="calibre11"> </p></div><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec23" class="calibre1"/>Applying a look-up table on color images</h3></div></div></div><p class="calibre8">In <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <em class="calibre9">Manipulating Pixels</em>, we defined a color-reduction function that modifies<a id="id284" class="calibre1"/> the BGR values of an image in order to reduce the number of possible colors. We did this by looping through the image's pixels and applying the color-reduction function on each of them. In fact, it would be much more efficient to precompute all color reductions and then modify each pixel by using a look-up table. This is indeed very easy to accomplish from what we learned in this recipe. The new color-reduction function would then be written as follows:</p><div><pre class="programlisting">void colorReduce(cv::Mat &amp;image, int div=64) {
  
    // creating the 1D lookup table
    cv::Mat lookup(1,256,CV_8U);
      
    // defining the color reduction lookup
    for (int i=0; i&lt;256; i++) 
      lookup.at&lt;uchar&gt;(i)= i/div*div + div/2;

    // lookup table applied on all channels
    cv::LUT(image,lookup,image);
}</pre></div><p class="calibre8">The color-reduction scheme <a id="id285" class="calibre1"/>is correctly applied here because when a one-dimensional look-up table is applied to a multichannel image, then the same table is individually applied to all channels. When a look-up table has more than one dimension, then it must be applied to an image with the same number of channels.</p></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch04lvl2sec81" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The next recipe shows you another way to improve the image contrast</li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec29" class="calibre1"/>Equalizing the image histogram</h1></div></div></div><p class="calibre8">In the<a id="id286" class="calibre1"/> previous recipe, we showed you how the contrast of an image can be improved by stretching a histogram so that it occupies the full range of the available intensity values. This strategy indeed constitutes an easy fix that can effectively improve an image. However, in many cases, the visual deficiency of an image is not that it uses a too-narrow range of intensities. Rather, it is that some intensity values are used more frequently than others. The histogram shown in the first recipe of this chapter is a good example of this phenomenon. The middle-gray intensities are indeed heavily represented, while darker and brighter pixel values are rather rare. In fact, you would think that a good-quality image should make equal use of all available pixel intensities. This is the idea behind the concept of<a id="id287" class="calibre1"/> <strong class="calibre2">histogram equalization</strong>, that is, making the image histogram as flat as possible.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec82" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">OpenCV offers an easy-to-use function that <a id="id288" class="calibre1"/>performs histogram equalization. It is called as follows:</p><div><pre class="programlisting">      cv::equalizeHist(image,result);</pre></div><p class="calibre8">After applying it on our image, the following screenshot is the result:</p><div><img src="img/00035.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">This <a id="id289" class="calibre1"/>equalized image has the following histogram:</p><div><img src="img/00036.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Of course, the <a id="id290" class="calibre1"/>histogram <a id="id291" class="calibre1"/>cannot be perfectly flat because the look-up table is a global many-to-one transformation. However, it can be seen that the general distribution of the histogram is now more uniform than the original one.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec83" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">In a perfectly uniform histogram, all bins would have an equal number of pixels. This implies that 50 percent of the pixels should have an intensity lower than <code class="email">128</code>, 25 percent should have an intensity lower than <code class="email">64</code>, and so on. This observation can be expressed using the rule that in a uniform histogram, <em class="calibre9">p%</em> of the pixels must have an intensity value lower than or equal to <em class="calibre9">255*p%</em>. The rule used to equalize a histogram is that the mapping of intensity <code class="email">i</code> should be at the intensity that corresponds to the percentage of pixels that have an intensity value below <code class="email">i</code>. Therefore, the required look-up table can be built from the following equation:</p><div><pre class="programlisting">lookup.at&lt;uchar&gt;(i)=   
        static_cast&lt;uchar&gt;(255.0*p[i]/image.total());</pre></div><p class="calibre8">Here, <code class="email">p[i]</code> is the number of pixels that have an intensity lower than or equal to <code class="email">i</code>. The <code class="email">p[i]</code> function<a id="id292" class="calibre1"/> is often referred to as a <strong class="calibre2">cumulative histogram</strong>, that is, it is a histogram<a id="id293" class="calibre1"/> that contains the count of pixels lower than or equal to a given intensity instead of containing the count of pixels that have a specific intensity value. Recall that <code class="email">image.total()</code> returns the number of pixels in an image, so <code class="email">p[i]/image.total()</code> is a percentage of pixels.</p><p class="calibre8">Generally, the histogram equalization greatly improves the image's appearance. However, depending on the visual content, the quality of the result can vary from image to image.</p></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec30" class="calibre1"/>Backprojecting a histogram to detect specific image content</h1></div></div></div><p class="calibre8">A histogram<a id="id294" class="calibre1"/> is an important characteristic of an image's content. If you look at an image area that shows a particular texture or a particular object, then the histogram of this area can be seen as a function that gives the probability that a given pixel belongs to this specific texture or object. In this recipe, you will learn how the concept of <a id="id295" class="calibre1"/>
<strong class="calibre2">histogram backprojection</strong> can be advantageously used to detect specific image content.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec84" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">Suppose you have an image and you wish to detect specific content inside it (for example, in the following image, the clouds in the sky). The first thing to do is to select a region of interest that contains a sample of what you are looking for. This region is the one inside the rectangle drawn on the following test image:</p><div><img src="img/00037.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In our program, the region of interest is obtained as follows:</p><div><pre class="programlisting">   cv::Mat imageROI;
   imageROI= image(cv::Rect(216,33,24,30)); // Cloud region</pre></div><p class="calibre8">You then <a id="id296" class="calibre1"/>extract<a id="id297" class="calibre1"/> the histogram of this ROI. This is easily accomplished using the <code class="email">Histogram1D</code> class defined in the first recipe of this chapter as follows:</p><div><pre class="programlisting">   Histogram1D h;
   cv::Mat hist= h.getHistogram(imageROI);</pre></div><p class="calibre8">By normalizing this histogram, we obtain a function that gives us the probability that a pixel of a given intensity value belongs to the defined area as follows:</p><div><pre class="programlisting">   cv::normalize(histogram,histogram,1.0);</pre></div><p class="calibre8">Backprojecting a histogram consists of replacing each pixel value in an input image with its corresponding probability value read in the normalized histogram. An OpenCV function performs this task as follows:</p><div><pre class="programlisting">  cv::calcBackProject(&amp;image,
            1,          // one image
            channels,   // the channels used, 
                        // based on histogram dimension
            histogram,  // the histogram we are backprojecting
            result,     // the resulting back projection image
            ranges,     // the ranges of values
            255.0       // the scaling factor is chosen 
            // such that a probability value of 1 maps to 255
       );</pre></div><p class="calibre8">The result is the<a id="id298" class="calibre1"/> following probability map, with probabilities belonging to the reference area ranging from bright (low probability) to dark (high probability):</p><div><img src="img/00038.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">If we apply a threshold on this image, we obtain the most probable "cloud" pixels:</p><div><pre class="programlisting">cv::threshold(result, result, threshold, 
                      255, cv::THRESH_BINARY);</pre></div><p class="calibre8">The result is shown in the following screenshot:</p><div><img src="img/00039.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec85" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">The preceding result <a id="id299" class="calibre1"/>is disappointing because, in addition to the clouds, other areas have been wrongly detected as well. It is important to understand that the probability function has been extracted from a simple gray-level histogram. Many other pixels in the image share the same intensities as the cloud pixels, and pixels of the same intensity are replaced with the same probability value when backprojecting the histogram. One solution to improve the detection result would be to use the color information. However, in order to do this, we need to modify the call to <code class="email">cv::calBackProject</code>.</p><p class="calibre8">The <code class="email">cv::calBackProject</code> function<a id="id300" class="calibre1"/> is similar to the <code class="email">cv::calcHist</code> function. The first parameter specifies the input image. You then need to list the channel numbers you wish to use. The histogram that is passed to the function is, this time, an input parameter; its dimension should match the one of the channel list array. As with <code class="email">cv::calcHist</code>, the <code class="email">ranges</code> parameter specifies the bin boundaries of the input histogram in the form of an array of float arrays, each specifying the range (minimum and maximum values) of each channel. The resulting output is an image, which is the computed probability map. Since each pixel is replaced by the value found in the histogram at the corresponding bin position, the resulting image has values between <code class="email">0.0</code> and <code class="email">1.0</code> (assuming a normalized histogram has been provided as input). A last parameter allows you to optionally rescale these values by multiplying them by a given factor.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec86" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">Let's now see how we can use the color information in the histogram backprojection algorithm.</p><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec24" class="calibre1"/>Backprojecting color histograms</h3></div></div></div><p class="calibre8">Multidimensional <a id="id301" class="calibre1"/>histograms can also be backprojected onto an image. Let's define a class that encapsulates the backprojection process. We first define the required attributes and initialize the data as follows:</p><div><pre class="programlisting">class ContentFinder {

  private:

  // histogram parameters
  float hranges[2];
   const float* ranges[3];
   int channels[3];

  float threshold;           // decision threshold
  cv::Mat histogram;         // input histogram 

  public:

  ContentFinder() : threshold(0.1f) {

    // in this class, all channels have the same range
    ranges[0]= hranges;  
    ranges[1]= hranges; 
    ranges[2]= hranges; 
  }</pre></div><p class="calibre8">Next, we define a threshold parameter that will be used to create the binary map that shows the detection result. If this parameter is set to a negative value, the raw probability map will be returned. Refer to the following code:</p><div><pre class="programlisting">   // Sets the threshold on histogram values [0,1]
   void setThreshold(float t) {

      threshold= t;
   }

   // Gets the threshold
   float getThreshold() {

      return threshold;
   }</pre></div><p class="calibre8">The input histogram is normalized (this is, however, not required) as follows:</p><div><pre class="programlisting">   // Sets the reference histogram
   void setHistogram(const cv::Mat&amp; h) {

      histogram= h;
      cv::normalize(histogram,histogram,1.0);
   }</pre></div><p class="calibre8">To backproject <a id="id302" class="calibre1"/>the histogram, you simply need to specify the image, the range (we assumed here that all channels have the same range), and the list of channels used. Refer to the following code:</p><div><pre class="programlisting">  // All channels used, with range [0,256[
  cv::Mat find(const cv::Mat&amp; image) {

    cv::Mat result;

    hranges[0]= 0.0;   // default range [0,256[
    hranges[1]= 256.0;
    channels[0]= 0;    // the three channels 
    channels[1]= 1; 
    channels[2]= 2; 

    return find(image, hranges[0], hranges[1], channels);
  }

  // Finds the pixels belonging to the histogram
  cv::Mat find(const cv::Mat&amp; image, 
                float minValue, float maxValue, 
                int *channels) {

    cv::Mat result;

    hranges[0]= minValue;
    hranges[1]= maxValue;

    // histogram dim matches channel list
    for (int i=0; i&lt;histogram.dims; i++)
        this-&gt;channels[i]= channels[i];

    cv::calcBackProject(&amp;image,
            1,         // we only use one image at a time
            channels,  // vector specifying what histogram 
            // dimensions belong to what image channels
            histogram,    // the histogram we are using
            result,       // the back projection image
            ranges,       // the range of values, 
                          // for each dimension
            255.0         // the scaling factor is chosen such 
            // that a histogram value of 1 maps to 255
       );
    }

    // Threshold back projection to obtain a binary image
    if (threshold&gt;0.0)
      cv::threshold(result, result, 
                255.0*threshold, 255.0, cv::THRESH_BINARY);

    return result;
  }</pre></div><p class="calibre8">Let's now <a id="id303" class="calibre1"/>use a BGR histogram on the color version of the image we used previously (see the book's website to see this image in color). This time, we will try to detect the blue sky area. We will first load the color image, define the region of interest, and compute the 3D histogram on a reduced color space as follows:</p><div><pre class="programlisting">  // Load color image
  ColorHistogram hc;
  cv::Mat color= cv::imread("waves2.jpg");

  // extract region of interest
  imageROI= color(cv::Rect(0,0,100,45)); // blue sky area

  // Get 3D colour histogram (8 bins per channel)
  hc.setSize(8); // 8x8x8
  cv::Mat shist= hc.getHistogram(imageROI);</pre></div><p class="calibre8">Next, you compute the histogram and use the <code class="email">find</code> method to detect the sky portion of the image as follows:</p><div><pre class="programlisting">  // Create the content finder
  ContentFinder finder;
  // set histogram to be back-projected
  finder.setHistogram(shist);
  finder.setThreshold(0.05f);

  // Get back-projection of color histogram
  Cv::Mat result= finder.find(color);</pre></div><p class="calibre8">The result of the detection on the color version of the image in the previous section is seen here:</p><div><img src="img/00040.jpeg" alt="Backprojecting color histograms" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The BGR color space<a id="id304" class="calibre1"/> is <a id="id305" class="calibre1"/>generally not the best one to identify color objects in an image. Here, to make it more reliable, we reduced the number of colors before computing the histogram (remember that the original BGR space counts more than 16 million colors). The histogram extracted represents the typical color distribution for a sky area. Try to backproject it on another image. It should also detect the sky portion. Note that using a histogram built from multiple sky images should increase the accuracy of this detection.</p><p class="calibre8">Note that in this case, computing a sparse histogram would have been better in terms of memory usage. You should be able to redo this exercise using <code class="email">cv::SparseMat</code> this time. Also, if you are looking for a bright-colored object, using the hue channel of the HSV color space would probably be more efficient. In other cases, the use of the chromaticity components of a perceptually uniform space (such as <em class="calibre9">L*a*b*</em>) might constitute a better choice.</p></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch04lvl2sec87" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The next recipe uses the HSV color space to detect an object in an image. This is one of the many alternative solutions you can use in the detection of some image content.</li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec31" class="calibre1"/>Using the mean shift algorithm to find an object</h1></div></div></div><p class="calibre8">The result of a<a id="id306" class="calibre1"/> histogram backprojection is a probability map that expresses the probability that a given piece of image content is found at a specific image location. Suppose we now know the approximate location of an object in an image; the probability map can be used to find the exact location of the object. The most probable location will be the one that maximizes this probability inside a given window. Therefore, if we start from an initial location and iteratively move around, it should be possible to find the exact object location. This is what is accomplished by the <strong class="calibre2">mean shift algorithm</strong>.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec88" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">Suppose we <a id="id307" class="calibre1"/>have identified an object of interest—here, a baboon's face—as shown in the following screenshot (refer to the book's graphics PDF to view this image in color):</p><div><img src="img/00041.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">This time, we will <a id="id308" class="calibre1"/>describe this object by using the hue channel of the HSV color space. This means that we need to convert the image into an HSV one and then extract the hue channel and compute the 1D hue histogram of the defined ROI. Refer to the following code:</p><div><pre class="programlisting">   // Read reference image
   cv::Mat image= cv::imread("baboon1.jpg");
   // Baboon's face ROI
   cv::Mat imageROI= image(cv::Rect(110,260,35,40));
   // Get the Hue histogram
   int minSat=65;
   ColorHistogram hc;
   cv::Mat colorhist= 
            hc.getHueHistogram(imageROI,minSat);</pre></div><p class="calibre8">As can be seen, the hue histogram is obtained using a convenient method that we have added to our <code class="email">ColorHistogram</code> class as follows:</p><div><pre class="programlisting">  // Computes the 1D Hue histogram with a mask.
  // BGR source image is converted to HSV
  // Pixels with low saturation are ignored
  cv::Mat getHueHistogram(const cv::Mat &amp;image, 
                             int minSaturation=0) {

    cv::Mat hist;

    // Convert to HSV colour space
    cv::Mat hsv;
    cv::cvtColor(image, hsv, CV_BGR2HSV);

    // Mask to be used (or not)
    cv::Mat mask;

    if (minSaturation&gt;0) {
    
      // Spliting the 3 channels into 3 images
      std::vector&lt;cv::Mat&gt; v;
      cv::split(hsv,v);

      // Mask out the low saturated pixels
      cv::threshold(v[1],mask,minSaturation,255,
                                 cv::THRESH_BINARY);
    }

    // Prepare arguments for a 1D hue histogram
    hranges[0]= 0.0;    // range is from 0 to 180
    hranges[1]= 180.0;
    channels[0]= 0;     // the hue channel 

    // Compute histogram
    cv::calcHist(&amp;hsv, 
      1,        // histogram of 1 image only
      channels, // the channel used
      mask,     // binary mask
      hist,     // the resulting histogram
      1,        // it is a 1D histogram
      histSize, // number of bins
      ranges    // pixel value range
    );

    return hist;
  }</pre></div><p class="calibre8">The resulting histogram <a id="id309" class="calibre1"/>is then passed to our <code class="email">ContentFinder</code> class instance as follows:</p><div><pre class="programlisting">   ContentFinder finder;
   finder.setHistogram(colorhist);</pre></div><p class="calibre8">Let's now open a <a id="id310" class="calibre1"/>second image where we want to locate the new baboon's face position. This image needs to be converted to the HSV space first, and then we backproject the histogram of the first image. Refer to the following code:</p><div><pre class="programlisting">   image= cv::imread("baboon3.jpg");
   // Convert to HSV space
   cv::cvtColor(image, hsv, CV_BGR2HSV);
   // Get back-projection of hue histogram
   int ch[1]={0};
   finder.setThreshold(-1.0f); // no thresholding
   cv::Mat result= finder.find(hsv,0.0f,180.0f,ch);</pre></div><p class="calibre8">Now, from an initial rectangular area (that is, the position of the baboon's face in the initial image), the <code class="email">cv::meanShift</code> algorithm of OpenCV will update the <code class="email">rect</code> object at the new baboon's face location. Refer to the following code:</p><div><pre class="programlisting">   // initial window position
   cv::Rect rect(110,260,35,40);

   // search object with mean shift
   cv::TermCriteria criteria(cv::TermCriteria::MAX_ITER,
                             10,0.01);
   cv::meanShift(result,rect,criteria);</pre></div><p class="calibre8">The initial (red) and new (green) face locations are displayed in the following screenshot (refer to the book's graphics PDF to view this image in color):</p><div><img src="img/00042.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec89" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">In this example, we used the <a id="id311" class="calibre1"/>hue component of the HSV color space in order to characterize the object we were looking for. We made this choice because the baboon's face has a very distinctive pink color; consequently, the pixels' hue should make the face easily identifiable. The first step, therefore, is to convert the image to the HSV color space. The hue component is the first channel of the resulting image when the <code class="email">CV_BGR2HSV</code> flag is used. This is an 8-bit component that varies from <code class="email">0</code> to <code class="email">180</code> (with <code class="email">cv::cvtColor</code>, the converted image is of the same type as the source image). In order to extract the hue image, the 3-channel HSV image is split into three 1-channel images using the <code class="email">cv::split</code> function. The three images are put into a <code class="email">std::vector</code> instance, and the hue image is the first entry of the vector (that is, at index <code class="email">0</code>).</p><p class="calibre8">When using the hue component of a color, it is always important to take its saturation into account (which is the second entry of the vector). Indeed, when the saturation of a color is low, the hue information becomes unstable and unreliable. This is due to the fact that for low-saturated color, the B, G, and R components are almost equal. This makes it difficult to determine the exact color that is represented. Consequently, we decided to ignore the hue component of colors with low saturation. That is, they are not counted in the histogram (using the <code class="email">minSat</code> parameter that masks out pixels with saturation below this threshold in the <code class="email">getHueHistogram</code> method).</p><p class="calibre8">The mean shift algorithm<a id="id312" class="calibre1"/> is an iterative procedure that locates the local maxima of a probability function. It does this by finding the centroid, or weighted mean, of the data point inside a predefined window. The algorithm then moves the window center to the centroid location and repeats the procedure until the window center converges to a stable point. The OpenCV implementation defines two stopping criteria: a maximum number of iterations and a window center displacement value below which the position is considered to have converged to a stable point. These two criteria are stored in a <code class="email">cv::TermCriteria</code> instance. The <code class="email">cv::meanShift</code> function returns the number of iterations that have been performed. Obviously, the quality of the result depends on the quality of the probability map provided on the given initial position. Note that here, we used a histogram of colors to represent an image's appearance; it is also possible to use histograms of other features to represent the object (for example, a histogram of edge orientation).</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec90" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The mean shift algorithm has been largely used for visual tracking. <a class="calibre1" title="Chapter 11. Processing Video Sequences" href="part0072_split_000.html#page">Chapter 11</a>, <em class="calibre9">Processing Video Sequences</em>, will explore the problem of object tracking in more detail</li><li class="listitem">The mean shift algorithm has been introduced in the article <em class="calibre9">Mean Shift: A robust approach toward feature space analysis</em> by <em class="calibre9">D. Comaniciu and P. Meer</em> in <em class="calibre9">IEEE transactions on Pattern Analysis and Machine Intelligence, volume 24, number 5, May 2002</em></li><li class="listitem">OpenCV also offers an implementation of the CamShift algorithm, which is an improved version of the mean shift algorithm in which the size and the orientation of the window can change.</li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec32" class="calibre1"/>Retrieving similar images using the histogram comparison</h1></div></div></div><p class="calibre8">Content-based image retrieval<a id="id313" class="calibre1"/> is an important <a id="id314" class="calibre1"/>problem in computer vision. It consists of finding a set of images that present content that <a id="id315" class="calibre1"/>is similar to a given query image. Since we have learned that histograms constitute an effective way to characterize an image's content, it makes sense to think that they can be used to solve the content-based retrieval problem.</p><p class="calibre8">The key here is to be able to measure the similarity between two images by simply comparing their histograms. A measurement function that will estimate how different, or how similar, two histograms are will need to be defined. Various such measures have been proposed in the past, and OpenCV proposes a few of them in its implementation of the <code class="email">cv::compareHist</code> function.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec91" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">In order to compare <a id="id316" class="calibre1"/>a reference image with a collection of images and find the ones that are the most similar to this query image, we <a id="id317" class="calibre1"/>created an <code class="email">ImageComparator</code> class. This class contains a reference to a query image and an input image, together with their histograms. In addition, since we will perform the comparison using color histograms, the <code class="email">ColorHistogram</code> class is used as follows:</p><div><pre class="programlisting">class ImageComparator {

  private:

    cv::Mat refH;       // reference histogram
    cv::Mat inputH;     // histogram of input image

    ColorHistogram hist; // to generate the histograms
    int nBins; // number of bins used in each color channel

  public:

    ImageComparator() :nBins(8) {

  }</pre></div><p class="calibre8">To get a reliable similarity measure, the histogram should be computed over a reduced number of bins. Therefore, the class allows you to specify the number of bins to be used in each BGR channel. Refer to the following code:</p><div><pre class="programlisting">  // Set number of bins used when comparing the histograms
  void setNumberOfBins( int bins) {

    nBins= bins;
  }</pre></div><p class="calibre8">The query image is specified using an appropriate setter that also computes the reference histogram as follows:</p><div><pre class="programlisting">  // compute histogram of reference image
  void setReferenceImage(const cv::Mat&amp; image) {

    hist.setSize(nBins);
    refH= hist.getHistogram(image);
  }</pre></div><p class="calibre8">Finally, a <code class="email">compare</code> method <a id="id318" class="calibre1"/>compares the <a id="id319" class="calibre1"/>reference image with a given input image. The following method returns a score that indicates how similar the two images are:</p><div><pre class="programlisting">  // compare the images using their BGR histograms
  double compare(const cv::Mat&amp; image) {

    inputH= hist.getHistogram(image);

    return cv::compareHist(refH,inputH,CV_COMP_INTERSECT);
  }</pre></div><p class="calibre8">The preceding class can be used to retrieve images that are similar to a given query image. The following code is initially provided to the class instance:</p><div><pre class="programlisting">   ImageComparator c;
   c.setReferenceImage(image);</pre></div><p class="calibre8">Here, the query image we used is the color version of the beach image shown in the <em class="calibre9">Backprojecting a histogram to detect specific image content</em> recipe earlier in the chapter. This image was compared to the following series of images. The images are shown in order from the most similar to the least similar, as follows:</p><div><img src="img/00043.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec92" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">Most histogram comparison<a id="id320" class="calibre1"/> measures are based on bin-by-bin comparisons. This is why it is important to work with a reduced number of histogram bins when measuring the similarity of two color histograms. The call to <code class="email">cv::compareHist</code> is straightforward. You just input the two histograms and the function returns the measured distance. The specific measurement method you want to use is specified using a flag. In the <code class="email">ImageComparator</code> class, the intersection method is used (with the <code class="email">CV_COMP_INTERSECT</code> flag). This method simply compares, for each bin, the two values in each histogram and keeps the minimum one. The similarity measure, then, is the sum of these minimum values. Consequently, two images that have histograms with no colors in common would get an intersection value of <code class="email">0</code>, while two identical histograms would get a value that is equal to the total number of pixels.</p><p class="calibre8">The other available methods are the Chi-Square measure (the <code class="email">CV_COMP_CHISQR</code> flag) that sums the normalized square difference between the bins, the correlation method (the <code class="email">CV_COMP_CORREL</code> flag) that is based on the normalized cross-correlation operator used in signal processing to measure the similarity between two signals, and the Bhattacharyya measure (the <code class="email">CV_COMP_BHATTACHARYYA</code> flag) that is used in statistics to estimate the similarity between two probabilistic distributions.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec93" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The OpenCV documentation provides a description of the exact formulas used in the different histogram comparison measures.</li><li class="listitem">Earth Mover Distance is another popular histogram comparison method. It is implemented in OpenCV as the <code class="email">cv::EMD</code> function. The main advantage of this method is that it takes into account the values found in adjacent bins to evaluate the similarity of two histograms. It is described in the article <em class="calibre9">The Earth Mover's Distance as a Metric for Image Retrieval</em> by <em class="calibre9">Y. Rubner, C. Tomasi, and L. J. Guibas in Int. Journal of Computer Vision, Volume 40, Number 2., 2000, pp. 99-121</em>.</li></ul></div></div></div>

<div><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch04lvl1sec33" class="calibre1"/>Counting pixels with integral images</h1></div></div></div><p class="calibre8">In the <a id="id321" class="calibre1"/>previous recipes, we learned that a histogram is computed by going through all the pixels of an image and cumulating a count of how often each intensity <a id="id322" class="calibre1"/>value occurs in this image. We have also seen that sometimes, we are only interested in computing our histogram in a certain area of the image. In fact, having to cumulate a sum of pixels inside an image's subregion is a common task in many computer vision algorithms. Now, suppose you have to compute several such histograms over multiple regions of interest inside your image. All these computations could rapidly<a id="id323" class="calibre1"/> become very costly. In such a <a id="id324" class="calibre1"/>situation, there is a tool that can drastically improve the efficiency of counting pixels over image subregions: the <strong class="calibre2">integral image</strong>.</p><p class="calibre8">Integral images<a id="id325" class="calibre1"/> have been introduced as an efficient way of summing pixels in image regions of interest. They are widely used in applications that involve, for example, computations over sliding windows at multiple scales.</p><p class="calibre8">This recipe will explain the principle behind integral images. Our objective here is to show how pixels can be summed over a rectangle region by using only three arithmetic operations. Once we have learned this concept, the <em class="calibre9">There's more...</em> section of this recipe will show you two examples where integral images can be advantageously used.</p></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch04lvl2sec94" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">This recipe will play with the following picture, in which a region of interest showing a girl on her bike is identified:</p><div><img src="img/00044.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Integral images are useful when you need to sum pixels over several image areas. Normally, if you wish to get the sum of all pixels over a region of interest, you would write the following code:</p><div><pre class="programlisting">  // Open image
  cv::Mat image= cv::imread("bike55.bmp",0);
  // define image roi (here the girl on bike)
  int xo=97, yo=112;
  int width=25, height=30;
  cv::Mat roi(image,cv::Rect(xo,yo,width,height));
  // compute sum
  // returns a Scalar to work with multi-channel images
  cv::Scalar sum= cv::sum(roi);</pre></div><p class="calibre8">The<a id="id326" class="calibre1"/> <code class="email">cv::sum</code> function<a id="id327" class="calibre1"/> simply loops over all the pixels <a id="id328" class="calibre1"/>of the region and accumulates the sum. Using an integral image, this can be achieved using only three additive operations. However, first you need to compute the integral image as follows:</p><div><pre class="programlisting">  // compute integral image
  cv::Mat integralImage;
  cv::integral(image,integralImage,CV_32S);</pre></div><p class="calibre8">As will be explained in the next section, the same result can be obtained using this simple arithmetic expression on the computed integral image as follows:</p><div><pre class="programlisting">  // get sum over an area using three additions/subtractions
  int sumInt= integralImage.at&lt;int&gt;(yo+height,xo+width)
            -integralImage.at&lt;int&gt;(yo+height,xo)
            -integralImage.at&lt;int&gt;(yo,xo+width)
            +integralImage.at&lt;int&gt;(yo,xo);</pre></div><p class="calibre8">Both approaches give you the same result. However, computing the integral image is costly, since you have to loop over all the image pixels. The key is that once this initial computation is done, you will need to add only four pixels to get a sum over a region of interest no matter what the size of this region is. Integral images then become advantageous to use when multiple such pixel sums have to be computed over multiple regions of different sizes.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch04lvl2sec95" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">In the previous section, you were introduced to the concept of integral images through a brief demonstration of the <em class="calibre9">magic</em> behind them, that is, how they can be used to cheaply compute the sum of pixels inside rectangular regions. To understand how they work, let's now define what an integral image is. An integral image is obtained by replacing each pixel with the value of the sum of all the pixels located inside the upper-left quadrant delimitated by this pixel. The integral image can be computed by scanning the image once, as the integral value of a current pixel is given by the integral value of the previously discussed pixel plus the value of the cumulative sum of the current line. The integral image is <a id="id329" class="calibre1"/>therefore a new image containing pixel sums. To <a id="id330" class="calibre1"/>avoid overflows, this image is usually an image of <code class="email">int</code> values (<code class="email">CV_32S</code>) or float values (<code class="email">CV_32F</code>). For example, in the following figure, pixel <strong class="calibre2">A</strong> in this integral image would contain the sum of the pixels contained inside the upper-left corner area, which is identified with a double-hatched pattern. Refer to the following figure:</p><div><img src="img/00045.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Once the integral image has been computed, any summation over a rectangular region can be easily obtained through four pixel accesses, and here is why. Considering the preceding figure again, we can see that the sum of the pixels inside the region delimitated by the pixels <strong class="calibre2">A</strong>, <strong class="calibre2">B</strong>, <strong class="calibre2">C</strong>, and <strong class="calibre2">D</strong> can be obtained by reading the integral value at pixel <strong class="calibre2">D</strong>, from which you subtract the values of the pixels over <strong class="calibre2">B</strong> and to the left-hand side of <strong class="calibre2">C</strong>. However, by doing so, you have subtracted twice the sum of pixels located in the upper-left corner of <strong class="calibre2">A</strong>; this is why you have to re-add the integral sum at <strong class="calibre2">A</strong>. Formally, then, the sum of pixels inside <strong class="calibre2">A</strong>, <strong class="calibre2">B</strong>, <strong class="calibre2">C</strong>, and <strong class="calibre2">D</strong> is given by <em class="calibre9">A-B-C+D</em>. If we use the <code class="email">cv::Mat</code> method to access pixel values, this formula translates to the following:</p><div><pre class="programlisting">      // window at (xo,yo) of size width by height
      return (integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;
                                        (yo+height,xo+width)
            -integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo)
            -integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo+width)
            +integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo));</pre></div><p class="calibre8">The complexity of this computation is, therefore, constant, no matter what the size of the region of interest is. Note that for simplicity, we used the <code class="email">at</code> method of the <code class="email">cv::Mat</code> class, which is not the most efficient way to access pixel values (see <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <em class="calibre9">Manipulating Pixels</em>). This aspect will be discussed in the <em class="calibre9">There's more...</em> section of this recipe, which presents two applications that benefit from the efficiency of the integral image concept.</p></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch04lvl2sec96" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">Integral images<a id="id331" class="calibre1"/> are used whenever multiple pixel summations must be performed. In this section, we will illustrate the use of integral images by introducing the concept of adaptive thresholding. Integral images are also useful for the efficient computation of histograms over multiple windows. This is also explained in this section.</p><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec25" class="calibre1"/>Adaptive thresholding</h3></div></div></div><p class="calibre8">Applying <a id="id332" class="calibre1"/>a threshold<a id="id333" class="calibre1"/> on an image in order to create a binary image could be a good way to extract the meaningful elements of an image. Suppose that you have the following image of a book:</p><div><img src="img/00046.jpeg" alt="Adaptive thresholding" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Since you <a id="id334" class="calibre1"/>are<a id="id335" class="calibre1"/> interested in analyzing the text in this image, you apply a threshold to this image as follows:</p><div><pre class="programlisting">  // using a fixed threshold 
  cv::Mat binaryFixed;
  cv::threshold(image,binaryFixed,70,255,cv::THRESH_BINARY);</pre></div><p class="calibre8">You obtain the following result:</p><div><img src="img/00047.jpeg" alt="Adaptive thresholding" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In fact, no matter what value you choose for the threshold, in some parts of the image, you get missing text, <a id="id336" class="calibre1"/>whereas in other parts, the text disappears under the shadow. To overcome this problem, one possible solution consists of using a local threshold that is computed from each pixel's neighborhood. This strategy is called<a id="id337" class="calibre1"/> <strong class="calibre2">adaptive thresholding</strong>, and it consists of comparing each pixel with the mean value of the neighboring pixels. Pixels that clearly differ from their local mean will then be considered as outliers and will be cut off by the thresholding process.</p><p class="calibre8">Adaptive thresholding, therefore, requires the computation of a local mean around every pixel. This requires multiple image window summations that can be computed efficiently through the integral image. Consequently, the first step is to compute the following integral image:</p><div><pre class="programlisting">  // compute integral image
  cv::Mat iimage;
  cv::integral(image,iimage,CV_32S);</pre></div><p class="calibre8">Now we can go through all the pixels and compute the mean over a square neighborhood. We could use our <code class="email">IntegralImage</code> class to do so, but <a id="id338" class="calibre1"/>this one <a id="id339" class="calibre1"/>uses the inefficient <code class="email">at</code> method for pixel access. This time, let's get efficient by looping over the image using the pointers as we learned in <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <em class="calibre9">Manipulating Pixels</em>. This loop looks as follows:</p><div><pre class="programlisting">  int blockSize= 21; // size of the neighborhood
  int threshold=10;  // pixel will be compared 
                      // to (mean-threshold)

  // for each row
  int halfSize= blockSize/2;
    for (int j=halfSize; j&lt;nl-halfSize-1; j++) {

      // get the address of row j
      uchar* data= binary.ptr&lt;uchar&gt;(j);
      int* idata1= iimage.ptr&lt;int&gt;(j-halfSize);
      int* idata2= iimage.ptr&lt;int&gt;(j+halfSize+1);

      // for pixel of a line
      for (int i=halfSize; i&lt;nc-halfSize-1; i++) {
 
        // compute sum
        int sum= (idata2[i+halfSize+1]-
                     idata2[i-halfSize]-
                 idata1[i+halfSize+1]+
                     idata1[i-halfSize])/
                        (blockSize*blockSize);

        // apply adaptive threshold
        if (data[i]&lt;(sum-threshold))
          data[i]= 0;
        else
          data[i]=255;
      }
    }</pre></div><p class="calibre8">In this example, a neighborhood of size 21 x 21 is used. To compute each mean, we need to access the four integral pixels that delimitate the square neighborhood: two located on the line pointed by <code class="email">idata1</code> and two on the line pointed by <code class="email">idata2</code>. The current pixel is compared to the computed mean, from which we subtract a threshold value (here, set to <code class="email">10</code>); this is to make sure that rejected pixels clearly differ from their local mean. The following binary image is then obtained:</p><div><img src="img/00048.jpeg" alt="Adaptive thresholding" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Clearly, this is a <a id="id340" class="calibre1"/>much better result than the one we got using a fixed threshold. Adaptive thresholding is a common image-processing technique. As such, it is also implemented in OpenCV as follows:</p><div><pre class="programlisting">cv::adaptiveThreshold(image,          // input image
        binaryAdaptive,               // output binary image
        255,                          // max value for output
        cv::ADAPTIVE_THRESH_MEAN_C,   // method
        cv::THRESH_BINARY,            // threshold type
        blockSize,                    // size of the block
        threshold);                   // threshold used</pre></div><p class="calibre8">This function call produces exactly the same result as the one we obtained using our integral image. In addition, instead of using the local mean for thresholding, this function allows you to use a Gaussian weighted sum (the method flag would be <code class="email">ADAPTIVE_THRESH_GAUSSIAN_C</code>) in this case. It is interesting to note that our implementation is slightly faster than the <code class="email">cv::adaptiveThreshold</code> call.</p><p class="calibre8">Finally, it is worth mentioning that we can also write an adaptive thresholding procedure by using the OpenCV image operators. This <a id="id341" class="calibre1"/>would be done as follows:</p><div><pre class="programlisting">  cv::Mat filtered;
  cv::Mat binaryFiltered;
  cv::boxFilter(image,filtered,CV_8U,
                 cv::Size(blockSize,blockSize));
  filtered= filtered-threshold;
  binaryFiltered= image&gt;= filtered;</pre></div><p class="calibre8">Image filtering will be covered in <a class="calibre1" title="Chapter 6. Filtering the Images" href="part0047_split_000.html#page">Chapter 6</a>, <em class="calibre9">Filtering the Images</em>.</p></div><div><div><div><div><h3 class="title2"><a id="ch04lvl3sec26" class="calibre1"/>Visual tracking using histograms</h3></div></div></div><p class="calibre8">As we<a id="id342" class="calibre1"/> learned<a id="id343" class="calibre1"/> in the previous recipes, a histogram constitutes a reliable global representation of an object's appearance. In this recipe, we will demonstrate<a id="id344" class="calibre1"/> the usefulness of integral images by showing you how we can locate an object in an image by searching for an image area that presents a histogram similar to a target object. We accomplished this in the <em class="calibre9">Using the mean shift algorithm to find an object</em> recipe by using the concepts of histogram backprojection and local search through mean shift. This time, we will find our object by performing an explicit search for regions of similar histograms over the full image.</p><p class="calibre8">In the special case where an integral image is used on a binary image made of <code class="email">0</code> and <code class="email">1</code> values, the integral sum gives you the number of pixels that have a value of 1 inside the specified region. We will exploit this fact in this recipe to compute the histogram of a gray-level image.</p><p class="calibre8">The <code class="email">cv::integral</code> function<a id="id345" class="calibre1"/> also works for multichannel images. You can take advantage of this fact to compute histograms of image subregions using integral images. You simply need to convert your image into a multichannel image made of binary planes; each of these planes is associated to a bin of your histogram and shows you which pixels have a value that falls into this bin. The following function creates such multiplane images from a gray-level one:</p><div><pre class="programlisting">// convert to a multi-channel image made of binary planes
// nPlanes must be a power of 2
void convertToBinaryPlanes(const cv::Mat&amp; input, 
                           cv::Mat&amp; output, int nPlanes) {

    // number of bits to mask out
    int n= 8-static_cast&lt;int&gt;(
      log(static_cast&lt;double&gt;(nPlanes))/log(2.0));
    // mask used to eliminate least significant bits
    uchar mask= 0xFF&lt;&lt;n; 

    // create a vector of binary images
    std::vector&lt;cv::Mat&gt; planes;
    // reduce to nBins by eliminating least significant bits
    cv::Mat reduced= input&amp;mask;

    // compute each binary image plane
    for (int i=0; i&lt;nPlanes; i++) {
      // 1 for each pixel equals to i&lt;&lt;shift
      planes.push_back((reduced==(i&lt;&lt;n))&amp;0x1);
    }

    // create multi-channel image
    cv::merge(planes,output);
}</pre></div><p class="calibre8">The <a id="id346" class="calibre1"/>integral image <a id="id347" class="calibre1"/>computations can also be encapsulated into one convenient template class as follows:</p><div><pre class="programlisting">template &lt;typename T, int N&gt;
class IntegralImage {

    cv::Mat integralImage;

  public:

    IntegralImage(cv::Mat image) {

    // (costly) computation of the integral image
    cv::integral(image,integralImage,cv::DataType&lt;T&gt;::type);
    }

    // compute sum over sub-regions of any size 
    // from 4 pixel accesses
    cv::Vec&lt;T,N&gt; operator()(int xo, int yo, 
                             int width, int height) {

    // window at (xo,yo) of size width by height
    return (integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;
                                       (yo+height,xo+width)
        -integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo)
        -integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo+width)
        +integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo));
    }

};</pre></div><p class="calibre8">We now want to find where the girl on the bicycle, whom we identified in the previous image, is in a subsequent image. Let's first compute the histogram of the girl in the original image. We <a id="id348" class="calibre1"/>can accomplish this using the <code class="email">Histogram1D</code> class we built in a previous recipe of this chapter. Here, we produce a 16-bin histogram as follows:</p><div><pre class="programlisting">  // histogram of 16 bins
  Histogram1D h;
  h.setNBins(16);
  // compute histogram over image roi 
  cv::Mat refHistogram= h.getHistogram(roi);</pre></div><p class="calibre8">The preceding <a id="id349" class="calibre1"/>histogram will be used as a referential representation to locate the target object (the girl on her bike) in a subsequent image.</p><p class="calibre8">Suppose that the only information we have is that the girl is moving more or less horizontally over the image. Since we will have many histograms to compute at various locations, we compute the integral image as a preliminary step. Refer to the following code:</p><div><pre class="programlisting">  // first create 16-plane binary image
  cv::Mat planes;
  convertToBinaryPlanes(secondIimage,planes,16);
  // then compute integral image
  IntegralImage&lt;float,16&gt; intHistogram(planes);</pre></div><p class="calibre8">To perform the search, we loop over a range of possible locations and compare the current histogram with the referential one. Our goal is to find the location with the most similar histogram. Refer to the following code:</p><div><pre class="programlisting">  double maxSimilarity=0.0;
  int xbest, ybest;
  // loop over a horizontal strip around girl 
  // location in initial image
  for (int y=110; y&lt;120; y++) {
    for (int x=0; x&lt;secondImage.cols-width; x++) {
  
      // compute histogram of 16 bins using integral image
      histogram= intHistogram(x,y,width,height);
      // compute distance with reference histogram
      double distance= cv::compareHist(refHistogram, 
                                histogram, CV_COMP_INTERSECT);
      // find position of most similar histogram
      if (distance&gt;maxSimilarity) {

        xbest= x;
        ybest= y;
        maxSimilarity= distance;
      }
    }
  }
  // draw rectangle at best location
  cv::rectangle(secondImage,
                 cv::Rect(xbest,ybest,width,height),0));</pre></div><p class="calibre8">The location with the most similar histogram is then identified as the following:</p><div><img src="img/00049.jpeg" alt="Visual tracking using histograms" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The white rectangle represents<a id="id350" class="calibre1"/> the search area. Histograms <a id="id351" class="calibre1"/>of all windows that fit inside this area have been computed. We kept the window size constant, but it could have been a good strategy to also search for slightly smaller or larger windows in order to take into account the eventual changes in scale. Note that in order to limit the complexity of this computation, the number of bins in the histograms to be computed should be kept low. In our example, we reduced this to <code class="email">16</code> bins. Consequently, plane <code class="email">0</code> of this multiplane image contains a binary image that shows you all pixels that have a value between <code class="email">0</code> and <code class="email">15</code>, while plane <code class="email">1</code> shows you pixels with values between <code class="email">16</code> and <code class="email">31</code>, and so on.</p><p class="calibre8">The search for an <a id="id352" class="calibre1"/>object consisted of computing the histograms of all windows of the given size over a predetermined range of pixels. This represents the computation of <code class="email">3200</code> different histograms that have been efficiently computed<a id="id353" class="calibre1"/> from our integral image. All the histograms returned by our <code class="email">IntegralImage</code> class are contained in a <code class="email">cv::Vec</code> object (because of the use of the <code class="email">at</code> method). We then use the <code class="email">cv::compareHist</code> function to identify the most similar histogram (remember that this function, like most OpenCV functions, can accept either the <code class="email">cv::Mat</code> or <code class="email">cv::Vec</code> object through the convenient <code class="email">cv::InputArray</code> generic parameter type).</p></div></div></div>

<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch04lvl2sec97" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a class="calibre1" title="Chapter 8. Detecting Interest Points" href="part0058_split_000.html#page">Chapter 8</a>, <em class="calibre9">Detecting Interest Points</em>, will present the <code class="email">SURF</code> operator that also relies on the use of integral images</li><li class="listitem">The article <em class="calibre9">Robust Fragments-based Tracking using the Integral Histogram</em> by <em class="calibre9">A. Adam, E. Rivlin, and I. Shimshoni in the proceedings of the Int. Conference on Computer Vision and Pattern Recognition, 2006, pp. 798-805</em>, describes an interesting approach that uses integral images to track objects in an image sequence</li></ul></div></div></div></body></html>