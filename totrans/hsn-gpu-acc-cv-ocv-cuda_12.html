<html><head></head><body><div><div><h1 class="header-title">Basic Computer Vision Applications Using PyCUDA</h1>
                
            
            
                
<p>In the previous chapter, we saw important programming concepts related to PyCUDA. We also learned how to develop some programs in PyCUDA using these programming concepts. This chapter will build on this knowledge and we will use PyCUDA for developing basic image processing and computer vision applications. The parallel programming concepts of atomic operations and shared memory will also be explained in detail. The histogram of an image conveys important information related to the contrast of an image and it can also be used as an image feature for computer vision tasks. The program to calculate the histogram using PyCUDA will be explained in detail in this chapter. Other basic computer vision applications, such as the conversion of color spaces, image addition, and image inversion using PyCUDA, will also be described. </p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Histogram calculation using atomic operations and shared memory</li>
<li>Basic computer vision applications using PyCUDA</li>
<li>Color space conversion for an image and video from a webcam</li>
<li>Image addition</li>
<li>Image inversion</li>
</ul>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires a good understanding of the Python programming languages. It also requires any computer or laptop with an Nvidia GPU on board. All the code used in this chapter can be downloaded from the following GitHub link: <a href="https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA">https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA</a>. Check out the following video to see the code in action: <a href="http://bit.ly/2prC1wI">http://bit.ly/2prC1wI</a></p>
<p class="mce-root"/>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Histogram calculation in PyCUDA</h1>
                
            
            
                
<p>The histogram of an image conveys important information related to the contrast of an image, and it can also be used as an image feature for computer vision tasks. A histogram indicates the frequency of the occurrence of a particular pixel value. While calculating the histogram of an 8-bit image that is 256 x 256 in size, the 65,535-pixel values will work on arrays of intensity values from 0-255. If one thread is launched per pixel, then 65,535 threads will work on 256 memory locations of intensity values.</p>
<p>Consider a situation in which a large number of threads try to modify a small portion of memory. While calculating the histogram of an image, read-modify-write operations have to be performed for all memory locations. This operation is <kbd>d_out[i] ++</kbd>, where first <kbd>d_out[i]</kbd> is read from memory, then incremented, and then written back to the memory. However, when multiple threads are doing this operation on the same memory location, it can give an incorrect output.</p>
<p>Suppose one memory location has an initial value of <kbd>0</kbd> and the <kbd>a</kbd> and <kbd>b</kbd> threads try to increment this memory location, then the final answer should be <kbd>2</kbd>. However, at the time of execution, it may happen that both the <kbd>a</kbd> and <kbd>b</kbd> threads read this value simultaneously, then both threads will get the value <kbd>0</kbd>. They increment it to <kbd>1</kbd> and both will store this <kbd>1</kbd> on the memory. So instead of <kbd>2</kbd>, the calculated answer is <kbd>1</kbd>, which is incorrect. </p>
<p>To understand how this can be dangerous, consider the example of an ATM cash withdrawal. Suppose you have a balance of $50,000 in your account. You have two ATM cards for the same account. You and your friend go to two different ATMs simultaneously to withdraw $40,000. Both of you swipe cards simultaneously; so, when the ATMs check the balance, both will get $50,000. If you both withdraw $40,000, then both machines will look at the initial balance, which is $50,000. The amount to withdraw is less than the balance, hence both machines will give $40,000. Even though your balance was $50,000, you got $80,000, which is dangerous. To avoid these scenarios, atomic operations are used when parallel programming, which is explained in the next section.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Using atomic operations</h1>
                
            
            
                
<p>CUDA provides an API called <kbd>atomicAdd</kbd> operations to avoid problems with parallel access of memory locations. It is a blocking operation, which means that when multiple threads try to access the same memory location, only one thread can access the memory location at a time. Other threads have to wait for this thread to finish and write its answer to memory. The kernel function to calculate a histogram using an <kbd>atomicAdd</kbd> operation is shown as follows:</p>
<pre>import pycuda.autoinit<br/>import pycuda.driver as drv<br/>import numpy<br/>import matplotlib.pyplot as plt<br/>from pycuda.compiler import SourceModule<br/>mod = SourceModule("""          <br/>__global__ void atomic_hist(int *d_b, int *d_a, int SIZE)<br/>{<br/> int tid = threadIdx.x + blockDim.x * blockIdx.x;<br/> int item = d_a[tid];<br/> if (tid &lt; SIZE)<br/> {<br/>  atomicAdd(&amp;(d_b[item]), 1);<br/> }<br/>}<br/>""")</pre>
<p>The kernel function has three arguments. The first argument is the output array in which the histogram will be stored after calculation. The size of this array will be 256 for an 8-bit image. The second argument is the flattened array of image intensities. The third argument is the size of a flattened array. The memory location of the histogram array indexed by pixel intensity at the thread index will be incremented for every thread. The number of threads is equal to the size of a flattened image array.  </p>
<p>The <kbd>atomicAdd</kbd> function is used to increment memory location. It takes two arguments. The first is the memory location we want to increment, and the second is the value by which this location has to be incremented. The <kbd>atomicadd</kbd> function will increase the cost in terms of execution time for histogram calculation. The Python code for histogram calculation using atomic operations is as follows:</p>
<pre>atomic_hist = mod.get_function("atomic_hist")<br/>import cv2<br/>h_img = cv2.imread("cameraman.tif",0)<br/><br/>h_a=h_img.flatten()<br/>h_a=h_a.astype(numpy.int)<br/>h_result = numpy.zeros(256).astype(numpy.int)<br/>SIZE = h_img.size<br/>NUM_BIN=256<br/>n_threads= int(numpy.ceil((SIZE+NUM_BIN-1) / NUM_BIN))<br/>start = drv.Event()<br/>end=drv.Event()<br/>start.record()<br/>atomic_hist(<br/>    drv.Out(h_result), drv.In(h_a), numpy.uint32(SIZE),<br/>    block=(n_threads,1,1), grid=(NUM_BIN,1))<br/><br/>end.record()<br/>end.synchronize()<br/>secs = start.time_till(end)*1e-3<br/>print("Time for Calculating Histogram on GPU with shared memory")<br/>print("%fs" % (secs)) <br/>plt.stem(h_result)<br/>plt.xlim([0,256])<br/>plt.title("Histogram on GPU")</pre>
<p>The pointer reference to the kernel function is created using the <kbd>get_function()</kbd> method. The image is read using the OpenCV library. If it is not installed for Python, you can execute the following command from the Command Prompt:</p>
<pre><strong>$pip install opencv-python</strong></pre>
<p>Then, <kbd>OpenCV</kbd> library can be imported from any Python program using the <kbd>import cv2</kbd> command. The image read function is similar to what has been explained earlier in this book. The image is read as a grayscale image. The image is stored as a <kbd>numpy</kbd> array in Python. This array is flattened to a vector so that it can be operated upon by one-dimensional threads and blocks. It is also possible to work on an image with two-dimensional threads without flattening it. The <kbd>numpy</kbd> library provides a <kbd>flatten()</kbd> method to perform this operation.</p>
<p> The total number of blocks and threads are calculated from the size of an image and the number of bins for the histogram. The flattened image array, blank histogram array, and size of the flattened array are passed as arguments while calling the kernel function along with the number of blocks and threads to be launched. The kernel function returns the calculated histogram, which can be displayed or plotted.</p>
<p>Python provides a <kbd>matplotlib</kbd> library that contains a rich set of plotting functions. The <kbd>stem</kbd> function from this library is used to plot a discrete <kbd>histogram</kbd> function. The <kbd>xlim</kbd> function is used to set limits of the <em>X </em>axis. The <kbd>title</kbd> function is used to give a title to the plot. The output of the program is shown in the following diagram:</p>
<div><img class="alignnone size-full wp-image-685 image-border" src="img/3d855bba-b5c5-4a11-a2d7-eb592c3d3b82.png" style="" width="800" height="384"/></div>
<p>If a histogram does not have a uniform distribution of all intensities, then it can result in poor contrast images. The contrast can be enhanced by performing histogram equalization, which converts this distribution to a uniform one. A histogram also conveys information about the brightness of an image. If the histogram is concentrated on the left-hand side of the plot, then the image will be too dark and if it is concentrated on the right-hand side, then the image will be too bright. Again, histogram equalization can be used to correct this issue.</p>
<p>The kernel function for calculating a histogram can also be developed using the concept of shared memory in parallel programming. This is illustrated in the following section.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Using shared memory</h1>
                
            
            
                
<p>Shared memory is available on-chip on a GPU device, hence it is much faster than global memory. Shared memory latency is roughly 100 times lower than uncached global memory latency. All the threads from the same block can access shared memory. This is very useful in many applications where threads need to share their results with other threads. However, it can also create chaos or false results if this is not synchronized. If one thread reads data from memory before the other thread has written to it, it can lead to false results. So, this memory access should be controlled or managed properly.  This is done with the <kbd>__syncthreads()</kbd> directive, which ensures that all write operations to memory are completed before moving ahead in the programs. This is also called a <strong>barrier</strong>. The meaning of barrier is that all threads will reach this line and wait for other threads to finish. After all the threads have reached this barrier, they can move further. This section will demonstrate how shared memory can be used from a PyCUDA program.</p>
<p>This concept of shared memory can be utilized for calculating the histogram of an image. The kernel function is shown as follows: </p>
<pre>import pycuda.autoinit<br/>import pycuda.driver as drv<br/>import numpy<br/>import matplotlib.pyplot as plt<br/>from pycuda.compiler import SourceModule<br/><br/>mod1 = SourceModule("""<br/>__global__ void atomic_hist(int *d_b, int *d_a, int SIZE)<br/>{<br/> int tid = threadIdx.x + blockDim.x * blockIdx.x;<br/> int offset = blockDim.x * gridDim.x;<br/> __shared__ int cache[256];<br/> cache[threadIdx.x] = 0;<br/> __syncthreads();<br/> <br/> while (tid &lt; SIZE)<br/> {<br/>  atomicAdd(&amp;(cache[d_a[tid]]), 1);<br/>  tid += offset;<br/> }<br/> __syncthreads();<br/> atomicAdd(&amp;(d_b[threadIdx.x]), cache[threadIdx.x]);<br/>}<br/>""")</pre>
<p>The number of bins is 256 for an 8-bit image, so we are defining shared memory of size equal to the number of threads in a block, which is equal to a number of bins. We will calculate a histogram for the current block, so shared memory is initialized to zero and the histogram is computed for this block in the same way as discussed earlier. But this time, the result is stored in shared memory and not in global memory. In this case, only 256 threads are trying to access 256 memory elements in shared memory instead of all 65,535 elements from the previous code. This will help in reducing the overhead time in the atomic operation. The final atomic add in the last line will add a histogram of one block to overall histogram values. As addition is a cumulative operation, we do not have to worry about the order in which each block is executed. The Python code to use this kernel function to calculate a histogram is shown as follows:</p>
<pre>atomic_hist = mod.get_function("atomic_hist")<br/><br/>import cv2<br/>h_img = cv2.imread("cameraman.tif",0)<br/><br/>h_a=h_img.flatten()<br/>h_a=h_a.astype(numpy.int)<br/>h_result = numpy.zeros(256).astype(numpy.int)<br/>SIZE = h_img.size<br/>NUM_BIN=256<br/>n_threads= int(numpy.ceil((SIZE+NUM_BIN-1) / NUM_BIN))<br/>start = drv.Event()<br/>end=drv.Event()<br/>start.record()<br/>atomic_hist(<br/> drv.Out(h_result), drv.In(h_a), numpy.uint32(SIZE),<br/> block=(n_threads,1,1), grid=(NUM_BIN,1),shared= 256*4)<br/><br/>end.record()<br/>end.synchronize()<br/>secs = start.time_till(end)*1e-3<br/>print("Time for Calculating Histogram on GPU with shared memory")<br/>print("%fs" % (secs)) <br/>plt.stem(h_result)<br/>plt.xlim([0,256])<br/>plt.title("Histogram on GPU")</pre>
<p>The code is almost similar to that in the last section. The only difference is in the kernel call. The size of the shared memory should be defined while calling the kernel. This can be specified using the shared argument in the kernel call function. It is specified as <kbd>256*4</kbd> because the shared memory has a size of 256 integer elements, which require 4 bytes of storage each. The same histogram will be displayed as shown in the previous section.</p>
<p>To check the authenticity of the calculated histogram and compare the performance, the histogram is also calculated using the OpenCV inbuilt function, <kbd>calcHist</kbd>, as shown in the following code:</p>
<pre>start = cv2.getTickCount()<br/>hist = cv2.calcHist([h_img],[0],None,[256],[0,256])<br/>end = cv2.getTickCount()<br/>time = (end - start)/ cv2.getTickFrequency()<br/>print("Time for Calculating Histogram on CPU")<br/>print("%fs" % (secs))</pre>
<p>The <kbd>calcHist</kbd> function requires five arguments. The first argument is the name of the image variable. The second argument specifies the channels in the case of a color image. It is zero for a grayscale image. The third argument specifies the mask if you want to calculate the histogram for a particular portion of an image. The fourth argument specifies the number of bins, and the fifth argument specifies the range of intensity values. OpenCV also provides <kbd>getTickCount</kbd> and <kbd>getTickFrequency</kbd> functions in Python for calculating the performance of the OpenCV code. The performance of the code without shared memory, with shared memory, and using the OpenCV function, is shown as follows: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-686 image-border" src="img/134bdb0d-ff13-4ef0-947e-80b4afae24b5.png" style="width:50.42em;height:15.75em;" width="605" height="189"/></p>
<p>The time taken by the kernel function without shared memory is 1 ms while, using shared memory, it is 0.8 ms, which further proves the point that the use of shared memory improves the performance of kernel functions. To summarize, in this section, we have seen two different methods of calculating histograms on the GPU. We have also seen the concept of atomic operations and shared memory, along with how they can be used in PyCUDA. </p>
<p class="mce-root"/>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Basic computer vision operations using PyCUDA</h1>
                
            
            
                
<p>This section will demonstrate the use of PyCUDA in developing simple computer vision applications. Images in Python are nothing but two- or three-dimensional <kbd>numpy</kbd> arrays, hence working and manipulating images in PyCUDA is similar to working with multidimensional arrays. This section will give you a basic idea of developing a simple application that you can utilize in developing complex computer vision applications using PyCUDA.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Color space conversion in PyCUDA</h1>
                
            
            
                
<p>Most computer vision algorithms work on grayscale images, so there is a need for converting a color image captured from a camera to a grayscale image. Though OpenCV provides an inbuilt function to do this operation, it can be done by developing your own function. This section will demonstrate the method to develop a PyCUDA function for converting a color image to a grayscale image. If formulas for converting an image from one color space into another are known, then the function shown in this section can be written for any color space conversion by just replacing formulas.</p>
<p>OpenCV captures and stores image in BGR format, where blue is the first channel followed by green and red. The formula to convert from BGR format to grayscale is given as follows:</p>
<pre>gray = 0.299*r+0.587*g+0.114*b Where r,g,b are color intensities of red, green and blue channel at a particular location</pre>
<p>The implementation of this function for an image and video is shown in the following two subsections.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">BGR to gray conversion on an image</h1>
                
            
            
                
<p>In this section, we will try to develop the kernel function for converting a BGR image into a grayscale image. The kernel function for converting a color image into grayscale is shown as follows: </p>
<pre>import pycuda.driver as drv<br/>from pycuda.compiler import SourceModule<br/>import numpy as np<br/>import cv2<br/>mod = SourceModule \<br/>  (<br/>    """<br/>#include&lt;stdio.h&gt;<br/>#define INDEX(a, b) a*256+b<br/><br/>__global__ void bgr2gray(float *d_result,float *b_img, float *g_img, float *r_img)<br/>{<br/> unsigned int idx = threadIdx.x+(blockIdx.x*(blockDim.x*blockDim.y));<br/> unsigned int a = idx/256;<br/> unsigned int b = idx%256;<br/> d_result[INDEX(a, b)] = (0.299*r_img[INDEX(a, b)]+0.587*g_img[INDEX(a, b)]+0.114*b_img[INDEX(a, b)]);<br/><br/>}<br/> """<br/>)</pre>
<p>A small <kbd>INDEX</kbd> function is defined to calculate a particular index value for a two-dimensional image of 256 x 256 in size. The flattened image arrays of three channels of a color image are taken as the input of the kernel function and its output is the grayscale image of the same size. The <kbd>INDEX</kbd> function is used to convert the thread index into a particular pixel location in an image. The grayscale value at that location is calculated using the function shown. The Python code for converting a color image to a grayscale image is shown as follows: </p>
<pre>h_img = cv2.imread('lena_color.tif',1)<br/>h_gray=cv2.cvtColor(h_img,cv2.COLOR_BGR2GRAY)<br/>#print a<br/>b_img = h_img[:, :, 0].reshape(65536).astype(np.float32)<br/>g_img = h_img[:, :, 1].reshape(65536).astype(np.float32)<br/>r_img = h_img[:, :, 2].reshape(65536).astype(np.float32)<br/>h_result=r_img<br/>bgr2gray = mod.get_function("bgr2gray")<br/>bgr2gray(drv.Out(h_result), drv.In(b_img), drv.In(g_img),drv.In(r_img),block=(1024, 1, 1), grid=(64, 1, 1))<br/><br/>h_result=np.reshape(h_result,(256,256)).astype(np.uint8)<br/>cv2.imshow("Grayscale Image",h_result)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</pre>
<p>The color image is read using the OpenCV <kbd>imread</kbd> function. The size of an image should be 256 x 256, so if it isn't, then it should be converted into that size using the <kbd>cv2.resize</kbd> function. The color image is stored in BGR format so blue, green, and red channels are separated from it using array slicing in Python. These arrays are flattened so that they can be passed to a kernel function. </p>
<p>The kernel function is called with three color channels as input and an array to store the output grayscale image. The kernel function will calculate a grayscale value at every pixel location and return a flattened array of a grayscale image. This resultant array is converted back to the original image size using the <kbd>reshape</kbd> function from the <kbd>numpy</kbd> library. The OpenCV <kbd>imshow</kbd> function needs an unsigned integer data type for displaying the image so that an array is also converted to the <kbd>uint8</kbd> data type. The grayscale image is displayed on the screen, as shown in the following screenshot:</p>
<div><img class="alignnone size-full wp-image-687 image-border" src="img/7458e8e8-add3-465f-b622-0fe1c14c3049.png" style="" width="617" height="314"/></div>


            

            
        
    </div></div>
<div><div><h1 class="header-title">BGR to gray conversion on a webcam video</h1>
                
            
            
                
<p>The same kernel function developed in the last section to convert an image into grayscale can be utilized to convert a video captured from a webcam into grayscale. The Python code for this is shown as follows:</p>
<pre>cap = cv2.VideoCapture(0)<br/>bgr2gray = mod.get_function("bgr2gray")<br/>while(True):<br/>  # Capture frame-by-frame<br/>  ret, h_img = cap.read()<br/>  h_img = cv2.resize(h_img,(256,256),interpolation = cv2.INTER_CUBIC)<br/><br/>  b_img = h_img[:, :, 0].reshape(65536).astype(np.float32)<br/>  g_img = h_img[:, :, 1].reshape(65536).astype(np.float32)<br/>  r_img = h_img[:, :, 2].reshape(65536).astype(np.float32)<br/>  h_result=r_img<br/>  <br/>  bgr2gray(drv.Out(h_result), drv.In(b_img), drv.In(g_img),drv.In(r_img),block=(1024, 1, 1), grid=(64, 1, 1))<br/><br/>  h_result=np.reshape(h_result,(256,256)).astype(np.uint8)<br/>  cv2.imshow("Grayscale Image",h_result)<br/><br/>  # Display the resulting frame<br/>  cv2.imshow('Original frame',h_img)<br/>  if cv2.waitKey(50) &amp; 0xFF == ord('q'):<br/>    break<br/><br/># When everything done, release the capture<br/>cap.release()<br/>cv2.destroyAllWindows()</pre>
<p>OpenCV in Python provides a <kbd>VideoCapture</kbd> class to capture video from a webcam. It requires a camera device index as an argument. It is specified as zero for a webcam. Then, a continuous <kbd>while</kbd> loop is started to capture frames from the webcam. The frames are read using the <kbd>read</kbd> method of a capture object. These frames are resized to 256 x 256 using the <kbd>resize</kbd> function of the <kbd>cv2</kbd> library. These frames are color images, so three channels are separated from them and flattened so that they can be passed to a kernel function. The kernel function is called in the same way as in the last section, and the result from it is reshaped for displaying on the screen. The output of the code for one frame of webcam stream is shown as follows:</p>
<div><img class="alignnone size-full wp-image-688 image-border" src="img/07916faa-c2e1-41c4-8a9a-37e22fff0b5f.png" style="" width="523" height="298"/></div>
<p>The webcam streaming will continue until the <em>q</em> key is pressed on the keyboard. To summarize, we have developed a kernel function in PyCUDA to convert a color image in BGR format into a grayscale image, which can work on an image as well as video. These kernel functions can be modified for other color space conversions by replacing equations for the same. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image addition in PyCUDA</h1>
                
            
            
                
<p>The addition of two images can be performed when two images are of the same size. It performs a pixel-wise addition of two images. Suppose that, in two images, the pixel at (0,0) has intensity values of 100 and 150 respectively, then the intensity value in the resultant image will be 250, which is the addition of two intensity values, as shown in the following equation:</p>
<pre>result = img1 + img2 </pre>
<p>OpenCV addition is a saturated operation, which means that if an answer of addition goes above 255, then it will be saturated at 255. So, the same functionality is implemented as a PyCUDA kernel function. The code to perform image addition is shown as follows: </p>
<pre>import pycuda.driver as drv<br/>from pycuda.compiler import SourceModule<br/>import numpy as np<br/>import cv2<br/>mod = SourceModule \<br/> (<br/>"""<br/> __global__ void add_num(float *d_result, float *d_a, float *d_b,int N)<br/>{<br/> int tid = threadIdx.x + blockIdx.x * blockDim.x; <br/> while (tid &lt; N)<br/>  {<br/> d_result[tid] = d_a[tid] + d_b[tid];<br/> if(d_result[tid]&gt;255)<br/> {<br/> d_result[tid]=255;<br/> }<br/> tid = tid + blockDim.x * gridDim.x;<br/>}<br/>}<br/>"""<br/>)<br/>img1 = cv2.imread('cameraman.tif',0)<br/>img2 = cv2.imread('circles.png',0)<br/>h_img1 = img1.reshape(65536).astype(np.float32)<br/>h_img2 = img2.reshape(65536).astype(np.float32)<br/>N = h_img1.size<br/>h_result=h_img1<br/>add_img = mod.get_function("add_num")<br/>add_img(drv.Out(h_result), drv.In(h_img1), drv.In(h_img2),np.uint32(N),block=(1024, 1, 1), grid=(64, 1, 1))<br/>h_result=np.reshape(h_result,(256,256)).astype(np.uint8)<br/>cv2.imshow("Image after addition",h_result)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</pre>
<p>The kernel function is similar to the array addition kernel function seen in the last chapter. The saturation condition is added to the kernel function, which indicates that if pixel intensity goes beyond 255 after addition, then it will be saturated at 255. Two images of the same size are read, flattened, and converted into a single precision floating point data type. These flattened images, along with their size, are passed as arguments to the kernel function. The result calculated by the kernel function is reshaped to the original image size and converted into an unsigned integer type for displaying, using the <kbd>imshow</kbd> function. The result is shown in the following screenshot, along with the original images:</p>
<div><img class="alignnone size-full wp-image-689 image-border" src="img/d61c8000-e347-4ead-a9fe-31422c27b7f0.png" style="" width="803" height="285"/></div>
<p>The same kernel functions can be used for other arithmetic and logical operations with minor modifications.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Image inversion in PyCUDA using gpuarray</h1>
                
            
            
                
<p>Apart from arithmetic operations, the <kbd>NOT</kbd> operation is also widely used for inverting an image where black is converted into white and white is converted into black. It can be represented by the following equation:</p>
<pre>result_image = 255 - input_image</pre>
<p>In the preceding equation, 255 indicates the maximum intensity value for an 8-bit image. The <kbd>gpuarray</kbd> class provided by PyCUDA is used to develop a program for image inversion, as follows: </p>
<pre>import pycuda.driver as drv<br/>import numpy as np<br/>import cv2<br/>import pycuda.gpuarray as gpuarray<br/>import pycuda.autoinit<br/> <br/>img = cv2.imread('circles.png',0)<br/>h_img = img.reshape(65536).astype(np.float32)<br/>d_img = gpuarray.to_gpu(h_img)<br/>d_result = 255- d_img<br/>h_result = d_result.get()<br/>h_result=np.reshape(h_result,(256,256)).astype(np.uint8)<br/>cv2.imshow("Image after addition",h_result)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</pre>
<p>The image is read as a grayscale image, flattened and converted into a single precision floating point data type for further processing. It is uploaded to the GPU using the <kbd>to_gpu</kbd> method of a <kbd>gpuarray</kbd> class. The inversion is performed on the GPU using the preceding equation and the result is downloaded back to the host using the <kbd>get()</kbd> method. The result is displayed on the screen by reshaping it to the original image size, as shown in the following screenshot:</p>
<div><img class="alignnone size-full wp-image-690 image-border" src="img/63d9d72c-1604-4e0f-bedc-b08461c13072.png" style="" width="525" height="288"/></div>
<p>To summarize, this section demonstrated the use of PyCUDA in developing basic computer vision operations, such as color space conversions, image addition, and image inversion. This concept can be used to develop complex computer vision applications using PyCUDA.</p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>This chapter described the use of PyCUDA in the development of simple computer vision applications. It described the use of PyCUDA in calculating the histogram of an array. The histogram is a very important statistical global feature of an image that can be used to find out important information about it. The concept of atomic operations and shared memory was explained in detail, using histogram calculation as an example. Images in Python are stored as <kbd>numpy</kbd> arrays, so manipulating images in PyCUDA is similar to modifying multidimensional <kbd>numpy</kbd> arrays. This chapter described the use of PyCUDA in various basic computer vision applications, such as image addition, image inversion, and color space conversion. The concepts described in this chapter can be utilized for developing complex computer vision applications using PyCUDA.</p>
<p>This chapter also marks an end to this book, which described the use of CUDA programming and GPU hardware in accelerating computer vision applications. </p>


            

            
        
    </div></div>
<div><div><h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>State true or false: The use of the <kbd>d_out[i]++</kbd> line instead of the <kbd>atomicadd</kbd> operation will yield an accurate result in histogram calculation.</li>
<li>What is the advantage of using shared memory with atomic operations?</li>
<li>What is the modification in the kernel call function when shared memory is used in the kernel?</li>
<li>Which information can be obtained by calculating the histogram of an image?</li>
<li>State true or false: The kernel function developed in this chapter for BGR into grayscale conversion will also work for RGB into grayscale conversion.</li>
<li>Why is the image flattened in all of the examples shown in this chapter? Is it a compulsory step?</li>
<li>Why is the image converted into the <kbd>uint8</kbd> data type from the <kbd>numpy</kbd> library before being displayed?</li>
</ol>


            

            
        
    </div></div></body></html>