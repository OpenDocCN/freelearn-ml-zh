<html><head></head><body>
		<div id="_idContainer100">
			<h1 id="_idParaDest-126"><em class="italic"><a id="_idTextAnchor129"/>Chapter 9</em>: Implementing a Batch Scoring Solution</h1>
			<p>You have trained regression, classification, and forecasting models with AutoML in Azure, and now it's time you learn how to put them in production and use them. <strong class="bold">Machine learning</strong> (<strong class="bold">ML</strong>) models, after all, are ultimately used to make predictions on new data, either in real time or in batches. In order to score new data points in batches in Azure, you must first create an ML pipeline. </p>
			<p>An ML pipeline lets you run repeatable Python code in the <strong class="bold">Azure Machine Learning services</strong> (<strong class="bold">AMLS</strong>) that you can run on a schedule. While you can run any Python code using an ML pipeline, here you will learn how to build pipelines for scoring new data.</p>
			<p>You will begin this chapter by writing a simple ML pipeline to score data using the multiclass classification model you trained on the Iris dataset in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. Using the same data, you will then learn how to score new data points in parallel, enabling you to quickly score models with millions to billions of data points simultaneously. </p>
			<p>Once you have written these two pipelines, you will learn how to create an ML pipeline for retraining an AutoML model. Finally, you will learn how to retrigger ML pipelines both manually through the GUI and programmatically through the <strong class="bold">Azure ML SDK</strong>.  </p>
			<p>By the end of this chapter, you will be able to not only train AutoML models but also use them to score new data in a reproducible, automatable fashion. Furthermore, the code and techniques you learn here apply to all ML models, not just those that are AutoML-generated. Coding batch scoring solutions is a key skill for any ML engineer, and by working through the exercises in this chapter, you will be well on your way to mastering that skill.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Creating an ML pipeline</li>
				<li>Creating a parallel scoring pipeline</li>
				<li>Creating an AutoML training pipeline</li>
				<li>Triggering and scheduling your ML pipelines</li>
			</ul>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor130"/>Technical requirements</h1>
			<p>This chapter will feature a lot of coding using Jupyter notebooks within AMLS. Thus, you will need a working internet connection, an <strong class="bold">AMLS workspace</strong>, and a <strong class="bold">compute instance</strong>. ML pipelines also require a <strong class="bold">compute cluster</strong>. You will also need to have trained and registered the Iris multiclass classification model in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. </p>
			<p>The following are the prerequisites for the chapter:</p>
			<ul>
				<li>Access to the internet.</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium.</li>
				<li>A Microsoft Azure account.</li>
				<li>Have created an AMLS workspace.</li>
				<li>Have created the <strong class="source-inline">compute-cluster</strong> compute cluster in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>.</li>
				<li>Understand how to navigate to the Jupyter environment from an Azure compute instance as demonstrated in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</li>
				<li>Have trained and registered the <strong class="source-inline">Iris-Multi-Classification-AutoML</strong> ML model in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>.</li>
			</ul>
			<p>The code for this chapter is available here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter09</a>.</p>
			<h1 id="_idParaDest-128"><a id="_idTextAnchor131"/>Creating an ML pipeline</h1>
			<p>ML pipelines<a id="_idIndexMarker488"/> are Azure's solution for batch scoring ML models. You can use ML pipelines to score any model you train, including your own custom models as well as AutoML-generated models. They can only be created via code using the Azure ML Python SDK. In this section, you will code a simple pipeline to score diabetes data using the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> model you built in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</p>
			<p>As in other chapters, you will begin by opening your compute instance and navigating to your Jupyter notebook environment. You will then create and name a new notebook. Once your notebook is created, you will build, configure, and run an ML pipeline step by step. After confirming your pipeline has run successfully, you will then publish your ML pipeline to a pipeline<a id="_idIndexMarker489"/> endpoint. <strong class="bold">Pipeline endpoints</strong> are simply URLs, web addresses that call ML pipeline runs.</p>
			<p>The following steps deviate greatly from previous chapters. You will have to load in many more libraries and also write a custom Python file for scoring new data. You will also learn how <a id="_idIndexMarker490"/>to create <strong class="bold">environments</strong>, that is, artifacts that specify which Python packages, package versions, and software settings you are using. </p>
			<p>In addition to creating an environment, you will need to containerize it. Finally, you will need to configure and run your ML pipeline, completing the process by publishing your pipeline to an endpoint. The entire process is shown in <em class="italic">Figure 9.1</em>:</p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/Figure_9.1_B16595.jpg" alt="Figure 9.1 – Steps involved in creating your ML scoring pipeline "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Steps involved in creating your ML scoring pipeline</p>
			<p>The <strong class="source-inline">ML-Scoring-Pipeline.ipynb</strong> file in the <a id="_idIndexMarker491"/>GitHub repository contains the code for all the steps.</p>
			<h2 id="_idParaDest-129"><a id="_idTextAnchor132"/>Coding the first three steps of your ML scoring pipeline </h2>
			<p>First, load in your<a id="_idIndexMarker492"/> libraries, set up your AMLS resources, and create a dataset to score with the following steps:</p>
			<ol>
				<li>Open <strong class="bold">Azure Machine Learning studio</strong> (<strong class="bold">AML studio</strong>) by <a id="_idIndexMarker493"/>navigating to <a href="https://ml.azure.com/">https://ml.azure.com/</a>.</li>
				<li>Click <strong class="bold">Compute</strong> and start up a compute instance. Any compute instance will work, as they all link to the same Jupyter notebook environment.</li>
				<li>Create a new Jupyter notebook and name it <strong class="source-inline">machine-learning-pipeline</strong>. If you need a refresher on how to do this, please review <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>.</li>
				<li>Open your newly created notebook and begin by importing all of the standard Azure libraries you will need using the following code: <p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment, Environment, Model</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p><a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, explains <strong class="source-inline">Workspace</strong>, <strong class="source-inline">Dataset</strong>, <strong class="source-inline">Datastore</strong>, <strong class="source-inline">Experiment</strong>, and <strong class="source-inline">ComputeTarget</strong>. <strong class="source-inline">Environment</strong> lets you create an object that contains information on which Python packages your ML pipeline will need to install to run successfully. <strong class="source-inline">Model</strong> lets you retrieve your previously trained ML models.</p></li>
				<li>Continuing on, import all of the Azure ML pipeline libraries with the following code:<p class="source-code">from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE</p><p class="source-code">from azureml.pipeline.steps import PythonScriptStep</p><p class="source-code">from azureml.pipeline.core import Pipeline, PublishedPipeline</p><p class="source-code">from azureml.pipeline.core import StepSequence</p><p class="source-code">from azureml.widgets import RunDetails</p><p><strong class="source-inline">RunConfiguration</strong> stores information that your ML pipeline will need to run, including the environment and base image. <strong class="source-inline">CondaDependencies</strong> lets you add Python packages to your environment. <strong class="source-inline">Default_CPU_Image</strong> is needed to specify<a id="_idIndexMarker494"/> which base image you will use in your run configuration. <strong class="source-inline">PythonScriptStep</strong> is a type of <strong class="bold">ML pipeline step</strong> for running non-specialized Python code. </p><p>There are additional specialized ML pipeline steps used for tasks such as training AutoML models that fall outside the scope of this chapter. </p><p><strong class="source-inline">Pipeline</strong> is the core package to build ML pipelines. <strong class="source-inline">PublishedPipeline</strong> lets you publish ML pipelines to endpoints. <strong class="source-inline">StepSequence</strong> lets you set the order of your ML pipeline steps and <strong class="source-inline">RunDetails</strong> simply shows you the output of your ML pipeline as it runs.</p><p class="callout-heading">Important note</p><p class="callout">If you are having trouble loading any Azure libraries, update the Azure ML SDK by running the <strong class="source-inline">Update AzureML SDK.ipynb</strong> notebook found here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb</a>.</p></li>
				<li>Import <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, and <strong class="source-inline">os</strong>. <strong class="source-inline">os</strong> will let you create and manipulate files and folders from your Jupyter notebook. <strong class="source-inline">random</strong> will let you generate random numbers, which is useful for simulating new Iris data:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import os</p><p class="source-code">import random as r</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace: <p class="source-code">ws = Workspace.from_config()</p><p>If you are prompted to log in, follow the instructions.</p></li>
				<li>Set your <a id="_idIndexMarker495"/>compute cluster to the one you created in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>: <p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your datastore: <p class="source-code">datastore = Datastore.get_default(ws)</p></li>
				<li>Next, you will create simulated Iris data to score. Begin by creating four variables that contain a list of numbers based on the minimum and maximum values of the original Iris dataset with the following code. These variables contain all the possible values contained within the Iris dataset:<p class="source-code">sepal_length_range = np.arange(4.3, 7.9, 0.1)</p><p class="source-code">sepal_width_range = np.arange(2, 4.4, 0.1)</p><p class="source-code">petal_length_range = np.arange(1, 6.9, 0.1)</p><p class="source-code">petal_width_range = np.arange(0.1, 2.5, 0.1)</p></li>
				<li>Continuing with the creation of simulated Iris data, create an empty <strong class="source-inline">pandas</strong> DataFrame called IrisDF, with the appropriate column names. Also, create an empty list called <strong class="source-inline">IrisList</strong>:<p class="source-code">columns =\ ['sepal_length','sepal_width','petal_length','petal_width']</p><p class="source-code">IrisDF = pd.DataFrame(columns=columns)</p><p class="source-code">IrisList = []</p></li>
				<li>Continuing with the creation of simulated Iris data, use the <strong class="source-inline">choice</strong> function from the <strong class="source-inline">random</strong> package within a <strong class="source-inline">for</strong> loop to create 100 new data points, rounding each value to <strong class="source-inline">1</strong> decimal place. <p>Combine each<a id="_idIndexMarker496"/> set of four data points with the column names in a Python dictionary within the <strong class="source-inline">for</strong> loop and append that dictionary to <strong class="source-inline">IrisList</strong> row by row: </p><p class="source-code">for i in range(0,100):</p><p class="source-code">    values = \</p><p class="source-code">[round(r.choice(sepal_length_range),1),round(r.choice(sepal_width_range),1),round(r.choice(petal_length_range),1),round(r.choice(petal_width_range),1)]</p><p class="source-code">    iris_dictionary = pd.DataFrame(dict(zip(columns, values)),index=[0])</p><p class="source-code">    IrisList.append(iris_dictionary)</p><p>This code will leave you with a list of randomly generated values from the original Iris dataset that can be turned into a <strong class="source-inline">pandas</strong> DataFrame.</p></li>
				<li>Completing the creation of simulated Iris data, append <strong class="source-inline">IrisList</strong> to <strong class="source-inline">IrisDF</strong>:<p class="source-code">IrisDF = IrisDF.append(IrisList,True)</p></li>
				<li>Register your simulated Iris data with the following code:<p class="source-code">Dataset.Tabular.register_pandas_dataframe(IrisDF, datastore, 'Iris_Scoring')</p></li>
			</ol>
			<p>This will save it to your <a id="_idIndexMarker497"/>datastore and create an Azure dataset named <strong class="source-inline">Iris Scoring</strong>.</p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor133"/>Creating a Python script to score data in your ML pipeline</h2>
			<p>In this<a id="_idIndexMarker498"/> section, you will create a folder and <a id="_idIndexMarker499"/>write a Python script that your ML pipeline will execute to score data using the following steps:</p>
			<ol>
				<li value="1">Make a folder to hold your scoring script using <strong class="source-inline">os</strong>: <p class="source-code">os.makedirs('Scoring_Scripts', exist_ok=True)</p><p>For every ML pipeline step you make, you have to have an accompanying Python script.</p></li>
				<li>Write a Python script to score new data. This script is long and has to be one block of code. Begin by writing out a new Python script file called <strong class="source-inline">Iris_Scoring.py</strong> using the <strong class="source-inline">%%writefile</strong> magic command. <strong class="bold">Magic commands</strong> are <a id="_idIndexMarker500"/>enhancements on top of normal Python that let you do common, useful tasks such as writing files. <p>Everything you type in this cell will be written out as a single Python script. Begin by loading in your Azure libraries:</p><p class="source-code">%%writefile Scoring_Scripts/Iris_Scoring.py</p><p class="source-code">from azureml.core import Run, Workspace</p><p class="source-code">from azureml.core import Dataset, Datastore, Model</p><p>You should recognize all of these packages with one exception. <strong class="source-inline">Run</strong> lets your program access the AMLS workspace you used to create the ML pipeline while running remotely on a compute cluster.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, import the other Python packages: <p class="source-code">import joblib</p><p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">import os</p><p>The only new package here is <strong class="source-inline">joblib</strong>, which will let you load saved ML models.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, set a variable called <strong class="source-inline">run</strong> using <a id="_idIndexMarker501"/>the <strong class="source-inline">Run</strong> function. You <a id="_idIndexMarker502"/>can use this variable to set your AMLS workspace:<p class="source-code">run = Run.get_context()</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, we are going to create a function called <strong class="source-inline">main</strong>. This function will run the main part of your scoring code. <p>First, connect to your AMLS workspace using the <strong class="source-inline">run</strong> variable you created. Next, set your datastore to the default option and your dataset to <strong class="source-inline">Iris Scoring</strong>. Convert the <strong class="source-inline">Iris Scoring</strong> dataset into a <strong class="source-inline">pandas</strong> DataFrame called <strong class="source-inline">scoringDF</strong>: </p><p class="source-code">def main():</p><p class="source-code">    ws = run.experiment.workspace</p><p class="source-code">    datastore = Datastore.get_default(ws)</p><p class="source-code">    dataset = Dataset.get_by_name(ws,'Iris Scoring')</p><p class="source-code">    scoringDF = dataset.to_pandas_dataframe()</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, load your <strong class="source-inline">Iris-Multi-Classification-AutoML</strong> model with the Azure <strong class="source-inline">Model</strong> and <strong class="source-inline">joblib</strong> packages:<p class="source-code">    model_path = Model.get_model_path('Iris-Multi-Classification-AutoML')</p><p class="source-code">    model = joblib.load(model_path)</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, use your model to make predictions on <strong class="source-inline">scoringDF</strong>, save those predictions to a <strong class="source-inline">pandas</strong> <strong class="source-inline">Series</strong>, and add the predictions back to your <strong class="source-inline">scoringDF</strong> DataFrame in a new column called <strong class="source-inline">Prediction</strong>:<p class="source-code">    predictions = model.predict(scoringDF)</p><p class="source-code">    predSeries = pd.Series(predictions)</p><p class="source-code">    scoringDF['Prediction'] = predSeries</p><p>When you add<a id="_idIndexMarker503"/> the new column, the <a id="_idIndexMarker504"/>predictions will be in the correct order and match the corresponding row.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, make a folder called <strong class="source-inline">Output_Folder</strong> using <strong class="source-inline">os</strong>:<p class="source-code">    output_datastore_path = 'Output_Folder'</p><p class="source-code">    os.makedirs(output_datastore_path, exist_ok=True) </p><p>This will create a folder on your compute cluster to store your predictions temporarily so you can transfer them to your datastore.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, specify a file called <strong class="source-inline">Iris_Predictions.csv</strong>. Then, use <strong class="source-inline">os</strong> to specify a path on the compute cluster where you will write that file out. Finally, use <strong class="source-inline">to_csv</strong> to write out <strong class="source-inline">scoringDF</strong> to your compute cluster:<p class="source-code">    FileName = "Iris_Predictions.csv"</p><p class="source-code">    OutputPath = os.path.join(output_datastore_path, FileName)</p><p class="source-code">    scoringDF.to_csv(OutputPath, index = False, sep=',')</p><p>This piece of code will write your output to your compute cluster. This is necessary to move it into your datastore.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Scoring.py</strong>, upload <strong class="source-inline">Iris_Predictions.csv</strong> to your datastore. This code will write it to a folder called <strong class="source-inline">Output_Folder</strong>, matching the directory structure on your compute cluster. <p class="source-code">    datastore.upload_files(files=[OutputPath], target_path=output_datastore_path, overwrite=True)</p></li>
				<li>Completing <strong class="source-inline">Iris_Scoring.py</strong>, use <strong class="source-inline">os</strong> to remove the file and folder from your compute cluster. Finish the cell with boilerplate code that will automatically <a id="_idIndexMarker505"/>run your <strong class="source-inline">main</strong> function<a id="_idIndexMarker506"/> when the Python script is called within the ML pipeline:<p class="source-code">    os.remove(OutputPath)</p><p class="source-code">    os.rmdir(output_datastore_path)</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    main()</p></li>
			</ol>
			<p>This completes your Python script. Write the next piece of code in a new cell.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor134"/>Creating and containerizing an environment</h2>
			<p>The difficult <a id="_idIndexMarker507"/>part is<a id="_idIndexMarker508"/> over and the rest is pure boilerplate, beginning with creating an environment. <strong class="bold">Environments</strong> are collections of Python packages that are required to run your code:</p>
			<ol>
				<li value="1">In a new cell, create an environment. Also, set a variable using <strong class="source-inline">CondaDependencies</strong>:<p class="source-code">Env = Environment(name='AutoML Environment')</p><p class="source-code">conda_dep = CondaDependencies()</p><p>All the packages and versions of packages that are required to run your Python script will be added to the <strong class="source-inline">conda_dep</strong> variable in the next step.</p></li>
				<li>Attach Python packages to your <strong class="source-inline">conda_dep</strong> variable, beginning with the packages found in the <strong class="source-inline">conda</strong> package manager:<p class="source-code">conda_dep.add_conda_package("numpy==1.18.5")</p><p class="source-code">conda_dep.add_conda_package("joblib==0.14.1")</p><p class="source-code">conda_dep.add_conda_package("pandas==0.25.3")</p><p class="source-code">conda_dep.add_conda_package("packaging==20.7")</p><p class="source-code">conda_dep.add_conda_package("xgboost==0.90")</p><p>There are <a id="_idIndexMarker509"/>two package managers, <strong class="source-inline">conda</strong> and <strong class="source-inline">pip</strong>. <strong class="source-inline">conda</strong> automatically<a id="_idIndexMarker510"/> resolves dependencies for you. So, if a package requires another package, you don't have to worry about it. <strong class="source-inline">pip</strong> requires you to resolve those dependencies yourself. As a result, if a package is available in both <strong class="source-inline">conda</strong> and <strong class="source-inline">pip</strong>, always install it via <strong class="source-inline">conda</strong>. </p><p>When installing packages, always specify the version. You can discover which version you are using by running the <strong class="source-inline">!pip freeze</strong> command in an empty cell. In addition to <strong class="source-inline">numpy</strong>, <strong class="source-inline">joblib</strong>, and <strong class="source-inline">pandas</strong>, AutoML-generated models also require <strong class="source-inline">packaging</strong> and <strong class="source-inline">xgboost</strong> to run.</p></li>
				<li>Attach Python packages to your <strong class="source-inline">conda_dep</strong> variable that are not available in <strong class="source-inline">conda</strong> using <strong class="source-inline">pip</strong> instead: <p class="source-code">conda_dep.add_pip_package("azureml-defaults==1.19.0")</p><p class="source-code">conda_dep.add_pip_package("azureml-automl-core==1.19.0")</p><p class="source-code">conda_dep.add_pip_package("azureml-automl-runtime==1.19.0")</p><p>There are three packages; <strong class="source-inline">azureml-defaults</strong> enables you to use standard Azure ML SDK functions, while <strong class="source-inline">azureml-automl-core</strong> and <strong class="source-inline">azureml-automl-runtime</strong> are required to score any AutoML-generated models.</p></li>
				<li>Add the <strong class="source-inline">conda_dep</strong> variable to your environment and register the environment to your AMLS workspace by using the following code:<p class="source-code">Env.python.conda_dependencies=conda_dep</p><p class="source-code">RegisteredEnvironment = Env.register(workspace=ws)</p><p>Now that your environment is registered, you can call it anywhere in AMLS.</p></li>
				<li>Create a <strong class="source-inline">RunConfiguration</strong> object for containerizing your environment. Set your<a id="_idIndexMarker511"/> environment, enable<a id="_idIndexMarker512"/> Docker, and use <strong class="source-inline">DEFAULT_CPU_IMAGE</strong> as your base image:<p class="source-code">run_config = RunConfiguration()</p><p class="source-code">run_config.environment = Env</p><p class="source-code">run_config.environment.docker.enabled = True</p><p class="source-code">run_config.environment.docker.base_image =\</p><p class="source-code"> DEFAULT_CPU_IMAGE</p></li>
			</ol>
			<p>This will<a id="_idIndexMarker513"/> create a <strong class="bold">Docker container</strong>, a portable package of code that can be run anywhere as it contains all your code's scripts and dependencies. Your environment can now be utilized by your ML pipeline, which you will configure in the last series of steps.</p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor135"/>Configuring and running your ML scoring pipeline </h2>
			<p>With your <a id="_idIndexMarker514"/>environment built and containerized, your Python script<a id="_idIndexMarker515"/> written, and all your AMLS resources set, you're ready to configure and run your ML pipeline by following these steps:</p>
			<ol>
				<li value="1">Configure your ML pipeline step with the following code. You need to give your step a name, <strong class="source-inline">iris-scoring-step</strong>, and specify your Python script name, Python script folder location, compute target, and run configuration. Always set <strong class="source-inline">allow_reuse</strong> to <strong class="source-inline">False</strong>:<p class="source-code">scoring_step = PythonScriptStep(name='iris-scoring-step',</p><p class="source-code">script_name='Iris_Scoring.py',</p><p class="source-code">source_directory='Scoring_Scripts', </p><p class="source-code">arguments=[],</p><p class="source-code">inputs=[],</p><p class="source-code">compute_target=compute_target,</p><p class="source-code">runconfig=run_config,</p><p class="source-code">allow_reuse=False)</p><p>Setting <strong class="source-inline">allow_reuse</strong> to <strong class="source-inline">True</strong> is for <a id="_idIndexMarker516"/>debugging multi-step <a id="_idIndexMarker517"/>pipelines where you want to skip rerunning a successfully completed step.</p></li>
				<li>Set your <strong class="bold">step sequence</strong> and <strong class="bold">pipeline object</strong>:<p class="source-code">step_sequence = StepSequence(steps=[scoring_step])</p><p class="source-code">pipeline = Pipeline(workspace=ws, steps=step_sequence)</p><p>The step sequence is the order in which your ML pipeline steps will run.</p></li>
				<li>Give your pipeline experiment run a name, <strong class="source-inline">Iris-Scoring-Pipeline-Run</strong>, and submit it with the following code: <p class="source-code">pipeline_experiment = Experiment(ws, 'Iris-Scoring-Pipeline-Run')</p><p class="source-code">pipeline_run = pipeline_experiment.submit(pipeline, show_output=True)</p><p>Finally, this is what kicks your pipeline off!</p></li>
				<li>Use <strong class="source-inline">RunDetails</strong> to watch your pipeline get built and execute in real time:<p class="source-code">RunDetails(pipeline_run).show()</p><p class="source-code">pipeline_run.wait_for_completion(show_output=True)</p><p>As it runs, you will see a lot of logs. If your pipeline runs successfully, it will complete <a id="_idIndexMarker518"/>with the words <strong class="bold">Finished</strong>. You should see a graphic identical to the one in <em class="italic">Figure 9.2</em>:</p><div id="_idContainer090" class="IMG---Figure"><img src="image/Figure_9.2_B16595.jpg" alt="Figure 9.2 – Successful pipeline run graphic "/></div><p class="figure-caption">Figure 9.2 – Successful pipeline run graphic</p></li>
				<li>Publish your pipeline to an endpoint with the following code, specifying a name, description, and version number:<p class="source-code">published_pipeline = pipeline_run.publish_pipeline(</p><p class="source-code">    name='Iris-Scoring-Pipeline',\</p><p class="source-code">    description='Pipeline that Scores Iris Data', version= '1.0')</p><p class="source-code">published_pipeline</p><p>All published pipelines require version numbers set by the creator. Running this code will give you a published pipeline ID as well as a link to the endpoint, as seen in <em class="italic">Figure 9.3</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/Figure_9.3_B16595.jpg" alt="Figure 9.3 – Successfully published pipeline "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Successfully published pipeline</p>
			<p>Now that you have executed and published your scoring pipeline, you can examine and download your <a id="_idIndexMarker519"/>scoring file. It was saved to a folder<a id="_idIndexMarker520"/> called <strong class="source-inline">Output_Folder</strong> in a file called <strong class="source-inline">Iris_Predictions.csv</strong>. Access the file directly by navigating to your storage account. You can do this either from the Azure portal (<a href="https://portal.azure.com">https://portal.azure.com</a>) or via <strong class="bold">AML</strong> <strong class="bold">studio</strong>.</p>
			<h2 id="_idParaDest-133"><a id="_idTextAnchor136"/>Accessing your scored predictions via AML studio</h2>
			<p>To <a id="_idIndexMarker521"/>access <strong class="source-inline">Iris_Predictions.csv</strong> and <a id="_idIndexMarker522"/>download it to your desktop, you first have to locate your storage account. You can find your storage account through AML studio. </p>
			<p>The following steps will have you locate your datastore through the AML studio, access your storage account, navigate to the correct file, and download it to your local machine. This way, you can use the AI-generated predictions for any purpose you wish:</p>
			<ol>
				<li value="1">Navigate to AML studio at <a href="https://ml.azure.com">https://ml.azure.com</a>.</li>
				<li>Click <strong class="bold">Datastores</strong> on the left-hand panel.</li>
				<li>Click the blue link to <strong class="bold">workspaceblobstore</strong> (default) in the center of the page.</li>
				<li>Click the blue link to your storage account under <strong class="bold">Account name</strong>. Each person will have a unique storage account name, prefixed with <strong class="source-inline">automlexamplew</strong> followed by a string of numbers. This will take you to your storage account resource in Azure.</li>
				<li>Once in your storage account, click the blue link to <strong class="bold">Containers</strong> in the center-left of your screen. Clicking anywhere in the box will work.</li>
				<li>You will now see a list of folders. Click the folder that begins with <strong class="source-inline">azureml-blobstore-</strong> followed by a unique identifier ID.</li>
				<li>Click <strong class="bold">Output_Folder</strong>. You should also see folders named <strong class="source-inline">azureml</strong>, <strong class="source-inline">managed-dataset</strong>, and <strong class="source-inline">UI</strong>. These folders hold logs for your experiments, among other<a id="_idIndexMarker523"/> objects. <em class="italic">Figure 9.4</em> shows the folder structure you need to follow to reach your file:<div id="_idContainer092" class="IMG---Figure"><img src="image/Figure_9.4_B16595.jpg" alt="Figure 9.4 – Path to your output files "/></div><p class="figure-caption">Figure 9.4 – Path to your output files</p></li>
				<li>Click <strong class="bold">Iris_Predictions.csv</strong>.</li>
				<li>Click the <strong class="bold">Download</strong> button near the top of your screen to download <strong class="source-inline">Iris_Predictions.csv</strong> to your local machine. It is a comma-separated file with headers.</li>
				<li>Open up your file with Microsoft Excel or similar software to look at your data.</li>
			</ol>
			<p>That was a lot of work, but now you have a working pipeline endpoint that can score new data points in batch. This is a huge accomplishment, as many organizations have trouble setting up such workflows. You can also easily reuse this code in multiple projects, as the vast <a id="_idIndexMarker524"/>majority is boilerplate. While <a id="_idIndexMarker525"/>you have to alter the Python script and add packages as appropriate, this template can also be used to score both AutoML and custom ML models. </p>
			<p>Next, you will learn how to score 10,000,000 data points in no time at all using a parallel scoring pipeline.</p>
			<h1 id="_idParaDest-134"><a id="_idTextAnchor137"/>Creating a parallel scoring pipeline</h1>
			<p>Standard ML <a id="_idIndexMarker526"/>pipelines work just fine for the majority of ML use cases, but when you need to score a large amount of data at once, you need a more powerful solution. That's where <strong class="source-inline">ParallelRunStep</strong> comes in. <strong class="source-inline">ParallelRunStep</strong> is Azure's answer to scoring big data in batch. When you use <strong class="source-inline">ParallelRunStep</strong>, you leverage all of the cores on your compute cluster simultaneously.</p>
			<p>Say you have a compute cluster consisting of eight <strong class="source-inline">Standard_DS3_v2</strong> virtual machines. Each <strong class="source-inline">Standard_DS3_v2</strong> node has four cores, so you can perform 32 parallel scoring processes at once. This parallelization essentially lets you score data many times faster than if you used a single machine. Furthermore, it can easily scale vertically (increasing the size of each virtual machine in the cluster) and horizontally (increasing the node count). </p>
			<p>This section will allow you to become a <em class="italic">big data</em> scientist who can score large batches of data. Here, you will again be using simulated Iris data, but instead of 100 rows, you will be scoring 10 million rows at once. </p>
			<p>Furthermore, this is an advanced solution that utilizes two pipeline steps, a step that scores data in parallel and a step that transfers data to an output folder. By working through this example, you'll understand how to create advanced multi-step pipeline runs to solve difficult problems.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Parallel runs score data in batches, dividing your dataset into many small parts. If you have any data preprocessing that relies on calculations made with previous rows, this preprocessing should be done in a separate <strong class="source-inline">PythonScriptStep</strong> before being passed on to <strong class="source-inline">ParallelRunStep</strong>.</p>
			<p>Much of this code<a id="_idIndexMarker527"/> is similar to the <em class="italic">Creating an ML pipeline</em> section. However, there are two pipeline steps to create instead of one. Furthermore, you will be introduced to new <a id="_idIndexMarker528"/>concepts such as <strong class="bold">pipeline data</strong> and using the <strong class="source-inline">input</strong> and <strong class="source-inline">output</strong> pipeline configuration options. At the end of this section, you will also publish your pipeline to an endpoint. <em class="italic">Figure 9.5</em> shows the entire process:</p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/Figure_9.5_B16595.jpg" alt="Figure 9.5 – Steps involved in creating a parallel scoring pipeline  "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – Steps involved in creating a parallel scoring pipeline </p>
			<p>If you need a refresher on any of the steps, please refer to the <em class="italic">Creating an ML pipeline</em> section. You can find the code for all the steps in the <strong class="source-inline">ML-Parallel-Pipeline.ipynb</strong> file in the GitHub repository.</p>
			<h2 id="_idParaDest-135"><a id="_idTextAnchor138"/>Coding the first three steps of your ML parallel scoring pipeline </h2>
			<p>To create your <a id="_idIndexMarker529"/>parallel scoring pipeline, begin with the following steps:</p>
			<ol>
				<li value="1">Navigate to your Jupyter environment on your compute instance and create a new Jupyter notebook. Name it <strong class="source-inline">ml-parallel-pipeline</strong>.</li>
				<li>Open your newly created notebook and import your standard Azure libraries: <p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment, Environment, Model</p></li>
				<li>From <strong class="source-inline">azureml.core.compute</strong>, import <strong class="source-inline">ComputeTargetNext</strong> and import all of the Azure ML pipeline libraries with the following code: <p class="source-code">from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE</p><p class="source-code">from azureml.pipeline.steps import PythonScriptStep, ParallelRunStep, ParallelRunConfig</p><p class="source-code">from azureml.pipeline.core import Pipeline, PublishedPipeline, PipelineData</p><p class="source-code">from azureml.pipeline.core import StepSequence</p><p class="source-code">from azureml.widgets import RunDetails</p><p>There are three additional packages compared to the previous section. <strong class="source-inline">ParallelRunStep</strong> is an ML pipeline step that lets you run Python code in parallel. <strong class="source-inline">ParallelRunConfig</strong> lets you configure <strong class="source-inline">ParallelRunStep</strong>. <strong class="source-inline">PipelineData</strong> lets you pass intermediate data from one step to another.</p><p class="callout-heading">Important note</p><p class="callout">If you are having trouble loading any Azure libraries, update the Azure ML SDK by running the <strong class="source-inline">Update AzureML SDK.ipynb</strong> notebook found here: <a href="https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb">https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Update-AzureML-SDK.ipynb</a>.</p></li>
				<li>Import <strong class="source-inline">pandas</strong>, <strong class="source-inline">numpy</strong>, <strong class="source-inline">os</strong>, and <strong class="source-inline">random</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import os</p><p class="source-code">import random as r</p></li>
				<li>As always, connect your Jupyter notebook to your AMLS workspace:<p class="source-code">ws = Workspace.from_config()</p><p>If you are prompted to log in, follow the instructions.</p></li>
				<li>Set your <a id="_idIndexMarker530"/>compute cluster with the following code: <p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your datastore: <p class="source-code">datastore = Datastore.get_default(ws)</p></li>
				<li>Use the following code to create simulated Iris data:<p class="source-code">sepal_length_range = np.arange(4.3, 7.9, 0.1)</p><p class="source-code">sepal_width_range = np.arange(2, 4.4, 0.1)</p><p class="source-code">petal_length_range = np.arange(1, 6.9, 0.1)</p><p class="source-code">petal_width_range = np.arange(0.1, 2.5, 0.1)</p></li>
				<li>Continuing with the creation of simulated Iris data, create an empty <strong class="source-inline">pandas</strong> DataFrame and list:<p class="source-code">columns =\</p><p class="source-code">['sepal_length','sepal_width','petal_length','petal_width']</p><p class="source-code">IrisDF = pd.DataFrame(columns=columns)</p><p class="source-code">IrisList = []</p></li>
				<li>Continuing with the creation of simulated Iris data, use the <strong class="source-inline">choice</strong> function from the <strong class="source-inline">random</strong> package within a <strong class="source-inline">for</strong> loop to create 10,000,000 new data points, rounding<a id="_idIndexMarker531"/> each value to <strong class="source-inline">1</strong> decimal place:<p class="source-code">for i in range(0,10000000):</p><p class="source-code">    values =\</p><p class="source-code">[round(r.choice(sepal_length_range),1),round(r.choice(sepal_width_range),1),\</p><p class="source-code">round(r.choice(petal_length_range),1),round(r.choice(petal_width_range),1)]</p><p class="source-code">    iris_dictionary = pd.DataFrame(dict(zip(columns, values)),index=[0])</p><p class="source-code">    IrisList.append(iris_dictionary)</p><p>This will take a while, so give it some time to run.</p></li>
				<li>Completing the creation of simulated Iris data, append <strong class="source-inline">IrisList</strong> to <strong class="source-inline">IrisDF</strong>:<p class="source-code">IrisDF = IrisDF.append(IrisList,True)</p></li>
				<li>Register your simulated Iris data with the following code: <p class="source-code">Dataset.Tabular.register_pandas_dataframe(IrisDF, datastore, 'Iris_Scoring')</p></li>
			</ol>
			<p>This will save it to your datastore and create an Azure dataset named <strong class="source-inline">Iris Parallel Scoring</strong>. You're now ready to write your Python script.</p>
			<h2 id="_idParaDest-136"><a id="_idTextAnchor139"/>Creating Python scripts to score data in your ML parallel pipeline</h2>
			<p>Next, create a <a id="_idIndexMarker532"/>folder and <a id="_idIndexMarker533"/>write two Python scripts that your ML pipeline will execute to score data. You will need one step to make predictions and another step to transfer your output to a final destination on your datastore:</p>
			<ol>
				<li value="1">Make a folder to hold your scoring script using <strong class="source-inline">os</strong>: <p class="source-code">os.makedirs('Scoring_Scripts', exist_ok=True)  </p><p>This folder should already exist from the previous section, but this code will not error out since <strong class="source-inline">exist_ok</strong> is set to <strong class="source-inline">True</strong>. This folder will hold both the scripts you will write for your parallel pipeline run.</p></li>
				<li>Write a Python script to score new data in parallel:<p class="source-code">%%writefile Scoring_Scripts/Iris_Scoring.py</p><p class="source-code">from azureml.core import Run, Workspace</p><p class="source-code">from azureml.core import Dataset, Datastore, Model</p><p>This script is significantly different from the previous script, but also has to be in one cell. Begin by writing a new Python script file called <strong class="source-inline">Iris_Parallel_Scoring.py</strong> using the <strong class="source-inline">%%writefile</strong> magic command. Begin by loading in your Azure libraries. You should recognize all of them from the previous section.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Scoring.py</strong>, import other Python packages, including the new <strong class="source-inline">argparse</strong> package: <p class="source-code">import os</p><p class="source-code">import joblib</p><p class="source-code">import argparse</p><p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p>This package lets you pass arguments into your script. <strong class="bold">Arguments</strong> are flexible pieces of code that you can pass into your pipeline at runtime. For example, you can use arguments to pass in different datastores or datasets.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Scoring.py</strong>, set a variable<a id="_idIndexMarker534"/> called <strong class="source-inline">run</strong> using the <strong class="source-inline">Run</strong> function: <p class="source-code">run = Run.get_context()</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Scoring.py</strong>, create a function <a id="_idIndexMarker535"/>called <strong class="source-inline">init</strong>. This function will pass in your arguments and load your ML model, setting it to a global variable. <p><strong class="bold">Global variables</strong> can be<a id="_idIndexMarker536"/> accessed across functions. Set a variable <a id="_idIndexMarker537"/>called <strong class="source-inline">parser</strong> to store your arguments and add the <strong class="source-inline">model_name</strong> argument to that variable. <strong class="source-inline">ParallelRunStep</strong> <a id="_idIndexMarker538"/>also <a id="_idIndexMarker539"/>passes hidden arguments behind the scenes, so you also need to set <strong class="source-inline">unknown_args</strong>. Once that is done, use <strong class="source-inline">joblib</strong> to load your model using the <strong class="source-inline">model_name</strong> argument, as shown in the following code:</p><p class="source-code">def init():</p><p class="source-code">    parser = argparse.ArgumentParser()</p><p class="source-code">    parser.add_argument('--model_name',\</p><p class="source-code">    dest="model_name", required=True)</p><p class="source-code">    args, unknown_args = parser.parse_known_args()</p><p class="source-code">    global model</p><p class="source-code">    model_path = Model.get_model_path(args.model_name)</p><p class="source-code">    model = joblib.load(model_path)</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Scoring.py</strong>, create a function called <strong class="source-inline">main</strong>. This function will score your data and return the result, which will be automatically stored in a file called <strong class="source-inline">parallel_run_step.txt.model</strong> with the Azure <strong class="source-inline">Model</strong> and <strong class="source-inline">joblib</strong> packages. <p>First, you will use the <strong class="source-inline">predict</strong> function on your <strong class="source-inline">model</strong> variable to make predictions. Notice that the data is automatically passed into this function as a <strong class="source-inline">pandas</strong> DataFrame<a id="_idIndexMarker540"/> called <strong class="source-inline">input_data</strong>. </p><p>You then convert these predictions into a series and add it back to <strong class="source-inline">input_data</strong> as a column<a id="_idIndexMarker541"/> called <strong class="source-inline">Prediction</strong>. Completing <strong class="source-inline">Iris_Parallel_Scoring.py</strong>, you return the finished <strong class="source-inline">input_data</strong> DataFrame <a id="_idIndexMarker542"/>to be <a id="_idIndexMarker543"/>automatically written to the text file:</p><p class="source-code">def run(input_data):</p><p class="source-code">    predictions = model.predict(input_data)  </p><p class="source-code">    predSeries = pd.Series(predictions)</p><p class="source-code">    input_data['Prediction'] = predSeries </p><p class="source-code">    print('Data written to parallel_run_step.txt')</p><p class="source-code">        return input_data </p></li>
				<li>Write a Python script to transfer your results to the output location of your choice. <strong class="source-inline">ParallelRunStep</strong> outputs a file called <strong class="source-inline">parallel_run_step.txt</strong>. This will be stored as pipeline data. <p>Pipeline data is data that is saved in your datastore as an intermediate step to be passed on to another ML pipeline step. Furthermore, <strong class="source-inline">parallel_run_step.txt</strong> has no headers and you need to add them. </p><p>Begin by writing out a new Python script file called <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong> using the <strong class="source-inline">%%writefile</strong> magic command. Start by loading in your Azure libraries as usual:</p><p class="source-code">%%writefile Scoring_Scripts/Iris_Parallel_Output_Creation.py</p><p class="source-code">from azureml.core import Run, Workspace</p><p class="source-code">from azureml.core import Dataset, Datastore</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, load in all of the standard Python packages you need: <p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">import os</p><p class="source-code">import argparse</p><p>You will<a id="_idIndexMarker544"/> once<a id="_idIndexMarker545"/> again need <strong class="source-inline">argparse</strong> to pass in arguments, namely the folder that holds <strong class="source-inline">parallel_run_step.txt</strong>.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, set a variable called <strong class="source-inline">run</strong> using the <strong class="source-inline">Run</strong> function:<p class="source-code">run = Run.get_context()</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, pass in your arguments to access the folder that holds <strong class="source-inline">parallel_run_step.txt</strong>: <p class="source-code">parser = argparse.ArgumentParser()</p><p class="source-code">parser.add_argument("--input_data_folder",type=str)</p><p class="source-code">args = parser.parse_args()</p><p>Call the <strong class="source-inline">input_data_folder</strong> argument and pass it in as an argument when you configure this pipeline step.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, write a function called <strong class="source-inline">main</strong>. This function will transfer your predictions from an intermediate pipeline data location to its final destination. <p>Begin by using <strong class="source-inline">os</strong> and <strong class="source-inline">input_data_folder</strong> to find the path holding <strong class="source-inline">parallel_run_step.txt</strong>. Then, read it in as a space-delimited text file with no <a id="_idIndexMarker546"/>headers<a id="_idIndexMarker547"/> in a <strong class="source-inline">pandas</strong> DataFrame called <strong class="source-inline">result</strong> using the following code:</p><p class="source-code">def main():  </p><p class="source-code">    FileName = "parallel_run_step.txt"</p><p class="source-code">    input_data_path =\</p><p class="source-code"> os.path.join(args.input_data_folder, FileName)  </p><p class="source-code">    result =\</p><p class="source-code"> pd.read_csv(input_data_path, delimiter=" ", header=None)</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, as part of your <strong class="source-inline">main</strong> function, add columns to your <strong class="source-inline">result</strong> DataFrame:<p class="source-code">    columns =\</p><p class="source-code">['sepal_length','sepal_width','petal_length','petal_width', 'Prediction']</p><p class="source-code">    result.columns = columns</p><p>It's important to remember that <strong class="source-inline">parallel_run_step.txt</strong> never has headers, so you need to enter the columns manually in the correct order as shown in the preceding code.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, as part of your <strong class="source-inline">main</strong> function, connect to your AMLS workspace using the <strong class="source-inline">run</strong> variable and set a variable for your datastore:<p class="source-code">    ws = run.experiment.workspace</p><p class="source-code">    datastore = Datastore.get_default(ws)</p><p>This is the datastore that will hold your final output file.</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, as part of your <strong class="source-inline">main</strong> function, use <strong class="source-inline">os</strong> to<a id="_idIndexMarker548"/> create a<a id="_idIndexMarker549"/> folder <a id="_idIndexMarker550"/>called <strong class="source-inline">Output_Folder</strong> on your compute cluster, and write a CSV file called <strong class="source-inline">Iris_Parallel_Predictions.csv</strong>: <p class="source-code">    output_datastore_path = 'Output_Folder'</p><p class="source-code">    os.makedirs(output_datastore_path, exist_ok=True) </p><p class="source-code">    FileName = "Iris_Parallel_Predictions.csv"</p><p class="source-code">    OutputPath = os.path.join(output_datastore_path, FileName)</p><p class="source-code">    result.to_csv(OutputPath, index = False, sep=',') </p><p>Even though the original <strong class="source-inline">parallel_run_step.txt</strong> file was space-delimited, you can set the delimiter on your final output file to whatever you wish.</p></li>
				<li>Completing <strong class="source-inline">Iris_Parallel_Output_Creation.py</strong>, upload <strong class="source-inline">Iris_Parallel_Predictions.csv</strong> to your datastore in a folder called <strong class="source-inline">Output_Folder</strong>.<p>Then, use <strong class="source-inline">os</strong> to remove both <strong class="source-inline">Iris_Parallel_Predictions.csv</strong> and <strong class="source-inline">Output_Folder</strong> from your compute cluster. Finally, trigger your <strong class="source-inline">main</strong> function as you did in the <em class="italic">Creating an ML pipeline</em> section:  </p><p class="source-code">    datastore.upload_files(files=[OutputPath], target_path = output_datastore_path, overwrite=True)</p><p class="source-code">    os.remove(OutputPath)</p><p class="source-code">    os.rmdir(output_datastore_path)</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    main()</p></li>
			</ol>
			<p>With both steps<a id="_idIndexMarker551"/> written, the<a id="_idIndexMarker552"/> rest of the code is pure boilerplate to containerize your environment and to configure and run your pipeline.</p>
			<h2 id="_idParaDest-137"><a id="_idTextAnchor140"/>Configuring and running your ML parallel scoring pipeline</h2>
			<p>Since you've <a id="_idIndexMarker553"/>already built your environment<a id="_idIndexMarker554"/> in the <em class="italic">Creating an ML pipeline</em> section, all that's really left is configuring your ML pipeline steps. Use the following steps:</p>
			<ol>
				<li value="1">In a new cell, retrieve the environment that you created in the <em class="italic">Creating an ML pipeline</em> section with the following code: <p class="source-code">Env = Environment.get(ws, 'AutoML Environment') </p></li>
				<li>Next, define a variable that defines your pipeline data and assigns it to a datastore:<p class="source-code">parallel_run_output =\</p><p class="source-code">PipelineData(name='parallel_predictions', datastore=datastore)</p><p>This is the location that will hold <strong class="source-inline">parallel_run_step.txt</strong> between your first and second steps. You must also give this pipeline data object a name. </p></li>
				<li>Enable Docker on your environment and specify <strong class="source-inline">DEFAULT_CPU_IMAGE</strong> as your base image for your <strong class="source-inline">ParallelRunStep</strong>: <p class="source-code">parallel_environment = Env</p><p class="source-code">parallel_environment.docker.enabled = True </p><p class="source-code">parallel_environment.docker.base_image = DEFAULT_CPU_IMAGE</p><p>You do not need to specify a <strong class="source-inline">RunConfiguration</strong> object for <strong class="source-inline">ParallelRunStep</strong>.</p></li>
				<li>Create a <strong class="source-inline">RunConfiguration</strong> object for your output creation step: <p class="source-code">run_config = RunConfiguration()</p><p class="source-code">run_config.environment = Env</p><p class="source-code">run_config.environment.docker.enabled = True</p><p class="source-code">run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE</p></li>
				<li>Set your <a id="_idIndexMarker555"/>parallel run configurations<a id="_idIndexMarker556"/> with the following code: <p class="source-code">parallel_run_config = ParallelRunConfig(</p><p class="source-code">    source_directory='Scoring_Scripts/',</p><p class="source-code">    entry_script="Iris_Parallel_Scoring.py",</p><p class="source-code">    mini_batch_size="1MB",</p><p class="source-code">    error_threshold=5,</p><p class="source-code">    output_action="append_row",</p><p class="source-code">    environment=parallel_environment,</p><p class="source-code">    compute_target=compute_target,</p><p class="source-code">    run_invocation_timeout=60,</p><p class="source-code">    node_count=4,</p><p class="source-code">    logging_level="DEBUG") </p><p>You need to input the name of your Python script as well as the source directory that holds it. You need to specify how much data will be scored in parallel with <strong class="source-inline">mini_batch_size</strong>. For all <strong class="bold">tabular data</strong>, that is, data with rows and columns, the recommended setting is 1 MB. </p><p><strong class="source-inline">error_threshold</strong> is how many times the step can fail in parallel before the entire pipeline fails. Next, setting <strong class="source-inline">output_action</strong> to <strong class="source-inline">append_row</strong> will automatically generate <strong class="source-inline">parallel_run_step.txt</strong> for you. Other options for <strong class="source-inline">output_action</strong> are labor-intensive. </p><p>Set your compute <a id="_idIndexMarker557"/>target to the appropriate <a id="_idIndexMarker558"/>compute cluster and specify your environment. Leave <strong class="source-inline">run_invocation_timeout</strong> at 60 seconds so your run will fail if it idles for too long and set <strong class="source-inline">node_count</strong> equal to the number of nodes in your compute cluster to ensure maximum parallelization. Lastly, set <strong class="source-inline">logging_level</strong> to <strong class="source-inline">DEBUG</strong> for informative logs.</p></li>
				<li>Set the two variables that you will need to create your parallel scoring step, your dataset, and your model name: <p class="source-code">dataset = Dataset.get_by_name(ws,'Iris Parallel Scoring')</p><p class="source-code">input_data =\</p><p class="source-code">dataset.as_named_input('Iris_Parallel_Scoring')</p><p class="source-code">model_name = 'Iris-Multi-Classification-AutoML'</p><p>Datasets need to be passed in with the <strong class="source-inline">as_named_input</strong> code and appear as the <strong class="source-inline">input_data</strong> variable in your Python script.</p></li>
				<li>Create your parallel scoring step using the following code: <p class="source-code">parallel_scoring_step = ParallelRunStep(</p><p class="source-code">    name="iris-parallel-scoring-step",</p><p class="source-code">    parallel_run_config=parallel_run_config,</p><p class="source-code">    inputs=[input_data],</p><p class="source-code">    output=parallel_run_output,</p><p class="source-code">    arguments=['--model_name', model_name],</p><p class="source-code">    allow_reuse=False) </p><p>You need to give the step a name, <strong class="source-inline">iris-parallel-scoring-step</strong>. No spaces are allowed. Pass in your configurations using <strong class="source-inline">parallel_run_config</strong> and pass in your dataset using <strong class="source-inline">inputs</strong>. Set <strong class="source-inline">output</strong> to your pipeline data object and pass in your model name as an argument. As always, set <strong class="source-inline">allow_reuse</strong> equal to <strong class="source-inline">False</strong>.</p></li>
				<li>Create your<a id="_idIndexMarker559"/> output creation step using the <a id="_idIndexMarker560"/>following code: <p class="source-code">output_step =\</p><p class="source-code"> PythonScriptStep(name='iris-output-step',</p><p class="source-code">script_name='Iris_Parallel_Output_Creation.py',</p><p class="source-code">source_directory='Scoring_Scripts', </p><p class="source-code">arguments=\</p><p class="source-code">["--input_data_folder", parallel_run_output,],</p><p class="source-code">inputs=[parallel_run_output],</p><p class="source-code">compute_target=compute_target,</p><p class="source-code">runconfig=run_config,</p><p class="source-code">allow_reuse=False)</p><p>Give this step the name <strong class="source-inline">iris-output-step</strong> and pass in your script name and source directory. For <strong class="source-inline">arguments</strong> and <strong class="source-inline">input</strong>, you need to pass in <strong class="source-inline">parallel_run_output</strong>. This lets your output creation step use <strong class="source-inline">parallel_run_step.txt</strong> generated by your parallel scoring step. Then, set your compute target, specify your run configuration, and set <strong class="source-inline">allow_reuse</strong> to <strong class="source-inline">False</strong>.</p></li>
				<li>Set your step sequence and create a pipeline object:<p class="source-code">step_sequence =\</p><p class="source-code"> StepSequence(steps=[parallel_scoring_step, output_step])</p><p class="source-code">pipeline = Pipeline(workspace=ws, steps=step_sequence)</p><p>This time, you have two steps to set, <strong class="source-inline">parallel_run_step</strong> and <strong class="source-inline">output_step</strong>.</p></li>
				<li>Give your pipeline <a id="_idIndexMarker561"/>experiment run a<a id="_idIndexMarker562"/> name, <strong class="source-inline">Iris-Parallel-Scoring-Pipeline-Run</strong>, and submit it to your compute cluster:<p class="source-code">pipeline_experiment = \</p><p class="source-code">Experiment(ws, 'Iris-Parallel-Scoring-Pipeline-Run')</p><p class="source-code">pipeline_run = \</p><p class="source-code">pipeline_experiment.submit(pipeline, show_output=True)</p></li>
				<li>Use <strong class="source-inline">RunDetails</strong> to watch your pipeline execute in real time:<p class="source-code">RunDetails(pipeline_run).show()</p><p class="source-code">pipeline_run.wait_for_completion(show_output=True)</p><p>Notice how fast this scores your data. If your pipeline runs successfully, it will complete with the word <strong class="bold">Finished</strong>. You should see a graphic identical to the one in <em class="italic">Figure 9.6</em>:</p><div id="_idContainer094" class="IMG---Figure"><img src="image/Figure_9.6_B16595.jpg" alt="Figure 9.6 – Successful parallel pipeline run graphic "/></div><p class="figure-caption">Figure 9.6 – Successful parallel pipeline run graphic</p></li>
				<li>Publish your pipeline to an endpoint as you did in the previous section, naming it <strong class="source-inline">Iris-Parallel-Scoring-Pipeline</strong> or whatever you wish:<p class="source-code">published_pipeline = pipeline_run.publish_pipeline(</p><p class="source-code">    name='Iris-Parallel-Scoring-Pipeline',\</p><p class="source-code">    description='\</p><p class="source-code">Pipeline that Scores Iris Data in Parallel', version= '1.0')</p><p class="source-code">published_pipeline</p><p>Running this <a id="_idIndexMarker563"/>code will give you your published <a id="_idIndexMarker564"/>pipeline ID as well as a link to the endpoint, as seen in <em class="italic">Figure 9.7</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/Figure_9.7_B16595.jpg" alt="Figure 9.7 – Successfully published parallel pipeline "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Successfully published parallel pipeline</p>
			<p>You can now examine and download your scoring file as you did in the previous section. Look inside <strong class="source-inline">Output_Folder</strong> in your datastore for a file called <strong class="source-inline">Iris_Parallel_Predictions.csv</strong>. It's quite a bit larger than your last file, at around 30 MB.</p>
			<p>With both a standard scoring pipeline and a parallel run pipeline built, you are now at the cutting edge of AMLS. Both of these pipelines can be used to score not only AutoML-generated ML models, but custom models as well. </p>
			<p>Even experienced data scientists have a hard time building these batch scoring solutions. So, you have acquired a desirable, marketable skill that will enable you to work alongside seasoned experts. </p>
			<p>In the next section, you will learn how to build a pipeline for training AutoML models instead of scoring. </p>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor141"/>Creating an AutoML training pipeline</h1>
			<p>Sometimes, it's <a id="_idIndexMarker565"/>necessary to retrain a model that you trained in AutoML. ML models can degrade over time if the relationship between your data and your target variable changes. This is true for all ML models, not just ones generated by AutoML. </p>
			<p>Imagine, for example, that you build an ML model to predict demand for frozen pizza at a supermarket, and then one day, a famous pizza chain sets up shop next door. It's very likely that consumer buying behavior will change, and you will need to retrain the model. This is true for all ML models. </p>
			<p>Luckily, AMLS has specialized ML pipeline steps built specifically for retraining models. In this section, we are going to use one of those steps, the AutoML step. The <strong class="bold">AutoML step</strong> lets you retrain models easily whenever you want, either with a push of a button or on a schedule. </p>
			<p>Here, you will build a two-step ML pipeline where you will first train a model with an AutoML step and register it with a typical Python script step. This will enable you to build complete end-to-end solutions with automated scoring and training, completing your skillset. Furthermore, this will familiarize you with the AutoML step and all of its caveats.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Not all ML models require retraining, particularly those that predict physical phenomena, as the relationship between your data and the target variable is unlikely to change over time. However, most ML models will improve with additional data points, so it does make sense to retrain models as you collect and label more data. </p>
			<p>By now, you should know what to expect in terms of creating ML pipelines. Most of the steps will be familiar to you, but you will have to work with specialized forms of pipeline data that pass data from your training step to your model registration step. </p>
			<p>The Python scripts involved in this pipeline are much simpler than those involved in scoring pipelines, and thus require less customization when you try it with your own data. At the end of this section, like others, you will also publish your AutoML training pipeline to an endpoint. <em class="italic">Figure 9.8</em> outlines the process:</p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/Figure_9.8_B16595.jpg" alt="Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Steps involved in setting up an AutoML retraining pipeline</p>
			<p>This process is a little<a id="_idIndexMarker566"/> bit different than the other pipelines, as you need to configure your AutoML settings early on. You can find the code for all the steps in the <strong class="source-inline">ML-Retraining-Pipeline.ipynb</strong> file in the GitHub repository.</p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor142"/>Coding the first two steps of your AutoML training pipeline</h2>
			<p><a id="_idTextAnchor143"/>To create your <a id="_idIndexMarker567"/>AutoML training pipeline, begin with the following steps:</p>
			<ol>
				<li value="1">Navigate to your Jupyter environment on your compute instance and create a new Jupyter notebook. Name it <strong class="source-inline">automl-training-pipeline</strong>.</li>
				<li>Open your newly created notebook and import the usual set of Azure libraries along with <strong class="source-inline">AutoMLConfig</strong>:<p class="source-code">from azureml.core import Workspace, Dataset, Datastore</p><p class="source-code">from azureml.core import Experiment, Environment, Model</p><p class="source-code">from azureml.core.compute import ComputeTarget</p><p class="source-code">from azureml.train.automl import AutoMLConfig</p><p><strong class="source-inline">AutoMLConfig</strong> lets you configure AutoML training runs.</p></li>
				<li>Continuing on, import the necessary Azure ML pipeline libraries with the following <a id="_idIndexMarker568"/>code: <p class="source-code">from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE</p><p class="source-code">from azureml.pipeline.steps import PythonScriptStep, AutoMLStep</p><p class="source-code">from azureml.pipeline.core import Pipeline, PublishedPipeline, PipelineData, TrainingOutput</p><p class="source-code">from azureml.pipeline.core import StepSequence </p><p class="source-code">from azureml.widgets import RunDetails</p><p>There are two new packages. <strong class="source-inline">AutoMLStep</strong> is an ML pipeline step that lets you run AutoML training runs. <strong class="source-inline">TrainingOutput</strong> lets you access the output from your AutoML step to pass on to your model registration step.</p></li>
				<li>Import <strong class="source-inline">os</strong>: <p class="source-code">import os</p><p>This is the only non-Azure Python package you will need to make this pipeline, and it will be used to create a new folder.</p></li>
				<li>Connect your Jupyter notebook to your AMLS workspace:<p class="source-code">ws = Workspace.from_config()</p><p>Log in if prompted by following the instructions.</p></li>
				<li>Set your compute cluster:<p class="source-code">compute_name = 'compute-cluster'</p><p class="source-code">compute_target = ComputeTarget(ws, compute_name)</p></li>
				<li>Set your datastore:<p class="source-code">datastore = Datastore.get_default(ws)</p></li>
				<li>Retrieve your <strong class="source-inline">Iris Training</strong> dataset with the following code. You will pass this dataset into your AutoML configuration settings:<p class="source-code">dataset = Dataset.get_by_name(ws, 'Iris Training')</p></li>
				<li>Retrieve the environment named <strong class="source-inline">AutoML Environment</strong> that you created in the <em class="italic">Creating an ML pipeline</em> section of this chapter: <p class="source-code">Env = Environment.get(ws,'AutoML Environment') </p></li>
			</ol>
			<p>This will be used <a id="_idIndexMarker569"/>only for your model registration step; your AutoML training step will use a standard, autogenerated environment.</p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor144"/>Configuring your AutoML model training settings and step</h2>
			<p>Next, you'll configure <a id="_idIndexMarker570"/>everything related to your AutoML training step with the following code:</p>
			<ol>
				<li value="1">Set variables to pass into your AutoML configuration settings: <p class="source-code">target_column = 'species'</p><p class="source-code">task = 'classification'</p><p class="source-code">primary_metric = 'accuracy'</p><p class="source-code">featurization = 'auto'</p><p class="source-code">num_classes = 3</p><p class="source-code">iterations = 4</p><p>Explanations for these settings can be found in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a>, <em class="italic">Building an AutoML Classification Solution</em>. One new setting is <strong class="source-inline">iterations</strong>. This will be used to determine how many AutoML models should be trained concurrently; this value should equal the number of nodes on your compute cluster to ensure maximum parallelization.</p></li>
				<li>Configure your <a id="_idIndexMarker571"/>AutoML training run: <p class="source-code">config = AutoMLConfig(task=task,</p><p class="source-code">                     primary_metric=primary_metric,</p><p class="source-code">                     num_classes=num_classes,</p><p class="source-code">                     featurization=featurization,</p><p class="source-code">                     compute_target=compute_target,</p><p class="source-code">                     training_data=dataset,</p><p class="source-code">                     label_column_name=target_column,</p><p class="source-code">                     experiment_timeout_minutes=15,</p><p class="source-code">                     enable_early_stopping=True,</p><p class="source-code">                     max_concurrent_iterations = iterations,</p><p class="source-code">                     n_cross_validations=5,</p><p class="source-code">                     model_explainability=True,</p><p class="source-code">                     enable_stack_ensemble=True,</p><p class="source-code">                     enable_voting_ensemble=True)</p><p>An explanation for these settings can be found in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>. If you would like higher accuracy, adjust <strong class="source-inline">experiment_timeout_minutes</strong> to give AutoML more time to train. Note that you are passing in your dataset here.  </p></li>
				<li>Set the output for AutoML metrics: <p class="source-code">metrics_data =PipelineData(name='metrics_data',\</p><p class="source-code"> datastore=datastore,pipeline_output_name='metrics output',\</p><p class="source-code">       training_output=TrainingOutput(type='Metrics'))</p><p>This code is standard boilerplate used in every AutoML step. It saves metrics from your AutoML run as intermediate pipeline data that you can use to pass on to other steps in your ML pipeline.</p></li>
				<li>Set the<a id="_idIndexMarker572"/> output for your best model: <p class="source-code">model_data = PipelineData(\</p><p class="source-code">name='model_data', datastore=datastore, pipeline_output_name='best_model_output',\</p><p class="source-code">         training_output=TrainingOutput(type='Model'))</p><p>This code is standard boilerplate used in every AutoML step. It saves information about the best model from your AutoML run as intermediate pipeline data to pass on to your model registration step.</p></li>
				<li>Configure your AutoML step: <p class="source-code">automl_training_step = AutoMLStep(</p><p class="source-code">    name='Multiclass_AutoML_Step',</p><p class="source-code">    automl_config=config,</p><p class="source-code">    outputs=[metrics_data, model_data],</p><p class="source-code">    allow_reuse=False)</p></li>
			</ol>
			<p>All you need to do is give it a name, pass in your AutoML configuration settings, and specify <strong class="source-inline">metrics_data</strong> and <strong class="source-inline">model_data</strong> as output. As always, set <strong class="source-inline">allow_reuse</strong> to <strong class="source-inline">False</strong>.</p>
			<h2 id="_idParaDest-141"><a id="_idTextAnchor145"/>Creating a Python script to register your model</h2>
			<p>With your<a id="_idIndexMarker573"/> AutoML<a id="_idIndexMarker574"/> training step configured, you now need to write another script to extract and register your model using the following steps:</p>
			<ol>
				<li value="1">Make a folder to hold your training script using <strong class="source-inline">os</strong>:<p class="source-code">os.makedirs('Training_Scripts', exist_ok=True)  </p></li>
				<li>Write a Python script to register your model. This script is very short compared to the others you wrote. Begin by writing out a new Python script file called <strong class="source-inline">Iris_Model_Registration.py</strong> using the <strong class="source-inline">%%writefile</strong> magic command <a id="_idIndexMarker575"/>and <a id="_idIndexMarker576"/>loading in your Azure libraries and <strong class="source-inline">argparse</strong>:<p class="source-code">%%writefile Training_Scripts/Iris_Model_Registration.py</p><p class="source-code">from azureml.core import Run, Workspace, Model</p><p class="source-code">from azureml.core import Dataset, Datastore</p><p class="source-code">import argparse</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong>, set a variable called <strong class="source-inline">run</strong> using the <strong class="source-inline">Run</strong> function:<p class="source-code">run = Run.get_context()</p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong>, pass in your arguments to access the best model as trained by AutoML as well as the dataset you used to train the model. For this, you will need three arguments, <strong class="source-inline">model_name</strong>, <strong class="source-inline">model_path</strong>, and <strong class="source-inline">dataset_name</strong>:<p class="source-code">parser = argparse.ArgumentParser()</p><p class="source-code">parser.add_argument("--model_name", dest="model_name")</p><p class="source-code">parser.add_argument("--model_path", dest="model_path")</p><p class="source-code">parser.add_argument("--dataset_name", dest="dataset_name")</p><p class="source-code">args = parser.parse_args() </p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong>, write a function called <strong class="source-inline">main</strong>. This function will register your best model. Begin by connecting to your AMLS workspace using the <strong class="source-inline">run</strong> variable:<p class="source-code">def main():  </p><p class="source-code">    ws = run.experiment.workspace </p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong>, as part of your <strong class="source-inline">main</strong> function, retrieve<a id="_idIndexMarker577"/> your <a id="_idIndexMarker578"/>dataset through the <strong class="source-inline">dataset_name</strong> argument: <p class="source-code">    ds = Dataset.get_by_name(ws, args.dataset_name)</p><p class="source-code">    dataset = [(Dataset.Scenario.TRAINING, ds)] </p><p>Use the <strong class="source-inline">Dataset.Scenario.Training</strong> line of code to specify the scenario in which it was used. This information will be saved when you register your model.  </p></li>
				<li>Continuing in the same cell as part of <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong>, as part of your <strong class="source-inline">main</strong> function, register your model using the <strong class="source-inline">model_path</strong> and <strong class="source-inline">model_name</strong> arguments: <p class="source-code">    model = Model.register(workspace=ws,</p><p class="source-code">                           model_path=args.model_path,</p><p class="source-code">                           model_name=args.model_name,</p><p class="source-code">                           datasets=dataset)</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    main()</p></li>
			</ol>
			<p>While <strong class="source-inline">model_name</strong> is something you specify, <strong class="source-inline">model_path</strong> will be automatically generated from <strong class="source-inline">model_data</strong>. The dataset you used to train your model will also be saved using<a id="_idIndexMarker579"/> this<a id="_idIndexMarker580"/> code. Finally, complete <strong class="source-inline">Iris_Model_Registration_Scoring.py</strong> with the boilerplate code that triggers <strong class="source-inline">main</strong>.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor146"/>Configuring and running your AutoML training pipeline</h2>
			<p>All that's left is<a id="_idIndexMarker581"/> to containerize your environment, configure<a id="_idIndexMarker582"/> your model registration step, and run and publish your pipeline by following these steps:</p>
			<ol>
				<li value="1">Create a <strong class="source-inline">RunConfiguration</strong> object for the model registration step:<p class="source-code">run_config = RunConfiguration()</p><p class="source-code">run_config.environment = Env</p><p class="source-code">run_config.environment.docker.enabled = True</p><p class="source-code">run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE</p><p>Note that this uses <strong class="source-inline">AutoML Environment</strong>, but you can get away with using a simpler environment without <strong class="source-inline">pandas</strong> or NumPy if you so desire.</p></li>
				<li>Set variables for your model name and dataset name: <p class="source-code">model_name = 'Iris-Multi-Classification-AutoML'</p><p class="source-code">dataset_name = 'Iris Training'</p><p>Your model name will be used to register the best model that AutoML produces and is your choice. Your dataset name, on the other hand, should match the dataset you used to train your model.</p></li>
				<li>Configure your model registration step: <p class="source-code">model_registration_step = \</p><p class="source-code">PythonScriptStep(script_name="Iris_Model_Registration.py",\</p><p class="source-code">               source_directory = 'Training_Scripts',\</p><p class="source-code">               name = "Model-Registration-Step",\</p><p class="source-code">               allow_reuse = False,\</p><p class="source-code">               arguments = ["model_name",model_name,\</p><p class="source-code"> "--model_path", model_data, "--dataset_name",\</p><p class="source-code"> dataset_name],\</p><p class="source-code">               inputs = [model_data],\</p><p class="source-code">               compute_target = compute_target,\</p><p class="source-code">               runconfig = run_config,\</p><p class="source-code">               allow_reuse = False)</p><p>Here, you <a id="_idIndexMarker583"/>must pass in three arguments, <strong class="source-inline">model_name</strong>, <strong class="source-inline">model_data</strong>, and <strong class="source-inline">dataset_name</strong>, and pass in <strong class="source-inline">model_data</strong> as <a id="_idIndexMarker584"/>input. This is because <strong class="source-inline">model_data</strong> is pipeline data generated by your AutoML training step, while <strong class="source-inline">model_name</strong> and <strong class="source-inline">dataset_name</strong> are simple string variables. As always, set <strong class="source-inline">allow_reuse</strong> to <strong class="source-inline">False</strong>.</p></li>
				<li>Set your step sequence and create a pipeline object:<p class="source-code">step_sequence =\</p><p class="source-code">StepSequence(steps=[parallel_scoring_step, output_step])</p><p class="source-code">pipeline = Pipeline(workspace=ws, steps=step_sequence)</p><p>This time, you have two steps to set, <strong class="source-inline">automl_training step</strong> and <strong class="source-inline">model_registration_step</strong>.</p></li>
				<li>Give your pipeline experiment run a name, <strong class="source-inline">Iris-AutoML-Training-Pipeline-Run</strong>, and submit it to your compute cluster: <p class="source-code">pipeline_experiment =\</p><p class="source-code">Experiment(ws, 'Iris-Parallel-Scoring-Pipeline-Run')</p><p class="source-code">pipeline_run =\</p><p class="source-code">pipeline_experiment.submit(pipeline, show_output=True)</p><p>This will take <a id="_idIndexMarker585"/>much longer than your other<a id="_idIndexMarker586"/> pipelines, perhaps around a half hour.</p></li>
				<li>Use <strong class="source-inline">RunDetails</strong> to watch your pipeline execute in real time:<p class="source-code">RunDetails(pipeline_run).show()</p><p class="source-code">pipeline_run.wait_for_completion(show_output=True)</p><p>If your pipeline runs successfully, it will complete with the word <strong class="bold">Finished</strong>. You should see a graphic identical to the one in <em class="italic">Figure 9.9</em>:</p><div id="_idContainer097" class="IMG---Figure"><img src="image/Figure_9.9_B16595.jpg" alt="Figure 9.9 – Successful AutoML training pipeline"/></div><p class="figure-caption">Figure 9.9 – Successful AutoML training pipeline</p></li>
				<li>Publish your pipeline to an endpoint as you did in the previous section, naming it <strong class="source-inline">Iris-AutoML-Training-Pipeline</strong> or whatever you wish:<p class="source-code">published_pipeline = pipeline_run.publish_pipeline(</p><p class="source-code">    name='Iris-AutoML-Training-Pipeline',\</p><p class="source-code">    description=\</p><p class="source-code">'Pipeline that Trains Iris Data with AutoML', version= '1.0')</p><p class="source-code">published_pipeline</p><p>Running this<a id="_idIndexMarker587"/> code will give you your published <a id="_idIndexMarker588"/>pipeline ID as well as a link to your endpoint, as seen in <em class="italic">Figure 9.10</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/Figure_9.10_B16595.jpg" alt="Figure 9.10 – Successfully published AutoML training pipeline"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.10 – Successfully published AutoML training pipeline</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Sometimes when you're running an ML pipeline, your computer will crash. However, your pipeline run will continue to run and you will still be able to publish it upon completion. To retrieve a completed pipeline so you can publish it, use the following code:</p>
			<p class="source-code">from azureml.pipeline.core import PipelineRun</p>
			<p class="source-code">experiment = Experiment(ws, 'your-experiment_name')</p>
			<p class="source-code">pipeline_run = PipelineRun(experiment, 'your-pipeline-run-id')</p>
			<p>You have now built three ML pipelines, a standard scoring pipeline, a parallel run pipeline, and an AutoML training pipeline. This was not a trivial effort, but all that hard work has paid off. You have mastered one of the most complex parts of AMLS. </p>
			<p>While making<a id="_idIndexMarker589"/> these pipelines is quite an undertaking, once<a id="_idIndexMarker590"/> you have them, they are very easy to manually rerun or automatically schedule, as you will see in the next section. </p>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor147"/>Triggering and scheduling your ML pipelines</h1>
			<p>One of the <a id="_idIndexMarker591"/>biggest<a id="_idIndexMarker592"/> problems data scientists face is creating easy, rerunnable, production-ready code and scheduling it in an automatic, reliable manner. You've already accomplished the first part by creating your three ML pipelines. Now, it's time to learn how to do the second part.</p>
			<p>In this section, you will first learn how to manually trigger the pipelines you've created through the GUI. Then, you will learn how to trigger the pipelines via code, both manually and on an automated schedule. This will enable you to put your ML pipelines into production, generating results on an hourly, daily, weekly, or monthly basis.</p>
			<h2 id="_idParaDest-144"><a id="_idTextAnchor148"/>Triggering your published pipeline from the GUI</h2>
			<p>Triggering<a id="_idIndexMarker593"/> your published pipeline from the AML studio<a id="_idIndexMarker594"/> GUI is easy. However, you cannot set up an automated schedule for your ML pipelines at this time. As such, it is most useful for triggering training pipelines when you notice that your results seem off. Use the following steps to manually trigger your ML pipeline through the AML studio: </p>
			<ol>
				<li value="1">Navigate to <a href="https://ml.azure.com">https://ml.azure.com</a> to access AML studio.</li>
				<li>Click <strong class="bold">Pipelines</strong> under <strong class="bold">Assets</strong> on the left-hand side.</li>
				<li>Click <strong class="bold">Pipeline endpoints</strong> near the top of the page.</li>
				<li>Click the blue link to <strong class="bold">Iris-AutoML-Training-Pipeline</strong>.</li>
				<li>Click <strong class="bold">Submit</strong>. This will open up a dialog box.</li>
				<li>Select an experiment name from the drop-down box under <strong class="bold">Existing Experiment</strong>. Use <strong class="source-inline">Iris-AutoML-Training-Pipeline-Run</strong>.</li>
				<li>Click <strong class="bold">Submit</strong>.</li>
				<li>Click <strong class="bold">Pipelines</strong> under <strong class="bold">Assets</strong> again and, on the top line, you should see a new run, as shown in <em class="italic">Figure 9.11</em>:</li>
			</ol>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/Figure_9.11_B16595.jpg" alt="Figure 9.11 – Pipeline run submitted through the GUI "/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – Pipeline run submitted through the GUI</p>
			<p>Compared to <a id="_idIndexMarker595"/>making an ML pipeline, resubmitting it <a id="_idIndexMarker596"/>is very easy. Next, we will look at ways to trigger our pipeline through code and create an automatic schedule.</p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor149"/>Triggering and scheduling a published pipeline through code</h2>
			<p>Triggering a<a id="_idIndexMarker597"/> published ML pipeline through code<a id="_idIndexMarker598"/> first requires you to obtain your pipeline ID. These were generated at the end of the previous sections whenever you published a pipeline. You can also find your pipeline ID by clicking on individual pipelines found under <strong class="bold">Pipeline endpoints</strong> through the AML studio. You will also need your pipeline IDs to set up schedules through code.</p>
			<p>All the code for this section can be found in the <strong class="source-inline">ML-Pipeline-Scheduling.ipynb</strong> file in the GitHub repository. Begin by opening a Jupyter notebook and following these steps:</p>
			<ol>
				<li value="1">Create a new Jupyter notebook as you have before. Name it <strong class="source-inline">pipeline-scheduling</strong>.</li>
				<li>Open your notebook and import the required Azure libraries, three of which are new. <strong class="source-inline">PublishedPipeline</strong> lets <a id="_idIndexMarker599"/>you <a id="_idIndexMarker600"/>access any ML pipelines you have published. <strong class="source-inline">Schedule</strong> and <strong class="source-inline">ScheduleRecurrence</strong> let you schedule ML pipelines:<p class="source-code">from azureml.core import Workspace, Datastore</p><p class="source-code">from azureml.pipeline.core import Pipeline, PublishedPipeline</p><p class="source-code">from azureml.core.experiment import Experiment</p><p class="source-code">from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule</p></li>
				<li>To manually trigger an ML pipeline, use the following code by replacing <strong class="source-inline">your-published-pipeline-id</strong> with the ID of your published AutoML training pipeline. That's it:<p class="source-code">experiment =\</p><p class="source-code">Experiment(ws,'AutoML-Retraining-Code-Trigger')</p><p class="source-code">published_pipeline =\</p><p class="source-code">PublishedPipeline.get(workspace=ws, id='your-published-pipeline-id')</p><p class="source-code">pipeline_run = experiment.submit(published_pipeline)</p></li>
				<li>To create a schedule for running your ML pipeline, first determine an interval with the following code. The interval options are <strong class="source-inline">Minute</strong>, <strong class="source-inline">Hour</strong>, <strong class="source-inline">Day</strong>, <strong class="source-inline">Week</strong>, or <strong class="source-inline">Month</strong>. You can also specify <strong class="source-inline">start_time</strong> and <strong class="source-inline">time_zone</strong> as optional arguments. Another optional argument is <strong class="source-inline">status</strong>, which you can set to <strong class="source-inline">Disabled</strong> to turn off your schedule:<p class="source-code">recurrence =\</p><p class="source-code">ScheduleRecurrence(frequency="Day", interval=1)</p></li>
				<li>Create your <a id="_idIndexMarker601"/>schedule by giving it a name <a id="_idIndexMarker602"/>and passing in your <strong class="source-inline">recurrence</strong> settings, experiment name, published pipeline ID, and a description:<p class="source-code">schedule = \</p><p class="source-code">Schedule.create(ws, name="IrisTrainingSchedule", </p><p class="source-code">                       description="AutoML Training",</p><p class="source-code">                       pipeline_id='your-pipeline-id', </p><p class="source-code">                       experiment_name='Iris-Retraining', </p><p class="source-code">                       recurrence=recurrence)</p></li>
			</ol>
			<p>You have now created a schedule that will automatically trigger your AutoML training pipeline once a day. This schedule will automatically spin up your compute cluster, train a model, and spin down. Many companies spend years trying to figure out how best to schedule ML training and scoring runs in a timely, reliable manner, and you've accomplished this task in a mere chapter! </p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor150"/>Summary</h1>
			<p>You have now implemented a fully automated ML batch scoring solution using an AutoML trained model. You've created pipelines that can score models, pipelines that can process big data in parallel, and pipelines that can retrain AutoML models. You can trigger them whenever you want and you can even set up an automated scoring schedule. This is no small feat, as many organizations have spent years trying to learn best practices for these tasks. </p>
			<p>In <a href="B16595_10_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 10</em></a>, <em class="italic">Creating End-to-End AutoML Solutions</em>, you will cement your knowledge as you learn how to ingest data into Azure, score it with ML pipelines, and write your results to whatever location you want.</p>
		</div>
</body></html>