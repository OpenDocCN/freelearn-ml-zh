- en: '*Chapter 17*: Preparing for a Successful ML Journey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations, you've made it – what an incredible journey you've been on!
    By now, you should have learned how to preprocess data in the cloud, experiment
    with **ML** models, train deep learning models and recommendation engines on auto-scaling
    clusters, optimize models, and deploy them wherever you want. And you should know
    how to add a cherry to the top of the cake by operationalizing all of these steps
    through **MLOps**.
  prefs: []
  type: TYPE_NORMAL
- en: In this last chapter, we will recap some important revelations we learned during
    this journey. It's easy to get lost or overwhelmed by technological and algorithmic
    choices. You could dive deep into modeling, infrastructure, or monitoring without
    getting any closer to having a good predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: In the first section, we will remind you that ML is mostly about data. Artificial
    intelligence should probably be called data cleansing and labeling, but of course,
    this doesn't sound as good as AI. You will come to understand that your data is
    key to great performance, so it's what you should care about the most. Your data
    is all that matters!
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will show you how to start your ML projects. We
    will do this by providing you with some guidance and making a point about the
    importance of a clean base infrastructure and thoughtful monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: After that, we will reiterate the importance of automation and how new technologies
    will take us further into the world of **machine learning as a service** (**MLaaS**).
    It is always great to understand where technology is heading and in the case of
    ML, it is meta-learning and systems that already automatically suggest fitting
    models and stack them to achieve good predictive performance. And what is left
    when modeling is fully automated? Exactly – your data!
  prefs: []
  type: TYPE_NORMAL
- en: Following that, we will talk about the constant change and evolution of cloud
    services while focusing on PaaS offerings. We will look at why PaaS solutions
    are built and what their foundation is. This will help you understand how best
    to prepare for change and why you are still betting on the right foundation, despite
    ever-changing services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will talk about a topic we have mostly ignored throughout this
    book. We will talk about some questions you should think about before starting
    any ML project: Should you do it? Will the results of your model have a grave
    impact on people''s lives? You may have guessed it: we will talk about **ethics**
    in terms of data processing. With a more and more connected world, you shouldn''t
    misuse the personal data of others, you shouldn''t build models that are extremely
    biased toward certain groups of people, and you shouldn''t influence people''s
    lives negatively with your deployed solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Remembering the importance of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting with a thoughtful infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating recurrent tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expecting constant change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking about your responsibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remembering the importance of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many algorithmic problems for predictions and model fitting are hard to model,
    compute, and optimize using classic optimization algorithms or complex heuristics.
    Supervised machine learning provides a powerful new way to solve the most complex
    problems using optimization and a ton of labeled training data.
  prefs: []
  type: TYPE_NORMAL
- en: Some may think you just should throw a metric ton of data at a model. Imagine
    that you have thousands of pictures of the same bird from every possible angle.
    A trained model based on those pictures would probably not be very predictive
    for classifying different bird families.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the Right Data Samples for Your Model
  prefs: []
  type: TYPE_NORMAL
- en: A trained model will increase in quality when it's using highly distinct data
    samples and data samples that are useful in the context of what your model should
    predict.
  prefs: []
  type: TYPE_NORMAL
- en: So, when you're working with ML algorithms, you need to remember that models
    are powered by the training data you provide them with, as well as their training
    labels. Good data is the key to good performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowing this, let''s reiterate the key takeaways when it comes to working with
    data and training ML models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spend most of your time wrangling the data**: As we discussed at the beginning
    of this book, in most ML projects, you''ll spend about 80% of your time on data
    analysis, preprocessing, and feature engineering. Understanding your data inside
    and out is critical to developing a successful predictive model. Think about it
    this way: the only thing that makes you stand out from your competition is your
    data. Most likely, your competitors have access to a similar set of algorithms,
    optimizations, and compute infrastructure that you do. The only thing they don''t
    have is your data and your skill to take apart this data (hopefully). Hence, this
    is where your secret to success lies: in interpreting, cleaning, modeling, and
    preparing your data for high-quality predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Emphasize the engineering of your features**: The biggest opportunity you
    get to increase the predictive baseline performance of any of your models is to
    improve your underlying dataset through better feature engineering or by adding
    more predictive features. Don''t get lost trying to tune and stack the model.
    Rather, spend most of your time and resources on data preprocessing and feature
    engineering. Feature engineering is where you can shine and win the prediction
    game. Are you dealing with dates? Pull in other data sources, such as local and
    global holidays, and nearby events; add relative dates, such as days before a
    holiday, days before a weekend, and so on. Are you dealing with locations, cities,
    or countries? Here, you should pull in demographic data, political data, or geographic
    data. You get the point.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Do not get sidetracked with model tuning**: There is only so much that your
    model can do. Yes, you can stack multiple models, tune and optimize them, optimize
    for different metrics, and so on. However, your biggest leverage is your data.
    A good plan for any ML model is to start with a very simple baseline model. Are
    you working with categorical data? If so, choose a gradient-boosted tree ensemble
    and stick with the default parameters. Are you predicting continuous values? If
    so, choose a logistic regression model. Start small and make sure you get your
    data right before you start to fiddle with your model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Always start with a baseline model**: Use a baseline model and start to build
    all your automation, infrastructure, and metrics around it. It''s worth noting
    that a baseline model should perform better than a random approach. Once the pipeline
    has finished, you can dive into the data, add new data, perform better feature
    engineering, deploy again, test, and re-iterate. Reducing your model to a primitive
    baseline model is a difficult step, but it will help you succeed in managing your
    priorities during the first phase of the project. Why is the baseline model approach
    so important? Because it sets your mindset for an iterative project, where you
    constantly measure, add data, retrain, and improve your model. Your model will
    require retraining and you need to measure when this is the case. To retrain,
    you will need new training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Continuously collect new, relevant data samples**: In a perfect setup, you
    would install a continuous data collection pipeline that collects new training
    data and training labels directly from your current product. Does your model predict
    search relevance? Collect search queries and the clicked results. Does your model
    predict fraud? Collect new data and the results of manually verified fraud cases.
    Does your model predict hashtags? Track the predictions and let your users change
    them if they''re not accurate. In all these examples, we continuously track relevant
    training data that we can use for constant retraining and fine-tuning. Having
    this constant stream of training data could be the competitive advantage for your
    business that sets you up for success. Hence, when you oversee an ML project,
    think about how you are going to retrain the model in the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides following these technical rules to handle an ML project, it is of utmost
    importance to understand the business side of your company. Such a project typically
    requires an interdisciplinary team of people to succeed. Therefore, it is vital
    to get C-level buy-in for a complete company data strategy. Data is your fuel,
    and it is typically distributed throughout the company in a vast amount of data
    silos, controlled by different departments. As you probably need access to a lot
    of these sources to implement and improve ML models, it is of utmost importance
    to have the authority to access and use that data.
  prefs: []
  type: TYPE_NORMAL
- en: This often requires a mental shift in most companies, as data from different
    departments needs to be combined and analyzed to be used in predictions. Hence,
    data quality matters, data lineage is important so that you can understand where
    it came from, timeliness is important, and correctness is essential. So, make
    sure that data is a first-class citizen in your company that gets the support,
    love, and care it deserves.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've reiterated these important facts about data processing, let's
    talk about the environment you are working with.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with a thoughtful infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Successfully applied ML projects depend on an iterative approach to tackle data
    collection, data cleansing, feature engineering, and modeling. After a successful
    deployment and rollout, you should go back to the beginning, keep an eye on your
    metrics, and collect more data. By now, it should be clear that you will repeat
    some of your development and deployment steps in the life cycle of your ML project.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the infrastructure and environment for your ML project right from the
    beginning will save you a lot of trouble down the road. One key to a successful
    infrastructure is automation and versioning, as we discussed in the previous chapter.
    So, we recommend that you take a few extra days to set up your infrastructure
    and automation and register your datasets, models, and environments from within
    Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: The same can be said for monitoring. To make educated decisions about whether
    your model is working as intended, whether the training data is still accurate,
    or whether the resource utilization is high enough, you need accurate metrics.
    Adding metrics to a project after deployment is quite tricky. Therefore, you should
    be aware of what you want to measure and what you want to be alerted on beforehand.
    Take some extra time at the beginning of your project to think about the metrics
    that you are going to track.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, prioritizing infrastructure while working on the data and models is
    hard. If you can afford the luxury to split these into separate teams for ML infrastructure,
    modeling, and data, then this may not be at the top of your mind. However, this
    is often not the case. To avoid this prioritization issue, we recommend starting
    with a simple baseline model and defining your infrastructure automation based
    on this simple model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the steps you should perform when you''re starting your ML project:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Choose a baseline model**: Pick the simplest model with default parameters
    for your use case, a small set of training data, and the most important engineered
    features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Build a simple pipeline**: Put all these model training steps into a pipeline
    that builds your model automatically and deploys it into a staging environment.
    The great thing about this approach is that you automatically prioritize infrastructure
    and always output a deployed scoring service. This will set you up for success.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Dive into the data**: Make sure you understand the data and its quality,
    how to fill in missing values, and how to pre-process features. You can add additional
    data and work on feature engineering to turn your raw input data into interpretable
    data. If you pick a good baseline model, this work should greatly improve the
    performance of the baseline and give your colleagues a scoring service API to
    use with the new service.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Experiment with more complex models**: Once you are confident that you have
    built a solid data pipeline, you can tackle modeling, including model selection,
    training, validation, optimization, and stacking. Again, you should be able to
    see incremental improvements that can be measured and continuously deployed to
    any QA environment. Once your performance is good enough, roll out the service
    to your customers and start collecting metrics and more training data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitor cloud usage**: When you develop using compute infrastructure in the
    cloud, it is easy to quickly spend a few thousand dollars for a couple of unused
    or underutilized virtual machines. We recommend that you regularly check the number
    of machines and their utilization. If something is not being used anymore, scale
    or shut it down. Remember that the cloud''s number-one benefit is scalable infrastructure.
    So, please take advantage of it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Following this guidance will help you set up a clean and monitored infrastructure
    that you can evolve along the way.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've talked about the base infrastructure you should set up, let's
    talk about automation again.
  prefs: []
  type: TYPE_NORMAL
- en: Automating recurrent tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training an ML model is a complex iterative process that includes data preparation,
    feature engineering, model selection, optimization, and deployment. Above all,
    an enterprise-grade end-to-end ML pipeline needs to be reproducible, interpretable,
    secure, and automated, which poses an additional challenge for most companies
    in terms of know-how, costs, and infrastructure requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, we learned the ins and outs of this process, so we
    can confirm that there is nothing simple or easy about it. Tuning a feature engineering
    approach will affect model training; the missing value strategy during data cleansing
    will influence the optimization process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Above all, the information that''s captured by your model is rarely constant,
    so most ML models require frequent retraining and deployments. This leads to a
    whole new requirement for MLOps: a DevOps pipeline for ML to ensure continuous
    integration and continuous deployment of your data, pipelines, and models.'
  prefs: []
  type: TYPE_NORMAL
- en: Automated ML helps simplify this complex iterative process by automating many
    of these challenges. Instead of manually tuning the input data, then selecting,
    optimizing, and deploying an ML model manually, an automated service just requires
    the input data, as well as a few business-related configurations, such as the
    type of prediction to train.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, using tools such as Azure DevOps and Azure Machine Learning pipelines
    greatly reduces errors and system downtime and frees the user from performing
    a bunch of manual tasks. In addition, services such as Azure Automated Machine
    Learning allows users to optimize ML training and even stack multiple models to
    improve prediction performance. The biggest benefit of this is that the user can
    focus on the most important part of the ML process: understanding, acquiring,
    and cleaning the data.'
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, automated ML services will outperform manually trained models
    while requiring significantly less in terms of training and operation costs. The
    reason for this is that many tasks, such as choosing the correct categorical embedding,
    handling imbalanced data, selecting the best model, finding the best parameters,
    and combining multiple models to improve performance, can be systematically optimized
    as opposed to being chosen manually.
  prefs: []
  type: TYPE_NORMAL
- en: Every major cloud provider offers mature services so that you can perform automated
    ML in the cloud and functionalities to deploy these models conveniently. Automated
    ML is a great way to save time and costs while providing your existing employees
    with the tools needed for training complex end-to-end ML pipelines. This makes
    automated ML a real service – MLaaS.
  prefs: []
  type: TYPE_NORMAL
- en: Speaking about tooling, let's talk about the changes you need to keep up with
    when you're working with modern cloud systems.
  prefs: []
  type: TYPE_NORMAL
- en: Expecting constant change
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Everything is in a constant state of change. 15 years ago, only a few people
    ever heard about neural networks and machine learning. Today, you have access
    to a vast amount of ML libraries, programs, and cloud services. Every day, new
    progress is made to automate ML tasks and improve ML modeling. Just think about
    the voice assistants you may use and what is happening with self-driving vehicles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to this, you are in for a whole bunch of constant changes being made to
    ML libraries and their tooling. This is especially true in a cloud environment,
    where updates can quickly be pushed out to the userbase compared to licensed software.
    As we learned previously, looking at the big cloud providers, their services can
    typically be divided into the following categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Infrastructure as a Service** (**IaaS**): IaaS services are all-infrastructure
    abstractions such as virtual machines (compute), disks (storage), and networking.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform as a Service** (**PaaS**): PaaS services are platforms built on
    top of these components with additional functionality that exposes a service while
    hiding the underlying infrastructure and operating system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software as a Service** (**SaaS**): SaaS services, in contrast, are exposed
    through a UI and don''t give you any access to the underlying software and hardware
    stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Machine Learning is a great example of a PaaS offering as it combines
    different infrastructure services, UIs, and SDKs to give you great new features
    and full access to the underlying services, such as blob storage, training clusters,
    and container registries while putting the operating system out of sight in most
    cases. On your monthly Azure bill, you will see that you spend most of your money
    on infrastructure services when using a PaaS solution.
  prefs: []
  type: TYPE_NORMAL
- en: While the underlying infrastructure builds the foundation for all cloud services,
    they are not likely to change drastically over the next few years. New improvements
    will make their way to the market that typically concentrate on throughput levels
    and network security. Still, you shouldn't expect major changes to be made to
    the existing APIs. In addition, these offerings are not likely to be discontinued
    since they are the backbone of many services.
  prefs: []
  type: TYPE_NORMAL
- en: The same is not true for PaaS services. They are designed to answer the requests
    of customers regarding an abstracted solution so that they are freed from implementing
    tons of boilerplate code and handling the lower-level infrastructure details of
    a solution. How many times have you seen a feature of Azure Machine Learning and
    thought, *Hey, I could easily implement this on my own*? This is certainly true,
    but you may want someone else to solve this simple thing so that you can concentrate
    on the complex problems you are trying to solve. And that's why PaaS exists in
    the first place.
  prefs: []
  type: TYPE_NORMAL
- en: However, the downside with customer-driven needs is that those needs and usage
    patterns are constantly evolving. New use cases are cropping up (such as MLOps)
    that ask for new services or extensions to existing services to be supported.
    Hence, you should always expect that PaaS will change over time.
  prefs: []
  type: TYPE_NORMAL
- en: If you were to look at the first version of this book, you would find that nearly
    half of the code and features that were shown in that version were either deprecated,
    replaced by something new, or merged with other parts of the Azure Machine Learning
    service. Depending on when you are reading this book, you may have found discrepancies
    between the features or APIs that we are describing here and the current APIs
    and features in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: If you were understandably confused and asked yourself how this book could already
    be out of date, we want to assure you that what we are presenting is the right
    technology to bet on. PaaS offerings in general and MLaaS offerings specifically
    undergo massive changes and improvements all the time. Expect change!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at some possible changes you may encounter over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Expect names to change**: This is probably the most common change. Companies
    are notoriously bad at naming products, and Azure and all other cloud providers
    are no exception. This may look like a big change or inconvenience, but it is
    nothing more than changing the name of a service or component or hiding it somewhere
    else in the cloud platform. In the past few years, a lot of changes were made
    to ML regarding Azure. There was a service called **Azure Machine Learning Studio
    (classic)**, which mostly survived as the **Designer** in Azure Machine Learning.
    There were – and still are – services called **Azure Batch**, **Azure BatchAI**,
    and **AML Compute**, which offered mostly the same functionality as the compute
    cluster for batch inference you will now find in Azure Machine Learning. Simply
    put, do not let yourself get distracted by this. Expect some interesting new names
    to pop up for the functionality that you know and love.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expect the UIs to change**: This is the most visible change and is quite
    common in cloud offerings of late. Many services get revamped UIs, some get integrated
    into the Azure UI, and some get placed in a separate application. Expect some
    functionality to be exposed only in one UI and not another. Most often, however,
    a new UI means that just the same or similar functionality is accessible through
    a new interface. This is one of the reasons why we trained you to work so much
    with the Python API or the Azure CLI instead of the graphical interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Expect classes and packages to change in the SDKs**: Most APIs of most cloud
    providers for ML solutions are constantly evolving. Azure has invested a lot of
    money in its ML service, so change is inevitable. A good way to prepare for this
    change is to abstract code into specific implementations that can be swapped out
    easily with new functionality. Another good practice is to be cautious with library
    updates, but also don''t stay behind the most recent version for too long.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do you agree that change is the only constant, given all these circumstances?
    Just keep in mind that all PaaS solutions are ultimately built on an underlying
    infrastructure, which provides a rock-solid foundation for your computing, storage,
    and networking.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, remember: despite the constant change, you are building on the right foundation!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Having talked about most of the things you should consider while using a cloud
    platform for ML, let''s talk about something far more important: data ethics.'
  prefs: []
  type: TYPE_NORMAL
- en: Thinking about your responsibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this final section of this book, we want to take a step back from models,
    deployments, and optimization to talk about a much more important topic: ethics
    when it comes to handling data or what is today known as **responsible AI/ML**.'
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B17928_01_ePub.xhtml#_idTextAnchor015), *Understanding the
    End-to-End Machine Learning Process*, we talked about **bias** in data, how it
    can be introduced willingly or unwillingly into a dataset, and what you have to
    look out for. This is but one small piece of the puzzle to reflect how you are
    gathering data and how your trained model can negatively influence other people's
    lives.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that you are training an ML model to suggest to a bank teller that the
    customer in front of him is allowed to receive a loan and what kind of interest
    rate the customer is allowed to have on that loan. Using an automated system to
    make this decision can be a blessing or a curse. If there is an inherent bias
    in most of the bank tellers of a company and you build a fair model, then this
    will probably be a blessing. However, if your model is based on the previous decisions
    of those bank tellers, you must be on the lookout for a lot of bias in your data.
    If not, you may create an even more unfair world because now, your ML system is
    in charge. A fair teller giving out the loan, even though they may understand
    that there is a bias in your ML system, is now probably not allowed to overrule
    it.
  prefs: []
  type: TYPE_NORMAL
- en: There are far worse examples than this one, but this should give you a good
    idea of what we want to talk about.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally speaking, we can group the responsibilities you have into the following
    categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Interpretability**: How well can you explain your model and the results it
    generates?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fairness**: How well can you ensure fairness by eliminating bias in the data?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Privacy**: How well are the **personally identifiable information** (**PII**)
    of individuals being safeguarded in your underlying data and model? Who has access
    to it?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance**: How well documented is everything you work with and have access
    to? How do you track who is using your data or model?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's have a more detailed look at what you have to watch out for and what tooling
    is offered through Azure Machine Learning to accommodate you while you're doing
    this.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Any deployed ML model is a black box. We send input and receive output in the
    form of a prediction or classification through the model. Therefore, it is hard
    for stakeholders to understand why and why not a system makes certain decisions.
    To alleviate this situation, you can apply new tooling to explain your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we talk about tooling and approaches to explain an ML model, let''s
    group models into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Black-box models**: Models where the calculations are so complex that we
    do not know how the decision came to be.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Glass-box models**: Models where the result can be relatively easily explained
    and calculated. Think about linear regression models, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Glass-box models tend to be simpler, so the trade-off seems to be between explainability
    and complexity (and therefore, possibly accuracy). But if your model handles a
    whole bunch of personal information, you will want to know how the model comes
    to its conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the need for an explainer arises that can interpret black-box models,
    called the **Black Box Explainer**. The following are the two most well-known
    explainers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shapley Additive Explanations** (**SHAP**): This is a game theory approach
    that''s applied to ML models and is used primarily for explainability. This family
    of methods assumes every feature in a model as a **player** in a game. Based on
    this assumption, you can use the so-called **Shapley values** to calculate the
    average contribution of a feature value to a prediction. Simply put, this is done
    by adding and removing features from **coalitions**, which in game theory is the
    group of players cooperating. SHAP can be used for any type of model, but it is
    well defined for linear regression, trees, ensemble trees, and deep learning with
    TensorFlow or Keras. Furthermore, it can explain individual predictions, not only
    explanations on a global scale. You can read more about SHAP in its open source
    release ([https://github.com/slundberg/shap](https://github.com/slundberg/shap)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local Interpretable Model-agnostic Explanations** (**LIME**): This is a method
    that creates a so-called surrogate glass-box model based on any black-box classifier
    model. A surrogate model tries to mimic the behavior of an underlying model while
    reducing its complexity. This is done by training a linear model in the vicinity
    of a particular instance. Users can then look at this newly created glass-box
    model to understand the black-box model''s outputs for this neighborhood or subset
    of predictions. Therefore, LIME can explain individual predictions of the black-box
    model. You can read more about LIME in its open source release ([https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are the techniques you can use to interpret black-box models. To alleviate
    the situation with glass-box models a bit, Microsoft Research is working on an
    ML model called **Explainable Boosting Machine** (**EBM**) that is as accurate
    as gradient boosting while still being completely explainable. Their original
    paper can be found at [https://arxiv.org/abs/2106.09680](https://arxiv.org/abs/2106.09680).
  prefs: []
  type: TYPE_NORMAL
- en: To try out these explainers, you can either use these packages directly in your
    project or you can use the `azureml-interpret` package ([https://docs.microsoft.com/en-us/python/api/azureml-interpret](https://docs.microsoft.com/en-us/python/api/azureml-interpret))
    from the Azure ML SDK. This package gives you access to the **Interpret Community
    SDK** ([https://github.com/interpretml/interpret-community](https://github.com/interpretml/interpret-community)).
    Have a read through the explainer that's available on that package.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to try this out, have a look at the following guide: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml).
    When you were looking at the Azure Machine Learning studio pages throughout all
    the hands-on exercises in this book, you may have noticed a tab called **Explanations**
    in the training runs and models. When you''re using this package, you can add
    the results of the explainers to your training runs and view the visuals online
    afterward.'
  prefs: []
  type: TYPE_NORMAL
- en: For further reading, have a look at the **InterpretML** project ([https://interpret.ml/docs/intro.html](https://interpret.ml/docs/intro.html)),
    which provides an overview of the different types of explainers.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an idea of how to interpret the results of our models, let's
    look at fairness.
  prefs: []
  type: TYPE_NORMAL
- en: Fairness in model training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the major tools for analyzing the fairness of a model is called **Fairlearn**
    ([https://fairlearn.org/](https://fairlearn.org/)). To define if a model behaves
    fairly, the algorithms and metrics in the Fairlearn package look for two types
    of harm that can be done, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Allocation harm**: A model or system withholds opportunities, resources,
    or information. This would fit our previous example, where we discussed an ML
    system giving out loans to individuals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quality-of-service harm**: A model or system that does not withhold something
    but behaves differently toward different groups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To assess the fairness in a given model, two constructs are used, assessment
    metrics and mitigation algorithms. These can be classified as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Assessment metrics**: Metrics can be calculated for a single model by comparing
    multiple models and for models that have been created through the mitigation algorithms.
    They span from simple metrics calculating the recall rate of a model up to adding
    grouping information to the mix to analyze the model results. Further information
    is available here: [https://fairlearn.org/main/user_guide/assessment.html](https://fairlearn.org/main/user_guide/assessment.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduction algorithms**: These build a new standard black-box model from a
    re-weighted training dataset after the assessment. Users can tweak this through
    different model runs to find the optimum trade-off between accuracy and fairness.
    Further information is available here: [https://fairlearn.org/main/user_guide/mitigation.html#reductions](https://fairlearn.org/main/user_guide/mitigation.html#reductions).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Post-processing algorithms**: These algorithms take the original model and
    the sensitive feature to calculate a transformation to be applied to the prediction
    of the model. Through this process, we avoid retraining the original model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Be aware that packages such as Fairlearn are still in development. Since deciding
    on fairness is not a simple topic, do not only rely on such tooling. When you''re
    thinking about the types of biases you can introduce, be reflective on what you
    are doing and use tools like these to get more insights. The developers of Fairlearn
    pointed the following out:'
  prefs: []
  type: TYPE_NORMAL
- en: '"Fairness is fundamentally a sociotechnical challenge. Many aspects of fairness,
    such as justice and due process, are not captured by quantitative fairness metrics.
    Furthermore, there are many quantitative fairness metrics which cannot all be
    satisfied simultaneously. Our goal is to enable humans to assess different mitigation
    strategies and then make trade-offs appropriate to their scenario."'
  prefs: []
  type: TYPE_NORMAL
- en: For a guide on how to use the Fairlearn package with Azure Machine Learning
    and how to upload your results, go to [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let's learn how to handle privacy and compliance with Azure Machine
    Learning.
  prefs: []
  type: TYPE_NORMAL
- en: Handling PII data and compliance requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the dawn of legislation such as the **General Data Protection Regulation**
    (**GDPR**) in Europe and the **California Consumer Privacy Act** (**CCPA**) in
    California, businesses are now in a predicament. Besides having clear instructions
    on how PII data can be utilized, they are also often required to store audit trails
    of any action that involved this data, from a user up to an employee of the company
    accessing this data.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is very important to have the tooling to support this effort.
    Most Azure services have security measures in place to deal with external intruders
    and to build multi-tenant applications, helping customers avoid seeing the PII
    data of others. Still, the ones administrating the system have access to this
    clear text data in most organizations. And the same is true for someone building
    an ML model. In addition, databases on Azure can typically log any access and
    build an audit trail for review. But what about the ML modeling pipeline or deployment
    pipeline? Who can see the data in which form and at which point?
  prefs: []
  type: TYPE_NORMAL
- en: 'All these questions need to be answered. Let''s look at some of the available
    tooling and research that''s being done in this area:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Differential privacy**: This mechanism is used to add noise or randomness
    to data to make the data of a person unidentifiable. In doing so, we can still
    build an accurate model on a slightly changed dataset. Be aware that this is not
    referring to obvious PII data, such as your name or email address. To give you
    something to think about: you can likely be identified directly by the version
    of the browser and the installed browser add-ons you are using. This method was
    implemented in a package called **SmartNoise** ([https://github.com/opendp/smartnoise-core](https://github.com/opendp/smartnoise-core)),
    which you can use in your ML projects. Additional information about this topic
    can be found here: [https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Homomorphic encryption**: This allows computation to be done on encrypted
    data without allowing access to a decryption key. Only the results of the computation
    need to be decrypted with a secret key. So far, even using encrypted data and
    decrypting it with a key was bothersome, since running encryption on TBs of data
    was time-consuming. Now, this technology, which has been researched by Microsoft,
    is available through the **Microsoft SEAL** project ([https://www.microsoft.com/en-us/research/project/microsoft-seal/](https://www.microsoft.com/en-us/research/project/microsoft-seal/)).
    Furthermore, you can learn how to use this method with an inferencing web service
    by following the guide at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Datasheets for models**: This provides guidelines for documenting ML assets
    and their life cycles. To be compliant with regulations and also just to work
    cleanly, a guideline called **ABOUT ML** ([https://partnershiponai.org/paper/about-ml-reference-document/](https://partnershiponai.org/paper/about-ml-reference-document/))
    can be adapted. A view of how to adapt this guideline in the context of Azure
    Machine Learning can be found here: [https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb](https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep an eye on these topics as they develop since failure to comply with these
    regulations can have dire consequences.
  prefs: []
  type: TYPE_NORMAL
- en: As you have seen, all the packages we've discussed in this section are still
    in alpha or beta stages since the topics of interpretability, fairness, and privacy
    are relatively new in the context of ML. For a decade, ML was more of a research
    topic than a real-life production environment. Nowadays, solutions that build
    on ML have found their way into our daily lives. Therefore, we need to take a
    step back and start asking if we can let machines decide for us without questioning
    their validity.
  prefs: []
  type: TYPE_NORMAL
- en: So, when you're running your next ML project that is bound for production, bring
    these topics into the discussion since they need to be handled from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at a few things from a much higher level by covering
    data, infrastructure, monitoring, automation, change management, and ethics. We
    hope that our coverage of these topics made sense to you after reading this book.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that your data will control and influence everything,
    so making data a first-class citizen in your company is the first important step.
    Hiring a *VP of Data* and defining standards on data quality, lineage, and discoverability
    are just a few of the measures you can take.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at automatization, we saw that Automated Machine Learning will run
    the world in a couple of years. The idea is quite simple: a trained meta-model
    will always be better at proposing, training, optimizing, and stacking models
    for higher predictive performance than humans. This makes total sense. It is just
    another parameter optimization step that also includes the model architecture.
    Another interesting thought is that Automated Machine Learning will offer true
    MLaaS to users who aren''t ML-savvy. Maybe a prediction column will be provided
    in Excel, or an ML transformation step in Power BI, meaning regular Office users
    can suddenly harness the power of ML through spreadsheet applications.'
  prefs: []
  type: TYPE_NORMAL
- en: We also mentioned that change is inevitable when working with PaaS in the cloud.
    This is because PaaS solutions are designed to implement typical customer solutions
    and drive you toward consuming more infrastructure services. As customer needs
    evolve, so do these PaaS offerings. Hence, a good takeaway is to not get too attached
    to product names, UIs, or SDK packages.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we understood the importance of ethics in data handling. We discussed
    the topics of building models that can be explained, assessing the fairness of
    our models, and how we can safeguard the personal data of individuals from ourselves
    and others.
  prefs: []
  type: TYPE_NORMAL
- en: We hope you have enjoyed this book and learned how to master ML and Azure Machine
    Learning. However, the rabbit hole is far deeper than this book. So, keep on learning,
    as we also will. Reach out to us on social media and tell us what you've learned,
    what you liked, and what could be improved in this book. We would love to hear
    your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Until then, happy machine learning!
  prefs: []
  type: TYPE_NORMAL
