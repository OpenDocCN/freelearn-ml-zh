["```py\nimport (\n    \"fmt\"\n     mnist \"github.com/petar/GoMNIST\"\n    \"github.com/kniren/gota/dataframe\"\n    \"github.com/kniren/gota/series\"\n    \"math/rand\"\n    \"github.com/cdipaolo/goml/linear\"\n    \"github.com/cdipaolo/goml/base\"\n    \"image\"\n    \"bytes\"\n    \"math\"\n    \"github.com/gonum/stat\"\n    \"github.com/gonum/integrate\"\n)\nset, err := mnist.ReadSet(\"../datasets/mnist/images.gz\", \"../datasets/mnist/labels.gz\")\n```", "```py\nset.Images[1]\n```", "```py\nfunc MNISTSetToDataframe(st *mnist.Set, maxExamples int) dataframe.DataFrame {\n length := maxExamples\n if length > len(st.Images) {\n length = len(st.Images)\n }\n s := make([]string, length, length)\n l := make([]int, length, length)\n for i := 0; i < length; i++ {\n s[i] = string(st.Images[i])\n l[i] = int(st.Labels[i])\n }\n var df dataframe.DataFrame\n images := series.Strings(s)\n images.Name = \"Image\"\n labels := series.Ints(l)\n labels.Name = \"Label\"\n df = dataframe.New(images, labels)\n return df\n}\n\ndf := MNISTSetToDataframe(set, 1000)\n```", "```py\ncategories := []string{\"tshirt\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"shoe\", \"bag\", \"boot\"}\n```", "```py\ntraining, validation := Split(df, 0.75)\n```", "```py\nfunc EqualsInt(s series.Series, to int) (*series.Series, error) {\n eq := make([]int, s.Len(), s.Len())\n ints, err := s.Int()\n if err != nil {\n return nil, err\n }\n for i := range ints {\n if ints[i] == to {\n eq[i] = 1\n }\n    }\n    ret := series.Ints(eq)\n    return &ret, nil\n}\n\ntrainingIsTrouser, err1 := EqualsInt(training.Col(\"Label\"), 1)\nvalidationIsTrouser, err2 := EqualsInt(validation.Col(\"Label\"), 1)\nif err1 != nil || err2 != nil {\n    fmt.Println(\"Error\", err1, err2)\n}\n```", "```py\nfunc NormalizeBytes(bs []byte) []float64 {\n    ret := make([]float64, len(bs), len(bs))\n    for i := range bs {\n        ret[i] = float64(bs[i])/255.\n    }\n    return ret\n}\n\nfunc ImageSeriesToFloats(df dataframe.DataFrame, col string) [][]float64 {\n    s := df.Col(col)\n    ret := make([][]float64, s.Len(), s.Len())\n    for i := 0; i < s.Len(); i++ {\n        b := []byte(s.Elem(i).String())\n        ret[i] = NormalizeBytes(b)\n    }\n    return ret\n}\n\ntrainingImages := ImageSeriesToFloats(training, \"Image\")\nvalidationImages := ImageSeriesToFloats(validation, \"Image\")\n```", "```py\nmodel := linear.NewLogistic(base.BatchGA, 1e-4, 1, 150, trainingImages, trainingIsTrouser.Float())\n\n//Train\nerr := model.Learn()\nif err != nil {\n  fmt.Println(err)\n}\n```", "```py\n//Count correct classifications\nvar correct = 0.\nfor i := range validationImages {\n  prediction, err := model.Predict(validationImages[i])\n  if err != nil {\n    panic(err)\n  }\n\n  if math.Round(prediction[0]) == validationIsTrouser.Elem(i).Float() {\n    correct++\n  }\n}\n\n//accuracy\ncorrect / float64(len(validationImages))\n```", "```py\n//Count true positives and false negatives\nvar truePositives = 0.\nvar falsePositives = 0.\nvar falseNegatives = 0.\nfor i := range validationImages {\n  prediction, err := model.Predict(validationImages[i])\n  if err != nil {\n    panic(err)\n  }\n  if validationIsTrouser.Elem(i).Float() == 1 {\n    if math.Round(prediction[0]) == 0 {\n      // Predicted false, but actually true\n      falseNegatives++\n    } else {\n      // Predicted true, correctly\n      truePositives++\n    }\n  } else {\n    if math.Round(prediction[0]) == 1 {\n      // Predicted true, but actually false\n      falsePositives++\n    }\n  }\n}\n```", "```py\n//precision\ntruePositives / (truePositives + falsePositives)\n//recall\ntruePositives / (truePositives + falseNegatives)\n```", "```py\nmodel2 := linear.NewSoftmax(base.BatchGA, 1e-4, 1, 10, 100, trainingImages, training.Col(\"Label\").Float())\n\n//Train\nerr := model2.Learn()\nif err != nil {\n  fmt.Println(err)\n}\n```", "```py\nfunc MaxIndex(f []float64) (i int) {\n  var (\n    curr float64\n    ix int = -1\n  )\n  for i := range f {\n    if f[i] > curr {\n      curr = f[i]\n      ix = i\n    }\n  }\n  return ix\n}\n```", "```py\n//create objects for ROC generation\n//as per https://godoc.org/github.com/gonum/stat#ROC\ny := make([][]float64, len(categories), len(categories))\nclasses := make([][]bool, len(categories), len(categories))\n//Validate\nfor i := 0; i < validation.Col(\"Image\").Len(); i++ {\n  prediction, err := model2.Predict(validationImages[i])\n  if err != nil {\n    panic(err)\n  }\n  for j := range categories {\n    y[j] = append(y[j], prediction[j])\n    classes[j] = append(classes[j], validation.Col(\"Label\").Elem(i).Float() != float64(j))\n  }\n}\n\n//Calculate ROC\ntprs := make([][]float64, len(categories), len(categories))\nfprs := make([][]float64, len(categories), len(categories))\n\nfor i := range categories {\n  stat.SortWeightedLabeled(y[i], classes[i], nil)\n  tprs[i], fprs[i] = stat.ROC(0, y[i], classes[i], nil)\n}\n\n```", "```py\nfor i := range categories {\n  fmt.Println(categories[i])\n  auc := integrate.Trapezoidal(fprs[i], tprs[i])\n  fmt.Println(auc)\n}\n```", "```py\nimport (\n  \"gonum.org/v1/plot\"\n  \"gonum.org/v1/plot/plotter\"\n  \"gonum.org/v1/plot/plotutil\"\n  \"gonum.org/v1/plot/vg\"\n  \"bufio\"\n)\n\nfunc plotROCBytes(fprs, tprs [][]float64, labels []string) []byte {\n  p, err := plot.New()\n  if err != nil {\n    panic(err)\n  }\n\n  p.Title.Text = \"ROC Curves\"\n  p.X.Label.Text = \"False Positive Rate\"\n  p.Y.Label.Text = \"True Positive Rate\"\n\n  for i := range labels {\n    pts := make(plotter.XYs, len(fprs[i]))\n    for j := range fprs[i] {\n      pts[j].X = fprs[i][j]\n      pts[j].Y = tprs[i][j]\n    }\n    lines, points, err := plotter.NewLinePoints(pts)\n    if err != nil {\n      panic(err)\n    }\n    lines.Color = plotutil.Color(i)\n    lines.Width = 2\n    points.Shape = nil\n\n    p.Add(lines, points)\n    p.Legend.Add(labels[i], lines, points)\n  }\n\n  w, err := p.WriterTo(5*vg.Inch, 4*vg.Inch, \"jpg\")\n  if err != nil {\n    panic(err)\n  }\n  if err := p.Save(5*vg.Inch, 4*vg.Inch, \"Multi-class ROC.jpg\"); err != nil {\n    panic(err)\n  }\n  var b bytes.Buffer\n  writer := bufio.NewWriter(&b)\n  w.WriteTo(writer)\n  return b.Bytes()\n}\n```", "```py\ntrainingOutputs := make([]float64, len(trainingImages))\nvalidationOutputs := make([]float64, len(validationImages))\n\nltCol:= training.Col(\"Label\")\nfor i := range trainingImages {\n    trainingOutputs[i] = ltCol.Elem(i).Float()\n}\n\nlvCol:= validation.Col(\"Label\")\nfor i := range validationImages {\n    validationOutputs[i] = lvCol.Elem(i).Float()\n}\n\n// FloatstoSVMNode converts a slice of float64 to SVMNode with sequential indices starting at 1\nfunc FloatsToSVMNode(f []float64) []libsvm.SVMNode {\n    ret := make([]libsvm.SVMNode, len(f), len(f))\n    for i := range f {\n        ret[i] = libsvm.SVMNode{\n            Index: i+1,\n            Value: f[i],\n        }\n    }\n    //End of Vector\n    ret = append(ret, libsvm.SVMNode{\n        Index: -1,\n        Value: 0,\n    })\n    return ret\n}\n```", "```py\nvar (\n  trainingProblem libsvm.SVMProblem\n  validationProblem libsvm.SVMProblem\n)\n\ntrainingProblem.L = len(trainingImages)\nvalidationProblem.L = len(validationImages)\nfor i := range trainingImages {\n  trainingProblem.X = append(trainingProblem.X, FloatsToSVMNode(trainingImages[i]))\n}\ntrainingProblem.Y = trainingOutputs\n\nfor i := range validationImages {\n  validationProblem.X = append(validationProblem.X, FloatsToSVMNode(validationImages[i]))\n}\nvalidationProblem.Y = validationOutputs\n\n// configure SVM\nsvm := libsvm.NewSvm()\nparam := libsvm.SVMParameter{\n  SvmType: libsvm.CSVC,\n  KernelType: libsvm.RBF,\n  C: 100,\n  Gamma: 0.01,\n  Coef0: 0,\n  Degree: 3,\n  Eps: 0.001,\n  Probability: 1,\n}\n```", "```py\nmodel := svm.SVMTrain(&trainingProblem, &param)\n```", "```py\nimport (\n \"github.com/patrikeh/go-deep\"\n \"github.com/patrikeh/go-deep/training\"\n)\n\nnetwork := deep.NewNeural(&deep.Config{\n // Input size: 784 in our case (number of pixels in each image)\n Inputs: len(trainingImages[0]),\n // Two hidden layers of 128 neurons each, and an output layer 10 neurons (one for each class)\n Layout: []int{128, 128, len(categories)},\n // ReLU activation to introduce some additional non-linearity\n Activation: deep.ActivationReLU,\n // We need a multi-class model\n Mode: deep.ModeMultiClass,\n // Initialise the weights of each neuron using normally distributed random numbers\n Weight: deep.NewNormal(0.5, 0.1),\n Bias: true,\n})\n```", "```py\n// Parameters: learning rate, momentum, alpha decay, nesterov\noptimizer := training.NewSGD(0.006, 0.1, 1e-6, true)\ntrainer := training.NewTrainer(optimizer, 1)\n\ntrainer.Train(network, trainingExamples, validationExamples, 500) \n// training, validation, iterations\n```", "```py\nimport (\n    \"fmt\"\n    \"github.com/kniren/gota/dataframe\"\n    \"github.com/kniren/gota/series\"\n    \"math/rand\"\n    \"image\"\n    \"bytes\"\n    \"math\"\n    \"github.com/gonum/stat\"\n    \"github.com/gonum/integrate\"\n    \"github.com/sajari/regression\"\n    \"io/ioutil\"\n)\n\nconst path = \"../datasets/housing/CaliforniaHousing/cal_housing.data\"\n\ncolumns := []string{\"longitude\", \"latitude\", \"housingMedianAge\", \"totalRooms\", \"totalBedrooms\", \"population\", \"households\", \"medianIncome\", \"medianHouseValue\"}\nb, err := ioutil.ReadFile(path)\nif err != nil {\n    fmt.Println(\"Error!\", err)\n}\ndf := dataframe.ReadCSV(bytes.NewReader(b), dataframe.Names(columns...))\n```", "```py\n// Divide divides two series and returns a series with the given name. The series must have the same length.\nfunc Divide(s1 series.Series, s2 series.Series, name string) series.Series {\n    if s1.Len() != s2.Len() {\n        panic(\"Series must have the same length!\")\n    }\n\n    ret := make([]interface{}, s1.Len(), s1.Len())\n    for i := 0; i < s1.Len(); i ++ {\n        ret[i] = s1.Elem(i).Float()/s2.Elem(i).Float()\n    }\n    s := series.Floats(ret)\n    s.Name = name\n    return s\n}\n\n// MultiplyConst multiplies the series by a constant and returns another series with the same name.\nfunc MultiplyConst(s series.Series, f float64) series.Series {\n    ret := make([]interface{}, s.Len(), s.Len())\n    for i := 0; i < s.Len(); i ++ {\n        ret[i] = s.Elem(i).Float()*f\n    }\n    ss := series.Floats(ret)\n    ss.Name = s.Name\n    return ss\n}\n\ndf = df.Mutate(Divide(df.Col(\"totalRooms\"), df.Col(\"households\"), \"averageRooms\"))\ndf = df.Mutate(Divide(df.Col(\"totalBedrooms\"), df.Col(\"households\"), \"averageBedrooms\"))\ndf = df.Mutate(Divide(df.Col(\"population\"), df.Col(\"households\"), \"averageOccupancy\"))\ndf = df.Mutate(MultiplyConst(df.Col(\"medianHouseValue\"), 0.00001))\ndf = df.Select([]string{\"medianIncome\", \"housingMedianAge\", \"averageRooms\", \"averageBedrooms\", \"population\", \"averageOccupancy\", \"latitude\", \"longitude\", \"medianHouseValue\" })\n```", "```py\nfunc Split(df dataframe.DataFrame, valFraction float64) (training dataframe.DataFrame, validation dataframe.DataFrame){\n    perm := rand.Perm(df.Nrow())\n    cutoff := int(valFraction*float64(len(perm)))\n    training = df.Subset(perm[:cutoff])\n    validation = df.Subset(perm[cutoff:])\n    return training, validation\n}\n\ntraining, validation := Split(df, 0.75)\n\n// DataFrameToXYs converts a dataframe with float64 columns to a slice of independent variable columns as floats\n// and the dependent variable (yCol). This can then be used with eg. goml's linear ML algorithms.\n// yCol is optional - if it does not exist only the x (independent) variables will be returned.\nfunc DataFrameToXYs(df dataframe.DataFrame, yCol string) ([][]float64, []float64){\n    var (\n        x [][]float64\n        y []float64\n        yColIx = -1\n    )\n\n    //find dependent variable column index\n    for i, col := range df.Names() {\n        if col == yCol {\n            yColIx = i\n            break\n        }\n    }\n    if yColIx == -1 {\n        fmt.Println(\"Warning - no dependent variable\")\n    }\n    x = make([][]float64, df.Nrow(), df.Nrow()) \n    y = make([]float64, df.Nrow())\n    for i := 0; i < df.Nrow(); i++ {\n        var xx []float64\n        for j := 0; j < df.Ncol(); j ++ {\n            if j == yColIx {\n                y[i] = df.Elem(i, j).Float()\n                continue\n            }\n            xx = append(xx, df.Elem(i,j).Float())\n        }\n        x[i] = xx \n    }\n    return x, y\n}\n\ntrainingX, trainingY := DataFrameToXYs(training, \"medianHouseValue\")\nvalidationX, validationY := DataFrameToXYs(validation, \"medianHouseValue\")\n```", "```py\nmodel := new(regression.Regression)\n\nfor i := range trainingX {\n  model.Train(regression.DataPoint(trainingY[i], trainingX[i]))\n}\nif err := model.Run(); err != nil {\n  fmt.Println(err)\n}\n```", "```py\n//On validation set\nerrors := make([]float64, len(validationX), len(validationX))\nfor i := range validationX {\n  prediction, err := model.Predict(validationX[i])\n  if err != nil {\n    panic(fmt.Println(\"Prediction error\", err))\n  }\n  errors[i] = (prediction - validationY[i]) * (prediction - validationY[i])\n}\n\nfmt.Printf(\"MSE: %5.2f\\n\", stat.Mean(errors, nil))\n```", "```py\nfunc FloatsToInterfaces(f []float64) []interface{} {\n    iif := make([]interface{}, len(f), len(f))\n    for i := range f {\n        iif[i] = f[i]\n    }\n    return iif\n}\n\ntx, trainingY := DataFrameToXYs(training, \"medianHouseValue\")\nvx, validationY := DataFrameToXYs(validation, \"medianHouseValue\")\n\nvar (\n    trainingX = make([][]interface{}, len(tx), len(tx))\n    validationX = make([][]interface{}, len(vx), len(vx))\n)\n\nfor i := range tx {\n    trainingX[i] = FloatsToInterfaces(tx[i])\n}\nfor i := range vx {\n    validationX[i] = FloatsToInterfaces(vx[i])\n}\n```", "```py\nmodel := Regression.BuildForest(trainingX, trainingY, 25, len(trainingX), 1)\n```"]