- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: MLOps Governance with Vertex AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Vertex AI的MLOps治理
- en: In the rapidly evolving digital era, the successful implementation of **machine
    learning** (**ML**) solutions is not just about creating sophisticated models
    that can predict outcomes accurately for complex use cases. While this is undoubtedly
    essential, the proficient management and governance of **artificial intelligence**
    (**AI**)/**ML operations** (**MLOps**) is equally important. This is especially
    important in an enterprise setting where companies have to ensure they adhere
    to several internal policies and regulatory compliance requirements. This chapter
    delves into different MLOps governance components and how you can utilize features
    available within Google Cloud to implement them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的数字时代，成功实施机器学习（ML）解决方案并不仅仅是创建能够准确预测复杂用例结果的复杂模型。虽然这无疑是必要的，但人工智能（AI）/机器学习操作（MLOps）的熟练管理和治理同样重要。这在企业环境中尤为重要，公司必须确保他们遵守多项内部政策和法规合规要求。本章深入探讨不同的MLOps治理组件以及如何利用Google
    Cloud中可用的功能来实施它们。
- en: MLOps governance revolves around instituting a structured approach to managing
    and optimizing the various moving parts of ML operations. It encompasses the processes,
    tools, and guidelines that ensure the smooth functioning of ML projects, all while
    complying with required policies and regulations.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps治理围绕建立一个结构化的方法来管理和优化机器学习操作的各个组成部分。它包括确保机器学习项目顺利运行并符合所需政策和法规的过程、工具和指南。
- en: 'In this chapter, we will cover MLOps governance on Google Cloud, with a focus
    on the following key areas:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖Google Cloud上的MLOps治理，重点关注以下关键领域：
- en: Understanding MLOps governance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解MLOps治理
- en: Case studies of MLOps governance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLOps治理案例研究
- en: Implementing MLOps governance on Google Cloud
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Google Cloud上实施MLOps治理
- en: By the end of this chapter, our goal is to equip you with a comprehensive understanding
    of MLOps governance, its implementation on Google Cloud, and its critical role
    in maintaining successful, scalable, and compliant ML operations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们的目标是让您全面了解MLOps治理、在Google Cloud上的实施以及它在维护成功、可扩展和合规的机器学习操作中的关键作用。
- en: What is MLOps governance and what are its key components?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是MLOps治理及其关键组成部分？
- en: MLOps refers to the discipline that combines ML, data science, and DevOps principles
    to manage the life cycle of ML models efficiently. The goal of MLOps is to create
    a streamlined pipeline for developing, deploying, and maintaining ML models, ensuring
    that these models provide reliable and consistent results. However, the implementation
    and management of such a practice require a governing framework to ensure adherence
    to best practices and standards. This governing framework is what we refer to
    as MLOps governance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是指将机器学习（ML）、数据科学和DevOps原则相结合的学科，以有效地管理机器学习模型的整个生命周期。MLOps的目标是创建一个简化的管道，用于开发、部署和维护机器学习模型，确保这些模型提供可靠和一致的结果。然而，实施和管理这种实践需要治理框架来确保遵守最佳实践和标准。我们所说的MLOps治理就是指这个治理框架。
- en: MLOps governance is an essential, yet often overlooked, aspect of implementing
    and managing ML models within an organization. It encapsulates a comprehensive
    set of rules, procedures, and guidelines aimed at overseeing the ML models throughout
    their life cycle. This governance plays a pivotal role in ensuring that the MLOps
    pipeline operates smoothly and ethically, mitigating any risks associated with
    ML model deployment and usage.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps治理是实施和管理组织内部机器学习模型的一个基本但往往被忽视的方面。它包含了一套全面的规则、程序和指南，旨在监督机器学习模型在其整个生命周期中的运行。这种治理在确保MLOps管道平稳和道德地运行、减轻与机器学习模型部署和使用相关的任何风险方面发挥着关键作用。
- en: 'The primary focus of MLOps governance is to create a reliable, transparent,
    and accountable ML system within an organization. This involves overseeing aspects
    such as data handling, model development, model deployment, model monitoring,
    and model auditing and can be broken down into two key facets: **data governance**
    and **model governance**.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps治理的主要焦点是在组织内部创建一个可靠、透明和可问责的机器学习（ML）系统。这包括监督数据管理、模型开发、模型部署、模型监控和模型审计，可以分为两个关键方面：**数据治理**和**模型治理**。
- en: Data governance
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据治理
- en: ML models are only as good as the data they are trained on. In MLOps governance,
    data handling refers to the governance of how data is collected, stored, processed,
    and used. It entails ensuring the quality and relevance of data, preserving data
    privacy, and complying with relevant regulations. This guarantees that the data
    that’s used for model training is not only of high quality but also ethically
    sourced and used.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ML 模型的质量仅取决于其训练所使用的数据。在 MLOps 管理中，数据处理指的是对数据收集、存储、处理和使用的管理。它包括确保数据的质量和相关性、保护数据隐私以及遵守相关法规。这保证了用于模型训练的数据不仅质量高，而且来源和用途符合伦理。
- en: Model governance
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型治理
- en: 'Model governance comprises the following components:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 模型治理包括以下组件：
- en: '**Model deployment management**: Overseeing model deployment involves ensuring
    that the model is correctly integrated into the organization’s system and that
    it operates as expected. It also involves checking that the model doesn’t inadvertently
    cause any harmful outcomes, such as biased results or privacy violations.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署管理**：监督模型部署包括确保模型正确集成到组织的系统中，并按预期运行。它还涉及检查模型是否无意中造成任何有害后果，例如偏差结果或隐私侵犯。'
- en: '**Model auditing**: MLOps governance ensures that there is a systematic review
    of the ML models in terms of their performance, ethical implications, and overall
    impact on the organization. Model auditing is essential to maintain transparency
    and accountability, particularly in scenarios where the model’s predictions significantly
    influence business decisions or user experiences.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型审计**：MLOps 管理确保对 ML 模型在性能、伦理影响和整体对组织影响方面进行系统性的审查。模型审计对于保持透明度和问责制至关重要，尤其是在模型的预测对商业决策或用户体验有重大影响的情况下。'
- en: '**Model monitoring**: Once the model has been deployed, MLOps governance requires
    that it be monitored continuously for any changes in its performance. This includes
    tracking the model’s accuracy, detecting data drift, and making sure the model
    continues to deliver reliable predictions.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：一旦模型部署，MLOps 管理要求持续监控其性能的任何变化。这包括跟踪模型的准确性、检测数据漂移，并确保模型持续提供可靠的预测。'
- en: MLOps governance is not a one-size-fits-all practice; it needs to be tailored
    to the specific needs and circumstances of each organization. This might involve
    customizing the governance based on the nature of the data being handled, the
    type of ML models being used, the specific applications of these models, and the
    broader regulatory landscape.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 管理不是一刀切的做法；它需要根据每个组织的具体需求和情况量身定制。这可能涉及根据处理的数据的性质、使用的 ML 模型类型、这些模型的具体应用以及更广泛的监管环境来定制管理体系。
- en: To summarize, MLOps governance is a critical component of any organization that
    employs ML models. By establishing robust MLOps governance, organizations can
    ensure that their MLOps practices are not just effective but also ethical, transparent,
    and compliant.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，MLOps 管理是任何采用 ML 模型的组织的关键组成部分。通过建立强大的 MLOps 管理体系，组织可以确保其 MLOps 实践不仅有效，而且符合道德、透明和合规。
- en: Enterprise scenarios that highlight the importance of MLOps governance
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 突出 MLOps 管理重要性的企业场景
- en: To understand the importance of MLOps governance, let’s go through some real-world
    scenarios that highlight this.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 MLOps 管理的重要性，让我们通过一些强调这一点的现实场景来探讨。
- en: Scenario 1 – limiting bias in AI solutions
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景 1 – 限制 AI 解决方案中的偏差
- en: Consider a financial services firm deploying a suite of ML models to predict
    credit risk. A large firm in the finance sector would have an array of internal
    policies around the data access, usage, and risk assessment of predictive models
    that its ML solutions will need to adhere to. This could range from limits on
    what data can be used for such purposes to who can access the model’s outputs.
    It would also be obligated to follow several regulatory requirements, such as
    preventing bias against protected classes in its decision-making models. For example,
    a bank would need to ensure that its decision-making process around loan approval
    is not biased based on race or gender. Even if the regulators can’t decipher the
    underlying ML models, they can conduct statistical analysis to detect whether
    there is a significant correlation between loan approvals and factors such as
    race. If a bank is found to be biased in its decision-making, besides being hit
    with substantial penalties by the regulators, it would also have a major public
    relations disaster on its hands. So the bank needs to build checks and balances
    in their ML development life cycle to flag any such issues in their models under
    development and prevent such models from ever reaching production environments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一家金融服务业公司部署了一套机器学习模型来预测信用风险。金融领域的这家大型公司会有一系列内部政策，涉及数据访问、使用和预测模型的风险评估，其机器学习解决方案需要遵守这些政策。这可能包括限制可用于此类目的的数据，以及谁可以访问模型输出。它还必须遵守多项监管要求，例如防止决策模型中对受保护群体的偏见。例如，银行需要确保其贷款审批的决策过程不会基于种族或性别产生偏见。即使监管者无法解读底层机器学习模型，他们也可以进行统计分析，以检测贷款审批与种族等因素之间是否存在显著的相关性。如果发现银行在决策中存在偏见，除了会受到监管机构的重大罚款外，还会面临重大的公关灾难。因此，银行需要在机器学习开发的生命周期中建立制衡机制，以标记其开发中的模型中可能出现的任何此类问题，并防止此类模型进入生产环境。
- en: Scenario 2 – the need to constantly monitor shifts in feature distributions
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景2 – 持续监控特征分布的变化
- en: Consider a scenario where an online e-commerce giant makes extensive use of
    AI to provide personalized recommendations to its retail customers. It has a set
    of models that seem to be working well in production. Now, the retailer is making
    a big marketing push to acquire users in additional regions that have been underrepresented
    in its customer base so far. As the influx of customers from new regions starts
    to grow, the retailer’s business development team notices a sharp decline in its
    click-through rate and revenue per user session based on the new monthly sales
    analytics report. When its analysts dig into the possible causes, they realize
    that the age distribution of users from the new regions is significantly different
    from the age distribution of the customers from the existing regions. This type
    of shift in feature/data distribution is known as **data drift** in MLOps parlance
    and can have a significant impact on user experience and, ultimately, the company’s
    bottom line. Although we are considering a hypothetical scenario where the company’s
    expansion into additional regions is causing a shift in data, this can happen
    due to several different scenarios, including, but not limited to, a shift in
    marketing strategy, a change in the economy, and a change in product offerings.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个在线电子商务巨头广泛使用人工智能为零售客户提供个性化推荐的情况。它有一套在生产中似乎运行良好的模型。现在，零售商正在进行大规模的市场推广，以获取其客户基础中迄今为止代表性不足的额外地区的用户。随着来自新地区客户的大量涌入，零售商的业务发展团队根据新的月度销售分析报告注意到其点击率和每用户会话收入急剧下降。当其分析师深入研究可能的原因时，他们意识到新地区用户的年龄分布与现有地区客户的年龄分布存在显著差异。这种特征/数据分布的变化在MLOps术语中被称为**数据漂移**，可能会对用户体验和公司最终底线产生重大影响。尽管我们正在考虑一个假设场景，即公司向额外地区的扩张导致数据发生变化，但这可能由多种不同的情况引起，包括但不限于营销策略的变化、经济的变化和产品供应的变化。
- en: So, it’s important to have checks in place to catch such material changes in
    inference input data early so that the data science team can mitigate its impact
    by either building newer models with more recent data or building more targeted
    models.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的是要建立检查机制，以便及早发现推理输入数据中的此类重大变化，以便数据科学团队能够通过构建使用更近期数据的更新模型或构建更针对性的模型来减轻其影响。
- en: Scenario 3 – the need to monitor costs
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景3 – 监控成本的需求
- en: With great power comes great responsibility. Just like any other scalable technology
    in the cloud, there is a possibility of your team running up a huge bill if the
    resources are not planned properly, and proper budgets and limits are not set
    in the Google Cloud projects as safeguards. Consider a situation where a data
    scientist spins up a Vertex AI Workbench environment with an expensive GPU attached
    to the node for a quick experiment but then forgets to shut down the machine.
    Another similar scenario would be where someone tries to schedule an MLOps pipeline
    to run once a month with an extremely large GPU cluster but mistakenly configures
    it to run once a day, thereby making the cost 30x what it should have been. One
    or two such mistakes by themselves might not break the bank for a typical mid-size
    company but you can imagine how such costs can quickly add up, especially in large,
    distributed teams where no single person has full context of whether a training
    job running on a $10k/month cluster for last 3 days is an actual experiment being
    tracked or whether it’s just a mistake. So, it’s extremely important to set up
    cost management policies and, more importantly, automated controls that would
    limit the usage of specific resources on **Google Cloud** **Platform** (**GCP**).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 权力越大，责任越大。就像云中的任何其他可扩展技术一样，如果资源没有合理规划，并且没有在 Google Cloud 项目中设置适当的预算和限制作为安全措施，您的团队可能会产生巨额账单。考虑这样一种情况，数据科学家启动了一个
    Vertex AI Workbench 环境，节点上连接了一个昂贵的 GPU 进行快速实验，但后来忘记了关闭机器。另一个类似的场景是，有人试图安排一个每月运行一次的
    MLOps 管道，使用一个极其庞大的 GPU 集群，但错误地将其配置为每天运行一次，从而使成本增加了 30 倍。这样的错误可能本身不会让一家典型的中型公司破产，但您可以想象这样的成本如何迅速累积，尤其是在大型、分散的团队中，没有人完全清楚在价值
    10,000 美元/月的集群上运行了 3 天的训练作业是否是实际跟踪的实验，或者它只是个错误。因此，设置成本管理政策非常重要，更重要的是，设置自动控制，以限制在
    **Google Cloud 平台**（**GCP**）上特定资源的使用。
- en: Scenario 4 – monitoring how the training data is sourced
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景 4 – 监控训练数据的来源
- en: Although data controls at the source of the data would primarily be handled
    by the data owners, AI product/solution leaders need to be cognizant of where
    they are sourcing their data from. If the data that’s being used to train the
    models is later discovered to be unlicensed or coming from sources with questionable
    data quality, it can lead to a significant amount of wasted resources, both in
    terms of infrastructure cost and personnel overhead.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据控制主要将由数据所有者处理，但 AI 产品/解决方案领导者需要意识到他们从哪里获取数据。如果用于训练模型的发现数据未授权或来自数据质量可疑的来源，这可能导致大量资源浪费，包括基础设施成本和人力成本。
- en: Now, let’s look at the different tools and features available within Vertex
    AI to help you implement MLOps governance across your ML solutions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 Vertex AI 内部可用的不同工具和功能，这些工具可以帮助您在您的机器学习解决方案中实施 MLOps 治理。
- en: Tools in Vertex AI that can help with governance
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vertex AI 中可以帮助进行治理的工具
- en: Vertex AI offers several tools to help with ML solution governance and monitoring
    that you can utilize to implement and track your organization’s standard governance
    policies and more generic governance best practices. Please keep in mind that
    for many of the governance policies, especially the ones around security and cost
    management, you will need to use tools outside of Vertex AI. For example, to set
    up monthly cost limits and budgets, you will need to use GCP’s native billing
    tools.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 提供了几个工具来帮助进行机器学习解决方案的治理和监控，您可以使用这些工具来实施和跟踪您组织的标准治理政策和更通用的治理最佳实践。请记住，对于许多治理政策，特别是关于安全和成本管理的政策，您将需要使用
    Vertex AI 之外的工具。例如，为了设置每月的成本限制和预算，您将需要使用 GCP 的原生计费工具。
- en: 'Let’s walk through the details of the different tools within Vertex AI that
    can be used as part of MLOps governance processes:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解 Vertex AI 内部可用于作为 MLOps 治理流程一部分的不同工具：
- en: Model Registry
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型注册表
- en: 'Vertex AI Model Registry provides a centralized, organized, and secure location
    for managing all ML models within an organization. This facilitates seamless and
    efficient ML operations, from development and validation to deployment and monitoring:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 模型注册表提供了一个集中、组织和安全的位置，用于管理组织内部的所有机器学习模型。这促进了从开发、验证到部署和监控的流畅和高效的机器学习操作：
- en: '![Figure 11.1 – Vertex AI Model Registry](img/B17792_11_1.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – Vertex AI 模型注册表](img/B17792_11_1.jpg)'
- en: Figure 11.1 – Vertex AI Model Registry
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – Vertex AI 模型注册表
- en: Acting as a central hub for managing your ML models’ life cycles, Vertex AI
    Model Registry offers a bird’s-eye view of your models, thus enabling a more organized
    and efficient method of tracking and training new model versions. It serves as
    an access point from where you can deploy your preferred model version to an endpoint,
    either directly or by employing aliases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为管理您的机器学习模型生命周期的中心枢纽，Vertex AI 模型注册表提供了对您模型的鸟瞰图，从而使得跟踪和训练新模型版本的方法更加有序和高效。它作为部署您首选模型版本到端点的接入点，无论是直接部署还是通过使用别名。
- en: Vertex AI Model Registry extends its support to custom models across all AutoML
    data types – be it text, tabular data, images, or videos. Moreover, it can incorporate
    BigQuery ML models, which means that if you have models that have undergone training
    via BigQuery ML, you can easily register them within Vertex AI Model Registry.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 模型注册表扩展了对所有 AutoML 数据类型的自定义模型的支持——无论是文本、表格数据、图像还是视频。此外，它还可以集成 BigQuery
    ML 模型，这意味着如果您有通过 BigQuery ML 训练的模型，您可以轻松地在 Vertex AI 模型注册表中注册它们。
- en: 'Navigating to the model version details page, you’re provided with numerous
    options: you can evaluate a model, deploy it to an endpoint, set up batch prediction,
    and inspect specific details related to the model. With its user-friendly and
    streamlined interface, Vertex AI Model Registry simplifies how you can manage
    and deploy your optimal models to a production environment.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到模型版本详情页面，您将获得许多选项：您可以评估模型、将其部署到端点、设置批量预测，并检查与模型相关的特定细节。凭借其用户友好的简化界面，Vertex
    AI 模型注册表简化了您管理和部署最佳模型到生产环境的方式。
- en: 'Let’s explore how Vertex AI Model Registry contributes to ML governance:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨 Vertex AI 模型注册表如何促进机器学习治理：
- en: '**Centralized repository for models**: Model Registry provides a single location
    where all models in the organization are stored. This centralized repository makes
    it easy for data scientists, ML engineers, and DevOps teams to store, access,
    and manage models. It also fosters cross-functional visibility and collaboration,
    which are essential elements in maintaining a robust governance framework.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型集中存储库**：模型注册表提供了一个单一的位置，用于存储组织中的所有模型。这个集中存储库使得数据科学家、机器学习工程师和 DevOps 团队能够轻松地存储、访问和管理模型。它还促进了跨职能的可见性和协作，这是维护强大治理框架的必要元素。'
- en: '**Version control and model lineage**: Every time a new model is trained or
    an existing model is updated, a new version is created in Model Registry. It maintains
    a history of all versions of a model, enabling easy tracking and comparison of
    different versions and ensuring that any updates or modifications are adequately
    logged and accounted for:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制和模型血缘**：每次训练新模型或更新现有模型时，模型注册表中都会创建一个新的版本。它维护了模型所有版本的记录，使得跟踪和比较不同版本变得容易，并确保任何更新或修改都得到适当的记录和考虑：'
- en: '![Figure 11.2 – Vertex AI Model Registry (version view)](img/B17792_11_2.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – Vertex AI 模型注册表（版本视图）](img/B17792_11_2.jpg)'
- en: Figure 11.2 – Vertex AI Model Registry (version view)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – Vertex AI 模型注册表（版本视图）
- en: '**Model metadata management**: In combination with the Metadata Store, it can
    help record the model’s lineage, providing information about the datasets, model
    parameters, and training pipelines that are used to build each version of the
    model. This lineage information is invaluable for auditing and compliance purposes,
    a critical aspect of ML governance.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型元数据管理**：结合元数据存储，它可以帮助记录模型的血缘关系，提供有关用于构建模型每个版本的训练数据集、模型参数和训练管道的信息。这种血缘信息对于审计和合规目的至关重要，是机器学习治理的关键方面。'
- en: '**Model validation and testing**: Before a model is deployed into production,
    it needs to be validated and tested to ensure it meets the requisite performance
    metrics. Model Registry supports this by integrating with Vertex AI’s model evaluation
    tools. These tools can compare different model versions and validate them against
    predefined metrics, ensuring that only accurate and reliable models are deployed.
    You can view detailed information about your models, including performance metrics,
    directly from the model details page:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证和测试**：在将模型部署到生产环境之前，需要对其进行验证和测试，以确保其满足所需的性能指标。模型注册表通过集成 Vertex AI 的模型评估工具来支持这一点。这些工具可以比较不同的模型版本，并验证它们是否符合预定义的指标，确保只有准确且可靠的模型被部署。您可以直接从模型详情页面查看有关您模型的详细信息，包括性能指标：'
- en: '![Figure 11.3 – Vertex AI model evaluation](img/B17792_11_3.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – Vertex AI 模型评估](img/B17792_11_3.jpg)'
- en: Figure 11.3 – Vertex AI model evaluation
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – Vertex AI 模型评估
- en: '**Integration with other Vertex AI services**: Model Registry integrates seamlessly
    with other Vertex AI services, including training pipelines and prediction services.
    Vertex AI Model Registry allows you to easily deploy your models to an endpoint
    with a few clicks or a few lines of code for real-time predictions. Integration
    with BigQuery allows you to register BQML models into Vertex AI Model Registry
    so that you can track all your models in one place. This integration facilitates
    end-to-end MLOps governance, allowing for efficient, consistent, and controlled
    ML operations.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与其他 Vertex AI 服务的集成**：模型注册表无缝集成到其他 Vertex AI 服务中，包括训练管道和预测服务。Vertex AI 模型注册表允许您通过几点击或几行代码轻松地将模型部署到端点进行实时预测。与
    BigQuery 的集成允许您将 BQML 模型注册到 Vertex AI 模型注册表中，以便您可以在一个地方跟踪所有模型。这种集成促进了端到端的 MLOps
    治理，允许高效、一致和受控的机器学习操作。'
- en: Next, let's look at the Metadata Store.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看元数据存储。
- en: Metadata Store
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元数据存储
- en: 'Vertex AI Metadata Store provides a robust, scalable system for tracking and
    managing all metadata associated with your ML workflows. Metadata, in this context,
    refers to information about the data used, the details of model training runs,
    the parameters used in these runs, the metrics generated, the artifacts created,
    and much more:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 元数据存储提供了一个强大、可扩展的系统，用于跟踪和管理与您的机器学习工作流程相关的所有元数据。在此背景下，元数据指的是关于使用的数据、模型训练运行细节、这些运行中使用的参数、生成的指标、创建的工件等信息：
- en: '![Figure 11.4 – Vertex AI Metadata Store model lineage](img/B17792_11_4.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – Vertex AI 元数据存储模型血缘](img/B17792_11_4.jpg)'
- en: Figure 11.4 – Vertex AI Metadata Store model lineage
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – Vertex AI 元数据存储模型血缘
- en: 'By systematically collecting and organizing this metadata, Vertex AI Metadata
    Store enables comprehensive tracking of the entire ML life cycle, facilitating
    effective ML governance. Here’s how:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过系统地收集和组织这些元数据，Vertex AI 元数据存储能够全面跟踪整个机器学习生命周期，从而促进有效的机器学习治理。以下是具体方法：
- en: '**Traceability**: One of the key features of Vertex AI Metadata Store is its
    ability to provide end-to-end traceability for tracked ML workflows. For every
    model built, it can trace back the lineage of the data and the steps taken during
    preprocessing, feature engineering, model training, validation, and deployment.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可追溯性**：Vertex AI 元数据存储的一个关键特性是能够为跟踪的机器学习工作流程提供端到端的可追溯性。对于每个构建的模型，它可以追溯数据来源和预处理、特征工程、模型训练、验证和部署过程中所采取的步骤。'
- en: '**Model experimentation and comparison**: Vertex AI Metadata Store allows you
    to track and compare different model versions, parameters, and metrics. This aids
    in governance by ensuring that the development and selection of models are systematic
    and transparent, making it easier to replicate and audit your processes.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型实验和比较**：Vertex AI 元数据存储允许您跟踪和比较不同的模型版本、参数和指标。这有助于治理，确保模型开发和选择是系统化和透明的，从而更容易复制和审计您的流程。'
- en: '**Consistency and standardization**: By using Vertex AI Metadata Store, organizations
    can standardize metadata across different ML workflows. This promotes consistency
    in how ML workflows are executed and tracked, making it easier to apply governance
    policies and procedures.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和标准化**：通过使用 Vertex AI 元数据存储，组织可以在不同的机器学习工作流程中标准化元数据。这促进了机器学习工作流程执行和跟踪的一致性，使得应用治理政策和程序更加容易。'
- en: '**Compliance and regulatory adherence**: In industries such as healthcare or
    finance, ML models must comply with strict regulatory requirements. Vertex AI
    Metadata Store aids in this compliance by providing a detailed lineage of the
    ML model that can link the final trained model to the source of data and showcase
    that model development best practices were followed and proper evaluation criteria
    were satisfied before the model was deployed in production.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性和监管遵从性**：在医疗保健或金融等行业，机器学习模型必须遵守严格的监管要求。Vertex AI 元数据存储通过提供详细的模型血缘来帮助实现合规性，该血缘可以将最终训练好的模型与数据源联系起来，并展示在模型部署到生产之前遵循了最佳实践和满足了适当的评估标准。'
- en: '**Reproducibility**: Vertex AI Metadata Store also plays a significant role
    in ensuring the reproducibility of ML experiments, a crucial aspect of ML governance.
    By keeping track of all elements of an experiment, including data, configurations,
    parameters, and results, it ensures that the experiment can be reliably reproduced
    in the future.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重现性**：Vertex AI元数据存储在确保机器学习实验的可重现性方面也发挥着重要作用，这是机器学习治理的一个关键方面。通过跟踪实验的所有元素，包括数据、配置、参数和结果，它确保实验可以在未来可靠地重现。'
- en: '**Collaboration and communication**: Metadata Store can foster better collaboration
    and communication within teams. With the comprehensive tracking of ML workflows,
    team members can understand what others are doing, promoting transparency and
    effective collaboration.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协作和沟通**：元数据存储可以促进团队内部的更好协作和沟通。通过全面跟踪机器学习工作流程，团队成员可以了解其他人正在做什么，促进透明度和有效协作。'
- en: 'Vertex AI Metadata Store serves as a comprehensive repository for the metadata
    associated with your ML operations, presented as a graph:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI元数据存储是您机器学习操作相关元数据的综合存储库，以图形的形式呈现：
- en: '![Figure 11.5 – Vertex AI Metadata Store](img/B17792_11_5.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – Vertex AI元数据存储](img/B17792_11_5.jpg)'
- en: Figure 11.5 – Vertex AI Metadata Store
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – Vertex AI元数据存储
- en: Within this graph-based metadata framework, both artifacts and executions form
    the nodes, while events serve as the connecting edges that designate artifacts
    as the inputs or outputs of specific executions. *Contexts* denote logical subgroups,
    encompassing select sets of artifacts and executions for ease of reference.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基于图形的元数据框架中，艺术品和执行形成节点，而事件作为连接边，指定艺术品为特定执行的输入或输出。*上下文*表示逻辑子组，包含选定的艺术品和执行集合，以便于参考。
- en: Vertex AI Metadata Store permits the application of metadata as key-value pairs
    to the artifacts, executions, and contexts. For instance, a trained model could
    carry metadata that provides details about the training framework used, performance
    indicators such as accuracy, precision, and recall, and so forth.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI元数据存储允许将元数据作为键值对应用于艺术品、执行和上下文中。例如，一个训练好的模型可以携带元数据，提供有关所使用的训练框架的详细信息，性能指标，如准确率、精确率和召回率等。
- en: To fully grasp shifts in the performance of your ML system, a thorough analysis
    of metadata produced by your ML workflows and the genealogy of its artifacts is
    mandatory. The lineage of an artifact encases all elements contributing to its
    origination, along with subsequent artifacts and metadata originating from this
    root artifact.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要全面掌握您的机器学习系统性能的变化，对由您的机器学习工作流程产生的元数据和其艺术品的家谱进行彻底分析是强制性的。一个艺术品的家谱包含了所有对其起源有贡献的元素，以及从这个根艺术品起源的后续艺术品和元数据。
- en: 'Take, for example, the lineage of a model, which could comprise the following
    elements:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个模型的谱系为例，它可能包括以下元素：
- en: The datasets that were utilized for model training, testing, and evaluation
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于模型训练、测试和评估的数据集
- en: The hyperparameters that were employed during the training process of the model
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练过程中使用的超参数
- en: The specific code base, which is instrumental in training the model
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练模型中起关键作用的特定代码库
- en: The metadata that was accrued from the training and evaluation stages, such
    as the accuracy of the model
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从训练和评估阶段积累的元数据，例如模型的准确率
- en: The artifacts that were derived from this parent model, such as batch prediction
    results
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从这个父模型派生出的艺术品，例如批量预测结果
- en: The Vertex ML Meta data system arranges resources in a hierarchical structure,
    necessitating that all resources belong to a Metadata Store. Therefore, establishing
    a MetadataStore is a prerequisite for creating Metadata resources.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex ML元数据系统以分层结构组织资源，需要所有资源都属于元数据存储。因此，建立元数据存储是创建元数据资源的先决条件。
- en: 'Let’s delve into the key concepts and terminology that’s used in Vertex ML
    Metadata, which forms the basis for organizing resources and components:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解在Vertex ML元数据中使用的核心概念和术语，这构成了组织资源和组件的基础：
- en: '**MetadataStore**: This forms the top-tier container for metadata resources.
    A MetadataStore is region-specific and linked to a unique Google Cloud project.
    Conventionally, organizations employ one shared MetadataStore per project to manage
    metadata resources.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据存储**：这是元数据资源的顶级容器。元数据存储是区域特定的，并与一个唯一的Google Cloud项目相关联。通常，组织在每个项目中使用一个共享的元数据存储来管理元数据资源。'
- en: '**Metadata resources**: Vertex ML Metadata presents a graph-like data model
    to embody metadata originating from and utilized by ML workflows. The chief concepts
    under this model are artifacts, executions, events, and contexts.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据资源**：Vertex ML Metadata 提供了一个类似于图的数据模型来体现来自和由 ML 工作流使用的元数据。该模型下的主要概念包括工件、执行、事件和上下文。'
- en: '**Artifact**: In the context of an ML workflow, an artifact is a distinct entity
    or data fragment generated or consumed. It could be datasets, models, input files,
    training logs, and so on.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工件**：在 ML 工作流中，工件是一个生成的或消耗的独立实体或数据片段。它可以是数据集、模型、输入文件、训练日志等等。'
- en: '**Context**: A context is leveraged to group artifacts and executions under
    one searchable and typed category. It can be used to denote sets of metadata.
    For instance, a run of an ML pipeline could be designated as a context.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：上下文被用来将工件和执行分组到一个可搜索和分类型的类别下。它可以用来表示一组元数据。例如，一个 ML 管道的运行可以被指定为一个上下文。'
- en: 'To illustrate, contexts can encapsulate the following metadata sets:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，上下文可以封装以下元数据集：
- en: A single run of a Vertex AI Pipelines pipeline, where the context represents
    the run and each execution symbolizes a step in the ML pipeline. This demonstrates
    how artifacts, executions, and context meld into Vertex ML Metadata’s graph data
    model.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI Pipelines 管道的一次运行，其中上下文代表运行过程，每个执行符号化 ML 管道中的一个步骤。这展示了如何将工件、执行和上下文融合到
    Vertex ML Metadata 的图数据模型中。
- en: 'An experiment run from a Jupyter Notebook. Here, the context could symbolize
    the notebook, and each execution could denote a cell within that notebook:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Jupyter Notebook 运行的实验。在这里，上下文可以代表笔记本，每个执行可以表示笔记本中的单元格：
- en: '**Event**: An event is the term that’s used to describe the connection between
    artifacts and executions. Each artifact can be generated by an execution and consumed
    by others. Events aid in establishing the lineage of artifacts in ML workflows
    by chaining together artifacts and executions.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**：事件是用来描述工件和执行之间连接的术语。每个工件可以由一个执行生成，并由其他执行消耗。事件通过将工件和执行链接在一起，有助于在 ML 工作流中建立工件的血缘关系。'
- en: '**Execution**: An execution is a log of a single step in the ML workflow, generally
    annotated with its runtime parameters. Examples of executions include model training,
    model evaluation, model deployment, data validation, and data ingestion.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**：执行是 ML 工作流中单个步骤的日志，通常带有其运行时参数。执行的例子包括模型训练、模型评估、模型部署、数据验证和数据摄取。'
- en: '**Metadata Schema**: A MetadataSchema provides a schema for specific types
    of artifacts, executions, or contexts. These schemas are employed to validate
    the key-value pairs at the time of creation of the corresponding Metadata resources.
    The schema validation only scrutinizes matching fields between the resource and
    the MetadataSchema. These types of schemas are depicted using OpenAPI schema objects
    and are generally described using YAML.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据模式**：MetadataSchema 为特定类型的工件、执行或上下文提供了一个模式。这些模式在创建相应的元数据资源时用于验证键值对。模式验证仅检查资源和
    MetadataSchema 之间的匹配字段。这些类型的模式使用 OpenAPI 模式对象表示，通常使用 YAML 进行描述。'
- en: Exercise – using Vertex AI Metadata Store to track ML model development
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 - 使用 Vertex AI 元数据存储跟踪 ML 模型开发
- en: Please refer to the accompanying notebook, *Chp11_Metadata_Store.ipynb*, [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Metadata_Store.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Metadata_Store.ipynb),
    which walks you through the exercise to create a Metadata Store to store artifacts
    from a Vertex AI Pipeline run.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅附带的笔记本，*Chp11_Metadata_Store.ipynb*，[https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Metadata_Store.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Metadata_Store.ipynb)，它将指导你完成创建元数据存储以存储
    Vertex AI Pipeline 运行中工件的操作。
- en: Let's talk about the Feature Store next.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们谈谈特征存储。
- en: Feature Store
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储
- en: Google Cloud’s Vertex AI Feature Store is a managed service that allows data
    scientists and ML engineers to create, manage, and share ML features. The service
    helps accelerate the process of turning raw data into ML models, ensuring the
    models are built with high-quality data that is both reliable and consistent.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 的 Vertex AI 特征存储是一个托管服务，允许数据科学家和 ML 工程师创建、管理和共享 ML 特征。该服务有助于加速将原始数据转换为
    ML 模型的过程，确保模型是用既可靠又一致的高质量数据构建的。
- en: 'While Vertex AI Feature Store primarily streamlines the model development process,
    it also plays a significant role in supporting ML governance. Let’s delve deeper
    into how this service assists with various facets of ML governance:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Vertex AI特征存储主要简化了模型开发过程，但它也在支持机器学习治理方面发挥着重要作用。让我们深入了解该服务如何协助机器学习治理的各个方面：
- en: '**Data management and traceability**: A key aspect of ML governance is ensuring
    that the data that’s used for developing ML models is accurate, relevant, and
    traceable. Vertex AI Feature Store facilitates this by maintaining metadata about
    model lineage. This level of traceability makes it possible to audit the entire
    data pipeline effectively, thus promoting transparency and accountability in ML
    operations.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管理和可追溯性**：机器学习治理的一个关键方面是确保用于开发机器学习模型的数据是准确、相关且可追溯的。Vertex AI特征存储通过维护模型血缘的元数据来促进这一点。这种可追溯性使得有效地审计整个数据管道成为可能，从而在机器学习操作中促进透明度和问责制。'
- en: '**Data consistency**: Consistency in the data used for training and serving
    models is essential for ML governance. Discrepancies can lead to skewed results,
    negatively impacting the model’s performance and reliability. Vertex AI Feature
    Store provides unified storage for both training and online serving, ensuring
    that the same data features are used across these stages.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据一致性**：在训练和部署模型使用的数据一致性对于机器学习治理至关重要。不一致性可能导致结果偏差，对模型的性能和可靠性产生负面影响。Vertex
    AI特征存储为训练和在线部署提供统一的存储，确保在这些阶段使用相同的数据特征。'
- en: '**Data quality monitoring**: Maintaining the quality of data is another important
    aspect of ML governance. Poor data quality can lead to biased or inaccurate model
    predictions. Vertex AI Feature Store helps manage this by providing functionalities
    to monitor and validate the data ingested into the feature store. It can help
    identify anomalies or changes in data distribution over time, allowing timely
    intervention and rectification.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量监控**：维护数据质量是机器学习治理的另一个重要方面。差劣的数据质量可能导致有偏或错误的模型预测。Vertex AI特征存储通过提供监控和验证输入到特征存储中的数据的功能来帮助管理这一点。它可以帮助识别数据分布随时间的变化或异常，从而允许及时干预和纠正。'
- en: '**Data versioning and reproducibility**: In the context of ML governance, managing
    different versions of features is essential to track changes over time and enable
    reusability. Vertex AI Feature Store automatically tracks data updates and supports
    point-in-time lookup, which helps with consistency in training experiments and
    model reproducibility.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据版本控制和可重复性**：在机器学习治理的背景下，管理特征的多个版本对于跟踪时间变化和实现可重用性至关重要。Vertex AI特征存储自动跟踪数据更新并支持时间点查找，这有助于训练实验的一致性和模型的可重复性。'
- en: '**Privacy and security**: ML governance also involves ensuring that data privacy
    and security regulations are adhered to. Vertex AI Feature Store is built on Google
    Cloud’s robust security model, ensuring that sensitive data is encrypted both
    at rest and in transit. With Google Cloud’s **Identity and Access Management**
    (**IAM**), organizations can also enforce fine-grained access controls to the
    feature store, ensuring that only authorized individuals have access to sensitive
    data features.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私和安全**：机器学习治理还涉及确保遵守数据隐私和安全法规。Vertex AI特征存储建立在Google Cloud强大的安全模型之上，确保敏感数据在静态和传输过程中都得到加密。借助Google
    Cloud的**身份和访问管理**（**IAM**），组织还可以对特征存储实施细粒度的访问控制，确保只有授权人员才能访问敏感数据特征。'
- en: 'The following are best practices when using Feature Store:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用特征存储时的最佳实践如下：
- en: '**Modeling features for multiple entities**: There can be scenarios where some
    features apply to more than one type of entity. Consider, for instance, a computed
    value that tracks the clicks on a product by a user. Such a feature jointly characterizes
    the product-user duo. In these cases, it’s advisable to form a new entity type
    such as **product-user** to group the shared features. Entity IDs can be formed
    by combining the IDs of the individual entities involved, given that the IDs are
    strings. These collectively formed entity types are known as composite entity
    types.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为多个实体建模特征**：存在一些特征适用于多种类型实体的场景。例如，考虑一个跟踪用户对产品点击的计数值。这样的特征共同描述了产品-用户对。在这些情况下，建议创建一个新的实体类型，如**产品-用户**，以分组共享的特征。如果ID是字符串，可以通过组合涉及实体的ID来形成实体ID。这些共同形成的实体类型被称为复合实体类型。'
- en: '**Regulating access with IAM policies**: IAM roles and policies provide a powerful
    way to govern access across multiple teams with diverse needs. For example, you
    might have ML researchers, data scientists, DevOps, and site reliability engineers
    who all need to access the same feature store, but the extent of their access
    can vary. Resource-level IAM policies can be employed to control access to a specific
    feature store or entity type. This allows for each role or persona within your
    organization to have a predefined IAM role tailored to the specific level of access
    required.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用IAM策略管理访问权限**：IAM角色和策略为满足不同需求的多个团队提供了强大的管理访问权限的方式。例如，您可能拥有机器学习研究人员、数据科学家、DevOps和站点可靠性工程师，他们都需要访问相同的特征存储，但他们的访问范围可能不同。资源级IAM策略可以用于控制对特定特征存储或实体类型的访问。这允许您的组织中的每个角色或角色都有预定义的IAM角色，以适应所需的特定访问级别。'
- en: '**Optimizing batch ingestion with resource monitoring and tuning**: Batch ingestion
    jobs can intensify the CPU utilization of your feature store, thereby affecting
    online serving performance. To strike a balance, consider starting with one worker
    for every 10 online serving nodes and then monitoring the CPU usage during ingestion.
    The number of workers can be adjusted for future batch ingestion jobs based on
    your monitoring results to optimize throughput and CPU usage.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过资源监控和调整优化批量导入**：批量导入作业可能会增加特征存储的CPU利用率，从而影响在线服务性能。为了达到平衡，可以考虑为每个在线服务节点启动一个工作进程，然后监控导入期间的CPU使用情况。可以根据监控结果调整工作进程的数量，以优化吞吐量和CPU使用率。'
- en: '**Managing historical data with the disableOnlineServing field**: During the
    process of backfilling – that is, ingesting historical feature values – you can
    disable online serving, which effectively bypasses any modifications to the online
    store.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用disableOnlineServing字段管理历史数据**：在回填过程中（即，导入历史特征值）期间，您可以禁用在线服务，这实际上绕过了对在线存储的任何修改。'
- en: '**Adopting autoscaling for cost optimization**: For users facing frequent fluctuations
    in load, autoscaling can help in cost optimization. This enables Vertex AI Feature
    Store to auto-adjust the number of nodes according to CPU utilization. However,
    it’s worth noting that autoscaling might not be the best solution for managing
    sudden surges in traffic.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采用自动扩展以优化成本**：对于面临负载频繁波动的用户，自动扩展可以帮助优化成本。这使Vertex AI特征存储能够根据CPU利用率自动调整节点数量。然而，值得注意的是，自动扩展可能不是管理流量突然激增的最佳解决方案。'
- en: '**Testing online serving nodes for real-time serving performance**: It’s essential
    to test the performance of your online serving nodes to ensure the real-time performance
    of your feature store. This can be accomplished by benchmarking parameters such
    as QPS, latency, and API. Remember to run these tests from the same region, use
    the gRPC API in the SDK for better performance, and conduct long-duration tests
    for more accurate metrics.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试在线服务节点以评估实时服务性能**：测试在线服务节点的性能对于确保特征存储的实时性能至关重要。这可以通过基准测试QPS、延迟和API等参数来实现。请记住，从同一区域运行这些测试，使用SDK中的gRPC
    API以获得更好的性能，并执行长时间测试以获得更准确的指标。'
- en: '`batchReadFeatureValues` or `exportFeatureValues` request. This ensures the
    request runs a query over a subset of available feature data, which can result
    in significant savings on offline storage usage costs.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batchReadFeatureValues`或`exportFeatureValues`请求。这确保请求在可用特征数据的一个子集上运行查询，这可以在离线存储使用成本上带来显著节省。'
- en: Exercise – using Vertex AI Feature Store to catalog and monitor features
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 - 使用Vertex AI特征存储对特征进行编目和监控
- en: Please refer to the accompanying notebook, *Chp11_feature_store.ipynb*, [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_feature_store.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_feature_store.ipynb),
    which walks you through the exercise of enabling model monitoring in Vertex AI
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅随附的笔记本，*Chp11_feature_store.ipynb*，[https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_feature_store.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_feature_store.ipynb)，它将指导您完成在Vertex
    AI中启用模型监控的练习
- en: We'll discuss Kubeflow Pipelines in the next section.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节讨论Kubeflow管道。
- en: Vertex AI pipelines
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Vertex AI管道
- en: This topic is covered in detail in [*Chapter 10*](B17792_10.xhtml#_idTextAnchor136),
    *Vertex AI Deployment and* *Automation Tools*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此主题在[*第10章*](B17792_10.xhtml#_idTextAnchor136)中详细讨论，*Vertex AI部署和自动化工具*。
- en: 'Vertex AI Pipelines is designed to help manage and orchestrate ML workflows,
    and it plays a significant role in ML governance. By providing a platform for
    building, deploying, and managing ML workflows, this tool enables organizations
    to implement effective governance processes for their ML operations:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI Pipelines旨在帮助管理和编排ML工作流，它在ML治理中发挥着重要作用。通过提供一个构建、部署和管理ML工作流的平台，这个工具使组织能够为其ML操作实施有效的治理流程：
- en: '**Defining and reusing ML pipelines**: Vertex AI Pipelines and Kubeflow Pipelines
    support defining pipelines as a series of componentized steps. These steps can
    encapsulate data preprocessing, model training, evaluation, deployment, and more.
    By defining these steps, you can enforce best practices, ensure that every step
    of the pipeline is traceable, and guarantee that all models are developed consistently.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义和复用ML管道**：Vertex AI Pipelines和Kubeflow Pipelines支持将管道定义为一系列组件化步骤。这些步骤可以封装数据预处理、模型训练、评估、部署等。通过定义这些步骤，您可以强制执行最佳实践，确保管道的每一步都是可追踪的，并保证所有模型都是一致开发的。'
- en: The reuse of pipelines and components across multiple workflows is another significant
    advantage. This allows for standardization across different ML projects, which
    is a crucial aspect of ML governance. Standardization not only promotes code and
    process reuse but also reduces the risk of errors and ensures consistency in how
    ML models are built and deployed.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多个工作流中复用管道和组件是另一个显著优势。这有助于在不同机器学习（ML）项目中实现标准化，这是ML治理的关键方面。标准化不仅促进了代码和流程的复用，还降低了错误的风险，并确保了ML模型构建和部署的一致性。
- en: '**Versioning and experiment tracking**: Both Vertex AI Pipelines and Kubeflow
    Pipelines offer capabilities for versioning and experiment tracking. With ML model
    versioning, different versions of models can be managed, and older versions can
    be rolled back when necessary.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制和实验跟踪**：Vertex AI Pipelines和Kubeflow Pipelines都提供了版本控制和实验跟踪的功能。通过ML模型版本控制，可以管理不同版本的模型，并在必要时回滚旧版本。'
- en: Experiment tracking is also critical for governance. It provides visibility
    into how different model parameters and datasets impact the performance of a model.
    The ability to record and compare experiments also facilitates auditability, allowing
    you to understand the decision-making process behind each model.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验跟踪对于治理也至关重要。它提供了不同模型参数和数据集如何影响模型性能的可见性。记录和比较实验的能力也促进了可审计性，使您能够了解每个模型背后的决策过程。
- en: '**Automated and reproducible pipelines**: Automating ML workflows ensures that
    all steps are executed consistently and reliably, which is an essential aspect
    of ML governance. Both Vertex AI Pipelines and Kubeflow Pipelines allow for the
    creation of automated pipelines, which means each step in the ML process is reproducible.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化和可重复的管道**：自动化ML工作流确保所有步骤都一致且可靠地执行，这是ML治理的一个基本方面。Vertex AI Pipelines和Kubeflow
    Pipelines都允许创建自动化管道，这意味着ML过程中的每一步都是可重复的。'
- en: Reproducibility is an often-understated aspect of ML governance. Reproducible
    pipelines mean you can track the data, code, configurations, and results at every
    step of the pipeline, which is crucial for debugging and auditing purposes. This
    is particularly important when your models need to comply with certain regulations
    that require transparent and explainable model development processes.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可重复性是ML治理中经常被低估的方面。可重复的管道意味着您可以在管道的每一步跟踪数据、代码、配置和结果，这对于调试和审计至关重要。当您的模型需要遵守某些法规时，这些法规要求透明的可解释模型开发过程，这一点尤为重要。
- en: '**Integration with other Google Cloud services**: Vertex AI Pipelines and Kubeflow
    Pipelines are designed to work seamlessly with other Google Cloud services, such
    as BigQuery for data management, Cloud Storage for storing models and data, and
    AI Platform for model deployment. This integration makes it easier to implement
    governance processes across your entire ML workflow. For example, you can ensure
    data privacy and security by using BigQuery’s data governance features, or you
    can manage access control and monitor model performance using the capabilities
    of AI Platform. Vertex AI Pipelines and Kubeflow Pipelines offer various features
    that support ML governance, including pipeline definition and reuse, versioning,
    experiment tracking, automation, reproducibility, and integration with other Google
    Cloud services. By leveraging these features, organizations can effectively manage
    their ML operations, ensure compliance with best practices and regulations, and
    create a transparent, accountable, and efficient ML workflow.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与其他 Google Cloud 服务的集成**：Vertex AI Pipelines 和 Kubeflow Pipelines 被设计成与其他
    Google Cloud 服务无缝协作，例如 BigQuery 用于数据管理，Cloud Storage 用于存储模型和数据，以及 AI Platform
    用于模型部署。这种集成使得在整个机器学习工作流程中实施管理流程变得更加容易。例如，您可以通过使用 BigQuery 的数据管理功能来确保数据隐私和安全，或者使用
    AI Platform 的功能来管理访问控制和监控模型性能。Vertex AI Pipelines 和 Kubeflow Pipelines 提供了各种支持机器学习管理的功能，包括管道定义和重用、版本控制、实验跟踪、自动化、可重复性和与其他
    Google Cloud 服务的集成。通过利用这些功能，组织可以有效地管理他们的机器学习操作，确保遵守最佳实践和法规，并创建一个透明、负责且高效的机器学习工作流程。'
- en: Now, let's talk about Monitoring in detail!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细谈谈监控！
- en: Model Monitoring
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型监控
- en: 'Vertex AI Monitoring plays a critical role in the MLOps governance process
    by offering tools for the real-time monitoring and management of ML models. It
    enables organizations to establish transparency, accountability, and reliability
    in their ML processes. Here’s an overview of how Vertex AI Monitoring helps with
    ML governance:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 监控在 MLOps 管理流程中发挥着关键作用，它提供了实时监控和管理机器学习模型的工具。它使组织能够在他们的机器学习过程中建立透明度、责任感和可靠性。以下是
    Vertex AI 监控如何帮助机器学习管理的概述：
- en: '**Model monitoring**: Vertex AI Monitoring offers automated monitoring of models
    deployed in production. This means the system tracks the model’s performance continuously,
    identifying any potential drift in the data and degradation in the model’s performance.
    If the model’s performance dips below a predefined threshold, it alerts the appropriate
    stakeholders. This continuous monitoring is vital for maintaining the model’s
    accuracy and relevance, which are fundamental aspects of MLOps governance.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：Vertex AI 监控提供了对在生产中部署的模型的自动化监控。这意味着系统会持续跟踪模型的表现，识别数据中的任何潜在漂移以及模型性能的下降。如果模型的表现低于预定义的阈值，它会向适当的利益相关者发出警报。这种持续的监控对于保持模型的准确性和相关性至关重要，这是
    MLOps 管理的基本方面。'
- en: '**Data skew and drift detection**: One of the main features of Vertex AI Monitoring
    is its ability to detect data skew and drift. Data skew is the difference between
    the data used for training a model and the data used for serving predictions.
    Drift, on the other hand, is the change in data over time. Both can lead to a
    decline in the model’s performance. Vertex AI Monitoring automatically detects
    these discrepancies and provides timely alerts, allowing for rapid remediation.
    Ensuring the consistency and reliability of data aligns with the principle of
    data governance, a critical component of MLOps governance.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据偏差和漂移检测**：Vertex AI 监控的主要功能之一是其检测数据偏差和漂移的能力。数据偏差是用于训练模型的训练数据与用于提供预测的服务数据之间的差异。另一方面，漂移是数据随时间的变化。两者都可能导致模型性能下降。Vertex
    AI 监控自动检测这些差异并提供及时的警报，允许快速修复。确保数据的一致性和可靠性符合数据管理的原则，这是 MLOps 管理的关键组成部分。'
- en: '**Automated alerts**: Automated alerts from Vertex AI Monitoring provide an
    early warning system for any potential issues with the models in production. Timely
    alerts ensure that any problems are identified and remediated promptly, preventing
    any long-term impact on the model’s performance or the business operations. This
    feature is vital for risk management, a crucial aspect of MLOps governance.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动警报**：Vertex AI 监控的自动警报为生产中模型的任何潜在问题提供了一个早期预警系统。及时的警报确保任何问题都能被迅速识别和解决，防止对模型的表现或业务运营产生长期影响。这一功能对于风险管理至关重要，是
    MLOps 管理的关键方面。'
- en: '**Integration with other Google Cloud tools**: Vertex AI Monitoring seamlessly
    integrates with other Google Cloud tools such as Cloud Logging and Cloud Monitoring.
    This allows you to create comprehensive dashboards for visualizing your ML model’s
    health and performance, and to receive alerts for any detected issues. These features
    enable more robust monitoring and troubleshooting capabilities, improving the
    overall governance of ML models.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与其他Google Cloud工具的集成**：Vertex AI Monitoring可以无缝集成到其他Google Cloud工具中，例如Cloud
    Logging和Cloud Monitoring。这使得您能够创建综合仪表板来可视化您的ML模型的健康状况和性能，并接收任何检测到的问题的警报。这些功能使监控和故障排除能力更加强大，从而提高了ML模型的总体治理水平。'
- en: Now, let’s look at the details of how a monitoring solution calculates training-serving
    skew and prediction drift.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看监控解决方案如何计算训练-服务偏斜和预测漂移的细节。
- en: 'Vertex AI Monitoring uses **TensorFlow Data Validation** (**TFDV**) to detect
    training-serving skew and prediction drift by calculating distributions and distance
    scores. The process involves two steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI Monitoring通过计算分布和距离得分来使用**TensorFlow Data Validation**（**TFDV**）检测训练-服务偏斜和预测漂移。这个过程涉及两个步骤：
- en: Calculating the baseline statistical distribution
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算基线统计分布
- en: 'In the context of Vertex AI Monitoring, skew detection and drift detection
    hinge critically on the accurate definition of a baseline statistical distribution.
    The distinction between the baselines for these two facets lies in the data used
    to compute them:'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在Vertex AI Monitoring的上下文中，偏斜检测和漂移检测的关键在于准确定义基线统计分布。这两个方面的基线之间的区别在于用于计算它们的数据：
- en: '**Skew detection**: The baseline is derived from the statistical distribution
    of the feature values present in the training data'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏斜检测**：基线是从训练数据中存在的特征值统计分布推导出来的'
- en: '**Drift detection**: Conversely, for drift detection, the baseline is formulated
    from the statistical distribution of the observed feature values from the recent
    production data'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**漂移检测**：相反，对于漂移检测，基线是从最近的生产数据中观察到的特征值的统计分布中制定的'
- en: 'The process of calculating these distributions unfolds as follows:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算这些分布的过程如下：
- en: '**Categorical features**: The distribution for categorical features is determined
    by computing the quantity or proportion of occurrences for each potential value
    of the feature.'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类特征**：分类特征的分布是通过计算特征每个潜在值的数量或比例来确定的。'
- en: '**Numerical features**: When dealing with numerical features, Vertex AI Monitoring
    segregates the entire range of possible feature values into uniform intervals.
    Subsequently, the number or percentage of feature values residing within each
    interval is computed.'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值特征**：在处理数值特征时，Vertex AI Monitoring将整个可能的特征值范围划分为均匀的区间。随后，计算每个区间内特征值的数量或百分比。'
- en: It is important to note that the baseline is initially set at the time of creating
    a model monitoring job and is subject to recalculation only if there are updates
    to the training dataset allocated for the job.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要的是要注意，基线最初是在创建模型监控作业时设置的，并且只有在分配给作业的训练数据集有更新时才会重新计算。
- en: Calculating the statistical distribution of recent feature values seen in production
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算生产中看到的最近特征值的统计分布
- en: 'The process initiates by contrasting the distribution of the most recent feature
    values, observed in a production environment, with a baseline distribution, through
    the computation of a distance score. Different methods are utilized for different
    types of features:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该过程通过计算距离得分，将最近在生产环境中观察到的特征值分布与基线分布进行对比来启动。对于不同类型的特征，使用不同的方法：
- en: '**Categorical features**: The L-infinity distance method is employed to compute
    the distance score'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类特征**：使用L-infinity距离法来计算距离得分'
- en: '**Numerical features**: The Jensen-Shannon divergence method is used to calculate
    the distance score'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值特征**：使用Jensen-Shannon散度法来计算距离得分'
- en: When the computed distance score exceeds a predefined threshold, indicating
    a significant disparity between the two statistical distributions, Vertex AI Monitoring
    identifies and flags the inconsistency, labeling it as skew or drift.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当计算出的距离得分超过预定义的阈值时，表明两个统计分布之间存在显著差异，Vertex AI Monitoring会识别并标记这种不一致性，将其标记为偏斜或漂移。
- en: 'The following are best practices for utilizing Vertex AI Monitoring:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在使用Vertex AI Monitoring时的最佳实践：
- en: '**Prediction request sampling rate**: To enhance cost efficiency, a prediction
    request sampling rate can be configured. This feature enables monitoring a portion
    of the production inputs to a model instead of the entire dataset.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测请求采样率**：为了提高成本效率，可以配置预测请求采样率。此功能允许监控模型的生产输入的一部分，而不是整个数据集。'
- en: '**Monitoring frequency**: It’s possible to define the frequency at which the
    recently logged inputs of a deployed model are scrutinized for skew or drift.
    This frequency, also known as the monitoring window size, dictates the time frame
    of logged data evaluated in each monitoring run.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控频率**：可以定义最近记录的部署模型输入被审查偏斜或漂移的频率。这个频率，也称为监控窗口大小，决定了每次监控运行中评估的日志数据的时间范围。'
- en: '**Alerting thresholds**: You can set alerting thresholds for each feature that
    is monitored. If the statistical distance between the input feature distribution
    and its respective baseline surpasses this threshold, an alert is generated. By
    default, both categorical and numerical features are monitored, each with a threshold
    value of 0.3.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报阈值**：您可以设置每个被监控特征的警报阈值。如果输入特征分布与其相应的基线之间的统计距离超过此阈值，则生成警报。默认情况下，分类和数值特征都被监控，每个特征都有一个阈值为0.3。'
- en: '**Shared configuration parameters across multiple models**: An online prediction
    endpoint can host more than one model. When skew or drift detection is enabled
    on an endpoint, certain configuration parameters, including detection type, monitoring
    frequency, and the fraction of input requests monitored, are shared across all
    models hosted on that endpoint.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨多个模型的共享配置参数**：在线预测端点可以托管多个模型。当在端点上启用偏斜或漂移检测时，包括检测类型、监控频率和监控的输入请求比例在内的某些配置参数将在该端点上托管的所有模型之间共享。'
- en: '**Model-specific configuration parameters**: Apart from the shared parameters,
    it is also possible to specify different values for other configuration parameters
    for each model. This flexibility allows you to tailor the monitoring settings
    according to the unique needs and behavior of each model.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型特定的配置参数**：除了共享参数外，还可以为每个模型的其它配置参数指定不同的值。这种灵活性允许您根据每个模型的独特需求和行为定制监控设置。'
- en: Exercise – [notebook] using Vertex AI Monitoring features to track the performance
    of deployed models in production environments
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 - 使用Vertex AI监控功能跟踪生产环境中部署的模型性能的[notebook]
- en: Please refer to the accompanying notebook, `Chp11_Model_Monitoring.ipynb`, [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Model_Monitoring.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Model_Monitoring.ipynb),
    which walks you through the exercise of enabling model monitoring in Vertex AI.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考随附的笔记本，`Chp11_Model_Monitoring.ipynb`，[https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Model_Monitoring.ipynb](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/blob/main/Chapter11/Chp11_Model_Monitoring.ipynb)，它将指导您在Vertex
    AI中启用模型监控的练习。
- en: We'll look at billing monitoring in the next section.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中查看账单监控。
- en: Billing monitoring
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 账单监控
- en: '**GCP** offers a suite of robust billing and cost management tools that can
    play a crucial role in MLOps governance. These tools provide fine-grained visibility
    into how resources are being utilized, helping organizations effectively manage
    costs associated with their ML workflows. Here’s how:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**GCP**提供了一套强大的账单和成本管理工具，这些工具在MLOps治理中可以发挥关键作用。这些工具提供了对资源如何被利用的精细可见性，帮助组织有效管理与其ML工作流程相关的成本。以下是方法：'
- en: '**Budgets and alerts**: GCP’s budget and alerts feature allows organizations
    to establish custom budgets for their GCP projects or billing accounts, and configure
    alerts when the actual spending exceeds the defined thresholds. This tool is instrumental
    in tracking and controlling the costs associated with training, deploying, and
    running ML models. When integrated into the MLOps governance framework, it ensures
    that the expenses related to ML workflows do not exceed their allocated budgets,
    preventing cost overruns and promoting financial responsibility.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预算和警报**：GCP的预算和警报功能允许组织为其GCP项目或账单账户建立自定义预算，并在实际支出超过定义的阈值时配置警报。这个工具在跟踪和控制与训练、部署和运行ML模型相关的成本方面起着至关重要的作用。当集成到MLOps治理框架中时，它确保与ML工作流程相关的支出不超过其分配的预算，防止成本超支并促进财务责任。'
- en: '**Detailed billing reports**: GCP’s detailed billing reports offer insights
    into the specific costs associated with each service. For instance, an organization
    can view detailed reports about the expenses incurred for services such as Vertex
    AI, Cloud Storage, BigQuery, and Compute Engine. These reports allow organizations
    to understand which ML workflows or components are more cost-intensive and need
    optimization. This granular visibility is essential for cost governance in MLOps,
    enabling organizations to strategically plan their resource usage and manage costs.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**详细的账单报告**：GCP的详细账单报告提供了关于每个服务具体成本的洞察。例如，一个组织可以查看关于Vertex AI、云存储、BigQuery和Compute
    Engine等服务产生的详细费用报告。这些报告使组织能够了解哪些机器学习工作流或组件成本更高，需要优化。这种细粒度的可见性对于MLOps中的成本管理至关重要，它使组织能够战略性地规划资源使用并管理成本。'
- en: '**Billing export to BigQuery**: GCP allows you to export detailed billing data
    to BigQuery, Google’s highly scalable and cost-effective data warehouse. This
    feature enables organizations to analyze their GCP billing data programmatically
    and build custom dashboards using data visualization tools such as Data Studio.
    With this, MLOps teams can better understand and manage the costs associated with
    various ML projects, and identify opportunities for savings and optimization.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**账单导出到BigQuery**：GCP允许您将详细的账单数据导出到BigQuery，这是Google高度可扩展且成本效益高的数据仓库。此功能使组织能够以编程方式分析其GCP账单数据，并使用数据可视化工具（如Data
    Studio）构建自定义仪表板。通过这种方式，MLOps团队可以更好地理解和管理与各种机器学习项目相关的成本，并识别节省和优化的机会。'
- en: '**Cost management tools**: GCP’s cost management tools, such as the Pricing
    Calculator and the **Total Cost of Ownership** (**TCO**) tool, help organizations
    forecast their cloud expenses and compare them with the costs of running the same
    infrastructure on-premises or on other cloud platforms. These tools are especially
    valuable in the planning and budgeting stages of ML projects, enabling MLOps teams
    to make more informed decisions about resource allocation and cost optimization.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本管理工具**：GCP的成本管理工具，如定价计算器和**总拥有成本**（**TCO**）工具，帮助组织预测其云费用，并将这些费用与在本地或其他云平台上运行相同基础设施的成本进行比较。这些工具有助于在机器学习项目的规划和预算阶段，使MLOps团队能够做出更明智的资源分配和成本优化决策。'
- en: '**Cloud Functions for automating cost controls**: GCP’s serverless execution
    environment, Cloud Functions, can be used to create functions that automatically
    stop or start services based on custom logic. For example, you can write a function
    that automatically stops a Compute Engine instance when it’s not being used, thereby
    saving costs. This level of automated cost control can be invaluable in managing
    the costs associated with running ML models, a crucial aspect of MLOps governance.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用于自动化成本控制的云函数**：GCP的无服务器执行环境Cloud Functions可以用来创建基于自定义逻辑自动停止或启动服务的函数。例如，您可以编写一个函数，当Compute
    Engine实例未被使用时自动停止，从而节省成本。这种级别的自动化成本控制对于管理运行机器学习模型相关的成本非常有价值，这是MLOps治理的一个关键方面。'
- en: Since billing and budget monitoring is a much broader topic than Vertex AI,
    it is outside the scope of this book, but you can refer to the GCP Billing documentation
    ([https://cloud.google.com/billing/docs/how-to](https://cloud.google.com/billing/docs/how-to))
    to dive deeper into the topic.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 由于账单和预算监控是一个比Vertex AI更广泛的话题，它超出了本书的范围，但您可以参考GCP账单文档（[https://cloud.google.com/billing/docs/how-to](https://cloud.google.com/billing/docs/how-to)）以深入了解此主题。
- en: Summary
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went over the fundamentals of MLOps governance, detailing
    its key role in maintaining ML systems’ efficiency, accuracy, and reliability.
    To emphasize the importance of MLOps governance in real-world scenarios, we explored
    case studies from various sectors, showcasing how this governance model can dramatically
    impact the success of AI/ML implementations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了MLOps治理的基础知识，详细说明了它在保持机器学习系统效率、准确性和可靠性中的关键作用。为了强调MLOps治理在现实场景中的重要性，我们探讨了来自各个行业的案例研究，展示了这种治理模式如何显著影响AI/ML实施的成败。
- en: As we dove deeper into the topic, we clarified the core components of MLOps
    governance – data governance and model governance – offering an overview of their
    function and necessity within the ML model life cycle. Additionally, we went through
    some real-world scenarios that effectively underscored the relevance and importance
    of MLOps governance.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们深入探讨这个主题，我们明确了 MLOps 治理的核心组件——数据治理和模型治理，提供了它们在机器学习模型生命周期中的功能和必要性的概述。此外，我们还讨论了一些现实世界的场景，这些场景有效地强调了
    MLOps 治理的相关性和重要性。
- en: On the technical side, we enumerated and discussed several tools available within
    Vertex AI that aid in ML solution governance and monitoring. We touched upon the
    functionalities of Model Registry, Metadata Store, Feature Store, Vertex AI Pipelines,
    Model Monitoring, and GCP’s cost management tools. Through their combined use,
    we illustrated how you can establish robust, transparent, and compliant ML operations.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术方面，我们列举并讨论了 Vertex AI 内部可用的几个有助于机器学习解决方案治理和监控的工具。我们提到了模型注册、元数据存储、特征存储、Vertex
    AI 管道、模型监控和 GCP 的成本管理工具的功能。通过它们的联合使用，我们展示了如何建立强大、透明和合规的机器学习操作。
- en: We supplemented this chapter with examples and exercises on implementing ML
    governance using Vertex AI to cement these concepts. These practical exercises
    offered hands-on experience with Vertex AI’s Model Registry, Metadata Store, and
    Model Monitoring functionalities.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用 Vertex AI 实施机器学习治理的示例和练习来补充本章，以巩固这些概念。这些实践练习提供了对 Vertex AI 的模型注册、元数据存储和模型监控功能的实际操作经验。
- en: In the next section of this book, *Part 3*, *Prebuilt/Turnkey ML Solutions Available
    in GCP*, we will cover different out-of-the-box ML models and solutions such as
    GenAI/LLM models, Document AI, Vision APIs, and NLP APIs, which you can utilize
    to build ML solutions for different use cases.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一部分，*第3部分*，*GCP 中可用的预建/一站式机器学习解决方案*，我们将介绍不同的现成机器学习模型和解决方案，例如 GenAI/LLM
    模型、文档AI、视觉API和NLP API，你可以利用这些工具为不同的用例构建机器学习解决方案。
- en: References
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章所涉及的主题，请查看以下资源：
- en: 'GCP Vertex AI Metadata Store documentation: [https://cloud.google.com/vertex-ai/docs/ml-metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: GCP Vertex AI 元数据存储文档：[https://cloud.google.com/vertex-ai/docs/ml-metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata)
- en: 'GCP Vertex AI billing and budgeting features: [https://cloud.google.com/billing/docs/how-to](https://cloud.google.com/billing/docs/how-to)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: GCP Vertex AI 账单和预算功能：[https://cloud.google.com/billing/docs/how-to](https://cloud.google.com/billing/docs/how-to)
- en: 'Practitioner’s guide to MLOps: [https://cloud.google.com/resources/mlops-whitepaper](https://cloud.google.com/resources/mlops-whitepaper)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 实践指南：[https://cloud.google.com/resources/mlops-whitepaper](https://cloud.google.com/resources/mlops-whitepaper)
- en: 'Part 3: Prebuilt/Turnkey ML Solutions Available in GCP'
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：GCP 中可用的预建/一站式机器学习解决方案
- en: In this part, you will learn about some of the most commonly used prebuilt ML
    solution offerings available in Google Cloud. Many of these solutions are ready
    to use and can be integrated with real-world use cases in no time. Most importantly,
    this part also covers the recently launched generative AI offerings within Vertex
    AI.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分，你将了解 Google Cloud 中一些最常用的预建机器学习解决方案。许多这些解决方案可以立即使用，并且可以迅速与实际应用场景集成。最重要的是，本部分还涵盖了最近在
    Vertex AI 中推出的生成式人工智能解决方案。
- en: 'This part has the following chapters:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 12*](B17792_12.xhtml#_idTextAnchor173), *Vertex AI – Generative AI
    Tools*'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B17792_12.xhtml#_idTextAnchor173)，*Vertex AI – 生成式人工智能工具*'
- en: '[*Chapter 13*](B17792_13.xhtml#_idTextAnchor194), *Document AI – an End-to-End
    Solution for Processing Documents*'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B17792_13.xhtml#_idTextAnchor194)，*文档AI – 处理文档的端到端解决方案*'
- en: '[*Chapter 14*](B17792_14.xhtml#_idTextAnchor203), *ML APIs for Vision, NLP,
    and Speech*'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B17792_14.xhtml#_idTextAnchor203)，*视觉、自然语言处理和语音的机器学习API*'
