["```py\njava –Xmx6g –jar h2o.jar\n\n```", "```py\nSparkSession spark = SparkSession.builder()\n    .master(\"local[8]\")\n    .appName(\"KMeansExpt\")\n    .getOrCreate();\n\n// Load and parse data\nString filePath = \"/home/kchoppella/book/Chapter09/data/covtypeNorm.csv\";\n// Selected K value \nint k =  27;\n\n// Loads data.\nDataset<Row> inDataset = spark.read()\n    .format(\"com.databricks.spark.csv\")\n    .option(\"header\", \"true\")\n    .option(\"inferSchema\", true)\n    .load(filePath);\nArrayList<String> inputColsList = new ArrayList<String>(Arrays.asList(inDataset.columns()));\n\n//Make single features column for feature vectors \ninputColsList.remove(\"class\");\nString[] inputCols = inputColsList.parallelStream().toArray(String[]::new);\n\n//Prepare dataset for training with all features in \"features\" column\nVectorAssembler assembler = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"features\");\nDataset<Row> dataset = assembler.transform(inDataset);\n\nKMeans kmeans = new KMeans().setK(k).setSeed(1L);\nKMeansModel model = kmeans.fit(dataset);\n\n// Evaluate clustering by computing Within Set Sum of Squared Errors.\ndouble SSE = model.computeCost(dataset);\nSystem.out.println(\"Sum of Squared Errors = \" + SSE);\n\nspark.stop();\n```", "```py\nint numDimensions = 16\nPCAModel pca = new PCA()\n    .setK(numDimensions)\n    .setInputCol(\"features\")\n    .setOutputCol(\"pcaFeatures\")\n    .fit(dataset);\n\nDataset<Row> result = pca.transform(dataset).select(\"pcaFeatures\");\nKMeans kmeans = new KMeans().setK(k).setSeed(1L);\nKMeansModel model = kmeans.fit(dataset);\n```", "```py\n// Trains a bisecting k-Means model.\nBisectingKMeans bkm = new BisectingKMeans().setK(k).setSeed(1);\nBisectingKMeansModel model = bkm.fit(dataset);\n```", "```py\nGaussianMixtureModel gmm = new GaussianMixture()\n    .setK(numClusters)\n    .fit(result);\n// Output the parameters of the mixture model\nfor (int k = 0; k < gmm.getK(); k++) {\n  String msg = String.format(\"Gaussian %d:\\nweight=%f\\nmu=%s\\nsigma=\\n%s\\n\\n\",\n              k, gmm.weights()[k], gmm.gaussians()[k].mean(), \n              gmm.gaussians()[k].cov());\n  System.out.printf(msg);\n  writer.write(msg + \"\\n\");\n  writer.flush();\n}\n```", "```py\n// Index labels, adding metadata to the label column.\n// Fit on whole dataset to include all labels in index.\nStringIndexerModel labelIndexer = new StringIndexer()\n  .setInputCol(\"class\")\n  .setOutputCol(\"indexedLabel\")\n  .fit(dataset);\n// Automatically identify categorical features, and index them.\n// Set maxCategories so features with > 2 distinct values are treated as continuous since we have already encoded categoricals with sets of binary variables.\nVectorIndexerModel featureIndexer = new VectorIndexer()\n  .setInputCol(\"features\")\n  .setOutputCol(\"indexedFeatures\")\n  .setMaxCategories(2)\n  .fit(dataset);\n\n// Split the data into training and test sets (30% held out for testing)\nDataset<Row>[] splits = dataset.randomSplit(new double[] {0.7, 0.3});\nDataset<Row> trainingData = splits[0];\nDataset<Row> testData = splits[1];\n\n// Train a RF model.\nRandomForestClassifier rf = new RandomForestClassifier()\n  .setLabelCol(\"indexedLabel\")\n  .setFeaturesCol(\"indexedFeatures\")\n  .setImpurity(\"gini\")\n  .setMaxDepth(5)\n  .setNumTrees(20)\n  .setSeed(1234);\n\n// Convert indexed labels back to original labels.\nIndexToString labelConverter = new IndexToString()\n  .setInputCol(\"prediction\")\n  .setOutputCol(\"predictedLabel\")\n  .setLabels(labelIndexer.labels());\n\n// Chain indexers and RF in a Pipeline.\nPipeline pipeline = new Pipeline()\n  .setStages(new PipelineStage[] {labelIndexer, featureIndexer, rf, labelConverter});\n\n// Train model. This also runs the indexers.\nPipelineModel model = pipeline.fit(trainingData);\n\n// Make predictions.\nDataset<Row> predictions = model.transform(testData);\n\n// Select example rows to display.\npredictions.select(\"predictedLabel\", \"class\", \"features\").show(5);\n\n// Select (prediction, true label) and compute test error.\nMulticlassClassificationEvaluator evaluator = new MulticlassClassificationEvaluator()\n  .setLabelCol(\"indexedLabel\")\n  .setPredictionCol(\"prediction\");\n\nevaluator.setMetricName(\"accuracy\");\ndouble accuracy = evaluator.evaluate(predictions);\nSystem.out.printf(\"Accuracy = %f\\n\", accuracy); \n```", "```py\nbin/samoa local target/SAMOA-Local-0.3.0-SNAPSHOT.jar \"PrequentialEvaluation -l classifiers.ensemble.Bagging \n -s (ArffFileStream -f covtype-train.csv.arff) -f 10000\"\n\n```", "```py\nbin/samoa storm target/SAMOA-Storm-0.3.0-SNAPSHOT.jar \"PrequentialEvaluation -l classifiers.ensemble.Bagging \n -s (ArffFileStream -f covtype-train.csv.arff) -f 10000\"\n\n```"]