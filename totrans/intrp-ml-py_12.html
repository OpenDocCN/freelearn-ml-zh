<html><head></head><body>
  <div id="_idContainer336" class="Basic-Text-Frame">
    <h1 class="chapterNumber">12</h1>
    <h1 id="_idParaDest-335" class="chapterTitle">Monotonic Constraints and Model Tuning for Interpretability</h1>
    <p class="normal">Most model classes have hyperparameters that can be tuned for faster execution speed, increasing predictive performance, and reducing overfitting. One way of reducing overfitting is by introducing regularization into the model training. In <em class="chapterRef">Chapter 3</em>, <em class="italic">Interpretation Challenges</em>, we called regularization a remedial interpretability property, which reduces complexity with a penalty or limitation that forces the model to learn sparser representations of the inputs. Regularized models generalize better, which is why it is highly recommended to tune models with regularization to avoid overfitting to the training data. As a side effect, regularized models tend to have fewer features and interactions, making the model easier to interpret—<em class="italic">less noise means a clearer signal</em>!</p>
    <p class="normal">And even though there are many hyperparameters, we will only focus on those that improve interpretability by controlling overfitting. Also, to a certain extent, we will revisit bias mitigation through the class imbalance-related hyperparameters explored in previous chapters.</p>
    <p class="normal"><em class="chapterRef">Chapter 2</em>, <em class="italic">Key Concepts of Interpretability</em>, explained three model properties that impact interpretability: non-linearity, interactivity, and non-monotonicity. Left to its own devices, a model can learn some spurious and counterintuitive non-linearities and interactivities. As discussed in <em class="chapterRef">Chapter 10</em>, <em class="italic">Feature Selection and Engineering for Interpretability</em>, guardrails can be placed to prevent this through careful feature engineering. However, what can we do to place guardrails for monotonicity? In this chapter, we will learn how to do just this with monotonic constraints. And just as monotonic constraints can be the model counterpart to feature engineering, regularization can be the model counterpart to the feature selection methods we covered in <em class="chapterRef">Chapter 10</em>!</p>
    <p class="normal">These are the main topics we are going to cover in this chapter:</p>
    <ul>
      <li class="bulletList">Placing guardrails with feature engineering</li>
      <li class="bulletList">Tuning models for interpretability</li>
      <li class="bulletList">Implementing model constraints</li>
    </ul>
    <h1 id="_idParaDest-336" class="heading-1">Technical requirements</h1>
    <p class="normal">This chapter’s example uses the <code class="inlineCode">mldatasets</code>, <code class="inlineCode">pandas</code>, <code class="inlineCode">numpy</code>, <code class="inlineCode">sklearn</code>, <code class="inlineCode">xgboost</code>, <code class="inlineCode">lightgbm</code>, <code class="inlineCode">catboost</code>, <code class="inlineCode">tensorflow</code>, <code class="inlineCode">bayes_opt</code>, <code class="inlineCode">tensorflow_lattice</code>, <code class="inlineCode">matplotlib</code>, <code class="inlineCode">seaborn</code>, <code class="inlineCode">scipy</code>, <code class="inlineCode">xai</code>, and <code class="inlineCode">shap</code> libraries. Instructions on how to install these libraries are in the preface.</p>
    <div class="note">
      <p class="normal">The code for this chapter is located here: <a href="https://packt.link/pKeAh"><span class="url">https://packt.link/pKeAh</span></a></p>
    </div>
    <h1 id="_idParaDest-337" class="heading-1">The mission</h1>
    <p class="normal">The issue of algorithmic fairness is one with massive social implications, from the allocation of welfare resources to the prioritization of life-saving surgeries to screening job applications. These machine learning algorithms can determine a person’s livelihood or life, and it’s often the most marginalized and vulnerable populations that get the worst treatment from these algorithms because they perpetuate systemic biases learned from the data. Therefore, it’s poorer families that get misclassified for child abuse; it’s racial-minority people who get underprioritized for medical treatment; and it’s women who get screened out of high-paying tech jobs. Even in cases involving less immediate and individualized risks such as online searches, Twitter/X bots, and social media profiles, societal prejudices such as elitism, racism, sexism, and ageism are reinforced.</p>
    <p class="normal">This chapter will continue on the mission from <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>. If you aren’t familiar with these techniques, please go back and read <em class="chapterRef">Chapter 6</em> to get a solid understanding of the problem. The recidivism case from <em class="chapterRef">Chapter 6</em> is one of <a id="_idIndexMarker1319"/>algorithmic bias. The co-founder of the company that developed the <strong class="keyWord">COMPAS algorithm</strong> (where <strong class="keyWord">COMPAS</strong> stands for <strong class="keyWord">Correctional Offender Management Profiling Alternative Sanctions</strong>) admitted that it’s tough to make a score without questions that are correlated with race. This correlation is one of the main reasons that scores are biased against African Americans. The other reason is the likely overrepresentation of black defendants in the training data. We don’t know for sure because we don’t have the original training data, but we know that non-white minorities are overrepresented in the population of incarcerated individuals. We also know that black people are typically overrepresented in arrests because of codified discrimination in terms of minor drug-related offenses and over-policing in black communities.</p>
    <p class="normal">So, what can we do to fix it?</p>
    <p class="normal">In <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, we managed to demonstrate via a <em class="italic">proxy model</em> that the COMPAS algorithm was biased. For this chapter, let’s say that the journalist published your findings, and an algorithmic justice advocacy group read the article and reached out. Companies that make criminal assessment tools are not taking responsibility for bias and claim that their tools simply reflect <em class="italic">reality</em>. The advocacy group has hired you to demonstrate that a machine learning model can be trained to be significantly less biased toward black defendants while ensuring that the model reflects only proven criminal justice <em class="italic">realities</em>.</p>
    <p class="normal">These proven realities include the monotone decrease of recidivism risk with age, and a strong correlation with priors, which increases strongly with age. Another fact supported by the academic literature is how females are significantly less prone to recidivism and criminality in general.</p>
    <p class="normal">Before we move on, we must recognize that supervised learning models face several impediments in capturing domain knowledge from data. For instance, consider the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Sample</strong>, <strong class="keyWord">exclusion</strong>, <strong class="keyWord">or</strong> <strong class="keyWord">prejudice bias</strong>: What if your data doesn’t truly represent the environment your model intends to generalize? If that’s the case, the domain knowledge won’t align with what you observe in the data. What if the environment that produced the data has a built-in systemic or institutional bias? Then, the data will reflect these biases.</li>
      <li class="bulletList"><strong class="keyWord">Class imbalance</strong>: As seen in <em class="chapterRef">Chapter 11</em>, <em class="italic">Bias Mitigation and Causal Inference Methods</em>, class imbalance could favor some groups over others. While taking the most effective route toward high accuracy, a model will learn from this imbalance, contradicting domain knowledge.</li>
      <li class="bulletList"><strong class="keyWord">Non-monotonicity</strong>: Sparse areas in a features histogram or high-leverage outliers could cause a model to learn non-monotonicity when domain knowledge calls for otherwise, and any of the previously mentioned problems could contribute to this as well.</li>
      <li class="bulletList"><strong class="keyWord">Uninfluential features</strong>: An unregularized model will, by default, try to learn from all features as long as they carry some information, but this stands in the way of learning from relevant features or overfitting to noise in the training data. A more parsimonious model is more likely to prop up features supported by domain knowledge.</li>
      <li class="bulletList"><strong class="keyWord">Counterintuitive interactions</strong>: As mentioned in <em class="chapterRef">Chapter 10</em>, <em class="italic">Feature Selection and Engineering for Interpretability</em>, there could be counterintuitive interactions that a model favors over domain knowledge-supported interactions. As a side effect, these could end up favoring some groups that correlate with them. And in <em class="chapterRef">Chapter 6</em><em class="italic">, Anchors and Counterfactual Explanations</em>, we saw proof of this through an understanding of double standards.</li>
      <li class="bulletList"><strong class="keyWord">Exceptions</strong>: Our domain knowledge facts are based on an aggregate understanding, but when looking for patterns on a more granular scale, models will find exceptions such as pockets where female recidivism is of higher risk than that of males. Known phenomena might not support these models but they could be valid nonetheless, so we must be careful not to erase them with our tuning efforts.</li>
    </ul>
    <p class="normal">The advocacy group has validated the data as adequately representative of only one county in Florida, and they have provided you with a balanced dataset. The first impediment is a tough one to ascertain and control. The second one has been taken care of. It’s now up to you to deal with the remaining four!</p>
    <h1 id="_idParaDest-338" class="heading-1">The approach</h1>
    <p class="normal">You have decided to take a three-fold approach, as follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Placing guardrails with feature engineering</strong>: Leveraging lessons learned in <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, as well as the domain knowledge we already have about priors and age, in particular, we will engineer some features.</li>
      <li class="bulletList"><strong class="keyWord">Tuning models for interpretability</strong>: Once the data is ready, we will tune many models with different class weighting and overfitting prevention techniques. These methods will ensure that the models not only generalize better but are also easier to interpret.</li>
      <li class="bulletList"><strong class="keyWord">Implementing model constraints</strong>: Last but not least, we will implement monotonic and interaction constraints on the best models to make sure that they don’t stray from trusted and fair interactions.</li>
    </ul>
    <p class="normal">In the last two sections, we will make sure the models perform accurately and fairly. We will also compare recidivism risk distributions between the data and the model to ensure that they align.</p>
    <h1 id="_idParaDest-339" class="heading-1">The preparations</h1>
    <p class="normal">You will find the code for this example here: <a href="https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/12/Recidivism_part2.ipynb"><span class="url">https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/blob/main/12/Recidivism_part2.ipynb</span></a></p>
    <h2 id="_idParaDest-340" class="heading-2">Loading the libraries</h2>
    <p class="normal">To run this example, you need to install the following libraries:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">mldatasets</code> to load the dataset</li>
      <li class="bulletList"><code class="inlineCode">pandas</code> and <code class="inlineCode">numpy</code> to manipulate it</li>
      <li class="bulletList"><code class="inlineCode">sklearn</code> (scikit-learn), <code class="inlineCode">xgboost</code>, <code class="inlineCode">lightgbm</code>, <code class="inlineCode">catboost</code>, <code class="inlineCode">tensorflow</code>, <code class="inlineCode">bayes_opt</code>, and <code class="inlineCode">tensorflow_lattice</code> to split the data and fit the models</li>
      <li class="bulletList"><code class="inlineCode">matplotlib</code>, <code class="inlineCode">seaborn</code>, <code class="inlineCode">scipy</code>, <code class="inlineCode">xai</code>, and <code class="inlineCode">shap</code> to visualize the interpretations</li>
    </ul>
    <p class="normal">You should load all of them first, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> copy
<span class="hljs-keyword">import</span> mldatasets
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> preprocessing, model_selection, metrics,\
    linear_model, svm, neural_network, ensemble
<span class="hljs-keyword">import</span> xgboost <span class="hljs-keyword">as</span> xgb
<span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb
<span class="hljs-keyword">import</span> catboost <span class="hljs-keyword">as</span> cb
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> bayes_opt <span class="hljs-keyword">import</span> BayesianOptimization
<span class="hljs-keyword">import</span> tensorflow_lattice <span class="hljs-keyword">as</span> tfl
<span class="hljs-keyword">from</span> tensorflow.keras.wrappers.scikit_learn <span class="hljs-keyword">import</span>\
                                                  KerasClassifier
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> scipy
<span class="hljs-keyword">import</span> xai
<span class="hljs-keyword">import</span> shap
</code></pre>
    <p class="normal">Let’s check that <code class="inlineCode">tensorflow</code> has loaded the right version with <code class="inlineCode">print(tf.__version__)</code>. This should be 2.8 and above.</p>
    <h2 id="_idParaDest-341" class="heading-2">Understanding and preparing the data</h2>
    <p class="normal">We load the data like this into a DataFrame we call <code class="inlineCode">recidivism_df</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df = mldatasets.<span class="code-highlight"><strong class="hljs-slc">load</strong></span>(<span class="hljs-string">"recidivism-risk-balanced"</span>)
</code></pre>
    <p class="normal">There should be over 11,000 records and 11 columns. We can verify this was the case with <code class="inlineCode">info()</code>, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df.info()
</code></pre>
    <p class="normal">The preceding code outputs the following:</p>
    <pre class="programlisting con"><code class="hljs-con">RangeIndex: 11142 entries, 0 to 11141
Data columns (total 12 columns):
#   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
0   sex                      11142 non-null  object
1   age                      11142 non-null  int64
2   race                     11142 non-null  object
3   juv_fel_count            11142 non-null  int64
4   juv_misd_count           11142 non-null  int64
5   juv_other_count          11142 non-null  int64
6   priors_count             11142 non-null  int64
7   c_charge_degree          11142 non-null  object
8   days_b_screening_arrest  11142 non-null  float64
9   length_of_stay           11142 non-null  float64
10  compas_score             11142 non-null  int64
11  is_recid                 11142 non-null  int64
dtypes: float64(2), int64(7), object(3)
</code></pre>
    <p class="normal">The output checks out. There are no missing values, and all but three features are numeric (<code class="inlineCode">sex</code>, <code class="inlineCode">race</code>, and <code class="inlineCode">charge_degree</code>). This is the same data we used in <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, so the data dictionary is exactly the same. However, the dataset has been balanced with sampling methods, and, this time, it hasn’t been prepared for us so we will need to do this, but before this, let’s gain an understanding of what the balancing did.</p>
    <h3 id="_idParaDest-342" class="heading-3">Verifying the sampling balance</h3>
    <p class="normal">We <a id="_idIndexMarker1320"/>can check how <code class="inlineCode">race</code> and <code class="inlineCode">is_recid</code> are distributed with XAI’s <code class="inlineCode">imbalance_plot</code>. In other words, it will tally how many records exist for each <code class="inlineCode">race</code>-<code class="inlineCode">is_recid</code> combination. This plot will allow us to observe if there are imbalances in the number of defendants that recidivate for each <code class="inlineCode">race</code>. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">categorical_cols_l = [
    <span class="hljs-string">'sex'</span>, <span class="hljs-string">'race'</span>, <span class="hljs-string">'c_charge_degree'</span>, <span class="hljs-string">'is_recid'</span>, <span class="hljs-string">'compas_score'</span>
]
xai.<span class="code-highlight"><strong class="hljs-slc">imbalance_plot</strong></span>(
    recidivism_df,
    <span class="hljs-string">'</span><span class="hljs-string">race'</span>,
    <span class="hljs-string">'is_recid'</span>,
    categorical_cols=categorical_cols_l
)
</code></pre>
    <p class="normal">The preceding code outputs <em class="italic">Figure 12.1</em>, which depicts how all races have equal amounts of <code class="inlineCode">is_recid=0</code> and <code class="inlineCode">is_recid=1</code>. However, <strong class="keyWord">Other</strong> is not at parity in numbers with the other races. Incidentally, this version of the dataset has bucketed all other races as <strong class="keyWord">Other</strong>, and the choice to not <code class="inlineCode">upsample</code> <strong class="keyWord">Other</strong> or <code class="inlineCode">downsample</code> the other two races to achieve total parity is made because they are less represented in the defendant population. This balancing choice is one of many that can be done in a situation such as this. Demographically, it all depends on what your data is supposed to represent. Defendants? Inmates? Civilians in the general population? And at what level? Of the county? The state? The country?</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_01.png" alt="" role="presentation"/></p>
    <p class="packt_figref">Figure 12.1: Distribution of 2-year recidivism (is_recid) by ethnicity</p>
    <p class="normal">Next, let’s <a id="_idIndexMarker1321"/>compute how well each of our features monotonically correlates to the target. Spearman’s rank-order correlation will be instrumental in this chapter because it measures the monotonicity between two features. After all, one of the technical topics of this chapter is monotonic constraints, and the primary mission is to produce a significantly less biased model.</p>
    <p class="normal">We first create a new DataFrame without <code class="inlineCode">compas_score</code> (<code class="inlineCode">recidivism_corr_df</code>). Using this DataFrame, we output a color-coded DataFrame with a <code class="inlineCode">feature</code> column with the first 10 features’ names and another one with the Spearman coefficient (<code class="inlineCode">correlation_to_target</code>) for all 10 features toward the 11th—the target variable. The code can be<a id="_idIndexMarker1322"/> seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_corr_df = recidivism_df.<span class="code-highlight"><strong class="hljs-slc">drop</strong></span>(
    [<span class="hljs-string">'compas_score'</span>], axis=<span class="hljs-number">1</span>
)
pd.<span class="code-highlight"><strong class="hljs-slc">DataFrame</strong></span>(
    {<span class="hljs-string">'feature'</span>: recidivism_corr_df.columns[:-<span class="hljs-number">1</span>],
     <span class="hljs-string">'correlation_to_target'</span>:\
          scipy.stats.<span class="code-highlight"><strong class="hljs-slc">spearmanr</strong></span>(recidivism_corr_df).\
          correlation[<span class="hljs-number">10</span>,:-<span class="hljs-number">1</span>]
    }
).style.background_gradient(cmap=<span class="hljs-string">'coolwarm'</span>)
</code></pre>
    <p class="normal">The preceding code outputs the DataFrame shown in <em class="italic">Figure 12.2</em>. The most correlated features are <code class="inlineCode">priors_count</code> followed by <code class="inlineCode">age</code>, the three juvenile counts, and <code class="inlineCode">sex</code>. The coefficients for <code class="inlineCode">c_charge_degree</code>, <code class="inlineCode">days_b_screening_arrest</code>, <code class="inlineCode">length_of_stay</code>, and <code class="inlineCode">race</code> are negligible.</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_02.png" alt="Table  Description automatically generated"/></p>
    <p class="packt_figref">Figure 12.2: Spearman coefficients of all features toward the target, prior to feature engineering</p>
    <p class="normal">Next, we will learn how to use feature engineering to “bake in” some domain knowledge into the features.</p>
    <h1 id="_idParaDest-343" class="heading-1">Placing guardrails with feature engineering</h1>
    <p class="normal">In <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, we learned that besides <code class="inlineCode">race</code>, the <a id="_idIndexMarker1323"/>features most prominent in our explanations were <code class="inlineCode">age</code>, <code class="inlineCode">priors_count</code>, and <code class="inlineCode">c_charge_degree</code>. Thankfully, the data is now balanced, so the racial bias attributed to this imbalance is now gone. However, through anchors and counterfactual explanations, we found some troubling inconsistencies. In the case of <code class="inlineCode">age</code> and <code class="inlineCode">priors_count</code>, these inconsistencies were due to how those features were distributed. We can correct issues with distribution through feature engineering, and, that way, ensure that a model doesn’t learn from uneven distributions. In <code class="inlineCode">c_charge_degree</code>'s case, being categorical, it lacked a discernible order, and this lack of order created unintuitive explanations.</p>
    <p class="normal">In this section, we will study <strong class="keyWord">ordinalization</strong>, <strong class="keyWord">discretization</strong>, and <strong class="keyWord">interaction terms</strong>, three ways in which you can place guardrails through feature engineering.</p>
    <h2 id="_idParaDest-344" class="heading-2">Ordinalization</h2>
    <p class="normal">Let’s first<a id="_idIndexMarker1324"/> take a look in the following code snippet at how many observations we have for every <code class="inlineCode">c_charge_degree</code> category:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df.c_charge_degree.<span class="code-highlight"><strong class="hljs-slc">value_counts()</strong></span>
</code></pre>
    <p class="normal">The preceding code produced the following output:</p>
    <pre class="programlisting con"><code class="hljs-con">(F3)     6555
(M1)     2632
(F2)      857
(M2)      768
(F1)      131
(F7)      104
(MO3)      76
(F5)        7
(F6)        5
(NI0)       4
(CO3)       2
(TCX)       1
</code></pre>
    <p class="normal">Each of the charge degrees corresponds to the charge’s gravity. There’s an order to these gravities, which is lost by using a categorical feature. We can easily fix this by replacing each category with a corresponding order.</p>
    <p class="normal">We can put a <a id="_idIndexMarker1325"/>lot of thought into what this order should be. For instance, we could look at sentencing laws or guidelines—there are minimum or maximum years of prison enforced for different degrees. We could also look at statistics on how violent these people are on average and assign this information to the charge degree. There’s potential for bias in every decision such as this, and if we don’t have substantial evidence to support it, it’s best to use a sequence of integers. So, that’s what we are going to do now. We will create a dictionary (<code class="inlineCode">charge_degree_code_rank</code>) that maps the degrees to a number corresponding to a rank of gravity, from low to high. Then, we can use the <code class="inlineCode">pandas</code> <code class="inlineCode">replace</code> function to use the dictionary to perform the replacements. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">charge_degree_code_rank = {
    <span class="hljs-string">'(F10)'</span>: <span class="hljs-number">15</span>, <span class="hljs-string">'(F9)'</span>:<span class="hljs-number">14</span>, <span class="hljs-string">'(F8)'</span>:<span class="hljs-number">13</span>,\
    <span class="hljs-string">'(F7)'</span>:<span class="hljs-number">12</span>, <span class="hljs-string">'(TCX)'</span>:<span class="hljs-number">11</span>, <span class="hljs-string">'(F6)'</span>:<span class="hljs-number">10</span>, <span class="hljs-string">'(F5)'</span>:<span class="hljs-number">9</span>,\
    <span class="hljs-string">'(F4)'</span>:<span class="hljs-number">8</span>, <span class="hljs-string">'(F3)'</span>:<span class="hljs-number">7</span>, <span class="hljs-string">'(F2)'</span>:<span class="hljs-number">6</span>, <span class="hljs-string">'(F1)'</span>:<span class="hljs-number">5</span>, <span class="hljs-string">'(M1)'</span>:<span class="hljs-number">4</span>,\
    <span class="hljs-string">'(NI0)'</span>:<span class="hljs-number">4</span>, <span class="hljs-string">'(M2)'</span>:<span class="hljs-number">3</span>, <span class="hljs-string">'(CO3)'</span>:<span class="hljs-number">2</span>, <span class="hljs-string">'(MO3)'</span>:<span class="hljs-number">1</span>, <span class="hljs-string">'(X)'</span>:<span class="hljs-number">0</span>
}
recidivism_df.c_charge_degree.<span class="code-highlight"><strong class="hljs-slc">replace</strong></span>(
    charge_degree_code_rank, inplace=<span class="hljs-literal">True</span>
)
</code></pre>
    <p class="normal">One way to assess how this order corresponds to recidivism probability is through a line plot that shows how it changes as the charge degree increases. We can use a function called <code class="inlineCode">plot_prob_progression</code> for this, which takes a continuous feature in the first argument (<code class="inlineCode">c_charge_degree</code>) to measure against probability for a binary feature in the second (<code class="inlineCode">is_recid</code>). It can split the continuous feature by intervals (<code class="inlineCode">x_intervals</code>), and even use quantiles (<code class="inlineCode">use_quantiles</code>). Lastly, you can define axis labels and titles. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_progression</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">c_charge_degree</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>, x_intervals=<span class="hljs-number">12</span>,
    use_quantiles=<span class="hljs-literal">False</span>,
    xlabel=<span class="hljs-string">'Relative Charge Degree'</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Relative Charge Degree'</span>
)
</code></pre>
    <p class="normal">The preceding<a id="_idIndexMarker1326"/> code generates the plot in <em class="italic">Figure 12.3</em>. As the now-ranked charge degree increases, the tendency is that the probability of 2-year recidivism decreases, except for rank 1. Below the probability, there are bar charts that show the distribution of the observations over every rank. Because it is so unevenly distributed, you should take the tendency with a grain of salt. You’ll notice that some ranks, such as 0, 8, and 13–15, aren’t in the plot because the charge-degree categories existed in the criminal justice system but weren’t in the data.</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_03.png" alt="Chart, line chart  Description automatically generated"/></p>
    <p class="packt_figref">Figure 12.3: Probability progression plot by charge degree</p>
    <p class="normal">Feature engineering-wise, we can’t do much more to improve <code class="inlineCode">c_charge_degree</code> because it already represents discrete categories now enhanced with an order. Any further transformations could produce a significant loss of information unless we have evidence to suggest otherwise. On the other hand, continuous features inherently have an order; however, a <a id="_idIndexMarker1327"/>problem may arise from the level of precision they carry because small differences may not be meaningful but the data may tell the model otherwise. Uneven distributions and counterintuitive interactions only exacerbate this problem.</p>
    <h2 id="_idParaDest-345" class="heading-2">Discretization</h2>
    <p class="normal">To understand <a id="_idIndexMarker1328"/>how to discretize our <code class="inlineCode">age</code> continuous feature best, let’s try two different approaches. We can use equal-sized discretization, also known as fixed-width bins or intervals, which means the size of the bin is determined by <img src="../Images/B18406_12_001.png" alt="" role="presentation"/>, where <em class="italic">N</em> is the number of bins. Another way to do this is with equal-frequency discretization, also known as quantiles, which ensures that each bin has approximately the same number of observations. Although, sometimes, given the histogram’s skewed nature, it may be impossible to split them <em class="italic">N</em> ways, so you may end up with <em class="italic">N-1</em> or <em class="italic">N-2</em> quantiles.</p>
    <p class="normal">It is easy to compare both approaches with <code class="inlineCode">plot_prob_progression</code>, but this time, we produce two plots, one with fixed-width bins (<code class="inlineCode">use_quantiles=False</code>) and another with quantiles (<code class="inlineCode">use_quantiles=True</code>). The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.plot_<span class="code-highlight"><strong class="hljs-slc">prob_progression</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>,
    x_intervals=<span class="hljs-number">7</span>,
    use_quantiles=<span class="hljs-literal">False</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Age Discretized in Fix-Width \</span>
    <span class="hljs-string">Bins'</span>,
    xlabel=<span class="hljs-string">'Age'</span>
)
mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_progression</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>,
    x_intervals=<span class="hljs-number">7</span>, use_quantiles=<span class="hljs-literal">True</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Age Discretized \</span>
    <span class="hljs-string">in Quantiles'</span>,
    xlabel=<span class="hljs-string">'Age'</span>
)
</code></pre>
    <p class="normal">The preceding snippet outputs <em class="italic">Figure 12.4</em>. By looking at the <strong class="screenText">Observations</strong> portion of the fixed-width bin plot, you can tell that the histogram for the <code class="inlineCode">age</code> feature is right-skewed, which causes the probability to shoot up for the last bin. The reason for this is that some outliers exist in this bin. On the other hand, the fixed-frequency (quantile) plot<a id="_idIndexMarker1329"/> histogram is more even, and probability consistently decreases. In other words, it’s monotonic—as it should be, according to our domain knowledge on the subject.</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_04.png" alt="" role="presentation"/></p>
    <p class="packt_figref">Figure 12.4: Comparing two discretization approaches for age</p>
    <p class="normal">It is easy to observe why using quantiles to bin the feature is a better approach. We can take <code class="inlineCode">age</code> and engineer a new feature called <code class="inlineCode">age_group</code>. The <code class="inlineCode">qcut</code> <code class="inlineCode">pandas</code> function can perform quantile-based discretization. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df[<span class="hljs-string">'age_group'</span>] = pd.<span class="code-highlight"><strong class="hljs-slc">qcut</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age</strong></span>, <span class="hljs-number">7</span>, precision=<span class="hljs-number">0</span>
).astype(<span class="hljs-built_in">str</span>)
</code></pre>
    <p class="normal">So, we now have discretized <code class="inlineCode">age</code> into <code class="inlineCode">age_group</code>. However, it must be noted that many model classes discretize automatically, so why bother? Because it allows you to control its effects. Otherwise, the model might decide on bins that don’t ensure monotonicity. For instance, maybe the model might always use 10 quantiles whenever possible. Still, if you attempt this level of granularity on <code class="inlineCode">age</code> (<code class="inlineCode">x_intervals=10</code>), you’ll end up with spikes in the probability progression. Our goal was to make sure that the models would learn that <code class="inlineCode">age</code> and the incidence of <code class="inlineCode">is_recid</code> have a monotonic relationship, and we cannot ascertain this if we allow the model to choose bins that may or may not achieve the same goal.</p>
    <p class="normal">We will remove <code class="inlineCode">age</code> because <code class="inlineCode">age_group</code> has everything we need. But wait—you ask—won’t we lose some important information by removing this variable? Yes, but only because<a id="_idIndexMarker1330"/> of its interaction with <code class="inlineCode">priors_count</code>. So, before we drop any features, let’s examine this relationship and realize how, through creating an interaction term, we can retain some of the information lost through the removal of <code class="inlineCode">age</code>, while keeping the interaction.</p>
    <h2 id="_idParaDest-346" class="heading-2">Interaction terms and non-linear transformations</h2>
    <p class="normal">We <a id="_idIndexMarker1331"/>already know from <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, that <code class="inlineCode">age</code> and <code class="inlineCode">priors_count</code> are two of the <a id="_idIndexMarker1332"/>most important predictors, and we can observe how, together, they impact the incidence of recidivism (<code class="inlineCode">is_recid</code>) with <code class="inlineCode">plot_prob_contour_map</code>. This function produces contour lines with color-coded contour regions, signifying different magnitudes. They are useful in topography, where they show elevation heights. In machine learning, they can show a two-dimensional plane representing feature interaction with a metric. In this case, the dimensions are <code class="inlineCode">age</code> and <code class="inlineCode">priors_count</code>, and the metric is the incidence of recidivism. The arguments received by this function are the same as <code class="inlineCode">plot_prob_progression</code> except that it takes two features corresponding to the <em class="italic">x</em> axis and <em class="italic">y</em> axis. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.plot_<span class="code-highlight"><strong class="hljs-slc">prob_contour_map</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">priors_count</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>,
    use_quantiles=<span class="hljs-literal">True</span>,
    xlabel=<span class="hljs-string">'Age'</span>,
    ylabel=<span class="hljs-string">'</span><span class="hljs-string">Priors Count'</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Age/Priors Discretized in \</span>
    <span class="hljs-string">Quantiles'</span>
)
</code></pre>
    <p class="normal">The preceding snippet generated <em class="italic">Figure 12.5</em>, which shows how, when discretized by quantiles, the probability of 2-year recidivism increases, the lower the <code class="inlineCode">age</code> and the higher the <code class="inlineCode">priors_count</code>. It also shows histograms for both features. <code class="inlineCode">priors_count</code> is very right-skewed, so discretization is challenging, and the contour map does not offer a perfectly diagonal progression between the bottom right and top left. And if this plot looks familiar, it’s because it’s just like the partial dependence interaction plots we produced in <em class="chapterRef">Chapter 4</em>, <em class="italic">Global Model-Agnostic Interpretation Methods</em>, except it’s not measured against the predictions of a model but the ground truth (<code class="inlineCode">is_recid</code>). We must distinguish<a id="_idIndexMarker1333"/> between <a id="_idIndexMarker1334"/>what the data can tell us directly and what the model has learned from it.</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_05.png" alt="" role="presentation"/></p>
    <p class="packt_figref">Figure 12.5: Recidivism probability contour map for age and priors_count</p>
    <p class="normal">We can now engineer an interaction term that includes both features. Even though the contour map discretized the features to observe a smoother progression, we do not need to discretize this relationship. What makes sense is to make it a ratio of <code class="inlineCode">priors_count</code> per year. But years since when? Years since the defendants were an adult, of course. But to obtain the years, we cannot use <code class="inlineCode">age - 18</code> because this would lead to zero division, so we will use <code class="inlineCode">17</code> instead. There are, of course, many ways to do this. The best way would be if we hypothetically had ages with decimals, and by deducting 18, we could compute a very precise <code class="inlineCode">priors_per_year</code> ratio. Still, unfortunately, we don’t have that. You can see the code in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df[<span class="hljs-string">'priors_per_year'</span>] =\
            recidivism_df[<span class="hljs-string">'priors_count'</span>]/(recidivism_df[<span class="hljs-string">'age'</span>] - <span class="hljs-number">17</span>)
</code></pre>
    <p class="normal">Black-box models<a id="_idIndexMarker1335"/> typically find interaction<a id="_idIndexMarker1336"/> terms automatically. For instance, hidden layers in a neural network have all the first-order interactions, but because of the non-linear activations, it is not limited to linear combinations. However, “manually” defining interaction terms and even non-linear transformation allows us to interpret these better once the model has been fitted. Furthermore, we can also use monotonic constraints on them, precisely what we will do later with <code class="inlineCode">priors_per_year</code>. For now, let’s examine if its monotonicity holds with <code class="inlineCode">plot_prob_progression</code>. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_progression</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">priors_per_year</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>,
    x_intervals=<span class="hljs-number">8</span>,
    xlabel=<span class="hljs-string">'Priors Per Year'</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Priors per Year (\</span>
    <span class="hljs-string">according to data)'</span>
)
</code></pre>
    <p class="normal">The preceding snippet outputs the progression in the following screenshot, which shows how the new feature is almost monotonic:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_06.png" alt="Chart, line chart  Description automatically generated"/></p>
    <p class="packt_figref">Figure 12.6: Probability progression for priors_per_year</p>
    <p class="normal">The <a id="_idIndexMarker1337"/>reason <code class="inlineCode">priors_per_year</code> isn’t more monotonic is how sparse the over-3.0 <code class="inlineCode">priors_per_year</code> interval is. It would therefore be very unfair to these few defendants to enforce<a id="_idIndexMarker1338"/> monotonicity on this feature because they present a 75% risk dip. One way to tackle this is to shift them over to the left, by setting <code class="inlineCode">priors_per_year = -1</code> for these observations, as illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">recidivism_df.loc[recidivism_df.priors_per_year &gt; <span class="hljs-number">3</span>,\
                  <span class="hljs-string">'priors_per_year'</span>] = -<span class="hljs-number">1</span>
</code></pre>
    <p class="normal">Of course, this shift changes the interpretation of the feature ever so slightly, knowing that the few values of <code class="inlineCode">-1</code> really mean over <code class="inlineCode">3</code>. Now, let’s generate another contour map, but this time, between <code class="inlineCode">age_group</code> and <code class="inlineCode">priors_per_year</code>. The latter will be discretized in quantiles (<code class="inlineCode">y_intervals=6, use_quantiles=True</code>) so that the probability of recidivism is more easily observed. The code is shown in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_contour_map</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age_group</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">priors_per_year</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>,
    y_intervals=<span class="hljs-number">6</span>,
    use_quantiles=<span class="hljs-literal">True</span>,
    xlabel=<span class="hljs-string">'Age Group'</span>,
    title=<span class="hljs-string">'Probability of Recidivism by Age/Priors per Year \</span>
    <span class="hljs-string">Discretized in Quantiles'</span>, ylabel=<span class="hljs-string">'Priors Per Year'</span>
)
</code></pre>
    <p class="normal">The<a id="_idIndexMarker1339"/> preceding snippet<a id="_idIndexMarker1340"/> generates the contours in <em class="italic">Figure 12.7</em>. It shows that, for the most part, the plot moves in one direction. We were hoping to achieve this outcome because it allows us, through one interaction feature, to control the monotonicity of what used to involve two features.</p>
    <p class="normal">The output can be seen here:</p>
    <p class="packt_figref"><img src="../Images/B18406_12_07.png" alt="" role="presentation"/></p>
    <p class="packt_figref">Figure 12.7: Recidivism probability contour map for age_group and priors_per_year</p>
    <p class="normal">Almost<a id="_idIndexMarker1341"/> everything<a id="_idIndexMarker1342"/> is ready, but <code class="inlineCode">age_group</code> is still categorical, so we have to encode it to take a numerical form.</p>
    <h2 id="_idParaDest-347" class="heading-2">Categorical encoding</h2>
    <p class="normal">The<a id="_idIndexMarker1343"/> best categorical encoding<a id="_idIndexMarker1344"/> method for <code class="inlineCode">age_group</code> is <strong class="keyWord">ordinal encoding</strong>, also known <a id="_idIndexMarker1345"/>as <strong class="keyWord">label encoding</strong>, because it will retain its order. We should also encode the other two categorical features in the dataset, <code class="inlineCode">sex</code> and <code class="inlineCode">race</code>. For <code class="inlineCode">sex</code>, ordinal encoding converts it into binary form—equivalent to <strong class="keyWord">dummy encoding</strong>. On <a id="_idIndexMarker1346"/>the other hand, <code class="inlineCode">race</code> is a tougher call because it has three categories, and using ordinal encoding could lead to bias. However, whether to use <strong class="keyWord">one-hot encoding</strong> instead <a id="_idIndexMarker1347"/>depends on which model classes you are using. Tree-based models have no bias issues with ordinal features but other models that operate with weights on a feature basis, such as neural networks and logistic regression, could be biased by this order. </p>
    <p class="normal">Considering that the dataset has been balanced on <code class="inlineCode">race</code>, there’s a lower risk of this happening and we will remove this feature later anyway, so we will go ahead and ordinal-encode it.</p>
    <p class="normal">To <a id="_idIndexMarker1348"/>ordinal-encode the three features, we will use scikit-learn’s <code class="inlineCode">OrdinalEncoder</code>. We can use its <code class="inlineCode">fit_transform</code> function to fit and transform the features in one fell swoop. Then, we should also delete unnecessary features while we are at it. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">cat_feat_l = [<span class="hljs-string">'sex'</span>, <span class="hljs-string">'race'</span>, <span class="hljs-string">'age_group'</span>]
ordenc = preprocessing.<span class="code-highlight"><strong class="hljs-slc">OrdinalEncoder</strong></span>(dtype=np.int8)
recidivism_df[cat_feat_l] =\
                  ordenc.<span class="code-highlight"><strong class="hljs-slc">fit_transform</strong></span>(recidivism_df[cat_feat_l])
recidivism_df.drop([<span class="hljs-string">'age'</span>, <span class="hljs-string">'priors_count'</span>, <span class="hljs-string">'compas_score'</span>],\
                    axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)
</code></pre>
    <p class="normal">Now, we aren’t entirely done yet. We still ought to initialize our random seeds and train/test split our data.</p>
    <h2 id="_idParaDest-348" class="heading-2">Other preparations</h2>
    <p class="normal">The next preparations are straightforward. To ensure reproducibility, let’s set a random seed everywhere it is needed, then set our <code class="inlineCode">y</code> as <code class="inlineCode">is_recid</code> and <code class="inlineCode">X</code> as every other feature. We perform <code class="inlineCode">train_test_split</code> on those two. Lastly, we reconstruct the <code class="inlineCode">recidivism_df</code> DataFrame with the <code class="inlineCode">X</code> followed by the <code class="inlineCode">y</code>. The only reason for this is so that <code class="inlineCode">is_recid</code> is the last column, which will help with the next step. The code can be seen here:</p>
    <pre class="programlisting code"><code class="hljs-code">rand = <span class="hljs-number">9</span>
os.environ[<span class="hljs-string">'PYTHONHASHSEED'</span>] = <span class="hljs-built_in">str</span>(rand)
tf.random.set_seed(rand)
np.random.seed(rand)
y = recidivism_df[<span class="hljs-string">'is_recid'</span>]
X = recidivism_df.drop([<span class="hljs-string">'is_recid'</span>], axis=<span class="hljs-number">1</span>).copy()
X_train, X_test, y_train, y_test = model_selection.<span class="code-highlight"><strong class="hljs-slc">train_test_split</strong></span>(
    X, y, test_size=<span class="hljs-number">0.2</span>, random_state=rand
)
recidivism_df = X.join(y)
</code></pre>
    <p class="normal">We will now verify that Spearman’s correlations have improved where needed and stay the same otherwise. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">pd.DataFrame(
    {
        <span class="hljs-string">'feature'</span>: X.columns,
        <span class="hljs-string">'correlation_to_target'</span>:scipy.stats.<span class="code-highlight"><strong class="hljs-slc">spearmanr</strong></span>(recidivism_df).\
        correlation[<span class="hljs-number">10</span>,:-<span class="hljs-number">1</span>]
    }
).style.background_gradient(cmap=<span class="hljs-string">'coolwarm'</span>)
</code></pre>
    <p class="normal">The preceding code outputs the DataFrame shown in <em class="italic">Figure 12.8</em>. Please compare it with <em class="italic">Figure 12.2</em>. Note that discretized in quantiles, <code class="inlineCode">age</code> is slightly less monotonically correlated with the target. Once ordinalized, <code class="inlineCode">c_charge_degree</code> is also much more correlated, and <code class="inlineCode">priors_per_year</code> has also improved over <code class="inlineCode">priors_count</code>. No other features should have been affected, including those that have the lowest coefficients.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_08.png" alt="Table  Description automatically generated"/></figure>
    <figure class="mediaobject">Figure 12.8: Spearman correlation coefficients of all features toward the target (after feature engineering)</figure>
    <p class="normal">Features with the lowest coefficients are likely also unnecessary in a model, but we will let the model decide if they are useful through regularization. That’s what we will do next.</p>
    <h1 id="_idParaDest-349" class="heading-1">Tuning models for interpretability</h1>
    <p class="normal">Traditionally, regularization <a id="_idIndexMarker1349"/>was only achieved by imposing penalty terms such as <strong class="keyWord">L1</strong>, <strong class="keyWord">L2</strong>, or <strong class="keyWord">elastic net</strong> on the coefficients or weights, which shrink the impact of the least relevant features. As seen in the <em class="italic">Embedded methods</em> section of <em class="chapterRef">Chapter 10</em>, <em class="italic">Feature Selection and Engineering for Interpretability</em>, this form of regularization results in feature selection while also reducing overfitting. And this brings us to another broader definition of regularization, which does not require a penalty term. Often, this comes as imposing a limitation, or a stopping criterion that forces the model to curb its complexity.</p>
    <p class="normal">In addition to regularization, both in its narrow (penalty-based) and broad sense (overfitting methods), there are other methods that tune a model for interpretability—that is, improve the fairness, accountability, and transparency of a model through adjustments to the training process. For instance, the class imbalance hyperparameters we discussed in <em class="chapterRef">Chapter 10</em>, <em class="italic">Feature Selection and Engineering for Interpretability</em>, and the adversarial debiasing in <em class="chapterRef">Chapter 11</em>, <em class="italic">Bias Mitigation and Causal Inference Methods</em>, enhance fairness. Also, the constraints we will study further in this chapter have potential benefits for fairness, accountability, and transparency.</p>
    <p class="normal">There are so many different tuning possibilities and model classes. As stated at the beginning of the chapter, we will focus on interpretability-related options, but will also limit the model classes to a popular deep learning library (Keras), a handful of popular tree ensembles (XGBoost, Random Forest, and so on), <strong class="keyWord">Support Vector Machines</strong> (<strong class="keyWord">SVMs</strong>), and logistic regression. Except for the last one, these are all considered black-box models.</p>
    <h2 id="_idParaDest-350" class="heading-2">Tuning a Keras neural network</h2>
    <p class="normal">For a Keras<a id="_idIndexMarker1350"/> model, we <a id="_idIndexMarker1351"/>will choose the best <a id="_idIndexMarker1352"/>regularization parameters through hyperparameter tuning and <strong class="keyWord">stratified K-fold cross-validation</strong>. We will do this using the following steps:</p>
    <ol class="numberedList" style="list-style-type: decimal;">
      <li class="numberedList" value="1">First, we need to define the model and the parameters to tune.</li>
      <li class="numberedList">Then, we run the tuning.</li>
      <li class="numberedList">Next, we examine its results.</li>
      <li class="numberedList">Finally, we <a id="_idIndexMarker1353"/>extract the best model and evaluate its predictive performance.</li>
    </ol>
    <p class="normal">Let’s look at each of these steps in detail.</p>
    <h3 id="_idParaDest-351" class="heading-3">Defining the model and parameters to tune</h3>
    <p class="normal">The first thing<a id="_idIndexMarker1354"/> we ought to do is create a function (<code class="inlineCode">build_nn_mdl</code>) to build and compile a regularizable Keras model. The function takes arguments that will help tune it. It takes a tuple with the number of neurons in hidden layers (<code class="inlineCode">hidden_layer_sizes</code>), and a value of L1 (<code class="inlineCode">l1_reg</code>) and L2 (<code class="inlineCode">l1_reg</code>) regularization to apply on the layer’s kernel. Lastly, it takes the <code class="inlineCode">dropout</code> parameter, which, unlike L1 and L2 penalties, is a <strong class="keyWord">stochastic regularization method</strong> because it <a id="_idIndexMarker1355"/>employs random selection. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="code-highlight"><strong class="hljs-title-slc">build_nn_mdl</strong></span>(<span class="hljs-params">hidden_layer_sizes, l1_reg=</span><span class="hljs-number">0</span><span class="hljs-params">, l2_reg=</span><span class="hljs-number">0</span><span class="hljs-params">, dropout=</span><span class="hljs-number">0</span>):
    nn_model = tf.keras.Sequential([
        tf.keras.Input(shape=[<span class="hljs-built_in">len</span>(X_train.keys())]),\
        tf.keras.layers.experimental.preprocessing.<span class="code-highlight"><strong class="hljs-slc">Normalization</strong></span>()
    ])
    reg_args = {}
    <span class="hljs-keyword">if</span> (l1_reg &gt; <span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> (l2_reg &gt; <span class="hljs-number">0</span>):
        reg_args = {<span class="hljs-string">'kernel_regularizer'</span>:\
                    tf.keras.regularizers.<span class="code-highlight"><strong class="hljs-slc">l1_l2</strong></span>(l1=l1_reg, l2=l2_reg)}
    <span class="hljs-keyword">for</span> hidden_layer_size <span class="hljs-keyword">in</span> hidden_layer_sizes:
        nn_model.add(tf.keras.layers.<span class="code-highlight"><strong class="hljs-slc">Dense</strong></span>(hidden_layer_size,\
                        activation=<span class="hljs-string">'relu'</span>, <span class="code-highlight"><strong class="hljs-slc">**reg_args</strong></span>))
    <span class="hljs-keyword">if</span> dropout &gt; <span class="hljs-number">0</span>:
        nn_model.add(tf.keras.layers.<span class="code-highlight"><strong class="hljs-slc">Dropout</strong></span>(dropout))
    nn_model.add(tf.keras.layers.<span class="code-highlight"><strong class="hljs-slc">Dense</strong></span>(<span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>))
    nn_model.<span class="hljs-built_in">compile</span>(
        loss=<span class="hljs-string">'binary_crossentropy'</span>,
        optimizer=tf.keras.optimizers.Adam(lr=<span class="hljs-number">0.0004</span>),
        metrics=[<span class="hljs-string">'</span><span class="hljs-string">accuracy'</span>,tf.keras.metrics.AUC(name=<span class="hljs-string">'auc'</span>)]
)
    <span class="hljs-keyword">return</span> nn_model
</code></pre>
    <p class="normal">The previous function initializes the model (<code class="inlineCode">nn_model</code>) as a <code class="inlineCode">Sequential</code> model with an input layer that corresponds to the number of features in training data, and a <code class="inlineCode">Normalization()</code> layer that standardizes the input. Then, if either penalty term is over zero, it will set a dictionary (<code class="inlineCode">reg_args</code>) with the <code class="inlineCode">kernel_regularizer</code> assigned to <code class="inlineCode">tf.keras.regularizers.l1_l2</code> initialized with these penalties. Once it adds the hidden (<code class="inlineCode">Dense</code>) layers with the corresponding <code class="inlineCode">hidden_layer_size</code>, it will pass the <code class="inlineCode">reg_args</code> dictionary as <a id="_idIndexMarker1356"/>extra arguments to each layer. After all hidden layers have been added, it will optionally add the <code class="inlineCode">Dropout</code> layer and the final <code class="inlineCode">Dense</code> layer with the <code class="inlineCode">sigmoid</code> activation for the output. The model is then compiled with <code class="inlineCode">binary_crossentropy</code> and an <code class="inlineCode">Adam</code> optimizer with a slow learning rate and is set to monitor <code class="inlineCode">accuracy</code> and <code class="inlineCode">auc</code> metrics.</p>
    <h3 id="_idParaDest-352" class="heading-3">Running the hyperparameter tuning</h3>
    <p class="normal">Now that we have <a id="_idIndexMarker1357"/>defined the model and parameters to tune, we initialize the <code class="inlineCode">RepeatedStratifiedKFold</code> cross-validator, which splits (<code class="inlineCode">n_splits</code>) the training data in five a total of three times (<code class="inlineCode">n_repeats</code>), using different randomization in each repetition. We then create a grid (<code class="inlineCode">nn_grid</code>) for the grid-search hyperparameter tuning. It’s testing only two possible options for three of the parameters (<code class="inlineCode">l1_reg</code>, <code class="inlineCode">l2_reg</code>, and <code class="inlineCode">dropout</code>), which will result in <img src="../Images/B18406_12_002.png" alt="" role="presentation"/> combinations. We will use a scikit-learn wrapper (<code class="inlineCode">KerasClassifier</code>) for our model to be compatible with the scikit-learn grid search. Speaking of which, we next initialize <code class="inlineCode">GridSearchCV</code>, which, using the Keras model (<code class="inlineCode">estimator</code>), performs a cross-validated (<code class="inlineCode">cv</code>) grid search (<code class="inlineCode">param_grid</code>). We want it to choose the best parameters based on precision (<code class="inlineCode">scoring</code>) and not raise errors in the process (<code class="inlineCode">error_score=0</code>). Finally, we fit <code class="inlineCode">GridSearchCV</code> as we would with any Keras model, passing <code class="inlineCode">X_train</code>, <code class="inlineCode">y_train</code>, <code class="inlineCode">epochs</code>, and <code class="inlineCode">batch_size</code>. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">cv = model_selection.<span class="code-highlight"><strong class="hljs-slc">RepeatedStratifiedKFold</strong></span>(
    n_splits=<span class="hljs-number">5</span>,
    n_repeats=<span class="hljs-number">3</span>,
    random_state=rand
)
nn_grid = {
    <span class="hljs-string">'hidden_layer_sizes'</span>:[(<span class="hljs-number">80</span>,)],
    <span class="hljs-string">'l1_reg'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.005</span>],
    <span class="hljs-string">'l2_reg'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.01</span>],
    <span class="hljs-string">'dropout'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.05</span>]
}
nn_model = KerasClassifier(build_fn=build_nn_mdl)
nn_grid_search = model_selection.<span class="code-highlight"><strong class="hljs-slc">GridSearchCV</strong></span>(
    estimator=nn_model,
    cv=cv,
    n_jobs=-<span class="hljs-number">1</span>,
    param_grid=nn_grid,
    scoring=<span class="hljs-string">'</span><span class="hljs-string">precision'</span>,
    error_score=<span class="hljs-number">0</span>
)
nn_grid_result = nn_grid_search.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(
    X_train.astype(<span class="hljs-built_in">float</span>),
    y_train.astype(<span class="hljs-built_in">float</span>),
    epochs=<span class="hljs-number">400</span>,batch_size=<span class="hljs-number">128</span>
)
</code></pre>
    <p class="normal">Next, we can <a id="_idIndexMarker1358"/>examine the results of our grid search.</p>
    <h3 id="_idParaDest-353" class="heading-3">Examining the results</h3>
    <p class="normal">Once the<a id="_idIndexMarker1359"/> grid search has been completed, you can output the best parameters in a dictionary with this command: <code class="inlineCode">print(nn_grid_result.best_params_)</code>. Or you can place all the results into a DataFrame, sort them by the highest precision (<code class="inlineCode">sort_values</code>), and output them as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">pd.<span class="code-highlight"><strong class="hljs-slc">DataFrame</strong></span>(nn_grid_result.<span class="code-highlight"><strong class="hljs-slc">cv_results</strong></span>_)[
    [
        <span class="hljs-string">'param_hidden_layer_sizes'</span>,
        <span class="hljs-string">'param_l1_reg'</span>,
        <span class="hljs-string">'param_l2_reg'</span>,
        <span class="hljs-string">'param_dropout'</span>,
        <span class="hljs-string">'mean_test_score'</span>,
        <span class="hljs-string">'std_test_score'</span>,
        <span class="hljs-string">'rank_test_score'</span>
    ]
].<span class="code-highlight"><strong class="hljs-slc">sort_values</strong></span>(by=<span class="hljs-string">'rank_test_score'</span>)
</code></pre>
    <p class="normal">The preceding snippet outputs the DataFrame shown in <em class="italic">Figure 12.9</em>. The unregularized model is dead last, showing that all regularized model combinations performed better. One thing to note is that given the 1.5–2% standard deviations (<code class="inlineCode">std_test_score</code>) and that the top performer is only 2.2% from the lowest performer, in this case, the benefits are marginal from a precision standpoint, but you should use a regularized model nonetheless because of other benefits.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_09.png" alt="Table  Description automatically generated"/></figure>
    <figure class="mediaobject">Figure 12.9: Results for cross-validated grid search for a neural net model</figure>
    <h3 id="_idParaDest-354" class="heading-3">Evaluating the best model</h3>
    <p class="normal">Another<a id="_idIndexMarker1360"/> important element that the grid search produced is the best-performing model (<code class="inlineCode">nn_grid_result.best_estimator_</code>). We can create a dictionary to store all the models we will fit in this chapter (<code class="inlineCode">fitted_class_mdls</code>) and then, using <code class="inlineCode">evaluate_class_mdl</code>, evaluate this regularized Keras model and keep the evaluation in the dictionary at the same time. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">fitted_class_mdls = {}
fitted_class_mdls[<span class="hljs-string">'keras_reg'</span>] = mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
    nn_grid_result.best_estimator_,
    X_train.astype(<span class="hljs-built_in">float</span>),
    X_test.astype(<span class="hljs-built_in">float</span>),
    y_train.astype(<span class="hljs-built_in">float</span>),
    y_test.astype(<span class="hljs-built_in">float</span>),
    plot_roc=<span class="hljs-literal">False</span>,
    plot_conf_matrix=<span class="hljs-literal">True</span>,
    <span class="code-highlight"><strong class="hljs-slc">ret_eval_dict=</strong><strong class="hljs-literal-slc">True</strong></span>
)
</code></pre>
    <p class="normal">The preceding snippet produced the confusion matrix and metrics shown in <em class="italic">Figure 12.10</em>. The accuracy is a little bit better than the original COMPAS model from <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>, but the strategy to optimize for higher precision while regularizing yielded a model with nearly half as many false positives but 50% more false negatives.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_10.png" alt="Chart, treemap chart  Description automatically generated"/></figure>
    <figure class="mediaobject">Figure 12.10: Evaluation of the regularized Keras model</figure>
    <p class="normal">Calibrating<a id="_idIndexMarker1361"/> the class balance can be improved even further by employing a custom loss function or class weights, as we will do later. Next, we will cover how to tune other model classes.</p>
    <h2 id="_idParaDest-355" class="heading-2">Tuning other popular model classes</h2>
    <p class="normal">In this<a id="_idIndexMarker1362"/> section, we will fit many different<a id="_idIndexMarker1363"/> models, both unregularized and regularized. To this end, we will pick from a wide selection of parameters that perform penalized regularization, control overfitting through other means, and account for class imbalance.</p>
    <h3 id="_idParaDest-356" class="heading-3">A quick introduction to relevant model parameters</h3>
    <p class="normal">For your reference, there<a id="_idIndexMarker1364"/> are two tables with parameters used to tune many popular models. These have been split into two parts. Part A (<em class="italic">Figure 12.11</em>) has five scikit-learn models with penalty regularization. Part B (<em class="italic">Figure 12.12</em>) shows all the tree ensembles, including scikit-learn’s Random Forest models and models from the most popular boosted-tree libraries (XGBoost, LightGBM, and CatBoost).</p>
    <p class="normal">Part A can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_11.png" alt="Table, calendar  Description automatically generated"/></figure>
    <figure class="mediaobject">Figure 12.11: Tuning parameters for penalty-regularized scikit-learn models</figure>
    <p class="normal">In <em class="italic">Figure 12.11</em>, you can observe models in the columns and corresponding parameter names in the rows with their default values to the right. In between the parameter name and default value, there’s a plus or minus sign indicating whether changing the defaults in one direction or another should make the model more conservative. These parameters are also grouped by the following categories:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">algorithm</strong>: Some training algorithms are less prone to overfitting, but this often depends on the data.</li>
      <li class="bulletList"><strong class="keyWord">regularization</strong>: Only in the stricter sense. In other words, parameters that control penalty-based regularization.</li>
      <li class="bulletList"><strong class="keyWord">iterations</strong>: This controls how many training rounds, iterations, or epochs are performed. Adjusting this in one direction or another can impact overfitting. In tree-based models, the number of estimators or trees is what’s analogous.</li>
      <li class="bulletList"><strong class="keyWord">learning rate</strong>: This controls how quickly the learning happens. It works in tandem with iterations. The lower the learning rate, the more iterations are needed to optimize the objective function. </li>
      <li class="bulletList"><strong class="keyWord">early stopping</strong>: These parameters control when to stop the training. This allows you to prevent your model from overfitting to training data.</li>
      <li class="bulletList"><strong class="keyWord">class imbalance</strong>: For <a id="_idIndexMarker1365"/>most models, this penalizes misclassifications on smaller classes in the loss function, and for tree-based models, in particular, it is used to reweight the splitting criterion. Either way, it only works with classifiers.</li>
      <li class="bulletList"><strong class="keyWord">sample weight</strong>: We leveraged this one in <em class="chapterRef">Chapter 11</em>, <em class="italic">Bias Mitigation and Causal Inference Methods</em>, to assign weights on a sample basis to mitigate bias.</li>
    </ul>
    <p class="normal">There are both classification and regression models in the headings, and they share the same parameters. Please note that scikit-learn’s <code class="inlineCode">LinearRegression</code> isn’t featured under <code class="inlineCode">LogisticRegression</code> because it doesn’t have built-in regularization. In any case, we will use only classification models in this section.</p>
    <p class="normal">Part B can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_12.png" alt="Table, calendar  Description automatically generated"/></figure>
    <p class="packt_figref"><img src="../Images/B18406_12_12.1.png" alt="Table, calendar  Description automatically generated"/></p>
    <figure class="mediaobject">Figure 12.12: Tuning parameters for tree-ensemble models</figure>
    <p class="normal"><em class="italic">Figure 12.12</em> is very similar to <em class="italic">Figure 12.11</em> except that it has a few more parameter categories that are <a id="_idIndexMarker1366"/>only available in tree ensembles, such as the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">feature sampling</strong>: This works by considering fewer features in node splits, nodes, or tree training. It is a stochastic regularization method because features are randomly selected.</li>
      <li class="bulletList"><strong class="keyWord">tree size</strong>: This constrains the tree either by maximum depth or maximum leaves, or some other parameter that restricts its growth, which, in turn, curbs overfitting.</li>
      <li class="bulletList"><strong class="keyWord">splitting</strong>: Any parameter that controls how nodes in the tree are split can indirectly impact overfitting.</li>
      <li class="bulletList"><strong class="keyWord">bagging</strong>: Also known<a id="_idIndexMarker1367"/> as <strong class="keyWord">bootstrap aggregating</strong>, this starts by bootstrapping, which involves randomly taking samples from the training data to fit weak learners. This method reduces variance and helps with overfitting, and by extension, the corresponding sampling parameters are usually prominent in hyperparameter tuning.</li>
      <li class="bulletList"><strong class="keyWord">constraints</strong>: We will explain these in further detail in the next section, but this maps how the features should be constrained to decrease or increase against the output. It can reduce overfitting in areas where data is very sparse. However, reducing overfitting is not usually the main goal, while interaction constraints can limit which features are allowed to interact.</li>
    </ul>
    <p class="normal">Please note that parameters with an asterisk (<code class="inlineCode">*</code>) in <em class="italic">Figure 12.12</em> denote those set in the <code class="inlineCode">fit</code> function as opposed to those initialized with the model. Also, except for scikit-learn’s <code class="inlineCode">RandomForest</code> models, all other parameters typically have many aliases. For these, we are using the scikit-learn wrapper functions, but all the parameters also exist in the native versions. We can’t possibly explain every model parameter here, but it is recommended that you go directly to the documentation for more insight into what each one does. The point of the section was to serve as a guide or reference.</p>
    <p class="normal">Next, we will take steps similar to what we did with the Keras model but for many different models at once, and, lastly, we will assess the best model for fairness.</p>
    <h3 id="_idParaDest-357" class="heading-3">Batch hyperparameter tuning models</h3>
    <p class="normal">OK—so, now <a id="_idIndexMarker1368"/>that we have taken a quick crash course on which levers we can pull to tune the models, let’s define a dictionary with all the models, as we’ve done in other chapters. This time, we have included a <code class="inlineCode">grid</code> with some parameter values for a grid search. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">class_mdls = {
    <span class="hljs-string">'logistic'</span>:{
        <span class="hljs-string">'model'</span>:linear_model.<span class="code-highlight"><strong class="hljs-slc">LogisticRegression</strong></span>(random_state=rand,\
                                                max_iter=<span class="hljs-number">1000</span>),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'C'</span>:np.linspace(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.49</span>, <span class="hljs-number">25</span>),
            <span class="hljs-string">'class_weight'</span>:[{<span class="hljs-number">0</span>:<span class="hljs-number">6</span>,<span class="hljs-number">1</span>:<span class="hljs-number">5</span>}],
            <span class="hljs-string">'solver'</span>:[<span class="hljs-string">'lbfgs'</span>, <span class="hljs-string">'liblinear'</span>, <span class="hljs-string">'newton-cg'</span>]
        }
     },
    <span class="hljs-string">'svc'</span>:{
        <span class="hljs-string">'model'</span>:svm.<span class="code-highlight"><strong class="hljs-slc">SVC</strong></span>(probability=<span class="hljs-literal">True</span>, random_state=rand),
        <span class="hljs-string">'grid'</span>:{<span class="hljs-string">'C'</span>:[<span class="hljs-number">15</span>,<span class="hljs-number">25</span>,<span class="hljs-number">40</span>], <span class="hljs-string">'class_weight'</span>:[{<span class="hljs-number">0</span>:<span class="hljs-number">6</span>,<span class="hljs-number">1</span>:<span class="hljs-number">5</span>}]}
    },
    <span class="hljs-string">'nu-svc'</span>:{
        <span class="hljs-string">'model'</span>:svm.<span class="code-highlight"><strong class="hljs-slc">NuSVC</strong></span>(
            probability=<span class="hljs-literal">True</span>,
            random_state=rand
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'nu'</span>:[<span class="hljs-number">0.2</span>,<span class="hljs-number">0.3</span>], <span class="hljs-string">'gamma'</span>:[<span class="hljs-number">0.6</span>,<span class="hljs-number">0.7</span>],\
            <span class="hljs-string">'class_weight'</span>:[{<span class="hljs-number">0</span>:<span class="hljs-number">6</span>,<span class="hljs-number">1</span>:<span class="hljs-number">5</span>}]}
        },
    <span class="hljs-string">'mlp'</span>:{
        <span class="hljs-string">'model'</span>:neural_network.<span class="code-highlight"><strong class="hljs-slc">MLPClassifier</strong></span>(
            random_state=rand,
            hidden_layer_sizes=(<span class="hljs-number">80</span>,),
            early_stopping=<span class="hljs-literal">True</span>
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'alpha'</span>:np.linspace(<span class="hljs-number">0.05</span>, <span class="hljs-number">0.15</span>, <span class="hljs-number">11</span>),
            <span class="hljs-string">'activation'</span>:[<span class="hljs-string">'relu'</span>,<span class="hljs-string">'tanh'</span>,<span class="hljs-string">'logistic'</span>]}
        },
        <span class="hljs-string">'rf'</span>:{
            <span class="hljs-string">'model'</span>:ensemble.<span class="code-highlight"><strong class="hljs-slc">RandomForestClassifier</strong></span>(
                random_state=rand, max_depth=<span class="hljs-number">7</span>, oob_score=<span class="hljs-literal">True</span>, \
                bootstrap=<span class="hljs-literal">True</span>
             ),
            <span class="hljs-string">'grid'</span>:{
                <span class="hljs-string">'max_features'</span>:[<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>],
                <span class="hljs-string">'max_samples'</span>:[<span class="hljs-number">0.75</span>,<span class="hljs-number">0.9</span>,<span class="hljs-number">1</span>],
                <span class="hljs-string">'class_weight'</span>:[{<span class="hljs-number">0</span>:<span class="hljs-number">6</span>,<span class="hljs-number">1</span>:<span class="hljs-number">5</span>}]}
            },
    <span class="hljs-string">'xgb-rf'</span>:{
        <span class="hljs-string">'model'</span>:xgb.<span class="code-highlight"><strong class="hljs-slc">XGBRFClassifier</strong></span>(
            seed=rand, eta=<span class="hljs-number">1</span>, max_depth=<span class="hljs-number">7</span>, n_estimators=<span class="hljs-number">200</span>
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'scale_pos_weight'</span>:[<span class="hljs-number">0.85</span>],
            <span class="hljs-string">'reg_lambda'</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">2</span>],
            <span class="hljs-string">'reg_alpha'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.75</span>,<span class="hljs-number">1</span>]}
        },
    <span class="hljs-string">'xgb'</span>:{
        <span class="hljs-string">'model'</span>:xgb.<span class="code-highlight"><strong class="hljs-slc">XGBClassifier</strong></span>(
            seed=rand, eta=<span class="hljs-number">1</span>, max_depth=<span class="hljs-number">7</span>
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'scale_pos_weight'</span>:[<span class="hljs-number">0.7</span>],
            <span class="hljs-string">'reg_lambda'</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">2</span>],
            <span class="hljs-string">'reg_alpha'</span>:[<span class="hljs-number">0.5</span>,<span class="hljs-number">0.75</span>,<span class="hljs-number">1</span>]}
        },
    <span class="hljs-string">'lgbm'</span>:{
        <span class="hljs-string">'model'</span>:lgb.<span class="code-highlight"><strong class="hljs-slc">LGBMClassifier</strong></span>(
            random_seed=rand,
            learning_rate=<span class="hljs-number">0.7</span>,
            max_depth=<span class="hljs-number">5</span>
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'lambda_l2'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">1</span>],
            <span class="hljs-string">'lambda_l1'</span>:[<span class="hljs-number">0</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">1</span>],
            <span class="hljs-string">'scale_pos_weight'</span>:[<span class="hljs-number">0.8</span>]}
        },
    <span class="hljs-string">'catboost'</span>:{
        <span class="hljs-string">'model'</span>:cb.<span class="code-highlight"><strong class="hljs-slc">CatBoostClassifier</strong></span>(
            random_seed=rand,
            depth=<span class="hljs-number">5</span>,
            learning_rate=<span class="hljs-number">0.5</span>,
            verbose=<span class="hljs-number">0</span>
        ),
        <span class="hljs-string">'grid'</span>:{
            <span class="hljs-string">'l2_leaf_reg'</span>:[<span class="hljs-number">2</span>,<span class="hljs-number">2.5</span>,<span class="hljs-number">3</span>],
            <span class="hljs-string">'scale_pos_weight'</span>:[<span class="hljs-number">0.65</span>]}
        }
}
</code></pre>
    <p class="normal">The next step is to add a <code class="inlineCode">for</code> loop to every model in the dictionary, then <code class="inlineCode">deepcopy</code> it and <code class="inlineCode">fit</code> it to produce a “base” unregularized model. Next, we produce an evaluation for it with <code class="inlineCode">evaluate_class_mdl</code> and save it into the <code class="inlineCode">fitted_class_mdls</code> dictionary we had previously created for the Keras model. Now, we need to produce the regularized version of the model. So, we do another <code class="inlineCode">deepcopy</code> and follow the same steps we took with Keras to do the <code class="inlineCode">RepeatedStratifiedKFold</code> cross-validated grid search with <code class="inlineCode">GridSearchCV</code>, and <a id="_idIndexMarker1369"/>we also evaluate in the same way, saving the results in the fitted model dictionary. The code is shown in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> mdl_name <span class="hljs-keyword">in</span> class_mdls:
    base_mdl = copy.deepcopy(class_mdls[mdl_name][<span class="hljs-string">'model'</span>])
    base_mdl = base_mdl.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(X_train, y_train)
    fitted_class_mdls[mdl_name+<span class="hljs-string">'_base'</span>] = \
        mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
            base_mdl, X_train, X_test,y_train, y_test,
            plot_roc=<span class="hljs-literal">False</span>, plot_conf_matrix=<span class="hljs-literal">False</span>,
            show_summary=<span class="hljs-literal">False</span>, ret_eval_dict=<span class="hljs-literal">True</span>
    )
    reg_mdl = copy.deepcopy(class_mdls[mdl_name][<span class="hljs-string">'model'</span>])
    grid = class_mdls[mdl_name][<span class="hljs-string">'grid'</span>]
    cv = model_selection.<span class="code-highlight"><strong class="hljs-slc">RepeatedStratifiedKFold</strong></span>(
        n_splits=<span class="hljs-number">5</span>, n_repeats=<span class="hljs-number">3</span>, random_state=rand
    )
    grid_search = model_selection.<span class="code-highlight"><strong class="hljs-slc">GridSearchCV</strong></span>(
    estimator=reg_mdl, cv=cv, param_grid=grid,
    scoring=<span class="hljs-string">'precision'</span>, n_jobs=-<span class="hljs-number">1</span>, error_score=<span class="hljs-number">0</span>, verbose=<span class="hljs-number">0</span>
    )
    grid_result = grid_search.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(X_train, y_train)
    fitted_class_mdls[mdl_name+<span class="hljs-string">'_reg'</span>] =\
        mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
            grid_result.<span class="code-highlight"><strong class="hljs-slc">best_estimator</strong></span>_, X_train, X_test, y_train,
            y_test, plot_roc=<span class="hljs-literal">False</span>,
            plot_conf_matrix=<span class="hljs-literal">False</span>, show_summary=<span class="hljs-literal">False</span>,
            ret_eval_dict=<span class="hljs-literal">True</span>
    )
    fitted_class_mdls[mdl_name+<span class="hljs-string">'_reg'</span>][<span class="hljs-string">'cv_best_params'</span>] =\
        grid_result.<span class="code-highlight"><strong class="hljs-slc">best_params</strong></span>_
</code></pre>
    <p class="normal">Once the code has finished, we can rank models by precision.</p>
    <h3 id="_idParaDest-358" class="heading-3">Evaluating models by precision</h3>
    <p class="normal">We can <a id="_idIndexMarker1370"/>extract the fitted model dictionary’s metrics and place them into a DataFrame with <code class="inlineCode">from_dict</code>. We can then sort the models by their highest test precision and color code the two columns that matter the most, which are <code class="inlineCode">precision_test</code> and <code class="inlineCode">recall_test</code>. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">class_metrics = pd.DataFrame.from_dict(fitted_class_mdls, <span class="hljs-string">'index'</span>)[
    [
        <span class="hljs-string">'accuracy_train'</span>,
        <span class="hljs-string">'accuracy_test'</span>,
        <span class="hljs-string">'precision_train'</span>,
        <span class="hljs-string">'precision_test'</span>,
        <span class="hljs-string">'recall_train'</span>,
        <span class="hljs-string">'recall_test'</span>,
        <span class="hljs-string">'</span><span class="hljs-string">roc-auc_test'</span>,
        <span class="hljs-string">'f1_test'</span>,
        <span class="hljs-string">'mcc_test'</span>
    ]
]
<span class="hljs-keyword">with</span> pd.option_context(<span class="hljs-string">'display.precision'</span>, <span class="hljs-number">3</span>):
    html = class_metrics.sort_values(
        by=<span class="hljs-string">'precision_test'</span>, ascending=<span class="hljs-literal">False</span>
    ).style.background_gradient(
        cmap=<span class="hljs-string">'plasma'</span>,subset=[<span class="hljs-string">'precision_test'</span>]
    ).background_gradient(
        cmap=<span class="hljs-string">'</span><span class="hljs-string">viridis'</span>, subset=[<span class="hljs-string">'recall_test'</span>])
html
</code></pre>
    <p class="normal">The preceding code will output the DataFrame shown in <em class="italic">Figure 12.13</em>. You can tell that regularized tree-ensemble models mostly rule the ranks, followed by their unregularized counterparts. The one exception is regularized Nu-SVC, which is number one, and its unregularized version is dead last!</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_13.png" alt="Table  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.13: Top models according to the cross-validated grid search</p>
    <p class="normal">You will find that<a id="_idIndexMarker1371"/> the Keras regularized neural network model has lower precision than regularized logistic regression, but higher recall. It’s true that we want to optimize for high precision because it impacts false positives, which we want to minimize, but precision can be at 100% and recall at 0%, and if that’s the case, your model is no good. At the same time, there’s fairness, which is about having a low false-positive rate but being equally distributed across races. So, there’s a balancing act, and chasing one metric won’t get us there.</p>
    <h3 id="_idParaDest-359" class="heading-3">Assessing fairness for the highest-performing model</h3>
    <p class="normal">To <a id="_idIndexMarker1372"/>determine how to proceed, we must first assess how our highest-performing model does in terms of fairness. We can do this with <code class="inlineCode">compare_confusion_matrices</code>. As you would do with scikit-learn’s <code class="inlineCode">confusion_matrix</code>, the first argument is the ground truth or target values (often known as <code class="inlineCode">y_true</code>), and the second is the model’s predictions (often known as <code class="inlineCode">y_pred</code>). The difference here is it takes two sets of <code class="inlineCode">y_true</code> and <code class="inlineCode">y_pred</code>, one corresponding to one segment of the observations and one to another. After these first four arguments, you give each segment a name, so this is what the following two arguments tell you. Lastly, <code class="inlineCode">compare_fpr=True</code> ensures that it will compare the <strong class="keyWord">False Positive Rate</strong> (<strong class="keyWord">FPR</strong>) between both confusion matrices. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">y_test_pred = fitted_class_mdls[<span class="hljs-string">'catboost_reg'</span>][<span class="hljs-string">'preds_test'</span>]
_ = mldatasets.<span class="code-highlight"><strong class="hljs-slc">compare_confusion_matrices</strong></span>(
    y_test[X_test.race==<span class="hljs-number">1</span>],
    y_test_pred[X_test.race==<span class="hljs-number">1</span>],
    y_test[X_test.race==<span class="hljs-number">0</span>],
    y_test_pred[X_test.race==<span class="hljs-number">0</span>],
    <span class="hljs-string">'Caucasian'</span>,
    <span class="hljs-string">'African-American'</span>,
    <span class="code-highlight"><strong class="hljs-slc">compare_fpr=</strong><strong class="hljs-literal-slc">True</strong></span>
)
y_test_pred =  fitted_class_mdls[<span class="hljs-string">'catboost_base'</span>][<span class="hljs-string">'preds_test'</span>]
_ = mldatasets.<span class="code-highlight"><strong class="hljs-slc">compare_confusion_matrices</strong></span>(
    y_test[X_test.race==<span class="hljs-number">1</span>],
    y_test_pred[X_test.race==<span class="hljs-number">1</span>],
    y_test[X_test.race==<span class="hljs-number">0</span>],
    y_test_pred[X_test.race==<span class="hljs-number">0</span>],
    <span class="hljs-string">'Caucasian'</span>,
    <span class="hljs-string">'African-American'</span>,
    <span class="code-highlight"><strong class="hljs-slc">compare_fpr=</strong><strong class="hljs-literal-slc">True</strong></span>
)
</code></pre>
    <p class="normal">The <a id="_idIndexMarker1373"/>preceding snippet outputs <em class="italic">Figure 12.14</em> and <em class="italic">Figure 12.15</em>, corresponding to the regularized and base models, respectively. You can see <em class="italic">Figure 12.14</em> here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_14.png" alt="Chart, treemap chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.14: Confusion matrices between races for the regularized CatBoost model</p>
    <p class="normal"><em class="italic">Figure 12.15</em> tells us that the FPRs are significantly lower for the regularized model. You can see <a id="_idIndexMarker1374"/>the output here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_15.png" alt="Chart, waterfall chart, treemap chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.15: Confusion matrices between races for the base CatBoost model</p>
    <p class="normal">However, the<a id="_idIndexMarker1375"/> base model in <em class="italic">Figure 12.15</em> has an FPR ratio of 1.11 compared to 1.47 for the regularized model, which is significantly more despite the similar overall metrics. But when trying to achieve several goals at once, it’s hard to evaluate and compare models, and that’s what we will do in the next section.</p>
    <h2 id="_idParaDest-360" class="heading-2">Optimizing for fairness with Bayesian hyperparameter tuning and custom metrics</h2>
    <p class="normal">Our mission is<a id="_idIndexMarker1376"/> to produce a model with high precision and good recall while maintaining fairness across different races. So, achieving this mission will require a custom metric to be designed.</p>
    <h3 id="_idParaDest-361" class="heading-3">Designing a custom metric</h3>
    <p class="normal">We could <a id="_idIndexMarker1377"/>use the F1 score, but it treats precision and recall equally, so we will have to create a weighted metric. We can also factor in how precision and recall are distributed for each race. One way to do this is by using the standard deviation, which quantifies the variation in this distribution. To that end, we will penalize precision with half the intergroup standard deviation for precision, and we can call this penalized precision. The formula is shown here:</p>
    <p class="center"><img src="../Images/B18406_12_003.png" alt="" role="presentation"/></p>
    <p class="normal">We can do the same for recall, as illustrated here:</p>
    <p class="center"><img src="../Images/B18406_12_004.png" alt="" role="presentation"/></p>
    <p class="normal">Then, we make a weighted average for penalized precision and recall where precision is worth twice as much as recall, as illustrated here:</p>
    <p class="center"><img src="../Images/B18406_12_005.png" alt="" role="presentation"/></p>
    <p class="normal">To compute this new metric, we will need to create a function that we can call <code class="inlineCode">weighted_penalized_pr_average</code>. It takes <code class="inlineCode">y_true</code> and <code class="inlineCode">y_pred</code> as the predictive performance metrics. However, it also includes <code class="inlineCode">X_group</code> with a <code class="inlineCode">pandas</code> series or array containing the values for the group, and <code class="inlineCode">group_vals</code> with a list of values that it will subset the predictions by. In this case, the group is <code class="inlineCode">race</code>, which can be values from 0 to 2. The function includes a <code class="inlineCode">for</code> loop that iterates through these possible values, subsetting the predictions by each group. That way, it can compute precision and recall for each group. After this, the rest of the function simply performs the three mathematical operations outlined previously. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="code-highlight"><strong class="hljs-title-slc">weighted_penalized_pr_average</strong></span>(<span class="hljs-params">y_true, y_pred, X_group,\</span>
<span class="hljs-params">                    group_vals, penalty_mult=</span><span class="hljs-number">0.5</span><span class="hljs-params">,\</span>
<span class="hljs-params">                    precision_mult=</span><span class="hljs-number">2</span><span class="hljs-params">,\</span>
<span class="hljs-params">                    recall_mult=</span><span class="hljs-number">1</span>):
    precision_all = metrics.<span class="code-highlight"><strong class="hljs-slc">precision_score</strong></span>(
        y_true, y_pred, zero_division=<span class="hljs-number">0</span>
    )
    recall_all = metrics.<span class="code-highlight"><strong class="hljs-slc">recall_score</strong></span>(
        y_true, y_pred, zero_division=<span class="hljs-number">0</span>
    )
    p_by_group = []
    r_by_group = []
    <span class="hljs-keyword">for</span> group_val <span class="hljs-keyword">in</span> group_vals:
        in_group = X_group==group_val
        p_by_group.append(metrics.<span class="code-highlight"><strong class="hljs-slc">precision_score</strong></span>(
            y_true[in_group], y_pred[in_group], zero_division=<span class="hljs-number">0</span>
            )
        )
        r_by_group.append(metrics.<span class="code-highlight"><strong class="hljs-slc">recall_score</strong></span>(
            y_true[in_group], y_pred[in_group], zero_division=<span class="hljs-number">0</span>
            )
        )
    precision_all = precision_all - \
                   (np.array(p_by_group).std()*penalty_mult)
    recall_all = recall_all -\
                (np.array(r_by_group).std()*penalty_mult)
    <span class="hljs-keyword">return</span> ((precision_all*precision_mult)+
            (recall_all*recall_mult))/\
            (precision_mult+recall_mult)
</code></pre>
    <p class="normal">Now, to put this function to work, we will need to run the tuning.</p>
    <h3 id="_idParaDest-362" class="heading-3">Running Bayesian hyperparameter tuning</h3>
    <p class="normal"><strong class="keyWord">Bayesian optimization</strong> is a <em class="italic">global optimization method</em> that uses the posterior distribution of black-box objective functions and their continuous parameters. In other words, it sequentially searches the best parameters to test next based on past results. Unlike grid search, it doesn’t try fixed combinations of parameters on a grid but exploits what it already knows and explores the unknown.</p>
    <p class="normal">The <code class="inlineCode">bayesian-optimization</code> library is model-agnostic. All it needs is a function and parameters with their bounds. It will explore values for those parameters within those bounds. The function takes those parameters and returns a number. This is the number, or target, that the Bayesian optimization algorithm will maximize.</p>
    <p class="normal">The following code is for the <code class="inlineCode">objective</code> function, which initializes a <code class="inlineCode">RepeatedStratifiedKFold</code> cross-validation with four splits and three repeats. It then iterates across the splits and fits the <code class="inlineCode">CatBoostClassifier</code> with them. Lastly, it computes the <code class="inlineCode">weighted_penalized_pr_average</code> custom metric for each model training and appends it to a list. Finally, the function returns the <code class="inlineCode">median</code> of the custom metric for all 12 training samples. The code is shown in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">def</span> <span class="code-highlight"><strong class="hljs-title-slc">hyp_catboost</strong></span>(<span class="hljs-params">l2_leaf_reg, scale_pos_weight</span>):
    cv = model_selection.<span class="code-highlight"><strong class="hljs-slc">RepeatedStratifiedKFold</strong></span>(
        n_splits=<span class="hljs-number">4</span>,n_repeats=<span class="hljs-number">3</span>, random_state=rand
    )
    metric_l = []
    <span class="hljs-keyword">for</span> train_index, val_index <span class="hljs-keyword">in</span> cv.split(X_train, y_train):
        X_train_cv, X_val_cv = X_train.iloc[train_index],\
                               X_train.iloc[val_index]
        y_train_cv, y_val_cv = y_train.iloc[train_index],
                               y_train.iloc[val_index]
        mdl = cb.<span class="code-highlight"><strong class="hljs-slc">CatBoostClassifier</strong></span>(
            random_seed=rand, learning_rate=<span class="hljs-number">0.5</span>, verbose=<span class="hljs-number">0</span>, depth=<span class="hljs-number">5</span>,\
            l2_leaf_reg=l2_leaf_reg, scale_pos_weight=scale_pos_weight
        )
        mdl = mdl.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(X_train_cv, y_train_cv)
        y_val_pred = mdl.<span class="code-highlight"><strong class="hljs-slc">predict</strong></span>(X_val_cv)
        metric = <span class="code-highlight"><strong class="hljs-slc">weighted_penalized_pr_average</strong></span>(
            y_val_cv,y_val_pred, X_val_cv[<span class="hljs-string">'race'</span>], <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)
        )
        metric_l.<span class="code-highlight"><strong class="hljs-slc">append</strong></span>(metric)
    <span class="hljs-keyword">return</span> np.<span class="code-highlight"><strong class="hljs-slc">median</strong></span>(np.array(metric_l))
</code></pre>
    <p class="normal">Now that the function has been defined, running the Bayesian optimization process is straightforward. First, set the parameter-bounds dictionary (<code class="inlineCode">pbounds</code>), initialize <code class="inlineCode">BayesianOptimization</code> with the <code class="inlineCode">hyp_catboost</code> function, and then run it with <code class="inlineCode">maximize</code>. The <code class="inlineCode">maximize</code> function takes <code class="inlineCode">init_points</code>, which sets how many iterations it should run initially using random exploration. Then, <code class="inlineCode">n_iter</code> is the number of optimization iterations it should perform to find the maximum value. We will set <code class="inlineCode">init_points</code> and <code class="inlineCode">n_iter</code> to <code class="inlineCode">3</code> and <code class="inlineCode">7</code>, respectively, because it could take a long time, but the larger these numbers, the better. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">pbounds = {
    <span class="hljs-string">'l2_leaf_reg'</span>: (<span class="hljs-number">2</span>,<span class="hljs-number">4</span>),
    <span class="hljs-string">'</span><span class="hljs-string">scale_pos_weight'</span>: (<span class="hljs-number">0.55</span>,<span class="hljs-number">0.85</span>)
    }
optimizer = <span class="code-highlight"><strong class="hljs-slc">BayesianOptimization</strong></span>(
    <span class="code-highlight"><strong class="hljs-slc">hyp_catboost</strong></span>,
    pbounds, 
    random_state=rand
)
optimizer.maximize(init_points=<span class="hljs-number">3</span>, n_iter=<span class="hljs-number">7</span>)
</code></pre>
    <p class="normal">Once it’s finished, you can access the best parameters, like this:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-built_in">print</span>(optimizer.<span class="hljs-built_in">max</span>[<span class="hljs-string">'params'</span>])
</code></pre>
    <p class="normal">It will return a dictionary with the parameters, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">{'l2_leaf_reg': 2.0207483077713997, 'scale_pos_weight': 0.7005623776446217}
</code></pre>
    <p class="normal">Now, let’s fit a model with these parameters and evaluate it.</p>
    <h3 id="_idParaDest-363" class="heading-3">Fitting and evaluating a model with the best parameters</h3>
    <p class="normal">Initializing <code class="inlineCode">CatBoostClassifier</code> with these parameters is as simple as passing the <code class="inlineCode">best_params</code> dictionary as an argument. Then, all you need to do is <code class="inlineCode">fit</code> the model and evaluate it (<code class="inlineCode">evaluate_class_mdl</code>). The code is shown in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">cb_opt = cb.<span class="code-highlight"><strong class="hljs-slc">CatBoostClassifier</strong></span>(
    random_seed=rand,
    depth=<span class="hljs-number">5</span>,
    learning_rate=<span class="hljs-number">0.5</span>,
    verbose=<span class="hljs-number">0</span>,
    **optimizer.<span class="hljs-built_in">max</span>[<span class="hljs-string">'params'</span>]
)
cb_opt = cb_opt.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(X_train, y_train)
fitted_class_mdls[<span class="hljs-string">'catboost_opt'</span>] = mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
    cb_opt,
    X_train,
    X_test,
    y_train,
    y_test,
    plot_roc=<span class="hljs-literal">False</span>,
    plot_conf_matrix=<span class="hljs-literal">True</span>,
    <span class="code-highlight"><strong class="hljs-slc">ret_eval_dict=</strong><strong class="hljs-literal-slc">True</strong></span>
)
</code></pre>
    <p class="normal">The preceding snippet outputs the following predictive performance metrics:</p>
    <pre class="programlisting con"><code class="hljs-con">Accuracy_train:  0.9652		Accuracy_test:   0.8192
Precision_test:  0.8330		Recall_test:     0.8058
ROC-AUC_test:    0.8791		F1_test:         0.8192
</code></pre>
    <p class="normal">They are the highest <code class="inlineCode">Accuracy_test</code>, <code class="inlineCode">Precision_test</code>, and <code class="inlineCode">Recall_test</code> metrics we have achieved so far. Let’s now see how the model fares with fairness using <code class="inlineCode">compare_confusion_matrices</code>. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">y_test_pred = fitted_class_mdls[<span class="hljs-string">'catboost_opt'</span>][<span class="hljs-string">'preds_test'</span>]
_ = mldatasets.<span class="code-highlight"><strong class="hljs-slc">compare_confusion_matrices</strong></span>(
    y_test[X_test.race==<span class="hljs-number">1</span>],
    y_test_pred[X_test.race==<span class="hljs-number">1</span>],
    y_test[X_test.race==<span class="hljs-number">0</span>],
    y_test_pred[X_test.race==<span class="hljs-number">0</span>],
    <span class="hljs-string">'Caucasian'</span>,
    <span class="hljs-string">'African-American'</span>,
    <span class="code-highlight"><strong class="hljs-slc">compare_fpr=</strong><strong class="hljs-literal-slc">True</strong></span>
)
</code></pre>
    <p class="normal">The preceding code outputs <em class="italic">Figure 12.16</em>, which shows some of the best fairness metrics we have obtained so far, as you can see here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_16.png" alt="Chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.16: Comparison of confusion matrices between races for the optimized CatBoost model</p>
    <p class="normal">These results are good, but we cannot be completely assured that the model is not racially biased because the feature is still there. One way to measure its impact is through feature importance methods.</p>
    <h3 id="_idParaDest-364" class="heading-3">Examining racial bias through feature importance</h3>
    <p class="normal">Although CatBoost is our best-performing model in most metrics, including accuracy, precision, and F1 score, we are moving forward with XGBoost because CatBoost doesn’t support interaction constraints, which we will implement in the next section. But first, we will compare them both in terms of what they found important. Also, <strong class="keyWord">SHapley Additive exPlanations</strong> (<strong class="keyWord">SHAP</strong>) values provide a robust means to measure and visualize feature importance, so let’s compute them for our optimized CatBoost and regularized XGBoost models. To do so, we need to initialize <code class="inlineCode">TreeExplainer</code> with each model and then use <code class="inlineCode">shap_values</code> to produce the values for each, as illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">fitted_cb_mdl = fitted_class_mdls[<span class="hljs-string">'catboost_opt'</span>][<span class="hljs-string">'fitted'</span>]
shap_cb_explainer = shap.<span class="code-highlight"><strong class="hljs-slc">TreeExplainer</strong></span>(fitted_cb_mdl)
shap_cb_values = shap_cb_explainer.<span class="code-highlight"><strong class="hljs-slc">shap_values</strong></span>(X_test)
fitted_xgb_mdl = fitted_class_mdls[<span class="hljs-string">'xgb_reg'</span>][<span class="hljs-string">'fitted'</span>]
shap_xgb_explainer = shap.<span class="code-highlight"><strong class="hljs-slc">TreeExplainer</strong></span>(fitted_xgb_mdl)
shap_xgb_values = shap_xgb_explainer.<span class="code-highlight"><strong class="hljs-slc">shap_values</strong></span>(X_test)
</code></pre>
    <p class="normal">Next, we can generate two <code class="inlineCode">summary_plot</code> plots side by side, using Matplotlib’s <code class="inlineCode">subplot</code>, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">ax0 = plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
shap.<span class="code-highlight"><strong class="hljs-slc">summary_plot</strong></span>(
    <span class="code-highlight"><strong class="hljs-slc">shap_xgb_values</strong></span>,
    X_test,
    plot_type=<span class="hljs-string">"dot"</span>,
    plot_size=<span class="hljs-literal">None</span>,
    show=<span class="hljs-literal">False</span>
)
ax0.set_title(<span class="hljs-string">"XGBoost SHAP Summary"</span>)
ax1 = plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
shap.<span class="code-highlight"><strong class="hljs-slc">summary_plot</strong></span>(
    <span class="code-highlight"><strong class="hljs-slc">shap_cb_values</strong></span>,
    X_test,
    plot_type=<span class="hljs-string">"dot"</span>,
    plot_size=<span class="hljs-literal">None</span>,
    show=<span class="hljs-literal">False</span>
)
ax1.set_title(<span class="hljs-string">"Catboost SHAP Summary"</span>)
</code></pre>
    <p class="normal">The preceding snippet generates <em class="italic">Figure 12.17</em>, which shows how similar CatBoost and XGBoost are. This similarity shouldn’t be surprising because, after all, they are both gradient-boosted decision trees. The bad news is that <code class="inlineCode">race</code> is in the top four for both. However, the prevalence of the shade that corresponds to lower feature values on the right suggests that African American (<code class="inlineCode">race=0</code>) negatively correlates with recidivism.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_17.png" alt="" role="presentation"/></figure>
    <p class="packt_figref">Figure 12.17: SHAP summary plot for the regularized XGBoost and optimized CatBoost models</p>
    <p class="normal">In<a id="_idIndexMarker1378"/> any case, it makes sense to remove <code class="inlineCode">race</code> from the training data, but we must first ascertain why the model thinks this is a critical feature. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">shap_xgb_interact_values =\
                shap_xgb_explainer.shap_interaction_values(X_test)
</code></pre>
    <p class="normal">In <em class="chapterRef">Chapter 4</em>, <em class="italic">Global Model-Agnostic Interpretation Methods</em>, we discussed assessing interaction effects. It’s time to revisit this topic, but this time, we will extract SHAP’s interaction values (<code class="inlineCode">shap_interaction_values</code>) instead of using SHAP’s dependence plots. We can easily rank SHAP interactions with a <code class="inlineCode">summary_plot</code> plot. A SHAP summary plot is very informative, but it’s not nearly as intuitive as a heatmap for interactions. To generate a heatmap with labels, we must place the <code class="inlineCode">shap_xgb_interact_values</code> summed on the first axis in a DataFrame, then name the columns and rows (<code class="inlineCode">index</code>) with the names of the features. The rest is simply using Seaborn’s <code class="inlineCode">heatmap</code> function to plot the DataFrame as a heatmap. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">shap_xgb_interact_avgs = np.<span class="hljs-built_in">abs</span>(
    <span class="code-highlight"><strong class="hljs-slc">shap_xgb_interact_values</strong></span>
).mean(<span class="hljs-number">0</span>)
np.fill_diagonal(shap_xgb_interact_avgs, <span class="hljs-number">0</span>)
shap_xgb_interact_df = pd.<span class="code-highlight"><strong class="hljs-slc">DataFrame</strong></span>(shap_xgb_interact_avgs)
shap_xgb_interact_df.columns = X_test.columns
shap_xgb_interact_df.index = X_test.columns
sns.<span class="code-highlight"><strong class="hljs-slc">heatmap</strong></span>(shap_xgb_interact_df, cmap=<span class="hljs-string">'Blues'</span>, annot=<span class="hljs-literal">True</span>,\
            annot_kws={<span class="hljs-string">'size'</span>:<span class="hljs-number">13</span>}, fmt=<span class="hljs-string">'.2f'</span>, linewidths=<span class="hljs-number">.5</span>)
</code></pre>
    <p class="normal">The <a id="_idIndexMarker1379"/>preceding code produced the heatmap shown in <em class="italic">Figure 12.18</em>. It demonstrates how <code class="inlineCode">race</code> interacts most heavily with <code class="inlineCode">length_of_stay</code>, <code class="inlineCode">age_group</code>, and <code class="inlineCode">priors per year</code>. These interactions would, of course, disappear once we removed <code class="inlineCode">race</code>. However, given this finding, careful consideration ought to be given if these features don’t have racial bias built in. Research supports the need for <code class="inlineCode">age_group</code> and <code class="inlineCode">priors_per_year</code>, which leaves <code class="inlineCode">length_of_stay</code> as a candidate for scrutiny. We won’t do this in this chapter, but it’s certainly food for thought:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_18.png" alt="Graphical user interface, application  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.18: Heatmap with SHAP interaction values for the regularized XGBoost model</p>
    <p class="normal">Another<a id="_idIndexMarker1380"/> interesting insight from <em class="italic">Figure 12.18</em> is how features can be clustered. You can draw a box around the lower-right quadrant between <code class="inlineCode">c_charge_degree </code>and <code class="inlineCode">priors_per_year</code> because, once we remove <code class="inlineCode">race</code>, most of the interaction will be located here. There are many benefits to limiting troubling interactions. For instance, why should all the juvenile delinquency features, such as <code class="inlineCode">juv_fel_count</code>, interact with <code class="inlineCode">age_group</code>? Why should <code class="inlineCode">sex</code> interact with <code class="inlineCode">length_of_stay</code>? Next, we will learn how to place a fence around the lower-right quadrant, limiting interactions between those <a id="_idIndexMarker1381"/>features with <strong class="keyWord">interaction constraints</strong>. We will also ensure monotonicity for <code class="inlineCode">priors_per_year</code> with <strong class="keyWord">monotonic constraints</strong>.</p>
    <h1 id="_idParaDest-365" class="heading-1">Implementing model constraints</h1>
    <p class="normal">We will <a id="_idIndexMarker1382"/>discuss how to implement constraints first with XGBoost and all popular tree ensembles, for that matter, because the parameters are named the same (see <em class="italic">Figure 12.12</em>). Then, we will do so with TensorFlow Lattice. But before we move forward with any of that, let’s remove <code class="inlineCode">race</code> from the data, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">X_train_con = X_train.<span class="code-highlight"><strong class="hljs-slc">drop</strong></span>([<span class="hljs-string">'race'</span>], axis=<span class="hljs-number">1</span>).copy()
X_test_con = X_test.<span class="code-highlight"><strong class="hljs-slc">drop</strong></span>([<span class="hljs-string">'race'</span>], axis=<span class="hljs-number">1</span>).copy()
</code></pre>
    <p class="normal">Now, with <code class="inlineCode">race</code> out of the picture, the model may still have some bias. However, the feature engineering we performed and the constraints we will place can help align the model against them, given the double standards we found in <em class="chapterRef">Chapter 6</em><em class="italic">, Anchors and Counterfactual Explanations</em>. That being said, the resulting model might perform worse against the test data. There are two reasons for this, outlined here:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Loss of information</strong>: Race, especially through interaction with other features, impacted the outcome, so it unfortunately carried some information.</li>
      <li class="bulletList"><strong class="keyWord">Misalignment between reality and policy-driven ideals</strong>: This occurs when the main reason to enforce these constraints is to ensure that the model not only complies with domain knowledge but also ideals, and these might not be evident in the data. We must remember that a whole host of institutional racism could have tainted the ground truth. The model reflects the data, but the data reflects reality on the ground, which is itself biased.</li>
    </ul>
    <p class="normal">With that in mind, let’s get started with constraint implementation!</p>
    <h2 id="_idParaDest-366" class="heading-2">Constraints for XGBoost</h2>
    <p class="normal">We will <a id="_idIndexMarker1383"/>take three simple steps in this section. We<a id="_idIndexMarker1384"/> will first define our training parameters, then train and evaluate a constrained model, and, lastly, examine the effects of the constraints.</p>
    <h3 id="_idParaDest-367" class="heading-3">Setting regularization and constraint parameters</h3>
    <p class="normal">We take the best <a id="_idIndexMarker1385"/>parameters for our regularized XGBoost model with <code class="inlineCode">print(fitted_class_mdls['xgb_reg']['cv_best_params'])</code>. They are in the <code class="inlineCode">best_xgb_params</code> dictionary, along with <code class="inlineCode">eta</code> and <code class="inlineCode">max_depth</code>. Then, to enforce monotonic constraints on <code class="inlineCode">priors_per_year</code>, we must first know its position and the direction of the monotonic correlation. From <em class="italic">Figure 12.8</em>, we know the answers to both questions. It is the last feature, and <a id="_idIndexMarker1386"/>the correlation is positive, so the <code class="inlineCode">mono_con</code> tuple should have nine items, with the last one being a <code class="inlineCode">1</code> and the rest <code class="inlineCode">0</code>s. As for interaction constraints, we will only allow the last five features to interact with each other, and the same goes for the first four. The <code class="inlineCode">interact_con</code> tuple is a list of lists that reflects these constraints. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="code-highlight"><strong class="hljs-slc">best_xgb_params</strong></span> = {<span class="hljs-string">'eta'</span>: <span class="hljs-number">0.3</span>, <span class="hljs-string">'max_depth'</span>: <span class="hljs-number">28</span>,\
                   <span class="hljs-string">'reg_alpha'</span>: <span class="hljs-number">0.2071</span>, <span class="hljs-string">'reg_lambda'</span>: <span class="hljs-number">0.6534</span>,\
                   <span class="hljs-string">'scale_pos_weight'</span>: <span class="hljs-number">0.9114</span>}
<span class="code-highlight"><strong class="hljs-slc">mono_con</strong></span> = (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)
<span class="code-highlight"><strong class="hljs-slc">interact_con</strong></span> = [[<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>],[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]]
</code></pre>
    <p class="normal">Next, we will train and evaluate the XGBoost model with these constraints.</p>
    <h3 id="_idParaDest-368" class="heading-3">Training and evaluating the constrained model</h3>
    <p class="normal">We will now train and <a id="_idIndexMarker1387"/>evaluate our constrained model. First, we initialize the <code class="inlineCode">XGBClassifier</code> model with our constraint and<a id="_idIndexMarker1388"/> regularization parameters and then fit it using training data that lacks the <code class="inlineCode">race</code> feature (<code class="inlineCode">X_train_con</code>). We then evaluate the predictive performance with <code class="inlineCode">evaluate_class_mdl</code> and compare fairness with <code class="inlineCode">compare_confusion_matrices</code>, as we have done before. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">xgb_con = xgb.XGBClassifier(
    seed=rand,monotone_constraints=<span class="code-highlight"><strong class="hljs-slc">mono_con</strong></span>,\
    interaction_constraints=<span class="code-highlight"><strong class="hljs-slc">interact_con</strong></span>, <span class="code-highlight"><strong class="hljs-slc">**best_xgb_params</strong></span>
)
xgb_con = xgb_con.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(X_train_con, y_train)
fitted_class_mdls[<span class="hljs-string">'xgb_con'</span>] = mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
    xgb_con, X_train_con, X_test_con, y_train, y_test,\
    plot_roc=<span class="hljs-literal">False</span>, ret_eval_dict=<span class="hljs-literal">True</span>
)
y_test_pred = fitted_class_mdls[<span class="hljs-string">'xgb_con'</span>][<span class="hljs-string">'preds_test'</span>]
_ = mldatasets.<span class="code-highlight"><strong class="hljs-slc">compare_confusion_matrices</strong></span>(
    y_test[X_test.race==<span class="hljs-number">1</span>],
    y_test_pred[X_test.race==<span class="hljs-number">1</span>],
    y_test[X_test.race==<span class="hljs-number">0</span>],
    y_test_pred[X_test.race==<span class="hljs-number">0</span>],
    <span class="hljs-string">'Caucasian'</span>,
    <span class="hljs-string">'African-American'</span>,
     <span class="code-highlight"><strong class="hljs-slc">compare_fpr=</strong><strong class="hljs-literal-slc">True</strong></span>
)
</code></pre>
    <p class="normal">The <a id="_idIndexMarker1389"/>preceding snippet produces the confusion matrix pair in <em class="italic">Figure 12.19</em> and some predictive performance metrics. If we<a id="_idIndexMarker1390"/> compare the matrices to those in <em class="italic">Figure 12.16</em>, racial disparities, as measured by our FPR ratio, took a hit. Also, predictive performance is lower than the optimized CatBoost model across the board, by 2–4%. We could likely increase these metrics a bit by performing the same <em class="italic">Bayesian hyperparameter tuning</em> on this model.</p>
    <p class="normal">The confusion matrix output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_19.png" alt="Chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.19: Comparison of confusion matrices between races for the constrained XGBoost model</p>
    <p class="normal">One thing to consider is that, although racial inequity is a primary concern of this chapter, we also want to ensure that the model is optimal in other ways. As stated before, it’s a balancing act. For instance, it’s only fitting that defendants with the most <code class="inlineCode">priors_per_year</code> are riskier than those with the least, and we ensured this with monotonic constraints. Let’s verify these outcomes!</p>
    <h3 id="_idParaDest-369" class="heading-3">Examining constraints</h3>
    <p class="normal">An <a id="_idIndexMarker1391"/>easy way to observe the constraints in action is to plot a SHAP <code class="inlineCode">summary_plot</code>, as we did in <em class="italic">Figure 12.17</em>, but this time, we will only plot one. Have a look at the following ode snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">fitted_xgb_con_mdl = fitted_class_mdls[<span class="hljs-string">'xgb_con'</span>][<span class="hljs-string">'fitted'</span>]
shap_xgb_con_explainer = shap.<span class="code-highlight"><strong class="hljs-slc">TreeExplainer</strong></span>(fitted_xgb_con_mdl)
shap_xgb_con_values = shap_xgb_con_explainer.<span class="code-highlight"><strong class="hljs-slc">shap_values</strong></span>(
    X_test_con
)
shap.<span class="code-highlight"><strong class="hljs-slc">summary_plot</strong></span>(
    shap_xgb_con_values, X_test_con, plot_type=<span class="hljs-string">"dot"</span>
)
</code></pre>
    <p class="normal">The preceding code produces <em class="italic">Figure 12.20</em>. This demonstrates how <code class="inlineCode">priors_per_year</code> from left to right is a cleaner gradient, which means that lower values are consistently having a negative impact, and the higher ones a positive one—as they should!</p>
    <p class="normal">You can see the output here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_20.png" alt="Chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.20: SHAP summary plot for the constrained XGBoost model</p>
    <p class="normal">Next, let’s<a id="_idIndexMarker1392"/> examine the <code class="inlineCode">age_group</code> versus <code class="inlineCode">priors_per_year</code> interaction we saw through the lens of the data in <em class="italic">Figure 12.7</em>. We can also use <code class="inlineCode">plot_prob_contour_map</code> for models by adding extra arguments, as follows:</p>
    <ul>
      <li class="bulletList">The fitted model (<code class="inlineCode">fitted_xgb_con_mdl</code>)</li>
      <li class="bulletList">The DataFrame to use for inference with the model (<code class="inlineCode">X_test_con</code>)</li>
      <li class="bulletList">The names of the two columns in the DataFrame to compare on each axis (<code class="inlineCode">x_col</code> and <code class="inlineCode">y_col</code>)</li>
    </ul>
    <p class="normal">The outcome is an interaction partial dependence plot, like those shown in <em class="chapterRef">Chapter 4</em>, <em class="italic">Global Model-Agnostic Interpretation Methods</em>, except that it uses the dataset (<code class="inlineCode">recidivism_df</code>) to create the histograms for each axis. We will create two such plots right now for<a id="_idIndexMarker1393"/> comparison—one for the regularized XGBoost model and another for the constrained one. The code for this can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_contour_map</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age_group</strong></span>, recidivism_df.<span class="code-highlight"><strong class="hljs-slc">priors_per_year</strong></span>,
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">is_recid</strong></span>, x_intervals=ordenc.categories_[<span class="hljs-number">2</span>],
    y_intervals=<span class="hljs-number">6</span>, use_quantiles=<span class="hljs-literal">True</span>, xlabel=<span class="hljs-string">'Age Group'</span>,
    ylabel=<span class="hljs-string">'Priors Per Year'</span>, model=<span class="code-highlight"><strong class="hljs-slc">fitted_xgb_mdl</strong></span>,
    X_df=<span class="code-highlight"><strong class="hljs-slc">X_test</strong></span>,x_col=<span class="hljs-string">'age_group'</span>,y_col=<span class="hljs-string">'priors_per_year'</span>,
    title=<span class="hljs-string">'</span><span class="hljs-string">Probability of Recidivism by Age/Priors per Year \</span>
          <span class="hljs-string">(according to XGBoost Regularized Model)'</span>
)
mldatasets.<span class="code-highlight"><strong class="hljs-slc">plot_prob_contour_map</strong></span>(
    recidivism_df.<span class="code-highlight"><strong class="hljs-slc">age_group</strong></span>, recidivism_df.<span class="code-highlight"><strong class="hljs-slc">priors_per_year</strong></span>,
    recidivism_df.is_recid, x_intervals=ordenc.categories_[<span class="hljs-number">2</span>],
    y_intervals=<span class="hljs-number">6</span>, use_quantiles=<span class="hljs-literal">True</span>, xlabel=<span class="hljs-string">'Age Group'</span>,
    ylabel=<span class="hljs-string">'Priors Per Year'</span>, model=<span class="code-highlight"><strong class="hljs-slc">fitted_xgb_con_mdl</strong></span>,
    X_df=<span class="code-highlight"><strong class="hljs-slc">X_test_con</strong></span>,x_col=<span class="hljs-string">'age_group'</span>,y_col=<span class="hljs-string">'priors_per_year'</span>,
    title=<span class="hljs-string">'(according to XGBoost Constrained Model)'</span>
)
</code></pre>
    <p class="normal">The preceding code produces the plots shown in <em class="italic">Figure 12.21</em>. It shows that the regularized XGBoost model reflects the data (see <em class="italic">Figure 12.7</em>). On the other hand, the constrained XGBoost model smoothened and simplified the contours, as can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_21.png" alt="Chart, diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.21: Recidivism probability contour map for age_group and priors_per_year according to XGBoost regularized and constrained models</p>
    <p class="normal">Next, we can <a id="_idIndexMarker1394"/>generate the SHAP interaction values heatmap from <em class="italic">Figure 12.18</em> but for the constrained model. The code is the same but uses the <code class="inlineCode">shap_xgb_con_explainer</code> SHAP explainer and <code class="inlineCode">X_test_con</code> data. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">shap_xgb_interact_values =\
        shap_xgb_con_explainer.<span class="code-highlight"><strong class="hljs-slc">shap_interaction_values</strong></span>(X_test_con)
shap_xgb_interact_df =\
        pd.<span class="code-highlight"><strong class="hljs-slc">DataFrame</strong></span>(np.<span class="hljs-built_in">sum</span>(<span class="code-highlight"><strong class="hljs-slc">shap_xgb_interact_values</strong></span>, axis=<span class="hljs-number">0</span>))
shap_xgb_interact_df.columns = X_test_con.columns
shap_xgb_interact_df.index = X_test_con.columns
sns.<span class="code-highlight"><strong class="hljs-slc">heatmap</strong></span>(
    shap_xgb_interact_df, cmap=<span class="hljs-string">'RdBu'</span>, annot=<span class="hljs-literal">True</span>,
    annot_kws={<span class="hljs-string">'size'</span>:<span class="hljs-number">13</span>}, fmt=<span class="hljs-string">'.0f'</span>, linewidths=<span class="hljs-number">.5</span>
)
</code></pre>
    <p class="normal">The preceding snippet outputs the heatmap shown in <em class="italic">Figure 12.22</em>. It shows how the interaction constraints were effective because of zeros in the lower-left and lower-right quadrants, which correspond to interactions between the two groups of features we separated. If we compare with <em class="italic">Figure 12.18</em>, we can also tell how the constraints shifted the most salient interactions, making <code class="inlineCode">age_group</code> and <code class="inlineCode">length_of_stay</code> by far the most important ones.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_22.png" alt="A picture containing application  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.22: Heatmap with SHAP interaction values for the constrained XGBoost model</p>
    <p class="normal">Now, let’s see<a id="_idIndexMarker1395"/> how TensorFlow implements monotonicity and other “shape constraints” via TensorFlow Lattice.</p>
    <h2 id="_idParaDest-370" class="heading-2">Constraints for TensorFlow Lattice</h2>
    <p class="normal">Neural <a id="_idIndexMarker1396"/>networks can be very efficient in finding <a id="_idIndexMarker1397"/>an optimal solution for the <code class="inlineCode">loss</code> function. The loss is tied to a consequence we wish to predict. In this case, that would be 2-year recidivism. In ethics, a <em class="italic">utilitarian</em> (or <em class="italic">consequentialist</em>) view of fairness has no problem with this as long as the model’s training data isn’t biased. Yet a <em class="italic">deontological</em> view is that ethical principles or policies drive ethical questions and supersede consequences. Inspired <a id="_idIndexMarker1398"/>by this, <strong class="keyWord">TensorFlow Lattice</strong> (<strong class="keyWord">TFL</strong>) can embody ethical principles in models as model shape constraints.</p>
    <p class="normal">A<a id="_idIndexMarker1399"/> lattice <a id="_idIndexMarker1400"/>is an <strong class="keyWord">interpolated lookup table</strong>, which<a id="_idIndexMarker1401"/> is a grid that approximates inputs to outputs through interpolation. In high-dimensional space, these grids become hypercubes. The mappings of each input to output are constrained<a id="_idIndexMarker1402"/> through <strong class="keyWord">calibration layers</strong>, and they support many kinds of constraints—not just monotonicity. <em class="italic">Figure 12.23</em> shows this here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_23.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.23: Some of the constraints supported by TensorFlow Lattice</p>
    <p class="normal"><em class="italic">Figure 12.23</em> shows several shape constraints. The first three are applied to a single feature (<em class="italic">x</em>) constraining the <img src="../Images/B18406_12_006.png" alt="" role="presentation"/> line, representing the output. The last two are applied to a pair of features (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1 </sub>and <em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>) constraining the color-coded contour map (<img src="../Images/B18406_12_007.png" alt="" role="presentation"/>). A brief explanation for each follows:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Monotonicity</strong>: This makes<a id="_idIndexMarker1403"/> the function (<img src="../Images/B18406_12_008.png" alt="" role="presentation"/>) always increase (1) or decrease (-1) against the input (<em class="italic">x</em>).</li>
      <li class="bulletList"><strong class="keyWord">Convexity</strong>: This forces<a id="_idIndexMarker1404"/> the function (<img src="../Images/B18406_12_009.png" alt="" role="presentation"/>) to be convex (1) or concave (-1) against the input (<em class="italic">x</em>). Convexity can be mixed with monotonicity to have an effect like the one in <em class="italic">Figure 12.23</em>.</li>
      <li class="bulletList"><strong class="keyWord">Unimodality</strong>: This<a id="_idIndexMarker1405"/> is like monotonicity, except that it goes in both directions, allowing the function (<img src="../Images/B18406_12_010.png" alt="" role="presentation"/>) to have a single valley (1) or peak (-1).</li>
      <li class="bulletList"><strong class="keyWord">Trust</strong>: This forces one<a id="_idIndexMarker1406"/> monotonic feature (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>) to rely on another one (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>). The example in <em class="italic">Figure 12.23</em> is <strong class="keyWord">Edgeworth Trust</strong>, but <a id="_idIndexMarker1407"/>there’s also<a id="_idIndexMarker1408"/> a <strong class="keyWord">Trapezoid Trust</strong> variation with a different shape constraint.</li>
      <li class="bulletList"><strong class="keyWord">Dominance</strong>: Monotonic <a id="_idIndexMarker1409"/>dominance constrains one monotonic (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">1</sub>) feature to define the direction of the slope or effects when compared to another (<em class="italic">x</em><sub class="subscript-italic" style="font-style: italic;">2</sub>). An alternative, range dominance, is similar, except both features are monotonic.</li>
    </ul>
    <p class="normal">Neural networks<a id="_idIndexMarker1410"/> are particularly prone to<a id="_idIndexMarker1411"/> overfitting, and the levers for controlling it are comparably more difficult. For instance, exactly what combination of hidden nodes, dropout, weight regularization, and epochs will lead to an acceptable level of overfitting is challenging to tell. On the other hand, moving a single parameter in a tree-based model, tree depth, in one direction will likely lower overfitting to an acceptable level, albeit it might require many different parameters to make it optimal.</p>
    <p class="normal">Enforcing shape constraints not only increases interpretability but also regularizes the model because it simplifies the function. TFL also supports different kinds of penalty-based regularization on a per-feature basis or to the calibration layer’s kernel, leveraging L1 and L2 penalties via <strong class="keyWord">Laplacian</strong>, <strong class="keyWord">Hessian</strong>, <strong class="keyWord">Torsion</strong>, and <strong class="keyWord">Wrinkle</strong> regularizers. These<a id="_idIndexMarker1412"/> regularizers <a id="_idIndexMarker1413"/>have the effect of making<a id="_idIndexMarker1414"/> functions <a id="_idIndexMarker1415"/>more flat, linear, or smooth. We won’t explain them but it suffices to say that there is regularization to cover many use cases.</p>
    <p class="normal">There <a id="_idIndexMarker1416"/>are also<a id="_idIndexMarker1417"/> several ways to implement the framework—too many to elaborate here! Yet, it’s important to point out that this example is just one of a handful of ways of implementing it. TFL comes with <a id="_idIndexMarker1418"/>built-in <strong class="keyWord">canned estimators</strong> that abstract some of the configurations. You can also create a <strong class="keyWord">custom estimator</strong> using <a id="_idIndexMarker1419"/>the TFL layers. For Keras, you can either use <strong class="keyWord">premade models</strong> or <a id="_idIndexMarker1420"/>build a Keras model with TensorFlow Lattice layers. This last one is what we will do next!</p>
    <h3 id="_idParaDest-371" class="heading-3">Initializing the model and Lattice inputs</h3>
    <p class="normal">We <a id="_idIndexMarker1421"/>will now create a series of <em class="italic">input layers</em>, which each include a single feature. These connect to <em class="italic">calibration layers</em>, which make each<a id="_idIndexMarker1422"/> input fit into a <strong class="keyWord">Piece-Wise Linear </strong>(<strong class="keyWord">PWL</strong>) function<a id="_idIndexMarker1423"/> that complies with individual constraints and regularizations, except for <code class="inlineCode">sex</code>, which will use categorical calibration. The calibration layers all feed into a multidimensional <em class="italic">Lattice layer</em>, producing output via a <em class="italic">Dense layer</em> with <em class="italic">sigmoid</em> activation. This description can be a lot to take in, so feel free to skip ahead to <em class="italic">Figure 12.24</em> to get some visual aid.</p>
    <p class="normal">Incidentally, there are<a id="_idIndexMarker1424"/> many kinds of layers available that you can connect to produce a <strong class="keyWord">Deep Lattice Network</strong> (<strong class="keyWord">DLN</strong>), including the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Linear</strong> for linear functions between more than one input, including those with dominance shape constraints.</li>
      <li class="bulletList"><strong class="keyWord">Aggregation</strong> to perform an aggregation function on more than one input.</li>
      <li class="bulletList"><strong class="keyWord">Parallel combination</strong> to place many calibration layers within a single function, making it compatible with Keras <code class="inlineCode">Sequential</code> layers.</li>
    </ul>
    <p class="normal">We won’t use any of these layers in this example, but perhaps knowing this will inspire you to explore the TensorFlow Lattice library further. Anyway, back to this example!</p>
    <p class="normal">The first thing to define is <code class="inlineCode">lattice_sizes</code>, which is a tuple that corresponds to a number of vertices per dimension. We have one dimension per feature in the chosen architecture, so we need to choose nine numbers greater than or equal to two. Features with less <a id="_idIndexMarker1425"/>cardinality for categorical features or inflection points for continuous ones warrant fewer <a id="_idIndexMarker1426"/>vertices. However, we might also want to restrict a feature’s expressiveness by purposely choosing an even smaller number of vertices. For instance, <code class="inlineCode">juv_fel_count</code> has 10 unique values, but we will assign only two vertices to it. <code class="inlineCode">lattice_sizes</code> is shown here:</p>
    <pre class="programlisting code"><code class="hljs-code">lattice_sizes = [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>]
</code></pre>
    <p class="normal">Next, we initialize two lists, one to place all the input layers (<code class="inlineCode">model_inputs</code>) and another for the calibration layers (<code class="inlineCode">lattice_inputs</code>). Then, for each feature, one by one, we define an input layer with <code class="inlineCode">tf.keras.layers.Input</code> and a calibration layer with either categorical calibration (<code class="inlineCode">tfl.layers.CategoricalCalibration</code>) or PWL calibration (<code class="inlineCode">tfl.layers.PWLCalibration</code>). Both input and calibration layers will be appended to their respective lists for each feature. What happens inside the calibration layer depends on the feature. All PWL calibrations use <code class="inlineCode">input_keypoints</code>, which asks where the PWL function should be segmented. Sometimes, this is best answered with fixed widths (<code class="inlineCode">np.linspace</code>), and other times with fixed frequency (<code class="inlineCode">np.quantile</code>). Categorical calibration instead uses buckets (<code class="inlineCode">num_buckets</code>) that correspond to the number of categories. All calibrators have the following arguments:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">output_min</code>: The minimum output for the calibrator</li>
      <li class="bulletList"><code class="inlineCode">output_max</code>: The maximum output for the calibrator—always has to match the output minimum + lattice size - 1</li>
      <li class="bulletList"><code class="inlineCode">monotonicity</code>: Whether it should monotonically constrain the PWL function, and if so, how</li>
      <li class="bulletList"><code class="inlineCode">kernel_regularizer</code>: How to regularize the function</li>
    </ul>
    <p class="normal">In addition to these arguments, <code class="inlineCode">convexity</code> and <code class="inlineCode">is_cyclic</code> (for monotonic unimodal) can modify the constraint shape. Have a look at the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">model_inputs = []
lattice_inputs = []
sex_input = <span class="code-highlight"><strong class="hljs-slc">tf.keras.layers.Input</strong></span>(shape=[<span class="hljs-number">1</span>], name=<span class="hljs-string">'sex'</span>)
lattice_inputs.append(<span class="code-highlight"><strong class="hljs-slc">tfl.layers.CategoricalCalibration</strong></span>(
    name=<span class="hljs-string">'sex_calib'</span>,
    num_buckets=<span class="hljs-number">2</span>,
    output_min=<span class="hljs-number">0.0</span>,
    output_max=lattice_sizes[<span class="hljs-number">0</span>] - <span class="hljs-number">1.0</span>,
    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=<span class="hljs-number">0.001</span>),
    kernel_initializer=<span class="hljs-string">'constant'</span>)(sex_input)
)
model_inputs.append(sex_input)
juvf_input = <span class="code-highlight"><strong class="hljs-slc">tf.keras.layers.Input</strong></span>(shape=[<span class="hljs-number">1</span>],\
                                   name=<span class="hljs-string">'juv_fel_count'</span>)
lattice_inputs.append(<span class="code-highlight"><strong class="hljs-slc">tfl.layers.PWLCalibration</strong></span>(
    name=<span class="hljs-string">'juvf_calib'</span>,
    <span class="code-highlight"><strong class="hljs-slc">monotonicity</strong></span>=<span class="hljs-string">'none'</span>,
    input_keypoints=np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">20</span>, num=<span class="hljs-number">5</span>, dtype=np.float32),
    output_min=<span class="hljs-number">0.0</span>,
    output_max=lattice_sizes[<span class="hljs-number">1</span>] - <span class="hljs-number">1.0</span>,\
    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=<span class="hljs-number">0.001</span>),
    kernel_initializer=<span class="hljs-string">'equal_slopes'</span>)(juvf_input)
)
model_inputs.append(juvf_input)
age_input = <span class="code-highlight"><strong class="hljs-slc">tf.keras.layers.Input</strong></span>(shape=[<span class="hljs-number">1</span>], name=<span class="hljs-string">'age_group'</span>)
lattice_inputs.append(<span class="code-highlight"><strong class="hljs-slc">tfl.layers.PWLCalibration</strong></span>(
    name=<span class="hljs-string">'age_calib'</span>,
    <span class="code-highlight"><strong class="hljs-slc">monotonicity</strong></span>=<span class="hljs-string">'none'</span>,
    input_keypoints=np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">6</span>, num=<span class="hljs-number">7</span>, dtype=np.float32),
    output_min=<span class="hljs-number">0.0</span>,
    output_max=lattice_sizes[<span class="hljs-number">7</span>] - <span class="hljs-number">1.0</span>,
    kernel_regularizer=(<span class="hljs-string">'hessian'</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1e-4</span>))(age_input)
)
model_inputs.append(age_input)
priors_input = <span class="code-highlight"><strong class="hljs-slc">tf.keras.layers.Input</strong></span>(shape=[<span class="hljs-number">1</span>],\
                                     name=<span class="hljs-string">'priors_per_year'</span>)
lattice_inputs.append(<span class="code-highlight"><strong class="hljs-slc">tfl.layers.PWLCalibration</strong></span>(
    name=<span class="hljs-string">'priors_calib'</span>,
    <span class="code-highlight"><strong class="hljs-slc">monotonicity</strong></span>=<span class="hljs-string">'increasing'</span>,
    input_keypoints=np.quantile(X_train_con[<span class="hljs-string">'priors_per_year'</span>],
                                np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, num=<span class="hljs-number">7</span>)),
    output_min=<span class="hljs-number">0.0</span>,
    output_max=lattice_sizes[<span class="hljs-number">8</span>]-<span class="hljs-number">1.0</span>)(priors_input))
model_inputs.append(priors_input)
</code></pre>
    <p class="normal">So, we<a id="_idIndexMarker1427"/> now<a id="_idIndexMarker1428"/> have a list with <code class="inlineCode">model_inputs</code> and another with calibration layers, which will be the input to the lattice (<code class="inlineCode">lattice_inputs</code>). All we need to do now is tie these together to a lattice.</p>
    <h3 id="_idParaDest-372" class="heading-3">Building a Keras model with TensorFlow Lattice layers</h3>
    <p class="normal">We already<a id="_idIndexMarker1429"/> have the first two building blocks of this model connected. Now, let’s create the last two building blocks, starting with the lattice (<code class="inlineCode">tfl.layers.Lattice</code>). As arguments, it takes <code class="inlineCode">lattice_sizes</code>, output minimums and maximums, and <code class="inlineCode">monotonicities</code> it should enforce. Note that the last item, <code class="inlineCode">priors_per_year</code>, has monotonicity set as <code class="inlineCode">increasing</code>. The lattice layer then feeds into the final piece, which is the <code class="inlineCode">Dense</code> layer with <code class="inlineCode">sigmoid</code> activation. The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">lattice = <span class="code-highlight"><strong class="hljs-slc">tfl.layers.Lattice</strong></span>(
    name=<span class="hljs-string">'lattice'</span>,
    lattice_sizes=<span class="code-highlight"><strong class="hljs-slc">lattice_sizes</strong></span>,
    <span class="code-highlight"><strong class="hljs-slc">monotonicities</strong></span>=[
        <span class="hljs-string">'</span><span class="hljs-string">none'</span>, <span class="hljs-string">'none'</span>, <span class="hljs-string">'none'</span>, <span class="hljs-string">'none'</span>, <span class="hljs-string">'none'</span>,
        <span class="hljs-string">'none'</span>, <span class="hljs-string">'none'</span>, <span class="hljs-string">'none'</span>, <span class="code-highlight"><strong class="hljs-string-slc">'increasing'</strong></span>
    ],
    output_min=<span class="hljs-number">0.0</span>, output_max=<span class="hljs-number">1.0</span>)(<span class="code-highlight"><strong class="hljs-slc">lattice_inputs</strong></span>)
model_output = tf.keras.layers.<span class="code-highlight"><strong class="hljs-slc">Dense</strong></span>(<span class="hljs-number">1</span>, name=<span class="hljs-string">'output'</span>,
                                     activation=<span class="hljs-string">'sigmoid'</span>)(lattice)
</code></pre>
    <p class="normal">The first two building blocks as <code class="inlineCode">inputs</code> can now get connected with the last two as <code class="inlineCode">outputs</code> with <code class="inlineCode">tf.keras.models.Model</code>. And voilà! We now have a fully formed model, with the code shown here:</p>
    <pre class="programlisting code"><code class="hljs-code">tfl_mdl = <span class="code-highlight"><strong class="hljs-slc">tf.keras.models.Model</strong></span>(inputs=model_inputs,
                                outputs=model_output)
</code></pre>
    <p class="normal">You can always run <code class="inlineCode">tfl_mdl.summary()</code> to get an idea of how all the layers connect, but it’s not as intuitive as using <code class="inlineCode">tf.keras.utils.plot_model</code>, which is illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">tf.keras.utils.plot_model(tfl_mdl, rankdir=<span class="hljs-string">'LR'</span>)
</code></pre>
    <p class="normal">The preceding code generates the model diagram shown here in <em class="italic">Figure 12.24</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_24.png" alt="Diagram  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.24: A diagram of the Keras model with TFL layers</p>
    <p class="normal">Next, we<a id="_idIndexMarker1430"/> need to compile the model. We will use a <code class="inlineCode">binary_crossentropy</code> loss function and an <code class="inlineCode">Adam</code> optimizer, and employ accuracy<a id="_idIndexMarker1431"/> and <strong class="keyWord">Area Under the Curve </strong>(<strong class="keyWord">AUC</strong>) as metrics, as illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">tfl_mdl.<span class="code-highlight"><strong class="hljs-built_in-slc">compile</strong></span>(
    loss=<span class="hljs-string">'binary_crossentropy'</span>,
    optimizer=tf.keras.optimizers.Adam(lr=<span class="hljs-number">0.001</span>),
    metrics=[<span class="hljs-string">'accuracy'</span>,tf.keras.metrics.AUC(name=<span class="hljs-string">'auc'</span>)]
)
</code></pre>
    <p class="normal">We are almost<a id="_idIndexMarker1432"/> ready to go now! What follows next is the very last step.</p>
    <h3 id="_idParaDest-373" class="heading-3">Training and evaluating the model</h3>
    <p class="normal">If you<a id="_idIndexMarker1433"/> take one hard look at <em class="italic">Figure 12.24</em>, you’ll notice that the model doesn’t have one input layer but nine, so this means that we must split our training and test data into nine parts. We can use <code class="inlineCode">np.split</code> to do <a id="_idIndexMarker1434"/>this, which will yield a list of nine NumPy arrays. As for the labels, TFL doesn’t accept arrays with a single dimension. With <code class="inlineCode">expand_dims</code>, we convert their shapes from <code class="inlineCode">(N,)</code> to <code class="inlineCode">(N,1)</code>, as illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">X_train_expand = np.<span class="code-highlight"><strong class="hljs-slc">split</strong></span>(
    X_train_con.values.astype(np.float32),
    indices_or_sections=<span class="hljs-number">9</span>,
    axis=<span class="hljs-number">1</span>
)
y_train_expand = np.<span class="code-highlight"><strong class="hljs-slc">expand_dims</strong></span>(
    y_train.values.astype(np.float32),
    axis=<span class="hljs-number">1</span>
)
X_test_expand = np.<span class="code-highlight"><strong class="hljs-slc">split</strong></span>(
    X_test_con.values.astype(np.float32),
    indices_or_sections=<span class="hljs-number">9</span>,
    axis=<span class="hljs-number">1</span>)
y_test_expand = np.<span class="code-highlight"><strong class="hljs-slc">expand_dims</strong></span>(
    y_test.values.astype(np.float32),
    axis=<span class="hljs-number">1</span>
)
</code></pre>
    <p class="normal">Now comes the training! To prevent overfitting, we can use <code class="inlineCode">EarlyStopping</code> by monitoring the validation AUC (<code class="inlineCode">val_auc</code>). And to account for class imbalance, in the <code class="inlineCode">fit</code> function, we<a id="_idIndexMarker1435"/> use <code class="inlineCode">class_weight</code>, as <a id="_idIndexMarker1436"/>illustrated in the following code snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">es = tf.keras.callbacks.<span class="code-highlight"><strong class="hljs-slc">EarlyStopping</strong></span>(
    monitor=<span class="hljs-string">'</span><span class="code-highlight"><strong class="hljs-string-slc">val_auc</strong></span><span class="hljs-string">'</span>,
    mode=<span class="hljs-string">'max'</span>,
    patience=<span class="hljs-number">40</span>,
    restore_best_weights=<span class="hljs-literal">True</span>
)
tfl_history = tfl_mdl.<span class="code-highlight"><strong class="hljs-slc">fit</strong></span>(
    X_train_expand,
    y_train_expand,
    <span class="code-highlight"><strong class="hljs-slc">class_weight</strong></span>={<span class="hljs-number">0</span>:<span class="hljs-number">18</span>, <span class="hljs-number">1</span>:<span class="hljs-number">16</span>},
    batch_size=<span class="hljs-number">128</span>,
    epochs=<span class="hljs-number">300</span>,
    validation_split=<span class="hljs-number">0.2</span>,
    shuffle=<span class="hljs-literal">True</span>,
    callbacks=[<span class="code-highlight"><strong class="hljs-slc">es</strong></span>]
)
</code></pre>
    <p class="normal">Once the model has been trained, we can use <code class="inlineCode">evaluate_class_mdl</code> to output a quick summary of predictive performance, as we have before, and then <code class="inlineCode">compare_confusion_matrices</code> to examine fairness, as we did previously. The code is shown in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code">fitted_class_mdls[<span class="hljs-string">'tfl_con'</span>] = mldatasets.<span class="code-highlight"><strong class="hljs-slc">evaluate_class_mdl</strong></span>(
    tfl_mdl,
    X_train_expand,
    X_test_expand,
    y_train.values.astype(np.float32),
    y_test.values.astype(np.float32),
    plot_roc=<span class="hljs-literal">False</span>,
    ret_eval_dict=<span class="hljs-literal">True</span>
)
y_test_pred = fitted_class_mdls[<span class="hljs-string">'tfl_con'</span>][<span class="hljs-string">'preds_test'</span>]
_ = mldatasets.<span class="code-highlight"><strong class="hljs-slc">compare_confusion_matrices</strong></span>(
    y_test[X_test.race==<span class="hljs-number">1</span>],
    y_test_pred[X_test.race==<span class="hljs-number">1</span>],
    y_test[X_test.race==<span class="hljs-number">0</span>],
    y_test_pred[X_test.race==<span class="hljs-number">0</span>],
    <span class="hljs-string">'Caucasian'</span>,
    <span class="hljs-string">'African-American'</span>,
    compare_fpr=<span class="hljs-literal">True</span>
)
</code></pre>
    <p class="normal">The preceding <a id="_idIndexMarker1437"/>snippet produced the confusion matrices in <em class="italic">Figure 12.25</em>. The TensorFlow Lattice model <a id="_idIndexMarker1438"/>performs much better than the regularized Keras model, yet the FPR ratio is better than the constrained XGBoost model. It must be noted that XGBoost’s parameters were previously tuned. With TensorFlow Lattice, a lot could be done to improve FPR, including using a custom loss function or better early-stopping metrics that somehow account for racial disparities.</p>
    <p class="normal">The output can be seen here:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_25.png" alt="Chart, treemap chart  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.25: Comparison of confusion matrices between races for the constrained TensorFlow Lattice model</p>
    <p class="normal">Next, we will make some conclusions based on what was learned in this chapter and determine if we accomplished the mission.</p>
    <h1 id="_idParaDest-374" class="heading-1">Mission accomplished</h1>
    <p class="normal">It’s often the data that takes the blame for a poor-performing, uninterpretable, or biased model, and that can be true, but many different things can be done in the preparation and model development stages to improve it. To offer an analogy, it’s like baking a cake. You need quality ingredients, yes. But seemingly small differences in the preparation of these ingredients and baking itself—such as the baking temperature, the container used, and time—can make a huge difference. Hell! Even things that are out of your control, such as atmospheric pressure or moisture, can impact baking! Even after it’s all finished, how many different ways can you assess the quality of a cake?</p>
    <p class="normal">This chapter is about these many details, and, as with baking, they are <strong class="keyWord">part exact science</strong> and<strong class="keyWord"> part art form</strong>. The concepts discussed in this chapter also have far-reaching consequences, especially regarding how to optimize a problem that doesn’t have a single goal and has profound societal implications. One possible approach is to combine metrics and account for imbalances. To that end, we have created a metric: a weighted average of precision recall that penalizes racial inequity, and we can efficiently compute it for all of our models and place it into the model dictionary (<code class="inlineCode">fitted_class_mdls</code>). Then, as we have done before, we put it into a DataFrame and output it but, this time, sort by the custom metric (<code class="inlineCode">wppra_test</code>). The code can be seen in the following snippet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> mdl_name <span class="hljs-keyword">in</span> fitted_class_mdls:
    fitted_class_mdls[mdl_name][<span class="hljs-string">'wppra_test'</span>] =\
    <span class="code-highlight"><strong class="hljs-slc">weighted_penalized_pr_average</strong></span>(
        y_test,
        fitted_class_mdls[mdl_name][<span class="hljs-string">'preds_test'</span>],
        X_test[<span class="hljs-string">'race'</span>],
        <span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)
    )
class_metrics = pd.<span class="code-highlight"><strong class="hljs-slc">DataFrame.from_dict</strong></span>(fitted_class_mdls, <span class="hljs-string">'index'</span>)[
    [<span class="hljs-string">'precision_test'</span>, <span class="hljs-string">'recall_test'</span>, <span class="hljs-string">'wppra_test'</span>]
]
<span class="hljs-keyword">with</span> pd.option_context(<span class="hljs-string">'display.precision'</span>, <span class="hljs-number">3</span>):
    html = class_metrics.<span class="code-highlight"><strong class="hljs-slc">sort_values</strong></span>(
        by=<span class="hljs-string">'</span><span class="code-highlight"><strong class="hljs-string-slc">wppra_test</strong></span><span class="hljs-string">'</span>,
        ascending=<span class="hljs-literal">False</span>
        ).style.background_gradient(
           cmap=<span class="hljs-string">'plasma'</span>,subset=[<span class="hljs-string">'precision_test'</span>]
        ).background_gradient(
           cmap=<span class="hljs-string">'viridis'</span>, subset=[<span class="hljs-string">'recall_test'</span>])
html
</code></pre>
    <p class="normal">The preceding code produced the DataFrame shown here in <em class="italic">Figure 12.26</em>:</p>
    <figure class="mediaobject"><img src="../Images/B18406_12_26.png" alt="Table  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 12.26: Top models in this chapter when sorted by weighted penalized precision-recall average custom metric</p>
    <p class="normal">In <em class="italic">Figure 12.26</em>, it’s tempting to propose one of the models at the very top. However, they were trained with <code class="inlineCode">race</code> as a feature and didn’t account for proven criminal justice <em class="italic">realities</em>. However, the highest-performing constrained model—the XGBoost one (<code class="inlineCode">xgb_con</code>)—lacked <code class="inlineCode">race</code>, ensured that <code class="inlineCode">priors_per_year</code> is monotonic and that <code class="inlineCode">age_group</code> isn’t allowed to interact with juvenile delinquency features, and it did all this while significantly improving predictive performance when compared to the original model. It is fairer, too, because it reduced the ratio of the FPR between the privileged and underprivileged groups from 1.84x (<em class="italic">Figure 6.2 </em>from <em class="chapterRef">Chapter 6</em>, <em class="italic">Anchors and Counterfactual Explanations</em>) to 1.39x (<em class="italic">Figure 12.19</em>). It’s not perfect, but it’s a massive improvement!</p>
    <p class="normal">The mission was to prove that accuracy and domain knowledge could coexist with progress toward fairness, and we have completed it successfully. That being said, there’s still room for improvement. Therefore, the plan of action would have to showcase the constrained XGBoost model to your client and continue improving and building more constrained models. The unconstrained ones should only serve as a benchmark.</p>
    <p class="normal">You can make substantial fairness improvements if you combine the methods from this chapter with those learned in <em class="chapterRef">Chapter 11</em>, <em class="italic">Bias Mitigation and Causal Inference Methods</em>. We didn’t incorporate them into this chapter, to focus solely on model (or in-processing) methods that are typically not seen as part of the bias-mitigation toolkit, but they very much can assist to that end, not to mention model-tuning methods that serve to make a model more reliable.</p>
    <h1 id="_idParaDest-375" class="heading-1">Summary</h1>
    <p class="normal">After reading this chapter, you should now understand how to leverage data engineering to enhance interpretability, regularization to reduce overfitting, and constraints to comply with policies. The primary end goals are to place guardrails and curb the complexity that hinders interpretability.</p>
    <p class="normal">In the next chapter, we will look at ways to enhance model reliability through adversarial robustness.</p>
    <h1 id="_idParaDest-376" class="heading-1">Dataset sources</h1>
    <ul>
      <li class="bulletList">ProPublica Data Store (2019). <em class="italic">COMPAS Recidivism Risk Score Data and Analysis</em>. Originally retrieved from <a href="https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis"><span class="url">https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis</span></a></li>
    </ul>
    <h1 id="_idParaDest-377" class="heading-1">Further reading</h1>
    <ul>
      <li class="bulletList">Hastie, T. J., Tibshirani, R. J. and Friedman, J. H. (2001). <em class="italic">The elements of statistical learning</em>. Springer-Verlag, New York, USA</li>
      <li class="bulletList">Wang, S. &amp; Gupta, M. (2020). <em class="italic">Deontological Ethics By Monotonicity Shape Constraints</em>. AISTATS. <a href="https://arxiv.org/abs/2001.11990"><span class="url">https://arxiv.org/abs/2001.11990</span></a></li>
      <li class="bulletList">Cotter, A., Gupta, M., Jiang, H., Ilan, E. L., Muller, J., Narayan, T., Wang, S. &amp; Zhu, T. (2019). <em class="italic">Shape Constraints for Set Functions</em>. ICML. <a href="http://proceedings.mlr.press/v97/cotter19a.html"><span class="url">http://proceedings.mlr.press/v97/cotter19a.html</span></a></li>
      <li class="bulletList">Gupta, M. R., Cotter A., Pfeifer, J., Voevodski, K., Canini, K., Mangylov, A., Moczydlowski, W. and van Esbroeck, A. (2016). <em class="italic">Monotonic Calibrated Interpolated Look-Up Tables. Journal of Machine Learning Research</em> 17(109):1−47. <a href="https://arxiv.org/abs/1505.06378"><span class="url">https://arxiv.org/abs/1505.06378</span></a></li>
      <li class="bulletList">Noble, S. (2018). <em class="italic">Algorithms of oppression: data discrimination in the age of Google</em>. NYU Press</li>
    </ul>
    <h1 class="heading-1">Learn more on Discord</h1>
    <p class="normal">To join the Discord community for this book – where you can share feedback, ask the author questions, and learn about new releases – follow the QR code below:</p>
    <p class="normal"><a href="Chapter_12.xhtml"><span class="url">https://packt.link/inml</span></a></p>
    <p class="normal"><img src="../Images/QR_Code107161072033138125.png" alt="" role="presentation"/></p>
  </div>
</body></html>