- en: '*Chapter 5*: Exploratory Data Analysis with DataRobot'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will cover tasks related to exploring and analyzing your
    dataset with DataRobot. DataRobot performs many functions that you will need to
    perform this analysis, but it is still up to you to make sense of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned how to utilize DataRobot
    to perform **exploratory data analysis** (**EDA**). In this chapter, we''re going
    to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data ingestion and data cataloging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data quality assessment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EDA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the target feature and correlation analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data ingestion and data cataloging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our datasets ready, we have two choices to bring them into
    DataRobot. We can go to either the **Create New Project / Drag Dataset** page
    (*Figure 1.5*) or the **AI Catalog** page (*Figure 1.17*). If the dataset is relatively
    small, we may prefer to start with the **Create New Project** method. After a
    few iterations, when the dataset has stabilized, you can move it into the **AI
    Catalog** page so that it can be reused in other projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by uploading our automobile dataset as a local file that we created
    in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087), *Preparing Data
    for DataRobot*. You can name the project `Automobile Example 1`, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Uploading dataset for a new project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.1_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – Uploading dataset for a new project
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that DataRobot automatically starts analyzing the data and performs
    a quick exploratory analysis. You can see that it found `30` features and `205`
    rows of data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: If you are using an Excel file that has multiple sheets, make sure that the
    data you want is in the first sheet.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DataRobot will also perform a data quality assessment and notify you if it
    finds any data issues, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Data quality issues'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.2_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – Data quality issues
  prefs: []
  type: TYPE_NORMAL
- en: In this case, it has found outliers in eight features. You can look into the
    details to see if these look acceptable or if you need to drop or otherwise fix
    these outliers. We will do this as we explore and analyze each of these features
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that it also looked for any disguised missing values or excess zeros
    in any feature. These can be hard to detect manually and can be problematic for
    your models, so it is important to fix these issues if they come up. For example,
    you saw in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087), *Preparing
    Data for DataRobot,* that we already fixed the issue of excess zeros in the `normalized-losses`
    feature. If we had not done that previously, DataRobot would alert us to fix this
    or filter out those rows before proceeding. It will also perform additional analysis
    once a target feature is selected.
  prefs: []
  type: TYPE_NORMAL
- en: You will carry out the same process with the Appliances Energy dataset.
  prefs: []
  type: TYPE_NORMAL
- en: EDA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you saw in the previous section, DataRobot automatically performed an initial
    analysis of the dataset. Let''s see how we will review this data and gain insights
    from it. If you scroll down the page, you will see a table of features and an
    overview of their characteristics, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Data analysis overview'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.3_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Data analysis overview
  prefs: []
  type: TYPE_NORMAL
- en: You can see that in this table, DataRobot has computed and listed any data quality
    concerns regarding a feature, what type of variable it is, how many unique values
    are in the dataset, and how many values are missing. These are all very important
    characteristics, and you need to review all of them to make sure that you understand
    what they are telling you.
  prefs: []
  type: TYPE_NORMAL
- en: For example, is the variable type selected by DataRobot what you expected? If
    you look at `num_of_doors`, you will notice that this is categorical. Even though
    this is correct because the data contained is in the form of text, you know that
    this is really numbers. You might want to fix this (just as we did for `num_of_cylinders`
    in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087), *Preparing Data
    for DataRobot*). Doing this ahead of time will reduce rework and wasted effort
    downstream. Similarly, you will notice that `num_of_doors` has two missing values.
    If this number were higher, we would have tried to address the missing values,
    as discussed in [*Chapter 4*](B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087),
    *Preparing Data for DataRobot*. Also, pay attention to unique values. For some
    features, we expect many unique values, while for others, we do not. Check if
    what DataRobot found is consistent with your expectations. If not, try to determine
    the reason for this. Pay special attention when a categorical variable has a large
    number of unique values. We will soon discuss how to address this issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'For numeric features, you will also see summary statistics such as **Mean**,
    **Median**, **Std Dev** (for standard deviation), **Min**, and **Max**. Review
    these for each feature to see if they all look reasonable. If you click on any
    feature row, it will expand and show more detail, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Feature details for "symboling"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.4_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – Feature details for "symboling"
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you can see a histogram of all the values. You can now see how this data
    is distributed. One aspect to pay special attention to is the area where you don''t
    have much data. For example, you can see that the amount of training data available
    for the value `-2` is very limited, so we should expect there to be problems trying
    to predict these values. Now, let''s look at the details of `normalized_losses`
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Feature details for "normalized_losses"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.5_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – Feature details for "normalized_losses"
  prefs: []
  type: TYPE_NORMAL
- en: 'In this view, we can see that there seem to be very few losses around `make`
    feature to see how it is distributed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Feature details for "make"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.6_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – Feature details for "make"
  prefs: []
  type: TYPE_NORMAL
- en: 'Since `make` is a categorical feature, you can see how frequently each value
    shows up. Remember that we had already consolidated some car types that had very
    little data into `other`. If we hadn''t done that, we would notice here that some
    types have very few data points and need to be addressed or they will not do well
    during training. Let''s look at `fuel_type` to see what we can glean from this
    data, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Feature details for "fuel_type"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.7_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – Feature details for "fuel_type"
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we notice that `diesel` cars are not well represented, and this might
    be normal for cars. Anytime we see such imbalances, we should try to see if they
    can be addressed. Now, when we look at the `engine_location` feature, as shown
    in the following screenshot, we see that we have a problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Feature details for engine_location'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.8_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.8 – Feature details for engine_location
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the preceding screenshot, the `rear` feature is barely registering
    on the dataset. From a practical standpoint, what this means is that the algorithms
    will ignore this feature. If you did not look carefully, you might assume that
    `engine_location` has no impact on your target, but as you can tell from this
    screenshot, our dataset is not large enough to make that determination. Let''s
    now look in the following screenshot at `engine_type` to see what we find here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Feature details for "engine_type"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.9_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.9 – Feature details for "engine_type"
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we find that one type dominates and some of the types are barely
    represented. Looking at this distribution, you might want to create another feature
    where you transform this into a binary value, `ohc` and **1** for every other
    type. This will also create some balance in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please bear in mind that this might or might not prove to be useful. You have
    to try it out in your models and see what works. Let''s now look in the following
    screenshot at `num_of_cylinders` and `cylinder_count`, a feature that we created
    during data preparation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – Feature details for "num_of_cylinders" and "cylinder_count"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.10_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.10 – Feature details for "num_of_cylinders" and "cylinder_count"
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, even though it is the same data, transforming the values provides
    a different impression compared to what you get when you first look at the histograms.
    The numeric values are a more accurate representation of the data and should result
    in a better model compared to the categorical values.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, we have highlighted what DataRobot provides automatically and what
    kinds of insights can be gained by looking at the graphs generated by DataRobot.
    We are now ready to set our target feature and do additional analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the target feature and correlation analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By the time you reach this stage, you should already have a pretty good idea
    of the problem you are trying to solve and what should be the target feature.
    It is not unusual to use different features as targets for different use cases.
    Also, sometimes you will set a transformed feature as a target (for example, log
    of a feature). For the Automobile dataset, we want to predict the **price** of
    cars. Once you select the target feature, as shown in the following screenshot,
    it will analyze that feature and provide some recommendations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Setting target feature'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.11_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.11 – Setting target feature
  prefs: []
  type: TYPE_NORMAL
- en: You can see from the preceding screenshot that it is showing how the price is
    distributed. DataRobot also cautions that some of the target values are missing.
    Ideally, we would filter out the rows with missing target values before uploading
    the dataset. You will also notice that DataRobot has characterized this as a regression
    problem. Another thing to note is that it has picked the optimization metric to
    be **Gamma Deviance**. You can read more about this metric in [*Chapter 2*](B17159_02_Final_NM_ePub.xhtml#_idTextAnchor039),
    *Machine Learning Basics*, or you can explore it in more detail in DataRobot's
    help sections. For now, it looks like a good choice, given the wide variance of
    price values.
  prefs: []
  type: TYPE_NORMAL
- en: Before we click on the **Start** button, we should explore the advanced options.
    The reason for this is that once you click the **Start** button, you cannot make
    changes to the options. Having said that, it is often hard to make all the right
    choices without completely understanding the data. One way to overcome this issue
    is to ignore the advanced options for now and go ahead with the exploration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we know what we want, we can create a new project and select the appropriate
    options. You can see that this is an iterative process, and we will often try
    something and come back and redo some of it. Also, notice that **Modeling Mode**
    in *Figure 5.11* is set to **Quick**. This is normally a good choice to get started.
    With that in mind, we can actually skip the options and go ahead and click the
    **Start** button. You will notice that DataRobot will get started on performing
    additional analysis, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12 – Feature analysis'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.12_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.12 – Feature analysis
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice that in addition to performing additional analysis, DataRobot
    will actually start building the models. This might be surprising since we are
    still doing analysis, but fear not—these are not the final models. Let DataRobot
    build these models, as some of these will provide useful insights into our data.
    We will most likely discard these models later on, but they will prove useful
    in our journey. Once DataRobot has finished doing all the tasks, you will see
    an **Autopilot has finished** message, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Initial analysis complete'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.13_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.13 – Initial analysis complete
  prefs: []
  type: TYPE_NORMAL
- en: 'You will now notice that DataRobot has populated an **Importance** column for
    all the features. This is the relative importance of a feature in reference to
    the target feature. We can also check to see if there are additional data quality
    issues that have been found. For that, let''s click on the **View info** dropdown
    in the **Data Quality Assessment** box. You will then see the options, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Data Quality Assessment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.14_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.14 – Data Quality Assessment
  prefs: []
  type: TYPE_NORMAL
- en: 'We saw some of the issues previously, but we now see that there are features
    that potentially have target leakage. If target leakage exists, we will filter
    those features out. By looking at the warning signs associated with each feature,
    we discover that these features are `horsepower` and `engine_size`. Since these
    are important features and have an obvious impact on price, we will retain these
    features. We also see another warning symbol in the header row, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Missing target values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.15_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.15 – Missing target values
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on the symbol, we see that DataRobot has already filtered out rows
    where the price is missing. This is good, as it means we don''t have to recreate
    our dataset and upload it again into DataRobot. You will also notice in the following
    screenshot that a new tab called **Feature Associations** is now present at the
    top left of the screen. This is a critical tab for our data analysis task. Let''s
    click on this tab to look at what DataRobot has found:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Feature Association'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.16_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.16 – Feature Association
  prefs: []
  type: TYPE_NORMAL
- en: DataRobot calls these *associations* instead of *correlations*, and the reason
    is that DataRobot uses `engine` that includes a group of tightly correlated features
    such as `engine_size`, `bore`, `cylinder_size`, and `stroke`. Understanding these
    relationships as a collective can be very important to solving a business problem.
    In this particular case, it tells you that you cannot modify one of these in isolation.
  prefs: []
  type: TYPE_NORMAL
- en: Changing the bore will affect many other features, even if your model does not
    end up with those features. Ignoring these aspects is what typically leads to
    downstream problems, so please pay special attention to these relationships.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can gain additional insights by sorting the associations by their importance,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Feature associations sorted by importance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.17_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.17 – Feature associations sorted by importance
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding screenshot shows the features sorted by their impact on the target
    feature. This tells you which features are most likely to be prominent in your
    model. One thing to look for is how this lines up with the causal model that you
    built during the problem understanding stage. Is it consistent? If not, where
    are the differences and surprises? These typically lead to new insights into your
    problem. It is also useful to look at the MI values in totality. For this, you
    can click on the `.csv` file. You can then analyze them in tools such as Excel,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.18 – MI values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.18_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.18 – MI values
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives you a better feel for the relative scale of these values. In this
    view, we can see that aspiration has very little impact on price. This seems a
    little counterintuitive and merits some additional investigation. For this, we
    can look at this association in more detail by clicking on the `price` and `aspiration`
    to see the association details, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Association pair details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.19_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.19 – Association pair details
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see that for the same value of `aspiration`, the price can vary
    quite a bit. Still, we can see that on average, `turbo` has a higher price. Based
    on this, we will keep it in the mix for modeling. We should also discuss with
    the domain experts to see why it is not correlating in a stronger fashion with
    `price`. These discussions can lead to creating other features that might clarify
    this relationship. On the other hand, the relationship between `price` and `num_of_doors`
    doesn't look very interesting.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is a good idea to review the association pairs to see what insights can
    be gained. At a minimum, review the ones with very high or very low values. Specifically,
    look for non-linear relationships. For example, let''s look at the association
    between `curb_weight` and `highway_mpg`, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Association between curb_weight and highway_mpg'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.20_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.20 – Association between curb_weight and highway_mpg
  prefs: []
  type: TYPE_NORMAL
- en: Here, you will notice that as `curb_weight` increases, the **miles per gallon**
    (**MPG**) value decreases, which makes intuitive sense. We also see that the curve
    starts flattening at higher weights. This could be due to many reasons, as other
    factors affecting MPG do not increase with weight.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that while this may or may not affect the predictive accuracy of the model,
    understanding these relationships is key to determining actions to be taken based
    on the model. For example, weight reduction might not provide much MPG benefit
    for weights larger than `curb_weight` and `drive _wheels`, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Association between curb_weight and drive_wheels'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.21_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.21 – Association between curb_weight and drive_wheels
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we can see that `curb_weight` is impacted by the
    choice of `drive_wheels`. It is possible that if we use both these features in
    our model, the model will give a much higher preference to `curb_weight` and might
    find not much value in using `drive_wheels`. Business users might therefore interpret
    `drive_wheels` as not very important.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this is not true since `curb_weight` is itself influenced by
    `drive_wheels`. It has been observed that an accurate model can sometimes give
    a false impression if you are not careful. DataRobot can do this analysis and
    produce these graphs, but it is up to you to understand and interpret these correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look again at some of the individual feature graphs we looked at before.
    For this, let''s look at the feature details shown in *Figure 5.13* and click
    on `curb_weight`. This will show us details about the feature, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Feature details for curb_weight'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.22_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.22 – Feature details for curb_weight
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice that we now have some more information in this graph. Specifically,
    we can now see how price varies with `curb_weight` as well as how the `curb_weight`
    value is distributed. Looking at these relationships can give you additional insights
    into your problem, especially when the relationship is non-linear. For example,
    let''s look at the details for `highway_mpg` in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Feature details for highway_mpg'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.23_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – Feature details for highway_mpg
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the price drops exponentially as the MPG value increases. Given
    this non-linearity, which also seems to be present in other features, it might
    be useful to try creating a new target feature by taking a log of the price. Similarly,
    by looking at the other features, you can get ideas on feature transformations
    that might prove beneficial. Some of you might be wondering why we should do this
    since the new algorithms can handle non-linearity. While that is true, it is still
    better to transform your non-linear problems if it makes sense from a business-understanding
    perspective. Also, it allows the algorithm to focus its computational energy in
    other areas that might otherwise be overlooked.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have understood the features and have transformed them as needed,
    we can focus on selecting a feature set to start the modeling process.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The basic idea behind feature selection is to select features that show high
    importance for the target. In addition, we want to remove any features that are
    highly cross-correlated (or have high MI values) to other features. The selected
    set of features are represented as feature lists in DataRobot. If you click on
    the **Feature Lists** menu on the top left of the page, as shown in the following
    screenshot, you will see the feature lists that DataRobot has created for the
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – Feature Lists'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.24_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.24 – Feature Lists
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, you will see a list that contains all the raw features, ones that have
    selections based on univariate analysis (that is, analysis of features one at
    a time), and also ones that have the most important features. The **DR Reduced
    Features M8** list or the **Univariate Selections** list look like good starting
    points. Click on the **Project Data** menu to go back to the data view. Now, let''s
    inspect the univariate list by selecting **Univariate Selections** from the **Feature
    List** dropdown, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25 – Selecting a feature list'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.25_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.25 – Selecting a feature list
  prefs: []
  type: TYPE_NORMAL
- en: You can now inspect the list of features that have been selected. You can modify
    this list and create new feature lists by dropping any features that you do not
    want to include in this list. As you can see, DataRobot has done much of the feature
    selection for you to get things started. You can remove some more now, or you
    can remove them in the next iteration after you have built an initial set of models.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, DataRobot has already built some models with some of these lists,
    which we will explore in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to bring data into DataRobot. We learned how
    to assess data quality and to perform EDA by using DataRobot's features. We saw
    how DataRobot makes it very easy to explore data, set up target features, and
    perform correlation (or, more accurately, association analysis).
  prefs: []
  type: TYPE_NORMAL
- en: We learned how to leverage DataRobot's output to gain a better understanding
    of our problem and dataset, and then how to create feature lists to be used in
    model building. You could do these tasks in Python or R and they are not very
    difficult, but they do consume some time. This time is better served in focusing
    on understanding the problem and the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will jump into something that most of you must be waiting
    for: building models.'
  prefs: []
  type: TYPE_NORMAL
