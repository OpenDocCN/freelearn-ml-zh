["```py\nval schema = StructType(Array(\n    StructField(\"state_code\", StringType, true),\n    StructField(\"account_length\", IntegerType, true),\n    StructField(\"area_code\", StringType, true),\n    StructField(\"international_plan\", StringType, true),\n    StructField(\"voice_mail_plan\", StringType, true),\n    StructField(\"num_voice_mail\", DoubleType, true),\n    StructField(\"total_day_mins\", DoubleType, true),\n    StructField(\"total_day_calls\", DoubleType, true),\n    StructField(\"total_day_charge\", DoubleType, true),\n    StructField(\"total_evening_mins\", DoubleType, true),\n    StructField(\"total_evening_calls\", DoubleType, true),\n    StructField(\"total_evening_charge\", DoubleType, true),\n    StructField(\"total_night_mins\", DoubleType, true),\n    StructField(\"total_night_calls\", DoubleType, true),\n    StructField(\"total_night_charge\", DoubleType, true),\n    StructField(\"total_international_mins\", DoubleType, true),\n    StructField(\"total_international_calls\", DoubleType, true),\n    StructField(\"total_international_charge\", DoubleType, true),\n    StructField(\"total_international_num_calls\", DoubleType, true),\n    StructField(\"churn\", StringType, true)))\n```", "```py\ncase class CustomerAccount(state_code: String, account_length: Integer, area_code: String, \n                 international_plan: String, voice_mail_plan: String, num_voice_mail: Double, \n                 total_day_mins: Double, total_day_calls: Double, total_day_charge: Double, \n                 total_evening_mins: Double, total_evening_calls: Double, total_evening_charge: Double, \n                 total_night_mins: Double, total_night_calls: Double, total_night_charge: Double,  \n                 total_international_mins: Double, total_international_calls: Double, \n                 total_international_charge: Double, total_international_num_calls: Double, churn: String)\n```", "```py\nimport spark.implicits._\n```", "```py\nval trainSet: Dataset[CustomerAccount] = spark.read.\n    option(\"inferSchema\", \"false\")\n    .format(\"com.databricks.spark.csv\")\n    .schema(schema)\n    .load(\"data/churn-bigml-80.csv\")\n    .as[CustomerAccount]\ntrainSet.printSchema()\n```", "```py\ntrainSet.show()\n```", "```py\nval statsDF = trainSet.describe()  \nstatsDF.show()\n```", "```py\ntrainSet.cache()\n```", "```py\ntrainSet.groupBy(\"churn\").sum(\"total_international_num_calls\").show()\n```", "```py\n+-----+----------------------------------+\n |churn|sum(total_international_num_calls)|\n +-----+----------------------------------+\n |False|                            3310.0|\n |True |                             856.0|\n +-----+----------------------------------+\n```", "```py\ntrainSet.groupBy(\"churn\").sum(\"total_international_charge\").show()\n```", "```py\n +-----+-------------------------------+\n |churn|sum(total_international_charge)|\n +-----+-------------------------------+\n |False|              6236.499999999996|\n | True|                        1133.63|\n +-----+-------------------------------+\n```", "```py\nval testSet: Dataset[CustomerAccount] = spark.read\n      .option(\"inferSchema\", \"false\")\n      .format(\"com.databricks.spark.csv\")\n      .schema(schema)\n      .load(\"data/churn-bigml-20.csv\")\n      .as[CustomerAccount]\n```", "```py\ntestSet.cache()\n```", "```py\ntrainSet.createOrReplaceTempView(\"UserAccount\") \nspark.catalog.cacheTable(\"UserAccount\")\n```", "```py\ntrainSet.groupBy(\"churn\").count.show()\n```", "```py\n +-----+-----+\n |churn|count|\n +-----+-----+\n |False| 2278|\n | True| 388 |\n +-----+-----+\n```", "```py\nval fractions = Map(\"False\" -> 0.1675, \"True\" -> 1.0)\n```", "```py\nval churnDF = trainSet.stat.sampleBy(\"churn\", fractions, 12345L)\n```", "```py\nchurnDF.groupBy(\"churn\").count.show()\n```", "```py\n +-----+-----+\n |churn|count|\n +-----+-----+\n |False|  390|\n | True|  388|\n +-----+-----+\n```", "```py\nspark.sql()(\"SELECT churn, SUM(total_day_charge) as TDC, \n                                    SUM(total_evening_charge) as TEC, SUM(total_night_charge) as TNC, \n                                    SUM(total_international_charge) as TIC, \n                                    SUM(total_day_charge) + SUM(total_evening_charge) +  \n                                    SUM(total_night_charge) + SUM(total_international_charge) \n                    as Total_charge FROM UserAccount GROUP BY churn \n                    ORDER BY Total_charge DESC\").show()\n```", "```py\nspark.sql()(\"SELECT churn, SUM(total_day_mins) + \n                    SUM(total_evening_mins) + \n                    SUM(total_night_mins) + \n                    SUM(total_international_mins) as Total_minutes \n                    FROM UserAccount GROUP BY churn\")\n                .show()\n```", "```py\nval trainDF = churnDF\n    .drop(\"state_code\")\n    .drop(\"area_code\")\n    .drop(\"voice_mail_plan\")\n    .drop(\"total_day_charge\")\n    .drop(\"total_evening_charge\")\n```", "```py\ntrainDF.select(\"account_length\", \"international_plan\", \"num_voice_mail\", \n                \"total_day_calls\",\"total_international_num_calls\", \"churn\")\n             .show(10)\n```", "```py\nval ipindexer = new StringIndexer()\n      .setInputCol(\"international_plan\")\n      .setOutputCol(\"iplanIndex\")\n\nval labelindexer = new StringIndexer()\n      .setInputCol(\"churn\")\n      .setOutputCol(\"label\")\n```", "```py\nval featureCols = Array(\"account_length\", \"iplanIndex\", \"num_voice_mail\", \n                        \"total_day_mins\", \"total_day_calls\", \"total_evening_mins\", \n                        \"total_evening_calls\", \"total_night_mins\", \"total_night_calls\", \n                        \"total_international_mins\", \"total_international_calls\", \n                        \"total_international_num_calls\")\n```", "```py\nval assembler = new VectorAssembler()\n      .setInputCols(featureCols)\n      .setOutputCol(\"features\")\n```", "```py\nval numFolds = 10\nval MaxIter: Seq[Int] = Seq(100)\nval RegParam: Seq[Double] = Seq(1.0) // L2 regularization param set 1.0 with L1 reg. to reduce overfitting\nval Tol: Seq[Double] = Seq(1e-8)// for convergence tolerance for iterative algorithms\nval ElasticNetParam: Seq[Double] = Seq(0.0001) //Combination of L1 & L2\n```", "```py\nval lr = new LogisticRegression()\n         .setLabelCol(\"label\")\n         .setFeaturesCol(\"features\")\n```", "```py\nval pipeline = new Pipeline()\n            .setStages(Array(PipelineConstruction.ipindexer,\n                  PipelineConstruction.labelindexer,\n                        PipelineConstruction.assembler, lr))\n```", "```py\nval paramGrid = new ParamGridBuilder()\n      .addGrid(lr.maxIter, MaxIter)\n      .addGrid(lr.regParam, RegParam)\n      .addGrid(lr.tol, Tol)\n      .addGrid(lr.elasticNetParam, ElasticNetParam)\n      .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\nval crossval = new CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predDF= cvModel.transform(Preprocessing.testSet)\nval result = predDF.select(\"label\", \"prediction\", \"probability\")\nval resutDF = result.withColumnRenamed(\"prediction\", \"Predicted_label\")\nresutDF.show(10)\n```", "```py\nval accuracy = evaluator.evaluate(predDF)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nClassification accuracy: 0.7679333824070667\n```", "```py\nval predictionAndLabels = predDF\n      .select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n      .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve : \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.5770932703444629\nArea under the receiver operating characteristic (ROC) curve: 0.7679333824070667\n```", "```py\nval tVSpDF = predDF.select(\"label\", \"prediction\") // True vs predicted labels\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval tn = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval fp = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\nval fn = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\n\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\n```", "```py\nTrue positive rate: 66.71664167916042%\nFalse positive rate: 19.04047976011994%\nTrue negative rate: 10.944527736131935%\nFalse negative rate: 3.2983508245877062%\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn))\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```", "```py\nval nb = new NaiveBayes()\n      .setLabelCol(\"label\")\n      .setFeaturesCol(\"features\")\n```", "```py\nval pipeline = new Pipeline()\n      .setStages(Array(PipelineConstruction.ipindexer,\n        PipelineConstruction.labelindexer,\n        PipelineConstruction.assembler,nb))\n```", "```py\n val paramGrid = new ParamGridBuilder()\n      .addGrid(nb.smoothing, Array(1.0, 0.1, 1e-2, 1e-4))// default value is 1.0\n      .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\nval crossval = new CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predDF = cvModel.transform(Preprocessing.testSet)\n```", "```py\nval accuracy = evaluator.evaluate(predDF)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nClassification accuracy: 0.600772911299227\n```", "```py\nval predictionAndLabels = predDF.select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n        .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)\nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve : \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.44398397740763046\nArea under the receiver operating characteristic (ROC) curve: 0.600772911299227\n```", "```py\nval tVSpDF = predDF.select(\"label\", \"prediction\") // True vs predicted labels\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval tn = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval fp = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\nval fn = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\n\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\n```", "```py\nTrue positive rate: 66.71664167916042%\nFalse positive rate: 19.04047976011994%\nTrue negative rate: 10.944527736131935%\nFalse negative rate: 3.2983508245877062%\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn))\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```", "```py\nval numFolds = 10\nval MaxIter: Seq[Int] = Seq(100)\nval RegParam: Seq[Double] = Seq(1.0) // L2 regularization param, set 0.10 with L1 regularization\nval Tol: Seq[Double] = Seq(1e-8)\nval ElasticNetParam: Seq[Double] = Seq(1.0) // Combination of L1 and L2\n```", "```py\nval svm = new LinearSVC()\n```", "```py\nval pipeline = new Pipeline()\n      .setStages(Array(PipelineConstruction.ipindexer,\n        PipelineConstruction.labelindexer,\n        PipelineConstruction.assembler,svm))\n```", "```py\nval paramGrid = new ParamGridBuilder()\n      .addGrid(svm.maxIter, MaxIter)\n      .addGrid(svm.regParam, RegParam)\n      .addGrid(svm.tol, Tol)\n      .addGrid(svm.elasticNetParam, ElasticNetParam)\n      .build()\n```", "```py\nval evaluator = new BinaryClassificationEvaluator()\n                  .setLabelCol(\"label\")\n                  .setRawPredictionCol(\"prediction\")\n```", "```py\nval crossval = new CrossValidator()\n      .setEstimator(pipeline)\n      .setEvaluator(evaluator)\n      .setEstimatorParamMaps(paramGrid)\n      .setNumFolds(numFolds)\n```", "```py\nval cvModel = crossval.fit(Preprocessing.trainDF)\n```", "```py\nval predDF= cvModel.transform(Preprocessing.testSet)\npredDF.show(10)\n```", "```py\nval accuracy = evaluator.evaluate(predDF)\nprintln(\"Classification accuracy: \" + accuracy)\n```", "```py\nClassification accuracy: 0.7530180345969819\n```", "```py\nval predictionAndLabels = predDF\n      .select(\"prediction\", \"label\")\n      .rdd.map(x => (x(0).asInstanceOf[Double], x(1)\n      .asInstanceOf[Double]))\n```", "```py\nval metrics = new BinaryClassificationMetrics(predictionAndLabels) \nprintln(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\nprintln(\"Area under the receiver operating characteristic (ROC) curve : \" + metrics.areaUnderROC)\n```", "```py\nArea under the precision-recall curve: 0.5595712265324828\nArea under the receiver operating characteristic (ROC) curve: 0.7530180345969819\n```", "```py\nval tVSpDF = predDF.select(\"label\", \"prediction\") // True vs predicted labels\nval TC = predDF.count() //Total count\n\nval tp = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval tn = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter($\"label\" === $\"prediction\")\n            .count() / TC.toDouble\n\nval fp = tVSpDF.filter($\"prediction\" === 1.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\nval fn = tVSpDF.filter($\"prediction\" === 0.0)\n            .filter(not($\"label\" === $\"prediction\"))\n            .count() / TC.toDouble\n\nprintln(\"True positive rate: \" + tp *100 + \"%\")\nprintln(\"False positive rate: \" + fp * 100 + \"%\")\nprintln(\"True negative rate: \" + tn * 100 + \"%\")\nprintln(\"False negative rate: \" + fn * 100 + \"%\")\n```", "```py\nTrue positive rate: 66.71664167916042%\nFalse positive rate: 19.04047976011994%\nTrue negative rate: 10.944527736131935%\nFalse negative rate: 3.2983508245877062%\n```", "```py\nval MCC = (tp * tn - fp * fn) / math.sqrt((tp + fp) * (tp + fn) * (fp + tn) * (tn + fn))\nprintln(\"Matthews correlation coefficient: \" + MCC)\n```"]